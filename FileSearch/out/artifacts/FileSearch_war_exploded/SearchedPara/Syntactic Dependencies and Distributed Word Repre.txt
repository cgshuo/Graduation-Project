 Relational similarity measures the correspondence between word-word relations (Medin et al., 1990). It is relevant to many tasks in NLP (Turney, 2006), such as word sense disambiguation, information extraction, question answering, information re-trieval, semantic role identification and metaphor detection. Typical tasks on relational similarity in-clude analogy detection , which measures the de-gree of relational similarities, and analogy mining , which extracts analogous word pairs from unstruc-tured text.

Recently, distributed word representations (i.e. embeddings ) (Mikolov et al., 2013a; Mikolov et al., 2013b; Levy and Goldberg, 2014b) have been used for unsupervised analogy detection. Mikolov et al. use attributional similarities between words in a relation to compute relational similarities, and show that the method outperforms the best sys-tem in the SemEval 2012 shared task on analo-gy detection. Levy and Goldberg (2014b) fur-ther improve Mikolov X  X  relational similarity mea-sure method using novel arithmetic combination-s of attributional similarities. For simplicity, we call the method of Mikolov et al. embedding-based analogy detection , without stressing the dif-ference between distributed and distributional (i.e. counting-based) word representations.

Most work on embedding-based analogy detec-tion uses relational similarities as a measure of the quality of embeddings. However, relatively little has been done in the opposite direction, exploring how to leverage embeddings for improving rela-tional similarity algorithms. We empirically study the use of word embeddings for Chinese analogy detection and mining, leveraging syntactic depen-dencies, which has been shown to be closely asso-ciated with semantic relations (Levin, 1993; Chi-u et al., 2007). Compared with many other lan-guages, this association is particularly strong for Chinese, which is fully configurational and lack-s morphology. To our knowledge, relatively little work has been reported on Chinese relational sim-ilarities, compared to other tasks in Chinese NLP, including syntactic parsing, information extraction and machine translation.

We work on three specific problems. First, we study the effect of dependency-based word em-beddings for analogy detection. There are two variations of Mikolov et al X  X  skip-gram embed-ding model, one training the distributed word rep-resentation of a word using its context words in local ngram window (Mikolov et al., 2013a), and the other training the distributed representation of a word using words in a syntactic dependency context (Levy and Goldberg, 2014b; Bansal et al., 2014). The latter has attracted much recent atten-tion due to its potential in capturing more syntac-tic regularities. It has been shown to outperfor-m the former in a variety of NLP tasks, and can potentially also improve relation similarity. Our experiments on both English and Chinese show that the dependency-context embeddings consis-tently under-perform ngram-context embeddings. We give some theoretical justifications to the find-ings.

Second, we propose to use syntactic depen-dencies as a context for improving embedding-based analogy detection, pruning the search space and filtering noise using syntactic dependencies. While highly useful for measuring relational sim-ilarities, attributional similarities between words are not the only source of information for analo-gy detection. Traditional methods, such as Tur-ney and Littman (2005), Turney (2006), Chiu et al. (2007) and  X  O S  X  eaghdha and Copestake (2009), also leverage context between word pairs in a corpus for better accuracies, which the current embedding-based methods ignore. Results show that our proposed method achieves significant im-provements for this task.

Third, we show that a novel distributed repre-sentation of syntactic dependencies between word pairs can be used to mine analogous dependencies from a large Chinese corpus. Inspired by the fact that distributed word representations can be used to measure word similarities, we use our distribut-ed dependency representations to measure relation similarities. We propose a bootstrapping algorith-m for analogy mining using dependency embed-dings, and experiments on a large Chinese corpus show that the method can achieve a precision of 95.2% at a recall of 56.8%.

Our automatically-parsed corpus, trained em-beddings and evaluation datasets are released publicly at http://people.sutd.edu.sg/  X  yue_zhang/publication.html . To our knowledge, we are the first to present results on Chinese analogy detection and to release large-scale Chinese word embeddings. 2.1 Relational Similarity Tasks There are three main tasks for relational similarity. This first is relation classification , which has been used in Task 2 of SemEval 2012 (Jurgens et al., 2012). In this task, all four words in two word pairs are given, and one needs to judge whether Figure 1: Dependency tree of the sentence  X 1991 c (in 1991)  X  (,) cn  X  (Obama) o  X  (President) .  X  (graduate) u (from) M  X  (Har-vard) {  X  (Law School) X . they belong to a same relation type. In order to address this task, various supervised methods have been used (Bollegala et al., 2008; Herda  X  gdelen and Baroni, 2009; Turney, 2013).

The second task is analogy detection (Mikolov et al., 2013b), which takes three words in two word pairs, and searches for a most suitable word from the vocabulary to recover the hidden word. This task has been addressed using word embed-dings (Mikolov et al., 2013b; Levy and Goldberg, 2014b).

The third task is analogy mining (Chiu et al., 2007), which takes one word pair belonging to a certain semantic relation as a seed, and searches for all the word pairs that share the same relation with the seed. Compared with relation classifi-cation and analogy detection, analogy mining can be practically more useful because it requires less given information, and provides a large quantity of analogous word pairs automatically. 2.2 Skip-gram Word Embeddings As a by-product of neural language models (Ben-gio et al., 2003; Mnih and Hinton, 2007), word embeddings are distributed vector representations of words, trained using local contexts. They cap-ture linguistic regularities in languages (Mikolov et al., 2013b) and have been used in various tasks (Collobert and Weston, 2008; Turian et al., 2010; Socher et al., 2011).

In this paper, we apply the Skip-gram method of Mikolov et al. (2013a) for training embed-dings, which works by maximizing the probabil-ity of a word given a context of multiple words. Mikolov et al. (2013b) use an ngram window as the context, and observe that the resulting embed-dings are highly useful for unsupervised analogy detection. 2.3 Embedding-based Analogy Detection Formally, the task of analogy detection is to find a word b* given a pair of words a:b and a word a* such that a*:b* is analogous to a:b . Mikolov et al. (2013b) show that the task can be solved by finding a word that maximizes: where sim is a similarity measure, typically the cosine function. Levy and Goldberg (2014b) show that the Equation 1 is equivalent to: score = cos ( b  X  ,b )  X  cos ( b  X  ,a )+ cos ( b  X  ,a  X  ) (2) As a result, the goal of analogy detection is to find a word b* which is similar to b and a* but differ-ent from a . Levy and Goldberg (2014b) further propose to substitute the addictive functions in E-quation 2 with multiplicative functions: Here  X  = 0 . 001 is used to prevent division by zero. Their experiments show that the use of Equation 3 can improve the state-of-the-art. Following Levy and Goldberg (2014b), we refer to Equation 1 and 2 as 3COSADD and Equation 3 as 3COSMUL, respectively. 2.4 Chinese Relational Similarity There are various types of relational similarities. Syntactically, inflections can be treated as a type of word-word relation (Mikolov et al., 2013b). For example, the comparative pairs  X  X ood:better X  and  X  X ough:rougher X  are analogous, and the past tense inflections  X  X ee:saw X  and  X  X eturn:returned X  are analogous. However, such inflectional rela-tions do not apply to Chinese, which is fully con-figurational and lacks morphology. Consequent-ly, our main focus is semantic similarities, which include antonymy (e.g. ( 9 (hot): e (cold)) VS (
 X  (fast):  X  (slow))), meronymy (e.g. (  X  (car):  X  f (wheel)) VS ( = (bear):  X  (paw))), gender (e.g. (
I &lt; (man):  X  &lt; (woman)) VS ( I (king):  X  (clothing): B (wear)) VS ( l f (hat):  X  (wear))), etc.

Chiu et al. (2007) show that English semantic relations are also reflected by syntactic dependen-cies. Their finding coincides with Levin (1993), who study English verbs. We find that this obser-vation is even more prevalent for Chinese. In our automatically-parsed Chinese corpus of 3.4 bil-lion words (Section 5.1), 86.4% word pairs from the analogy test dataset (Section 5.2) have corre-sponding dependencies, each of which appearing at least ten times.

The frequent correlation between semantic re-lations and syntactic dependencies can be due to the lack of morphology and function words in Chinese. In fact, Chinese syntactic ambigui-ties often need to be resolved by leveraging se-mantic information (Xiong et al., 2005; Zhang et al., 2014). Although not all occurrences of semantically-related word pairs must also form a syntactic dependency in a corpus, we show that syntactic dependencies can effectively improve analogy detection. A first use of syntactic dependencies for embedding-based analogy detection is to use them directly for embeddings. Recently, a depen-dency context has been used for the skip-gram method, for capturing more syntactic regularities. Taking the sentence in Figure 1 for example, a bi-gram context for the word  X  .  X  (graduate) X  can be  X  cn  X  (Obama), o  X  (President), u (from), M  X  (Harvard) X , while a dependency context of the same word can be  X 1991 c /ADV, o  X  /SBV, u /CMP, {  X  /POB u  X  1 , where  X  X DV, SBV, CMP, POB X  indicate adverbial modifier, subject, complement and prepositional object, respectively.

It has been shown that a dependency context leads to embeddings that better help parsing (Bansal et al., 2014) and measuring word sim-ilarity (Levy and Goldberg, 2014a), compared with ngram contexts. However, little previous work has systematically compared dependency contexts with ngram contexts in analogy detec-tion. We empirically study this problem (c.f Sec-tion 6.3), finding that dependency context lead-s to significantly worse analogy detection results for both Chinese and English using state-of-the-art embedding-based methods (Levy and Goldberg, 2014b). We give analysis in Section 6.4. We study an alternative way of making use of syn-tactic dependencies, by using them to prune the vocabulary-sized search space of analogy detec-tion. Given two word pairs a:b and a*:b* , where b* is hidden and a is the head word, we search for dependencies, taking a* as the head word. The dependent words in the search candidates need to share the POS tag of b . If there are several type-s of dependencies between a and b , only the one with highest frequency is used. We rank all result-ing dependencies using the 3COSMUL objective, and take the word b* in the highest-scored depen-dencies as the answer.

For example, given the word pair ( i . 9  X  (Sarajevo):  X   X  (Bosnia and Herzegovina) ), whose most frequency dependency is &lt; i . 9  X  (Sarajevo),  X   X  (Bosnia and Herzegovina), ATT &gt; , and the unknown pair (  X   X  (London):b* ), we acquire a list of dependencies, including &lt;  X   X  (London), { I (USA), ATT &gt; , &lt;  X   X  (Lon-don), n i (Paris), COO &gt; , &lt;  X   X  (London), \ &lt;  X  (Canada), ATT &gt; and &lt;  X   X  (London), = I (England), ATT &gt; . Some of these dependencies, such as &lt;  X   X  (London), n i (Paris), COO &gt; , are parsed as the coordinate relation (COO), and thus pruned because the target syntactic relation is ATT . From the resulting list, the 3COSMUL ob-jective successfully ranks the triple &lt;  X   X  (Lon-don), = I (England), ATT &gt; as the top candidate. In contrast, Levy and Goldberg X  X  method takes  X  H  X  (South Africa) X  as the answer, which does not form an attributive-head phrase with  X   X   X  (Lon-don) X . Formally, analogy mining is the task of mining analogous dependencies &lt;x 1 ,y 1 ,r&gt; , &lt;x 2 ,y 2 ... &lt;x n ,y n ,r&gt; that share the same relation r with a given dependency &lt;a,b,r&gt; . We mine analo-gous dependencies by considering relational sim-ilarity and attributional similarity simultaneously using the skip-gram model for embeddings. 5.1 Dependency Embedding Inspired by the fact that word similarities can be measured by using distributed word representa-tions, we hypothesize that relation similarities can
Algorithm 1: Bootstrapping for analogy mining. be measured by distributed relation representa-tions. Based on the observation in Section 2.4, semantically analogous word pairs typically have syntactic dependencies. We use the skip-gram al-gorithm to train distributed representations of syn-tactic dependencies , and use them for mining anal-ogous word pairs.

With respect to the skip-gram model, words are the most common target for embeddings (Levy and Goldberg, 2014b; Levy and Goldberg, 2014a; Mikolov et al., 2013a), although continuous vec-tor representations can be trained for other struc-tures. For example, Mikolov et al. (2013a) take idiomatic phrases as embedding targets. Depen-dencies , which consist of a modifier word, a head word and a syntactic relation between them, can also be represented by continuous embeddings us-ing the same algorithm.

To induce dependency embeddings, we take the union of the dependency context of both the dependent and the head of a dependency as the context. For instance, in the example sentence, the context of the dependency &lt; o  X  (Presiden-t), .  X  (graduate), SBV &gt; consists of four to-kens:  X 1991 c /ADV X ,  X  cn  X  /ATT X ,  X  u /CMP X  and  X  {  X  /POB u  X . The same skip-gram algo-rithm is used to train embeddings for dependency structures. 5.2 Analogy Mining by Bootstrapping A bootstrapping algorithm is used to mine anal-ogous word pairs based on dependency-context word embeddings and dependency embeddings. Algorithm 1 shows pseudocode of the recursive bootstrapping algorithm.

The recursive function Mine (Algorithm 1) contains three steps with six parameters, includ-ing the dependency embeddings DT , word embed-dings DW , a seed dependency s , and two thresh-olds  X  and  X  . Step 1 (lines 3 to 5) is an initial-ization process, where the dependency embedding is used to return up to 100 most similar dependen-cies for the given seed s . These dependencies are stored in SimDT , and the candidate analogous de-pendency set DTSet is initialized to an empty set.
In Step 2 (lines 6 to 16), an analogous score S-coreXY is computed for each dependency Triple in SimDT by multiplying the similarity scores be-tween the two dependents and the two heads in Triple and s , respectively. Triple is stored into the set DTSet if ScoreXY is ranked top  X  . The top 1 score in DTSet is referred to as MScore . In Step 3 (lines 17 to 24), if the score of a dependency Triple in DTSet is larger than  X   X  MScore , it is used as a new seed for mining more analogous dependen-cies, by calling the function Mine recursively.
We take the seed dependency &lt; (play), g  X  (piano), VOB &gt; as an example to illustrate the work-flow of the Mine function. In Step 1, a set of similar dependencies (e.g., &lt; (play), 3  X  (gui-tar), VOB &gt; , &lt; (play),  X  (lyra), VOB &gt; ), is cal-culated using the dependency embeddings DT and stored in SimDT . Each dependency in SimDT is s-cored in Step 2, and the top  X  scores are put into the set DTSet . Finally, a dependency is used as seed to mine new analogous dependencies if its s-core is larger than a threshold (  X   X  MScore ). For instance, the dependency &lt; (play),  X  (lyra), VOB &gt; is used to mine the new dependency &lt; (play), 8 (zheng), VOB &gt; , which is then used to mine other dependencies such as &lt; N (blow),  X  j (cucurbit flute), VOB &gt; and &lt; N (blow), i  X  d (sax), VOB &gt; . 6.1 Word Embeddings We train three sets of word embeddings: NG5 (n-gram context with 5 words to the left of the target word and 5 words to the right), NG2 (2 words to the left and right) and DEP (dependency context), and one set of dependency embeddings DT (de-pendency context), using the Skip-Gram model. negative-sampling parameter is set to 15 in all the training processes.

All embeddings are trained on a free Chinese s sentences and 3.4 billions words. We segment and parse these sentences using the MVT imple-which is trained on a large-scale annotated cor-pus and achieves state-of-the-art analyzing accu-Targets and contexts for word and dependency em-beddings were filtered with a minimum frequency of 100 and 10, respectively, and all the four types of embeddings are trained with 200 dimensions. 6.2 Datasets and Evaluation Metrics Three datasets are used for evaluating Chinese embeddings. First, we construct a set of se-mantic analogy questions. This set contains five types of semantic analogy questions, including capital-country (136 word pairs, and 18354 anal-ogy questions), provincial capital-province (28, 756), city-province (637, 386262), family mem-ber (male-female) (18, 306) and currency-country (62, 3782). We collect the five types of word pairs and then produce analogy questions automatical-ly by concatenating two word pairs. The resulting analogy dataset contains 400K analogy question-s. We refer to this dataset as the Chinese Analogy Question Set (CAQS).
Because embeddings are central for analogy de-tection, yet there is little large-scale evaluation results on Chinese embeddings in the literature, we perform embedding evaluation on two dataset-s. The first one is the Chinese WordSim (CWS), translated from the English WordSim-353 Set and re-scored by native Chinese speakers (Jin and Wu, 2012). This dataset consists of 297 word pairs. The second one is the Chinese thesaurus Tongyicicilin (Cilin) (Che et al., 2010), which groups 74,000 Chinese words into five-layer hi-erarchies and has been used for evaluating the accuracy of word similarity by traditional sparse vector space models (Qiu et al., 2011; Jin et al., 2012). The third level of Cilin , which contain-s 1428 classes, is used to evaluate whether two words are semantically similar.

For comparison between Chinese and English, we also use an English analogy question dataset, valuate the English word embeddings of Levy and
On both the CAQS and the Google dataset-s, the 3COSMUL method (Levy and Goldberg, 2014b) is used to to answer analogy questions based on given embeddings. The results on the CWS dataset are evaluated using the two standard metrics for the task, namely Spearman X  X   X  and K-endall X  X   X  rank correlation coefficients. The re-sults on Cilin are evaluated using Precision@ K : the percentage of words from the top-K candidates that belong to the Cilin category of the target word. If one of the top-K candidates belongs to the same third-level category in Cilin as the target word, the candidate word is taken as correct. 6.3 Dependency-based and Word-based Word Similarity Table 2: Results on CAQS. MUL and IMP indi-cate 3COSMUL and our improved method, re-spectively.

Table 1 shows the results of the three Chinese embedding on Cilin and CWS, where NG2 per-forms much better than NG5 on both datasets. This demonstrates that one does not need to use large window sizes in training word-based embed-dings for capturing word similarities. The result is similar to the finding of Shi et al. (2010), which indicates that a window size of 2 is better than a window size of 4 for capturing word similarity by using distributional word representations.
 DEP performs slightly worse than NG2 on CWS and Cilin in P@1 and P@5. However, it achieves better results on Cilin in P@10 to P@100 when more candidate similar words are evaluated. In contrast, NG5 and NG2 mix more semantically related words. This finding is consistent with that of Levy and Goldberg (2014a).
 Analogy Detection
Table 2 shows the results of the three Chinese embeddings on CAQS. Unlike on Cilin and CWS, NG5 outperforms DEP, and is also slightly better than NG2. Similar tendency is shown in Table 3 for the three English embeddings evaluated on the Google dataset. These results show that dependen-cy embeddings are relatively weak for answering analogy questions. On the other hand, the perfor-mance also varies across different relation types. 6.4 Analysis To analyze the difference between the three Chi-nese embeddings methods qualitatively, we man-ually inspect the words  X  B (wear) X ,  X  '  X  (Guan Yu, a person name in the novel  X  n I  X   X  (Romance of the three kingdoms)  X ) X , and  X  x X  (Zhengzhou, a city) X . Their most similar words are shown in Table 4.
 Word Similarity
For the word  X  B (wear) X , both NG5 and NG2 yield similar words such as  X  B (wear) X ,  X  X (wear) X ,  X   X  (wear) X  and related words such as  X   X   X  (shorts) X ,  X  ; (slim-fit) X ,  X  @ (coat) X ,  X  * f (skirt) X , although NG5 gives more related words. In contrast, DEP gives only words that are similar both syntactically and semantically. This observation holds for other verbs and nouns, and can be explained by the context extraction method-s. For instance, the word  X  B (wear) X  usually takes one of the words  X   X   X  (shorts) X ,  X  @ (coat) X ,  X  * f (skirt) X  as its object, and thus shares sim-ilar contexts with them in NG5 and NG2. The context extraction method in DEP, on the oth-er hand, yields different context across syntactic roles, such as verbs (e.g.  X  B (wear) X ) and their objects (e.g.  X   X   X  (shorts) X  and  X  @ (coat) X ). Observations on the person name  X  '  X  (Guan Yu) X  and location  X  x X  (Zhengzhou) X  are simi-lar. For  X  '  X  (Guan Yu) X , NG5 and NG2 can yield more person names in the same novel, while DEP yields person names from other novels (i.e.  X   X  &amp; (Hanxin) X  and  X  C ?  X  (Asura) X ). For  X  x  X  (Zhengzhou) X , the provincial capital of  X   X  H (Henan) X , NG5 and NG2 give more cities in the same province  X   X  H (Henan) X , while DEP yields capitals of other provinces.
 Analogy Detection
As mentioned in Section 2.3, both 3COSADD and 3COSMUL seek a word b  X  that is similar to b and a  X  but dissimilar to a . Ideally, the two word pairs b : b  X  and a : a  X  should be semantically similar while the two word pairs a : b and a  X  : b  X  should be semantically related . Therefore, 3COSADD and 3COSMUL require the embeddings to give high-er cosine scores for both semantically similar and related words.

Our analysis above shows that word-context embeddings tend to mix semantically related and similar words, but dependency-context embed-dings only capture semantic similarity . This partly explains the reason that dependency-context word embeddings are weak for analogy detection.

It has also been shown in Section 6.3 that the performances of analogy detection vary across dif-ferent types of relations, which indicates that there are more sophisticated underlying factors. One in-tuitive explanation is that different semantic rela-tions correspond to different syntactic dependency structures. For example, the male-female family member relation is expected to stand less frequent-ly in a syntactic dependency relation, compared with geographic relations such as city-country, which stand frequently in attributional syntactic relations (e.g.  X  X ondon, England X ). As a result, where the coupling between syntactic and seman-tic relations is weak, our analysis in Section 6.3 and other work based on syntactic relations can find limitations. 6.5 Syntactic Dependencies for Improved The results on CAQS using the method in Section 4 are shown in the IMP rows of Table 2. The method achieves significant improvements (from 80.0% to 90.9% using NG5) compared with Levy and Goldberg X  X  method. In addition, DEP al-so performs significantly better than with MUL, with an increase from 22.0% to 89.8%. The main reason for this improvement is that the filtering process using syntactic dependencies successfully prunes noisy words.
Error analysis shows that the main errors by the improved method are quite different from those by the baseline. For instance, the main errors of Levy and Goldberg X  X  method for the city-province relation are caused by giving another province as the answer, while the improved method gives the name of the country as answer. This is because ir-relevant provinces do not co-occur frequently with the city in syntactic dependencies, and hence can be filtered by our method. On the other hand, both the country name and province name co-occur fre-quently with the city name in syntactic dependen-cies, and our method cannot make a choice be-tween them. 6.6 Dependency Structure Embeddings for Shown in Table 5, we use six seeds to mine anal-ogous dependencies. The first seed is used for de-velopment and the others for test. The first three seeds, the fourth seed and the last two seeds be-long to the Use:Thing, Produce:Thing and Sub-Location:Location relations, respectively.  X  and  X  are set to 20, and 0.6, respectively. Each set of mined dependencies together with the seed depen-dency and relation type is shown to two human evaluators, who are required to give a Yes/No an-swer to each dependency in the set. We take the average scores of the two evaluators (the average inter-annotator agreement is 0.95) as the final pre-cision scores.

As shown in the table, the precisions using dif-ferent seeds are quite different, ranging from 40% to 96%. One possible reason is that different rela-tions have different numbers of analogous depen-dencies, ranging from dozens to thousands, and thus the fixed thresholds tuned on a development seed does not apply as effectively to all test cas-es. For instance,  X  (play) X  and its analogous ac-tions,  X  N (blow) X  and  X  . (play) X , are all human actions on musical instruments, while the action-s  X   X  (eat) X  and  X  (write) X  can apply to many patients. For the seed &lt; (play), g  X  (piano), VOB &gt; , irrelevant results such as &lt; &lt; (use), f (scissors), VOB &gt; and &lt; &lt; (use), &gt;  X  (flash-light), VOB &gt; , have the verb  X  &lt; (use) X , which is also a human action, yet cannot be considered as usage of the patients  X  } f (scissors) X  and  X  &gt;  X  (flashlight) X . Because of the stricter selectional preference of  X  (play) X , its precision of analogy mining is lower.

We tentatively measure the recall of the algo-rithm by taking the first three types of word pairs in CAQS as the gold set, which contains 801 word pairs. All the three types of word pairs belong to the relation Sub-Location:Location . The recall is computed as the percentage of the gold word pairs covered by the mined dependencies. When us-ing the two seeds &lt; ...  X  (Wuhan), (Hubei), ATT &gt; and &lt;  X  (Beijing),  X  I (China), ATT &gt; for analogy mining, the recalls are 50.2% and 11.3%, respectively. Their union recall is 56.8%. When the precision of each seed is similar, we can achieve better recall without precision loss by us-ing more seeds. Turney (2006) introduces a latent relational anal-ysis (LRA) model to measure relational similari-ty, and apply a novel co-occurrence-based method for analogy filtering. The model can be used for both analogy detection and relation classifi-cation, yet cannot scale up well to large dataset-s due to the complexity of Singular Value De-composition. Recently, distributed word repre-sentations using the skip-gram model (Mikolov et al., 2013a) has been shown to give competi-tive results on analogy detection. Levy and Gold-berg (2014a) extends the skip-gram method with dependency-context embeddings. We study the ef-fect of Levy and Goldberg X  X  embeddings on analo-gy detection, and further extend their embeddings to dependency-context dependency structure em-beddings for analogy mining.

Chiu et al. (2007) presents a similarity graph tranversal (SGT) method to mine analogous re-lations from raw English text automatically, us-ing syntactic dependencies to find candidate rela-tions. The method is unsupervised, and can scale up well to large data sets. However, Chiu et al. (2007) mainly focuses on relations between sub-jects and objects because of its word-pair extrac-tion method.  X  O S  X  eaghdha and Copestake (2009) is a supervised method, which combines lexical similarity and relational similarity to classify se-mantic relations. These methods are based on dis-tributional word representation models and fit for classifying noun-noun word pairs. In contrast, our methods are based on distributed word representa-tion models, and can mine noun-noun word pairs as well as verb-noun word pairs. In addition, our analogy mining method is unsupervised, while the methods of both Turney (2006) and  X  O S  X  eaghdha and Copestake (2009) are supervised. We studied several Chinese relational similarity tasks to train embeddings under the context of dis-tributed word representations using the skip-gram model and syntactic dependencies. For Chinese analogy detection, we compared word-context and dependency-context embeddings, finding that the former results in much better accuracies. Observ-ing that common relations in Chinese are frequent-ly represented by syntactic dependencies, we im-proved Chinese analogy detection using a depen-dency context. Further, we empirically studied Chinese analogy mining by proposing a bootstrap-ping algorithm using a novel distributed represen-tation of syntactic dependencies.
 We thank the anonymous reviewers for their con-structive comments, and gratefully acknowledge the support of the Singapore Ministry of Educa-tion (MOE) AcRF Tier 2 grant T2MOE201301, the National Natural Science Foundation of Chi-na (No. 61572245, 61170144, 61103089), Ma-jor National Social Science Fund of China (No. 12&amp;ZD227), Scientific Research Foundation of Shandong Province Outstanding Young Scientist Award (No. BS2013DX020) and Humanities and Social Science Projects of Ludong University (No. WY2013003).

