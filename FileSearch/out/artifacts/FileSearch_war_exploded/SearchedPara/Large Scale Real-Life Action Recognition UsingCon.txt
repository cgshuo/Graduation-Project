 Acceleration sensor based ac tion recognition is useful i n practical applications [1,2,3,4]. For example, in some medical programmes, researchers hope to prevent lifestyle diseases from being exacerbated. However, the traditional way of coun-seling is ineffective both in time and accu racy, because it requires many manual operations. In sensor-ba sed action recognition, an accelerometer is employed (e.g., attached on the wrist of people) to a utomatically captur e the acceleration statistics (e.g., a temporal sequence of t hree-dimension acceler ation data) in the daily life of counselees, and the corresponding categories of behaviors (actions) can be automatically identified with a certain level of accuracy.

Although there is a considerable literature on action recognition, most of the prior work discusses action recognition in a pre-defined limited environment [1,2,3]. It is unclear whether or not the previous methods perform well in a more natural real-life environment. For example, most of the prior work assumes that the beginning and ending time of each action are known to the target recogniz-ing system, and the produced system only performs simple classifications to the action signals [1,2,3]. However, this is not the case for real-life action sequences of human beings, in which different types of actions are performed one by one without an explicit segmentation on the boundaries. For example, people may first walk, and then take a taxi, and then take an elevator, in which the bound-aries of the actions are unknown to the target action recognition system. An example of real-life actions with continuous sensor signals is shown in Figure 1. For this concern, it is necessary and important to develop a more powerful sys-tem not only to predict the types of the actions, but also to disambiguate the boundaries of those actions.

With this motivation, we collected a large-scale real-life action data (continu-ous sensor-based three-dimension acceleration signals) from about one hundred people for continuous real-life action recognition. We adopt a popular structured classification model, conditional random fields (CRFs), for recognizing the ac-tion types and at the same time disambiguate the action boundaries. Moreover, good online training methods are necessary for training CRFs on a large-scale data in our task. We will compare different online training methods for training CRFs on this action recognition data. Most of the prior work on action recognition treated the task as a single-label classification problem [1,2,3]. Given a sequence of sensor signals, the action recog-nition system predicts a single label (rep resenting a type of action) for the whole sequence. Ravi et al. [3] used decision trees, support vector machines (SVMs) and K -nearest neighbors (KNN) models for classification. Bao and Intille [1] and P  X  arkk  X  a et al. [2] used decision trees for classi fication. A few other works treated the task as a structured cla ssification problem. Huynh et al. [4] tried to discover latent activity patterns by using a Bayesian latent topic model.
 Most of the prior work of action recognition used a relatively small data set. For example, in Ravi et al. [3], the data w as collected from two persons. In Huynh et al. [4], the data was collected from only one person. In P  X  arkk  X  a et al. [2], the data was collected from 16 persons.

There are two major approaches for training conditional random fields: batch training and online training. Standard gradient descent methods are normally batch training methods, in which the gradient computed by using all training in-stances is used to update the parameters of the model. The batch training meth-ods include, for example, steepest gradi ent descent, conjugate gradient descent (CG), and quasi-Newton methods like Limited-memory BFGS (LBFGS) [5]. The true gradient is usually the sum of the gradients from each individual training instance. Therefore, batch gradient des cent requires the training method to go through the entire training set before updating parameters. Hence, the batch training methods are slow on training CRFs.

A promising fast online training method is the stochastic gradient method, for example, the stochastic gradient descent (SGD) [6,7]. The parameters of the model are updated much more frequentl y, and much fewer iterations are needed before the convergence. For large-scale data sets, the SGD can be much faster than batch gradient based training methods. However, there are problems on the current SGD literature: (1) The SG D is sensitive to noise. The accuracy of the SGD training is limited when the data is noisy (for example, the data inconsistency problem that we will disc uss in the experiment section). (2) The SGD is not robust. It contains many hyper-parameters (not only regularization, but also learning rate) and it is quite sensitive to them. Tuning the hyper-parameters for SGD is not a easy task.

To deal with the problems of the traditional training methods, we use a new online gradient-based learning method, the averaged SGD with feedback (ASF) [8], for training conditional random fields. According to the experiments, the ASF training method is quite robust for training CRFs for the action recognition task. Many traditional structured classification models may suffer from a problem, which is usually called  X  X he label bias problem X  [9,10]. Conditional random fields (CRFs) are proposed as an alternative solution for structured classification by solving  X  X he label bias problem X  [10]. Assuming a feature function that maps a pair of observation sequence x and label sequence y to a global feature vector f , the probability of a label sequence y conditioned on the observation sequence x is modeled as follows [10,11,12]: where  X  is a parameter vector.

Typically, computing  X  y exp  X   X  f ( y , x ) could be computationally intractable: it is too large to explicitly sum over all possible label sequences. However, if the dependencies between labels have a linear-chain structure, this summation can be computed using dynamic programming techniques [10]. To make the dynamic programming techniques applicable, the dependencies of labels must be chosen to obey the Markov property. More precisely, we use Forward-Backward algorithm for computing the summation in a dynamic programming style. This has a computational complexity of O ( NK M ). N is the length of the sequence; K is the dimension of the label set; M is the length of the Markov order used by local features.

Given a training set consisting of n labeled sequences, ( x i , y i ), for i =1 ...n , parameter estimation is performed by maximizing the objective function, The first term of this equation represents a conditional log-likelihood of a training data. The second term is a regularizer for reducing overfitting. In what follows, we and therefore: 3.1 Stochastic Gradient Descent The SGD uses a small randoml y-selected subset of the t raining samples to ap-proximate the gradient of the objective function given by Equation 3. The num-ber of training samples used for this approximation is called the batch size. By using a smaller batch size, one can update the parameters more frequently and speed up the convergence. The extreme ca se is a batch size of 1, and it gives the maximum frequency of updates, which we adopt in this work. Then, the model parameters are updated in such a way: where k is the update counter and  X  k is the learning rate. A p roper learning rate can guarantee the convergence of the S GD method [6,7]. A typical convergent choice of learning rate can be found in Collins et al. [13]: where  X  0 is a constant. This scheduling guarantees ultimate convergence [6,7]. In this paper we adopt this learning rate schedule for the SGD. Averaged SGD with feedback (ASF) is a modification and extension of the tra-ditional SGD training method [8]. The naive version of averaged SGD is inspired by the averaged perceptron technique [14]. Let  X  iter ( c ) ,sample ( d ) be the parame-ters after the d  X  X h training example has been processed in the c  X  X h iteration over the training data. We define the averaged parameters at the end of the iteration c as:
However, a straightforward application of parameter averaging is not ade-quate. A potential problem of traditional parameter averaging is that the model parameters  X  receive no information from the averaged parameters: the model parameters  X  are trained exactly the same like before (SGD without averaging).  X  could be misleading as the training goes on. To solve this problem, a natural idea is to reset  X  by using the averaged paramet ers, which are more reliable. The ASF refines the averaged SGD by applying a  X  X eriodic feedback X  .

The ASF periodically resets the parameters  X  by using the averaged param-eters  X  . The interval between a feedback operation and its previous operation is called a training period or simply a period . It is important to decide when to do the feedback, i.e., the length of each period should be adjusted reasonably as the training goes on. For example, at the early stage of the training, the  X  is highly noisy, so that the feedback operation to  X  should be performed more frequently. As the training goes on, less frequent feedback operation would be better in order to adequately optimize the parameters. In practice, the ASF adopts a schedule of linearly slowing-down feedback : the number of iterations increases linearly in each period, as the training goes on.

Figure 2 shows the steps of the ASF. We denote  X  b,c,d as the model parameters after the d  X  X h sample is processed in the c  X  X h iteration of the b  X  X h period. Without making any difference, we denote  X  b,c,d more simply as  X  b,cn + d where n is the number of samples in a training data. Similarly, we use g b,cn + d to denote  X   X  L s ( d,  X  )inthe c  X  X h iteration of the b  X  X h period. Let  X  in the b  X  X h period. Let  X  ( b ) be the averaged parameters produced by the b  X  X h period. We can induce the explicit form of  X  (1) : When the 2nd period ends, the parameters are again averaged over all previous Similarly, the averaged parameters produced by the b  X  X h period can be expressed as follows:
The best possible convergence resu lt for stochastic learning is the  X  X lmost sure convergence X  : to prove that the stochastic algorithm converges towards the solution with probability 1 [6]. The ASF guarantees to achieve almost sure convergence [8]. The averaged parameters produced at the end of each period of the optimization procedure of the ASF training are  X  X lmost surely convergent X  towards the optimum  X   X  [8]. On the implementation side, there is no need to keep all the gradients in the past for computing the averaged gradient  X  :we can compute  X  on the fly, just like the averaged perceptron case. We use one month data of the ALKAN dataset [15] for experiments. This is a new data, and the data contains 2,061 sessions, with totally 3,899,155 samples (in a temporal sequence). The data was collected by iPod accelerometers with the sampling frequency of 20HZ. A sample contains 4 values: { time (the seconds past from the beginning of a session), x-axis-acceleration, y-axis-acceleration, z-axis-acceleration } , for example, { 539.266(s), 0.091(g), -0.145(g), -1.051(g) } 1 .There are six kinds of action labels: act-0 means  X  X alking or running X  , act-1 means  X  X n an elevator or escalator X  , act-2 means  X  X aking car or bus X  , act-3 means  X  X aking train X  , act-4 means  X  X p or down stairs X  ,and act-5 means  X  X tanding or sitting X  . 5.1 How to Design and Implement Good Features Wesplitthedataintoatrainingdata(85%),adevelopmentdataforhyper-parameters (5%), and the final evaluation data (10%). The evaluation metric are sample-accuracy (%) ( equals to recall in this ta sk: the number of correctly predicted samples divided by the number of all the samples). Following previous work on action recognition [ 1,2,3,4], we use acceleratio n features, mean features, standard deviation, energy, and correlation (covariance between different axis) features. Features are extracted fro m the iPod accelerometer data by using a window size of 256. Each window is about 13 seconds long. For two consecutive windows (each one contains 256 samples), they have 128 samples overlapping to each other. Feature extraction on windows with 50% of the window overlapping was shown to be effective in previous work [1]. The features are listed in Table 1. All features are used without pruning. We use exactly the same feature set for all systems.
The mean feature is simply the averaged signal strength in a window: where s 1 ,s 2 ,... are the signal magnitudes in a window. The energy feature is defined as follows: The deviation feature is defined as follows: where the m i is the mean value defined before. The correlation feature is defined as follows: where the d i ( x )and d i ( y ) are the deviation values on the i  X  X h window of the x -axis and the y -axis, respectively. The covariance i ( x, y ) is the covariance value between the i  X  X h windows of the x -axis and the y -axis.Inthesameway,wecan define c i ( y, z )and c i ( x, z ).

A naive implementation of the propose d features is to design several real-value feature templates representing the mean value, standard deviation value, energy value, and correlation value, and so on. However, in preliminary experi-ments, we found that the model accuracy is low based on such straightforward implementation of real features. A possible reason is that the different values of a real value (e.g., the standard deviation) may contain different indications on the action, and the difference of the indications can not be directly reflected by evaluating the difference of their real values. The most easy way to deal with this problem is to split an original real value feature into multiple features (can still be real value features). In our case, the feature template function automat-ically splits the original real value features into multiple real value features by using a heuristic splitting interval of 0.1. For example, the standard deviations of 0.21 and 0.31 correspond to two different feature IDs, and they correspond to two different model parameters. The standard deviations of 0.21 and 0.29 correspond to an identical feature ID, with only difference on the feature values. In our experiment, we found splitting th e real features improves the accuracy (more than 1%).

It is important to describe the implem entation of edge features, which are based on the label transitions, y i  X  1 y i . For traditional implementation of CRF systems (e.g., the HCRF package), usually the edges features contain only the information of y i  X  1 and y i , without the information of the observation sequence (i.e., x ). The major reason for this simple implementation of edge features is for reducing the dimension of features. Otherwise, there can be an explosion of edge features in some tasks. For our action recognition task, since the feature dimension is quite small, we can combine observation information of x with label transitions y i  X  1 y i , and therefore make  X  X ich edge features X . We simply used the same observation templates of node features for building rich edge features (see Table 1). We found the rich edge features significantly improves the prediction accuracy of CRFs. 5.2 Experimental Setting Three baselines are adopted to make a comparison with the ASF method, in-cluding the traditional SGD training (SGD), the SGD training with parameter-averaging but without feedback (averaged SGD), and the popular batch training method, limited memory BFGS (LBFGS).

For the LBFGS batch training method, which is considered to be one of the best optimizers for log-linear models like CRFs, we use the OWLQN open source package [16] 2 . The hyper-parameters for learning were left unchanged from the default settings of the software: the convergence tolerance was 1e-4; and the LBFGS memory parameter was 10.

To reduce overfitting, we employed an L2 prior R (  X  )= ||  X  || 2 2  X  2 for both SGD and LBFGS, by setting  X  = 5. For the ASF and the averaged SGD, we did not employ regularization priors, assuming that the ASF and the averaged SGD con-tain implicit regularization by performing parameter averaging. For the stochas-tic training methods, we set the  X  0 as 1.0. We will also test the speed of the various methods. The experiments are run on a Intel Xeon 3.0GHz CPU, and the time for feature generation and data input/output is excluded from the training cost. 5.3 Results and Discussion The experimental results are listed in Table 2, and the more detailed results of the respective action categories are listed in Table 3. Since recognizing actions from real-life continuous signals require the action-identification and the boundary-disambiguation at the same time, it is expected to be much more difficult than the previous work on simply action-identification. An additional difficulty is that the data is quite noisy. The number of iterations are decided when a training method goes to its empirical convergence state 3 .

Note that, the ASF training achieved better sample-accuracy than other on-line training methods. The ASF method is relatively stable among different iter-ations when the training goes on, while the SGD training faces severe fluctuation when the training goes on. The averaged SGD training reached its empirical con-vergence state faster than the ASF training. The ASF training converged much faster than the SGD training. All of the online training methods converged faster than the batch training method, LBFGS.

In Figure 3, we show the curves of sampl e-accuracies on varying the number of training iterations of the ASF, the averaged SGD, and the traditional SGD. As can be seen, the ASF training is much more stable/robust than the SGD training. The fluctuation of the SGD is quite severe, probably due to the noisy data of the action recognition task. The robus tness of the ASF method relates to the stable nature of the averaging technique with feedback. The ASF outperformed the averaged SGD, which indicates that the feedback technique is helpful to the naive parameter averaging. The ASF also outperformed the LBFGS batch training with much fewer iteration numbers (therefore, with much faster training speed), which is surprising. 5.4 A Challenge in Real-Life Action Recognition: Axis Rotation One of the tough problems in this action recognition task is the rotation of the x-axis , y-axis ,and z-axis in the collected data. Since di fferent people attached the iPod accelerometer with a different r otation of iPod accelerometer, the x-axis , y-axis ,and z-axis faced the risk of inconsistency in the collected data. Take an extreme case for example, while the x-axis may represent a horizontal direction for an instance, the same x-axis may represent a vertical direction for another instance. As a result, the acceleration sig nals of the same axis may face the prob-lem of inconsistency. We suppose this is an important reason that prevented the experimental results reaching a higher level of accuracy. A candidate solution to keep the consistency is to tell the people to adopt a standard rotation when Accuracy (%) collecting the data. Howev er, this method will make the collected data not  X  X at-ural X  or  X  X epresentative X , because usu ally people put the accelerometer sensor (e.g., in iPod or iPhone) randomly in their pocket in daily life. In this paper, we studied automatic non-boundary action recognition with a large-scale data set collected in real-life activities. Different from traditional simple classification approaches to action recognition, we tried to investigate real-life continuous action recognition, and adopted a sequential labeling approach by using conditional random fields. To achieve good performance in continuous action recognition, we presented how to design and implement useful features in this task.

We also compared different online optimization methods for training condi-tional random fields in this task. The ASF training method demonstrated to be a very robust training method in this task with noisy data, and with good performance. As future work, we plan to deal with the axis rotation problem through a principled statistical approach.
 X.S., H.K., and N.U. were supported by the FIRST Program of JSPS. We thank Hirotaka Hachiya for helpful discussion.

