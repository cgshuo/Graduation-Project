 We study a problem setting of transfer learning in which classifiers for multiple tasks have to be learned from biased samples . Some of the multiple tasks will likely relate to one another, but one cannot assume that the tasks share a joint conditional distribution of the class label given the input variables. The challenge of multi-task learning is to come to a good generalization across tasks: each task should benefit from the wealth of data available for the entirety of tasks, but the optimization criterion needs to remain tied to the individual task at hand.
 A common method for learning under covariate shift (marginal shift) is to weight the biased train-ing examples by the test-to-training ratio p test ( x ) p [1]. Instead of separately estimating the two potentially high-dimensional densities one can directly estimate the density ratio  X  by kernel mean matching [2], minimization of the KL-divergence be-tween test and weighted training data [3], or by discrimination of training against test data with a probabilistic classifier [4].
 Hierarchical Bayesian models are a standard statistical approach to multi-task learning [5, 6, 7]. Here, a common prior on model parameters across tasks captures the task dependencies. Similar to the idea of learning under marginal shift by weighting the training examples, [8] devise a method for learning under joint shift of covariates and labels over multiple tasks that is based on instance-specific rescaling factors. We generalize this idea to a setting where not only the joint distributions between tasks may differ but also the training and test distribution within each task.
 Our work is motivated by the targeted advertising problem for which the goal is to predict sociode-mographic features (such as gender, age, or marital status) of web users, based on their surfing history. Many types of products are specifically targeted at clearly defined market segments, and marketing organizations seek to disseminate their message under minimal costs per delivery to a targeted individual. When sociodemographic attributes can be identified, delivering advertisements to users outside the target segment can be avoided. For some campaigns, clicks and resulting on-line purchases constitute an ultimate success criterion. However, for many campaigns  X  including campaigns for products that are not typically purchased on the web  X  the sole goal is to deliver the advertisement to customers in the target segment.
 The paper is structured as follows. Section 2 defines the problem setting. In Section 3, we devise our transfer learning model. We empirically study transfer learning for targeted advertising in Section 4 and Section 5 concludes. We consider the following multi-task learning scenario. Each of several tasks z is characterized by the task z . The joint distributions of different tasks may differ arbitrarily but usually some tasks from different tasks is available. For each test example, attributes x i and the originating task z i are known. The test data for task z are governed by p test ( x | z ) .
 from several tasks. In addition to x i and z i , the label y i is known for each example. The training differ from the test distribution in terms of the marginal distribution p train ( x | z ) . The training and test marginals may differ arbitrarily, as long as each x with positive p test ( x | z ) also has a positive p train ( x | z ) . This guarantees that the training distribution covers the entire support of the test distri-bution for each task. The conditional distribution p ( y | x , z ) of test and training data is identical for a given task z , but conditionals can differ arbitrarily between tasks. The entire training set over all proportions. There may be tasks with only a few or no labeled data.
 The goal is to learn a hypothesis f z : x 7 X  y for each task z . This hypothesis f z ( x ) should correctly predict the true label y of unseen examples drawn from p ( x | z ) for all z . That is, it should minimize the expected loss with respect to the unknown distribution p test ( x , y | z ) for each individual z .
 This abstract problem setting models the targeted advertising application as follows. The feature vector x encodes the web surfing behavior of a user of web portal z (task). For a small number of users the sociodemographic target label y (e.g., gender of user) is collected through web surveys. For new portals the number of such labeled training instances is initially small. The sociodemographic ent between portals since they attract specific populations of users. The training distribution differs from the test distribution because the response to the web surveys is not uniform with respect to the test distribution. Since the completion of surveys cannot be enforced, it is intrinsically impossible to obtain labeled samples that are governed by the test distribution. Therefore, a possible difference between the conditionals p test ( y | x , z ) and p train ( y | x , z ) cannot be reflected in the model. One reference strategy is to learn individual models for each target task z by minimizing an ap-propriate loss function on the portion of L z = { ( x i , y i , z i )  X  L : z i = z } . This procedure does not exploit data of related tasks. In addition, it minimizes the loss with respect to p train ( x , y | z ) ; the minimum of this optimization problem will not generally coincide with the minimal loss on p test ( x , y | z ) . The other extreme is a one-size-fits-all model f  X  ( x ) trained on the pooled training sample L . The training sample may deviate arbitrarily from the target distribution p test ( x , y | z ) . In order to describe the following model accurately, we introduce selector variable s which distin-p ( x , y | z, s =1) ; likewise, p test ( x , y | z ) = p ( x , y | z, s =  X  1) . In learning a classifier f t ( x ) for target task t , we seek to minimize the loss function with respect identifies the current target task. Simply pooling the available data for all tasks would create a sample governed by weight r t ( x , y ) for each element of the pool of examples. The resampling weights match the pool distribution to the target distribution p ( x , y | t, s =  X  1) . The resampled pool is governed by the correct target distribution, but is larger than the labeled sample of the target task. Instead of sampling from the pool, one can weight the loss incurred by each instance by the resampling weight.
 The expected weighted loss with respect to the mixture distribution that governs the pool equals the loss with respect to the target distribution p ( x , y | t, s =  X  1) . Equation 1 defines the condition that the resampling weights have to satisfy.
 In the following, we will show that satisfies Equation 1. Equation 3 expands the expectation and introduces two fractions that equal one. We can factorize p ( x , y | t, s =  X  1) and expand the sum over z in the numerator to run over the entire expression because the integral over ( x , y ) is independent of z (Equation 4). Equation 5 rearranges some terms and Equation 6 is the expected loss over the distribution of all tasks weighted by r t ( x , y ) .
 E = = = Equation 5 signifies that we can train a hypothesis for task t by minimizing the expected loss over the distribution of all tasks weighted by r t ( x , y ) . This amounts to minimizing the expected loss with respect to the target distribution p ( x , y | t, s =  X  1) . The resampling weights of Equation 2 have an intuitive interpretation: The first fraction accounts for the difference in the joint distributions across tasks, and the second fraction accounts for the covariate shift within the target task.
 Equation 5 leaves us with the problem of estimating the product of two density ratios r t ( x , y ) = one for each of the two numerators and the two denominators. However, obtaining estimators for potentially high-dimensional densities is unnecessarily difficult because ultimately only a scalar weight is required for each example. 3.1 Discriminative Density Ratio Models without estimating the individual densities.
 model p ( t | x , y, s = 1) . This conditional has the following intuitive meaning: Given that an in-stance ( x , y ) has been drawn at random from the pool distribution p ( t | x , y, s = 1) . The following equations assume that the prior on the size of the target sample is greater than zero, p ( t | s = 1) &gt; 0 . In Equation 7 Bayes X  rule is applied to the numerator and z is summed out in the denominator. Equation 8 follows by dropping the normalization factor p ( t | s =1) and by canceling p ( x , y | s =1) . can be determined without knowledge of any of the task densities p ( x , y | z, s = 1) . The right hand side of Equation 8 can be evaluated based on a model p ( t | x , y, s = 1) that discriminates labeled instances of the target task against labeled instances of the pool of examples for all non-target tasks. using a conditional model p ( s = 1 | x , t ) . In Equation 9 Bayes X  rule is applied twice. The two terms p ( s =  X  1 | x , t ) = 1  X  p ( s =1 | x , t ) , Equation 10 follows. The significance of the above derivations is that instead of the four potentially high-dimensional densities in r t ( x , y ) , only two conditional distributions with binary variables (Equations 8 and 10) need to be estimated. One can apply any probabilistic classifier to this estimation. 3.2 Estimation of Discriminative Density Ratios For estimation of r 1 t ( x , y ) we model p ( t | x , y, s =1) of Equation 8 with a logistic regression model over model parameters u t using a problem-specific feature mapping  X ( x , y ) . We define this map-ping for binary labels,  X ( x , y ) = of prior knowledge about the similarity of classes, input features x of examples with different class labels y are mapped to disjoint subsets of the feature vector. With this feature mapping the models for positive and negative examples do not interact and can be trained independently. Any suitable mapping  X ( x ) can be applied. In [8], p ( t | x , y, s = 1) is modeled for all tasks jointly in single op-timization problem with a soft-max model. Empirically, we observe that a separate binary logistic regression model (as described above) for each task yields more accurate results with the drawback of a slightly increased overall training time.
 Optimization Problem 1 For task t : over parameters u t , maximize The solution of Optimization Problem 1 is a MAP estimate of the logistic regression using a Gaussian prior on u t . The estimated vector u t leads to the first part of the weighting factor empirical distribution over the pool L sums to one, 1 | L | from p ( s = 1 | x , t ) which is the likelihood that a given x for task t originates from the training distribution, as opposed to from the test distribution. A model of p ( s = 1 | x , t ) can be obtained by discriminating a sample governed by p ( x | t, s =1) against a sample governed by p ( x | t, s =  X  1) using a probabilistic classifier. Unlabeled test data T t is governed by p ( x | t, s =  X  1) . The labeled pool L over all training examples weighted by r 1 t ( x , y ) can serve as a sample governed by p ( x | t, s = 1) ; the labels y can be ignored for this step. Empirically, we find that using the weighted pool L instead of just L t (as used by [4]) achieves better results because the former sample is larger. We model p ( s =1 | x , v t ) of Equation 10 with a regularized logistic regression on target variable s with parameters v t (Optimization Problem 2). Labeled examples L are weighted by the estimated first factor  X  r 1 t ( x , y ) using the outcome of Optimization Problem 1.
 Optimization Problem 2 For task t : over parameters v t , maximize 1 , according to Equation 10.  X  r 2 t ( x ) is normalized so that the final weighted empirical distribution over the pool sums to one, 1 | L | 3.3 Weighted Empirical Loss and Target Model Optimization Problems 1 and 2. These weights can now be used to reweight the labeled pool over loss over the weighted training data as displayed in Equation 11. It is the regularized empirical counterpart of Equation 6.
 Optimization Problem 3 minimizes Equation 11, the weighted regularized loss over the training data using a standard Gaussian log-prior with variance  X  2 w on the parameters w t . Each example is weighted by the two discriminatively estimated density fractions from Equations 8 and 10 using the solution of Optimization Problems 1 and 2.
 Optimization Problem 3 For task t : over parameters w t , minimize In order to train target models for all tasks, instances of Optimization Problems 1 to 3 are solved for each task. We study the benefit of distribution matching and other reference methods on targeted advertising for four web portals. The portals play the role of tasks. We manually assign topic labels, out of a fixed set of 373 topics, to all web pages on all portals. For each user the topics of the surfed pages are tracked and the topic counts are stored in cookies of the user X  X  web browser. The average number of surfed topics per user over all portals is 17. The feature vector x of a specific surfer is the normalized 373 dimensional vector of topic counts.
 A small proportion of users is asked to fill out a web questionnaire that collects sociodemographic user profiles. About 25% of the questionnaires get completely filled out (accepted) and in 75% of the cases the user rejects to fill out the questionnaire. The accepted questionnaires constitute the training data L . The completion of the questionnaire cannot be enforced and it is therefore not possible to obtain labeled data that is governed by the test distribution of all users that surf the target portal. In order to evaluate the model, we approximate the distribution of users who reject the questionnaire as follows. We take users who have answered the very first survey question (gender) but have then discontinued the survey as an approximation of the reject set. We add the correct proportion (25%) of users who have taken the survey, and thereby construct a sample that is governed by an approximation of the test distribution. Consequently, in our experiments we use the binary target label y  X  X  male , female } . Table 1 gives an overview of the data set.
 Table 1: Portal statistics: number of accepted, partially rejected, and test examples (mix of all partial reject (=75%) and 25% accept); ratio of male users in training (accept) and test set. We compare distribution matching on labeled and unlabeled data (Optimization Problems 1 to 3) and distribution matching only on labeled data by setting  X  r 2 t ( x ) = 1 in Optimization Problem 3 to the following reference models. The first baseline is a one-size-fits-all model that directly trains a is a logistic regression trained only on L t , the training examples of the target task. Training only on the reweighted target task data and correcting for marginal shift with respect to the unlabeled test data is the third baseline [4].
 The last reference method is a hierarchical Bayesian model. Evgeniou and Pontil [6] describe a fea-ture mapping for regularized regression models that corresponds to hierarchical Bayes with Gaus-sian prior on the regression parameters of the tasks. Training a logistic regression with their feature mapping over training examples from all tasks is equivalent to a joint MAP estimation of all model parameters and the mean of the Gaussian prior.
 We evaluate the methods using all training examples from non-target tasks and different numbers of training examples of the target task. From all available accept examples of the target task we randomly select a certain number (0-1600) of training examples. From the remaining accept exam-ples of the target task we randomly select an appropriate number and add them to all partial reject examples of the target task so that the evaluation set has the right proportions as described above. We repeat this process ten times and report the average accuracies of all methods.
 We use a logistic loss as the target loss of distribution matching in Optimization Problem 3 and all reference methods. We compare kernelized variants of Optimization Problems 1 to 3 with RBF, polynomial, and linear kernels and find the linear kernel to achieve the best performance on our data set. All reported results are based on models with linear kernels. For the optimization of the logistic regression models we use trust region Newton descent [9].
 We tune parameters  X  u ,  X  v , and  X  w with grid search by executing the following steps. 1.  X  u is tuned by nested ten-fold cross-validation. The outer loop is a cross-validation on L t . In 2.  X  v is tuned by likelihood cross-validation on T t  X  L . The labels of the labeled data are ignored Figure 1: Accuracy over different number of training examples for target portal. Error bars indicate the standard error of the differences to distribution matching on labeled data. Figure 1 displays the accuracies over different numbers of labeled data for the four different target portals. The error bars are the standard errors of the differences to the distribution matching method on labeled data (solid blue line).
 For the  X  X amily X  and  X  X V channel X  portals the distribution matching method on labeled and unla-beled data outperforms all other methods in almost all cases. The distribution matching method on labeled data outperforms the baselines trained only on the data of the target task for all portals and all data set sizes and it is at least as good as the one-size-fits-all model in almost all cases. The hierarchical Bayesian method yields low accuracies for smaller numbers of training examples but becomes comparable to the distribution matching method when training set sizes of the target portal increase. The simple covariate shift model that trains only on labeled and unlabeled data of the target task does not improve over the iid model that only trains on the labeled data of the target task. This indicates that the marginal shift between training and test distributions is small, or could indicate that the approximation of the reject distribution which we use in our experimentation is not sufficiently close. Either reason also explains why accounting for the marginal shift in the distribution matching method does not always improve over distribution matching using only labeled data.
 Transfer learning by distribution matching passes all examples for all tasks to the underlying logistic regressions. This is computationally more expensive than the reference methods. For example, the single task baseline trains only one logistic regression on the examples of the target task. Empiri-cally, we observe that all methods scale linearly in the number training examples. We derived a multi-task learning method that is based on the insight that the expected loss with respect to the unbiased test distribution of the target task is equivalent to the expected loss over the biased training examples of all tasks weighted by a task specific resampling weight. This led to an algorithm that discriminatively estimates these resampling weights by training two simple conditional models. After weighting the pooled examples over all tasks the target model for a specific task can be trained.
 In our empirical study on targeted advertising, we found that distribution matching using labeled data outperforms all reference methods in almost all cases; the differences are particularly large for small sample sizes. Distribution matching with labeled and unlabeled data outperforms the reference methods and distribution matching with only labeled data in two out of four portals. Even with no labeled data of the target task the performance of the distribution matching method is comparable to training on 1600 examples of the target task for all portals.
 Acknowledgments We gratefully acknowledge support by nugg.ad AG and the German Science Foundation DFG. We wish to thank Stephan Noller and the nugg.ad team for their valuable contributions.

