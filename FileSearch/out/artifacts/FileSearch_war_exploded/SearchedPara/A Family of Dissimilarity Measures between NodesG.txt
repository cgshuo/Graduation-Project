 This work introduces a new family of link-based dissimilarity mea-sures between nodes of a weighted directed graph. This measure, called the randomized shortest-path (RSP) dissimilarity, depends on a parameter  X  and has the interesting property of reducing, on one end, to the standard shortest-path distance when  X  is large and, on the other end, to the commute-time (or resistance) distance when  X  is small (near zero). Intuitively, it corresponds to the expected cost incurred by a random walker in order to reach a destination node from a starting node while maintaining a constant entropy (related to  X  ) spread in the graph. The parameter  X  is therefore bi-asing gradually the simple random walk on the graph towards the shortest-path policy. By adopting a statistical physics approach and computing a sum over all the possible paths (discrete path integral), it is shown that the RSP dissimilarity from every node to a partic-ular node of interest can be computed efficiently by solving two linear systems of n equations, where n is the number of nodes. On the other hand, the dissimilarity between every couple of nodes is obtained by inverting an n  X  n matrix. The proposed measure can be used for various graph mining tasks such as computing be-tweenness centrality, finding dense communities, etc, as shown in the experimental section.
 H.2.8 [ Database Management ]: Database applications  X  Data min-ing; G.2.2 [ Discrete Mathematics ]: Graph theory  X  Graph algo-rithms; G.3 [ Probability and Statistics ]: Markov processes; I.2.6 [ Learning ]: Knowledge acquisition. Algorithms; theory; experimentation.
 Graph mining, biased random walk, kernel on a graph, shortest path, resistance distance, commute-time distance.
Network link analysis is an important research topic that has been the subject of much recent work in various fields of science: applied mathematics [35], social science [17, 63], physics [42], computer science [15]. Within this framework, one key issue is the proper definition of a similarity/dissimilarity measure between the nodes of the network, taking both direct and indirect links into account. Such a meaningful measure should consider two nodes as similar if there are many short paths connecting them (for a short survey of the different link-based dissimilarity measures proposed in the literature, see the related work section below). Once such a dissimilarity matrix has been defined, it can be exploited for various mining tasks, for instance finding communities, outliers, important nodes, etc.

This paper proposes such a measure of dissimilarity between nodes, together with algorithms for computing it, by applying and extending ideas that appeared in [52] in the context of routing. The proposed measure will be called the randomized shortest-path (RSP) dissimilarity and has three interesting properties. First, it has a clear, intuitive, interpretation in terms of a biased random walk on the graph. Second, it nicely generalizes the shortest-path and the commute-time distances (also called the resistance dis-tance) by computing an intermediate dissimilarity depending on one parameter  X  (the inverse temperature). When  X  is large, the dissimilarity reduces to the standard shortest-path distance while for  X  = 0 , it reduces to the commute-time distance, also called the resistance distance [18, 30]. Third, the dissimilarity between a par-ticular node and all the other nodes can be computed efficiently by solving two linear systems of n equations where n is the number of nodes. On the other hand, all-pairs of nodes dissimilarity can be computed by inverting an n  X  n square matrix. Notice, how-ever, that while being a distance metric for  X   X  0 and  X   X   X  , the proposed dissimilarity measure need not satisfy the triangle in-equality for intermediate values 0 &lt;  X  &lt;  X  , and is therefore not necessarily a distance metric.
The definition of this dissimilarity measure relies on a model in-spired by the work of Akamatsu in transportation networks [3], and extended recently by Saerens et al. in [52] in the framework of net-work routing. Consider a graph or network G where a positive cost is associated to each arc connecting two nodes. Consider further the infinite set of all possible paths (including cycles) between two nodes of interest. We define a biased random walk on the graph that favors short paths by associating a high probability of follow-ing these short paths and a low probability of following long paths. A Boltzmann probability distribution controlled by a parameter  X  , having exactly this property, is assigned to this set of paths. It is shown that this choice minimizes the expected cost for reaching node j from node i when a constant cross-entropy with respect to the natural, unbiased, random walk is spread in the graph.
In this biased random walk model, the expected cost d ( j | i ) in-curred when reaching node j from node i can be computed effi-ciently by using standard linear algebra. We regard this quantity d ( j | i ) as the directed dissimilarity between nodes i and j . The ran-domized shortest-path (RSP) dissimilarity between nodes i and j is
This section provides a short survey of the related work aiming to define meaningful link-based similarities between the nodes of a graph, and taking the form of a dissimilarity measure or a ker-nel matrix. Similarity between nodes is also called relatedness in the literature and the most well-known quantities measuring relat-edness are co-citation [58] and bibliographic coupling [29].
More sophisticated measures have been proposed as well. In their pioneering work, Klein &amp; Randic [30] proposed to use the effective resistance between two nodes as a meaningful distance measure. They call this quantity the resistance distance between nodes. Indeed, it can be shown that the effective resistance is a Euclidean distance [4, 20, 30, 37]. The close link between the ef-fective resistance and the commute time of a random walker on the graph was established in [10] while the links between the Laplacian matrix and the commute-time (as well as the Fiedler vector) were studied in [53]. Therefore, the resistance distance is sometimes called the commute-time distance .

Chebotarev &amp; Shamis proposed in [11, 12] a similarity measure between nodes integrating indirect paths, based on the matrix-forest theorem. Interestingly, this quantity, called the  X  X egularized Lapla-cian kernel X  [18], defines a kernel matrix and is related to the Lapla-cian matrix of the graph. Ito et al. [25] further propose the mod-ified regularized Laplacian kernel, an extension of the regularized Laplacian kernel, by introducing a new parameter controlling im-portance and relatedness. Moreover, in [25, 57] it is shown that the regularized Laplacian kernel overcomes some limitations of the von Neumann kernel [27], when ranking linked documents. This modified regularized Laplacian kernel is also closely related to a graph regularization framework introduced by Zhou &amp; Sch X lkopf in [69]. The exponential and von Neumann diffusion kernels, based this time on the adjacency matrix, are introduced in [27, 56]. The defined kernel matrices are computed through a power series of the adjacency matrix of the graph; they are therefore closely related to graph regularization models [31].

Moreover, some authors recently considered similarity measures based on random-walk or electrical concepts. For instance, Harel &amp; Koren [24] investigated the possibility of clustering data accord-ing to some random-walk related quantities, such as the probabil-ity of visiting a node before returning to the starting node. They showed that their algorithm is able to cluster arbitrary nonconvex shapes. White &amp; Smyth [64] investigated the use of the average first-passage time as a similarity measure between nodes. Their purpose was to generalize the random-walk approach of Page et al. [9, 43] by capturing a concept of  X  X elative centrality X  of a given node with respect to some other node of interest. A recent study, comparing several measures (including the average first-passage time) for analyzing the proximity of nodes in a graph in the frame-work of co-authorship networks, is presented in [36].

On the other hand, Kondor &amp; Lafferty [31] as well as Smola &amp; Kondor [59] defined a graph regularization model related to the graph PCA introduced in [53]. This model results in the definition of a family of kernels on a graph that provide similarities between nodes, just as any other graph kernel [56]. An interesting attempt to learn the regularization operator in the context of semi-supervised learning can be found in [72]. The result is a kernel on a graph maximizing kernel alignment to the labeled data. Still another ap-proach has been investigated by Palmer &amp; Faloutsos [44] who de-fine a similarity function between categorical attributes, called  X  X e-fined escape probability X , based on random walks and electrical networks. They show that this quantity provides a reasonably good measure for clustering and classifying categorical attributes.
The  X  X ommute-time X  (CT) kernel has been introduced in [18, 53] and was inspired by the already mentioned work of Klein &amp; Randic [30] and Chandra et al. [10]. It takes its name from the average commute time, which is defined as the average number of steps a random walker, starting from a given node, will take before entering another node for the first time, and go back to the starting node. The CT kernel is defined as the inner product in a Euclidean space where the nodes are exactly separated by the commute-time distance. An interesting method allowing to efficiently compute truncated commute-time neighbors appears in [54].
 Almost at the same period, Qiu &amp; Hancock [47, 48], Ham, Lee, Mika &amp; Sch X lkopf [23], Yen et al. [67] as well as Brand [8] de-fined the same CT embedding, preserving the commute-time dis-tance, and applied it to image segmentation and multi-body motion tracking [47, 48], to dimensionality reduction of manifolds [23], to clustering [67] as well as to collaborative filtering [8], with interest-ing results. On the other hand, Zhou [70, 71] uses the average first passage time between two nodes as a dissimilarity index in order to cluster them. He studies various greedy clustering techniques based on this dissimilarity index. Another similarity measure re-lated to the average fist-passage time appears in [62]. It is defined as the escape probability, that is the probability that a random walker starting from one node will visit the other node, before returning to the starting node. The resulting similarity is directed and closely related to the effective conductance between the two nodes. Also related is the measure investigated by Koren et al. [32, 33]. In this work, the authors propose to replace the effective conductance by a cycle-free effective conductance.

In two recent papers [39, 40], Nadler et al. as well as Latapy et al. [46] proposed a well-formulated distance measure between nodes of a graph based on a diffusion process, called the  X  X iffusion distance X . A valid kernel, called the  X  X arkov diffusion kernel X  has been derived from this diffusion distance in [19]. An application of the diffusion distance to dimensionality reduction and graph vi-sualization appears in [34]. The natural embedding induced by the diffusion distance is called the  X  X iffusion map X  by Nadler et al. [39, 40]. Moreover, in [46], Pons &amp; Latapy defined a hierarchical clus-tering approach for clustering the nodes according to the squared diffusion distance.

Two recent PageRank-inspired attempts to define meaningful sim-ilarities between nodes appear in [22, 45, 61]. In these two last works, the authors propose a random walk with restart procedure while in the first work, Gori and Pucci define a random walk pro-cess starting from the node of interest, controlled by some pre-computed correlation matrix between nodes. These two algorithms are thus inspired from the well-known PageRank procedure [9, 43], adapted in order to provide relative similarities between nodes. Yet another PageRank-inspired algorithm defining similarities between nodes was proposed in [6]. It provides a general way of computing similarities between the nodes of two different graphs. Applying this procedure to the same graph allows to find self-similarities, that is, similarities between nodes of the same graph. Finally, a simi-larity between nodes based on the number of different paths con-necting two nodes, and therefore on the maximum flow/minimum cut, is studied in [38]. This measure has been tested in two collab-orative recommendation tasks [18], but did not perform well in this context. Finally, Tahbaz-Salehi &amp; Jadbabaie [60] introduce a one-parameter family of algorithms that, as the algorithm developed in this work, recover both the Bellman-Ford procedure for finding shortest paths as well as the iterative algorithm for computing the average fist-passage time. However, it is based on heuristic grounds and not on a well-defined cost function to optimize.

There are also several attempts to generalize graph kernels to di-rected graphs. Indeed, not all of the above mentioned similarity measures are applicable to directed graphs. For instance, an exten-sion of the Laplacian matrix to directed graphs is proposed in [14] while an extension of the regularized Laplacian kernel to directed graphs appears in [1, 2]. Zhou et al. [69] used the regularized normalized Laplacian matrix defined in [14] in the context of semi-supervised classification of labeled nodes of a directed graph while Chen et al. [13] used the same kernel matrix, but this time unnor-malized, for directed graph embedding. Zhao et al. [68] propose a directed contextual distance and define a directed graph from which the Laplacian matrix is computed. It is then used for ranking and clustering images.
This work has three main contributions: (i) the randomized shor-test-path (RSP) dissimilarity, generalizing both the shortest-path and the commute-time distances, is introduced; (ii) it is shown that the RSP dissimilarity can be computed efficiently from the cost or adjacency matrix of the graph, and (iii) the RSP dissimilarity is ap-plied to two graph mining tasks, namely computing betweenness centrality and nodes clustering.

Section 2 develops the model as well as the procedure for com-puting the directed dissimilarity between two nodes, from which the RSP dissimilarity is derived as its symmetrized version. Sec-tion 3 describes an algorithm for computing the RSP dissimilarity between every pair of nodes. Section 4 presents some simple exper-iments on clustering and betweenness to demonstrate the properties of the dissimilarity. Section 5 is the conclusion.
The basis of the dissimilarity measure we propose is a new, bi-ased, random walk model in which each path between two nodes of interest is assigned an independent probability of being followed, such that the incurred expected cost-to-go from one node to the other is minimized under a fixed degree of randomness. The dis-similarity measure will then be defined in terms of this expected cost-to-go, or the expected energy . We first introduce the notation and the natural (or unbiased) random walk on the graph.
Consider a weighted directed graph or network, G , with a finite set of n nodes (or vertices) V and a set of arcs (or edges) E , without self-loops. To each arc linking node k and node k 0 (denoted as k  X  k ), we associate a weight c kk 0 &gt; 0 representing the immediate cost of following this arc. If there is no arc from k to k consider that c kk 0 takes a large value, denoted by  X  . The cost matrix C is the matrix containing the immediate costs c kk 0
Given this cost matrix, a natural random walk on the graph will be defined in the following obvious way. The choice to follow an arc k  X  k 0 will be made according to the transition proba-bility of jumping from node k to its successor node k 0  X  S ( k ) , where S ( k ) = { k 0 | ( k  X  k 0 )  X  E } is the set of succes-sors of k . The transition probabilities defined on each node k will be denoted as p kk 0 = P ( k 0 | k ) for k 0  X  S ( k ) . For nodes k 0 6 X  S ( k ) , the corresponding transition probabilities are set to zero, so p kk 0 = 0 . The natural random walk will be defined by p tion probability matrix containing the p ref kk 0 is P ref the random walker chooses to follow an arc with a probability pro-portional to the inverse of the immediate cost, therefore locally fa-voring arcs having a low cost. If, instead of C , we are given an affinity (adjacency) matrix with elements a kk 0 indicating the affin-ity between node k and node k 0 , the corresponding costs are com-puted from c kk 0 = 1 /a kk 0 and the transition probabilities associ-ated to each node are simply proportional to the affinities (and then normalized). Notice that other relations (not only the inverse rela-tion) between affinity and cost could be considered as well. These transition probabilities corresponding to the natural random walk will be used as reference probabilities later; hence the addition of the superscript  X  X ef X  on the transition probability matrix P
The rest of Section 2 deals with the problem of measuring the dissimilarity between a fixed pair of nodes. The computation of all-pairs dissimilarities will be discussed in Section 3.
Suppose we are interested in the dissimilarity between a fixed pair of nodes i and j . We consider a random walk starting from node i and eventually reaching node j , at which point the walk is terminated. Thus node i is called the initial node , and j the des-tination node . To ensure termination upon reaching node j , we modify the graph structure and make j an absorbing node having no outgoing arcs (i.e., c jk =  X  ,  X  k  X  V ). We also assume a prob-lem structure (the graph and costs) such that any natural random walk will eventually reach the destination node j with probability one; i.e., termination is inevitable. The conditions for which this is true are, basically, related to the fact that the destination node can be reached in a finite number of steps from any potential initial node, hence this assumption does not restrict the applicability of the model severely. For a rigorous treatment, see for instance [5].
Let R be the set of all paths (including cycles) from node i to node j in the modified graph (with node j absorbing). R is gener-ally an infinite (but countable) set. We define a probability distribu-tion over set R representing the probability P (  X  ) of choosing path  X  among all the paths from node i to j . Our idea is to seek the prob-ability distribution minimizing the expected cost-to-go among all the probability distributions having a fixed relative cross-entropy with respect to the natural random walk on the graph . This choice naturally defines a probability distribution on the set of paths such that long (with a high cost) paths between i and j occur with a low probability while short paths (with a low cost) occur with a high probability. We then use this expected cost as a dissimilarity mea-sure.

Let us denote the total cost associated to path  X  as E (  X  ) , hence-forth, following the statistical physics terminology, referred to as the energy of that path. We assume that the total cost associated to a path is additive , i.e., for a path  X  = ( i = k 0 , k 1 represented as a sequence of nodes, E (  X  ) = recall that  X   X  X  is a valid path from node i to node j in the modi-fied graph in which j is made an absorbing node. Hence the path is finite, and every k t 6 = j for any t 6 =  X  (  X  ) . Moreover, c along that path.

We now derive the path probability distribution minimizing the expected energy for reaching node j from i , and subject to a fixed relative entropy (Kullback-Leibler divergence; see for instance [16]) with respect to the reference probability. To be precise, we seek the solution (probability distribution) P(  X  ) to the following con-strained optimization problem: where P ref (  X  ) represents the probability of following path  X  when walking according to the natural random walk, i.e., when using transition probabilities p ref kk 0 . J 0 is provided a priori by the user, according to the desired degree of randomness he is willing to con-cede. In this work, the value of J 0 will be a parameter fixed by the user; when J 0 tends to 0 , we recover the natural random walk while as J 0 increases, the path probability distribution will be more and more peaked around the shortest paths. By defining the Lagrange function and observing that its derivative with respect to the path probabili-ties should vanish at the minimum, we obtain the following proba-bility distribution where  X  = 1 / X  is called the inverse temperature in statistical physics. Thus, as expected, short paths (having small E (  X  ) ) are favored in that they have a large probability of being followed. In other words, the random walk is more and more biased towards the shortest path as  X  increases.

With the probability distribution minimizing the expected energy at hand, we define the directed dissimilarity between i and j ex-actly as this minimum expected energy, and denote it by d ( j | i ) . In other words, d ( j | i ) is the expected cost incurred when reaching node j from node i , according to the probability distribution P(  X  ) provided by Equation (4). We can also define a symmetric dis-We call d ( i, j ) the symmetric randomized shortest-path (RSP) dissimilarity , or symmetric dissimilarity for short.

These dissimilarity measures depend on the parameter  X  . Equa-tion (3) implies that when  X  is large, the probability distribution on the paths is peaked on the shortest path. On the other hand, when  X  is near zero, the exponential in Equation (3) tends to 1 and the Markov chain reduces to the natural random walk defined previously. In this case, the directed dissimilarity simply becomes the expected cost for reaching the destination node. Indeed, for  X  = 0 , it has been shown that this expected cost d ( j | i ) can be computed from the elements of the pseudoinverse of the Lapla-cian matrix of the graph for the natural random walk; see Equa-tion (18) in [18]. A little calculus shows that the symmetric quan-costs c ij and is proportional to the commute-time between nodes i and j . Therefore, the symmetric dissimilarity d ( i, j ) provides the commute-time distance, up to a proportional factor, when  X  = 0 . Notice that the symmetric RSP dissimilarity is a Euclidean distance when  X  is near zero (commute-time distance), a distance when  X  is large (shortest-path distance), but it is not necessarily a distance for intermediate values of  X  . We indeed observed experimentally that the triangular inequality could not be respected for intermediate values of  X  .
We defined the directed dissimilarity d ( j | i ) as the expected en-ergy for reaching the destination node j from the initial node i , under the probability distribution given by Equation (4). We show that this expected energy can be computed from a quantity, Z , de-fined as and which corresponds to the partition function in statistical physics (see [26] or any textbook in statistical physics; for instance [50, 55]).
 The expected energy E = terms of the partition function via
E =  X  (  X  ln( Z )) The partition function is related to other quantities of interest as well [52]. For instance, the expected number of transition steps through arc k  X  k 0 is given by where  X  (  X  ; k, k 0 ) indicates the number of times arc k  X  k present in path  X  , and thus the number of times the arc is traversed. The expected number of passages in node k is then provided by which corresponds to the expected number of incoming transitions. We will use  X  kk 0 to compute the betweenness centrality measures [41, 63] in Section 3.

Notice that the definition for the partition function (Equation (5)) involves summation over (generally an infinite number of) paths in R . In Section 2.4, we will discuss how to compute the partition function efficiently.
By applying the ideas introduced by Akamatsu [3], let us show how the partition function Z can be computed from the cost matrix. Recall that we have changed the costs c jk to ensure that the random walk terminates at the destination node j (see Section 2.2). The cost matrix after this change, denoted by e C , is identical to the original cost matrix C except that elements of row j consist entirely of  X  . Consequently, the modified cost matrix takes the following form The corresponding transition-probabilities matrix for the natural random walk will be denoted by e P ref ; it is obtained from P replacing row j with 0 T .

From the modified cost matrix e C , we build a new matrix given by where the logarithm/exponential functions are taken elementwise and the operator  X  is the elementwise (Hadamard) matrix product. Now, since ln P ref (  X  ) = that element ( i, j ) of the matrix f W t ( f W to the power t ) is [ P connecting the initial node i to the destination node j in exactly t steps . Consequently, the partition function is
Z = Thus element i of the j th column of the matrix sponds to the partition function when starting from node i . Com-puting this infinite series for the problem at hand is relatively easy: the series of powers of f W provides which converges if the spectral radius of f W ,  X  ( f W ) , is less than 1 . Thus Z can be computed thanks to (we assume i 6 = j in the sequel) Now, if we pose e Z = ( I  X  f W )  X  1 , the partition function is Z = [ e
Z ] ij = e z ij . Thus, the matrix e Z plays a role similar to the funda-mental matrix in the theory of finite Markov chains [28].
From Equations (6) and (8), we see that in order to obtain the quantities of interest, namely E and  X  kk 0 , we have to compute the derivatives of Z , provided by Equation (12), with respect to  X  and e c kk 0 (the calculus is quite similar to the one appearing in [52]; see that paper for details). To compute these quantities, we only need the i th row and the j th column of matrix e Z , which are given by the column vectors 1 e z i = e Z T e i and e z j = e Ze j . These vectors can be obtained by solving the following linear systems of equations Let us denote the elements of e Z by e z kk 0 = [ e Z ] kk 0 Z = e z ij = [ e z i ] j = [ e z j ] i . Algorithm 1 Computation of the directed dissimilarity between node i and node j .
 Input: Node i is the initial node while node j is the destination Output: The directed dissimilarity between nodes i and j , d ( j | i ) . 1. In matrix C , replace each entry of row j by  X  and denote the 3. if  X  ( f W ( j ) )  X  1 then 4. return  X  X he spectral radius is greater than one. X  5. end if 6. Solve 7. return d ( j | i ) =  X 
Now, for the expected energy or expected cost , we obtain, after differentiating Z provided by Equation (12), The expected number of passages through arc k  X  k 0 is for k 6 = j . The expected number of passages through node k forward/backward variables when estimating transition probabili-ties in a hidden Markov model [49]. The difference here is that we are dealing with general graphs and not with acyclic graphs (lat-tices), as in hidden Markov models.

As stated earlier, the directed dissimilarity between node i and node j is defined as the expected cost incurred when reaching node j from node i : d ( j | i ) = E . In Algorithm 1, we present the pseu-docode for computing the directed dissimilarity between node i and node j . In the pseudocode, we added the superscript ( j ) to vari-tion node j .
We now discuss how to compute the directed dissimilarity be-tween every pair of nodes. Thus our objective is to compute the di-rected dissimilarity matrix D whose elements are given by [ D ] d ( j | i ) . Notice that instead of fixing the entropy, we fix the param-eter  X  which is kept constant for every pair of nodes. A straight-forward approach would be to apply Algorithm 1 repeatedly for every pair of nodes i and j . But a better approach is desirable, as each run of Algorithm 1 involves solving ( I  X  f W ) T e z ( I  X  f W ) e z j = e j (Equation (13)), with different f with an explicit superscript ( j ) added to variables to represent their dependence on j : from Let W = P ref  X  exp [  X   X  C ] . It is easy to see that f computed from W by replacing its j th row by zeroes (a zero row, 0 ). Equivalently, e C ( j ) is computed from C by replacing its j th row by a  X  T row. By defining w j = row j ( W ) , where row returns the column vector containing the transpose of row j , W and f W ( j ) are related by f W ( j ) = W  X  e j w T j .

Finally, we show how to compute efficiently all the entries of D in terms of Z = ( I  X  W )  X  1 . This is a simple application of the Sherman-Morrison formula [21], which allows to compute e Z ( j ) = ( I  X  f W ( j ) )  X  1 ( I  X  W )  X  1 . Indeed, from f W ( j ) = W  X  e j w T j , we have ( I  X  f W ( j ) ) = ( I  X  W ) + e j w T j . By setting A = ( I  X  W ) , c = e and d = w j in Equation (19), we obtain From Equation (14), once the matrix e Z ( j ) has been computed, the column j of the dissimilarity matrix D , d j = col j ( D ) , is where  X  is the elementwise division. In Algorithm 2, the proce-dure for computing the similarity between every node i and node j is detailed. The directed dissimilarity matrix is then defined by D = will be used in the experiments and which reduces to the commute-time distance for a small  X  is simply D RSP = ( D + D T ) / 2 .
Moreover, it is not hard to show that the expected number of passages through each arc and node can be computed by the same trick. For instance, let e N ( j ) be the matrix containing as elements [ e
N ( j ) ] ik , the expected number of passages through node k when starting from node i and ending in node j (absorbing node). Using the same notation as in Algorithm 2, this matrix can be computed by From the expected number of passages through each arc when start-ing from node i and ending in j ,  X  ( j ) kk 0 ( i, j ) (see Equation (16)), a betweenness centrality measure can easily be computed in the same spirit as the random-walk betweenness proposed by Newman in [41]. The RSP betweenness centrality of a node k will therefore be defined as the net flux entering in node k for all possible pairs of initial and destination nodes: b Algorithm 2 Computation of the symmetric RSP dissimilarity ma-trix between all pairs of nodes.
 Input: The graph has one single connected component containing Output: The symmetric RSP dissimilarity matrix D RSP . 1. W = P ref  X  exp [  X   X  C ] , where  X  is the elementwise product, 2. if  X  ( f W ( j ) )  X  1 then 3. return  X  X he spectral radius is greater than one. X  4. end if 5. Z = ( I  X  W )  X  1 6. for j = 1 to n do 7. In matrix C , replace each entry of row j by  X  and 8. In matrix W , replace each entry of row j by 0 and de-9. Define w j = row j ( W ) and z j = col j ( Z ) . 13. end for 14. D = 15. return D RSP = ( D + D T ) / 2 where N ( k ) is the set of nodes adjacent to k . This betweenness re-duces to Freeman X  X  betweenness [63] based on shortest paths when  X   X  X  X  and is very similar in spirit to Newman X  X  betweenness [41] when  X   X  0 .
The experimental section aims to answer two important research questions, namely (1) Does the RSP dissimilarity behave correctly, according to our intuition. For instance, the dissimilarity should be highly correlated with the shortest-path distance when  X   X  X  X  and with the commute-time distance when  X   X  0 . (2) Do the results obtained by using the RSP dissimilarity differ significantly from the results obtained when using the shortest-path and the commute-time distances. In other words, does the RSP dissimilarity show some added value in graph mining tasks. In order to investigate these questions, we performed three simple experiments.

First experiment. This first experiment aims at computing the linear correlation between the RSP dissimilarity, the shortest-path distance and the commute-time distance for various graphs. Two examples of such correlations study are shown in Figures 1(a) X (b), for the graph constructed from documents belonging to five news-groups (figure a; for details about the dataset and the graph con-struction, see [65]) and for the IMDb graph (figure b; described in [66]). Notice that various other graphs were analyzed as well (Zachary karate club, dolphins network, Florentine families, net-science co-authorship network, etc); the results and conclusions were similar but are not reported here. From Figures 1 (a) X (b), we clearly observe that the RSP dissimilarity is highly correlated with the commute-time distance when  X   X  0 and with the shortest-path distance when  X   X   X  (actually, it is already met when  X  = 15 ). We also observe that for intermediate values of  X  , the RSP dis-for 0 &lt;  X   X  20 . similarity still remains correlated with both the shortest-path and the commute-time distances. However, in a range of  X  values of about [10  X  3 , 1] , the correlation of the RSP dissimilarity with the shortest-path distance, and more obviously with the commute-time distance, tend to stagnate and even eventually decrease. This some-what counter-intuitive behavior could be explained by the fact that some high-probability paths promoted by the shortest-path and the commute-time policy could be conflicting, which results in a de-crease in correlation.

Second experiment. This second experiment aims to compare the clustering results obtained on a graph node clustering task, for various values of  X  . In this experiment, we used exactly the same methodology and datasets as in [65, 66]. In summary, a kernel k-means is performed on various graphs in order to retrieve the clusters, as detailed in [65, 66]. Due to the lack of space, only the results on a newsgroup as well as on the IMDb datasets will be presented. To this aim, a similarity matrix on a graph is derived from the RSP dissimilarity matrix, K RSP =  X  1 2 HD RSP H , where H = I  X  ee T /n is the centering matrix and e is a column vector full of ones. This is the standard way for deriving a similarity from a dissimilarity [7] when the dissimilarity matrix contains square distances. Indeed, the commute-time distance is the square of the Euclidean commute-time distance, which is Euclidean (see [18, 53] for details). Thus, when  X  is small, the commute-time kernel, the natural kernel associated to the Euclidean commute-time distance  X  which takes the form of the pseudoinverse of the Laplacian matrix [18]  X  is obtained. Notice that the matrix K RSP is not necessarily semi-positive definite; for instance, the shortest-path distance is not Euclidean. In Figures 1 (c) and (d), the correct classification rate, averaged on 20 runs, is displayed in terms of parameter  X  for the newsgroup and the IMDb datasets respectively. The results are re-ported for two different settings of the clustering algorithm: with and without the computation of a sigmoid transform of the kernel matrix. Indeed, it has been observed that the sigmoid transform on the commute-time kernel allows to improve the performances of the clustering [65, 66]. First, we observe that when  X   X  0 , the clus-tering performances of the basic algorithm are poor. But the appli-cation of the sigmoid transform allows to smoothen the curve and raise the performance for small values of  X  to a competitive cluster-ing rate. Second, we observe that the best results are obtained for an intermediate value of  X  , where the dissimilarity need not to be a distance and thus K RSP is not actually a valid kernel matrix. The results obtained for intermediate values of  X  are usually better or comparable to those obtained with the commute-time (  X   X  0 ) and the shortest-path (  X   X  X  X  ) kernels. Finally, it can be observed that the kernel associated to the shortest-path distance also offers good performances, despite the fact that the distance is not Euclidean, which was unexpected. Tests on various other datasets show that the value of  X  for which the clustering rate is the highest strongly depends on the properties and the structure of the graph. But, in general, the best performances are obtained for  X   X  [10  X  3 Third experiment. The last experiment aims to compare the RSP betweenness (see the end of Section 3), computed for vari-ous values of  X  , with the well-known Freeman X  X  [63] betweenness as well as with Newman X  X  [41] betweenness. The linear correla-tion between the RSP betweenness and Freeman X  X  + Newman X  X  be-tweenness are reported in Figure 1 (e) X (f) for two datasets, the dol-phins graph and the netscience co-authorship network. The same test has been performed on various other networks, with compara-ble results. By examining the figures, we observe that the correla-tions vary smoothly when  X  varies in the range ]0 , 20] . Moreover, it is clear that the RSP betweenness comprises both Freeman X  X  and Newman X  X  betweenness. However, since the results of the three be-tweenness measures remain highly correlated, the added value of our RSP betweenness is somewhat questionable in this context.
Discussion of the results. Let us now come back to our research questions. The experiments clearly show that the symmetric RSP dissimilarity behaves as expected, although the fact that the correla-tion between the RSP dissimilarity and the commute-time distance is not always monotonically decreasing when  X  increases is some-what counter-intuitive and deserves further investigations. It also appears that the parameter  X  influences significantly the results and could be considered as a meta-parameter to be tuned. For instance, the clustering benefits from the tuning of  X  . However, this is less clear for the RSP betweenness centrality measure, for which the betweenness based on the shortest-path and the betweenness based on the natural random walk are already highly correlated.
This work introduced a new family of dissimilarity measures be-tween the nodes of a weighted, directed, graph that generalizes both the shortest-path and the commute-time distances. It depends on a meta-parameter,  X  , biasing gradually the simple random walk on the network towards the shortest path policy. Simple experiments involving graph mining tasks showed that performances could be improved by tuning the meta-parameter  X  .

In future work, comparisons between this dissimilarity measure and other popular choices mentioned in Section 1.1 will be per-formed on collaborative recommendation and semi-supervised clas-sification tasks. We will also try to tackle Markov decision pro-cesses through the sum-over-paths statistical physics framework. Still another application of this formalism results in the definition of a correlation measure between nodes of the graph. Indeed, the second-order derivative of the partition function with respect to the immediate costs provides a covariance measure between nodes. In short, two nodes are correlated if they often occur in the same path. Finally, links between the proposed sum-over-paths framework and the matrix-forest theorem [11] as well as the generating function approach to random walks [51] will be investigated.
