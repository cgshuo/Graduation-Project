 We in this paper explore a new research paradigm, called query homogeneity , to process KNN queries on road net-works for online LBS applications. While previous works in the literature concentrate on the improvement of query processing time, we turn to examine the issue of response time for a user query, which needs to additionally consider the waiting time in the queue. Note that the response time is the more precise value corresponding to the user expe-rience in an online service, and the unacceptable response time is likely to turn away disgruntled users. Surprisingly, we will show in this paper that the response time will be more signi cantly dominated by the waiting time but it is left unexplored thus far. Since previous works all perform queries in the one-by-one fashion, which will lead to unex-pected long waiting time, we thus in this paper propose a novel query framework, called SHI , aiming at diminishing the waiting time by a new group-by-group solution. SHI re-lies on the natural phenomenon of query homogeneity , which refers to the behavior that queries are usually issued in the sense of spatial and temporal correlation. Motivated by this natural behavior, operations of query processing and queue processing are incorporated in the SHI framework. During the network expansion for a query, a group of homogeneity queries in the waiting queue, which have results identical to the processing query, will be picked up and ushed out together when the query processing is accomplished, achiev-ing the group-by-group query processing and reducing the waiting time signi cantly.
 H.2.8 [ Database Management ]: Database Applications| Spatial databases and GIS KNN search; road network; query homogeneity
As the signi cant advancements in manufacturing cost-effective mobile devices with the geo-positioning capability, location-based services (LBS) become the most promising applications in recent years. Many mobile services and web-based social network services, such as Foursquare, Facebook and Google+, provide geo-tagging interfaces for the growing number of users sharing and acquiring real-time location-dependent information online. The location-dependent spa-tial queries (abbreviated as LDSQ), e.g., KNN (K Nearest Neighbors) queries or range queries, which allow users to search nearby events of interest, have thus been deemed as the indispensable means to the success of LBS applications [14][15].

Recently, LBS applications call for the need of providing advanced LDSQ which consider user trajectories on road networks. LBS equipped with LDSQ on road networks is more favorable since it enables the search of surrounding objects by measuring the distance in the metric of the net-work distance or the traveling time [11][17]. An example of such a KNN query may like " nd ve nearest hotels, sorted by the walking distance away from the conference venue". Generally, the deployment of LDSQ on road networks is rel-atively costly for online services due to its intrinsic need of expensive network traversals for each query [15]. As such, a signi cant number of research efforts has been devoted to alleviate the computational overhead for LDSQ on road networks in the past few years [4][11][9][15][17].
However, two critical challenges coming along with the nature of online services, which are generally not simulta-neously considered in depth in the literature, would cause current LDSQ algorithms on road networks to behave in-sufficiently for online LBS applications. The rst challenge is the difficulty in guaranteeing acceptable query latency. Note that the query latency had been proven to be the most important factor of QoS (quality of services) for web search-related services. Even a slight increase of search latency will incur the severe decline in the user population [1][16]. However, due to the dramatic growth of users and digital contents, the increase of query workload is inevitably higher than the increase of affordable capital cost. Clearly, the hardware reinforcement is no longer feasible to prevent users from experiencing poor services in the big data era [8].
The second challenge arises from the essential requirement of supporting data updates in online applications. As of today, time-variant messages, such as the insertion of new activities, the deletion of expired information, and the move-ment of ongoing events, are prevalent in LBS applications, and burst updates are anticipated in some special events like Olympic games or the presidential election. Since users are generally interested in the most recent data, an online LBS application that is incapable of handling frequent updates will lead to the limitation of its marketing growth.
Note that current LDSQ algorithms usually suffer from the dilemma of striking a compromise between query effi-ciency and the support of data updates. Speci cally, strate-gies used in previous works for query efficiency can be clas-si ed into three paradigms, namely query caching , object-embedded index and road-skeleton index , as shown in Fig-ure 1. Among them, query caching [7] and object-embedded index [3][4][5][9] will fail in the presence of data updates due to the tight association between the designed network structure and the object information [11]. We will discuss the details in Section 2. Recent advances propose the road-skeleton index solutions, which independently manipulate two essential operations, i.e., network traversal and object lookup , in processing a single query [2][11][17]. Since objects are only checked when queries are issued, the side-effect of data updates is able to be resolved spontaneously. However, road-skeleton index solutions still rely on the manner of net-work expansion for each query. The processing time for each query will depend on the number of visited nodes and edges [2].

Unfortunately, we will show in Section 2.2 that the current solutions, which cannot accomplish a query in the constant time, will incur the unacceptable waiting time for a query when the query arrival rate exceeds the peak workload they provision for. The poor service will continue to be suffered for most users until requests are consumed completely. It will lead to the decline in popularity for an online service that is incapable of handling such a situation. Note that the waiting time is generally proportional to the average processing time of the single query multiplied by the amount of waiting requests in the queue. Clearly, the response time to a query 1 will be more signi cantly dominated by the time waiting in the queue than its processing time. Despite of its critical impact, this challenging problem is however left unexplored thus far.

The aforementioned discussion infers that optimization on the processing time for the single query is insufficient to con-quer this critical challenge in online applications. To further improve the response time in the presence of data updates, we therefore in this paper turn to explore a new paradigm
No te that the response time to a query generally consists of the processing time to generate its result and its waiting time in the system until being processed. from the system aspect, called the collective query ush by homogeneity identi cation , to process queries in the group-by-group manner and to diminish the waiting time in the queue. The research paradigm is inspired by the observa-tion that queries tend to behave in the sense of spatial and temporal correlation. Similar observations are also revealed in different disciplines such as the rst law of geography, which states that "Everything is related to everything else, but near things are more related than distant things"[19]. It is expected that queries of searching surrounding restaurants may be intensively issued during the lunch time or dinner time in the weekday in the business metropolis. In addition, queries for outdoor activities are usually frequently issued in the residential district on the weekend morning. Since queries are highly spatially and temporally correlated, a set of unprocessed queries in the waiting queue is likely to have the identical query result. This phenomenon, called query homogeneity in this paper, can be utilized to simultaneously ush a set of queries with the same query result in one ex-ecution of query processing. Clearly, the higher degree of query homogeneity will lead to the better bene t for the group-by-group processing. Even when the burst workload is encountered, the worst query latency will not be increased linearly with the amount of requests in the queue, achieving the better guarantee of QoS in online services.

As such, we devise a framework of LDSQ on road net-works, called SHI (standing for S patial query by H omogeneity I denti cation), in this paper. SHI is implemented by incor-porating the operation of query processing and the operation of handling the waiting queue. To demonstrate the effective-ness of query homogeneity , we in this paper concentrate on designing SHI for KNN queries, which are the most popular and relatively complicated LDSQ queries [15]. Note that the phenomenon of query homogeneity is not a kind of caching which tends to have the issue of expiration. SHI will pro-cess queries in the group-by-group fashion and each group is independently processed, inherently achieving the support of data updates.

The overview of the proposed SHI framework is illustrated in Figure 2. Speci cally, following the FIFO policy which de-queues the rst query q f in the single-server waiting queue, the SHI framework will process q f in accordance with the general ow of network traversal [11][15]. During the net-work expansion for q f , SHI will collect queries Q c = f q ; ..., q c n g , which are associated to the traversed nodes and are identi ed relative to q f in the sense of query homogene-ity . While the result r f of q f is obtained and returned to the user, SHI will further determine each query in Q c if r equ als its query result according to various policies of homo-geneity identi cation. Clearly, SHI can serve a set of queries in one time of network traversal, thus leading to signi cant improvement of the system throughput. To the best of our knowledge, the research spectrum of query homogeneity is not explored in the literature thus far.

Note that the spectrum of query homogeneity pursuits the better system throughput from the perspective of saving the waiting time in the queue. It is orthogonal to other mecha-nisms for improving processing time of the single query, and many sophisticatedly designed query processing algorithms for the single query, such as query caching and road-skeleton index , can also be integrated into SHI to further improve the total throughput without the clash. We will discuss the implementation issue in Section 3.

The contributions of this work can be summarized as fol-lows: (1) while previous works mostly concentrate on the improvement of query processing time, the paper is the rst work to address that the waiting time queued in the wait-ing pool will more signi cantly impact the user experience. (2) The natural behavior of query homogeneity is compre-hensively discussed in this paper and is applied to devise the novel mechanism of ushing out a set of queries simul-taneously. (3) We theoretically analyze the requirement of group-by-group based query processing and show its effec-tiveness of diminishing waiting time and response time. (4) The experimental studies demonstrate that, instead of im-provement on query processing time, the improvement on response time will be more bene cial to real applications. In addition, the proposed SHI framework can apparently achieved the goal.

The rest of this paper is organized as follows. Section 2 gives preliminaries including related works and the problem description. In Section 3, the design of the SHI framework is discussed. The experimental results are shown in Section 4. Finally, this paper concludes with Section 5.
In this section, we rst give related works of KNN queries on road networks. in Section 2.1. For the orthogonal prob-lem to retrieve KNN objects in the Euclidean space, inter-ested readers can refer to [18][20] for the comprehensive in-troduction. For more interesting issues in query processing on spatial databases, materials in [14] also give discussions in details. Section 2.2 will give the discussion on the query response time. In Section 2.3, necessary de nitions and the model background are addressed.
Since the work in [15] rst formally explores the problem of KNN queries on road networks, a signi cant number of research efforts have been devoted to alleviate the computa-tional overhead in this challenging issue [2][3][6][9][11][15][17]. Formally, the topology of road networks is generally modeled as the graph structure, consisting of vertices which are con-nected by edges. As summarized in [11], there are two essen-tial operations involved in processing KNN queries, namely network traversal and object lookup . The operation of net-work traversal is in charge of traversing through the graph according to some traversal criteria, and the object lookup is to check if objects of interest associate in the visited vertices or edges. Generally, the network traversal starts from the vertex which corresponds to the location of query issued, and the traversal ends when all KNN objects of interest are collected during the expansion. Clearly, the processing time for a query depends on the size of traversed nodes and the amount of operations in object lookup.

The INE (incremental network expansion) algorithm is the rst work to address the search of KNN objects on road networks [15]. INE extends the Dijkstra's algorithm and gradually expands the network space until all KNN ob-jects are identi ed. To achieve better query efficiency, the Euclidean lower bound property, which states that the Eu-clidean distance is the lower bound of the network distance, is also exploited to prune the unnecessary expansion of the search space in the extension of INE. However, the blind node-by-node traversal in INE has been recognized the root cause of the query latency, especially when queries are issued in a huge spatial network.

To further improve the query efficiency of the KNN search, three paradigms of algorithmic strategies are successively proposed. As illustrated in Figure 1, they are query caching , object-embedded index and road-skeleton index , respectively. We individually discuss these approaches below.

The rst paradigms, i.e., query caching , simply utilizes caches of previous query results for sequential queries [7]. In this work, the LRU cache-replacement is applied. It can response queries in the constant time in cases that cache hits [7]. However, in the presence of data updates, this solution will be infeasible since caches tend to be invalid in a short time period.

In addition, solutions in the object-embedded index cat-egory will take the object distribution into consideration while building the initial index, and every query can be ef-ciently processed in the pre-computed index without the expensive blind search [3][4][5][9]. Speci cally, the VN 3 gorithm [9] creates a Network Voronoi polygons (NVP) for each object, and as such the object is the nearest neighbor for all network nodes inside the NVP. Therefore, the near-est object can be quickly obtained by checking NVPs. The UNICONS algorithm obtains KNN objects by precomputing nearest objects for some condensed points, where condensed points are nodes with large fanouts [3]. When the network search reaches a condensed point, the precomputed NN lists can be retrieved directly to reduce the search space. Simi-lar to UNICONS, the SPIE algorithm [5] applies a network reduction approach to reduce the road network to a set of interconnected trees. In SPIE, each node in the tree will precompute its nearest object. In this method, the KNN objects can be obtained by traversing the tree without us-ing the network expansion like the Dijkstra's algorithm.
However, the object-embedded index solutions are infeasi-ble to support data updates. Note that the network index is built based on the object locations. The update of objects will make the initial index invalid for future queries.
The road-skeleton index solutions are the state-of-the-art mechanism to deal with KNN queries on road networks, which independently manipulate operations of network traver-sal and object lookup, in processing a single query [2][11][17]. Basically, the aforementioned INE approach is a kind of road-skeleton index algorithms. In [17], the distance brows-ing algorithm is proposed to exploit the phenomenon of path coherence for maintaining shortest paths between all nodes. For processing KNN queries, a non-incremental best-rst al-gorithm is devised without blind network traversals. Note that the KNN search in this work still needs a node-by-node fa shion until KNN objects are identi ed. The ROAD algo-rithm, which is proposed in [11], exploits the network hop concept to avoid blind node-by-node expansions for KNN queries. The whole road network needs to be initially par-titioned into a set of disjointed sub-networks, called Rnets. It relies on the precomputation step to identify the set of borders in each Rnet, where a border is a network node con-necting with nodes in another Rnet. While a KNN query is issued, if no required object is located within the Rnet, op-erations of the network expansion within this Rnet can be skipped and replaced by shortcuts between borders which are also precomputed. Essentially, the query overhead of the ROAD algorithm still depends on the number of vis-ited nodes. Recently, an extension of the ROAD algorithm, called the SQUARE algorithm, is proposed in [2]. SQUARE utilizes the phenomenon of 80-20 rules that most queries will be issued in so-called hot regions. The idea of caching KNN information in borders of hot regions is used to facilitate the pruning of search spaces while the procedure of network traversal reaches such kinds of borders. Since the cache is utilized, SQUARE needs additional procedures to examine if the cache is expired. Moreover, its query overhead is also proportional to the number of visited nodes and edges.
Essentially, road-skeleton index solutions build necessary structures without embedding the object information. The support of data updates can be easily achieved without the extra effort. However, the processing time will depend on the number of visited nodes and edges, incurring unbounded query latency while burst queries arrive. We will show this observation in Section 2.2.
We examine in this paper the issue of query response time from the perspective of online applications. Speci cally, the response time to a query consists of the processing time to generate the desired query result and the waiting time stay-ing in the request queue. Note that the slow response time has been recognized as the crucial factor of user dissatis-faction in many observations [1][16], and service operators should prepare sufficiently powerful hardware referring to the peak response time. Note that previous works mostly assume that queries are one-by-one processed individually. Unfortunately, we will show in Example I that solutions like road-skeleton index algorithms, which processing time for a query is generally proportional to the size of visited vertices [15][11], will incur the unacceptable response time when the query arrival rate exceeds the peak workload they provision for. Even worse, the unexpectedly poor service is suffered by not only users who send requests during the request surge but also users who issue queries at the moment far away from the demand peak. Inevitably, the signi cant proportion of users will receive the bad experience (requests are dropped out or time out), thus likely to turn away disgruntled users. Before the example, we give necessary de nitions at rst. De nition 1 (Query response time): For a query q i issued at time t 1 , q i will be registered in the single-server queue and will be processed in accordance with the FIFO policy. Suppose the time of q i being dequeued is t 2 , and the time of q i being completely processed is t 3 . The waiting time of q i in the queue is t w = t 2 t 1 , and the query processing time of q i is t p = t 3 t 2 . The query response time t r be the sum of t w and t p , i.e., t r = t w + t p = t 3 t De nition 2 (Query arrival rate): For queries contin-uously input in an online service, the query arrival rate in a speci c time period [ t 1 ; t 2 ] is the number of queries which are issued within [ t 1 ; t 2 ] . In addition, the average response time in [ t 1 ; t 2 ] will be the average of response time to every query issued in [ t 1 ; t 2 ] .
 Example I: We discuss a scenario simulating the demand surge that may occur in practice. Suppose that an online LBS application provides the KNN query on road networks for searching nearby restaurants with real-time discounts. Consider the bell-shaped distribution of query arrival rate as illustrated in Figure 3, where the x-axis depicts the time axis, the left-side y-axis denotes the query arrival rate per second, and the right-side y-axis denotes the corresponding average query response time. Suppose that queries will stay in the waiting queue until it becomes the rst query in the queue (no dropped out case). Let P A e denote the expected peak of the arrival rate which is estimated by the service operator, and P A r denote the real peak of the arrival rate. Ideally, the arrival rate will monotonically increase during the dinner time till reaching P A e . The service operators generally prepare the sufficiently powerful hardware which is able to consume queries within the acceptable response time, which is denoted by P R e , when the arrival rate does not exceed P A e . Figure 3(a) shows the situation of the arrival rate conforming the expectation. In this case, queries are one-by-one processed and are completely consumed as expected. The expected peak response time P R e will appear at the same time corresponding to P A e .

However, the query arrival rate may dramatically increase during some seldom events such as the carnival day, and the traffic is likely to poke through the estimated peak P A e reaching the unexpected but real peak P A r eventually. As shown in the Figure 3(b), queries cannot be completely con-sumed in time, starting from t 1 . The unconsumed queries will accumulate continually even when the time correspond-ing to P A r is passed. The peak response time P R r will appear for queries issued at t 3 , since the peak of the queue size will appear at t 3 . In addition, the response time will exceed P R e all the while until t 2 . In this case, requests is-sued between t 1 and t 2 , namely more than 70% queries, will suffer the bad experience (response time exceeds P R e ) even they issue queries at the moment far away from the demand peak.  X 
From this observation, we know the concern of waiting time signi cantly dominates the impact for the service qual-ity. Clearly, optimization on the linear processing time for a single query is not the key to the success of admirable user experience in online services. As such, we will examine the improvement of the waiting time in this paper.
We rst give the notations and de nitions used hereafter and formalize the problem addressed in this paper. There are two fundamental structures involved in our model, namely the structure for indexing the road network topology and objects, and the structure of the waiting queue.
 Road Network and Object: Generally, a road network is represented as a graph G , which consists of a set of nodes, denoted by N , and a set of edges, denoted by E . A node n 2 N denotes a starting/ending point of a road segment, and an edge e = ( u; v ) 2 E denotes a road segment that connects node u and node v . The traversal distance or the walking time of the road segment ( u; v ) is denoted by j A routing path between two nodes u and v is modeled as edges, i.e., ( u; n 1 ) 2 E , ( n l ; v ) 2 E , and ( n i for 1 i l 1. The distance of path p ( u; v ) is de-ned as the sum of distance corresponding to each edge in p , i.e., j p j = j ( u; n 1 ) j + j ( u l ; v ) j + the shortest path between two nodes u and v , denoted by p ( u; v ), corresponds to the path having the minimum dis-tance between u and v .

In addition, the database maintains a set of data objects or messages, denoted by O ( t ) = f o 1 ; o 2 ; :::; o m g object contains the information of its location and its de-scription for the keyword search. Since the model is update-aware, O ( t ) represents to objects which are valid at the timestamp t . Note that we can logically transform the lo-cation of object o i to the graph location l g ( o i ) in G as &lt; v; d ( v; o i ) &gt; , where v denotes the node in G closest to o and d ( v; o i ) denotes Euclidean distance between v and o As such, o i is said to be associated with v if its graph loca-of associated objects O v ( t ) in node v at time t contains all objects in which each one is valid at time t and its associated node is v .
 Spatial Query and Queue: Formally, a spatial query for retrieving k nearest objects on G is denoted by q j ( t ), where t is its issued time. Same as the graph location of a object, the graph location of g j ( t ) can be modeled as l g ( q v; d ( v; q j ( t )) &gt; . For simplicity, we may say that q issued at node v in the sequel.

Speci cally, the waiting queue Q ( t ) is the set of queries in which each query is unprocessed and is issued before time t . Queries in Q ( t ) are sorted in order of the issued time. That is Q ( t ) = f q 1 ( t 1 ) ; q 2 ( t 2 ) :::q n ( t n i &lt; j . In addition, q 1 ( t 1 ) corresponds to the head of the queue and will be processed in advance of other queries in Q ( t ) according to the FIFO policy.

Note that in the presence of data updates, the query result of a query q i ( t i ) is generally accepted to be the result in any snapshot before it is really processed. We formally de ne this issue below.
 De nition 3 (Snapshot query result): Suppose that for query q j ( t 1 ) , in light of the FIFO policy to process queries in the one-by-one fashion, q j ( t 1 ) will be processed at time t . The snapshot query result sr ( q j ( t 1 )) for q j ( t the result retrieving from any O ( t k ) ; for t 1 t k t 2
In this paper we aim at simultaneously accomplishing a set of queries in Q ( t ) according to the phenomenon of query homogeneity, which is de ned as follows. De nition 4 (Query homogeneity and homogeneity queries): Suppose that the system is processing query q f at time t . Let Q ( t ) = f q 1 ( t 1 ) ; q 2 ( t 2 ) :::q ing queue of unprocessed queries. The query homogeneity is which each one has the same snapshot query result of q f ( t i.e., H ( q f ( t f ) ; t ) = f8 q k ( t k ) j sr ( q k ( t H ( q f ( t f ) ; t ) Q ( t ) :
The set of H ( q f ( t f ) ; t ) is called homogeneity queries of q ( t f ) . There are two types of homogeneity queries: (1) Order-sensitive homogeneity queries: homogeneity queries should have the KNN order same as the order of sr ( q f ( t (2) Order-insensitive homogeneity queries: homogeneity queries have the same result without the order concern.

Note that for some applications, the order-insensitive re-sult is adequate for user browsing necessary information. If users can accept order-insensitive result, they will trade for better query response time. The details will be given in Section 3. Formally, sr ( q j ( t 1 )) is obtained after query pro-cessing for q f ( t f ), and at the same time, it will be copied for every query in H ( q f ( t f ) ; t ). Note that H ( q f ( t to be a random subset of Q ( t ) so that queries may be re-turned without following the original one-by-one FIFO rule. We in this paper use the group-by-group FIFO policy which extends the same spirit of the one-by-one FIFO policy. De nition 5 (Group-by-group FIFO policy): Suppose that at time t , the system is executing the network expansion for query q f ( t f ) . Let Q ( t ) = f q 1 ( t 1 ) ; q 2 waiting queue and q 1 ( t 1 ) be the head of Q ( t ) . In the group-by-group FIFO policy, three operations can be manipulated in the queue: (1) dequeue for query processing : the operation can only be manipulated on q 1 ( t 1 ) after sr ( q f ( t f )) is retrieved. (2) reference link for homogeneity identi cation : the operation links the query reference in Q ( t ) to the list of col-lective homogeneity candidates, which are the set of all pos-sible candidates with the result identical to sr ( q f ( t (3) queue remove for homogeneity queries : the opera-tion will ush queries of homogeneity queries out of Q ( t ) .
Figure 4 illustrates these three operations applied in the group-by-group FIFO queue. In the following, we formally introduce the proposed paradigm for group-by-group query processing.
 Problem Formulation (Co llective query ush by ho-mogeneity identi cation): Our goal in this paper is to di-minish the time waiting in the queue by utilizing the group-by-group manner of query processing. The operations of queue processing and query processing are consolidated in the system. For processing a single query, other queries in the waiting queue will be simultaneously checked if they fol-low the sense of query homogeneity. Finally, these queries with the identical result will be ushed out of the waiting queue after one time query processing. Note that the pro-cedure should also follow two criteria: (1) It must comply with the group-by-group FIFO policy. (2) The overhead of homogeneity identi cation should be as small as possible. The criterion can guarantee that the response time of the head query q 1 ( t 1 ) in Q ( t ) will not be sig-ni cantly affected by the check of query homogeneity. Rea-sonably, it is prohibitive to enhance the system throughput at the sacri ce of users staying in the front of the queue.
In this section we introduce the proposed SHI framework, standing for S patial query by H omogeneity I denti cation, to effectively realize the collective query ush by homogene-ity identi cation paradigm. Note that group-by-group query processing may be trivially achieved by referring to cache-like mechanism. When we nish the query processing for q ( t ), all queries in the waiting queue Q ( t ) can be iteratively checked if they have the same result. However it is clear that the naive solution to check all queries in Q ( t ) is prohibitively costly, and will violate the criterion 2 stated in our problem formulation. To achieve the better performance, SHI is de-vised by consolidating the operation of query processing and queue processing. Before presenting the details of the sys-tem ow, we give some initial data structures and lemmas.
At rst, SHI exploits the object index used in ROAD [11] and SQUARE [2]. The index is basically implemented as a B + -Tree or a hash table, with the key equal to the graph node id and values mapping to the set of objects associated at the node. In addition, the waiting queue is also imple-mented as the similar way of a hash table, that key of the hash table is the node id and the corresponding value is the set of queries issued in the node. Each query will also maintain links referring to its previous and next query. Such structures can facilitate the object and query lookup, and can easily support data updates and queue insertion and deletion [11].

In addition, the network graph is also devised as the form of adjacency lists which have utilized in many conventional network storage schemes [11]. The adjacency list maintains the neighbors of each node, and we can easily traverse the network by checking the adjacency list of a node and ex-panding to each neighbor by BFS or DFS traversal strate-gies. Note that for processing KNN queries, the priority queue is usually used to sort traversed nodes with respect to the distance to the source node.
 To fully utilize the phenomenon of query homogeneity in SHI , we conduct several useful lemmas to support various ltering policies for query homogeneity.
 Lemma 1: Suppose that for a object o i and an edge ( v a ; v between nodes v a and v b , the distance of the shortest path between o i and v b is j p s ( o; v b ) . The distance of the shortest path between o i and v a must be: j p ( o i ; v b ) j j ( v a ; v b ) j &lt; j p s ( o i ; v a ) Proof: Let j p s ( o i ; v a ) j = a , j p s ( o i ; v b ) c , as shown in Figure 5(a) : Since p s ( o i ; v b ) is the shortest path between o i and v b , a routing path of o i and v b that walks through v a must be longer than p s ( o i ; v b ) : Therefore we have a + c &gt; b; i.e., a &gt; b c: Similarly, the property also By integrating these two formulas, we can conclude that b c &lt; a &lt; b + c:  X  Lemma 2: Suppose that object o i is the nearest object (1NN) of v b , and v a is adjacent to v b . We follow Dijkstra's algorithm and start the network traversal from v b . While the 1NN o i is found, we can continue to traverse the network by the length of 2 j ( v a ; v b ) j . If no new object is found within 2 j ( v a ; v b ) j , the 1NN of v b is also the 1NN of v a Proof: Let j p s ( o i ; v a ) j = a , j p s ( o i ; v b ) c: We know that b c &lt; a &lt; b + c in light of Lemma 1. As shown in Figure 5(b), nodes in the shadow area are already visited when o i is reached (follow the traversal way in Dijkstra's algorithm), and no other object is found in the shadow area. Let p  X  be a shortest path between v b and a search boundary s i that walks via v a . The distance of shortest path between v a and s i will be b c . However, according to Lemma 1, we know that b c &lt; a &lt; b + c: To ensure that o i is still the 1NN of v a , we have to traverse the road network from s i by the length of 2 c to verify that there is no object whose shortest path to v a is shorter than the shortest path between v a and o i . If no object is found during the extra network traversal, o i must be the 1NN of v . Since we have already traverse the road network from v a by length of b + c and no other object is found, we can conclude that o i is the 1NN of v a .  X 
In the following, we extend Lemma 2 to the KNN case, and deliver the determination for homogeneity identi cation. Le mma 3 (Homogeneity Identi cation): Suppose that the object set f o 1 ; o 2 ; :::; o k g is the KNN of v b notes the i th NN, and v a is adjacent to v b . During the net-work traversal, when the KNN is found we continue travers-ing the network by the length of 2 j ( v a ; v b ) j to check if any object can be reached. If no object is found, the set of KNN of v b is also be the set of KNN of v a .
 Proof: Let shortest paths between o 1 ; o 2 ; :::; o k and v a ; a 2 ; :::; a k ; respectively, and shortest paths between o o ; :::; o k and v b be b 1 ; b 2 ; :::; b k ; and j ( v a ; v the following formulas in light of Lemma 1:
Since b 1 &lt; b 2 &lt; ::: &lt; b k ; we have b 1 c &lt; b b when o k is reached during the traversal process, we expand the network by the additional length of 2 j ( v a ; v b ) visited nodes whose shortest path is smaller than or equal to b k + 2 c . Because b 1 + c &lt; b 2 + c &lt; ::: &lt; b b found, f o 1 ; o 2 ; :::; o k g is still the set of KNN of v when j b i b i 1 j 2 c; the order of o i and o i 1 is unchanged. Otherwise, the order of KNN of v a may not be the same of that of v b .  X 
The owchart of SHI is illustrated in Figure 6. The group-by-group FIFO queue, the road index structures, and the object repository are three important components in SHI . Note that SHI is devised by fully utilizing the advantages from other works without the clash. As such, we refer the technology of query caching and devise the backward-lookup process. The component is simply implemented, and for the case of data updates, the ltering insert-check for cache validation can be applied [2]. On the other hand, the key component of SHI , i.e., the forward-lookup process, is de-vised according to the strategy of homogeneity identi cation stated in Lemma 3. The details are discussed as the way of pseudo codes below.
 A lgorithm 1 SHI query
A t rst, we give the details of the procedure to process a KNN query in SHI . The algorithm of SHI query is out-lined in the algorithm 1. Algorithm inputs include: the object index OI , the number of KNN objects k , and the query point q , the spatial network SN , the xed size cache C and the homogeneity threshold . Note that is a user parameter to de ne the maximum distance between q and queries in the collective homogeneity candidates CHC . The algorithm 1 will return the KNN result AN S and the ho-mogeneity queries HQ . We rst check if the result of q is contained in C . If C contains the answer, we can retrieve the result from C directly without network traversal, and re-turn the answer to the user (in the backward-lookup check). Otherwise, the procedure SHINetworkSearch is called to get the result and return the answer to the user. Meanwhile, the cache is updated. In the procedure SHINetworkSearch, CHC and nish-state priority queue F SP Q are also ob-tained. After SHINetworkSearch nishes its job, the proce-dure ForwardLookup is invoked to obtain the homogeneity queries HQ , and the results are returned to all queries in HQ .

The procedure SHINetworkSearch is described in algo-rithm 2 to show the process of network traversal. There are 5 input parameters and the procedure will return the KNN result ; CHC and F SP Q . P Q is a priority queue. In P Q , the element ( v; v:dist ) represents a node and its distance from the query point. The elements in P Q are sorted by the distances in the ascending order. The dequeue operation will remove an element from P Q that has the smallest dis-tance. The procedure begins by enqueuing ( q; 0) onto P Q . An element ( v; v:dist ) is dequeued repeatedly from P Q until P Q is empty or top-k objects are identi ed. After an ele-ment is dequeued, three operations are executed: (1) Check the dequeued node whether it is visited. If the dequeued node is visited, further network expansion from the node is unnecessary. The search procedure continues dequeuing the next element from P Q . (2) If the element is an object, it is inserted to the set of KN N . (3) Enqueue candidate objects retrieved from v into P Q and enqueue following nodes that should be explored from v into P Q . We will then check v . If v is attached with queries and the distance between v and q is smaller than ; v is inserted to the set of CHC . Finally, the network traversal is terminated when P Q is empty or the size of KN N is k . Then if P Q is not empty, all ele-ments in P Q are inserted to F SP Q . Otherwise, F SP Q is set as null.
 Al gorithm 2 Traverse the spatial network to nd the KNN results, CHC and FSPQ.
The procedure ForwardLookup is outlined in algorithm 3. Here OSHQ and OIHQ denote order-sensitive homo-geneity queries and order-insensitive homogeneity queries, respectively. We identify the queries in CHC that are is-sued at the same location of q and inserted these queries to OSHQ . A temporary set tmp is set as CHC OSHQ . We also check other queries in CHC and obtain the maximum distance M AX between q and these queries. According to Lemma 2, a threshold T H can be derived with M AX . Then we could invoke the procedure of advance network expan-sion. The procedure dequeues an element v from F SP Q iteratively until F SP Q is empty or v:dist is larger than T H or an object is found. If v:dist is larger than T H and no other object is found, OIHQ is set as tmp . Otherwise, the elements in tmp whose distance to q is smaller than ET H are inserted to OIHQ .
 A lgorithm 3 Forward-lookup mechanism
In this section, we evaluate the performance of SHI in terms of query processing time and the response time. Note that the response time of a query includes the waiting time in the queue. Speci cally, in the following experiments, the query arrival time is generated with a normal distribution as the demand surge shows in Figure 3. Basically, we generate a set of 100,000 queries, which are normally distributed with = 0 and 2 = 0 : 5. Then the data is split into 2,000 bins and these bins are mapped to 72 hours.

We used three real road networks: CA, NA, and SF, ob-tained from [12][13]. These datasets are popularly utilized to evaluate the query performance [2][11][10]. Speci cally, CA represents California road network containing 21,048 nodes and 21,693 edges. NA represents road network of North America with 175,813 nodes and 179,179 edges. SF repre-sents San Francisco road network with 174,956 nodes and 223,001 edges. The simulation was implemented by Java1.7 in Windows 7, and experiments are executed on 2.4GHz Core 2 CPU and 4GB RAM. We implement ROAD [11] the state-of-the-art one-by-one query processing algorithm, as the baseline method. Four methods with different policies of homogeneity identi cation, i.e., SHI-B , SHI-FOS , SHI-F and SHI-B-F , are implemented to demonstrate the effective-ness of various policies used in the proposed model. Here SHI-B corresponds to the SHI framework which only con-siders cache mechanism, i.e., the backward-lookup process; SHI-FOS corresponds to the model which only applies the forward-lookup process with the Order-Sensitive homogene-ity. In addition, SHI-F is the model to use the forward-lookup process with both Order-Sensitive homogeneity and Order-Insensitive homogeneity. SHI-B-F corresponds to the model both applying the backward-lookup process and the forward-lookup processes. The default settings of parame-ters in the following experiments are shown in the Table 1. The setting of the query distribution is to simulate the spa-tially correlated behavior, and the stronger spatial correla-tion exists in the higher percentage of clustered distribution. In addition, the parameter for the forward-lookup process is set as average edge distance in the road network. In this studies, the data will be the baseline for our observations by default.

We rst evaluate the performance of cache mechanisms utilized in the backward-lookup process of SHI , i.e., the SHI-B model. Note that the effectiveness of caching is highly impacted by the cache size and the frequency of object up-dates. In this experiment, we simulate the updates all as the insert events, and implement the ltering insert-check for cache validation, which is proposed in SQUARE [2]. Figure 7 measures the effectiveness of caches by setting the cache size as 0 (no cache in Figure 7), 1000, 2000 and 5000, accord-ing to the LRU replacement. In Figure 7, we also measure the maintenance overhead caused by the object update un-der various frequencies of updates. Here the update events are generated as the percentages 0.0001, 0.001 and 0.01 of 100,000 queries and are uniformly distributed in the tempo-ral domain.

Figure 7(a) shows the processing time of various mod-els. We can observe that SHI-B with the larger cache size has the better performance. Clearly, SHI-B with the larger cache size tends to reuse previous query results with the high probability. However, the cache will be invalid when the object updates appear frequently. Even worse, as can be seen in the case of percentage=0.01 in Figure 7(a), the check of cache validation is highly expensive, especially when the cache size is the larger one since more caches must be validated once an update appears. This observation con-forms our expectation that the cache mechanism inevitably suffers from performance degradation in case of frequent ob-ject updates. The overhead is generally left undiscussed in previous works.

In Figure 7(b) we also evaluate the query performance in terms of the response time. The similar phenomenon can also be observed in this study. Note that the response time of SHI increases signi cantly for the large cache size and frequent updates. It means that users have to spend more time to wait for their query results, suffering bad experiences when using the system.
We conduct experiments to evaluate the query process-ing time on various networks, various k, various numbers of objects and various object distributions, respectively. The results are shown in Figure 8, where baseline indicates the ROAD algorithm in the one-by-one fashion. In this experi-ment, the processing time is accumulated by the time used to perform network expansions in the system. We run the experiments on 100,000 queries with the default parameter setting shown in Table 1. In Figure 8(a), the query process-ing time on various networks is studied. As can be seen, SHI-B-F and SHI-F both outperform other models as ex-pected. The results show the feasibility of SHI in various network topologies. In addition, the processing time of SHI-F is close to that of SHI-B-F , meaning that the bene t from the forward-lookup process of checking order-sensitive and order-insensitive query homogeneity is more signi cant than the bene t from the cache-based backward-lookup process. It is worth mentioning that, we do not include data updates in this experiment. It is expected that cache-based solutions will perform badly in such a case.

Note that for SF data set, which contains extremely many edges, the cost of query processing time is higher than that of NA data set. But the processing time of SHI-F and SHI-B-F are drastically better than the baseline method, showing the effectiveness of the forward-lookup process in compli-cated networks. Note that the SHI-B performs poorly like the baseline model, since the query size is not so large and queries tend to associate at different nodes (it is difficult to have cache hits).

We also investigate the impact of k, with the range from 1 to 50 in Figure 8(b). It can be clearly seen that, SHI-F and SHI-B-F outperform other methods for various k setting. Figure 8(c) shows the experimental results by varying object number from 100 to 10,000, and we can see the similar result. It is noted that SHI performs signi cantly better than the baseline algorithm when number of objects is smaller since the processing time for single query is more expensive in this case. While queries belong to same group to ush out together, it will signi cantly improve the total throughput.
Finally, Figure 8(d) evaluates the performance of differ-ent object distributions, to simulate different behavior of the spatial correlation. As can be seen, when the number of object clusters increases, the required processing time is de-creased. For the case that objects are uniformly distributed, the performance of all methods are worse than the perfor-mance in cases of 100 and 1000 object clusters. This reason is that, for uniformly distributed objects, the search algo-rithm has to traverse more nodes to obtain KNN results since objects are not close to each other. Same as other experiments, the experimental result of various object dis-tributions also demonstrates the effectiveness of the forward-lookup process. Overall, SHI with forward-lookup process outperforms other models in terms of query processing time.
Here we evaluate the performance of different models in terms of the response time on various networks, various k, various numbers of objects and various object distributions, respectively. The experimental results are shown in Figure 9, 10, 11 and 12, respectively. The results clearly demonstrate that the forward-lookup process can bring signi cant bene t when we consider the response time. These investigations on various environments show the robustness of SHI in terms of the response time.

The more interesting experiment is to conform the obser-vation in Figure 3. The study on the burst arrival rate is shown in Figure 13, which query arrivals are generated as a normal distribution with = 0 and 2 = 0 : 5. The x-axis represents the time passed. The right y-axis represents the number of queries issued within the corresponding time, and the left y-axis represents the average response time of queries issued at that time. For ease of presentation, only the results of ROAD (baseline), SHI-FOS , and SHI-F are depicted. As shown in Figure 13, the state-of-the-art one-by-one query processing algorithm, i.e., ROAD , cannot process incoming queries on time. The queries issued after burst ar-rivals are still affected by these unconsumed queries. In fact, SHI-FOS and SHI-F are also encountered the same issue. But SHI-FOS and SHI-F can quickly handle burst queries as possible.
Note that if users can accept order-insensitive result (as the consideration of SHI-F ), the system can have the best throughput, and can return results to users in acceptable re-sponse time. The experimental results in Figure 13 conform our discussions on the illustrative example in Figure 3. We discussed in this paper an efficient framework, called SHI , to diminish the waiting time for KNN queries on road networks. We are the rst work to address the critical issue arising from the long waiting time. As compared to previous works which perform the query processing in the one-by-one fashion, SHI is devised to exploit the natural phenomenon, called query homogeneity , and to ush out a set of user re-quests simultaneously in group-by-group fashion. The effec-tiveness of SHI is also validated by our empirical studies. As our comprehensive studies in this paper, we demonstrate that SHI can signi cantly diminish the waiting time, thus better guaranteeing QoS in online services. This paper was supported in part by National Science Council of Taiwan, R.O.C., under Contract NSC 100-2221-E-001-016-MY3 and NSC 101-2221-E-006-246-MY3. [1] J. Brutlag. Speed matters for google web search. [2] Y.-J. Chen, K.-T. Chuang, and M.-S. Chen. Coupling [3] H.-J. Cho and C.-W. Chung. An Efficient and Scalable [4] H. Hu, D. L. Lee, and V. C. S. Lee. Distance Indexing [5] H. Hu, D. L. Lee, and J. Xu. Fast Nearest Neighbor [6] X. Huang, C. Jensen, and S. Saltenis. The Island [7] X. Huang, C. Jensen, and S. Saltenis. Multiple k [8] A. Jacobs. The pathologies of big data. Commun. [9] M. Kolahdouzan and C. Shahabi. Voronoi-based k [10] K. C. Lee, W.-C. Lee, and B. Zheng. Fast Object [11] K. C. Lee, W.-C. Lee, B. Zheng, and Y. Tian. ROAD: [12] F. Li. Real Datasets for Spatial Databases: Road [13] F. Li, D. Cheng, M. Hadjieleftheriou, G. Kollios, and [14] Y. Manolopoulos, A. Nanopoulos, A. N.
 [15] D. Papadias, J. Zhang, N. Mamoulis, and Y. Tao. [16] G. Rivlin. Wall ower at the web party. In The new [17] H. Samet, J. Sankaranarayanan, and H. Alborzi. [18] Z. Song and N. Roussopoulos. K-Nearest Neighbor [19] W. Tobler. A computer movie simulating urban [20] J. Zhang, M. Zhu, D. Papadias, Y. Tao, and D. L.
