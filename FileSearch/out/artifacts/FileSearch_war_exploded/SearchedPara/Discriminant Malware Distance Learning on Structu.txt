 The voluminous malware variants that appear in the Internet have posed severe threats to its security. In this work, we explore tech-niques that can automatically classify malware variants into their corresponding families. We present a generic framework that ex-tracts structural information from malware programs as attributed function call graphs, in which rich malware features are encoded as attributes at the function level. Our framework further learns discriminant malware distance metrics that evaluate the similarity between the attributed function call graphs of two malware pro-grams. To combine various types of malware attributes, our method adaptively learns the confidence level associated with the classifi-cation capability of each attribute type and then adopts an ensem-ble of classifiers for automated malware classification. We evaluate our approach with a number of Windows-based malware instances belonging to 11 families, and experimental results show that our automated malware classification method is able to achieve high classification accuracy.
 I.2.6 [ Artificial Intelligence ]: Learning; D.4.6 [ Operating Sys-tem ]: Security and Protection Malware, distance learning, metric learning, structure, graph match-ing, optimization, function call graph
Malware are responsible for a large number of malicious activi-ties in the cyber space, such as spamming, identity theft, and DDoS (Distributed Denial of Service) attacks. Behind the sheer number of malware instances, however, lies the fact that a large number of them came from the same origins. More than 75 percent of mal-ware detected belong to as few as 25 families, based on the 2006 Microsoft Security Intelligence report [15]. For the instances be-longing to the same malware family, we can study their common characteristics and develop defensive methods accordingly, much alike developing vaccines against a specific flu family ( e.g. , swine flu). Accurate prediction of the evolution trend of a malware family also enables us to deploy effective mitigation methods in advance and thus alleviate the damage caused by this malware family.
A question that naturally follows is: how should we classify a large number of malware instances into their corresponding fam-ilies ? Anti-Virus (AV) companies commonly rely on signatures, such as strings and regular expressions, to determine malware fam-ilies, but it is well known that signature-based methods are error-prone and can be easily evaded by intelligent malware programs. On the other hand, manually reverse-engineering every malware variant to figure out its lineage requires advanced skills and is often a time-consuming, sometimes even tedious, process.

Therefore, there is an urgent need of developing methods that can automatically classify malware instances into their correspond-ing families accurately. To achieve automated malware classifica-tion, we need to extract useful information  X  or features in par-lance of machine learning  X  from labeled samples for which we know their families, and build a model that predicts which family a newly observed malware instance belongs to based on the feature values it carries. Although it sounds a standard supervised learn-ing procedure, we are faced with a fundamental challenge when constructing malware features: the rich structural information con-tained in malware programs, such as their function call graphs and basic block graphs, is not amenable to traditional supervised learn-ing techniques, which usually operate on numerical vectorial rep-resentations of data objects.

Against this backdrop, the goal of this work is to develop a framework that automatically classifies malware instances accord-ing to their inherent rich structural information. This framework extracts the function call graph from each malware program, and collects various types of fine-grained features at the function level, such as what system calls are made and how many I/O read and write operations have been made in each function. For each type of features, our framework evaluates the similarity of two mal-ware programs by iteratively applying the following two basic tech-niques: (1) discriminant distance metric learning , which projects the original feature space into a new one such that malware in-stances belonging to the same family are closely clustered while clusters formed by different malware families are separated with large margins; (2) pairwise graph matching , which aims to find the right pairwise function-level matching between the function call graphs of two malware instances in order to measure their structural similarity. The similarity score estimated between two malware in-stances for each type of features reflects the likelihood that they should be classified into the same malware family  X  if observed f eature values of that type are used as our evidence . We further learn our confidence level in each type of evidence and henceforth build a classifier that predicts the family of a new malware instance by combining different types of evidences with their corresponding confidence levels.

In a nutshell, our key contributions are summarized as follows. (1) We present a generic framework that extracts structural infor-mation from a malware program and represents it as an attributed function call graph, where fine-grained malware features are en-coded as attributes associated with each function node in the graph. (2) We formulate the processes of discriminant distance metric learn-ing and pairwise graph matching as two optimization problems, and develop novel eigen-based methods to solve them. (3) Our framework adaptively learns the confidence levels associated with different types of evidences provided to the ensemble of classi-fiers by assigning increasingly higher penalty to those training sam-ples misclassified previously. (4) With extensive experiments, we demonstrate that our proposed method is able to classify malware instances into their corresponding families with high accuracy.
The remainder of this paper is organized as follows. Section 2 states the problem to be addressed in this work, and Section 3 de-scribes the overview of our methodology. Section 4 discusses how to extract features based on function call graphs. We further present our method for malware distance learning in Section 5 and how to use an ensemble of classifiers for automated malware classification in Section 6. Section 7 shows experimental results. We present re-lated work in Section 8 and draw concluding remarks in Section 9.
In this work, we are interested in the problem of classifying mal-ware instances into their corresponding families automatically. Let Y be the set of different malware families. To start with, we have a labeled dataset with n l elements, L = { ( x 1 , y 1 ) , ( x ) } where x i is a malware instance and y i  X  Y is the family that mal-ware x i belongs to, for 1  X  i  X  n l . The labeled dataset can include those samples manually labeled by malware experts who reverse-engineered the malware programs, or be obtained through consensus by major AV software. Our goal is to develop a model or classifier that can accurately predicts the family of an unseen mal-ware sample f : X  X  Y , where X denotes the set of all possible unseen malware samples. It is noted here the classifier f build only consider known malware families, and we are thus not interested in identifying new malware families.

In order to build a classifier f , we first need to extract useful information from each labeled malware instance x i . Feature ex-traction from malware programs can be done through either static analysis or dynamic analysis . Static analysis refers to studying a malware X  X  code statically without actually executing it, and by contrast, dynamic analysis runs the malware program (usually in a virtual controlled environment) and understands its run-time be-havior. Although dynamic analysis has the advantage of revealing the true behavior of often obfuscated malware programs, it requires a virtual execution environment, which makes it more demanding than static analysis. Hence, this study focuses on features extracted from only static analysis.

Static malware features considered in the literature include byte sequence n-gram [21, 11, 18], disassembly code [2], and PE header fields [23, 19]. These features, however, do not embody the rich structural information inherent in malware programs. The function call graph obtained from disassembly analysis, for instance, rep-resents the calling relationships among functions, and thus reflects the overall structure of the malware program. Compared with the Figure 1: Overview of our automated malware classification fr ame-work (solid lines are used for the training process, and dashed line for the process of classifying a new malware variant) aforementioned types of static features, structural information is more difficult to obfuscate , and can thus be used as robust features for classifying malware instances.

Such structural information, however, poses significant technical challenges, as it is not amenable to standard supervised learning methods, which usually operate on numerical vectorial representa-tions of data objects. In order to apply automated malware classifi-cation on structural information inherent in malware programs, it is necessary to solve the following problems: (1) How to extract and represent structural information from malware programs? (2) How to effectively compute the distance between two malware instances given their structural information? (3) How to build an automated malware classifier based on distance measures among malware pro-grams? Our work offers a framework that tackles these three prob-lems in a principled way, as illustrated in the following sections.
The overview of our automated malware classification frame-work is depicted in Figure 1. The training phase includes the fol-lowing four key steps.

Step 1: FCG-driven feature extraction. To extract structural information from a malware program, we first disassemble the mal-ware program, and build its function call graph. The function call graph is further used to drive the process of feature extraction: for every node (i.e., a function) in the graph, we extract various types of attribute , including what library APIs are made and how many I/O read and write operations have been made in this function. In-formation regarding each type of features is represented as a vector of numerical values. For example, for library API attribute, each el-ement in the vector provides the number of times a corresponding API has been called in this function. After Step 1, each labeled mal-ware program is abstracted into an attributed function call graph, where each function node contains a number of feature vectors.
Step 2: Discriminant malware distance learning. The next step concerns how to compute the distance between two malware distances represented as their attributed function call graphs. For each type of attribute, we project the original feature space onto a new one such that malware instances belonging to the same fam-ily are closely clustered while clusters formed by different mal-ware families are separated with large margins. Moreover, we per-form pairwise graph matching, which aims to find the right pair-wise function-level matching between the attributed function call graphs of two malware instances for the purpose of measuring their structural similarity.

Step 3: Training individual classifiers. For each type of fea-tures, once we have computed the similarity between any two la-beled malware instances, we train an individual classifier for it. Our framework is open to any classifier that, in order to classify a new sample, requires only information of a set of anchor in-stances , which are usually the subset of labeled samples in the orig-inal dataset. Such classifiers include the kNN classifier, for which the anchor instance set includes the k c losest instances from the test instance, and the SVM classifier, whose support vector contains all the anchor instances.

Step 4: Building ensemble of weighted classifiers. For each type of features we have considered, the similarity measure be-tween two malware instances reflects the likelihood that they be-long to the same family. Given a new malware variant, for each type of features, we form its evidence as the distance it is from each of its anchor instances as well as the label information of each anchor instance. The type of an evidence is defined to be the type of attribute from which it is formed. For different types of attribute , we can have different confidence levels about their evidences, be-cause some attribute types are more indicative of a malware X  X  lin-eage than the others. To learn the confidence level associated with a type of evidence, we use an Adaboost-like approach, which gives an increasingly higher penalty to training samples that are wrongly classified. We henceforth build a classifier that predicts the family of a new malware instance by combining different types of evi-dences according to their corresponding confidence levels.
The output of the training phase of our automated malware clas-sification framework is an ensemble of classifiers. Given a new unknown malware sample, we first construct its function call graph from the disassembly code, and for each function node in it, we extract different types of attribute. Next, for each type of attribute, we form its evidence that describes the distance between the new sample and the anchor instances as well as how each anchor in-stance is labeled. We then feed the evidence to the corresponding individual classifier. By combining all the evidences, the ensemble of weighted classifiers makes the final decision on which malware family it should be classified into.
Structural information inherent in a malware program can be rep-resented at two different resolutions: functions and basic blocks . The function call graph of a program, which is a directed graph, represents the calling relationships among the functions. A basic block in a program is a piece of code with a single entry point and a single exit point, and the transitions among basic blocks form the control flow graph of the program. In this work, we use function call graph (FCG for short) to drive the process of extracting impor-tant features from malware programs.

The FCG captures the calling relationship of a program, and each vertex in it represents a local function. For each local function, we first translate it into an intermediate language and then extract six types of attributes from it. They include opcode (the frequency of appearances for each opcode), API (the number of times each library API function is called), memory (the number of memory reading and writing operations made in this function), IO (the num-ber of I/O reading and writing operations), Register (the num-ber of reading and writing operations on each register), and Flag (the number of changes on each flag). For each attribute type, we represent it as a feature vector associated with the local function.
The output of the step of FCG-driven feature extraction is an at-tributed FCG , which contains an FCG with vertices each carrying a number of feature vectors, as illustrated in Figure 2. An example of extracting features over FCG is shown in the following, where this attributed FCG abstracts our knowledge about a malware program. In the next section, we shall discuss how to evaluate the similar-ity of two malware programs based on their attributed FCGs. As a number of notations will be used in the next few sections, we summarize all these notations in Table 1 for clarity.
F igure 3: Demonstration of malware distance metric learning
Automated malware classification requires methods to evaluate the distances among malware instances. Having extracted an at-tributed FCG graph for each malware program, we next look for the appropriate distance metric to compute the distance between two malware programs based on attributed FCG graphs.
Our search for malware distance metric is guided by the maxi-mum margin principle , i.e., the malware in the same family should be closely clustered while clusters formed by different malware families should have large margins to separate them. See Fig. 3 for a motivating example. Before distance metric learning, mal-ware from the same class may have a large distance than those from different classes based on the naive Euclidean distance (e.g., dist(a,b) &gt; dist(a,f) in Fig. 3(1)). After learning the ap-propriate distance metric, which projects data points in the original feature space into a different space, the intra-class distance is de-creased while the inter-class distance is increased. Following the same example, we have dist(a,f)&gt;&gt;dist(a,b) , as shown in Fig. 3(2).

More formally, let G i be the attributed function call graph of malware i where 1  X  i  X  n l , and E q be the feature vector of type q where q  X  T . Let D q malware G i and G j computed according to attribute type q the within-class distance S q among all pairs of malware belonging to the same family according to feature type q , is given by:
Similarly, the between-class distance S q squared distances among all pairs of malware belonging to different families according to attribute type q , is given by:
Thus following the maximum margin principle, we need to maxi-mize the between-class distance while minimizing the within-class distance for attribute type q , i.e.,
Note we use a trace difference criterion in Eq. (3). As is known in the machine learning community, it has some advantages over opti-mizing the trace quotient criterion (i.e., max S q b ity formulation, ease for manipulation, etc. To minimize Eq. (3), we need to compute pairwise malware distance D q type q , which will be shown next. malware samples i and j , their distance D ij can be computed through the graph distance between G i and G j . To simplify computation, we assume there exists one-to-one match between function nodes in and G j . Letting V m pairwise graph distance problem breaks down into the following two subproblems: (1) How to compute the optimal pairwise node How to compute the optimal pairwise node distance between and V n
For problem (1), we learn the pairwise malware graph match-ing matrix A ij , where A ij matches node n in malware G j , and A ij problem (1) the graph match A -learning problem . 1 For problem (2), supposing that F q malware i  X  X  attributed FCG, is a d q -dimension vector (note that varies with the feature type q ), our goal is to learn distance metric W q  X  &lt; d q  X  d , where d is the dimension of the new subspace after projection, w.r.t. each attribute type q , 2 : For example, if W = I , distance metric D is Euclidean distance. Actually, the learned distance metric  X  = WW T ,  X   X  &lt; is a symmetric semi-definite positive matrix, and now metric Mahalanobis distance. Note here W is required to be orthonormal, i.e., W T W = I . We call problem (2) the distance metric learning problem . This process is done for each attribute type
Once we have obtained distance metric W and pairwise graph matching matrix A , we define the pairwise malware distance for attribute type q (for simplicity, we ignore superscript where D im,jn is the node distance between node m in G ment ( node match ) for matching of node m in G i with node G assignment ( edge match ), where both node m  X  V i matches with not only the substitution of nodes but also the edge structure play a role in the computation of distance between the attributed FCGs of two malware programs (more details will be introduced in  X 6.4). A key observation is that the distance between two attributed FCGs contributed by edges mirrors the number of edge deletion/insertion operations, and thus if the graph matching is given, this portion of distance is fixed (see  X 6.4 for more details ). Define J ij Then we have: Then substituting Eq. (7) into Eqs. (1, 2), we have: G j = ( V j , E j ) , they may have different number of function nodes, values) are added to make a alignment. where
Substituting Eqs. (1, 2, 7) into the optimization goal in Eq. (3), we have: for each attribute type q , where
B = X and  X  q is the coefficient for the cost contributed by B associated with edge cost. As once the graph matching A is fixed, B is a con-stant and we thus need to solve the following optimization problem in each iteration:
Note in the above formulation, we need to solve: (1) distance met-ric
W for each attribute type q , (2) graph matching A during com-putation of U w and U b for pairwise malware distance.

Next, we present a learning framework to solve the above prob-lem of Eq. (10). The key idea is to apply the expectation max-imization algorithm [5], to iteratively update parameters A . More specifically, we repeatedly perform the following two steps: (1) estimate pairwise malware matching matrix A , given the current distance metric W ( X 5.3); (2) predict the optimal distance metric W , given the current pairwise malware matching matrix ( X 5.4). These two steps are iterated for several iterations. To sum-marize, the whole algorithm is illustrated in Alg. 1.
In Eq. (10), given the current graph matching A , the optimal solution W can be obtained according to the following theorem: matrix with eigenvalues  X  1  X   X  2  X   X   X   X   X   X  d and the correspond-ing eigenvectors U = [ u 1 , u 2 ,  X   X   X  , u d ] , then Moreover, the optimal W  X  = [ u 1 , u 2 ,  X   X   X  , u k ] subject to orthon-normal transformation.
 To apply Ky Fan X  X  theorem here, we first let H = ( U w  X  U We can thus obtain the optimal solution W with d smallest eigen-vectors of H .
We now discuss how to match nodes in the attributed FCGs of two malware programs. Note that the unary distance determined with Eq. (4), which represents the node distance; for pairwise distance D ferent cases, which are illustrated in Fig. 4, according to the graph structure of G i and G j . (1) There exist both an edge from node m to m 0 in G i and also an edge from n to n 0 in G j (Fig. 4(a)). It means the edge Algorithm 1 d istance metric learning algorithm 1: 2: is substituted with edge e ( m, m 0 ) and ( n, n 0 ) have been matched in the unary node matching process, no edit cost is needed for transforming one edge in another in G j , i.e., D (2) Only edge ( m, m 0 ) exists, or only edge ( n, n 0 ) edge exists (Fig. 4(b) or 4(c)). It means one edge insertion/deletion operation is needed. We assume all the edge insertion/deletion operation has the same cost, and thus assign D (3) Neither edge ( m, m 0 ) nor edge ( n, n 0 ) exist in (Fig. 4(d)). No edge edit operation is needed to transform edge
In order to perform pairwise graph matching to obtain A 1 , we first establish the following lemma:
L E MMA 1. Let p = |V i | X |V j | , a  X  &lt; p , r = ( m  X  1)  X |V between G i and G j , i.e., as shown in Eq. (5), is equivalent to solving: D M ing to the four cases discussed before.
 P ROOF . First note that finding the solution to min equivalent to solving: virtual node in the computation of Eqs.(12,17). After we get (min |V i | , |V j | ) pairwise one-to-one match, we just match the un-matched ( ||V i |  X  |V j || ) nodes to virtual nodes with null values.
Supposing a r = A i j relationship between Eq. (13) and Eq. (12). Clearly, In Eq. (5), for the node distance, for the edge distance,
By making a sum over of Eq. (15) and Eq. (16) on both sides, we have LHS = RHS, where LHS gives Eq. (13) and RHS gives Eq. (12). This completes the proof.

Optimal solution: E q. (12) is a discrete optimization problem, which is NP-hard and thus hard to handle. We relax the constraint a  X  { 1 , 0 } to a T a = 1 , and have:
Clearly, according to Theorem 1 (Ky Fan [26]), we obtain the op-timal solution of b is given by the smallest eigenvector of use b to obtain the pairwise graph matching A as follows.
Computation of pairwise graph matching A : Before com-puting pairwise graph matching matrix A ij for pairwise malware G and G j , firstly we set A ij = 0 . After obtaining b , we select the one with the largest value in it, i.e., find and set the pairwise matching matrix A ij (( t  X  1) / |V j | + 1) , n = mod (( t  X  1) , |V j | ) + 1 pairs that involve m or n will no longer be considered. Again, in the remaining pairwise node, we select the t 0 = arg max t 6 = t, m 0 = (( t 0  X  1) / |V j | + 1) , n 0 = mod (( t 0 until no node can be selected from b . If there are still unmatched nodes, they are matched with virtual node with null evidence val-ues. Finally, the updated solution A is used for malware distance computation.
With learned distance metric W q for each attribute type q next discuss how to combine results from classifiers developed for different attribute types. To this end, we use the Adaboost al-gorithm [6], which was proposed by Freund and Schapire, and can be used in conjunction with many other learning algorithms to further improve the classification performance. The key idea of Adaboost is that the classifiers are repeatedly improved by giving higher weights to those instances misclassified previously. Training stage. Given the distance calculated between the attributed FCGs of two malware programs, we use the standard support vec-tor machine (SVM) or the k-nearest neighbor classifier (kNN) for classification. For SVM, we use the Gaussian kernel, where: where  X  is a tunable parameter, and t is the average distance of the k -nearest neighbors for each malware, which plays the role of normalization. Note that the classifier built herein deals with pair-wise distances as the input for classification, rather than feature vectors as in most previous works. We further feed the similarity measures to the standard support vector machine (SVM) or the k-nearest neighbor classifier (kNN) for classification. Once we train a classifier with respect to each attribute type, we further use the Ad-aboost algorithm [6] to learn the confidence level associated with each classifier. Taking the SVM classifier as an example, suppose that we have obtained classification results using SVM for differ-ent attribute types on the training dataset. We then set the SVM classifier for feature type q correctly labeled malware otherwise Z iq = 0 . Our goal is to learn the confidence level each attribute type q , such that the classification error is minimized on the training malware samples. A similar approach is adopted for the kNN classifier.
 Classification stage. Having obtained the confidence level sociated with the classifier for each feature type q , we can use the ensemble of classifiers to classify new malware samples. Given a new malware instance, we first extract its attributed FCG for each individual classifier corresponding an attribute type form the evidence for this malware instance, including a set of an-chor instances and their labels (i.e., the family each anchor instance belongs to), as well as the distance that the new malware sample is from each anchor instance. For instance, if the SVM classifier is used, the anchor instances are exactly those in the classifier X  X  sup-port vector, and for the kNN classifier, the k closest instances from the new malware sample are the anchor instances. Based on the evidence provided for each attribute type as well as the confidence level associated with each type of evidence, the ensemble of clas-sifiers makes a decision on which family the new malware sam-ple belongs to, where it always chooses the malware family that collects the highest total confidence weight from all the individual classifiers.
In this section, we first introduce the malware dataset used in our experiments, and then show the performance of our method. Malware dataset . We use a malware dataset from Offensive Computing [17], which contains 526,179 unique malware variants collected in the wild. Using the VirusTotal website [24], we find that the average detection rate for 43 Anti-Virus software (such as NOD32, Symantec, McAfee, etc) is 60 . 5% . The malware dataset contains both packed and unpacked instances, and in our evalua-tion, we only use unpacked ones, and disasemble them with IDA pro [8].

Automated malware classification requires labeled malware in-stances for which we know their families. As reverse engineering each malware variant to obtain its family information, is a daunting task, we use majority agreement results from the five well-reputated Anti-Virus Software, McAfee, NOD32, Kaspersky, Microsoft, and Symantec. If more than three of them classify a malware into the same family, we label this malware as a variant belonging to this family. Through this way, we obtain 11 families of malware: Bagle(Ba) , Bifrose(Bi) , Ldpinch(Ld) , Swizzor(Sw) , Zbot(Zb) , Koobface(Ko) , Lmir(Lm) , Rbot(Rb) , Sdbot(Sd) , Vundo(Vu) , Zlob(Zl) . All these malware target the Windows system, and they belong to different categories, including worms, backdoor trojans, multi-component malware, etc. These malware have diverse functionalities, such as stealing user data, connection to remote IP addresses, establishment of IRC communications, etc.
Number of local functions in FCGs In Fig.( 5), we show the mean and standard deviation of the number of local functions in the FCGs for each malware family. We note that the number of local functions for the Lmir family varies more significantly than other families. Clearly, simple statistical test using the number of Figure 5: M ean number of functions per sample (one standard deviation). function nodes is not sufficient for identifying all malware f amilies. Next, we show the performance of our proposed method, which exploits the structural information in these malware instances for automated malware classification.
Five-fold cross validation: In the experiments, we use 80% of the malware samples from each family to train our model, and the remaining ones are used for testing the effectiveness of our ap-proach. This process is iterated for five times, and we report the averages as the classification performance.

Performance evaluation: The performance of a classifier can be quantified with precision , recall , and F 1 . Let the number of true positives, false positives, true negatives, and false negatives be n fp , n tn and n fn , respectively, w.r.t, a classifier. The precision The F 1 measure is the harmonic mean of precision and recall, i.e., F close to 1, implying that both precision and recall are close to 1.
Parameter settings: For the k NN classifier, we choose k tween 6 and 10 in our experiments. For malware similarity compu-tation of Eq. (18), we choose  X  between 0.3 and 0.7 in one set of experiments, and t is computed using the three nearest neighbors.
As the key components of our proposed method consists of dis-tance metric learning and ensemble of weighted classifiers, we com-pare the performances of the methods in different scenarios as shown in Table 2. It is noted that our method corresponds to the ES-dis scenario. The distinction among these different scenarios is helpful for us to understand the origin of performance improvement.
Overall improvement: We show the F 1 measure for each fam-ily of malware in Figs. (6a, 6b) at k = 6 and 10 , respectively, using the kNN classifier, and in Figs. (6d, 6e) at  X  = 0 . 3 and spectively, for the SVM classifier. In Table 3, we show the average performance improvement across all malware families. Clearly, for both classifiers, the F 1 measure is significantly improved using our method (i.e., ES-dis ). For instance, considering both the aver-age cases, our method improves over the best individual method by 9.3% for the SVM classifier, and by 23.2% for the kNN classifier.
Breakdown of performance improvement: In order to show how the performance improvement of our proposed method at-tributes to the two steps involved, distance metric learning and en-semble learning, we present in Table 4 the average F-1 measures for scenarios when distance learning is performed on individual Table 3: Average F-1 measure in terms of percentage across all families. Table 4: A nalysis of performance improvement. Values are shown in per-attribute types, as well as those scenarios when the ensemble learn-ing is used to combine individual classifiers without distance met-ric learning. We make two important observations from the re-sults. First, even for the individual classifier trained for a single attribution type, distance metric learning significantly improves the classification performance, except a few cases (e.g., when kNN is used and the attribute type is opcode, memory, or register). This suggests that distance metric learning indeed helps separate mal-ware instances belonging to different families, which eventually improves classification performance. Second, although the ensem-ble of classifiers does not provide significant performance improve-ment over the best classifier trained for a single attribute type, it does have the capability of approaching the performance of the best individual classifier trained for a single attribute. This is impor-tant, because from Figure 6 we observe that no individual classifier trained for a single attribute type is able to provide the best classi-fication performance for different malware families on a consistent basis. Hence, ensemble learning has the advantages of finding the best-performed individual classifier, and even provides slight per-formance improvement over it.
In the following, we discuss how different parameter setting of  X  and k affects the performance of the SVM and kNN classifiers, respectively. In a new set of experiments, we choose the parameter  X  from [0 . 1 , 0 . 3 , 0 . 5 , 0 . 7 ,  X   X   X  , 1 . 5 , 1 . 7 , 1 . 9] used for the SVM classifier, and k from [2 , 4 , 6 , 8 , 10 , 12 , 14 , 16] for the kNN classifier. The F 1 measures are shown in Fig. 6, where both distance metric learning and ensemble learning are performed in all these experiments. Clearly, irrespective of  X  and k the SVM and kNN classifier, respectively, our proposed method improves the classification performance over the individual classi-fier trained for each feature type. Moreover, we observe that there is no apparent trend of change of classification performance when we increase parameter  X  (or k ) for the SVM (or kNN) classifier. Actually, for the individual classifier trained for a single attribute type, we find that for some attribute types (e.g., opcode features for kNN and flag feature for SVM), changing the parameter of the clas-sifier leads to unstable classification performance. This may be due to the majority agreement kNN used in our approach, where for some malware samples, its k nearest neighbors may vary greatly. For SVM classifier, it is known that it can be influenced a lot by different kernel parameters.
We show in Fig. 7 the confusion matrix, which depicts how mal-ware instances belonging to each family are classified  X  or mis-classified  X  into different families. A confusion matrix is a tabular layout in which each column corresponds to a predicted class while each row represents a real class of instances. The ( i, j ) a confusion matrix shows the percentage of instances from class are labeled as class j . Hence, the diagonals of the confusion matrix (i.e., the ( i, i ) elements) provide the percentages of correctly la-beled instances, whereas the off-diagonals indicate the percentages of incorrectly labeled ones.

It is known that the source code of Sdbot was published in the In-ternet, and the development of Rbot was influenced by it [22]. This is verified in our results, as shown in Fig. 7, where 18% instances are labeled as Sdbot and 12% of Sdbot instances are labeled as Rbot . Moreover, for the Lmir family, the number of lo-cal function nodes in its attributed FCGs is highly divergent across different instances, as seen from Fig. 5, which adversely affects the computation of intra-family malware distances. This explains its poor classification performance relative to the other families.
In practice, a newly captured executable program may not belong to the malware families which are already known to us. It can come from an unknown malware family, or even be a legitimate program. Our proposed framework can be easily extended to deal with both scenarios with little extra computation cost. In the following we show how to use the standard kNN classifier for classifying an un-known malware variant or a legimate program. As discussed above, once we learn the distance metric, for each malware family, we ob-tain the shortest distance between any two labeled instances in this family. Given a new sample x t , if it is classified as family method, we further check its distance from its nearest neighbor in this family. If the distance d ( x t , y t ) &gt; (1 + )  X  the smallest distance between any two labeled samples in family and is a tunable parameter, then we flag the new sample as one not belonging to any known malware family. The smaller parame-ter is, a sample that does not belong to any known family will be detected as such with a higher probability, but a sample that indeed belongs to any known family is also more likely to be misclassified.
We further perform two sets of experiments. In the first one, we choose 30 samples from the Hupigon family, and the second one has 15 benign executable programs. is set to be 0 and the classification accuracy (shown as percentages) is as follows: Clearly, our scheme can detect samples that do not belong to kn own families with high accuracy.
Since the seminal works done by Schultz et al. [21] and Kolter et al. [11], machine learning has been used in a number of efforts to automatically distinguish malware from benign executable pro-grams (e.g., [18, 20]). In contrast to these earlier works on malware detection, our study focuses on malware classification, which aims to distinguish instances belonging to different malware families. Even if we treat malware detection as a binary classification p rob-lem, the machine learning method proposed in this work is still unique: rather than using distance metrics that are predefined in an ad-hoc way, we learn the distance metrics in order to separate different malware families with large margin. Our experimental re-sults tell us that distance metric learning plays an important role in improving the overall performance of automated malware clas-sification. In [16], Nataraj et al. conducted a comparative assess-ment of malware classification using binary texture analysis and dynamic analysis, and found that binary texture analysis performs as equally effectively as dynamic analysis but is much more effi-cient than dynamic analysis. Although we did not compare our proposed method against the two techniques they studied, we be-lieve that in order to improve the robustness of automated malware classification, we should consider using a combination of malware features extracted from malware programs. Hence, the structural information of malware programs considered in this work adds an-other layer of protection to those techniques that rely solely on bi-nary representations of the malware programs (e.g., binary texture analysis [16]) or features extracted from dynamic execution traces.
Most existing works on malware detection and classification [18, 20] use vector features, which are amenable to traditional classifi-cation techniques such as SVM and kNN. A few other efforts ( e.g. , [7, 14, 10, 1, 12, 13]) also considered using the structure infor-mation in malware programs. For instance, Hu et al. used FCGs extracted from malware programs for fast indexing, which aims to find the nearest neighbors of a new malware sample [7], and Kruegel et al. formulated the problem of polymorphic worm de-tection as coloring of control flow graphs [14]. In [25], Yan et al. compared the discriminative power of different types of malware features for automated malware classification. Our work differs from these efforts not only because our goal is to automatically classifying instances into their corresponding families but also our method is more generic as it learns malware distance metrics based on the structural information of labeled malware programs rather than using a predefined metric to evaluate malware similarity.
Another direction for malware research is clustering malware in-stances to identify groups of malware that share similar characteris-tics [3, 4, 9]. In contrast to malware clustering, automated malware classification trains malware classifiers from labeled data. Hence, the malware distance metric learning method proposed in this work is not suitable for malware clustering, as it requires labeled data to guide how to separate malware families with large margin. Some other contributions made in this work, such as FCG-driven feature extraction and pairwise graph matching, could be used for malware clustering as well.
In this paper, we present a generic framework that exploits the rich structural information inherent in malware programs for auto-mated malware classification. Towards this end, we use the func-tion call graph of a malware program to drive the process of feature extraction. We develop methods to compute the similarity of two malware programs based on their attributed function call graphs, and use an ensemble of classifiers that learn from the pairwise mal-ware distances and classify new malware instances automatically. In the future, we plan to improve the process of obtaining labeled samples for bootstrapping automated malware classification and will also consider transductive malware classification when only limited labeled samples are available.

