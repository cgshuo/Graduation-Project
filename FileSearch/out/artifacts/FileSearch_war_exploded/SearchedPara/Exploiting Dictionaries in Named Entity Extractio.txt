 We consider the problem of improving named entity recog-nition (NER) systems by using external dictionaries X  X ore specifically, the problem of extending state-of-the-art NE R systems by incorporating information about the similarity of extracted entities to entities in an external dictionary . This is difficult because most high-performance named en-tity recognition systems operate by sequentially classify ing words as to whether or not they participate in an entity name; however, the most useful similarity measures score entire candidate names. To correct this mismatch we for-malize a semi-Markov extraction process, which is based on sequentially classifying segments of several adjacent words, rather than single words. In addition to allowing a natural way of coupling high-performance NER methods and high-performance similarity functions, this formalism also all ows the direct use of other useful entity-level features, and pr o-vides a more natural formulation of the NER problem than sequential word classification. Experiments in multiple do -mains show that the new model can substantially improve extraction performance over previous methods for using ex-ternal dictionaries in NER.
 Categories and Subject Descriptors: H.3.1[Information Storage and Retrieval]: Content Analysis and Indexing X  Dictionaries ; I.2.6[Artificial Intelligence]: Learning General Terms: Algorithms, Experimentation.
 Keywords: Learning, information extraction, named en-tity recognition, data integration, sequential learning.
Named entity recognition (NER) is finding the names of entities in unstructured text. Well-studied cases of NER ar e  X  Both authors contributed equally to this research. identifying personal names and company names in newswire text ( e.g. , [5]), identifying gene and protein names in biomed-ical publications ( e.g. , [7, 20]), and identifying titles and authors in on-line publications ( e.g. , [25, 29]). Named en-tity recognition is an important step in deriving structure d database records from text.

In many cases, the ultimate goal of this information ex-traction process is to answer queries which combine infor-mation from structured and unstructured sources. For ex-ample, a biologist might want to look for publications about proteins from a particular superfamily, where the superfam -ily is defined in a structured database of biomedical informa -tion; a business analyst might want to find articles concern-ing companies in a particular industry sector; or an intelli -gence analyst might wish to look for documents that  X  X ink X  persons previously known to have engaged in suspicious ac-tivity. In each of these applications, NER is successful onl y to the extent that it finds entity names that can be matched to something in a pre-existing database.

When NER methods are used as the first step of such a query process, it is natural to want to optimize them so that they perform best on the most important entities X  i.e. , en-tities that appear in the external databases that will be use d in these structured queries. Moreover, it is reasonable to e x-pect that a large collection of names of known entities (such as the collection associated with some type in a structured database) would improve NER performance.

This paper investigates this problem X  i.e. , the task of improving NER systems using external dictionaries. This problem is surprisingly subtle. Naively, one might ex-pect that given a large dictionary, simply looking for ex-act matches to some dictionary entry would be a reasonable NER method. In fact, this is seldom the case. The sur-face form of a name in free text can vary substantially from its dictionary version, leading to issues analogous to thos e that arise in linking or  X  X e-duping X  heterogeneous databas e records [10, 32]. This problem is compounded in extract-ing from text which is informal or otherwise prone to noise and errors, such as the email corpus and the address corpus we consider in the experiments in this paper. Thus taking a good external dictionary and transforming it to a useful NER system is often difficult.

Conversely, taking a state-of-the-art NER system and in-corporating information about possible linkage to an exter -nal dictionary is also non-trivial. The primary issue here is that most high-performance NER systems operate by se-quentially classifying words as to whether or not they par-ticipate in an entity name, while record-linkage systems op -erate by scoring entire candidate names by similarity to an existing dictionary entry. This fundamental mismatch in representation means that incorporating dictionary infor ma-tion is awkward, at best.

In this paper we will discuss a new formalism for NER that corrects this mismatch. We describe a semi-Markov extrac-tion process which relaxes the usual Markov assumptions made in NER systems. This process is based on sequen-tially classifying segments of adjacent words, rather than single words. In addition to allowing a natural way of link-ing NER and high-performance record linkage methods, this formalism also allows the direct use of other useful entity-level features, such as the length of an entity. It is also arguably a more natural formulation of the NER problem than sequential word classification, in that it eliminates c er-tain decisions about problem encoding.

Below we will present the new model and describe a learn-ing algorithm for it. We then present experimental results for the new algorithm, discuss related work, and conclude.
Named entity recognition (NER) is the process of anno-tating sections of a document that correspond to  X  X ntities X  such as people, places, times and amounts. As an example, the output of NER on the email document might be A common approach to NER is to convert name-finding to a tagging task. A document is encoded as a sequence x of tokens x 1 , . . . , x N , and a tagger associates with x a parallel sequence of tags y = y 1 , . . . , y N , where each y i is in some tag set Y . If these tags are appropriately defined, the name segments can be derived from them. For instance, one might associate one tag with each entity type above, and also add a special  X  X ther X  tag for words not part of any entity name, so that the tagged version of the sentence would be A common way of constructing such a tagging system is to learn a mapping from x to y from data [3, 5, 27]. Typically this data is in the form of annotated documents, which can be readily converted to ( x , y ) pairs.

Most methods for learning taggers exploit, in some way, the sequential nature of the classification process. In gen-eral, each tag depends on the tags around it: for instance, if person names are usually two tokens long, then if y i is tagged  X  X erson X  the probability that y i +1 is a  X  X erson X  is increased, and the probability that y i +2 is a  X  X erson X  is de-creased. Hence the most common learning-based approaches to NER learn a sequential model of the data, generally some variant of a hidden Markov model (HMM) [15].

It will be convenient to describe our framework in the con-text of one of these HMM variants, in which the conditional distribution of y given x is defined as (Here we assume a distinguished start tag y 0 which begins every observation.) This is the formalism used in maximum entropy taggers [30], and it has been variously called a maxi -mum entropy Markov model (MEMM) [28] and a conditional Markov model (CMM) [21]. Inference in this model can be performed with a variant of the Viterbi algorithm used for HMMs. Given training data in the form of pairs ( x , y ), the  X  X ocal X  conditional distribution P ( y i | i, x , y i  X  1 learned from derived triples ( y i , i, x , y i  X  1 ), for example by using maximum entropy methods.
We will relax this model by assuming that tags y i do not change at every position i ; instead, tags change only at cer-tain selected positions, and after each tag change, some num -ber of tokens are observed. Following work in semi-Markov decision processes [35, 18] we will call this a conditional semi-Markov model (CSMM).

For notation, let S =  X  S 1 , . . . , S M  X  be a  X  X egmentation X  of x . Each segment S j consists of a start position t j , which is an index between 1 and M , an end position u j , and a label `  X  Y . A segmentation S is valid if  X  j , t j = u j  X  1 + 1. We will consider only valid segmentations.

Conceptually, a segmentation means that the tag ` j is given to all x i  X  X  between i = t j and i = u j , inclusive: al-ternatively, it means that the tags y t j . . . y u j corresponding index j such that t j  X  i  X  u j , and define the tag sequence y
For instance, a segmentation for the sample sentence above might be S = { (1 , 1 , Person), (2 , 4 , Oth), (5 , 6 , Loc), (7 , 8 , Time) } , which could be written as
A CSMM is defined by a distribution over pairs ( x , S ) of the form More generally, we use the term semi-Markov model (SMM). for any model in which each S j depends only on the label ` j  X  1 associated with S j  X  1 , and is independent of S j 0 j 6 = j , j 0 6 = j  X  1.
Two issues need to be addressed: inference for CSMMs, and learning algorithms for CSMMs. For inference, we will present below a version of Viterbi for CSMMs that finds the most probable S given x in time O ( NL | Y | ), where N is the length of x and L is an upper bound on segment length X  X hat is,  X  j , L  X  u j  X  t j . Since L  X  N , this infer-ence procedure is always polynomial. (In our experiments, however, it is sufficient to limit L to rather small values.)
For learning, inspection of Equation 1 shows that given training in the form of ( x , S ) pairs, learning the  X  X ocal X  dis-tribution P ( S j | t j , x , ` j  X  1 ) is not much more complex than for a CMM. 1 However, conditionally-structured models like the CMM are not the ideal model for NER systems: better performance can often be obtained by algorithms that learn a single global model for P ( y | x )[11, 24]. Below we will also present an extension of one such  X  X lobal X  learning algorith m to a semi-Markov distribution.

We emphasize that an SMM with segment length bounded by L is quite different from an order-L CMM, as in an order-L CMM, the next label depends on the previous L labels , but not the corresponding tokens. A SMM is also different from a CMM which uses a window of the previous L tokens to predict y i , since the SMM makes a single labeling decision for a segment, rather than making series of interacting deci -sions incrementally. In Section 3.5.3 we will experimental ly compare SMM X  X  and high-order CMMs.
The learning algorithm we use for training SMMs is de-rived from Collins X  perceptron-based algorithm for discri m-inatively training HMMs [11], which can be summarized as follows. Assume a local feature function f which maps a pair ( x , y ) and an index i to a vector of features f ( i, x , y ). Define and let W be a weight vector over the components of F . During inference we need to compute V ( W, x ), the Viterbi decoding of x with W , i.e. , For completeness, we will outline how V ( W, x ) is computed. To make Viterbi search tractable, we must restrict f ( i, x , y ) to make limited use of y . To simplify discussion here, we assume that f is strictly Markovian, i.e. , that for each com-ponent f k of f , For fixed y and y 0 , we denote the vector of f k ( g k ( i, x ) , y, y for all k as f 0 ( i, x , y, y 0 ).

Viterbi inference can now be defined by this recurrence, where y 0 is the designated start state: and then V ( W, x ) = max 0 y V x ,W ( | x | , y ).
The goal of learning is to find a W that leads to the globally best overall performance. This  X  X est X  W is found by repeatedly updating W to improve the quality of the Viterbi decoding on a particular example ( x t , y t ). Specifi-cally, Collin X  X  algorithm starts with W 0 = 0 . After the t -th example ( x t , y t ), the Viterbi sequence  X  y t = V ( W computed. If  X  y t = y t , W t +1 is set to W t , and otherwise W
The additional complexity is that we must learn to predict not only a tag type ` j , but also the end position u j of each segment (or equivalently, its length).
 Perceptron-Based SMM Learning Let f ( j, x , S ) be a feature-vector representation of segment S , and let F ( x , S ) = P | S | j =1 f ( j, x , S ). Let SCORE ( x , W ; S ) = W  X  F ( x , S ).
 For each each example x t , S t : 1. Use a modified version of Equation 3 to find the 2. Let W t +1 = W t . 3. For each i such that SCORE ( x t , W t ;  X  S i ) is greater As the final output of learning, return W , the average of the W t  X  X . To segment x with W , use Equation 3 to find the best segmentation.
 is replaced with After training, one takes as the final learned weight vector W the average value of W t over all time steps t .
This simple algorithm has performed well on a number of important sequential learning tasks [11, 2, 34], includ-ing NER. It can also be proved to converge under certain plausible assumptions [11].

The natural extension of this algorithm to SMM X  X  assumes training data in the form of pairs ( x , S ), where S is a segmen-tation. We will assume a feature-vector representation can be computed for any segment S j of a proposed segmenta-tion S , i.e. , we assume a function f ( j, x , S ). Again defining immediately, as long as it is possible to perform a Viterbi search to find the best segmentation  X  S for an input x .
For SMM Viterbi search, we need to restrict each f k to be of the form and as before, we let f 0 ( t, u, x , y, y 0 ) be the vector of f To implement Viterbi, we use the recurrence:
V x ,W ( i, y ) = (3) Conceptually, V ( i, y ) is the score of the best segmentation of the first i tokens in x that concludes with a segment S such that u j = i and ` j = y .
The SMM Viterbi search can be made more efficient if the segment size is bounded by some number L . In this case we can replace the i 0 &lt; i in the max term of Equation 3 to be i : i  X  L  X  i 0 &lt; i .
We also experimentally evaluated a number of variants of Collins X  method, and obtained somewhat better perfor-mance with the following extension. As described above, the algorithm finds the single top-scoring label sequence  X  y , and updates W if the score of  X  y is greater than the score of the correct sequence y (where the  X  X core X  of y 0 is W  X  F ( x , y In our extension, we modified the Viterbi method to find the top K sequences  X  y 1 , . . . ,  X  y K , and then update W for all  X  y  X  X  with a score higher than (1  X   X  ) times the score of y .
The complete algorithm is shown in Figure 1. The same technique can also be used to learn HMMs, by replacing S with y and Equation 3 with Equation 2.

Like Collins X  algorithm, our method works best if it makes several passes over the data. There are thus four parameters for the method: K ,  X  , L , and E , where E is the number of  X  X pochs X  or iterations through the examples.
In a semi-Markov learner, features no longer apply to indi-vidual words, but instead are applied to hypothesized entit y names. This makes it somewhat more natural to define new features, as well as providing more context.
 In the notation of this paper, recall that we assumed each SMM feature function f k can be written as f k ( j, x , S ) = f and the sequence x . Typically, g k will compute some prop-erty of the proposed segment  X  x t j . . . x u j  X  (or possibly of the tokens around it), and f k will be an indicator function that couples this property with the label ` j . Some concrete examples of possible g k  X  X  are given in Table 1.
Since any of these features can be applied to one-word segments ( i.e. , ordinary tokens), they can also be used for a HMM-like, word-tagging NER system. However, some of the features are much more powerful when applied to multi-word segments. For instance, the pattern  X  X + X+ X  (two capitalized words in sequence) is more indicative of a person name than the pattern  X  X + X . As another example, the  X  X ength X  feature is often informative for segments.
Since we are no longer classifying tokens, but are instead classifying segments as to whether or not they correspond to complete entity names, it is straightforward to make use of similarity to words in an external dictionary as a feature .
Let D be a dictionary of entity names and d be a distance metric for entity names. Define g D/d ( e 0 ) to be the minimum distance between e 0 and any entity name e in D : For instance, if D contains the two strings  X  X rederick flint-stone X  and  X  X arney rubble X , and d is the Jaro-Winkler dis-tance metric [37], then g D/d (  X  Fred  X  ) = 0 . 84, and g  X  Fred,please  X  ) = 0 . 4, since d ( X  X red X , X  X rederick flintstone X ) = 0 . 84 and d ( X  X red please X ,  X  X rederick flintstone X ) = 0 . 4. A feature of the form g D/d can be trivially added to the SMM representation for any pair D and d .

One problem with distance features is that they can be relatively expensive to compute, particularly for a large d ic-tionary. In the experiments below, we pre-processed each dictionary by building an inverted index over the charac-ter n -grams appearing in dictionary entries, for n = 3 , 4 , 5, discarding any  X  X requent X  n -grams that appear in more than 80% of the dictionary entries. We then approximate g D/d ( e by finding a minimum over only those dictionary entries that share a common non-frequent n -gram with e 0 .
To evaluate our proposed method for learning SMMs, we compared it with the HMM-based version of the same algo-rithm. This is a strong baseline. In previous experimental studies, Collins X  method has proved to be superior to max-imum entropy CMM-based tagging methods for NER and shallow parsing, and a close competitor to conditional ran-dom fields for POS tagging and shallow parsing [2, 11, 34]. Our extension to the method performs better on four of the five NER tasks we use (and also usually gives comparable improvements to both the SMM and HMM version of the algorithm X  X ee Section 3.5.1 below). In the experiments, we used  X  = 0 . 05, K = 2, and E = 20.

As features for the i -th token, we used a history of length one, plus the lower-cased value of the token, letter cases, and letter-case patterns (as illustrated in Figure 1) for al l tokens in a window of size three centered at the i -th token. Additional dictionary-based features are described below .
We experimented with two ways of encoding NER as a word-tagging problem. The simplest method, HMM-VP (1) , predicts two labels y : one label for tokens inside an entity, and one label for tokens outside an entity.

The second encoding scheme we used is due to Borthwick et al [5]. Here four tags y are associated for each entity type, corresponding to (1) a one-token entity, (2) the first token of a multi-token entity, (3) the last word of a multi-token entity, or (4) any other token of a multi-token entity. There is also a fifth tag indicating tokens that are not part of any entity. For example, locations would be tagged with Other, and a tagged example like is encoded (omitting for brevity the  X  X ther X  tags) as We will call this scheme HMM-VP (4) .

To add dictionary information to HMM-VP (1) , we simply add one additional binary feature f D which is true for every token that appears in the dictionary: i.e. , for any token x f ( x i ) = 1 if x i matches any word of the dictionary D and f ( x i ) = 0 otherwise. This feature is then treated like any other binary feature, and the training procedure assigns an appropriate weighting to it relative to the other features.
To add dictionary information to HMM-VP (4) , we again follow Borthwick et al [5], who proposed using a set of four features are analogous to the four entity labels: for each token x i the four binary dictionary features denote, respec-tively: (1) a match with a one-word dictionary entry, (2) a match with the first word of a multi-word entry, (3) a match with the last word of a multi-word entry, or, (4) a match with any other word of an entry. For example, the token x = X  X lintstone X  will have feature values f D.unique ( x i ) = 0, f (for the dictionary D used in Table 1).
Function g ( t, u, x ) Explanation Examples g =  X  x t , . . . , x u  X  value of segment g (1 , 1 , x ) =  X  X red X  g = u  X  t length of segment g (1 , 1 , x ) = 1 g = x t  X  1 value of left window (size 1) g (1 , 1 , x ) = none g
As an additional baseline NER method, we evaluated rote matching against a dictionary ( i.e. , extracting all phrases that exactly match a dictionary entry). This approach will have low recall when the dictionary is incomplete, and can-not handle variations between the way names appear in the text and the dictionary ( e.g. , misspellings or abbreviations). However, these results do provide an indication of the qual-ity of the dictionary.

We note that in some cases better performance might be obtained by carefully normalizing dictionary entries. One simple normalization scheme might be to eliminate case and punctuation; more complex ones have also been used in NER [6, 7, 19]. However, just as in record linkage problems, nor-malization is not always desirable ( e.g. ,  X  X ill X  is more likely to be a name than  X  X ill X , and  X  X T-6 X  is more likely to be a chemical than  X  X t 6 X ) and proper normalization is certainly problem-dependent. In the experiments below we do not normalize dictionary entries, except for making the match case insensitive.
 As a final  X  X aseline X  use of dictionary information for HMM-VP (1) and HMM-VP (4) , we extended the distance features described to tokens X  i.e. , for each distance d , we compute as a feature of token x i the minimum distance be-tween x i and an entity in the dictionary D . These features are less natural for tokens than for segments, but turned out to be surprisingly useful, perhaps because weak partial matches to entity names are informative.

To our knowledge features of this sort have not been used previously in NER tasks. We used the dictionaries described below, and three distance functions from the SecondString open source software package [9, 10]: Jaccard, Jaro-Winkle r, and SoftTFIDF.

Briefly, the Jaccard distance between two sets S and S 0 is treating them as sets of words. The Jaro-Winkler distance is a character-based distance, rather than a word-based dis -tance: it is based on the number of characters which appear in approximately the same position in both strings. TFIDF is another word-based measure. As with Jaccard distance, TFIDF scores are based on the number of words in com-mon between two strings; however, rare words are weighted more heavily than common words. SoftTFIDF is a hybrid measure, which modifies TFIDF by considering words with small Jaro-Winkler distance to be common to both strings.
Below we will use SMM-VP to denote our implementation of the algorithm of Figure 1. The parameters  X  , K and E are set as for HMM-VP (1) and HMM-VP (4) .

Like HMM-VP (1) , SMM-VP predicts only two label values y , corresponding to segments inside and outside an entity. We limit the length of entity segments to at most L , and limit the length of non-entity segments to 1. The value of L was set separately for each dataset to a value between 4 and 6, based on observed entity lengths.

We used the same baseline set of features that were used by HMM-VP (1) and HMM-VP (4) . Additionally, for each feature used by HMM-VP (1) , there is an indicator function that is true iff any token of the segment has that feature; an indicator function that is true iff the first token of the segment has that feature; and an indicator function that is true iff the last token of the segment has that feature. For instance, suppose one of the baseline indicator-function f ea-tures used by HMM-VP (1) was f office , where f office ( i, x , y ) was true iff x i has the value  X  X ffice X  and y t = i . Then SMM-VP would also use a function f office , any ( t, u, x ) which would be true if any x i : t  X  i  X  u has the value  X  X ffice X ; a function f office , first ( t, u, x ), which would be true if x t has the value  X  X ffice X ; and an analogous f office , last . Like the 4-state output encoding, these  X  X irst X  and  X  X ast X  features enable SMM-VP to model token distributions that are different for different parts of an entity.
 As an alternative to the distance features as described in Section 2.6, we also provided binary dictionary informatio n to SMM-VP by introducing a binary feature that is true for a segment iff it exactly matches some dictionary entity.
SoftTFIDF corresponds to the JaroWinklerTFIDF class in the SecondString code.
We evaluated our systems on five information extraction problems derived from three different datasets.

Address data. The Address dataset consists of 395 home addresses of students in a major university in India. The ad-dresses in this set are much less regular than US addresses, and therefore extracting even relatively structured fields like city names is challenging [4]. We found two external dictio-naries, a list of cities in India and a list of state names in India, and defined two corresponding extraction tasks: to identify city names, and to identify state names.
Email data. This dataset consists of email messages from the CSpace email corpus, which contains approximately 15,000 email messages collected from a management game conducted at Carnegie Mellon University. In this game, 277 MBA students, organized in approximately 50 teams of four to six members, ran simulated companies in different mar-ket scenarios over a 14-week period [22]. All messages sent during a one-day time period were manually tagged for per-son names. Person names in email headers are more regular than names in email bodies; to reduce the effect of this in our testing, we used only two header fields, the  X  X rom X  field and the  X  X ubject X  field. As a dictionary, we used a list of all students who participated in the game.

Jobs data. This is a set of 300 computer-related job post-ings posted in the 1990 X  X  to the Austin.jobs newsgroup. These postings were manually annotated for various entitie s by researchers from the University of Texas [8]. Two of the annotated entities are  X  X ompany names X  and  X  X ob titles X . To construct a dictionaries for these entities, we manually extracted company names and job titles for current hi-tech job listings in the Austin area from a large job-listing boar d.
In Table 2 we give a summary of the five extraction tasks, listing the number of instances, entities, and dictionary e n-tries; the average number of words in an entity; and the average number of words in dictionary entries. One indi-cation of the difference between the dictionary entries and the entities to be extracted is seen in the difference in the number of tokens per entity in the two cases.
The results of our initial experiments are shown in Ta-ble 3. Since many of these NER tasks can be learned rather well regardless of the feature set used, given enough data, in the table the learners are trained with only 10% of the available data, with the remainder used for testing. (We will later show results with other training set sizes.) All results reported are averaged over 7 random selections of disjoint training and test examples, and we measure accu-racy in terms of the correctness of the entire extracted enti ty ( i.e. , partial extraction gets no credit).

We compared each of the above NER methods on the five different tasks, without an external dictionary (first co l-umn), with an external dictionary with binary features (sec -ond column), and with an external external dictionary with distance features (third column). For each we report recall , precision and F1 values 3 . We make the following observa-tions concerning the results of Table 3.
For a more concise view of the results, Table 4 summarizes the impact on performance of the two novel techniques pro-posed in this paper X  X istance-based dictionary features an d semi-Markov extraction methods X  X nd compares them to the baseline method of HMM-VP (4) with binary dictionary features, which we take to be representative of the previous state of the art for using dictionary features in NER. F1 is improved on all five NER tasks if the baseline is modified by either using distance features rather than binary featur es (the line labeled binary  X  distance), or by using SMM-VP rather than HMM-VP (4) (the line labeled HMM  X  SMM). SMM-VP with distance features improves F1 scores over the baseline by an average of 44.5%. Below, we will perform a more detailed comparison of SMM-VP and HMM-VP (4) under various conditions. We focus on comparing the F1 performance of SMM-VP and HMM-VP (4) with distance features. We will not present any detailed comparisons of running times of the two methods since our implementation is not yet optimized for running
F1 is defined as 2*precision*recall/(precision+recall). Table 4: Summary of improvements in F1 measure over the baseline method of HMM-VP (4) with binary dictionary features. time. (As implemented, the SMM-VP method is 3-5 times slower than HMM-VP (4) , because of the more expensive dis-tance features and the expanded Viterbi search.)
Table 5 compares the F1 performance of (our implemen-tation of) Collins X  original method (labeled Collins) to ou r variant (labeled C &amp; S). We also compare the natural semi-Table 5: F1 performance of the voted perceptron variant considered here vs the method described by Collins.
 Markov extension of Collins X  method to SMM-VP. In both cases Collins X  method performs much better on one of the five problems, but worse on the remaining four. The changes in performance associated with our extension seem to affect both the Markovian and semi-Markovian versions of the al-gorithm similarly. In none of the five tasks does the change from Collins X  original method to our variant change the rel-ative order of the two methods. Table 6: Effect of increasing history size of HMM-VP (4) on F1 performance, compared to F1 perfor-mance of SMM-VP.
In Figure 2 we show the impact of increasing training set size on HMM-VP (4) and SMM-VP on three representative NER tasks. Often when the training size is small, SMM-VP is much better than HMM-VP (4) , but when the training size increases, the gap between the two methods narrows. This suggests that the semi-Markov features are less important when large amounts of training data are available. How-ever, the amount of data needed for the two methods to converge varies substantially, as is illustrated by the cur ves for address-city and email-person.
It is straightforward to extend the algorithms of this paper so that HMM-VP (4) can construct features that rely on the last several predicted classes, instead of only the last cla ss. Table 6 we show the result of increasing the  X  X istory size X  for HMM-VP (4) from one to three. We find that the perfor-mance of HMM-VP (4) does not improve much with increas-ing history size, and in particular, that increasing histor y size does not change the relative ordering of HMM-VP (4) and SMM-VP. This result supports the claim, made in Sec-tion 2.3, that a SMM-VP with segment length bounded by L is quite different from an order-L HMM.
We re-ran two of our extraction problems on alternative dictionaries to study sensitivity to dictionary quality. F or emails we used a dictionary of 16623 student names, ob-tained from students at universities across the country as part of the RosterFinder project [36]. For the job-title ex-traction task, we obtained a dictionary of 159 job titles in California from a software jobs website 4 . Recall that the original email dictionary contained the names of the peo-ple who sent the emails, and the original dictionary for the Austin-area job postings was for jobs in the Austin area.
Table 7 shows the result, for HMM-VP (4) and SMM-VP with distance features. Both methods seem fairly robust http://www.softwarejobs.com to using dictionaries of less-related entities. Although t he quality of extractions is lowered for both methods in three of the four cases, the performance changes are not large.
Besides the methods described in Section 3.1 for integrat-ing a dictionary with NER systems [5, 7], a number of other techniques have been proposed for using dictionary informa -tion in extraction.

A method of incorporating an external dictionary for gen-erative models like HMMs is proposed in [33, 4]. Here a dictionary was treated as a collection of training examples of emissions for the state which recognizes the correspond-ing entity: for instance, a dictionary of person names would be treated as example emissions of a  X  X erson name X  state. This method suffers from a number of drawbacks: there is no obvious way to apply it in a conditional setting; it is highly sensitive to misspellings within a token; and when the dictionary is too large or too different from the training text, it may degrade performance.

In concurrent work by one of these authors, a scheme is proposed for compiling a dictionary into a very large HMM in which emission and transition probabilities are highly c on-strained, so that the HMM has very few free parameters. This approach suffers from many of the limitations described above, but may be useful when training data is limited.
Krauthammer et al [23] describe an edit-distance based scheme for finding partial matches to dictionary entries in text. Their scheme uses BLAST (a high-performance tool designed for DNA and protein sequence comparisons) to do the edit distance computations. However, there is no obvi-ous way of combining edit-distance information with other informative features, as there is in our model. In experimen -tal studies, pure edit-distance based metrics are often not the best performers in matching names [10]; this suggests that it may be advantageous in NER to be able to exploit other types of distance metrics as well as edit distance.
Some early NER systems used a  X  X liding windows X  ap-proach to extraction, in which all word n -grams were clas-sified as  X  X ntities X  or  X  X on-entities X  (for n of some bounded size) ( e.g. , [16]). Such systems can easily be extended to make use of dictionary-based features. However, in prior ex -perimental comparisons, sliding-window NER system have usually proved inferior to HMM-like NER systems. Sliding window approaches also have the disadvantage that they may extract entities that overlap.

Another mechanism of exploiting a dictionary is to use it to bootstrap a search for extraction patterns from unla-beled data [1, 12, 14, 31, 38]. In these systems, dictionary entries are matched on unlabeled instances to provide  X  X eed  X  positive examples, which are then used to learn extraction patterns that provide additional entries to the dictionary . These extraction systems are mostly rule-based (with some exceptions [12, 14]), and appear to assume a relatively clea n set of extracted entities. In contrast our focus is probabil is-tic models and the incorporation of large noisy dictionarie s.
To our knowledge, semi-Markov models have not been pre-viously been used for information extraction, although the y have been used in other domains [18, 35]. To our knowl-edge, the SMM with dictionaries is also the first method that can combine arbitrary similarity measures on multi-word segments with a Markovian, HMM-like extraction-learning algorithm. In future work, we plan to explore adapting the semi-Markov NER learning algorithms discussed here to conditional random fields [24, 34].
In many cases, the ultimate goal of an information ex-traction process is to answer queries which combine infor-mation from structured and unstructured sources. In these applications, NER is successful only to the extent that it finds entity names that can be matched to something in a pre-existing database. However, extending state-of-the-art NER systems by incorporating an external dictionary is dif-ficult. In particular, incorporating information about the similarity of extracted entities to dictionary entries is a wk-ward, because the best NER systems operate by sequentially classifying words as to whether or not they participate in an entity name, while the best similarity measures score entir e candidate names.

To correct this mismatch we relax the usual Markov as-sumptions, and formalize a semi-Markov extraction process . This process is based on sequentially classifying segments of several adjacent words, rather than single words. In addi-tion to allowing a way of coupling high-performance NER methods and high-performance record linkage metrics, this formalism also allows the direct use of other useful entity-level features (such as the length of entity). It also provid es an arguably more natural formulation of the NER prob-lem than sequential word classification. For instance, in the usual formulation, one must design a new set of output tags (and make a corresponding change in the tag-to-entity decoding scheme) to account for distributional differences between words from the beginning of an entity and words elsewhere in an entity. In the semi-Markov formulation, one merely adds new features for entity-beginning words.
We compared our proposed algorithm to a strong base-line NER, which uses Collins X  perceptron-based algorithm for training an HMM and a state-of-the art, multi-label en-coding for dictionary information. The new algorithm is surprisingly effective: on our datasets, it always outperfo rms the previous baseline, sometimes dramatically.
 The authors thank the reviewers for this paper for a num-ber of substantive comments which greatly improved the fi-nal version. The preparation of this paper was supported in part funded by grants from the Information Process-ing Technology Office (IPTO) of the Defense Advanced Re-search Projects Agency (DARPA), as well as National Sci-ence Foundation Grant No. EIA-0131884 to the National In-stitute of Statistical Sciences, and a contract from the Arm y Research Office to the Center for Computer and Communi-cations Security (CyLab) at Carnegie Mellon University. [1] E. Agichtein and L. Gravano. Snowball: Extracting [2] Y. Altun, I. Tsochantaridis, and T. Hofmann. Hidden [3] D. M. Bikel, R. L. Schwartz, and R. M. Weischedel. [4] V. R. Borkar, K. Deshmukh, and S. Sarawagi.
 [5] A. Borthwick, J. Sterling, E. Agichtein, and [6] R. Bunescu, R. Ge, R. J. Kate, E. M. Marcotte, R. J. [7] R. Bunescu, R. Ge, R. J. Mooney, E. Marcotte, and [8] M. E. Califf and R. J. Mooney. Bottom-up relational [9] W. W. Cohen and P. Ravikumar. Secondstring: An [10] W. W. Cohen, P. Ravikumar, and S. E. Fienberg. A [11] M. Collins. Discriminative training methods for [12] M. Collins and Y. Singer. Unsupervised models for [13] K. Crammer and Y. Singer. Ultraconservative online [14] M. Craven and J. Kumlien. Constructing biological [15] R. Durban, S. R. Eddy, A. Krogh, and G. Mitchison. [16] D. Freitag. Multistrategy learning for information [17] Y. Freund and R. E. Schapire. Large margin [18] X. Ge. Segmental Semi-Markov Models and [19] D. Hanisch, J. Fluck, H. Mevissen, and R. Zimmer. [20] K. Humphreys, G. Demetriou, and R. Gaizauskas. [21] D. Klein and C. D. Manning. Conditional structure [22] R. E. Kraut, S. R. Fussell, F. J. Lerch, and J. A. [23] M. Krauthammer, A. Rzhetsky, P. Morozov, and [24] J. Lafferty, A. McCallum, and F. Pereira. Conditional [25] S. Lawrence, C. L. Giles, and K. Bollacker. Digital [26] N. Littlestone. Learning quickly when irrelevant [27] R. Malouf. Markov models for language-independent [28] A. McCallum, D. Freitag, and F. Pereira. Maximum [29] A. K. McCallum, K. Nigam, J. Rennie, , and [30] A. Ratnaparkhi. Learning to parse natural language [31] E. Riloff and R. Jones. Learning Dictionaries for [32] S. Sarawagi and A. Bhamidipaty. Interactive [33] K. Seymore, A. McCallum, and R. Rosenfeld.
 [34] F. Sha and F. Pereira. Shallow parsing with [35] R. S. Sutton. Integrated architectures for learning, [36] L. Sweeney. Finding lists of people on the web. [37] W. E. Winkler. Matching and record linkage. In [38] R. Y. Winston Lin and R. Grishman. Bootstrapped
