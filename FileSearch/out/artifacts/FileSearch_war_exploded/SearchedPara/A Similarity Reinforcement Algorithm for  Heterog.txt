 The performance of many data mining algorithms such as document clustering and between the data objects in the input space [1] [30]. It is therefore important to calcu-late the similarity as effectively as possible [28]. of data objects. In the original vector space model (VSM) [23],  X  X erms X  (keywords or stems) were used to characterize queries and documents, creating a document-term relationship matrix where it is straightforward to compute the similarities between and among terms and documents by taking the inner product of the two corresponding row or column vectors. Dice, Jaccard and Cosine measurements[20] are a few classi-cal methods that use the document-term relationship to measure the similarity of documents for retrieval and clustering purposes. Deerwester and Dumais [9, 10] thought that the concept in a document might not be well presented by keywords they Singular Vector Decomposition (SVD) method to map the document-term matrix into some lower dimension matrix where each dimension associates with a  X  X idden X  con-cept, then the similarity of text objects (documents or queries) are measured by their relationships to these  X  X oncepts X  rather than the key works they contained. method is also called co-citation. Kessler [14] measured the similarity of two journal called bibliographic coupling. Co-citation and bibliographic coupling had been suc-cessfully used to cluster scientific journals [18]. With the advent of World Wide Web, calculate the similarity of web objects. Dean [8] and Kleinberg [15] used hyper-links among a web pages community to discover similar web pages. Larson [16] and Pit-similarity of web pages. In the Collaborative Filtering [12] and Recommendedr Sys-tems [21] field researchers tried to analyze the similarity of peoples by examining the people-document and people-artifacts relationship respectively. measure the similarity of data objects. However, these approaches run into serious problems when various information applica tions require a more real and accurate similarity measuring method where multiple types of data objects and their relation-ship must be handled in an integrated manner. Thus in the extended VSM [11], other related spaces via inter-type rela tionships. By doing so, information from computation were obtained through the calculation on these enhanced feature vectors. The extended feature vector had been used for document search [25] or clustering vector using the frequent terms appeared in the top documents retrieved by the query and improved the search effectiveness, the idea of using terms found in related documents to extend the query term vector is also referred to as  X  X uery Expansion X . Similarly, Brauen [4] modified document vector by adding or deleting the terms in the referred to as  X  X ynamic Document Space X  method [24]. measuring the similarity of their related data objects. For example, Raghavan and Sever [18] tried to measure the similarity of two queries by calculating the similarity queries using the similarity of their clicked web pages and cluster web pages using the similarity of the queries that lead to the selection of the web pages. Wen [19] and Su the similarity of the documents that retrieved by queries; they calculated the similarity of documents in a similar way. Although research works introduced above used inter-not consider the mutual reinforcement effect on similarities of the interrelated hetero-geneous data objects. Most recently, Wang et, al.[29] proposed an iteratively rein-data type. Their method was shown to be eff ective for clustering and is much related finding the best cluster for individual documents, Wang X  X  algorithm may not be very precise when used to calculate the similarity of individual data objects. Davidson analyzed multiple term document relationships by expanding the traditional document-term matrix into a matrix with term-term, doc-doc, term-doc, and doc-term sub-matrices. He proposed that the links of the search objects (web-page or terms) in the expanded matrix could be emphasized. With enough emphasis, the principal ei-genvector of the extended matrix will have the search object on top with the remain-idea is sounding, he didn X  X  point the reason that difference kind of relationship can be calculated in a unified manner in his paper. Then we propose a novel iterative similar-ity learning approach to measure the similarity among the objects combining inter-type relationship over the Intra-and Inter-Type Relationship Matrix (IITRM). Our proposed algorithm is based on an intuitive assumption that the intra-relationship ships (such as latent term association discovered by LSI) among heterogeneous data objects, which can be used to improve the quality of various information applications that require the combination of information from different data sources. Experimental results the MSN logs dataset show that our algorithm outperforms the traditional Cosine similarity. heterogeneous data sources in a unified manner, which we call it as an Inter-and Intra-Type Relationship Matrix (IITRM) and the problem formulation of similarity measure. In Section 3, we will present an information-processing assumption that form the theo-retical basis of our proposed study and the unified similarity calculating algorithm that section 4. We conclude this paper and describe our future work in Section 5. inter-type relationships among data objects from two data sources in a unified man-Then we will present the Intra-and Inter-Type Relationship Matrix (IITRM) to repre-sent a set of heterogeneous data objects and their inter-relationships. 2.1 Second-Order IITRM x relationship from the x th object in S i to the j th object in S j . stand for the inter-type relationships from objects in X to objects in Y and inter-type relationships from objects in Y to objects in X respectively. If we merge data spaces X and Y into a unified data space U , then, previous inter-and intra-type relationships R as shown in Eq. (1) below: lationship Matrix and denote as 2 IITRM L . The 2 IITRM L matrix can be used to explain a lot of real world information application scenario s. For example, if we only consider one data space: the web pages; and one type of intra-type relationship: the hyperlink rela-tionship, the 2 IITRM L matrix is reduced to the link adjacency matrix of the web graph. a web page as defined in the PageRank algorithm [5], we would be actually analyzing two data spaces: user , web page , and one inter-(browsing), two intra-(hyperlink, user endorsement relationship) type similarities as shown in Figure1. Where, L user is the endorsement relationship matrix for user space, L bowse is the brows-ing relationship matrix between user space and web page space; L hyperlink is the hyper-way of representing web objects and their relationships. 2.2 Intra-and Inter-ype Relationship Matrix As the second-order IITRM, we present the formal matrix that represents both intra-and inter-type relationships among data objects from heterogeneous data sources in a unified manner. Using the notations in the first paragraph of this section, Eq. (1) can N interrelated data spaces, as shown in Eq. (3). spaces except x S . We can rewrite IITRM as below: objects from heterogeneous data sources coul d also be iteratively reinforced by inter-and intra-type relationships among heterogeneous data spaces under a simple as-sumption. More specifically, this reinforcem ent process can also be modeled as an iterative calculation over IITRM. Following that is the convergence proof of this algorithm. 3.1 Similarity Reinforcement Algorithm Firstly, let us interpret our basic assumption,  X  the intra-relationship should affect the inter-relationship, and vice versa.  X  We believe iteratively reinforcement the similarity of a set of heterogeneous data objects by their inter-and intra-type relationships can forcement calculation would discover some hidden similarities between data objects as illustrated in Figure 2. with objects p 1 , p 2 and p 3 in data space via some inter-type relationship. The objects q and q 2 in A are considered simila r because they link to the same object p 2 in B. p 1 objects converge. low equations over IITRM: entries of similarity matrices will between zero and one in the proof of lemma 2 in the appendix. However, since the similarity of the same object should be one, we can assign the diagonal of the similarity matrix a score of 1. Then we rewrite the recursive equations as: Where (6) the basic Similarity Equations of Similarity Reinforcement Algorithm (SRA). We choose initial value iteration algorithm. We experimented with various values for the parameters 1  X  and  X  in equation (5) and (6), and found little difference in the solution. In our experiments, 3.2 Convergence Proof We give a proof summary of the existence and uniqueness for the basic Similarity Equations of our proposed Similarity Reinforcement Algorithm (SRA). uct AB  X  is, Definition 2. The Row-First Vectorization of a matrix mn AR  X   X  , denoted as A be represented as 12 (,,, ) T m Aaa a = over ()() T ABA A A B = X  Lemma 2. The matrices x L and x L defined in the basic SRA equations are bounded. non-decreasing. Theorem 1. The interactive iteration basic SRA equations converge to a unique solution. Proof: from lemma 2 and 3 we know that x L and x L are bounded and non-decreasing, so they converge to some solution. Let X  X  prove the uniqueness of the solution. tions. Then, element in x L correspond to () x lg is (, ) x lij , we have For all the diagonal elements This leads to the conclusion that '' , x xx x LLLL == perimental results based on cosine similarity and our proposed SRA. This experiment posed SRA achieves 80.6% improvement on the precision of similar queries. 4.1 Dataset In order to study the effectiveness of SRA for measuring the similarity of web objects, experiments are conducted on a real user query click-through log collected by the MSN Web search engine in December, 2003. It contains about 4.2 million query requests recorded sampled from a period of six hours. The log we obtained has al-with the URL of one clicked web page. A single query (or web page URL) can occur multiple times in the query click-through log. average query length is about 2.7 words. A ll URLs are converted into canonical form and collapsing sequences like  X ..\.. X . Each UR L is considered as a feature, while each query is treated as an object. (We can also treat URLs as objects, and treat queries as features). Our proposed algorithm can solve similarities between objects and between features at the same iteration.) The weight for a query on a URL is the frequency of the query leading to the URL. 4.2 Evaluation Metrics Since our proposed algorithm aims to find better similarity between objects by comb-evaluate the performance. Given an object as input, we ask 10 volunteers to identify precision is defined as number of correct similar objects tagged by the volunteers. The final relevance judg-ment for each object is decided by majority vote. In our experiment, | | N is set as 10. 4.3 Finding Similar Queries cameras, Disney, mapquest, msn content, Presario 2100, united airlines, and weather We found that SRA outperforms the cosine similarity in precision by 80.6%. model, we found that our proposed algorithm not only can filter some un-related queries, but also can find some close-related laptop models. In Table 1 the tag  X  X  X  cates  X  X ot similar X . Although the cosine similarity returns some similar queries (the 1  X  Presario 2100  X  and  X  Linux Compaq 2100  X  share some clicked web pages, how-ever, those web pages discuss how to install Linux in Presario 2100, and therefore, those common clicked web pages is actually a kind of  X  X oise feature X  for  X  X resario 2100 X  , which causes  X  Linux Compaq 2100  X  to be returned as a similar query by cosine similarity. On the other hand, SRA finds out similar models which are not revealed by the cosine similarity. Although different models have many different clicked web pages, those clicked web pages are computed as  X  X imilar X  since they are queried by  X  X imilar X  queries, such as  X  X ompaq Presario X  ,  X  Compaq notebook X ,  X  X ompaq laptop X  , etc. Hence, different models have higher similarity based on SRA than based on cosine similarity. 1 Compaq Presario Y Compaq Presario Y 2 Compaq notebook Y Compaq notebook Y 3 Compaq laptop Y Compaq laptop Y 4 online Compaq Presario Y online Compaq Presario Y 5 Compaq Presario laptop Y Compaq Presario laptop Y 6 compaque N Compaq Presario 9642 Y 7 Notebook price compare N Presario 2800 sale Y 8 Compaq support N Compaq 2575us Y 9 Linux Compaq 2100 N Presario 9642 Y 10 Used Compaq reseller N Compaq batteries N propose a novel iterative similarity learning approach to measure the similarity among the objects combining inter-type relationship over the Intra-and Inter-Type Relation-ship Matrix (IITRM). apply our approach to more complex settings, such as in digital libraries, where there are more types of objects, so as to demonstrate further the generality of SRA. Besides, we will give some variations of SRA in our future work. Jun Yan thanks the support of Professor Qiansheng Cheng. 
