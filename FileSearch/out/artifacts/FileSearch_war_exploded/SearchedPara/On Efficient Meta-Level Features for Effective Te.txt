 This paper addresses the problem of automatically learn-ing to classify texts by exploiting information derived from meta-level features (i.e., features derived from the original bag-of-words representation). We propose new meta-level features derived from the class distribution, the entropy and the within-class cohesion observed in the k nearest neighbors of a given test document x , as well as from the distribution of distances of x to these neighbors. The set of proposed fea-tures is capable of transforming the original feature space into a new one, potentially smaller and more informed. Ex-periments performed with several standard datasets demon-strate that the effectiveness of the proposed meta-level fea-tures is not only much superior than the traditional bag-of-word representation but also superior to other state-of-art meta-level features previously proposed in the litera-ture. Moreover, the proposed meta-features can be com-puted about three times faster than the existing meta-level ones, making our proposal much more scalable. We also demonstrate that the combination of our meta features and the original set of features produce significant improvements when compared to each feature set used in isolation. I.5.4 [ Applications ]: Text processing; Algorithms; Experimentation Classification; Meta-level features This work was partially supported by CNPq and CAPES.
Automated Text Classification (ATC) is one of the pri-mary applications of machine learning which exploits the general paradigm of supervised learning. Given a set of training documents classified into one or more predefined categories, the task of ATC is to automatically learn how to classify new (unclassified) documents, using a combina-tion of features of these documents that associates them to categories. ATC has been used in a number of different applications: automatic indexing, document organization, text filtering, word sense disambiguation, hierarchical cate-gorization of web pages, among others [21]. Consequently, a number of techniques have been proposed to deal with ATC [3, 16].

A recent trend that has emerged for ATC, that works in the data engineering level instead of in the algorithmic level, is the introduction of meta-level features 1 that can replace or work in conjunction with the the original set of (bag-of-words-based) features [12, 13, 18]. Such meta-level features, which are usually manually designed and extracted from other features, capture intrinsic relationships among a pair ( document,class ) or a triple ( document,class,algorithm ). These meta-level features can capture insightful new infor-mation about the unknown underlying data distribution that relates the observed patterns to the associated category.
However, despite their potential, meta-level features have not been extensively studied in multi-class ATC tasks. Specif-ically, they were not evaluated with the most traditional benchmarks adopted to compare algorithms for this task (e.g., 20NewsGroups, Reuters, WebKB, Medline, RCV1 and ACM). In this paper we fulfill this gap. Moreover, inspired by recent work [9, 25] which takes into account the labels of training documents to generate meta-level features, we propose a new set of meta-level features based on the lazy classifier method kNN. These new meta-level features ex-ploit point-wise distances, the entropy, and the class distri-butions observed in the example X  X  neighborhood. In more details, our meta-level features are computed by learning the class distribution observed in the k nearest neighbor set of a given test document x , by analyzing the distribution of distances of x to these neighbors as well as the within-class cohesion and entropy of this neighborhood.
In this paper, we will use the terms  X  X eta-level features X  and  X  X eta-features X  interchangeably.
In our experiments, the proposed meta-level features pro-duced effectiveness not only much superior than the tradi-tional bag-of-words representation (up to 45% in MacroF 1 and 16% in MicroF 1 ) but also superior to other state-of-art meta-level features previously proposed in the literature [9, 25] (up to 7% in MacroF 1 and 6% in MicroF 1 ), when used to derive SVM-based classifiers. We also empirically demon-strate that further improvements can be obtained with the combination of some (automatically filtered) subsets of our meta features and the original set of features (bag-of-words) with gains of up 5% over the best feature set used in isolation (usually, the meta-level ones).

Moreover, the newly proposed meta-level features are about three times faster to compute than the state-of-art kNN-based meta level features proposed in [9, 25], making our proposal much more scalable. Finally, in order to improve even further the efficiency of the computation of the kNN based meta-level features, we propose a new GPU-based par-allel implementation of the kNN algorithm designed to work with high dimensional, sparse datasets, as is the case of tex-tual datasets.

In sum, the main contributions of this paper are: (i) the proposition and evaluation of new kNN-based meta-level features that exploit the labeled information in the train-ing set; (ii) a comprehensive (original) study on the use of ours and previously proposed kNN-based meta-level features for ATC, in isolation and in conjunction with the original features; (iii) a simple method to automatically filter out the worst groups of meta-features from each dataset; and (iv) an empirical study of the processing time and memory consumption necessary for obtaining kNN-based meta-level features using both a serial version and a new GPU-based parallel implementation.

This paper is organized as follows. In Section 2 we discuss some related work which aims at improving machine learn-ing methods by using meta-level features. In Section 3 we introduce our proposed meta-level features and the state-of-art kNN-based meta-level features, as well our parallel method to efficiently compute meta-features based on GPU. In Section 4 we present the experimental setup and discuss the experimental results. Finally, in Section 5 we present our conclusions and highlight future work.
Several meta-level features have been proposed in order to improve the effectiveness of machine learning methods. They can be based on ensemble of classifiers [4, 22, 23], derived from clustering methods [11, 12, 18] or from the instance-based kNN method [9, 25].

The authors of [23] suggested that a supervised ensemble method, where each base-level classifier predicts a probabil-ity distribution vector over all classes, is better than predict-ing a single nominal value. A modification of this approach was proposed in [22], where different sets of meta-level fea-tures should be used for each one of the binary prediction problems. In particular, only the probability values for the class under consideration should be used at meta-level, in-stead of concatenating the probability distributions of all classifiers, thus reducing the number of meta-level features. Experimental results showed an improvement over the pre-vious ensemble method with probability distributions. Fur-thermore, in [4] the use of class probability distributions augmented with an additional set of meta-level features was investigated. Such a set is based on the entropies of the class probability distributions and the maximum probability re-turned by each classifier. This scheme was found to perform better than using only probability distributions.

Unlike ensemble methods, where meta-level features are created based on an ensemble of classifiers, the technique proposed in [18] augments the feature space with new meta-level features derived from a previous clustering step consid-ering both the labeled and unlabeled data. A non-hierarchi-cal single-pass clustering algorithm is used to cluster labeled and unlabeled examples. In order to derive only the useful information from the clusters, the clusters are sorted by their sizes, and the largest n clusters are chosen as representatives of the major concepts. Each cluster c contributes the follow-ing meta-level features to the new feature space of the data: ( i ) a binary feature indicating if c is the closest of the n clus-ters to the example, ( ii ) the similarity of the example to the cluster X  X  centroid, ( iii ) the similarity of the example to the cluster X  X  unlabeled centroid, i.e. the centroid of the subset of c containing only unlabeled documents, and ( iv ) for each class l in the labeled set, the similarity of the example to the centroid defined as the average of the examples in class l that belong to c . The clusters are thought of as higher level  X  X oncept X  in the feature space, and the features derived from the clusters indicate the similarity of each example to these concepts. The unlabeled data is used to improve the repre-sentation of these concepts. They evaluate the method using SVM classifiers on well known corpora, and find significant improvements in the classification performance.

In [12] the training and testing sets are augmented with new meta-level features derived from clustering. The ap-proach consists of three steps: clustering, expansion and classification step. In the clustering step, the number of clusters is chosen to be equal to the predefined number of classes. A divisive clustering algorithm with repeated bisec-tions is selected to cluster both training and testing sets. In the expansion step, each cluster contributes one meta-level feature to the feature space of the training and testing sets: given the total n features that are used in the representation of the testing and training feature vectors, and the k clusters derived from the clustering step, create meta-level features x n +1 ,...,x n + k . An example x in the cluster C j is character-ized by the meta-feature x n + j . Finally, in the classification step, a linear SVM is trained on the expanded training set and employed to classify the expanded testing set. Eval-uation of this approach using several widely used corpora indicates that it is useful for improving the classifier X  X  per-formance, especially when the number of training examples is very small. The algorithm has also been successfully used in a spam-filtering setting [11, 13].

Recently, [9] reported good results by designing meta-level features that make a combined use of local informa-tion (through kNN-based features) and global information (through category centroids) in the training set. Despite the fact that these meta features are not created based on an ensemble of classifiers, they differ from the previously pre-sented meta features derived from clusters because they ex-plicitly capture information from the labeled set. Moreover, in [25] the authors present extensive empirical evaluations and in-depth analyses for a broader range of learning-to-rank algorithms, reinforcing the benefits of using the previously proposed kNN-based meta features.

The kNN-based meta features proposed in this work differ from the ones presented in previous works [9, 25] due to the fact the we not only exploit the distances of a test example to its neighbours as meta features, but we consider a much richer information space which includes, among others: (i) the number of neighbors in each class; (ii) the class distribu-tion of the distances to the neighbors; (iii) the within-class cohesion; (iv) the entropy of the neighborhood, etc. In the next section we will describe in details the previously pro-posed meta-level features, as well as our newly proposed kNN-based ones. As we shall see, our proposed features are not only more effective but much more efficient to be com-puted.
Let X and C denote the input (feature) and output (class) spaces, respectively. Let D train = { ( x i ,c i )  X  X  X C}| the training set. Recall that the main goal of supervised classification is to learn a mapping function h : X 7 X  X  which is general enough to accurately classify examples x 0 6 X  D train
The kNN-based meta-level features proposed in [9], are de-signed to replace the original input space X with a new infor-mative and compact input space M . Therefore, each vector of meta-level features m f  X  X  is expressed as the concate-nation of the sub-vectors below, which are defined for each example x f  X  X  and category c j  X  X  for j = 1 , 2 ,..., |C| as: considering the k nearest neighbors of class c j to the target vector x f . More specifically, ~x ij is the i th ( i  X  k ) nearest neighbor to ~x f , and cos( ~x ij , ~x f ) is the cosine similarity between them. Thus, k meta-level features are generated to represent x f . ments d 1 ( ~x ij ,~x f ) denote the L 1 distance between ~x the i th nearest class c j neighbor of ~x f (i.e., d 1 ( ~x || ~x ij  X  ~x f || 1 ). ments d 2 ( ~x ij , ~x f ) denote the L 2 distance between ~x the i th nearest class c j neighbor of ~x f (i.e., d 2 ( ~x || ~x ij  X  ~x f || 2 ). where ~x j is the c j centroid (i.e., vector average of all train-ing examples of the class c j ).

Considering k neighbors, the number of features in vector x f is (3 k + 2) per category, and the total of (3 k + 2) |C| for all categories. The size of this meta-level feature set is much smaller than that typically found in ATC tasks, while ex-plicitly capturing class discriminative information from the labeled set. Each test example is directly compared to a set of nearest labeled examples and category centroids, which are assumed to be enough to effectively characterize and discriminate categories. The intuition behind these meta-features consists in the assumption that if the distances be-tween an example to the nearest neighbors belonging to the category c (and its corresponding centroid) are small, then the example is likely to belong to c .
Similarly to the meta-level features previously presented, the proposed meta-features are also based on nearest neigh-bor search. However, we here go beyond by also exploiting the distribution of the nearest neighbor similarities and the within-class cohesion. The objective of our new features con-sists in improving the effectiveness of a classification task by augmenting the feature space with new useful discriminative information.

The space of the kNN dist -based meta-level features M = { m d } proposed in this work contains the vectors of meta-level features expressed as the concatenation of each feature vector m d , which is defined for each example x f  X  X and category c j  X  X  for j = 1 , 2 ,.., |C| as: the number n j of neighbors (among the k neighbors) of ~x f which are positive training examples in category c j the sum s j of the neighbor X  X  cosine similarity (among the k neighbors) of ~x f which are positive training examples in category c j . Such a sum is then normalized by s max which corresponds to the largest sum. by considering five points that characterize the distribu-tion of similarities of ~x f to its category j neighbours x (1  X  i  X  k ), where k is the neighorhood size, as measured by the cosine similarity between both. Among all com-puted similarity values, we pick five representative points: the lowest similarity, the highest similarity, the median similarity, the lower quartile (that splits the lowest 25% of points) and the upper quartile (that splits the highest 25% of points). computes the similarity ( cos ( q ej ,c ej ) between each previ-ously described quartile q ej and the centroid c ej computed among quartiles of the same kind of q ej but obtained from the training examples of class c j . For example, suppose the quartile q ej is the lowest similarity quartile regard-ing ~x f . We obtain the lowest similarity quartile regarding each training element of class c j and obtain the centroid c ej of these quartiles by computing the average quartile among them. Next, we compute the cosine similarity be-tween q ej and c ej . We repeat this process for the four other quartiles, obtaining the 5-dimensional vector. mension | C | containing the mean similarity between the class c j centroid ~x j and all the ~x ej  X  Neig c j ( x f
Neig c j ( x f ) is the set of neighbohrs of the ~x f belonging to category c j . to the Information Gain [1] measure, a 3 -dimensional vector is produced, considering the point which best splits the neighbors of ~x f belonging to category c j . Specifically, these neighbors are ranked according to their similarity to ~x f and, similarly to decision trees X  splitting step, we se-lect the point that better splits the ranking into two parts.
The best split point is the one which maximizes the in-formation gain for the class c j . For example, suppose ~x belongs to category c j . It is expected, in this case, that the top ranked neighbors documents also belong to c j , and the best splitting point to be selected is the least similar neighbor of ~x f which belongs to c j (with the low ranked neighbors probably not belonging to c j ) X  X  (quasi-)zero-entropy case. The three meta-features selected in this process are: (i) the maximized information gain value, (ii) the position of the split point in the ranking and (iii) the similarity between the splitting point and ~x f . tures the correlation between the neighbors of ~x f which belong to category c j and the remaining neighbors that do not belong to c j , considering a neighorhood of size k . Let  X  j be the mean similarity of the positive neighborhood (i.e., those belonging to c j ), given by 1 k P cos ( ~x and  X  i the mean similarity of the negative neighborhood (i.e., the neighbors not in c j ). Also, let V j and V i variances computed from each positive and negative simi-larities, respectively. The Fisher X  X  correlation measure [6]
Recall that our baseline set of meta-features contains a total of (3 k + 2) |C| , which is linear in the number of cat-egories and in the neighborhood size. On the other hand, the proposed meta-features set has a total of |C| (16 + |C| ) = 16 |C| + |C| 2 . That is, while our strategy produces a number of meta-features quadratic in the number of categories, it does not depend on the neighborhood size ( k factor). More-over, usually a quadratic growth in the number of categories is not a huge problem, since |C| tends to be reasonably small, resulting in a dimensional space much smaller than the orig-inal one.

The proposed meta-features are able to capture discrim-inative information from the labeled set under several as-pects, namely the class distribution in the neighborhood of the test example ~x f , the within-class cohesion and entropy. We now analyze them further, describing which characteris-tics of the data each of them aim to explore.

The features ~v cnt ~x guarantees the kNN classifier X  X  success: the existence of a mode in the weighted class distribution of the neighborhood of ~x f usually determines the category of ~x f .

Another key aspect concerning the class distribution on the neighborhood of ~x f is the observed similarities between the neighbors and ~x f . This aspect is exploited by the ~v meta-features: they capture the relationship between the majority class and the similarity information between the neighbors and ~x f , by means of similarity sums.

The similarity distribution is further explored by the ~v meta-features, which considers the three quartiles along with the minimum and maximum similarity value, exploring the within-class cohesion tied together with the locality infor-mation w.r.t. ~x f . The use of quartiles instead of the full distribution reduces considerably the number of dimensions, preventing overfitting in small datasets. These quartiles (to-gether with min-max values) are further explored by the ~v meta-features, by evaluating their deviance to the expected values, which provides global pieces of information related to each class. Following this direction, a simple set of fea-of the neighbors of ~m f belonging to some class c i 6 = c the centroid of c j . This directly evaluates the class cohesion in the neighborhood of ~x f , being an important information regarding the uncertainty level in such region of the input space.

Another key aspect exploited by the proposed meta-fea-tures refers to the entropy observed in the neighborhood of ~x . The ~v IG ~x hood of ~x f , which maximizes the information gain of class c , similarly to the splitting strategy of decision trees. If the splitting point is low ranked among the nearest neigh-bors, this ultimately highlights a low entropy scenario, since the majority of the most similar examples belong to the same class. Finally, the ~v fisher ~x tion between the similarities among the positive examples (those in c j ) and the similarities among the negative exam-ples (those not in c j ) inside the neighborhood of ~x f . Again, low correlation values underline low entropy regions in the neighborhood.
As we shall see in Section 4, making use of all groups of meta-features simultaneously may lead to overfitting prob-lems. We propose two strategies to deal with this issue. The first one, based on a stacking strategy, tries to learn the  X  X deal X  weight of each group of features and the best way to combine them for the final classification decision. This is a feature weighting strategy. The second strategy, a greedy one, tries to reduce the set of meta-features used, while still maximizing their discriminative power. This can be consid-ered as an explicit feature selection strategy. Notice that both procedures should be applied only in the training set by means of cross-validation within this set. We describe both strategies in more details next.
We propose a variation of the traditional stacking tech-nique to combine an ensemble of classifiers derived from the proposed meta-level features. Instead of using hetero-geneous algorithms to learn different classifiers to form the ensemble, we learn distinct classifiers using the same learn-ing algorithm (SVM) trained using different groups of meta-features. We adopted a two-level stacking procedure. In the first level, we first learn a separate SVM-based classifier for each of the seven groups of the meta-level features presented in Section 3.2. Then, we apply each classifier to every doc-ument in the considered dataset (training data). As the result, we have for each document |C| scores, each repre-senting the likelihood that a document belongs to a distinct class in C possible classes. For instance, we learn a SVM classifier using only meta-level feature ~v cnt ~x this classifier to each document and obtain for each class c a score corresponding to the likelihood that the document belongs to class c j . This process is repeated with each of the seven groups of meta-features, generating seven vectors of |C| scores each.

In the second level of the ensemble procedure, we obtain a new dataset in which each document is represented by the concatenation of the seven vectors obtained in the first level. A new SVM-based classifier is then trained to learn the best weights for each of the features of this first level document representation. The second level SVM is then applied to the test documents for final classification.
The strategy, called GreedyF filter, is quite simple and can be outlined by the following steps: 1. Let M sub = M , the entire meta-features set. 2. Find a subset M bad  X  M sub which, when removed, 3. Do M sub = M sub \M bad and go to step 2.

For example, let X  X  assume that M sub initially corresponds to all the proposed meta-features, and each meta-feature set proposed in Section 3.2 corresponds to a candidate for M bad In each iteration, GreedyF removes the group M bad which causes the most harm to the effectiveness according to a cross-validation experiment on the training set. When there is no statistically significant effectiveness improvements with the removals, the method stops.
In order to make the generation of these meta-features feasible and, consequently applicable in combination with classifiers, it is important to use an efficient kNN implemen-tation. We investigate different implementations of kNN and identify a tendency in strategies focused on parallelization using graphics processing units (GPUs) [17, 7]. We eval-uated these proposals and conclude none of them considers specific ATC idiosyncrasies, which include high dimensional-ity and heterogeneity in the representation of the documents (i.e., most of the documents do not share the same fea-tures). The high dimensionality, for example, lead to exces-sive (sometimes infeasible) memory consumption if proper data structures are not considered. Therefore, in this work we have implemented our own kNN parallelized in GPU.
We use a compact data structure based on two vectors to represent data. The first one, called docIndexV ector , stores the documents. The other, called docV ector , stores the information of each document. In docIndexV ector , each position represents a document and its value contains the in-dex from where its content is represented in docV ector . The docV ector , in turn, contains tuples with the terms and corre-sponding frequencies in each document, stored sequentially. We specifiy the parallelization of the algorithm in two main steps: the distances calculation and sorting steps. detailed below:  X  Distances calculation: A kernel performs the distance calculations between a test document to be classified and all training documents. In a call to this kernel, one thread is associated with each training document. Thus, each thread is responsible for calculating the distance between their respective training document and the target test document. At the end of the kernel execution, there is a vector with the distances between each of the training documents and the test document.  X  Distances sorting: After the distances calculation step, the distances are sorted by their similarity value. To par-allelize this step, we used the thrust library, distributed as part of the CUDA SDK. In the particular case, we use the function sort by index , which returns a second sorted index vector. Thus it is possible to find what are those k closest documents to the test document.
In this section, we experimentally study the proposed meta-level features on six datasets from different contexts. In Section 4.1, we first present the experimental setup and in Section 4.2 we present results of experiments using distinct sets of meta-level features.
In order to evaluate the meta-level strategies, we consider six real-world textual datasets, namely, 20 Newsgroups, Four Universities, Reuters, ACM Digital Library, MEDLINE and RCV1 datasets. For all datasets, we performed a traditional preprocessing task: we removed stopwords, using the stan-dard SMART list, and applied a simple feature selection by removing terms with low  X  X ocument frequency (DF) X  2 . Re-garding term weighting, we used TFIDF for both, SVM and KNN. Next, we give a brief description of each dataset. 4 Universities (4UNI), a.k.a, WebKB this dataset con-20 Newsgroups (20NG) this dataset contains 18 , 805 news-ACM-DL (ACM) a subset of the ACM Digital Library
Reuters (REUT90) this is a classical text dataset, com-MEDLINE (MED) a subset of the MedLine dataset, with
RCV1Uni The Reuters Corpus Volume 1 (RCV1) is a
We removed all terms that occur in less than six documents (i.e., DF &lt; 6).
The meta-level features were compared using two stan-dard text categorization measures: micro averaged F 1 (MicroF 1 ) and macro averaged F 1 (MacroF 1 ) [15, 24]. While the MicroF 1 measures the classification effectiveness over all decisions (i.e., the pooled contingency tables of all classes), the MacroF 1 measures the classification effectiveness for each individual class and averages them. All experiments were executed using a 5-fold cross-validation procedure. The pa-rameters were set via cross-validation on the training set, and the effectiveness of the algorithms running with distinct types of features were measured in the test partition.
In order to evaluate the performance of different groups of features, we adopted the LIBLINEAR [5] implementa-tion of the SVM classifier. The regularization parameter was chosen among eleven values from 2  X  5 to 2 15 by using 5-fold cross-validation on each trainig dataset. The other parameter necessary to execute the experiments is the size of neighborhood used in kNN-based meta-level features. We adopted the size k = 30 on all experiments, since it was empirically demonstrated as the best parameter to execute kNN on text classification [2, 24].
 All experiments were run on a Quad-Core Intel R  X  Xeon R  X  E5620, running at 2 . 4GHz, with 16Gb RAM. The GPU ex-periments were run on a GeForce GTX 690, with 2Gb RAM. In order to consider the cost of all data transfers in our GPU-based algorithms, we report the wall time of the pro-cess execution in all efficiency experiments. To compare the average results on our cross-validation experiments, we as-sess the statistical significance of our results by means of a paired t-test with 95% confidence and Bonferroni correction to account for multiple tests. This test assures that the best results, marked in bold , are statistically superior to others. The obtained results (and their 95% confidence intervals) are described in Section 4.2.

We would like to point out that some of the results ob-tained in some datasets with and without the meta-features may differ from the ones reported in other works for the same datasets (e.g., [10, 14, 8]). Such discrepancies may be due to several factors such as differences in dataset preparation the use of different splits of the datasets (e.g., some datasets have  X  X efault splits X  such as REUT and RCV1 4 ), the appli-cation of some score thresholding, such as SCUT, PCUT,
For instance, some works do exploit complex feature weighting schemes or feature selection mechanisms that do favour some algorithms in detriment to others.
In fact, we do believe that running experiments only in the default splits is not the best experimental procedure as it does not allow a proper statistical treatment of the results. etc., which, besides being an important step for multilabel problems, also affects classification performance by minimiz-ing class imbalance effects, among other factors. We would like to stress that we ran all alternatives under the same conditions in all datasets, using the best traditional feature weighting scheme (TFIDF), using standardized and well-accepted cross-validation procedures that optimize parame-ters for each of alternatives, and applying the proper statis-tical tools for the analysis of the results. All our datasets are available for others to replicate our results and test different configurations.
We conducted controlled experiments to evaluate the ef-fectiveness and efficiency of classifiers learned with six dif-ferent sets of features. The names and the descriptions of each set of features are given as follows: Orig set containing only the original features, i.e, TF-IDF Liter set of meta-level features proposed recently in litera-Prop set of meta-level features proposed in this paper and *+Greed, *+ Stacking set of resulting features after ap-
We also analysed each group of proposed meta-level fea-tures presented in Section 3.2. In order to facilitate report-ing results with these features we decided to give names to each group of feature. Table 1 shows the group of features and their corresponding names. Table 1: Name for each group of features in Prop set of features.
In this section we present results for a series of exper-iments we conducted to evaluate the effectiveness and ef-ficiency of computing the meta-level features. Initially, we present results of two meta-feature selection/weighting mech-anisms. Next we present results of the effectiveness of clas-sifiers using each set of features: Prop, Liter, Prop+Greed, Liter+Greed, Orig and Orig+Prop+Greed. After that we present an analysis of the effectiveness of each group of fea-tures (cnt, ncnt, qrt, cqrt, sum cent, IG, Fisher, and allMF) that composes the Prop set of meta-level features. Finally, we present results about the computation time of the sets of features Prop and Liter.
We start by analysing the two strategies proposed in Sec-tion 3.3 to select or weight the best subset of meta-level features to use in each of the tested datasets. Results of ex-periments run with each strategy are shown in Table 2 5 . As can be seen, the Greedy strategy outperformed the Stacking one in all datasets. We hypothesized that this is due to the lack of capability of the SVM classifier in capturing interac-tions and dependencies among the groups of meta-features. Because of that, as well as the large memory consumption of the Stacking strategy, from now on, we will only consider the Greedy strategy in our experiments and analyses.
In this section we present comparisons between classifiers trained with ours and the state-of-art meta-features, with and without feature selection. Table 3 shows the values of MacroF 1 and MicroF 1 for four set of meta-level features: Prop, Prop+Greed, Liter and Liter+Greed.

As can be seen, our proposed Prop+Greed 6 set of features is the best among the four set of features compared. Notice particularly, the large improvements obtained by the Greedy filtering in the REUT90 dataset (we further discuss this is-sue later). Prop+Greed produced statistically significant gains in MacroF 1 (7%) and MicroF 1 in the 4UNI dataset and in MacroF 1 (6%) in the REUT90 dataset, when com-pared to the best set found in the literature (Liter+Greed). In the other datasets there were ties among the results of Prop+Greed, Liter, and Liter+Greed sets.

Perhaps even more important, the Prop+Greed set al-lowed the generation of SVM classifiers for all six datasets. The set of meta-level features Liter, on the contrary, could not be computed in feasible time for the RCV1Uni dataset, neither in the CPU used in our experiments (it would take literally months to be computed.) nor in our GPU imple-mentation due to memory limitations. Consequently, we do not have the MacroF1 and MicroF 1 for Liter+Greed (this fact is marked with  X * X  in Table 3) in this dataset.
Table 3 also shows that Prop features benefited more from the proposed Greedy feature selection than the state-of-art ones (the Liter set). For instance, the set Prop pre-sented inferior MacroF 1 and MicroF 1 values for the REUT90 dataset when compared to the corresponding results of Liter and Liter+Greed. This happens because the group of fea-tures sum cent in the Prop set introduces much noise in this dataset. When this group is filtered out the resulting set, Prop+Greed surpasses both sets (Liter and Liter+Greed.). On the other hand, no statistically significant enhancements were observed when using Liter+Greed instead of Liter.
Due to the enormous memory demands for the Stacking strategy, it was not possible to compute it for the largest datasets: MED and RCV1Uni
The Greedy feature selection does not remove any group of the Prop set from the 4UNI, ACM and MED datasets. On 20NG, the meta-features IG and ncount were removed. Only the group sum cent was removed from REUT90 and RCV1Uni.
We now compare the effectiveness of our best set of meta-level features (Prop+Greed) with the set of original features (Orig) when both are used to train SVM classifiers. As Ta-ble 4 shows, the set Prop+Greed of meta-level features per-formed better than the Orig in four out of the six datasets. For instance, gains of up to 45%, 23%, and 18% were ob-tained in MacF 1 for the REUT90, 4UNI, and ACM, respec-tively. Gains of up to 16.7%, 13%, 12% were aso obtained in MicF 1 for these same datasets. In fact, some of these results are the best ever reported in these datasets. Smaller, but statistically significant gains, were also obtained in the 20NG dataset.

However, in the MED and RCV1Uni datasets, the Orig set performed slightly better (in MicF 1 and MacF 1 in MED and in MacF 1 in RCV1Uni). One possible justification for this fact is that the number of documents in these datasets is one order of magnitude higher than in the other datasets. As a consequence, the training sets in cross-validation have sufficient examples to deal with the large space of textual features 7 . In the case of the other datasets the small size of the training set is not sufficient to learn good classifiers in the so large and noisy textual space. Thus, in these datasets classifiers using a reduced set of high quality features, as is the case of Prop+Greed, perform better. However, as we shall see soon, the combination of both sets, Prop+Greed and Orig, produced results better than both sets in isolation.
For sake of completeness, Table 4 also shows the results for the kNN classifier using only textual features. As it can be seen, the SVM classifiers using the Prop+Greed meta-level features performed consistently better than kNN classifiers using the Orig set of features in all datasets and metrics, but MicF 1 in the MED dataset. However, while the kNN classifier was only slightly superior in MicroF 1 in the MED dataset (at most 3% of gains), its effectiveness in terms of MacroF 1 was much inferior (up 20.7% of losses). Overall, our results show that the combination of the SVM classifier with a rich set of kNN-based meta-levels features is much su-perior than using SVM or the kNN classifier with the original features.

Finally, we also experimented with the combination of our meta-level features with the original ones as explained in Section 5.1.3. Table 5 shows that, differently from what occurred with the Prop+Greed set, the Orig+Prop+Greed now performs consistently better than the Orig set of fea-tures in all six tested datasets with gains of up to 5.3% in MacF 1 in MED. The improvements over Prop+Greed are even higher in MED and RCV1Uni. We can notice, however, that there is no statistically significant gains of the Orig+Prop+Greed set over Prop+Greed meta-level fea-tures in the first four datasets. We can conclude that in these datasets the SVM classifiers are very effective in giv-ing proper weights to features of the Prop+Greed set among the combined features so that the textual features in the same set do no spoil the classifier work. In the case of the larger MED and RCV1Uni datasets, the size of the training sets are sufficient large to cope better with the large space of textual features. Again, the SVM classifier weighted ef-
Prop+Greed showed statistically better results than SVM (Orig) in experiments made using random samples with 1% of the MED and RCV1Uni datasets. set is consistently among the best on all evaluated datasets. classifiers. Prop+Greed presented the best results on the most datsets. fectively the two kind of features in Orig+Prop+Greed so that it could benefit from the best features of each kind and avoid interference of noisy textual features.
In this section we investigate the quality of each group of meta-level features in the Prop set. For the sake of analysis, here we focus in the datasets in which the meta-level fea-tures were more effective, namely, 4UNI, ACM, REUT90, and 20NG.

Table 6 shows the effectiveness the SVM classifier trained with each group of the proposed meta-features in isolation. As can be seen, in all datasets, the meta-feature group qrt achieved the best results among all others. This is interest-ing because the information captured by this group is not directly captured by the algorithms used in classifiers such as the kNN and the SVM. However, in comparison with the full set of meta-features (allMF) in the last line of the table, qrt does not surpass it in 4UNI and ACM, showing evidence that there are additional and complementary discriminative information in the other meta-feature groups. REUT90 is the only dataset in which qrt is better than allMF. We con-jecture that this happens because there is only a few training examples per class in REUT90 (average of 140 documents per class) and using only a reduced set of meta-features (i.e. only a few dimensions) may prevent overfitting, leading to better results.

In order to further analyse the effects of noisy meta-features and the complementary information provided by them, we performed a new set of experiments in which we removed one group of meta-features from the full set allMF before train-ing the SVM classifier. Table 7 shows the effects of such procedure. Removing the meta-feature groups ncnt and IG from 20NG causes, small but statistically significant gains in MacroF 1 and MicroF 1 over allMF (those ties are not shown in Table 7 ). Therefore, there is evidence that these groups are adding some noisy dimensions to 20NG.

On the other hand, in REUT90, the group of meta-features sum cent is clearly the responsible for the significant effec-tiveness losses of 18% in MacF 1 . We suspect that the large number of dimensions added by sum cent is causing over-fitting in this dataset. On the other hand, the removal of sum cent and qrt from 4UNI and ACM caused significant losses over allMF, ranging from 1% to 5% in MicF 1 . Those losses point to an important complementary discriminative evidence provided by sum cent and qrt. The removal of group IG also produced small, but statistically significant, losses over allMF in 4UNI and 20NG.
After demonstrating the effectiveness of our strategy, it is fundamental to evaluate its computational feasibility. As discussed, ours and the literature meta-features are based on computing nearest neighbors similarities and summariz-ing the properties of this neighborhood. Thus, our efficiency evaluation is based on measuring the execution time for gen-erating these meta-features with kNN. As all effectiveness evaluations were performed based on a 5-fold cross validation procedure, we also measure the execution time in each fold, reporting in Table 8 the average time in 5 folds to generate the Prop and the Liter set of meta-features. We performed such an evaluation using a CPU 8 and our GPU implementa-tion of kNN. Table 9 shows the average time for meta-feature generation per instance with both implementations.
 Table 8: Average time (in seconds) to generate meta-features (*aborted due to long time). The use of the kNN implemented in GPU reduces 10 x the execution time to generate the meta-features.

A first issue to highlight is that we use only the cosine distance to compute our meta-features, while the state-of-art approach also adopts the L 1 and L 2 distances. Con-sequently, our strategy is up to 3 x more efficient than the literature approach, being also more effective in most cases, as we have seen. Another point to be highlighted is related to the use of a GPU implementation of kNN. As it can be observed in the Tables, for all evaluated scenarios, the use of a GPU implementation of kNN is much faster, being up to 10 x more efficient when compared to the CPU implemen-tation. In spite of that, even when using the GPU imple-
For this, we use the ANN algorithm implementation ( http: //www.cs.umd.edu/~mount/ANN ) to compute an exact kNN as in [25]. is consistently among the best on all evaluated datasets. gains, losses and draws over the set of all proposed meta-features allMF. meta-feature, and  X  indicates an informative one. mentation, the time for generating the Liter meta-features was so long, making it infeasible to use them in the largest datasets: MED and RCV1Uni.

A complementary experiment was performed considering the execution time to generate the meta-features related to each test document, in order to evaluate if it is possible to adopt these approaches in scenarios of data streams. We calculate the average of the execution time to generate the meta-features for each test instance, considering the 10 fold cross-validation. For this experiment we evaluate our ap-proach using the GPU implementation of kNN and the lit-erature one that considers the ANN algorithm. We summa-rize these results in the Table 9. As can be observed, our approach was able to generate the meta-features for each test document, in average, in less than 0.5 seconds for all analysed datasets. On the other hand, the literature ap-proach, for some cases, failed to generate the meta-feature in function of the high memory consumption. These results demonstrate that, considering the execution time, our ap-proach is appropriate to be used in data streams scenarios. Table 9: Average time (in seconds) per instance to generate meta-features (*aborted due to memory limitation). Our approach was able to generate the meta-features for each test document in less than 0.5 seconds. The literature approach was unfeasible for large datasets.

Finally, we performed an evaluation of the memory con-sumption. We measured the average memory consumption considering 10 runs for our approach and for the literature one in order to compare them. In cases where it was not possible to perform these measurements, due to the physi-cal limitations of the machine memory used in our experi-ments, we made an estimated calculation of how much mem-ory would be needed. The result of these measurements are presented in Table 10.
 Table 10: Memory use to generate meta-features. The literature approach has high memory consump-tion in the process of generating the features, mak-ing it unfeasible for some large datasets.

As can be seen, the memory consumption of the litera-ture approach makes it unfeasible to execute it in largest datasets. On the other hand, the memory consumption of our approach was reasonable in all cases, with 510 MB of peak consumption in the RCV1Uni dataset. This happens because ANN uses a data structure that is not appropriate for textual datasets, as it generates a dense matrix, with a lot of zeros to represent features vs. instances relationships. We, on the other hand, exploit a more compact represen-tation, as discussed in Section 3.4. In sum, by observing the results related to both, time response and memory con-sumption, we can state that another significant contribution of our work is to make the use of meta-features effectively applicable in large real-world text classification tasks.
In this paper we proposed new meta-level features for automated text classification. We experimentally analysed them, in isolation and in conjunction with the original fea-tures (bag-of-words), and compared them with previously proposed state-of-the-art meta features found in the litera-ture for ATC. Our controlled experiments with these new meta features on six benchmark datasets showed significant effectiveness improvements on most datasets over the orig-inal features and the previous meta features. Our experi-mental results also showed that the proposed meta features are significantly faster to generate than the previous ones (up to 3x faster), making them much more scalable. More-over, we also introduce a new GPU-based implementation of kNN which provided speedup gains in the generation of our meta-features of up to 10 times, with a fraction of the mem-ory consumption of the traditional implementations. By in-troducing meta-level features that effectively and efficiently capture important information about the relationships be-tween instances and categories and by keeping the standard formulation of the automated classification problem, we en-able our solution to be applied in a number of different clas-sification scenarios.

We hope this study provides useful insights into how to enhance the performance of ATC methods by improving the representation schemes for instances, categories and their relationships and by creatively leveraging dimensionality re-duction. A line of future research would be to explore our meta features with other classification algorithms, using fea-ture selection techniques in order to automatically discover the best neighborhood measures, as well as the best size of the neighborhood. Other possible line of research would be to explore the scalability of the proposed meta features in order to improve the efficiency of recent classification meth-ods by also exploiting other dimensionality reduction tech-niques. [1] L. Breiman, J. Friedman, R. Olshen, and C. Stone. [2] H. Chen and T. K. Ho. Evaluation of decision forests [3] K. Crammer, M. Dredze, and F. Pereira. Confidence [4] S. Dzeroski and B. Zenko. Is combining classifiers with [5] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, [6] R. A. Fisher. Statistical Methods for Research [7] V. Garcia, E. Debreuve, and M. Barlaud. Fast k [8] S. Godbole and S. Sarawagi. Discriminative methods [9] S. Gopal and Y. Yang. Multilabel classification with [10] S.-B. Kim, K.-S. Han, H.-C. Rim, and S.-H. Myaeng. [11] A. Kyriakopoulou and T. Kalamboukis. Text [12] A. Kyriakopoulou and T. Kalamboukis. Using [13] A. Kyriakopoulou and T. Kalamboukis. Combining [14] M. Lan, C.-L. Tan, and H.-B. Low. Proposing a new [15] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A [16] S. Manne, S. Kotha, and S. Sameen Fatima. Text [17] N. Miranda, E. Chavez, M. F. Piccoli, and N. Reyes. [18] B. Raskutti, H. L. Ferr  X a, and A. Kowalczyk. Using [19] L. Rocha, F. Mour  X ao, A. Pereira, M. A. Gon  X calves, [20] G. Salton and M. J. McGill. Introduction to Modern [21] F. Sebastiani. Machine learning in automated text [22] A. Seewald. Towards understanding stacking . PhD [23] K. M. Ting and I. H. Witten. Issues in stacked [24] Y. Yang. An evaluation of statistical approaches to [25] Y. Yang and S. Gopal. Multilabel classification with
