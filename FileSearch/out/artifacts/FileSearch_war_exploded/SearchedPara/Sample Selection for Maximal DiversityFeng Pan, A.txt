
The problem of selecting a sample subset sufficient to preserve diversity arises in many applications. One exam-ple is in the design of recombinant inbred lines (RIL) for genetic association studies. In this context, genetic diver-sity is measured by how many alleles are retained in the resulting inbred strains. RIL panels that are derived from more than two parental strains, such as the Collaborative Cross [2, 14], present a particular challenge with regard to which of the many existing lab mouse strains should be in-cluded in the initial breeding funnel in order to maximize allele retention. A similar problem occurs in the study of customer reviews when selecting a subset of products with a maximal diversity in reviews. Diversity in this case im-plies the presence of a set of products having both positive and negative ranks for each customer. In this paper, we demonstrate that selecting an optimal diversity subset is an NP-complete problem via reduction to set cover. This re-duction is sufficiently tight that greedy approximations to the set cover problem directly apply to maximizing diver-sity. We then suggest a slightly modified subset selection problem in which an initial greedy diversity solution is used to effectively prune an exhaustive search for all diversity subsets bounded from below by a specified coverage thresh-old. Extensive experiments on real datasets are performed to demonstrate the effectiveness and efficiency of our ap-proach.
Selecting a sample subset sufficient to preserve the diver-sity seen within a given data set is a recurring problem in a variety of application domains including biology, customer review analysis and text mining. A set X  X  diversity cover can be viewed as a variation of the classical set cover problem where at least one example including and omitting each set element is required. Furthermore, it is useful to relax the requirement of a strict cover by specifying a minimal di-versity threshold (usually specified as a percentage) that is to be retained by the selected subset. The implications and motivation for finding diversity subsets also varies between application domains.

There are many experimental scenarios where the ulti-mate objective is to maintain, or at least maximize, genetic diversity within relatively small breeding populations. Ex-amples include the design of breeding programs for live-stock, the captive breeding of endangered species, and the construction of recombinant inbred lines for genetic map-ping in animals and plants. Allele diversity is also an im-portant consideration when designing association studies. In the case of genetic mapping in mice, there are several existing RIL panels [15] with greater than 50 lines whose genotypes are known. Economics might dictate perform-ing a pilot study across only a subset of the available lines [16, 10]. The following question arises: What subset pre-serves that greatest diversity among a set of selected mark-ers?
Low-cost genotyping technologies provide an important tool for measuring diversity at a biomolecular level in terms of Single Nucleotide Polymorphisms (SNPs). The knowl-edge of a SNP X  X  presence, frequency, and location is lever-aged in a wide range of experimental designs. By definition, a SNP must be present in a minimum frequency in a popu-lation (typically 5% in human studies). We consider a SNP to be lost if it is not represented within a population sample, and our goal is to minimize this loss.
 It has been previously shown in [9] that over 99% of SNPs are biallelic, which enables us to represent alleles as a binary matrix. It is straightforward to extend our approach to polymorphisms with more than two alleles.

Previously, pairwise phylogenetic distances were used to identify maximum genetic diversity subsets [7, 13]. When applied to SNPs, this approach only considers the number of inconsistencies between column pairs in the allele diversity matrix, which is less information than the full matrix that our method considers.

Besides SNPs, gene expression values in other microar-ray data can also be used as a measurement for genetic di-versity with proper discretization. And it is a similar prob-lem to select a subset of the samples that preserves the great-est diversity among the genes.

In e-commerce, vendors often need to solicit customer opinions on the objects (e.g., products and/or services) they provide. This feedback is valuable for profiling customers, analyzing product preferences, and building recommenda-tion systems. There is a practical limit on the number of objects that can be listed in a questionnaire. In fact, objects should be selected carefully to maximize information for subsequent analysis. That is, they should be a small number of informative (and unbiased) representatives of all avail-able objects of interest. Intuitively, we want the selected objects to be non-redundant and cover the full range of cus-tomer X  X  opinions (i.e., including both positive and negative ratings). The goodness of a selection can be measured by its customer-rating diversity coverage.

A small number of selected objects is also preferred for certain data modelling tasks, such as classification. We will show in the experiment section that subsets of ob-jects, which cover large diversity, can be used to build better (more accurate and simpler) classifiers than the full object set.
 The problem of finding an optimal diversity cover is NP-Complete. An interesting variant of this problem is to find an optimal diversity subset of a given size or smaller that achieves at least a given level of diversity. In this paper, we present practical algorithms for finding such optimal diver-sity subsets.

Our algorithm has two phases. In the first phase, a greedy approach is used to find an initial solution and establish an achievable bound in terms of subset size and coverage. Then in the second phase, an exhaustive search for all op-timal subsets is systematically performed which is seeded with parameters derived from the initial greedy solution. We then employ pruning strategies to enable an efficient search for the globally optimal solution. Extensive exper-iments on real datasets from three applications demonstrate the effectiveness and efficiency of our algorithm.
Many algorithms have been designed to establish a sum-mary of a data matrix such that the maximum information (or diversity) is retained.

In [11], representative elements (rows) are selected from the data matrix based on mutual information. The data ma-trix is considered as a joint probability distribution between the rows and columns. Rows are selected such that the max-imum mutual information of the original data matrix is re-tained in the sub-matrix of selected representatives.
Co-clustering algorithms which cluster rows and columns of a data matrix simultaneously based on informa-tion theory are presented in [1, 5]. Dhillon et al . [5] gener-ates a flat partition of the data matrix into row and column clusters that maximizes the mutual information. The algo-rithm proposed by Chakrabarti et al . [1] partitions the rows and columns such that the sum of the entropy in each cluster is minimized. The sub-matrix generated by combining the rows and columns in each cluster found by these algorithms can be considered as a summary of the original data.
Feature selection has been used extensively in the clas-sification literature [4]. Given a class label for each row in the data matrix, the features that can maximize the classifi-cation accuracy are selected. Regardless of the diversity re-tention, the feature selection algorithms only select the most relevant features. These algorithms are based on heuristic methods and are not guaranteed to find an optimal solution.
The greedy solutions to the Set Cover problem and its variations are studied in [8]. These algorithms find greedy solutions which maximize the coverage over the elements at each step. Greedy solutions are only guaranteed to be within a specific ratio of the optimal solution.
In this section, we develop notations that will be used in the paper and we provide formal problem definitions.
Let S = { s 1 ,s 2 ,...,s n } represent a set of samples, e.g., inbred lines or objects to be reviewed, and let M = { m 1 ,m 2 ,...,m z } represent a marker set, e.g., SNPs or reviewers. We denote the Sample-Marker matrix as H , H = M  X  S . H is a binary matrix. In the case of SNP data, H ( i, j )=0 represents a majority allele at SNP m i for sample s j and H ( i, j )=1 represents that sample s j has a minority allele at SNP m i . While in the review data, H ( i, j )=1 represents that reviewer m i ranks ob-ject s j positively and H ( i, j )=0 represents that reviewer m i ranks object s j negatively. An example of matrix H is shown in Table 1.

Given a subset of samples, S j  X  S , the diversity of marker m i is covered by S j if and only if there are two samples in S j , s l and s k , such that H ( i, l )=1 and H ( i, k )=0 . For the sample subset S of the covered markers is called the diversity coverage of S , denoted as C ( S j ) , 0  X  C ( S j )  X  1 . For example, given the matrix in Table 1, the sample subset { s 4 ,s 5 } has diver-sity coverage 0.75, C ( { s 4 ,s 5 } )=0 . 75 . Obviously, for any single sample, its coverage is 0. It is generally reasonable to assume that the coverage of the entire sample set is 1, C ( S )=1 .
 Now we define the Diversity Cover problem.

Diversity Cover (DC) Problem : Given a sample set S , a marker set M and a sample-marker matrix H , find the minimum subset D , D  X  S such that Coverage ( D )=1 .
For example, given the sample-marker matrix in Ta-ble 1, the minimum subset that covers all the markers is { s
We show DC is NP-complete via a reduction from set cover [3]. Given a collection of subsets, S , from the finite universal set, U , a set cover solution is the smallest group of subsets from S that covers all of U . Consider the fol-lowing matrix construction for set cover. We associate each row with an element in U and each column with a subset in S . Each 1 in the matrix indicates an element X  X  membership in a corresponding subset. Thus, set cover corresponds to finding the smallest subset of columns that provide a 1 in every row.

Suppose that we augment a set cover problem matrix with an additional row (element) and column (subset) with all 0 entries except for a single 1 at the intersection of the new row and column. This forces a DC solution to choose this newly added column. Moreover, if we ignore this added column, the remaining subsets are a solution to the original set cover problem. On the other hand, if given a solution to the original set cover problem, one can just add the last row to get a DC solution. Thus, DC is NP-complete.
In the Diversity Cover (DC) problem, we want to find the minimum subset that covers all markers. However, in some cases users are willing to lose the coverage of a few markers in order to find a smaller subset, e.g., in some SNP data, al-most all the samples must be included to cover all the SNPs because of the large number of singleton SNPs (i.e., SNPs in which the rarer allele is present in a single strain). There-fore, we modify the DC problem by allowing a  X  X inimum coverage ratio X ,  X  , rather than a full cover. Now we want to find the minimum subsets that covers no less than  X  . Parameterized Diversity Cover (PDC) Problem : Given a sample set S , a marker set M and a sample-marker matrix H , find the minimum subset D (or subsets), D  X  S such that Coverage ( D )  X   X  .
 We can see that the DC problem is a special case of the PDC problem when the minimum coverage  X  is set to 1.
Given a sample subset, D, D  X  S , the upper bound of its coverage can be calculated using the coverage of its subsets. Property 3.1 Given sample subset D = { s 1 ,s 2 , ..., s k } ,k  X  3 , the upper bound of C ( D ) is: Proof :Let D = { s 1 ,s 2 , ..., s k  X  2 } , D = D { s k  X  1 Let X be the marker set covered by D { s k  X  1 } , Y be the marker set covered by { s k  X  1 } { s k } and Z be the marker set covered by D { s k } : Let W be the marker set covered by D .Wehave For any marker m l in Z , either it is already covered by D or it is only covered when sample s k is considered to-gether with D . In the first case, m l also belongs to X since markers in X are covered by D { s k  X  1 } . In the second case, all the samples in D have the same value on marker m l and sample s k has the opposite value on m l .Ifsam-ple s k  X  1 has the same value on m l as s k , m l is also cov-ered by D { s k  X  1 } and belongs to X .Orif s k  X  1 has the opposite value on m l compared to s k , m l is covered by { s k  X  1 } { s k } and belongs to Y . Therefore we have For any marker m l in X  X  Y which is covered by D { s k  X  1 } but not by { s k  X  1 ,s k } , we know that m ther covered by D alone or by D together with { s k  X  1 } and we know that s k has the same value as s k  X  1 on m l Therefore, in either case, m l is also covered by D { s k and belongs to Z . Similarly, for any marker m l in Y  X  X which is covered by { s k  X  1 ,s k } but not D { s k  X  1 } know that samples in D have the same value as s k  X  1 on m l while sample s k has the opposite value to s k  X  1 on m Therefore, m l is also covered by D { s k } and belongs to Z . We can get
Since ( X  X  Y ) ( Y  X  X )=  X  ,wehave According to Equations 3 and 5, Therefore,
When the subset D contains only 3 samples, the upper bound in Equation 1 becomes the exact value of C ( D ) . Property 3.2 Given the pair-wise diversity coverage of three samples, s i , s j and s k , the coverage of set { s is known.

The proof is similar and is omitted for brevity. Obvi-ously, by using Equations 1 and 6 recursively, we can es-tablish an upper bound of subset coverage using only the pair-wise coverages.
 Theorem 3.1 Given a sample subset D = { s 1 ,s 2 , ..., s we can calculate the upper bound of C ( D ) using only the pair-wise coverage C ( { s i ,s j } ) , s i ,s j  X  D according to Equations 1 and 6.
For example, the upper bound of C ( { s 1 ,s 2 ,s 3 ,s 4 } )
Note that for a sample subset D , we can get several cov-erage upper bounds based on Theorem 3.1 by exchanging the order of the samples in D . We discuss the details of calculating a diversity upper bound using Theorem 3.1 in Section 4.2.4.
In this section, we present our Exhaustive Subset Enu-meration ( ESE ) algorithm that solves the Parameterized Di-versity Problem. Our algorithm guarantees to find all the minimum sample subsets that have diversity coverage no less than  X  .The ESE algorithm has two phases. In the first phase, a greedy algorithm, Parameterized Greedy Diversity Subset ( PGDS ), is used to find an initial sample subset S that has C ( S G )  X   X  . Then in the second phase, we present an optimal K - X  Diversity Subset ( K X DS ) algorithm to ex-haustively search for all sample subsets with sizes K and smaller and with coverages no less than  X  . The initial sam-ple subset S G and several pruning strategies are used to re-duce the searching space. The pseudocode of the ESE algo-rithm is shown in Figure 1.

In Section 3, we proved that Diversity Cover is NP-complete and can be mapped to Set Cover. There is a well known greedy algorithm for the Set Cover problem. It chooses the subset that maximizes the increase in cov-erage in each step until all the elements are covered. The greedy algorithm can achieve an approximation ratio of H ( z ) , H ( z )= z
In the first phase of ESE , we design a similar algo-rithm, Parameterized Greedy Diversity Subset ( PGDS ), to find greedy approximations to the Parameterized Diversity Cover problem. The PGDS algorithm also chooses the sam-ple that maximizes the increase in the diversity coverage in each step. There are two differences in the PGDS algorithm compared with the greedy approach of the Set Cover prob-lem. 1. The PGDS algorithm cannot pick the best first sam-2. The PGDS algorithm stops once the coverage of the
The details of the PGDS algorithm are shown in Fig-ure 2. The algorithm considers each sample in step 2, and the minimum subset among all the S is reported as S G .The time complexity of PGDS is O ( kn 2 ) where k = | S G | .
For example, if we are given the matrix in Table 1 and set  X  =1 , the subset found by PGDS is S G = { s 1 ,s 4 ,s 5 ,s 6 } which is larger than the optimal minimum subset { s 4 ,s 5 ,s 6 } . 4.2 Optimal K - X  Diversity Subset Algo-
In the first phase of the ESE algorithm, the PGDS algo-rithm finds an initial subset S G satisfying C ( S G )  X   X  .It establishes an upper bound on the size of the optimal sub-sets in I , i.e., any subset S which has C ( S )  X   X  should have size smaller than or equal to subset S G .Let K = | S the exhaustive enumeration need to be performed only on the subsets having size no larger than K . The exhaustive enumeration can take exponential time in principle. How-ever, with efficient pruning strategies, our enumeration al-gorithm, K X DS , performs much better in practice, finding the optimal subsets quickly.

The K X DS algorithm searches all possible combina-tions of samples up to size K in an enumeration tree. Fig-ure 3 illustrates part of the enumeration tree of the matrix in Table 1 and represents our search when we do not apply any pruning strategies. Each node in the tree stores a sample subset S and the corresponding C ( S ) . The root represents the empty set. For each child node, the sample subset has one more sample than its parent node.

The K X DS algorithm performs a depth-first search [3] on the enumeration tree. By imposing an order on the samples, the algorithm is able to perform a systematic search by enumerating all combinations, i.e., no combina-tion is missed or revisited. Without loss of generality, let X  X  assume the order is s 1 ,s 2 ,...,s n . For example, the depth-first search order on the enumeration tree in Figure 3 is
Among all the subsets that achieve the coverage thresh-old  X  , only the minimum sample subsets are reported. For example, if we set  X  =0 . 8 , only the nodes { s 1 ,s 2 ,s and { s 4 ,s 5 ,s 6 } , which are below the dashed line in Fig-ure 3, satisfy the  X  -threshold and subset-size constraints. Note that among all the nodes below the line, only those on the boundary need to be examined since nodes below the boundary have subsets of larger size. Details of the basic K X DS algorithm are shown in Figure 4.

The enumeration tree is dynamically materialized ac-cording to a depth-first searching order. At each node, the coverage of the corresponding sample subset S is calcu-lated based on the sub-matrix H = M  X  S , where M is the set of markers that are not covered by the sample set in the parent node. The use of the dynamically generated sub-matrix can efficiently reduce the runtime of the K X DS algorithm.

In the worst case, the K X DS algorithm takes exponen-tial time. In order to accelerate the search, we use several pruning strategies to reduce the search space. 4.2.1 Pruning Strategy 1: Dynamically Limit the Size In the first phase of ESE , the greedy algorithm PGDS pro-vides an upper bound of the size of the minimum sample subset. When the K X DS algorithm searches the enumera-tion tree, it does not need to check any node of more than K samples.

The size of the minimum sample subsets can also be up-dated dynamically during enumeration. It is possible that K may be larger than the minimum size. The value of K is updated to be the size of the smallest subset S , satisfying C (
S )  X   X  , found so far. All remaining nodes represent-ing larger subsets can be pruned from the enumeration tree without further examination. For example, if K is 9 and the algorithm finds a subset of 8 samples that can satisfy the threshold  X  , K is revised to 8 and any subsequent subsets of more than 8 samples are pruned from the enumeration tree.
Pruning strategy 1 is applied at step 5 of subroutine Enu-merate() in Figure 4. When cSample X  { s i } is inserted into cList , its size is compared with that of the smallest sub-set in cList .If cSample X  { s i } is smaller, K can be up-dated accordingly and all the subsets in cList having larger size can be dumped. 4.2.2 Pruning Strategy 2: Order Samples by Pair-wise For each node, we can estimate the increase in coverage for each sample from rSample based on its pair-wise cover-age with every sample in cSample . For example, in Fig-ure 3, consider node cSample = { s 1 ,s 2 } , rSample = { s 3 ,s 4 ,s 5 ,s 6 } . We know that the pair-wise coverages are:
For each sample in rSample , we use the sum of its pair-wise coverage with each sample in cSample as its score. This score is an (optimal) estimate of the additional cover-age this sample can bring.

We sort, in descending order, the samples in rSample based on their scores so that in the sub-tree of node cSample = { s 1 ,s 2 } , sample s 4 and s 5 will be added first followed by s 3 and s 6 . We can see that subsets having larger coverage are searched first in this case.

The sample sorting is conducted at each node dynami-cally. The pair-wise coverage of all samples can be calcu-lated in advance and retrieved to compute the scores. At the root of the enumeration tree, the samples are initially sorted according to their order selected by the PGDS algorithm.
Pruning strategy 2 can be used before step 3 of subrou-tine Enumerate() in Figure 4. Samples in rSample X  are sorted accordingly.

In some cases where the estimated size of minimum sub-sets, K ,by PGDS is equal to or close to their actual size, pruning strategy 2 itself cannot reduce the search space dra-matically. However, when combined with the following pruning strategy, it always delivers a substantial improve-ment in efficiency. 4.2.3 Pruning Strategy 3: Estimate a Branch Upper The coverage of sample subsets generally increases mono-tonically when adding new samples. For each node in the enumeration tree, we can calculate an upper bound, C ( cSample rSample ) , on the coverage of any sample subsets represented in the subtree. Any subsets represented in the branch must have coverage no larger than that value. We call it the branch-upper-bound . For example, consider node { s 1 ,s 3 ,s 5 } in Figure 3, cSample = { s 1 ,s 3 ,s rSample = { s 6 } . The upper bound is C ( { s 1 ,s 3 ,s 5 which is 0 . 825 .Ifthe branch-upper-bound of the subtree is less than the minimum coverage threshold  X  , we can safely prune the subtree.

It is inefficient to calculate the upper bound at each node independently by adding up the samples in cSample and rSample . However, we can calculate it simultaneously with the depth-first search by tracking the samples that are absent in the subtree under each node.

Given a node with its cSample and rSample = { s i 1 ,s i 2 , ..., s i q } , its left-most child node has the same branch-upper-bound .Let cSample 1 and rSample 1 be the current and remaining samples at the left-most child node. We have where s i 1 is the first sample in rSample .

For the j th child nodes ( 1 &lt;j  X  q ) of the current node, we have
Therefore, we can calculate the branch-upper-bound of a node according to the upper bound of its parent node or its siblings. The branch-upper-bound at the root node is 1 since every sample appears in some nodes. When we pro-ceed along a branch, this value decreases as more samples are absent in the sub-tree. For example, if we know that the upper bound at node { s 1 ,s 3 } in Figure 3 is 1,  X  for its child node { s 1 ,s 3 ,s 4 } , the upper bound is still  X  for { s 1 ,s 3 ,s 5 } , sample s 4 is absent, its upper bound  X  for { s 1 ,s 3 ,s 6 } , sample s 4 and s 5 are absent. Its
Pruning strategy 3 can be used before step 4 of subrou-tine Enumerate() in Figure 4. If the upper bound on branch coverage is less than  X  , the subroutine can stop and return to its previous level.

As mentioned earlier, pruning strategy 2 can improve the efficiency of pruning strategy 3. After we sort the suc-ceeding samples at each node in the tree, the last several branches are likely to be pruned by strategy 3 because they contain only those samples that have the least increase in coverage. Our experiments on real datasets suggest that us-ing pruning strategies 1 and 3 together reduces the runtime of the K X DS algorithm by 70%  X  80% . Combining prun-ing strategies 1, 2 and 3 can reduce the runtime by more than 95% . 4.2.4 Pruning Strategy 4: Refine the Branch Upper In pruning strategy 3, we estimate the branch-upper-bound using the current sample subset and all its succeeding sam-ples in rSample X  . This upper bound is loose because in many cases, we cannot include all the succeeding samples into the current subset. For example, if the current node represents a subset of p samples and there are q succeed-ing samples in rSample X  , we can at most include a subset of K  X  p samples from rSample X  during the search in the subtree under the current node. If we can calculate the max-imum increase in coverage after adding any subset of K  X  p samples from rSample X  , we get a tighter upper bound than the one in pruning strategy 3.

Suppose that the current sample subset is cSample = { s i 1 ,s i 2 , ..., s i p } and the succeeding samples are rSample = { s j 1 ,s j 2 , ..., s j q } . cSample covers the marker subset M a , M a  X  M , and the uncovered marker subset is M b , M b = M  X  M a . Since marker set M b is uncovered by cSample , all the samples in cSample have the same value on each marker in M b . Therefore, we can use a dummy sample s j 0 to represent the diversity of cSample on M b . When adding a subset of samples from rSample , S , into the current subset cSample , the increase of coverage is the coverage of S { s j 0 } on M b . We can calculate the pair-wise coverage on M b between any two coverage be C pair = { c 1 ,c 2 , ..., c m | m =( q +1) q/ Note that coverage is still calculated based on | M | , so that the total coverage on M can be calculated by adding the coverage on M b (increase of coverage) and the coverage on M a (current coverage) together.

In order to know the maximum increase in coverage after adding any subset of K  X  p samples from rSample X  ,we need to calculate the upper bound of the coverage of any ( K  X  p ) samples from rSample together with s j 0 on M b . However, in order to make the problem easier, we loosen the requirement and calculate the upper bound of the coverage of any K  X  p +1 samples of rSample X  { s j 0 } on M b .
According to Theorem 3.1 in Section 3, by recursively applying Equation 1, we can get the upper bound of the coverage of any u samples using their pair-wise coverage. The upper bound should be in the following form
Now we have q +1 samples in total and we know the set of all their pair-wise coverage C pair , we can calculate the upper bound of the coverage of any subset of K  X  p + 1 samples by replacing C ( s j ,s k ) in Equation 7 with the pair-wise coverage in C pair are sorted in descending order, the upper bound of increasing coverage after adding K  X  p samples into cSample is
Let C be the current coverage, C = | M a | | M | .If C + C is still less than  X  ,the K X DS algorithm does not need to search the subtree under the current node because there is no sample subset in the subtree that is not larger than K in size and with coverage not less than  X  .

Equation 8 provides a tighter upper bound than the one in pruning strategy 3 especially when there are large number of samples in the data. However, in order to get the upper bound, pair-wise coverage on M b between { s j 0 ,s j 1 ,s j 2 , ..., s j q } must be computed. Note that the co-efficients a i in Equations 7 and 8 are constants and can be calculated for each size of sample sets in advance. The com-putation and the pruning can be inserted before step 7 of subroutine Enumerate() in Figure 4. We can see that prun-ing strategies 3 and 4 are used in different places in the al-gorithm. In fact, these two strategies can be used together though strategy 4 provides tighter upper bound. Pruning strategy 3 is much faster than strategy 4 and, therefore, it is used as the pre-pruning step before pruning with strategy 4.
Though calculating the pair-wise coverage of { s j 0 ,s j 1 , ..., s j q } at each node takes time, we demon-strate in our experiments that the extra time used for coverage calculation is negligible compared with the runtime saved by pruning branches using pruning strategy 4. Also, as a side product, the actual increase in coverage for adding each sample from rSample into cSample is known during the pair-wise coverage calculation. There-fore, in pruning strategy 2, instead of ordering the samples by the estimated score, the algorithm can now order the samples in rSample by their actual increase in coverage.
In this section, we present results on synthetic and real data to show the efficiency of our algorithms and the effec-tiveness of the selected sample subsets. One real dataset is a SNP panel from recombinant inbred mouse strains. The other two real datasets are of customer review type.  X  Perlegen data 1 : The Perlegen dataset contains  X  Congressional Voting Records data 3 : The voting  X  Jester data 4 [6]: The Jester dataset contains 4.1 Million  X  Synthetic data: The synthetic data is randomly gen-
The synthetic dataset is mainly used to demonstrate the efficiency of our algorithms. And the three real datasets are mainly used to demonstrate the effectiveness of the selected sample subsets.

Except as otherwise noted, we use all the four pruning strategies collectively in the experiments because this com-bination provides the best runtime performance. The algo-rithms are implemented in MATLAB, and all experiments are conducted on a PC with CPU P4 3GHz, 1G RAM and 80G HDD. In this section, we demonstrate the efficiency of the PGDS and the K X DS algorithm using the synthetic data and some of the real datasets.
For the synthetic data, we vary the number of rows, the number of columns and the minimum coverage  X  respec-tively. The default values for these settings are: number of rows= 40 k , number of columns= 80 and minimum cover-age  X  = 0 . 965 . While we are varying one of the settings, the other two use the default values. The runtime performance of PGDS and K X DS is shown in Figure 5. The runtime of both algorithms increases linearly when the number of rows increases in Figure 5(a). And the runtime increases quadrat-ically when the number of columns and  X  increase for both algorithms as shown in Figure 5(b) and (c).
For the real datasets, we only vary the minimum cover-age  X  setting and use all the rows and columns. Both PGDS and K X DS can finish searching the Voting data in 1 sec-ond. Therefore, we only show the runtime performance on Perlegen and Jester data in Figure 6.
The runtime performance on the Jester data is similar to that of the synthetic data for both algorithms. For Perlegen data, K X DS can even be faster than PGDS because of the pruning strategies. Also, the runtime of K X DS begins to drop when  X  is larger than 0 . 985 . The reason is that the entire searching space becomes smaller when  X &gt; 0 . 985 The minimum subsets have size larger than 9 when  X &gt; 0 . 985 and causes the shrinking of the entire searching space because a subset of 10 samples or more contains more than half of the samples in the data.

Note that the total runtime of the ESE algorithm is the sum of the runtime of PGDS and K X DS .
 Comparison of Subsets Found by PGDS and K X DS
As we discussed in Section 4, the sample subsets found by PGDS may not be the optimal subset, i.e., either there exists a smaller subset that can achieve the minimum cov-erage  X  or there exists a subset with the same size but has larger coverage. Thus, in this section, we compare the sub-sets found by PGDS and K X DS . In the first part of the experiments, we vary minimum coverage  X  and compare the size of the minimum subsets found by both algorithms. Then we use the set of sizes of the minimum subsets found by K X DS in the first part, and compare the optimal cover-age that is achieved by the two algorithms for each of the subset size. The results are shown in Figure 7.
As we can see, on the synthetic dataset, PGDS finds a larger subset when  X  becomes large. And for subsets of size 8 and 10, the true optimal subset found by K X DS has larger coverage than the subset found by PGDS . However, as shown in Figure 7(c-f), PGDS always find the same opti-mal subset as K X DS on the real datasets. The result on the Voting data is the same as the Perlegen and Jester data and is omitted.

In this section, we compare the efficiency of the pruning strategies discussed in Section 4. We vary the minimum coverage parameter  X  and compare the runtime performance on Perlegen and Jester data. The synthetic data is not used because it is too large for K X DS to search without any one of the pruning strategies. And the Voting data is too small to be used to show the difference.
Figure 8(a) shows the results on the Perlegen data. We observe that pruning strategies (1,2,3) and pruning strate-gies (1,2,3,4) give the best performance, which is orders of magnitude faster than other strategy combinations. The reason that pruning strategy 4 does not improve the perfor-mance significantly when used in combination with strate-gies 1,2 and 3 is that the Perlegen dataset only contains 16 samples. This is sufficiently small that the two upper bounds from strategies 3 and 4 are close to each other. Us-ing only pruning strategies 1 and 2 (sorting) just slightly reduces the runtime. This is because sorting only helps the K X DS algorithm find minimum subsets faster, but can-not reduce the search space by pruning sub-trees. Using only pruning strategies 1 and 3 saves about 70%  X  80% of the runtime of enumerating with strategy 1 only. Without sorting, strain subsets offering good coverage are randomly distributed in the enumeration tree. Strain sorting helps to bring these branches together in the enumeration tree so that effective pruning can be achieved.

On the Jester data, the K X DS algorithm can finish the tasks in reasonable time only with pruning strategies (1,2,3) or pruning strategies (1,2,3,4). And for pruning strategies (1,2,3), it also can not afford a minimum coverage  X  larger than 0 . 96 . As we can see, pruning strategies (1,2,3,4) are orders of magnitude faster than pruning strategies (1,2,3). As we discussed in Section 4, pruning strategy 4 has a large advantage over pruning strategy 3 when the number of sam-ples becomes large.
In this section, we apply our algorithm on the three real datasets and demonstrate the effectiveness by analyzing the selected sample subsets.
 The Perlegen dataset has 16 samples and more than 8 M SNPs. As we discussed in Section 1, in the design of re-combinant inbred lines, an important measurement for a set of lines (samples) is its diversity coverage on the SNPs. A subset of 8 strains was hand selected for the Collaborative Cross [2] by biologists based on the phylogenetic relation-ships assumed for strains. We compare this subset with the best 8-strain subsets found by the ESE algorithm in Table 2.
Table 2. Perlegen Data: Comparing the 8-strain sub-sets of the Collaborative Cross with the maximum di-versity solution found by ESE
As we can see, the ESE subset achieves higher cov-erage than the Collaborative Cross subset. Four strains are common to both subsets: 129S1/SvImJ , CAST/EiJ , PWD/PhJ and WSB/EiJ . Aside from 129S1/SvImJ ,all strains are wild-derived from the three major Mus musculus subspecies. We plot the distribution of the diversity cover-age of random set of 8 samples in Figure 9. The coverage of the Collaborative Cross subset, 0 . 8926 , is labelled by the red dotted line in the figure. The Collaborative Cross subset has coverage larger than more than 70% of the randomly se-lected 8-sample subsets while the ESE subset is obviously the one has the largest coverage. Figure 9. Perlegen Data: Distribution of Diversity Coverage of 8-sample Subsets
The Voting data includes votes of the 435 Congressmen on 16 key votes. We consider the congressmen as markers and the key votes as samples. Our ESE algorithm finds two sample subsets that consist of 5 samples and have diversity coverage =1 , i.e., all the markers (congressmen) are cov-ered. The two subsets are listed in Table 3.
 Table 3. Voting Data: Subsets of 5 Samples found by ESE that have coverage =1
As we discussed in Section 1, these subsets can be used to generate simpler yet more accurate classification models. We use Weka 5 , which is a data mining software in Java, to build different classifiers based on all the 16 samples and the two 5-sample subsets. Classification accuracy is calcu-lated by using 10-fold cross-validation. The accuracy of the classifiers are listed in Table 4.

Table 4. Voting Data: Accuracy of Classifiers based on full set and subsets
As shown in Table 4, except for SMO(SVM), the high-est accuracy always occurs in one of the subsets found by ESE for all the other classifiers. As expected, the randomly selected subset which also consists of 5 samples always has the lowest accuracy. Moreover, the decision trees built by NBTree on Subsets 1 and 2 are much simpler than that of the full sample set because of the smaller number of sam-ples. The trees are omitted here for space restriction.
We discussed in Section 1 that subsets of samples can also be helpful in designing customer review study. By ap-plying our ESE algorithm on the Jester data, we get many sample (joke) subsets that are small and cover most markers (reviewers). Given the minimum coverage  X  , the number of qualified sample subsets and their sizes are listed in Table 5. The sample (jokes) subsets in Table 5 suggest that review-ers X  ratings on a small number of objects are sufficient to retain most diversity.

Table 5. Jester Data: Number of qualified sample subsets and their sizes for given  X 
According to the experiment results we presented in this section, we demonstrated that our algorithms are both effi-cient and effective.
In this paper, we introduced the Parameterized Diver-sity Cover problem: given a sample-marker dataset and a minimum coverage threshold  X  , find the minimum sample subset that achieves coverage  X  . We propose an efficient exhaustive subset enumeration algorithm ( ESE ) which can find the optimal solution. The algorithm has two stages: (1) a greedy approach, PGDS , is used to first find an approx-imate solution for minimum subset with coverage no less than  X  ; (2) an enumeration algorithm, K X DS , then searches for the optimal solution in the enumeration tree using sev-eral pruning strategies. We have evaluated the performance on three real datasets.

In the diversity cover problem, each marker is given equal weight. The problem can be extended to allow a weight to be associated with each marker. The weight can be assigned to reflect the importance of each marker and may be dynamically adjusted. For instance, groups of mark-ers may be highly correlated. The weight of each uncovered marker is 1 before any sample is selected, and is assigned to the lowest dissimilarity of this marker to any covered marker 6 . The goal of this weighted diversity cover problem is to select samples such that the total weight of all markers is maximized.

In our future work, we will continue to investigate and evaluate alternative approaches that may offer further per-formance gains. An alternative greedy strategy for PGDS is to start from the full set of samples and remove the sample that minimizes the decrease in coverage in each subsequent step until no sample can be further removed without vio-lating the minimal coverage requirement. Note that a sim-ilar strategy can also be employed in the K X DS algorithm which enumerates the sample subsets that can be removed without losing more than 1  X   X  coverage. In some cases where a minimum subset of coverage  X  contains more than half of the samples, these alternative strategies can have a better runtime performance because they imply a smaller search space.

