 Among techniques attempting to alleviate the impact of information overload, topic models can serve to organize information to users according to topics, helping them easily acquire knowledge. For people who want to learn about important events in the past, they can just glance over the topics discovered from a news archive without reading every document in the collection. However, it is common that some of the topics found are time-general; in other words, they concern daily and trivial topics which are considered having little retrospective value. A concrete example of daily topics is the topic document D 1 talks about.
As we can see, D 1 talks about a topic involving ups and downs of stock index, which is reported every day or every week regularly. From a retrospective viewpoint, the topic about temporary stock index has little value for general audience. In contrast, D 2 concerns a specific topic about an important event  X  air crash. If one wants to learn about important events in some year (e.g. 2000), what he is interested in should be the specific topics like D 2 discusses.
Distinguishing specific topics (time-specific) and daily topics (sometimes called time-general, routine or recursive topics) is a useful task for many applications in natural languages processing and data mining. One typical example is event chronicle generation [6] an d timeline generation [8,7]. As we know, chronicles and timelines have been adopted as a way to organize information by many websites such as Wikipedia and Facebook due to their readability and briefness. For generating a chronicle/timeline, it is necessary to distinguish specific topics from daily topics since only specific topics should be included.

Also, distinguishing specific and daily topics can help improve cross-document event coreference resolution systems whi ch aim to find coreferential events in dif-ferent documents. As Ge et al. [5] consid ered, the performance of cross-document event coreference resolution systems is likely to be affected by daily topics shown as follows:
Note that D 3and D 4 were written in 2001 and 2004 respectively. If a cross-document event coreference resolution system can distinguish specific and daily topics, it will not consider these two events coreferential.

In this paper, we focus on distinguishing daily and specific topics without depending on documents X  timestamps . The reasons why we do not use doc-uments X  timestamps are: First, the timestamp of documents, especially on the web, is unavailable (missing) or incredible due to arbitrary copy-paste behaviors such as retweet and reprint on the web, as [1,3,5] reported; Second, analyzing time distribution of topic is not feasible or reliable unless whole text stream during a time period is available; in other words, if the database used is just a sample of some text stream, the time distribution of a topic does not make sense. We investigate several numeric features for this task. For modeling the numeric features, we propose a novel B ayesian model with mixture of Poisson distributions. The experiments evaluate our model in terms of temporal distri-bution and semantic coherence and show that our model is more effective to discover and distinguish daily and specific topics from a collection of documents than conventional Bayesian topic models in an unsupervised manner.

The main contribution of this paper is: (1) we propose a Bayesian model for effectively discovering and disti nguishing specific and daily topics; (2) we propose a general framework for incorporating numeric features into Bayesian models; (3) we give some measures for evaluating models for this task. 2.1 Features for Distinguishing Specific and Daily Topics As discussed in section 1, we attempt to distinguish between daily and specific topics using only textual features. For repr esenting textual information, categor-ical features (also called nominal features) such as n-grams are usually adopted in NLP tasks. However, categorical features alone are not enough for describing statistical information such as the count of numerals in a document, which is im-portant for this task. We introduce numeric features describing useful statistical information of documents for this task. #PERSON Named Entities: Named entities are often discussed during spe-cific time period. Intuitively, if a topic involves a number of PERSON names then this topic is less likel y to be a daily topic. Hence, the count of PERSON named entities in a document is selected as a feature. #Numerals: It is easy to understand that the documents concerning daily topics usually involve something that frequently changes such as temporary stock price, which should be updated in time. The most salient features for describing such variations and fluctuations are numerals. If a document contains too many numerals, it is very likely that the article may talk about a daily topic. Based on the intuition, the count of numerals in a document is selected as a feature. #IDF: In addition to document-based features, we also investigate an important corpus-based feature  X  inverse documen t frequency (IDF) which is a measure of whether a term is common or rare across a co llection of documents. Intuitively, if IDF of salient words of a topic tend to be high, this topic will be less likely to be frequently mentioned all the time. According to our analysis of corpus of Gigaword, we find that the terms whose idf is greater than 60% of MAXIDF is distinguished for determining a topic to some extent. Thus, we refer terms in set H which is defined as follows to high-idf terms.

Given that the counts of high-idf terms in a document can indicate whether the document concerns a daily topic or a specific topic to some ex-tent, we select it as a feature for the task. 2.2 A Bayesian Model with Mixtures of Poisson Distributions For distinguishing specific and daily topics, we adopt a Bayesian model which is proved to be suitable for tasks concerning topics due to its ability of discovering topics hidden in a text collection and its flexibility that it can introduce various features with their dependencies.

In section 2.1, a variety of integer nume ric features used for distinguishing specific and daily topics are discussed. Effective to reflect some statistical in-formation as the features seem, it is som ewhat difficult to directly incorporate these features such as into a Bayesian model. Although numeric features can be discretized into several categorical bins in advance which can be modeled by a multinomial distribution, that appears not very applicable. On one hand, if the numeric variables are discrectized into too many bins, data sparsity problem would arise, which may have an adverse effect on the performance. On the other hand, if the number of bins is too small, the discretization might be unreasonable. To deal with this problem, we assume that the integer numeric features follow Poisson distributions which are proved to be very suitable for expressing the probability distribution of the integer numeric variables such as the count of a term in a document, and use the poisson distributions in our Bayesian model. The plate diagram of our Bayesian model is given in figure 1 and notations of our model are summarized in table 1.

The left part of the plate diagram of our model shown in figure 1 is similar to general latent dirichlet allocation (LDA) [2]. But unlike the general LDA model in which a document is a mixture of topics, our model assumes that a document corresponds to only one topic. Moreover, our model introduces another latent variable p which indicates the type of a topic (daily or specific), and poisson distributions which aim to express the probability distribution of the count of PERSON named entities, numerals and high-idf terms in a document respectively. As shown in figure 1, the n umeric features can be considered as being generated by a component of the mixture of Poisson distributions.
In addition, our model assumes that the topic distributions under different topic types are different, which is reasonable. While constructing topics, not only does our model consider the word distribution, but also takes into consideration the numeric features. In this way, we can even distinguish topics through the difference of the numeric features even if they have the similar word distribution. For example, a document about tempora ry stock price and another document talking about a specific stock market crash might be assigned to two different topics in our model due to differences of the numeric features while they might be in the same topic cluster in conventional Bayesian topic models because their word distributions are similar. As a result, specific topics found by our model can be more time-specific and daily to pics found by our model could be more time-general than those found by conventional Bayesian topic models.
The generative story of our model is presented in figure 2. Note that f i in figure 2 is the i th feature of a document and i  X  X  1 , 2 , ..., F } ,  X  p i denotes the parameter of the Poisson distribution for the i th feature of a document whose topictypeis p . In this way, daily and specific topics can be distinguished while constructing topics.

Model inference and the method for estimation of parameters  X  of the Poisson distributions are to be discussed in detail in section 2.3. 2.3 Model Inference and Parameter Estimation For model inference, we use Gibbs sampling approach to sample latent variables p and z . Specifically, for a given document m , the conditional probabilities of its latent variable p and z are shown in (1) and (2) respectively: where W m denotes tokens in document m , c z,p is the number of documents whose topic and topic type are z and p respectively, c z,w is the number of words w in documents whose topic is z , c p is the number of documents whose topic type document m . P ( f i ( m ) |  X  p i ) can be easily computed using the probability mass function of Poisson distributions.
 Now, the problem for our model is how to estimate the parameters  X  of the Poisson distributions. As mentioned in section 2.2, the features can be regarded as being generated by their corresponding mixture of poisson distributions; thus, we use an EM-based method to estimate the parameters of the Poisson distri-butions. As is known, the only parameter  X  of a Poisson distribution is the expectation of the distribution. Theref ore, whenever we finish sampling the la-tent variable p for document m , we re-estimate  X  of the Poisson distribution  X  p i using maximum likelihood estimation (MLE) as shown in (3). where f i ( j ) denotes the i th feature of document j .
 In our method of parameter estimation, (1) and (3) can be considered as E-step and M-step respectively. Diffe rent from the general EM algorithm, the latent variable p sampled in the E-step is a hard estimation instead of a soft one for efficiency. In this way, the parameter  X  p i of the Poisson distributions can be estimated during sampling. 3.1 Experimental Setting Since there is no standard benchmark dataset for this task, we use all the news articles written in the year 2000 of the Xinhua News Agency in Gigaword En-glish Corpus to evaluate our model. This dataset contains 99,538 news articles involving a variety of subjects.

As preprocessing, we use Stanford CoreNLP toolkit [10] to do lemmatization, named entity extraction and POS tagging. In this way, we can obtain PERSON named entities and numerals whose count is used as features in our Bayesian model as mentioned in section 2. Also, we compute idf of all terms in the vocab-ulary except numerals whose idf is set to 0. We normalized the count of PERSON named entities, numerals and high-idf terms in document m as follows: where f ( m ) denotes a feature of document m which could be the count of PER-SON named entities, numerals or high-idf tokens in document m and length ( m ) is document m  X  X  length.
We empirically set hyperparameters  X  =0 . 05,  X  =0 . 01,  X  =0 . 5. The number of topics K is set to 100. We simply select the topic with the largest prob-ability for a document as the document X  X  topic. Formally, for document m , where P m ( z ) denote the probability of a topic for document m and it can be estimated as follows: where z ( i ) is the topic sampled for document m at the i th iter after burn-in,  X  ( . ) is an indicator function and S is the number of iterations of after burn-in.
In order to verify the effectiveness of features we use, we try different combina-tions of features. Parameters  X  of poisson distributions after the model converges is shown in table 2. It should be noted that even though the topic type of a given topic can be indicated by the topic type label p ( p  X  X  0 , 1 } ), the meaning of p  X  X  value is unknown since our Bayesian model is an unsupervised approach. In other words, we do not know the topic type label p of a daily topic should be 0 or 1. Therefore, we must make clea r what the exact meaning of p  X  X  values are. Based on the intuition discussed in section 2.1, we can use the estimated parameter  X  of the mixture of Poisson distributions of the integer numeric features under dif-ferent topic type p to help understand p  X  X  value X  X  meaning. Intuitively, as for the daily topic type, its average count of PER SON named entities and high-idf terms per document should be less while its average count of numerals per document should be much more than the counterpart of the specific topic type. After mak-ing clear the meaning of p  X  X  values (as shown in table 2), we set a high confidence threshold (0.9) for determining the daily topics. Specifically, if the probability of atopic z to be a daily topic is larger than 0.9 (i.e. P ( p =0 | z ) &gt; 0 . 9, assuming that p = 0 indicates that the a topic is daily), the topic z will be considered as a daily topic; otherwise, the topic is considered specific. The probability P ( p | z ) can be estimated as follows: 3.2 Experimental Results In this section, we evaluate and compare our method with other Bayesian models in terms of temporal perplexity and log-likelihood per document.
 Temporal Perplexity. Since there is no golden standard for evaluating whether a topic or a document concerns a daily topic or not, we alternatively use an indirect way to evaluate our model  X  using temporal distribution to measure a topic X  X  distribution over time. If the temporal distribution of a topic is almost uniform, then the topic might be a daily topic. In contrast, if the temporal distribution of a topic fluctuates significantly over time or the number of articles involving the topic surge during a short period of time, the topic is more likely to be a specific topic. Therefore, it is possi ble to use temporal distribution to help evaluate our model. Inspired by the perplexity measure in information theory, we define temporal perplexity ( TP for short) for measuring the temporal distribution of a topic, as shown in (4).
 where t denotes a time epoch whose granularity can be either a day, a week or amonth, c z,t denotes the number of documents involving topic z at t and c z is the number of documents involving z across the collection. According to (4), the more uniform the temporal distribution of a topic is, the larger the TP of the topic will be. Therefore, the temporal perplexity of daily topics should be larger than that of specific topics.

Table 3 reports the temporal perplexity of the identified daily topics and the specific topics under different combinations of features. Note that the temporal granularity is day. In table 3, max , min and avg foratopictypedenotethe maximal, minimal and average temporal perplexity of topics of the topic type (daily or specific).  X  avg denotes the difference between the average temporal perplexity of the identified daily topics and that of the specific topics:
As shown in table 3, the features we used (i.e. count of PERSON named entities, numerals and high-idf terms in one document) are all capable of distin-guishing daily and specific topics, which is reflected by a positive  X  avg value. Among these features, the count of hig h-idf terms seems to be the most effec-tive, which achieves the largest  X  avg since IDF is a corpus-based feature, just as temporal perplexity which is also a measure based on a corpus. Hence, compared with the other document-based features , the count of high-idf terms appears to be more correlated with temporal perplexity.

As for the combination of features, it is not difficult to find that the num+idf combination performs best. This combinat ion achieves the highest temporal per-plexity for the identified daily topics in terms of max , min , avg as well as  X  avg . As discussed in section 2.1, the count of numerals in a document is an important feature for distinguishing between specific topics and daily topics. Although the feature alone may not result in a large  X  avg , it is very helpful in improving the performance when it is combined with idf . However, the combination of all the three features does not achieve a better result than num+idf and per+idf combi-nations. The possible reason is that the combination of per and num may affect the Bayesian model. As mentioned above, the task is to distinguish between the documents about daily topics which tend to contain few PERSON named en-tities and many numerals, and the documents about specific topics which tend to contain many PERSON named entities and few numerals. Nevertheless, it is not uncommon that a news article contains both few PERSON named entities and few numerals, or contains both many PERSON named entities and many numerals (e.g. list of top Premier League goal scorers). When per and num are simultaneously selected as features, the two features may interfere each other, which perhaps leads to a poor performance. In contrast, other feature combina-tions seem less likely to suffer from such a problem.
 In addition, we compare our model with two typical Bayesian topic model  X  Naive Bayes (NB) and Latent Dirichlet Allocation (LDA). For NB and LDA, we first detect topics and then use idf+num feature to distinguish specific and daily topics. Formally, we define a score for topic z as follows: where features (e.g. # numeral z ) are average of their counterparts of documents whose topic is z .

According to the intuition in section 2.1, the higher score, the more likely the topic is to be daily. Since our model identifies 13 daily topics with idf+num features, we identify the 13 topics with the highest score as daily topics for NB and LDA model. The performance of NB and LDA is given in table 4. It can be easily seen that our model performs much better than LDA and NB in terms of temporal perplexity. One main reason is that our model considers the numeric information while constructing topic clusters, as discussed in section 2.2. When a document contains many high-idf terms and few numerals, it would be more likely to be assigned to a specific topic cluster. In contrast, NB and LDA consider only word distribution when constructing topic clusters. Hence, in NB and LDA, a specific topic (e.g. stock market crash) and a daily topic (e.g. temporary stock price) might be in the same topic cluster owing to similar word distribution while they are less likely to be the same cluster in our model due to difference of numeric features. Therefore, specific topics found by our models tend to be more time-specific and daily topics found by our models tend to be more time-general. Figure 3 also verifies the claim. It is shown that our model can find more extremely daily(TE &gt; 300) and specific(TE &lt; 50) topics than those found by NB and LDA.
 Max Log-likelihood Per Document. In addition to temporal perplexity which evaluates the temporal distribution of topics found by our model, we also use Max log-likelihood per document to compare our model with NB and LDA in terms of semantic coherence which is an important measure for evaluating topic models.
As is known, topic models assume a coll ection of documents are generated by mixture of language models. Thus, we can use the idea for evaluating language models for evaluations. Log-likelihood per document is one for such measures for topic model evaluation [4]. Since our work assumes that a docu-ment is associated with only one topic, therefore, we use max log-likelihood per document instead of log-likelihood for evaluations. Formally, max log-likelihood per document ( MLLPD ) for a test set T is computed as (5): where z  X  d = argmax z w
We use the news articles written during June 2000 by Associated Press World-stream as test set which contains 4,392 news articles. Table 5 shows the com-parison of MLLPD between NB, LDA and our model on this test set. It can be seen that our model performs almost the same with NB and better than LDA, which verifies that incorporating the numeric features while constructing topic clusters do not affect the semantic coherence of topics.

At last, we list the top 5 daily and specific topics identified by our model (using num+idf feature combination) as well as their top words in table 6 for comparingthetwotopictypes.Asweca n see, the most of daily topics concern economic and financial issues such as temporary stock prices and fluctuations of exchange rates, which are actually the most common daily topic in news genre. In addition, some daily topics are weather forecasts and air pollution reports. By contrast, the specific topics identified by our model seem to correspond to one or more specific events (e.g. Eritrea X  X  border issue), which are usually time-specific. Distinguishing specific and daily topics based on text has not been well studied so far. As far as we know, Ge et al. [5] is the most related work to ours, which identifies daily events based on text for avoiding arbitrarily considering them coreferential. Unlike our unsupervised approach, they used an extra collection of documents with timestamps to generate a training set (but not golden standard) and trained a maximum entropy classifier with several categorical features like unigrams for identifying daily events. Another similar work is done by Li and Cardie [7], who used a hierarchical dirichlet process (HDP) model [9] to recognize time-specific and time-general topics for generating timelines for individuals from Twitter data.

Different from the previous work, our model only uses textual information and thus can be applied to any collection o f documents even if their timestamps are unreliable or unavailable. In this paper, we investigate several numeric features and propose a novel Bayesian model with mixtures of Poisson distributions for distinguishing daily and specific topics. Our proposed model can be easily generalized to other tasks for incorporating numeric features in Bayesian models.
 Acknowledgements. We thank the anonymous reviewers for their valuable comments. This paper is supported by National Key Basic Research Program of China 2014CB340504 and NSFC project 61375074. The contact author of this paper is Zhifang Sui.

