 Jianhong Feng ( crowdsourced select query with multiple predicates aims to find all objects from a data collection by asking crowdsourcing workers to identify whether each object satisfies every query predicate. We find that different predicates have different selectivities and if we first verify a highly selective predicate, we can avoid check-ing other predicates for those objects that do not satisfy the predicate and thus can significantly reduce the cost. An important problem is to determine a good predicate order. However, it is usually very expensive to obtain the optimal pred-icate order. To address this problem, we propose a sampling-based framework to determine a good predicate order.
 cate order is deployed as our global order. To reduce the cost, we propose two methods to compute the predicate order. The first method, called minimum ran-dom selection, generates predicate order by choosing the predicates sequence in randomly predicates arrangements. The second method, namely filtering based, further reduces the cost by selecting the better predicate order. We propose the sampling-based framework. To answer a given select query over global dataset, a random subset of objects is chosen and published on the crowd-sourcing platform to generate the optimal predicate order. Then the rest of objects are asked by adopting this predicate order. To generate an optimal pred-icate order is a key component in the sampling-based framework. Therefore, next we formally define the optimal predicate order determination problem. Definition 1. Given a set of sampling objects R and a select query with n predicates, {A 1 ( o )= a 1 , A 2 ( o )= a 2 ,  X  X  X  , A n ( o )= a predicate order  X   X  which has the minimum cost to answer the query. The minimum random selection (denoted by MRS ) includes two steps: (1) it randomly generates m permutations  X  1 ,  X  X  X  , X  m over attributes The algorithm calculates the cost of each permutation and selects the one with the minimum cost as the optimal predicate order. We calculate the cost of a permutation  X  i by adding up the cost on each attribute. Suppose  X  the attributes of  X  i and we ask questions on crowd with sequence  X  The algorithm first asks all the objects whether they satisfy attribute  X  obtains the candidate set Q 1 .Nextitasks  X  2 i from the candidate objects in Q and obtains Q 2 . Then it continues to ask all the remaining attributes and calculates the total cost Cost (  X  i ). Notice that there exist a large amount of dupli-cated questions if we ask m permutations separately. To avoid asking duplicated questions, we utilize an auxiliary matrix M to record the results that we have retrieved.
 Next we analyze the approximate ratio that  X   X  compared with the real opti-mal predicate order, denoted by  X   X   X  .Given k  X  Z and  X   X  within the k best orders with probability larger than  X  , then we must select at least m random permutations and m satisfies 1  X  m  X  1 i =0 A limitation of the minimum random selection algorithm is that it selects per-mutations randomly over predicates. Therefore, we propose the filtering based selection algorithm. We maintain a filtering profile to record the selectivity of each predicate. The profile is updated with the temporal results obtained by crowd. To generate the next permutation, we filter out the non-optimal permu-tations by considering the predicate selectivity. At last we select the permutation with the minimum cost. 4.1 Predicate Selectivity Let P ( A j ) denotes the probability that an object satisfies predicate can represent the selectivity of a predicate. P ( A j ) can be estimated by maximiz-ing the likelihood of observed objects by P ( A j )= N ( a of observed objects over A j , N ( a j ) is the number of objects satisfies A We make the equation as a validated function only if N is larger than a certain threshold. If we only observer a small proportion of objects over this proportion, 0 &lt;C&lt; 1), we can not utilize them to calculate the predicate selectivity. The threshold is set to be C  X |R| . 4.2 Permutation Selection with Predicate Selectivity Given a permutation, if there exist two predicates A i , A P (
A i ) &lt;P ( A j )and A j is in front of A i in the permutation, then the permuta-tion is called conflict . There are two processing steps to generate permutations without conflicts. First we generate a random permutation. Next we check the permutation with the profile and obtain a proper permutation. In the second step, there are two possible situations. (1) The permutation is conflicting with the profile. Therefore, it is not a proper permutation and we discard it. (2) The permutation does not conflict with the profile, then we ask questions.  X  OS  X  m . The first method selects a fixed number of orders m , where m is  X  OS  X  k/ X  . In this method, we dynamically determine m during the process 5.1 Experimental Setup Dataset. People consists of 1000 photos of people from the Attributes-Dataset . We verified five attributes of each photo using CrowdFlower.
 Evaluation Metrics. (1) Sampling Cost is the number of tasks to obtain the predicate order. (2) To t a l C o s t is the number of tasks to perform select query in the predicate order.
 Comparing methods. We used the Brute-Force method as baseline, which enumerates all the permutations, calculates their cost and selects the best one (denoted by BF ). We compared performance between our approaches and BF . To evaluate To t a l C o s t of our approaches, we first obtained optimal predicate order using BF on the entire dataset. Then we compared the To t a l C o s t between optimal predicate order (denoted by Optimal ) and our selected predicate order. 5.2 Sampling Cost and Total Cost Analysis The Sampling Cost and To t a l C o s t of our methods on the dataset are shown in Figure 1 . We have the primary observations as following: (1) the Sampling Cost of both OS  X  m and OS  X  k/ X  was always less than that of both BF and MRS , while the To t a l C o s t of both OS  X  m and OS  X  k/ X  was almost the same as that of Optimal and outperformed MRS . That is because both OS OS  X  k/ X  utilized the selectivity to select  X  X etter X  permutations which required less questions. (2) Sampling Cost of MRS was less than that of BF . Additionally, with smaller k and larger  X  ,the To t a l C o s t of MRS was close to Optimal because of taking advantage of both k and  X  to control the quality of the predicate order. The most common method of crowdsourced select query is sampling which can significantly save the cost [ 1  X  3 ]. Marcus et al. [ 1 ] primarily studied how to make use of human instinct to design the interface of tasks. Trushkowsky et al. [ 2 , 3 ] used species estimation techniques to process select query with a single predicate. In this paper, we studied the problem of query optimization for crowdsourced select query with multiple predicates. We proposed a minimum random selection algorithm to obtain the optimal predicate order. In order to further reduce the cost, we proposed the filtering based selection method. Experimental results indicated that our proposed methods significantly reduce the cost.
