 Event-based social networks (EBSNs), in which organizers publish events to attract other users in local city to attend offline, emerge in recent years and grow rapidly. Due to the large volume of events in EBSNs, event recommendation is essential. A few recent works focus on this task, while almost all the methods need that each event to be recommended should have been registered by some users to attend. Thus they ignore two essential characteristics of events in EBSNs: (1) a large number of new events will be published every day which means many events have few participants in the beginning, (2) events have life cycles which means outdated events should not be recommended. Overall, event recom-mendation in EBSNs inevitably faces the cold-start problem.
In this work, we address the new problem of cold-start lo-cal event recommendation in EBSNs. We propose a collec-tive Bayesian Poisson factorization (CBPF) model for han-dling this problem. CBPF takes recently proposed Bayesian Poisson factorization as its basic unit to model user response to events, social relation, and content text separately. Then it further jointly connects these units by the idea of stan-dard collective matrix factorization model. Moreover, in our model event textual content, organizer, and location in-formation are utilized to learn representation of cold-start events for predicting user response to them. Besides, an ef-ficient coordinate ascent algorithm is adopted to learn the model. We conducted comprehensive experiments on real datasets crawled from EBSNs and the results demonstrate our proposed model is effective and outperforms several al-ternative methods.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information Filtering, Retrieval Models c  X  Algorithms, Experimentation Event Recommendation, Bayesian Poisson Factorization, Event-Based Social Networks, Cold-start Recommendation
Along with the trend of combining online and offline in-teractions among users in the mobile Internet era, event-based social networks (EBSNs) have emerged in recent years and enjoyed a booming development. Meetup 1 and Douban Event 2 are two standard EBSNs which prove to be widely used by many users. The core goal of EBSNs is to gather neighbors (users located in the same city) together to do what they are commonly interested in.

Among all the elements in EBSNs, event is the most sig-nificant one which bridges the gap of online and offline in-teraction. Formally, a event consists of the following core elements: 1) content, which provides introduction of the event theme, 2) organizer, who launches and organizes the event, 3) location, where the event will be held, and 4) time, when the event will start. As users always prefer to partic-ipate in the events nearby [28], many EBSNs divide events by cities and provide users with the events which are lo-cated in the same city to attend. Due to a large volume of events, personalized event recommendation is essential for avoiding the information overload problem. Moreover, it is beneficial for EBSNs as the better user experience can attract more users to register on their websites. Although various recommendation problems have been studied in the last decade, only a few recent works study event recommen-dation in EBSNs. Moreover, event recommendations imple-mented in popular EBSNs are very simple for only ranking events by their popularity, chronological order, and location distance from users.

Two most recent works [21, 4] are proposed to explore this task. Both of them have one essential assumption that each event has already been registered by some users for attend-ing. Based on this assumption, they further directly asso-ciate each event with a latent factor and learn it from corre-sponding users X  participation records. Nevertheless, this as-sumption does not conform to the real scenario of event rec-ommendation in EBSNs since it ignores the fact that events http://www.meetup.com http://beijing.douban.com/events have life cycles. The outdated events whose starting time are past should be removed from the event candidate list. Be-sides, many new events which are published in a short time are registered by only a few users or not even one. They ac-count for a certain proportion in all candidates without the outdated events. As a consequence, event recommendation in EBSNs inevitably faces a serious cold-start challenge [24].
To address the above issues, we formulate a new problem called cold-start local event recommendation in event-based social networks. The substantial distinction from the task studied by [21, 4] is that our problem concentrates on cold-start event recommendation with each candidate event hav-ing no registered users for attending. Thus new event rec-ommendation results can be generated as soon as the events are published. The main challenge lies in how to learn the representations of the cold-start events without interaction behaviors with users. For overcoming this challenge, we pro-pose a C ollective B ayesian P oisson F actorization (CBPF) model. CBPF combines the merits of Bayesian Poisson factorization (BPF) [6] and collective matrix factorization (CMF) [25].

First of all, it takes Bayesian Poisson factorization as its basic unit and each unit is responsible for reconstructing dif-ferent types of data when modeling. In our problem setting, user response, social relation, and event content text should be modeled. Then CBPF jointly connects these units to construct a unified model inspired by the idea of collective matrix factorization. To learn representations of cold-start events, it associates each event with its content introduc-tion, organizer, and location information. Thus the unit of modeling user response is more complex than BPF as it in-volves interaction betweens factors of user, event content, organizer, and location. An efficient coordinate ascent algo-rithm is adopted and corresponding parameter update for-mulas are derived for CBPF. After the model learning stage, optimal factors except content factor of new events can be acquired. To generalize to the cold-start events, CBPF nat-urally infers their content factor based on content text and optimal word topic factors learned from training data. Fi-nally, we can get recommendation results by sorting the new events according to the predicted user response to them.
We should emphasize that start time information of events is also considered in this work, yet they seem to be not effective for the future event recommendation task, which will be discussed in the experiments.
 Contributions. In summary, the main contributions of this paper lie in the following three aspects: In the rest of the paper, we first discuss the related work in Section 2. Then we formulate the problem we studied and give some preparations in Section 3. Section 4 detailedly introduce the proposed model and the learning algorithm. In Section 5, the experimental comparisons among between adopted methods and some analysis are provided. Finally, we draw a conclusion about this paper.
In this section, we expand the related work in two di-rections, i.e., either they study problems similar to the cold-start local event recommendation task or they propose meth-ods relevant to it.
There are only a few research works studying on recom-mending events published online by organizers and held of-fline. Before proceeding, we should first emphasize that some researches have also mentioned event recommendation. Nevertheless, the concept of event in their work is different from what we study. For example, the activities in [29] mean broad human behaviors like shopping, tourism, and so on. The events in [12] and [18, 14] mean daily happened news and academic reports, respectively. As the carrier of events, event-based social networks are first analyzed in data mining field in [16]. In [28, 20], event-based group recommendation in EBSNs and their variants are formulated. However, as the group information is necessary and they do not consider textual content of events, the problems are still different from the event recommendation problem. Until recently, two works [21, 4] appear to address this problem. In [21], a standard matrix factorization approach which jointly mod-els event, location, and social relation is proposed. Yet they ignore content and organizer information of events. There is no clear difference between their method and other methods applied to other recommendation problems such as location recommendation [13]. Du et al. further considers event con-tent information [4]. However, their content modeling part is only based on topic distributions inferred from the stan-dard topic model [2] and the learning process is separated from the final model. Moreover, their problem setting is bi-nary classification for judging whether a user will attend an event and thus is a little different from the recommendation problem. Most of all, for the above two works, both of them associate a latent factor directly with each event and try to learn them from training data, which is not very demanding in real scenario. As we mentioned before, they ignore the life cycles of outdated events and newly published events which cause cold-start event recommendation. Hence, learning the latent factors directly from training data is impossible and their methods cannot be applied to our problem setting.
As the cold-start local event recommendation in EBSNs is a new problem and there is no standard method to solve this. We introduce several lines of research methods that are relevant to some aspects of the problem.
 Textual content based methods. These methods focus on how to effectively model textual content information of users and items for recommendation. They are often utilized in cold-start recommendation. Word-based similarity meth-ods [19] recommend items based on textual content similar-ity in word vector space. In [4], standard topic model [2] is utilized to learn topics of users based on the content of their attended events, and then the similarity between topic factor of user and events is calculated, which is an impor-tant component of their method. In [26], CTR is proposed to combine standard topic model with matrix factorization for recommendation. Gopalan et al. [5] recently propose a Bayesian Poisson factorization (BPF) approach for modeling content in recommending articles.
 Location based methods. There are many works adopt-ing location information for recommendation in recent years. Some of them utilize distance information between loca-tions [27, 28] and the idea is also adopted by [4] in event recommendation. Moreover, latent factor models such as matrix factorization [29] can model location information by associating each location with a latent factor. In [21], their partial method is to model location for event recommenda-tion, which first clusters locations of events into regions and then assigns a latent factor to each region.
 Multiple factor models. Latent factor models tend to integrate multiple factors to handle more complex relations in recommender systems in recent years. Tensor factoriza-tion [11] reconstructs the elements in a tensor by getting inner product of three factors, but not two factors in tra-ditional factor models. In [1], factors from item side are enhanced by other factors. It addresses the pairwise interac-tion between multiple factors. Word latent factor is further incorporated into the multiple latent factor models in [3].
We adapt the above related methods to the cold-start local event recommendation problem. By comparing these alter-natives with CBPF in the experiments, we demonstrate the superiority of our proposed model for the new problem.
We first provide some necessary definitions and formulate the cold-start local event recommendation problem. Then we describe two methods that are related to the proposed model.
Event based social network connects online and offline world through events. In the following, we formally define event based social network from the centric view of events. Definition 1 (Event Based Social Network (EBSN)) An event based social network is a heterogeneous graph G = (
V , E ) mainly containing six types of nodes V = ( E,U,O,C, L,T ) . Among them, event set E is the most significant one which associates other nodes together. For an event e  X  E , it should be published by an organizer o e ( o  X  O ) online. Mean-while, the location l e ( l  X  L ) where it will be held and the timestamp t e when it will start are also specified. Besides, event e should have a content text c e ( c  X  C ) to introduce itself. The textual document c e consists of multiple words from a vocabulary V and C c e v denotes the occurrence count of word v  X  V in the document c e . For a user u  X  U , if he is ing. Thus the event has a user attendance list U ( e ) . All the above relations are directly relevant to event node, which can be regarded as event-oriented relations. Besides, each user u  X  U may have a friend list F ( u ) . Hence, event-oriented relations and social relations form the edge set E .
Figure 1 provides a simple example to illustrate the di-verse relations existed in event based social networks. As Figure 1: A toy example showing diverse relations in EBSNs. we mentioned, each event connects to a unique organizer, textual content document, location address, and start time moment. However, for an organizer, he may organize several different events, such as the organizer who has organized the event of Bachelor Party and Machine Learning Salon shown in the figure. For a user, he may also attend more than one events and have many friends. It is also similar for a loca-tion at which several events are held. In summary, there are 1-to-1, 1-to-n, and n-to-n relations in the networks. Event recommendation plays a significant role for EBSNs. Usually, events to be recommended for each user should be held in the city where the user stays. Moreover, cold-start events are the main targets studied in this work. According to the above two requirements for events, we formally define the cold-start local event as follows, Definition 2 (Cold-start Local Event) Given a target city x , a cold-start local event e  X  E not only should be held in this city, but also has been published online recently and thus has no registered users for attendance currently, i.e., U ( e )  X  X  X  .

The two requirements for cold-start local events are ra-tional. Location requirement makes it possible for users to go to the locations where events held. And cold-start status requirement is realistic for many new events. Now based on the above definitions, we formally define the new problem studied in this work as below, Problem (Cold-start Local Event Recommendation) In an event based social network, given a target city x , its local event list is represented as E new ( x ) and user list is event e  X  E new ( x ) according to the user response R u,e is computed by a suitable predictive model. The model is constructed based on the known user response to historical events e  X  E old ( x ) . Finally, different top-n ranked events are recommended for each user.

Naturally, how to compute the user response R u,e is the core of the problem. It is intuitive to utilize users X  event attendance histories, social relations, and events X  related in-formation to construct an effective predictive model.
Bayesian Poisson factorization is proposed recently for im-plicit feedback and content based recommender system [6, 5]. Although Poisson factorization is already utilized for recommendations [17, 15], the key difference is that BPF combines Poisson factorization with Bayesian learning which can handle sparse data well and is more robust to the issue of overfitting. It shows promising results compared to tradi-tional factorization models such as matrix factorization [22].
Specifically, the Poisson distribution for the rating R of user u to item v is defined to be Poisson( R u,v ;  X  T u  X  v ) = (  X  T u  X  v ) R u,v exp(  X   X  where  X  u  X  R K denotes the latent factor of user u and  X  v  X  R K represents the latent factor of item v .  X  T regarded as the shape parameter of Poisson factorization. Each component of the above two factors is assumed to drawn from a Gamma distribution defined as where  X  a is the shape parameter of the Gamma distribution and  X  b is the rate parameter of the Gamma distribution.
The goal of Poisson factorization is to learn optimal  X  and  X  v to reconstruct original training data. Under Bayesian learning framework,  X  u and  X  v should be marginalized and it is intractable to directly optimize them. To address the issue, Gibbs sampling [23] and variational Bayesian infer-ence [6] are proposed. In this work, our proposed model CBPF builds on Bayesian Poisson factorization by taking it as its basic unit to model different types of data.
To jointly model multiple relational matrices together, col-lective matrix factorization is proposed [25]. The core idea of this model is to simultaneously reconstruct the several relation matrices through designed objective functions. All the matrices are associated with some shared elements.
For example, suppose there are two relation matrices M 1 and M 2 . A i denotes the factor of row i in matrix M 1 and B represents the factor of column j in the same matrix. It is similar for M 2 that B n and C m corresponds the factor of row n and column m , respectively. Hence B are the shared latent factors. To jointly model the two matrices, the following hybrid objective function is defined as, where  X  1 and  X  2 are relative weights to control the two sub-objectives. They are commonly tuned on validation datasets.

Unlike traditional settings of recommender system where only a user-item matrix needs to be modeled, multiple matri-ces exist in the cold-start local event recommendation prob-lem, such as social relation matrix and event-word matrix. Therefore, we resort to the idea of collective matrix factor-ization. Particularly, we adopt Poisson factorization instead of matrix factorization as a basic unit and connect them through the idea of collective reconstruction. In this section, we first give an overview of the model. Then we describe the model in detail, including mathemati-cal formulations. In what follows, the optimization approach based on coordinate ascent algorithm is provided. Finally, the way to infer the content topic factors of new events and predict user response to the events are introduced.
Figure 2: Graphical model of the CBPF model.
From a high-level perspective, CBPF combines the mer-its of Bayesian Poisson factorization and collective matrix factorization. As the graphical model of CBPF shown in Figure 2, the new model first utilizes BPF as its basic unit to model social relation, user response to events, and event content text separately. Then it connects each unit through the idea from CMF. The components in social relation and response matrices take binary value, but not in content word matrix, where the components take positive integer. In latent factor models such as matrix factorization and Poisson factorization, each row and column of matrices as-sociates with a K-dimensional latent factor. The main goal of latent factor models is to learn these latent factors in a model learning stage and predict the missing elements in ma-trix by inner product of their corresponding row and column factors in a prediction stage. However, in our problem set-ting, cold-start events which will be recommended to users do not occur in user-event and event-word matrices in the learning stage. As a result, we cannot directly associate a latent factor with each of them. The above problem is called out-of-matrix prediction in [26].

It is intuitive to utilize organizer, introduction textual con-tent, location, and starting time information of events to overcome the cold-start issue. In CBPF model, event latent factor is replaced by the summarization of event organizer latent factor, event location latent factor, and event intro-duction content latent factor. We also try temporal latent factor in the experiments, nonetheless it is ineffective for this task, which will be discussed in the experimental part.
The number of organizers is much smaller than that of events and users. Besides, the total count of locations in a city is limited. Therefore, the cold-start degree of organizers and locations is minor. Based on this phenomenon, we as-sume each organizer and location occurs in training data at least once, and thus their latent factors can be learned when training model. Unlike the above two types of latent factors, the content factor of cold-start events should be inferred in the prediction stage. CBPF achieves this by modeling in-troduction textual content in both stages. More specifically, optimal word factors can first be obtained when learning the model. Then in the prediction stage, word factors are fixed and the knowledge contained in them are transferred to in-troduction content factors when modeling word occurrence count of content text.

Moreover, social relations are also considered in CBPF. In the binary social relation matrix we mentioned before, value one denotes users have social relation while zero not. CBPF aims at reconstructing the social matrix in model learning stage. The goal of modeling social relations is to ensure latent factors of friends are similar.
We assume the dataset for a city is given. We denote the historical event set as E old and cold-start event to be recom-mended as E new according to the Definition 1, We shall use a user event pair ( u,e ) as an example for later introduction. A social friend f u of the user, organizer o e , introduction con-tent c e , and location l e of the event e are also considered. We initiate the detailed specification of CBPF by the order of data generation process.

For latent factors shown in Figure 2, we assume they are drawn from Gamma distributions. This is because Gamma distributions are the conjugate priors for the shape param-eters of Poisson distributions and it will facilitate Bayesian learning. Specifically, they are defined to be where  X  f u  X  R K is the social factor of user u ,  X  u  X  R preference factor of user u . Hence, each user is associated with two types of factors.  X  o  X  R K is the latent factor of organizer o , and it is similar for  X  l  X  R K of location l ,  X  R
K of event introduction textual content c , and  X  v  X  R K word v . The expression of the Gamma distribution is shown in Equation 2.

To represent latent factor  X  e of event e , we utilize organizer factor, textual content factor, and location factor. Specifi-cally, we incorporate relative weights between three factors to adjust their final contributions to the preference response R u,e . Formally, the formula of computing  X  e is defined as below, where  X  o ,  X  c , and  X  l are relative weights and can be tuned based on recommendation performance on validation datasets. One simple way to tune them is to first determine the most significant factor and set its relative weight to be one. Then we can constrain the other two relative weights to be within the range of zero to one. Finally a grid search approach with a fixed step size can be applied to determine them. The de-tailed settings of the these three relative weights can be seen in the experimental part.

Suppose S uu 0 denotes the binary value of social relation between user u and u 0 . We specify the values of S uu 0 and C e e v to be generated from Poisson distributions. Par-ticularly, they can be expressed as
Based on the above description, we can conclude the gen-erative story of CBPF as following, 1. For each user u , 2. For each organizer o , draw latent factor 3. For each location l , draw latent factor 4. For each word v , draw topic factor 5. For each event e , 6. For each user-user pair ( u,u 0 ), draw the binary social 7. For each user-event pair ( u,e ), draw the preference re-For convenience, we denote all the Gamma priors of latent factors with an integrated expression p ( X  , X  ;  X   X  ,a , X   X  = {  X  u , X  o , X  c e , X  l , X  f L,  X  u 0  X  U . The joint probability of generating all visible data is defined to be, p ( R,S,C ) = p ( X  , X  ;  X   X  ,a , X   X  ,b )
The core goal in the model learning stage is to get the op-timal latent factors, i.e., {  X  , X  } , for predicting user response to events. As the events to be recommended are cold-start, their content factor  X  c e ( e  X  E new ) cannot be obtained in the learning stage, we leave the details of inferring  X  the prediction stage. Given a set of training data, the way to achieve the goal under Bayesian learning is to compute the posterior distribution p ( X  , X  | R,S,C ). However, it is in-tractable to directly compute the posterior because the nor-malization term shown in Equation 7 contains the coupling integration variables. We resort to variational Bayesian in-ference [10, 2, 5] to address this issue.

The general idea of variational Bayesian inference is to derive a lower bound of the normalization term in this work, i.e, p ( R,S,C ;  X   X  ,a , X   X  ,b ). and then optimizes the lower bound through standard learning algorithms. The lower bound is usually obtained by applying Jensen X  X  inequality though a new designed variational distribution q ( X  , X  ), log p ( R,S,C ) = log
To implement variational Bayesian inference for CBPF, we should first incorporate several types of auxiliary la-tent variables to facilitate inference like [5]. Specifically, for user-user pair ( u,u 0 ), we add K latent variables s Poisson(  X  u,k  X  f butions ensure they are integers whose sum is equal to S uu Similar operation is repeated for z c e v,k  X  Poisson(  X  c C ev = P k z c e v,k . The operation for user-event pair ( u,e ) is different as  X  e consists of three types of latent variables. Following [5], we construct a 3K latent space by adding K latent variables r uo e ,k  X  Poisson(  X  o  X  u,k  X  o e Poisson(  X  c  X  u,k  X  c e ,k ), and r ul e ,k  X  Poisson(  X  spectively. Their sum should satisfies the requirement R ue P r 0. And it is the same for s uu 0 ,k and z c e v,k . This feature helps decreasing the complexity of variational parameter space and complexity of learning algorithm. After adding these new latent variables, the variational distribution becomes q ( X  , X ,Z ) where Z denotes all the added latent variables.
Before we continue, we first get the complete conditional distribution [7] for each latent variable, which will be used for later parameter updating. We divide the latent variables into two categories. The first category includes  X  and  X  whose priors are Gamma distributions. We take  X  v,k as an example and fix other latent variables. After extracting the relevant terms of  X  v,k from Equation 7, we can derive the complete condition distribution of  X  v,k as below, = Gamma(  X  va + X It is similar to derive the conditionals for other latent vari-ables belonging to the first category. The second category covers all the auxiliary latent variables whose priors are Pois-son distributions. It is a little more complex to derive them than the variables in first category. We utilize the conclu-sion from [9, 6] that given the sum of a set of latent variables drawn from Poisson distributions, the conditional distribu-tion of the variables is a multinomial whose parameters are the normalized values of their priors. For example, the con-ditional distribution of z c e v is where  X  denotes the element-wise product operation. The integrated list of conditional distributions for all latent vari-ables is shown in Table 1, in which the parameter form of Multinomial distribution corresponds to its formula in an exponential family.

To maximize the lower bound L ( q ), we first define q ( X  , X ,Z ) with a mean-field variational form [10], q ( X  , X ,Z ) = Y Y Y
Y Table 1: Conditional distribution of latent variables. where each p denotes the corresponding type of its vari-ables in Table 1. The parameters with superscript shp rep-resent the shape parameters of Gamma distributions while the parameters with superscript rte mean the rate param-eters.  X  c e v,k and  X  uu 0 ,k are the multinomial parameters for z v,k and s uu 0 ,k , respectively.  X  o ue,k is one part of multino-mial parameter for r ue,k which belongs to the dimension of 1 to K . Analogously,  X  c ue,k belongs to K + 1 to 2 K and  X  to 2 K + 1 to 3 K . Overall, each latent variable is indepen-dent on the others. If the optimal variational parameters can be obtained, then approximate posterior distribution, i.e., p ( R,S,C ;  X   X  ,a , X   X  ,b ), can be calculated.
After substituting the variational distribution in Equa-tion 8 with Equation 11, we optimize the lower bound to get optimal variational parameters through a coordinate as-cent algorithm adopted in [7, 6, 5]. The central idea of the algorithm is to optimize one variable each time while fixing all other variables. The conclusion from [7] shows that if the complete conditional distribution of a latent vari-able is in an exponential family and its corresponding vari-ational distribution has the same form, then its variational parameters have a closed-form solution using coordinate as-cent algorithm. More specifically, the variational parame-ter equals the expectation of the conditional parameter in its corresponding posterior distribution under the complete variational distribution q ( X  , X ,Z ). Luckily, Bayesian Pois-son factorization satisfies the requirements [5] and it is also suitable for the proposed CBPF.

We choose the variational parameters, i.e.,  X   X  c e ,k and  X  as examples to derive their closed-form solution in each up-date. The solutions for other variational parameters can be educed similarly. For  X   X  shp c above, the closed-form solutions can be represented as, where E q [ x ] denotes the expectation of variable x under the probability distribution q . After solving the expecta-tion terms, we can get the following update expressions, For  X  ue,k , it has a similar expectation like Equation 12. However, its update expression is more complex since the expectation contains logarithms and  X  ue,k lies in a 3 K prob-ability space. Formally, the derived update formula is  X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X  where  X (  X  ) denotes the Digamma function. We should em-phasize that the above parameters should be normalized to-gether to ensure their sum to be one. The above updates utilize the conclusion about the expectation of a logarithm variable x with a Gamma prior, i.e., E q [log x ] =  X ( x )  X  log x . Relative weights such as  X  o can be incorporated here by as-suming they are drawn from Gamma distributions with the shape parameters being  X  o ,  X  c , or  X  l , and the rate parame-ters just being value one.

Based on the above update formulas and their variants for other variational parameters, we can update each of them one time in a circulation and repeat this process iteratively until the values of the parameters converge.
The prediction stage of CBPF for the cold-start local event recommendation task mainly consists of two steps. The first step is to infer the variational parameters of con-tent topic factors for new events and the second step is to predict user response to the events.

First, we only update  X   X  c e ,k and  X  c e v,k ( e  X  E new other variational parameters fixed. While the update for-mula of  X  c e v,k is similar to that in the model learning stage, the way to compute  X   X  c e ,k is different and shown below, where user related terms such as  X  c ue,k vanish. It is intu-itive since the real responses of users to the new events are unknown.  X   X  c e ,k and  X  c e v,k are updated iteratively and only several iterations are necessary to achieve good results.
Then the preference response of user u to the new event e can be predicted based on the following formula, Finally, the events are ranked according to the response scores of each user and then personalized top-n event rec-ommendations are delivered to users.
In this section, our goal is to evaluate the effectiveness of the proposed model. To achieve this, we first describe the real datasets we used in the experiments. Then we intro-duce the evaluation metrics, adopted comparison methods, and parameter settings of the proposed model. Finally, we compare the results of CBPF and the comparison methods.
Because no benchmark datasets are available for evalu-ating performance on the event recommendation task, we collected real datasets for events and users by crawling from Douban Event in 2012. For each event, we get its organizer, content introduction, geographical address (including loca-tion name, longitude and latitude), start time information, and a list of registered users for attending. For each user, we acquire his event attendance list and social friend list. Table 2: Introduction of experimental datasets.

To simulate real scenarios, we first partition all events ac-cording to their corresponding cities. We then choose Bei-jing 3 and Shanghai 4 , the two largest cities in China, to cre-ate two local event datasets. As home addresses of users are private, we choose users for both cities just based on whether they have attended the events in them. We further remove users who attended less than five events to filter noisy data. To test the proposed model, we divide both cities X  events into training and prediction set based on chronological order with a common ratio of 7:3. The user register list of events in the prediction sets are unknown when learning models, and thus we can regard events in prediction set as cold-start events. We further partition the prediction set into validation and test set with a ratio of 1:2. For event content information, we first conducted Chinese word segmentation and removed stop words from it. Then we construct a word vocabulary by filtering some noisy words which occur very few times in the datasets. Finally, the basic statistics of the datasets we used are shown in Table 2.
We adopt Precision and Normalized Discounted Cumula-tive Gain at position n (P@n and NDCG@n), both of which are widely used in the top-n recommendation task. In our task, P@n measures the ratio of the recommended events that are really attended by users. NDCG@n further as-sumes the events appearing earlier in a recommendation list are more important and assigns more weights to the ground-truth events that are ranked higher.

In real scenario of recommender systems, it is desirable that the first event a user is willing to attend should appear as early as possible in a top-n recommendation list. To mea-sure this point, we employ Mean Reciprocal Rank (MRR) which measures the reciprocal of the first occurrence posi-tion of ground truth event for each user.

All the three metrics are first calculated on each user X  X  recommendation list separately and then taken an average among all users. If the values of the three metrics are larger, the recommendation performance is better. http://en.wikipedia.org/wiki/Beijing http://en.wikipedia.org/wiki/Shanghai
As there is no standard method to solve this new problem, we adopt several alternative location-based, content-based, and multiple factor methods. For the multiple factor models we adopted, we also incorporate relative weights into them as we do for CBPF to ensure fair comparisons. The hyper-parameters of all the adopted methods, such as regulariza-tion parameter and relative weights, are tuned according to performances on validation datasets. For latent factor mod-els, we set the dimensions to be 50 uniformly, which is large enough for comparing different results.

L-Dis. We implement distance-based method as [27] by learning an exponential decay function about distance be-tween users X  visited locations and target locations.
L-HeSig. Although HeSig proposed in [21] cannot be directly applied to our task, its partial method which divides events X  locations into regions and learn user preferences to the regions can be compared here. The number of clusters is set to be 100 experimentally.

L-BPF. As the basic Bayesian Poisson factorization [6] is the basic unit of our method, we adopt it here for event recommendation by utilizing events X  location information.
Word-based Similarity (WBS). WBS constructs word vectors for new events based on their introduction content and for users based on content of their attended events. The events whose word vectors are more similar to users X  will be recommended.

Topic-based Similarity (TBS). Unlike word space ado-pted in WBS, TBS utilizes topic model to get low-dimensional topic vectors for users and new events. It is the partial method adopted in [4] for using content information.
C-BPF. Bayesian Poisson factorization [5] is also utilized in content-based recommendation. Hence we should com-pare CBPF with it.
 O-BPF. It utilizes organizer information with Bayesian Poisson factorization. The modeling process is similar to L-BPF.

CTR. CTR [26] is a standard content-based recommen-dation algorithm which combines topic model with matrix factorization for recommending content-based items.
Tensor Factorization (TF). 3-way tensor factorization is employed in recommender systems related to three dif-ferent types of factors [11]. Here we specify them as user, organizer, and location factor.

MLFM. Multiple latent factor model is adopted in many works such as [1]. It addresses the pairwise interactions be-tween user factor and other factors.

WMLFM. Word-enhanced multiple latent factor model is similar to MLFM by additionally adding word-based la-tent factors. It is similar to the models proposed in [3, 8]. However, it is not very efficient as latent factors of all words in an event should be summarized in every computation.
We follow the hyper-parameter settings in [5]. Specifically, the Gamma prior parameters of all the latent factors are fixed to be 0.3. We initialize the variational parameters of  X  and  X  v using the topic factors learned from the standard topic model [2]. The variational parameters of  X  u ,  X  o ,  X   X  f are set to be their Gamma priors with a small random noise. By setting  X  o to be 1,  X  c and  X  l are tuned to be 0.4 and 0.1, respectively.
In this section, we analyze the results of all the adopted comparison methods and CBPF on metrics of NDCG@3, Precison@3, NDCG@5, Precision@5, and MRR. The results of them on both datasets are shown in Figure 3.

We first compare the performance of the location-based methods. From the Figure 3(a) and 3(b) we can see L-HeSig performs a little worse than the basic method, i.e., L-Dis. Thus it is not very effective in this setting. L-BPF out-performs the above two methods significantly. Particularly, by comparing L-BPF with L-HeSig, we can conclude that a more fine-grained location factor is more suitable than a re-gion based latent factor in this task. The results provide the intuition of modeling location information through a latent factor model such as BPF.
 We then analyze the results of content-based methods, i.e., WBS, TBS, C-BPF, and CTR. As expected, WBS performs worst among the four methods due to the fact that the word vectors of users and events are very long (vocabulary size) and relatively sparse, which may lead to inaccurate simi-larities. TBS overcomes the data sparsity issue by utilizing topic model to learn low-dimensional topic vectors and gain notable improvements over WBS on both datasets. Hence, topic-based similarity is better than bag-of-words based sim-ilarity for event recommendation. It is a surprise that CTR performs not well in this task, with only better results than WBS. C-BPF performs best among the related algorithms. [5] also shows its improvement over CTR. In summary, uti-lizing BPF as a basic unit in CBPF to model content infor-mation of events is promising.
 Now we study the results of O-BPF. By comparing it with L-BPF and C-BPF, we find that O-BPF behaves better than the two methods in Figure 3(e) and 3(f). It reveals the orga-nizer information is more important to the cold-start local event recommendation task. We also see that O-BPF even outperforms MLFM which additionally incorporates loca-tion factor into the model slightly. This is mainly explained by the reason that BPF is more suitable for modeling im-plicit user feedback than matrix factorization methods [6] and user response to events is one kind of such implicit feed-back.

Finally, we make comparisons between CBPF and the other methods, especially the adopted multi-factor models. TF does not behave very well due to the sparsity of user-organizer-location cube. WMLFM performs the third best because it integrates all related factors. CBPF-S is the sub-method of CBPF by removing the social factor from CBPF. Although CBPF is slightly better than CBPF-S, it can still indicate the rationality of incorporating social relations into the model. CBPF achieves the best results consistently in both datasets, which demonstrates it is effective and better than the other alternative methods for the new cold-start local event recommendation problem.
Organizer, content, and location factor are three main fac-tors for events in this task. Although the results of L-BPF, C-BPF, and O-BPF shown in Figure 3(e) and 3(f) can indi-cate their effectiveness for the task alone, the contribution of each factor to CBPF should also be explored. This is because combining multiple latent factors to form a unified (c) Content -Beijing (g) Multi-factor -Beijing model does not mean the results of the new model is the performance summarization of each factor.

We adopt the strategy of removing one factor from CBPF each time to test the contribution of the removed factor to CBPF. Specifically, we test three sub-methods, i.e., CBPF-O, CBPF-C, and CBPF-L. The results of them are displayed in Figure 4. We find CBPF-O performs clearly worse than the other methods, which again indicates the importance of organizer information to the task. The reason may be at-tributed to the characteristics of offline meeting in events. Users are more cautious to make decisions and inclined to attend the events held by the organizers their trust. CBPF-L achieves better results than CBPF-C, which reveals loca-tion information makes a smaller contribution to CBPF than content information. This is because organizers get used to holding events in several fixed locations, which leads to the decrease of information gain when location factors are added to the integrated model.

Lastly, we provide some more results of modeling social relations collectively as a complementary to the comparison of CBPF and CBPF-S shown in Figure 3(g) and 3(h). We construct SC-BPF which is an extension of C-BPF by in-corporating social relations and observe the improvements of SC-BPF over C-BPF presented in Figure 4(c) and 4(d). This also indicates that considering social relations is effec-tive for the task, although the improvements are minor.
We try to utilize the start time information of events for recommendation. As time is continuous, we should first dis-cretize the time space. Specifically, we create a 48-dimensional time vector. Each dimension corresponds to a one-hour pe-riod in a weekday or weekend. Bayesian Poisson factor-ization is applied to model user preference to the time pe-riods. However, the performances of event recommenda-tion are relatively low on both datasets, with 0.0109 on NDCG@3 of Beijing dataset and 0.0113 on NDCG@3 of Shanghai dataset. It reveals that the start time informa-tion of events is not very effective for this task. One main reason is that the users X  online register behaviors for at-tending events mainly reflect their interests. They may not consider whether they are available at the start time of a specific event. Actually, it is not easy for users to determine it so long before the events will be held.
As [6] indicates, the computational cost mainly depends on non-zero elements in matrices such as user-friend, user-event, and event-word count matrices in this work. Here we provide an illustration for our method. For coordinate as-cent algorithm, its computational cost is mainly determined by the space complexity of parameters to be updated. We take  X  ue shown in Equation 14 as an example to illustrate the variational parameters of added latent factors as they dominate the space complexity of all latent factors. Sup-pose the number of non-zero elements in user-event interac-tion matrix is | A ue | which satisfies | A ue || U || E | . For R which is equal to 0, its corresponding enhanced latent vari-be 0 as we discussed before. Thus there is no need to learn  X  ue,k for these latent variables as they are already known. As a result, the space complexity of  X  ue,k to be learned is | A ue || K | instead of | U || E || K | . It is the same for  X   X  v that their parameter space complexities are based on the number of non-zero elements in user-user social matrix and event content-word matrix as well. For the other varia-tional parameters shown in Equation 11, their complexities are much lower than the above variational parameters and some of them are also based on the number of non-zero el-ements, such as  X   X  shp c learning algorithm is efficient.

To quantifiably verify the efficiency of CBPF, the learning time cost comparison with WMLFM is provided in Table 3. As we can see, CBPF costs much less time than WMLFM, which confirms to the expectation.
In this paper, we have studied a new problem on cold-start local event recommendation in event-based social so-cial networks. We propose a new model called collective Bayesian Poisson factorization to handle this problem. The new model collectively integrates user response, social rela-tion, and event content information through Bayesian Pois-son factorization. To address the cold-start issue, the model further utilizes events X  organizer, location, and textual con-tent information to learn representations for the cold-start events. An efficient coordinate ascent algorithm is adopted to learn the optimal parameters fo the model. The exper-imental results on real event datasets have shown that our model is effective and outperforms several alternative meth-ods.
 We thank the anonymous reviewers for their valuable and constructive comments. This work was supported in part by National Basic Research Program of China (973 Program) under Grant No. 2014CB340505, National Natural Science Foundation of China under Grant No. 61272088, and Ts-inghua University Initiative Scientific Research Program.
