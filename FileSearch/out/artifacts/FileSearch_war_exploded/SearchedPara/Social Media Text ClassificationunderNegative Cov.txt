 Applications using social media data, such as reviews, discussion posts, and (micro) blogs are becoming increasingly popular. We observed from our collaborations with social science and health science researchers that in a typical appl i-cation, the researcher first need to obtain a set of posts of a particular topic that he/she wants to study, e.g., a political issue. K eyword search is often used as the first step. However, that is not s ufficient due to low precision and low recall . A post contain ing the keyword  X  X olitics  X  may not be a political post while a post that does not co n-tain the key word may be a political post. Thus, t ext classification is needed to make more s o-phisticated decision s to improve accuracy . bel s a set of relevant posts (positive data ) about the political issue and irrelevant posts (negative data ) not about the political issue and then build s a classifier by running a learning algorithm , e.g. SVM or na X ve Bayes . Howeve r, the resulting classifier may not be satisfactory. T here may be many re a sons . O ne key reason we observed is that the labeled negative training data is not fully representative of the negative test data. and the set of all other irrelevant topics discussed in a social media source be T = { T 1 , T 2 , ..., T which forms the negative data . n is usually large. However, d ue to the labor -intensive effort of manual labeling, the user can label only a certain num ber of t raining posts. Then the labeled neg a-tive training post s may cover only a small nu m-ber of irrelevant topics S of T ( S  X  T ) as neg a-tive. Further, due to the highly dynamic nature of social media, it is probably impossible to label all possible negative topics. In testing, w hen posts of other negative topics in T  X  S show up, the ir classification can be unpredictable. For e x-ample, in a n application, the training data has no negative example s about sport s . However, in testing, some sports posts show up . These une x-pected sports posts may be classified arbitrarily, which result s in low classification accuracy. In this paper , we aim to solve this problem.
 covariate shift , a type of sample selection bias . In classic machine learning, it is assume d that the training and test ing data are drawn from the same distribution . However, this assumption may not hold in practice such as in our case above , i.e., the training and the test distributions are different ( Heckman 1979 ; Shimodaira 2000; Zadrozny 2004; Huang et al. 2007; Sugiyama et al. 2008; Bickel et al. 2009) . In general, th e sample sele c-tion bias problem is not solvable because the two distributions can be arbitrarily far apart from each ot her. Various assumptions were made to solve special cases of the problem. One main assumption was that the conditional dis tribution of the class given a data instance is the same in the training and test data sets (Shimodaira 2000; Huang et al. 2007; Bicke l et al. 2009). This gives the covariate shift problem.
 covariate shift problem . We assume that the c o-variate shift problem occurs mainly in the neg a-tive training and test data, and no or minimum covariate shift exists in the positive training and test data. This assumption is reasonable because the user knows the type of posts / documents that s / he is looking for and can label many of them. 2009), our speci al case of the covariate shift problem can be stated formally as follows: l et the set of training examples be {( x 1 , y 1 ), ( x 2 , y 2 ( x k , y k )}, where x i is the data/feature vector and y is the class label of x i . Let the set of test case s be { x k + 1 , x k + 2 , ... , x n }, which have no class labels. Since we are interested in binary classification, y i is either 1 (positive class ) or -1 (negative class ). T he labeled training data and the unseen test data have the same target conditional distribution p ( y | x ) and the marginal distributions of the pos i-tive data in both the training and testing are also the same. But the marginal distributions of the negative data in the training and testing are di f-ferent , i.e.,  X  ! (  X  ! )  X   X  ! (  X  ! ) , where L , T , and  X  represent the labeled training data, test data, and the negative class respectively. shift problem basically work as follows (see the Related Work section) . First, they estimate the bias of the training data based on the gi ven test data using some statistical techniques. Then, a classifier is trained on a weighted version of the original training set based on the estimated bias. R equiring the test data to be available in training is , however, a major weakness. In the social m e-dia post classification setting , the system needs to constantly classify the incoming data. It is i n-feasible to perform training constantly. technique that does not need the test data to be available during tra ining due to the specific n a-ture of our problem, i.e., the positive training data does not have the covariate shift issue. class classification ( Sch X lkopf et al. 1999; Tax and Duin, 1999a ), i.e., one -cla ss SVM. We sim p-ly discard the negative training posts / documents completely because they have the covariate shift problem . Although this is a valid solution, as we will see in the evaluation section, the models buil t based on one -class SVM perform poorly. Although it is conceivable to use an u nsupe r-vised method such clustering, SVD ( Alter et al., 2000) or LDA (Blei et al., 2003) , supervised learning usually give much higher accuracy. ing supervised learning in the original document space based on n -grams , we perform learning in a similarity space. Thus, t he key novelty of the method is the transformation from the original document space (DS) to a center -based similarity space (CB S) . In the new space, the covariate shift problem is significantly mitigated, which enables us to build more accurate classifiers. The reason for this is that in C B S based learning the vectors in the similarity space enable SVM (which is the learning algorithm that we use ) to find a good boundary of the positive class data based on similarity and to sep a rate it from all possible negative class data , including those ne g-ative data that is not represented in training . We will explain this in greater detail in Section 3 .5 after we present the proposed algorith m, which we call CBS -L (for CBS L earning ) . 
This paper makes three contributions: First, it formulates a special case of the covariate shift problem. This case o ccurs frequently in social media data classification as we discussed above . Second, it proposes a novel CBS space based learning method , CBS -L , which avoid s the c o-variate shift problem to a large extent because it is able to find a good similarity boundary of the positive data. Third, it experimentally demo n-strates the effectiveness of the proposed method . Traditional supervised learning assumes that the training and test examples are drawn from the same distribution. Howeve r, this assumption can be violated in many applications. This is esp e-cially the case for social media data because of the hi gh topic diversity and constant changes of topics . This problem is known as covariate shift , which is a form of sample selection bia s. econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias ( Bickel et al. 2009 ). ma and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio is then used to generate weighted training exa m-ples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estim a-tion, while Hu ang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Ts u-boi et al. (2008) estimated the weights for the training instances by minimizing the Kullback -Leibler divergence between the test and the weighted training distributions. Bickel et al. ( 2009 ) proposed an integrated model. As we di s-cussed in the introduction, the need for the test data at the training time is a major weakness for social media data classification. The proposed technique CBS -L doesn X  X  have this restriction . classification is a suitable approach to solve the problem. Tax and Duin (1999a and 1999b) pr o-posed a model for one -class classification called Support Vector Data Description (SVDD) to seek a hyper -sphere around the positive data that encompasses points in the data with the min i-mum radius. In order to balance between model over -fitting and under -fitting, Tax and Duin (2001) proposed a method that tries to use artif i-cially generated outliers to optimize the model p arameters . However, their experiments suggest that the procedure to generate artificial outliers in a hyper -sphere is only feasible for up to 30 d i-mensions. Also, as pointed out by (Khan and Madden, 2010; 2014), one drawback of their methods is that they o ften require a large dataset and the methods become very inefficient in high dimensional feature spaces. Since text documents are usually represented in a much higher dime n-sional space, these methods are less suitable for text applications. Manevitz and Yo usef (2001) performed one -class text classification using one -class SVM as proposed by Sch X lkopf et al. (1999) . The method is based on identifying outl i-er data that are representative of the second class. Instead of assuming the origin is the only me m-ber o f the outlier class, it assumes those data points with few non -zero entries are also outliers. However, as reported in the paper, their method s produce quite weak results ( Sch X lkopf et al., 1999 ; 2000 ) . Li et al. (2003) present ed an i m-proved version of one -class SVM for detecting anomalies . Their idea is to consider all data points that are close to the origin as outli ers. Both (Yang and Madden, 2 007) and (Tian and Gu, 2010) tried to refine Sch X lkopf X  X  model s by searching optimal parameters. Luo et al., (20 07) proposed a cost -sensitive one -class SVM alg o-rithm for intrusion dete ction . W e will see in the experiment section that one -class classification is far inferior to our proposed CBS -L method. 
In this work, we propose to represent doc u-ments in the similarity space and thus it is related to works on document representation. Alternative document representations have been proposed in the past and have been shown to perform well in many applications ( Radev et al., 2000; He et al., 2004; Leb anon 2006 ; Ranzato and Szummer , 2008, Wang and Domeniconi, 2008 ) . In ( Radev et al., 2000), although the centroid se n-tence/document vector was computed, it was not transform ed to a similarity space vector represe n-tation. Wang and Domeniconi (2008) proposed to use external knowledge to build semantic ke r-nels for documents in order to improve text cla s-sification. In our problem, the main difficulty is that testing negative documents cannot be well covered in training. It is not clear how the e n-riched document representation s could help solve our problem.

Our work is also related to learning from p os i-tive and unlabeled examples, also known as PU learning ( Denis , 1998 ; Yu et al . 2002 ; Li u et al. 2003 ; Lee and Liu, 2003; Elkan and Noto, 2008; Li et al. 2 010). In this learning model, there is a set of labeled positive training data and a set of unlabeled data, but there is no labeled negat ive training data. Clearly, their setting is different from ours too . There is also no guarantee that the unlabeled data has the same distribution as the future test data.

Our problem is also very different from d o-main adaption as we work in the same domain. Due to the use of document similarity, our met h-od has some resemblance to learning to rank (Li, 2011; Liu, 2011). However, CBS -L is very di f-ferent because we perform supervised classific a-tion. Our similarity is also center -based rather than pair -wise document similarity, which is also used in (Qian and Liu 2013) for spam detection. W e now f ormulate the proposed supervised learning in the CBS space , called CSB -L. The key difference between CBS learning and the classic document space (DS) learning is in the document representation, which applies to both training and te sting documents or posts . In the next subsection, we first give the intuitive idea and a simple example. The detailed algorithm follow s . I n Section 3.5 , we explain why CB S -L is better than DS -based learning when une x-pected negative data appear in the test set . 3.1 Basic Idea In the proposed CB S -L formulation, each doc u-ment d is still represented as a feature vector, but the vector no longer represents the document d itself based on n -grams . Instead, it represents a set o f similarity values between document d and the center of the pos itive documents. Specifically, the learning consists of the following steps: 1. Each document d (in the positive or negative 2. A center vector c is then computed for each 3. Each document d in the positive and negative 4. We now have a binary classification problem 3.2 CBS Based Learning We are given a binary text classification problem. Let D = {( d 1 , y 1 ), ( d 2 , y 2 ), ..., ( d n , y of training examples , where d i is a document and y i  X  {1, -1} is its class label . Traditional class i-fication directly uses D to build a binary classif i-er. However, i n the CBS space, we learn a class i-fier that returns 1 for documents that are  X  X lose enough X  to the center of the training positive documents and -1 for documents elsewhere. 
We now detail the proposed technique. As we mentioned above , i nstead of using one single ds -vector to represent a document d i  X  D, we use a set R d of p ds -vectors R d = {  X  ! ! ,  X  ! ! , ... ,  X  Each vector  X  ! ! denotes one document space re p-resentation of the document , e.g., unigram repr e-sentation . We then compute the center of positive training documents , which is represented as a set of  X  centroids C = { c 1 , c 2 , ..., c p } , each of which corresponds to one document space represent a-tion in R d . The way to compute each center c i similar to that in the Rocchio relevance feedback method in information retrieval ( Rocchio, 1971; Manning et al. 2008 ) , which uses the correspon d-ing ds -vector s of all training positive and neg a-tive documents . The detail will be given below . Based on R d for document d and the center C , we can transform a document d from its document space representations R d to one center -based si m-ilarity vector cbs -v by applying a similarity fun c-tion  X  X  X  X  on each element  X  ! ! of R d and its corr e-sponding center c i . We now detail document transformation.
 Training document transformation : The trai n-2. Not -in -training : In th is case, the t est negative 3. Combined: In this case, the test data contains Due to a large number of experiment results, we cannot report all the details. Table 2 summarize s the results. Notice that for ds -osvm , it does not make sense to have in -training and not -in -training results because it do es not use any trai n-ing negative data . Thus, there is only one set of results for  X  X ombined, X  which is duplicated i n the table for easy comparison. H owever, note that cbs -osvm uses negative data for training in order to compute the center for the positive class. observations (since there are many numbers, we only focus on F1 -scores). 1. The proposed CBS -L method performs mar k-2. ds -osvm performs poorly. cbs -osvm is much 3. SVM in the document space performed poorly 4. Finally, we can also see that with the number 
Table 3 : F1 -score for each positive topic or class
To give a flavor of the detailed results for each topic (product) , we give t he full results for one setting with 30 randomly selected topic s as the training negative data (Table 3 ) . The results in the table are F1 -scores of the combined case. T he ability to get relevant posts accurately about a topic from soci al media is a challenging pro b-lem . T his paper a ttempted to solve this problem by identifying and dealing with the technical i s-sue of covariate shift . The key idea of our tec h-nique is to tr ansform document representation from the traditional n -gram feature space to a similarity based space. Our experimental results show that the proposed method CBS -L outpe r-formed strong baselines by large m argins.
 This research was partially supported by the NSF grants IIS -1111092 and IIS -1407927, and a Google faculty award.
 Alter, O., Brown, P.O. and Bostein, D. 2000. Singular Value Decomposition for Genome -
Wide Expression Data Processing and Mode l-ing. Proc. Nat',l Academy of Scienc e, vol. 97, no. 18, pp. 10101 -10106, Aug.
 Blei, D. Ng, A. and Jordan, M., 2003. Latent d i-richlet allocation, The Journal of Machine Learning Research , 3, p.993 -1022, 3/1/2003 Buckley, C., Salton, G., Allan, J. 1994. The E f-Bickel, S., Bruckner, M., and Scheffer. 2009. T. Bickel S. and Scheffer T. 2007. Dirichlet -Cha , S. -H. 2007. Comprehensive Survey on Di s-Chang, C -C. and Lin, C -J. 2011. LIBSVM: a Colas, F. and Brazdil. P. 2006. Comparison of 
SVM and some older classification algorithms in text classification tasks. Artificial Intell i-gence in Theory and Practice . IFIP Intern a-tional Federation for Information Processing, pp. 169 -178.
 Denis , F., PAC learning from positive statistical queries . ALT , 1998.
 Radev , D . , Jing , H. and Budzikowska , M . 2000. 
Centroid -based summarization of multiple documents: Sentence extraction, utility -based evaluation, and user studies. In ANLP / NAACL Workshop on Summarization , Seatt le, April. Dudik , M., Schapire , R., and Phillips , S. 2005. Elkan, C. and Noto, K. 2008. Learning classifiers He , X. , Cai , D., Liu , H. and Ma , W. -Y. 2004. Heckman , J. 1979. Sample selection bias as a Huang , J., Smola , A. and Gretton , A., Borgwardt Joachims, T. 1998. Text categorization with Jindal, N. and Liu, B. 2008. Opinion Spam and Khan, S., and Madden, M. 2010. A survey of recent trends in one class classification. Artif i-cial Intelligence and Cognitive Science , vo l-ume 6206 of Lecture Notes in Computer Sc i-ence. 188  X  197.
 Khan, S. and Madden, M. 2014. One -Class Cla s-sification: Taxonomy of Study and Review of 
Techniques. The Knowledge Engineering R e-view , 1 -30.
 Lebanon , G . 2006. Seq uential document repr e-sentations and simplicial curves. UAI .
 Lee, W. S. and Liu, B. 2003. Learning with Pos i-Li , H. 2011. Learning to Rank for Information Retrieval and Natural Language Processing . Morgan &amp; Claypool publishers.
 Li, K., Huang, H., Tian, S. and Xu, W. 2003. 
Improving O ne -class SVM for anomaly dete c-tion. Proc. of the Second International confe r-ence on Machine Learning and Cybernetics , volume 5, pages 3077  X  3081.
 Li, X., Liu, B. and Ng. S. -K. 2010. Negative Liu , B, Dai, Y., Li, X., Lee, W -S. and Yu. P. Liu. T. 2011. Learning to Rank for Information Retrieval . Springer.
 Luo , J., Ding, L., Pan, Z., Ni, G. and Hu, G. 2007. Research on cost -sensitive learning in one -class anomaly detection algorithms. Aut o-nomic an d Trusted Computing , volume 4610 of Lecture Notes in Computer Science.
 Manevitz, L. and Yousef. M. 2001. One -class Manning, C. D., Prabhakar R . , and Hinrich, S. Qian, T. and Liu, B. 2013. Identifying Multiple Ranzato , M. and Szummer , M . 2008. Semi -Rocchio, J. 1971. Relevant feedback in info r-Sch X lkopf, B., Williamson, R., Smola, A., Ta y-Sch X lkopf, B., Platt, J., Shawe -Taylor, J., Smola, 
A. and Williamson, R. 1999. Estimating the support of a high -dimensional distribution. Technical R eport , Microsoft Research, MSR -TR -99 -87.
 Shimodaira , H. 2000. Improving predictive Sugiyama , M. and Muller , K. -R. 2005. Input -Sugiyama , M., Nakajima , S., Kashima , H., von Tax, D. and Duin, R. 1999a. Data domain d e-scription using support vectors. Proceedings ESAN99 , Brussels. 251 -256 Tax, D. and Duin, R. 1999b. Support vector d o-main description. Pattern Recognition Letters 20. 1191 -1199 Tax, D. and Duin, R. 2001. Uniform object ge n-eration for optimizing one -class classifiers. J . of Machine Learning Research , 2:155  X  173. Tian, J. and Gu, H. 2010. Anomaly detection combining one -class SVMs and particle swarm optimization algorithms. Nonlinear Dynamics , 61(1 -2): 303  X  310.
 Tsuboi , J., Kashima , H., Hido , S., Bickel , S., and Wang, P. and Domeniconi, C. 2008. Building Yang, Y. and Pedersen, J. O. 1997. A compar a-Yang, L., and Madden, M. 2007. One -class su p-Yu, H. , Han, J. and Chang , K . 2002. PEBL: Pos i-Zadrozny , B. 2004. Learning and evaluating 
