
Many real-world problems can be caste as problems of learning from different in-formation sources. One such example is sel f-maintenance of xerographic machines based on both sensory data of the faulty machines and on image samples of the hard copies. Another one is gene function disc overy based on microarray expression data and and phylogenetic profiles.
 studied in machine learning and in computer vision, where the problem is referred to as multimodal learning. 1 Generally, there are two types of multimodal learning: Feature-level integration and semantic integration (Wu et al. 1999). The feature in-tegration combines the information at the feature level and performs learning in the joint feature space. The corre lation structure between different sources can be discov-ered via learning. The semantic integration, on the other hand, first builds individual models based on separate information sources and then combines these models via some processes, say, mutual information maximization (Becker 1996).

In many applications, the ability to use both labelled and unlabelled data is very useful because labelling samples is us ually expensive and, in most cases, only a limited number of labelled samples and a lot of unlabelled samples are available.
Having data from different information sources could help us take advantage of both labelled and unlabelled data. In our recent work, we have provided a theoretical ex-planation as to why minimising the disagreement between two individual models could lead to the improvement of the classi fication accuracy of individual models.
In light of the observation, we proposed a co-updating method (as an improvement of the algorithm presented in one of our papers) for minimising the disagreement between the individual models taking both labelled and unlabelled data into consider-ation. To demonstrate the effectiveness and efficiency of our approach, we conducted in this paper three sets of experiments: (i) webpage classification from both content and hyperlinks, (ii) functional classification of genes using gene expression data and phylogenetic data and (iii) machine self-mai ntaining from both sensory and image data.

The co-updating approach can be thought of as a kind of semantic integration. We prefer semantic integration over feature-level integration for the following four rea-sons: First, although the structure in the joint feature space is often more informative than that available to each of the individua l sources, feature integration tends to gen-eralize poorly. The model complexity, computation intensity and training difficulty typically are other problems associated with the feature-integration approach (Wu et al. 1999). Second, learning in the joint space is not able to marginalize over the missing sources and requires future patterns for classification containing all feature dimensions (De Sa and Ballard 1998). While we intend to learn from a joint feature space, we still need to be able to analyse a nd act on the information from a single source. For example, we sometimes would like to predict the copy/printer failures solely based on the image information or predict the functional classifications solely based on the DNA microarray information. Feature integration is thus not suitable.
Third, we would like to utilize both labe lled and unlabelled data because there are scenarios in which some gene category information is available while the other is unavailable. Finally, the semantic integration appears to have biological and physi-cal plausibility. It is well known that the cerebral cortex competently classifies uni-modal stimuli while keeping the different modalities largely separate. Also, McGurk showed that, although the information from different sensory modalities is combined in determining human X  X  perception, the combination is often not subject to conscious control (McGurk and MacDonald 1976).

A preliminary version of this method was published in Bio-informatics track in 2003 ACM Symposium on Applied Computing (SAC2003) (Li et al. 2003), where the focus is gene functional discovery fro m heterogeneous data types. We provide detailed theoretical analysis and present extensive experimental results with three case studies in this paper. The paper is organized as follows. Section 2 shows the theoretical reason as to why minimisatio n of disagreement is useful and Sect. 3 presents the co-updating algorithm. Section 4 reviews related work on using labelled and unlabelled data and discusses the c onnections and differences between them.
Section 5 presents the results of the expe riments. Finally, Sect. 6 concludes and discusses future research directions.

In this section, we show that, theoretically, minimising the disagreement between two individual models could lead to the improvement of the classification accuracy of individual models. In this paper, we focus on binary classification problems and we use 0 , 1 to label the two classes respectively space X = ( X 1 , X 2 ) ,where X 1 and X 2 are from different observations. Let D be the distribution over X .If f is the target function over D , then for any example x = ( x target functions over X 1 and X 2 , respectively. We also use Y to denote the target label.

Definition 1. We s a y t h a t f is a nontrivial classifier if Pr  X  u | Y = u ) ,where u  X  X  0 , 1 } and  X  u is the complement of u .

Remark 1. The nontrivial conditions can be restated as Pr
Pr ( f = Y )  X  Pr ( f = u ), u  X  X  0 , 1 } .
 independent given the labels, i.e.

The independence assumption is rather strong but it is used by many successful ap-plications. Suppose we build hypotheses f 1 on X 1 and f x 2 are conditional independent given the labels, then f 1 and f independent. The cond itional independence of f 1 and f lows: where u ,v, y  X  X  0 , 1 } . The following theorem holds.

Theorem 1. Under the conditional independence assumption, the disagreement up-per bounds the misclassification error for the nontrivial classifier.
 Proof. The misclassification error of f 1 is To s h ow t h a t P r ( f 1 = Y )  X  Pr ( f 1 = f 2 ) , it is enough to verify that Note that Hence, it reduces to check This amounts to requiring that Observe that Similarly,
In other words, if Pr ( f 1 = Y )  X  Pr ( f 1 = u ), u  X  X  0 bounds the misclassification error:
Remark 2. When the conditional independence condition (e.g., Eq. (1)) doesn X  X  hold, to guarantee that disagreement upper bounds the misclassification error, we need In other words, if then the disagreement still upper bounds the m isclassification error without the con-ditional independence condition.
 bounds the misclassification error. Thus, minimising the disagreement would decrease the upper bound on the misclassification error and could bootstrap the learning al-gorithm.
Theorem 1 can also be derived from Bayes perspective. Let x observation vector, the Bayes decision rule for the first modal is which indicates that, if the posteriori probability of class 1 given x the probability of class 0, x 1 is assigned to class 1 and vice versa. Using Bayes theorem and eliminating the common term Pr ( x 1 ) ,weget
The Bayes error can be computed as 3 where L 1 1 is the region where and L 1 2 is the region where x  X  L 1
Under the conditional independence assumption, the disagreement between two components can be computed as where L 2 1 is the region where and L 2 2 is the region where
Similarly, if an observation x 2  X  L 2 1 , it will be classified as in class 1 and if x it will be classified as in class 0.

Observe that and The above formula can be reduced to The formula in Eqs. (5) and (6) are essentially the same as those in Eqs. (2) and (3). Hence, this quantity of disagreement is an upper bound on the Bayes error.
Remark 3. Figure 1 gives an explicit example to illustrate the mathematical deriva-tions above. The example is a one-dimensional classification problem with two dif-ferent modalities. In this example, L 1 1 = (  X  X  X  , b 1
L follows: Algorithm co-updating
Based on Theorem 1, we have developed a co-updating approach to learn from both labelled and unlabelled data that aims at minimising the disagreement on unlabelled data. The co-updating approach is an iterative expectation-maximization (EM)-type procedure. Its basic idea is as follows: T he labelled samples are first used to get weak classifiers f 0 1 on X 1 and f 0 2 on X 2 . Then for each iteration, the expectation step uses current classifiers to predict the labels of unlabelled data, the maximiza-tion step rebuilds the classifiers using the labelled samples and a random collection of unlabelled samples on which the classifiers agree (i.e. they have the same pre-dictions). This process is then repeated until some termination criterion is met. The detailed description of the algorithm is given in Fig. 2.
 unlabelled samples on which the two component classifiers agree and then use them, along with the labelled samples, to train/upda te the classifiers. Co-updating iteratively updates classifier models by using current models to infer (a probability distribution on) labels for unlabelled data and then adjusting the models to fit the (distribution on) filled-in labels. When the model defines a joint probability distribution over ob-servable data and unobservable labels, each iteration of the EM algorithm can be shown to increase the probability of the observable data given the model parame-ters (Dasgupta et al. 2001). Intuitively, the added agreed unlabelled samples help the classifiers to achieve more agreement and hence minimise disagreement. If the initial classifiers are nontrivial and the ag reement of the predictions from the two modal is conditional independent, then, on av erage, the co-updating approach, trying to minimise the disagreement, should progress toward higher performance.
 criterion.  X  defines the fraction of agreed unlabe lled samples we want to include for updating the model at each iteration. 4 The co-updating approach is a variant of the
EM algorithm, which is a general method fo r parameter estimates in the presence of missing data. In the generalized formulation (Neal and Hinton 1998), a current parameter estimate and a distribution Q over the missing data is maintained, the
E step updates the distribution Q and the M-step modifies the estimate. In the co-updating approach, we use current classifiers to predict the unlabelled data, which amounts to computing the distribution Q over the missing data. In the M-step, we use the selected unlabelled samples along with labelled samples to retrain the classifiers, which is equivalent to modifying the parameter estimates.
Figure 3 illustrates the co-updating procedure through an example. The simple ex-ample helps us understand the procedures of the co-updating approach. One thing to note is that, in the example, all the agreed unlabelled samples along with labelled samples are used to retrain the classifiers. In our algorithm, to avoid the phenomenon that the model may be overwhelmed by the unl abelled samples, especially when the number of labelled samples is small, a parameter  X  of agreed unlabelled samples we want to include for updating the model at each iteration.
There has been much recent interest in t he problem of learning with both labelled and unlabelled data. From a theoretical pe rspective, it has been shown that labelled data are exponentially more useful than unlabelled data in risk reduction under cer-tain assumptions (Castelli and Cover 1996). Discriminative and generative learning architectures have been shown to take adv antage of unlabelled data in various prob-abilistic frameworks (Zhang and Oles 2000). Gen erally, the approaches for handling both labelled and unlabelled data can be roughly divided into four categories: proba-bilistic, cotraining, transductive interference and others. Probabilistic approaches in-clude using expectation-maximization (Dempster et al. 1977; Ghahramani and Jor-dan 1994) to maximize the estimates of posteriori parameters and using generative models to perform classification (Nigam et al. 2000). Unfortunately, when the data do not match the generative assumptions, the information from unlabelled data may overwhelm that of labelled data and the algorithm goes astray. The ideas of cotrain-ing first appeared on unsupervised learning. Becker (1996) proposed the approach of learning coherence structure in data by maximizing the mutual information be-tween the outputs of two groups of units, whi ch receive inputs physically separated in modality. De Sa and Ballard (1998) described a unsupervised network algorithm learning from co-occurring patterns of lip motion and sound signals from a human speaker to minimise the fraction of training samples on which the two patterns dis-agree. The cotraining parad igms combining both labelle d and unlabelled data were first introduced by Blum and Mitchell (1998), where the features in the problem do-main are naturally divided into two disjoint sets (or in other words, is two-modal) to exploit the compatibility between different views of the samples. The compatibility of the instance distribution means that the ta rget functions over each feature set predict the same label. Blum and Mitchell (1998) showed that, under certain assumptions, PAC-style guarantee on learning with labelled and unlabelled data holds. Roth and
Zelenko (2000) developed a theory for learning scenarios where multiple learners coexist but there are mutual compatibility constraints on their outcomes. Nigam and
Ghani (2000) showed that, when an independent and redundant feature split exists, cotraining algorithms outperform other algorithms using unlabelled data. A co-EM algorithm, which runs EM in each view and int erchanges the probabilistic labels be-fore new EM iterations, was also proposed in the paper. Abney (2002) refined the cotraining analysis and evaluated a greed y agreement algorithm by constructing rules on unlabelled samples. Goldman and Zhou (2000) presented a new cotraining strat-egy that does not assume there are two redundant views both of which are sufficient for perfect classification. When we have tw o different information sources for self-maintaining and gene functional classification, we generally fall into the cotraining setting.
Transductive inference, first introduced by Vapnik (1998), aims to estimate the test labels directly from the labelled and unlabelled data without first building the latent function models. There are some other approaches that could handle both la-belled and unlabelled data, such as using graph mincuts (Blum and Chawla 2001), ensemble methods (Bennett et al. 2002), boosting (Buc et al. 2002) and a com-bination of clustering and support vector machines (Fung and Mangasarian 2001).
A detailed survey on labelled and unlabelled data is given in Seeger (2000). In brief, the related work with co-updating can be summarized in Fig. 4.
In this section, we discuss the connections and differences between them and our co-updating approach as presented in Fig. 4. Cotesting (Muslea et al. 2000) is a family of active-learning algorithms that searches for the most informative unlabelled sam-ples and asks the user to label them.
 The major difference between co-updating and cotraining lies in two aspects.
First, the cotraining procedure does not directly seek to find classifiers that agree on the unlabelled data and the proof given in Blum and Mitchell (1998) did not justify the procedure of the algorithm. Co-updating aims to minimise disagreement via iterative expectation-maximization (EM)-type procedures and we have presented theoretical analysis on mini mising the disagreement, which would decrease the mis-classification error. Second, co-updating does not commit to a label for the unla-belled samples; instead, it uses probabilistic labels that may change from iteration to iteration. By contrast, cotraining incrementally incorporates the unlabelled data into learning: the most confi dent unlabelled samples a ssigned to each class are cho-sen at each iteration and those labels beco me permanent. Hence, during the early iterations when the models have less prediction power, cotraining X  X  commitment to high-confidence prediction may add a large number of mislabelled samples into train-ing. There are also some connections be tween them because both methods are trying to use the knowledge in both modalities to utilize unlabelled samples. In addition, if the agreement between two views and t he accuracy of the individual classifier is positively correlated, the agreed unlabelled samples usually have high confidence to be correctly labelled.
 in that it directly seeks the classifiers that agree on unlabelled samples. Co-boost-ing (Collins and Singer 1999) explicitly expre sses the minimising disagreement in the objective function and adaptively updates the distribution of the samples to build the ensemble classifier. Co-updating differs from co-boosting in that, at each iteration, only the distribution on the unlabelled samples is updated and, in particular, only the agreed unlabelled samples are consid ered because the algorithm only chooses a portion of the agreed unlabelled samples for training. In some sense, the ideas of coboosting and co-updating are complementary. The cotesting (Muslea et al. 2000) is an active learning strategy by selecting the disagreed samples for human labelling because these disagr eed samples are most informative in the sense that at least one of them is correct. The ideas of co-updating and cotesting are orthogonal and they can be easily combined: co-updating uses the agreed unlabelled samples to train the classifier and cotesting selects the disagr eed unlabelled samples for human labelling.
The combination is expected to fu rther improve the performance.
We performed three sets of experiments to investigate the behaviour of co-updating.
We used the same dataset of web pages as in Blum and Mitchell (1998). The dataset consists of 1,051 web pages collected from C omputer Science department web sites at four universities: Cornell, University of Washington, University of Wisconsin and
University of Texas. The task is to identify the web pages that are course home-pages (about 22% pages fall i nto the category). The two sources for each web page are the words that occur on the web page and the words occurring in the anchor text of hyperlinks pointing to the page. Classifiers that were trained separately for the individual source are referred as the page-based and hyperlink-based classifiers, respectively.
 could successfully use the unlabelled data to outperform standard supervised training of naive Bayes classifiers. The experiment setups are the same as that in Blum and
Mitchell (1998). In each experiment, 263 (25%) of the 1,051 web pages were ran-domly selected as a test set. The remaining data were used to generate a labelled data set containing three positive and nine negative examples drawn at random. Five trials of the experiments were conducted using diff erent training/test splits. The results of supervised training were obtained using only the 12 labelled training samples. The combined classifiers were constructed, with the naive Bayes assumption of condi-tional independence, by multiplying the probability outputs of the page-based and hyperlink-based classifiers. The results are summarized in Table 1.
 supervised learning; the second row shows error rates for the classifiers formed by co-updating. The third row presents the error rates of cotraining cited from Blum and Mitchell (1998). 6 Note that, for this data, the default hypothesis that always predicts negative achieves an error rate of 22%. Figure 5(a) gives a plot of error versus number of iterations and Fig. 5(b) gives a plot of error versus the differ-ent choice of  X  . For all three types of classifiers (hyperlink based, page based, and combined), the classifier obtained by co-updating outperforms the classifier formed by supervised learning. On page-based and combined classifiers, the co-updating ap-proach achieves better performance than cotraining. The hyperlink-based classifier is helped less by both cotraining and co-updating. This may be due to the fact that the hyperlinks contain fewer words and are less capable of expressing an accurate approximation to the target function. These results do indicate that the co-updating can provide a useful way of taking advantage of unlabelled data. From Fig. 5(a), we observe that the error rate of page-based classifier drops sharply as the number of iterations increases from 5 to 25 and the va riations become small thereafter. As shown in Fig. 5(b), we observe that, when the selection probability the performance of classifiers may degra de, as more unlabelled data may dominate the training. Currently, we choose  X  based on experience. A good future research direction is to explore more the effects of  X  .
Discovery of gene functions is a fundament al problem in genetics. The microarray technology enables monitoring of gene expression of tens of thousands of genes in a single experiment and thereby makes i t possible to infer functions of genes by studying correlations of expression among genes. In Pavlidis et al. (2001), gene function classifiers are built by means of feature-level integration of gene expression data and phylogenetic profiles (the exist ence of homologs of each gene in 24 other genomes). We used the same data set as Pavlidis et al. (2001) and applied the co-updating method.
The first set of data is gene expression of 2,465 yeast genes on 79 samples. The second set of data is the result of BLAST homolog search of these genes on 24 other genomes. Gene classification was based on the Munich Information Center for
Protein Sequences Comprehensive Yeast Genome Database (CYGD) contains several hundred functional classe s, the Definitions of which come from bio-chemical and genetic studies of gene function. Our experiments used the five most learnable classes of Pavlidis et al. (2001). The five classes, which will be referred to by I X  X , are given in Table 2.
 tems that try to classify data points in the input space by mapping them into a higher dimension feature space (using kernel function) and then finding the separating hy-perplane in the feature space with the largest margin. More details on SVMs can be found in Vapnik (1998). In our experiments, as in Brown et al. (2000) and Pavlidis et al. (2001), we used the kernel where X  X  Y is the inner product and  X  is the L2 norm. The co-updating parameters were set to their default values.
Experiments were then conducted using co-updating. For each class, about 25% genes were chosen as the test set, 10% gene s were selected as labelled samples and all the remaining genes were used as unlabelled samples. The detailed distributions of the samples for each class are shown i n Table 3. The experimental results are presented in Table 4. E and P show, respect ively, the accuracy of expression-based classifiers and of phylogeny-based classifiers. Column A shows the results when the classifiers are individually trained using the labelled samples only. Column B shows co-updating use and Column C shows when the unlabelled samples are included in the training set with their correct labels. The quadruples are the number of true pos-itives, the number of true negatives, the number of false positives and the number of false negatives. Such quadruples are u seful in measuring accu racy when the class distribution is highly skewed (Weiss and Provost 2001). The results seem to indicate that the co-updating approach utilizes the unl abelled samples to improve the learning performance on most counts. Co-updating, however, does not help when the class data are too sparse (class IV and the expression-based classifier for classes I and the labelled samples, have no true positives on the test sets due to the sparse nature of the data. In all the other cases, the co-updating approach improves the learning performance of both classifiers.
Self-maintaining, which includes machine self-diagnosis, machine self-repair and cus-tomer self-help, is attracting more and more attention in many industrial systems. It brings intelligence to the industrial system t o enable its robustness, high availability and cost effectiveness.
 ure prediction problems could be abstracted as the following classification prob-lem of predicting whether there are any f ailures based on current system status.
Usually, when a failure occurs in an industrial system, there are several different kinds of information available for analysis. For example, when an error occurs in a copier/printer, the relevant machine dat a of the faulty machine, such as sensory readings and job control data, are availabl e for analysis. In addition, image samples can also be acquired based on the hard-copy samples obtained using the faulty ma-chine. Either information could be sufficient to predict certain kinds of failures. We have successfully used the m achine data to predict cleaner failure and the image-defect analysis for ground failure of a xerographic engine. However, for some fail-ures, methods are required to combine both information to improve the prediction accuracy. Moreover, collecting samples for m achine failure predic tion is usually ex-pensive and, in most cases, we might have only limited number of labelled sam-ples and a lot of unlabelled samples. In this section, we present the case study of using semisupervised learni ng for machine self-maintaini ng from different informa-tion sources.
We used a dataset of cleaner failure data containing both machine and image in-formation for a xerographic machine. The image data for each sample are a 32-dimension vector and machine data are a 46-dimension vector. One hundred sam-ples were selected as a test set. We chose decision tree C4.5 (Quinlan 1993) as base classifiers. Decision tree produces interpre table results and has been widely used in many industrial diagnostic applications. The decision tree is a classification model in a tree structure and it is built up based on training samples. C4.5 uses the infor-mation gain of the attribute, which is the expected reduction in entropy caused by partitioning samples according to the attr ibute, as the measure to recursively select the splitting attribute and build the tree. A postpruning process is then carried out to prevent overfitting. A more detailed description of the algorithm can be found in Mitchell (1997). Experiments were then conducted to determine whether this co-updating algorithm could successfully use the unlabelled data to outperform standard supervised algorithms. Classifiers that were trained separately for different sources are referred as image-based classifiers an d machine-based classifier. Figures 6(a) and 6(b) present, respectively, the performan ce comparisons of supe rvised learning and co-updating on the image-based classifier and machine-based classifiers with different sizes of labelled samples. The results of supervised learning were obtained by using the classifiers built from the labelled data. The co-updating approach outperforms the supervised learning on the machine-based classifier. However, as shown in Fig. 6(a), co-updating degrades the performance of the image-based classifier in some cases.
This suggests that unlabelled data sometimes may hurt. The fact that using unla-beneficial has been previously reported (Zhang and Oles 2000; Nigam 2001; Coz-man and Cohen 2002). The reason may be that the consistency constraints in the model is violated.
In this paper, we propose a co-updating approach for semisupervised learning from multiple information sources. The co-upda ting approach tries to minimise the dis-agreement between the individual models and makes use of both labelled and un-labelled data. We have conducted three sets of experiments on different datasets investigating the behaviour of the co-updating approach.
 tion probability  X  . Second, the co-updating approach can be applied to multimodal learning tasks, such as word learning and object recognition, becau se spatiotemporal and cross-modal coherence is a powerful constraint in sensory data of the physical world. We could apply the co-updating appr oach to utilize the approximately co-incident information of different modalities in these tasks. Third, another obvious research direction is to extend the co-updating approach for multiple data sources and to handle multiclass classification. Finally, many feature selection techniques could be incorporated into the co-updating approach.

