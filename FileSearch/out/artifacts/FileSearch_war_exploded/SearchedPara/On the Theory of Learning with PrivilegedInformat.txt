 In the classical supervised machine learning paradigm the learner is given a labeled training set of examples and her goal is to find a decision function with the small generalization error on the unknown test examples. If the learning problem is easy (e.g. if learner X  X  space of decision functions contains a one with zero generalization error) then, when the training size increases, the decision function found by the learner converges quickly to the optimal one. However if the learning problem is hard and the learner X  X  space of decision functions is large then the convergence (or learning) rate is slow. The example of such hard learning problem is XOR when the space of decision functions is 2-dimensional hyperplanes.
 The obvious question is  X  Can we accelerate the learning rate if the learner is given an additional information about the learning problem?  X . During the last years several new paradigms of learning with additional information were proposed that, under some conditions, provably accelerate the learning rate. For example, in semi-supervised learning such additional information is unlabeled training examples.
 In this paper we consider a recently proposed Learning Using Privileged Information (LUPI) paradigm [8, 9, 10], that uses additional information of different kind. Let X be a decision space. In LUPI paradigm, in addition to the standard training data, ( x, y )  X  X  X  Y , a teacher supplies the learner with a privileged information x  X  in the correcting space X  X  . The privileged information is only available for the training examples and is never available for the test examples. The LUPI with the small generalization error for the unknown test examples x  X  X .
 The above question about accelerating the learning rate, reformulated in terms of the LUPI paradigm, is  X  What kind of additional information should the teacher provide to the learner in order to accel-erate her learning rate?  X . Paraphrased, this question is essentially  X  Who is a good teacher?  X . In this paper we outline the conditions for the additional information provided by the teacher that allow for fast learning rate even in the hard problems. LUPI paradigm emerges in a number of applications, for example time series prediction, protein classification and human computation. The experiments [9] in these domains demonstrated a clear advantage of LUPI paradigm over the supervised learning.
 LUPI paradigm can be implemented by SVM+ algorithm [8], which in turn is based on the well-known SVM algorithm [2]. We now present the version of SVM+ for classification, the version for regression can be found in [9]. Let h ( x ) = sign( w  X  x + b ) be a decision function and  X  ( x  X  i ) = w  X   X  x  X  i + d be a correcting function . The optimization problem of SVM+ is The objective function of SVM+ contains two hyperparameters, C &gt; 0 and  X  &gt; 0 . The term taining  X  .
 on the example x  X  . The optimization problem (1) can be rewritten as The following optimization problem is a simplified and a generalized version of (2): where ` X and ` X  X  are arbitrary bounded loss functions, H is a space of decision functions and  X  is relaxation of (3): We refer to the learning algorithm defined by the optimization problem (6) as empirical risk mini-mization with privileged information , or abbreviated Privileged ERM .
 assumption reflects the human learning process, where the teacher tells the learner what are the most important examples (the ones with the small loss in the correcting space) that the learner should take into account in order to find a good decision rule.
 The regular empirical risk minimization (ERM) finds a hypothesis b h  X  X  that minimizes the training error privileged ERM minimizes the training error of h indirectly, via the minimization of the training error of the correcting function  X  and the relaxation of the constraint (4).
 Let h  X  be the best possible decision function (in terms of generalization error) in the hypothesis space inequalities: We denote the learning algorithm defined by (7) as OracleERM . A straightforward generalization of the proof of Proposition 1 of [9] shows that the generalization error of the hypothesis b h found by OracleERM converges to the one of h  X  with the rate of 1 /n . This rate is much faster than the worst-case convergence rate 1 / In this paper we consider more realistic setting, when the above oracle is not available. Our subse-quent derivations rely heavily on the following definition: Definition 1.1 A decision function h is uniformly better than the correcting function  X  if for any Given a space H of decision functions and a space  X  of correcting functions we define Note that  X   X   X  and  X  does not contain correcting functions that are too good for H . Our results are based on the following two assumptions: Assumption 1.2  X  6 =  X  .
 This assumption is not restrictive, since it only means that the optimization problem (3) of Privileged ERM has a feasible solution when the training size goes to infinity.
 Assumption 1.3 There exists a correcting function  X   X   X  , such that for any ( x, x  X  , y ) that has non-zero probability, ` X ( h  X  ( x i ) , y i ) = ` X  X  (  X  ( x  X  i ) , y i ) .
 Put it another way, we assume the existence of correcting function in  X  that mimics the losses of h  X  . Let r be a learning rate of the Privileged ERM when it is ran over the joint X  X  X  X  space with the space of decision and correcting functions H X   X  . We develop an upper bound for the risk of the decision function found by Privileged ERM. Under the above assumptions this bound converges to h  X  with the same rate r . This implies that if the correcting space is good, so that the Privileged ERM in the joint X  X  X  X  space has a fast learning rate (e.g 1 /n ), then the Privileged ERM will have the same fast learning rate (e.g. the same 1 /n ) in the decision space. That is true even if the decision space is hard and the regular ERM in the decision space has a slow learning rate (e.g. 1 / illustrate this result with the artificial learning problem, where the regular ERM in the decision space can not learn with the rate faster than 1 / learns in the decision space with the rate of 1 /n .
 The paper has the following structure. In Section 2 we give additional definitions. In Section 3 we review the existing risk bounds that are used to derive our results. Section 4 contains the proof of the risk bound for Privileged ERM. In Section 5 we show an example when Privileged ERM is provably better than the regular ERM. We conclude and give the directions for future research in Section 6. Due to the space constraints, most of the proofs appear in the supplementary material. Previous work The first attempt of theoretical analysis of LUPI was done by Vapnik and Vashist [9]. In addition to the analysis of learning with oracle (mentioned above), they considered the algorithm, which is close, but different from Privileged ERM. They developed a risk bound (Proposition 2 in [9]) for the decision function found by their algorithm. This bound also applies to Privileged ERM. The the correcting space. By contrast, our bound holds for any bounded loss functions and allows the loss functions ` X and ` X  X  to be different. The bound of [9] depends on generalization error of the correcting function b  X  found by Privileged ERM. Vapnik and Vashist [9] concluded that if we could bound the convergence rate of b  X  then this bound will imply the bound on the convergence rate of the decision function found by their algorithm. The triple ( x, x  X  , y ) is sampled from the distribution D , which is unknown to the learner. We denote distribution D X is given by the nature and the distribution D X  X  is constructed by the teacher. The spaces H and  X  of decision and correcting functions are chosen by learner. ization errors of the decision function h and the correcting function  X  respectively. We assume that the loss functions ` X and ` X  X  have range [0 , 1] . This assumption can be satisfied by any bounded loss function by simply dividing it by its maximal value. We denote by h  X  = arg min h  X  X  R ( h ) and  X   X  = arg min  X   X   X  R (  X  ) the decision and the correction function with the minimal gener-R 01 = arg min h  X  X  R 01 ( h ) the decision function in H with the minimal generalization 0 / 1 error. Let R 0 n ( h,  X  ) = 1 n be respectively empirical and generalization errors of the hypothesis ( h,  X  ) w.r.t. the loss function different from h 0 , and also  X  0 can be different from  X   X  .
 Let By Assumption 1.2, ( H ,  X ) 6 =  X  . We will use additional technical assumption: Assumption 2.1 There exists a constant A &gt; 0 such that inf This assumption is satisfied, for example, in the classification setting when ` X and ` X  X  are tion D is bounded away from zero for all points with nonzero probability. In this case A  X  inf { p ( x, x  X  , y ) | ( x, x  X  , y ) such that p ( x, x  X  , y ) 6 = 0 } .
 The following lemma (proved in Appendix A in the full version of the paper) shows that for suffi-ciently large C the optimization problems (3) and (6) are asymptotically (when n  X  X  X  ) equivalent: Lemma 2.2 Suppose that Assumptions 1.2, 1.3 and 2.1 hold true. Then there exists a finite C 1  X  R such that for any C  X  C 1 , ( h 0 ,  X  0 )  X  ( H ,  X ) . Moreover, h 0 = h  X  and  X  0 =  X  . equivalent. Later on we will show how we choose the value of C that optimizes the forthcoming risk bound.
 The risk bounds presented in this paper are based on VC-dimension of various function classes. While the definition of VC-dimension for binary functions is well-known in the learning community, the one for the real-valued functions is less known and we review it here. Let F be a set of real-valued functions f : S  X  R and T ( F ) = { ( x, t )  X  X   X  R | X  f  X  X  s . t . 0  X | f ( x ) | X  t } . We say VC-dimension of F is defined as a VC-dimension of the set T ( F ) , namely the maximal size of the set T  X  T ( F ) that is shattered by F . We derive our risk bounds from generic excess risk bounds developed by Massart and Nedelec [6] and generalized by Gine and Koltchinskii [4] and Koltchinkii [5]. In this paper we use the version of the bounds given in [4] and [5].
 Let F be a space of hypotheses f : S  X  S 0 , ` : S 0  X  { X  1 , +1 }  X  R be a real-valued loss function such that 0  X  ` ( f ( x ) , y )  X  1 for any f  X  F and any ( x, y ) . Let f  X  = terms of the variance) between hypothesis f and the best hypothesis f  X  in F . The vertical axis is the minimal error of hypotheses in F with the fixed distance from f  X  . Note that the error function displayed in graphs can be non-continuous. The large value of D in the hypothesis space in graph (b) is caused by hypothesis A , which is significantly different from f  X  but has nearly-optimal error. arg min f  X  X  E ( x,y ) { ` ( f ( x ) , y ) } , b f n = arg min f  X  X  such that for any f  X  X  , This condition is a generalization of Tsybakov X  X  low-noise condition [7] to arbitrary loss functions and arbitrary hypothesis spaces.
 E as f  X  then the variance in the left hand side of (9), as well as the value of D , will be small. But if f differs significantly from f  X  then the variance in the left hand side of (9), as well as the value of D , will be large. Thus, if we take the variance in the left hand side of (9) as a measure of distance between f and f  X  then the hypothesis spaces with large and small D can be visualized as shown in Figure 1.
 Let V be a VC-dimension of F . The following theorem is a straightforward generalization of The-orem 5.8 in [5].
 probability of at least 1  X   X  Let B = ( V log n + log(1 / X  )) /n . If the condition of Theorem 3.1 does not hold, namely if n  X  V  X  D 2 then we can use the following fallback risk bound: 1  X   X  , that E ( x,y ) { ` ( f  X  ( x ) , y ) } &lt; B .
 For n  X  T the bound (11) has a convergence rate of 1 /n , and for n &gt; T the bound (11) has a convergence rate of 1 / of 1 /n vs. the slow one of 1 / from n &gt; n ( D ) = V  X  D 2 we always have the convergence rate of 1 /n . Thus, the smaller value of D , the smaller will be the threshold n ( D ) for obtaining the fast convergence rate of 1 /n . For any C  X  1 , any ( x, x  X  , y ) , any h  X  X  and  X   X   X  , and any loss functions ` X and ` X  X  , Hence, using (5) we obtain that h  X  X  be a constant such that for all ( h,  X  )  X  X  X   X  , to hypotheses from H X   X  and V L ( H ,  X ) be a VC-dimension of L ( H ,  X ) . Similarly, let L ( H ) = { ` correspond to the hypotheses in H and  X  , and V L ( H ) and V L ( X ) be VC dimensions of L ( H ) and L ( X ) respectively. Note that if ` X = ` 01 then V L ( H ) is also a VC-dimension of H (the same holds also for V L ( X ) ).
 Proof See Appendix C in the full version of the paper.
 probability at least 1  X   X  Using (12) we obtain that It follows from Assumption 1.3 and Lemma 2.2 that H ,  X  then for any  X  &gt; 0 , with probability at least 1  X   X  , We bound V H ,  X  by Lemma 4.1 and obtain our final risk bound, that is summarized in the following theorem: Theorem 4.2 Suppose that Assumptions 1.2, 1.3 and 2.1 hold. Let D H ,  X  be as defined in (14), C n &gt; V L ( H ,  X )  X  D 2 H ,  X  . Then for any  X  &gt; 0 with probability of at least 1  X   X  , where K &gt; 0 is a constant. In this case the upper bound on R ( b h ) converges to R (  X  0 ) with the rate of 1 /n . ` X  X  (  X  0 ( x  X  ) , y ) and D  X   X  0 be a constant such that for any  X   X   X  , Similarly, let D 0 H ,  X   X  0 be a constant such that for all ( h,  X  )  X  ( H X   X ) \ ( H ,  X ) , Lemma 4.3 D H ,  X   X  max Proof See Appendix B in the full version of the paper.
 By Lemma 4.3, C  X  D H ,  X   X  max( D  X  , C  X  D 0 H ,  X  ) . Since the loss function ` 2 depends on C , the constant D 0 H ,  X  depends on C too. Thus, ingoring the left-hand logarithmic term in (17), the optimal minimum indeed exists. By the definition of the loss function ` 2 , Consequently lim C  X  X  X  C  X  D 0 H ,  X  =  X  . Since the function g ( C ) = C  X  D 0 H ,  X  is continuous and finite in C = C 1 , there exists a point C = C  X   X  [ C 1 ,  X  ) that minimizes it. We show an example that demonstrates the difference between the emprical risk minimization in X space and empirical risk minimization with privileged information in the joint X  X  X  X  space. conditions of Theorems 11 and 4.2) the learning rate of the regular ERM in X space is 1 / the learning rate of the privileged ERM in the joint X  X  X  X  space is 1 /n .
 D distributions in D X have non-zero support in four points, denoted by X 1 , X 2 , X 3 and X 4 . We assume that these points lie on a 1-dimensional line, as shown in Figure 2(a). Figure 2(a) also shows the probability mass of each point in the distribution D X (  X  ) . The hypothesis space H consists of generalization error is 1 / 4  X  2  X  . The hypothesis space H contains also a hypothesis h 0 3 , which is D X (  X  ) and H the constant D H (defined in equation (13)) is Note that the inequality in (20) is very tight since  X  can be arbitrary small. The VC-dimension V H H , the condition should be satisfied. But since  X  can be very small, the condition (21) is not satisfied for a large range obtain that R 01 ( b h ) converges to R 01 ( h  X  ) with the rate of at least 1 / The following lower bound shows that R 01 ( b h ) converges to R 01 ( h  X  ) with the rate of at most 1 / bility at least  X  n , exactly 1 / Suppose that the teacher constructed the distribution D X  X  (  X  ) of examples in X  X  space in the fol-lie on a 1-dimensional line, as shown in Figure 2(b). Figure 2(b) shows the probability mass of each point in X  X  space. We assume that the joint distribution ( X, X  X  ) has non-zero support only generalization error is 0 . However there is no h  X  H that is uniformly better than  X  0 2 . The best hy-pothesis in  X  , among those that have uniformly better hypothesis in H , is  X  0 1 and its generalization constant D  X  (defined in equation (18)) is Note that the inequality in (22) is very tight since  X  can be arbitrary small. Moreover, it can be and D  X  /C = 1 . 06 . It is easy to see that our example satisfies Assumptions 1.2 and 1.3 (the last A = 1 / 4  X  2  X  and C 1 = 1 . 1 &lt; C  X  satisfies Lemma 2.2. The VC-dimension of  X  is 2 . Hence by the rate of at least 1 /n . Since our bounds on D  X  and D 0 H ,  X  are independent of  X  , the convergence rate of 1 /n holds for any distribution in D X .
 1 /n , while the upper bound (11) converges to R 01 ( h  X  ) with the rate of 1 / caused the value of D H to be large and thus prevented us from 1 /n convergence rate for a large range of n  X  X . We constructed D X  X  (  X  ) and  X  in such a way that  X  does not have a hypothesis  X  that has exactly the same dichotomy as the bad hypothesis h 0 3 . With such construction any  X   X   X  , such For example, the best hypothesis in  X  for which h 0 3 is uniformly better, is  X  0 and its generalization error is 1 / 2 . We formulated the algorithm of empirical risk minimization with privileged information and derived will allow fast learning in the decision space, even if the original learning problem in the decision space is very hard. We showed an example where the privileged information provably significantly improves the learning rate.
 In this paper we showed that the good correcting space can improve the learning rate from 1 / to 1 /n . But, having the good correcting space, can we achieve a learning rate faster than 1 /n ? Another intersting problem is to analyze Privileged ERM when the learner does not completely trust important direction is to develop risk bounds for SVM+ (which is a regularized version of Privileged ERM) and show when it is provably better than SVM. [1] S. Boucheron, O. Bousquet, and G. Lugosi. Theory of classification: a survey of some recent [2] C. Cortes and V. Vapnik. Support-vector networks. Machine Learning , 20(3):273 X 297, 1995. [3] L. Devroye and G. Lugosi. Lower bounds in pattern recognition and learning. Pattern Recog-[4] E. Gine and V. Koltchinskii. Concentration inequalities and asymptotic resutls for ratio type [5] V. Koltchinskii. 2008 Saint Flour lectures: Oracle inequalities in empirical risk minimization [6] P. Massart and E. Nedelec. Risk bounds for statistical learning. Annals of Statistics , [7] A. Tsybakov. Optimal aggregation of classifiers in statistical learning. Annals of Statistics , [8] V. Vapnik. Estimation of dependencies based on empirical data . Springer X  X erlag, 2nd edition, [9] V. Vapnik and A. Vashist. A new learning paradigm: Learning using privileged information. [10] V. Vapnik, A. Vashist, and N. Pavlovich. Learning using hidden information: Master class
