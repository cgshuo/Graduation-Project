 We propose an expert finding method based on assumption of sequential dependence between a candidate expert and the query terms in the scope of a document. We assume that the strength of relation of a candidate to the document X  X  con-tent depends on its position in this document with respect to the positions of the query terms. The experiments on the official Enterprise TREC data demonstrate the advantage of our method over the method based on independence of query terms and persons in a document.
 Categories and Subject Descriptors: H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval.
 General Terms: Algorithms, Measurement, Performance, Experimentation. Keywords: Enterprise search, expert finding, dependence modeling.
The search for people with relevant expertise rather than for relevant documents is becoming more and more of a nec-essary everyday activity in organizations. Recently, the ex-pert finding task attracted the close attention of IR research community and stays a part of the Enterprise track of the Text REtrieval Conference (TREC) [2] already since 2005. The majority of approaches proposed so far is based on in-ferring personal expertness by analyzing the degree of co-occurrence of personal identifiers with the query terms in top retrieved organizational documents. The state-of-the-art methods relying on this principle in fact consider that the candidate X  X  expertness can be measured by the sum of retrieval scores of related documents [1, 5]. In this paper we propose to take not only the fact of co-occurrence into ac-count, but also the important property of this co-occurrence: the sequential order of a candidate X  X  identifier and the query terms mentioned in a document.
One of the most known expert finding methods based on the principle of co-occurrence is proposed by Balog et al. [1]. The method basically represents the propagation of rel-evance probability from documents to related candidates. It calculates the probability of expertness for a candidate as: where P ( D ) is distributed uniformly, P ( Q | D ) is the proba-bility of the document D to generate the query Q , measur-ing the document relevance according to the probabilistic language modeling principle of IR, P ( e | D ) is the probabil-ity of association between the candidate and the document. The described method in fact models the assumption that the more often the candidate appears in documents contain-ing many query terms the more likely the candidate is an expert. For that purpose, the method calculates the proba-bility P ( e, q 1 , ..., q k ) of observing the candidate expert e to-gether with query terms q 1 , ..., q k in some sample generated by language models of top documents, considering that the candidate and the query terms are generated independently given a ranked document.

Despite that the assumption of independence is very pop-ular in various IR tasks, it does not always lead to the best performance. Including other features that characterize co-occurrence of terms often helps to improve. Two kinds of approaches are especially popular in document retrieval and, namely, in query expansion. While one approach measures the degree of proximity of a term to the query terms in the scope of a document [3], another one also takes the sequential order of terms into account [6]. While the as-sumption of independence between terms in a document is sometimes a too rough approximation, the assumption of in-dependence between the document X  X  content and its related persons seems even more doubtful.

Recently, it was shown for expert finding that the over-all pairwise distance between a candidate X  X  mention and the query terms in a document expresses the degree of associ-ation between the document and the candidate [7]. At the same time, the importance of an order in which personal identifiers and query terms occur in documents was never studied to the best of our knowledge.

We propose to use the sequential order of query terms and the candidate expert for estimating the amount of doc-ument relevance probability that should be propagated to the candidate. Since our approach is based on the assump-tion of dependency between query terms and the candidate, we rewrite Formula 1 in the following way: where P ( e | Q, D ) is the probability of association between the candidate and the document and a ( e, Q, D ) is the non-normalized association score between the candidate and the document proportional to their strength of relation. Both the probability and the association score are query-dependent . They depend on where the candidate X  X  personal identifier is mentioned in the text with respect to the positions of the query terms. We differentiate the following types of se-quences to weight them differently:
Such orders may have various meanings, depending on specifics of a collection. For instance, authors of documents are usually mentioned before any topical words, people which are used to describe the topic probably occur somewhere in between of query terms and those who made lesser con-tributions are mentioned in the acknowledgments after all topical words. The proposed approach allows to distinguish these roles even when documents are not structured and persons mentioned in them are not semantically annotated. The experiments described in the next section simulate this widespread case. We experiment with the CSIRO collection used by the Enterprise TREC community in 2007. It represents a crawl from Australia X  X  national science agency X  X  (CSIRO) web site. 50 queries with judgments made by retired CSIRO employ-ees and 3500 candidates found in the collection were used for the evaluation. At the collection preparation stage, we extracted associations between candidate experts and doc-uments by searching for the candidates email addresses and full names in the text of documents. It was enough to re-trieve 50 documents containing at least one candidate X  X  men-tion for the best performance of the baseline method.
Two expert finding methods are evaluated: the baseline method based on the assumption of independence between query terms and the candidate X  X  mention (see Formula 1) and our method using the assumption of their sequential dependence (see Formula 3). For the baseline method the association score between the document and any candidate mentioned is always equal to 1.0. Since our method has only 3 parameters, we calculated their optimal setting with a simple coordinate-level hill climbing search method. The best performance of our method was reached with the fol-lowing values for association scores: w before ( e, Q, D ) = 10 . 0, w after ( e, Q, D ) = 0 . 1, w between ( e, Q, D ) = 1 . 0. In the case of several mentions of the same candidate in a document (what rarely happened), the maximum weight was used. Table 1: The performance of expert finding methods using two assumptions: independence and sequen-tial dependence of a candidate and query terms This result suggests that the most important persons in the most relevant documents are always mentioned before top-ical words (for instance, it often happens in resumes that are very important evidence of expertness in CSIRO). Of course, this may vary between organizations and should ac-tually depend on what kinds of documents prevail in the organization.

Both methods are compared in terms of common Informa-tion Retrieval performance measures officially used in TREC evaluations: Mean Average Precision (MAP), precision at top 5 ranked candidate experts (P@5) and Mean Reciprocal Rank (MRR). Table 1 demonstrates the advantage of our method based on the assumption of sequential dependence over the baseline method assuming sequential independence.
We presented an expert finding method taking the sequen-tial dependence of a person and query terms occurring in a document into account. We claimed that it is useful to dif-ferentiate the orders of their occurrence in a document to estimate the strength of the relation of a candidate expert to the document X  X  content. Experiments on the dataset from the Enterprise TREC 2007 justified our assumptions.
In the future we plan to develop a unified model combin-ing all features describing co-occurrence into account: the proximity of a candidate to query terms, the order of their occurrence, the frequency of a candidate X  X  occurrence etc. It is also promising to make the document-candidate weights dependent not only on the positions of candidate experts with respect to query terms positions in a document, but also on their absolute positions in the document or on the type of the document (at least, on its easily determined prop-erties like extension or length). [1] K. Balog, T. Bogers, L. Azzopardi, M. de Rijke, and [2] N. Craswell, A. de Vries, and I. Soboroff. Overview of [3] J. Gao, M. Zhou, J.-Y. Nie, H. He, and W. Chen. [4] V. Lavrenko and W. B. Croft. Relevance based [5] C. Macdonald and I. Ounis. Voting for candidates: [6] D. Metzler and W. B. Croft. Latent concept expansion [7] D. Petkova and W. B. Croft. Proximity-based
