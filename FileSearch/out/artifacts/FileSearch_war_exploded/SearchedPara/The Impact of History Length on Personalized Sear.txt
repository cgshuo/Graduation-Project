 Personalized search is a promising way to better serve dif-ferent users X  information needs. Search history is one of the major information sources for search personalization. We investigated the impact of history length on the effective-ness of personalized ranking. We carried out task-based user study for Web search, and obtained ranked relevance judg-ments for all queries. Query co ntexts derived from previous queries in the same task are used to re-rank results for the current query. Experimental results show that the perfor-mance of personalization generally improves as more queries are accumulated, but most of the benefits come from a few immediately preceding queries.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Measurement, Experimentation.
 Keywords: Personalized Search, Web Search, Evaluation
Web search queries are usually short and ambiguous. Per-sonalized search aims to better understand information needs by modeling user interests. User profiles are built from var-ious sources including searching, clicking and browsing his-tory. This study focuses on the utilization of short-term context [2] for personalization. We try to answer one re-search question: How many related queries do we need to understand the current query?
The effectiveness of traditional information retrieval sys-tems is evaluated using binary relevance judgments. Web search systems use multivalued relevance assessments be-cause there are many relevant documents, with varying de-grees of relevance. Teevan et al. [3] obtained relevance rat-ings on a 3-point scale (highly relevant, relevant, non-relevant), and used Normalized Discounted Cumulative Gain (NDCG) [1] to characterize the potential of personalizing search. In this paper, we exploit the usage of ranked judgments, which is much finer-grained than multivalued ones. Compared with binary or multivalued judgments, ranked judgments are more expensive to obtain. However, they can be approx-imately induced from large amounts of click-through data.
Given a query, we form its context by aggregating the user-ranked best results from previous queries for the same task. The context is a term vector with TFIDF term weight-ing. For each result of the current query, we calculate its co-sine similarity to the context. We map the original ranking r to exponentially decreasing score s = a  X  r ,a &gt; 1. Linear combinations of the original ranking scores and similarity scores are used to re-rank the top 10 results.
The ranked relevance judgments enable us to calculate not only traditional binary style metrics, but also rank-based metrics. We use two existing and one novel metrics to mea-sure the quality of personalized ranking.

Since the original NDCG [1] is sensitive to the base of the logarithm, we use a widely used variation of NDCG: where n is the number of results, v i is the relevance value of the i th result, f ( n ) is a normalization factor. We map ranked judgments linearly to relevance values. For example, the best result has value 10, while the non-relevant ones share value 0.

Kendall-Tau distance is widely used for comparing two ranked lists. It is defined as the number of pair-wise dis-agreements normalized by the total number of pairs. How-ever, it does not consider the relative importance of different results.

In Web search, putting highly relevant results at the top is extremely important. We propose a general weighted rank distance (WRD) to measure the quality of document rank-ing.
 where n is the length of either list, R i is the user ranking of the i th result, w is a non-increasing weighting function, d is a pair-wise distance function, and z ( n ) is the normalizer that ensures WRD  X  [0 , 1]. z ( n ) is calculated using the worst case (reversed user ranking). Note that when d ( R i ,i )= ( R i  X  i ) 2 and w ( R i ) = 1, WRD resembles Spearman X  X  rank R i for WRD(1), and w ( R i )= R
We are interested in the impact of accumulating history on personalization. When history length is h ,thecontext for current query is derived from the immediately preced-ing h query. Since we collected 164 queries from 24 tasks, there are 140 queries with at least one previous query. Ta-ble 2 presents the performance of personalization with vary-ing history length. Considering the immediate preceding 1 or 2 queries improves the performance, but adding longer history only provides small further improvement, and occa-sionally hurts performance.

Why longer history does not help in our experiments? The value of personalization primarily lies in its disambiguation power. For perfectly clear queries, there is little room for personalization. For ambiguous queries, we need to find the right disambiguating direction. Longer history provides richer contextual information, but also brings in more noise. Our study suggests two common patterns [4] in the user behavior of forming queries. One pattern is from general
