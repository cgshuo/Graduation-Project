 In this paper, patterns of communication are examined in order to unpack the extent to which verbal equity is a critical factor in determining group success. A microanalysis of 20 teams working to complete a complex, information dependent , collaborative task was conducted . Interaction analysis methods were used as means to determine patterns of interaction and the sophistication of cognitive activity that teams e ngaged in. Findings suggest that verbal equity may not be as important as previous research indicates. A more critical variable may be cognitive specialization. The authors explain their findings by drawing on theories of cognition , thereby contribut ing to a better understanding of collective intelligence . K.4 .3 [ Organizational Impacts ]: Computer -supported collaborative work .
 Measurement, Performance, Design, Experimentation, Security, Human Factors, Theor y Collective cognition, macrocognition, collective intelligence, verbal equity, collaborative decision -making, cognitive specialization , collaborative problem solving, information analysis Though it is generally accepted that groups are better than individuals at solving complex, ill -structured problems, many questions regarding group processes still remain. Over the past two decades , the study of groups has evolved from the study of how individual minds and task characteristics interact with group processes towards the study of group processes themselves [8, 21]. A range of different group process variables has been examined: from knowledge building and argumentation to motivation and stress [13, 22]. More recently, researchers have examined patterns of group interaction in an attempt to understand group cognition or predict a group X  X  likelih ood of p roblem solving success [7, 9, 2 8, 30] . These studies point to the importance of key communication patterns such as equal access to information and integration of diverse pe rspectives. Wooley et al. [ 30] even indicate that there may be a collective intelligence quotient, one that is highly associa ted with verbal equity. Though W ooley et al . [30] shed new light on the study of group processes , with regards to turn -tak ing patterns and performance, they did not closely examine the content of communication and therefore could not explain why verbal equity was associated with collective intellig ence. In order to develop a better understanding of group cognition, it is necessary to examine communication patterns at a finer grain of scale than proportions of verbal contributions. We must examine the content of what is being verbalized , as this is where group cognition lives: in the verb alizations between indiv iduals [2 3, 16]. It is also necessary to examine the effect of verbal equity on more complex problems than those employed in many of the studies we have cited, including the Wooley et al. study. This is why we are interested in further unpacking verbal equity by examining patterns and content of communication.
 In this paper , we focus on information analysis, an important complex collaborative problem -solving domain , and elaborate on a prior study that suggested tha t verbal equity may not be as important as many have been led to believe [2]. We present a larger data set and a more comprehensive analysis, specifically with respect to unpacking the role of cognitive specialization in explaining the benefits of verbal equity. Our findings contribute to a deeper understanding o f group cognitive processes as they pertain to verbal participation and a group X  X  ability to perform consistently well over time. One of the challenges to stud ying group cognition is developing a task complex enough for teams to engage in kn owledge building and negotiation processes , in order to create knowledge that did not exist prio r to collaboration [2 2]. Previous studies built on the hidden profile work of Stasser and Titus [24] and designed an emergency management scenario in order to examine team communication patterns [5 ]. Findings from this study suggested that certa in patterns of communication might be associated with a team X  X  ability to develop common ground and may also indicate when tea ms are having problems building shared under standing. For example, frequency of particular speech acts can be associated with higher and lower perfo rmance [6 ]. Though these earlier studies produced interesting findings related to communication patterns, one of the biggest limiting factors in unders tanding the team X  X  processes was the scenario itself; it was not complex enough. Participants only worked with 25 facts, and solving the problem, assuming all information was shared in simplest form, was a counting task  X  the option with the least cons was the answer. Furthermore, none of the teams created complex forms of information artifacts (i.e., emergent representations developed to help synthesize or build on information) ; they only made annotations on a map. More complex forms of information artifacts (i.e., charts, lists, graphical representations) could have provided more insights into the teams' processes for combining information and building on that knowledge, perhaps even help ing to explain differences between h igh and low performing teams. Thu s, their absence was problematic.
 Wooley et al. [ 30] examined team processes and characteristics in order to determine whether there was such a thing as a group intelligence factor: a measure of a team X  X  collective intelligence that could predict a team X  X  performance outcomes across a variety of tasks. They conducted two studies on 192 groups as they completed a series of diverse, simple tasks and measured both individual and group characteristics. They found that a single measure, which they termed collect ive intelligence, or  X  X  X , significantly predicted group performance. In trying to understand what  X  X  X  might be, they were able to rule out many variables that might be expected to predict group performance: average team intelligence, level of intelligence of the most intelligent member, motivation, group cohesion, and satisfaction. The three variables most correlated with  X  X  X  were social sensitivity, proportion of females on the team, and variance in number of spe aking turns. Social sensitivity and proport ion of females w ere strongly positively correlated, but the proportion of females was largely mediated by social sensitivity: females were significantly higher on social sensitivity than men. Variance in the number of speaking turns, a measure of verbal eq uity that looks at the spread between speakers in a team, was negatively correlated with performance. Teams where one person largely dominated speech turns tended to do worse on tasks than teams that were more equitable. These findings suggest that equity of participation may be an important factor in and of it s self and not because it might indicate motivation or cohesion. However, given that only turn taking was measured, but actual communication was not captured , they could not conduct qualitative studies of their participants  X  communication patterns to determine why verbal equity was a factor. So the question remains as to whether verbal equity is an important factor or simply a variable moderated by another variable that their methods could not me asure. Understanding what types of cognitive processes might predict or improve group process is important for researchers in CSCW and CSCL , as such findings have implications for design of collaborative tools and the cognitive supports we provide. Given t he limitations of the emergency management scenario and the study conducted by Wooley et al., there was a need to examine collaborative problem solving processes using a more complex task with more robust measures of communication and interaction. In this way , the relationship between verbal equity, group cognition, and performance could be further unpacked . As part of our previous work, our research lab designed a complex information analysis and decision -making scenario that required teams to work togeth er to solve a complex, information -based problem over a four hour time period [2]. Participants had to solve a crime that required them to understand the nature of the task, find relevant facts, make connection between facts, and connect evidence in order to make inferences about means, motive, and opportunity. Teams were also provided with a collection of materials that they could use to create shared artifacts, but they were not required to do so. Nonetheless , most teams created elaborate artifacts [4 ]. The information analysis and decision -making scenario allowed for closer analysis of patterns of interaction that occurred between team members [2, 4 ]. Early findings based on a microanalysis of ten teams, five high -and five low -performing, found a positiv e relationship between verbal equity and performance, but also suggested that verbal equity might be moderated by distribution of cognitive r esponsibilities [2]. Carroll et al. [4 ] also found that higher performing teams use d information artifacts in more sophisticated ways than low er performing teams . Such findings raise questions regarding importance of verbal equity in problem solving teams: is verbal equity a crucial factor in determining a team X  X  potential or is it simply moderated by patterns of colle ctive cognitive activity? In this paper , we extend this work by conducting a microanalysis of 20 teams as they work on this complex problem -solving task. Our research questions are as follows: when the analysis is extended to 20 teams, (R1) to what extent do high performing teams show more verbal equity t han low performing teams, (R2) to what extent do high performing teams show more cognitive specialization than low performing teams, and (R3) to what extent are patterns of cognitive specialization associa ted with more sophisticated forms of collective cognition? Buildi ng on previous studies [2, 4, 5, 6, 1 6], we used a collaborative information analysis scenario as a means to study communication patterns during a complex, collaborative problem -solving activity. The scenario required each person on a three -person team to take on the role of specific intelligence analyst for the entire scenario . They then had to work with team members as part of a police taskforce and collectively solve an ongoing ring of computer thefts . The team had to search, select, share, synthesize , and interpret existing intelligence in order to make complex decisions. In total, the scenario contained 222 unique pieces of data embedded into nine separate intellige nce reports. These reports were distributed amongst the three intelligence analysts , each receiving entirely different, but complementary information. Each analyst receiv ed three reports total: one prior to each part of a three -part scenario. All three ana lysts also receive d a General Mission Statement containing the same information: crime descriptions, detail s about the reliability of information, and "rules" associated with alibis and opportunity to commit the crime.
 The entire scenario t ook about 4 hours to complete . P articipants had to use a mix of inductive and deductive reasoning in order to solve each part o f the scenario accurately: (part one) narrow down a list of 26 Persons of Interest (POIs) to a list of the eight most likely suspects; (part two ) identify thieves for each of four thefts, instigators or accomplices, motives, and whether there were connections among the four thefts; and (part three) predict the thief, time , and place of the next crime.
 Over 70 hours of video from 20 microanalyzed teams -ten consistently high performing and ten consistently low performing -was the primary data source for the findings presented in this paper. This data is used to unpack the types of cognitive activities and process problems e xperienced by teams and whether patterns exist between particular cognitive processes and performance. Participants were recruited from a large northeastern United States university. Thirty -nine teams took part in the study. Each team was comp rised of three participants for a total of 117 participants. The majority of the participants were recruited from undergraduate information sciences , security and risk analysis, and psychology courses. Of these 39 teams, 20 were selected for microanalysis, based on performance. Thus, there were 60 total participants included in the microanalysis. Upon arrival, each participant was randomly assigned one of the three information analyst roles. The information analyst roles were , Records Specialist, Web Specialist, and Interview Specialist. Each team was also provided with a collection of materials in case they chose to create shared representations, i.e., large paper, maps, calendars, markers, pencils, notepaper, etc. Prior to beginning part 1 of th e scenario, each analyst was provided with 15 minutes to read through their first report (four to six pages, depending on role) and the General Mission Statement, (three pages). They were also asked to write down initial thoughts on potentially important i nformation. Teams were provided with updated information between parts of the scenario and given time to reflect before beginning the next part of the scenario. The experimentor observed from a separate room and only interacted with teams in between parts of the scenario. Task performance was scored based on accuracy of solutions in each part of the task: total points received/total possible points. There were eight points possible in part 1, sixteen in part two , and three points in part three. Percentages were calculated for each phase , and the average performance was used. Average performance across the three tasks ranged from 16.33% to 73%, indicating the high level of difficulty of the task. Since identification of characteristics of consistently high performing teams was the primary goal , selection was based upon consistency of performance , rather than average performance , across t he three parts of the scenario. Ten consistently high performing teams and ten consistently low performing teams were chosen . Cut-offs were determine d by using sums of quartile rank scores across the three parts of the scenario . In cases where the sums of quartile rank scores were to o similar to distinguish between cut -offs, average performance across the three parts of the scenario was used as a secondary filter. Each of the ten selected teams' videos was transcribed following a similar format. Each new speaker utterance and /or behavior was numbered, denoting a new  X  X urn X . A  X  X urn X  ended when a different speaker introduced a new utterance. These turns were then split up into dialogue acts: separate sentences. Compound sentences were spl it into separate acts as well. The particip ants were referred to by the role s they played and were given pseudo nyms in the transcript. Parentheses were used to label nonverbal gestures and events (i.e., leaving the group, making faces, creating an artifact , etc.). Brackets were used for codes, time stamps, and notes relevant to the analyses but not found in the video itself. These transcripts were utilized along with video when analyzing the artifacts and detecting common task errors. The coding schema used in this study was one used by previous researche rs in CSCW [5, 6 ] and later refined to better align with literature in cognitive and educational psychology [2]. reliability for the coding schema is Kappa= .67, indicating substantial inter -rater reliabi lity [1 5], particularly for the relatively high number of codes . The coding schema divides dialogue into four classes of cognitive activity (in bold below) and then furt her breaks these down into acts. Breaking down communication to such a fine grain leve l allows researchers to look for patterns in different types of cognition with other variables such as problems, distribution of thought, cognitive strategies, and performance [2]. The coding schema is as follows: Information Transfer -How new information, existing prior to collaboration, is added (i.e., information from existing documents) (AI): Add Info -Add new information w/o prompting (Q): Question -Prompt someone for new information (R): Re ply-Provide new information in response to a prompt Check Un derstanding -How previously added info is checked, confirmed, or repaired (CH): Check -verifying information (CL): Clarify -clarifying or restating information (AC): Acknowledge -signaling receipt or understanding of information Management of Processes -How work is orchestrated (MN) Management -discussions centered on inte ractions, planning how to do the work, or reflecting on what has b een done (CM) Command for action, order, or instruction that does not take others into account (RQ) Request for action -posed as a question or indirect prompt (not a question) Interpretation -How task information is interpreted and decisions are made (J): Judge -Individual preference, opinion, or claim, with or without deliberation (RA): Rationale that supports a ju dge (J) o r alternative (AT) act (AT): Proposing an alternative to a (J) OR (RA) act (CO): Confirmation -Requesting agreement on a proposed decision (AG): Agreement -Indicating agreement for prior judgment or decision Identifying MN acts, management of process, and distinguishing between RA and AI were the most difficult aspect s for coders. MN acts were hard for coders to identify , because they were often mistakenly coded as task -related activity, i.e., judgment acts, rational acts, etc. C oders had to learn to distinguish between content and process in order to distinguish this code. Also, in the process of providing rational e, participants could introduce new information about the task, making it difficult to distinguish between AI and RA acts. These difficulties were discussed and mitigated, but i n order to further ensure proper coding, coders were paired , and problematic codes were collectively examined . Over 70 hours of video was transcribed , resulting in over 34,000 dialogue acts across the 20 teams. Once dialogue was coded, the raw scores for each team were normalized. This was accomplished by calculating the percentage of specific dialogue acts to total dialogue acts. In this way, comparisons could be made across teams. Dialogue act co ding was used as a means of looking for patterns of interaction as they occurred in different primary activities within the scenario. Given that the study uses a dichotomous comparison of high and low performing teams, tests of corr elation would not be appropriate. Therefore , we had to create ordinal categories that coincided with variance in speech turns. The goal was to distinguish between groups where one person dominated, two people shared authority, or all three members contribu ted equally. However, we wanted to be able to do th is objectively and therefore used Verbal Equity Scores, a system of categorizing patterns of communication by the amount of variance between members of a team [2]. This method allowed teams to be assigned to categori es mathematically . The standard deviation of talk for all participants, across all speech acts, was used as a means to determine cut -offs: SD = 0.08, or 8% talk. There are three categories : a score of 3, or equitable verbal participation, a score of 2, or shared authority, and a score of 1, or dominance of one team member. To get a score of three, the difference in percent of total talk between the highest and lowest speaker in a team had to be less than two SDs, or 16%. To get a score of 2, the difference between highest and lowest speaker had to be more than 16%, but the difference between the two highest speakers had to be less than 8%. To get a score of 1, one of two criteria had to be met: the difference between the two highest speakers h ad to be more than 16% or the difference between highest and lowest speaker had to be more than 16% and the difference between the two highest speakers had to be more than 8%. Each team received a total verbal equit y score , indicating the pattern of verbal equity across the entire four -hour task. Cognitive specialization refers to the extent to which team members distribute cognitive responsibilities. This is different than distribution of tasks in that people may verbalize similar forms of thinking even though they are working on two different tasks . W hereas distribution of cognitive responsibility requires that members focus on and verbalize different types of cognitive activity. Cognitive specialization is determined by examining two classes of cognitive activity associated with authority: (1) management of processes and (2) interpretation and decision -making activity [2]. For this reason , percent talk related to these activities was identified by team member. Based on patterns of talk, teams were then classified into one of three ordinal, cognitive specialization patterns. The lowest is a type 1, where no cognitive spec ialization is shown: one person controls both types of thinking process es. Type two indicates that some specialization is present, but people share rather than completely distribute cognitive responsibilities: one person controls majority of one form of t hinking and shares the other with a team member. A type 3, the highest form of cognitive specialization, is defined as complete cognitive specialization, where one person controls one form of thinking and another member controls another. For example, one p erson might contribute 50% of all the interpretation talk, but a different person would contribute over 50% of the talk related to managing team processes. Strategy use wa s u tilized as a means to identify the sophistication of collective cognitive behaviors. This is because the strategies people use can provid e a lens as to how people go about solving a problem [ 20]. We used interaction analysis as our primary method for analyzing the video data [11 ]. The identification of externalized collective problem -solving strategies was the result of extensive qualitative analysis headed by the first author and informed by membe rs of the research team. Students were trained to observe and take notes on teams in order to create detailed content logs of important behaviors such as artifact use, reference to critical inform ation, and cognitive strategies . Content logs of video acti vity were developed , and notes of behaviors were stored for each of the microanalyzed teams. These logs were used to develop conceptual models of the activities the teams engaged in and were compared to student observations . Research g roup discussions were used as a means to verify observations and organize the primary tasks and related activities. The transcripts were also visually coded in order to indicate when certain behaviors occurred. T hese behaviors were then connected to speech acts. Video, transcr ipts, and artifacts were examined in concert in order to evaluate cognitive activity (see figure 1). Once observed behaviors were agreed upon and connected to theory, a construct map was developed of the most common observed strategies, classified by sophi stication of cognitive behavior. These were defined, assigned a code, and informed by examples of what the behavior would look like in practice. Though the first author analyzed all of the externalized cognitive strategies presented in this study, an inter -rater test was conducted in order to determine the reliability of the coding construct. As such, a senior undergraduate researcher with two years on communication analysis training used the coding construct to assess a four hour session that included 1362 speech acts and 175 speech acts assoc iated with a cognitive artifact: Kappa = 0.71 . In order to contrast discourse content and the sophistication of cognitive behaviors on a finer grain scale of analysis, two teams were selected with similar input characteristics but different cognitive specialization and performance. Both teams included two male s and one female member, showed equal levels of engagement, contained students with similar majors, and reported similar levels of psych ological safety. Both teams were also extremely equitable in information transfer speech acts: verbal contributions related to members transferring information from existing documents to other team members. They also contributed similar amounts of critical information: the information that needed to be shared to solve the task. The main difference between teams was that they were on opposite spectrums of cognitive specialization and performance: one team was a high performing team with complete cognitive sp ecialization and one team was a low performing team with no cognitive specialization. Figure 1. This picture illustrates the process that coders enacted when assessing collective problem -solving strategies and how artifacts were used. When categorizing behavio rs, c oders watched video while reading transcripts that identified the artifacts used and examining the artifacts referenced by the video and transcripts. The first research question centered on examining the extent to which consistently high performing teams would show higher levels of verbal equity when compared to consistently low performing teams. Findings showed no signif icant difference s or trends in verbal equity between consistently high and consistently low performing teams (see figu re 2). The medians for verbal equity were actually higher for low performing teams than high performing teams; the medians were 3 and 1.5, respectively. The second research question focused on examining the extent to which cognitive specialization differed between consistently high and low performing teams . Findings showed a significant difference in cognitive specialization. The median for cognitive specialization for low performing teams was 1 , and for high performing teams , it was 2. The mean rank s for low and high performing teams were 8.10 and 12.90, respectively; U = 26, Z = -2.068, p &lt; 0.05, r = 0.46. There were also no examples of low performing teams showing high levels of cognitive specialization. Eight out of the ten low performing teams had one person dominating both forms of cognitive activity. On the other hand, the majority of high performing teams (6/10) displ ayed some sort of cognitive specialization. Within both groups , there was also a trend for higher average scores to be associated with more cognitive specialization. Our two highest teams showed complete cognitive specialization. Thus , cognitive specializa tion seems to have its main effects at the extremes of our data, where scores of one are highly associated with poor performance and scores of three are only found among our highest performing teams (see figure 3 ). In order to have a better understanding as to why cognitive specialization may help teams to perform consistently better over time, it is necessary to e xamine the content of the teams X  cognitive activity and illustrate what cognitive specialization looks like in practice . For this reason , two teams were contrasted that share d similar input characteristics but differ ed in cognitive spe cialization and performance . These two extremes were compared because our findings indicate that cognitive specializat ion is most influential at these extremes. The major process characteristics of each team are provided first , followed by summaries and transcript examples of how the team s progressed through the activity. The two teams are team 2 1, a low performing team with no cognitive specialization , and team 2, a high performing team with complete cognitive specialization.
 Figure 4 illustrates the process characteristics of the two teams and shows how speech acts were distributed among team members. Information transfer speech acts are not shown, s ince both teams were perfectly equitable in this category . This means that all members contributed equally when sharing information from their intelligence reports.
 The first column in figure 4 shows the distribution of tota l speech acts for each team (i.e., verbal equity ) across the entire scenario . The next two colu mns show distribution of speech acts related to different forms of thinking: process management and interpretation of content. This figure makes it possible to see visually how one member dominates process management and interpretation talk in team 21. In contrast, two different members dominate the different forms of thinking in team 2.
 These differences in process characteristics and cognitive specialization can be seen in context , as the teams  X  progression through the activity is closely examined . Both teams faced similar challenges with cognitive load, but how this load was managed varied by team. Both teams used emergent artifact s to help reduce cognitive load, but only one team distributed cognitive responsibilities.
 Both team s began part 1 of the scenario in similar fashion: they introduced themselves and the type of data they each had. Reca ll that the aim of part 1 was to narrow down a list of 26 persons of interest (POIs) to the eight most like ly suspects by using intelligence reports to make a case for means, motive, and opportunity. Both teams proposed the same off -loading strategy about 30 minutes into part 1 of the task: create a table to go through and eliminate names as members share information about POIs . In the next few sections, differences in how this strategy was implemented and the strategies that followed are illustrated. In team 21, the members are Interview (male), Record (male) , and Web (female). Table 1, example 1, includes the transcript example, referred to in this section. Turns of speech are numbered for easy reference. Interview attempts to manage the process of sharing information by suggesting they create an elimination list by crime event ( turn 1 ). Record steps in and suggests they also add suspects who could have done it (turn 4 ). Interview agrees and then Record leads the information sharing process by imposing the use of his list along with an organization strategy based on personal preference (turn 6 ). Record then states he will write down everyone X  X  name on his paper and write down rationale related to potential opportunity to commit the crime . Given that th is is an individual document and not immediately accessible to others , this gives Record the primary access to information neces sary for decision -making . These actions inadvertently place two forms of cognitive demands on Record: (1) managing the process of information sharing and synth esis activity and (2) interpreting synthesized information.
 About ten minutes in to their strategy use , they begin to show signs of cognitive overload (see table 1, team 21, e xample 2) . Team members are sharing information about a person of interest (POI) n amed Jeff. Record is managing the synthesis of information and leading the decision -making process. This example demonstrates what happens when a person dominates two different forms of cognitive activity. Record is making most of the decision -making and p rocess management speech acts. He decides when to m ove on to the next person (turns 1 and 11 ). When Record pushes to the next POI and states that he does not have any information on him in turn 1 , Web states that she does (turn 2) , but Record cuts her off to share irrelevant information seemingly unaware that she has spoken (turns 3). As they share information, each takes separate notes, making it difficult to pay attention to important aspects of shared information. This may be why we see people repeating information q uestioningly (turns 6 and 10) . Record claims that Jeff may be a suspect because they have very little information about him , and Web agrees with his claim ( turns 6 -7). Record then remembers that they have no 
Table 1 . Transcript examples for teams 21 and 2. Each episode includes time stamp s above example s to indicate when in the task the example occurred. Turns are numbered for easier referencing. Team members are referred to by their task role names: interview (Int), web, and record (Rec). In team 21 (low performing), Interview proposes an initial strategy.
 motive for Jeff (turn 9) . Meanwhile , Interview is unsure about who m the group is talking about (turn 10) . This pattern of checking and clarifying previously shared information persists even when teammates make important claims. Though the team displays signs of cognitive overload, they persist with the same strategy , unable to recognize that creating a shared artifact may help them with part 1 of the task. The team has 55 minutes to select the 8 most likely suspects from a list of 26 POIs, but 43 minutes in to th e activity, the team has only  X  X uessed X  two names. The team is unable to see that their process is flawed and that their strategy is not working. Record even states,  X  X o far we only have like two guesses. So this is pretty good... It X  X  working right... X  We turn now to team 2. In team 2 , the members are Interview (male), Record (female), and Web (male). Similar to team 21, Team 2 (high performing) also proposes going through and eliminating names (see table 1, Team 2, Example 1) . Web makes the suggestion , and R ecord agrees without modify ing Web X  X  strategy (turns 1 -2). Web then proceeds to call for information on the first suspect by alphabetical order (turn 4). At this point, T eam 2 also does not create a shared team artifact . Instead, each person takes notes.
 About ten m inutes into their strategy use, similar to team 21, team 2 begins to experience problems keeping track of shared information, but team 2 handles the situation differently. At this point , Record begins to ta ke control over managing team processes . This is where over t cognitive specialization begins for Record (see table 1 , Team 2, Example 2).
 In this example, Record recognizes that there is too much information to keep track of it separately , so she creates a l arge shared artifact, a table ( turn 1 ). Web asks what Record is creating, but before answering, Record begins to ask the team for some of the task variables and creates a matrix of POI names by crime event ( turns 1 -9). Record proposes using this artifact so they can enter data together and cross people out (turn 10) . Web asks if Record plans to list all 26 names, but Record replies that only the names of those they discuss will be written down (turns 13 -14) . Record writ es down the names of those the team has already discussed in alphabetical order , ending with Elle , and Web adds,  X  X kay, I guess Frank now  X  (turn 16 ), accepting that Record will manage this process. The team uses the table to discuss people in alphabetical order and keep track of who m they had and had not discussed . They also keep track of whethe r each person they discuss is available for each of the four crimes. All during information sharing and synthesis , Record manages the team X  X  time, makes sure each member shares relevant information, and suggests they look at maps or other artifacts when necessary. At this point , interpretation activity is still fairly distributed. This changes towards the end of part 1. Once the team finishes synthesizing all the in formation on the shared artifact, they realize they only selected six out of the eight suspects and are unsure how to continue . Web steps in and decides to go over the information contained on the table , making checking and clarifying statements about inform ation contained in the table. Rec serves as a resource for clarification of the information she wrote on the table . After this point in part 1, t he primary exchanges are between Web and Rec, with Int only adding information from his documents when necessary. Their exchanges were similar to the following example: This is when Web takes over responsibil ity of interpretation activity, pushing the team to think more deeply. Meanwhile, Rec ord continues to manage the artifacts and time management , pushing the team to use shared data and make progress . In the end, Record asks Web to pick the final suspect for the team when they cannot decide based on the information contained in the artifact.
 After both teams submitted their solutions to part 1, they were provided with the actual solutions and given time to reflect. In provide d by the police (the solution s to p art 1) and identify four thieves, accomplices, motives, and determine whether any of the thefts were related . The interaction patterns in part 2 for both teams remain the same as those th ey developed in part 1 . In team 21 (low perf orming), Record continues to dominate all forms of cognitive activity. Interview initiates creation of the shared artifact in part 2 of the task, but Record eventually takes this over. Interview creates a system of color -coding and symbols, but as Record juggles decision -making and management responsibilities , Record begins to make repeated mistakes in how the symbols and colors are applied. Record even tually starts using the artifact as a means to collect his pet theories rather than as a means to analyze shared data. Over time , Record begins to pull information from members that he sees as relevant , rather than letting team members share information th ey believe to be relevant. For this reason , the team uses the ir artifact s in fairly unsophisticated ways (see table 2) . The artifacts are primarily used as a means to record shared information and pull out information as necessary. In team 2 (high perf orming) , Record manages most of the artifacts in p art 2, creating and writing on them as the team works to deconstruct the task and synthesize information. However, when it come s time to m ake final decisions, Web creates a shar ed decision-making table and man ages it for the team while Record continues to manage the other artifacts. Over the entire three -par t scenario, both teams displayed a variety of strategic behaviors associated with artifact use, but Team 2 engaged in more sophisticated strategic behaviors than team 2 1. Table 2 illustrates the different types of strategies displayed by both teams. Team 2 displayed sophisticated cognitive behaviors associated with deep thinking p rocesses and abstract thinking [1 , 12] . They used the inherent properti es of their elimination table to organize and exclude information they included on the table and on successor artifact s. They also use d multiple representa tions to link information across artifacts during their decision -making process. In essence , Team 2 c reated different artifacts to offload and organize different aspects of the task and then linked the artifacts together by pulling information from the artifacts simultaneously to look for patterns during decision -making.
 It might be possible to argue tha t differences between the teams could have been due to motivation, but that doesn X  X  seem to be the case. All of our participants stated greatly enjoying the task and many, including team 21 , were surprised by their poor performance . Most spent considerable time after the tasks trying to understand where they went wrong. For example, following part 1 of the scenario , Team 21 was so troubled by their poor performance that they revisited their information in attempts to figure out how they went wrong . At one p oint , they look ed to see how they could have missed a key piece of information about one of the suspects, George. Record question s his team: It turned out that Web had highlighted one of George X  X  Facebook posts as important since it referenced a victim , but Web did not share it with the team. Web accepts responsibility for the failure, but in reality it was a failure of the team , as Record controlled the sharing process . Record only asked for certain forms of information and decided when to move on to another suspect . At one point , when the team was discus sing an irrelevant suspect, Web interjected that George seemed particularly violent , but Web was ignored by the team . Web made various attempts to place George as a suspect, but Web X  X  statements were consistently overlooked . Web asked,  X  X eorge, did we do G eorge? What was his status? X  To which Record responded,  X  X eah, George is out. X  It is important to note that Record was not being purposefully rude and team interactions were not overtly negative. Rather, the team was simply not effectively synthesizing an d negotiating ideas from all team members. When it comes to complex collaborative tasks, our findings suggest that cognitive specialization may be a more critical variable than verbal equity. We found no significant differences between the verbal equity of high and low performing teams, but did find significant differences in cognitive specialization. The majority of the highest performing teams had some form of cognitive specialization. In con trast, our lowest performing teams had one member control both types of cognitive activity. Our data further suggests that cognitive specialization may be associated with higher quality collective cognitive processes . Findings regarding the range of sop histication of cognitive behaviors and strategies used by teams indicate that when teams distribute responsibility for thinking about how to synthesize information and how to negotiate information the team as a whole engages in more sophisticated forms of thinking . Our qualitative findings illustrate that this may be due to an individual  X  X  cognitive limitations . It may be that when an individual takes on too much cognitive responsibility , they may be more prone to error and therefore act as a bottleneck to higher quality forms of team reasoning. This suggests that simply sharing cognitive responsibilities may not be helpful for a team. The goal should be to maximize cognitive power through cognitive specialization. Existing theories of cognition and learning can help to support and explain this claim . Cognitive psychologists have long claimed that humans have a limited capacity of working memory , and this limited capacity must deal with all of the cognitive demands a person faces at any given time ( for review see 1 4, 26). Tasks that pose high cognitive demands can overwhelm individuals [25], but researchers have theorized that cognitive optimization may be the solution to better collaborative performance [1 4]. This may be because there are more individuals to share the cognitive load. However, as most people have experienced, the inclusion of more people on a team does not necessarily lead to better team performance. From a cognitive l oad perspective, one would expect better performance from teams that can utilize their members more effectively while keeping in mind the limits of individual working memory [14]. This suggests that allowing a member to specialize in one form of cognitive activity while reducing other s may provide that individual with the required amount of working memory to engage in more sophisticated forms of thinking around their specialized form of cognition . Collectivel y, such behaviors could lead to more sophisticated levels of team reasoning. Our findings also help shed light on previous studies that examined collective problem solving. For ex ample, Convertino et al. [6] found the freq uency of certain speech acts to be associated with performance. They found that higher amounts of check and clarify acts were negatively associated with team performance and Push acts (where members added information without prompting) were more beneficial than Pull acts (where members were asked for specific types of i nformation). Our analysis supports and extends these findings . Team 21 (low performing) had a high freque ncy of check and clarify acts and our microanalysis suggests that this pattern may be indicative of cognitive overload. As such , the team d isplays chec k and clarify behaviors as a means to try to establish common g round. Thus some check and clarify acts may be helpful, but too many may be indicative of an inability to establish common ground. Our findings may also help to explain why Push acts may be mo re beneficial than Pull acts. Drawing from our microanalysis of Team 21 (high performing), a high frequency of Pull acts may narrow down the scope of what is shared prematurely and may also be indicative of dominant members.
 Our qualitative findings sugges t there are a number of diverse cognitive deficiencies that can occur during collective problem solving. For this reason , enhancing collective intelligence may not be a simple matter of driving up one subskill or one behavior (like equity) , but rather it will require a broader collection of support. Many collaborative environments focus on supporting and testing a single skill, but our findings suggest that collaborative teams need more systemic cognitive support. Researchers have long main tained that technology must provide systemic support of cognitive, met acognitive, and social activity in order to facilitate the development of complex scientific thinking practices [21, 2 9]. Our findings indicate that this type of systemic support may be necessary for complex , information -dependent problem solving in general.
 Studies on collective intelligence are still in their infancy and there is a need to examine collaborative processes further through the use of more complex tasks. The tasks commonly utilized in studies of collaborative problem solving tend to be less complex, as they do not require participants to engage in a range of sophisticated cognitive activities all at once. As such, these shorter, simplified tasks may not generalize well to r eal -world collaborative teams encumbered with solving far more complex problems. Though our study used a more sophisticated task and examined group processes at multiple scales of analysis, it was still limited . Given our rigorous methods, w e were only able to analyze a small amount of teams. Since we were looking to identify characteristics associated with performance, we also chose to do a comparison study; this limited the types of analysis we could conduct. Thus , more research in the area of collective intelligence is needed. Specifically , the field needs to look for additional variables at the process level that may impact learning and decision -making. The results of this study are important given recent, high impact studies that indicate the impor tan ce of verbal equity [ 30] . Our findings provide an argument against focusing too narrowly on designing for equitable participation , a common theme in CSCW and CSCL [10, 1 8]. Moreover, i t is important to examine interactions at the process level in order to better inform the design of collaborative technologies . For example, many researchers have focused on developing technologies to encourage verbal equity, but our findings indicate that such features may pose trade -offs that need to be considered carefully, as increasing or decreasing a specific member X  X  amount of participation at any given time may interfere with the development of cognitive specialization.
 Future research should examine the trade -offs associated with the scripting of strategies to promote cognitive specialization or technology support that enhances a team X  X  ability to monitor and regulate information synthesis and negotiation processes . Whether or not teams can learn to engage in more sophisticated collective thinking processes and to what extent such improvement would enhance joint knowledge-building activity and collective intelligence are important questions that remain to be answered. A great deal of research has focused on examining the relationship between group characterist ics, processes, and group outcomes but primarily from a traditional, in dividualistic cognitive perspective [17 ], whereby the group context serves individual learning or individual character istics affect group outcomes . Unfortunately , such studies have done little to inform our theories of collective cognition [8, 1 3, 2 6]. Current research paradigms place more importance on large, quantitative studies, but these studies have limitations when it comes to unpacking phenomenon that is dependent upon interactions between individuals, such as collective intelligence . Large quantitative studies are quite useful for detecting patterns with input and output , but are less useful in determining why these patterns exist at th e process level. U nderstand ing the collective cognitive processes that determine collective intelligence and the resulting cognitive needs of teams requires that we also carefully examine language and inte ractions between group members [8, 23]. This necess itates the utilization of difficult and time -consuming methods that limit the size of the population being examined. For this reason it is imperative that we as a research community do not prioritize either large quantitative or more in -depth qualitative a pproaches to understanding collective intelligence , but rather find ways to synthesize findings across levels of scale. In this way we can make combined progress on identifying and evaluating key variables associated with this complex phenomenon.
 One of the most important contributions of this study is to push the field to recognize that "collective intelligence" needs to be theorized more broad ly. At this stage of work on collective intelligence , we should be looking for more constructs to include and ev aluate, and we should avoid focusing too singularly on equity or even cognitive specialization. We thank Craig Ganoe and Shin-I Shih for help in designing the scenario and coordinating the study. We also are grateful to all of the research assistants who worked on this project but particularly Scott Cunningham, Dan iel Nussbaum, and Jennifer Stout , who spent countless hours transcribing, cleaning, and coding data. This project was partially supported by the US Office of Naval Research (N0001 40910303/ N000141110221 ), the Edward M. Frymoyer Chair Endowment , and the National Science Foundation ( IIS -1319445). [1] Ainsworth, S. (2006). DeFT: A conceptual framework for [2] Borge, M., Ganoe, C., Shih, S., and Carroll, J. (2012). [3] Brown T. , Miller, C. (2000). Communication networks in [4] Carroll, J., Borge , M., &amp; Shih, S. (2013). Cognitive Artifacts [5] Convertino, G., Mentis, H., Bh ambare, P., Ferro, C., Carroll, [6] Convertino, G., Mentis, H. M., Rosson, M. B., Slavkovic, A., [7] Cooke, N.J., DeJoode, J.A., Pedersen, H.K., Gorman, J.C., [8] Dillenbourg, P., &amp; Traum, D. (1999). The long road from a [9] Fiore, S., Rosen, M., Smith -Jentsch, K., &amp; Salas, E. (2010). [10] Harris, A., Rick, J., Bonnett, V., Yuill, N., Fleck, R., [11] Jordan, B., &amp; Henderson, A. ( 1995). Interaction analysis: [12] Kaput, J. J. (1989). Linking representations in the symbol [13] Kerr, N. L., &amp; Tindale, R. S. (2004). Group performance and [14] Kirschner, P. A. (2002). Cognitiv load theory: Implications [15] Landis, J. R., Koch, G. G. The measurement of observer [16] Letsky, M., &amp; Warner, N. (2008). Macrocognition in teams. [17] Norman, D. A. (1990). Four (more) issues for cognitive [18] Marshall, P., Hornecker, E., Morris, R., Dalton, N. S., &amp; [19] Schafer, W.A., Ganoe, C.H. &amp; Carroll, J.M. Supporting [20] Schraw, G., Crippen, K. J., &amp; Hartley, K. (2006). Promoting [21] Shimoda, T., White, B., Borge, M., &amp; Frederiksen, J. (2013). [22] Stahl, G. (2006). Knowledge negotiation online. In G. Stahl [23] Stahl, G., Koschmann, T., &amp; Suthers, D. (2006). Computer -[24] Stasser, G., &amp; Titus, W. (1985). Pooling of unshared [25] Sweller, J. (1994). Cognitive load theory, learning di fficulty, [26] Van Merrienboer, J. J., &amp; Sweller, J. (2005). Cognitive load [27] Warner, N., Burkman, L., &amp; Biron, C. H. Special operations [28] West, G. P. Collective Cognition: When Entrepreneurial [29] White, B. Y., &amp; Frederiksen, J. R. (1998). Inquiry, modeling, [30] Woolle y, A., Chabris, C., Pentland, A., Hashmi, M., &amp; 
