 We develop a new static index pruning criterion based on the notion of information preservation. This idea is mo-tivated by the fact that model degeneration, as does static index pruning, inevitably reduces the predictive power of the resulting model. We model this loss in predictive power us-ing conditional entropy and show that the decision in static index pruning can therefore be optimized to preserve infor-mation as much as possible. We evaluated the proposed ap-proach on three different test corpora, and the result shows that our approach is comparable in retrieval performance to state-of-the-art methods. When efficiency is of concern, our method has some advantages over the reference methods and is therefore suggested in Web retrieval settings. H.1.1 [ Systems and Information Theory ]: Information theory; H.3.1 [ Content Analysis and Indexing ]: Index-ing methods; H.3.4 [ Systems and Software ]: Performance evaluation (efficiency and effectiveness) Experimentation, Performance Information Retrieval, Index Pruning, Conditional Entropy
Static index pruning is a technique that seeks to reduce in-dex size during or immediately after index construction. The reduction is achieved by permanently removing unwanted in-dex entries, i.e., postings , from a production retrieval system. At the cost of sacrificing some degree of retrieval accuracy, this practice has been shown to enhance both disk usage and query throughput [4]. To date, static index pruning has gathered much attention for its implication to search efficiency over Web-scale text collections [2, 3].
To minimize the effect of index pruning on retrieval ac-curacy, many previous efforts prioritize the index entries according to their impact on the retrieval result. Carmel et al. proposed using raw retrieval scores, such as tf-idf or BM25, to measure the importance of a posting [4]. B  X  uttcher and Clarke measured the usefulness of a posting ( t, d ) based on the contribution of term t to the Kullback-Leibler diver-gence score between document d and the entire collection [3]. Blanco and Barreiro used the odd-ratio of relevance in prob-ability ranking principle (PRP) [5] as the decision criterion [2]. Alternative criteria other than impact have also been in-vestigated, such as document-centric entropy-based pruning [6], and informativeness and discriminative value [1]. These measures have been shown useful in specific query scenarios.
In this paper, we discuss the idea of information preser-vation and use that to motivate a new decision measure for static index pruning. Consider that an inverted index is essentially a nonparametric predictive model p ( d | t ), with which one estimates the likelihood of some document d be-ing relevant to some query term t . Pruning this model per-manently removes the connections between some terms and some documents, and thus causes a loss in predictive power. We propose using the conditional entropy H ( D | T ) to quan-tify the predictive power and minimizing the loss with re-spect to the choice of pruned entries.
Information retrieval is a practice about ranking docu-ments in response to information needs. To achieve optimal performance, documents shall be retrieved in order of the decreasing probability of relevance [5]. This notion of rele-vance can be realized in many different ways. For simplic-ity, here we consider a simple term relevance model p ( d | t ) that assesses the probability of document d being relevant to some query term t . The model p ( d | t ) is a nonparametric predictive model , in a sense that prediction is made over the choice of documents with respect to the textual input from the user. In static index pruning, the problem that we face is to preserve as much predictive power in p ( d | t ) during the course, in spite of a considerable amount of information will be discarded afterwards.

We propose using the conditional entropy H ( D | T ) to quan-tify the predictive power in p ( d | t ). The conditional entropy is a summary statistic regarding how difficult it is to pre-dict the right outcome D (document) given the predictor T (MAP/P@10). Columns indicate different query types (short/long). (term). Generally, it is written as: where p ( t ) denotes the probability of term t being used in a query, and p ( d | t ) is the predictive model that assesses the relevance between document d and term t .

The distribution p ( t ) is independent of the retrieval model in use. To estimate p ( t ), we simply assume that it is uni-formly distributed. Note that this estimate can be further improved by using session logs. Now, we write H ( D | T ) as a summation of uncertainties A ( t, d ) contributed by individ-ual term-document pairs to the model:
Consider any two term-document pairs ( t, d ) and ( t  X  , d such that A ( t, d ) &lt; A ( t  X  , d  X  ). The formulation implies that predicting d from t requires less information than predict-ing d  X  from t  X  , meaning that we are more certain about the connection for t and d . In this case, removing ( t, d ) from the index has less effect on the overall predictive power than removing ( t  X  , d  X  ). By setting a cutting threshold  X  , it is now straightforward to scan over the entire index and discard any entry whose uncertainty A ( t, d ) is strictly lower than  X  . This simple maneuver guarantees to retain the most predic-tive power with respect to a specific choice of  X  .
We implemented two baseline approaches using the In-dri API 1 : top-k term-centric pruning (denoted as TCP) and h ttp://www.lemurproject.org/indri.php probability ranking principle (denoted as PRP). Our imple-mentation does not update the document length values after pruning. For TCP, we set k = 10 to maximize the precision for the top 10 documents [4] and used BM25 as the score function. For PRP, we set  X  = 0 . 6 for query likelihood estimation, and applied the suggested approximations to es-timate the rest of the probabilities [2]. These probability estimates are summarized as follows.
To reduce the effect of retrieval method, a similar setting was adopted for the proposed method. We used Equation (4) to estimate the query likelihood p ( t | d ) (setting  X  = 0 . 6). For estimating document prior p ( d ), we experimented with two approaches, which are hyperbolic-tangent approximation as in Equation (5) (denoted as IP-ht) and uniform prior , i.e., p ( d ) = 1 / | D | (denoted as IP-u).

We managed to control the prune ratio at different levels (e.g., 10%, 20%, . . . , 90%.) For PRP and IP-based methods, the prune ratio depends on a global threshold  X  . To prune the index to the right size, we sampled the decision scores from the entire index to estimate the percentiles, and then used the estimates to find the right threshold value. For TCP, we manually adjusted the parameter  X  to approach the designated prune ratio. In our experiments, the error is controlled to roughly  X  0 . 2% in prune ratio. We conducted a series of experiments on the LATimes, TREC-8, and WT2G corpora, using TREC topics 401-450 as queries. We tested two different query types, short (using title) and long (using title and description), using BM25 as the retrieval function. Performance is evaluated using mean average-precision (MAP) and precision-at-10 (P@10).
I P-ht 253 N 246 N 2 30 223 N 194 158 116  X  0 83 075 N 283
I P-u 251 N 246 N 231 223 N 1 97 151 119  X  0 83 076 N 281 257 superior or inferior (p &lt; 0.05) to TCP are denoted by superscripts
The performance result is given in both figural and tab-ular formats. Figure 1 summarizes the evaluation result on tion of query type and performance measure. Each method is plotted as a curve or a series of points according to the measured performance (y-axis) at some prune ratio (x-axis). The full detail is covered in Table 1, which stresses more on performance differences between methods. Statistical sig-nificance in this respect is assessed using two-tailed paired t-test for p &lt; 0 . 05. We use superscripts ( N and H ) and subscripts (  X  and  X  ) in Table 1 to highlight these entries.
The result shows that the performance for IP-based meth-are therefore omitted here. ods is generally comparable to that for PRP. No consistent pattern is observed across all settings to assess one method is better than the others. Significant difference in either MAP or P@10 between IP-based methods and PRP is de-tected for 10 out of 54 experimental runs, among which IP-based methods are shown superior to PRP in 8 runs (de-noted as  X  in Table 1). PRP significantly outperforms only for short queries on TREC-8 at 30% and long queries on WT2G at 80% (denoted as  X  ), but the latter result is incon-sistent across performance measures.

It is interesting to note that TCP is generally doing slightly worse than the rest of methods in MAP but slightly better in P@10, which suggests that IP-based methods favor more on recall. This trend is observed across different corpora and T able 2: Correlation analysis for the decision mea-sures on the LATimes corpus. The correlation is estimated using Pearson X  X  product-moment correla-tion coefficient, weighted using term frequencies of index entries. experimental settings, and is more amplified in the short query case. Comparing IP-based methods with TCP in all 54 runs, we find that IP-based methods significantly out-perform TCP in 14 (denoted as N ), and TCP significantly outperforms IP-based methods in 6 (denoted as H ). The case we have observed for long queries on WT2G at 90% prune ratio is difficult to interpret: TCP performs signifi-cantly worse in MAP but does better in P@10.
Our experimental result gives rise to an interesting ques-tion that whether different pruning methods lead to different prioritization over index entries. To investigate the effect of pruning methods in this respect, we conducted a simple cor-relation analysis on the LATimes corpus. For each index entry, we retrieved the decision scores produced by all four algorithms and compiled them into a tuple. We collected totally 36,497,224 such tuples. For each pair of methods, we computed Pearson X  X  product-moment correlation coefficient, weighted using term frequencies of index entries.
The result, which is summarized in Table 2, shows that the decision scores produced by two IP-based methods are strongly correlated (0.998). In this case, we conclude that uniform prior is more favorable than hyperbolic-tangent ap-proximation in real-world settings, since the former is easier to compute. IP-based methods also show medium correla-tion (0.661 and 0.665) with TCP, slightly stronger than that (0.332) with PRP. We want to point out here that, since the decision score used in TCP corresponds to BM25, IP-based scores lean more toward BM25 in terms of the effect on in-dex entry prioritization. This can be useful in some other information retrieval applications.
In this paper, we develop the notion of information preser-vation in the context of static index pruning, and use this idea to motivate a new decision criterion. In the experi-ments conducted on three different test corpora, the pro-posed method shows consistent, competitive performance to state-of-the-art methods. So far, there is only minor evi-dence to interpret the performance differences between the proposed approach and the reference methods for specific cases. We expect this to be made clear with further experi-mentation.
 Our approach has a few advantages in terms of efficiency. First, term-centric pruning has an overhead in computing the cutting threshold for each term, since a sorting algo-rithm is involved to order the postings in terms of their im-pact values. Our decision measures do not suffer from this issue. Second, computation for the PRP measure depends on three different probability estimates, while the proposed IP-u measure (uniform prior) relies on only the query like-lihood. In our experiments, it took roughly 146 seconds for PRP to scan through all the entries in the TREC-8 corpus; IP-u did the same thing in only 126 seconds. We believe that this 20-second difference can be far more amplified on a Web-scale setting.

There are many ways to extend this work. One possible di-rection that we have in mind is to combine weakly-correlated measures, such as ours and PRP. Given the correlation anal-ysis result, we believe that doing so is feasible and can be beneficial. Moreover, this study also provides an alternative viewpoint toward prioritization of index entries. Impact and uncertainty are intrinsically two different concepts, while in this very application our result somehow closes the gap in between. This connection may lead to a new postulation for information retrieval. We hope that our efforts will invite further investigation into these interesting issues.
We thank the anonymous reviewers for their valuable com-ments. The research effort described in this paper is sup-ported under the National Taiwan University Digital Archives Project (Project No. NSC-98-2631-H-002-005), which is spon-sored by National Science Council, Taiwan. [1] R. Blanco and A. Barreiro. Static pruning of terms in [2] R. Blanco and A. Barreiro. Probabilistic static pruning [3] S. B  X  uttcher and C. L. A. Clarke. A document-centric [4] D. Carmel, D. Cohen, R. Fagin, E. Farchi, [5] S. Robertson. The probability ranking principle in IR. [6] L. Zheng and I. J. Cox. Entropy-Based static index
