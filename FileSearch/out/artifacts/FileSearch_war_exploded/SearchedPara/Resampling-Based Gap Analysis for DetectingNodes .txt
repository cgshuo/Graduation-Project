 that have been posted on social media because those topics can rapidly and widely spread through the networks. Thus, in recent years, social media plays an important role as information infrastructure, and social networks constructed on it have been extensively investigated from various angles [ 4 , 8 ]. a given network by using the node centrality [ 1 , 3 , 5 , 7 , 14 ], which characterizes nodes in the network based on its topology. Typical ones include the degree, closeness, and betweenness centralities. Some of them such as the degree cen-trality are based only on the information of neighboring nodes of a target node, but some others are also on global structure of a network. For example, to com-pute the betweenness centrality, we have to enumerate paths between arbitrary node pairs, which is computationally very expensive. Since a social network on the web can easily grow in size, it is crucial to efficiently compute values of such a centrality to analyze a large network.
 proposed so far [ 6 , 10 , 11 ], which investigate sampling methods that can obtain better approximations of true centrality values. Those methods are roughly cate-gorized into uniform sampling, non-uniform sampling, and traversal/walk-based sampling. In contrast to them, we proposed a framework that ensures the accu-racy of the approximations under uniform sampling [ 13 ], in which we estimated the approximation error referred to as resampling error by considering all pos-sible partial networks of a fixed size that are generated by resampling nodes according to a given coverage ratio and approximated centrality values derived from them. It is empirically shown that the resampling-based framework provides a tighter approximation error with a higher confidence level than the traditional standard error in statistics under a given sampling ratio.
 of nodes having a high centrality value only from approximations derived from sampled nodes with an adequate confidence level, instead of trying to accurately estimate the centrality value itself. We are interested in such nodes because they tend to play an important role for information diffusion on the network. To this end, we consider a list of nodes in descending order of the approximate centrality value, and devise an algorithm to efficiently detect gaps that exist between two adjacent nodes in the list. Here, we say a gap, or a boundary exists between two adjacent nodes in the list if it can divide the ordered list of nodes into two groups so that any node belonging to one group has a higher centrality value than any node in another group with a given confidence level. We incorporate confidence intervals of true centrality values for each node to detect such gaps, and adopt the above resampling-based estimation framework to estimate the confidence intervals as accurately as possible. The results of extensive experiments on three real world social networks demonstrate that using the resampling error for detecting gaps outperforms using the standard error in terms of the number of gaps detected, and that the resulting gaps allow us to correctly identify nodes having a high centrality value.
 N = L , but not SE ( N ). Note that the true standard deviation  X  is needed in both Equations ( 1 ) and ( 2 ), but in practice, we can use, instead of  X  ,the standard deviation  X  that is derived from a subset S (  X  S ) such that | S | = L is small enough to compute  X  within a reasonable time if | S | is too large to compute  X  , which is just the case where sampling is needed. 2.2 Application to Node Centrality Estimation Next, we present the way to apply the above estimation framework to node centrality estimation of a social network that is represented as a directed graph G =( V, E ), where V and E (  X  V  X  V ) are the sets of all the nodes and the links in the network, respectively. Here, we consider two node centrality measures, the closeness centrality and the betweenness centrality as in [ 13 ].
 where spl G ( u, v ) stands for the shortest path length from u to v in G ,andwe set spl G ( u, v )=  X  when node v is unreachable from node u on G . Intuitively, anode u has a high value for this closeness centrality if a large number of nodes are reachable from u within relatively short path lengths. A standard technique for computing cls G ( u )ofeachnode u  X  V is the burning algorithm [ 12 ] whose computational complexity is O ( | E | ). Thus, it takes a large amount of computation time for a huge social network consisting of millions of nodes. To apply the above estimation framework to the computation of an approximation of the closeness centrality cls G ( u )ofeachnode u  X  V , we instantiate the set of objects S and the function f to this problem. In fact, we consider S u = V \{ u } as the set S and f u ( v )=1 /spl G ( u, v ) as the function f , and thereby can calculate a partial average value cls G ( u ; T ) from an arbitrary subset T  X  S u  X  X  u } and its approximation error, RE ( u ; | T | )and SE ( u ; | T | ), according to the above framework.
 where nsp G ( v, w ) is the number of the shortest paths from v to w in G ,and nsp G ( v, w ; u ) is the number of the shortest paths from v to w that pass through node u . Thus, the betweenness of a node u becomes high if a large number of shortest paths between two nodes pass through node u . The Brandes algorithm [ 2 ] is a standard technique for computing btw G ( u )ofeachnode u  X  V and its computational complexity is O ( | E | ). Thus, it requires a large amount of com-putation time for a large social network, too. Again, we consider instantiating S and f of the above estimation framework for computing an approximation definitions, we can compute LB ( V H ( v ); T, X  )and UB ( V L ( v ); T, X  ) for every node v  X  V by making only one pass, each, through the list ( v tively, which implies that we can detect all gaps by making two passes through the ordered list. More specifically, in the first pass, referred to as the forward step, we compute LB ( V H ( v k ); T, X  )varying k from 1 to | V | X  1, and then, in the second pass called the backward step, we compute UB ( V L ( v k ); T, X  ) and detect computational complexity of this method is governed by that of its sorting pro-cess, and thus becomes O ( | V | log | V | ), which enables the practical gap analysis even for a large social network. The procedure is summarized as follows: 1. A  X  X  X  , LB ( V H ( v 1 ); T, X  )=  X  G ( v 1 ; T )  X  z (  X  )  X  ( v 1 ; | T | )), and 2. (Forward step) For k =2to | V | X  1, 3. (Backward step) For k = | V | X  1to2, 4. Output A , and terminate.
  X  ( v ; | T | )= RE ( v ; | T | ). We refer to these methods as the naive, SE ,and RE method, respectively. Note that the naive method assumes  X  G ( v ; T )=  X  G ( v ). Thus, it determines that there exists a gap between nodes v k and v k +1 for every k mates the approximation error of  X  G ( v ; T ) compared to RE ( v ; | T | ), the number of gaps detected by the SE method becomes less than that by the RE method. For more details, we empirically compare these methods through experiments on real world social networks as described below. 4.1 Datasets We empirically evaluated the three gap detection methods described in the pre-vious section on three datasets of real world networks that are represented as directed graphs. The first dataset is a network extracted from a Japanese blog service site  X  X meba X  1 , which has 56 , 604 nodes representing blogs in  X  X meba X  and 734 , 737 directed links among them. Each directed link is constructed from  X  and btw G ( u ; v ) / ( | V | X  2) for btw G ( u ). From these figures, we can observe that higher-ranked nodes in each centrality measure are distinguishable from each other in every network because of their distinctive values of the centrality, while it looks hard to do the same for lower-ranked nodes. This tendency can be found more clearly in the plots for the betweenness centrality in which nodes are scattered over a larger area. From these observations, we can expect that it is harder to detect gaps that exist between lower-ranked nodes compared to the ones between higher-ranked nodes and that more gaps can be detected for the betweenness centrality than for the closeness centrality. 4.2 Results We applied the naive, SE ,and RE methods to the three networks mentioned above for the closeness and betweenness centralities, and examined the number of gaps they detected and how many gaps among them were correct. A correct gap is the one that the resulting upper half set V H ( v k ; T ) corresponds exactly to the true upper half set that is a set of the top k nodes in the descending order of the true centrality value. In this experiment, we adopted the confidence level of 95% (  X  =0 . 05) as a typical one and fixed it, while we varied the coverage |
T | / | V | from 0 . 01 to 1 . 00 by 0 . 01 points to see how the number of gaps detected changes according to the coverage. More precisely, we randomly sampled nodes from V without replacement, added it to the subset T one by one, and counted the number of gaps detected and the number of gaps correctly detected each time the coverage increases by 0 . 01. Since we are interested in nodes having a high centrality value, we considered only the top K nodes in descending order of the estimated value of the corresponding centrality at each coverage. We repeated this process R =1 , 000 times and computed the average over them.
 The horizontal axis means the coverage, and the vertical axis means the number of gaps. The blue solid line and the red broken line represent the number of gaps detected and the number of gaps incorrectly detected by the corresponding method, respectively, which are defined as follows: where A ( c, r ) is the set of nodes corresponding to gaps, i.e., A in the algorithm in Section 3 detected by the respective method at coverage c in the r -th iteration, while A  X  ( c, r ) is the set of nodes correctly detected among them. It is noted that since some of the top K nodes may have the same estimation, these numbers comes from their nature that the resampling error RE ( v ; | T | ) converges to 0 as | T | approaches to | V | , while the standard error SE ( v ; | T | ) does not. These tendencies are also observed in the results for the betweenness centrality shown in Fig. 3 .
 limitation, we will show only the results for the Ameblo network here, but we observed the same tendencies for the others. Figures 4 and 5 show the results for the closeness centrality and for the betweenness centrality, respectively. From Figs. 4(a) and 5(a) , the number of gaps incorrectly detected by the naive method is relatively small compared to the results for K = 100 although it is still larger than the ones by the other methods that are almost 0 in this case, too. This is because the higher-ranked nodes in the true centrality value are distinguishable as shown in Fig. 1 . Due to the same reason, the number of gaps detected either by the SE or RE method is relatively large compared to the case of K = 100. It is more clearly found that the RE method can correctly detect more gaps than the SE method does at the same coverage by comparing Figs. 4(b) and 4(c) for the closeness centrality, and by comparing Figs. 5(b) and 5(c) for the betweenness centrality. Furthermore, as expected above, by comparing Figs. 4(b) and 5(b) , we can observe that the number of gaps detected by the SE method for the betweenness centrality is larger than that for the closeness centrality. The similar tendency can be observed for the RE method from Figs. 4(c) and 5(c) . On the other hand, we can observe from the results for K =1 , 000 that the number of gaps incorrectly detected by the naive method is relatively large, and the number of gaps detected by the other methods is relatively small, compared to the other results. This result demonstrates our expectation that it is harder to correctly detect gaps that exist between lower-ranked nodes.
 K . It can detect many gaps correctly for a small K , say 10, but it detects incorrect gaps if the coverage is low. This is not desirable as a means to reduce the computational cost for detecting nodes having a high centrality value. On the other hand, the SE and RE methods satisfactorily detect gaps correctly regardless of the value of coverage. The SE method is more conservative by overestimating the error margin and less useful than the RE method in terms of the number of gaps detected at the same coverage. Note that although the number of gaps detected by the RE method is limited for a low coverage, the resulting gaps are more likely to appear between nodes having a high centrality value, which is desirable for us to detect important nodes in a network. In this paper, we addressed a problem of identifying nodes having a high cen-trality value in a social network based only on its approximation derived from a limited number of sampled nodes. To this end, we focused on confidence intervals of true centrality value for each node, and considered detecting gaps that divide a set of nodes into two groups so that any node in one group has a higher central-ity value than any one in another does with a given confidence level. To estimate confidence intervals as accurately as possible, we employed the resampling-based framework for estimation of the approximation error, and devised an algorithm that can efficiently detect gaps whose computational complexity is O ( | V | log | V | ) for the number of nodes in a network, | V | , which is much less than O ( | V | 3 ) of the straightforward approach. Through extensive experiments on three real world social networks for the closeness and betweenness centralities, we empir-ically confirmed that the proposed method can correctly detect gaps that exist between high-ranked nodes with the confidence level of 95% even for a partial network whose coverage is small, say 0 . 2, and can detect more gaps compared to the one that uses the standard error to estimate confidence intervals at the same coverage ratio. Especially, the ratio of gaps incorrectly detected to the total number of detected gaps is almost 0 for both the methods. It is noted that the method we proposed is not only specific to identification of nodes having a high
