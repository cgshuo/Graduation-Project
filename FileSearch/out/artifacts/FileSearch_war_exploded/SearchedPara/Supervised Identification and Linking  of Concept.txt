 We propose a pipelined supervised learning approach named SDOI to the task of interlinking the concepts mentioned within a document to the concepts within an ontology . Concept mention identification is performed by training a sequential tagging model . candidate ontology concepts along with a feature vector based on features proposed in the literature and novel ones based on new algorithm is defined for handling collective features . We show a lift in performance over applicable baselines against the ability to identify the concept mentions within the 139 KDD-2009 conference paper abstracts , and to link these concept mentions to a domain-specific ontology for the field of data mining . Additional experiments of 22 ICDM-2009 abstracts suggest that their ability to reduce annotation time . H.3.3 [ Information Search and Retrieval ]: Information Systems  X  Information Storage and Retrieval . Algorithms, Experimentation. Concept mentions; Semantic Annot ation; Supervised Learning, Ontology; Collective Inference. The value that can be gained fro m the growing availability in both electronic documents and ontologies will increase significantly once these two resource types are deeply interlinked. Documents would behave more like hyperli nked webpages and would enable more navigational strategic readi ng, when required. IR searches on domain specific concepts such as  X  supervised approaches to concept mention linking X  could also be more effective than the current ad hoc approach of ever more finely tuned keyword-based searchers. Similarly, the use and development of ontologies will benefit seeing how a concept is used in natural language passages. An obstacle however to the vision of deeply interlinked information is the significant amount of manual effort required by both subtasks. 1 The task of annotating text with semantic information has been addressed by several research areas ranging from natural language processing (such as word sens e disambiguation [1] and named entity recognition [5]), information retrieval, and information extraction. Other related research arises from biomedical text mining [14], the extraction of technical terms to automatically create a book X  X  subject index [12], and automated population of database and ontologies [10]. Recently, some research has begun to investigate the more general task of identifying and linking of concept mentions to those concepts that are found in Wikipedia using supervised learning [4,8, and 9]. Some of this research also begins to explore the application on non-Wikipedia documents, such as news articles. Our proposed approach is to first train a sequential classifier to identify concept mentions that need not have been mentioned before in the corpus nor be present in the ontology. Next, SDOI identifies a set of candidate concepts for each mention based on heuristic candidacy rules that are more general than those currently proposed in order to expand the recall rate. For each candidate concept, an expanded set of features is defined in order to improve precision. We addre ss the procedural challenge of collective features with an iterative classification algorithm. The approach simplifies SDOI  X  X  reimplementation, naturally allows for the addition of more features, and enables the use of an off-the-shelf supervised binary classification algorithm. Assume that we are given a corpus of text documents d i  X  each document is composed of sentences based on sequences of tokens (orthographic words or punctuation). Assume also the existence of an ontology of interrelated concepts , o represent and describe some c oncept within some domain. The concepts are interconnected by directed edges referred to as internal links (  X  ) that link one concept to another concept, o ) . Each concept o c can be associated with: a preferred name , p , a set of (also-known-as) synonyms A c , and descriptive text t As described, an ontology is a directed and labeled multigraph that could be used to represent such diverse structures as Wikipedia (with its rich text and weak semantics) to the Gene Ontology (with its rich semantics and terse descriptions). Assume next that each document d i has a set of non-overlapping non-partitioning subsequences of tokens referred to as concept mentions , m m  X  d i , that refers to a domain specific meaning not This paper X  X  abstract illustrates the envisioned annotation. Its concept mentions are identified and linked to an ontology. generally found in a dictionary. We assume that the domain of the corpus overlaps the domain of the domain-specific ontology. Every concept mention m m is connected via a directed edge to meaning, or to the symbol  X  ?  X  that denotes the absence of the concept within the ontology. We refer to these edges as external because the concept is not yet deemed to be present in the ontology. We can refer to a mention X  X  token sequence as its anchor text , a m , to distinguish the text from the concept it links to. Given a document from the same domain as the ontology that lacks the concept mention information, the task is to identify each of the concept mentions w ithin the document: both their anchor text and their corresponding external link . To identify concept mentions in a document we train a sequence tagging model (using BIO tagging) in the same spirit as proposed recognition. These approaches use of the token and its part of speech (POS) role as features. For the POS information the use of an automated part-of-speech tagger (rather than manual annotation) is accepted practice. We include features also proposed for the named entity recognition task of: whether the special character and whether the token contains fewer than four characters. We use a five token window and test the unigram, bigram and trigrams that include the target token. A concept mention can be linked to any one of the many concept nodes in the ontology. However, knowledge of the mention X  X  anchor text can be used to significantly reduce the number of candidates for the assignment, w ithout discarding the correct node in the process. Table 1 presents four tests, each of which result in a set of accepted concepts and the overall heuristic returns the union of all accepted concepts. For a given anchor text a stemmed version) its candidate set is composed of zero or more distinct concepts from the ontology:  X  C m = {  X  , o c X  t t t t Given a candidate concept set for each mention, and given training examples that identify the correct concept link, the task of identifying the concept links in unseen documents can be accomplished by training a supervised binary classification produced. With possession of some disambiguated links to the ontology, the ontology can be used to provide some background knowledge into the classification decision for the remaining links. In order to replicate the work in [9] we include the relatedness measure they propose, which in tu rn is based on the Normalized Google Distance ( NGD ) metric [2] that assesses the dissimilarity between two sets. We extend this feature space by also including the components used in the calculation of NDG . We also include a Jaccard set similarity feature. Detailed feature definitions can be found in [7]. 
Table 2  X  Linking task training data structure. Each concept mention and candidate from the ontology is associated with a feature vector and a label based on whether it corresponds to Mention Concept The  X  X ollective-based X  features defined in Section 5.7 require that some portion of a document X  X  concept mentions be already linked to the ontology. We propose an incremental approach, as in classification algorithm inspired by the one proposed in [11]. Our algorithm first trains a model on an idealized context set, S all the correctly labeled mentions; then, during the testing phase, proportion of the most likely predictions. Because our collective features all zeroed (0) initially, we enhance the approach of [11] by first training a model on all but the collective features to seed the first guesses with informed choices. Assume that we define a The algorithm used is as follows: 1. Train model ( M col ) without the collective features 2. Train a model ( M col ) with the collective features 3. For each iteration of  X  from 1 to  X  4. Output the final set of predictions on all mentions.
 concept/link per candidate set. Th e classifier however may assign the label of  X  X rue X  to more than one concept associated to a mention. SDOI uses the likelihood score reported by the supervised classifier to select the more likely concept. SDOI is evaluated on the publicly available 2 kdd09cma1 corpus whose concept mentions have been identified and linked to the kddo1 ontology [6]. We further test the portability of the model trained on the above data to identify and link concepts mentions from abstracts of a separate conference track: IEEE X  X  ICDM 2009 conference. We compare performance against baseline algorithms for each of the subtasks. For the mention iden tification task our baseline is a dictionary based algorithm ( dict ) that selects the longest sequence of tokens that matches a concep t X  X  preferred name or synonym. We reimplement the supervised a pproach proposed in [9] as the main baseline algorithm for the linking task. For the joint task of identification and linking, both the baseline and the proposed SDOI algorithm simply direct the output of their identification algorithm (the predicted anchor text for the concept mentions) as input to their linking algorithm. The performance of the sequential model-based algorithm on the mention identification task was evaluated on the kdd09cma1 performance trends for different training set sizes. We also present performance on exact and partial matches of anchor text; where a partial match is defined as starting on the correct token but ending on a different token. SDOI outperform the dictionary-based baseline due to its sequential model X  X  ability to identify mentions not in the nascent ontology. The learning curve suggests that human expert-level performance could be attained with two orders of more data (and that advanced feature engineering may not lead to significant improvements). Finally, there is a significant effect when a partial match criteria is applied on multi-word mentions. When these mismatches occur the algorithm is doubly penalized for making two false predictions and for missing one true prediction; while with partial matches, the algorithm achieves one correct prediction and one false prediction. We first determine the compositi on of the candidacy heuristic defined in Section 3 (primary and stemmed) by incrementally t t significantly decreases accuracy, likely because the average number of training cases per mention increases from approximately 2.5 to 47 cases per mention on average. http://www.gabormelli.co m/Projects/kdd/data/ We use CONLL-2000 X  X  conlleval.pl evaluation script. 
Figure 1 Log-scale learning curve analysis of SDOI  X  X  and the baseline X  X  F1 performance on the kdd09cma1 dataset under To estimate algorithm performance we performed a leave-one-out cross-validation study. Specifically, we iterated through all 139 documents, leaving one document out of the training corpus and testing on all the mentions with in the excluded document. The CRF++ 4 package was used to generate the sequential tagging model used in the identification task. SVMlight 5 was used as the classification model training system used for the linking task. The number of iterations for the iterativ e classifier was set to five (  X  =5). Table 11 reports performan ce against the Milne &amp; Witten, 2008) algorithm on. On true anchor texts SDOI performed much better at linking concept mentions to the ontology than the baseline. This is likely due to the additional features and the expanded definition of candidacy. On predicted anchor texts SDOI performed significantly better than the baseline because of the cumulative effects of performance on mention identification and linking. For many mentions the baseline algorithm could not make a link prediction because it had failed to identify them in the identification task. 
Table 3  X  Accuracy of the SDOI and baseline algorithms on the linking subtask applied to the kdd09cma1 corpus when To assess the portability of the models trained on kdd09cma1 we tested the models on a corpus ( icdm09cma1 ) composed of twenty two manually annotated abstracts from the papers accepted into IEEE X  X  annual conference on data mining in 2009 http://crfpp.sourceforge.net/ http://svmlight.joachims.org/ (ICDM X 09) 6 . Seven domain experts we re asked to annotated using the following four-step procedure: 1) read the abstract on the official IEEE webpage for the paper, 2) identify and annotate concept mentions without referencing the ontology, 3) link mentions to their first best guess of the concepts preferred name in the ontology, and 4) revise their annotations based on active search of the ontology. an ontology. Our main contributions are the ability to identify mentions not yet present in the ontology, proposing a set of tests for selecting candidate concepts , and proposing a formalized and expanded feature set. We plan to expand the corpus to include all past and future KDD and ICDM conference abstracts, and to expand the data mining ontology to include many of the main concepts and relationships discovered in the process. Ideally we would like to integrate SDOI into the submission process of future data mining conferences in order to have the authors themselves validate and correct the pre-annotated versions of their abstracts. Performance on the second corpus -reported in Table 4 -is only slightly lower than those reported in the second row of Table 3 ; suggesting that the trained models are portable to other corpora. abstracts, where matches are exact or partial (correct start). [1] Satanjeev Banerjee, and Ted Pedersen. (2002). An Adapted [3] Eugene Charniak. (2000). A Maximum-Entropy-Inspired [4] Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and As reported in Table 5 , on average, 70% of each person X  X  annotations are identical to the ground truth -suggesting annotation subjectivity but also significant room for improvement from SDIO  X  X  current accuracy of 45.4%. [5] A. McCallum, and W. Li. ( 2003). Early Results for Named Table 5  X  Average accuracy of the annotator X  X  abstract versus the consolidated  X  X old X  annotation. The second row accounts for the annotator X  X   X  X earning curve X  by excluding the first [6] Gabor Melli. (2010a). "Concept Mentions within KDD-2009 [7] Gabor Melli. (2010b). Supervised Document to Ontology [8] Rada Mihalcea, and A. Csomai. (2007). Wikify!: Linking Table 6 analyses whether an annotator worked faster from a document with annotations predicted by SDOI instead of an unprocessed document or from baseline predictions. On average, annotators required significantly less time on all three phases when abstracts were pre-annotated using SDOI  X  X  output. The result suggests that SDOI can deliver real-world value on some tasks. To the best of our knowle dge, this type of time-savings evaluation has not been performed to date on a related task. [9] David N. Milne, and Ian H. Witten. (2008). Learning to Link [10] Roberto Navigli, Paola Vela rdi, and Aldo Gangemi. (2003). [11] Jennifer Neville, and David Jensen. (2000). Iterative 
Table 6  X  Average seconds required to annotate each unique [13] Fei Sha, and Fernando Pereira. (2003). Shallow Parsing with [14] P. Zweigenbaum, D. Demner-F ushman, H. Yu, and K. B. In this paper we present a supervised learning based algorithm, SDOI , for the task of identifying and linking concept mentions to http://ieeexplore.ieee.org/xpl/mos tRecentIssue.jsp?reload=true&amp; punumber=5360037 
