 1. Introduction
With the emergence and proliferation of Internet services and e-commerce applications, organizations and individuals typically generate, gather, and maintain a tremendous amount of textual documents. To facilitate their subsequent access to these documents, use of categories to manage this ever-increasing volume of documents is often observed at both orga-ular category (or categories) to which a new document belongs. In addition to its document management applications (i.e., automatically organizing documents into categories) that facilitate users X  browsing through a set of related documents  X  web pages ( Ntoulas, Najork, Manasse, &amp; Fetterly, 2006 ).
 and the category assignment (or prediction) of new documents. However, as a result of the globalization of business envi-ronments and advances in Internet technology, an organization or individual often generates or acquires, and subsequently uments. This existing set of categorized documents can serve as training documents for constructing a text categorization model with respect to language L 1 . However, the branch may receive from other branches documents written in different language L 2 . To archive these newly received documents into the existing categories, the branch faces the challenge of
L according to the text categorization model induced from the set of categorized documents in L ments written in one language ( L 1 ) and classifying new documents in a different language ( L lenges encountered by these two types of multilingual text categorization, CLTC generally presents a more challenging research issue because of the language barrier between training and unclassified documents.
This study is motivated by the importance and challenge of providing CLTC support to organizations and individuals in the increasingly globalized environment. Specifically, we propose a CLTC technique on the basis of a statistical-based the effectiveness of the proposed CLTC technique using monolingual text categorization as a performance reference. The ing monolingual and CLTC techniques and cross-lingual information retrieval (CLIR). We depict the detailed development of mary, discussion of our research contributions, and some future research directions in Section 5 . 2. Literature review
In this section, we review literature related to this research, including monolingual text categorization techniques and approach for conquering the language boundaries faced by CLTC. 2.1. Monolingual text categorization techniques uments and the subsequent assignment of unclassified documents to one or more predefined categories on the basis of the induced text categorization model. Formally, on the basis of a set of n preclassified training documents of the form {( d y ), ... ,( d n , y n )}, where d i e D (a domain of documents) and y model learning is to seek a function (i.e., text categorization model) / : D category assignments (or prediction) of new documents. Broadly, the learning of a (monolingual) text categorization model is comprised of three main phases: feature extraction and selection, document representation, and induction ( Apte, Damerau, &amp; Weiss, 1994; Wei &amp; Lee, 2004 ).

The feature extraction and selection phase extracts and selects from the training documents one or multiple feature sets approach is employed, feature extraction simply identifies all words appearing in the training documents as  X  X  X eatures. X  each training document to produce a list of terms (features) with the selected syntactic classes. Subsequently, stop-word selection. Common examples include TF (term frequency), TF IDF (term frequency inverse document frequency), corre-Hull, &amp; Pedersen, 1995 ).

In the document representation phase, each training document is represented using the features in the dictionary or dic-ence or absence of a feature in a document), within-document TF, and TF IDF.

The induction phase is designed to induce a text categorization model automatically that distinguishes categories from one another on the basis of the set of training documents. Common learning techniques employed for text categorization tions of different learning techniques for text categorization. 2.2. Cross-lingual text categorization (CLTC) techniques
Existing text categorization research mainly concentrates on classifying monolingual documents and only few prior stud-first selects the best k (e.g., 40 X 150) terms per category from a set of preclassified documents in language L sifier is employed to assign each translated Czech document (now in English) to an appropriate category based on the nique that uses a machine translation system for translating between English and Italian documents and subsequently ex-ploits the expectation X  X aximization (EM) algorithm for text categorization. Gliozzo and Strapparava (2006) exploit the occurrences of common words in English and Italian (i.e., identical words used by the two languages) and the availability of English X  X talian dictionaries (i.e., MultiWordNet 1 and Collins unclassified documents in Italian (or English).

The existing CLTC techniques involve only European languages (English, Spanish, Italian, and Czech). Crossing language boundaries between closely related European languages (e.g., English X  X panish and French X  X talian) appears to be less com-plicated than crossing language boundaries between European languages and Oriental languages, due to the lexical and sified document into another language singly. However, the effectiveness of such individual-based method for translation and category assignment may suffer from the word mismatch and the out-of-vocabulary (OOV) problem. Thus, besides the individual-based method, we will propose a cluster-based method in our CLTC technique. 2.3. Cross-lingual information retrieval (CLIR) ically, documents are manually indexed using a predetermined vocabulary, and queries from users use terms drawn from the
The free text approach in CLIR attempts to cross the language barrier through some form of translation. Common trans-lation approaches employed by existing CLIR techniques include dictionary-based, machine translation, and corpus-based in its vocabulary and phrases. For example, abbreviations, technical terms, and names of persons, corporations, or events may not appear in the dictionary, nor might new or slang terms.

Machine translation has also been widely investigated in CLIR. In the Cross-Language Evaluation Forum (CLEF) work-shops 3 and the NII Text Collection for Information Retrieval (NTCIR) workshops, new machine translation techniques to decode the meaning of a source text and encode the meaning in a target language or tive to deal with novel terms, technical terms, and proper nouns.

The corpus-based method resolves the problems of the dictionary-based and the machine translation approaches by mak-based bilingual thesaurus. The parallel corpus contains a set of parallel documents prepared in two (or more) languages extended by expanding the number and coverage of parallel documents. In addition, prior empirical evaluations show that
Luk, 2003 ). Although the corpus-based method overcomes the limitations of the dictionary-based and the machine transla-to conquer the language boundaries faced by CLTC. 3. Design of a cross-lingual text categorization technique matically. For the categorization learning task, we employ the preclassified documents in language L gual text categorization model in L 1 . Finally, when new documents in L new documents from L 2 to L 1 ) and employs the text categorization model in L appropriate categories. In the following subsections, we depict each task involved in our proposed technique. 3.1. Bilingual thesaurus construction document in the corpus. Because our study concentrates on categorizing documents according to their subjects (topics), we only consider nouns and noun phrases since they typically represent domain concepts that characterize topics, whereas adjectives, verbs, and adverbs describe concept properties and actions among domain concepts and thus are not included.
However, it is worth noting that our feature extraction method can easily be extended to include terms of other syntactic classes.
 To extract nouns and noun phrases in the parallel corpus, we adopt the rule-based part-of-speech tagger developed by employ the approach proposed by Voutilainen (1993) to implement a noun phrase parser and extract noun phrases from each syntactically tagged English document. For the Chinese documents in the parallel corpus, we employ a hybrid approach &amp; Li, 2005b ).

Following extraction, the term selection process selects representative terms in both languages for each parallel docu-ment in the corpus. In this study, we adopt the TF IDF-based scheme proposed by Yang and Luk (2003) as the selection metric. Specifically, the term weight of a term f j (English or Chinese) in an English/Chinese parallel document d as follows: where tw ij is the term weight of f j in d i , tf ij is the term frequency of f corpus, df j is the number of parallel documents in which f denotes the number of English words if f j is an English term and the number of Chinese characters if f specific than  X  X  X nformation retrieval X  (whose length is 2). Thus, the incorporation of l sign a higher weight to a more specific term.

For each parallel document in the corpus, the k clt English and k that simultaneously occur in more than d DF documents are selected as inputs for the subsequent cooccurrence analysis. On cooccurrence analysis first measures the co-importance weight cw parallel document d i , as follows: where tf ijh is the minimum of tf ij and tf ih in d i , and df
Finally, the relevance weights between the English term f follows: where rw jh denotes the relevance weight from f j to f h and rw language to another term in the other language is less than a relevance threshold d ature dataset collected for our evaluation study (which we will describe in Section 4 ). As illustrated, the term  X  X  database in Chinese) has a higher weight (0.95) with the term  X  X  X atabase X  but a lower weight (0.66) with the term  X  X  X ata warehouse. X  The term  X  X  X ata mining X  can be translated into  X  X  higher than that for other translations. 3.2. Categorization learning
Fig. 3 illustrates, the categorization learning task starts by extracting and selecting, from the training documents in L global feature set. As with the bilingual thesaurus construction task, if the training documents are in English (i.e., L nouns and noun phrases (features) for each English document. However, if L nary-based and statistical approaches to extract Chinese terms for each document in the training corpus. Subsequently, feature selection).

In the document representation phase, using the TF IDF representation scheme, each training document is represented niques to induce a text categorization model from the preclassified documents in L nique is made mainly because of its stability when only a small-size set of training examples is available, its learning
In essence, the Na X ve Bayes classification approach uses the joint probabilities of words and categories to estimate the given that category. The Na X ve Bayes approach estimates the posterior probability of category C (i.e., p ( C i | d )) using the Bayes rule, as follows: where p ( C i ) is the probability that category C i occurs, p ( d ) is the probability that d occurs, and p ( d | C ability that d occurs given C i . p ( C i ) can be estimated as the number of documents in category C probability p ( d ) can be ignored when estimating p ( C i bility of the categories can be used to determine the category assignment for document d . Moreover, assuming the word independence assumption, the probability p ( d|C i ) can be derived as follows: where f j represents a feature in d .

We then adopt the maximum likelihood estimate, smoothed by Lidstone X  X  law of succession, to estimate p ( f et al., 2000 ). For k P 0, p ( f j | C i ) is estimated as follows: where freq ( C i , f j ) is the number of occurrences of f across categories. 3.3. Category assignment
In the category assignment task, we classify unclassified documents in L deal with the language difference between unclassified documents (in L two category assignment methods, namely, individual-and cluster-based, whose details are depicted in the following subsections. 3.3.1. Individual-based category assignment method
The individual-based category assignment method, as shown in Fig. 4 , directly translates representative terms of each sified document on the basis of the TF IDF selection metric. Similarly, the TF IDF scheme is adopted for document rep-resentation, and all unclassified documents are represented by the representative features in L
The feature translation phase translates the feature vector of each unclassified document d ously constructed bilingual thesaurus. Specifically, in the statistical-based bilingual thesaurus, for each term e to one or more features in d i , we estimate its weight for d thesaurus) from each feature f j in d i to e h , weighted by the TF IDF value of f where aw ih is the estimated weight of the translated term e weight from f j to e h as defined in Formula (3) , and m is the number of features in d feature e h in the statistical-based bilingual thesaurus.

Assume that the unclassified document d i in L 2 contains five features, f w is associated with f 1 and f 2 , the term e 3 is associated with f ingly, the estimated weight of the translated term e 1 for d and the weight of e 2 need not be calculated because it is not related to any features in d
After the weight of each translated term is derived for d terms whose weight (i.e., aw ih ) is no less than a prespecified threshold d
Fig. 5 for illustration. If we set d aw as 0.8, the translated term e than the threshold. In this case, only e 3 will be retained in the translated feature set for d e document given in Fig. 6 a. The document shows the abstract and keywords of a research article about a data mining ap-proach to discover association rules from Web logs (organized as a data warehouse) for improving the efficiency of proxy servers. Fig. 6 b indicates the 20 representative features with the highest TF IDF values from that document. Finally,
Fig. 6 b and Eq. (7) .As Fig. 6 c illustrates,  X  X  X eb log X  (Web nique X  (  X   X   X   X   X   X  ),  X  X  X ata warehouse X  (  X   X   X   X  ),  X  X  X ssociation rule X  ( generated after feature translation.

The completion of the feature translation phase generates a feature vector in L category for the document on the basis of the text categorization model (in L task. 3.3.2. Cluster-based category assignment method The individual-based category assignment method translates each unclassified document into a different language singly.
However, due to the word mismatch problem, the effectiveness of the feature translation and the subsequent classification by the individual-based method may degrade. In response, we propose a cluster-based category assignment method (as similarities of their features in the original language (i.e., L lation and category prediction.
 tion as well as document representation) form a feature vector in L ward, the clustering phase groups similar documents into distinct clusters. Let the feature vectors of documents d their original language be ~ d i and ~ d j . The similarity between d follows: where k ~ d i k is the Euclidean norm of the vector ~ d i Common document clustering approaches include partitioning-based ( Boley et al., 1999; Cutting, Karger, Pedersen, &amp; based approach because the number of clusters need not be prespecified and can be decreased (increased) by simply moving up (down) the resultant clustering hierarchy. Furthermore, the hierarchical approach can achieve comparable clustering approach (specifically, the hierarchical agglomerative clustering, HAC, algorithm) for clustering documents and employ ity among all intercluster pairs of documents is the highest will be joined first. Furthermore, we use a user-specified of HAC, if the similarity between the two most similar clusters is less than a as the clustering result, those clusters that are not children of any other clusters.

We then generate the feature vector for each cluster by averaging the feature vectors of all individual documents in the in L 1 ) of each cluster is employed to determine an appropriate category for all unclassified documents in the cluster on the basis of the text categorization model (in L 1 ) induced during the categorization learning task. 4. Empirical evaluation
In this section, we report on our empirical evaluation of the proposed CLTC technique, using monolingual (only L our empirical evaluation. 4.1. Data collection Chinese (or Chinese for short) for constructing a statistical-based bilingual thesaurus and two monolingual (English and Chinese, respectively), precategorized document corpora for evaluating the effectiveness of our proposed CLTC technique. management information systems departments in major universities in Taiwan between 1992 and 2003. The English corpus knowledge management, and wireless network) from 1994 to 2004. The Chinese corpus, also related to the six categories words for our evaluation purpose.
 The News Press dataset is collected from Government Information Center, Hong Kong Special Administrative Region of of Chinese and English news presses, whereas the English and Chinese corpora consist of 278 news presses respectively
Table 3 details the distributions of documents in each dataset. 4.2. Evaluation procedure and criteria ping cross-validation approach. For monolingual text categorization, because training and testing documents need to be in the same language, we randomly select 80% of the documents in the L ing set and the remaining 20% of the L 1 documents as the testing set. For CLTC, because training and testing documents should be in different languages, we therefore randomly select 80% of the documents in the L of each dataset as the training set and 80% of the documents in the L by averaging the effectiveness obtained from these 30 individual train-and-test trials.
 cation accuracy, which we define as the percentage of documents in the testing set that the text categorization technique under investigation correctly classifies into the predefined categories. 4.3. Parameter-tuning experiments and results 4.3.1. Monolingual text categorization
As we depicted previously, the Na X ve Bayes classifier, our underlying classification method, involves two parameters: k (number of features) and k (for smoothing the maximum likelihood estimate). According to our preliminary experiment re-monolingual text categorizations for the Literature dataset exceeds 95% and 80%, respectively, whereas that for the News the Chinese corpus. Thus, we adopt these values for the respective monolingual text categorizations. 4.3.2. Cross-lingual text categorization
The first parameter-tuning task required by the proposed CLTC technique is to determine appropriate parameter values parallel document, the selected terms must satisfy the document frequency threshold d in at least d DF documents in the parallel corpus) and be the top k isfy a prespecified relevance threshold d rw . Our preliminary evaluation results suggest that setting d to 0.15 is appropriate. Thus, we adopt these values for our subsequent experiments. Table 4 shows a summary of terms (in of English terms included in the respective bilingual thesaurus are between 1 and 3 words, whereas most of Chinese terms are between 2 and 4 Chinese characters. 4.3.2.1. CLTC with individual-based category assignment method. The parameters involved in the proposed CLTC technique with the individual-based category assignment method include k and k (required by the Na X ve Bayes classifier), as well as d (required by the feature translation phase). Similar to the monolingual text categorization experiments, we use all fea-documents (denoted as Chinese ? English) and classifying English documents using a text categorization model induced from Chinese training documents (denoted as English ? Chinese). Fig. 9 shows the classification accuracy of the individ-and d aw (note that to reduce the complexity of the figure, we show only a subset of values for d accuracy ranges between 30% and 75%, and the effects of k appear less significant than those of d classification accuracy of the individual-based CLTC technique increases initially but gradually deteriorates when d sification accuracy. On the contrary, a higher threshold for d tiveness (i.e., 73.88%) of the individual-based method for the Chinese achieved when k equals 0.3 and d aw equals 1.2.

Similar patterns are also observed in the Chinese ? English scenario for the News Press dataset. The effects of k appear less significant than those of d aw . However, an increase of d best classification effectiveness (i.e., 62.91%) is achieved when k equals 0.7 and d
We investigate the same ranges of parameter values in the English wise, k and d aw also have similar effects on classification accuracy in the English effectiveness for the News Press dataset (i.e., 61.27%). category assignment method, the cluster-based method requires, during the clustering phase, two additional parameters: feature size k cs (a global feature set representing the target documents in L termination condition of the merging process in HAC). We adopt the values selected previously for those parameters com-mon to the individual-based method and investigate values of k in increments of 0.05.

Fig. 11 shows the classification accuracy of the cluster-based CLTC technique in the Chinese
Literature dataset across all value combinations for k cs and 75%. When a s is greater than 0.4, the classification accuracy is nearly invariable across the range of k
However, when a s decreases to less than 0.4, the classification accuracy declines rapidly for any level of k contains a larger number of documents. Consequently, the chance that the documents in a large-size cluster pertaining to different categories increases. Because the cluster-based method assigns all of the documents in a cluster into the same category, the classification accuracy of large-size clusters will be undermined. Among all parameter value combinations, the Literature dataset) are grouped into 320 clusters.
Fig. 12 shows the classification accuracy of the cluster-based CLTC technique in the Chinese highest classification accuracy (i.e., 63.81%) in the Chinese into 190 clusters).

Fig. 13 depicts the resulting classification accuracy, which ranges between 55% and 77%, of the cluster-based CLTC tech-nique in the English ? Chinese scenario for the Literature dataset. Fig. 13 shows that, as a cation accuracy gradually improves, which also demonstrates the positive effect of document grouping on CLTC. However, when a s decreases from 0.25 to 0.2, the classification accuracy drops dramatically at any level of k and k cs is 1200, the CLTC technique achieves the highest classification accuracy (i.e., 75.44%) in the English scenario. Specifically, the cluster-based method groups the 392 English documents (i.e., 80% of the English corpus in the
Literature dataset) into 110 clusters. We observe similar effects of a the highest classification accuracy at 67.13% when a s is 0.35 and k each technique in various scenarios for the two datasets. 4.4. Comparative evaluations
In this subsection, we compare the effectiveness of the two category assignment methods of our proposed CLTC technique in two different scenarios (i.e., Chinese ? English and English categorization as a performance reference. As we summarize in Table 6 a, the classification accuracy of the monolingual rization. Moreover, for the Literature dataset, the cluster-based method outperforms the individual-based method in the than that achieved by the individual-based method in this particular scenario ( p &lt; 0.001). based method also outperforms the individual-based one in the Chinese cluster-based method is significantly higher than that achieved by the individual-based method ( p &lt; 0.05).
As we summarize in Table 7 a, the classification accuracy of the monolingual (Chinese) text categorization is 91.85% for the Literature dataset and 79.94% for the News Press dataset. As with the Chinese nor the cluster-based method in the English ? Chinese scenario for both datasets achieves the effectiveness level of the monolingual text categorization. However, the performance gaps between the proposed CLTC technique and the perfor-mance reference (i.e., monolingual text categorization) are similar in both scenarios (i.e., Chinese
English ? Chinese) for each dataset. The classification accuracy achieved by the individual-based method is 68.49% (for the Literature dataset) and 61.27% (for the News Press dataset), approximately 23.4% and 18.7% less than the respective monolingual (Chinese) text categorization. The classification accuracy of the cluster-based method is 75.44% and 67.13% for the Literature and News Press datasets respectively, which is 16.41% and 12.81% less than the respective monolingual (Chinese) text categorization. As previously, the cluster-based method appears to outperform the individual-based method significantly higher than that achieved by the individual-based method ( p &lt; 0.001) for each respective dataset.
Subsequently, we assess the sensitivity of the two category assignment methods of our proposed CLTC technique to the train-and-test process 30 times and evaluate the effectiveness of each category assignment method by averaging the clas-sification accuracy obtained from these 30 individual train-and-test trials. As Table 8 a shows, for the Chinese 4.74% (from 61.27% to 56.53%) for the News Press dataset. Although the effectiveness of the cluster-based method deterio-rates more rapidly in this case, the cluster-based method generally remains more effective than the individual-based method. However, as the training size of each dataset further decreases to 40%, the classification accuracy achieved by the individual-based method (i.e., 67.06% for the Literature dataset and 45.93% for the News Press dataset) appears to be ing the classification accuracy when the effectiveness of the individual-based method is satisfactory (as shown when the vidual-based method when given a larger training set. 5. Conclusion and future research directions
With the globalization of business environments and advances in Internet technology, organizations and individuals often classifies new (unclassified) documents in different language (e.g., L posed in the literature; however, most of them deal with monolingual documents. In response, we propose a CLTC technique with two different category assignment methods, namely, individual-and cluster-based. Specifically, the individual-based method translates representative terms of each unclassified document in language L ginal language (i.e., L 2 ) and subsequently translates the representative terms of each document cluster into L tistical-based bilingual thesaurus. Compared with monolingual text categorization, our empirical evaluation results based method in both Chinese ? English and English ? Chinese scenarios for the two datasets (i.e., Literature and News Press).

Some additional research extending this study might include the following: First, our current evaluation study employs technique using other document corpora that pertain to more diversified domains (e.g., web pages, patent documents, study focuses on a best-scenario vs. best-scenario comparison between the two category assignment methods of our pro-posed CLTC technique and does not address issues pertaining to parameter value decisions. Thus, developing an intelligent opment and evaluation of a training corpus translation-based CLTC technique that translates the preclassified training documents is currently underway. Fourth, in this study, we focus only on the feature-based CLTC approach. Therefore, the lingual document management issues (e.g., multilingual document clustering, multilingual event detection, cross-lingual question and answering) demand further research attention.
 Acknowledgments This work was supported in part by the National Science Council of the Republic of China under the Grants NSC 93-2416-H-110-021 and NSC 94-2416-H-110-002.
 References
