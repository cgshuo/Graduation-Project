 Every user has a distinct context and a specific background when searching for information. The goal of contextual information retrieval (CIR) is to tailor search results to a particular user according t o his/her specific context and preferences [1]. This implies the need to go beyond the topical relevance assessment to a multi-dimensional relevance assessment, where the considered relevance dimen-sions encompass besides the topical rel evance, some contextual relevance [2].
We are specifically interested in the emerging mobile IR field, where mobile users X  queries are known to be sensitive to several interdependent contextual criteria (e.g., users X  interests, location, time) and where users can be differently interested in each context criterion depe nding on their information needs [3]. For example, let us consider the query  X  cultural event.  X  Document relevancy of this query may depend on a user X  X  implicit interest  X  jazz events  X  and location  X  in Paris.  X 
Traditionally, IR algorithms have been evaluated primarily at a system level with little reference to the user. This discrepancy has led to criticism of the IR community for relying on relevance criteria that are solely objective, consid-ering only the relationship between a r etrieved document and the query with respect to a topical perspective, rather th an considering subjective dimensions of relevance related to the person whose individual information needs led to the query being conducted [2]. Several researchers [9,10] have thus argued for the multidimensional nature of the concept o f relevance. Mizzaro [10], for example, proposed a relevance model in which relevance is represented as a four dimen-sional relationship between an information resource and a representation of the user X  X  problem. A further judgment is made according to the topic, task, or con-text, at a particular point in time. Th ese dimensions pointed out by Mizzaro were extended by Coppola et al. [11] in an attempt to define the concept of relevance in mobile IR settings. The authors argued for the necessity to move the notion of relevance into the  X  X eal/physical world X  so that it will be closer to what users want and need.

Multidimensional personalization approaches that include aspects of the mo-bile user X  X  contextual environment hav e then been proposed. For instance, au-thors in [12,5] integrated users X  interes ts as a second criterion besides the topical relevance, to personalize search resul ts. Given the importance of location for mobile users, other works have integrated the user X  X  location as a criterion to select or to rank the retrieved search resu lts according to their spatial distance from the user X  X  location [13,6,14]. Some works attempt to go besides the location context, and also handle time context [15,16] or social context [4,17]. The main limitations of the aforementioned works is that these new personalization dimen-sions are considered as filters or are combined in a linear model independently of users X  preferences over the relevance dimensions. None of these works has at-tempted to formulate a functional relationship between the combined criteria and the user X  X  perception of relevance in a multi-criteria setting. An interesting research direction related to persona lized search is to make the user an actor in determining such an aggregation model.

The contribution of this paper is twofold. First, we propose a multidimensional ranking model based on the three dimensi ons of topic, interest, and location. The multidimensional rank has the peculiarity of exploiting some  X  X rioritized aggregation operator X  [7,8] allowing a flexible personalization of search results according to users X  preferences. In this way, for a same query and a same user, different document rankings can be computed based on the user X  X  preference over the different relevance criteria. The proposed prioritization is modeled by making the weights associated with a criterion dependent upon the satisfaction of the higher-priority criteria. Hence, it is possible to take into account the fact that the weight of a less important criterion should be proportional to the satisfaction degree of more important criteria. This combination has the merit of being user-dependent, by allowing the user to express his/her preference order on the considered criteria. To illustrate this, let us come back to our introductory example query  X  cultural event , X  depending on user X  X  preferences, we can imagine a scenario in which the user, who does not want to move, will favor document about any cultural event in  X  Paris , X  independently of being a  X  jazz event , X  and dismiss documents about  X  jazz events  X  X hatareoutside X  Paris. X  In another scenario, the user may favor documents about his/her interest in  X  jazz events  X  although the event location is different from  X  Paris.  X  Second, in the absence of a standard evalua tion collection suited to evaluate an IR system which is user-dependent, we propose to build a simulated user-centered evaluation framework in order to test the effects of the prioritized aggregation operators on the final system performance in comparison with a standard linear combination approach.

The paper is organized as follows. Sectio n 2 presents the prioritized multi-criteria aggregation backg round. Section 3 presents ou r multidimensional rele-vance ranking model. In section 4, we present our simulation-based framework to evaluate our approach and discuss the obtained results. In the last section, we conclude and outline future work. The problem of prioritized aggregation is typical in situations when one wants to model a relationship between multiple criteria. In such a case, the lack of satisfaction of a higher priority criterion cannot be compensated with the sat-isfaction of a lower priority criterion. In this section we apply the approach proposed in [7,8] for a priority-based aggregation of distinct relevance assess-ments. In sect. 2.1 the problem representa tion is introduced as a multi-criteria decision making problem where the possible alternatives are the documents in the considered document collection. In sect. 2.2 the priority-based aggregation operators  X  X rioritized scoring X  and  X  X rioritized and X  are described. 2.1 Problem Representation Let us consider a decision making setting in which we have the following com-ponents:  X  The set C of the considered criteria: C = { C 1 ,...,C n } . In order to simplify  X  The collection of documents D .  X  The C j ( d ) satisfaction score (of document d with respect to relevance crite- X  An aggregation function F to calculate for each document d  X  D an overall For each criterion C i  X  C , an importance weight is computed in a way that is both document and user-dependent. In fact, the weight computation depends both on the preference order expressed by the user over the criteria, and also on both the weight computed for criterion C i  X  1 (of greater priority with respect to C i ), and the satisfaction degree of the document with respect to C i  X  1 .In other words, for a considered document d , for each criterion C i an importance weight  X  i  X  [0 , 1] is computed, which varies in a ccordance with the considered documents. The weights associated with th e ordered criteria (criteria are ordered by users on the basis of their preferences), are computed as follows:  X  For each document d , the weight of the most important criterion C 1 is set  X  The weights of the other criteria C i for i  X  [2 ,n ] are calculated as follows: What is changing in this aggregation model is the way in which function F is defined, as is explained in the next section. 2.2 Prioritized Aggregation Operators In this section we present two alternative formalizations of the proposed priori-tized aggregation operator F :  X  X rioritized scoring X  and  X  X rioritized and. X   X  Prioritized  X  X coring X  ( F s ) . This operator allows to calculate the overall  X  Prioritized  X  X nd X  ( F a ) . The peculiarity of such an operator, which also In this paper, we apply the proposed prioritized relevance model as a ranking model within personalized IR in a mobile environment. Our personalization ap-proach is multidimensional, considering within this context the set of three main relevance criteria: C = { topic, interest, location } . The final ranking of a docu-ment d ,givenaquery Q , a user X  X  interest I and a location L will be represented by his overall score RSV ( d ) defined by: uating the topic (respectively interest , location ) criterion, and F is the priori-tized aggregation operator. In this section we present a description and a formal definition for each of these criteria and their associated relevance functions. 3.1 Topic The  X  X opic X  criterion refers to the sta ndard topical relevance computed by IR systems. The topical relevance is generally measured with an IR model. One of the prominent models is the probabilistic model [18] with the BM25 weighting scheme as a ranking function. For this reason, we adopt this model although topical relevance could be also comput ed based on alternative models. BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms occurring in each document. More precisely, given a query Q containing keywords t 1 ,...,t n ,the topic relevance score of a document d is: where f ( t i ,d ) is the frequency of term t i in the document d , | d | is the number of words occurring in document d ,and avgdl is the average document length in the text collection from which documents are retrieved. k 1 and b are free parameters usually chosen such that k 1 =2 . 0and b =0 . 75. IDF ( t i ) is the inverse document frequency of the query term t i , usually computed as: where N is the total number of documents in the collection, and n ( t i )isthe number of documents containing t i . 3.2 Interest The  X  X nterest X  criterion measures how strongly a retrieved document is similar to the user X  X  interest. Users X  interests are known to be the most important con-textual factor that can be used to personalize web search in an ad hoc retrieval task [19]. The Interest criterion is measurable when the system makes use of a user profile. In this paper, we use the semantic user profile model proposed in our previous work [20], where user X  X  interests are represented as a list of weighted concepts from the ODP 1 . Each concept c j in the ODP is represented by a term vector of its sub-concepts. Each term X  X  weight w i in a concept tf  X  idf weighting scheme. In order to compute the interest score of a docu-ment d according to the user profile I ,document d is represented by a vector of weighted terms. The interest relevance function of the document d is computed according to a term-based similarity measure, namely the cosine similarity mea-sure between the document d and the top k ranked concepts of the user profile I as follows: where sw ( c j ) is the similarity weight of the concept c j in the user profile I . 3.3 Location In this paper, we recognize the importance of location information in mobile search (more than 31% according to a r ecent study [21]), and propose to in-corporate the user X  X  location in addition to user X  X  interest in the personalized search. Dealing with geographical infor mation needs and localizing search re-sults is a known problem within the field of geographical IR [22]. Of the various geographical ranking functions defined in the literature, we adapted the geo-graphical weighting function presented in [23], as a geographical relevance score of a document. Given a geographic hierarchy GH , a geographical place L of a user query, and a document d ,the location relevance function is given by: where f ( L ) refers to the number of occurrences of location L in d and the offspring locations L i of the given location L are identified from GH . In the absence of a standard evaluation co llection suited to evaluate an IR system which is user-dependent, we propose an evaluation protocol that integrates the user context in the evaluation by means o f simulation. Our experimental setup is in line with simulation-based evaluation [24]. The objective of our experimen-tal evaluation is twofold: 1) to study the effectiveness of the combination of the multi-relevance criteria in comparison with the traditional topical relevance as-sessment standard, and 2) to compare the effect of the prioritized aggregation operators in the retrieval performance in comparison with the linear combina-tion schemes. In the following, we first present our experimental settings then we discuss the obtained results. 4.1 Experimental Settings For experimental purposes, we use a branching part of the ODP Ontology con-sisting of the set of web pages classified under the US region. The ODP is the most widely distributed data base of web content classified by humans. These web pages are in fact classified under concepts but also under geographical places allowing us to study all our criteria topicality, interest and location. We crawled of the crawled web pages, and a profile set (P) composed of the remaining web pages. The documents were randomly assigned to one of the two subsets. Document col lection. The (T) set is used as the document collection for search, it is indexed using the Terrier 2 search engine [25], and is used as the search collection. For all these documen ts, we kept track of which concepts and locations these documents were originally classified under. This information is exploited as an evidence source in the relevance judgment as described below. Users X  interests. We simulated 30 users profiles. For simplicity, we assigned one interest to each user ( k =1and sw ( c 1 ) = 1 in formula 5). To simulate users X  interests we randomly selected 30 concep ts from the ODP. More specifically, each interest is represented as a concept from the ODP using the set of documents from (P) classified under this concept as described in sect. 3.2.
 Users X  locations. Users X  locations are chosen from the US cities. We suppose a different location for each user. They a re simply added to the users X  queries. Users X  Queries. To simulate search, we designed a set of 6 queries for each user profile. They are constructed using different strategies. As a result, a query may be formulated in each one of the following ways: 1. A set of terms describing a particula r information need about the concept. 2. The most frequent term in the concept. 3. The two most frequent terms in the concept. 4. The three most frequent terms in the concept. 5. Two or more overlapping terms within highest weighting 10 terms among 6. An information need expressed using terms from another concept (different Our goal behind these strategies was twofold: (1) since the queries of mobile users tend to be short and ambiguous [26], we wanted to cover such queries, and (2) to cover at the same time situations in which the user formulates queries in line with his/her interest, but also queries formula ted on new interests (not yet present in his/her profile). We finally obtained a set of 180 queries (30  X  6). Table 1 gives an example of queries constructed accord ing to each strategy. Queries 1 to 5 are constructedontheconcept X  X otelsandMotels X  X ndquery6isonananother concept  X  X arks. X  Evaluation scenarios and relevance judgment assignment. The impor-tance order ( ) of a user on the three relevance criteria (topic, interest, and location) allows us to define six possible evaluation scenarios:  X  TIL: Topical Interest Location.  X  TLI: Topical Location Interest.  X  ITL: Interest Topical Location.  X  ILT: Interest Location Topical.  X  LTI: Location Topical Interest.  X  LIT: Location Interest Topical.
 Each pair (query, document) returned in the result list was judged according to each one of these evaluation scenarios. Relevance judgments were made auto-matically by exploiting the locations and concepts from which the documents were originally classified in the ontology. Relevance assignment of each individual criterion was done like this:  X  If a document was classified under the query concept, it was judged topically  X  If a document was classified under a concept which corresponds to the current  X  If a document was classified under the user X  X  location, it was judged relevant Algorithm 1. Assigning relevance judgment depending on the ordered criteria sat-The final relevance judgment of a document is made by combining its individual relevances using a four-level relevance scale. It is done according to Algorithm 1 depending on the ordered crit eria satisfaction degree.
 Evaluation metrics. To estimate the quality of the produced ranks, three measures are used. The MAP, the nDCG at n and the Precision at n ,which are usually used to represent the syst em performance. We computed them with standard trec eval 3 program. The computed values were averaged over all the evaluated queries results and/or over the different evaluation scenarios. 4.2 Results and Discussions Effectiveness of the Combination of the Multi-Relevance Criteria. In this first series of experiments we performed for each query a standard baseline search using a topical based relevance system Terrier [25]; we then computed an interest score and a location score, for all the documents in the collection like de-scribed in sect. 3.2 respectively in sect. 3 .3. In order to combine these scores, we computed a normalization of these individual scores. We then performed a com-bination relevance scheme using standard operators min , average and weighted average (denoted w-average ) where we assigned weights for the criteria in accor-dance with their importance order in the evaluated scenario. We have carried out experiments with the aforementioned evaluation scenarios. Figure 1(a) and 1(b) show the results performance, measured using Precision respectively nDCG at different cut-off points, averaged over all the evaluation scenarios. Results show that in general, the combination of relevance criteria outperforms the topical relevance assessment standard, with the weighted average combination achiev-ing best performance in terms of nDCG and Precision at different cut-off points. This confirms the effectiveness of the multi-relevance based model.
 Effectiveness of the Prioritized Aggregation Operators. In this second series of experiments we combined the multi-relevance criteria using the priori-tized aggregation operators. We then compared the obtained result ranks with the rank of the standard weighted average as the baseline . Figure 2(a) and 2(b) show results performance in terms of Pr ecision respectively nDCG at different cut-off points, averaged over all the evaluation scenarios. Results show that the  X  prioritized scoring  X  operator outperforms its counterpart standard weighted av-erage . However, the  X  prioritized and  X  operator degrades the results.
In order to evaluate significance of the  X  scoring  X  operator improvement, we conducted a paired two-tailed t -test. Table 2 shows the performance results in terms of MAP computed for each evaluat ion scenario. Results show that the improvement of the  X  scoring  X  operator comparatively to the baseline was found to be statistically significant (noted * in the table) with p -values &lt; 0.01 for the majority of the scenarios. However improvements are different between the tested scenarios. We notice that best im provements are obtained on scenarios where user X  X  interest is the first order criterion. Little and no improvement was noticed on the MAP of the two scenarios L TI respectively LIT where the location criterion is the first order criterion. We notice also that the MAP of the two scenarios LTI and LIT are somewhat better than the other scenarios. This is likely due to the fact that the score of the location criterion is computed with higher precision than the interes t and the topical based scores.

Further, we analyzed the results perfor mance for the different types of queries issued from the different con struction strategies. Table 3 shows comparison on MAP results averaged over the six evaluat ion scenarios for ea ch query construc-tion strategy, obtained by the  X  scoring  X  X ndthe weighted average ranks. Results show that the  X  scoring operator  X  shows its superiority in all query construction strategies, with a statistically significant improvement (noted * in the table) with p -values &lt; 0.01 over the standard weighted average operator. In this paper, we have proposed a multi-criteria relevance model for personalizing mobile IR. The main contribution of this work concerns the adoption of a  X  X ri-oritized operators X  for aggregating the considered relevance criteria. Thanks to this aggregation scheme, it is possible to take the user X  X  preference order over the criteria in the aggregated score of a document. Experimental results show that: (1) the  X  X rioritized scoring X  aggregation scheme allows to improve the ranking of the documents for the majority of the considered preference orders and all the query strategies, and (2) the  X  X nd operator X  is not suited for the aggregation of criteria within our retrieval mobile IR settings. In future work, we plan to enhance our multidimensional model to include other contextual criteria and to conduct experiments with real mobile users and queries.

