 Social computing applications are transforming the way we make new social ties, work, learn and play, thus becoming an essential part our social fabric. As a re sult, people and systems routinely make inferences about people X  X  personal information based on their disclosed personal information. Despite the significance of this phenomenon the opportunity to make social inferences about users and how this process can be managed is poorly understood. In this paper we 1) outline why so cial inferences are important to study in the context of social computing applications, 2) how we can model, understand and predict social inference opportunities 3) highlight the need for social inference management systems, and 4) discuss the design space and associated research challenges. Collectively, this pa per provides the first systematic overview for social inference research in the area of social computing. H.1.2 [Information Systems]: User/Machine Systems Human Factors, Design, Theory Social inference, social comp uting, impression management, privacy, personalization Social computing applications c onnect users to each other to support interpersonal communicati on (e.g. Instant Messaging), social networking (e.g. Facebook) and the sharing of user-generated content (e.g. YouTube ). These applications are transforming the way we make ne w social ties, work, learn and play, thus becoming an essential pa rt our social fabric. Everyday use of social computing applications, such as posting on a Facebook wall, checking-in to a lo cation, uploading a picture, or liking or sharing a website, gene rates an enormous amount of personal data. The richness and widespread availability of this data enables social inferences about user preferences, identity, location, and private user information. Such social inferences are an emergent form of social computing that can occur when unrevealed personal user information, e.g., identity, location, user preferences, or profile information, is correctly inferred from revealed information in combination with background knowledge . We define background knowledge as information that has not been provided by the user or revealed by a social computing system and is available from other sources. The following scenarios illustrate the ubiquity, versatility and the basic dynamics of social inferences in social computing: These scenarios illustrate how the increasing use and sophistication of social computi ng applications and their related technologies has significantly in creased the opportunities for social inferences. Motahari et al. [19] found that people often make both incorrect guesses and so cial inferences about other users based on their social networking profiles. However, at the same time people are very poor judge s of the ability of other users and software systems to make inferences about them [22]. Unfortunately, current social co mputing system designs do not adequately take into account the potential for social inferences and do not provide users the tools necessary to manage them. When users of social computing applications provide or share personal information through the system (e.g. their interests, demographics, a picture, or their location), they are not informed about how their decision to reveal this information may impact potential social inferences. As a result, users of social computing applications have a lim ited understanding of the implications of their personal information sharing decisions. In order to gain a solid understa nding of social inferences and their impact on social computing system design we believe that extensive research into the different components of social inferences and the dynamics of social inference opportunities is necessary. Unfortunately, the unde rlying logic, namely that background knowledge when combined with revealed user information can lead to a social inference opportunity (Figure 1) , has not been examined and researched systematically. To support the exploration of this problem we introduce a model outlining and linking the various components of social inferences. The understanding of these compone nts and how they relate to each other will aid in effective social inference management system design and building. We pose the following questions in order to structure the discussion of our social inference model: Collectively, this paper provides the first holistic overview of the social inference phenomenon in social computing systems and lays out future direct ion for researchers. The remainder of this paper is organized as follows. In the next section we provide an overview of the diverse aspects of social computing in which social inferences occur and explain the basic dynamics of social inferences. In section 3 we present four different social inference modeling approaches that can be used to identify social inference opportunities. Section 4 highlights the need for tools that raise awareness and allow users to control social inference opportunities. In section 5 we discuss open research challenges related with the principled design of social inference management system s. Section 6 concludes. Although there has been relatively little research into the social inference phenomenon in social co mputing systems, some other fields have explored the inference problem. The problem of inferences is well known to databa se researchers [8, 23, 24, 40]. A typical example comes from the database privacy literature [5]: the relation &lt;Name, Salary&gt; is a secret, but user u may request the following two queries:  X  X ist the rank and salary of all employees X  and  X  X ist the name and rank of all employees. X  None of the queries contain the secured &lt;Name, Salary&gt; pair; however, an individual may utilize the known information &lt;Rank, Salary&gt; and &lt;Rank, Name&gt; to infer the private &lt;Name, Salary&gt; information through deductive reasoning. For example, the knowledge that Bob is a manager and all managers earn $x, can help one deduce that Bob earns $x. This problem is known as data re-identification [31], the process of linking datasets without explicit identifiers such as name and address to datasets with explicit identifiers through common attributes. Another example is the linkage of hospital discharge data to voter registration lists that allows sensitive medical information to be inferred [32]. Considerable work has been undertaken exploring the general inference problem as a security threat to databases [8] and as a privacy risk in data mining [23, 24, 40]. K-anonymity [31], a method widely used in the database and privacy domain to detect and prevent such inferences about private user information works on the principle that  X  X ata is safe to release if at least k entities share the same attributes X . However, social inferences in social computing systems are very different in nature than inference problems that typically arise in the database and data mining doma ins (as seen from the example scenarios above). This is because both the inferred personal user information, as well as backgr ound knowledge used to make an inference may not be stored in the application database. Some examples of inferable information are users X  identity at physical appearance granularity (seeing the only person with a phone nearby -scenario 2) and users X  activity and location (tweets about an upcoming vacation in Mexico -scenario 5). Furthermore, the availability of revealed user information and background knowledge is extremely dynamic in nature, especially in mobile social application, since it can be based on the user X  X  context, such as time and location. Social inferences are also not only a privacy-risk but also have the potentia l to be beneficial and actively desired by the user (to impress or to receive valuable recommendations -scenario 1 and 6). Social inference can affect very diverse aspects of social computing. Until now, inferences were only studied for certain and very limited contexts (e.g., as threat to database security). However, it is important to underst and that social inferences occur across various areas of social computing and may have very different implications. Social inferences in social computing 1) can help users to manage their online impressions ( impression management) , 2) may lead to privacy invasions and loss of anonymity ( user-privacy and security), and 3) can help to receive personalized social recommendations ( system personalization) . These three aspects of social computing affected by social inferences are illustrated in the sub-sections below. According to Goffman [12], people routinely manage impressions through varying self-presentations depending on the social setting and audience. Social inferences usually occur in this context because impressions are formed both based on explicitly revealed personal information as well as unrevealed but inferred information. Similarly, users of social computing systems, particularly social networking sites (SNS), consciously or unconsciously attempt to influen ce the perceptions other people have about them by regulating and controlling the personal information they share [12] (see scenario 1). For example, an important part of the value propos ition of business-oriented Social Networking Sites (SNS) such as LinkedIn comes from the social inferences they enable about members. Users often make inferences about other members X  skills and business networks based on fairly limited user-pro file information and weak-tie relationships. Social inferences a bout the extent of an individual's expertise made from information provided through LinkedIn could be used to find worthwhile employees. However, while users routinely re ly on social inferences made about them when presenting them selves on SNS these systems do not provide users a method to unde rstand what others might be able to infer from their profile information. Thus, to effectively aid impression manageme nt users require methods to go beyond traditional profile management a nd enable them to perform what we call 'social infe rence management'. Due to the growing ubiquity of social computing and the manner in which people use them and in turn how those systems collect and share information raise pe rtinent privacy and security concerns. Social inferences can potentially lead to unwanted disclosure of personal user information, for example, a user X  X  identity or location. This is illustrated by the following actual incident [29]. During the deployment of Ca mpusWiki, a location-aware application that allows users to create and edit location-linked content which can be anonymous or identified, a student anonymously added unpleasant comments about a course professor. The professor was able to utilize the time-location stamps of page edits to deter mine that the comments were made during his class period and near th e classroom. He then proceeded to monitor laptop use by students during the class in question, and was then able to determine th e student responsible for the comments. The result was a confr ontation, which lead to the student dropping the course. In this case a user X  X  expected privacy was violated due to a social inference. A simple, yet to-the-point definiti on of privacy is  X  X  person's right to control access to his or her pe rsonal information X  [3], i.e., the expectation that others will not know and cannot find out what they wish to keep secret. In other words, a person should have the ability to exclude others fro m accessing individuals X  personal information and to determine when, how, and to what extent he or she will release persona l information. Anonymity preservation, to be unidentifiable among a certain number of other people [22], also is an important aspect of privacy. While privacy is well researched in the literature, there has been scant research on the social inference problem as threat to user privacy in social computing communities. Motahari et al. [20, 21, 22] investigated identity inferen ces in open partially anonymous computer-mediated communica tion (CMC) used to support interaction between partially or fully anonymous individuals and found that users were able to make social inferences about their chat partners X  identity while they assumed to be anonymous. Users of social computing applications often engage in conversations (chats) where they want to stay anonymous, e.g., initial conversations on social matching / dating sites, private messages with an unknown member on Twitter, online forums, Chat roulette, or in massively multi-player online games (MMOG). Here, information disclosed during the conversation may allow for identity inferences while users still assume to be anonymous. User-location is increasingly po pular information item collected and shared via social computing applications (e.g ., location-based social networks like Foursquare). Motahari et al. [22] also investigated anonymity and identity inferences in proximity-based social applications and found th at disclosure of location and patterns of co-location often lead to social inferences about users X  identity (see scenario 2). A study by Krumm [16] showed that the location of a user X  X  home and hi s/her identity can be computed only using pseudonymous GPS data, simple algorithms and a free Web service. An official warning by the United States Military was given due to the risks posed by geotagging, adding a geographical metadata to a pict ure and uploading it to a social computing application [26]. This could potentially allow inferences about the exact location of a soldier by an enemy allowing for an attack. This risk can basically be extended to anyone who uploads geotagged pictures to social computing applications. A factor mediating this risk is having hundreds of  X  X riends X  that may have never b een met in person. From tagged locations like the frequently visited restaurants, the gym visited everyday and the street living in, these  X  X riends X  (that are actually strangers) can infer routines a nd habits. This way, social inferences may also enable stalking. For example, a college student X  X  SNS profile includin g information about residence location, class schedule, and locat ion of last login may help a potential stalker to determine the user X  X  whereabouts [13]. PleaseRobMe [11] is a website that aims at raising awareness about oversharing, particularly how users of location-based services make themselves vul nerable to housebreaking by checking-in to locations online (see scenario 5). A possible consequence of identity inferences is identity theft. Making birth date, hometown, cu rrent residence, and current phone number publicly available at the same time can be used to estimate a person X  X  social securi ty number and exposes her to identity theft. Since a vast majo rity of Facebook profiles not only include birthday and hometown information, but also current phone number and residence (often used for verification purposes by financial institutions and other credit agencies), users are exposing themselves to substantial risks of identity theft. Passwords and answers to security questions may also be jeopardized as a result of a social inference. Users often select passwords that have a personal mean ing for them as they are easy to remember [28, 17, 37] (e.g. na me of a favorite pet, birth date, social security number) that may be able to be determined via a social inference. Furthermore, many systems insist on the use of security questions for lost or forgotten passwords intentionally based on potentially inferable personal information [28]. For example, typical security ques tions ask users about their home town, their mother X  X  maiden name or their pet X  X  name; information that is often publicly visible on social networks or through search engine results (see scenario 4). A very public and well known example of this probl em is known as the  X  X alin Hack X  [39]. During the 2008 United States presidential election campaign someone had obtained ac cess to Sarah Palin's private email account and posted several screenshots of her emails in an online forum. The  X  X alin Hack X  did not require any real skill, instead, the hacker simply reset Palin X  X  password by answering the security questions on the ac count using her birth date, ZIP code and information about where she met her spouse -information that was easily obtained by a simple web search. This shows how answers to security questions are prone to be inferable from revealed personal information and by searching various sources for user attributes which may lead to security holes. These diverse examples illustrate how social inferences can have significant implications on user-p rivacy. In order to effectively protect users X  privacy in social computing, we need to understand and model social inference opportunities which in turn will allow us to build and develop social inference management systems. Social inferences can also be valuable to the user for system personalization, specifically for recommendations. System personalization is usuall y based on explicit data such as interests or implicit data such as context of each individual user or user group [35]. With the exponential gr owth of available information on the Web, social inferences about user preferences can help to tackle the information overload problem by personalizing the systems appearance and behavior and recommending information that is relevant to the user. Social computing systems often provide personalized services based on user profile information. Social inferences about user preferences that are not explicitly stated provide a sophisticated way to personalize recommendations . For example, personalized social recommendations can help us ers form new relationships by suggesting other individuals of interest (e.g., Facebook X  X  and LinkedIn X  X   X  X eople You May Know X ) [35]. Social matching systems (e.g., dating sites like Match.com) typically base match recommendations on users X  explicit matching-preferences and/or measures of the overall affinity between individuals. Current personalized services often inadequately inform the user about the reasons for the pers onalized recommendations and do not provide adequate contro l over how recommendations are made. This may lead to frustrations and undesired recommendations when users do not agree with or understand the reasons for the system X  X  personali zation decisions (e.g., repeatedly being shown the hated ex-girlfri end as  X  X eople you may know X ). Furthermore, this can potentially reveal information that invades users X  privacy or leads to compromised security, for example when user-location is used for people recommendations and the system reveals the proximity between two users leading to an identity inference (see scenario 2). Social inference about users X  match preferences (e.g., interest in another student from the same U.S. college while traveling in Japan  X  scenario 6) can potentially yield to more desirable social match recommendations. Context (user location, activity, resources, etc.) is a helpful pie ce of information to allow for valuable social inferences in the area of mobile social matching. Mayer et al. [18] found that recommendations made based on user-context and contextual rarity of shared user attribute are more interesting to users. We need to gain a deeper understanding as to how social inferences can be used to personalize services in socially intelligent ways based on information such as user-context, as well as how users want them to be used for system personalization. Together with impression manageme nt and user-privacy, system pers onalization needs to be effectively managed by users by providing them with social inference management tools. We define social inferences as inferences about personal user information (e.g. user preferences, identity, location, and profile information) that has not been explicitly revealed but can be inferred from revealed inform ation in combination with background knowledge. The act of inferring always involves two entities: 1) an individual about w hom something is inferred, i.e. the inferee, using his/her revealed personal information and 2) an inferring entity (an individual or system), i.e. the inferer, who combines this information with background knowledge to perform a social inference (see Figure 2). Figure 3 shows a more detailed version of the simple underlying logic of social inferences in Figure 1. It illustrates what different types of background knowledge can, when combined with revealed user information , lead to a social inference opportunity . Since the inferring entity can be a system or a user we differentiate between two different types of social inferences; those made by systems ( system-based social inferences ) and those made by people ( human social inferences ). System-based social inferences can occur when a system combines its background information (implicitly collected, e.g., from internal user-profiling, web crawling, sensor data) with information explicitly disclosed by the user by applying heuristic rules. This is similar to the id ea of emulating human reasoning to extend a system X  X  knowledge base that is explored in the field of artificial intelligence and sema ntic web using methods like statistical inference (e.g. Bayesian inference [33]), or automated ontology construction [4]. In social computing, system-based social inferences about users X  social matching preferences can be valuable for personalized social recommendations [18]. On the other hand, human social inference are inferences users of social computing systems can often perform when interpreting other users X  revealed information. By combining personal background knowledge with what the system reveals about a user, an inferee might be able to infer unrevealed information, such as a user X  X  nationality based on the use r X  X  name or hometown, a user X  X  approximate age based on the gra duation year, or the impression made based on personal pictures and status updates. Users can build up background knowledge in various ways over time, for example, through experience and learning, through observation, or a web search. Revealed user information is the information a user explicitly discloses through a social compu ting system. This information can be static (e.g. user X  X  demogr aphics) or dynamic (e.g., user X  X  location). For example, users disc lose personal information, such as interests, hobbies or educational and professional information on SNS profiles like Facebook or LinkedIn. Behavioral information, such as user X  X  ac tivity and interactions could be revealed through status updates on Facebook or Twitter. Geotemporal information, such as a user X  X  current location, is typically disclosed though check-ins (e.g. Foursquare, Facebook Places). Today X  X  social computing applic ations tend to promote and push users to share more and more pe rsonal information. The value of social computing systems comes from sharing. Systems are designed in a way to get users create rich personal profiles disclosing increasing amounts of pe rsonal information and sharing it with the world. A social inference opportunity exists if it is logically possible to make a social inference. We consider a social inference logically possible if unrevealed information can be deduced by analysis of a user X  X  or system X  X  background knowledge using the additional revealed information provided by the user. The fact that a social inference is logically possible (a social inference opportunity ) does not mean that a person or system will make a social inference. To calculate the probability that a social inference will actually occur, requires 1) knowing that an inference is logically possible, th en 2) having a reliable estimate of (a) the number of potential in ferers exposed to the revealed information, (b) the range of c ontexts in which the potential inferers are exposed to the re vealed information and (c) the likelihood that for each  X  potential inferrer-inference context  X  an inference will actually be made. Clearly, it is considerably more difficult to determine the likelihood of a social inference than if a social inference opportunity exists . However, for system designers and CSCW researchers we do not believe that the initial focus of our efforts should be on assessing the social inference probability. The following analogy helps illustrate why this is the case: People routinely lock their cars in public parking even though on most occasions no individual will attempt to open the door to steal items inside. The decision to lock the doors can be based on the logical possibility of easy item theft, rather than the overall probability that some body will walk past and try opening the car door in case it is unlocked and st eal an item. Car designers do not worry about such probabilities; instead they provide drivers with the ability to know if they have controlled easy access  X  i.e. if they have locked the door. Similarly, we first need to provide users with an understanding of the social inference opportunities of various information sharing d ecisions. To achieve this end we need to be able to model the logical possibilities of social inferences. In following four subsections, we provide a brief overview of the approaches we are aware of for identifying social inference possibilities: 1) entropy calculati ons, 2) user-generalizations, 3) rarity calculations, and 4) user attribute-linking. The entropy approach is based on the following fact: as individuals or applica tions collect more info rmation about a user, our uncertainty about other attri butes, such as his/her identity, may be reduced, thus increasing the opportunity of a social inference. The following scenario from a user experiment of online chat between anonymous partners illustrates the social inference opportunity asse ssment framework [22]. Here, as Bob combines his background knowledge of the female Hispanic soccer players on campus with what Alice reveals, his uncertainty about his chat partner's identity decreases, thus increasing the opportunity of a social inference. This uncertainty can be measured by an information entropy calculation [30]. Information entropy, as used in information theory for telecommunications, is a measure of the decrease of uncertainty in a signal value at the receiver site. Here we use the fact that the more uncertain or random an event (outcome) is, the higher the entropy it possesses. If an event is very likely or very unlikely to happen, it will not be highly random and will have low entropy. Therefore, entropy is influenced by the probability of possible outcomes. It also depends on the number of possible events, because a greater number of possible outcomes make the result more uncertain. In our context the probability of an event is the probability that an attribute (s uch as a user X  X  name) takes a specific value. As the inferrer collects more information, the number of entities that match her/his collected information decreases, resulting in fewer possible values for the attribute and lower information entropy. The information entropy modeling approach was tested in two different areas of social comput ing: 1) for anonymous computer-mediated communication, through a laboratory chat experiment between unknown chat partners and 2) for proximity-based applications, through a mobile phone field study that explored patterns of co-location and anony mity of the subjects. In both studies, entropy-based inferenc e modeling was the strongest predictor of social inference opportunities [20, 21, 22]. This approach is based on the following fact: Individuals or applications can derive general concepts from repeated experiences or observations and th en apply these concepts to a certain user, allowing for a potential social inference. This is typically done by recommender systems that attempt to infer user preferences based on buying behavior and preferences of other users (e.g., someone buying se veral science fiction books must like other science fiction books because other users showed that same interest). Furthermore, matchmaking systems are usually based on the concept of homophily, i.e., that people like people who are like them (similar demographics, intere sts, etc.). Currently, social matching systems calculate user affinities by weighting the similarities between users over a set of user attributes stored in the user profile. Standard user attr ibutes include interests (hobbies, favorite music), social ties, demographics and personality. In order to find valuable social matches, rich user profiles are needed. The more information a system has about a user, the better it can compute social matches. Ideally, mobile social matching systems could improve matching by leveraging geo-temporal social data [18]. Generalizations about geo-temporal data can be used to make inferences about user X  X  local cont ext, for example, involvement in an activity based on location: Tony is at the gym, so he is probably working out [10, 15, 34]. Short-term and long-term trajectories, location logs, and ge o-temporal patterns may also be used to infer user X  X  interests from a user X  X  frequently visited places (Susan regularly goes to the church; then she is Christian). Proximity patterns can be used to identify people who are nearby each other often but do not know each other yet [15]. Potential social inferences can also be identified based on user attribute rarity. This is based on the following fact: the rarer an information item in the system is the more meaningful it is to the system, thus increasing the social inference opportunity. This is related to the concept of TF *IDF (term frequency-inverse document frequency) in data mining [25] which assumes that the frequency of a word in a document compared to the frequency of that word in the set of all documents is an indicator of the importance of that word. The rarity-based approach was expl ored in the context of mobile social matching. Social matching systems are social recommender systems that help users to find ot her individuals of interest [35]. Traditional social matching systems calculate user affinities by weighting the similarities betw een users over a set of user attributes. Mobile social matching extends social matching to mobile devices by recommending people to people based on their current local context. It was found that in mobile social matching not only the similarity between two users is useful to determine the value of a match but also the rarity of this similarity in the user X  X  current context [18]. C ontextual rarity is a measure of how many other individuals have the same attribute in the user X  X  social context. A generally common attr ibute can become 'contextually rare' in certain contexts. The scenario that follows illustrates this point: In the above example, the match relevance was inferred from the rarity of the particular context (it is really unusual for two students who do not know each other and are from the same American college to be in each other X  X  vicinity in Italy). This scenario highlights how the rarity of a user attribute can lead to beneficial social inferences about users X  match preferences. The prevalence of an attribute in a certain population, which might be the user X  X  greater social environment or a particular current context, is calculated the following way:  X   X   X   X   X   X   X  attribute a equals the number of occurre nces of attribute a divided by the size of the population N . Rarity is the inverse of the prevalence, i.e. attributes with a high prevalence are not rare (i.e., are common) but attributes with low prevalence are very rare. For example, rarity of being German at an American college equals the number of people at the American college divided by the number of Germans at this college. The contextual rarity approach was tested using a personalized self-reported web survey exploring seven different affinity types (interests, needs, geographi cal background, educational background, distinct characteristic s, places and friends) [18]. For each section respondents were instructed to enter three of their own user attributes. Then, for each attribute and the combination of all three in this section, they were asked two sets of questions: First, they had to rate the comm onness of the attribute in different contexts (home, work, social circ le, etc.) and second, they were asked about their level of interest in a potential match with same user attribute in different stat ionary, mobile, common and rare situations. The results of this survey study confirmed that people are generally more interested in matches based on rare user attributes. They also found that th e relative contextual rarity can influence the desire for a social match [18]. We consider this relationship between contextual rarity and users X  match preference as a social inference opportunity. Systems can potentially infer users X  context-dependent match preferences using rarity calculations. However, this approach has not yet been implemented and we only have a limited understanding of the applicability and genera lizability of this met hod to detect logical possibilities of a social inference. This approach is based on the following fact: individuals or applications can link together a number of isolated facts from various sources, thus leading to a potential social inference. It has been shown previously that a large portion of the US population can be re-identified using a combination of 5-digit ZIP code, gender, and date of birth [3 2]. For example, information can be searched from several online sources. People routinely search what personal information about them or others are publicly available online, e.g. using sear ch engines, to make potential social inferences. In addition to these easily accessible search results, there are other personal data publicly availabl e that are not directly accessible through co mmon search engines, e.g., intelius.com [14] to find somebody X  X  age, zabasearch.com [38] to find an address or home phone num ber, or portals to public government data to find a state employee X  X  salary [1]. Often times, inferees are not aware that this kind of information is publicly available, which could lead to potential social inference, for example about a user X  X  password (see  X  X alin Hack X  [39]). User attribute linking can also be used for face re-identification by linking facial images from social networking profiles to other available facial images, e.g., from public websites. Gross and Acquisti [13] were able to correctly link facial images from Friendster profiles without exp licit identifiers with images obtained from fully identified university web pages using a commercial face recognizer. Current social computing systems do not consider social inference opportunities. They implement basi c access control systems that provide users with an interface to directly control people X  X  access to their information [7]. Social networking sides (SNS) usually provide users with profile manage ment and privacy setting user interfaces (UIs) that allow them to manage revealed profile information . These are usually structured for the kind of data a user can enter (e.g. name, interests, contact information, demographics and a profile pictur e). Some social network systems (e.g., LinkedIn, Facebook) differ entiate between a public profile (visible to everybody) and a priv ate profile (visible only certain people in the social network system s, e.g. friends, contacts). For example, Facebook's privacy setti ngs allow users to customize the visibility of each item on their prof ile for different friend lists, as does Google+ with the  X  X ircles X  feat ure. Similarly, various mobile location-aware applicati ons such as Loopt allow users to set rules about their locatability in particul ar locations for particular people. Users are generally able to view how their profile is seen by other users based on the informati on explicitly disclosed. However, users are often neither aware nor informed about the issue that personal information a bout them might be inferable. Simple access control systems a nd profile management UIs only allow users to see and control the information explicitly revealed about them but none of these syst ems consider and inform users about social inference opportunities. This shows that current simple rule-based approaches to privacy and security do not cope well with the dynamic and context-dependent nature of social inference opportunities. Based on the highlighted issues , we propose social inference management systems that support users X  awareness of social inference opportunities through UIs and visualizations and allow users to control them through ma nagement tools. These systems would ideally provide users with visualizations of social inferences opportunities in relation to: 1) Their digital self-presentation for impression management ; 2) Resulting privacy and security implications of data sharing 3) Opportunities for personalized recommendations (e.g., Unfortunately, there is a large gap in social computing research investigating system interfaces and mechanisms to manage social inferences. In order to build effective social inference management systems we believe th at broad and extensive research efforts are necessary to study the social inference phenomenon across the different presented areas. There are several research challenges associated with the principled design of social inference management systems. Based on the previous discussion we argue that current social computing system designs do not provide users with the proper methods to understand and manage social infe rences. In order to transform our understanding of social inference opportunities in social computing and be able to design and build effective social inference management systems, we need to overcome research challenges in terms of: We will discuss each of these challenges in more detail in the following three sub-sections. In order to design social computing systems that incorporate social inference management, we first need to explore people's current understanding and percepti ons of the social inference opportunities associated with the social computing applications they presently use. Research into users X  awareness of social inference opportunities (to what extent people guess that systems or other users can infer private in formation about them), and what users perceive to be the implic ations of such opportunities (to what extent people perceive social inferences as negative, e.g., privacy invasion, or as beneficial, e.g., personalization), will inform us about how users currently experience social inferences in social computing systems. In particular we need to explore: 1) People X  X  beliefs about other users X  abilities to infer 2) What they want (and do not want) to be inferable about 3) Their satisfaction and frustra tions with personalization, 4) People X  X  inferences about other users in order to identify 5) Their preferences, from a privacy-point of view as well as Collectively, this will provide us with a better understanding of how social inferences are perceived by the broad user-community. This in turn will provide us with important insights into social inference manageme nt system design requirements. Social computing systems that incorporate social inference management must be able to effe ctively and efficiently model the logical possibility of social infe rences. In order for systems to provide social inference based impression management, privacy and personalization we need to le arn how to evaluate and compute potential social inference opport unities associated with user-information sharing in various c ontexts. We must also generate methods for understanding and ev aluating the quality of social inference detection. To achieve this goal we need to thoroughly examine how to: 1) Quantify and model the background knowledge used by 2) Create and populate a world model that can be used to 3) Assess and refine the entropy, rarity, user-generalizations, To achieve this goal, profound studies examining users X  ability to make inferences about others as well as to assess other users X  ability to make inferences about them are necessary. Many of the social inference calculations require the accurate assessment of the probability/prevalence of an attribute occurring in a particular context; e.g., the chance of a student knowing another random student who is on campus and the chance that a student is coming from Germany and studying HCI. As a result, the world model needed will need to contain extremely detailed information. This could be achieved using commercial entities that have much of this data on hand (e.g. over 90% of current students have Facebook accounts) or using a software tool that enables the collection of rich social networ k data and in-depth information from a large number of individuals within short timeframes (e.g. [22]). It is important to gain knowl edge of subject's social ties, to profile individual users and collect background knowledge of the social activities subjects engage in. Based on that, research efforts need to further examine how social inferences can logically be predicted by combining revealed information with the data contai ned in the world model. The aim here should not be to create an ideal world model, but rather to learn about the requirement s for effective modeling. Data management and system build ing is another challenge that requires our attention. To mode l social inference opportunities, data could be pulled from the outside sources or it could be stored in massive internal databases. Furthermore, the computational models could be constructed internally or externally. We have to explore advantages and disadvantages related to various options and create and eval uate IT artifacts that can help us gain deeper understanding about social inference opportunity modeling. A third research challenge is to learn how visualizing social inferences opportunities can help users to: 1) learn about digital self-presentation for impression management; 2) estimate more accurately the privacy and security implications of data sharing; and 3) control personalization of various social software services. We need to develop theories and t ools that allow for the principled design and development of social inference management systems by providing the user with the opportunity to learn about and control the social inference possibilities associated with their system use and personal data-sharing. Basic design alternatives can in clude visualizations showing highlighted profile sections that could be inferred in addition to the user profile as seen by others, awareness displays [2, 6] that visualize the logical possibility of a social inference and visualizations that explain social inference opportunities to users in form of words, statistics, probabilities, etc., so users can learn and understand the process. Furthe rmore, different intervention mechanisms could be incorporated: Passive mechanisms could warn or alert the user about soci al inference opportunities when disclosing certain information w ithout inhibiting the disclosure, while active mechanisms could blur the information, e.g. revealing the age bracket instead of date of birth or even blocking the information sharing. Automated mechanisms could allow users to set a certain required level of privacy and instruct the system to keep this level by prohibiting social inferences. Social inferences are a ubiquitous yet under researched phenomenon in social computing sy stems. This current situation poses a serious challenge to the Group/CSCW research community since social inferences happen regularly, users and researchers lack awareness and understanding, current access control systems are far from sufficient in addressing this issue, and social inferences impact wide aspects of system use (impression management , user privacy and security, system personalization). Therefore, the aim of this paper was to make the case for a focused effort to be made by the Group/CSCW community to understand and address these challe nges. Much more remains to be done, however, our work shows that social inference opportunities can successfully be modeled and predicted, and shows that we can establish guide lines that will help designers make informed decisions when designing social computing systems that take social infere nce opportunities into account. [1] Asbury Park Press DataUniverse Portal to Public [2] Biskup, J. and Bonatti, P. 2004. Controlled query evaluation [3] Black, G., 2011. Publicity Rights and Image . Oxford: Hart [4] Blaschke, C. and Valencia, A. 2002. Automatic ontology [5] Brodsky, A., Farkas, C. and Jajodia, S. 2000. Secure [6] Cadiz, J. J., Venolia G.D. , Jancke G., Gupta A., 2002. [7] Crampton, J. and Khambhammettu, H. 2008. Delegation in [8] Cuppens, F. and Trouessin, G. 1994. Information Flow [9] Dey A., Lederer S., Beckma nn, C., Mankoff, J. 2003. [10] Eagle, N., Pentland, A. 2006. Reality mining: sensing [11] Fletcher, D. February 18, 2010. Please Rob Me: The Risks of [12] Goffmann E. 1059. The presentation of self in everyday life. [13] Gross, R. and Acquisti, A. Information revelation and [14] Intelius People Search. Retrieved Nov 10, 2011. [15] Jones, Q. and Grandhi , S.A. P3 Systems: Putting the Place [16] Krumm, J. 2007. Inference Attacks on Location Tracks. Fifth [17] Lennon, M. Oct 12, 2010. Survey Reveals How Stupid [18] Mayer, J.M., Motahari, S., Schuler, R.P. and Jones, Q. 2010. [19] Motahari, S., Manikopoulos, C., Hiltz, R. and Jones, Q. [20] Motahari, S., Ziavras, S. an d Jones, Q., 2009. Preventing [21] Motahari, S., Ziavras, S., Naaman, M., Ismail, M. and Jones, [22] Motahari, S., Ziavras, S., Schu lar, R. and Jones, Q. 2008. [23] Narayanan, A. and Shmatikov, V., 2005. Obfuscated [24] O'Leary, D.E. 1995. Some Privacy Issues in Knowledge [25] Robertson, S. 2004. Unde rstanding inverse document [26] Rodewig, C. March 7, 2012. Geot agging poses security risks. [27] Samarati, P. and Sweeney, L. 1998. Protecting privacy when [28] Schechter, S., Bernheim Brush, a. J., Egelman, S.2009. It X  X  [29] Schuler, R.P., Laws, N. , Bajaj, S., Grandhi , S.A. and Jones, [30] Shannon, C.E. 1950. Prediction and entropy of printed [31] Sweeney, L. 2002. Achieving k-Anonymity Privacy [32] Sweeney, L. 2004. Uniqueness of simple demographics in [33] Tenenbaum, J.B., Griffiths T.L., 2001. Generalization, [34] Terry, M., Mynatt , E.D., Ryall, K., Leigh, D., 2002. Social [35] Terveen, L., and McDonald D. 2005. Social Matching: A [36] Weiser, M. 1991. The Computer for the 21st Century. [37] Yam, M. Jan 22, 2010. Your Top 20 Most Common [38] ZabaSearch. Free People Search and Public Information [39] Zetter, K.,(2008, Sept 18) Palin E-Mail Hacker Says It Was [40] Zhan, J. and Matwin, S. 2006. A Crypto-Based Approach to 
