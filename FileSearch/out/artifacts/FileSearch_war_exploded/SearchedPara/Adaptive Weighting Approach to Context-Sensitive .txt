 The majority of queries submitted to the search engine are short and ambiguous, and [11][12][14][15]. The  X  X ne size fits all X  a pproach fails to be optimized for each indi-vidual X  X  specific information need. Personali zed search appeared as a promising solu-has been revealed that the contextual approach may be a good choice [13]. 
So far, there exist two frameworks of context-sensitive retrieval. One is the classic-learning mechanism, esp. the learning-to-rank techniques (e.g., [3-6][11][16]). An essential issue among these works is how to exploit context information in the retriev-closely related to current query, a linear combination of current query and context is often adopted in above mentioned studies. In fact, context may not always help. Several previous works [8][9] have discov-ered that the current query can also be unrelated to its preceding queries in the same within a session, documents related to context should be promoted; while in the case of query reformulation, documents related to context should be demoted [2]. In other closeness. performance gap between the current context-sensitive models with a fixed form weight and those with adaptive weight for contextual information. Instead of relying retrieval model to best exploit the context information. 
The rest of the paper is organized as follows. Section 2 explores Potential for adap-paper is concluded in Section 5. 2.1 Context-sensitive Retrieval Model context here refers to queries and Web pages viewed prior to the current query in the same session. Context-sensitive retrieval problem involves how to exploit the current query together with its context to model a user X  X  search need. 
Statistical language models are often used to model a user X  X  information need. One method of combining all the pieces of evidence that contribute to user search need. language model and the clickthrough history by another n -gram language model, then retrieval framework can be viewed as following [1]. with fixed coefficient. 
The key to accurately estimate search need model is to choose parameters appro-priate to combine current query model and context model. Different forms of estima-tion result from specifying the values of. A simplest choice to estimate , kk  X   X  set is the query. A better estimation comes from values dependent on the document length. Assumed to update the query model over time during search interaction, decaying weights is assigned to the previous query so as to trust a recent query. Known as Di-richlet smoothing, Bayesian estimation is generally applied to this process. 2.2 Ideal Performance details of the datasets are described in Table 1. mance measures: (1) Mean Average Precision (MAP), a standard non-interpolated average precision and serves as a good measure of the overall ranking accuracy. (2) Precision at top 20 documents (pr@20), reflecting the utility of the top 20 documents. 
Under the framework described in Section 2.1, we examine the ideal performance of existing context-sensitive retrieval model. Two concepts are defined as follows. Definition 1. Ideal Parameter. Given a set of candidate parameters A, ideal parame-ters  X  *  X  A,  X  *  X  X  are picked so as to maximize retrieval performance max  X   X   X   X  is a ranking functi , and E  X   X   X  is evaluation function. performance is attained when combine q u , h c and h q using ideal parameters. 
The ideal parameter represents an ideal situation in which if each query intention is other. Then we use linear search algorithm (step size is 0.1) to try each possible com-highest value. Thus achieved performance is now called ideal performance , and cor-responding parameters are called ideal weights . 
We compare fixed parameters against ideal parameters in Fig.1 and Fig.2. The ho-corresponding ideal weights. The common fixed parameters of the current model are which is different for each query. In contrast to the fixed parameters (marked as fixed- X  ways equal to the ideal ones. 2.3 Potential for Adaptability Under the same framework as in Section 2.1, we compare the performance gap be-tween the current context-sensitive models with fixed weights and those with adaptive weights for contextual information. model, its potential for adaptability is the actual retrieval performance deviations from the ideal performance. 
Fig.3 shows MAP for the ideal context-sensitive ranking with dynamically weight-23.70% improvement over fixed-weighting in terms of MAP and pr@20, respective-gain by dynamic context-sensitive search system. tention is properly expressed. In addition, the retrieval model has substantial room for improvement if the context weight could be properly assigned. 3.1 Regression-Based Context Weight Prediction Model To demonstrate the baseline for the improvement of a dynamic context-sensitive model, we adopt the same framework as described in [1] without any change. which allows the retrieval system to adapt to changing conditions, changing user be-havior patterns and different search setting. We attempt to learn an adaptive strategy automatically instead of relying on heuristics or insights. 
We apply machine learning technique to predict suitable parameter according to the search behavior. In practice, there are two extra prediction models in our adaptive context-sensitive retrieval models. One is used for generating proper parameter  X  , the other is used for generating proper parameter  X  . viewed as a regression issue naturally. Here we choose Support Vector Machines (SVMs), which performs well for most tasks. Specifically, we choose to use Support nuous target value. The support vector regression problem also allows for a zone-of-insensitivity defined by a parameter  X  . 
We apply  X  -SVR, which only cares the errors as long as deviations are larger than  X  y ideal parameters. 3.2 Features Query , CurrentQuery&amp;HistoryClick , and CurrentQuery&amp;HistoryQuery , as summa-rized in Table 2. The broad range of features used enables us to capture many aspects of search activity. previous queries respectively. CurrentQuery&amp;History Click Features: These features appear to be important in sults page and current query. HistoryQuery Features: We can capture the pre-query interaction behavior from racterize the nature of history query from the aspects of query length and the number of previous queries. CurrentQuery&amp;History Query Features: Users have their own habits of expressing search intent and there may be common ground between previous queries and current query. These features are also important in predicting parameters and mainly capture aspects of current query and its relation to previous queries, such as overlap between current query terms and previous queries, as well as the fraction of query term deleted in previous queries. work [6][7]. However, our features are not identical: their features only derived from reformulations between successive history qu eries whereas ours are also derived from current query and the viewed documents. account. The new features are distinguished by bold in Table 2. Our major hypothesis is that the terms which are preserved or amended in user X  X  search interactive behavior suggest the strength of the relation between the current query and corresponding con-text. One advantage of our prediction model is that it can capture the basic rules when accordingly. In order to compare the retrieval performances, we use two performance measures MAP and pr@20. For evaluation we use 90 test queries that have contextual informa-weights. The others are default settings. 4.1 Baseline Methods Specifically, we compare the following methods as described in [1]: models: current query model, history query model and history click model. BayesInt: The only difference between BayesInt and FixInt is that, the interpolation coefficients in BayesInt are adaptive to qu ery length. By treating history query model When viewing BayesInt as FixInt, we see that  X   X  |Q  X  | |Q are both prior sample size.  X  value is 5.0, and  X  value is 0.2. BatchUp: Once collecting new click or new query, information need model is up-dated. It introduces a decaying factor to history queries. BatchUp is described as fol-lows: AdaptiveEW: Our refinements of FixInt and BayesInt take advantages of predicted to optimal combination of history queries and history clicks (  X   X  ), as well as optimal combination of current query and context (  X   X  ). AdaptiveDW: Our refinement of BatchUp takes advantage of a prediction model based on interaction behavior features to obtain proper decaying factor. 
FixInt , BayesInt and AdaptiveEW described above have something significant in common that history information, including history queries and history clicks, are all treated equally, while BatchUp and AdaptiveDW are context-sensitive models which soon as new query or new click is obtained. 4.2 Results are queries containing only one preceding query(hence denoted as Q2), 1/3 contain-ing two preceding queries(Q3), and the rest (Q4) containing three preceding queries. AdaptieDW. 
From the Figures 4 to 5, we can see th at our adaptive model AdaptiveEW consis-tently outperforms baseline models in terms of all evaluation measures, while Adapti-performance is substantially improved with more history information available. Gains reach the climaxatwhen the number of preceding queries is 3. Modest improvements accurate weights predicted by the model depend heavily on rich search behaviors. with  X * X  in Table 2). It reaveals that user interactions behavior is an important indica-tor when assigning weight between current query and context properly. weight (e.g. FixInt method) are not at their best to augment current query with context Regression algorithm to build a weight-prediction model, which enables a more flexi-ble combination of current query and its context. The experimental results show that the proposed model outperforms current static models. Acknowledgments. The work of this paper is supported by the key project of Nation-al High Technology Research and Development Program of China (863 Program, No. 2011AA01A207), the project of National Natural Science Foundation of China (Grant No. 61105072 &amp; 61272384) and the Fundamental Research Funds for the Central Universities. 
