 Many methods for cross-lingual processing tasks are resource-dependent, which will not work without machine translation system or bilingual lexicon. In this paper, we propose a novel approach for multilingual sentiment classification just by few seed words. For a given language, the proposed approach learns a sentiment classifier from the initial seed words instead of any labeled data. We employ our me thod both in supervised learning and unsupervised learning. Experime ntal results demonstrate that our method relies less on external resource but performs as well as or better than the baseline. I.2.7 [ Artificial Intelligence ]: Natural Language Processing Algorithms, Experimentation, Performance multilingual sentiment classificati on, opinion words, clustering, machine translation many multilingual websites are built. For a non-native reader, it is hard to acquire useful information from cross-lingual customer reviews, thus cross-lingual sentim ent analysis has received more attention recently. translation-based methods ha ve been developed. Through translation, the training data and testing data belong to the same language, so that monolingual sentiment classification algorithms can be conducted. However, it is expensive and challenging to build the translation system or bilingual lexicon for the languages that are lack of adequate para llel corpora. Even if there are already translation tools, the translation-based methods suffer from two major drawbacks. On one hand, machine translation system usually generates only one best translation result, so the loss of translation accuracy may deteriorate the sentiment classification accuracy. On the other, the source language and target language may follow differe nt distributions, so the cross-lingual classifier may not perfo rm as well as the monolingual classifier. sentiment classification just by few seed words. For a given language, the proposed approach l earns a sentiment classifier from the initial seed words instead of any labeled data. Our work candidate opinion words by an a dverb. The second step is using two adjectives to cluster the opinion words and unlabeled data into two categories (positive or negative) simultaneously. In opinion words and samples cluste ring, we propose an iterative KL-divergence method to enhance the performance. The third step is to learn a classifier by semi-supervised learning. resource but performs as well as or better than the machine translation method. The impr ovements achieved are mainly because it overcomes the drawbacks of machine translation method. However, our approach is language independent because we don X  X  require any labeled data in either source language or target language. Instead, all we need are few seed words and an amount of unlabeled data in the target language. the Natural Language Processing community (Tang and Tan,2009). A key problem of sentim ent analysis is to determine the polarity of a review is positive (thumbs up) or negative (thumbs down). Pang et al.(2002) compared multiple supervised machine learning algorithms (Naive Bayes, Maximum Entropy, Support Vector Machines) for the ta sk of sentiment classification. This dependency on annotated training data is one major shortcoming of all supervised methods. classification using two human-selected seed words (the words  X  X oor X  and  X  X xcellent X ) in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words. The sentiment of a sample is calculated as the average semantic orientation of all such phrases. Koster, et al. (2003). Mihalcea et al. (2007) discussed different shortcomings of lexicon-based translation scheme and proposed to use a parallel-corpus to train a new classifier with sentences in the target language corresponding to source language. based on machine translation have been prevailed. Fortuna and Shawe-Taylor (2005) studies the us e of machine translation tools for the purpose of cross-lingual te xt classification and mining. Wan (2009) applies a co-training method to leverage resources from both a source and a target language. Shi et al. (2010) transfers the classification knowledge by translating the model features and by using an Exp ectation Maximization algorithm. been applied to cross-lingual sen timent analysis recently. Blitzer et al. (2006) propose an effective algorithm for unsupervised domain adaptation, called structural correspondence learning. Prettenhofer and Stein (2010) propose a cross-lingual text classification approach that builds on SCL. The approach uses unlabeled samples, along with a simp le word translation oracle, in order to induce task-specific, cross-lingual word correspondences. resource-dependent, which will not work without machine translation system or bilingual lexicon. Futhermore, methods based on machine translation rely on the machine translation tool while machine translation itself is a hard problem. Methods based on SCL need a word translation oracle and several human-selected pivot features. However, it is expensive and challenging languages that are lack of adequate parallel corpora. from the labeled source language. When confronted with a target language without any annotated source language data, traditional methods don X  X  work. independent method for multilingual sentiment classification. opinion, sentiment or attitude of reviewers. The intuition of opinion words extraction is to find out words with strong emotion, for these words are informative and discriminative when predicting the polarity of a sample. degree in every language. For exampl e,  X  X ery X  is often used to give emphasis to adjectives or a dverbs in English. Therefore, we first use  X  X ery X  as heuristic info rmation to extract the candidate opinion words by Pattern  X  very w i  X , and then remove stop words from candidate opinion words, such as  X  X f X ,  X  X he X . Here, stop words are generated by words w ith high frequency for individual language. For every extracted opinion word w i , its weight is assigned by Equation 1: Algorithm 1. Algorithm 1 Opinion Word Extraction Input: Unlabeled data, a seed word Output: Stop word list and opinion word list Procedure: 1. Extract all w i according to pattern  X  w i BEHIND very  X  to get the candidate opinion word set C 2. Generate stop words list automatically Statistic the frequency of every word in unlabeled data Put the word with frequency over threshold into stop word list 3. Remove stop word from C to get opinion word List S 4. for every word in S
Statistic the co-occurrence frequency of  X  very w i the weight of w i by Equation 1 list but we don X  X  know the polarity of each word, so we hope to classify the opinion words into two categories. For a given language, there X  X e at least two ad jectives representing the positive polarity and the negative polarity, such as  X  X ood X ,  X  X ad X  in English and  X   X   X ,  X   X   X  in Chinese. These adjectives can be regarded as seed words to cluster the opinion words. In this paper, we propose an iterative KL divergence method to cluster the opinion words and samples simu ltaneously. Our method can be described as three steps: and opinion words roughly. More specifically, a sample containing word  X  X ood/bad X  is re garded as positive/negative and the opinion words in that sample are labeled as positive/negative too. opinion word. A opinion word may occur in both positive and negative samples, so its polarity is ambiguous. We introduce KL-divergence to do the disambiguation work. First, let X  X  explain the basic idea of KL divergence. KL-divergence is a non-symmetric measure of the difference between two probability distributions P and Q. If KL-divergence is applied to single sample, it is called pointwise KL-divergence: appears in Q distribution, junc tion between this word and P distribution is tight, and vice versa. In our work, P represents the positive samples and Q represents the negative samples. The polarity of each ambiguous opinion word is assigned by comparing its  X  (w; pos||neg) and  X  (w; neg|| pos) , and the function is defined as: iteratively. After step 1 and step 2, more polar opinion words are acquired and they provide more he uristic information that can be utilized to re-label the samples. According to the re-labeled samples, we can obtain more accurate polar words and then apply Equation 3 to refine the polarity la beling. Here, the sample is re-labeled by the up-to-date polar opinion word and the opinion word score of a sample d is calculated as: number of positive opinion words, n represents the number of w . Algorithm 2. Algorithm 2 Opinion word Clustering Input: Unlabeled data, unlabeled opinion words, two seed words Output: Labeled opinion words and labeled data Procedure: 1. Labeled all samples and opi nion words by two polar words Loop for I iterations 2. Select n positive and n negative the most confidently predicted 3. Label the opinion words according to selected seed samples Rectify the label of opinion words by Equation 3 4. Re-label all samples according to the up-to-date labeled of labeled opinion words can be improved too, and vice versa. Therefore, we employ an iterative strategy to make labeled samples and labeled opinion words boost each other. corpus translation and features tran slation. In corpus translation, either the training data is translated into target language or the monolingual sentiment classification algorithms can be applied. In transferred by translating the features into target language. Above two methods both suffers from the errors caused by translation and the discrepancy of culture and expression between two different languages. Instead, our method is self-learning and perform as well as or better than the translation-based method. Firstly, we choose a small number of the most confidently labeled samples as initial training data. Secondly, a classifier is trained on the initial training data. Finally, the most confidently predicted samples are added to training data to retrain the classifier in each iteration. It is well known that the performance of semi-supervised learning depends on the initial samples chosen and criterion for samples selected duri ng iteration. In order to improve the accuracy of initial training data, we sort all the samples by opinion word score (Equation 4) a nd pick out the highest ranked samples. Moreover, bias is unavoidable in self-learning, for this reason we propose a new criterion fo r sample selection. The new criterion combines the posterior probability generated by classification model and the opi nion word we have already acquired. For a sample, its final sc ore is calculated as the posterior probability plus the opinion word score under the corresponding category. Algorithm 3 Semi-supervised Learning Input: Initial training data, unlabeled data, labeled opinion words Output: Sentiment Classifier Procedure: 1. Train a base classifier on initial training data Loop for I iterations 2. for each sample Generate the posterior probability p for each category Calculate the opinion word score s for each category 3. Rank all samples according to ( p + s ) for each category 4. Select n positive and n negative samples with the highest ( p + s ) 5. Add the chosen samples to exis ting training data and retrain the classifier conduct experiments on multilingua l hotel reviews (French, German, Spanish, Dutch). These multilingual samples are http://www.booking.com/. Each set of the four languages contains 2000 positive and 2000 negative reviews. classification, we choose Eng lish as source language for the reason that many annotated corpora for English sentiment classification are freely available on the Web. In the experiments of translation-based sentiment classification, we choose 50% labeled data of source language fo r training and 50% labeled data of target language for testing. In semi-supervised learning, we choose 10% the most confidently predicted samples as seed, 50% labeled data as testing set and 40% data as unlabeled set. words as heuristic information. One of the three seed words is used to opinion word extraction and the other two are used to opinion word clustering. For English, we choose the mostly common used three words  X  X ery X ,  X  X ood X  and  X  X ad X . For the other languages, the seed words are translated by Google translation system from  X  X ery X ,  X  X ood X  and  X  X ad X  directly. Table 1 shows the seed words we used in our experiments. Pat, 1995) as base classifier and all words in the corpus as features without reduction and selection. In the contrast test, our approach is compared with two baseline methods: method that we proposed, we conduct several experiments on multilingual hotel reviews. Table 2 contrasts the accuracy of the first 10% confidently predicted samples before and after applying the iterative KL-divergence method. Seen from table 2, after KL iteration, the average accuracy of the first 10% selected samples exceeds the baseline method with a performance improvement of 6.54%. The comparison results de monstrate that using iterative KL-divergence method can improve the performance of initial training data selection. our multilingual sentiment classification approach in supervised learning and unsupervised learning respectively. In supervised learning, testing data of target la nguage is translated into English. In unsupervised learning, the English sentiment-lexicon is translated into target language. Fr om Table 3, we can see that our approach outperforms the baseline1 and baseline2 with a performance improvement of 7.23% and 2.01% on average respectively after semi-supervised learning. sentiment lexicon method with our language-independent Language Baseline 1 Baseline 2 
English-&gt;French 0.7041 0.7700 0.7770 0.8037 
English-&gt;German 0.7402 0.7779 0.7245 0.7913 
English-&gt;Spanish 0.7483 0.7895 0.7935 0.8005 
English-&gt;Dutch 0.7270 0.7910 0.7945 0.8133 Average 0.7299 0.7821 0.7724 0.8022 which proves that machine-transla tion-based method is better than sentiment-lexicon-based met hod in cross-lingual sentiment classification. Our multilingual sen timent classification approach outperforms machine-translation-based method because our approach overcomes the drawbacks of machine translation method. For one reason, machin e translation system usually generates only one best translati on result, and errors caused by translation may deteriorate the sentiment classification accuracy. For the other, the source language and target language follow different distributions, so the cross-lingual classifier may not perform as well as the monoli ngual classifier. However, our method learns the sentiment classi fier on target language directly and its performance just depends on the quality and characteristics of target language. sentiment classification by the least resource. Moreover, our approach is language-independent because we don X  X  require any labeled data in either source la nguage or target language. All we need are few seed words and an amount of unlabeled data in the target language. Our work can be described into three steps: The first step is to extract the candidate opinion words by one seed word. The second step is using two seed words to cluster the opinion words and unlabeled data into two categories (positive or negative) simultaneously. In opinion words and samples clustering, we propose an iterative KL-divergence method to enhance the performance. The third step is to learn a classifier by semi-supervised learning. In order to avoid bias, we combine the posterior probability of classifier and opinion word score together to select samples in each iteration. This work was mainly supported by two funds, i.e., the National Natural Science Foundation of China (60933005 &amp; 60803085). [1] Bla X  Fortuna and John Shawe-Taylor. 2005. The use of [2] Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. [3] John Blitzer, Ryan McDonald, and Fernando Pereira.2006. [4] John Blitzer, Mark Dredze, and Fernando Pereira. 2007. [5] John George and Langley Pat. 1995. Estimating Continuous [6] Lei Shi, Rada Mihalcea et al.2010. Cross-lingual Text [7] Nuria Bel, Cornelis H. A. Ko ster, and Marta Villegas. 2003. [8] Peter Prettenhofer and Benno St ein. 2010. Cross-lingual Text [9] Peter Turney. 2002. Thumbs up or thumbs down? Semantic [10] Rada Mihalcea and Carmen Banea. 2007. Learning [11] Xiaojun Wan. 2009. Co-training for crosslingual sentiment [12] H. Tang, S. Tan and X. Ch eng. A Survey on Sentiment [13] S. Tan, G. Wu, H. Tang and X. Cheng. A novel scheme for [14] S. Tan, X. Cheng, Y. Wang, H. Xu. Adapting Naive Bayes to 
