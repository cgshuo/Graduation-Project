 In some applications such as filling in a customer informa-tion form on the web, some missing values may not be explic-itly represented as such, but instead appear as potentially valid data values. Such missing values are known as dis-guised missing data , which may impair the quality of data analysis severely, such as causing significant biases and mis-leading results in hypothesis tests, correlation analysis and regressions. The very limited previous studies on cleaning disguised missing data use outlier mining and distribution anomaly detection. They highly rely on domain background knowledge in specific applications and may not work well for the cases where the disguise values are inliers.

To tackle the problem of cleaning disguised missing data, in this paper, we first model the distribution of disguised missing data, and propose the embedded unbiased sample heuristic. Then, we develop an effective and efficient method to identify the frequently used disguise values which capture the major body of the disguised missing data. Our method does not require any domain background knowledge to find the suspicious disguise values. We report an empirical eval-uation using real data sets, which shows that our method is effective  X  the frequently used disguise values found by our method match the values identified by the domain ex-perts nicely. Our method is also efficient and scalable for processing large data sets.
 H.2.8 [ Database Applications ]: Data mining Algorithms, Design, Experimentation Data Quality, Data Cleaning, Disguised Missing Data This research is supported in part by NSERC Discovery Grant 312194-05. All opinions, findings, conc lusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00.
Processing missing values is one of the most important tasks in data cleaning. Many methods have been developed to handle explicitly missing values or conduct analysis and data mining on noisy data sets with explicitly missing data.
Interestingly, in many applications, some missing values may not be explicitly represented as such, but instead ap-pear as potentially valid data values. Such missing values are known as disguised missing data [5].

Example 1 (Disguised missing values). Consider the situation where a customer fills in an online applica-tion form of a frequent flyer program. Attribute gender has two choices: male or female . A system may set one of the two values, say male in this example, as the default value. Many customers may not want to disclose this information, or may not want to spend time to fill in the information. The consequence is that many missing values may disguise themselves as the default value, male in this case.
Using system default values is not the only cause trans-lating to disguised missing data. As another example, the attribute birth date isoftenrequiredinmanycustomerac-count registration forms. However, many customers do not want to disclose their privacy. Popularly, one may choose January 1 (the first value in the pop-up lists of month and day, respectively) in order to pass. Here, January 1 is a disguise for the missing data.

Disguised missing data exist in real applications. For ex-ample, we will analyze two real data sets in Section 5: the Pima Indians Diabetes database containing records about Pima Indian females who are at least 21 years old and tested either positive or negative for diabetes, and the Adverse Event Reporting System data set from the U.S. Food and Drug Administration in the first quarter of 2004. Disguised missing data are detected in both data sets. Interestingly, many previous machine learning studies (e.g., [2, 6]) use the Pima Indians Diabetes database but presume that the data set has no missing data.

Disguised missing data may impair the quality of data analysis severely. Significant biases may be caused by the disguised missing data. As illustrated in [5], due to the dis-guised missing data, some simple statistics such as standard deviation may shift to some anomalous values. Moreover, hypothesis tests, correlation analysis and regressions using disguised missing data may give misleading results.
Disguised missing data pose a much more serious chal-lenge for data cleaning than explicitly missing values. For explicitly missing values, the exact missing entries are known and thus strategies can be developed to avoid using those entries in data analysis. For disguised missing data, how-ever, we may not even know the exact missing entries. In the situations illustrated in Example 1, the resulting data set may contain the male customers who did provide the information, and some customers born on January 1. How to distinguish those disguised missing values and those real values is far from trivial.

Although there are extensive studies on data analysis with missing values, to the best of our knowledge, the problem of cleaning disguised missing data has not been investigated thoroughly. In this paper, we tackle the problem and make the following contributions. First, we analyze the distribu-tion of disguised missing values and identify the important and interesting embedded unbiased sample (EUS) heuristic that often holds for disguised missing values: the projected database of a disguise value often contains a large unbi-ased sample of the whole data set. Based on this prop-erty, we propose a general framework to identify suspicious frequently used disguise values. Second, mining frequently used disguise values from large data sets is computationally challenging. We devise efficient and scalable heuristic al-gorithms. Last, we test our approach using both real data sets and synthetic data sets. The experimental results show that our method is effective X  X he frequently used disguise values found by our method match the values identified by the domain experts nicely. Our method is also efficient and scalable for processing large data sets.

The rest of the paper is organized as follows. In Section 2, we describe disguised missing data formally and review re-lated work. In Section 3, we present the embedded unbiased sample property and propose a framework of finding suspi-cious frequently used disguise values. We develop an efficient data mining approach in Section 4. Experimental results are reported in Section 5. The paper is concluded in Section 6.
For a tuple t in a table T ,thevalueof t on attribute A is denoted by t.A , which is also called an entry .Indata collection, for an entry t.A , three situations may arise.
Case 1: The user provides a value to the entry that, to the best of the user X  X  knowledge, reflects the fact in the real world and should be captured . Due to observation errors, it is possible that a user provides an incorrect value to the entry. The point we want to make in this case is that the entry value is not missing in its nature .

Case 2: The user does not provide a value .Inotherwords, t.A is explicitly missing , denoted by t.A =  X  ,where  X  is a meta symbol not in the domain of any attribute.

Case 3: The user does not intend to provide a value that reflects the fact in the real world . However, due to some data collection mistakes, such as the cases illustrated in Exam-ple 1, a value in the domain of A is recorded in the table. In other words, a disguised missing value happens. Although the entry value is missing in its nature, the table records a  X  X ake X  value, which is called a disguise value.

Formally, let T be the truth table and T be the recorded table . Here, the truth table contains the data that should be recorded. There exists a one-to-one mapping between the tuples in T and T . That is, for any tuple t  X  T ,thereisa corresponding tuple t  X  T ,andviceversa.
 For any entry t.A ,if t.A =  X  ,then t.A = t.A .That Symbol Explanation t.A , t.A An entry in the fact/recorded table  X  ( T, T ) The correlation-based sample quality score is, if an entry in the truth table is not missing, then it is collected correctly in the recorded table. However, if t.A =  X  ,then t.A can be either  X  or a legal value in the domain of A . Particularly, an entry t.A is called disguised missing if t.A =  X  but t.A =  X  .Thevalue t.A is the disguise of the disguised missing entry, or called a disguise value .Figure1 summarizes some frequently used notations in the paper.
In data cleaning, we are given the recorded table T , while the truth table T is typically unavailable. Ideally, the prob-lem of cleaning disguised missing data is to find the values that are frequently used as disguise values, and the set of disguised missing entries.
 Cleaning disguised missing data in general is very difficult. As an extreme example, if the missing values in the truth table are disguised by independent and random values in the domain of the attribute, it is very hard to unmask them without any hints.

Several heuristic approaches have been considered for clean-ing disguised missing data. For example, with background knowledge, a domain expert can screen entries with suspi-cious values, such as blood pressure of 0. More generally, outliers can be found and considered as potential disguised missing values [4]. However, if a data set has many disguised missing entries, such as those disguised male entries in Ex-ample 1, they may not appear as outliers. One heuristic way to detect the existence of such disguised missing data is to detect distribution anomalies [4]. For example, if we observe that the number of tuples having value male is much larger than that of tuples having value female ,andweknowthat the populations of males and females in the data set should be balanced, then we can conclude that some male entries in the data set may be disguised missing.

Although the problem of cleaning disguised missing data has been tackled from some angles, the existing approaches often rely on domain knowledge heavily, and are developed for specific applications. However, domain knowledge is of-ten incomplete or even unavailable for many data analysis tasks. For example, the correct distribution of an attribute may not be known. Then, analyzing suspicious values, out-liers and distribution may become difficult and unreliable. As observed in [1], a missing value may disguise itself as an inlier , a data value that lies in the interior of the statistical distribution of normal data values. Those inlier disguised missing values cannot be detected effectively using the ex-isting methods. In addition, due to their heavy reliance on domain knowledge, most of the existing methods are not general and capable for generic applications.
In this section, we first observe the embedded unbiased sample heuristic of frequent disguise values. Then, we pro-pose a framework for cleaning disguised missing data, and analyze the computational challenges.
As analyzed before, if missing values disguise themselves randomly, it is very difficult to identify the disguised missing data. Fortunately, such random disguising often does not happen extensively in practice. Instead, as illustrated in Example 1, a small number of values (typically one or two in an attribute) are frequently used as the disguises. It is practical to make the following assumption.

Assumption 1 (Frequently used disguises). On an attribute, there often exist only a small number of disguises that are frequently used by the disguised missing data.
Under the missing completely at random (MCAR) and missing at random (MAR) models [3], missing data are often distributed randomly in real data sets. Consequently, dis-guised missing entries are often distributed randomly, too, as verified by our experimental results using real data sets.
Example 2 (EUS heuristic). Consider the situation described in Example 1. Let T male be the set of tuples carry-ing value male on attribute gender . Conceptually, T male be divided into two exclusive subsets as shown in Figure 2.
The first subset, R male , contains those tuples whose values on attribute gender are not missing in the truth table. The second subset, S male , contains those tuples whose values on attribute gender are disguised missing and the value male is used by them as the disguise value.

Heuristically, if the disguised entries are randomly dis-tributed and value male is frequently used as a disguise, the set S male is an unbiased sample of the truth table except for attribute gender itself (all tuples in S male take value male on gender ). Similarly, we can also divide T female ,thesetof tuples having value female on attribute gender ,intotwo subsets R female and S female .Ifvalue male is used more fre-quently as the disguise value on attribute gender ,then S
According to Assumption 1, on each attribute, there are only a very small number of values that are used as disguises. In other words, it is likely those disguise values contain sub-sets of tuples that are unbiased samples of the whole data set. As a heuristic, if a value contains a large subset of tu-ples that is an unbiased sample of the whole data set, this value is suspicious of a disguise value.

For a value v on attribute A , the set of tuples in T carrying the value on the attribute is called the projected database of v , denoted by T A = v = { t  X  T | t.A = v } . Hereafter, for the Figure 3: The relationship among several concepts. sake of brevity, we assume that the domains of attributes are exclusive, and thus a value belongs to the domain of at most one attribute. Then, we can write T A = v as T v .
We observe the following embedded unbiased sample heuris-tic ( EUS heuristic for short) of disguised missing data. The Embedded Unbiased Sample Heuristic If v is a frequently used disguise value on attribute A ,then T A = v tains a large subset S v  X  T A = v such that S v is an unbiased sample of T except for attribute A .

Interestingly, the heuristic is also applicable to contin-uous attributes and does not need discretization, since as the frequently used disguise values are fixed, their projected databases may often be much larger than the projected databases of other values. It is insensitive to the variances of attribute values due to the same reason.
Since a small number of values may be used frequently as disguises, a critical step in cleaning disguised missing data is to find the disguise values used frequently in attributes .
For each value v on attribute A ,let T v be the set of tuples carrying value v in the truth table. Clearly, T v  X  T v . Then, S v =( T v  X  T v ) is the set of tuples using v as the disguise on attribute A .Wecall S v the disguised missing set of v .
According to the EUS heuristic, S v is an unbiased sample of T . The larger the size of S v , the more frequently v is used as the disguise value. A value v is called a frequent disguise value if it is frequently used as disguises.

Unfortunately, S v is unknown and cannot be computed accurately from T in general. The EUS heuristic suggests a heuristic way to find those frequent disguise values. Es-sentially, on each attribute, we can find a small number of attribute values whose projected databases contain a large subset as an unbiased sample of the whole table. Such at-tribute values are suspects of frequently used disguise values. The larger the unbiased sample subset, the more likely the value is a disguise value.

Technically, for value v on attribute A ,let M v  X  T v be the maximal subset of T v that is an unbiased sample of D . M is called the maximal embedded unbiased sample ,or MEUS for short. We can use the size and the quality (i.e., how well it resembles the distribution of the whole data set) of M v as the indicators of how likely that v is a disguise value. Those values with a large MEUS should be reported as the suspects of frequent disguise values. Figure 3 illustrates the relationship among the three sets T v , M v ,and S v .
On the other hand, the above heuristic may not hold all the time. For example, many people may submit their tax returns on the deadline day. Thus, on attribute submission-date , the projected databases of the dates on or right before Phase 1: Mining candidates of frequent disguise Input: Atable T and a threshold on the number of Output: for each attribute, k candidates of frequent Method: 1: FOR each attribute A DO 2: // applicability test 3: FOR each value v on A DO derive M v ; 4: find the value(s) with the best and largest M v  X  X ; Phase 2: postprocessing : verify the candidates of the deadline may likely contain large unbiased samples of all tax returns, while the dates on or right before the deadline are often not frequently used disguise values.

To ensure that the EUS heuristic fits a data set, before we apply the heuristic approach to look for suspicious dis-guise values in an attribute, we should first test whether most of the projected databases of the frequent values in the attribute are unbiased samples of the whole database. The heuristic should be applied only if most of the projected databases are not unbiased samples.

Based on the above discussion, a general framework of cleaning disguised missing data is shown in Figure 4. The framework is in two phases. In the mining phase, we ana-lyze each attribute to check whether our heuristic approach is applicable. We find the candidates of frequent disguise values on the applicable attributes. In the postprocessing phase, those candidates can be verified by domain experts or other data cleaning methods.

In the rest of this paper, we focus on the first phase of the framework, which reduces the number of candidates sub-stantially and thus makes the domain experts X  analysis effec-tive. Please note that in our approach, the first phase does not require any domain knowledge and can be conducted automatically. There are some important technical challenges.

First, how can we measure whether a set of tuples is an unbiased sample of a table? Typically, the table in ques-tion is of multiple attributes. A sample with a non-trivial sample rate (i.e., not close to 100%) may lose some informa-tion about the rare combinations of attribute values. Statis-tically, measuring whether two multidimensional data sets have a similar distribution is far from trivial.

Second, how can we compute a maximal embedded unbi-ased sample M v from the projected database T v ? One serious difficulty is that the subsets are not monotonic in terms of their similarity to the whole data set in distribution. For U  X  T v , U may contain a subset V  X  U such that V re-sembles the distribution of T better than U . On the other hand, another subset W  X  U may be worse than U in terms of being an unbiased sample. In general, finding M v is com-putationally costly.

Last, Can we avoid computing the MEUS for every at-tribute value v ? As computing the MEUS for a value is already costly, computing all MEUS X  X  for all values on all attributes can be too expensive in large databases where there are tens of attributes and each attribute has tens or hundreds of possible values on average. Given table T on attributes A 1 ,...,A n and a subset T  X  T , we want to measure whether T is a good sample of T .In-tuitively, correlations can capture the distribution of a data set nicely. If values correlated in T are also correlated in T and vice versa, then likely T and T are of similar dis-tribution. Based on this intuition, we can use correlations of pairs of values to measure how good a sample T is with respect to T .

Technically, let v i 1 ,...,v i l be values on attributes A A l , respectively, where A i j = A i k for j = k . The probabil-ity of a tuple in T having v i 1 ,...,v i l is given by The correlation among the occurrences of v i 1 ,...,v i l sured by Similarly, we can obtain the probability and the correlation on subset T .

Computing correlations on multiple variables can be costly on large data sets. Practically, we can consider only corre-lations of variable pairs. Let v i and v j be two values on attributes A i and A j , respectively. The correlation between v and v j (also called the lift sometimes) is given by
To measure how good a sample the subset T is with re-spect to T , we compare the correlations in T and T and calculate the correlation-based sample quality score , denoted by  X  ( T, T ), as where Corr T and Corr T are the correlations on T and T , respectively, and q is the order imitating the order of Minkowski distances.

The correlation-based sample quality score uses the value pairs in the subset T as features to measure the sample quality. A sample quality score is a non-negative number. The larger the score, the better T an unbiased sample of T . In the score, we accommodate the following major factors.
First, the score opts for subsets T where the correlations in T are similar to those in T . However, since T is a sample of T and is smaller in size, there can be many pairs of at-tribute values appearing in T but not in T .Thus,thescore does not check pairs correlated in T but not appearing in T . Instead, to measure whether those popular correlations are captured, the probability of an attribute value pair (i.e., P ( v i ,v j ) as the numerator) is used as the weight. A sample capturing more correlations and more popular correlations has a higher score.

Second, in the score, we use correlations of attribute value pairs. Generally, we can use correlations of sets of attribute values of arbitrary size. In the worst case, two data sets may have very similar correlations on every pair of attribute values, but may still be quite different in the full space dis-tribution. However, computing correlations among multiple attribute values can be expensive on large data sets. On the other hand, in practice, correlations of attribute value pairs are often good enough to serve the purpose of measuring the similarity of distributions, as shown by our experimental re-sults on real data sets.

Last, we normalize the difference between the correlations of an attribute value pair in T and T to range [0 , 1] by using the difference of correlations in the denominator. This technical treatment avoids biasing value pairs of very similar correlations in T and T .
 For each value v on attribute A , we compute M v ,the MEUS of v . To measure the potential that a value v is a frequent disguise value, we consider two aspects: the quality oftheMEUSmeasuredby  X  ( T v ,M v ) and the relative size of M v with respect to T v . The latter aspect reflects how well the projected database fits the EUS heuristic. Thus, we define the disguise value score (DV-score for short) of a subset U  X  T v as dv ( v, U )= | U | | T (frequent) disguise value score ( DV-score for short) of v is defined as M v , the maximal embedded unbiased sample, is a subset maximizing the DV-score. That is,
Generally, the DV-score is not monotonic with respect to the set containment relation. That is, for a subset U  X  T v and W  X  U , dv ( v, W ) may be larger or smaller than dv ( v, U ). The non-monotonic nature of the DV-score indi-cates that computing the maximal embedded unbiased sam-ples is computationally challenging. In the worst case, one may have to consider an exponential number of subsets in order to find M v . It is often too costly for popular values (i.e., | T v | is large) in large databases.

To tackle the problem practically, we adopt a greedy ap-proach as shown in Figure 5. We start with the projected database T v as the initial sample. In each interaction, for a tuple t in the current sample, we calculate the DV-score gain if t is removed from the current sample set. A tuple with the largest positive DV-score gain is removed as the result of the current iteration. The iteration continues un-til the DV-score cannot be improved further by removing one tuple from the current sample. The resulting sample is output as the approximation of M v .
 Input: atable T and a value v on attribute A ; Output: approximate M v ; Method: 1: U  X  T v ; 2: REPEAT 3: FOR EACH tuple t  X  U 4: remove a tuple t 0 with the largest DV-score gain if 5: UNTIL no tuple can be removed; 6: RETURN U ; Figure 5: A greedy method to compute approximate MEUS.
A straightforward implementation of the greedy algorithm may still be costly on large databases. Once a tuple is re-moved, the total number of tuples in the current sample is reduced, and thus the correlation between every value pair changes. Therefore, for each round in the iteration, we may have to update the correlation of each value pair, and also re-compute the DV-score gain for every surviving tuple in the current sample. The complexity of the algorithm is O ( | T Clearly, when the projected database T v is large, the over-head can be substantial. Here, we present some techniques to improve the efficiency of the greedy search.
Since the DV-score of a tuple changes whenever the sam-ple changes, and computing the DV-score gain can be costly, we would like to find some heuristics that help us to, with-out re-computing the DV-scores for all tuples, identify the tuples that may lead to good DV-score gains.

Let support sup ( v i ) be the number of tuples in the cur-rent sample that contain value v i . Wedenotethenumber of tuples in the current sample by n . Then, the correla-tion of v i and v j in the current sample can be rewritten as
Once a tuple is removed, one of the following three cases arises.

Case 1: If the tuple does not contain v i or v j ,then sup ( v i ,v j ), sup ( v i )and sup ( v j ) remain, but n decreases. The correlation decreases, too. The change is sup ( v i ,v
Case 2: If the tuple contains both v i and v j ,removingthe tuple leads to a change of the correlation between v i and v However, how the correlation changes depends on the values of the supports of v i , v j and their combination.
Case 3: If the tuple contains only v i or v j but not both, then removing the tuple boosts the correlation between v i tuple contains v j but not v i .

Based on the above observations, we can maintain the cor-relation information as follows. For each value pair ( v i we keep its correlation and its probability in the whole data set, i.e., Corr T ( v i ,v j )and P T ( v i ,v j ). Those values do not change during the computation and thus should be com-puted only once.
We also maintain the correlation between v i and v j in the current sample, i.e., Corr U ( v i ,v j ), and whether it is greater than or smaller than Corr T ( v i ,v j ). Instead of computing the DV-score gain for each tuple at each iteration, which is very costly, we assign each tuple t a contribution score as f ( v i ,v j , t )=1ifremoving t reduces the difference between Corr U ( v i ,v j )and Corr T ( v i ,v j ); and, otherwise,
The value of f can be computed quickly using the three cases of how Corr ( v i ,v j ) changes as analyzed before. Once a tuple is removed, we update the correlations affected. Then, a surviving tuple in the current sample changes its contri-bution score only if it contains some value pairs whose cor-relations are affected. We do not need to recompute the contribution scores of other tuples. Comparing to comput-ing DV-score gains, contribution scores are often much easier to maintain.

Following the spirit of the greedy search, we pick the tu-ple with the largest positive contribution score, compute its DV-score gain, and remove it from the current sample if the gain is positive. The algorithm terminates if we cannot find any tuple with a positive contribution score, or the DV-score gain is not positive. As shown in our experiments us-ing real data sets, the heuristic method improves the search efficiency substantially, and still gets results of good quality.
Computing the approximate MEUS for a value v may not be cheap. If we have to compute the approximate MEUS for each value on an attribute, it can be expensive. Once we compute the MEUS for one value or some MEUS X  X  for several values on one attribute, can we use the information to prune the computation of the MEUS X  X  of other values on the same attribute? There are multiple values on an attribute. In which order should we process those values and derive their DV-scores so that more pruning may happen?
If we can get large DV-scores from the first several values that we process, then we may have a better opportunity to prune the remaining values. Based on this observation, we should start with the most frequent value on an attribute. Heuristically, a large projected database may have a better chance to have a subset as an unbiased sample, and thus achieve a better DV-score. Therefore, on each attribute, we should process the values in their support descending order to compute their DV-scores.
 Suppose u is the value on attribute A that has the largest DV-score so far. When we consider value w on the same attribute, if we can determine that dv ( w ) must be smaller than dv ( u ), then we do not need to compute the exact value of dv ( w ), since u is a better suspect of frequent disguise value on this attribute. How can we determine early that dv ( w ) is smaller than dv ( u ) ?
If U is the current sample of w in the greedy search (Fig-ure 5), then, since in the definition of the correlation-based sample quality score (Equation 1) an upper bound of d ( w, U )isgivenby
Therefore, during the greedy search, we check after each search should stop since v cannot have a better DV-score than u due to the first inequality of Equation 2. smaller than dv ( u ), then we even do not need to search for v according to the second inequality of Equation 2. For many infrequent values on the attribute, this case may happen and thus those infrequent values can be pruned directly.
In this section, we report a systematic empirical study using real data sets and synthetic data sets. All the ex-periments were conducted on a PC computer running the Microsoft Windows XP Professional Edition operating sys-tem, with a 3 . 0 GHz Pentium 4 CPU, 1 . 0 GB main memory, and a 160 GB hard disk. Our algorithms were implemented in Microsoft Visual C++ V6.0. By default, our method was implemented as described in Section 4. We used the greedy search method with the help of contribution score, and set the order q = 1 in the correlation-based sample quality score (Equation 1). We tested our method on two real data sets, the Pima Indians Diabetes Database from the UCI Machine Learn-ing Database Repository 1 and the AERS (Adverse Event Reporting System) data set from the U.S. Food and Drug Administration (FDA) 2 . In both data sets, all attributes pass the applicability test of our approach. That is, for each attribute there exists at least one relatively frequent value whose projected database is not an unbiased sample of the whole data set. We used some thresholds to conduct the test. Limited by space, we omit the details here.
In the rest of this section, our goal is to find the most likely frequent disguise value for each attribute.
There are 768 records in the Pima Indians Diabetes data set. All the records are on eight attributes of Pima Indian females who are at least 21 years old and tested either pos-itive or negative for diabetes. The domain of each attribute is numeric, and no explicitly missing value is reported. How-ever, some disguise missing data are detected by examining the suspicious values found in our experiments as shown in Table 1.

On the attributes diastolic blood pressure , triceps skin fold thickness , 2-hour serum insulin ,and body mass index ,our method detects 0 as the most frequent disguise value. The results match the domain knowledge. In those attributes, 0 is a suspicious value since unlikely those attributes take values 0 for a person of reasonable condition. There are 35, 227, 374 and 11 tuples having value 0 in those four attributes, respectively. Each projected database of those values forms the maximum embedded unbiased sample of the whole database. In other words, those values are quite evenly distributed in the data set. This observation strongly supports the embedded unbiased sample property of the fre-quent disguise values.
Figure 6: Distribution of covariance cor-relation between the frequent disguise value and values in other attributes.
Let us further analyze the suspicious disguise value di-astolic blood pressure 0 in detail. Figure 6 plots the co-variance correlations between value 0 and values on other attributes. To make the figure easy to read, we plot the cumulative frequencies of the correlations. That is, we sort all values on other attributes according to their covariance correlations with respect to 0 on attribute diastolic blood pressure , in value ascending order. The figure plots the per-centage of values whose covariance correlation with 0 are up to e , while e is the variable shown in the horizontal axis. More than 80% of the values have a covariance correlation in range [  X  0 . 1 , 0 . 1]. This highly indicates that value 0 on this attribute is distributed evenly. For comparison, we also plot the distribution of normal value 50 as an example. As can be seen, value 50 has stronger correlations with values other than 0.

Our method is different from simply picking the most fre-quent value on an attribute as the suspect. For example, on attribute diastolic blood pressure , our method picks value 0, which turns out is a suspicious value. In the same attribute, value 70 is the most frequent one, appearing 57 times. In fact, value 70 corresponds to the normal blood pressure of a human being in good health. The reason that our method can pick 0 as a suspicious value instead of 70 is that the normal blood pressure may be correlated with some other attribute values for a person in good health, which makes the value 70 not evenly distributed in the database.
Our method can find not only disguise values that are outliers or suspects in the domains of the attributes, but also those inliers which cannot be found by previous methods. For example, on the attribute age , value 21 is picked by our method as a suspicious frequent disguise value. The domain of the attribute is from 21 to 81. However, value 21 appears in 63 tuples, nearly 10% of the data set. Our greedy method finds a sample of 57 tuples that resembles the distribution of the whole data set well. A conjecture here is that value 21 may be used as the default value when the patients X  age information is collected.

On some attributes where the domain is highly diverse and the frequency of every value is very low, our method cannot find any suspicious frequent disguise values. For example, in the attribute Diabetes pedigree function , the frequencies of all values are below 1%. Therefore, no suspicious disguise value is reported. In our implementation, we used a support threshold to prune.

The Pima Indians Diabetes Data set is widely used in pre-vious machine learning studies (e.g., [2, 6]). Most of the pre-vious studies using this data set presume that the data set has no missing data. However, the above analysis strongly indicates that a substantial part of the tuples may have dis-guised missing data in the five attributes, namely diastolic blood pressure , triceps skin fold thickness , 2-hour serum in-sulin , body mass index ,and age . With the disguised missing data, the results of those analysis may not be accurate.
We also tested our method on the AERS data set, which contains adverse events reported to FDA from January 1, 2004 to March 31, 2004. Since some attributes contain a large portion of explicitly missing values, we pick the 7 at-tributes with the fewest missing values, namely ISR , CASE , Event DT , FDA DT , AGE , WT ,and Rept DT ,andremove the tuples with missing entries. There are totally 18 , 174 records in the resu lting data set.

Our method detects some inlier suspicious frequent dis-guise values, such as value 20030101 (i.e., Jan 1, 2003) on attribute Event DT ,value 20040319 on attribute FDA DT , and value 20040311 on attribute Rept DT .Ourresultsmatch the analysis reported in [5], which identifies the suspicious disguise values using domain knowledge to detect abnormal statistic distributions. Different from [5], our method de-tects those disguise values without any domain knowledge.
The results on the two real data sets highly suggest that our method is effective and accurate in finding suspicious frequent disguise values. Moreover, our method can be ap-plied to a wide range of applications, and does not need to use any domain knowledge to identify suspects. It can find frequent disguise values as outliers or inliers.
We also tested whether our method can be used to detect not only the frequent disguise values, but also the disguised missing entries, that is, the exact locations (the tuples and the attributes) where the entries are disguised missing.
To the best of our knowledge, there are not real data sets in which the disguised missing entries are annotated. Thus, we modified a real data set in our test.
 We used the Breast Cancer Wisconsin data set from the UCI Machine Learning Database Repository 3 . Totally there are 699 records in the data set. Each record represents one breast cancer case. There are only 16 missing values re-ported in the data set.

We randomly injected the disguised missing data into the attribute Uniformity of Cell Size whose domain is integers between 1 and 10 (inclusive). We chose this attribute be-cause there is one very frequent value in this attribute, value 1 occurring in 384 tuples (i.e., 54 . 94% of the tuples in the data set). We want to test how sensitive our method is with respect to the population of disguised missing data.
We tested the capability of our method in detecting dis-guised missing values from two aspects.

First, we tested how well our method can identify the disguised missing values which use an outlier as the disguise. We randomly chose s % of the tuples in the data set and replaced their values on the Uniformity of Cell Size attribute by 0, where s is a parameter varying from 1% to 10% in our experiments. Figure 7 shows the DV-score of the outlier disguise value 0 and those of the top-2 legal values in the domain with the highest DV-scores.

When the support of 0 is greater than 6%, the DV-score of 0 is the highest on the attribute and thus 0 is captured by our method as the frequent disguise value. Although here the support of 1 is much higher than the support of 0 in such a case, our method can detect the disguise value accurately based on the distribution, and is robust to the large difference in frequency.

When the support of 0 is smaller than 6%, the DV-score of 0 cannot exceed those of 1 and 3, the two legal values with the highest DV-scores. In such a situation, the projected database of 0 is too small to resemble the distribution of the whole data set, and thus 0 cannot be detected by our method as a frequent disguise value.

This experiment clearly shows that our method can de-tect outlier disguise values in very low support, and is not sensitive to popular but not disguise values.

In the above case, the projected database of 0 is the MEUS returned by our method. Thus, once 0 is detected as the disguise value, all disguised missing entries can be identified correctly.

Second, we tested the effectiveness of our method on dis-guised missing entry detection for disguise values as inliers. We chose value 6 as disguise since it has the lowest DV-score in the attribute, which means that its projected database is the most biased. We randomly chose s % of tuples in the data set and replaced their values on the Uniformity of Cell Size attribute by 6, where s is a parameter varying from 1% to 10% in our experiments. The results are shown in Fig-ure 8. When the support of 6 is 8% or over, value 6 has the largest DV-score and thus is identified by our method as the top suspicious frequent disguise value. When the support of 6 is 8%, there are 82 tuples in the projected database of 6, 56 of them are disguised missing values injected by us. Our method reports a MEUS of 6 having 75 tuples. Among those tuples, 55 are those injected by us. In other words, the MEUS returned by our method captures most of the disguised missing data. This also verifies the effectiveness of our greedy method in searching MEUS X  X .

From this set of experiments, we can clearly see that our method is capable of finding MEUS X  X  for disguise values as either outliers or inliers. The MEUS X  X  cover most of the disguised missing data. This property is important and very useful for cleaning disguised missing data.
The correlation-based sample quality score (Equation 1) takes a parameter, order q , to imitate the order of Minkowski distances. To test the effect of the parameter, we varied the order from 1 to 6 and compared the average size of the approximate MEUS X  X  returned by our greedy method for all values in each attribute in the Pima Indians Diabetes data set. In Figure 9, we measure the relative size of a MEUS of value v by dividing the number of tuples in the MEUS by the number of tuples in the projected database of v . Limited by space, the figure shows the results on only three attributes, while the trends in other attributes are consistent.
The average MEUS size decreases when the order increases, though the changes are quite moderate. With a higher or-der, a sample is penalized more if it has more value pairs of correlations different from the whole data set. On the other hand, small samples with less value pairs in the sam-ple may avoid some penalties, and thus are preferred by a higher order.

Interestingly, the frequent disguise values are stable with respect to the order. Among all the attributes in the Pima Indians Diabetes data set, when the order varies from 1 to 6, only the suspicious disguise value on attribute Body mass index changes. When the order is 3 or higher, value 312 replaces value 0 as the top frequent disguise value, but value 0 still has the second highest score among all the values. Therefore, our method is insensitive to the order.
In Section 4.3.1, we introduce contribution scores to im-prove the efficiency. We tested the effectiveness of the contri-bution scores. That is, we compared the MEUS X  X  computed using the DV-score gain-based greedy search and those com-puted using the contribution score-based greedy search.
We used the Pima Indians Diabets data set. The results are shown in Table 2. We compared the most frequent dis-guise values returned by the two search methods on the 7 attributes (i.e., except for the attribute diabetes pedigree function where attribute values are of very low frequency as analyzed before). In the table, the most frequent disguise values and the numbers of tuples in the MEUS X  X  returned by the two search methods are shown. We also list the num-
Figure 9: Average relative MEUS size with respect to order in sam-ple quality score. ber of common tuples in the MEUS X  X  returned by the two methods. We observe the following.

First, in most cases, the two search methods return the most frequent disguise values consistently. In this experi-ment, the only exception is the attribute diastolic blood pres-sure , where the DV-score gain-based method returns value 70 (the most frequent value on this attribute) and the contri-bution score method returns value 0 (the suspicious value). It happens the contribution score method picks the correct answer in this case. Overall, the two methods are consistent.
Second, the MEUS X  X  returned by the two methods are highly consistent as long as they pick the same suspicious disguise value. Occasionally, the contribution score method returns a larger MEUS (e.g., for attributes triceps skin fold thickness and age ). The similarity between the MEUS X  X  is at least 86% in our experiments 4 .

The experiments clearly show that the contribution score method is consistent with the DV-score gain method. As we can see in the next section, the contribution score method can be much faster and more scalable than the DV-score gain method, and is practical for large real data sets.
We also evaluated the efficiency and the scalability of our approach with respect to the size of the data set and the dimensionality. We tested both the method using the DV-score gain and the one using the contribution score in the greedy search. To obtain large data sets, we duplicate the AERS data set up to 5 times (with 7 attributes). As shown in Figure 10, both methods have a linear scalability, but the contribution score-based se arch is much more efficient.
We tested the scalability of the two methods with respect to the dimensionality of the data sets using the Pima Indi-ans Diabetes data set. The results are shown in Figure 11. The contribution score-based search is faster. However, the dimensionality curse appears. The runtime of both methods increases exponentially as the number of attributes goes up. The reason is that, with more attributes, there is an expo-nential increase in the number of value pairs that need to be checked in computing the scores.
Data cleaning is a foremost step for many data analy-sis tasks. In this paper, we tackle the important, practical and challenging problem of cleaning disguised missing data. We identify the interesting and useful embedded unbiased sample property of disguised missing data in practice, and propose a novel and practical heuristic approach. Our ex-tensive empirical evaluation using both real data sets and synthetic data sets clearly show that our method is effective and efficient for cleaning large data sets, and can be used in practical applications.
