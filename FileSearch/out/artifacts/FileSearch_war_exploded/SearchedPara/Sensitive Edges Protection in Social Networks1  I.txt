 A social network can be modeled as a graph in which each node represents an individual, and the connections between individuals are summarized by the edges. An original graph G is shown in figure 1( a ), and figure 1( b )demonstrates the naive anonymization G  X  [1] which replaces all identifiers of individuals with randomized integers. However, this simpl e strategy can X  X  resist attacks by the structural knowledge of individuals such as degree, neighborhood graph, and so on. Most of the previous works have been studied on protecting the node re-identification and edge re-identification in social networks. Recently, online social network sites of twitter and weibo have developed the new application of close friends, which means a person X  X  close friends are confidential for participators in the social networks. For example, in figure1( c ), Bob and Carol are close friends, while Alice and Carol are regular friends. The sensitive edge represented by the dotted line is the sensitive information which needs to be protected in our paper.
Zheleva et al.[2] first considered a link re-identification attacks in which the adversary infers sensitive relationships from non-sensitive ones in the graph that contains multiple types of edges. Comparing with anonymous strategy in [2], our method has the following differences. First, the graph in [2] contains multiple types of edges which could simultaneously exist between two nodes. In our paper, there are two types(sensitive or non-sensitive) edges in the graph, and only one edge could exist between two nodes. Seco nd, the node in our graph is described by a label, which is neglected in [2]. This label, generalized in the anonymization, is available for the data utility of aggregate network queries. Third, [2] applies clustering-based method in producing super nodes and super edges to protect relationships disclosure, while our method create some noise edges. Some graph properties, such as clustering co-effici ent and average path length, couldn X  X  be calculated in their anonymous results.

The remainder of the paper is organized as follows. Section 2 gives the problem definition. Section 3 introduces two anonymous algorithms. Section 4 reports experimental results. Section 5 concludes the paper. In this paper, a social network is modeled as an undirected simple graph G ( V,E s , E n ,L, L ), where V is a set of nodes, E s is a set of sensitive edges, E n is a set of non-sensitive edges, L is a set of labels and a function L : V  X  L assigns each node a label. A label has an identity(such as user id or name), and a set of properties(such as age, gender and country). Let G  X  denotes the anonymous graph of G .
The first step to anonymization is to know what external information of a graph may be acquired by an adversary. In an social network, an attack can easily view a person X  X  partial profile and his connection information. So we assume the attacker X  X  background knowledge as follows: An attacker knows a user X  X  label and degree. For example, an attacker knows Bob is 23 years old with degree 2. Definition 1 (sensitive node). A node is called a sensitive node, if there are at least one sensitive edge connecting to it.
 We use V s to denote the set of sensitive nodes. As each sensitive edge connects to two sensitive nodes in the graph, the sensitive nodes disclosure will increase the probability of the sensitive edges disclosure. For example, in figure 1( c ), if an attack can re-identify Ed an Fred in the graph, he can also ascertain the sensitive edge between them. To better pro tect the sensitive edges, our objective is to protect both sensitive nodes and sensitive edges in the anonymous graph. Definition 2 ( k -sensitive anonymity). A graph G  X  is a k -sensitive anonymity if, for each sensitive node u in G  X  , the probability that an attack re-identifies u is at most 1 k ; for any two nodes u x and u y , the probability that an attack can re-identify that there is a sensitive edge between them is at most 1 k . Generalization is to group nodes and enable the nodes within each group possess identical label. We use a similar method in [3] to calculate the generalization cost, and also use this cost to partition the sensitive nodes. To protect edges, [4] focuses on masking the mapping via grouping the nodes of the graph. This technique retains the entire graph structure but perturbs the mapping from labels to nodes. They propose a Safety Condition that each node must interact with at most one node in any group and no edges exist in a group. [5] defines the Edge Identification which measures the likelihood of identifying an interaction. Both Safety Condition and Edge Identification ensure sparsity of interactions between nodes of any two groups, but Safety Condition is more restrictive than Edge Identification . Based on them, we limit the number of sensitive edges between any two groups while partitioning the sensitive nodes. 3.1 Sensitive Nodes Partition We aim to protect both sensitive nodes and sensitive edges. Sensitive edges don X  X  exist among non-sensitive nodes. So groupi ng is processed among sensitive nodes. Definition 3 (Sensitive Safety Condition). A grouping of sensitive nodes in graph G , satisfies the Sensitive Safety Condition if Theorem 1. If sensitive nodes partition satisfies Sensitive Safety Condition, the anonymous graph can protect sensitive edges against attacks with background knowledge of node X  X  label.
 Proof. The first condition in Sensitive Safety Condition constrains sensitive edges not exist in one group, the second condition constrains the number of sensi-tive edges x between any two groups is no more than | g x || g y | k . Edge Identification is the probability an attacker can attach to a particular pair of users between any two groups. With res pect to sensitive nodes partition, sen-after generalization, the probability of attack with label X  X  background knowledge can re-identify a sensitive edge is no more than 1 k , which satisfies the sensitive edges privacy protection.
 The algorithm SNP performs sensitive nodes partition. The input of SNP is an original graph G and a parameter k , and the output is a set of groups with size at least k . The groups are created one at a time. To form a new group, a sensitive node in V s with maximum degree and not yet a llocated to any group is selected as a seed for the new group(lines 3-4). Then the algorithm adds nodes into the group with the minimum generalization cost under Sensitive Safety Condition until the group size reaches k (lines 5-13). At each step, we calculate the group X  X  candidate set under Sensitive Safety Condition , and add one sensitive node into the group. The selected one node has to be unallocated yet to any group and has the minimum generalization cost in candidate set. In some cases, the group size is less than k (lines 14-17). For each node in the group, we add it into the previous constructed group which has the minimum generalization cost for the node addition. The SNP ceases when there is no sensitive node left in V s .
After grouping the sensitive nodes, we generalize the label of sensitive nodes in any group. In this way, using background knowledge of node X  X  label, an attacker can X  X  re-identify a sensitive edge with a probability higher than 1 k . Algorithm 1. Sensitive Nodes Partition (SNP) Algorithm 3.2 Non-sensitive Edges Addition To resist attacks with node X  X  degree, we should enable all the nodes in the same group have the same degree. As sensitive edges are privacy information, we only create non-sensitive edges. First , we set a target degree for each group and put nodes whose degree needs to be increased into a NodeList (lines 1-7). In lines 8-19, we create non-sensitive edges between nodes in NodeList .Last,we randomly create non-sensitive edges bet ween sensitive nodes and non-sensitive nodes.
 Algorithm 2. Non-sensitive Edges Addition (NEA) Algorithm In this section, we study the utility of anonymous graphs from the average path length and clustering co-efficient on Sp eed Dating and a synthetic dataset. As the anonymous method in [2] alters the network structure, we couldn X  X  compare our anonymous results with it. In this experiment, we just compare our approach with k -degree anonymity[6]. Figure 2 shows average path length and clustering co-efficient of anonymous graphs for k =4 , 6 , 8 , 10 , 12 , 14. Generally, all these observations verify that the k -sensitive anonymity cou ld acceptably capture main features of the social network.
 In this paper, we protect sensitive edges in social network. We present two heuris-tic algorithms. Our experiments show anonymous graph has acceptable utility.
