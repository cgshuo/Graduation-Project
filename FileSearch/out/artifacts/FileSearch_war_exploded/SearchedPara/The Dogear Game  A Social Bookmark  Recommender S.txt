 We describe the Dogear Game, which works with an enterprise social bookmarking system. The game is designed to accomplish individual, collaborative, and organization goals. Individual players receive entertainment and learn about their colleagues' bookmarks. The player's colleagues receive recommendations of websites and documents of potential interest to them. And the organization benefits from a richer knowledge-base of bookmarks as recommendations are accepted. The Dogear Game builds on von Ahn's "serious games," useful in motivati ng and distributing game-like entertaining "work" to a large group of game players. This note presents the design and implemen tation of a working prototype and some initial user feedback. H.5.3. Group and organizational interfaces/Collaborative computing &amp; CSCW. K.8.0 General/Games Measurement, Design, Human Factors Games, Enterprise, Social software, tagging This note describes a first combination of three concepts as applied to social-tagging sy stems: bookmark recommendations [2], purposeful games [11], a nd enterprise social-tagging systems [1, 7, 9]. There currently exist many social bookmark sites on the [6, 8]). Social bookmarking systems allow users to create records of the form where the resource is typically a URL (or any other addressable object), and each tag is a word or phrase that describes the resource. Social bookmarking syst ems allow individual users to create these records and to share them with other users. Social bookmarking systems have also been moved behind firewalls within enterprises [1, 7, 9]. Some of these social bookmarking sites support the ability to recommend bookmarks to other users. Recommendations may be created automatically through machine learning, may come from experts, or may be sent by friends. Del.icio.us allows users to add a special  X  X or: username  X  tag to any bookmark to recommend it to another user [2]. Del.icio.us then displays all recommendations made for a particular user in a special  X  X inks for you X  view. Social bookmarking systems that promote recommendations can benefit through increasing the redundancy (and hence reliability) that comes from multiple people bookmarking a single resource as recommendations are accepted. One of the promises of social bookmarking is the aggregation of community knowledge through ma ny small increments by individuals. Von Ahn has demons trated the use of games in motivating users to make such incremental contributions, by turning the process of contributi ng into a form of entertainment [11]. For example, in his ESP game [12] the goal is to provide labels for images that are likely to be used by other people  X  a problem which computers have typically had a hard time solving. The Google image-la beling site moves von Ahn X  X  concept from a research dataset to a public web resource [4]. We developed a research prototype, called the Dogear Game, that also moves Von Ahn X  X   X  X  ames with a purpose X  concept within the enterprise. The goal of the Dogear Game is to generate human-sourced bookmark recommendations for a user of a social bookmark system, written by someone who knows that user  X  including that user X  X  in terests, skills, etc  X  rather than using a more automated approach, such as machine learning. By analogy to Von Ahn X  X  analysis, much as it is unlikely that humans will label images for long periods of time with no incentive, we also thought it unlikely that they would take the time to go through bookmark after bookmark explicitly deciding whether to recommend it to each of their colleagues. The Dogear Game benefits from the same kind of  X  X uman computation X  that von Ahn a dvocates in  X  X ames with a Purpose X  [11]. The Dogear Game is a guessing game, much like the ESP game. Instead of images, we use the bookm arks in an enterprise social-bookmarking system called Dogear [9]. In the language of expression (1) above, the game di splays a resource and tags, and the player X  X  task is to guess which user wrote the bookmark for that resource. Contrast with the ESP Game: The ESP game depends on common knowledge that is assumed to be shared by all (sighted) users  X  the ability to label an image. Therefore, the ESP game can be collaborative and synchronous, because it can be assumed that any two players who happen to be accessing the game at the same time share sufficient knowledge to be able to label images together. ESP X  X  pa rtnering strategy is not only possible but also necessary, in order to determine correctness of labels through corroboration by two independent humans. By contrast, the Dogear Game relies on the player X  X  personal knowledge of other Dogear users. This design difference is necessary, because our domain is not images with common descriptors, but websites and documents that may require extensive domain-knowledge for proper interpretation. While it is likely that two people will play the Dogear Game at the same time, it is unlikely that they will share the domain knowledge of the specific resources (e.g., URLs) and that they will have personal knowledge of the same colleagues. For these reasons, we could not use Von Ahn X  X  approach which capitalizes on general knowledge only. Therefore, we designed the Dogear Game so that it could be played by a single player, with gradual and asynchronous combinations of the contributions of multiple players. A second difference from Von Ahn X  X  game was that, unlike the social-agreement strategy of the ESP game (i.e., players have to agree on a descriptive label), we were able to determine the precise accuracy (correct vs. incorrect) of each guess. That is, the underlying Dogear social-bookmarking database provides a clear association of author to bookmark and the game can use this data to score the correctness of a player X  X  guess. In order to reach a large number of users in a corporate-approved manner, the game was im plemented as a plug-in to a corporate instant messaging (IM) client [5] used by over 100,000 employees. As such, it shares the same window and space as the user X  X  IM contact list. As shown in Figure 1, the design includes a simple set of li nks across the top that control the content in the View area, a score section, and two play buttons. The five different views are: About , My Scores , Preferences , Main , and Recommendations . The About view describes the game and key features and gives instructions for how to play. As part of the instructions, the player is encouraged to edit their list of colleagues in the Preferences view by providing email addresses. The player is also given the option of adding people directly from their contact list. It is this list of colleagues that becomes important through the game, as it affects th e bookmarks collected for game play, the possibilities for recommendations, and ultimately whose bookmarks the pl ayer learns about. As the player X  X  colleagues are entered, bookmarks created by those users are fetched from Dogear. To populate the game materials with potential inco rrect answers (i.e., bookmarks created by  X  X on-colleagues X ), the game also fetches recent bookmarks created in Dogear that were not made by the player X  X  colleagues. When a player initiates a round of play, one of the collected bookmarks is randomly chosen by the system and displayed to the player. The selected bookmark is displaye d to the user in a slide-out panel (Figure 2). The slide-out displays the title, social-bookmarking tags, and description of the bookmark, along with a dynamic count-down timer and controls for the player to choose a guess. The game supports two levels of difficulty: On the  X  X asy X  level the user ma y choose between  X  X  colleague 
Figure 1. A screenshot of the Dogear Game. Links across the top produce different displays of content in the view dogeared. X  (i.e., bookmarked) and  X  X obody I know! X  On the  X  X ard X  level, the user is in stead presented with a pulldown menu containing all the colleagues in the user X  X  colleagues list as well as the  X  X obody I know! X  op tion, as shown in Figure 2. In both versions, the user has 15 seconds to make their decision before the question times out. Points are awarded for correct answers and subtracted for wrong answers and timeouts. The actual poi nt values were arbitrary but the relative differences were chosen to promote the recommendation goals of the game. In the Hard version, guessing correctly adds 500 points, while in the Easy version guessing correctly adds only 100 points. Incorrect answers in both versions lose 100 points, while 300 points are lost if a timeout occurs. As recommendations are only made in the Hard version, players stand to gain much more by playing it. Incorrect responses are not overly penalized and timeouts lose the most points because they provide no value to the system. The Hard version of the game finds enterprise utility in certain incorrect answers. If the player guesses a colleague from the list and the bookmark was actually created by a different colleague or a non-colleague, then the player is presented with the option of recommending the bookmark to the colleague whom the player had (incorrectly) guessed. Because the system is a scored game, the player is seeking to maximize his/her score; and because the scoring system is set up to reward correct guesses, the player has no incentive to intentionally guess incorrectly. Therefore, if the player choos es the wrong colleague as the author of a bookmark, he/she must have had a good reason for that mistake. The game offers the player the option of recommending the website to the colleague who the player believed was interested in that website. Of course, the player could have chosen  X  X obody I know! X  if there was not a strong enough belief that any colleague s had bookmarked it. However, because it is a game situation and there are timing constraints, the final say of whether or not to recommend the bookmarked website is provided as an explicit option that the player must select. The recommendations are saved back to the Dogear system as bookmarks made by the player with a special  X  X or: username  X  tag, as in Del.icio.us [2]. Recommendations made to the player are displayed within the game in a special Recommendations view (one of the options available in Figure 1). A preview of the number of new recommendations is provided at the top of the screen to encourage exploring those recommendations. Players can double click on recommendations to open them in a browser. To encourage the use of recommendations and to provide all new players with at least some recommendations, whether or not their colleagues had already played the game, this list was populated with tw o initial recommendations to all Dogear Game users from the Dogear Game team. As users play the game, they can check their accuracy on a per-colleague basis in the My Scores view. This shows the number of bookmarks a player has seen from each colleague, and the percentage guessed correctly out of those. This view can make explicit either the incremental learning taking place by noticing improving scores, or it can highlight particular colleagues the player could get to know better. Finally, the Main view is a list of all bookmarks that the user has played with (whether they got them right or wrong), the guesses made, along with the correct answers if the guesses were wrong, as shown in the current view area of Figure 1. The user can double-click to open th ese bookmarks in a browser if they would like to further explore the original websites. An initial version of The Dogear Game was deployed on November 8, 2006 on an internal site listing plug-ins for the corporate instant messaging client. As of November 27, 87 internal users from more than ten countries had installed the game. 1 The game was offered from th e IM client site, so some people who installed it had not used the Dogear system, and not surprisingly made little use of the game. For analysis, we divided the 24 game-players who also had bookmarks in Dogear, into two groups: 12 high-volume bookmarkers, and 12 low-volume bookmarkers. The Dogear high-volume group played the game an average of 25 times/player during the brief trial period, which was about fi ve times as much as the low-volume group and the non-Dogear users. We are in the process of conducting systematic interv iews with players, and of analyzing the voluminous log data from the trial. We also provided a forum page (the equiva lent of an internal newsgroup) for player comments. The detailed logging of player actions in the game, along with informal comments from players, has triggered design iterations, even in the early stages of data analysis. The kinds of changes the log information has influenced range from minor usability improvements to more subs tantial design changes. One user who posted in the forum associated with the game did not understand the meaning of  X  X olleagues X  within the game and remarked  X  X eople that show up as my [colleagues] I have never heard of before. X  This confirmed what we had seen in initial passes through the log: Fewer people than expected were changing their colleagues list and were playing the game using the colleagues list that came pr epopulated with the Dogear Game team. This was done in the first version because game play is not enabled if no colleagues are entered and we wanted to support casual browsers and new users who had not edited their list yet. A second version of the game used a social networking tool that provided a list of people  X  X elated X  to the player to automatically populate the list of colleagues with 10 people. Surprisingly, we found that so me people who downloaded and played the game were not bookmar kers in the Dogear system. This observation reaffirmed the initial choice of populating the list of colleagues with default values so users could play the game somehow and potentially become interested in the Dogear system by seeing examples of so cial bookmarks. It also led to Data from the authors, and from members of the Dogear Game team and related teams, were excluded from these analyses. the decision of actively promoting Dogear from within the game. There is now an  X  X pe n Dogear X  link prominently displayed with the View links, wh ich opens the Dogear web site in a browser. One potential area of future exploration in the Dogear Game is to mine other information  X  X reated X  in the game. The colleagues list could become another input to a social networking tool; each player X  X  correctness scores for respective colleagues could provide an additional metric of knowledge about other people in the social network analysis. The information concerning correct and incorrect guesses about bookmar ks could also be fed back into the Dogear social-bookmarking system to provide other orderings for a user X  X  bookmarks or new views on bookmarks. Other broader areas of explor ation include looking for ways through which  X  X ames with a purpose X  and  X  X uman computation X  [11] can be app lied to other social software systems. In these kinds of systems, it may be less important that a computer cannot solve the probl em or would have a hard time (as in [12]). Instead, it may be more important that the game leverages human social knowle dge (such as knowing which websites will appeal to our friends and colleagues). To apply games meaningfully to these systems might also mean that specialized knowledge requirements are placed on the player (as in requiring a Dogear Game player to know people who use Dogear). However, precisely because of this, these games might offer the player more value (such as learning about colleagues and their bookmarks in The Dogear Game), over the more casual enjoyment provided by generalist games such as ESP. We anticipate that lessons from th e Dogear Game will help us to design future enterprise  X  X ames with a purpose. X  We speculate that each game will need to deliver at least three types of value: x Value to the individual player (e.g., Dogear Game players x Value to at least one colleague of the player (e.g., the x Value to the enterprise (e.g., the enterprise in which people The Dogear Game may also assist with identifying and sustaining user communities. As noted above, one of the corollary benefits of the game will be an additional measure of the strength of interpersonal associ ation, which can be used with other enterprise metrics, such as email [10], to diversify the data for social network analyses of th e organization. We may be able to use these elaborated social network analyses to identify subpopulations or communities of users, such as communities of practice. Once communities have been identified, then it may be possible to re-orient the Dogear Game, or other, similar games, so that they serve the needs of these communities. For example, the colleagues list might be auto matically populated with names of other community members, and the selection of the bookmarks for gameplay might depend on common tagging of selected resources by a criterial percentage of community members. These developments would allow an additional benefit for the game or games, namely x Value to the player X  X  community of practice In this way, we may be able to test the ability of a game based on community knowledge to strengthen ties within a community of practice. Games may not, of course , be a good match for all organizational cultures. We hope that the Dogear Game and its successors will prove useful in a broad range of enterprises and other organizations that are willing to experiment with new ways to engage their employees in delivering value to themselves, their colleagues, and their organizations. We thank Suzanne Minassian a nd Meng Mao for testing early prototypes of the Dogear Game and providing feedback and Jonathan Feinberg for his Dogear technical advice. [1] Damianos, L., Griffith, J., &amp; Cuomo, D.,  X  X nomi: Social [2] Del.icio.us, http://del.icio.us /, retrieved: Jan 11, 2007. [3] Golder, S.A., &amp; Huberman, B.A.,  X  X tructure of [4] Google, n.d., http://images .google.com/imagelabeler/ [5] IBM Sametime 7.5, http:// www-142.ibm.com/software/sw-[6] Hammond, T., Hannay, T., Lund, B., &amp; Scott, J.,  X  X ocial [7] John, A., &amp; Seligmann, D.,  X  X ollaborative Tagging and [8] Lund, B., Hammond, T.,Flack, M., &amp; Hannay, T.,  X  X ocial [9] Millen, D.R., Feinberg, J., Kerr, B. (2006):  X  X ogear: [10] Tyler, J.R., Wilkinson, D.M., &amp; Huberman, B.A.,  X  X mail [11] Von Ahn, L.,  X  X ames with a Purpose. X  IEEE Computer [12] Von Ahn, L., Dabbish, L.,  X  X abeling Images with a 
