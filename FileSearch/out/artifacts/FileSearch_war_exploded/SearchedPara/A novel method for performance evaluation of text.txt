 Abstract Evaluation of text chunking is revisited. The proposed method tries to analyze the errors made by a chunker and formulates an evaluation strategy that brings out the strength and weakness of a chunker in a better way than the existing precision, recall and F score based methods or their variants do. A tree-matching based algorithm of linear time complexity is designed, analyzed, and illustrated by giving examples. Correctness of the algorithm is checked by using a chunker and a set of test sentences.
 Keywords Text chunking Performance evaluation CoNLL 2000 PARSEVAL Tree matching Indic languages 1 Introduction Text chunking (Abney and Abney 1991 ) refers to seeking a complete partitioning of a sentence into chunks of different types like noun groups (or base NPs), verb groups, etc. In natural language processing, text chunking plays an important role as full parsing is often expensive, and is not very robust. Partial parsing can be much faster, more robust, yet may be sufficient for many applications like information parsing.
 As chunking has been viewed as a shallow parsing, many researchers prefer PARSEVAL method (Manning and Schutze 1999 ) for evaluating chunking results. PARSEVAL, in its original form, measures the similarity between two parsed structures (bracketed representation): one corresponds to the gold standard and the other refers to the parsing result. Initially, the crossing bracket rate and recall were used to compare parsers (Black et al. 1991 ). Later on, adding the precision to the two previous measures the Grammar Evaluation Interest Group measures (Srinivas et al. 1996 ; Carroll et al. 2002 ) were evolved. The natural language processing community has been mostly using PARSEVAL for evaluation of parsers (Paroubek et al. 2008 , 2010 ).
 There was a shared task on chunking in CoNLL 2000 (Sang Tjong Kim and Buchholz 2000 ). In this task, the precision (the percentage of detected phrases that are correct), recall (the percentage of phrases in the data that were found by the chunker) and F score were used as the measures for evaluation of the chunkers. Computation of these measures, i.e. recall, precision and F score is very similar to what PARSEVAL does for evaluating parsers. Later on, Singh et al. ( 2005 ) proposed an HMM-based Hindi chunker which has been evaluated by measuring tag accuracy. However, measurement of tag accuracy has been discouraged in CoNLL 2000 shared task (Sang Tjong Kim and Buchholz 2000 ) arguing that the tagging accuracy is not a good evaluation measure for chunking.

Despite giving a vivid idea about the degree of matching between the parsed result and the Gold-standard, there are several shortcomings of recall, precision and F score based measures as experienced by many researchers (Carroll et al. 1998 ; Srinivas 2000 ). One major problem is the vague relationship of the metrics with the overall parsing efficiency. The method mainly emphasizes on the structural dissimilarity between the gold standard and the parsed tree giving less details about the types of errors encountered. Therefore, several other approaches (Roark 2002 ; Lin 2003 ; Sampson and Babarczy 2003 ) have been proposed in the literature.
While analyzing chunking errors, one may find that the errors mostly originate from different sources like: type (i) X  X ttachment of a word to a chunk may be wrong, type (ii) X  X ords may be correctly grouped together but the chunk has been assigned a wrong label, or type (iii) X  X ne or more words remain unattached. Recall/ Precision/F score measures as given by CoNLL 2000 could not address the details of these errors. Because of this problem the development of chunker for a new language does not gain much from evaluation results. For example, chunkers for Indic languages are still under development stage. The developers require detailed knowledge about the errors in order to improve the chunkers but the CoNLL 2000 evaluation technique fails to provide the required details. Considering this gap, this paper is aimed at proposing a novel method for evaluating of a text chunker.
The proposed method integrates two types of errors namely structural errors and grammatical errors. Structural errors are similar to what is reported by CoNLL 2000, PARSEVAL or some other measures like one in Sampson and Babarczy ( 2003 ) and grammatical errors keep track of what types of labeling errors are encountered and how severe they are. These two types of errors are integrated to give a single figure of merit but interestingly, the errors can be studied separately in order to understand the origin and nature of the chunking errors. Finally, the proposed method is used for evaluating a Bengali Chunker (De et al. 2011 ) and it is shown how the method is better in analyzing the chunking errors over PARSEVAL.
 This paper draws together information previously reported in an unreferred ICON proceedings (Biswas et al. 2010 ) along with modifications in the evaluation algorithm. The rest of the paper is as follows. Section 2 presents a background of the problem that motivated us for proposing a new method for evaluation of text chunking results. Section 3 algorithmically outlines our proposed method and presents an analysis of the algorithm along with the assumptions used in the algorithm. The algorithm has been explained by giving an example. Section 4 describes the experimental results where an Indian language (i.e. Bengali) text chunker has been evaluated using the proposed algorithm. Section 5 concludes the paper. 2 Background Consider two Bengali sentences (refer Fig. 1 corresponding to S1 and Fig. 2 for S2): The corresponding chunking results as well as the gold standard results are also given. The chunker described in De et al. ( 2011 ) is used to get the chunk results. Different types of chunk errors are discussed in the previous section. In Fig. 1 , type (ii) error occurs (i.e. when a set of words is correctly grouped together but the label of the chunk is wrong) whereas in Fig. 2 both the type (i) and (ii) errors occur (recall that type (i) error refers to a case when a word is attached to a wrong chunk). The error occurrences in Figs. 1 and 2 are highlighted by underlining the affected chunks. When these results (the chunker X  X  output and the corresponding gold standard results) are compared using PARSEVAL [as it was done in De et al. ( 2011 )], we get the values of precision, recall, and F score as 0.75, 0.75, and 0.75 for Fig. 1 and 0.7143, 0.6250, and 0.6667 for Fig. 2 . These values do not provide any details about what types of errors occurred during chunking. In Fig. 1 , words are perfectly chunked together but only one chunk got a wrong label (VGNF -&gt; VGF). On the other hand, in Fig. 2 , both the type (i) and type (ii) errors occurred (three chunks with labels VGF, NP, and NP containing 2 words, 2 words and 1 word respectively have been changed to two chunks with labels VGF and NP with 3 words and 2 words respectively). However, these details are not reflected in PARSEVAL X  X  measures.

This paper attempts to bridge this gap. The goal is to formulate a novel performance evaluation measure where the overall penalty comes from both the issues namely, structural errors which deals with the structural mismatch between the result and the groundtruth, and grammatical errors, i.e. what types of labeling errors are encountered and how severe they are. Traditional string matching algorithms like Levenshtein distance are not sufficient for the present purpose as they fail to take care of word attachment error as well as chunk type error together. Finally we tried Dynamic Time Warp algorithm (Sakoe and Chiba 1978 ), but in vain, as the deletion and insertion operations were treated as completely distinct phenomena, which contradicted our present problem scenario.

On the other hand, as both the gold standard and output results basically involve trees, a tree-matching based performance evaluation seems to be a natural choice. However, the traditional tree-matching algorithms (Zhang and Shasha 1989 ) are of little help. One reason is that the algorithms first attempt to modify the geometric structure of the candidate tree to make it similar to the gold standard one. Next, node labels are checked. For example, Zhang and Shasha X  X  algorithm first re-structure the candidate tree so that its post-order traversal sequence corresponds to that of the gold standard. This adds extra penalty to the overall distance between two trees which does not often convey any physical meaning or interpretation for a given problem like evaluation of a chunking (or parsing) result. Moreover, the computational complexity of such a tree-matching algorithm is quite high. For example, the time complexity of Zhang and Shasha X  X  algorithm is h ( n 4 ) where n is the number words in a sentence.

This paper attempts to formulate a simple tree-matching method in order to address the key issue related to evaluation of a text chunking method. The algorithm has two parts. The first part concerns about finding the structural error that corresponds to two aspects: (1) how many chunks are not identified properly and (2) how many words have attachment errors. The second part of the algorithm deals with the grammatical labeling. The algorithm also provides a facility to treat different types of errors with different weights. For example, if a chunker labels a VGF (finite verb chunk) group as VGNF (non-finite verb chunk) and another chunker labels the same VGF group as NP (noun chunk), the error of the latter chunker should be penalized more than that of the former one. The problem of unattached words is taken care of by considering the chunk types of the unattached words to be NULL. These aspects of the proposed evaluation method make the assessment more judicious. Moreover, both the structural and grammatical errors are captured using a unified tree-matching based algorithm. The matching algorithm is designed for the specific purpose (i.e. evaluation of text chunking) and hence, it outperforms the others generic tree-matching algorithms in computational com-plexity. It operates in a linear time complexity. 3 The algorithm Before we illustrate the algorithm let X  X  first define the data structures and the underlying assumptions. We assume that text chunking generates a three-level tree. The tree root is at level 0, chunks are at level 1, and the words and punctuations are at level 2. The data structure called m-ary tree is used to represent the chunk tree. In our algorithm, level-1 and level-2 nodes of the tree are linearly connected from left to right order (same as a linear linked list). This is similar to what we do for the leaf nodes of a B ? tree (Cormen et al. 2009 ). Use of these additional pointers helps us to implement a tree-matching based evaluation method of linear time complexity. The algorithm assumes that the words in an input sentence are not re-ordered by the chunker.

Level-1 nodes are tagged with chunk type and the chunk type of a word (i.e. level-2 node) is found by looking at its parent X  X  chunk type. Hence, chunk types are not stored at level-2 nodes.

In addition, each node has a field to store post-order sequence number, i.e. the left-most leaf will have the sequence number 1 as this node is visited first in the post-order traversal of the tree. Figure 3 shows a typical node structure. The Label field of level-1 nodes contains chunk label whereas this field in level-2 nodes contains post-of-speech (POS) tag.

The Algorithm-1 presents the proposed algorithm for computing error in text chunking. The notations used in the algorithm are explained next. 3.1 The notations T : tree representing the gold-standard result.
 T : tree representing the chunked result.
 C : number of chunks in the gold standard data.
 C : number of chunks in the output n : number of words in the sentences m : number of words show attachment errors ( m B n ) sizeof ( node ): size of a node as calculated as sum over the sizes of its children ? 1. Hence, size of a leaf node (i.e. level-2 nodes of our trees) is considered as 1. We use the post-order traversal result to compute the size of a node. This value is computed as the difference between the post-order sequence number of a node and that of its left sibling, i.e. sizeof( node ) = node .PostOrderSeq -node ? previous .PostOr-derSeq. The post-order traversal number of the left sibling of the leftmost level-2 node is assumed to be zero.
 T [level-l ]. i : the i th node of the l th level in the tree T g . chunkLabelof( node ): chunk type of a node. For a level-1 node, its chunk type is available within its node structure. For a level-2 node, its chunk type is the chunk type of its parent. e : number of occurrences where chunk type x has wrongly been labelled as y . w xy : a weight vector that determines how the error (i.e. chunk type x has wrongly been labelled as y) will be penalized.
 E : computes structural error between two trees without considering errors in assigning chunk types.
 E : computes grammatical error. 3.2 Analysis of the algorithm Computation of E s does not consider chunk labels, rather it put emphasis to find errors in geometric structures of the trees. As the sizeof () operator in the steps (1b) and (1c) of the algorithm works on the post-order trees, the step 1 of the algorithm requires only the post-order sequence numbers of the nodes. For example, consider the chunking results shown in Fig. 2 . Figure 4 shows the results using trees. The gold standard chunking is shown in Fig. 4 a and the chunker X  X  output is shown in Fig. 4 b. The post-order traversal sequences of the nodes of these two trees are shown in Fig. 5 .

For the given example, execution of step (1) gives structural error, E s equals to 5 as computed at step (1b). The analysis of this value shows that it basically computes the difference between the numbers of chunks in two representations, i.e. | C g -C p | and adds twice the number of the words showing attachment errors, i.e. in other words, E s = | C g -C p | ? 2 9 m . The factor 2 comes to correct a word X  X  wrong chunk (one deletion and one insertion operations: delete the word from the wrong chunk and insert it into the correct chunk). Note that the maximum value of E s can be 3 n assuming that the maximum error occurs when each of the n words will form different chunks (i.e. n chunks) in the gold standard result and all of the n words remain unattached in the output. Hence, the structural error is normalized in step (3) through dividing E s by 3 n .

The step (2) of the algorithm computes the grammatical error. For each word (or punctuation), it checks whether its chunk type is correct. If not, then the count ( e xy ) of that particular error is incremented at step (2b.iii). For the given example, this error is encountered for only one chunk, i.e. the 6th word of the sentence, the chunk label has been changed to VGF instead of NP. Different types of errors carry different weights and summed up at the step (2c). The weight matrix looks like one as given in Fig. 6 where L i  X  X  denote chunk types. Say, there are k different chunk types including a NULL type. The inclusion of NULL is required as some word(s) may not be assigned to any chunk in the output and hence its chunk type will be treated as NULL while executing the step (2b).

Formation of the above weight matrix requires judicious assignment of the weights. We treat this issue as a future extension of the present study. Instead, in the present experiment, we assign equal weights to all types of errors. Note that the value of E g can be at most n if w xy = 1. Hence, E g is divided by n to normalize the overall chunking error, E at step (3).

Note that if E s and E g are not normalized and the concept of error weight is ignored then E becomes 6 for the given example, i.e. 5 comes from structural error and 1 comes from grammatical error. We easily get physical interpretation of this error value: (i) one chunk (level-1 node) has to be created (inducing error 1), (ii) two words are in wrong chunks, correction for each word requires two operations, i.e. one deletion and one insertion (so, for two words, in total, four operations inducing NP NP NP NP NP NP VGNF VGF NP NP NP NP NP VGNF VGF error 4), and (iii) chunk type of one word, i.e. the 6th word of the example is wrong (inducing error 1). However, if we compare these two trees in Fig. 5 by using Zhang and Shasha X  X  algorithm (Zhang and Shasha 1989 ), a distance of 13 is resulted. This is not only over-weighted, seeking any physical interpretation of this distance value is difficult for the given problem. Moreover, the algorithm which is given above works in a linear time complexity, i.e. h ( n ) vis-a-vis h ( n 4 ) of Zhang and Shasha X  X  algorithm.
 If the above example is evaluated using PARSEVAL, we get recall, precision and F score values as 0.6250, 0.7143, and 0.6667. From these values we know how much of the output reached the gold standard (here, 5 out of 8 chunks) and how many of the chunks are correct (here, 5 out of 7). However, these measures shade no light on the details of the errors. 4 Experiment Using the proposed evaluation method we evaluated a Bengali chunker developed by our team (De et al. 2011 ). This chunker is a rule-based one and rules are generated from a training dataset distributed by the NLP Tool Contest Committee of ICON 2010 (Husian et al. 2010 ). This set contains about one thousand (1,000) sentences tagged with chunking results. For tagging the chunks and storing any other information, Shakti Standard Format (SSF) proposed by Bharti et al. ( 2007 ) has been used. The tagging scheme and the tag set used are described in Bharti et al. ( 2009 ).
 The rules are mainly obtained by looking at the particular order by which a set of POSs make a chunk. While framing the rules, we considered the following points: (1) No Repetition: No rule is written more than once. (2) Uniqueness: A group of POS tags in a particular order gives one and only one chunk. (3) Exhaustiveness: The rule set must be exhaustive such that all the possible Chunks in the language can be covered (it is difficult to guarantee, but the coverage is maximized for the training set).

The chunker takes a POS tagged sentence as input and matches a maximum possible ordered sequence of POSs of the sentence with a rule. When a match is found, the corresponding group of words of the sentence is tagged as a chunk and is named as described in the rule. The results are stored in SSF in a text file. Testing of this chunking method was conducted on a test (separate from the training set) of 150 sentences.

To ensure that the algorithm of Sect. 3 is correct we manually checked the errors sentence are computed manually and again by the given algorithm. We found that the errors computed through both the methods were in agreement. Figure 7 plots these errors sentence-wise (for randomly picked 60 sentences from the test set). Here the error values have not been normalized. The plot shows that the chunker makes more structural errors and less grammatical errors, i.e. grouping of words encounters more error than that of assigning the chunk types to the words. 5 Conclusion A novel text chunking evaluation method has been discussed. The method attempts to overcome the shortcomings of recall, precision and F score based method for evaluating text chunking. In the proposed method, chunking errors are thoroughly analyzed to bring out strengths and weaknesses of a given chunker. Such kind of analysis has not been supported by any of the existing evaluation schemes. Therefore, using this method a more judicious comparison among different chunking approaches is possible.

With the evolution of the non-canonical languages which are generally used in chat, informal conversation, blog or twitter, the tasks of summarization, question answering, information extraction etc. have been facing tough challenges as the aforementioned languages do not follow the predefined grammatical or linguistic structure. In this scenario, a more detailed chunking evaluation method can be fruitfully exploited to select the best chunker when chunking is a fundamental processing step for further language processing tasks. We plan to address this issue as part of the future extension of the present research.

Moreover, the present work talks about a weight matrix as outlined in Sect. 3 but its detailed formulation remained unexplored. This will be addressed in subsequent extension of this research. At present, the evaluation algorithm while calculating the structural error ( E s ) sometimes penalises chunk outputs that produce a different number of chunks more heavily than those that coincidently get the right number of chunks by merging some and splitting others. Though this effect is often nullified while calculating the grammatical error ( E g ), a more judicious scheme can be thought of so that the structural error itself can show more details about the errors. References
 Abstract Evaluation of text chunking is revisited. The proposed method tries to analyze the errors made by a chunker and formulates an evaluation strategy that brings out the strength and weakness of a chunker in a better way than the existing precision, recall and F score based methods or their variants do. A tree-matching based algorithm of linear time complexity is designed, analyzed, and illustrated by giving examples. Correctness of the algorithm is checked by using a chunker and a set of test sentences.
 Keywords Text chunking Performance evaluation CoNLL 2000 PARSEVAL Tree matching Indic languages 1 Introduction Text chunking (Abney and Abney 1991 ) refers to seeking a complete partitioning of a sentence into chunks of different types like noun groups (or base NPs), verb groups, etc. In natural language processing, text chunking plays an important role as full parsing is often expensive, and is not very robust. Partial parsing can be much faster, more robust, yet may be sufficient for many applications like information parsing.
 As chunking has been viewed as a shallow parsing, many researchers prefer PARSEVAL method (Manning and Schutze 1999 ) for evaluating chunking results. PARSEVAL, in its original form, measures the similarity between two parsed structures (bracketed representation): one corresponds to the gold standard and the other refers to the parsing result. Initially, the crossing bracket rate and recall were used to compare parsers (Black et al. 1991 ). Later on, adding the precision to the two previous measures the Grammar Evaluation Interest Group measures (Srinivas et al. 1996 ; Carroll et al. 2002 ) were evolved. The natural language processing community has been mostly using PARSEVAL for evaluation of parsers (Paroubek et al. 2008 , 2010 ).
 There was a shared task on chunking in CoNLL 2000 (Sang Tjong Kim and Buchholz 2000 ). In this task, the precision (the percentage of detected phrases that are correct), recall (the percentage of phrases in the data that were found by the chunker) and F score were used as the measures for evaluation of the chunkers. Computation of these measures, i.e. recall, precision and F score is very similar to what PARSEVAL does for evaluating parsers. Later on, Singh et al. ( 2005 ) proposed an HMM-based Hindi chunker which has been evaluated by measuring tag accuracy. However, measurement of tag accuracy has been discouraged in CoNLL 2000 shared task (Sang Tjong Kim and Buchholz 2000 ) arguing that the tagging accuracy is not a good evaluation measure for chunking.

Despite giving a vivid idea about the degree of matching between the parsed result and the Gold-standard, there are several shortcomings of recall, precision and F score based measures as experienced by many researchers (Carroll et al. 1998 ; Srinivas 2000 ). One major problem is the vague relationship of the metrics with the overall parsing efficiency. The method mainly emphasizes on the structural dissimilarity between the gold standard and the parsed tree giving less details about the types of errors encountered. Therefore, several other approaches (Roark 2002 ; Lin 2003 ; Sampson and Babarczy 2003 ) have been proposed in the literature.
While analyzing chunking errors, one may find that the errors mostly originate from different sources like: type (i) X  X ttachment of a word to a chunk may be wrong, type (ii) X  X ords may be correctly grouped together but the chunk has been assigned a wrong label, or type (iii) X  X ne or more words remain unattached. Recall/ Precision/F score measures as given by CoNLL 2000 could not address the details of these errors. Because of this problem the development of chunker for a new language does not gain much from evaluation results. For example, chunkers for Indic languages are still under development stage. The developers require detailed knowledge about the errors in order to improve the chunkers but the CoNLL 2000 evaluation technique fails to provide the required details. Considering this gap, this paper is aimed at proposing a novel method for evaluating of a text chunker.
The proposed method integrates two types of errors namely structural errors and grammatical errors. Structural errors are similar to what is reported by CoNLL 2000, PARSEVAL or some other measures like one in Sampson and Babarczy ( 2003 ) and grammatical errors keep track of what types of labeling errors are encountered and how severe they are. These two types of errors are integrated to give a single figure of merit but interestingly, the errors can be studied separately in order to understand the origin and nature of the chunking errors. Finally, the proposed method is used for evaluating a Bengali Chunker (De et al. 2011 ) and it is shown how the method is better in analyzing the chunking errors over PARSEVAL.
 This paper draws together information previously reported in an unreferred ICON proceedings (Biswas et al. 2010 ) along with modifications in the evaluation algorithm. The rest of the paper is as follows. Section 2 presents a background of the problem that motivated us for proposing a new method for evaluation of text chunking results. Section 3 algorithmically outlines our proposed method and presents an analysis of the algorithm along with the assumptions used in the algorithm. The algorithm has been explained by giving an example. Section 4 describes the experimental results where an Indian language (i.e. Bengali) text chunker has been evaluated using the proposed algorithm. Section 5 concludes the paper. 2 Background Consider two Bengali sentences (refer Fig. 1 corresponding to S1 and Fig. 2 for S2): The corresponding chunking results as well as the gold standard results are also given. The chunker described in De et al. ( 2011 ) is used to get the chunk results. Different types of chunk errors are discussed in the previous section. In Fig. 1 , type (ii) error occurs (i.e. when a set of words is correctly grouped together but the label of the chunk is wrong) whereas in Fig. 2 both the type (i) and (ii) errors occur (recall that type (i) error refers to a case when a word is attached to a wrong chunk). The error occurrences in Figs. 1 and 2 are highlighted by underlining the affected chunks. When these results (the chunker X  X  output and the corresponding gold standard results) are compared using PARSEVAL [as it was done in De et al. ( 2011 )], we get the values of precision, recall, and F score as 0.75, 0.75, and 0.75 for Fig. 1 and 0.7143, 0.6250, and 0.6667 for Fig. 2 . These values do not provide any details about what types of errors occurred during chunking. In Fig. 1 , words are perfectly chunked together but only one chunk got a wrong label (VGNF -&gt; VGF). On the other hand, in Fig. 2 , both the type (i) and type (ii) errors occurred (three chunks with labels VGF, NP, and NP containing 2 words, 2 words and 1 word respectively have been changed to two chunks with labels VGF and NP with 3 words and 2 words respectively). However, these details are not reflected in PARSEVAL X  X  measures.

This paper attempts to bridge this gap. The goal is to formulate a novel performance evaluation measure where the overall penalty comes from both the issues namely, structural errors which deals with the structural mismatch between the result and the groundtruth, and grammatical errors, i.e. what types of labeling errors are encountered and how severe they are. Traditional string matching algorithms like Levenshtein distance are not sufficient for the present purpose as they fail to take care of word attachment error as well as chunk type error together. Finally we tried Dynamic Time Warp algorithm (Sakoe and Chiba 1978 ), but in vain, as the deletion and insertion operations were treated as completely distinct phenomena, which contradicted our present problem scenario.

On the other hand, as both the gold standard and output results basically involve trees, a tree-matching based performance evaluation seems to be a natural choice. However, the traditional tree-matching algorithms (Zhang and Shasha 1989 ) are of little help. One reason is that the algorithms first attempt to modify the geometric structure of the candidate tree to make it similar to the gold standard one. Next, node labels are checked. For example, Zhang and Shasha X  X  algorithm first re-structure the candidate tree so that its post-order traversal sequence corresponds to that of the gold standard. This adds extra penalty to the overall distance between two trees which does not often convey any physical meaning or interpretation for a given problem like evaluation of a chunking (or parsing) result. Moreover, the computational complexity of such a tree-matching algorithm is quite high. For example, the time complexity of Zhang and Shasha X  X  algorithm is h ( n 4 ) where n is the number words in a sentence.

This paper attempts to formulate a simple tree-matching method in order to address the key issue related to evaluation of a text chunking method. The algorithm has two parts. The first part concerns about finding the structural error that corresponds to two aspects: (1) how many chunks are not identified properly and (2) how many words have attachment errors. The second part of the algorithm deals with the grammatical labeling. The algorithm also provides a facility to treat different types of errors with different weights. For example, if a chunker labels a VGF (finite verb chunk) group as VGNF (non-finite verb chunk) and another chunker labels the same VGF group as NP (noun chunk), the error of the latter chunker should be penalized more than that of the former one. The problem of unattached words is taken care of by considering the chunk types of the unattached words to be NULL. These aspects of the proposed evaluation method make the assessment more judicious. Moreover, both the structural and grammatical errors are captured using a unified tree-matching based algorithm. The matching algorithm is designed for the specific purpose (i.e. evaluation of text chunking) and hence, it outperforms the others generic tree-matching algorithms in computational com-plexity. It operates in a linear time complexity. 3 The algorithm Before we illustrate the algorithm let X  X  first define the data structures and the underlying assumptions. We assume that text chunking generates a three-level tree. The tree root is at level 0, chunks are at level 1, and the words and punctuations are at level 2. The data structure called m-ary tree is used to represent the chunk tree. In our algorithm, level-1 and level-2 nodes of the tree are linearly connected from left to right order (same as a linear linked list). This is similar to what we do for the leaf nodes of a B ? tree (Cormen et al. 2009 ). Use of these additional pointers helps us to implement a tree-matching based evaluation method of linear time complexity. The algorithm assumes that the words in an input sentence are not re-ordered by the chunker.

Level-1 nodes are tagged with chunk type and the chunk type of a word (i.e. level-2 node) is found by looking at its parent X  X  chunk type. Hence, chunk types are not stored at level-2 nodes.

In addition, each node has a field to store post-order sequence number, i.e. the left-most leaf will have the sequence number 1 as this node is visited first in the post-order traversal of the tree. Figure 3 shows a typical node structure. The Label field of level-1 nodes contains chunk label whereas this field in level-2 nodes contains post-of-speech (POS) tag.

The Algorithm-1 presents the proposed algorithm for computing error in text chunking. The notations used in the algorithm are explained next. 3.1 The notations T : tree representing the gold-standard result.
 T : tree representing the chunked result.
 C : number of chunks in the gold standard data.
 C : number of chunks in the output n : number of words in the sentences m : number of words show attachment errors ( m B n ) sizeof ( node ): size of a node as calculated as sum over the sizes of its children ? 1. Hence, size of a leaf node (i.e. level-2 nodes of our trees) is considered as 1. We use the post-order traversal result to compute the size of a node. This value is computed as the difference between the post-order sequence number of a node and that of its left sibling, i.e. sizeof( node ) = node .PostOrderSeq -node ? previous .PostOr-derSeq. The post-order traversal number of the left sibling of the leftmost level-2 node is assumed to be zero.
 T [level-l ]. i : the i th node of the l th level in the tree T g . chunkLabelof( node ): chunk type of a node. For a level-1 node, its chunk type is available within its node structure. For a level-2 node, its chunk type is the chunk type of its parent. e : number of occurrences where chunk type x has wrongly been labelled as y . w xy : a weight vector that determines how the error (i.e. chunk type x has wrongly been labelled as y) will be penalized.
 E : computes structural error between two trees without considering errors in assigning chunk types.
 E : computes grammatical error. 3.2 Analysis of the algorithm Computation of E s does not consider chunk labels, rather it put emphasis to find errors in geometric structures of the trees. As the sizeof () operator in the steps (1b) and (1c) of the algorithm works on the post-order trees, the step 1 of the algorithm requires only the post-order sequence numbers of the nodes. For example, consider the chunking results shown in Fig. 2 . Figure 4 shows the results using trees. The gold standard chunking is shown in Fig. 4 a and the chunker X  X  output is shown in Fig. 4 b. The post-order traversal sequences of the nodes of these two trees are shown in Fig. 5 .

For the given example, execution of step (1) gives structural error, E s equals to 5 as computed at step (1b). The analysis of this value shows that it basically computes the difference between the numbers of chunks in two representations, i.e. | C g -C p | and adds twice the number of the words showing attachment errors, i.e. in other words, E s = | C g -C p | ? 2 9 m . The factor 2 comes to correct a word X  X  wrong chunk (one deletion and one insertion operations: delete the word from the wrong chunk and insert it into the correct chunk). Note that the maximum value of E s can be 3 n assuming that the maximum error occurs when each of the n words will form different chunks (i.e. n chunks) in the gold standard result and all of the n words remain unattached in the output. Hence, the structural error is normalized in step (3) through dividing E s by 3 n .

The step (2) of the algorithm computes the grammatical error. For each word (or punctuation), it checks whether its chunk type is correct. If not, then the count ( e xy ) of that particular error is incremented at step (2b.iii). For the given example, this error is encountered for only one chunk, i.e. the 6th word of the sentence, the chunk label has been changed to VGF instead of NP. Different types of errors carry different weights and summed up at the step (2c). The weight matrix looks like one as given in Fig. 6 where L i  X  X  denote chunk types. Say, there are k different chunk types including a NULL type. The inclusion of NULL is required as some word(s) may not be assigned to any chunk in the output and hence its chunk type will be treated as NULL while executing the step (2b).

Formation of the above weight matrix requires judicious assignment of the weights. We treat this issue as a future extension of the present study. Instead, in the present experiment, we assign equal weights to all types of errors. Note that the value of E g can be at most n if w xy = 1. Hence, E g is divided by n to normalize the overall chunking error, E at step (3).

Note that if E s and E g are not normalized and the concept of error weight is ignored then E becomes 6 for the given example, i.e. 5 comes from structural error and 1 comes from grammatical error. We easily get physical interpretation of this error value: (i) one chunk (level-1 node) has to be created (inducing error 1), (ii) two words are in wrong chunks, correction for each word requires two operations, i.e. one deletion and one insertion (so, for two words, in total, four operations inducing NP NP NP NP NP NP VGNF VGF NP NP NP NP NP VGNF VGF error 4), and (iii) chunk type of one word, i.e. the 6th word of the example is wrong (inducing error 1). However, if we compare these two trees in Fig. 5 by using Zhang and Shasha X  X  algorithm (Zhang and Shasha 1989 ), a distance of 13 is resulted. This is not only over-weighted, seeking any physical interpretation of this distance value is difficult for the given problem. Moreover, the algorithm which is given above works in a linear time complexity, i.e. h ( n ) vis-a-vis h ( n 4 ) of Zhang and Shasha X  X  algorithm.
 If the above example is evaluated using PARSEVAL, we get recall, precision and F score values as 0.6250, 0.7143, and 0.6667. From these values we know how much of the output reached the gold standard (here, 5 out of 8 chunks) and how many of the chunks are correct (here, 5 out of 7). However, these measures shade no light on the details of the errors. 4 Experiment Using the proposed evaluation method we evaluated a Bengali chunker developed by our team (De et al. 2011 ). This chunker is a rule-based one and rules are generated from a training dataset distributed by the NLP Tool Contest Committee of ICON 2010 (Husian et al. 2010 ). This set contains about one thousand (1,000) sentences tagged with chunking results. For tagging the chunks and storing any other information, Shakti Standard Format (SSF) proposed by Bharti et al. ( 2007 ) has been used. The tagging scheme and the tag set used are described in Bharti et al. ( 2009 ).
 The rules are mainly obtained by looking at the particular order by which a set of POSs make a chunk. While framing the rules, we considered the following points: (1) No Repetition: No rule is written more than once. (2) Uniqueness: A group of POS tags in a particular order gives one and only one chunk. (3) Exhaustiveness: The rule set must be exhaustive such that all the possible Chunks in the language can be covered (it is difficult to guarantee, but the coverage is maximized for the training set).

The chunker takes a POS tagged sentence as input and matches a maximum possible ordered sequence of POSs of the sentence with a rule. When a match is found, the corresponding group of words of the sentence is tagged as a chunk and is named as described in the rule. The results are stored in SSF in a text file. Testing of this chunking method was conducted on a test (separate from the training set) of 150 sentences.

To ensure that the algorithm of Sect. 3 is correct we manually checked the errors sentence are computed manually and again by the given algorithm. We found that the errors computed through both the methods were in agreement. Figure 7 plots these errors sentence-wise (for randomly picked 60 sentences from the test set). Here the error values have not been normalized. The plot shows that the chunker makes more structural errors and less grammatical errors, i.e. grouping of words encounters more error than that of assigning the chunk types to the words. 5 Conclusion A novel text chunking evaluation method has been discussed. The method attempts to overcome the shortcomings of recall, precision and F score based method for evaluating text chunking. In the proposed method, chunking errors are thoroughly analyzed to bring out strengths and weaknesses of a given chunker. Such kind of analysis has not been supported by any of the existing evaluation schemes. Therefore, using this method a more judicious comparison among different chunking approaches is possible.

With the evolution of the non-canonical languages which are generally used in chat, informal conversation, blog or twitter, the tasks of summarization, question answering, information extraction etc. have been facing tough challenges as the aforementioned languages do not follow the predefined grammatical or linguistic structure. In this scenario, a more detailed chunking evaluation method can be fruitfully exploited to select the best chunker when chunking is a fundamental processing step for further language processing tasks. We plan to address this issue as part of the future extension of the present research.

Moreover, the present work talks about a weight matrix as outlined in Sect. 3 but its detailed formulation remained unexplored. This will be addressed in subsequent extension of this research. At present, the evaluation algorithm while calculating the structural error ( E s ) sometimes penalises chunk outputs that produce a different number of chunks more heavily than those that coincidently get the right number of chunks by merging some and splitting others. Though this effect is often nullified while calculating the grammatical error ( E g ), a more judicious scheme can be thought of so that the structural error itself can show more details about the errors. References
