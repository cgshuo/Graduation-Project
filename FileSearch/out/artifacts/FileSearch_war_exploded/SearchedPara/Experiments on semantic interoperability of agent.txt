 1. Introduction
The growing use of the Internet in the last decades stimulated the increase in the number of available online e-services, such as e-Commerce, e-Government and e-Science ( Rowley, 2006 ). Nowa-days, most of the search, selection and use of these services are directly performed by humans. However, in the near future, people are expected to delegate these tasks to software components, requiring them to cooperate and negotiate among themselves.
In order to this scenario becomes practical, there is a need for autonomous components that act and interact in flexible ways to achieve their objectives in such uncertain, dynamic and open environments. Agent-based computing has been advocated as the natural computational model for such systems ( Jennings, 2001 ), since it presents the capabilities for both acting autonomously and engaging in social activities such as cooperation, negotiation and collaboration ( Wooldridge, 2009 ).

Nevertheless, in open environments, where agents can enter or leave at any time, taking part in social activities may expose them to risks, for instance, when making decisions based on informa-tion provided by non-knowledgeable or malevolent agents.
Therefore, as occurs in human societies, agents in a virtual society may become susceptible to the emergence of social dilemmas.
A social dilemma occurs whenever individuals in interdependent situations face choices in which the maximization of short-term self-interest yields outcomes leaving all participants worse off from feasible alternatives ( Ostrom, 1998 ).
 serve as a decision criterion for an agent to act and engage in social activities. In the last years, some computational agent trust models were proposed, for instance, Histos and Sporas ( Zacharia and Maes, 2000 ), MMH (Mui, Mohtashemi and Halberstadt) ( Mui et al., 2002a ), ReGreT ( Sabater-Mir and Sierra, 2002 ), FIRE ( Huynh et al., tion for Agent Reputation )( Muller and Vercouter, 2008 ). These models are mostly based on the concept of reputation borrowed from the social sciences, in which reputation could be considered a social property or a social process ( Conte and Paolucci, 2002 ). In order to accelerate and to improve the robustness of their reputa-tion evaluations, agents generally exchange reputation information about third-parties. However, since there is no consensus about a single unifying reputation definition, the semantics associated with reputation concepts differ from one model to another, which raises an interoperability problem as depicted in Fig. 1 .
 that Alice and Bob have directly in teracted with Clara (dashed line) and internally represented her reputation evaluation. In order to improve her reputation evaluation of Clara, Alice requests Bob his reputation evaluation of Clara. Since Alice and Bob use different reputation models, respectively, RM 1 and RM 2 ,theyareunable to communicate directly using their internal reputation model concepts as depicted, which requires some mechanism or architec-ture to overcome such limitation a nd provide support to the agent reputation interoperability.

In some of our previous work ( Nardin, 2009 ; Nardin et al., 2008a , b ; Nardin et al., 2009 ), the service oriented architecture named SOARI (Service Oriented Architecture for Reputation Inter-action) was presented and preliminary experiments were con-ducted. SOARI is an architecture that aims at providing semantic interoperability among agent reputation models and, thus, at enabling a more expressive communication about reputation among agents. Here they are followed up, presenting new experiments using SOARI and their associated results in order to answer two questions: (1) is there any improvement in the reputation evaluation accuracy when enabling a more expressive communication? and (2) is there any improvement in the reputa-tion evaluation accuracy when considering the heterogeneity of reputation models? Such questions were already addressed in
Nardin (2009) and Nardin et al. (2009) considering just two agent reputation models (Repage and L.I.A.R.) and the analysis is now extended by rebuilding the experiments with the inclusion of a third model (MMH).

The rest of the document is structured as follows. Section 2 provides some background information on Semantic Interoper-ability and contextualizes our work while comparing it with the literature. In Section 3, the SOARI architecture and some imple-mentation decisions are discussed. Some experiments in the art appraisal domain are presented in Section 4, followed by their results and analysis in Section 5. Finally, some conclusions and future work are presented in Section 6. 2. Semantic interoperability issues and related work
Interoperability is the ability of two or more systems or components to exchange and use shared information ( IEEE, 1991 ).
In order to do that, systems should be able to access, process and interpret such information. Therefore, issues related to the informa-tion heterogeneity among these systems or components may endanger the activities that must be executed to achieve interoper-ability. Such activities could be classified as integration ones and can be defined along three dimensions ( Sheth, 1998 ): structural, syntactic and semantic. The semantic dimension refers to integra-tion activities related to the need of solving semantic conflicts among heterogeneous data sources. For instance, this occurs when different applications mean different things by using similar terms.
In this work, the focus is related to semantic interoperability, which is closely tied to the systems or components domain.

Semantic interoperability is the ability that two or more hetero-geneous and distributed systems or components have of working together while sharing information with common understanding of its meaning ( Buranarach, 2001 ). Several communities are dealing with this problem: Service Oriented Architecture (SOA) ( Vetere and Lenzerini, 2005 ), geographical information systems (GIS) ( Visser et al., 2002 ), health care ( Ryan and Eklund, 2008 ) and enterprise application integration (EAI) ( Contreras and Sheremetov, 2008 ), among others.

According to Visser et al. (2000) , there are three approaches for dealing with semantic interoperability: centralized, decentralized and hybrid. In the centralized approach, all agents use the same common ontology to internally repre sent information and to interact with other agents. Interoperabili ty is not a problem in this approach, since all agents share the same on tology to describe the domain in which they are interacting. In the decentralized approach, each agent has its own ontology to internally represent information and to interact with other agents. In this ca se, full semantic interoperability is achieved if each agent has the mapping from its own ontology to the ontologies of all other agents it interacts with. In the hybrid approach, each agent has its own internal ontology to represent the domain and uses a common domain on tology to interact with other agents. Interoperability occurs if each agent has the mapping of its own ontology to the common domain ontology.

Whenever multiagent systems (MAS) are considered, specially the ones characterized as open and distributed, semantic interoper-ability is an issue that is still unsolved. Nonetheless, the existence of heterogeneous reputation models brings the problem of semantic interoperability to the reputation domain ( Vercouter et al., 2007 ). This specific problem is the one we have been working on: semantic interoperability concerning agent interaction about repu-tation in MAS. This issue has been gaining attention of the research community but, at the best of our knowledge, there are just a few related work about this specific subject in the literature.
Alnemr et al. (2010) deal with reputation interoperability issues through the definition of an object named reputation object ( RO ). They adopt RO to represent the reputation of someone or something using the reputation information related to several domain contexts. They propose an OWL-ontology to describe their RO model and show some applications in rule-based open systems. Their approach allows domain independent interaction concerning reputation, but they do not mention how such an interaction could occur among agents that are not rule-based specified, which is the case our approach deals with.
Trivellato et al. (2009a) define POLIPO, an ontology-based framework to enable interoperability, portability and autonomy in dynamic coalitions of heterogeneous systems. Such a frame-work adopts some trust management through credentials and authorization rules from a global and shared ontology. Therefore, they define a reputation-based ontology alignment for enhancing POLIPO to deal with different ontologies from the same domain ( Trivellato et al., 2009b ). Their focus is on access control during dynamic coalitions while ours is on reputation interaction. 3. SOARI: Service Oriented Architecture for Reputation Interaction
SOARI ( Fig. 2 ) is a service oriented architecture that provides support to the semantic interoperability among agents that implement heterogeneous reputation models. Its main underlying idea is that the mapping among different reputation models, represented as ontologies, may be executed externally to the agents and be available online as a service for agents to use.
The advantage of using service oriented architecture, from a design/programming perspective, is that the agents become simpler and they have their dynamic workload alleviated since they do not need to perform the ontology mapping function internally. Moreover, since the ontology mapping results are stored in an external service, they may be reused by other agents that enter the system and have an internal reputation model that is available in the service.

The architecture design considers that different agents may have heterogeneous reputation models and the interoperation among them is performed using the hybrid semantic interoper-ability approach proposed by Visser et al. (2000) . By adopting the hybrid approach, agents are prevented from knowing other agents X  internal reputation models and avoid the use of such information in a hazardous way. As a common domain ontology, we adopted the functional ontology of reputation (FORe) ( Casare and Sichman, 2005a ), since it subsumes several of the available reputation models ( Casare and Sichman, 2005b ) and it was developed in our research group. Other candidates for being the common reputation ontology were proposed in Chang et al. (2006) and Alnemr et al. (2010) ; however, they cover a narrower scope of the reputation domain than FORe. Due to space limita-tion, details about FORe are not presented here. Interested readers are pointed to Casare and Sichman (2005a , b) .

SOARI is an extension of the general agent architecture for reputation interoperability proposed in Vercouter et al. (2007) .It extends the previous architecture by splitting its reputation mapping module (RMM) into two distinct and specialized modules: the ontology mapping service (OMS), an external service which performs ontology mapping and translation functions ( Kalfoglou and
Schorlemmer, 2003 ), and the translator module (TM), an agent X  X  internal module which performs message translation functions. agents occurs using the common ontology and follows the sequence presented in Fig. 3 . (1) Agent A wants to communicate with Agent B, then it uses the TM to query the OMS in order to obtain its message X  X  internal reputation ontology concepts trans-lated to the common ontology concepts; (2) After receiving the translation, it uses its interaction module (IM) to send the translated message to Agent B; (3) Agent B receives the message through its IM, and it uses the TM to query the OMS and translate the message X  X  concepts to its internal reputation ontology. Below, we briefly describe the ontology mapping service and the translator module modules. 3.1. Ontology mapping service two main functionalities: (i) to map concepts from the target reputation model ontology to the concepts of the common ontology and vice-versa; and (ii) to answer ontology concept translation requests from the TM. The latter is performed via its web services ( Booth et al., 2004 ) interface. Therefore, the OMS existence is independent of the agents since it is provided as a service. Moreover, it also inherits the technological benefits from web services, for instance, scalability and fault tolerance.

The OMS is composed of the ontology repository , the classifier module , the inference engine interface , the inference engine , the translation repository and the query interface .

The classifier module is the core component of the OMS and its functioning follows a three-step process, which is required to be performed only once for each reputation model ontology. The classifier module continually observes the ontology repository .
When it detects the insertion of a new reputation model ontology in the repository, it reads the ontology and classifies it using the inference engine through the inference engine interface . In the sequence, it identifies the mapping between the FORe concepts and the reputation model ontology concepts analyzing their subsumption relation and, finally, it stores the mapping in the translation repository , a relational database. Such mapping is then available for querying through the query interface .

So that the classifier module is able to classify the reputation model ontology, the latter must be described in OWL DL (web ontology language description logic) ( McGuinness and van Harmelen, 2004 ). This constraint is explained in Section 3.3.
Moreover, its concepts must be described using the terms of the common vocabulary, the same terms used to describe the con-cepts of the common reputation ontology. More details about the function of each component can be found in Nardin et al. (2008a) . 3.2. Translator module
The translator module ( Fig. 5 ) resides inside the agent and it translates reputation messages. It has four main activities: (i) to translate the concepts in reputation messages from the common ontology into the internal agent X  X  reputation model ontology whenever the message comes from the interaction module (IM); (ii) to translate the concepts in reputation messages from the internal agent X  X  reputation model ontology into the common ontology whenever the message is sent to IM; (iii) to trigger a function in the reputation reasoner module (RRM) based on the interpretation of messages written using the reputation model ontology; and (iv) to create a message using the reputation model ontology concepts whenever requested by RRM.

The TM utilizes the mappings available at the OMS translation repository in order to perform the message translation. Among its functionalities, two important ones are: (i) dealing with transla-tion issues and (ii) reputation value transformation.
Translation issues are considered any concept translation from a source ontology to a target ontology the mapping of which is not one to one. For instance, incompleteness is a translation issue in which a concept from a source ontology is not mapped to any concept of a target ontology; and ambiguity is a translation issue in which a concept from a source ontology maps more than one concept of the target ontology.

The TM translation strategy interface is the module responsible for implementing the strategies to handle translation issues. When some concept translation incurs in a translation issue, it may not only solve the translation issue but also it must guarantee that the strategy implemented is logically equivalent (A 3 B), meaning that if concept A is translated into concept B, then concept B must be translated into concept A. Examples of strategies to deal with translation issues can be found in Nardin et al. (2008b) .
Another important TM functionality is the reputation value transformation, which is implemented through the value trans-form interface module. It transforms the reputation value repre-sented in a source ontology into the value representation of a target ontology.

Flexibility and configurability were considered the main required characteristics for this module design, since not all the agents implement the same IM and RRM, and each agent may have different translation strategies. Flexibility allows TM adap-tation to interact with different kinds of IM and RRM, while configurability allows the selection of specific translation strate-gies and value transformations to satisfy the agent needs. A more detailed description about its components and operation can be found in Nardin et al. (2008a) . 3.3. Implementation considerations
The OWL DL language was chosen as the default ontology language description in this work. Even not using its full cap-abilities, this was the selected language since OWL is the World Wide Web Consortium (W3C) recommendation for creating and sharing ontologies, there are sound and complete DL reasoners ( Sirin et al., 2007 ; Tsarkov and Horrocks, 2006 ; Haarslev and M  X  oller, 2003 ) that provide the classification service necessary for the classifier module , and FORe was already described in OWL DL.
Besides the OWL DL reasoning, rule-based OWL reasoning is another approach that could be used by the classifier module to perform the ontology mapping function. The idea of this approach is to map OWL to a rule formalism that applies (a subset of) the OWL semantics in the KB of a rule engine ( Antoniou et al., 2005 ; Meditskos and Bassiliades, 2008 ). This approach is more advanta-geous than using OWL DL reasoning when applied to ontologies with a very large amount of instances ( Antoniou et al., 2005 ; Meditskos and Bassiliades, 2008 ). SOARI deals only with ontology concepts and the reasoning for classifying them. Nevertheless, the adoption of a rule-based approach would increase the OMS proces-sing requirements and the risk of inserting translation errors, since the ontology would need to be translated into a set of rules. Therefore, there is no advantage in adopting such approach.
In order to perform the classification service required by OMS, the inference engine chosen was Pellet ( Sirin et al., 2007 ). Its selection was motivated because it is completely developed in Java, open-source and has a method call integration to the Prote  X  ge  X  -OWL Plugin. Additionally, the OMS was designed with inference engine if required, guaranteeing flexibility to the architecture.

Probability distribution was chosen to represent the reputation value in SOARI, since it is more expressive than the boolean , bounded real and discrete sets representations proposed in Pinyol et al. (2007) . Due to space limitation, details about the transfor-mation functions among these representations implemented in SOARI can be found in Pinyol et al. (2007) .

SOARI is operational and available at http://soari.sou rceforge.net . 4. Experiments
In order to demonstrate the usefulness of SOARI, this section describes some experiments and pr esents the impact on the accuracy of the agents reputation evaluation when using (i) a more expressive reputation communication and (ii ) heterogeneous reputation mod-els. More specifically, two questions are to be answered: 1. Is there any improvement in the accuracy of the agents reputation evaluation when enabling a more expressive com-munication about reputation? 2. Is there any improvement in the accuracy of the agents reputation evaluation when considering the heterogeneity of reputation models?
In order to answer those questions, some experiments were performed using the ART (Agent Reputation and Trust Testbed) ( Fullam et al., 2005a , b ) and FOReART (FORe Agent Reputation and
Trust Testbed) ( Vercouter et al., 2007 ; Brand ~ ao et al., 2007 ) testbeds considering agents with three (Repage, L.I.A.R. and
MMH) reputation models. These experiments extend the ones presented in our previous work ( Nardin et al., 2009 ; Nardin, 2009 ), since they were rebuilt and reconducted, including a third reputation model (MMH). 4.1. Reputation models The agent reputation models used in this work are Repage,
L.I.A.R. and MMH. The selection of those reputation models was motivated by the fact that, although they have some similarities such as perform direct and indirect reputation evaluations about third-parties, they differ significantly regarding the semantic of their reputation concepts.

Next, we describe the terminologies identified as concepts in each of the reputation models are described.

L.I.A.R. is a model for the implementation of social control during agent interaction proposed by Muller and Vercouter (2008) .It has five different types of reputation: direct interaction-based reputation (DIbRp), which is built on directly exchanged mes-sages between the evaluator agent and the target; Indirect interaction-based reputation (IIbRp), which is built on messages observed by the evaluator agent about the target; Observation recommendation-based reputation (ObsRcbRp), which is built on messages received by the evaluator agent from third-parties concerning the target; Evaluation recommendation-based reputa-tion (EvRcbRp), which is built on evaluations received by the evaluator agent from third-part ies concerning the target; and
Reputation recommendation-based reputation (RpRcbRp), which is built on reputation evaluations received by the evaluator agent from third-parties concerning the target. L.I.A.R. reputation values are represented by a unique real number in the domain  X  1 ,  X  1 [ unknown .

Repage is a computational system based on a reputation model proposed by Conte and Paolucci (2002) . It is composed of two 4.2. Simulation testbeds provides a common environment to compare different agent reputation models and implementations. It simulates an iterative art appraisal game, in which agents evaluate paintings for clients and gather reputations and opinions from other agents to produce accurate appraisals. In this game, there are two types of agents: appraisal agents and client agents. The client agents contract and pay appraisal agents in order to have their paintings evaluated. The appraisal agents have different knowledge (expertise) about dif-ferent painting eras and they can buy reputation and opinion about third-parties from other appraisal agents in order to improve their reputation and painting evaluations. At the end of the game, the winner is the agent that obtains the highest final bank balance. of the need for cooperation to evaluate some of the paintings because the agents are only competent in some painting eras, and the competition to earn the largest share of the client pool. by mapping the reputation models evaluations into a single value in the domain [0:1]. Although not explicitly defined, it is assumed that value 0 refers to the lowest reputation value and 1 to the highest reputation value. A more detailed description about the ART testbed can be found in Fullam et al. (2005b) .
 agents, has some drawbacks: (i) it limits the communication expressiveness among agents to values in the domain [0:1], and (ii) it generates initial random values to execute each simulation, turning impossible the use of the same input data in other simulations for comparison purposes.
 proposed an extension to the ART testbed named FOReART. Such extension enables the agents to communicate through symbolic messages. Moreover, the function that generates the initial random values were replaced by one that loads initial data from a text file, thus allowing the use of the same initial data in different simulations. Nevertheless, the game is the same played at ART testbed. More details about the FOReART testbed can be found in Brand ~ ao et al. (2007) , Vercouter et al. (2007) . 4.3. Agent model
In the ART and FOReART testbeds, the game proceeds as a series of time steps and, at each iteration, the simulation engine triggers a predefined set of methods in a synchronous and ordered way. Such predefine set of methods represents the agent model, which is used to implement the agent X  X  strategy. In this section, the general strategy used by all the agents in the experiments performed using both testbeds is described.
This general strategy allows the representation of two types of appraisal agents: honest and dishonest. Honest agents answer the requests from other appraisal agents only when they have expertise about the requested painting era and their answer contains information coherent with their internal belief. Dishonest agents answer all the requests from other appraisal agents, even when they do not have enough expertise about that painting era, and they never answer the requests with information coherent with their internal belief.

Agent models in the ART and FOReART testbeds are imple-mented by extending the abstract agent class and implementing the predefined methods that describe the agent X  X  strategy ( Fullam et al., 2005a ). The pseudo-code representing the general strategy is presented in Algorithm 1.

Algorithm 1 ( General agent model strategy ). prepareReputationRequests(){ //Request reputation of all other agents } prepareReputationAcceptsAndDeclines(){ if lie  X  X jj X  expertise 4 expertiseThreshold  X  then return true else return false end if } prepareReputationReplies(){ if lie() then return reputation 0.4 else return reputation end if } prepareCertaintyRequests(){ // Request certainty of the first in the list} prepareCertaintyReplies(){ if lie() then return expertise  X  0.5 else if  X  expertise 4 expertiseThreshold  X  then return experise end if } prepareOpinionRequests(){ if TrustFor  X  X jj X  certainty 4 certaintyThreshold  X  then // Request opinion end if } prepareOpinionCreationOrders(){ request } prepareOpinionProviderWeights(){ requested opinion } prepareOpinionReplies(){ }
In the beginning of each game iteration, a set of client paintings is assigned to an appraisal agent for appraisal. For each painting assigned, the appraisal agent performs reputation trans-actions. First, it requests to other agents in the testbed the reputation of possible appraisers of that painting era ( repare ReputationRequests() ). Then, it answers the reputation requests received from other agents ( prepareReputationAcceptsAndDe-clines() and prepareReputationReplies() ). If it is a dishonest agent, it accepts all the requests. Otherwise, it only accepts the requests it has expertise greater than a predefined expertise threshold ( expertise threshold  X  0.7). To all the accepted requests, the dishonest agent answers with a reputation value, which does not reflect its internal reputation evaluation.

After performing the reputation transaction, the agent per-forms certainty transactions. It first selects a group of agents and requests them their certainty about a specific painting era ( pre-pareCertaintyRequests() ). Next, it answers the certainty requests received from other agents ( prepareCertaintyReplies() ). An honest agent whose expertise is greater than a predefined expertise threshold ( expertise threshold  X  0.7), answers the request with its expertise value. However, a dishonest agent answers the request with the maximum between 1 and its expertise value plus 0.5.

After performing the certainty transactions, the agent requests the opinion of the agents it trusts 1 or the agents from which it received a certainty value greater than a predefined certainty threshold ( certaintythreshold  X  0.5) ( prepareOpinionRequests() ). Such trust thresholds were defined arbitrarily; however, they will not endanger the experiments since all the agents use this same general values.

In order that the simulator computes the final opinion values, agents provide it with the opinions ( prepareOpinionCreationOr-ders ()) and the weights ( prepareOpinionProviderWeights ()). Finally, the opinion values are also provided to the requester agents ( prepareOpinionReplies ()). 4.4. SOARI integration and usage
In order to integrate with SOARI and use it, the agent must adapt its IM and RRM modules, and have its reputation model ontology mapping available in the OMS.

Albeit required, the adaptations in IM and RRM modules are reduced to a minimum since the translator module was designed guided by the flexibility and configurability characteristics. The IM requires to be adapted in order (i) to identify messages about reputation that are expressed us ing common reputation ontology concepts; (ii) to extract the messa ges content; and (iii) to send it to
It must also be capable of receiving messages from the IMI and of sending it to the target agents. The adaptation required on the RRM is simpler since it only needs to register itself in the reputation reasoner interface (RRI) to allow its callback. However, a specific RRI instance must be developed for e ach reputation model in order to enable the message exchange from TM to RRM and vice-versa.
On the other hand, if the agent reputation model ontology mapping is not available in the OMS, a three-step process must be performed in order to have it available. First, the reputation model concepts have to be identified. In Section 4.1, all the
Repage, L.I.A.R. and MMH reputation model concepts are identified.

After that, it is necessary to describe, in OWL ( Horridge et al., 2004 ), each of the reputation model concepts identified in the previous step in terms of the same common vocabulary adopted to describe the common reputation model concepts; in our case, FORe concepts. For example, the L.I.A.R Direct Interaction-based
Reputation ( DIbRep ) concept that has at least one association through the hasInformationSource relation to the DirectExperience from the common vocabulary, is formally described: ( hasInformationSource  X  DirectExperience  X 
Finally, the ontology must be uploaded to the OMS, which will execute the classifier module to process it and generate an ontology mapping as a result. For example, the mapping result of L.I.A.R. and FORe associated the L.I.A.R. DIbRep concept with the FORe DirectReputation concept.

It is worth noting that the two first steps were performed manually, while the third is automated by SOARI. A more detailed description of the SOARI usage and the mapping results can be found in Nardin et al. (2008a) . 4.5. Experiments description
The experiments consist of executing the art appraisal game previously described using the ART and FOReART testbed with 20 honest agents and 01 dishonest agent.

The main objective of these experiments was to identify the mean value of the reputation assigned by the honest agents to the dishonest agent. In order to enable the comparison between the experiments, the initial painting era knowledge and clients distribution were identical in all of them. Moreover, all agents used the same configuration parameters ( Table 1 ) and agent model (see Section 4.3) in all the simulations.

To attain the goal, we considered the execution of 10 simula-tions ( p  X  10) for each experiment with 100 cycles each. Each simulation was composed of 21 agents ( n  X  21); 20 agents were honest and 1 agent was dishonest ( i  X  [1,20] and j  X  21). The mean value of the reputation assigned to the dishonest agent by each honest agent ( r j ) considered only the value obtained in the last simulation cycle ( l  X  100 and m  X  100). The value of the last simulation cycle was used because we considered it the most accurate reputation evaluation.
 are honest agents and j  X  n is a dishonest agent. Moreover, consider that r sk ij is the reputation value assigned by agent i to agent j in cycle k on simulation s . Typically, the reputation value assigned by agent i to agent j on simulation s corresponds to the mean reputation value of a set of cycles. Thus, where l and m represent, respectively, the lower and upper cycle limits. The mean reputation value assigned by the honest agents to the dishonest agent in simulation s is
Finally, given a set of simulations s  X  1 , ... , p that compose an experiment, the mean value of the dishonest agent is r j  X  dimensions: (1) reputation model(s) used by the honest agents (Repage, L.I.A.R., MMH or mixed), (2) reputation model used by the dishonest agent (Repage, L.I.A.R., MMH), and (3) platform used (ART or FOReART) ( Table 2 ). Moreover, the mixed experiments (exp4 and exp8) are split into three others based on the reputa-tion model of the dishonest agent. In the other experiments, the dishonest agent uses the same reputation model as the honest agents. In addition, in the mixed experiments, each type of the 03 reputation models is used by 07 of the 21 agents. 5. Experiments analysis experiments results. However, first a brief explanation of the methodology used to analyze them is presented, and then the actual analysis and some discussion about it are provided. presented in Nardin et al. (2009) , since those experiments were analyzed considering that the resulting data followed the normal distribution. However, this was a strong constraint that could not be true all the time and the conduction of new analysis without considering such a constraint was imperative to validate the analysis X  results. Also, it extends the results presented in Nardin (2009) , in which a nonparametric hypothesis test was adopted (Wilcoxon X  X  Rank Sum Test) ( Boslaugh and Watters, 2008 )to analyze the resulting data of experiments conducted using just two reputation models (Repage and L.I.A.R.).

The methodology used to analyze the data generated by the experiments described in Section 4 is based on a statistical hypothesis testing. The statistical hypothesis test adopted is the nonparametric statistical hypothesis test Wilcoxon  X  s rank sum test .
As aforementioned, this hypothesis test was selected because the experiments resulting data did not follow the normal distribution and we could not ignore such data characteristic.
 The analysis performed in this section was based on the
L.I.A.R., Repage and MMH reputation models attributes. For reputation model attribute, we mean the different concepts of reputation defined in each reputation model. The analyzed attributes are presented in Table 3 . 5.1. Analyzing the effects of the communication expressiveness
In order to analyze the effects of the more expressive com-munication enabled by SOARI, it was verified if the mean value of the dishonest agent X  X  reputation model attributes ( r j ) obtained using numerical reputation values (ART experiments) were greater than the similar ones obtained in the symbolic testbed (FOReART experiments). The underlying idea was that if these results were statistically different, then it would mean that the dishonest agent is better identified if reputation is expressed and exchanged in a more expressive way. Thus, using Wilcoxon X  X  rank sum test, a set of hypotheses was required to demonstrate it. The general form of the hypothesis is: H1: The mean value of the reputation model attribute from
ART experiments is greater than the same attribute mean value from the FOReART experiments, in which a greater reputation mean value means a worse detection of the dishonest agent.

This hypothesis, from the point of view of the reputation model attribute is expressed mathematically as Q X ART 4 Q where X is a L.I.A.R., a Repage or a MMH reputation model attribute. In order to validate this hypothesis using the Wilcoxon X  X  rank sum test, the following test was performed:
The complete set of hypotheses to demonstrate the effects of the more expressive communication is composed of hypotheses from
A to H, and each one is related to a reputation model attribute, respectively, DIbRp , IIbRp , RpRcbRp , Image , Reputation , EncRep , ObsRep and PropRep .

The hypothesis test was applied to the results of pairs of experiments presented in Table 2 , considering the risk level ( a )of 0.05 and the degree of freedom of 18, the hypotheses generated the results presented in Table 4 ( means that H0 was rejected, which confirms the hypothesis; | means that H0 was not rejected; thus, the hypothesis cannot be confirmed; and -(dash) means that the hypothesis is not applicable for the pair of experiments).

Analyzing the information in Table 4 , hypotheses C, D, E and H are verified to reject the H0 (indicated by ), except in the case of (exp4.1, exp8.2) for parameter D, confirming that there is some gain in using more expressive communication, while hypotheses A, B, F and G do not (indicated by | ). From the reputation model point of view, hypotheses A, B and C are associated with the L.I.A.R. reputation model ( DIbRp , IIbRp and RpRcbRp attributes), hypotheses D and E are associated with the Repage reputation model ( image and reputation attributes), while hypotheses F, G and H are associated with the MMH reputation model ( EncRep , ObsRep and PropRep attributes).

Considering that the Repage agents update image and reputa-tion attributes with received information, while the L.I.A.R. and MMH agents update only the RpRcpRp and PropRep attribute, respectively, one can conclude that a more expressive commu-nication about reputation has a significant statistical impact on agents using all three reputation models, since the detection of the dishonest agent is improved in the hypotheses that consider the attributes impacted by communication.

Hence, there is an improvement in the accuracy of the agents X  reputation evaluation when enabling more expressive commu-nication concerning reputation.

This conclusion is the same obtained in Nardin (2009) ; how-ever, in the latter the same set of experiments was performed using only two reputation models (L.I.A.R. and Repage). This suggests that even with more than two reputation models, a more expressive communication improves the accuracy in the detection of a dishonest agent. Therefore, our architecture, while dealing with semantic interoperability through an ontology-based approach, brings some benefits while supporting a more expres-sive communication among agents with heterogeneous reputa-tion models. 5.2. Analyzing the effect of the reputation model heterogeneity
The analysis of the effect of reputation model heterogeneity was performed by testing if the mean value of the dishonest agent X  X  reputation model attributes ( r j ) obtained from experi-ments with a homogeneous reputation model were higher than the similar ones obtained from mixed experiments. The under-lying idea was that if these results were statistically different, it would then mean that heterogeneous environments, composed of agents with different reputation models, would better identify the dishonest agent, since different aspects of the behavior of the latter could be better captured in the presence of different reputation models. Thus, to demonstrate it using Wilcoxon X  X  rank sum test a set of hypotheses was required. The general form of the hypothesis is:
H1: The mean value of the reputation model attribute from experiments with homogeneous reputation model is greater than the same attribute mean value from mixed experiments, where greater reputation mean value means a worse detection of the Dishonest agent.

This hypothesis, from the point of view of the reputation model attribute is mathematically expressed as Q X P = M 4 Q , where M is the reputation model (L.I.A.R., Repage or MMH), X is an attribute and P is the testbed platform (ART or FOReART). In order to validate this hypothesis using the Wilcoxon X  X  rank sum test, the following test was performed:
The complete set of hypotheses to demonstrate the effects of heterogeneous reputation models is composed of hypotheses from I to X. Hypotheses I to P are related to the ART platform ( Table 5 ), where each one is related to a reputation model attribute, respectively, DIbRp , IIbRp , RpRcbRp , image , reputation , EncRep , ObsRep and PropRep . Hypotheses Q to X are related to the
FOReART platform ( Table 6 ), where the same attributes and order of Table 5 were used.
 presented in Table 2 , considering the risk level ( a ) of 0.05 and the degree of freedom of 18, those hypotheses generate the results presented in Tables 5 and 6 ( means that H0 was rejected, which confirms the hypothesis; | means that H0 was not rejected; thus, hypothesis cannot be confirmed; and -(dash) means that the hypothesis is not applicable for the pair of experiments).
 one can see that almost all the hypotheses did not reject H0 (indicated by | ). This indicates that heterogeneity, in most cases, does not improve the detection of a dishonest agent. This result differs from the one obtained in Nardin (2009) , since in the latter the hypothesis related to the RpRcbRp attribute rejected H0 (indicated by ), while the other L.I.A.R. and Repage hypotheses did not (indicated by | ).
 were some intrinsic or implementation model characteristics that provided benefits to the L.I.A.R. reputation model, this could not be confirmed when including a third reputation model. Since a quantitative analysis was not enough to provide a conclusion about how heterogeneity influences the detection accuracy of a dishonest agent in the ART testbed, a detailed qualitative analysis should be conducted in order to understand the interdependence among the reputation models.
 are hypotheses that rejected H0 (indicated by ), which are related to the RpRcbRp attribute from L.I.A.R. (hypothesis S), and EncRep and ObsRep attributes from MMH (hypotheses V and W). cluded to have a significant statistical impact on agents using
L.I.A.R. and MMH reputation models. Diversely, the Repage reputation model does not present a significant statistical impact on agents when in a heterogeneous environment and when using a more expressive communication.
 obtained in Nardin (2009) . However, when comparing the results obtained for MMH and L.I.A.R., they can be considered to be the inverse since the attrib utes characteristics from both reputation models are similar ( DIbRp EncRep , IIbRp ObsRep and RpRcbRp PropRep ) and their analysis result are the inverse (while in L.I.A.R. the RpRcbRp attribute, which is the only one affected by the communication, has a significant statistical impact, in MMH the attributes EncRep and ObsRep that have a significant statistical impact are the two that are not affected by the communication).
 possible to conclude that the significant statistical impact on agents is related to heterogeneity, since they do not follow the same behavior pattern. Therefore, it is necessary to perform a detailed qualitative analysis in order to understand the inter-dependence among the reputation models and how heteroge-neity influences them. 6. Conclusions and future work reputation models using the SOARI architecture in the art apprai-sal domain were presented. Simulations were conducted consid-ering L.I.A.R., Repage and MMH reputation models in order to answer two questions: (1) is there any improvement in the reputation evaluation accuracy when enabling a more expressive communication? and (2) how does the heterogeneity of reputa-tion models influence the evaluation accuracy of the dishonest agents X  reputation? These questions were defined considering that the inclusion of semantics within communicative acts among agents give more expressive power to communication.

The results obtained using a more expressive communication concerning reputation presented an improvement in the accuracy of the reputation evaluation of other agents and corroborated the results presented in Nardin (2009) . However, the results of reputation model heterogeneity did not allow us to conclude such improvement and/or corroborate with the conclusions pre-sented in Nardin (2009) . It is thus made necessary to perform a detailed qualitative analysis to explain the quantitative analysis results and for better understanding the reputation models interdependence.

Although our approach and architecture were implemented and tested in a specific problem domain, we believe they are applicable to other domains. Therefore, we intend to evaluate the possible application of the general approach, i.e. providing agent interoperability using a service oriented architecture based on ontology in different aspects of multiagent systems other than reputation, for instance, organizational models ( Coutinho et al., 2008 ).

Additionally, we also intend to perform some experiments considering dishonest agents that do not lie all the time and compare their results to the one that always lies.

We advocate that the proposed approach, when the associated technologies are fully developed, will heavily impact any applica-tion area that could benefit from accurate information concerning the reputation of autonomous agents, for instance e-Commerce, e-Government and e-Services.

The possibility of automating the process of aligning ontolo-gies for further mapping is also among our future work objectives.
In this case, both the ontology mapping service (OMS) and the translator module (TM) would be redesigned to enable the use of automatic ontologies alignment approaches ( Jean-Mary et al., 2009 ; Noy and Musen, 2001 ; Wang and Xu, 2009 ).
 Acknowledgments This project is partially supported by FAPESP/Brazil. Jaime S.
Sichman is partially supported by CNPq/Brazil. We would like to acknowledge Toma  X  s Monteiro Chaib for the implementation of the MMH reputation model and its integration to SOARI. References
