 Ontology-mediated data access and management systems are rapidly emerging. Besides standard query answering, there is also a need for such systems to be coupled with explanation facilities, in particular to explain missing query answers (i.e. desired answers of a query which are not deriv-able from the given ontology and data). This support is highly demanded for debugging and maintenance of big data, and both theoretical results and algorithms proposed. How-ever, existing query explanation algorithms either cannot scale over relative large data sets or are not guaranteed to compute all desired explanations. To the best of our knowl-edge, no existing algorithm can efficiently and completely explain conjunctive queries (CQs) w.r.t. ELH  X  ontologies. In this paper, we present a hybrid approach to achieve this. An implementation of the proposed query explanation algo-rithm has been developed using an off-the-shelf Prolog en-gine and a datalog engine. Finally, the system is evaluated over practical ontologies. Experimental results show that our system scales over large data sets.
 I.2.4 [ Artificial Intelligence ]: Knowledge Representation Formalisms and Methods X  Representations ; H.4.0 [ Information Systems Applications ]: General Abductive reasoning; description logics; conjunctive query. c  X 
One promising solution to the effective access and man-agement of the ever-growing sea of digital information has been to use computers in setting up databases of informa-tion, completed with ontologies that assist in organization and access. In such an ontology-mediated data access frame-work, ontologies are used as virtual schemas over data sets to enrich query answering with ontological knowledge through logical reasoning, while making use of practical database management systems to scale over very large data sets. The standardised web ontology language OWL 2 and its three profiles, EL, QL and RL 1 , are based on description logics (DLs), and conjunctive queries (CQs) are used as a vital querying tool.

Besides standard query answering, explanation services are often required by end-users to understand why certain answers are derived or missing. For instance, suppose on-tology O specifies that a PhD student is a student, i.e., PhD v Student , each PhD student has some supervisor, i.e., PhD v  X  hasSupervisor . Person , Tom is a PhD student and Mary is a student, i.e., PhD ( Tom ) and Student ( Mary ). For the query to retrieve those individuals who have supervisors, which can be expressed as Q ( x ) =  X  y. hasSupervisor ( x,y ),  X  X om X  is an answer whereas  X  X ary X  is not. One explana-tion for  X  X ary X  being missing is that PhD ( Mary ) is absent. Such explanation services are critical for knowledge manage-ment to identify specific pieces of the knowledge that need to be revised. For example, the observation that Mary should have a supervisor indicates that the current knowledge is incomplete and PhD ( Mary ) could be added.

On the other hand, however, the implementation of ex-isting OWL reasoners does not support such an explanation mechanism even through tracing the execution of query an-swering. For this reason, extensive efforts have been devoted to equip ontology-based systems with various explanation fa-cilities [22, 23, 4, 15, 24, 6]. While early research was mainly on explaining derived answers (a.k.a. positive answers, like  X  X om X  in the above example), explaining missing answers (a.k.a. negative answers, like  X  X ary X ) has attracted much attention lately [3, 6]. Such an explanation facility is es-sential to understand why the ontology-based system fails http://www.w3.org/TR/owl2-profiles/ to derive certain desired answers, and to enrich incomplete data according to user observations. Such a query explana-tion problem is usually formalised as a problem of abduction in AI, called query abduction .

Existing research efforts showed that query abduction is challenging. First, while ontology-based reasoning empow-ers query answering, it also complicates query abduction. The computational complexity of query abduction is indeed higher than query answering [6]. Also, efficiency of abduc-tion implementation has not been a central concern in AI but it is essential for ontology-based systems, and it is highly non-trivial to develop a scalable algorithm for query abduc-tion. Furthermore, existing query abduction approaches are either incapable to scale over large data sets or incomplete in explaining CQs (i.e., they may fail to compute certain explanations, see a detailed discussion in Section 2). In this paper, we demonstrate that it is possible to achieve both scalability and completeness in one framework , by present-ing a complete and scalable query abduction method for ELH  X  ontologies. We choose ELH  X  because it underlies the OWL 2 EL profile, is expressive enough for many practical ontologies such as SNOMED CT, and is a core fragment of most expressive DLs. CQ answering for ELH  X  ontologies has attracted intensive interest lately [19, 26].

The main contributions of the paper include: (1) We re-duce a query abduction problem in ELH  X  to an equivalent one in datalog, and prove the soundness and completeness. (2) We introduce a method to extract (often very small) modules of the data through data summarisation, and we introduce an advanced pruning strategy to couple the basic backward chaining procedure in the search for solutions. (3) We implemented a prototype system that integrates highly optimised Prolog and datalog engines, and our evaluation shows that the algorithm is capable of handling query ab-duction involving around 10 million facts.
Several approaches to query abduction have been pro-posed, which vary according to their underlying DLs and types of observations. Some of these focused on expressive DLs and observations formulated by simple atomic queries or ground CQs [17, 14, 21, 9]. These approaches typically use tableau-based methods, which however, could rarely scale over relative large data sets. One exception is the approach by Du et al. [9], which we will discuss in detail later.
Query abduction for CQs with existentially quantified vari-ables, which will be referred to as general CQs , has been in-vestigated only for light-weight DLs underlying OWL 2 RL and QL profiles. Borgida et al. [3] are among the first who advocated to study the explanation of negative answers, and they focused on OWL 2 QL. Du et al. [10] have proposed a practical approach in OWL 2 RL, and an OWL 2 RL ontol-ogy can be directly translated into a datalog program. Cal-vanese et al. [6] investigated the computational complexity of query abduction in OWL 2 QL. To the best of our knowl-edge, we are the first to study query abduction for general CQs in OWL 2 EL.

Du et al. [9, 8] were among the first to tackle the scalability issue, yet those approaches still suffer from some shortcom-ings. The method proposed in [9] is incomplete for general CQs, that is, their method is unable to compute all mini-mal explanations for some general CQs. This is mainly due to the ontology transformation adopted in that approach, which discard rules with existentially quantified variables in the head. Such rules will be referred to as genuine ex-istential rules . For example, consider the ontology O in Section 1, the algorithm developed in [9] discards the ax-iom PhD v  X  hasSupervisor . Person and thus cannot obtain the explanation PhD ( Mary ). Also, the system developed in [9] still has difficulty in processing large data sets (see Sec-tion 5 for details). In [8], a notion of a representative expla-nation is introduced, which is informally a schema of mul-tiple explanations. While a scalable algorithm is developed, the approach works only for first-order (FO) rewritable on-tologies, and ontologies expressed in popular ontology lan-guages, such as OWL 2 EL which we look into, may not be FO rewritable. It is challenging to efficiently compute representative explanations for ontologies that may not be FO rewritable. To see this, consider an ontology consisting of one axiom  X  R.A v A . For the observation A ( a ), there would an infinite number of representative explanations of the form { R ( a,u 1 ) ,R ( u 1 ,u 2 ) ,...,R ( u n  X  1 ,u
In summary, compared to existing query abduction ap-proaches, our approach is the only one that enjoys all the following three properties: (1) In contrast to [17, 14, 21], our approach scales over large data sets. (2) In contrast to [9], our approach is complete for general CQs in a sense that all (minimal) explanations can be computed. (3) In contrast to [3, 10, 6, 8], our approach applies to ELH  X  ontologies that are not necessarily FO rewritable.
We use standard notions of first-order (FO) constants, variables, terms, substitutions, predicates, atoms, (ground) formulae, and sentences. All atoms and formulae considered in the paper are function free. A fact is a ground atom. For a formula  X  , with  X  ( ~x ) we denote that ~x are the free vari-ables in  X  . For a (set of) formula(e)  X  , pred (  X  ), term (  X  ), const (  X  ) denote the set of predicates, terms, and constants occurring in  X  . First-order entailment are defined as usual. For convenience, we sometimes treat a conjunction of atoms as a set consisting of the atoms.
Consider countably infinite and mutually disjoint sets N C N
R , N I , and N V of concept names (i.e., unary predicates), role names (i.e. binary predicates), individuals (i.e. con-stants), and variables respectively. In ELH  X  , a concept de-scription (or simply concept ) C is defined inductively using the following constructors: where A  X  N C , R  X  N R , and C 1 and C 2 are concepts. A TBox is a finite set of axioms of the forms C v D , and R v S , where C,D are both concepts and R,S  X  N R . An ABox is a finite set of facts of the forms A ( a ) and R ( a,b ), where A  X  N C , R  X  N R and a,b  X  N I . A knowledge base (KB) K = ( T , A ) consists of a TBox T and an ABox A . The semantics of ELH  X  is defined as usual in terms of an interpretation I = ( X  I ,  X  I ), and we refer to [1] for details.
An ELH  X  TBox is normalized if it consists of only axioms of the forms A v B , A 1 u X  X  X u A n v A , A 1 v X  R.A ,  X  R.A A , and R v S , where A ( i )  X  N C  X  X &gt;} , B  X  N C  X  X &gt; ,  X } , and R,S  X  N R . An ELH  X  TBox can be transformed in polynomial time to a normalized TBox that is equivalent to the TBox [1]. Without loss of generality, we consider only TBoxes in normal form.

An FO query Q ( ~x ) is a first-order formula (with free vari-ables ~x , we will sometimes write Q for simplicity). It is called boolean if ~x is empty. For a tuple of constants ~a with the same arity as ~x , we write Q ( ~a ) to denote the Boolean FO query obtained from Q ( ~x ) by substituting the variables ~x with constants ~a . For a TBox T , an ABox A , and a FO query Q ( ~x ), a tuple of constants ~a is a certain answer (or simply an answer ) to Q ( ~x ) over T and A , if the arity of ~a agrees with that of ~x and T  X  X  | = Q ( ~a ). Otherwise, if T  X  X 6| = Q ( ~a ) then ~a is a negative answer .

A conjunctive query (CQ) Q ( ~x ) is of the form  X  ~y. X  ( ~x,~y ), where  X  is a conjunction of atoms with predicates and terms from N C  X  N R and N I  X  N V , respectively. Variables ~x are answer variables and ~y are quantified variables . A ground CQ is a CQ where ~y is empty, and an atomic query is a ground CQ where  X  ( ~x,~y ) consists of a single atom. We consider the query abduction problem (QAP) where a CQ and an answer tuple are given as the observation and a solution to the problem (or equivalently an explanation to the query answer) is a set of facts [6]. Formally, given a background ontology consisting of a TBox T and an ABox A , taking an instantiated CQ (or a BCQ) Q ( ~a ) as the ob-servation , a solution to the query abduction problem is a (possibly empty) set E of facts such that E is consistent with T  X  X  and ~a is an answer to Q ( ~x ) over T  X  X  (only) to-gether with E . In classical abduction setting, to reduce the search space and retrieve only relevant solutions, the predi-cates allowed in the solutions are often pre-specified, which are called abducibles . Furthermore, for the ease of under-standing, solutions should be as succinct as possible, and the minimal solutions (w.r.t. set containment) are desired. The formal definition of QAP and a solution to the QAP is given as follows.

Definition 1 (QAP). An instance of a query abduc-tion problem (QAP) is a five tuple P =  X  X  , A , Q ( ~a ) ,  X  ,  X   X  , where T is an ELH  X  TBox, A is an ELH  X  ABox, Q ( ~x ) is a CQ, ~a a tuple of constants with the same arity as ~x ,  X   X  N C  X  N R is a finite set of predicates, and  X  is a finite set of constants. BCQ Q ( ~a ) is the observation ,  X  is the set of abducibles , and  X  is the domain .

A solution E to the QAP P is a set of facts such that 1. pred ( E )  X   X  and const ( E )  X   X  ; 2. T  X  X  X  X  | = Q ( ~a ) ; 3. T  X  X  X  X  6| =  X  ; and 4. E 6| = Q ( ~a ) ; Conditions 3 and 4 are called non-triviality conditions for a solution. Let sol ( P ) be the set of solutions to P . Moreover, E is minimal if there is no solution E 0  X  sol ( P ) s.t. E
In contrast to the definitions in [6, 8], the above definition has a finite domain  X  as an additional attribute, and  X  contains all the constants occurring in a solution. In [6, 8], a solution can contain any constants, including arbitrarily many fresh constants not present in the initial ABox. In this case infinitely many (minimal) solutions often exist for a QAP, and hence it is impossible to compute all the (minimal) solutions. Even if representative solutions are considered [8], which ignore renaming of fresh constants and are minimal up to substitution, still infinitely many such representative solutions may exist in general, as shown in Section 2. On the other hand, allowing uncontrolled introduction of fresh constants to QAP solutions is arguably of mere theoretical interest. In query explanation, a finite number of constants are often sufficient. Hence, we assume a finite domain  X  in a QAP, which can either be specified by the user, or by default set to be the set of all the constants in the initial ABox A and/or the constants in the observation Q . Given that the predicates and constants allowed in a solution are both finite and pre-specified, the total number of solutions to a QAP is always finite (even for ontologies that are not FO rewritable).
Since our new approach translates a QAP for ELH  X  into a problem of abduction in programs of existential rules, we recall some basics of existential rules in this subsection. For-mally, an existential rule [5, 2] is a sentence of the form where  X  ( ~x,~y ) and  X  ( ~x,~z ) are conjunctions of function-free atoms and ~x , ~y and ~z are pairwise disjoint. For convenience of presentation, universal quantifiers are often omitted. For-mula  X  is the body and formula  X  is the head of the rule. It is shown in [5] that ELH  X  can be captured by existen-tial rules. In particular, given an ELH  X  TBox T , T can be transformed into an existential program R T that is seman-tically equivalent to T in first-order logic. Query answering and query abduction in programs of existential rules are de-fined in the same way as in ELH  X  , and for query abduction of existential rules, we extend the definition QAP to allow Q in observations to be a FO query.

A datalog rule is an existential rule whose head  X  ( ~x,~z ) consists of a single atom and ~z is empty. In logic program-ming, the semantics of a datalog program D is given by the least Herbrand model. For a datalog program D , let M be the least Herbrand model of D X  X  , it is well known that for a tuple ~a , D X  X  | = Q ( ~a ) if and only if M satisfies Q ( ~a ).
Answering CQs w.r.t. a datalog program can also be achieved through a backward chaining procedure based on SLD-resolution (with tabling , a technique to control cycles and to guarantee termination), which we formally present as follows. A goal is a conjunction of atoms  X  1  X  ...  X   X  m SLD-resolution rule takes as premises a goal and a datalog rule, and it produces a new goal as follows where  X  is the most general unifier of  X  1 and  X  . An SLD-proof of a goal G 0 w.r.t. a datalog program D and a set F of facts is a sequence of goals G 0 ,...,G n , where G n  X  F and each G i +1 is obtained from G i by a single SLD-resolution. SLD-resolution is sound and complete for datalog: for a dat-alog program D , a set F of fact, a CQ Q ( ~x ) =  X  ~y. X  ( ~x,~y ) and a tuple ~a of constants, D  X  X  | = Q ( ~a ) iff there exists an SLD-proof of the goal  X  ( ~a,~y ) w.r.t. D and F . In this case, we call it an SLD-proof of Q ( ~a ) w.r.t. D and F . For a rule r  X  D , denote r  X  SLD ( Q , D , F ) if r is involved in an SLD-proof of Q w.r.t. D and F ; and for a fact  X  , denote  X   X  SLD ( Q , D , F ) if there exists an SLD-proof G 0 ,...,G of Q ( ~a ) such that  X   X  G n .
In our query abduction setting, observations may contain existentially quantified variables and ontologies may have genuine existential rules. It is well observed in query an-swering and abduction literature that the sophisticated in-teraction between general CQs and genuine existential rules often post great challenges to computation. Our approach to address the scalability and completeness issues in query abduction combines several novel techniques for ontology transformation, query rewriting, data summarisation and module extraction, and our system integrates a datalog en-gine, a Prolog engine and an RDBMS. The key feature of our approach is that it reduces ontological query abduction in ELH  X  to rule-based reasoning and thus can make use of off-the-shelf rule-based systems (instead of less scalable OWL reasoners). Also, it is sound and complete in comput-ing all the minimal solutions, and at the same time scales over large data sets.
In a nutshell, given a QAP P =  X  X  , A , Q ,  X  ,  X   X  in ELH our approach computes all its minimal solutions in the fol-lowing steps.
 Ontology transformation and observation rewriting : Our first step is to compute a datalog approximation D of the initial TBox T and a rewriting Q  X  of the initial ob-servation. In the construction of D T , instead of eliminating all the axioms in T that cannot be equivalently translated into datalog, we replace the existentially quantified variables with fresh constants. For approximated reasoning, we could replace T with D T and compute solutions for the new QAP using a resolution-based procedure. However, the approxi-mation may introduce incorrect solutions, and hence Q  X  is constructed by adding filtering conditions to Q , which will invalidate certain resolution proofs and hence filter out the corresponding (spurious) solutions.
 Module Extraction : In the second step, we extract (small) modules of each component (except for the observation) of the QAP that are used for query abduction, and we achieve this through data summarisation. First, we obtain a com-pact summary  X  ( A ) of the initial ABox A by grouping and merging individuals in A . Then, using  X  ( A ) together with D
T and Q  X  , we extract modules of D T , A ,  X  and  X  that are relevant to the query abduction. For example, two (small) modules A Q and A  X  of A are extracted, one for solution generation and one for solution verification. The module A
Q is obtained through a resolution-based procedure and by tracking the facts in  X  ( A ) that participate in some reso-lution proof of Q .
 Solution generation and verification with pruning : In the final step, we use the modules extracted in the pre-vious step to generate and verify solution candidates. We employ a Prolog engine in this step and the previous step to perform resolution, by encoding the corresponding QAPs in Prolog. Besides a systematic search for solutions via resolu-tion, an advanced pruning strategy is also applied. That is, once a solution E is computed, we exploit it further to gener-ate other candidates E 0 , by applying hierarchical knowledge from the TBox T . In this the resolution proof for construct-ing E 0 is often pruned. Verifications of solution candidates are performed with a datalog engine. Hence, our approach consists of a combination of backward chaining (for solution generation) and forward chaining (for verification).
For an ELH  X  KB K = ( T , A ) with a normalized TBox, we will first transform T into a datalog program D T way similar to [26]. In particular, D T consists of the rules in Table 1, plus one rule A ( x )  X  &gt; ( x ) for each concept name A occurring in T and two rules R ( x,y )  X  &gt; ( x ) and R ( x,y )  X &gt; ( y ) for each role name R occurring in T , where we use &gt; as a special unary predicate in datalog. These datalog rules capture the semantics of &gt; in ELH  X  . Table 1: Transformation from ELH  X  to datalog.
 The following example illustrates the transformations.
Example 1. Let TBox T consist of the following three axioms: Axiom T1 says that a research assistant ( RA ) is a person and she works in some research group ( RG ), and axioms T2 and T3 say that a student is a person who takes some courses. The corresponding existential program R T has five rules R1 X  X 5: where R5 is an abbreviation of two rules and the auxiliary concept introduced via normalization is omitted for brevity.
Then, R T is transformed into the datalog program D T containing R1, R3, R5, and the following datalog rules S1 X  S4: where c 1 , c 2 are fresh constants, S1 and S2 are transformed from R2, and S3 and S4 from R4.

The following result states that the datalog approximation of each KB is complete for query abduction. That is, each solution to the QAP w.r.t. KB T  X  X  is a solution to the corresponding QAP w.r.t. datalog program D T  X  X  .
Proposition 1. Let P =  X  X  , A , Q ( ~a ) ,  X  ,  X   X  be a QAP in ELH  X  , and P 0 be the QAP obtained from P by replacing T with D T . Then, sol ( P )  X  {E  X  sol ( P 0 ) | D T  X  X  X  X  6| =  X  x.  X  ( x ) } .

However, the converse of Proposition 1 may not hold, that is, the transformation is not necessarily sound, and the fol-lowing example illustrates it.

Example 2. Let TBox T = { A v X  R.A } . Then, the dat-alog program D T contains the following datalog rules A ( x )  X  R ( x,c ) and A ( x )  X  A ( c ) . Take  X  = { A } and  X  = { a,b } . 1. Consider CQ Q 1 ( x,y ) =  X  z. [ R ( x,z )  X  R ( y,z )] and 2. Consider CQ Q 2 ( x ) =  X  y. [ R ( x,y )  X  R ( y,y )] and QAP The cause of incorrect solutions is that the above transfor-mation from a TBox to a datalog program enforces fork-shaped and cyclic structures in the models by unifying the instantiation of existentially quantified variables in each rule.
To retain the soundness of our TBox transformation, we rewrite observations to filter out spurious solutions. In par-ticular, we rewrite a CQ Q ( ~x ) into a FO query Q  X  ( ~x ) such that for any observation Q ( ~a ), the solutions to a QAP P are exactly those to the QAP P 0 obtained by replacing the TBox T in P with D T . Our rewriting approach is adapted from [20], where a rewriting method is used to filter out spuri-ous query matching. While the rewriting in [20] is shown to be sufficient for query answering, it was unknown whether it works for abduction. Also, it is worth noting that our rewriting is simpler than that of [20], as we use a different program transformation from theirs. In what follows, we show that the rewriting technique can be used in abduction and in particular, our transformation-based procedure and the adapted observation rewriting form a sound and com-plete algorithm for query abduction in ELH  X  .

We first introduce unary predicates Ind and Aux to assert respectively the individuals occurring in the initial ABox and the auxiliary constants (i.e., those fresh constants generated in the approximation phase shown in Table 1). Then, to pre-vent spurious solutions introduced by fork-shaped or cyclic structures in the least Herbrand model of D T (but not in models of T ), for a CQ Q , we define the equivalence rela-tion  X  over the terms (i.e., variables and constants) in Q as in [20]. Formally,  X  X  X  term ( Q )  X  term ( Q ) is the smallest reflexive, symmetric and transitive relation that satisfies the following condition: (*) if R 1 ( s,t ) ,R 2 ( s 0 ,t 0 )  X  X  with t  X  t 0 then s  X  s Intuitively, the relation  X  will be used to guarantee that if an instantiation of the query is satisfied by the least Herbrand model of D T , then the instantiation does not contain a fork or cycle introduced by auxiliary constants (e.g., as in Ex-ample 2). For each equivalent class  X  of  X  , a representative t  X   X  is chosen.

For a CQ Q , the following notions help us to identify sub-structures in Q that can possibly lead to spurious solutions, as their instantiations may contain forks and cycles: Fork and Cyc can be also computed in time polynomial to the size of Q [20].
 Now, we introduce the rewriting of observations. Let CQ  X  ~y. [  X   X   X  1  X   X  2 ] where Intuitively, filter  X  1 says that fork-shaped substructures in Q should be instantiated in a way that all the legs merge into one, and  X  2 says that a cyclic substructure in Q can only be instantiated with individuals (not auxiliary constants).
Example 3 (Cont X  X  Example 1). There are two equiv-alence classes { x,y } and { z } with respect to the relation  X  in Q 1 ( x,y ) , and the rewriting of CQ Q 1 ( x,y ) is Q  X  1 ( x,y ) =  X  z. [ R ( x,z )  X  R ( y,z )  X  ( Aux ( z )  X  x = y )] . Let P 00 1 be obtained from P 0 1 by replacing Q 1 ( a,b ) with Q then { A ( a ) ,A ( b ) } is not a solution to P 00 1 no solution just as P 1 .

There is only one equivalence classes { x,y } with respect to the relation  X  in Q 2 ( x ) , and the rewriting of CQ Q is Q Let P 00 2 be obtained from P 0 2 by replacing Q 2 ( a ) with Q then { A ( a ) } is not a solution to P 00 2 , and no solution exists
Note that our rewriting is simpler than that of [20], largely due to the datalog transformation we adopt in the paper, which provides a tighter approximation on the models. For example, given an axiom A v X  R.B u X  S.B , it is transformed into four datalog rules A ( x )  X  R ( x,c R,B ), A ( x )  X  B ( c A ( x )  X  S ( x,c S,B ), and A ( x )  X  B ( c S,B ). In an approxi-mated model in [20], however informally, c R,B and c S,B are not distinguished. Thus, it is not hard to see that we do not need the filter queries related to Fork 6 = and Fork H in [20].
The following theorem states that the ontology transfor-mation combined with observation rewriting is sound and complete in ELH  X  .
 Theorem 1. Let P =  X  X  , A , Q ( ~a ) ,  X  ,  X   X  be a QAP in ELH  X  and P 0 =  X  X  T , A , Q  X  ( ~a ) ,  X  ,  X   X  . Then, sol ( P ) = {E  X  sol ( P 0 ) | D T  X  X  X  X  6| =  X  x.  X  ( x ) } .

Reducing a QAP in ELH  X  to an equivalent one in data-log allows us to use a resolution-based procedure, like SLD-resolution, to generate solution candidates E . Let  X  be the set of all facts constructed from the predicates in  X  and the constants in  X . Then, all the candidates for minimal solutions can be generated by enumerating the SLD-proofs of goal Q ( ~a ) w.r.t. D T and A  X   X . We will speak infor-mally about (SLD-)resolution proofs of Q  X  ( ~a ), which are SLD-proofs of Q ( ~a ) validated against the additional filter-ing conditions in Q  X  ( ~a ). Practically, Q  X  ( ~a ) can be encoded in Prolog, and hence it makes sense to talk about resolu-tion proofs of Q  X  ( ~a ) and the solution candidates generated from them. We will omit ~a in the (rewritten) observation for simplicity.

To verify the non-triviality of a solution E , existing query abduction algorithms [10] often use an OWL reasoner like HermiT or Pellet. Theorem 1 shows that we can use a data-log engine for such verifications, which is often more efficient than an OWL reasoner.
Although reducing a QAP in ELH  X  to a QAP in datalog allows us to apply rule-based reasoning and highly efficient rule-based systems to compute solutions, a resolution proce-dure can still be computationally very expensive, especially when handling a large number of facts. In such cases, even if there are a small number of datalog rules, a resolution pro-cedure may suffer from a significant computational overhead when it attempts to find out valid substitutions for a large number of constants. This is illustrated with the following example.
 Example 4. Consider the BCQ Q =  X  x. [ A ( x )  X  B ( x )  X  C ( x )] , datalog program D = { R ( x,y )  X  D ( y )  X  B ( x ) ,E ( x )  X  F ( x ) } , and ABox A = { A ( a ) ,C ( a ) ,D ( b ) ,A ( c E ( d 1 ) ,...,E ( d n ) } . Let  X  = { R } and  X  consist of all the individuals in A . Then the QAP P =  X  X  , A ,Q,  X  ,  X   X  has a single solution { R ( a,b ) } . Yet in the computation of (all min-imal) solutions, a resolution procedure will attempt to resolve A ( x ) with each A ( c i ) ( 1  X  i  X  m ). Then, after resolving it will attempt to resolve y in R ( c i ,y ) with all the individuals including all the d j  X  X  ( 1  X  j  X  n ). Such an effort only fails eventually when trying to resolve say D ( d j ) and C ( c When the ABox is large, a huge number of similar unfortu-nate attempts may occur, and as a result the computation suffers.

Hence, we want to reduce the number of input facts by extracting modules of the initial QAP components that are sufficient for the query abduction. Using ABox modules can effectively reduce the search spaces for resolution. We achieve this through data summarisation, a technique used in query answering [7, 11, 27]. Yet instead of using the result of summarisation directly for reasoning, we apply a novel method to extract modules of the initial QAP compo-nents. A data summarisation method groups the individuals in the ABox according to their occurrences in the ABox and merges individuals within the same group. In the result of summarisation, only one representative individual remains for each group. Individuals are grouped according to their
We assume the resolution proceeds from left to right as implemented in most Prolog engines, which may not be the case for every resolution procedure. Indeed, certain optimi-sation with ordering could help in this specific example, yet the example is to demonstrate a general issue not necessarily tied to ordering. types in the ABox. For an ABox A and an individual a in A , the type of a in A is  X  = { A | A ( a )  X  X  ,A  X  N C } , i.e., a type is a finite set of concept names an individual is asserted to be a member in the ABox. Then, an ABox summary is defined as follows.

Definition 2. Given an ABox A , for each type  X  of an individual in A , assign a distinct fresh individual c Let  X  map each individual a in A to c  X  where  X  is the type of a in A . Then,  X  ( A ) is the ABox obtained by replacing each individual a in A with  X  ( a ) , and is referred to as the summary of A .
 In practice, the number of types of individuals in a dataset is often much smaller than the number of individuals. As individuals with the same type tend to behave in a similar way in reasoning, merging them in data summarisation often leads to a compact and tight approximation of the initial ABox.

For a QAP P 0 =  X  X  T , A , Q  X  ,  X  ,  X   X  , we first show how to use the ABox summary to extract two modules of the ABox A , one for generating QAP solutions and the other for verifying non-triviality. After that, we will show how to extract modules of other components of the QAP. For convenience, we regard  X  as a mapping defined on the set of individuals in  X  by defining  X  ( a ) = a for each a not occurring A . Given an ABox summary, we are able to define two modules as follows. Recall that  X  is the set of all facts over the predicates in  X  and the constants in  X .
 Module A Q is for generating candidate solutions, whereas module A  X  is for verifying non-triviality. To extract A we start with QAP P 00 =  X  X  T , X  ( A ) , X  ( Q  X  ) ,  X  , X  ( X )  X  , and generate solution candidates to P 00 with a resolution-based procedure. Note that using ABox summary  X  ( A ) instead of A can largely reduce the number of input facts. In the pro-cess of generating solution candidates, we keep track of the facts in  X  ( A ) that are involved in the resolution. Finally, the corresponding facts in A are extracted to form the module A Q . Module A  X  is extracted analogously.

In the same resolution and solution generation processes, we can also extract modules for other components of the QAP. In particular, define Note that A Q , D Q ,  X  Q and  X  Q can be extracted in one go via the resolution of  X  ( Q  X  ), and A  X  and D  X  can be extracted via the resolution of  X  x.  X  ( x ).

Example 5 (Cont X  X  Example 4). There are four types in A : { A,C } for a , { D } for b , { C } for each c i ( 1  X  i  X  m ), and { E } for each d j ( 1  X  j  X  n ). Using a and b themselves as representatives, and c and d as representatives for c i d A B ( x ) } , D  X  =  X  ,  X  Q = { R } ,  X  Q = { a,b } .
The following theorem shows that the above modules are sufficient for query abduction.

Theorem 2. Let P =  X  X  , A , Q ,  X  ,  X   X  be a QAP in ELH  X  Then, E is a minimal solution in sol ( P ) iff the following con-ditions hold: 1. pred ( E )  X   X  Q and const ( E )  X   X  Q ; 2. D Q  X  X  Q  X  X  | = Q  X  ; 3. D  X   X  X   X   X  X  6| =  X  x.  X  ( x ) ; 4. E 6| = Q ; and 5. no E 0  X  X  exists satisfying conditions 1 X 4.

In Exampe 5, E = { R ( a,b ) } , which is the only ABox that satisfies the conditions in Theorem 2. E can be obtained via a SLD-proof of Q (the same as Q  X  ) w.r.t. D Q and A Q  X   X  where  X  Q is the set of all facts over  X  Q and  X  Q . Then, E is verified against non-triviality conditions D  X   X  X   X   X  X  6| =  X  x.  X  ( x ) and E 6| = Q , and is returned as a solution.
After preprocessing of the initial QAP, we obtain a data-log QAP of relatively small size. Our basic approach system-atically searches for solution candidates using a resolution-based procedure (with tabling to guarantee termination), verifies each candidate using a datalog engine, and keeps only the minimal solutions. Besides systematically enu-merating the resolution proofs, the search for solutions can largely benefit from advanced pruning methods. In particu-lar, when a solution E is computed, instead of discarding E and constructing a new resolution proof, a pruning method further exploits E to generate another candidate solution E When E 0 is verified to be a solution, the resolution proofs for E 0 and those for its supersets are pruned. Various heuris-tics can be applied in pruning. In [9], a pruning strategy that exploits the subsets E 0 of E is proposed, which allows the minimality of a solution to be checked immediately af-ter its generation. Although such a pruning strategy for query abduction may require a larger number of verifica-tions than the basic approach, such verifications are often less expensive than resolution. Given that the candidates E obtained from E are close enough to valid solutions and can be enumerated efficiently, a search with pruning can largely outperform a basic one.

Once a minimal solution E is computed, we propose a new pruning strategy for solution search that exploits E and the hierarchical knowledge from the TBox. A hierarchical axiom in ELH  X  is of the form A v B or R v S . Such hierarchical axioms often constitute a large portion of practical ontology axioms, and can cause computation difficulty in resolution. This is illustrated in the following example.

Example 6. Consider the BCQ Q = A 1 ( a 1 )  X  ...  X  A 1 ( a and the datalog program D = { A i +1 ( x )  X  A i ( x ) | 1  X  i  X  n } . Let A =  X  ,  X  = { A 1 ,...,A n } , and  X  = { a 1 ,...,a The QAP P =  X  X  , A ,Q,  X  ,  X   X  has n m minimal solutions of the form { A j 1 ( a 1 ) ,...,A j m ( a m ) | 1  X  j 1 ,...,j
Constructing a resolution proof for each of the minimal so-lution is a tedious job and involves a large amount of repeti-tion. However, from one minimal solution { ...,A j ( a i it is convenient to directly construct another minimal solu-tion { ...,A j +1 ( a i ) ,... } using hierarchical rule A A ( x ) .

Based on this observation, we propose the following prun-ing technique that makes use of the hierarchical knowledge on concept names and role names in the TBox. Consider the QAP P 0 =  X  X  T , A , Q  X  ,  X  ,  X   X  and the modules of its com-ponents D Q , A Q ,  X  Q , and  X  Q . For a solution E  X  sol ( P ), a weakening of E is obtained by replacing some A ( a )  X  E with B ( a ) such that B  X   X  Q and T | = A v B , or by re-placing some R ( a,b )  X  E with S ( a,b ) such that S  X   X  and T | = R v S ; a strengthening of E is obtained by re-placing some A ( a )  X  E with B ( a ) such that B  X   X  Q and T | = B v A , or by replacing some R ( a,b )  X  E with S ( a,b ) such that S  X   X  Q and T | = S v R . E  X  and E  X  denote a weakening and a strengthening of E , respectively.
 Proposition 2. Let P =  X  X  , A , Q ,  X  ,  X   X  be a QAP in ELH  X  . For a solution E  X  sol ( P ) , the following conditions hold: Note that in the second condition, the minimality of E  X  not guaranteed by the second half of the condition. For ex-ample, let Q = D ( a ), D Q = { B ( x )  X  A ( x ) ,A ( x )  X  C ( x )  X  D ( x ) ,B ( x )  X  D ( x ) } ,  X  Q = { A,B,C } ,  X  Q = { a } , and D and A Q  X  X   X  are both empty. Then, a minimal solution is but not minimal.

Once a solution E is computed, our pruning method checks the minimality of E as in [9]. If E is minimal, the method enumerates and verifies whether each E  X  and each E  X  minimal solution. E  X  and E  X  are enumerated using the con-cept and role hierarchies pre-computed from T using an OWL reasoner. Verifications of E  X  and E  X  are performed efficiently using a datalog engine.
Based on the approach proposed in Section 4, we have implemented a prototype system called ABEL (ABduction for EL). Our experiments show that ABEL is efficient and can be used to compute minimal explanations for large on-tologies and data sets in ELH  X  .

ABEL is implemented in Java. In our system, the KARMA system [26] is used for ontology transformation, Prolog en-gine XSB 3.4 [25] is used for generating solution candidates, and OWL reasoner Pellet 3 as well as datalog engine RDFox is used for verifying solution candidates. We have evaluated our system on three suites of ontology benchmarks and un-der different settings. All the experiments were performed on a PC with an Intel Xenon 2.8 GHz processor and 16 GB RAM. The system and testing data are available at http://www.ict.griffith.edu.au/~kewen/AbductionEL/ .
In our experiments, we have employed ontologies that are widely used for benchmarking ontology-based CQ answering and for abduction [19, 26, 9]. The ontologies, corresponding data sets and queries are described as follows. To gener-ate observations, we instantiated each query by substituting clarkparsia.com/pellet www.cs.ox.ac.uk/isg/tools/RDFox their query variables with randomly chosen constants from the corresponding data set and verified that each instantia-tion indeed formed a negative answer to the query.
 VICODI : The VICODI ontology 5 describes European his-tory and contains no genuine existential rules. This bench-mark has a moderate-sized data set, has been widely used for evaluating atomic queries, and hence is useful for comparing our system with DuQAP, a system developed by Du et al. [9], since it allows only atomic queries. We generated 40 atomic queries for this benchmark with a random set of atomic con-cepts and roles.
 SEMINTEC : The SEMINTEC ontology 6 for modelling fi-nancial processes contains genuine existential rules and is coupled with a moderate-sized data set. We used it in com-paring our system with DuQAP, and we generated 40 atomic queries for this benchmark as above.
 LSTW : The LSTW ontology [19] extends the Lehigh Uni-versity benchmark LUBM [13] with many genuine existential rules. Corresponding data sets can be automatically gener-ated in a range of sizes using EUGen [19]. LSTW( n ) denotes the variant with a data set of n universities. Besides using this benchmark for comparison, with 40 atomic queries gen-erated as above, we also used it in the scalability evaluation, with 120 CQs generated using the query generator SyGENiA [16] 7 .

Table 2 shows some statistics on the aforementioned on-tologies: the numbers of their concept names (#C), role names (#R), TBox axioms ( |T| ), genuine existential rules (#E), ABox facts ( |A| ), and individuals (#I).
 Ontology #C #R |T| #E |A| #I VICODI 194 10 214 0 116,181 32,238 SEMINTEC 60 16 207 8 65,244 17,945 LSTW( n ) 132 32 223 29  X  10 5 n  X  10 4 n We evaluated ABEL in three different configurations. ABEL-N is the naive version of ABEL without pruning nor module extraction, and was used for comparison with DuQAP. In order to have a fair comparison, database tech-niques were not employed in ABEL-N. Also, Pellet was used instead of a datalog engine for reasoning tasks such as solu-tion verification.
 ABEL-P uses MySQL database system to store data and enables the pruning optimisation. Also, datalog engine RD-Fox was employed for solution verification. However, module extraction was disabled in order to study its effect on per-formance.
 ABEL-M is the optimised version of ABEL-P using the module extraction technique. It is tested in the scalability evaluation with large data sets.
In the first set of experiments, we compared our system with DuQAP. DuQAP accepts as input expressive ontolo-http://www.vicodi.org http://www.cs.put.poznan.pl/alawrynowicz/ semintec.htm
As SyGENiA failed to terminate in some cases on LSTW, we set a bound on the chase algorithm of SyGENiA to gen-erate CQs with up to three atoms. gies in SHIOQ but only allows observations formulated in atomic queries. For each of our testing ontologies, we gen-erated 40 observations by instantiating the corresponding 40 atomic queries. We included all concepts in the ontol-ogy as abducibles, and the domain includes all constants in the corresponding data set. Roles were not included in the abducibles, since DuQAP ran out of memory in those cases.
Table 3 shows the comparison results: the average num-bers of minimal solutions (# E , averaged over 40 observa-tions) 8 , and the average times (in seconds) for computing all the minimal solutions. DuQAP could not handle LSTW(10) or beyond due to running out of memory. It is worth not-ing that ABEL-N already outperformed DuQAP, and this superiority is largely enhanced with other optimisations like pruning (with the time reduced by at least 90%).

To evaluate the scalability of our system with observations formulated in general CQs that can interact with genuine existential rules in a complex manner, we evaluated ABEL-P and ABEL-M with the 120 generated CQs, a large portion of which are general CQs. One observation is generated for each query. Since LSTW contains no disjointness axiom, to enforce non-triviality checks, we added 5 disjointness axioms to the LSTW ontology. We increased the scope of abducibles so that all the concepts and all the roles in the ontology are included, and each domain is of size 5 (with constants in the observation plus possibly some from the data set). We set a 10 minutes X  time bound for each QAP instance, and a QAP instance is considered to be successfully processed only if all its minimal solutions are computed in the time bound.
ABEL-P was able to handle all the 120 observations for moderate-sized LSTW(1), and the average computation time was 19.2 seconds. Table 4 shows the results for large-sized LSTW(10), LSTW(50) and LSTW(100): the number of ob-servations successfully processed (#), the times for comput-ing all the minimal solutions and for extracting modules ( t and t m , in seconds, both averaged over the successfully pro-cessed observations), and the sizes of modules divided by the sizes of the initial data set A ( |A Q | and |A  X  | , in percentage, both averaged over the successfully processed observations).
ABEL-P was able to successfully process most of the ob-servations (105, that is 88%) for LSTW(10), and nearly half of them (55, that is 46%) for each of LSTW(50) and LSTW(100). ABEL-M could handle all the observations successfully processed by ABEL-P, and the advantage of ABEL-M (in particular, the module extraction optimisa-tion) becomes more obvious when the data sets get larger. In
The numbers were the same for both ABEL(-N and -P) and DuQAP. Table 4: Scalability evaluation on generated queries.
LSTW ABEL-P ABEL-M (n) # t c # t c t m |A Q | |A  X  | 10 105 39.2 106 25.6 15.4 3.4% 10.7% 50 55 23.6 83 41.1 26.2 3.7% 8.5% 100 55 43.7 82 31.5 31.4 0.3% 1.8% particular, for LSTW(50) and LSTW(100), ABEL-M could process 28 and 27 observations respectively, on which ABEL-P failed. Moreover, for all the observations over LSTW(50), ABEL-M could compute at least some minimal solutions, and failed to output any solutions for only two observations in the case of LSTW(100). These two difficult observations are both associated with recursive rules in the ontology.
Figure 1 shows the reasoning times and the numbers of so-lutions computed by ABEL-P and ABEL-M, on 20 selected observations over LSTW(50). These 20 observations are the most challenging ones among those successfully processed by both ABEL-P and ABEL-M. The column chart shows the computation and module extraction times of ABEL-P and ABEL-M (the left vertical axis, in seconds). The line chart shows the total numbers of minimal solutions (the right ver-tical axis, in logarithm scale).

Figure 1 demonstrates the efficiency gain as well as the overhead for module extraction in ABEL-M (compared to ABEL-P). On the observations that could be easily pro-cessed by ABEL-P, the efficiency gain from module extrac-tion was often not significant enough to override its over-head. The efficient gain was significant however, on obser-vations that were hard for ABEL-P, such as Q14, Q17, Q45, and Q47, where the computation times were reduced by half because of module extraction. On hard observations where ABEL-P failed to process, the advantage of module extrac-tion became very significant, as shown in Table 4. Hence, in general, for query explanation over large data sets, it would be a good strategy to first attempt to generate explanations with ABEL-P, and to employ module extraction (ABEL-M) only when ABEL-P fails in the time bound.
We have developed a scalable and complete system for query abduction w.r.t. observations formulated in BCQs and background ontologies in ELH  X  . Our approach involves transforming an ELH  X  ontologies to a datalog program and rewriting the observation. While the ontology transforma-tions and rewriting techniques have been intensively studied for query answering, our work initiates to adapt such tech-niques from standard query answering to query abduction. Indeed, by adapting these techniques, we provide, to the best of our knowledge, the first sound and complete algo-rithm for query abduction that supports both general CQs and ontologies with genuine existential rules. Moreover, we introduced a novel method for module extraction in query abduction, by applying data summarisation techniques, and we developed a pruning strategy that largely enhances the efficiency of solution generation. Finally, the potential of using our algorithm to handle practical ontologies and large data sets in practice is corroborated through our evaluation.
Interesting future work includes, firstly, extending the cur-rent approach to other ontology languages, including Horn DLs and existential rules. The approach in [18] can be a starting point. For more expressive Horn DLs and exis-tential rules, an interesting research problem is to decide which fragments or which ontologies/queries are combined rewritable , that is, an ontology transformation and an obser-vation rewriting exist that are sound and complete for query abduction. The study on combined rewritability of existen-tial rules regarding query answering in presented in [12], and would shed light on this research direction. Moreover, although the observation rewriting explores the structures of the CQs to some extent, we believe a more fine-grained analysis of query structures and possibly specific structures of some ontology axioms will allow us to apply advanced heuristics in solution construction. This work was partially supported by Australian Research Council (ARC) under grants DP110101042 and DP130102302. Jianfeng Du is partially supported by NSFC (61375056) and Guangdong Natural Science Foundation (S2013010012928). [1] F. Baader, S. Brandt, and C. Lutz. Pushing the EL [2] J.-F. Baget, M. Lecl`ere, M.-L. Mugnier, and E. Salvat. [3] A. Borgida, D. Calvanese, and M. Rodriguez-Muro. [4] A. Borgida, E. Franconi, I. Horrocks, D. L.
 [5] A. Cal` X , G. Gottlob, T. Lukasiewicz, and A. Pieris. [6] D. Calvanese, M. Ortiz, M.  X  Simkus, and G. Stefanoni. [7] J. Dolby, A. Fokoue, A. Kalyanpur, E. Schonberg, and [8] J. Du and Y.-D. S. Kewen Wang. Tractable approach [9] J. Du, G. Qi, Y. Shen, and J. Z. Pan. Towards [10] J. Du, S. Wang, G. Qi, J. Z. Pan, and Y. Hu. A new [11] B. Glimm, Y. Kazakov, T. Liebig, T. Tran, and [12] G. Gottlob, M. Manna, and A. Pieris. Polynomial [13] Y. Guo, Z. Pan, and J. Heflin. LUBM: A benchmark [14] K. Halland and K. Britz. ABox abduction in ALC [15] M. Horridge, B. Parsia, and U. Sattler. Laconic and [16] M. Imprialou, G. Stoilos, and B. C. Grau.
 [17] S. Klarman, U. Endriss, and S. Schlobach. ABox [18] R. Kontchakov, C. Lutz, D. Toman, F. Wolter, and [19] C. Lutz, n. Seylan, D. Toman, and F. Wolter. The [20] C. Lutz, D. Toman, and F. Wolter. Conjunctive query [21] Y. Ma, T. Gu, B. Xu, and L. Chang. An ABox [22] D. L. McGuinness and A. T. Borgida. Explaining [23] D. L. McGuinness and P. F. Patel-Schneider. Usability [24] R. Pe  X naloza and B. Sertkaya. Complexity of axiom [25] P. Rao, K. Sagonas, T. Swift, D. Warren, and [26] G. Stefanoni, B. Motik, and I. Horrocks. Introducing [27] Y. Zhou, Y. Nenov, B. C. Grau, and I. Horrocks.
