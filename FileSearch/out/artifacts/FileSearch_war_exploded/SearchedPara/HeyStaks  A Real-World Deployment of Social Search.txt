 The purpose of this paper is to provide a deployment update for the HeyStaks social search system which uses recommen-dation techniques to add collaboration to mainstream search engines such as Google, Bing, and Yahoo. We describe our the results of initial deployments, including an assessment of the quality of HeyStaks X  recommendations, and highlight some lessons learned in the marketplace.
 H.3.3 [ Information Search and Retrieval ]: Information Filtering; H.3.5 [ Online Information Services ]: Web-Based Services social search, recommender systems, deployed application
Recently researchers have begun to recognise the poten-tial of web search as a platform for a more social and col-laborative approach to information discovery. For example, researchers in the area of collaborative information retrieval have sought to make web search more collaborative and more social in a variety of ways; see for example [1 X 3]. The driv-ing insight is that search is an inherently collaborative af-fair as people frequently search for similar things in similar ways [6, 8, 10, 12]. By embracing collaboration mainstream search deliver improved result relevance especially in the face of ongoing challenges by co called content farms and increas-ingly aggress SEO (search engine optimization) strategies 1 . For instance, novice searchers have much to gain from the search experiences of more expert searchers. But such ex-periences and recommendations need to be integrated into mainstream search contexts. http://searchengineland.com/google-forecloses-on-content-farms-with-farmer-algorithm-update-66071 results page.
 Google and HeyStaks for All and Top n conditions. where with free wifi, might search for  X  X histler accommoda-tion free wifi X  and benefit from relevant specific results that were found by her friends.

Early versions of HeyStaks delivered social search via a browser plugin, to integrate directly with mainstream search engines at the interface level; examples of this can be seen in [9]. More recently HeyStaks has been deployed through a range of mobile and tablet apps for iOS and Android re-quiring a different approach to search engine integration via search engine APIs. In the remainder of this section we will provide some examples from the iPad HeyStaks app and summarise the system architecture and basic recommenda-tion components.
Figures 1(a-d) show screenshots from the iPad app. Our user starts with a query for  X  X ard rock X  ; see Figure 1(a). The default results from Google tend towards music and casinos; see Figure 1(b). In this instance our searcher is interested in mountain biking; there is one recent example of this type of result recommended from their personal  X  X y Searches X  stak but in addition HeyStaks recommends two staks as possi-ble sources of additional results, one is a  X  X ountain Bik-ing X  stak and the other a  X  X usic X  stak; these are presented above the main search results in Figure 1(b). By taping on either of these stak communities the user can join them and benefit from more topically focused recommendations. In this case, the user opts to join the  X  X ountain Biking X  stak and instantly receives a new set of recommendations, this time from the relevant search histories of the most reputable members of this particular stak. The recommendations are inserted at the top of the results list as in Figure 1(c). Fi-nally, the user selects one of the results and views it within the app from where they can chose to tag or share it with their contacts or social networks; see Figure 1(d).
The HeyStaks system architecture is shown in Figure 2, highlighting two important elements: the client-side apps (browser, mobile, tablet) and the backend HeyStaks server. The client apps provides direct access to key HeyStaks func-tionality and recommendations and integrate directly with mainstream search engines. The HeyStaks server manages the individual staks (indexing individual pages against query or tag terms and positive or negative votes), the stak database (stak titles, members, descriptions, status, etc.) and the core recommendation and reputation engines.

The recommendation engine at the heart of HeyStaks uses a combination of content-based and social recommendation strategies to identify and rank pages for recommendation to the searcher, based on their target query and stak mem-bership. Its ranking component uses a relevance score to prioritise pages that are similar to the target query and that were frequently selected by stak members for similar search contexts. In addition, this relevance score is combined with the reputation of the stak members who originally sourced the page in question. This reputation score is based on a collaboration model in which reputation propagates between users when results which originated from one user are recom-mended and selected by another. For the interested reader, these relevance [9] and reputation [4] components have been described and evaluated elsewhere. the CTR for the n HeyStaks recommendations in a session and compare this to the CTR for the top n Google results; we call this the Top n condition.

The results shown in Figure 3(b) are clearly very posi-tive. In each condition we can see that HeyStaks enjoys a significantly higher CTR than Google. The difference is particularly striking for the Top n Results condition. In this case, HeyStaks enjoys a CTR of more than 80% compared to Google X  X  22% CTR on a like-for-like basis. This means that HeyStaks results attract selections almost 4 times as frequently as Google, which is surely s strong indicator that HeyStaks X  more targeted, social recommendations are prov-ing to be more relevant that the one-size-fits-all organic re-sults from leading mainstream search engines.
Finally, we would like to briefly outline some of the lessons that have been learned as a result of our deployment expe-riences over the past 12 months. Many are not unique to the deployment of recommendation apps but we hope that they will nonetheless help others to learn from some of the challenges that we have faced.

Most recommender systems are subject to the cold-start problem and the challenge of making recommendations to users from the start. For HeyStaks this was a consider-able challenge since the absence of a critical mass of users and stak content limited recommendations. To partially ad-dress this issue we added a number of high-level recommen-dation triggers or filters to staks, basically URL patterns that would trigger the promotion of certain types of organic Google or Bing results. For example, a Gadgets &amp; Technol-ogy might include filters for techcrunch.com, theverge.com, or mashable.com to ensure these results would be promoted when returned by Google or Bing. This provided an op-portunity to kick-start recommendations for new users by including reliable filters in newly created staks.

Another important lesson concerned the need to reduce app complexity. The HeyStaks browser apps contain a wide variety of functions, including allowing users to create and maintain their own staks. The motivation here was obvi-ously to use this as an opportunity to crowd-source the early staks and their content. However, this functionality was rarely used and so increased app complexity. The mo-bile and tablet apps provided a more streamlined service, removing stak creation features, and instead prioritising the recommendation of pre-existing staks for users to join at search time. As well as simplifying the user experience this also helped ensure that new users were recommended high-quality staks on topics that mattered to them.

This simplification limits the opportunity to crowd-source new staks which in turn motivates the development of a semi-automatic stak creation workflow for use in-house. The precise details of this are beyond the scope of this short pa-per but briefly, by harvesting and clustering trending terms from public search and social network sources it is possible to produce a comprehensive list of stak topics. These topics and their associated seed terms are expanded to produce a comprehensive set of popular queries. And by submitting these queries to a range of search resources (Google, Bing, YouTube, Delicious, etc.) we obtain a large collection of candidate pages. We developed a rating tool to evaluate the quality of these pages, seeding new staks with those pages that passed the ratings test, and extracting recurring filter
