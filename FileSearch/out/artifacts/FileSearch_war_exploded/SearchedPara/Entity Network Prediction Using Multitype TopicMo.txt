 The primary purpose of the documents that report factual events, such as news articles, is to convey information on who , what , when and where . For this kind of documents, statistical entity-topic models [8] were p roposed to capture dependencies between who / where (i.e. named entities such as persons, organizations, or locations) and what (i.e. topics) mentioned in each article. In spite of the fact that each entity type has different characteristics and so it has different distribution, these models represented all types of entities as a single class. This paper attempts to directly capture dependencies be-tween multiple types of entities, such as who-entities (i.e. persons, organizations, or facilities), and general words.

In this paper, we review a series of graphical models that extended a statistical topic model called Latent Dirichlet Allocation (LDA) [4] to explicitly model entities men-tioned in text. As in [8] we take advantage of recent developments in named entity recognition to identify entities mentioned in articles. We then develop a multitype topic model that can explicitly capture dependencies between an arbitrary number of word types, such as who-entity type, where-entity type and general word type. We demon-strate that our model can predict who-entities more effectively, comparing with two other different topic models. We also exhibit that links between entities can be effec-tively predicted using our model. Statistical topic models (e.g., [7,4,11,6,10]) are based on the idea that documents are mixtures of topics, where a topic is a probability distribution over words. Blei et al. [4] proposed one of the topic models called Latent Dirichlet Allocation (LDA), introducing a Dirichlet prior on multinomial distribu tion over topics for each document. To estimate the LDA model, they used Variational Bayesian method. Instead of using the Variational Bayesian method, Griffiths et al. [6] applied the Gibbs sampling method to estimate the LDA model.

More recently, Newman et al. [8] proposed several statistical entity-topic models, extending the LDA model. Those models attempted to capture dependencies between entities and topics, where the entities are mentioned in text; however, the models did not those models are hardly sufficient to represent an event that consists of multiple types of entities. On the other hand, our goal is to model the events that are mentioned in text. As a step towards this goal, this paper develops a multitype topic model by extending the models mentioned above to represent dependencies between an arbitrary number of word types, such as who-entity type, where-entity type and general word type. To estimate our model, we use the Gibbs sampling method, following [6]. In this section we describe three graphical models. We start with LDA, followed by SwitchLDA and GESwitchLDA. The LDA is a popular model that can automatically infer a set of topics from a collection of documents [4]. The SwitchLDA was modeled by extending the LDA to capture dependencies between entities and topics, and its prediction performance was shown to be stable over different corpora [8]. The third model, GESwitchLDA is our model that aims to better fit multi-class textual data, such as of who-entities, where-entities and general words, by generalizing the SwitchLDA model. We use the LDA [4] as a baseline model for comparing with our GESwitchLDA in the experiments in Section 4. We also use the SwitchLDA as another baseline model. Here we introduce the notation used in graphical models, generative processes and Gibbs sampling equations in the rest of this paper: D is the number of documents, T is the number of topics, N d is the total number of words in document d ,  X  and  X  are Dirichlet prior hyper-parameters,  X  is a Beta or Dirichlet prior hyper-parameter,  X  is the topic-document distribution,  X  is the word-topic distribution, z i is a topic, and w i is a word or entity. In the case of the SwitchLDA, a tilde mark is used to denote the entity version of a variable. In the case of the GESwitchLDA, a tilde mark and a hat mark are used to denote the who-entity version and where-entity version, respectively. 3.1 LDA To explain the differences between the three graphical models, let us start with the LDA model shown in Fig.1. The LDA X  X  generative process is: 1. For all d documents sample  X  d  X  Dirichlet (  X  ) 2. For all t topics sample  X  t  X  Dirichlet (  X  ) 3. For each of the N d words w i in document d : Some estimation algorithms were applied to the LDA [4,6]. Following [6], we use the Gibbs sampling to estimate the LDA model. Note that the LDA does not distinguish specific types of words, and so this distinction was made at post-processing stage (i.e. outside of the model) when we made predictions about who-entities in Section 4. 3.2 SwitchLDA SwitchLDA model shown in Fig.2 was introduced in [8], extending the LDA model. In this model, an additional Binomial distribution  X  (withaBetapriorof  X  )wasin-corporated to control the fraction of entities in topics. The generative process of the SwitchLDA is: 1. For all d documents sample  X  d  X  Dirichlet (  X  ) 3. For each of the N d words w i in document d : The estimation algorithm for the SwitchLDA followed the Gibbs sampling approach, as described in [8]. Note that the SwitchLDA does not distinguish more specific types of entities, and so this distinction was made at post-processing stage (i.e. outside of the model) when we made predictions about who-entities in Section 4. 3.3 GESwitchLDA In our GESwitchLDA model shown in Fig.3, we generalize the SwitchLDA to han-dle an arbitrary number ( M ) of word types. Therefore, we redefine  X  as Multinomial distribution with the Dirichlet prior  X  . The generative process of the GESwitchLDA is: 1. For all d documents sample  X  d  X  Dirichlet (  X  ) 2. For all t topics: 3. For each of the N d words w i in document d : We use the Gibbs sampling approach to estimate the GESwitchLDA model using the equations in Appendix.

In the experiments in Section 4, we divided entities into two classes, who-entity and where-entity, and thus the number of word types M =3 in this case. The GESwitchLDA X  X  generative process when M =3 is: 1. For all d documents sample  X  d  X  Dirichlet (  X  ) 3. For each of the N d words w i in document d : 4.1 Data Sets We used the TDT2 and TDT3 collections [1] that were tagged by the BBN Identi-finder [3] for our experiments. They originally contained a mix of broadcast news and newswire stories. We used for the experiments only the English stories in these collec-tions, but not the stories in other languages or the metadata such as pre-defined topics or categories. We used the TDT2 for training and the TDT3 for testing. Statistics for the data sets are summarized in Table 1. We removed the 418 stopwords included in the stop list used in InQuery system [5], and also removed words and entities that occurred in less than 10 documents.
 4.2 Who-Entity Prediction Estimation. For who-entity prediction task, the three models: the LDA, the SwitchLDA and the GESwitchLDA are first trained on words, who-entities, and where-entities. The models then make predictions about who-en tities using just word s or both words and where-entities. We need to set hyper-parameters for the LDA [4,6], as well as for the SwitchLDA, and the GESwitchLDA. For all of the experiments, we set the number of topics T = 100 , 200 ,and 300 for each of the three models. We fixed Dirichlet priors  X  =50 /T and  X  =0 . 01 , which were reported to be appropriate for various collec-tions [10]. The other hyper-parameters were empirically determined using the training data, as described in the rest of this section.
 Prediction. We evaluated all three models on a specific who-entity prediction task. For this task, the models were first trained on words, who-entities, and where-entities using the TDT2. The model then makes predicti ons about who-en tities over the TDT3 in the following two ways: 1. using words and where-entities(w+e). 2. using only words(w). The likelihood of an entity in each test document is calculated by p ( e | d )=  X  test document p ( t | d ) is estimated by resampling both all words and all where-entities (or by resampling only all words) using learned word distribution p ( w | t ) and where-entity distribution p ( o | t ) . We estimated p ( t | d ) using Gibbs sampling.
We illustrate the process of the who-entity prediction in Table 2 using an example from the TDT data. The first row shows an excerpt from an article of TDT3, with who-entities indicated by XXXXX. Middle row shows the list of actual who-entities. The bottom row shows the predicted who-entity lis t ordered by likelihood computed using both words and where-entities (or using only words). Some examples of the topics captured by GESwitchLDA are shown in Fig. 4.
 Evaluation Metrics. Using the model parameters es timated in training, the models computed the likelihood of every possibl e entity, and then listed the who-entities in order of the likelihood. We computed MAP (mean average precision) [2], and GMAP (geometric mean average precision) [9], as well as average best rank and average me-dian rank. The average best rank is defined as the average of the best rank of relevant who-entities, and the average median rank is the average rank of who-entities at median of relevant who-entity ranked list.
 Results. The best results for LDA, SwitchLDA and GESwitchLDA are shown in Ta-ble 3. To obtain the best results, we determined through experiments that T = 300 was the best parameter for all three models, except the case of the LDA using only words. We determined that T = 200 was the best parameter for the LDA using only words. We determined the best parameters  X   X  =  X   X  =0 . 01 for both the SwitchLDA and the GESwitchLDA,  X  =5 . 0 for the SwitchLDA, and  X  =4 . 0 for the GESwitchLDA.
Given the best parameters in our expe riments, our GESwitchLDA model gave the best results, in terms of both MAP and GMAP, over the other two models in the GESwitchLDA gave 2.5% improvement in this case 1 , comparing with the best results of the LDA model under the same condition. We further performed the Wilcoxon signed-rank test (two-tailed) to the pair of GESwitchLDA -LDA and the pair of GESwitchLDA -SwitchLDA. In terms of MAP, the resulting p -values of these pairs were less than 0 . 01 in the case of using both words and where-entities. It means the the performance improvement of the GESwitchLDA over both the SwitchLDA and the LDA was sta-tistically significant, in this case. As for the case of using only words, the improve-ment of the GESwitchLDA over the LDA was also statistically significant at 0 . 01 level; however, that over the SwitchLDA was not. In terms of average best rank and average median rank, we observed that few very bad results made performance values unfairly poor. In contrast, MAP was observed to be more stable in this sense.
 We also calculated likelihood of who-entitie s in the manner of not using resampling. p ( w | d ) . In this manner we can predict who-entities incrementally for a given document. The results using the GESwitchLDA are shown in Table 4. The results show that the model can predict who-entities even for incoming streams of documents, keeping fairly good prediction performance. Furthermore, we also applied some heuristics for name identification at pre-processing stage, such as, when only the first name of a person appears in a document, replacing it with his/her full name found by searching backward in the document. The results of the GESwitchLDA are shown in Table 5, where the performance was improved by applying the name identification processing. 4.3 Entity Link Prediction We further carried out experiments on who-entity link prediction. We computed affinity training in the same manner in the previous section. Following [8], we generated two ing document but were seen in test documents; and (2) false pairs that contain pairs that were never seen in any training or test document. The number of true pairs N t and false pairs N f were 104,721 and 98,977, respectively. The results can be seen in Table 6. We used a couple of evaluation metrics: mean average precision (MAP) and accuracy at top-ranked N t predicted result. Our GESwitchLDA modestly outperformed the other two models: the LDA and the SwitchLDA, in terms of both MAP and accuracy. The maximum improvement was 3 . 2% in the case of MAP. Some examples of predicted who-entity networks are shown in Fig. 5, where each vertex represents an entity and each edge length represents strength of affinity between a pair of entities at the incident vertices. Although the networks of who-en tities were discussed above, more specific social networks (e.g. person-entity networks) or where-entity networks can also be pre-dicted in the same manner. We developed a graphical model GESwitchLDA, generalizing for an arbitrary number of word types such as words, who -entities (i.e. persons, organizations, or nationalities) order to enable to capture dependencies between them. We compared this model with two other models on who -entity prediction task and entity link prediction task, using real data of news articles. We showed that the GESwitchLDA achieved significant im-provement over the previous models in terms of some measures that are well-accepted in information retrieval research area, by distinguishing multiple types of entities: in this case, who and where . Using our model, entity networks, such as social networks, can be effectively constructed from textual information.

This model can also be applied to other multiple types of words. For example, we can use this model to capture multiple types of entities in bio-medical articles, such as protein names, gene names and chemical compound names, even if more than two entity types are involved. In another direction of future work, we plan to extend the model to incorporate a temporal aspect of events.
 We thank Giridhar Kumaran, University of Massachusetts Amherst, for providing an-notation data. We also thank Atsuhiro Takasu, National Institute of Informatics, for valuable discussions. This work was supported in part by the Grant-in-Aid for Sci-entific Research on Priority Areas  X  X nfo-plosion X  (#19024055), Young Scientists A (#17680011) and Exploratory Research (#18650057) from the Ministry of Education, Culture, Sports, Science and Technology of Japan. Gibbs Sampling Equations for GESwitchLDA In the following equations.  X  and  X  are Dirichlet priors, and  X  is another Dirichlet prior.  X  y corresponds to Dirichlet prior for type-y words. The notation C PQ from respective count matrices, e.g. count of words in a topics, or counts of topic in a document.
