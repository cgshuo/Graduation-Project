 As more and more knowledge bases become available, the question of how end users to access this body of knowledge becomes of cru cial importance. As the de facto standard of a knowledge base, RDF (Resource Description Framework) repository is a collection of triples, denoted as subject, predicate, object . An RDF dataset can be represented as a graph, where subjects and objects are vertices connected by labeled edges (i.e., predicates). Fig. 1 shows an example RDF graph, which is a part of a well-known knowledge base Yago [11]. The numbers besides the vertices are IDs.

SPARQL query language is a standard way to access RDF data and is based on the subgraph (homomorphism) match semantic [9]. More specifically, SPARQL can be rep-resented by a query graph Q . Answering SPARQLs equals to finding subgraph matches of query graph Q over RDF graph G . Hence, the query intension should be modeled as a query graph Q to enable SPARQL query processing. In contrast, keyword search pro-vides an intuitive way of specifying fuzzy information needs. Generally speaking, most existing keyword search techniques over RDF graphs take the following assumption: A small-size substructure containing all keywords is an informative result .
In fact, we observe in some real applications, the user X  X  query intent cannot be well modeled using one query type. To better illustrate this, consider the following example. Example 1. Which actors / actresses played in Philadelphia are mostly related to Academy Award and Golden Globe Award in Yago?
In this example,  X  X ctors / actresses played in Philadelphia X  is a precise query require-ment. It is easy to write down a SPARQL statement. However, the possible relationship between actors / actresses with Academy Award and Golden Globe Award is arbitrary. We cannot use SPARQL to represent the query intension. Thus, we resort to keyword search to discover potential relationships.

Motivated by the above example, we propose a hybrid query that integrates S PA R Q L and k eyword (called an SK query) over large RDF graphs. The whole query require-ment includes two parts. The first is  X  X ctors / actresses played in Philadelphia X  which is a precise query criterion and we represent it as a SPARQL query 1 . The second part is  X  X elated to the Academy Award and Golden Globe Award X , which is a fuzzy query requirement. Thus, it is better modeled as a  X  X eyword search X  to discover possible re-lationships between an actor and an award.  X  X hortest path distance X  is a widely used measure to evaluate the relationship strength [15]. The shorter the path between entities is, the stronger their relationship is.

Let us recall Example 1 again. We issue the SK query Q , q as in Fig. 2(a). Fig. 2(b) shows three di ff erent results. First, there are three di ff erent subgraph matches of query 001, 015 and 026. The distance between a subgraph match M and a keyword in q is the shortest distance between M and one vertex containing keywords. We find that M 1 is the closest to the two keywords. It says  X  X oanne Woodward starring in Philadelphia film won both Academy Award and Golden Globe Award X . Obviously, this is an informative answer to the query in Example 1.

In summary, we made the following contributions in this paper. 1. We propose a new query paradigm over RDF data combining keywords and 2. We design an index to speed up SK query processing. We propose a frequent star 3. We evaluate the e ff ectiveness and e ffi ciency of our method in real large RDF graphs The remainder of this paper is organized as follows: Section 2 defines the preliminary concepts. Section 3 gives an overview of our approach. We introduce a structural index to e ffi ciently find the candidates of variables in Section 4. We discuss how to compute the results of SK queries in Section 5. Experimental results are presented in Section 6. Related works and the final conclusion are drawn 8. In this section, we introduce the fundamental definitions used in this paper. An RDF dataset consists of a number of triples, which is corresponding to an RDF graph. An corresponding to all subjects and objects in RDF data; E ( G ) is the set of edges in G ; and L is a finite set of edge labels, i.e. predicates.
 The SK query is to find k SPARQL matches that are top-k closest to all keywords. Definition 1. An SK ( S PA R Q L &amp; K eyword) query is a pair Q , q ,whereQisa SPARQL query graph and q is a set of keywords { w 1 , w 2 ,..., w n } .

Given an SK query Q , q ,the result of Q , q in a G is a pair M , { v 1 , v 2 ,..., v n } , where M is a match of Q and v i (i = 1 ,..., n) is a literal vertex containing keyword w i .
Given an SK query Q , q , the cost of a result r = M , { v 1 , v 2 ,..., v n } contains two parts. The first part is the content cost and the second part is the structure cost. is the structure cost of r (defined in Definition 4).
 Definition 3. Given a result r = M , { v 1 , v 2 ,..., v n } ,the content cost of r = M , { v where C ( v i , w i ) is the matching cost between v i and keyword w i .

Any typographic or linguistic distances, such as google similarity distance [2], can be used to measure C ( v i , w i ).

For the structure cost, we use shortest path distance to measure the relevances be-tween SPARQL query matches and keywords in RDF graph G .
 between match M and vertex v i (i = 1 ,..., n) is defined as follows. where v is a vertex in M and d ( v , v i ) is the shortest path distance between v and v i in RDF graph G.
 Then, the structure cost of a result r = M , { v 1 , v 2 ,..., v n } is defined as follows. ( Problem Definition. ) Given an SK query Q , q and a parameter k, our problem is to find k results (Definition 1), which have the k-smallest costs. In this section, we give an overview of the di ff erent steps involved in our process of SK query, which is depicted in Fig. 3. In this paper, we are concerned with the challenge of e ffi ciently finding the results of SK queries. We propose an approach in which the best results of the SK query are computed using the graph exploration. We detail the di ff erent steps of the approach below.
 Keyword Mapping. In the o ffl ine phase, we create an inverted index storing a map from keywords to its locations in the RDF graph. In the online phase, we map keywords to vertices based on the inverted index. We call the vertices mapping keywords keyword vertices . In this paper, because our primary foc us is finding matches of SPARQL query and their relations to keywords, we use an existing IR engine to analyze given keywords, perform an imprecise matching, and return a list of graph elements having labels that are syntactically or semantically similar.
 Candidate Generation. When we find a vertex reachable to elements of all keywords, we need to run subgraph homomorphism to check whether there exist some matches (of Q ) containing v . As we know, subgraph homomorphism is not e ffi cient due to its high complexity [4]. Thus, we propose a filter-and-refine strategy to reduce the number of subgraph homomorphism operations. The basi c idea is to build a frequent star pattern-based structural index to filter out some vertices that are not in any subgraph match of Q . We call them  X  dummy  X  vertices and do not perform subgraph homomorphism algorithm for them. We will detail how to build the structural index in Section 4.1 and how to use the index to reduce the candidates of all variables in Section 4.2. Top-k Results Computation. Based on the keyword vertices and variables X  candidates, we propose a solution based on graph exploration to compute out the top-k results of SK queries. Our approach starts graph exploration from all keyword vertices, and explores to their neighboring vertices recursively until the distances between a vertex and keyword vertices have been computed out. The exploration terminates when the top-k results have been computed. We also propose some early stop strategies for top-k computation to reach early termination after obtaining the t op-k results, instead of searching the data graph for all results. We discuss the detai l of top-k results computation in Section 5. In this section, we first introduce a structural index based on a certain kind of patterns in Section 4.1. Then, we discuss how to generate the candidate lists of variables based on our structural index in Section 4.2. 4.1 Structural Index In this section, we propose a frequent star pattern-based index. We mine some fre-quent star patterns in G . For each frequent star S , we build an inverted list L ( S )that includes all vertices (in RDF graph G ) contained by at least one match of S . A reason for selecting stars as index elements is that SPARQL queries tend to contain star-shaped subqueries, for combining several attrib ute-like properties of the same entity [6].
We propose a sequential pattern mining-based method to find frequent star patterns in RDF graphs. For each entity vertex in an RDF graph, we sort all its adjacent edges in lexicographic order of edge labels (i.e. predicates). These sorted edges can form a sequence. For example, vertex  X  X hiladel phia(film) X  has five adjacent edges, that are actedIn , actedIn , actedIn , name , type . Then, we employ the existing sequential pat-where each sequential pattern corresponds to a star pattern in RDF graphs. For exam-ple, assume that the minimal support count s = 2, actedIn , type and actedIn , type , wonPrize are two frequent sequential patterns for the RDF graph in Fig. 1. It is easy to know that a sequential pattern always corresponds to one star pattern. For ease of pre-sentation, we use the terms  X  X equential patterns X  and  X  X tar patterns X  interchangeably in the following discussion.

For each frequent star pattern S , we maintain an inverted list L ( S ) = { v | S occurs in v  X  X  adjacent edge sequence } . Note that, to ensure the completeness of the indexing, we always choose the (absolute) support to be 1 for size-1 stars (star with only one edge). This method can guarantee no-false-negative, since all vertices (in G ) are indexed in at least one inverted list. Then, we can find out vertices that cannot be contained by any matches as discussed in the following theorem.
 Theorem 1. Given a SPARQL query Q, a vertex v in graph G can be pruned (there exists no subgraph match of Q containing v) if the following equation holds. where S  X  Q means that S is included in Q.
 Proof. Please refer to the full version [8] of our paper at arXiv. 4.2 Candidate Generation Given an SK query, we first tag the vertices that can be pruned by Theorem 1. For each variable in SPARQL, we locate its candidates in RDF graph. Each variable can map to a predicate sequence according to the SPAR QL statement. For example, variable  X ?a X  of the SPARQL query in Fig. 2(a) has the predicate sequence actedIn , type . Then, for each variable x , we look up our structural index and find the maximum pattern contained by x  X  X  predicate sequence. We load the v ertex list of the maximum pattern as x  X  X  candidates. A vertex in at least one vertex lists of variables is not dummy. We define these pruned vertices as dummy vertices as follows.
 Definition 5. Dummy Vertex. Given a SPARQL query Q, a vertex v in graph G is called as dummy vertex if the following equation holds. where S  X  Q is a star pattern included in Q.

When the graph exploration meets a dummy vertex v during top-k results computa-tion, we do not need to perform subgraph isomorphism algorithm beginning with v . In this section, we introduce our approach for SK queries, which is based on the  X  X raph exploration X  strategy [12]. Our algorithm for searching top-k results of SK queries is shown in Algorithm 1. This algorithm consists of three parts: 1) graph exploration to find vertices connecting the keyword verti ces, 2) generation of SPARQL matches from the vertices connecting the keyword vertices and 3) top-k computation. In the following, we will elaborate on these three tasks.
 5.1 Graph Exploration The objective of the exploration is to find vertices in the graph that connect these key-word vertices and compute their distances to these keyword vertices. Let V i denote all literal vertices (in RDF graph G ) containing keyword w i .
 To explore the RDF graph, we maintain a priority queue PQ i for each keyword w i . avertexin V i to v and | p | denotes the path distance. All elements in PQ i are sorted in the non-descending order of | p | . Each keyword w i is also associated with a result set RS i . In order to keep track of info rmation related to each vertex v , we associate v with this case, we set d [ v ][ i ] = d ( v , w i ); otherwise, we set d [ v ][ i ] = null .
Initially, the exploration starts with a set of vertices containing keywords. For each vertex v containing keyword w i ,anelement( v ,  X  , 0) is created and placed into the queue PQ i (Line 3 in Algorithm 1). During the exploration, at each step, we pick a queue PQ i ( i = 1 ,..., n ) to expand in a round-robin manner (Line 5 in Algorithm 1). We assume that We can prove that the following theorem holds.
 Algorithm 1. Graph Exploration for Top-k Results of SK Queries Theorem 2. When a queue head ( v , p , | p | ) is popped from queue PQ i , the following equation holds. Proof. Please refer to the full version [8] of our paper at arXiv.

When a queue head ( v , p , | p | ) is popped from queue PQ i , the distance between v and keyword w i has been computed out. We also say that v is seen by keyword w i . Definition 6. Seen by Keyword . When a queue head ( v , p , | p | ) is popped from queue PQ i ,wesayvertexvis seen by keyword w i .

Assume that ( v , p , | p | ) is popped from queue PQ i . For each incident edge vv to v ,we obtain a new element ( v , p  X  vv , | p | + 1), where p  X  vv means appending an edge to p . Then, we check whether there exists another element ( v , p , | p | ) that has the identical ( v , p , | p | ) with ( v , p  X  vv , | p | + 1) in PQ element for v ,weinsert( v , p  X  vv , | p | + 1) into PQ i directly(Line 12 in Algorithm 1). Definition 7. Fully-seen Vertex, Partially-seen Vertex and Un-seen Vertex . Given a v is not a fully-seen vertex but it has been seen by at least one keyword, v is called a partially-seen vertex; if v is not seen by any keyword, v is called an un-seen vertex.
At each step, we check whether the vertex v just popped from the queue has been seen by all keywords. If all dimensions of v  X  X  vector d [ v ] are not null, it means that all keywords have seen vertex v , i.e., v is a fully-seen vertex.Whenwemeetafully-seen vertex v , we will employ a subgraph homomorphism algorithm to find matches containing v (Line 13-14 in Algorithm 1). 5.2 Generation of SPARQL Matches When we explore a fully-seen vertex v , it means that we have known the distance be-tween v and each keyword w i . The next step is to compute SPARQL matches containing vertex v if any. Here, we perform subgraph homomorphism algorithm to find matches (of query Q ) containing v . The matching process consists of determining a function f that associates vertices of Q with vertices of G . The matches are expressed as a set of pairs ( u , v )( u  X  Q and u  X  G ). A pair ( u , v ) represents the matching of a vertex u of query Q with a vertex v of RDF graph G . The set of vertex pairs ( u , v ) constitutes a SPARQL match.

A high-level description of finding matches from vertex v is outlined in Algorithm Assume that we introduce a new candidate vertex pair ( v , u ) into the current function f to form another function f . 5.3 Top-k Computation The native solution for computing top-k results of an SK query is to explore the graph until that all vertices (in RDF graph G ) are fully-seen vertices. Then, according to the
Algorithm 2. SPARQL Matching Algorithm especially when G is very large. In this subsection, we design an early-stop strategy.
Let us consider a snapshot of some iteration step in Algorithm 1. All subgraph matches of SPARQL query Q can be divided into three categories: fully-seen matches, partially-seen matches and un-seen matches.
 Definition 8. Fully-seen Match, Partially-seen Match and Un-seen Match. Given a match M of SPARQL query Q, if all vertices in M are fully-seen vertices, M is called a fully-seen match ; if M is not a fully-seen match and M contains at least one fully-seen vertex, it is called a partially-seen match ; otherwise, it is called an un-seen match .
The idea of our early-stop strategy is as follows. We can compute the cost of fully-seen matches according to Definition 4. Then, we use the fully-seen matches to find a threshold  X  , which is the k -th smallest cost so far. We also compute the lower bounds  X  1 and  X  2 for partially-seen matches and un-seen matches. The algorithm can early stop if  X &lt; X  Given a partially-seen match, we compute the lower bound of its cost as follows. Theorem 3. Given a partially-seen match M of SPARQL query Q, v is a partially-seen vertex or an un-seen vertex in the match. The following equation holds.
 where d [ v ][ w i ] is the i-th dimension of v X  X  vector corresponding to keyword w i , and | p | corresponds to the current queue head ( v , p Proof. Please refer to the full version [8] of our paper at arXiv.

According to Theorem 3, the lower bound  X  1 of all partially-seen matches can be defined as follows.
 Definition 9. Lower Bound  X  1 of Partially-seen Matches . The lower bound  X  1 of all partially-seen matches is as follows. where PS denotes all partially-seen matches.
On the other hand, let us consider the lower bound of an un-seen match M .Thereare two kinds of vertices in M , i.e., partially-seen vertices and un-seen vertices. Theorem 4. For an un-seen vertex v, if threshold  X   X  , the following equation holds. Proof. Please refer to the full version [8] of our paper at arXiv.

According to Theorem 4, it is not necessary to consider un-seen vertices to define the lower bound for un-seen matches. Therefore, we define the lower bound for all un-seen matches as follows.
 Definition 10. Lower Bound  X  2 of Un-seen Matches . The lower bound  X  2 for all un-seen matches is as follows. the v X  X  vector corresponding to keyword w i and | p i | corresponds to the current queue head ( v , p i , | p i | ) in queue PQ i .

With the increasing of the iteration steps, some partially-seen matches become fully-seen matches. Then, the threshold  X  ,  X  1 and  X  2 are updated accordingly. 6.1 Datasets and Setup We use two real-world RDF graphs Yago and DBPedia in our experiments. Here, all sample queries are shown in Appendix of the full version [8] at arXiv. Our experi-ments are conduct on a machine with 2 Ghz Core 2 Duo processor, 16G RAM memory and running Windows Server 2008. All experiments are implemented in Java. We use MySQL to store the indices. The details about the two datasets are as follows. Yago .Yago 2 extracts facts from Wikipedia and integrates them with the WordNet the-saurus. The RDF graph has 19 , 012 , 849 edges and 12 , 811 , 222 vertices. We define 8 sample SK queries for Yago.
 DBPedia and QALD .DBPedia 3 is an RDF dataset extracted from Wikipedia. The DB-Pedia contains 73 , 766 , 900 edges and 13 , 100 , 739 vertices. QALD 4 is an evaluation campaign on question answering over linked data. In this campaign, the committee pro-vides some questions. Each question is annotated with some recommended keywords and the answers that these queries retrieve. Note that, many questions in QALD are so simple to be split into a SPARQL query and some keywords. Thus, we only select 10 complex queries from QALD for evaluation. 6.2 E ff ectiveness Study In this section, we compare our method with a classical keyword search algorithm BANKS [1] over Yago and DBPedia to show the e ff ectiveness of our method. Fur-thermore, since each resource in DBPedia i s annotated by Wikipedia documents, we design a stronger baseline named as  X  X nnotated SPARQL X  for DBPedia, which first finds out all matches of the SPARQL query, then ranks these matches by how closely the corresponding Wikipedia documents match the keywords.
 NDCG@k over Yago. In order to quantify the e ff ectiveness of SK query, we evaluate the NDCG (Normalized Discounted Cumulative Gain [5]) of both SK query and the keyword search. Since there are no golden standards, we invite 10 volunteers to judge the result quality. Specifically, we ask each volunteer to rate the goodness of the results returned by SK query and the keyword search method. The score is between 1 and 5. Higher the score, better the result.

Table 1 reports NDCG@k values by varying k from 3 to 10 in Yago. SK query outperforms the traditional keyword search by 0%-50%. The reason is that Yago has a complex schema and keywords may result in lots of ambiguity in Yago. It means that the superiority of SK query is more pronounced in semantic-rich data.
 MAP over DBPedia. Since QALD provides the standard answers of each queries, we evaluate the MAP (Mean Average Precision [13]) to compare the SK query with BANKS and  X  X nnotated SPARQL X . Table 2 reports MAP values of our ten QALD queries.

Both SK query and annotated SPARQL outperforms the traditional keyword search by a order of magnitude. The MAP value of the  X  X nnotated SPARQL X  is smaller than the SK query. This is because that the  X  X nnot ated SPARQL X  can do well when the doc-uments associated with the matches contains the keywords. In other words, the  X  X nno-tated SPARQL X  can work, only when the relation between the matches and the keywords is explicit. However, in pracit ce, the relation betw een the matches and the keywords is often implicit. Then, the SK query do better. 6.3 E ffi ciency Study In this section, we evaluate the e ffi ciency of SK query in large real graphs. Here, the de-fault number of returned results is set to be 10. Because there is no existing method for SK queries, we evaluate our approach with two baselines, i.e., the exhaustive computing and the naive backward search for e ffi ciency study.  X  X xhaustive computing X  works as follows: we first find all subgraph matches of Q (in RDF graph G ) by existing tech-niques; then, we compute the shortest path distances between these subgraph matches and the vertices containing keywords on the fly; finally, the matches with shortest dis-tances to keywords are returned as answers. The naive backward search is to run the backward search algorithm un til that all vertices have been fully-seen by keywords. Then, according to the results X  c ost, we find the top-k results.
 O ffl ine Performance. We report the index size and index construction time in Table 3. Since our structural index is based on the e ffi cient sequential pattern mining, we can finish the structural index construction in several minutes.
 Online Performance. In this section, we evaluate the e ffi ciency of our method. Fig. 4 shows the time cost of the three methods. The performance of our method is always not worse than the comparative methods. Especially for Q 3 on Yago, our method only takes one fifth of the exhaustive-computing. This is because that th e matches of these SPARQLs are close to vertices containing keywords. Thus, the query processing can terminate soon.

Note that, because our inverted index for keywords are stored in disk, keyword map-ping processing costs much time and takes up a large part of the total time. Hence, it is di ffi cult for our method to improve the e ffi ciency by orders of magnitudes. To the best of our knowledge, although there exist a few previous works [3,14] for the hybrid query combined SPARQL and keyords, there has been no existing work on SK query defined as the above. Elbassuoni et al. [3] assumes that each RDF triple may have associated documents. Then, Elbassuoni et al. extend the triple patterns in SPARQL with keyword conditions. CE 2 [14] assumes that each resource associate with a document. Then, CE 2 extend the variables in SPARQL with keyword conditions. Nonetheless, many current RDF datasets do not provide documents to annotate triples or resources. Hence, these methods cannot handle our example queries.

In addition, [10] defines a new query language that blends keyword search with structured query processing. [16] translates natural language questions into SPARQL queries. In this paper, we first propose a new kind of query (SK query) that integrates SPARQL and keywords. To handle this kind of query, we build up a frequent star pattern-based index and propose a method based on graph exploration. With two real RDF graphs, we show that our method can outperform the baseline both in e ff ectiveness and e ffi ciency. Acknowledgments. This paper was supported in part by National High-tech R&amp;D Program (863 Program) under Grant 2015AA015402, National Science Foundation of China (NSFC) under Grant 61370055. This work was also supported by Tencent.
