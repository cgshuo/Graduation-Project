 Abebe Rorissa * 1. Introduction
Although images are visual information sources with little or no text associated with them, users of image collections tend to mainly use text to describe images (e.g., flickr , www.flickr .com, and other social tagging services) and formulate their queries. The vast majority of web search engines (e.g., Google Image Search) that allow image searches provide search inter-faces for text queries through keywords ( Tjondronegoro &amp; Spink, 2008 ). Keywords, subject headings, and text annotations are integral parts of both concept-based and content-based image indexing and retrieval systems, although some of the annotations by content-based image retrieval systems are achieved through automated means, albeit to a limited extent.
However, for now,  X  X  X uccessful retrieval is based largely on attaching appropriate annotations to each image and collection since automated image content analysis is still limited X  ( Shneiderman, Bederson, &amp; Drucker, 2006, p. 69 ). The good news is that users are investing more effort in annotating not only their own images but also those that belong to other users ( Shnei-derman et al., 2006 ).

There are apparent drawbacks to concept-based image retrieval, such as the cost (in terms of time, manpower, and money) of manual annotation and indexing of images ( Layne, 1994 ). Also, manual annotations are not always precise.
At the same time, content-based image retrieval systems have failed to bridge the semantic gap ( Datta, Li, &amp; Wang, 2005; Lew, Sebe, Djeraba, &amp; Jain, 2006; Neumann &amp; Gegenfurtner, 2006; Smeulders, Worring, Santini, Gupta, &amp; Jain, 2000 ). Words remain the predominant, if not the only means for describing the high level semantic attributes and content of images. This is perhaps partly because  X  X  X he natural way to describe images is through words and phrases X  ( Rafferty &amp;
Hidderley, 2005, p. 180 ). Therefore, at least in the foreseeable future, image indexing and retrieval systems will depend on text annotations, especially for image collections with social tagging and photo sharing services such as flickr where users add textual tags (descriptions) to images, both their own and others X . This makes the need to understand the nature of attributes and descriptions of individual and groups of images by users even more crucial, and works such as this more relevant and significant.

The astronomical increase in the number of images in digital libraries, both personal and institutional, coupled with in-creased reliance on text annotations for archiving (by users and institutions), indexing (by image retrieval systems), and searching, calls for a two pronged approach to organization, indexing, and visualization of images for retrieval and browsing purposes. One approach focuses on grouping of images for browsing and exploratory search and providing browsing inter-faces (through faceted, hierarchical, and other types of taxonomies). The second approach indexes both individual images and groups of images for directed search through formal queries using terms that represent image content or concepts peo-ple associate with that content. The bulk of image research focuses on the latter, indexing and retrieval of individual images, while there is minimal attention given to groupings of images except when there is talk about taxonomies and, recently, folksonomies. Among researchers who emphasize the two pronged approach are Hearst and her colleagues ( Hearst, 2006a, 2006b; Yee, Swearingen, Li, &amp; Hearst, 2003 ), Marchionini (2006), and Shneiderman et al. (2006). Hearst (2006a) emphasized the difficult task of labeling groups of images and, at the same time, recognized users X  desire for meaningful groupings of search results. In response to these needs and desires, they have designed, built, and evaluated appropriate im-age browsing and retrieval systems, some of which use hierarchical and facet based groupings. In order to inform the design of such systems and other systems for indexing and retrieval of image collections (the web, social tagging services, digital libraries, etc.), a continued investigation as to what types of attributes are described through tagging and descriptions of individual and groups of images is crucial. This will ensure that image retrieval system design is user-centered and that these systems would remain effective and efficient for the retrieval of individual images and browsing groupings of those images by human users.

Knowledge of the underlying structure of user-generated tags could also inform and lead to better design of professional indexing tools such as taxonomies and thesauri. In the past, calls have been made for new ways and means for image index-ing, constant evaluation and improvement of current image indexing tools and systems ( J X rgensen, 1998; Layne, 1994 ), and for user-centered indexing ( Fidel, 1994; Matusiak, 2006 ). Some of the reasons for not involving users in the indexing process fact, one of the limitations of concept-based image indexing and retrieval is cost of manual assignment of index terms ( Lay-ne, 1994 ). With social tagging becoming ever so widespread, these are now less of a limitation; at least as far as user-gen-erated image collections such as flickr are concerned. However, an understanding of the nature of social tagging and the tags themselves is paramount at this early stage of social tagging in order to incorporate the users X  language into indexing tools and systems. This can only be achieved through empirical research that investigates the nature of image attributes, including user-generated descriptions of both individual images and groups of images.

One of the means by which researchers sought to understand the nature of image attributes and their descriptions by users is through the study of the meanings and levels of abstraction of the terms used in those descriptions. Classifications and taxonomies of the various types of attributes of individual images and the terms used to describe them have been the subject of previous research. Most of the researchers are among the highly cited in image research and LIS literature while their taxonomies and classification frameworks are among the widely used (e.g., Enser &amp; McGregor, 1992; Greisdorf &amp;
O X  X onnor, 2002b; Hollink, Schreiber, Wielinga, &amp; Worring, 2004; J X rgensen, 1995, 1998; Laine-Hernandez &amp; Westman, 2006; Panofsky, 1955; Shatford, 1986 ). There is no doubt that research into types and classes of image attributes as well as terms people use to describe and search for images is crucial to user-centered design of image organization and retrieval systems.

Terms human beings use to describe objects, convey knowledge, and express concepts have levels of generality and abstraction. Construction of hierarchical taxonomies and ontologies of domains of objects and knowledge, especially those that will aid browsing, needs to take this into account. As a hierarchical taxonomy and general framework, the basic level theory had been widely used in fields such as psychology, cognitive science, and philosophy, although its use has been lim-ited in library and information science research and practice ( Green, 2006 ). One of those who applied basic level theory in library and information science is J X rgensen (1995). J X rgensen (1995) analyzed attributes in terms of the three levels of abstraction, namely subordinate, basic, and superordinate, and then, along with Green (2006) , called for further research in this area. Iyer (1995) also discusses the characteristics, pros, and cons of applying the basic level theory to information retrieval vocabularies. Not only are comparisons of descriptions of individual images and labels of groups of images gen-erally rare, LIS research in general did not use the basic level theory enough to tackle relevant research problems or to make sense of these comparisons. Therefore, in this work, results of an analysis of text descriptions of individual images and labels of groups of images supplied by participants of three studies are presented. The focus is on the types of terms used as well as their level of abstraction vis- X -vis the basic level theory. The primary question that guided this research was: to what extent do user-generated textual descriptions of individual images differ from labels assigned to groups of images? 2. Image attributes and indexing
An attribute of a stimulus is a characteristic of contents of the stimulus. In the case of an image, it is a characteristic of both its visual and non-visual or semantic contents. An image attribute is  X  X  X hat is depicted or represented in the image X  pretive responses to the image such as those describing spatial, semantic, or emotional characteristics X  ( J X rgensen, 2003, p. 3 ) . Almost all forms of indexing and representation, in both concept-based and content-based image representation and re-trieval, are based on one or more attributes of the images ( J X rgensen, 1995; Rasmussen, 1997 ). While the number of indi-vidual attributes of a particular image could be innumerable, there are finite numbers of types as well as levels of abstraction of image attributes identified in the literature of both concept-based and content-based image retrieval. Some
Sepponen, Nirkkonen, &amp; Sormunen, 2001; Panofsky, 1955; Shatford, 1986 ), and four or more broad categories (e.g., Greisdorf &amp; O X  X onnor, 2002a ). These finite number of types and levels of abstraction of image attributes are strong candidates to serve as frameworks to provide an interface to large image collections for browsing and exploratory search.

The earliest of these classifications and taxonomies of image attributes was proposed by Panofsky (1955) whose work and the three classes (namely pre-iconography, iconography, and iconology) of the meaning of visual arts form  X  X  X he basis for much of the theoretical work that has been done on the classification of art images X  ( J X rgensen, 2003, p. 117 ). Preiconograph-ical attributes are basic or natural characteristics, usually names of objects. Iconographical level attributes have meaning at-tached to them as a result of interpretation, while iconological attributes involve deeper syntheses and multiple interpretations ( J X rgensen, 2003 ). Shatford X  X  (1986) three groups of attributes, which are  X  X  X pecific of X ,  X  X  X eneric of X , and  X  X  X bout X , loosely match the three classes in Panofsky X  X  (1955) classification.

One researcher who studied the nature of attributes of images extensively is J X rgensen (1995, 1996, 1998, 2003) . In her dissertation research ( J X rgensen, 1995 ), participants performed a description, a sorting, and a searching task. She identified three general categories of image attributes (which are further subdivided into 12 classes), namely perceptual (P), interpre-tive (I), and, to a lesser extent, reactive (R). According to J X rgensen (1995) , perceptual attributes relate to physical charac-teristics of images including objects in the images, image color, and other visual elements; whereas interpretive attributes are in the eyes of the viewer and require more than just perceiving. In an attempt to further classify image attri-butes, J X rgensen and her colleagues ( J X rgensen et al., 2001 ) provide a hierarchical conceptual framework for categories of visual attributes in the form of a  X  X  X yramid X . They divide image attributes into 10 levels and two general categories. The first category, syntax, consists of four mainly perceptual (or basic) attributes, while the second category, semantics, is made up of six conceptual (higher level or semantic) attributes.

A number of these investigators have developed these and other taxonomies through user reactions to images and image description tasks ( Greisdorf &amp; O X  X onnor, 2002a; Greisdorf &amp; O X  X onnor, 2002b; J X rgensen, 1995, 1996, 1998; O X  X onnor, O X  X on-nor, &amp; Abbas, 1999; Turner, 1994, 1995 ) as well as through solicitation of queries from image users ( Chen, 2001a, 2001b;
Choi &amp; Rasmussen, 2002, 2003; Goodrum &amp; Spink, 2001; Hastings, 1995 ). Rosch (1975) laid the foundations for the basic also studied categories of attributes of objects vis- X -vis the basic level theory. A recent work by Laine-Hernandez and West-man (2006) reviewed most of the above-mentioned classifications (except basic level theory) and suggested a framework that integrates some of their common classes and added a few more classes.

So far, the discussion in this paper focused on the types, levels of abstraction, and classifications of image attributes as well as the terms used to describe those attributes. One of the major problems in information storage, organization, access, and retrieval is related to representation (including indexing) of the documents. This research, because it is a good match for the type of data analyzed (text descriptions of individual images and labels of groups of images), adopted the concept-based definition of image indexing which is the representation of images through textual descriptions of their contents and what they are of or about ( Shatford, 1986 ). While an image could be of and about something, its ofness is mainly concrete and objective (e.g., a picture of a cowboy) and its aboutness is more abstract and subjective ( Layne, 1994; Shatford, 1986 ). Human viewers of a picture attach meaning to what the picture represents above and beyond its ofness . The visual nature of images and the fact that an image is not just of something and that an image is truly worth a thousand words compounds the prob-lem of their representation and indexing even more.

Blair (1990) argues that representation is  X  X  X rimarily a problem of language and meaning X  (p. 1). It is even more so in the case of concept-based image indexing where the documents being represented are visual images, rather than structured text documents, and the task of representation involves description of image attributes using text while the task of retrieval in-volves matching those text descriptions with users X  query terms. O X  X onnor et al. (1999) argue that representation of images using terms generated through users X  reactions might address this problem. As pointed out earlier, one of the limitations of concept-based image indexing and retrieval is the cost of manual assignment of index terms by human indexers, especially for large image collections. In spite of this, textual descriptions of image attributes remain one of the popular methods of their indexing ( Enser, 2000; J X rgensen, 1995, 1996, 1998, 2003 ). Most image users formulate their queries using words although this is neither always the necessary nor the only way ( O X  X onnor et al., 1999 ).

In an ideal situation, automatic extraction, annotation, and indexing of images based on low-level as well as high-level and semantic features would be possible. However, most of the current content-based image retrieval (CBIR) methods could only enable the extraction of low-level features such as color, shape, texture, luminosity, and edge. Even though content-based image retrieval (CBIR) mechanisms offer cost effective alternatives, they still lag far behind in bridging the semantic gap ( Datta et al., 2005; Lew et al., 2006; Neumann &amp; Gegenfurtner, 2006; Smeulders et al., 2000 ). There is still continued dependence on concept-based image indexing and retrieval, mostly with the help of human indexers. Therefore, it is increas-ingly important for image retrieval systems to take advantage of the recent phenomenon of social tagging (e.g., flickr ) and for system designers to adopt more user-centered approaches. To address this, continued investigations and full understanding of the nature of image descriptions by users are required and this work is a step in that direction.

In summary, concept-based image indexing methods based on textual descriptions of image content remain the domi-nant representation mechanisms. Multimedia searching on the World Wide Web is mainly based on keywords. Therefore, any image indexing tool and system should encompass the full range of attributes, including those that are perceived and concrete or otherwise. Most of the various classifications and taxonomies of image attributes discussed above were mainly developed in LIS through grounded theory approaches and some of them are non-hierarchical. This work focuses on a hier-archical and widely used (across several disciplines) framework. The basic level theory and its three levels of abstraction (subordinate, basic, and superordinate), are used here to compare descriptions of individual images and labels of groups of images. The choice of basic level theory was justified because existing taxonomies used by previous LIS researchers for similar investigations were built inductively and were constructed with a specific purpose in mind. On top of its wider appli-cation in a number of fields, basic level theory provides a neutral, hierarchical, general, and deductive framework. It also brings a new approach to LIS research on this topic. 3. Basic level theory
According to the basic level theory, objects, human concepts, and natural categories have a hierarchical structure with three levels of abstraction and generality, namely subordinate, basic, and superordinate ( Rosch &amp; Mervis, 1975; Rosch et al., 1976 ). Among these three levels, people, in general, prefer to use the basic level when they are thinking about the world around them ( Murphy &amp; Wisniewski, 1989; Rosch et al., 1976 ). The basic level is preferred especially when a task in-volves identification of single and isolated objects rather than labeling groups of objects ( Murphy &amp; Wisniewski, 1989 ). For an in depth description of the three levels, please see Appendix A .

There are a number of characteristics that set the three levels of abstraction of concepts apart. Whereas basic level con-cepts are generally more similar to each other, superordinate concepts are not. Basic level concepts are more similar because their instances share more common attributes than instances of superordinate concepts do ( Rosch et al., 1976 ). It has been confirmed that the more common features two stimuli have, the more similar they are ( Tversky, 1977 ). For instance, various types of chairs have more in common than various types of furniture (e.g., chair, table, and bed). Subordinate concepts have an even greater similarity among their instances than among instances of basic or superordinate concepts ( Rosch et al., 1976 ). For instance, several types of rockers (subordinate term) are more similar than various types of tables (basic term) and furniture. Stated differently, basic and subordinate level categories have a higher degree of within-category similarity than members of superordinate categories ( Markman &amp; Wisniewski, 1997 ). What is more, while both basic level and super-ordinate categories have a low degree of between-category similarity, subordinate categories have a high degree of between-category similarity, especially if they belong to the same or neighboring basic level categories ( Markman &amp; Wisniewski, 1997; Murphy &amp; Brownell, 1985 ). This makes members of a superordinate category less confusable, and more likely to be correctly classified at their respective level ( Markman &amp; Wisniewski, 1997 ), compared to members of a subordinate or a basic level category.
 Children have been found to learn the more concrete terms before abstract ones ( Horton &amp; Markman, 1980; Mervis &amp;
Crisafi, 1982 ) and nouns before verbs ( Gentner, 1982 ). In other words, they learn basic level concepts before superordinates children learn categories, basic level names are short and appear in high frequency ( Markman &amp; Wisniewski, 1997 ). As adults, in their discourses, they continue to use more basic level terms than they do superordinates ( Wisniewski &amp; Murphy, 1989 ). There are two main reasons for this. First, in a natural language, basic level terms appear with higher frequency com-pared to superordinate or subordinate terms ( Markman &amp; Wisniewski, 1997 ). Second, for novices, the basic level is the most adults differ in their view of superordinate categories. To children, superordinate categories are collections with a part-whole structure (e.g., a father is part of a family, or an arm is part of a body) whereas to adults, they are classes whose members have an ISA relation (e.g., a car is a, ISA, kind of vehicle) ( Wisniewski &amp; Murphy, 1989 ).

In summary, both children and adults, particularly novices to a domain of knowledge, prefer basic level terms to refer to single and isolated objects. In written text, superordinate terms are used more to refer to groups of objects ( Wisniewski &amp;
Murphy, 1989 ). This was confirmed through analysis of human subjects X  categorization of pictures of objects isolated or in scenes ( Murphy &amp; Wisniewski, 1989 ). Clearly, there is a distinction in the level of abstraction, at least with respect to the basic level theory, between terms used to describe individual and groups of objects. This is the distinction this work sought of individual images and labels of groups of images vis- X -vis the basic level theory. Specifically, this work sought to deter-mine if people use more basic level terms to describe individual images and use superordinate terms to label groupings of them than terms at the other two levels. In order to achieve this, data from 180 participants who either provided text descriptions or group labels for 130 individual and groups of images were analyzed through content analysis. 4. Methods 4.1. Studies
Three separate studies were conducted between March 2003 and November 2006. For Studies 1 and 2, data were col-lected using the free sorting method ( Coxon, 1999 ) where participants were asked to sort two separate samples of 50 images without any constraints on time and number of categories and assign labels to groups of images. Study 3 was different from
Studies 1 and 2 in that data were collected, as part of a larger study, through an image description task involving 30 images performed by 75 participants. 4.2. Materials
For Studies 1 and 2, two separate random samples of 50 color digital images were selected from disc number 6 (which contains all photographs in the  X  X  X eople X  category) of the Hemera Photo Objects Volume I , a stock photo collection of over 50,000 images ( http://www.hemera.com ), printed on a 4 5 in. (10.2 12.7 cm) card. For Study 3, a random sample of 30 images, 375 250 pixels in dimension, was selected from a collection of color photographs included in O X  X onnor and
Wyatt (2004) . 4.3. Participants
Participants in the three studies were 180 volunteer graduate students at two major US universities (one in the Southwest and the other in the Northeast). Thirty of those participated in Study 1 (16 female and 14 male), 75 in Study 2 (59 female and 16 male), and the remaining 75 in Study 3 (56 female and 19 male). All participants were between the ages of 21 and 60 years old. 4.4. Procedures 4.4.1. Data collection
Participants of Studies 1 and 2 were instructed to: (a) inspect the images first, (b) sort them into as many or as few groups (or categories) as they wished using their own general criteria for similarity, and (c) label each group. The cards were reshuf-fled before being given to the next participant. A different data collection procedure was followed in Study 3. An e-mail mes-sage introducing the study and containing the URL for an image description task was sent to each participant during the summer and fall 2004 semesters. Two weeks later, a follow-up e-mail message was sent to those participants who did not complete the task. Each participant read the instructions and was presented with a web-based form with a random im-age displayed at the top. No two participants were shown the 30 images in the same order. To ensure internal validity, a time constraint of 90 seconds was enforced within which participants were asked to type as many terms describing the images and their attributes as possible. To familiarize participants with the task, two images (not in the sample) were included at the beginning of the task. Participants were not constrained in terms of the number of words they could use as group labels or descriptions. 4.4.2. Data analysis
The main data analysis technique used was content analysis while the v variance (one-way ANOVA) were used mainly to test the difference between the number of labels of groups of images and terms used to describe individual image features at the three levels of abstraction (subordinate, basic, and superordinate). A four-step content analysis procedure was followed: (a) the creation and testing of a coding scheme that involves the defini-tion of recording units and categories, (b) assessment of the accuracy of coding, (c) revision of coding rules, and (d) coding the entire text ( Weber, 1990 ). Terms used by participants to describe individual image features and labels of groups of images (including single words and  X  X  X ord senses X ) were the recording units (basic unit of text coded or categorized). Here, the word  X  X  X erm X  is used to mean a concept that is referenced using one or more words. Phrases constituting a semantic unit such as idioms ( X  X  X aken for granted X ), proper nouns ( X  X  X he Empire State Building X ), as well as other phrases (e.g.,  X  X  X weet home X ,  X  X  X ife routine X ) ( Weber, 1990 ) are examples of  X  X  X ord senses X . These  X  X  X ord senses X  and terms were coded as single terms.

Due to lack of an established coding dictionary, a coding scheme (see Appendix A ) was specifically developed for the work by Rorissa and Iyer (2008) based on the definition, explanations, and examples given for the three levels of abstraction (superordinate, basic, and subordinate) in previous literature. It was modified and enhanced mostly through consultation of the book by Iyer (1995) and through several discussions between the author, a colleague of the author, and a graduate student. Labels of groups of images from Studies 1 and 2 were already coded (please see Rorissa &amp; Iyer, 2008 ) while the author and the graduate assistant coded all the descriptions of individual images supplied by the participants of Study 3 using the coding dictionary until they reached 100% agreement. A third coder, a colleague of the author who was blind to the purpose of the study, coded a random sample (20%) of the descriptions of individual images (Study 3). Percent agreement and Cohen X  X  (1960) j , two popular measures of intercoder agreement, were used to measure the reliability of coding be-tween the author and the third coder. The computed values of the percent agreement and Cohen X  X  (1960) j were 0.91 and 0.79 for Study 1, 0.89 and 0.80 for Study 2, and 0.92 and 0.80 for Study 3, respectively. These values are within the rec-ommended range for good levels of intercoder agreement ( Neuendorf, 2002 ). 5. Results 5.1. Description of the three studies
In total, participants of Studies 1 and 2 supplied 899 group labels (240 in Study 1; 659 in Study 2). The total number of terms supplied by participants of Study 3 is 15,301, including duplicates. Out of these, 4110 (26.86%) were unique terms. The minimum, maximum, median, mode, and mean number of terms supplied by all participants of Study 3 per image were 352, 652, 514, 550, and 510, respectively. Table 1 is a summary of the three studies. 5.2. Level of abstraction of labels of groups of images and descriptions of individual images
Out of the 899 labels of groups of images supplied by 105 participants of Studies 1 and 2, 39 (4.34%) were coded at the subordinate level (3.33% and 4.7% for Studies 1 and 2, respectively), 342 (38.04%) were coded at the basic level (42.5% and 36.42% for Studies 1 and 2, respectively), and 518 (57.62%) were coded at the superordinate level (54.17% and 58.88% for
Studies 1 and 2, respectively Table 2 ). Unlike group labels, descriptions of individual images required some cleaning. Words and phrases used in the descriptions of individual images by 75 participants of Study 3 were screened first in order to ensure that only proper words and phrases, not stop words, were considered for coding. After the screening, a total of 15,301 proper terms were coded where terms supplied by more than one participant were considered separate and coded accordingly.
Of the 15,301 words and phrases, 4250 (27.78%), 9684 (63.29%), 1367 (8.93%) were at the subordinate, basic, and superor-dinate levels, respectively (see Table 4 ).

On the face of it, based on the above frequencies and the mean number of subordinate, basic, and superordinate group labels and descriptions ( Table 3 ), there seems to be an apparent difference in the level of abstraction (vis- X -vis the three lev-els of subordinate, basic, and superordinate) between the types of terms people use to label groups of images and those they use to describe individual images. For instance, participants of the group labeling tasks (Studies 1 and 2) supplied about one and half times as many superordinate labels as the number of basic and subordinate labels combined. On the other hand, participants of Study 3 used more than seven times as many basic level terms than superordinate terms to describe individ-ual images. However, further analysis must be done to determine whether or not these apparent differences are also statis-tically significant. The next Section 5.3 is devoted to this. Because two studies (Studies 1 and 2) were conducted to solicit labels of groups of images, before conducting further analysis to answer the research question this work is attempting to answer, combining the data from the two studies is essential. This will create two distinct levels of the type of task (labeling groups of images, Studies 1 and 2, and describing individual images, Studies 3). In order to justify this, three separate tests were conducted.

First, the homogeneity of their variances, that is, whether or not samples from the two studies (Studies 1 and 2) have the same variances in terms of the number of labels of groups of images supplied by participants coded at the three levels (sub-with p &gt; 0.05 for subordinate, basic, and superordinate levels, respectively) were statistically non-significant. This is proof that the number of corresponding subordinate, basic, and superordinate group labels from the two studies satisfy the homo-geneity of variance criterion and assumption of equal variances is justified.

Second, to complement the homogeneity of variance test, an independent groups t -test (with equal variances) was con-ducted in order to see if the mean number of subordinate, basic, and superordinate level group labels from the two studies are comparable. The t -test indicated a non-significant difference between the corresponding mean number of group labels at the two studies. Hence, not only that the two samples have equal variances, the mean number of subordinate, basic, and superordinate level group labels from the two studies have very little or no difference (pairwise).

Third, a chi-square ( v 2 ) test of independence was conducted to determine whether the numbers of subordinate, basic, and superordinate labels of groups of images from the two studies are independent of the samples of images and participants. A are independent of the samples of images and participants. Hence, the two samples from Studies 1 and 2 were considered similar in their structure vis- X -vis the three levels. Based on results from the homogeneity of variances test, the independent groups t -test, and the v 2 test, the two samples from Studies 1 and 2 (labels of groups of images) were combined and will be treated as a single sample (group labels) in subsequent analyses (except in one-way analysis of variance). Table 4 presents the frequencies and percentages of the group labels (Studies 1 and 2 combined) and descriptions of individual images (Study 3). 5.3. Difference between labels of groups of images and descriptions of individual images
To reiterate, the research question guiding this work is: to what extent do user-generated textual descriptions of indi-vidual images differ from labels assigned to groups of images? Within the framework of the basic level theory and the three levels of abstraction (subordinate, basic, and superordinate), it could be restated as: do labels of groups of images and descriptions of individual images supplied by people have different underlying structures with respect to the three levels? If so, which level is used more for each task (labeling groups of images and describing individual images)? To answer this, a v 2 test of independence and a one-way (single factor  X  level of abstraction) analysis of variance (one-way ANOVA) were used. The v 2 test of independence was based on the frequencies in Table 4 and it was used mainly to see if the group labels and descriptions of individual images have different underlying structures with respect to the three levels (subordinate, basic, and superordinate). A statistically significant chi-square value ( v
N = 16,200) = 1993.33, p = 0.000) was obtained. This was interpreted as evidence that the type of task (labeling groups of images and describing individual images) is not independent of the level of abstraction. That is, the underlying struc-ture of labels of groups of images and descriptions of individual images are different vis- X -vis the basic level theory and the three levels.

These data show that there is a difference in the underlying structure of labels of groups of images and descriptions of individual images and, as a result, addressed the first part of the question. However, the v help answer the question: which level is used more for each task (labeling groups of images and describing individual images)? To answer this second part of the question, a one-way (single factor  X  level of abstraction) analysis of variance was necessary. First, data from each of the three studies were subjected to an initial screening to determine whether they satisfy the homogeneity of group variances criterion. For each study, the groups were the three levels of abstraction (subor-dinate, basic, and superordinate). The first screening resulted in unequal variances for data from all three studies. A correc-tive measure, transformation of the data (taking the square root of the number of subordinate, basic, and superordinate level terms), was taken in order to satisfy the homogeneity of group variances criterion. Levene X  X  test for homogeneity of group variances confirmed that the transformation yielded statistically non-significant differences between all possible pairs of variances of the number of subordinate, basic, and superordinate level group labels and descriptions of individual images for all three studies.

To determine if terms at one of the three levels of abstraction were used more for each of the two tasks (labeling groups of images and describing individual images) than at the other two levels, One-way ANOVA was conducted on the single factor of level of abstraction with the three levels of subordinate, basic, and superordinate. Tukey X  X  honestly significant difference (HSD) post hoc test was used for multiple comparisons. Both tests were conducted on the transformed data from all three studies and results from analyses of the transformed data are presented below.

For all three studies, results from the one-way ANOVA revealed that there was a significant overall difference be-tween the levels of abstraction. That is, the number of subordinate, basic, and superordinate level terms used as labels of groups of images and descriptions of individual images were significantly different for both the group labeling task (Study 1: F (2, 87) = 59.3, p = 0.000; Study 2: F (2, 222) = 128.3, p = 0.000) and description task (Study 3: F (2, 222) = 225.6, p = 0.000). Tukey X  X  HSD post hoc test conducted to compare all three pairs of means yielded mixed re-sults for the group labeling tasks (Studies 1 and 2). For both studies, even though all other pairs of the mean number of subordinate, basic, and superordinate level terms were significantly different from each other, the difference be-tween the mean number of superordinate and basic level group labels were not significant for Study 1. This could be attributed to the small sample size in Study 1. Participants of Study 2 supplied more group labels at the super-ordinate level ( M = 5.17) than at the basic ( M = 3.20) and subordinate ( M = 0.41) levels. Participants of Study 1 also supplied more basic level group labels ( M = 3.40) than subordinate ones ( M = 0.27). On the other hand, comparisons of the number of subordinate, basic, and superordinate terms supplied by participants of the other task, description of individual images (Study 3), indicated that individual images are described more at the basic level ( M = 129.12) than at the subordinate ( M = 56.67) and superordinate ( M = 18.23) levels. This is a clear indication that labels of groups of images and descriptions of individual images have markedly different underlying structures vis- X -vis the three levels. What is more, superordinate level terms are preferred to those at the subordinate and basic levels for labeling groups of images while basic level terms are used more than those at the other two levels to describe indi-vidual images. 6. Discussion and concluding remarks 6.1. Summary of results
Participants of three studies involving 130 images completed two sorting (and labeling of groups of images) tasks and a description of individual images task. The 180 participants produced a total of 899 group labels and 15,301 description terms. Using the basic level theory and three levels of abstraction (subordinate, basic, and superordinate) as framework, this work sought to determine the extent of the difference between user-generated labels of groups of images and descriptions of individual images. In addition, it attempted to test previous researchers X  assertions that people use more superordinate level terms to label groups of things whereas they mainly use basic level terms to refer to individual objects and concepts. It has been argued that people predominantly use basic level terms in free-naming tasks ( Rosch et al., 1976 ). In their discourses, when adults are thinking about the world around them, their preferred level of categorization is the basic level and they use more basic level terms than superordinate ones ( Murphy &amp; Wisniewski, 1989; Rosch et al., 1976; Wisniewski &amp; Murphy, 1989 ). However, Wisniewski and Murphy (1989) assert that superordinate terms are used more to refer to groups of objects. With the help of a combination of the v 2 test of independence, one way (single factor -level of abstraction) ANOVA, and
Tukey X  X  HSD post hoc test, this work provided support for these assertions. They hold true also when people label groups of images and describe individual images.

Through analyses of data from two tasks, sorting and labeling of groups of images (Studies 1 and 2) and description of individual images (Study 3), this work has shown that:
User-supplied labels of groups of images and descriptions of individual images have different underlying structures. Also, the type of task (labeling groups of images and describing individual images) is not independent of the level of abstraction (vis- X -vis the three levels of subordinate, basic, and superordinate).

For all three studies, the number of subordinate, basic, and superordinate level terms have statistically significant differences.

While, for the most part, more superordinate than basic and subordinate terms were supplied as group labels, descriptions of individual images were mainly at the basic level as opposed to the other two levels.
 These results are in agreement with previous research in fields other than LIS, and they also complement the work of
J X rgensen (1995) who, after conducting similar studies that involved image sorting tasks, arrived at the conclusion that image groupings by people were at the superordinate level while subgroups were at the basic level. Rosch et al. (1976) have also observed that sorting tasks that involved subjects to group things together lead to categorization at the super-ordinate level. This could be due to the fact that grouping entities establishes a global order and provides an overall struc-ture while description of the entities concentrates on the individual entity ( Soergel, 1985 ). In conclusion, this research is consistent with the views of many researchers ( Greisdorf &amp; O X  X onnor, 2002a; Hollink et al., 2004; J X rgensen, 1998; Laine-
Hernandez &amp; Westman, 2006 ) concerning labeling groups of images and description of individual images. When describing images, people made references to objects (mainly named at the basic level) in images much more than other types of attributes. 6.2. General implications of results
The existence of a marked difference, in terms of level of abstraction, between user-supplied labels of groups of images and descriptions of individual images shown in this work within the framework of the basic level theory and the three levels of abstraction will have a number of implications. Chief among these is that basic level theory could provide a possible solution to the problem and concern raised by some (e.g., Hollink et al., 2004 ) regarding lack of a common classification framework and taxonomy to study the nature of image attributes and compare results across several studies. The basic level theory provides the theoretical grounding and explanation to some of the views and assertions of the above researchers. What is more, basic level theory is closest to a universal hierarchical taxonomy of concepts and objects because it was found to be reliable across cultures ( Lakoff, 1985 ). For instance, basic level the-ory explains, partially, why people make more references to objects in images than to other attributes and why, as re-sults of the three studies above showed, groups of objects are labeled using superordinate level terms. Basic level terms are used by people more when the task involves identification of single and isolated objects rather than labeling groups of them ( Murphy &amp; Wisniewski, 1989 ). Moreover, children learn basic level concepts first ( Horton &amp; Markman, 1980;
Mervis &amp; Crisafi, 1982 ). Because basic level names are short and appear in high frequency in natural languages ( Mark-man &amp; Wisniewski, 1997 ), adults continue to use more basic level terms ( Wisniewski &amp; Murphy, 1989 ). Besides, for novices, the basic level is the most useful level of abstraction when referring to objects ( Rosch et al., 1976; Tanaka &amp; Taylor, 1991 ).

The significance of the basic level theory is not limited to just naming of objects. Search behaviors of image users exhibit some of the hierarchical nature of the basic level theory. For instance, Goodrum and Spink (2001) showed that users use, for the most part, search terms such as  X  X  X irls X  (a basic level term) and modify them to  X  X  X retty girls X  (a subordinate level term).
Moreover, most natural categories and some of the classificatory structures (e.g., taxonomies and classification systems) are hierarchical and they are organized from general to specific. For instance, some indexing tools such as the Art &amp; Architecture
Thesaurus (AAT) contain facets that are conceptually organized hierarchically from abstract to concrete. However, this orga-nization may not be the same as the organization of natural categories. Natural categories are organized in such a way that the cognitively basic level is almost always  X  X n the middle X  of the hierarchy ( Lakoff, 1985 ). This makes the basic level theory unique because  X  X  X he classical theory of categories gives no special importance to categories in the middle of a taxonomic hierarchy X  ( Lakoff, 1985, p. 46 ). 6.3. Implications of results for browsing and indexing of image collections
The results in this work and the use of basic level theory as a framework have other implications, too, especially for the design of browsing interfaces for large image collections and design of taxonomies, classificatory tools, thesauri, and other similar indexing tools. The current practice of design of these interfaces and tools is uncoordinated and no common frame-works exist. A common framework would help the design efforts tremendously because some groups of users, usually pro-fessionals (journalists, architectural designers, art directors, etc.), want to use browsing and textual category labels to search for images ( Armitage &amp; Enser, 1997; Markkula &amp; Sormunen, 2000 ) and an appropriately designed browsing interface could be crucial to their success in finding the needed image.

For these and other reasons, it is essential to find a common framework. To provide access to large image collec-tions and successfully support such users, a category based approach for browsing and exploratory search could be the way to go ( Hearst, 2006a; Shatford, 1986; Yee et al., 2003 ). One of these approaches is an appropriate hierarchical browsing interface. Several reasons and scenarios could be cited for using the basic level theory as a framework for designing these interfaces and other image indexing tools. For instance, the three levels of abstraction of concepts (subordinate, basic, and superordinate) provide a hierarchical taxonomy in order to build hierarchical classificatory structures which are often appropriate for building browsing interfaces and systems. Users have been shown to prefer hierarchies rather than disorderly groupings because a hierarchical grouping allows flexible ways to access a large document collection ( Hearst, 2006a ). With social tagging becoming popular and users willing to provide annotations and tags for images, imposing an automatic hierarchical (or faceted) structure onto image collections such as those in flickr is possible because user tags are readily available a priori ( Hearst, 2006a ). Availability of tags also solves one of the problems associated with clustering and groupings of documents, the difficulty of manually labeling groups of documents. Whether the browsing interface is hierarchical or facet based, appropriate labels for groupings of doc-uments are crucial.

The need for better tools to support browsing is real. For instance, half of the searches conducted by users of a video re-trieval system (Open Video Digital Library) begin with browsing ( Marchionini, 2006 ). However, because there are at least two types of users of an image collection, or any information system for that matter (those that conduct directed searches and those that prefer browsing), an image retrieval system should provide suitable interfaces and a combination of both searching and browsing services. There are some who view search and browsing as two ends of the exploratory search con-tinuum ( Cutrell &amp; Dumais, 2006 ). We concur with Marchionini (2006) that retrieval systems should support both explor-atory search or browsing and lookup because there are perhaps as many users who have no clear idea of what they are looking for as users with specific search requests. Users without concrete requests are likely to need an appropriate browsing interface while those who have a good idea of what they want could use advanced search features of retrieval systems. Both types of users could benefit from browsing interfaces, especially ones with hierarchical taxonomies, at the searching (query formulation) and browsing (search results review) stages.

An added advantage of using the three levels of abstraction (subordinate, basic, and superordinate) as a framework for designing either a hierarchical or faceted taxonomy and browsing interface such as Flamenco ( Yee et al., 2003 ) is that it could reduce the number of  X  X  X rill-down X  levels (unlike tools such as WordNet sificatory structure for browsing and exploratory search. An alternative approach in terms of the  X  X  X rill-down X  for image col-lections where keyword searching (or directed searching) using object names is predominant could start at the basic (middle) level and provide the user with a view where both the superordinate and subordinate levels are visible allowing the user to broaden or narrow his/her search, respectively. This could solve the problem with some browsing interfaces where  X  X  X he user is usually not given an overview of the category space other than a top-level view of the most general labels X  interface or system could be designed such that it would determine the level of abstraction of individual terms or a combi-nation of the query terms and start at the appropriate level for browsing. In other words, a taxonomy or interface based on the three levels of abstraction (subordinate, basic, and superordinate) should not be limited to providing access to image col-lections through browsing. Results of a directed search could also be displayed using the taxonomy in order to assist the user in either narrowing down and/or broadening his/her search based on the category within which the bulk of relevant items fall.

Another area where the basic level theory could serve as a framework in the design of browsing interfaces, taxono-mies, and indexing tools is interoperability. The design of a general, yet simple and less complex, taxonomy or classifi-catory structure, with three levels in depth (corresponding to the levels of subordinate, basic, and superordinate) could play a role in polling results together using a single query from several collections and/or systems. Such a taxonomy or classificatory structure would facilitate the interoperability of indexing tools and controlled vocabularies such asthesauri (e.g., AAT) and subject headings (e.g., LCSH, MeSH) as well as cross-searching and browsing across distributed digital libraries, including image collections. Entries in an indexing tool and/or controlled vocabulary could be mapped to the three levels of subordinate, basic, and superordinate before they are matched with entries in the indexingtools and controlled vocabularies of other collections and/or systems. This approach to interoperability between indexing tools and controlled vocabularies, thereby facilitating the interoperability and standardization of browsing interfaces and taxo-nomies, complements efforts being made by others (e.g., see Nicholson, Dawson, &amp; Shiri, 2006 , and the High-Level The-saurus project at: http://hilt.cdlr.strath.ac.uk/ ). Such a framework also has the potential to partially solve another problem that arises from matching individual entries and index terms in these indexing tools, controlled vocabularies, and image collections across various domains. Because most of these tools and collections are specialized and were built to serve a specific area/domain or specific types of users, term level matching is rendered ineffective, if not inappropriate.
An additional feature of a taxonomy based on the basic level theory and the three levels of subordinate, basic, and superordinate is that it fits the general trend in the number of levels in depth of existing taxonomies for browsing and the study of image attributes. For instance, the Picture Australia network ( www.pictureaustralia.org ) has a two-level sub-ject-based taxonomy, the taxonomy for the British Library X  X  Collect Britain network of historical resources ( www. collectbritain.org ) and the Heritage Colorado network ( www.aclin.org ) have three levels, while that of the Online Archive of California ( www.oac.cdlib.org ) has up to four levels of depth ( Chaudhry &amp; Jiun, 2005 ). Limiting the number of levels of depth in a taxonomy and browsing interface to three has previous research support as well. For instance, most researchers have been using taxonomies with three levels to study the nature of image attributes. The three levels of subordinate, basic, and superordinate make the basic level theory comparable (though not equivalent) to three levels of previous frameworks and taxonomies of the meaning of images and art such as J X rgensen X  X  (1995) (perceptual, interpretive, and reactive), Shatford X  X  (1986) ( X  X  X pecific of X ,  X  X  X eneric of X , and  X  X  X bout X ), and Panofsky X  X  (1955) (pre-iconography, iconography, and iconology), making it a logical candidate for a general framework to study the attributes, meaning, and subjects of images. 6.4. Summary and recommendations for future work
In summary, results and the subsequent discussions presented here as well as previous research in LIS and other fields suggest that the basic level theory and the three levels of subordinate, basic, and superordinate have a number of implications and possible applications. They may provide possible solutions to a number of problems ranging from browsing interfaces to standardization of taxonomies and labeling of categories. While a taxonomy based on the three levels would fit most current taxonomies in terms of the number of levels of depth, results of the three studies reported in this work have shown that for browsing purposes labels for individual images and objects in them could be at the basic level while labels for groups of images could be at the superordinate level. Furthermore, taxonomy and thesaurus developers could use the three levels to define categories and for sorting or grouping concepts and terms as part of their procedures. For instance, Step 5 of the taxonomy development procedure used by Chaudhry and Jiun (2005) could be augmented by the use of the basic level theory. A thesaurus developer could use the three levels to determine relation-ships between terms and concepts, more so for the hierarchical relationships  X  broader and narrower term relationships  X  and the associative relationships, albeit to a lesser degree. The basic level theory conforms to the general model of thesaurus construction, at least as far as hierarchical (broader and narrower term) and, to some extent, associative rela-tionships between concepts are concerned. It also conforms to the  X  X  X lass inclusion X  type of hierarchical relationship where a  X  X  X arrower concept has all the characteristics of the broader concept and, in addition, at least one further char-( Soergel, 1985, p. 282 ).

This work is among very few studies that deal with the topic of the extent of the difference between labels of groups and descriptions of individual images. It attempted to not only use the basic level theory to determine this difference but also show the implications and applications of the basic level theory to image indexing and retrieval.
It should be noted that even though the basic level theory was used as a framework in this work because of its strengths, it has some weaknesses. For instance, the three levels may not hold in all cases across languages. What is more, domain knowledge may affect the level of concepts people use to either group or name objects and concepts that are superordinates for experts could be considered basic for novices ( Tanaka &amp; Taylor, 1991; Wisniewski &amp; Murphy, 1989 ).

It goes without saying that results reported here need to be verified using a number of different samples of images and participants in order for them to be used as a basis for either design of image indexing and retrieval tools or the conduct of future research. Some of the studies reported here were conducted before flickr data were made widely and publicly available to researchers. This is an exploratory research and the impact the types of images selected for the three studies could have had on the results needs to be checked by future research. The samples of images of people from a stock photo collection could be a possible limitation. The author plans to use flickr as a source of data and materials (images, tags, descriptions, etc.) in future studies regarding user-generated descriptions of images and recommends that other researchers also do the same in order to have comparable results and to arrive at useful and general conclusions. A recent work by Stvilia and J X rgensen (2007) is an example of a step in this direction. What is more, this will also help determine whether the choice of images in the three studies influenced the results.
 Acknowledgements This work was partly supported financially by the School of Library and Information Sciences, University of North
Texas. I thank Dr. Carol Doll, Dr. Deborah Andersen, and Dr. Hemalata Iyer for their very useful feedbacks and great editing, and Stephen Maher for coding and help in data analyses. I am grateful to all participants of the three studies.
 Appendix A. Coding scheme used References
