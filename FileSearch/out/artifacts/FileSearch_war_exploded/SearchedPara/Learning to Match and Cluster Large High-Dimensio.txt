
Part of the process of data integration is determining which sets of identifiers refer to the same real-world entities. In integrating databases found on the Web or obtained by us-ing information extraction methods, it is often possible to solve this problem by exploiting similarities in the textual names used for objects in different databases. In this paper we describe techniques for clustering and matching identifier names that are both scalable and adaptive, in the sense that they can be trained to obtain better performance in a par-ticular domain. An experimental evaluation on a number of sample datasets shows that the adaptive method sometimes performs much better than either of two non-adaptive base-line systems, and is nearly 'always competitive with the best baseline system. 
Learning, clustering, text mining, large datasets 
Data integration is the problem of combining information from multiple heterogeneous databases. One step of data integration is relating the primitive objects that appear in the different databases--specifically, determining which sets of identifiers refer to the same real-world entities. A num-ber of recent research papers have addressed this problem by exploiting similarities in the textual names used for ob-jects in different databases. (For example one might suspect that two objects from different databases named "USAMA 
FAYYAD" and "Usama M. Fayyad .... respectively might refer to the same person.) Integration techniques based on textual similarity are especially useful for databases found on the Web [1] or obtained by extracting information from text [6, 13, 11], where descriptive names generally exist but permission and/or a fee. SIGKDD '02 Edmonton, Alberta, Canada global object identifiers are rare. Previous publications in using textual similarity for data integration have considered a number of related tasks. Al-though the terminology is not completely standardized, in this paper we define entity-name matching as the task of taking two lists of entity names from two different sources and determining which pairs of names are co-referent (i.e., refer to the same real-world entity). We define entity-name clustering as the task of taking a single list of entity names and assigning entity names to clusters such that all names in a cluster are co-referent. Matching is important in at-tempting to join information across of pair of relations from different databases, and clustering is important in remov-ing duplicates from a relation that has been drawn from the union of many different information sources. Previous work in this area includes work in distance functions for matching [14, 3, 9, 8] and scalable matching [2] and clustering [13] al-gorithms. Work in record linkage [15, 10, 21, 20, 7] is similar but does not rely as heavily on textual similarities. In this paper we synthesize many of these ideas. We present techniques for entity-name matching and clustering that are scalable and adaptive, in the sense that accuracy can be improved by training. 
We will begin defining the problems of adaptive match-ing and clustering by describing a very general notion of an adaptive system. Assume a source of training examples. 
Each training example is a pair (x,y*), where x is a prob-lem instance and y" is a desired solution to x. We will also assume a loss function, Loss(y,y*), measuring the quality of a proposed solution y relative to a desired solution y*. 
The goal of an adaptive system L is to take a set of training examples (x l, y[) .... , (xm, y~) and learn to propose "good" solutions to novel problems xj. In other words, the input to L is the set {(xl,y~)}~=l and the output is a function f such that the loss Loss(f(xj),y~) is small, where y~ is the desired solution for xj. One simple, well-explored example 
Consider the task of learning to match names from some pie, we might wish to learn to match a researcher's name and address with a university name if and only if the researcher is affiliated with that university. To formalize this, we let each problem instance x be a pair, x = (A, B), where A and 
B are sets of strings. For instance, A might be names and addresses of researchers registered for KDD-02, and B might be names of universities in the United States. A solution y is set of A x B that indicates which pairs are to be matched. 
A natural loss function Loss(y, y*) might be the size of the symmetric difference of y and y*: i.e. if y = {(a~,bi)}~=l and y* {(a;, * k" = b3)}~=1 then 
Loss(y,y,) =_ [{(ai,b,)  X  y: (a,,b,) Cy*}[ 
Other related measures are recall, precision, and F-measure---all of which are based on the symmetric difference of two sets. 
Many matching problems are more constrained than this example. For instance, if the a'a and b's are entity names, sense for a proposed solution y to contain both (a, b) and (a, b'). We define a constrained adaptive matching problem to be one in which the set of pairs in every desired pairing y* is a one-to-one function. 
Constrained matching problems are common--in fact, both of the matching problems considered in Section 4 are con-strained. However, we consider here the more general case, which is useful (for instance) in matching datasets that may duplicates. The second problem we consider is adaptive clustering. 
In this case, each problem instance x is set of strings D = to clusters, encoded as a function z from D to the integers between 1 and k (where k is the number of clusters). 
For example, consider clustering descriptions consisting of a researcher's name, together with some additional piece of identifying information, such as his or her affiliation in 
July, 2002. A problem instance x would be a set of strings (like "William W. Cohen, Whizbang Labs", "W. Cohen, WhizBang Labs -Research", "Jude Shavlik, University of 
Wisconsin", etc) and a solution y* would be a function z such that z(dl) = z(d2) iff dl and d2 refer to the same per-son. Adaptive clustering is learning to cluster better given a sequence of training data in the form of (x, z) pairs. 
The definitions above are extensions of the model for adap-tive ranking systems described by Cohen, Singer and Schapire [5]. To oversimpfy slightly, Cohen, Singer and Schapire con-sidered adaptive systems in which each problem instance x was an unordered set of objects x = {dl,... ;din}, and each desired solution y* was a total ordering over the objects in x. The problem of learning to order instances was addressed by learning a preference function, p(d, d')--conceptually, a function p : X x X ~ {0, 1} indicating if d should be ranked before d' in the desired ordering y*. Adaptive matching and clustering can be implemented in 1. Build a training sample S for the pairing function h. (a) Let 5; = 0. (b) Fori=l ..... m: 2. Train a classification learner on S. The result will be a hypothesis h that labels pairs (d, d') as positive or negative. 1. Build a gxaph G with vertex set D, where an edge exists between dl and dj iff h(dl, dj) = +. 2. Make each connected component of G be a cluster. 
The algorithm of Figure 1 has two problems: a small num-
To address these problems, we modify Figure 1 in three 
Second, we will exploit the fact that classification learners 
We next consider the generation of candidate pairs (an 
The canopy method, shown in Figure 3, begins with an 
To train from ((D1, Zl) .... , (D,~, zm)}: 1. Build a training sample S for the pairing function h. 2. Train a classification learner on S. The result will be a hypothesis h that labels pairs (d, d') as positive or negative. 3. Let c(d,d') be the confidence given by h that the 
To cluster a new set D = {dx,..., d,~} into K clusters: 1. Build a graph G with vertex set D, where an edge exists between dl and d~ iff (di,d X ) E tween d and de is c(di, d X ). 2. Perform greedy agglomerative clustering (GAC) on G to produce K clusters. 3. Use the clustering produced by GAC on G as the clus-tering of D. 
Figure 2: A better and more efficient adaptive clus-tering algorithm picking a random "center point" d. After d is picked, all are found. These "canopy" points are paired with each other, and the resulting pairs are added to the set of can-didate pairs. Next, the set of poflsible "center points" is decreased by removing all points d within distance Tt,ght of ble center points are chosen. 
For the benchmark problems considered in Section 4, it was fairly easy to find thresholds Ttight and Tt .... that allow generation of nearly all "true" pairs (pairs that belong in a desired cluster) without generating too many spurious pairs. 
In learning, two issues must be addressed: how to repre-sent a pair (d, d'), and which learning algorithm to use. We explored several different classification learning systems, and different feature sets for representing pairs (d, d'). Here we will report results for a maximum entropy learner [16]. This learning system requires that examples be represented as a vector of binary features. Examples of the features used to encode a pair are shown in Table 1. Here the edit distance 
To compute CandidatePairs(D): 1. Let CandidatePairs = 0. 2. Let PossibleCenters = D. 3. While PossibleCenters is not empty: 4. Return CandidatePairs 
Figure 3: Computing a set of candiate pairs us-ing the canopy algorithm of McCallum, Nigam and 
Unger gives every character insertion and deletion unit cost, and 
Jaccard distance [18] is computed by treating d and d' as sets of tokens and using [d n d'[/[d u d'[ as a distance function. In some of the test datasets we considered, the items to be clustered are not strings, but records consisting of several strings (for instance, a record containing a name and an address, or a bibliographic entry containing a title, author, date, and publication venue). For such datasets, a pair was encoded by extracting the features of Table 1 for every pair of fields, and combining all the features: for in-stance, in pairing name/address records, we computed the features SubstringMatchname, SubstringMat ch~ddr~s~, PrefixMatch ..... PrefixMatch~ad ..... ..., 
StrongNumberMatch~ame, StrongNumberMatchadd ..... ) It is fairly simple to adapt the algorithm above to the problem of constrained adaptive matching. Generation of candidate pairs is substantially easier, since one need only consider pairs (a, b) where a E A and b E B. One possible technique is to use the canopy algorithm of Figure 3 with these modifications:  X  in Step 2, let PossibleCenters = A;  X  in Step 3b, let Canopy(a) = {(a,b) : b E B and  X  in Step 3d, let Ttiaht = 0 (i.e., only remove a from the set of PossibleCenters). 
A functionally equivalent but somewhat more efficient ap-proach would be to use a soft join algorithm [3]. Learning a pairing function and construction of the graph 
G is identical. The greedy agglomerative clustering step, SubstringMatch PrefixMatch EditDistance(k) MatchAToken(n) MatchBToken(n) MatchABigram(n) JaccardDistance(k) 
StrongNumberMatch Benchmark Cora OrgNamel OrgName2 Restaurant Parks Benchmark] TFIDF 
Cora 0.751 
OrgNamel 0.925 
OrgName2 0.958 
Restaurant 0.981 
Parks 0.976 Table 4: Experimental results: F-measure 
Table 3: Experimental results: precision and recall however, should be replaced with an operation that enforces the constraints required for constrained adaptive matching. 
This can be done by computing the minimal weight cutset of G, and returning the edgee~ of this cutset as the pairing. 
We have experimented with ooth a greedy approach and an exact minimization (which exploits the fact that the graph is bipartite [17]). The experiments in this paper are for a simple greedy mincut-finding algorithm, which is more efficient for large graphs. 
We note that the problems of learning pairing functions, clustering, and matching are closely related, but distinct. In unconstrained matching, the pairs do not correspond imme-diately to clusters, since pairs may overlap, but clusters are disjoint. In constrained matching, matching can be reduced to clustering, but exploiting the additional constraint that a pairing is one-to-one can substantially change the difficulty of a clustering task. Finally, while learning a pairing func-tion is a natural way of making a clustering system adaptive, obtaining an accurate hypothesis h does not mean that the ensuing clustering will be any good, as it is possible for small errors in h to cause large clustering errors [4]. 
We used several datasets for evaluation purposes. Two of the datasets require clustering, and two require match-ing. The first clustering dataset, Cora, is a collection of paper citations from the Cora project [12, 13]. The second dataset, 0rgName, is a collection of 116 organization names. 
We considered two target clusterings of this data, one into There are also two constrained matching datasets. The 
We assumed[ that the number of intended clusters K is 
To evaluate performance we split the data into two parti-
As success measures for the algorithms, we used several vention in information retrieval, we define the recall relative to y* to be lY N y* I/[y*l, the precision to y* to be [yNy*l/ly h the F-measure ofy relative to y* to be the harmonic mean of recall and precision. 3 
For clustering algorithms, recall that a problem instance x is a set of objects D, and a solution y* is a mapping z from D into the integers {1,..., K}, and define pairs(D, z) to be the set of all pairs {(d, dt) E D x D : 
We will define recall and precision in terms of pairs(D, i.e., we define the recall of z relative to z* is column of Table 2 shows the maximum recall obtainable us-ing the CandidatePairs produced by the canopy algorithm. 4 
In addition to the algorithm described in Section 3, we considered two additional clustering/matching algorithms as performance baselines. The first one replaces c(a, b) in the graphs above with Levenstein edit distance. Applied to clustering, this aseline algorithm is similar to the algo-rithm proposed by McCallum, Nigam and Unger; applied to matching, it is similar to the method proposed by Monge and 
Elkan[14]. The second baseline replaces c(a, b) with TFIDF distance, using the formula given in [18], which is similar to the algorithm used in WHIRL [2]. 
The experimental results for these algorithms on the datasets of Table 2 are shown in Tables 3 and 4. The baseline results for edit distance are taken from [13], who used hand-tuned edit distance, and unlike the other entries in the table, they apply to the whole set, rather than a single partition. In 
Table 4, the best F-measure obtained on each problem is placed in bold. 
A first observation on the results of Table 4 is that neither baseline system appears to outperform the other. Discount-ing Cora (for which the edit-distance function was hand-3That is, F = 2.P.R 4Creating appropriate partitions for training and test is non-trivial, since one must ensure that the test cases are inde-pendent of the training cases, and a simple random parti-tion of would likely lead to a situation in which some of the intended clusters were split between the training and test sets. To avoid this, we split the data so that no algorithm that considers only pairs produced by the canopy algorithm would ever consider a pair containing one instance from the test set and one instance from the training set. A disadvan-tage of this procedure is that it was sometimes impossible to create well-balanced splits, biasing the results away from adaptive methods. engineered), the TFIDF-based baseline obtains a better F1 score than the distance-function baseline on five runs, per-forms worse on two runs, and performs identically on one run. This confirms our belief that both TFIDF and edit-distance distance metrics are useful in data integration set-tings. 
The adaptive method does far better than either base-line technique on the Cora dataset. Notice that the  X ora dataset is the largest of the datasets considered, as well as the one for which the baseline methods perform the worst; hence it offers the most opportunity for adaptive techniques to improve performance. In the remaining eight runs, the adaptive technique performs best on five, and nearly equals the best result on two more (the first split of 0rgNamel and the second split of Restau.rant). Thus on nine of the ten partitions, the adaptive method obtains results comparable to or better than the best of the baseline approaches. 
The adaptive methods performs poorly on only one of the ten runs--the second partition of 0rgNamel. We conjecture that for this dataset (by far the smallest we considered) the constraints on partitioning used above resulted in substan-tial variation across the two partitions used for training and testing. 5 
We have presented a scalable adaptive scheme for cluster-ing or matching entity names. Experimental results with the method are comparable to or better than results obtained by clustering or matching with two plausible fixed distance metrics. 
As noted above, our formalization of adaptive clustering and matching is inspired by the model of "learning to order" of Cohen, Schapire, and Singer [5]. They consider adap-tive ordering systems and show that this problem can be solved by supervised learning of a binary ordering relation, followed by a greedy method for constructing a total order given a set of (possibly inconsistent) binary ordering deci-sions. They also give provable bounds on the loss of such SNotice that the TFIDF-based baseline system does much better than the edit-distance based baseline on the first par-tition, but that the opposite holds on the second partition. Thus even the trivial adaptive system that chooses the bet-ter of the two baseline systems based on training data would perform poorly. The size of the pairing-function training sets and the number of entities per cluster is also varies greatly in the two partitions. 
The architecture of the adaptive matching and clustering 
The "core" idea of learning distance functions for entity 
ChoiceMaker.com, a recent start-up company, has also 
A number of enhancements to the current method are similarity in information access. Autonomous Agents and Multi-Agent Systems, pages 65-86, 1999. joins and a word-based information representation language. A CM Transactions on Information Systems, 18(3):288-321, July 2000. information representation language. Artificial 
Intelligence, 118:163-196, 2000. match and cluster entity names. In Proceedings of the 
Methods in Information Retrieval, New Orleans, LA, 2001. Singer. Learning to order things. Journal of Artificial 
Intelligence Research, 10:243-270, 1999. 
T. Mitchell, K. Nigam, and S. Slattery..Learning to extract symbolic knowledge from the world wide web. In Proceedings of the Fifteenth National Conference on 
Artificial Intelligence (AAAI-98), Madison, WI, 1998. linkage. Journal of the American Statistical Society, 64:1183-1210, 1969. AJAX: an extensible data-cleaning tool. In 
Proceedings of ACM SIGMOD-2000, June 2000. problem for large databases. In Proceedings of the 1995 ACM SIGMOD, May 1995. techniques--1985. Statistics of Income Division, Internal Revenue Service Publication 1299-2-96. 
Available from http://www.bts.gov/fcsm/methodology/, 1985. Digital libraries and autonomous citation indexing. 
IEEE Computer, 32(6):67-71, 1999. 
Automating the construction of internet portals with machine learning. Information Retrieval, 2000. clustering of high-dimensional data sets with application to reference matching. In Proceedings of 
Discovery and Data Mining, pages 169-178, 2000. algorithm and applications. In Proceedings of the 
Discovery and Data Mining, August 1996. A. P. James. Automatic linkage of vital records. 
Science, 130:954-959, 1959. Using maximum entropy for text classification. In 
Filtering Workshop, IJCAI '99, Stockholm, Sweden, 1999. algorithm, s for bipartite graph. Technical Report DCC-03/93, Departamento de Cincia da Computao, 
Universidade Estudal de Campinas, 1993. 
Addison Welsley, Reading, Massachusetts, 1989. Felligi-Sunter model of record linkage. Statistics of Income Division, Internal Revenue Service Publication 
RR93/12. Available from http://www.census.gov/srd/www/byname.html, 1993. current research problems. Statistics of Income Division, Internal Revenue Service Publication 
R99/04. Available from http://www.census.gov/srd/www/byname.html, 1999. Business Survey methods. Wiley, 1995. 
