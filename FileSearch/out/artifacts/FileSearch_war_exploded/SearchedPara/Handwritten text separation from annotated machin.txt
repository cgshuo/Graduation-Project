 ORIGINAL PAPER Xujun Peng  X  Srirangaraj Setlur  X  Venu Govindaraju  X  Ramachandrula Sitaram Abstract The convenience of search, both on the personal computer hard disk as well as on the web, is still lim-ited mainly to machine printed text documents and images because of the poor accuracy of handwriting recognizers. The focus of research in this paper is the segmentation of hand-written text and machine printed text from annotated docu-ments sometimes referred to as the task of  X  X nk separation X  to advance the state-of-art in realizing search of hand-anno-tated documents. We propose a method which contains two main steps X  X atch level separation and pixel level separa-tion. In the patch level separation step, the entire document is modeled as a Markov Random Field (MRF). Three dif-ferent classes (machine printed text, handwritten text and overlapped text) are initially identified using G-means based classification followed by a MRF based relabeling procedure. A MRF based classification approach is then used to sepa-rate overlapped text into machine printed text and handwrit-ten text using pixel level features forming the second step of the method. Experimental results on a set of machine-printed documents which have been annotated by multiple writers in an office/collaborative environment show that our method is robust and provides good text separation performance. Keywords Text identification  X  Markov Random Field  X  Documents retrieval  X  Ink separation  X  Segmentation 1 Introduction After decades of research and development, automatic docu-ment processing systems have attained considerable success in that large volumes of paper documents can be digitized and processed to recognize textual content and facilitate infor-mation retrieval. Unfortunately, the convenience of retrieval and search is limited to clean machine-printed text docu-ment images and recognition of free-form handwriting still remains a considerable challenge. In many scenarios, a mix-ture of machine printed text and handwriting occur within a single document, such as hand-filled medical forms, tax forms, annotated correspondence as shown in Fig. 1 . Some-times, it may be of interest to know who signed or edited a document or what was written on a document and retrieve memos or a specific keyword by a particular author. The pre-processing of mixed documents to isolate handwritten text from machine printed text is a necessary step in the design of such recognition and retrieval systems.

Although research into the location of text blocks and dis-crimination of machine printed and handwritten text can be traced back to the early work on extraction and recognition of handwritten ZIP codes from mail pieces [ 36 ], much of it was focused on identification of clearly separated and clean text. A significant amount of prior research for handwrit-ing identification is based on document layout analysis and zone classification wherein a document is segmented into words, lines, and zones in a bottom-up approach or in a top X  down manner [ 15 , 27 ] and contextual information based on the location of text zones points to the location of handwritten data.
Another thrust has been on using textual elements alone without considering context or layout. Eduardo et al. [ 9 ] sug-gested two types of features (content related features and shape related features) to characterize handwritten text on bank check images. This approach uses a fixed size frame to extract features, but locating and labeling overlapped text is not part of the model in their work. Jang et al. [ 20 ] proposed an approach using geometric features to classify machine printed and handwritten addresses on mail-pieces. Guo and Ma [ 17 ] separated handwritten material from doc-uments using a Hidden Markov Model (HMM) by using the vertical projection of each word on the horizontal axis and considering a projected word as a sequential signal. This model is reliable for recognizing machine printed isolated characters but it is difficult to extend the work to recognize annotations and handwritten text because of the large varia-tions of personal fonts and styles. Farooq et al. [ 12 ]usedan EM based Bayesian neural network model in order to iden-tify Arabic handwritten text in mixed documents. They used multiple classifiers which were weighted by their posterior probabilities and introduced a new neurons layer which used an error function to penalize solutions that led to mis-clas-sification. Fan et al. [ 11 ] isolated the machine printed text from handwritten text based on their differences between the geometric arrangement. In order to extract names in mixed documents, Likforman-Sulem et al. [ 26 ] identified handwrit-ten and printed pseudo words and classified them with a neural network using both image-based and textual-based features.

One potential problem of previous research on text sep-aration is that although the basic unit (zone, line or word) of the system works well to classify those patches whose sizes are typically larger than words, it cannot separate over-lapped patches which contain both handwritten and machine printed text because they are considered as a single unit in the system. Zhao and Davis [ 38 ] used color information of each pixel to segment picture foreground from background which can also be used for document segmentation. How-ever, color information is rarely available in the document analysis field where the input is usually a scanned binary document image. Some work in computer vision also pro-vides us with interesting clues to address the problem of overlapped text patches. Eran and Shimon [ 10 ] presented a top X  X own/bottom X  X psegmentationmethodusingsmallfrag-ments that contain common object parts. Corso [ 8 ] suggested a multilevel aggregation procedure which groups each pixel to a set of aggregate regions in a multilevel coarsening of the image. Alpert et al. [ 2 ] used a Bayes rule to determine whether or not to merge two neighbor regions and segment images using these regions. All these approaches show that we can use a unit which is smaller than words as the basic element to separate overlapped text.
 Inrecentyears,inspiredbythesuccessofMarkovRandom Field (MRF) in the area of image processing and restora-tion [ 13 , 14 ], considerable research has been made to extend MRF to document restoration and preprocessing. Cao and Govindaraju [ 6 , 7 ] proposed a method using small fixed size patches to represent handwriting and restore broken hand-written text based on a MRF framework. Similarly, Banerjee [ 3 ] used a flexible MRF-based optimization framework to remove noise and restore machine-printed text. These meth-ods can be looked at as an extension of Freeman X  X  algorithm [ 13 ]. Zheng et al. [ 39 ] proposed a two step approach to iden-tify three different types of text in mixed documents. They initially separated text using a Fisher classifier followed by a Gibbs network based relabeling which was further opti-mized using a Highest Confidence First algorithm. A similar approach but using Conditional Random Field has been pro-posed by Shetty et al. [ 35 ]. 2 System structure Inthispaper,weproposeatwo-stepcompositemethodtosep-arate handwritten text, machine printed text and overlapped text from annotated documents.

As shown in Fig. 2 , the first step (step I) of the proposed method takes the entire document as its input and separates the text into three classes: machine printed text, handwritten text and overlapped text on patch level. This step has three sub-procedures. The first sub-procedure is a preprocessing procedure to extract patches of the document and extract fea-tures for each patch which is covered in Sect. 4.1 . Section 4.2 describes the second sub-procedure of step I which is a G-means based initial classification procedure. The last sub-procedure of patch level text separation is to relabel the result of initial classification using a MRF based model. Section 4.3 describes the details of the relabeling. Section 4.4 presents the experimental results of MRF based patch level text sep-aration.

The second step (step II) takes the overlapped text patch as its input which is then further separated into machine printed text and handwritten text on pixel level. The first sub-procedure in step II is to extract shape-context based fea-tures for each pixel. The next sub-procedure is an aggregation coarsening algorithm which extracts the basic element for the overlapped text separation. Sections 5.1 and 5.2 describe these two sub-procedures. The last sub-procedure is the sep-aration of machine printed text and handwritten text using a MRF model and is described in Sect. 5.3 . Section 5.4 shows the experimental setup and results of overlapped text separa-tion.

Prior to presenting the details of each step of the proposed method, we briefly provide a background of MRF in Sect. 3 and our conclusions are presented in Sect. 6 3 Background X  X arkov Random Field The Markov Random Field (MRF) is a graphical model in which a set of random variables have a Markov property described by an undirected graph and  X  provides a convenient and consistent way of modeling context-dependent entities such as image pixels and correlated features  X  X  25 ]. MRFs are widely used in the field of image processing and document analysis, including image binarization [ 21 , 22 ], document restoration and image super-resolution [ 18 , 33 ], image and document segmentation [ 5 ], noise removal and filtering [ 3 ], etc. These applications can be categorized as the low-level processing. The high-level processing in image processing and vision field includes object detection and recognition. Li proposed a general framework of using MRFs for a computer vision problem by converting the high-level vision problem to a low-level labeling problem [ 24 ]. He used this idea to match objects in [ 23 ]. To detect objects in the image, Sheikh designed a two-step algorithm which used the probability density to estimate the object, and refined the final result by using the MAP-MRF decision framework [ 34 ].

From the view of mathematics, the MRF can be consid-ered as a labeling procedure which is a proper model for the purpose of the document text separation (labeling).
We can use MRF to model the entire document in step I or overlapped text in step II and to separate patches (defined in Sect. 4.1 )instepIoraggregations(definedinSect. 5.2 )instep II. We assume that the the foreground of a document/over-lapped text image I is represented by a graph G = ( V , E ) where V ={  X  : 1  X   X   X  N } is the set of vertices which cor-respond to patches or aggregations in the image. E is the set of edges which connect vertices based on a neighbor system. The neighbor system can be based on four-neighbors lattice connectivity or any other metric defined by the user.
Given the graph G = ( V , E ) , a random field X = x ,..., x vertex takes a random variable x  X  from a set of possible con-figurations as its underlying label. In this paper, the con-figurations are taken from a set of cluster centers which are described in the following sections in details. According to these configurations (cluster centers), we can easily map a hidden random variable x  X  to the corresponding index as its label. Let Y = y 1 ,..., y N be the observations which are the corresponding features for each vertex. An optimal configu-ration of the random field X is computed by maximizing the posterior:  X  X = arg max where y  X  and x  X  are the observed feature and hidden configu-ration respectively for a given vertex  X  , and V  X   X  is the set of all vertices in graph G except vertex  X  . This equation shows that the configuration of site  X  is dependent on its observation and all other vertices in the graph.

By taking the Bayes rule and the Markov property, Eq. 1 can be rewritten as:  X  X = arg max
Since the denominator P ( y  X  | X V  X   X  ) is just a normaliz-ing constant and remains unchanged, we can disregard it and have the following equation: where prior P ( x  X  | X N ( X ) ) means the configuration of site is conditioned by its immediate neighbors N ( X ) . Likelihood P ( y  X  | x  X  ) describes the relation of a configuration and its corresponding observation for a given site  X  . Equation 3 shows that the configuration of site  X  is dependent on its observation and immediate neighbors only.

Inference of the MRF model can be achieved using belief propagation (BP) method. We use the topology as shown in Fig. 3 to illustrate the belief propagation and message update procedure for our MRF model. The messages in a network propagate in two opposite directions [ 13 , 28 , 37 ] which lead to two update rules for vertex  X  . 1. The procedure for calculating maximum a posteriori 2. The method to update the message from vertex  X  to ver-The prior P ( x  X  | x  X  ) and likelihood P ( y  X  | x  X  ) in Eqs. 4 and 5 are approximated as a similarity function and dependency function respectively in our MRF model and are described in detail in Sect. 4.3.2 for step I and Sect. 5.3.2 for step II.
 4 Patch level text separation (step I) The first step of our proposed method consists of three com-ponents: (i) preprocessing which segments entire document into patches and extracts features for each patch, (ii) G-means based initial classification and (iii) MRF based relabeling. 4.1 Preprocessing Our pre-processing consists of two steps: patch extraction and feature extraction. 4.1.1 Patch extraction Prior to classification, each binarized document is segmented into patches which are small snippets of the image as described in [ 29 ]. The patches are the basic units in our MRF based classification system for patch level text sepa-ration which models each document as a random field. The extraction of patches is done by using a m  X  n (5  X  5in our experiments) sized window based morphology closing operation on the original binarized image and the original content within the bounding box of each connected compo-nent is defined as a single patch. The size of the window is empirically chosen such that the resultant patch typically represents a handwritten or machine-printed word. Patches are eliminated as noise if their size is smaller than a threshold t or larger than a threshold t h .

The procedure of patch extraction for a binarized docu-ment is shown in Fig 4 . 4.1.2 Feature extraction Three different categories of features are considered for clas-sification of a given patch into one of three classes viz., hand-written text, machine-printed text and overlapped text. These features were introduced briefly in [ 29 ] and are described in greater detail in the following sections.  X  Patch level features  X  Connected component (CC) features  X  Gabor features 4.2 G-means based training and classification Training on the three different kinds of patches is carried out using a modified K-means clustering algorithm known as G-means [ 19 ].

Unlike normal K-means which is widely used in cluster-ing methods but where k has to be determined in advance, G-means estimates the number of clusters based on the dis-tribution of the training data. The underlying principle of G-Means is to split the training set using K-means with k = and if any sub-cluster does not have a Gaussian distribution, then K-means with k = 2 is applied again for this sub-cluster until each cluster has a Gaussian distribution. Further details of G-means can be found in [ 19 ].

In our training phase, we run G-means clustering algo-rithm for machine printed patches, handwriting patches and overlapped patches individually to get three sets of clus-ters and corresponding centers which construct the con-figuration set of the MRF. The total number of centers is M .
 For each cluster m , we calculate the co-variance:  X  where K m is the number of feature vectors within the cluster, y k is a feature vector belonging to this cluster and c m is the center of the cluster.

During the patch classification phase (i.e., the labeling initialization process), for each test feature vector y which is an observation in the MRF framework, we find the nearest cluster to this feature point using Mahalanobis distance D which is defined in Eq. 11 and maps the test feature point to the center of this cluster. The index of this cluster is initially assigned as the label of the corresponding vertex  X  of the graph G :
This G-means based classification can be looked at as a nearest neighbor search (NNS) with a reduced search space. The label of the test feature point can be further mapped to one of the three classes because the class to which each center belongs(handwrittentext,machineprintedtextoroverlapped text) is already known during the training phase.
From the viewpoint of the MRF, our G-means based initial classification is a vector quantization (VQ) procedure which constructs the configuration set for the MRF as described in Sect. 3 . 4.3 MRF based relabeling In practice, misclassification cannot be avoided using a sin-gle classifier due to overlaps in the feature space. There-fore, postprocessing or relabeling is needed. The intuition for relabeling is that a patch surrounded by patches from a single different class has a high probability of belonging to that class. We use a MRF which describes the statistical dependency between observed patch features and their hid-den states (label) to model different patches in an annotated machine printed document and then relabel the patches in our scenario.

In step I of the proposed method where we do word (patch) leveltextseparation,wemodeltheannotatedmachineprinted document I as the graph G defined in Sect. 3 . Each ver-tex in set V represents a patch within the document and the set of edges E connect vertices based on a neighbor system describedinSect. 4.3.1 .Therandomfield X definedinSect. 3 is consistent with the graph G and we let the set of centers which is extracted using G-means from Sect. 4.2 to be the set of all possible configurations of X , and the patch features be the observations Y .
 As described in the previous Sect. 3 , the inference of the MRFmodelisimplementedbyusingbeliefpropagationalgo-rithm which is shown in Fig. 3 . Each grey node x  X  in the hidden layer exclusively corresponds to a hidden configura-tion for a document patch and is assigned to a label m ( 0 m &lt; M ) after initial classification. Each white node y  X  is a observed feature point for that patch. In real documents, the neighbor system of patches is determined by a convex-hull based distance metric as defined in Sect. 4.3.1 but may not necessarily be located on a grid as shown in Fig. 3 . 4.3.1 Definition of neighbor system AsshowninEqs. 4 and 5 , we need to update the message and belief in the network based on a neighbor system to compute the optimal configuration for MRF X . Normally, the neigh-bor system of a MRF is based on a four-neighbors lattice connectivity. However, if we consider each patch in the doc-ument as a single vertex in the graph G which may not be rigidly located on a grid, we need to define a flexible neighbor system to represent the spatial relationship between patches.
Firstly, we define a distance metric to measure the spatial distance between each pair of patches in a document: D where [ d h ( X ,  X  ), d v ( X ,  X  ) ] represent the convex-hull dis-tance between patches  X  and  X  in the horizontal and vertical directions,  X  v is the dominant gap between words and  X  h is the dominant gap between text lines over the entire document. Dominant gaps  X  v and  X  h can be estimated using histograms. Based on spatial distance, the four closest neighbors are con-sidered for each patch. The bottom part of Fig. 8 shows the four nearest neighbors (which are represented by the four black rectangles) of the patch contained in the red rectangle.
By using the convex-hull distance metric based neigh-bor system, we can measure the similarity between patches in spatial space by taking the distance as the variable of an exponential function. In other words, the similarity to a given patch decreases exponentially as the distance increases and only patches which have the greatest similarity are considered as the neighbors of the center patch. The plot at the top of Fig. 8 shows the decrease of similarity with distance from the center patch. 4.3.2 Prior and likelihood In order to compute an optimal configuration which maxi-mizes the posterior as described in Eq. 1 , we use belief prop-agation which calculates the local maximum messages and beliefs for each vertex to achieve global maximum. To use belief propagation for a given vertex  X  , the prior P ( x  X  and likelihood P ( y  X  | x  X  ) in Eqs. 4 and 5 are modeled by a similarity function which measures the similarity of config-uration between hidden node x  X  and x  X  and a dependency function which describes the influence of the observation y  X  on its hidden node x  X  .
 The prior P ( x  X  | x  X  ) is approximated by: P ( where D x ( X ,  X  ) is the distance between two neighboring patches (which corresponds to vertex  X  and  X  in graph G ) calculated from Eq. 12 . D e ( x  X  , x  X  ) is the Euclidean dis-tance between the configurations of two patches which rep-resent the assigned centers in the feature space as described in Sect. 4.2 .  X  and  X  are two parameters that control the influence from neighbors in the spatial space and the feature space respectively (We set  X  = 0 . 1 and  X   X  X  1 . 0 , 1 . our experiment). The final prior is normalized with a linear transformation L so that P ( x  X  | x  X  )  X  X  0 , 1 ] .
Equation 13 illustrates that the influence from the neigh-bors of a patch depends not only on their spatial distance but also on the distance of the two configurations in feature space. So, in our system, belief propagation is encouraged for those patches which are close to each other in both the spatial as well as the feature space.
 Similarly, the likelihood P ( y  X  | x  X  ) is approximated by: P where D y ( x  X  , y  X  ) is the Mahalanobis distance calculated from Eq. 11 , which measures the distance from the observa-tion y  X  of vertex  X  to its assigned center x  X  in feature space. Parameter  X  controls the influence of observations and their hidden states (The final parameter of  X  we chose in our exper-iment is  X   X  X  0 . 1 , 1 . 0 ] ). The final likelihood is normalized to the range between 0 and 1 using a linear mapping L .
Equation 14 shows the relationship between the configura-tion of a given patch and its corresponding observed features. Optimal configuration for MRF is achieved by applying BP algorithm as shown in Eqs. 4 and 5 . All messages m  X , X  in these two equations are initially set to 1. During the infer-ence, the prior P ( x  X  | x  X  ) and the likelihood P ( y  X  calculated according to Eqs. 13 and 14 . The updated mes-sage m  X , X  is passed from node  X  to node  X  and updating is terminated until there is no flipping occurring during belief propagation or when maximum iteration is achieved. More details of belief propagation can be found in [ 13 ]. 4.4 Experimental results for patch level text separation Experiments were conducted on data sets generated at HP Labs to train and test for patch level text separation (step I). Precision ( P ) and recall ( R ) metrics were used to estimate the performance of the MRF based relabeling system and compare the proposed method with other classifiers. To any one of three classes, the precision and recall are defined by: P ( k ) = T P R ( k ) = where T P ( k ) is the true positive which counts the number of correctly classified patches of class k by the system, F P the false positive which counts the number of patches mis-classified as class k by the system, and F N ( k ) is the false negative which measures the number of patches classified as other classes than k but belonging to class k .

The HP Labs data set consists of binarized images of anno-tated office documents scanned at a resolution of 300 dpi. 82 documents from the HP Labs data set were used for these experiments where the fonts of machine printed text in doc-uments were mainly Calibri and Times New Roman with the size of 10 X 12 points. The handwritten text (annotations) which included arrows, brackets, circles, cross-lines, signa-tures and comments were annotated by 10 different writers. The data in the documents can be broadly classified into three classes X  X achine printed text, handwritten text, and overlap-ping text. This extremely imbalanced data set contains over 25,000 machine printed text patches, around 3,200 handwrit-ten text patches and less than 400 overlapped text patches. We used N -fold cross-validation technique to estimate the classification accuracy for patch level text separation where the data set was exclusively divided into N subsets ( N = in our experiment) and one subset was used for testing and the remaining subsets were used for training iteratively.
In Fig. 9 , we showed distributions of different type of text for the entire data set and training sets of three splits. We can see that three training sets have the similar distribution to the entire data set. Thus, the evaluation on each fold predicts the classification capability on the entire data set.
Prior to classification, a few preprocessing steps were per-formed. A morphological closing operation with a 5  X  5 window was applied and patches were extracted. This was followed by feature extraction. The G-means based cluster-ing algorithm described in Sect. 4.2 was used to extract cen-ters for the machine printed patches, handwritten patches and overlappedpatchesonthetrainingdatasetindividuallyandto construct our configuration set X . The initial classification was carried out by assigning each test patch to the nearest center in the feature space eventually mapping them to one of the three classes. The MRF based relabeling procedure was used to correct the misclassification for all patches as described in Sect. 4.3 .

In Table 1 , we compared the proposed method to a G-means based classifier and a backpropagation neural network classifier which was implemented using a modified public ANN tool, FANN [ 1 ]. The BP neural network with two hid-den layers used the sigmoid function for each neuron in the hidden layer and the sigmoid symmetric function for output the layer. The overall accuracy in the table is defined as: the number of all patches correctly classified by the system divided by the total number of patches in the test set. We see that the MRF based relabeling method had an overall accuracy of 95 . 52% which outperformed the backpropaga-tion neural network (91.72%) as well as the G-means based classifier (94.16%). The precision and recall, especially for the two minor classes (handwritten text and overlapped text), werealsoincreasedbyusingtheMRFbasedlabelingmethod.
In Table 2 , we showed the  X  X rror Reduction Rates X  which were defined as: ( k ) = F N r ( k ) = F N g where r denotes the reduction rate of misclassified patches between Neural network and the MRF based method for a given type of text. F N r ( k ) is the false negative of class k by using Neural network and F N t ( k ) counts the false neg-ative by using MRF based method. Similarly, g calculates the error reduction rate between G-means based method and the proposed method. As shown in the table, by using the MRF based method, the error rate reduced to around 45 and 20% for machine printed text compared with Neural net-work and G-means based method. The error reduction rates for handwritten text and overlapped text were also decreased effectively in the table.

Figure 10 shows results of the MRF based text identifi-cation on a sample image from the HP Labs data set where the original binarized document (Fig. 10 a) is decomposed to handwritten text document (Fig. 10 b), overlapped text document (Fig. 10 c) and machine printed text document (Fig. 10 d).

To illustrate the effectiveness of the MRF based label-ing, we showed three example results of machine printed text extracted by different methods. As shown in Fig. 11 ,BP Neural network based classification algorithm only consid-ered the features of every single patch. Thus some machine printed text were misclassified as other type of text, such as word X  X creenSize X , X  X oard X  X nd X  X aptop X ,eventhesewords were among the context of machine printed text. Due to the smoothness effect, MRF based method obtained better clas-sification performance than Neural network and G-Means based method, especially in the case of that a large amount neighboring text were from the same class.

In our experiment, the patches which contained several touched words by underline, rule-line or noises were labeled as machine printed but were typically classified by the system as overlapped patches as shown in the Fig. 10 c. The machine printed text were easily classified as overlapped text in our system either if the size of text was big or the font of text was bold. Most misclassifications for handwritten patches and overlapped patches happened in the case of isolated hand-written patch or overlapped patch surrounded by machine printed patches which was smoothed by MRF.

The relatively low precision for handwritten text and over-lapped text is mainly due to the imbalanced nature of the HP Labs data set. The amount of machine printed text is much more than the handwritten annotations and overlapped text and dominates in the data set. If even a small propor-tion of the machine printed text is misclassified as one of the other two classes, it is still a significant number when compared to the handwritten or overlapped text samples and hence leads to low precision. A tree-structured initial classi-fier could perhaps be used to overcome the imbalanced data set problem and we propose to test this in future work. 5 Pixel level text separation (step II) As shown in Fig. 2 , the second step of our proposed method takes as its input the overlapped text from step I. Since the overlapped text is considered as a single unit in step I, its basic element (patch) and the features for patches are not suitable to further segment the overlapped text into machine printed and handwritten text. In this section, we propose a method to decompose the overlapped text image into smaller units using a coarsening procedure, which aggregates foreground pixels of the overlapped text image according to their coher-ence properties [ 30 ]. Shape context, a pixel level feature, is used to measure the coherence or variance between pixels or aggregations. The MRF based segmentation of overlapped text is based on these small aggregations which are the basic element in step II. 5.1 Shape context features Prior to coarsening pixels to aggregations, we first extract features at each pixel. We use shape context features to char-acterize each pixel or aggregation. Shape context features were first used by Belongie et al. [ 4 ] to compare the similar-ity between two shapes.

Given a shape which contains a set of points, we can draw vectors from a given point on this shape to each of the other points and the shape can be exactly represented by these vec-tors. Shape context features were inspired by this notion but instead of using vectors to characterize each point on the shape, shape context features tend to capture the coarse dis-tribution of the rest of the points on a shape with respect to a given point.

To compute the shape context features v i , j for a fore-ground pixel whose coordinate is ( i , j ) , a polar system is centered on this pixel which divides the entire image into several small bins. The feature v i , j is obtained by calculat-ing the number of foreground pixels within each bin. More details of computing shape context features can be found in [ 4 ].

Figure 12 illustrates two examples of computing histo-grams for two different points on the same shape by center-ing the polar coordinate system on the points. The bottom part of each polar system shows the extracted shape context features where each colored rectangle corresponds to a bin in the polar system and darker color represents a larger value. In our experiments, we use three circles and eight quadrants to divide the overlapped text patch into 24 bins as shown in Fig. 12 . 5.2 Aggregation coarsening In order to separate overlapped text, we propose a coarsening procedure by which foreground pixels in the overlapped text are grouped to aggregations, which have coherent attributes (similar feature for each foreground pixel within aggrega-tion) and can be used as the basic element for training and classification.

We assume an overlapped text image I is modeled by a graph G = ( V , E ) , where each vertex corresponds to an aggregation which contains a set of neighboring foreground edges E connect vertices based on four-neighbors lattice con-nectivity.

For each vertex  X  , we measure its coherence by using the corresponding aggregation.

Then we define the diversity between two adjacent verti-ces  X  and  X  as the difference of their mean values:  X 
By using variance  X   X  within a vertex  X  and difference  X   X , X  between two adjacent vertices  X  and  X  , we define a criterion as presented in Eq. 20 to determine which neighboring ver-tex needs to be merged with a given vertex  X  to create a new single vertex (aggregation).  X   X  = arg max where  X   X  N ( X ) represents the neighbors of vertex  X ,  X   X  N ( X )  X   X  represents all neighbors of the vertex  X  but excludes vertex  X  , X  means a test vertex which is merged by vertex  X  test new merged vertex (  X  merged with  X  ).

The underlying principle of Eq. 20 is that a vertex  X  is tem-porarily merged with its immediate neighbors  X  individually to create a set of candidate vertices {  X  } whose variances are {  X   X  } . Then, the vertex  X   X  whose average feature value is close to vertex  X   X  X  average feature value and minimizes the variance of the new merged vertex  X  is the optimal vertex which should be merged with  X  .

Based on this criterion, we can extract aggregations start-ing from a single pixel to produce larger coherent coarsened regions. Figure 13 shows the procedure of coarsening. Ini-tially, each aggregation for the vertex  X  contains only one pixel and all vertices V in graph G are pushed in a queue Q . Prior to executing the main loop of the coarsening proce-dure, the size t of all vertices is checked and the first vertex whose size is smaller than a pre-defined threshold  X  is picked as the working vertex. The working vertex  X  is merged with an optimal immediate neighbor according to Eq. 20 to pro-duce a new vertex which is stored at the end of queue Q and its neighbors are inherited from its two parent vertices. The two merging vertices are removed from the queue Q and the neighbor system for graph G is also updated accordingly. The iteration of coarsening is stopped when every vertex X  X  size is bigger than threshold  X  which is set to 130 in our experiment.

Figure 14 shows an example of coarsening for an over-lapped text image where machine printed text is circled and touched by handwriting. Figure 14 a is the original bina-rizedoverlappedtextimage.Figure 14 bshowsthecoarsening result after first iteration when every pixel is coarsened with its neighbor at least once. Figure 14 c shows the aggregations after the third round of iteration and Fig. 14 d is the final coarsening result. The aggregations are randomly colored in these figures. 5.3 MRF based classification 5.3.1 Modeling overlapped text using MRF Markov Random Field model is reused in step II to separate handwritten text from an overlapped text image. As shown in Sect. 3 , a key step in the usage of MRF is the defini-tion of the random field X , the hidden configuration set and the observations Y . Unlike the definition of an MRF for the entire document in Sect. 4.3 where each vertex in the MRF corresponds to a text patch, the overlapped text image is modeled as a random field whose nodes represent aggre-gations extracted using the coarsening algorithm from Sect. 5.2 . To build the configuration set , G-means clustering algorithm is used as a vector quantization (VQ) procedure to separate the training set into several small clusters and the center of each cluster is used to build a codebook to repre-sent the configuration set . The observations Y for each vertex is obtained by normalizing each aggregation to the size of 16  X  16. The neighbor system for the MRF of step II is inherited from the coarsening algorithm where the neigh-bors of each vertex are its direct connected vertices based on the four-neighbors lattice connectivity relation. 5.3.2 Prior and likelihood Similar to step I which uses Belief Propagation (BP) algo-rithm to obtain the optimal configuration X for MRF in Sect. 4.3 , our MRF based classification for overlapped text also achieves the optimal configuration based on Eq. 2 but re-models the prior P ( x  X  | x  X  ) and likelihood P ( y  X 
The prior P ( x  X  | x  X  ) which is approximated by a simi-larity function in our MRF based overlapped text separation step is modeled as: P ( x  X  | x  X  )  X  L ( t {  X  f ( x  X  , x  X  ) +  X  e  X  D e ( x  X  where x  X  , x  X   X  are two configurations assigned to vertex  X  and  X  respectively and satisfy  X   X  N ( X ), t is the size of vertex  X  which indicates the number of pixels contained in the corresponding aggregation represented by the vertex  X  f ( x  X  , x  X  ) is the function that counts the pairwise occurrence frequency of configurations of x  X  and x  X  for the neighbor-ing vertex  X  and  X  in training set, and function D e ( x  X  measures the Euclidean distance between two configurations (corresponding cluster centers) in the feature space respec-tively. Parameters  X  and  X  control the strength of the influ-ence from these two terms on vertex  X  (We set  X  = 0 . 05 and  X  = 0 . 01 in our experiment for overlapped text separation).
Equation 21 indicates that for two neighboring vertices  X  and  X  , two aggregations which co-occur frequently in the training set and whose configurations are close to each other in the feature space are encouraged by our criterion. The size t in this equation shows that a larger vertex has more influence on its neighbors.

The final prior P ( x  X  | x  X  ) is normalized to the range between 0 and 1 using a linear mapping L .

The likelihood P ( y  X  | x  X  ) in Eq. 2 is modeled by a depen-dency function which can be approximated as: P ( y  X  | x  X  )  X  1 where x  X  is a configuration assigned to vertex  X , D e ( x  X  is an Euclidean distance function to measure the distance from an observation to a configuration x  X  for vertex  X  .This equation represents the probability of a configuration for a vertex given its observation y  X  .
 The same belief propagation algorithm as described in Sect. 3 is used again for step II to get the optimal configura-tion X . The final classification result is obtained by mapping the optimal configuration to two classes (machine printed text and handwritten text) as their relationship is already known during the G-means clustering procedure. 5.4 Experimental results for overlapped text separation To estimate the performance of MRF based classification algorithm for overlapped text separation, we used the same morphology closing operation as step I to collect a total of 330 overlapped patches (including crosses, edit marks and other annotations within a single patch) from the HP Labs data set. The set of overlapped patches was exclusively split into three subsets and each subset was used for testing and the remaining for training iteratively. Figure 15 shows the similar distributions of machine printed text and handwritten text for different training sets.

In the training phase, the coarsening method described in Sect. 5.2 was used to extract aggregations for training Recall data followed by a vector quantization procedure based on G-means clustering to construct the configuration set for machine printed text and handwritten text.

A similar coarsening procedure was applied on the test data samples to extract aggregations for each vertex  X  to build the MRF to model the overlapped text patch.
PriortoMRFbasedclassification,isolatedcharacterswere filtered out based on an estimation of their size. The MRF classification described in Sect. 5.3.2 was implemented to segment overlapped text patch into machine printed and handwritten text.

We measured the performance of the MRF classification algorithm for step II using the recall metric and precision metric. The recall for machine printed text is defined as the ratio of the amount of pixels which are correctly classified as machine printed text to all machine printed pixels in the test set. The precision for machine printed text is defined as the ratio of the amount of pixels which are correctly classi-fied as machine printed text to all pixels which are classified as machine printed text. The same metrics were applied to handwritten text.

Figure 16 shows the recall curves of machine printed text andhandwrittentextduringBPiterationofclassification.The recall for handwritten text increased 27.72% and the overall accuracy increased 4.38% from the start of BP.

We compared the proposed MRF based segmentation algorithm with an artificial neural network classifier which was implemented using FANN [ 1 ]. The neural network had one hidden layer which used sigmoid function for each hid-den neuron in our experiment. Table 3 shows that our MRF based method achieved higher overall accuracy as well as higher accuracy on handwritten text than FANN.
 Figure 17 shows sample segmentation results from step II. Red strokes represent handwriting and black strokes rep-resent machine printed text.

The main reason for the misclassification of overlapped text in step II of proposed method is that although the coars-ened aggregations have coherent attributes, their sizes are determined by a predefined threshold  X  which causes them to not be strictly along the edges of areas where the machine printed text and handwriting intersect. Using a heuristic method to calculate an optimal threshold for each overlapped text segment and applying a shape-driven coarsening algo-rithm to restrict the growth of aggregates along certain direc-tions should improve performance. 6 Conclusions In this paper, we propose a novel MRF based framework to classify three different kinds of text (machine printed text, handwritten text and overlapped text). The proposed method contains two individual steps. In step I, where a document image is segmented into handwritten, machine printed and overlapped text, a distance function is defined to measure the spatial distance between patches which is used to construct the neighbor system for MRF. Unlike other relabeling sys-temsthatonlyconsidertheneighboringrelationshipinspatial space, our model uses distances from both feature space and spatial space to determine the similarity of two neighbors. A similar MRF framework is used in step II to further separate the overlapped text into machine printed text and handwritten text. In step II, we propose a coarsening procedure to extract the basic element for classification. The merit of the proposed MRF framework is that it is easy to integrate other classifi-ers which can provide a reliable distance measure in feature space into our system as an initial classifier. The experimen-tal results show that the proposed method outperforms other methods upon the accuracy. Our future work includes the use of other classifiers to overcome the issue of imbalanced data sets, and development of better algorithms for shape-driven coarsening.
 References
