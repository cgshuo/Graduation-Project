 ORIGINAL PAPER Mohamed Benjelil  X  Slim Kanoun  X  R X my Mullot  X  Adel M. Alimi Abstract Page segmentation and classification is very important in document layout analysis system before it is presented to an OCR system or for any other subsequent processing steps. In this paper, we propose an accurate and suitably designed system for complex documents segmenta-tion. This system is based on steerable pyramid transform. The features extracted from pyramid sub-bands serve to lo-cate and classify regions into text (either machine-printed or handwritten) and non-text (images, graphics, drawings or paintings) in some noise-infected, deformed, multilingual, multi-script document images. These documents contain tab-ular structures, logos, stamps, handwritten script blocks, photographs, etc. The encouraging and promising results ob-tained on 1,000 official complex document images data set are presented in this research paper. We compared our re-sults with those from existing state-of-the-art methods. This comparison shows that the proposed method performs con-sistently well on large sets of complex document images. Keywords Steerable pyramid  X  Complex document segmentation  X  Multi-resolution analysis  X  Invariant features 1 Introduction In the face of the very important mass of information exchanged between different organizations, the need for sys-tems allowing the recognition, the indexation, the informa-tion retrieval and the automatic classification of complex multi-lingual and multi-script document images has grown continuously. However, most works of retro-conversion of printed Arabic document images are limited to textual block recognition without handling complex documents such as letters of information, forms, all types of application sheet, etc. In practice, these documents can be noised Fig. 7 a, skewed, deformed Fig. 11 a, multi-lingual Fig. 11 g, multi-script Fig. 11 m, with irregular textures and may contain sev-eral heterogeneous blocks such as annotations, machine print and/or handwritten script, graphics, pictures, logos, photo-graphs, tabular structures. This situation makes it difficult to analyze and recognize document images.

In addition, most of the methods of page segmentation and layout analysis described in the literature rely on prior knowl-edge or assumptions about generic document layout structure and textual and graphical attributes. Utilizing such knowl-edge results in simple, elegant and efficient page decompo-sition systems but also limits the range of applicability of the algorithm. Noise and degradation, multi-directional and curved text lines, gray-level or inverted text, complex layout structure, and differences in language, font size and other textual attributes are among the problems that limit most model-based approaches. Therefore, in some applications, it is desirable to have segmentation methods that do not rely heavily on apriori knowledge about the content or attributes of the document. Although several texture-based methods have achieved high content-based image retrieval rates [ 30  X  32 ], some of them were evaluated under controlled scenar-ios. In this context, the next challenge consists in achieving rotation and scale-invariant feature representations for non-controlled environments. Based on these observations, we propose a texture segmentation-based method. Our algorithm does not assume the availability of any information about the layout and can, in general, be applied to any document type (check, memo, journal, newspaper, etc.).

In this paper, we essentially focus our interest on the seg-mentation of complex document images in text and non-text regions. Text and non-text regions in a document image are regarded as two classes of texture. Multi-resolution multi-channel steerable pyramid decomposition is utilized as input to a text and non-text regions classifier. A distinctive fea-ture of this work, compared to other texture segmentation problems, is that there is large intra-class as well as inter-class variation in textural attributes. The multi-scale nature of the document constituents (e.g. characters, lines) justi-fies the use of a multi-scale representation and classification scheme. Our motivation in using steerable pyramids relies not only on the fact that they have demonstrated discrim-ination properties for texture characterization [ 1 ] but also that, unlike other image decomposition methods, the feature coefficients are less modified under the presence of image rotations or even scales. Experimentations demonstrate the performance of our propositions and the advances that they represent in terms of characterization of content of a deeply heterogeneous corpus.

The rest of the paper is organized as follows: related previ-ous works for document segmentation and zone classification are presented in Sect. 2 . In Sect. 3 , we present an overview of the steerable pyramid decomposition. Section 4 describes our segmentation strategy, experimental results and perfor-mance analysis are presented in Sect. 5 , and future works and conclusion are provided in the last section. 2 Related works Various schemes of page segmentation have been proposed by researchers. One of the most well-known approaches for page segmentation is the one of connected components aggregation [ 2 ]. Connect component-based algorithms fall in the category of bottom-up segmentation algorithms. Simi-lar components are iteratively grouped together to form pro-gressively higher-level descriptions of the printed regions of the document such as words, lines and paragraphs [ 3 ]. Other approaches use the description of white space to iden-tify homogeneous regions. In [ 4 , 5 ], the authors use the con-tours of the white space to delineate the boundary of text and image regions in the page. In most of the other approaches in the literature, researchers make assumptions about the gen-eral layout of the document page to be segmented. Some assume that the text or image blocks may only be rectangu-lar [ 6 ], while others may assume that sentences in text are all evenly spaced. Others assume that the document belongs to a specific category, such as a newspaper [ 7 ] or a technical article [ 8 ]. In [ 9 ], a text-image-structure-analysis, analogous to a document structure analysis, is needed to enable a text information extraction system to be used for any type of im-age, including both scanned document images and real scene images.

However, making such assumptions restricts the applica-bility of the page segmentation scheme to a limited number of document classes. These methods cannot work in a generic environment as they work on an assumption that the prior knowledge of the document model is available [ 10 ]. In [ 11 ], most of the work makes use of deterministic models. Such models fail in the presence of noise or ambiguity. Much of the work on logical structure analysis of documents assumes that physical layout analysis has already been performed. In some of the work, quantitative performance evaluation issues have been neglected. Texture analysis is often used as a means to finalize the segmentation of an image. Indeed, in the case of natural images, the only study of the distribution of gray levels is insufficient to characterize homogeneous zones.
Texture analysis plays a significant role in many im-age processing and pattern recognition applications such as remote sensing, cartography, robot vision, military surveil-lance and medical imaging. Over the years, many approaches for texture characterization have been developed for analy-sis [ 12  X  14 ] and synthesis [ 15 ]. Traditional texture charac-terization is based on extracting some statistic features from the pixel domain data (using histograms, autocorrelation and moments).

In addition, the co-occurrence matrix is a popular statis-tical technique for extracting textural features. It has been first proposed by [ 16 ] for texture characterization and used in the analysis and classification of many types of texture im-ages [ 17 , 18 ]. Furthermore, the texture image was modeled in several techniques as a Markov random field of pixels gray level, where the relationships between the gray levels of neighboring pixels are statistically characterized [ 13 , 19 ]. In [ 13 ], a probabilistic texture model using a Gauss X  X arkov random field has been proposed for hyper spectral textures characterization. Also, multi-resolution models for Gauss X  Markov random fields with applications to texture charac-terization were proposed in [ 20 ] and applied for texture segmentation. In spite of this, feature-based approaches have been proposed during the last two decades which is some-times less computationally demanding and more effective than Markov random field-based approaches. Textural fea-tures are typically extracted by using spectral information [ 13 ], wavelet basis functions [ 21 ] and Gabor filters [ 12 , 22 ]. Two-dimensional Gabor filters have been proved to be an important tool in texture analysis. They consist of a sinusoi-dal plane wave of some frequency and orientation modulated by Gaussian envelope. A Gabor filter is a band-pass filter, which can be used to extract a specific band of frequency components from an image [ 23 ]. Gabor functions appear to share many properties with the human visual system [ 24 ]. They are used as non-orthogonal basis functions for signal representation. Their magnitude responses in the frequency domain are well behaved, having no side lobes [ 17 ]. In [ 25 ], the authors compare several texture features based on the local power spectrum obtained by a bank of Gabor filters. These features are as follws: Gabor energy, complex mo-ments and grating cell operator features. It has been shown that the grating cell operator gives the best discrimination and segmentation results. In [ 26 ], the authors proposed a modification of two existing texture-based techniques such as Gabor feature-based method &amp; Log polar wavelet sig-nature method with the inclusion of Harris corner detectors for document images. Connected component analysis in bi-narized images has been used in [ 27 ] to segment non-text areas based on the size information of the connected regions. A Gabor function-based filter bank is used to separate the text &amp; non-text areas of comparable size. More recently, Ga-bor filters and gray-level co-occurrence probability features have been fused in [ 22 ] to improve the texture recognition and segmentation. It has been also shown in [ 12 ] that for noisy texture recognition, the features based on Gabor filters outperform the discrete Fourier transform features. Wavelets are another type of filter family. They are constructed from a mother wavelet, which can be any admissible function (a function with no DC component; the Fourier transform of that function evaluated at 0 is 0). A family is constructed by dilating and translating the mother wavelet by different amounts. [ 28 ] proposed globally matched wavelet filters with Fisher classifiers for text extraction from document images and scene text images. [ 29 ] employed Haar wavelet transform to detect edges of candidate text regions, which is followed by the application of dilation operators, and this method can handle caption text images. The advantage over simply using the Fourier transform for frequency analysis is that wavelets respond better to discontinuities (that is, edges) and spikes. Prominent examples of wavelet families are the Daubechies, Coiflet, Haar and Symmlet. The Daubechies family is of par-ticular interest because it is fractal in nature, as is the Haar because it is shaped like a simple square wave. More recently, a novel approach for texture characterization and synthesis based on Textons (texture elements) was proposed in [ 15 ] where textures are assumed to be composed of three compo-nents, namely illumination, structure and stochastic.
Even though the previous approaches present some advan-tages, there are drawbacks to these schemes. We can sum-marize these drawbacks as follows:  X  Although several methods have achieved high content- X  Furthermore, it is observed that some second order non- X  Typical classification processes utilizing only the original  X  Moreover, design of the appropriate filters to separate text  X  The parameters setting such as frequency, orientation and  X  X n[ 38 ], although the algorithm segments out the image
In this context, the next challenge consists in achiev-ing rotation, and scale-invariant feature for non-controlled environments document image segmentation. In this paper, we propose a new approach to the document segmentation, which is based on steerable pyramid decomposition. The steerable pyramid model has been proposed by [ 39 ]asa rotation-invariant texture model. Indeed, a rotation-invariant image retrieval scheme based on a transformation of the texture information via a steerable pyramid has been also pre-sented in [ 40 ] where the distributions of the sub-band coeffi-cients are exploited to capture their non-Gaussian behavior. New rotation and scale-invariant representations for texture image retrieval based on steerable pyramid decomposition have been proposed in [ 41 ]. In this approach, the texture feature vectors are extracted by calculating the mean and standard deviation of decomposed image sub-bands [ 41 ]. The steerable pyramid performs a polar-separable decom-position in the frequency domain, thus allowing independent representation of scale and orientation. More importantly, the representation is translation-invariant (i.e., the sub-bands are aliasing-free) and rotation-invariant (i.e., the sub-bands are steerable). This can make a big difference in applications that involve representation of position or orientation of im-age structure. Steerable pyramids mostly avoid the problem of aliasing or the confusion of low and high frequency com-ponents. Table 1 summarizes the main advantages of steer-able pyramid decomposition over four approaches for texture characterization. 3 Steerable pyramid (S.P) 3.1 Presentation Steerable pyramid decomposition [ 42 ], is a linear multi-ori-entation, multi-resolution image decomposition method, by which an image is subdivided into a collection of sub-bands localized at different scales and orientations. The synoptic diagram for a first level image decomposition using steerable pyramid is shown in Fig. 1 . Using a high-pass and low-pass filter ( H 0 , L 0 ) , the input image is initially decomposed into two sub-bands: a high-pass and a low-pass sub-band, respec-tively. Further, the low-pass sub-band is decomposed into K -oriented band-pass portions B 0 to B K  X  1 and into a low-pass sub-band L 1. The decomposition is done recursively by sub-sampling the low-pass sub-band by a factor of 2 along the rows and columns. The recursive construction of a pyra-mid is achieved by inserting a copy of the shaded portion of the diagram at the location of the solid circle. Each recursive step captures different directional information such as vari-ation of a texture in both intensity and orientation at a given scale.

The basic functions of the steerable pyramid are direc-tional derivative operators that come in different sizes and orientations. The simplest example of this is the oriented first derivative of Gaussian. Consider the two-dimensional circu-larly symmetric function G written in Cartesian coordinates x and y: G The scaling and normalization constants have been set to 1 for convenience. The directional derivative operator is steerable as is well known [ 43 , 44 ], let us write the n th derivative of a Gaussian in the x direction as G n .Let (. . .)  X  represent the rotation operator such that for any function f ( x , y ), is f ( x , y ) rotated through an angle  X  about the origin. The first x derivative of a Gaussian G 0  X  1 is G The same function, rotated 90  X  ,is G These functions are shown in Fig. 2 . It is straightforward to show that a G 1 filter at an arbitrary orientation  X  can be synthesized by taking a linear combination of G 0  X  1 and G G ters for G  X  1 . The cos ( X  ) and sin ( X  ) terms are the correspond-ing interpolation functions for those basis filters. Because convolution is linear operation, we can synthesize an image filtered at any arbitrary orientation by taking linear combina-resent convolution and I the input image, for R 0  X  1 = G and R 90  X  1 = G 90  X  1  X  I , the resulting image is R 3.2 Filters design Considering the polar separability of the filters in the Fourier domain, the first low-pass and high-pass filters are defined as [ 45 ]: L H where r , X  are the polar frequency coordinates. L ( r , X ) H ( r , X ) are raised cosine low-pass and high-pass transfer functions, respectively:
L ( r , X  ) = H ( r , X  ) = The band-pass filter B k ( r , X ) at each orientation k is com-posed of radial part H ( r ) and angular part G k ( X  ) : B ( r , X ) = H ( r ). G where G And  X  K is a constant for a fixed K , which is defined as:  X  For instance, an example of one-level image decomposition can be found in Fig. 3 , where four band-pass filters are in-volved.
 3.3 Example Figure 4 gives an example of steerable pyramid decomposi-tion of three input images. The first one is for machine-printed Arabic word; the second is for machine-printed Latin word. The third one is for a photograph. Each pyramid has 3 levels and 4 orientations.

We tested the S.P on 300 images of text blocks and 300 images of non-text objects (images of natural scene). For each image sub-bands, we calculated the variance, the mean, the homogeneity and energy. Each marker in the scatter plot, Fig. 5 , represents an observation, and its position shows the values of mean and standard deviation for that observation. This figure shows how the statistical measurements differ between text and non-text objects. This means that the S.P features have a distinguishing capability between text and non-text objects. Since the complex document images are basically constituted by such types of objects, we decided to use the S.P features in the classification part of our segment system. 4 Segmentation strategy We consider text and non-text as regions with different tex-tures. Since the distinguishing characteristics of text are frequency information, orientation, approximately with the same size and line thickness, located at a regular distance from each other, we can use them to characterize machine-printed text regions. Handwritten script and annotations detection is more difficult to implement than machine-printed text due to the diversified human handwriting styles and cus-toms. To overcome this problem, our system must satisfy the following conditions:  X 
Robust to transformations X  X he image features should be as invariant as possible to image transformations including translation, rotation and scaling, etc.  X 
Feature extraction efficiency X  X mage features can be com-puted efficiently  X  A representative training data set.
 In order to satisfy the two first conditions, we used the steer-able pyramid decomposition due to its invariance to transla-tion, rotation and scaling [ 42 ]. To satisfy the third condition, we used a representative training data set containing, in addi-tion to machine print text, handwritten script with different sizes, orientations and writing styles. Figure 6 shows the syn-optic diagram of proposed system. 4.1 Preprocessing Some preprocessing operations are required before the ensu-ing document segmentation. First, document content must be segmented from the background and we adopt Otsu X  X  [ 58 ] global thresholding technique for document binariza-tion. Second, we used a classical filtering technique such as morphological operators that remove isolated small objects without removing texts diacritic points. Figure 7 ashowsthe noisy input image, while Fig. 7 b shows the filtered image. 4.2 Regions labeling, mask generation and application Since text shows spatial cohesion, characters appear in clus-ters at a regular distance aligned to a virtual line. By merging characters inside each cluster by image dilatation with suit-able horizontal and vertical structuring elements, we can cre-ate a document mask Fig. 8 b. This mask will serve to extract corresponding regions from original image. We applied the steerable decomposition on each region. Each region will be classified as text or non-text based on feature values obtained from pyramid sub-bands. Figure 8 c shows some samples of words and images and their corresponding S.P decomposi-tion. Figure 8 d shows the final result. 4.3 Features extraction The document image is decomposed into 3 levels (1, 2 and 3) and 4 orientations ( 0  X  , 45  X  , 90  X  and 135  X  ) for sub-bands, using the steerable pyramid transforms. This configuration gives 12 sub-bands (3 levels  X  4 orientations). The feature vector Eq. ( 13 ) (with dimension 48 to represent 12 sub-bands) was constructed based on the computed mean  X  mn Eq. ( 14 ), the standard deviation  X  mn Eq. ( 15 ) of the transformed re-gion image and the energy E mn Eq. ( 16 ), and the homogene-ity H mn Eq. ( 17 ) calculated from gray-level co-occurrence matrix applied to the same transformed region image. This feature vector is defined as: Mean  X  = Standard deviation  X  2 = Energy E = Homogeneity H = 4.4 Classification To classify the extracted regions into text or non-text classes, we tested three classification methods. In the first method, we used a non-supervised k -means classifier with two clas-ses based on regions detected in a single document, one for the text and the other for the non-text. We consider the class that includes more items as the text class. This is justified by the idea that in a document, the number of textual regions is greater than the number non-textual ones. In the second method, we used a supervised K nearest neighbor X  X  classi-fier (KNN) with different values of K (3, 5, and 7). In this framework, starting with 4,664 text block images and 1,258 graphic blocks, we choose 600 text block images and 600 graphic blocks as training data set. Figure 8 c shows some samples of extracted regions and their corresponding S.P transform, Fig. 8 d shows the final segmentation result. In the third method, we used a Na X ve Bayes classifier with reject op-tion. This classifier is based on Gaussian distribution. Maxi-mum likelihood estimation is used to calculate the means and variances of each class. The class conditional probability den-sity functions p ( x | C ) is then calculated using the multivariate Gaussian distribution. Finally, the posterior probabilities are calculated using Bayes rule: P ( C | x ) = P ( C ) where, P ( C ) = Prior probability of training data C P ( x | C ) = Probability of x given C P ( C | x ) = Probability of C given x The class of an example is decided by calculating the maxi-mum posterior probabilities of classes. The conditional inde-pendence of the attributes of the instances is required for the use of naive Bayesian classifiers. Na X ve Bayes classifiers assume that the effect of a variable value on a given class is independent of the values of other variables. This assump-tion is called class conditional independence. It is made to simplify the computation and in this sense considered to be  X  X a X ve X . Let x i = (a1, a2... an) denote the ith instance of test set and c j denote the jth target class.

Naive Bayes assumption: c = max = max = max c = max P ( c 4.5 Rejection Scheme The goal of rejection is to improve the classification accuracy by rejecting patterns for which the classifier has low confi-dence. The ambiguity reject option can be formalized for the Bayesian classifiers as follows. Let p ( ci | x ) represent the pos-terior probability of class ci given x . Then pattern vector x is classified into class ci if the following conditions are satis-fied (i) p ( ci | x )  X  p ( cj | x ),  X  j = i ; (ii) p ( ci where t represents the threshold for the ambiguity rejection. denote C(Text), C(Non-text), the condition for classifying the input region image as Text and Non-Text, respectively. P ( a 1 , a 2 ... a n | c j ) =
Figure 9 presents cascade architecture for combining one-class classifiers. Region images are processed by the cascade as follows: each input region image is initially presented to the first stage, S 1. If the classification output exceeds the first-stage threshold, t , then it is classified by the first stage and processing stops. If not, then the sample is rejected (by the first stage) and is passed on to the next stage. This process is repeated till the sample gets classified by some stage or it is ultimately rejected.
In order to evaluate the performance of our classifier, we operated it at different reject rates; the ambiguity threshold was varied from 1 to 0. We used the receiver operating char-acteristic (ROC) curves which are two-dimensional graphs that visually depict the performance and performance trade-off of a classification model [ 46 ]. The area under the ROC curve (AUC) is a scalar measure gauging one facet of per-formance. To draw a ROC curve, only the true positive rate TPR, as x axis, and false positive rate FPR, as y axis, are needed. TPR determines a classifier performance on classi-fying positive instances correctly among all positive samples available during the test. FPR, on the other hand, defines how many incorrect positive results occur among all nega-tive samples available during the test. TPR is equivalent with sensitivity and FPR is equal to 1-specificity. Each prediction result or one instance of a confusion matrix represents one point in the ROC space. The best possible prediction method would yield a point in the upper left corner or coordinate (0, 1) of the ROC space, representing 100% sensitivity (no false negatives) and 100% specificity (no false positives). The (0, 1) point is also called a perfect classification. The diagonal line divides the ROC space in areas of good or bad classi-fication/diagnostic. Points above the diagonal line indicate good classification results, while points below the line indi-cate wrong results. Let us look into our system prediction results in Fig. 10 , the area under the ROC curve (AUC) of 0.86 and area under convex hull of 0.907 was satisfactory. Since high-quality tests will have an AUC-ROC approaching 1, we can consider our results as satisfactory. 5 Results and performance analysis 5.1 Experimentation Set-up This algorithm has been tested over a corpus of 1,000 images with 3 sets of images and various metrics have been evaluated from tested results.  X  Set1 contains 350 dispatch notes.  X  Set2 contains 350 forms  X  Set3 contains 300 newspapers
The S.P parameters used are sp3filter with 3 levels (scales) and 4 orientations [ 42 ]. 5.2 Performance Analysis Metrics used to evaluate the performance of the system are precision, recall and F -score. Precision and recall rates have been computed based on the number of correctly detected regions in an image in order to evaluate the efficiency and robustness of the algorithm and the metrics are as follows:  X  Precision rate (P) is defined as the ratio of correctly de- X  False positives (FP) / false alarms are those regions in  X  False negatives (FN)/ misses are those regions in the im-F -score is the harmonic mean of recall and precision rates as represented in Eq. ( 26 ).
 F  X  Score = 2  X  precision 5.3 Results In Fig. 11 , we tested our segmentation method for different document images types: original images are on the left and segmented image mask are in the middle. The output of the text/non-text segmentation is on the right. The first example is for a noisy and skewed official document image. The sec-ond document image is for a magazine with non-Manhattan layout. The third document image is for a form with bilingual content (Arabic and French machine-printed text). The fourth document image is for a form with inversed machine-printed text regions and non-Manhattan layout. The fifth example is for a noisy and skewed official document image with mixed machine print and handwritten script. From Table 2 , we can see that the na X ve Bayes classifier achieves the highest accuracy with F -score 95.03%. The k -means follows it with F -score 93.44%. The KNN classifier with K = 5, achieves the lowest accuracy with F -score 88.56%. The segmentation results by type of document with k -means, KNN and Bayes classifier are presented in Tables 3 , 4 and 5 , respectively. From these tables, we can see that the highest segmentation rates are obtained with forms, while the lowest segmentation rates are obtained with newspapers. This is justified by the complexity of newspapers when compared with forms. The na X ve Bayes classifier achieves the highest accuracy for the three types of documents. It excels if there are many equally important features that jointly contribute to the classification decision. Na X ve Bayes X  X  main strengths are its efficiency and its robustness to noise features.

The overall segmentation rate is about 92.34%. This is reasonable at this stage, and we can afford adding some preprocessing and more improved feature selection. The quality and the reliability of our segmentation method are sensitive to some kinds of acquired noises that form a certain texture, which can be mistaken for the texture of a textual zone of the document image. 5.4 Robustness to skew The skewed document image is another challenge for our segmentation system. To try out the robustness of our system to skew, we skewed the input document images by an angle h. This skew angle was ranged from 0  X  to 7  X  . We extracted the pyramid features at different skew angle values. Table 6 shows the variation in identification rates corresponding to skew angle variation. Despite the degradation of document images, we note that the overall identification rates are main-tained at certain reasonable bounds. This is a result of steer-able pyramid invariance to rotation. The actual results can be considered as satisfactory. The experimentation set-up is as follows:  X  Filter: Sp3filter  X  Number of levels: 3  X  Number of orientations: 4 ( 0  X  , 45  X  , 90  X  and 135  X  Classifier: KNN with K = 5 5.5 Comparison with other segmentation techniques 5.5.1 Performance evaluation methodology In order to evaluate the performance of our system, we com-pared it with Docstrum [ 47 ] and X X  X  cut [ 48 ] algorithms for page segmentation. The performance evaluation method used is based on counting the number of matches between the entities detected by the algorithm and the entities in the ground truth [ 49 , 50 ]. We use a global MatchScore table for all entities whose values are calculated according to the inter-section of the ON pixel sets of the result and the ground truth (a similar technique is used at [ 51 ]).

Let I be the set of all image points, G i the set of all points inside the i ground truth region, R j the set of all points inside the j result region. Table MatchScore represents the matching results of the I ground truth region and the j result region as follows: MatchScore ( i , j ) = The performance evaluator searches within the Match-Score table for pairs of one-to-one matches. We call a pair a one2one match if the matching score for this pair is equal to or above the evaluator X  X  acceptance threshold th  X  0.95. A g_one2many match is a ground truth region that  X  X artially X  matches with two or more regions in the detected result. A g_many2one match corresponds to two or more ground truth regions that  X  X artially X  match with one detected region. A d_one2many match is a detected region that  X  X artially X  matches two or more regions in the ground truth. Finally, a d_many2one match corresponds to two or more detected regions that  X  X artially X  match one region in the ground truth.
If N is the count of ground truth regions, M is the count of result regions, and w 1, w 2, w 3, w 4, w 5 and w 6 are pre-determined weights, we can calculate the detection rate and recognition accuracy as follows: Detection Rate = W 1 Recognition Accuracy = W 4 Where the entities one2one, g_ one2many, g_ many2one, d_ one2many and d_ many2one are calculated from Match-Score table Eq. ( 27 ) following the steps of [ 52 ] and corre-spond to the number of one2one, g_ one2many, g_ many2one, d_ one2many and d_ many2one, respectively.

A performance metric for detecting each entity can be extracted if we combine the values of the entity X  X  detection rate and recognition accuracy. We can define the following entity detection metric (EDM): EDM = 2  X  5.5.2 Experimental results We have randomly selected dozens of document images from MediaTeam Document Database [ 53 ], from the Page Seg-mentation Competition of ICDAR2009 [ 54 ]. The data set is divided into 100 training images and 200 test images. The purpose of the training images is to find suitable parameter values for the segmentation algorithms.

We evaluated the performance of the 3 segmentation algo-rithms using Eqs. ( 27 ) X ( 30 ) for all test images with parame-ters w1 = 1, w2 = 0.75, w3 = 0.75, w4 = 1, w5 = 0.75 and w6 = 0.75. All evaluation results for all entities are shown in Fig. 12 where the EDM values averaged over all images are depicted. In this figure, we see that the proposed method achieved the highest averaged detection rate, recog-nition accuracy and EDM rate values (86.96%, 83.33 and 85.11%, respectively). The Docstrum algorithm achieved a detection rate better than X X  X  cut algorithm, while X X  X  cut algorithm achieved recognition accuracy better than Doc-strum one. The proposed method has an overall advantage. Figure 13 a shows the ground truth of document of Fig. 11 d. Figure 13 b, c and d show the segmentation results obtained with Docstrum, X X  X  cut, and with the proposed method, respectively. 5.6 Comparison with other texture-based segmentation In order to evaluate the performance of our system, we com-pared it with Gabor filter bank designed for image texture segmentation. In this comparison, we used three data sets namely: dispatch notes, forms and newspapers. The classi-fication results for the two multi-resolution decompositions for the three data sets are presented in Table 7 .Fromthis Table, we can see that the steerable pyramid with sp3filters orientations achieves the highest accuracy for the second data set. The Gabor wavelet follows with Sx = 4, Sy = 8, f = 18,  X  = 0, 45, 90,135 on the same data set. For data set 1 and 3, the steerable pyramids with sp3filters have the best classifi-cation accuracy.

One of the segmentation systems using Gabor filter bank for image texture segmentation was outlined in [ 55 ]. In addi-tion to Gabor filters, the authors have used Harris corner detector and Delaunay triangulation as additional preprocess-ing and post-processing steps, respectively. Given a set of data points, the Delaunay triangulation is a set of lines con-necting each point to its natural neighbors. In [ 56 ], the Dela-unay triangulation has been applied for the extraction of text areas in document page by representing the location of con-nected components in a document image with their centroids. Harris corner detector [ 57 ] is a function that returns binary image marking corners. It returns also the row and column coordinates of corner points.

This implies that the only use of Gabor filters is not suffi-cient to discriminate between text and non-text regions. Fac-ing that, our system gives the same results without using any additional either preprocessing or post-processing steps. Much more, our system can handle multilingual documents. As a result, our system reduces the complexity of treatments and can be easily implemented. 6 Conclusion and future work The work developed in this paper aims at setting up a sys-tem of segmentation of complex multilingual multi-script document images. Thus, we began with a study of the exist-ing systems of document images segmentation. Within this framework, we showed a few systems that handled complex multilingual multi-script document images. We presented the proposed system, which is based on steerable pyramid. Lastly, we exposed the results obtained on a data set of 1,000 documents. The rate of correct segmentation obtained is about 93.44%.

The major advantages of our system are the following:  X  Handling multi-script documents  X  Invariant to skew, to rotation and to translation  X  Working fairly well on different types of documents  X  Accommodating complex layout, involving different
While the major limits and shortcomings of our system are the following:  X  It fails to locate text blocks that are not well separated  X  The classification failed when some words or text blocks  X  The primary drawback is that the representation is over
In the future, additional efforts on both the theoretical and the practical side need to be made on at least the following points:  X  Multi-oriented annotations detection  X  Improved separation of graphic linked to text  X  Automate the choice of some parameters especially the References
