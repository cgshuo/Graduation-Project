 Rough set theory has been introduced by [9] as a tool for concept approximation from uncertainty. Till now, one can find many efficient applications of rough sets in machine learning and data mining, since many problems like classification, clustering or regression can be formulated as concept approximation problem [4]. In a typical process of concept approximation we assume that there is given information consisting of values of conditional and decision attributes on objects from a finite subset (training set) of the universe and using this information one should induce approximations of the concept over the whole universe. by unmanned vehicle aircraft (UAV), the target concept is too complex and it can not be approximated directly from feature value vectors. The difficulty is based either on the unlearnability of the hypothesis space or on the high complexity of the the learning algorithm. In such cases, there is a need of using a domain knowledge to improve the learning process. In this paper, we assume that domain knowledge is given as a concept ontology, which can be understood as a treelike structure with the target concept located at the root, with attributes (variables, features) located at leaves, and with some additional concepts located in internal nodes. With this assumption, the layered learning [15] seen as a generalization of standard approach to concept approximation.
 concept from simpler ones. The importance of hierarchical concept synthesis is now well recognized by researchers (see, e.g., [8] [11]). An idea of hierarchical concept synthesis, in the rough mereological and granular computing frameworks has been developed (see, e.g., [11] [14]) and problems connected with compound concept approximation are discussed, e.g., in [1] [8] [13].
 in decision systems [9]. The crucial for inducing concept approximations is to cre-ate the description of concepts in such a way that makes it possible to maintain the acceptable level of imprecision along all the way from basic attributes to final decision. We discuss some strategies for concept composing based on rough set theory. The effectiveness of layered learning approach and the comparison with standard rule-based learning approach are performed with respect to generality of concept approximation, preciseness of concept approximation, computation time required for concept induction and concept description lengths. The problem of concept approximation can be treated as a problem of searching for description (expressible in a given language) of an unknown concept. interpreted as a subset of X , the problem is to find a description of C which can be expressed in a predefined descriptive language L . We assume that L consists of such formulas that are interpretable as subsets of X . The approximation is required to be as close to the original concept as possible.
 attributes (features) A = { a 1 , .., a k } . Each attribute a  X  A corresponds to the function a : X X  V a where V a is called the domain of a . For any non-empty set of attributes B  X  A and any object x  X  X  , we define the B -information vector called the B -information set . The language L , which is used to describe approx-imations of the given concept, consists of Boolean expressions over descriptors of the form ( attribute = value )or( attribute  X  set of values ).
 learning problem , i.e., the problem of searching for a (approximated) description of a concept C based on a finite set of examples U  X  X  , called the training set. The closeness of the approximation to the original concept can be measured by different criteria like accuracy, description length, etc., which can be also estimated by test examples .
 which is a tuple S =( U, A, dec ), where U is a non-empty, finite set of training objects , A is a non-empty, finite set, of attributes and dec /  X  A is a distinguished attribute called decision .If C  X  X  is a concept to be approximated, then the decision attribute dec is a characteristic function of concept C , i.e., if x  X  C we have dec ( x )= yes , otherwise dec ( x )= no . In general, the decision attribute dec can describe several disjoint concepts. Therefore, without loss of generality, we assume that the domain of the decision dec is finite and equal to V dec = { 1 ,...,d } . For any k  X  V dec , the set CLASS k = { x  X  U : dec ( x )= k } is called the k th decision class of S . The decision dec determines a partition of U into decision classes, i.e., U = CLASS 1  X  ...  X  CLASS d .
 algorithm from inductive learning area. In the next Section we concentrate on methods based on layered learning and rough set theory. Let C  X  X  be a concept and let S =( U, A, dec ) be a decision table describing the training set U  X  X  . Any pair P =( L , U ) is called rough approximation of C (see [1] [9]) if it satisfies the following conditions: 1. L  X  U  X  X  ; 2. L , U are expressible in the language L ; 3. L  X  U  X  C  X  U  X  U  X  U ; 4. L is maximal and U is minimal among those L -definable sets satisfying 3. mation of the concept C , respectively. The set BN = U  X  L is called the boundary region of approximation of C . For objects x  X  U , we say that  X  X robably, x is in C  X . The concept C is called rough with respect to its approximations ( L , U )if L = U , otherwise C is called crisp in X .
 to make it possible to induce approximations of higher quality of the concept on the whole universe X . In practical applications the last condition in the above definition can be hard to satisfy. Hence, by using some heuristics we construct sub-optimal instead of maximal or minimal sets. 3.1 Rough Classifier The rough approximation of a concept can be also defined by means of a rough membership function. A function  X  C : X X  [0 , 1] is called a rough membership function of the concept C  X  X  if, and only if ( L  X  C , U  X  C ) is a rough approxima-tion of C , where L  X  C = { x  X  X  :  X  C ( x )=1 } and U  X  C = { x  X  X  :  X  C ( x ) &gt; 0 } (see [1]). The rough membership function can be treated as a fuzzyfication of rough approximation. It makes the translation from rough approximation into membership function. The main feature that stands out rough membership func-tions is related to the fact that it is derived from data. Any algorithm that computes the value of a rough membership function  X  C ( x ) having information vector inf ( x ) of an object x  X  X  as an input, is called the rough classifier . of construction of rough classifiers have been proposed, e.g., the classical method based on reducts [9][10], the method based on k-NN classifiers [1], or the method based on decision rules [1]. Let us remind the Rough Set based algorithm, called RS algorithm , that constructs rough classifiers from decision rules. This method will be improved in the next section.
 is construction of some decision rules, i.e., implications of a form rules with high confidence from a given decision table is a big challenge for data mining. Some methods based on rough set theory have been presented in [3] [5] [10] [12]. Let RULES ( S ) be a set of decision rules induced from S by one of the mentioned rule extraction methods. One can define the rough membership function  X  k : X X  [0 , 1] for the concept determined by CLASS k as follows: 1. For any object x  X  X  ,let M atchRules ( S ,x ) be the set of rules which are sup-2. We define two real values w yes ,w no by 3. The value of  X  k ( x ) is defined by: 3.2 Construction of Complex Rough Classifier from Concept In this section we describe a strategy that learns to approximate the concept established on the higher level of a given ontology by composing approximations of concepts located at the lower level. We will discuss the method that gives us the ability to control the level of the approximation quality along all the way from attributes (basic concepts) to the target concept.
 The concept hierarchy should contain either inference diagram or dependence diagram that connects the target concept with input attribute through inter-mediate concepts. Formally, any concept hierarchy can be treated as a treelike structure H =( C , R ), where C is a set of all concepts in the hierarchy including basic concepts (input attributes), intermediated concepts and target concept and R X  X  X C is a dependency relation between concepts from C . Usually, concept hierarchy is a rooted tree including target concept at root and input attributes at leaves. We also assume that concepts are divided into levels in such a way that every concept is connected with concepts in the lower levels only. Some examples of concept hierarchy are presented in Fig. 2 and Fig. 4.
 cept approximation problem. This algorithm works for flat hierarchy of concepts (i.e., the target concept (decision attribute) is connected directly to input at-tributes). The specification of RS algorithm is as follows:
Input: Given decision table S C =( U, A C ,dec C ) for a flat concept hierarchy Parameters:  X  C , X  C ;
Output: Approximation of C , i.e., such a set of hypothetical classifiers h C that a building block to develop a layered learning algorithm. The idea is to apply the RS algorithm to approximate the successive concepts through the hierar-chy (from leaves to target concepts). Let prev ( C )= { C 1 , ..., C m } be the set of concepts in the lower layers, which are connected with C in the hierarchy. The rough approximation of the concept C can be determined by two steps: 1. Construct a decision table S C =( U, A C ,dec C ) appropriated the concept C ; 2. Apply RS algorithm to extract an approximation of C from S C ; of an adequate decision table. In this paper, we assume that the set of training objects U is common for the whole hierarchy. The set of attributes A C is strictly where h C i denotes the set of hypothetical attributes related to the concept C i . If C i is an input attribute a  X  A then h C i ( x )= { a ( x ) } , otherwise h C ( x )= {  X 
C ( x ) , X  C ( x ) the lack of decision attributes for intermediate concepts (see Section 4.1). In such situations, we use a supervised clustering algorithm (using decision attribute of the target concept as a class attribute) to create a synthetic decision attribute. ( U, A, D ), where D is a set of decision attributes corresponding to all interme-diate concepts and to the target concept. Decision values indicate if an object belong to the given concept in the ontology. The most advanced feature of the proposed method is the possibility of tuning the quality of concept approxima-tion process via the parameters  X  C , X  C . More details about this problem will be discussed in our next contribution. The layered learning algorithm based on rough set theory is presented in Algorithm 1.
 Algorithm 1. Layered learning algorithm We have implemented the proposed solution on the basis of RSES system [2]. To verify a quality of hierarchical classifiers we performed the following experiments. 4.1 Nursery Data Set This is a real-world model developed to rank applications for nursery schools [7]. The concept ontology is presented in Figure 2. The data set consists of 12960 objects and 8 input attributes which are printed in lowercase. Besides the target concept (NURSERY) the model includes four undefine intermediate concepts :EMPLOY,STRUCT FINAN, STRUCTURE, SOC HEALTH. To ap-proximate intermediate concepts we have applied a supervised clustering algo-rithm, in which the similarity between two vectors is determined by a distance between their class distributions. Next, we use rule based algorithm to approxi-mate the target concept. The comparison results are presented in Table 1. 4.2 Road Simulator Learning to recognize and predict traffic situations on the road is the main issue in many unmanned vehicle aircraft (UVA) projects. It is a good example of hierarchical concept approximation problem. Some exemplary concepts and a dependency diagram between those concepts are shown in Fig. 4. Definitions of concepts are given in a form of a question which one can answer YES, NO or NULL (does not concern). We demonstrate the proposed layered learning approach on the simulation system called road simulator . The detail description of road simulator has been presented in [6].
 vehicle movements on the roads and at the crossroads. Such data sets are next used to learn and test complex concept classifiers working on information coming from different devices (sensors) monitoring the situation on the road. During the simulation data may be generated and stored in a text file in a form of a rectangular table (information system). Each line of the table depicts the situation of a single vehicle and contains the sensors X  and concepts X  values for the vehicle and its neighboring vehicles, see Fig. 3.
 Experiment Setup: We have generated 6 training data sets: c10 s100, c10 s200, c10 s300, c10 s400, c10 s500, c20 s500 and 6 corresponding testing data sets named by c10 s100N, c10 s200N, c10 s300N, c10 s400N, c10 s500N, c20 s500N . All data sets consists of 100 attributes. The smallest data set consists of above 700 situations (100 simulation units) and the largest data set consists of above 8000 situations (500 simulation units).
 induced by the rule set method, and RS-L: the hierarchical classifier induced by the RS-layered learning method. The comparison results are performed with re-spect to the accuracy of classification, covering rate of new cases, and computing time necessary for classifier synthesis. Classification Accuracy: Similarly to real life situations, we are interested on the accuracy and the coverage of classifiers on the decision class  X  X afe driving = NO X , i.e., dangerous situations. This is a issue for this problem, since datasets are is unbalanced (the concept states only 4% -9% of training sets). can see that the hierarchical classifier showed to be much better than the stan-dard classifier for this class. Accuracy of  X  X O X  class of the hierarchical classifier is quite high when training sets reach a sufficient size. The generality of classi-fiers usually is evaluated by the recognition ability for unseen objects. One can observe the similar scenarios to the accuracy degree. The recognition rate of dangerous situations is very poor in the case of the standard classifier. One can see in Table 2 the improvement on coverage of the hierarchical classifier. Computing Speed: The layered learning approach also shows a tremendous advantage with respect to the computation time. One can see in Table 3 that speed up ratio of the layered learning approach to the standard one reaches from 40 to 130 times.
 We presented a new method for improving rough classifiers using concept ontol-ogy. It is based on the layered learning approach. Unlike traditional approach, in the layered learning approach the concept approximations are induced not only from accessed data sets but also from expert X  X  domain knowledge, which is nec-essary to created an concept ontology. In the paper, we assume that knowledge is represented by concept dependency hierarchy. The layered learning approach showed to be promising for the complex concept synthesis. The advantages of this new approach in comparison to the standard approach have been illustrated by experiments with the road traffic simulator.
 Acknowledgements. The research has been partially supported by the grant 3T11C00226 from Ministry of Scientific Research and Information Technology of the Republic of Poland. The authors are deeply grateful to Dr. J. Bazan for his road simulator system and Prof. A. Skowron for valuable discussions on the layered learning approach.

