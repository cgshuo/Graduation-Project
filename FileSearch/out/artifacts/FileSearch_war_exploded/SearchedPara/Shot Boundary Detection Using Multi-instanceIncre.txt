 A video shot, which represents a continuous action in time and space, is com-of frames within a sliding window are thresholded by a value that is equal to the median plus two times of the standard deviation. In [ 3 ], the strength of of videos which challenge threshold setting, a support vector machine (SVM) based approach is adopted to treat the SBD as a classification problem. This decomposition to cut down the processing time.
 In this paper, inspired by previous work [ 6 ], we propose a novel framework to detect shot boundaries on the basis of One-Class Support Vector Machine OCSVM that operates in an unsupervised manner. Since OCSVMs work to incorporate as many data points inside as possible but leave out outliers, the and an Immediate Future Set (IFS), to train two OCSVMs as the summary of the two frame sets. We then examine the divergence between the two OCSVMs, and significant divergence will indicate the shot boundary.
 The main contributions of our paper are as follows:  X  We propose a novel learning method, referred to as Multi-instance Incremen-tal and Decremental One-Class Support Vector Machine (MID-OCSVM), to update OCSVM classifier in an online fashion, requiring very low computa-tional cost.  X  We present a unified framework to detect different types of shot boundary
This simplifies the computational complexity of the approach while maintain-ing a high accuracy.  X  Instead of comparing the difference between successive frames, we define a function to measure the divergence between IPS and IFS. This approach con-tributes to robustness to noises such as abrupt illumination changes and large movements.
 The rest of the paper is organized as follows. Details of the proposed compu-settings and the results obtained on the TRECVID 2007 SBD datasets. We conclude the paper in Sect. 4 , also discussing some possible future work. 2.1 Overview The flowchart of our approach is illustrated in Fig. 1 . Given the IPS and IFS measure the divergence between the two sets based on the concept of OCSVM. From t to t + 1, we add a new frame and remove the oldest one in each set while updating the classifier using the proposed MID-OCSVM algorithm. Shot boundaries are detected based on the divergence output.
 2.2 Feature Extraction colour histogram is calculated, and the frame is represented by concatenating colour histograms from all blocks. We chose this feature for several reasons. to the space limit. 2.3 OCSVM data in a compact region. Here  X  is a feature map that transforms x from the input space X to the feature space F .
 programming problem: trade-off between structure and empirical risks.
 By introducing Lagrange multipliers  X  i , X  i  X  0, the corresponding Lagrangian is formulated as: zero, giving: instead: ity between the two examples x i and x j , with maximum similarity 1 and no similarity 0. Correspondingly, the separating function is rewritten as: Considering the histogram-based representation of our feature descriptor, we two inputs: where b indicates the corresponding bin in x i and x j . 2.4 MID-OCSVM oldest one to learn a new OCSVM classifier for divergence measure. It is very time-consuming to train a classifier in the batch mode whenever a new input comes. Therefore, we propose MID-OCSVM by extending previous work [ 9  X  11 ]. Karush-Kuhn-Tucker Conditions. To elaborate our approach, we rewrite the dual problem Eq. ( 3 ) as a saddle-point formulation: conditions: margin support vectors S ,errorsupportvectors E , and the remaining set O .In parallel, their corresponding indexes set are given as: I C } , I will abbreviate k ( x i , x j )to k ij . For two subsets S and O , k matrix, whose rows are indexed by S , and the columns are indexed by O . Derivation. As depicted in Fig. 1 , suppose we add a new arriving data x is initialized as 0 (i.e.  X  a = 0). If g a &gt; 0, we append x it already satisfies the KKT conditions. Likewise, we discard x corresponding coefficient a r equals to 0. For x a and x r conditions are to be kept: be re-written in matrix notations: where  X  is a step length. Together with Eq. ( 8 ), we can write: where Substituting ( 9 ) and ( 11 )into( 7 ): where Online Update. The ideal situation is that  X  equals to 1, so adding data x becomes an error support vector and  X  r becomes zero. However, we cannot obtain the new OCSVM state directly in most situations since in Eqs. ( 10 )and  X  X  and  X g i . Therefore, as shown in Fig. 2 , we have identified the following conditions: 1. g 2. g in E becomes zero, equivalent to x i transferring from E to S . The most likely occurred constrain  X  E equals to finding the minimal increment: 3. g in O becomes zero, equivalent to x i transferring from O to S . The most likely occurred step is computed as: 4. x in S reaches a bound,  X  i with equality 0 is equivalent to transferring x from S to O , and equality C from S to E . The most likely increment equals: where The largest possible step length  X  is determined as: and x a , satisfy KKT conditions and  X  r reaches 0.
 Recursive Update of Q . It is time-consuming if we compute the inverse matrix Q whenever the set S has changed. Fortunately, by applying the Sherman-Morrison-Woodbury formula [ 12 ] for block matrix inversion, we can update the where  X  Q is computed as: where  X  = k ii  X  VQV T .
 original inverse matrix  X  Q to the reduced inverse matrix Q is calculated as: 2.5 OCSVM Divergence To measure the divergence between two OCSVM classifiers, we first analyse the representation of OCSVM in the feature space F .Using v i are all mapped on a hypersphere S with radius r = 1. The OCSVM in corresponds to find the optimal hyperplane w that most mapped training set v have w  X  v i  X   X &gt; 0. Figure 3 (a) illustrates the OCSVM classifiers in a segment cut by the hyperplane w on the hypersphere S . boundary, their segments in F should be different from each other. In other words, the size as well as the location of the two segments are different from each other. To this end, we define a divergence function D in the following. Let c t 1 and c t 2 be centre points of segments learnt from B corresponding segments, as shown in Fig. 3 , the divergence function D between B and B t 2 is given as: where c t 1 c t 2 is the arc distance from c t 1 to c t 2 However, we cannot calculate Eq. ( 15 ) directly in feature space because we have to transform D from F into X . Specifically, for any two points a and b lying on an arbitrary sphere, the arc distance is given by: where r is the radius, and  X  is the central angle between a and b . Meanwhile, the dot product between vector a and vector b is given by: where || a || = || b || = r .
 reside on the sphere.
 ( oc t 2 ) is perpendicular to w t 1 ( w t 2 ), so we can replace c ( w t 2 / || w t 2 || ) after some geometric computations. The arc distance c is calculated as: and B t 2 respectively.
 frames directly, assessing the divergence between two OCSVMs trained on frame sets is supposed to large as the overall distribution will be quite different. 3.1 Setup We have carried out experiments on TREC Video Retrieval Evaluation (TRECVID) 2007 SBD dataset 1 . The TRECVID is an annually worldwide benchmarking activity, whose goal is to encourage research on content-based information retrieval in digital video. The TRECVID 2007 SBD dataset con-Among them, 90 % of the shots are hard cuts, and the rest are gradual tran-sitions. Contents of the dataset are diverse, covering a wide range from news reports to archived grayscale videos.
 For comparison purposes, three criteria are selected to evaluate the SBD performance, i.e., recall, precision and F 1 , given as: where  X  X rue positive X  and  X  X alse positive X  correspond to numbers of correctly threshold of divergence to identify shot boundaries. Following the measurement of TRECVID, a correct shot boundary detection is defined as at least one frame overlap between the detected transition and the annotated transition. 3.2 Performance Evaluation SBD performance. Three parameters have to be evaluated, namely, parameter C by fine-tuning one parameter while fixing the rest of them. The impact of C on compare with the start-of-the-art approaches using the aforementioned optimal settings, i.e., C =0 . 2, m = 20, and l =3.
 mance. Compared with the published results in TRECVID 2007 2.7GHZ Intel Core i5 and 8GB RAM, the overall running time our approach speed has increased from 92 frames/second using batch mode OCSVM to 125 frames/second using MID-OCSVM, where the processing time for each OCSVM classifier training has decreased from 5 . 4  X  10  X  3 second to 2 . 5 ary detection. Using online OCSVMs, a unified framework to detect all types of boundaries is proposed. We reduce the computational cost through a multi-properties of OCSVM, our method is robust to noises while effective to gradual competitive performance of our approach compared with the state-of-the-art. We intend to further optimize the incremental and decremental algorithmic within video, multiple kernel learning [ 17 ] is also considered.
