 With the quick growth of graph data generated and collected by many applica-tions in social networks, bioinformatics and chemistry, there is a huge demand of developing effective analysis tools on the big graph datasets. The graph similar-ity join provides an indispensable functionality to such analysis tasks. However, most previous graph similarity join algorithms are in-memory algorithms, be-ing incompetent to analyze the graph datasets with large sizes. Worse still, the graph similarity functions, e.g. graph edit distance, is commonly computation-ally expensive [1], making the performance of the graph similarity join faced with large-scale sets a serious concern.

To solve the problems above, a potential solution is to resort to the popular distributed computation paradigms, such as MapReduce [2][3]. However, to our best knowledge, it has not been reported that the works of large-scale graph similarity joins based on MapRedu ce. In this paper, we implement the GSimJoin algorithm [6] in parallel, that is the state-of-the-art centralized graph similarity join method with edit distance constrains. In particular, we optimize this parallel algorithm with scalable prefix-filtering and compression techniques.
We propose the progressive MR -GSimJoin algorithm in Section 2. Extensive experimental results are reported in Section 3. We discuss related work in Section 4 and Section 5 concludes this paper.
 This paper focuses on undirected label graphs and employs the popular graph edit distance as the graph similarity metric.
 Definition 1. Given two graph sets R and S , and a similarity threshold  X  ,the graph similarity join retrievals all pairs of similar graphs from each graph set, i.e., { ( r, s ) | GED ( r, s )  X   X ,r  X  R, s  X  S } .
 For ease of description, this paper focu ses on self-joins scenario. Our solution can also be extended to implement the general graph similarity join between any two different graph sets.
 We first propose a naive MapReduce implementation named N -GSJ based on GSimJoin . First, one MapReduce job is utilized to compute the q -grams global frequency. Second, another MapReduce job is started to implement candidate filtering and verifying. Although N -GSJ algorithm seems simply, it will suffer serious performance issues due to the same problems as algorithms in [6][8].
In order to solve problems above, we propose the MR -GSJ algorithm, which sorts q -grams of every graph according to the global frequency without com-puting the q -grams global order to improve the efficiency and the scalability of the prefix filtering. Moreover, the MR -GSJ utilizes the graph id to produce the candidate id pairs, then substitutes the graph id with the graph data through two-round dataset access to relieve the d ata explosion of the reduce phase. The dataflow of the MR -GSimJoin framework is illustrated in Fig. 1. The map and reduce functions are shown in Table 1.
 The MR -GSimJoin algorithm is compared with the N -GSJ proposal and the state-of-art proposal SSJ -2. The following parameters were compared: 1)running time, 2)scaleup and 3)speedup.
 The real dataset AIDS contains 40,000 graphs, one of which represents an AIDS chemical compound ( http : //dtp.nci.nih.gov/docs/aids/aids data.html ).
All synthetic graph datasets are generated with the GraphGen [4]. Statistics of the SY N 1 synthetic dataset are described as follows: ngraphs =10,000,000, graph size =20, nnodel =100, nedgel =6, and density =0.3.

We employ a cluster of 30 nodes, one of which has the same configuration: two 3.1GHz CPUs, 8GB RAM, 500GB hard disk, Redhat 4.4.4-13 and Hadoop-0.20.2.

The running time of all three proposals is compared over sample datasets from AIDS and SY N 1 . The results described in Table 2 show that MR -GSimJoin outperforms both N -GSJ and SSJ -2 over sample datasets of AIDS . Because N -GSJ need to filter and verify duplicate results, which intro-duces unnecessary expense. SSJ -2 generates candidate pairs and then remotely accesses the DFS for achieving graph data in its third MapReduce job.
The speedup of MR -GSimJoin is analyzed on the SY N 1 dataset as shown in Fig. 2. Fig. 2(a) shows that the MR -GSimJoin running time reduces with the node increasing from 6 to 30, which displays a satisfactory speed up. Fig. 2(b) depicts that a higher parallelization c an better accelerate the processing.
The scaleup of MR -GSimJoin is evaluated on the SY N 1 dataset as shown in Fig. 3. The running time of job one -four slightly increases with the growth of scalefactor , while validating displays a obvious upward trend. This is because the growth rate of candidate pairs is beyond the dataset growth rate, yielding more and more candidate results in the process of scalable prefix-filtering with the augment of dataset size.
 The graph similarity join problem has b een widely studied in r ecent years[1][5][6]. However, none of these solutions can handle increasingly large-scale data sets due to the lack of scalability. Many algorithms based on MapReduce are proposed to perform similarity joins over large-scale datasets of various data types, such as documents, sets, etc[7][8][9][10][11][12]. Unfortunately, these existing algorithms are not directly applied to tackle similarity joins on large-scale graph datasets. This paper proposes a parallel MR -GSimJoin algorithm based on the MapRe-duce framework to perform similarity joins on large-scale graph datasets. A scal-able prefix-filtering technique is proposed to adapt the MR -GSimJoin algorithm to suit large q -gram alphabets. The candidate results are compressed to reduce the communication cost and enhance t he performance. The data access costs are decreased through a two-round full copy method. Extensive experiments on real and synthetic datasets demonstrate that our algorithm outperforms the state-of-the-art method in efficiency and scalability.
 Acknowledgments. This work is supported by the National Natural Science Foundation of Chin a(Nos. 61272179,61173028).

