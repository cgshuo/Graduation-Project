 We explore an alternative Info rmation Retrieval paradigm called Query-By-Multiple-Examples (QBME) where the in-formation need is described not by a set of terms but by a set of documents. Intuitive ideas for QBME include using the centroid of these documents or the well-known Rocchio algorithm to construct the query vector. We consider this problem from the perspective of text classification , and find that a better query vector can be obtained through learning with Support Vector Machines (SVMs). For online queries, we show how SVMs can be learned from one-class examples in linear time. For offline queries, we show how SVMs can be learned from positive and unlabeled examples together in linear or polynomial time. The effectiveness and efficiency of the proposed approaches have been confirmed by our ex-periments on four real-world datasets.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Performance, Experimentation Support Vector Machine, One-Class Learning, PU Learning.
We explore an alternative Info rmation Retrieval paradigm called Query-By-Multiple-Examples (QBME): given a set of documents P = { x 1 ,..., x l } as query, retrieve/rank the doc-uments in a corpus U = { x l +1 ,..., x l + u } accordingtotheir relevance to P . The problem of QBME occurs frequently in practice. This is because only relevant documents are usu-ally stored, and it is often desirable to find more relevant documents. For example, a researcher may have saved in her computer some journal articles on a subtopic in bioin-formatics ( P ), and she wants to find more materials on that subtopic from the PubMed Central digital library ( U ).
In this paper, we distinguish between two types of queries: online queries where response is required immediately and offline queries where the user is willing to wait in order to get better results. For online queries, we restrict ourselves to using only P because of efficiency consideration. For offline queries, it may be feasible to use U in addition to P to improve retrieval performance.
Taking the classic Vector Space Model [5], we represent every document as a normalized document vector, and seek to best describe P as a query vector w such that all the documents in U can be ranked appropriately by a linear function f ( x )= w T x . The intuitive idea to solve the prob-lem of QBME is to use the centroid of P , w = 1 l l i =1 x as the query vector for online processing, or to use the sim-plified Rocchio algorithm [5] to construct the query vector ever, given that we have a set of relevant documents which should be more informative than just keyword queries, we may hope to obtain a better query vector by considering this problem from the perspective of text classification .Ac-tually QBME crosses the traditional boundary of retrieval and classification. Support Vector Machine (SVM) [6] in its simplest form, linear SVM, consistently provides state-of-the-art performance for various text classification tasks.
We propose to use the following one-class SVM formu-lation SVM struct 1 c to construct the query vector w taking P as training examples. It can be shown by adapting the proof from [3] that SVM struct 1 c is equivalent to the standard linear SVM using only positive examples. Moreover, un-like the original one-class SVM formulation [6] that requires quadratic time for training, SVM struct 1 c can be trained by the cutting-plane algorithm in linear time w.r.t. | P | =
If we have not only a set of relevant documents P , but also a set of irrelevant documents N , we can use the standard linear SVM to construct the query vector w taking P and N as positive and negative examples respectively. However, what we have in addition to P is only the unlabeled corpus U where relevant and irrelevant documents are mixed. This problem of training a classifier with positive and unlabeled examples is called PU learning [4]. Our solution is to take the relevant documents in U as noise thus U can be consid-ered as a very noisy set of negative examples. Denote the observed label of an example x by y , i.e.,  X  x i  X  P : y and  X  x i  X  U : y i =  X  1. Denote the actual label of an exam-ple x by z that indicates its true relevancy. Unfortunately, the standard linear SVM that minimizes the observed error rate does not guarantee to achieve the minimal actual error rate [1]. Nevertheless, under a reasonable assumption that the documents in P are randomly sampled from the class of relevant documents with a certain probability  X  ,wecan prove that optimizing the observed values of the following two performance measures is in fact equivalent to optimizing their corresponding actual values.
 Balanced Accuracy .The balanced accuracy a.k.a. the AUC for just one run of a classifier is the average of its sen-sitivity and specificity . With some simple calculation [1] we can see that the observed balanced accuracy B is connected to the actual balanced accuracy B via B  X  1 2  X  B  X  1 2 . It can be shown by adapting the proof from [3] that the following SVM formulation SVM struct ba minimizes the cost function  X  ba (  X  h (  X  x ) ,  X  y )=1  X  B .Moreover, SVM struct trained by the cutting-plane algorithm in linear time w.r.t. | P  X  U | = l + u [2].
 min
Precision-Recall Product . An IR system is usually evaluated in terms of its precision and recal l [5]. We can prove that the observed recall  X  r is equal to the actual recall r and the observed precision  X  p is proportional to the actual precision p , consequently their product satisfies pr  X  pr is noteworthy that the precision-recal l product closely cor-relates with the popular F 1 measure [5]: pr  X  F 1  X  The cost function  X  pr (  X  h (  X  x ) ,  X  y )=1  X  pr can be minimized using the following SVM formulation SVM perf pr according to [2]. Moreover, SVM perf pr can be trained by a sparse-approximation algorithm in polynomial time w.r.t. | P  X  U | l + u because the loss function  X  pr can be computed from the contingency table [2].

We conduct experiments on four real-world datasets which are pre-processed and publicly available 1  X  (1) news20 , (2) siam-competition2007 , (3) mediamill-exp1 with its top 5 topics and (4) reuters-21578 with its top 65 top-ics. Given a retrieval topic, the query P consists of the relevant documents before the split point, while the corpus U consists of all (relevant and irrelevant) documents after the split point. We simply set the SVM parameter C = 100 throughout all our experiments. The code for the proposed SVM algorithms is available on the 1st author X  X  homepage. The effectiveness of QBME methods evaluated by Mean Av-erage Precision (MAP) [5] is shown in Table 1. The efficiency of QBME methods evaluated by the average CPU seconds of training on a PC with Pentium 4 (3GHz) processor and 2GB memory is shown in Table 2.

As we have anticipated learning from both P and U leads to much higher performances than learning from P only. Us-ing just P , SVM 1 c worksaseffectivelyastheCentroidal-gorithm, but it provides sparser query vectors which is ben-eficial to further similarity computation based on inverted index [5]. Using both P and U , SVM struct ba and SVM perf work significantly better than the Rocchio algorithm, with SVM struct ba being orders of magnitude faster than SVM perf http://www.csie.ntu.edu.tw/  X  cjlin/libsvmtools/datasets/ http://www.cs.cmu.edu/  X  hustlf/r21578 vec download.html
