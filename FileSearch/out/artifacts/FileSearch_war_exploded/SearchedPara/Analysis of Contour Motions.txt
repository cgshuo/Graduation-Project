 Humans can reliably analyze visual motion under a diverse set of conditions, including textured as well as featureless objects. Computer vision algorithms have focussed on conditions of texture, event [11]. To properly analyze motions of featureless objects requires a different approach. the simple two bar stimulus in Figure 1 (from [18]). The gray bar is moving rightward in front of the leftward moving black bar, (a). If we analyze the motion locally, i.e. match to the next frame such a motion by the depicted objects.
 One approach to handling the spurious motions of corners or T-junctions has been to detect such junctions and remove them from the motion analysis [18, 12]. However, T-junctions are often very difficult to detect in a static image from local, bottom-up information [9]. Motion at occluding can properly analyze the motions of featureless objects.
 In this paper, we use a boundary-based approach which does not rely on motion estimates at corners or junctions. We develop a graphical model which integrates local information and assigns proba-motions of the underlying objects. Boundary completion and discounting the motions of spurious Our system is able to automatically detect and group the boundary fragments, analyze the motion where a fragment is a chain of edgelets and a contour is a chain of fragments. Each edgelet within a boundary fragment has a position and an orientation and carries local evidence for motion. The events are properly explained. The result is a specialized motion tracking algorithm that properly analyzes the motions of textureless objects.
 Our system consists of four conceptual steps, discussed over the next three sections (the last two steps happen together while finding the optimal states in the graphical model): We restrict the problem to two-frame motion analysis though the algorithm can easily be extended to multiple frames. Extracting boundaries from images is a nontrivial task by itself. We use a simple algorithm for in a manner similar to that of the Canny edge detector [2]. A more sophisticated boundary detector simple boundary detection algorithm works well.
 Mathematically, given an image I , we seek to obtain a set of fragments B = { b i } , where each embeds both location p ik  X  R 2 and orientation  X  ik  X  [0 , 2  X  ) information. each pixel we find the maximum energy orientation and check if it is local maximum within a slice this test for all the pixels.
 We find the primary boundary point with the maximum orientation energy from the pool and do the current edgelet generates a new one by following its orientation with a certain step size. In T 2 play the same roles as those in Canny edge detection [2]. While the boundary tracker should stop at sharp corners, it can turn around and continue tracking. We run a postprocess to break the boundaries by detecting points of curvature local maxima which exceed a curvature threshold. We next break the boundary contours into very short edgelets and obtain the probabilities, based on local motion of the boundary fragment, for the motion vector at each edgelet. We cannot use conventional algorithms, such as Lucas-Kanade [5], for local motion estimation since they rely on corners. The orientation  X  ik for each edgelet was obtained during boundary fragment extraction. of the flow weighted by the orientation energy in the window. The mean and covariance matrix is Grouping the boundary fragments allows the motion uncertainties to be resolved. We next discuss the mathematical model of grouping as well as the computational approach. 4.1 Two Equivalent Representations for Fragment Grouping two possible representations for grouping. One representation is the connection of each end of the boundary fragment. We formulate the probability of this connection to model the local saliency of contour saliency was proposed in [14]; in [7], both edge saliency and curvilinear continuity were used to extract closed contours from static images. In [15], contour ends are grouped using loopy belief propagation to interpret contours.
 The connections between fragment ends are modeled by switch variables. For each boundary frag-b fragment, or simply have no connection. An exclusive switch is further called reversible , i.e. or in a more compact form  X  [ From the values of the switch variables we can obtain contours, which are chains of boundary fragments. A fragment chain is defined as a series of the end points c = Two open chains are identical if the fragment and end labels are reversed. Two closed chains are the values of the reversible switch variables, as illustrated in Figure 3 (d) and (e). 4.2 The Graphical Model Given the observation O , the two images, and the boundary fragments B , we want to estimate the variables S (switches) or equivalently C (fragment chains). Since the grouping variable S plays an essential role in the problem, we shall first infer S and then infer V based on S . 4.2.1 The Graph for Boundary Fragment Grouping We use two equivalent representations for boundary grouping, switch variables and chains. We use  X  [ S (  X  [ connects to the end of other fragments. Intuitively, two ends should be connected if is the KL divergence between the two Gaussian distributions of the flow vectors ary  X  that connects the two ends. The illusory boundary is simply generated by minimizing the energy of the curve. The saliency is defined as third term is computed by extracting the mean of local patches located at the two ends  X   X  ( S ( i, t i )=( i, t i )) =  X  .
 that convex occluding contours are more salient, and additional T-junctions along the contour may increase or decrease the occlusion perception. Here we simply enforce that a contour should have Thus, the (discrete) graphical model favoring the desired fragment grouping is where Z S is a normalization constant. Note that this model measures both the switch variables S ( i, t i ) for local saliency and the fragment chains c i to enforce global structural saliency. 4.2.2 Gaussian MRF on Flow Vectors Given the fragment grouping, we model the flow vectors V as a Gaussian Markov random field (GMRF). The edgelet displacement within each boundary fragment should be smooth and match the observation along the fragment. The probability density is formulated as where  X  ik and  X  ik are the motion parameters of each edgelet estimated in Sect 3. nected, or mathematically  X  ( V ( i, t i ) , V ( S ( i, t i ))) = The (continuous) graphical model of the flow vectors is therefore defined as where Z V is a normalization constant. When S is given it is a GMRF which can be solved by least squares. 4.3 Inference Having defined the graphical model to favor the desired motion and grouping interpretations, we of S and V in our graphical model to performing two-step inference. We first infer the boundary grouping B , and then infer V based on B . The second step is simply to solve least square problem since Pr( V | S ; B ,O ) is a GMRF. This approach does not globally optimize Eqn. (9) but results in reasonable solution because V switch variable is set to be fragments). Each end is sampled only once, to ensure reversibility. This procedure is repeated each contour has no self-intersection. If  X  ( c i )=0 then this sample is rejected. The marginal distributions are estimated from the samples. Lastly the optimal grouping is obtained by replacing random sampling with selecting the maximum-probability connection over the estimated marginal distributions. The number of samples needed depends on the number of the fragments. In practice we find that n 2 samples are sufficient for n fragments. Figure 6 shows the boundary extraction, grouping, and motion estimation results of our system for The algorithm is implemented in MATLAB, and the running time varies from ten seconds to a few minutes, depending on the number of the boundary fragments found in the image.
 The two-bar examples in Figure 1(a) yields fourteen detected boundary fragments in Figure 6(a) and two contours in (b). The estimated motion matches the ground truth at the T-junctions. The fragments belonging to the same contour are plotted in the same color and the illusory boundaries are synthesized as shown in (c). The boundaries are warped according to the estimated flow and completions.
 The second example is the Kanizsa square where the frontal white square moves to the right bottom. generated illusory boundary also match the ground truth and human perception. Notice that the arcs tend to connect to other ones if we do not impose the structural saliency  X  (  X  ) . We apply our system to a video of a dancer (Figure 5 (a) and (b)). In this stimulus the right leg moves downwards, but there is weak occluding boundary at the intersection of the legs. Eleven occluded boundary of the right leg and the invisible boundary of the left leg.
 The final row shows challenging images of a rotating chair (Figure 5 (c) and (d)), also showing proper contour completion and motion analysis. Thirty-seven boundary fragments are extracted and seven contours are grouped. To complete the occluded contours of this image would be nearly impossible working only from a static image. Exploiting motion as well as static information, our system is able to complete the contours properly.
 Note that the traditional motion analysis algorithms fail at estimating motion for these examples (see supplementary videos) and would thus also fail at correctly grouping the objects based on the motion cues. We propose a novel boundary-based representation to estimate motion under the challenging vi-sual conditions of moving textureless objects. Ambiguous local motion measurements are resolved through a graphical model relating edgelets, boundary fragments, completed contours, and their motions. Contours are grouped and their motions analyzed simultaneously, leading to the correct handling of otherwise spurious occlusion and T-junction features. The motion cues help the contour completion task, allowing completion of contours that would be difficult or impossible using only handles featureless contour motions is an essential element in a visual system X  X  toolbox of motion analysis methods.

