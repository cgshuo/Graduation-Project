 Energy minimization is the problem of finding a maximum a posteriori (MAP) configuration in a Markov random field (MRF). A MAP configuration is an assignment of values to variables that maximizes the probability (or minimizes the energy) in the MRF. Energy minimization has many applications; for example, in computer vision it is used for applications such as stereo matching [11]. As energy minimization in general MRFs is computationally intractable, approximate inference al-gorithms based on belief propagation are often necessary in practice. Such algorithms are split into two classes: max-product and variants address the problem by trying to find a MAP configuration directly, while sum-product and variants return approximate marginal distributions which can be used to estimate a MAP configuration. It has been shown that the max-product algorithm converges to neighborhood optimums [18], while the sum-product algorithm converges to local minima of the Bethe approximation [20]. Convergence of these algorithms are important for good approximations. Recent work (e.g. [16, 8]) on sufficient conditions for convergence of sum-product algorithms sug-gests that they converge better on MRFs containing potentials with small strengths. In this paper, we propose a novel algorithm, called Relaxed Survey Propagation (RSP), based on performing the sum-product algorithm on a relaxed MRF. In the relaxed MRF, there is a parameter vector y that can be optimized for convergence. By optimizing y to reduce the strengths of potentials, we show empirically that RSP converges on MRFs where other algorithms fail to converge.
 The relaxed MRF is built in two steps, by first (i) converting the energy minimization problem into its weighted MAX-SAT equivalent [17], and then (ii) constructing a relaxed version of the survey propagation MRF proposed in [14]. We prove that the relaxed MRF has approximately equal joint distribution (and hence the same MAP and marginals) as the original MRF, independent (to a large extent) of the parameter vector y. Empirically, we show that RSP, when run at low temperatures ( X  X ooled X ), performs well for the application of energy minimization. For max-product algorithms, we compare against the max-product algorithm and its sequential tree-reweighted variant, which is guaranteed to converge [11]. For sum-product algorithms, we compare against residual belief propagation [6] as a state-of-the-art asynchronous belief propagation algorithm, as well as the tree-structured expectation propagation [15], which has been shown to be a special case of generalized belief propagation [19]. We show that RSP outperforms all approaches for Ising models with mixed couplings, as well as in a supervised clustering application for web person disambigation. Figure 1: The variables x 1 , x 2 in (a) are binary, resulting in 4 variables in (b). The clauses  X  1 to  X  4 in (b) are entries in the factor a in (a),  X  1 and  X  2 (resp.  X  3 and  X  4 ) are from b (resp. c ).  X  (1) and  X  (2) are the positivity clauses. The relaxed MRF for RSP has a similar form to the graph in (b). A MRF, G = ( V,F ) , is defined by a set of variables V , and a set of factors F = {  X  a } , where each  X  a is a non-negative function depending on X a  X  V . We assume for simplicity that variables in V have the same cardinality q , taking values in Q = { 1 ,..,q } . For X i  X  V and X a  X  V , we denote by x i the event that X i = x i , and by x a the event X a = x a . To simplify notation, we will sometimes write i  X  V for X i  X  V , or a  X  F for  X  a  X  F . The joint distribution over configurations is defined by P ( x ) = 1 Z Q a  X  a ( x a ) where Z is the normalization factor. When each  X  a is a positive function, the joint distribution can be written as P ( x ) = 1 Z exp(  X  E ( x ) /T ) where E ( x ) = P a  X  log  X  a ( x a ) is the energy function, and the temperature T is set to 1. A factor graph [13] is a graphical representation of a MRF, in the form of a bipartite graph with two types of nodes, the variables and the factors. Each factor  X  a is connected to the variables in X a , and each variable X i is connected to the set of factors, N ( i ) , that depends on it. See Figure 1(a) for a simple example. Weighted MAX-SAT conversion [17]: Before describing RSP, we describe the weighted MAX-SAT (WMS) conversion of the energy minimization problem for a MRF. The WMS problem is a generalization of the satisfiability problem (SAT). In SAT, a set of boolean variables are constrained by a boolean function in conjunctive normal form, which can be treated as a set of clauses. Each 1. The SAT problem consist of finding a configuration that satisfies all the clauses. In WMS, each clause has a weight, and the WMS problem consists of finding a configuration with maximum total weight of satisfied clauses (called the weight of the configuration). We describe the conversion [17] of a MRF G = ( V,F ) into a WMS problem W = ( B,C ) , where B is the set of boolean variables and C the set of weighted clauses. Without lost of generality, we normalize factors in F to take values in (0 , 1] . For each X i  X  V , introduce the variables  X  ( i,x For convenience, we index variables in B either by k or by ( i,x i ) , denote factors in F with Roman alphabet (e.g. a,b,c ) and clauses in C with Greek alphabet (e.g.  X , X , X  ) . For a clause  X   X  C , we denote by C (  X  ) as the set of variables in  X  . There are two types of clauses in C : interaction and positivity clauses.
 Definition 1. Interaction clauses: For each entry  X  a ( x a ) in  X  a  X  F , introduce the clause  X  =  X  i  X  x a  X  ( i,x i ) with the weight w  X  =  X  log( X  a ( x a )) . We write  X  @ a to show that the clause  X  comes from the factor  X  a  X  F , and we denote a = src(  X  ) to be the factor  X  a  X  F for which  X  @ a . The violation of an interaction clause corresponding to  X  a ( x a ) entails that  X  ( i,x x . This correspond to the event that X i = x i for X i  X  X a .
 Definition 2. Positivity clauses: for X i  X  V , introduce the clause  X  ( i ) =  X  x i  X  Q  X  ( i,x for a positivity clause  X   X  C , we denote src(  X  ) for the corresponding variable in V . {  X  ( i,x i ) } x i  X  Q equals 1. To map  X  back to a configuration in the original MRF, exactly one variable in each set of {  X  ( i,x 1. There are two types of invalid configurations: MTO configurations where more than one variable in the set {  X  i,x i } x i  X  Q equals 1, and AZ configurations where all variables in the set equals zero . For valid configurations  X  , let x (  X  ) be the corresponding configuration of  X  in V . For valid configurations  X  , and for each a  X  F , exactly one interaction clause in {  X  }  X  @ a is violated: when  X  corresponding to  X  a ( x a ) is violated, we have X a = x a in x (  X  ) . Valid configurations have locally maximal weights [17]: MTO configurations have low weights since in all interaction clauses, variables appear as negative literals. AZ configurations have low weights because they violate the positivity clauses. See Figure 1 for an example of a WMS equivalent of a simple factor graph. In this section, we transform the WMS problem W = ( B,C ) into another MRF, G s = ( V s ,F s ) , based on the construction of the MRF for survey propagation [14]. We show (in Section 3.1) that under this framework, we are able to remove MTO configurations, and AZ configurations have negligible probability. In survey propagation, in addition to the values { 0 , 1 } , variables can take a any clause. In this section, we assume that variables  X  k take values in { 0 , 1 ,  X  X  . Definition 4. [14] A variable  X  k is constrained by the clause  X   X  C if it is the unique satisfying variable for clause  X  (all other variables violate  X  ). Define CON k, X  (  X  C (  X  ) ) =  X  (  X  k is constrained by  X  ) , where  X  ( P ) equals 1 if the predicate P is true, and 0 otherwise. We introduce the parameters { y a } a  X  F and { y i } i  X  V by modifying the definition of VAL in [14]: Definition 5. An assignment  X  is invalid for clause  X  if and only if all variables are unsatisfying except for exactly one for which  X  k =  X  . (In this case,  X  k cannot take * as it is constrained). Define The term exp(  X  y src(  X  ) ) is the penalty for violating clauses, with src(  X  )  X  V  X  F defined in Defi-nitions 1 and 2. For interaction clauses, we index y a by a  X  F because among valid configurations, exactly one clause in the group {  X  }  X  @ a is violated, and exp(  X  y a ) becomes a constant factor. Posi-tivity clauses are always satisfied and the penalty factor will not appear for valid configurations. Definition 6. [14] Define the parent set P i of a variable  X  k to be the set of clauses for which  X  k is the unique satisfying variable, (i.e. the set of clauses constraining  X  k ).
 We now construct the MRF G s = ( V s ,F s ) where variables  X  k  X  V s are of the form  X  k = (  X  k ,P k ) , with  X  k variables in the WMS problem W = ( B,C ) . (See Figure 1). We define single-variable compatibilities (  X  k ) and clause compatibilities (  X   X  ) as in [14]: where  X  is defined in Definition 4. The single-variable compatibilities  X  k (  X  k ) are defined so that when  X  k is unconstrained (i.e. P k =  X  ),  X  k (  X  k ) takes the values  X   X  or  X  0 depending on whether  X  k equals *. The clause compatibilities introduce the clause weights and penalties into the joint distribution. The factor graph has the following underlying distribution: where n 0 is the number of unconstrained variables in  X  , and n  X  the number of variables taking  X  . Comparing RSP with SP- X  in [14], we see that Theorem 1. In the limit where all y a ,y i  X  X  X  , RSP is equivalent to SP- X  [14], with  X  =  X   X  . Taking y to infinity correspond to disallowing violated constraints, and SP- X  was formulated for satisfiable SAT problems, where violated constraints are forbidden. In this case, all clauses must be satisfied and the term Q  X   X  C exp( w  X  ) in Equation 4 is a constant, and P (  X  )  X   X  n 0 0  X  n  X   X  . 3.1 Main result In the following, we assume the following settings: (1)  X   X  = 1 and  X  0 = 0 ; (2) for positivity clauses  X  ( i ) , let y i = 0 ; and (3) in the original MRF G = ( V,F ) , single-variable factors are defined on all variables (we can always define uniform factors). Under these settings, we will prove the main result that the joint distribution on the relaxed MRF is approximately equal to that on the original MRF, and that RSP estimates marginals on the original MRF. First, we prove the following lemma: Lemma 1. The joint probability over valid configurations on G s is proportional to the joint proba-bility of the corresponding configurations on the original MRF, G = ( V,F ) .
 Proof. For valid configurations, all positivity clauses are satisfied, and for each a  X  F , all valid configurations have one violated constraint in the set of interaction clauses {  X  }  X  @ a . Hence the penalty term for violated constraints Q a  X  F exp( y a ) is a constant factor. Let W = P  X   X  C w  X  be the sum of all weights. For a valid configuration  X  , Lemma 2. All configurations containing * have zero probability in the MRF G s , and there is a one-to-one mapping between configurations  X  = {  X  k ,P k } k  X  V s and configurations  X  = {  X  k } k  X  B Proof. Single-variable factors on G translate into single-literal clauses in the WMS formulation, which in turn becomes single-variable factors in G s . For a variable  X  k = (  X  k ,P k ) with a single-variable factor,  X   X  , we have VAL  X  (  X  k =  X  ) = 0 . This implies  X   X  (  X  k = (  X  ,P k )) = 0 . Lemma 3. MTO configurations have n 0 6 = 0 and since  X  0 = 0 , they have zero probability. Proof. In MTO configurations,  X  ( i,x i ,x 0 i ) , X  i,x i =  X  i,x 0 non-constraining for these variables, and since all other clauses connected to them are interaction clauses and contain them as negative literals, both variables are unconstrained. Hence n 0 6 = 0 , and from Equation 4, for  X  0 = 0 , they have zero probability.
 The above lemma lead to the following theorem: Theorem 2. Assuming that exp( w  X  ( i ) ) 1 for all X i  X  V , the joint distribution over the relaxed MRF G s = ( V s ,F s ) is approximately equal to the joint distribution over the original MRF, G = ( V,F ) . Moreover, RSP estimates the marginals on the original MRF, and at the fixed points, the beliefs at each node, B (  X  ( i,x We can understand the above theorem as follows: if we assume that the probability of AZ in-valid configurations is negligible (equivalent to assuming that the probability of violating positivity clauses are negligible, i.e. exp( w i ) exp(  X  y src(  X  ( i )) ) = 1 ), then we have only valid configura-tions left. MTO invalid configurations are ruled out by Lemma 3. Since the positivity clauses have large weights, exp( w i ) 1 are usually satisfied. Hence RSP, as the sum-product algorithm on the relaxed MRF, returns estimations of the marginals P ( X i = x i ) as B (  X  ( i,x 3.2 Choosing y Valid configurations have a joint probability with the factor Q a  X  F exp(  X  y a ) while AZ configura-tions do not. However, Theorem 2 states that, if exp( w i ) 1 , AZ configurations have negligi-ble probability. Empirically, we observe that for a large range of values of { y a } a  X  F , RSP returns marginals satisfying P x negligible probability. We can hence select the values of { y a } a  X  F for better convergence properties. We describe heuristics based on the sufficient conditions for convergence of sum-product algorithms in [16]. To simplify notations, we write the conditions for a MRF with pairwise factors  X  a , Mooij and Kappen [16] have also derived another condition based on the spectral radius of a ma-trix having N ( X  a ) as entries. These conditions lead us to believe that the sum-product algorithm converges better on MRFs with small N ( X  a ) (or the  X  X trengths X  of potentials in [8]). To calculate N ( X   X  ) for the interaction clause  X  , we characterize these factors as follows: A good approximation for y a would be the median of { X  w  X  }  X  @ a . For our experiments, we divide the search range for y a into 10 bins, and use fminsearch in Matlab to find a local minimum. 3.3 Update equations and efficiency While each message in RSP has large cardinality, we show in the supplementary material that, under the settings of Section 3.1, the update equations can be simplified such that each factor passes a single number to each variable. The interaction clause  X  sends a number  X   X   X  ( i,v ) to each ( i,x )  X  update equations are as follows: (proofs in the supplementary material): We found empirically that the schedule of message updates affect convergence to a large extent. A good schedule is to update all the  X  -messages first (by updating the groups of  X  -messages belonging to each factor a  X  F together), and then updating the  X  -messages together. This seems to work better than the schedule defined by residual belief propagation [6] on the relaxed MRF. In terms of efficiency, for a MRF with N pairwise factors, the sum-product algorithm has 2 Nq real numbers in the factor to variable messages, and RSP has 2 Nq + q . Empirically, we observe that RSP on the relaxed MRF runs as fast as the simple sum-product algorithm on the original MRF, with an overhead for determining the values of y . While Ising models with attractive couplings are exactly solvable by graph-cut algorithms, general Ising models with mixed couplings on complete graphs are NP-hard [4], and graph cut algorithms are not applicable to graphs with mixed couplings [12]. In this section, we perform three sets of experiments to show that RSP outperforms other approaches: the first set compares RSP and the residual belief propagation on a simple graph, the second set compares the performance of various methods on randomly generated graphs with mixed couplings, and the third set applies RSP to the application of the web person disambiguation task.
 A simple example: we use a 4-node complete graph of binary variables, with the two sets of factors defined in Figure 2(a), for = +1 and -1. The case =  X  1 was used in [8] to illustrate how the strengths of potentials affect convergence of the sum-product algorithm. We also show the case of = +1 (an attractive network) as a case where the sum-product algorithm converges well. Both sets of graphs ( = +1 or  X  1 ) have uniform marginals, and 2 MAP configurations (modes). In Figure Figure 2: In Figure (a), we define factors under the two settings: =  X  1 . Figure (b) and (c) show the L 2 distance between the returned marginals and the nearest mode of the graph. Circles on the lines mean failure to converge, where we take the marginals at the last iteration. 2(b) and 2(c), we show experimental results for = +1 and  X  1 . In each case, we vary  X  from 0 to 12, and for each  X  , run residual belief propagation (RBP) damped at 0 . 5 and RSP (undamped) on the corresponding graph. Both methods are randomly initialized. We plot the L 2 distance between the returned marginals and the nearest mode marginals (marginals with probability one on the modes). The correct marginals are uniform, where the L 2 distance is converge to the correct marginals. As  X  is increased, for = +1 in Figure 2(b), both approaches converge to marginals with probability 1 on one of the modes. For =  X  1 , however, RSP converges again to marginals indicating a mode, while RBP faces convergence problems for  X   X  8 .
 Increasing  X  corresponds to increasing N ( X  i,j ) , and the sum-product algorithm fails to converge for large  X  when =  X  1 . When the algorithms converge for large  X  , they converge not to the correct marginals, but to a MAP configuration. Increasing  X  has the same effect as decreasing the tem-perature of a network: the behavior of sum-product algorithm approaches that of the max-product algorithm, i.e. the max-product algorithm is the sum-product algorithm at the zero temperature limit. Ising models with mixed couplings: we conduct experiments on complete graphs of size 20 with different percentage of attractive couplings, using the Ising model with the energy function: percentage of attractive couplings, we draw  X  i,j from U [0 , X  ] , and randomly assign negative signs to the  X  i,j with probability (1  X   X  ) , where  X  is the percentage of attractive couplings required. We vary  X  from 1 to 3. In Figure 3, we plot the difference between the optimal energy (obtained with a brute force search) and the energy returned by each of the following approaches: RSP, max-product belief propagation (MBP), the convergent tree reweighted max product belief propagation (TRW-S) [11], residual sum-product belief propagation (RBP) [6], and tree-structured expecation propagation (TEP) [15]. Each point on the graph is the average over 30 randomly generated networks. In Table 1, we compare RSP against these methods. When an algorithm does not converge, we take its result at the last iteration. We damp RBP and TEP with a 0.5 damping factor. For RSP, MBP, TRW-S and RBP, we randomly initialize the initial messages, and take the best result after 5 restarts. For TEP, we use five different trees consisting of a maximal spanning tree and four random stars [19]. For RSP, RBP and TEP, which are variants of the sum product algorithm, we lower the temperature by a factor of 2 each time the method converges and stop when the method fails to converge or if the results are not improved over the last temperature. We observe that MBP outperforms TRW-S con-stantly: this agrees with [11] that MBP outperforms TRW-S for graphs with mixed couplings. While the performance of TRW-S remains constant from 25% to 75%, the sum-product based algorithms (RBP and TEP) improve as the percentage of attractive potentials is increased. In all three cases, RSP is one of the best performing methods, beaten only by TEP at 2 points on the 50% graph. TEP, being of the class of generalized belief propagation [19], runs significantly slower than RSP. Supervised clustering: Finley and Joachims [7] formulated SV M cluster , which learns an item-pair similarity measure, Sim( i,j ) , to minimize a correlation clustering objective on a training set. In are cluster-ids of item i , and U an upper-bound on the number of clusters. They tried a greedy and a linear programming approach, and concluded that the two approaches are comparable.
 Due to time constraints, we did not implement SV M cluster : instead we test our inference algorithms on the pairwise classification clustering (PCC) baseline in [7]. The PCC baseline trains svmlight [9] on training item-pairs, and run the classifier through all test pairs. For each test pair ( i,j ) , we apply softmax to the classifier outputs to obtain the probability p i,j that the pair is in the same cluster. Figure 3: Experiments on the complete graph Ising model with mixed couplings (legend in (a)), with different percentage of attractive couplings. The y-axis shows, in log scale, the average energy difference between the configuration found by the algorithm and the optimal solution. Table 1: Number of trials (out of 30) where RSP does better/worse than various methods. In partic-ular, the last row (opt) shows the number of times that RSP does worse than the optimal solution. the various inference algorithms perform poorly on the MRF for large U , even when they converge (probably due to a large number of minima in the approximation). We are able to obtain lower energy configurations by the recursive 2-way partitioning procedure in [5] used for graph cuts. (Graph cuts do not apply here as weights can be negative). This procedure involves recursively running, for e.g. RSP, on the MRF for E ( x ) with U = 2 , and applying the Kernighan-Lin algorithm [10] for local refinements among current partitions. Each time RSP returns a configuration that partitions the data, we run RSP on each of the two partitions. We terminate the recursion when RSP assigns a same value to all variables, placing all remaining items in one cluster.
 We use the web person disambiguation task defined in SemEval-2007 [1] as the test application. Training data consists of 49 sets of web pages (we use 29 sets with more than 50 documents), where each set (or domain) are results from a search query on a person name. The test data contains another 30 domains. Each domain is manually annotated into clusters, with each cluster containing pages referring to a single individual. We use a simple feature filtering approach to select features that are useful across many domains in the training data. Candidate features include (i) words occurring in only one document of the document-pair, (ii) words co-ocurring in both documents, (iii) named entity matches between the documents, and (iv) topic correlation features. For comparison, we replace RSP with MBP and TRW-S as inference algorithms (we did not run RBP and TEP as they are very slow on these problems because they often fail to converge). We also implemented the greedy algorithm (Greedy) in [7]. We tried using the linear programming approach but free off-the-shelf solvers seem unable to scale to these problems. Results comparing RSP with Greedy, MBP and TRW-S are shown in Table 2. The F-measure attained by RSP for this SemEval task [1] is equal to the systems ranked second and third out of 16 participants (official results yet unpublished). We found that although TRW-S is guaranteed to converge, it performs poorly. RSP converges far better than MBP, but due to the Kernighan-Lin corrections that we run at each iteration, results can sometimes be corrected to a large extent by the local refinements.

Table 2: Results for the web person disambiguation task. (*: TRW-S is guaranteed to converge) In this paper, we formulated RSP, generalizing the formulation of SP- X  in [14]. SP- X  is the sum-product interpretation for the survey propagation (SP) algorithm [3]. SP has been shown to work well for hard instances of 3-SAT, near the phase transition where local search algorithms fail. However, its application has been limited to constraint satisfaction problems [3]. In RSP, we took inspiration from the SP-y algorithm [2] in adding a penalty term for violated clauses. SP-y works on MAX-SAT problems and SP can be considered as SP-y with y taken to  X  , hence disallowing violated constraints. This is analogous to the relation between RSP and SP- X  [14] (See Theorem 1). RSP is however different from SP-y since we address weighted MAX-SAT problems. Even if all weights are equal, RSP is still different from SP-y , which, so far, does not have a sum-product formulation on an alternative MRF. We show that while RSP is the sum-product algorithm on a relaxed MRF, it can be used for solving the energy minimization problem. By tuning the strengths of the factors (based on convergence criteria in [16]) while keeping the underlying distribution approximately correct, RSP converges well even at low temperatures. This enables it to return low-energy configurations on MRFs where other methods fail. As far as we know, this is the first application of convergence criteria to aid convergence of belief propagation algorithms, and this mechanism can be used to exploit future work on sufficient conditions for the convergence of belief propagation algorithms. Acknowledgments We would like to thank Yee Fan Tan for his help on the web person disambiguation task, and Tomas Lozano-Perez and Leslie Pack Kaelbling for valuable comments on the paper. The research is par-tially supported by ARF grant R-252-000-240-112.

