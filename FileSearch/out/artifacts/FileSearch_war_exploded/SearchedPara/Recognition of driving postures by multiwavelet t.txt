 1. Introduction very interested in the development of an intelligent Driver
Assistance System (DAS) that continuously monitors not only the surrounding environment and the status of vehicle, but also the driver X  X  behaviors. Driving is stressful and requires intensive cognitive processing from the driver, as well as carefully perform-ing maneuvers. As a result, recent research on vehicle automation has focused on developing Human-centric Driver Assistance
Systems (HDAS), which include integrated sensing, processing and networking. These systems aim to find solutions to traffic problems, such as traffic accidents and traffic congestion, and bring together the factors of people, roads and vehicles into a unified consideration. Automatic understanding and characterizing of driver behaviors is one of the key aspects for the development of HDAS.
 as attention, fatigue levels and other unsafe actions including eating and talking on a cellular telephone. They will reduce the driver X  X  alertness to the vehicle X  X  surrounding environment, and are more prone to being inattentive. Nadeau et al. Nadeau et al. (2003) carried out an epidemiological study on two large cohorts, namely users and non-users of cell phones, and the most significant finding was that the adjusted relative risks for heavy users were at least two times to those making minimal use of cell phones. To develop an effective driver behavior recognition system, two important techniques have to be included, i.e., how to efficiently describe a driver X  X  postures or maneuvers, and how to reliably classify the postures accordingly.
 manner using vision sensors. In the last decade, many new techniques have been proposed for the recognition of some simplified driving postures, such as moving forward, turning left and turning right. Simon and Berger ( Simon and Berger, 1998 ) presented a model registration system capable of tracking an object, and the heart of the model registration system is the pose computation method, which handles various features, such as points, lines and freeform curves. Oliver and Pentland ( Oliver and
Pentland, 2002 ) proposed a machine learning framework for modeling and recognizing a driver X  X  movements, with emphasis on how the context affects the driver X  X  performance using graphical models, Hidden Markov Models (HMMs) and Coupled Hidden Markov Models (CHMMs). Liu et al. (2002) described a vision system that tracks the driver X  X  face and estimates face poses while driving using yaw orientation angles. Eren et al. (2007) presented a stereo vision system for predicting driver X  X  face poses using Principle Components Analysis (PCA). Sekizawa et al. (2007) designed an intelligent system of modeling driver X  X  collision avoidance behaviors at the moment that a vehicle ahead is brought to a sudden halt. Watta et al. (2007) presented a vision system that recognizes the directions, at which the driver is looking, using a nearest neighbor-neural network classifier. Tran et al. (2012) developed a vision-based framework for driver foot behavior analysis using optical flow for foot tracking, and a Hidden Markov Model (HMM) based technique to characterize the temporal foot behavior. Adam and Untaroiu (2011) proposed a methodology for classification of pre-crash occupant posture using a Bayesian classification approach. Nine predefined classes of occupant postures were simulated with a human model, and the corresponding data was recorded using sensor models imple-mented in a mid-size car interior.

To address the problem of lacking stable illumination in images captured during driving by a color camera, Kato et al. (2004) developed a far infrared camera system to recognize the directions of the driver X  X  gaze using the feature points of nose, mouth and ears. Ki et al., (2007) researched the gaze-based 3D interaction techniques on stereo display, such as parallax barrier or lenticular stereo display. Cheng et al. (2007) introduced a multiple video-based system for recognizing the driver X  X  body orientation using images of the driver X  X  head from thermal and color cameras, hands images from thermal cameras, and steering wheel angle data from Controller Area Network (CAN) bus of the vehicle. Demirdjian and Varri ( Demirdjian and Varri, 2009 ) used an infrared time-of-flight (TOF) camera to estimate the location and orientation of a driver X  X  limbs, including arms, hands, head and torsion. Also, Cheng and Trivedi ( Cheng and Trivedi, 2006 ) suggested identifying a driver X  X  body pose using a commercial motion-capture system that uses retroreflective markers placed on the driver X  X  head, right hand and left hand. Yang et al. (2009) presented an ECG system to monitor a driver X  X  sitting postures, i.e., forward movement, back movement, right back movement and left back movement. In ( Cheng and Trivedi, 2010 ), a modified histogram-of-oriented-gradients feature descriptor and a support vector machine were used to classify occupants of the front seats as driver, passenger, or none.

Most of the above research works for driver activities recogni-tion focused on the detection of driver face direction, head orientation and gaze, etc. Although many other kinds of motion-capture technologies exist in the literature to recover body poses by using different kind of sensors like mechanical, magnetic or optical marker-based sensors to provide either three Degrees-Of-Freedom (DOF) position of a point on the subject X  X  body or full six DOF body-part position and orientation, such techniques have the biggest disadvantage that a subject is required to attach the sensor device or markers to his/her cloth or body, which is not a natural way of monitoring a driver X  X  activities. So, it is unlikely that drivers would accept any tethered sensing solution, i.e. using wired sensors or wireless sensors attached to the driver X  X  body. For this reason, image-based motion-capture would be more applicable in a consumer car without the requirement of special markers or user intervention. A few of recent works attempted to recognize and understand the driver X  X  postures, such as grasping the steel wheel, operating the shift lever, eating a cake and talking on a cellular telephone by using the image-based system. Only Harini et al. (2005 , 2007 ) proposed an agglomerative clustering and a Bayesian Eigen-image classifier to recognize two types of a driver postures: safe type and unsafe type with a side-mounted camera capturing the driver X  X  profile. How to characterize more realistic driving postures, however, is still a challenging problem.
A decisive step in developing image-based driver posture recognition is to extract suitable feature representation of the driver images and characterize the differences between different driving postures. In this paper, we propose an efficient feature extraction of driving postures based on Geronimo X  X ardin X  X as-sopust (GHM) multiwavelet transform, to describe driving pos-tures. And Multilayer Perceptron (MLP) classifiers, compared with the Intersection Kernel Support Vector Machines (IKSVMs), the k -Nearest Neighbor ( k NN) classifier and the Parzen classifier, are the redefined classes of driving postures: grasping the steel wheel, operating the shift n exploited in classifying feature vectors into one of the four lever, eating a cake and talking on a cellular telephone. The rest of this paper is organized as follows. In Section 2 , the background of Southeast University (SEU) driving posture data acquisition and normalization is outlined. In Section 3 , feature extraction by GHM multiwavelet transform is intro-duced. MLP classifier is presented in Section 4 . Section 5 intro-duces IKSVMs, k NN classifier and Parzen classifier. Section 6 details the experiments and reports the classification results for the driving postures. Finally, Section 7 gives our conclusions. 2. Driving posture data acquisition and normalization
Driving posture dataset is collected in this work by using a side-mounted Logitech C905 CCD camera. There are 10 male drivers and 10 female drivers in the driving postures dataset (Southeast University (SEU) dataset), and the lighting varied under the natural outdoor conditions, as the car was in an outdoor parking lot. The SEU driving posture dataset consists of four driving postures, i.e., grasping the steering wheel, operating the shift lever, eating a cake and talking on a cellar phone. Fig. 1 shows samples of our SEU driving posture dataset consisting of 80 driving posture images, each with a resolution of 480 640 pixels.

In order to address the problem of illumination variations in images of SEU driving postures dataset, the well-known normal-ization technique, called Homomorphic Filter (HOMOF), is adopted to enhance the image quality ( Heusch et al., 2005 ). With HOMOF, the images are first transformed into logarithm and then a frequency domain to emphasize the high frequency compo-nents. Then the images are transformed back into spatial domain by applying the inverse Fourier transform, followed by appro-priate exponential operation. The objects of interest in the driving images are the skin-like regions, such as the driver X  X  head, right hand and left hand. It is a fact that human skin tones have very similar chromatic properties regardless of race, and skin-color detection can be fairly robust under certain illumination condi-tions. The classification of color pixels into skin tones and non-skin tones can be performed by working in the normalized RGB space. An RGB triplet ( r , g , b ) with values for each primary color between 0 and 255 is normalized into the triplet ( r 0 , g 0 , b 0 )by using the following relationships: r 0  X  255 r r  X  g  X  b , g 0  X  255 g r  X  g  X  b , b 0  X  255 b lies within the region of the normalized RGB space described by the following rules ( Vezhnevets et al., 2003 ). max r 0 , g 0 , b 0 min r 0 , g 0 , b 0 4 15 8 &gt; &lt; &gt; :
Fig. 2 shows the skin-color segmentation results of the four example images preprocessed by HOMOF.
 3. Feature extraction using multiwavelet transform primarily because of the wide range of configurations and appearances of a human body, and its tendency to occlude itself in images. The problem is further complicated by the vehicular requirement for algorithms to be robust to changing illumination.
In this section, we show the potential of using the exposed skin spatial position of the driver X  X  head, right hand and left hand to build the driver X  X  posture features. Generalizing the wavelet case, one can allow a multiresolution analysis { V n }, n A N ,of L generated by a finite number of scaling functions f ( t )  X  ( f et al., 1999 ). Then, the multiscaling function f ( t ) T scale equation U  X  t  X  X  where 0 r c f r m 1 and L 1 [ c ]isa m m low-pass matrix with real coefficients. The multiresolution analysis structure gives
V 1  X  V 0 W 0 , where W 0 is the orthogonal complement of V V 1 . We can construct an orthonormal basis of W 0 generated by W ( t ) derived by W  X  t  X  X  where L 2 [ c ]isa m m high-pass matrix with real coefficients obtained by completion of { L 1 [ c ]}. Introduce the refinements masks L 1 z  X  :  X  1 2 L 2 z  X  :  X  1 2 where 0 r n 1 , n 2 r n 1, and z is a matrix variable. Eqs. (3) and (4) translate in Fourier domain into U (2 o )  X  L 1 ( e J U o able. Furthermore, we will assume that sequences { L 1 ( c ),0 r c r m 1} and { L 2 ( c ),0 r c r m 1} are finite, and thus that U ( t ) and W ( t ) have compact support. We also assume that
L 1 ( z ) verifies a matrix Smith X  X arnwell orthonormality condition so that the scaling function and their integer translate form an orthonormal basis of V 0 . Thus, for S ( t ) A V 0 , we have S  X  t  X  X  S  X  t  X  X 
Then, we derive the well-known relations between the coeffi-cients at the analysis step S 1  X  n  X  D 1  X  n  X  For the synthesis, we get S  X  n  X 
Geronimo et al. Tham et al. (2000) constructed one of the most well-known multiwavelet, called Geronimo X  X ardin X  X assopust (GHM) multiwavelet, which has two important features, i.e., orthonormality of integer translates of scaling functions and an approximation order of two. The resolution of images with 2 2 2  X  n 1 , n 2 A N  X  pixels is needed for GHM multiwavelet transform, and images of skin-color segmentation are rescaled to the same dimension of 256 256 pixels in this paper. Fig. 3 shows one example sub-images decomposed to level  X  1, 2, 3, using GHM multiwavelet transform. From each of the detail coefficient matrices of sub-images decomposed to level  X  3 using GHM multiwavelet transform, the first-order and second-order statis-tics means and standard deviations are calculated as features vectors of driving postures, and a 1 (256 2 3  X  1) dimension feature vector is extracted for a given driving posture image in this paper. 4. Multilayer perceptron classifier
In pattern classification, the most commonly used neural classifier is the feed-forward back-propagation Multilayer Percep-tron (MLP) ( Simon 1998 ). MLP, using a back-propagation algo-rithm, is the standard algorithm for any supervised-learning pattern recognition process ( Vigdor and Lerner, 2006 ; Martins et al., 2007 ; Kyperountas et al., 2007 ). MLP is also useful in research in terms of their ability to solve problems stochastically, which often allows one to get approximate solutions for extremely complex problems like fitness approximation. In this paper, MLP classifier with three layers is exploited in classifying driving postures, and its structure is illustrated in Fig.4 .
In the input layer, X  X  X  x 1 , , x i , , x p  X  T is the feature vector of driving postures, and p is the dimension of feature vector. In the weight vector of the hidden layer and q is the number of neurons in the hidden layer. U h  X  X  u 1 , , u j , , u q  X  T is the weighted sum vector of the hidden layer, and H  X  X  h 1 , , h j , , h q  X  output value vector of the hidden layer. In the output layer, W y  X  X  w y o is the class number of classification. U o  X  X  v 1 , , v is the weighted sum vector of the output layer, and Y  X  X  y 1 , , y r , , y o  X  T is the driving posture class. In the three layers, s h and s o are the activation transfer functions in the hidden layer and the output layer, respectively. Four activation transfer functions, which are commonly used in pattern classifi-cation, are the following.

Linear activation function  X  x  X  X  ax  X  ba and b are constants  X  12  X 
Logistic activation function  X  x  X  X  X  1  X  e x  X  1  X  13  X 
Softmax activation function  X  x  X  X 
Hyperbolic tangent activation function  X  x  X  X 
The linear activation function only produces positive numbers over the entire real number range. The logistic function is a common sigmoid curve, given its name by Verhulst ( Stefanie et al., 2003 ), and scales input data to (0, 1) according to Eq. (13) . The softmax activation function, proposed by Bridle ( Bridle, 1990 ), scales all of the output vales between 0 and 1, and their sum is 1, which is a generalization of the logistic function to multiple variables. The hyperbolic tangent function ( Spanier and Oldham, 1987 ) is defined as the ratio between the hyperbolic sine and the cosine functions. In our designed MLP structure, the hyperbolic tangent function is adopted in the hidden layer and other three activation functions, i.e., linear activation function, logistic activation function and softmax activation function, are adopted in the output layer compared, respectively.

Levenberg and Donald Marquardt ( Hagan and Menhaj, 1994 ), is ranked as one of the most efficient training algorithms of MLP for small and median size patterns ( Wilamowski, 2009 ). The basic idea of LM algorithm is that it performs a combined training process: around the area with complex curvature, LM algorithm switches to the Steepest Descent (SD) algorithm, until the local curvature is proper to make a quadratic approximation; then it approximately becomes the Gauss X  X ewton (GN) algorithm, which can accelerate the convergence significantly. The weight update rule of LM algorithm is where l is the current training time, W l is the current weight matrix, W l  X  1 is the next weight, J l is the current Jacobian matrix,
E l is the last total error, I is the identity matrix, and m is the combination coefficient. The training process using LM algorithm is designed as follows: 1) with the initial weights, evaluate the total error; 2) do an update as directed by Eq.16 to adjust weights; 3) with the new weights, evaluate the total error; 4) if the current total error is increased as a result of the update, 5) if the current total error is decreased as a result of the update, 6) go to step 2 with the new weights until the current total error 5. Other classification methods compared with models with associate learning algorithms that analyze data and recognize patterns, used for classification and regression analysis ( Cortes and Vapnik, 1995 ). The k -Nearest Neighbor algorithm ( k NN) is a method for classifying objects based on closest training examples in feature space ( Bremne et al., 2005 ). The Parzen classifier estimates probability density for each class using a non-parametric approach based on stored training examples ( Kraaijveld, 1996 ). The three classifiers are most commonly used in pattern classification, and adopted to classify driving postures in our study, to be compared with our designed MLP classifier in this paper. 5.1. Support vector machines with intersection kernel linear classification using the kernel trick, implicitly mapping the inputs to high dimensional feature spaces. Tuning the hyperpara-meters of a SVM classifier is a crucial step in order to establish an efficient classification system. Generally, at least two parameter values have to be chosen carefully in advance. They concern respectively the regularization parameter, which sets the trade-off cost between the training error and the complexity of the model, and the kernel function parameter. The problem of choosing these parameters values is called model selection in the literature and the results of choosing parameters strongly impact the performance of the classifier. In our study, we follow the conventional grid search method which selects the para-meters empirically by trying a finite number of values and keeping those that provide the least test error ( Chapelle et al., 2002 ). The histogram intersection kernel has been used as a measurement of similarity between two histograms. Due to the positive definite property, it can be used as a kernel for discrimi-native classification using SVMs. Recently, Intersection Kernel
Support Vector Machines (IKSVMs) have shown to be successful for a number of tasks, for instance, detection and recognition ( Maji, 2008 ). However, the earlier successful application of
IKSVMs often comes at great computational cost compared to simpler linear SVMs, because non-linear kernels require memory and computation linearly proportional to the number of support vectors for classification. Recently Maji et al. Platt (1999) pro-posed a fast IKSVM with an approximation scheme whose time and space complexity is O ( n N ), where n N is the dimension of training data, independent of the number of support vectors. The key idea is that for a class of kernels including the intersection kernel, the classifier can be decomposed to a sum of functions, one for each histogram bin, each of which can be efficiently computed. 5.2. k-Nearest Neighbor classifier based learning ( Bremne et al., 2005 ), or lazy learning where the function is only approximated locally and all computation is deferred until classification. The k -nearest neighbor algorithm is amongst the simplest of all machine learning algorithms: an object is classified by a majority vote of its neighbors, with the object being assigned to the class most common amongst its k-nearest neighbors ( k is a positive integer, typically small). If k  X  1, then the object is simply assigned to the class of its nearest neighbor. The k NN rule is optimal in the asymptotic case, i.e., the error tends to the Bayes error when the size of the training set tends to infinity. The major drawback of the k NN algorithm is the computational complexity, caused by the large number of dis-tance computations. 5.3. Parzen classifier
The Parzen classifier is a technique for non-parametric density estimation ( Kraaijveld, 1996 ), which can be used for classification. Using a given function, the technique approximates a given training set distribution via a linear combination of kernels centered on the observed points. The Parzen classifier estimates the relevant kernel width using the maximum likelihood principle proposed by Duin. 6. Experiments
Two standard experimental procedures, named the holdout approach and the cross-validation approach, are used to validate the proposed feature extraction method and MLP classifiers, compared with IKSVMs, the k NN classifier and the Parzen classifier. The MLP classifier is configured as a structure with three layers, i.e., one input layer, one hidden layer and one output layer. The number of neurons in the input layer is 2049, according to the feature vector dimension of driving postures extracted by GHM multiwavelet transform. There are 20 neurons in the hidden layer, and the number of neurons in the output layer is 4, according the class number of driving postures. The initial weights of the hidden layer and the output layer are drawn from a zero mean and unit variance isotropic Gaussian distribution, and normalized using the method of Nguyen and Widrow ( Nguyen and Widrow, 1990 ). LM algorithm ( Hagan and Menhaj, 1994 ) is used to train the MLP classifier, and  X  X  X arly stopping X  X  mechanism is used to overcome the problem of over-fitting ( Caruana et al., 2001 ). During the training process, the maximum number of epochs and the combi-nation coefficient are 1000 and 0.01, respectively. In the holdout approach, certain amounts of feature vectors extracted from images of SEU driving postures dataset (shown in Fig. 5 )are reserved for testing, and the rest are for training. In k -fold cross-validation approach, the driving posture datasets are partitioned into k sub-datasets. The k th sub-dataset is retained for testing and the remaining k X  1 sub-datasets are used for training. 6.1. Holdout experiments
Holdout experiments are based on randomly dividing feature vectors of driving postures into a training dataset (80% of feature vectors of driving postures extracted from images of SEU driving posture dataset) and a test dataset (20% of feature vectors of driving postures extracted from images of SEU driving posture dataset). Using the holdout experiment approach, only the test dataset is used to estimate the generalization error. We repeat the holdout experiment 100 times by randomly splitting SEU driving posture dataset, and recorded the classification results.
In the first holdout experiment, the same set of training and testing are applied to MLPs using three different activation functions (i.e., linear activation function, logistic activation func-tion and Softmax activation function) in the output layer, and hyperbolic tangent activation function in the hidden layer. The classification performances are simultaneously compared, and the results of classification rate for the driving postures are displayed in the bar plots of Fig. 6 (a) and box plots of Fig. 6 (b), which are the averaged classification results from the 100 random splits of SEU driving posture dataset into training and testing sets. The average classification accuracies of MLP classifiers, using linear activation function, logistic activation function and softmax activation function in the output layer, are 87.81%, 88.69% and 89.25%, respectively. From Fig. 6 , it is clear that MLP classifier, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, offers the best performance in the first holdout experiment.

In the second holdout experiment, the same set of training and testing are applied to MLP, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, and the other three classifiers, i.e., IKSVMs, the k NN classifier and the Parzen classifier, and their classification perfor-mances are simultaneously compared. The results of classification rate of IKSVMs, the k NN classifier, the Parzen classifier and MLP using softmax activation function in the output layer and hyper-bolic tangent activation function in the hidden layer, displayed in Fig. 7 , are 83.31%, 87.63%, 87.38% and 90.5%, respectively. From Fig. 7 , it show that MLP classifier, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, offers the best classification performance rate of the four classifiers in the second holdout experiment.
To further measure the classification performance regarding the information about actual and predicted classifications acquired, confusion matrix is often used. A confusion matrix is a square matrix or table that represents the number/proportion of examples from one class classified into another (or same) class. In the confusion matrix, the rows and columns indicate true and predicted class, respectively. The diagonal entries represent correct classifications, while the off-diagonal entries represent incorrect ones. In the holdout experiment, the confusion matrix that summarizes the detailed performance of feature extraction by GHM multiwavelet transform and MLP classifier, using soft-max activation function in the output layer and hyperbolic tangent activation function in the hidden layer, is shown in Table 1 . The rows and columns of the confusion matrix express the posture classes of grasping the steering wheel, operating the shift gear, eating a cake and talking on a cellular phone. The corresponding classification accuracies are 93.27%, 92.82%, 87.59% and 83.01%. From the confusion matrix of the holdout experi-ments, it is clear that of the four classes, talking on a cellular phone is the most difficult to classify. 6.2. Cross-validation experiments
The k -fold cross-validation approach ( Zhang and Zhang, 2008 ) is another commonly used technique that takes a set of m examples and randomly partitions them into k folds of size m / k . For each fold, the classifier is tested on one fold (consists of m / k examples) and trained on the other k  X  1 folds (consisting of m (1 X 1/ k ) examples). In the following experiments, 10-fold cross-validation was used. The 80 sets of feature vectors of driving posture extracted from images of SEU driving posture dataset are randomly divided into 10 subset of equal size (every subset consists of 8 feature vectors). Nine of these 10 subsets are trained and then tested on the one left out, each time leaving out a different one.

In the first cross-validation experiment, the comparisons of MLP classifiers using three different activation functions (i.e., linear activation function, logistic activation function and Softmax activa-tion function) in the output layer, and hyperbolic tangent activa-tion function in the hidden layer, are processed similarly as in the above. The feature vectors of driving postures extracted from images of SEU driving posture dataset are randomly divided into 10 folds for 100 times, and 100 cross-validation experiments are carried out. The average classification accuracies of the 100 cross-validation experiments are displayed in the bar plots of
Fig. 8 (a) and the box plots of Fig. 8 (b). The average classification accuracies of MLP classifiers, using three different activation functions (i.e., linear activation function, logistic activation func-tion and Softmax activation function) in the output layer, and hyperbolic tangent activation function in the hidden layer, are 88.38%, 89.42%, and 90.44%, respectively. It again show that MLP classifier, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, offers the best performance in the first cross-validation experiment.
In the second cross-validation experiment, 10-fold cross vali-dations are applied to MLP classifier, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, and the other three classifiers, IKSVMs, the k NN classifier and the Parzen classifier, and their classification performances are simultaneously compared. The results of classification rate of IKSVMs, the k NN classifier, the Parzen classifier and MLP using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, displayed in Fig. 9 , are 84.64%, 89.56%, 89.43% and 90.61%, respectively. From Fig. 9 , it also show that MLP, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer, offers the best classification performance rate of the four classifiers in the second cross-validation experiment.

In the second cross-validation experiment, the confusion matrix that summarizes the detailed performance of feature extraction by GHM multiwavelet transform and MLP classifier, using softmax activation function in the output layer and hyper-bolic tangent activation function in the hidden layer, is shown in Table 2 . The accuracies of the four classes are 97.78%, 91.74%, 89.09% and 84.04%, and once again, it is clear that talking on a cellular phone is the most difficult posture to classify among the four classes in the cross-validation experiments. 6.3. Discussions
Nguyen widrow weight initialization ( Maji, 2008 ) is a means of assigning initial values to the weight of a neural network, and this technique is one of the most effective neural network weight initialization methods available. In our designed MLP classifier, the initial weights of the hidden layer and the output layer are drawn from a zero mean and unit variance isotropic Gaussian distribution, and normalized using the method of Nguyen widrow weight initialization. The following experiment is created to show the impact of Nguyen widrow weight initialization on the classification results of four driving posture classes in this paper. One training dataset (80% of feature vectors of driving postures) is randomly sampled from SEU driving posture dataset, and the rest acts as the test dataset (20% of feature vectors of driving postures). Using the same training dataset and test dataset, the classification experiments are conducted 100 times with the weights of MLP classifier initialized 100 times using Nguyen widrow weight initialization. The 100 times experimental results of Nguyen widrow weight initialization are shown in Fig. 10 . From Fig. 10 , it shows that the most experimental accuracies are over 86%, and only one is less than 86%, which can be considered as the outlier result. In order to eliminate the outlier impact on the experimental results, the mean value of n times experiments can be used, and in our 100 experiments, the mean value of the experimental results is 93.31%, which show that Nguyen widrow weight initialization is effective in our designed MLP classifier, using softmax activation function in the output layer and hyper-bolic tangent activation function in the hidden layer, in classifica-tion of driving postures.

Compared to other state of the art methodologies for monitor-ing driver X  X  behaviors in current research literature, three contributions are presented in this paper. With the potential for short support and the capability of being both symmetric and orthogonal, multiwavelet transform has the good ability for feature description of images. The first contribution of this paper is that we proposed an effective feature extraction approach for driving postures using GHM multiwavelet transform. The second contribution is the MLP classifier with three layers, i.e., the input layer, the hidden layer and the output layer, is exploited in classifying four pre-defined classes of driving postures. The third contribution is that the holdout and cross-validation experiments are created, and the experimental results show the effectiveness of our proposed feature extraction method and our designed MLP classifier with three layers, using softmax activation function in the output layer and hyperbolic tangent activation function in the hidden layer. The confusion matrices of the holdout and cross-validation experiments show that talking on a cellular phone is the most difficult one among the four driving posture classes studied. The most advantage of our proposed approach for recognizing driver postures is that four detailed classes of driving postures have been be realized with high recognition rates using the vision sensor.
 recognizing driving postures is more sensitive to the skin-like color areas in the vehicles. When a driver dressed in clothes of skin-like color, the recognition system of driving postures will detect not only two hands and faces of drivers, but also the area of skin-like color clothes. And also when a driver dressed in gloves of no skin-like color, the area of two hands will be missed using our recognition system of driving postures. In the future, we will continue researching on the hand detection methods of drivers under bad conditions. 7. Conclusions behaviors, we proposed an effective features extraction approach based on GHM multiwavelet transform, and then, MLP classifiers with three layers, using hyperbolic tangent activation function in the hidden layer and softmax activation function in the output layer, was exploited in recognizing predefined four classes of driving postures, compared with IKSVMs, the k NN classifier and the Parzen classifier. With features extracted from SEU driving posture dataset, the holdout and cross-validation experiments show that feature extraction by GHM multiwavelet transform and
MLP classifier with three layers, using hyperbolic tangent activa-tion function in the hidden layer and softmax activation function in the output layer, offers the best classification performance than
IKSVMs, the k NN classifier and the Parzen classifier. The experi-mental results also showed that talking on a cellular phone is the most difficult one among the four classes studied, with classifica-tion accuracies of 83.01% and 84.04% in the holdout and cross-validation experiments. The results demonstrate the effectiveness of the proposed feature extraction approach and MLP classifiers in automatically understanding and characterizing driver behaviors towards HDAS.
 Acknowledgments Foundation of China under Project no. 51078087.
 Appendix. definition of symbols used in this paper s h the activation transfer function s o the activation transfer function
Y  X  X  y 1 , , y r , , y o  X  T The vector of driving posture
W l the current weight matrix where W l  X  1 1 2 the next weight matrix
J l the current Jacobian matrix
E l the last total error matrix
I the identity matrix m the combination coefficient References
