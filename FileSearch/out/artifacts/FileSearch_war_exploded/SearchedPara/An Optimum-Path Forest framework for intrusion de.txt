 1. Introduction
In the last decade, advances in technology allowed computers to be remotely managed and also provided a gateway to all kind of information through the Internet. In addition, organizations face the problem of keeping their information protected, available and reliable. Besides, obtaining confidential and privileged infor-mation coupled with the challenge to get them, became even more exciting to those people interested in obtaining unauthor-ized access in computer networks.

The motivations for such intrusions arise from obtaining secret data from companies with similar business in order to gain advantages to common people that are interested into learning how to attack private networks. In the last decade, the exponen-tial growing of wireless networks have attracted a wide range of users to find alternative methods for breaking the network X  X  cryptography. Initially, the main idea was to obtain access to the Internet, but further the people realized that a common hotspot could be a gateway to the companies X  information. The losses can be summarized as changes in private data due to malicious codes, network flooding, and comp uters X  interoperability, among others.

Since we have a wide variety of malicious codes that appear daily, approaches to contain intrusions have become more popular and widely pursued. In order to tackle this problem, companies have increased their budgets aiming the development of more effective intrusion detection systems, which are based on artificial intelligence techniques. Such approaches that try to model the human brain and the social dynamics have been used in several domain of applications, since biometrics Jia et al., 2008 , classifiers X  ensemble Zhang and Chau, 2009 and long-term discharge prediction Lin et al., 2006 , for instance.
Ghosh et al. (1998) , Cannady (1998) and Chabaa et al. (2010) applied Artificial Neural Networks with Multi-layer Perceptron (ANN-MLP) ( Haykin, 1998 ) to detect anomalies in computer networks. Zanero and Savaresi (2004) , Kayacik et al. (2007) and
Lei and Ghorbani (2004) employed Self-Organizing Maps (SOM) ( Haykin, 1998 ) for the same purpose. Some works ( Chen et al., 2005 ; Li and Gu, 2009 ; Haijun et al., 2007 ) have applied Support
Vector Machines (SVM) ( Cortes and Vapnik, 1995 ) to diagnose anomalies in computer networks. Wang and Wu (2010) proposed to use entropy analysis together with Holt X  X inters estimation to detect intrusions.

Very recently, Wu and Banzhaf (2010) have presented an extensive analysis of supervised, unsupervised and evolution-ary-based optimization techniques for intrusion detection in computer networks. Sindhu et al. (2012) proposed an approach composed of three steps in order to tackle the same problem: (i) to identify redundant data for further removal, (ii) to select the most representative subset of features and (iii) to design a decision tree-based classifier. Finally, Juca  X  et al. (2002) proposed an approach based on the human immune system to tackle the same task.
 niques may not be suitable to handle huge volumes of data in real time. A log file generated by a small network traffic monitoring system, for instance, can produce a considerable amount of information in a period of time. Artificial Neural Networks and
Support Vector Machines require high computational burden on training. The parameter optimization of the latter technique turns the quadratic optimization problem as an exponential one, which can be a serious problem in case of real time training systems. problem often faced. Several information of network packets, such as IP (Internet Protocol) and port address, access to system and file permissions, among others, increase the dimensionality of the feature space. Shyu et al. (2003) and Zhang and Wang (2008) have proposed to use Principal Component Analysis (PCA) ( Jolliffe, 2002 ) to reduce the number of features in the context of intrusion detection in computer networks. Stein et al. (2005) applied
Genetic Algorithms together with a decision tree-based classifier in order to select the optimum subset of features.
 for graph-based pattern recognition techniques called optimum-path forest (OPF), which reduces the problem of pattern recogni-tion to a problem of a graph partition into optimum-path trees (OPTs). In that approach, each OPT is rooted by a key sample (prototype) previously chosen, and any element that belongs to a given tree is more strongly connected to its root than to any other in the whole optimum-path forest (collection of OPTs). The strength of connectivity is established by a smooth path-cost function ( Falc ~ ao et al., 2004 ).
 based on the OPF framework, which is composed of a set of 2008 ), as well as a pruning algorithm, which can speed up the classification phase by selecting a compact but representative training set ( Papa et al., 2010 ), and also by a collection of feature selection methods based on evolutionary computing ( Ramos et al., , 2011 , 2002 ) that employ the OPF accuracy as the objective function. Our schema comprises both the intrusion detection in large volumes of data with supervised OPF and also the feature selection problem with efficiency and effectiveness. Therefore, the main contributions of this paper are fourfold: (i) as far as we know, this is the first time that OPF is applied to this context, as well as (ii) its pruning algorithm, (iii) we employed the OPF-based feature selection algorithms to reduce the dimensionality of datasets, since we have features that may be time consuming to be computed. Finally, (iv) we have shown how to further reduce redundancy in NSL-Kdd dataset. Experiments with SVM, SOM and a Bayesian classifier (Bayes) were conducted in order to assess the robustness of our proposed approach.
 theory is stated in Section 2 , and a brief review about the evolu-tionary-based feature selection technique is given by Section 3 .The experimental results and methodology are discussed in Section 4 .
Finally, conclusions are stated in Section 5 . 2. Optimum-path forest classifier recognition as a graph partition in a given feature space. The nodes are represented by the feature vectors and the edges connect all pairs of them, defining a full connectedness graph.
This kind of representation is straightforward, given that the graph does not need to be explicitly represented, allowing us to save memory. The partition of the graph is carried out by a competition process between some key samples (prototypes), which offer optimum paths to the remaining nodes of the graph. Each prototype sample defines its optimum-path tree (OPT), and the collection of all OPTs defines an optimum-path forest, which gives the name to the classifier ( Papa et al., 2009a , 2012 ). The OPF can be seen as a generalization of the well known Dijkstra X  X  (1959) algorithm to compute optimum paths from a source node to the remaining ones. The main difference relies on the fact that OPF uses a set of source nodes (prototypes) with any smooth path-cost function ( Falc ~ ao et al., 2004 ). In case of Dijkstra X  X  algorithm, a function that summed the arc-weights along a path was applied. In regard to the supervised OPF version addressed here, we have used a function that gives the maximum arc-weight along a path, as explained below.

Let Z  X  Z 1 [ Z 2 [ Z 3 be a dataset labeled with a function l ,in which Z 1 , Z 2 and Z 3 are, respectively, a training, evaluating and test sets. Let S D Z 1 a set of prototype samples. Essentially, the OPF classifier creates a discrete optimal partition of the feature space such that any sample s A Z 2 can be classified according to this partition. This partition is an optimum path forest (OPF) com-puted in R n by the Image Foresting Transform (IFT) algorithm ( Falc ~ ao et al., 2004 ).

The OPF algorithm may be used with any smooth path-cost function which can group samples with similar properties ( Falc ~ ao et al., 2004 ). Particularly, we used the path-cost function f which is computed as follows: f f max  X  p / s , t S  X  X  max f f max  X  p  X  , d  X  s , t  X g ,  X  1  X  in which d  X  s , t  X  means the distance between samples S and t , and a path p is defined as a sequence of adjacent samples. In such a way, we have that f max  X  p  X  computes the maximum distance between adjacent samples in p , when p is not a trivial path.
The OPF algorithm assigns one optimum path P n  X  s  X  from S to every sample s A Z 1 , forming an optimum path forest P (a function which can be reached from P ( s ). The OPF algorithm computes for predecessor P ( s ).

The OPF classifier is composed of two distinct phases: (i) training and (ii) classification. The former step consists, essentially, in finding the prototypes and computing the opti-mum-path forest, which is the union of all OPTs rooted at each prototype. After that, we take a sample from the test sample, connect it to all samples of the optimum-path forest generated in the training phase and we evaluate which node offered the optimum path to it. Notice that this test sample is not perma-nently added to the training set, i.e., it is used only once. The next sections describe in details this procedure. 2.1. Training
We say that S n is an optimum set of prototypes when the OPF algorithm minimizes the classification errors for every s Minimum Spanning Tree (MST) and optimum-path tree for f max and an OPF classifier rooted at S n .

By computing an MST in the complete graph  X  Z 1 , A  X  , we obtain a connected acyclic graph whose nodes are all samples of Z the arcs are undirected and weighted by the distances d between adjacent samples. The spanning tree is optimum in the sense that the sum of its arc weights is minimum as compared to any other spanning tree in the complete graph. In the MST, every pair of samples is connected by a single path which is optimum accord-ing to f max . That is, the minimum-spanning tree contains one optimum-path tree for any selected root node. The optimum prototypes are the closest elements of the MST with different Algorithm 1 implements the training procedure for OPF. Algorithm 1. OPF training algorithm.
 I
NPUT : A l -labeled training set Z 1 and the pair ( v , d ) for feature O
UTPUT : Optimum-path forest P 1 , cost map C 1 , label map L A
UXILARY : Priority queue Q , set S of prototypes, and cost variable 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Return a classifier  X  P 1 , C 1 , L 1 , Z 0 1 .

Lines 1 X 4 initialize maps and insert prototypes in Q . The main loop computes an optimum path from S to every sample S in a non-decreasing order of cost (Lines 5 X 13). At each iteration, a path of minimum cost C ( s ) is obtained in P when we remove its last node S from Q (Line 6), i.e., the one with minimum C ( s ). Ties are broken in Q using first-in-first-out policy. That is, when two optimum paths reach an ambiguous sample S with the same minimum cost, S is assigned to the first path that reached it. Lines 10 X 13 evaluate if the path that reaches an adjacent node t through S is cheaper than the current path with terminus t and update the position of t in Q , y  X  9
Z 1 9 2  X  , due to the main (Lines 5 X 13) and inner loops (Lines 8 X 13) in Algorithm 1 , which run y  X  9 Z 1 9  X  times each. 2.2. Classification
For any sample t A Z 3 , we consider all arcs connecting t with samples s A Z 1 , as though t were part of the training graph. Considering all possible paths from S n to t , we find the optimum incrementally by evaluating the optimum cost C ( t )as C  X  t  X  X  min f max f C  X  s  X  , d  X  s , t  X gg , 8 s A Z 1 :  X  2  X 
Let the node s n A Z 1 be the one that satisfies Eq. (2) (i.e., the predecessor P ( t ) in the optimum path P n  X  t  X  ). Given that this procedure.
 Algorithm 2. OPF classification algorithm.
 I NPUT : Classifier  X  P 1 , C 1 , L 1 , Z 0 1 , test set Z O
UTPUT : Label L 2 and predecessor P 2 maps defined for Z A UXILIARY : Cost variables tmp and mincost . 1 2 3 4 5 6 7 8 9
In Algorithm 2 , the main loop (Lines 1 X 9) performs the classification of all nodes in Z 3 . The inner loop (Lines 4 X 9) visits 2.3. Learning from errors on the evaluation set
From an initial choice of Z 1 and Z 2 , the algorithm projects an instance I of a given classifier from Z 1 and evaluates it on Z misclassified samples of Z 2 are randomly selected and replaced by samples of Z 1 (under certain constraints). This procedure assumes that the most informative samples can be obtained from the errors. The new sets Z 1 and Z 2 are then used to repeat the process during a few iterations T . The instance of classifier with highest accuracy is selected along the iterations. The accuracy values L  X  I  X  obtained for each instance I form a learning curve, whose non-decreasing monotonic behavior indicates a positive learning rate for the classifier. Afterwards, by comparing the accuracies of the classifier on Z 3 , before and after the learning process, we can evaluate its learning capacity from the errors.
 account that the classes may have different sizes in Z 2 (similar definition is applied for Z 3 ). If there are two classes, for example, with very different sizes and a classifier always assigns the label error rate on the smallest class.

Let NZ 2  X  i  X  , i  X  1 ; 2 , ... , c , be the number of samples in Z each class i (similar definition is applied for Z 3 ). We define e  X  respectively. That is, FP ( i ) is the number of samples from other classes that were classified as being from the class i in Z
FN ( i ) is the number of samples from the class i that were incorrectly classified as being from other classes in Z 2 e and e i , 2 are used to define
E  X  i  X  X  e i , 1  X  e i , 2 ,  X  4  X  L  X  I  X  , I  X  1 ; 2 ... , T , are written as L  X  I  X  X  2 c
Algorithm 3 presents this learning procedure. Line 4 is imple-mented by computing S n Z 1 as described in Section 2.1 and the predecessor map P , label map L and cost map C by Algorithm 1 . The classification is done by setting L  X  t  X   X  L  X  s n  X  , where s n sample that satisfies (2). The constraints in Lines 19 X 20 refer to keep the prototypes out of the sample interchanging process between Z 1 and Z 2 . Lines 5 and 6 initialize the false positive and false negative arrays for accuracy computation. The classification of each sample is performed in Lines 7 X 13, updating the false positive and false negative arrays. Misclassified samples are stored in the list LM (Line 13). Line 14 computes the accuracy inner loop in Lines 17 X 20 changes the misclassified samples of Z by randomly selected samples of Z 1 , under the aforementioned constraints.
 Algorithm 3. OPF learning algorithm.
 2.4. Learning with pruning of irrelevant patterns on Z 2 , during a few iterations in order to select the instance of that the most informative samples in Z 2 are the misclassified ones. It replaces these samples by non-prototype samples in Z
We have relaxed the restriction of replacing samples only that belong to the same class, as proposed by Papa et al. (2009a) . The idea is to allow classes that require more samples in the training set to have them without increasing the training set size. The restriction of preserving prototypes is kept, but observe that those samples may be selected for replacement in future iteration, if they are no longer prototypes.
 samples in Z 1 in order to speedup learning and further reduce that number to speedup classification. Therefore, we propose a new learning algorithm which starts from 9 Z 1 9 o 9 Z 2 9 and combines
Algorithm 3 with the identification and elimination of irrelevant samples from Z 1 to reduce its size ( Papa et al., 2010 ). A sample is said irrelevant if it is not used to classify any sample in Z it does not belong to any optimum path which was used to classify the samples in Z 2 . The remaining samples, said relevant, can be easily identified during classification by marking them in the optimum path P n  X  t  X  (2), as we follow backwards the predecessor nodes of t in P until its root prototype R ( t ) (Note that P  X  R  X  t  X  X  X  nil ). However, by moving the irrelevant samples (samples that did not participate from the classification process can repeat the learning and pruning processes until no irrelevant sample exists in Z 1 . This algorithm is presented below. Algorithm 4. Learning-with-pruning algorithm.
 I
NPUT : Training and evaluation sets, Z 1 and Z 2 , labeled by O UTPUT : OPF classifier with reduced training set.
 A
UXILIARY : Sets R  X  | and I  X  | of relevant and irrelevant 1 2 3 4 5 6 7 8 9 10
The main loop (Lines 1 X 10) executes the learning algorithm with pruning until no irrelevant samples remains in Z 1 . Line 2 obtains the most informative samples from Z 1 [ Z 2 to project an OPF classifier on Z 1 . All samples in Z 1 used to classify samples in Z are included in the relevant set R (Lines 4 X 8). Line 9 inserts in I the irrelevant samples of Z 1 and these samples are moved from Z to Z 2 in Line 10. 3. Evolutionary optimization background
This section presents the evolutionary techniques for feature selection addressed in this paper: Particle Swarm Optimization, Harmony Search and Gravitational Search Algorithm. 3.1. Particle swarm optimization
Particle Swarm Optimization (PSO) is an algorithm modeled on swarm intelligence that finds a solution in a search space based on social behavior dynamics ( Kennedy and Eberhart, 2001 ). Each possible solution to the problem is modeled as a particle in the swarm that imitates its neighborhood based on the values of the fitness function found so far. In this context, each particle has a memory that stores its best local solution (local maxima) and the best global solution (global maxima). Thus, taking this information into account, each particle has the ability to imitate the others that give to it the best local and global maxima. This socio-cognitive mechanism can be summarized into three main principles ( Kennedy and Eberhart, 2001 ): (i) evaluating, (ii) comparing and (iii) imitating. Each particle can evaluate others in its neighborhood through some fitness function, can compare it with its own value and, finally, can decide whether it is a good choice to imitate them.
The entire swarm is modeled in a multidimensional space R N , in which each particle p i  X  X  x i ! , v i !  X  features: (i) position ( x i ! ) and (ii) velocity ( v i ! current position b x i ) and global solutions b s are also known. After defining the swarm size, i.e., the number of particles, each one of them is initialized with random values for both velocity and position. Each individual is then evaluated with respect to some fitness function and its local maximum is updated. At the end, the global maximum is updated with the particle that achieved the best position in the swarm. This process is repeated until some convergence criterion is reached. The updated position and velocity equations of particle p i , in the simplest form that governs the PSO, are, respectively, given by v !  X  wv i !  X  c 1 r 1  X  b x i x i !  X  X  c 2 r 2  X  b s x i !  X  X  6  X  and x !  X  x i !  X  v i ! ,  X  7  X  where w is the inertia weight that controls the power of the interactions between the particles, and r 1 , r 2 A  X  0 ; 1 are random variables that give the idea of stochasticity to the PSO method. Constants c 1 and c 2 are used to guide particles onto good directions. 3.2. Harmony search
Harmony Search (HS) is an evolutionary algorithm inspired in the improvisation process of music players ( Geem, 2009 ). The main idea is to use the same process adopted by musicians to create new songs to obtain a near-optimal solution for some optimization process. Basically, any possible solution is modeled as a harmony and each parameter to be optimized can be seen as a musical note. The best harmony (solution) is chosen as the one that maximizes some optimization criteria. The algorithm is composed of few steps, as follows: (1) initialize the optimization problem and algorithm parameters; (2) initialize a Harmony Memory (HM); (3) improvise a new harmony from HM; (4) update the HM if the new harmony is better than the worst harmony in the HM (if so, include the new harmony in HM, and remove the worst one from HM); and (5) if the stopping criterion is not satisfied, go to Step 3.
The HS parameters required to solve the optimization problem are the harmony memory size (HMS), the harmony memory considering rate (HMCR), the pitch adjusting rate (PAR), and the stopping criterion. HMCR and PAR are parameters used to improve the solution vector, i.e., they can help the algorithm to find globally and locally improved solutions in the harmony search process.

In Step 2, the HM is initialized with randomly generated solution vectors with their respective values for the objective function. Note that in HS principles, each harmony h i  X  X  x only the information about its position in the search space (Harmony Memory). In Step 3, a new harmony h 0  X  X  x 0 !  X  , such based on memory considerations, pitch adjustments, and rando-mization (music improvisation). In Step 4, if the new harmony h is better than the worst harmony in the HM, the latter is replaced by this new harmony. Finally, in Step 5, the HS algorithm finishes when it satisfies the stopping criterion. Otherwise, Steps 3 and 4 are repeated in order to improvise a new harmony again. 3.3. Gravitational search algorithm
Gravity is one of the four fundamental interactions of nature, along with the strong force, electromagnetism and the weak force. The idea that rules gravity concerns with the fact that an object with mass attracts one another.

One of the most accepted theory is the Newton X  X  law of universal gravitation, which says that  X  X  X very massive particle in the universe attracts other massive one with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between them ( Halliday et al., 2000 ). Newton X  X  second law says that when a force is applied to a mass, its acceleration only depends on the force and its own mass.
 Based on such principles, Rashedi et al. (2009) proposed the
Gravitational Search Algorithm (GSA), which models the optimi-zation problem in a similar manner that PSO does, but now the particles are replaces by masses, and the interaction between them is ruled by the Newton X  X  laws of gravitation. In order to avoid local optimal solutions, only the best masses, i.e., the ones with highest fitness values, will attract others. 4. Experimental results
In this section we described the experiments conducted in order to assess the robustness of OPF classifier to detect intru-sions in computer networks, as well as the datasets employed to this task ( Section 4.1 ). The experiments were conducted in three rounds: in the former ( Section 4.2 ) we compared OPF against some state-of-the-art supervised pattern recognition techniques, and in the second experiment ( Section 4.3 ) we introduced the OPF training set pruning algorithm in the context of intrusion detec-tion systems. This algorithm was designed to learn the most informative samples of the training set and to discard the remaining ones. Thus, one can identity and remove redundancy in datasets, speeding up the training phase. Finally, in the last round of experiments ( Section 4.4 ), we have evaluated three optimization algorithms to select the best set of features that maximize the OPF accuracy over an evaluating set. 4.1. Datasets
In this work, we have employed three public datasets, as described below:
IDS_Bag 1 : this dataset comprises a collection of systems call sequences collected at the Massach usetts Institute of Technology
Lincoln Lab during one week. The original datasets were mapped to a bag of system calls representation ( Kang et al., 2005 ), and were originally designed to detect misuse and anomalies in computer networks.

KddCup 2 : this dataset is composed of hundreds of thousands of samples and is divided into 23 classes, being 22 of them related with network attacks, and the remaining one stands for a normal access. The number of features is 41. In this paper, we used a reduced dataset, which is composed of 10% of the original dataset size.

NSL-Kdd 3 : this is a dataset specially designed to remove redundancy of the well known KDD X 99 dataset. More details about it can be found in Tavallaee et al. (2009) .
 In case of KddCup dataset, we used four distinct variants:
KddCup-5: this version contains six classes, being five attacks and the normal access. The attacks comprises back DoS, buffer overflow, ftp_write, guess_passwd and imap;
KddCup-10: this version contains 11 classes, being 10 attacks and the normal access. The attacks comprises back DoS, buffer overflow, ftp_write, guess_passwd, imap, ipsweep, land DoS, loadmodule, multihop and neptune and
Table 1 displays more information about the above datasets. 4.2. Supervised classification applied to intrusion detection systems assess the robustness of the supervised pattern recognition techniques, with 50% for training and the remaining 50% to compose the test set. The experiments were executed over a 10-cross-validation in order to compute the mean accuracy and training and test times in seconds. Recall that these values were empirically chosen, and the labels X  distribution of datasets has been preserved after data partitioning.

In regard to the pattern recognition techniques, we have compared OPF with SVM-RBF (SVM with Radial Basis Function for kernel mapping function), SOM and a Bayesian classifier. For OPF and SVM-RBF we have used LibOPF ( Papa et al., 2009b )and SVMTorch ( Collobert and Bengio, 2001 ) packages, respectively, and with respect to SOM and Bayesian classifier we have employed our own implementation. For SOM, we used a 100 100 neural lattice with 10 iterations for learning, and the SVM-RBF parameters have been optimized through cross-validation. Tables 2 and 3 display the results over IDS_Bag and KddCup and NSL-Kdd datasets, respectively. One can see from Table 2 that IDS_Bag is composed of subsets, which stand for different weekdays.

From Table 2 , one can see that OPF has been the sole classifier that achieved the best recognition rates for Monday and Thursday subsets if we consider the standard deviation. In regard to the remaining subsets, OPF, SVM-RBF and Bayes achieved similar recognition rates. Although Bayes has been the fastest approach for training in all subsets, OPF was the most efficient in the testing phase. In addition, if one takes into account the whole execution time, i.e., training and testing, OPF has been faster than SVM-RBF and Bayes for all subsets. A paired T student test with 95% of significance was performed in order to validate the results, and the final conclusion attests there is no difference among the pairs (OPF,SVM-RBF), (BAYES,SVM-RBF) and (BAYES,SOM). The statis-tical test has found that OPF is significantly more accurate than BAYES and SOM, and also that SVM-RBF is significantly more accurate than SOM classifier.

From Table 3 , one can see that OPF, SVM-RBF and Bayes have been the most effective techniques for all KddCup subsets, being Bayes the fastest one again for training, and OPF the fastest approach for testing. Again, if one considers the whole execution time, OPF has the fastest classifier for all subsets. In regard to NSL-Kdd dataset, we can see that OPF, Bayes and SOM classifiers have achieved similar recognition rates. A paired T student test with 95% of significance was performed in order to validate the results, and the final conclusion attests there is no difference among all classifiers.

The most interesting behavior concerns with the recognition rate, which increases as we consider more attacks. One of the possible explanation for that concerns with the accuracy measure (Eq. (5)), which penalizes misclassification in unbalanced data-sets. Just to show that, imagine a dataset with 100 samples, in which 90 of them belong to class 1, and the remaining 10 belong to class 2. If a classifier misclassifies all samples from class 2, and correct classifies all samples from class 1, a traditional accuracy measure would give us 90% of recognition rate. However, using our accuracy measure, the recognition rate would be 50%. There-fore, as we increase the number of classes, the penalization over misclassification is minimized among all classes. 4.3. Pruning redundant data
There exist some situations in which we have limited compu-tational resources (e.g., storage capacity and consuming time). Since the training step is the one that often requires high computational burden, it is desirable to have compact, but representative training sets. Recently, Papa et al. (2010) proposed a learning algorithm that is capable to identify the most relevant training samples and discard the remaining ones. This procedure may lead us to compact representations of training data, without loss of generality.

The idea is to mark the training samples that participated from some classification process over the evaluating set. After that, the unmarked samples are then moved to the evaluating set and the process is repeated over again until some criterion is reached. In our case, the stop criterion is given by MLoss , which is defined as the maximum loss of accuracy with respect to the original evaluating set. In order to make it clear, if one set MLoss  X  0.3, for instance, this means that the absolute difference between the accuracy over the pruned evaluating set and the accuracy over the original one is bounded by 30%.

Finally, the pruned training set will be used to assess the effectiveness over the unseen test set. Thus, the MLoss parameter can be seen as a trade-off between the training set pruning rate and the efficiency over the test set. If one choose high values of MLoss , the algorithm may prune too much samples, affecting the effectiveness over the test set. Otherwise, low values of MLoss may lead us to poor pruning rates.

Let Z 1  X  Z 11 [ Z 12 , in which Z 11 is the new training set, and Z stands for the evaluating set. In this experiment, we divided the training set ( Z 1 ) used in the previous experiment ( Section 4.2 ) into 30% for Z 11 and 20% for Z 12 . This experiment was carried out only with KddCup dataset, since IDS_Bag dataset does not contain more than a few hundred samples. Although the OPF pruning algorithm can be applied to any situation, we are interested in large datasets. Table 4 displays the mean accuracy and testing time over 10 running with training, evaluating and testing sets randomly generated for KddCup and NSL-Kdd datasets. We have used MLoss  X  0.6. Note that this value has been empirically chosen.

Table 5 shows the speedup of OPF with pruning over tradi-tional OPF, and also the mean pruning rate. One can see that OPF with pruning has been much faster than traditional OPF for all
KddCup subsets, and also for NSL-Kdd. The mean pruning rate shows the amount of redundant data inherent to datasets. It is important to shed light over that OPF with pruning has achieved better results than SOM, SVM-RBF and SOM again for KddCup-5,
KddCup-10 and KddCup-15 datasets, respectively. Actually, with respect to this latter dataset, the OPF with pruning accuracy has been much closer to the one obtained with Bayesian classifier. Another point that needs to be highlighted concerns with
NSL-Kdd dataset, which has been designed in order to reduce redundant data from KddCup one. In this paper, we have shown that we can further reduce its redundancy up to 72%.

Finally, Table 6 shows the classification time of OPF with pruning for each dataset sample, as well as their testing set sizes.
One can clearly see that OPF with pruning is suitable for on-line intrusion detection in computer networks. In case of KddCup-5 dataset, for instance, OPF with pruning only needed about 5 ms to classify one sample. 4.4. Feature selection through optimization techniques
In regard to feature selection, we have evaluated three algo-rithms: PSO-OPF ( Ramos et al., 2011 ), HS-OPF ( Ramos et al., 2002 ) and GSA-OPF ( Ramos et al., ). For that, we have used 30% to compose the training set, 20% to the evaluating one and the remaining 50% for the test set. Table 7 displays the parameters used to tune the algorithms. The number of iterations for convergence has been set to 10 for all approaches. The same occurs with the number of initial solutions, i.e., number of particles for PSO-OPF, number of harmonies for HS-OPF and number of masses for GSA-OPF, which has been set to 100. Notice that these values were empirically chosen in order to avoid meta-optimization.
 same number of features, we have applied the feature selection algorithm only over KddCup-15, since it is the one that has a wider range of attacks. Table 8 displays the results over the test set. One can see that all techniques have obtained the same results for both datasets. The difference relies on the execution time, in which PSO-OPF and HS-OPF have been executed in a similar period of time, being up to two times faster than GSA-OPF. We can see that HS-OPF has selected 16 out 41 features for
KddCup dataset, which means about 150% of reduction in the number of features. In case of NSL-Kdd, HS-OPF has also allowed about 86.36% of reduction. It is important to shed light over that this reduction can provide a faster feature extraction procedure, with the compromise of similar and good recognition rates as in the original datasets, i.e., without feature selection. 5. Conclusions in the last years. Since the number of malicious and unauthorized accesses to private information has increased, a special attention has been devoted to intrusion detection systems that make use of artificial intelligence to improve their effectiveness. always with reasonable efficiency. In this paper, we have pro-posed a new intrusion detection system that employs a recent pattern recognition technique called optimum-path forest, which has never been applied to this context up to date. The experi-ments were carried out in three phases: in the former we compared OPF with SVM-RBF, a Bayesian classifier and SOM networks, in the second round we showed how to make OPF even faster to detect attacks in computer networks, and finally we have employed evolutionary-based feature selection algorithms. SVM-RBF and Bayesian classifier achieved similar results, being
OPF the fastest approach if we consider the whole execution time, i.e., training and testing. Further, we applied the OPF pruning algorithm in order to make OPF faster, aiming to obtain a reduced and representative training set. The results indicated that OPF with pruning can be fast enough to detect anomalies in real time with reasonable accuracy. Finally, we evaluated three evolution-ary techniques in order to reduce feature extraction time through selecting the best set of features: PSO-OPF, HS-OPF and GSA-OPF, in which all of them have obtained the same accuracy, being PSO-OPF the fastest approach. The experiments have showed that one can use less features and also to improve the recognition rate.
For future works we intend to apply OPF in more datasets, as well as to evaluate new learning algorithms in the context of intrusion detection in computer networks. Another research will be guided to employ OPF clustering to the same task. In addition, we are now working on new methods to make OPF training phase faster. Therefore, the large volume of data provided by intrusion detection datasets can be very useful to validate such ideas. Acknowledgments
The authors would like to thank FAPESP grants #2009/16206-1, #2010/02045-3 and #2010/11676-7. We would also like to thank Professor Dae-Ki Kang from Division of Computer Engineering, Dongseo University  X  South Korea, for IDS_Bag dataset. References
