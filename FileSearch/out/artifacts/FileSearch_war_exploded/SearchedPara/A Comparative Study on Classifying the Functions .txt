 In this paper, we study the problem of learning block clas-sification models to estimate block functions. We distin-guish general models, which are learned across multiple sites, and site-specific models, which are learned within individ-ual sites. We further consider several factors that affect the learning process and model effectiveness. These factors include the layout features, the content features, the classi-fiers, and the term selection methods. We have empirically evaluated the performance of the models when the factors are varied. Our main results are that layout features do better than content features for learning both general and site-specific models.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information filtering, selection process ; I.7.m [ Document and Text Processing ]: Mis-cellaneous Algorithms Web page block, block function, block classification model, feature selection, layout features, content features.
Dividing a Web page into blocks and classifying their func-tions is the basis for many Web IR and mining tasks, for instance, Web page classification clustering and topic ex-traction. Also, it can assist fragment-based caching systems in deciding their caching policies on individual fragments. Additionally, block function classification can directly help Web users focus on the blocks of interest in a page, if the blocks with different functions are marked differently.
Existing work has studied a few factors in block function learning, but these factors are usually considered in isolation and little work has studied all factors systematically. For instance, Chen [2] and Song [3] do not consider term features and do not fully explore layout features. Especially, Chen [2] uses some heuristic rules to evaluate the block functions.
In this paper, we systematically study the problem of learning block function models from some example blocks with known functions. First, we divide each page in a train-ing set into blocks. Then, we extract features to represent the blocks and manually label their functions. After this preprocessing step, we use a classification method to auto-matically train a block function classification model from the labeled examples. Depending on where the training ex-amples are from, we call the model either general or site-specific . A general model is trained from pages of multiple sites whereas a site-specific model is from a single site.
After a block function classification model is trained from examples, we can then classify the function of the blocks in a new page. We divide the page into blocks and represent each block as a set of features. After that, we pass the feature representation of the blocks to the model. The functions of the blocks are automatically obtained by the model. There are several factors that affect model effectiveness. First, what features should we use to represent a block? Although both textual content features and visual layout features can reflect block function, it is unclear which one will be more effective or whether mixing them will enhance the performance of the model. Second, if content features are used, what term feature selection method is the best and how many content features do we need to use? Third, how is the performance of site-specific models versus general models? What are their respective scopes of application? Fourth, how do classification methods affect the effectiveness of the models? In this paper, we attempt to answer these questions through a systematic comparative study.
In this section, we describe in detail the block function classification process, and discuss general models versus site-specific models.

We first used the VIPS algorithm [1] to divide a Web page into multiple blocks. We then extract and select the features to represent each block. The features that we consider in-clude textual content features, i.e., the words contained in the text of the block, and visual layout features that express the presentation style, the spatial information, and the vi-sual appearance of the block.

To extract and select content features, we first extract the text contained in a block, break it into words, and remove the stop words. Then, we use a method to select keywords in the resulting set of words to construct the term feature space. After that, we record the number of occurrences of each selected term feature as its feature value. We consider four candidates for the term selection method. They are document frequency (DF), information gain (IG), mutual information (MI), and  X  2 statistic (CHI).

We categorize the extracted layout features into four types: 1) spatial features that describe spatial location and size of ablock,2)presentationfeaturesofthetextandimagesin a block including the font information, the length of inner and anchor text, the number and the size of the images, etc., 3) tag features, which record the numbers of various HTML tags in the HTML source of a block such as &lt; form &gt; &lt; p &gt; , etc., and 4) hyperlink features including the numbers of intra-site and inter-site hyperlinks, hyperlinks on anchor text and images, etc.

After the blocks are represented as features, we label the functions of some example blocks. We categorize the func-tions of blocks with two schemes. One is a 5-class scheme, in which the functions of blocks are information , interac-tion , navigation , advertisement ,and others . The other is a 2-class scheme, in which we consider the information and navigation functions as informative blocks, and the remain-ing three functions as noisy blocks. Even though other clas-sification schemes are also possible, these two schemes are sufficient for the purpose of our comparative study.
Since we view a block as a vector of features x and the function of the block as its label y , our classification problem is a single-label, k-class one, with k being 2 or 5.
The learning process is to take the labeled training set ( x, y ) n i =1 , where n is the number of instances in the training set, as input to a classifier to train a classification model f ( x ). After f ( x ) is generated by the classifier, we can use it to label the functions of the blocks in new Web pages.
There exist several learning methods to train a classifica-tion model. In this paper, we study four representative ones, including Naive Bayes (NB), Logistic Regression (LR), lin-ear Support Vector Machine (L-SVM), and nonlinear SVM with a Gaussian RBF kernel (SVM-RBF).

We also study the effects of the Web site context on classi-fying block functions, i.e., compare site-specific models and general models. A site-specific model is expected to perform better than a general model because pages in a site are of a more consistent layout and presentation style than pages in different Web sites and tend to use particular words in a category of blocks. Therefore, the block examples from one site can be more representative for the characteristics of different block functions and can produce a more effective model than examples from different Web sites. However, building site-specific models is more costly since it requires learning from examples on a per-site basis.

Given the pros and cons of site-specific models and gen-eral models, we suggest they be used in different scopes of applications. Site-specific models should be used for a few Table 1: Number of blocks in four kinds of data sets. sites with a large number of pages, to label the block func-tions more accurately, as these pages are accessed frequently. In contrast, it is sufficient to build a general model for the large number of small sites, which are accessed infrequently, to label the block functions less accurately.
We have conducted experiments to study the effect of var-ious factors on the performance of the models, either general or specific, using the two function schemes. These factors include different classifiers, feature schemes, and content fea-ture selection methods. Table 1 shows the numbers of blocks in the data set we used to train and test the models.
We find that layout features outperform 25-1600 term fea-tures in both general and site-specific models. For example, with the 5-class function scheme, using layout features can achieve a micro-averaged classification accuracy of 0.81 in general models and 0.87 in site-specific models. In compar-ison, using term features results in 0.56 in general models and 0.87 in site-specific models. In addition, mixing lay-out and term features helps improve the performance of the models. For example, with the 2-class function scheme, the micro-averaged accuracy of general models trained by L-SVM increases from 0.89 to 0.93 when layout features are combined with 800 terms selected by IG.

We also study the impact of four term selection methods and four classifiers. DF, IG, and CHI have similar capabili-ties of feature selection while MI has the worst. The L-SVM, SVM-RBF, and LR classifiers outperform the NB classifier on training block function models.

Site-specific models have a better performance than gen-eral models. For example, with the 2-class function scheme, the micro-averaged accuracy of the general model trained by LR using layout features is 0.86, and that of the site-specific model trained by the same classifier using the same feature scheme is enhanced to 0.91.
In this paper, we study the problem of learning block func-tion classification models from example Web page blocks. We classify our model into two kinds, site-specific or gen-eral, based on the source of the training pages. Moreover, we study various factors that affect the learning process and model effectiveness through experimental evaluation. [1] D. Cai, S. Yu, J.-R. Wen, and W.-Y. Ma. Vips: a [2] J. Chen, B. Zhou, J. Shi, H. Zhang, and Q. Fengwu. [3] R. Song, H. Liu, J.-R. Wen, and W.-Y. Ma. Learning
