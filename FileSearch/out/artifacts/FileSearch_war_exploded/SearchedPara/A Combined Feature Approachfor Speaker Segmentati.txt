 Speaker segmentation aims at detecting the time reversal point of speakers in an audio stream, and focuse s on segmenting the audio stream into pieces, each contains only one speaker X  X  voice. Speaker segmentation plays an important role in speech application [ 1 ] , speaker di arization [2,3] and content -based audio signals analysis [4] .
In general, there are two main categories of the speaker segmentation task: one is mentation algorithm [ 7 ]. The most common segmentation algorithms based on distance KL2) [9] and Gener alized Likelihood Ratio(GLR) [ 10], which are used to measure the voices are from the same person or not. Among these algorithms, BIC is widely used decoding -based segmentation algorithm, such as Gaussian Mixture Model(GMM) [11], is used to train speaker segmentation model by a priori knowledge about the content of news broadcast and customer service calls of the major business services, this kind of voice background environment is called as CALL_CENTER. Therefore, this paper fo-cuses on the model -based speaker se gmen tation algorithm in CALL_CENTER envi-ronment.

CNN is a deep neural network with a special kind of layer the convolution layer. The two characteristics of CNN local perception and parameter sharing can greatly reduce structed by CNN can be set to different depth and breadth, so CNN has been applied research [13,14].
 CALL_CENTER environment, a speaker segmentation algorithm is proposed based on a Combined feature approach by using CNN, which i s used to train the speakers X  voice features model and to estimate the speaker change point. The paper uses a voice that contains two speakers, the different voic e information between the opera tor and non -method does not need to set the threshold value, which greatly reduces the computation the changes of acoustic characteristics. Compa red with the traditional speaker segmen-algorithm is more effective in this paper.

The main contributions of the proposed results in this paper are summarized as fol-lows:  X 
The C NN method is introduced into the speaker segmentation, which further reduces the redundant segmentation problem in t he speaker segmentation pro-cess.  X 
In order to more fully describe the feature of speech, this paper combines MFCC and SPECTROGRAM , as a new combined feature is used to the speaker seg-mentation problem , and got better segmentation effect .
 This paper is organized as follows. In Section 2, the combined feature is proposed. The overall framework of the algorithm is proposed in Section 3. In Sectio n 4, the ex-periments for the speaker segmentation are described in detail, and Section 5 contains some concluding remarks. SPECTROGRAM is a kind of graphical display of the squared magnitude of the time -the phonetic essence, which is compact and efficient in representation carrying infor-SPECTROGRAM combines the characteristics o f the spectrum with the time -domain SPECTROGRAM and hence it is widely used as a tool for speech analysis [16,17]. Fig. 1 shows a 9 -second SIGNAL time -domain waveform and SPECTROGRAM:
The S PECTROGRAM in Fig. 1, the horizontal axis represents the time and the ver-tical axis represents the frequency. Each coordinate point value represents the energy data of the speech. The SPECTROGRAM consists of the different degrees of color, the this paper introduces the SPECTR OGRAM into the problem of speak er segmentation.
On the other hand, Mel -Frequency Cepstral Coefficients (MFCC) [1 8 ] is the most common feature extraction technique in speaker identification. The Mel scale was first ness. Therefore, MFCC has been widely used in signal processing, espe cially, speech processing [ 20 -23 ].
 Combined feature based on SPECTROGRAM and MFCC' characteristics. The pro cess of Combined feature is shown in Fig.2.  X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X  length is 30ms, and the frame shift is 15ms, the Hamming window is used to extract the audio frames in the speech process, then sets the number of sampling points equal to the number of windows. Second, MFCC features and SPECTROGRAM features are after these two features are combined based on the sequence of each frame. CALL_CENTER environment, that is, the operator' s voice information characteris tics are known. Then, based on the Combined feature approach, a one -dimensional matrix input to the CNN to train segmentation model of operator and non -operator. Finally, a speaker segmentation algorithm for the speech data based on Combined feature using model framework is shown in Fig. 3, which shows that the audio file is pre -segmented and each segment is remarked by 1 or 0. If the audio belongs to the operator, it is 1, otherwise it is remarked as 0. 
After obtaining the trained operator's voice model, a new speech is input to the model to detect the time reversal point of speakers. The detection frame is shown in Fig. 4, which demonstrates that the speech is pre -segmente d, then each segments is marked in chronological order and the obtained Combined feature as features input to CNN to get if not the same, which means that two voices c ome from the different speaker, corre-spondingly, the time reversal point between the two speech will be achieved, otherwise from the same people.
 4.1 Datasets In this secti on, the dataset comes from a telemarketing company, the audios related to with sampling rate of 16000HZ from the real environment. In this experiment, first of each recording is uniformly segmented into 500ms pieces. Second, the train ing set con-sists of 500 pieces of operator X  X  voice and 500 pieces of non -operator X  X  voice by man-ual ly selecting from whole segmented pieces. Last but not least, the complete dialogue set to detect the time rev ersal point for different speak ers. 4.2 Evaluation M etrics
There are many evaluation parameters of speaker segmentation system. Among paper. A false alarm occurs when a speaker change is detected even though it does not exist, this type of error is measured using the pr ecision measure (PRC). Misdetec tion occurs when the algorithm does not detect an existing speaker change, this type is meas-ured u sing the recall measure(RCL). They are defined as follows: Where N1: the number of correctly found changes; N2: total number of changes found; N3: total number of correct changes.

The combined F -measure (F) is also used to evaluate the performance and to com-pare the results with different systems. This measure is defined as: F -measure is the measure of a grammar X  X  accuracy. It considers both the precision and value of F -measure is higher, indicating that the performance is better. 4.3 Experimental 
There are two examples to show the advantages and the effectiveness of the devel-oped methods in our work. Example 1 is presented to show that three parameters ob-tained by CCN is better than by BIC under the same MFCC feature. Example 2 demon-strates that t hree evaluation parameters are obtained by CCN based on three different features, namely, MFCC  X  SPECTROGRAM  X  Combined feature.
 frame length is selected as 30ms, the frame shi ft is selected as 15ms, and the number of sampling points is equal to the number of window points. Then, to compare the ef-fectiveness of the CNN approach to BIC approach, we only use MFCC feature in this experi ment. The experimental results are shown in Ta ble 1.

Table 1 obviously illustrates that, under the same dataset and the same MFCC fea-ture, the accuracy and recall rate obtained by CNN are better than BIC 3.5% and 2.45%, respectively, and the comprehensive F -measure performance is better than BIC 2.94 %. The results reveal that the proposed algorithm based on CNN can get better segmen ta-tion results compared with BIC approach, and the RCL indicates that the CNN method reduces the number of redundant points of speaker segmentation.
 results better than other features (MFCC, SPECTROGRAM), we use these three dif-shows the result find that the comprehensive performance F -meature curves of the de-tected speakers X  time reversal points in three different features. Using the Combined feature, the F -measure is l ower than that of MFCC and SPECTROGRAM before the number of training times is 6, but the growth rate of the Combined feature is obvious. When the number of training times is 28, the F -measure is basically stable and obvi-ously higher than MFCC and SPECTROGR AM. Using MFCC features, the F -measure Using the SPECTROGRAM feature, the results are between the other two features X .
The use of Combined features, the comprehensiv e performance of speaker segmen-basically stable, the mean values of the speaker segmentation parameters are shown in Table 2 segmentation algorithm, whose average precision and recall rate are higher than MFCC 3.25% and 5.53%, respectively, and are better than SPECTROGRAM 2% and 3.44%, respectively. The comprehensive performance average F -measure of the Combined fea-ture is better than MFCC 4.48%, is better than SPECTROGRAM 2.77%. It obviously get better segmentation resu lts compared with MFCC and SPECTROGRAM. In this paper, for the dialogue speech of CALL_CENTER environment, a speaker seg-CNN. First, the MFCC and SPECTROGRAM of speech are extracted, and a new Com-bined feature is gener ated by fusion operation. Second, the combined feature is input to the CNN for training the speaker segmentation model and finding the time point of the different speakers. Then, The MFCC is used as the acoustic feature to compare two speaker segmentation algorithms of BIC and CNN. At the same time, the MFCC, the SPECTROGRAM and the Combined feature are used as the input for CNN respectively to compare the speaker segmentation effect under the three different features. Finally, Combined feature by using CNN  X  presented by this paper, has a better segmentation effect.
 Acknowledgement. This work was supported in part by the National High -tech R&amp;D Program of China (NO.2015AA015308, Fundamental Research Funds for the Central Universities (NO.106112014CDJZR188801) .

