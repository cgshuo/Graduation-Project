 Criteo Kilian Weinberger KILIAN @ WUSTL . EDU Washington University in St. Louis University of Southern California Yoshua Bengio Universit  X  e de Montr  X  eal, Canadian Institute for Advanced Research Learning with artificially corrupted data, which are train-ing samples with manually injected noise, has long been a well-known trick of the trade. For example, images of ob-jects or handwritten digits should be label-invariant with re-spect to small distortions (e.g, translation, rotation, or scal-ing) applied to the images. This prior knowledge has been exploited to generate additional training samples for SVM classifiers or neural networks to improve generalization to unseen samples (Bishop, 1995; Burges &amp; Sch  X  olkopf, 1997; Herbrich &amp; Graepel, 2004; Ciresan et al., 2012). Learning with corruption also has benefits in scenarios where no such prior knowledge is available. Denoising auto-encoder (DAE), one of the few building blocks for deep learning architectures, learns useful representations of data by denoising, i.e., reconstructing input data from artificial corruption (Vincent et al., 2008; Maillet et al., 2009; Vincent et al., 2010; Mesnil et al., 2011; Glorot et al., 2011). Moreover, dropout regularization  X  ran-domly deleting hidden units during the training of deep neural networks  X  has been shown to be highly effective at preventing deep architectures from overfitting (Hinton et al., 2012; Krizhevsky et al., 2012; Srivastava, 2013). However, these advantages come at a price. Explicitly cor-rupting the training data (or hidden units) effectively in-creases the training set size, which results in much longer training time and increased computational demands. For example in the case of DAEs, each data sample must be corrupted many times and passed through the learner. This may present a serious challenge for high-dimensional in-puts. In the case of dropout regularization, each random deletion gives rise to a different deep learning architecture, all sharing subsets of parameters, and the need to average over many such subsets increases training time too. In this paper, we propose a novel auto-encoder that takes advantage of learning from many corrupted samples, yet elegantly circumvents any additional computational cost. Instead of explicitly corrupting samples, we propose to im-plicitly marginalize out the reconstruction error over all possible data corruptions from a pre-specified corrupting distribution. We refer to our algorithm as marginalized De-noising Auto-encoder (mDAE).
 While in spirit similar to several recent works, our ap-proach stands in stark contrast to them. Although Chen et al. (2012) also marginalizes out corruption in auto-encoders, their work is restricted to linear auto-encoders, whereas our proposed model directly marginalizes over nonlinear encoding and decoding. In contrast to several fast algorithms for log-linear models, our approach learns hidden representations while the formers do not (van der Maaten et al., 2013; Wang &amp; Manning, 2013; Wager et al., 2013). Nonetheless, our approach generalizes many of those works when nonlinearity and latent representations are stripped away.
 We evaluate the efficacy of mDAE on several popular benchmark problems in deep learning. Empirical stud-ies show that mDAE attains up to 1-2 order-of-magnitude speedup in training time over denoising auto-encoders and their variants. Furthermore, in most cases, mDAE learns better representation of the data, evidenced by significantly improved classification accuracies than those competing methods. This can attributed to the fact that mDAE are effectively trained on infinitely many training samples. The rest of the paper is organized as follows. We start by describing our approach in section 2. We discuss related work in section 3 and contrast with our approach. We re-port experimental results in section 4, followed by conclu-sion in section 5. In what follows, we describe our approach. The key idea is to marginalize out the noise of the corrupted inputs in the denoising auto-encoders. We start by describing the con-ventional denoising auto-encoders and introducing neces-sary notations. Afterwards, we present the detailed deriva-tions of our approach. Our approach is general and flexible to handle various types of noise and loss functions for de-noising. A few concrete examples with popular choices of noise and loss functions are included for illustration. We then analyze the properties of the proposed approach while drawing connections to existing works. 2.1. Denoising Auto-encoder (DAE) The Denoising Auto-Encoder (DAE) is typically imple-mented as a one-hidden-layer neural network which is trained to reconstruct a data point x  X  R D from its (par-tially) corrupted version  X  x (Vincent et al., 2008). The cor-rupted input  X  x is typically drawn from a conditional distri-bution p (  X  x | x )  X  common corruption choices are additive Gaussian noise or multiplicative mask-out noise (where values are set to 0 with some probability q and kept un-changed with probability of 1  X  q ).
 The corrupted input  X  x is first mapped to a latent represen-tation through the encoder ( i.e., the nonlinear transforma-tion between the input layer and the hidden layer). Let z = h  X  (  X  x )  X  X  D h denote the D h -dimensional latent repre-sentation, collected at the outputs of the hidden layer. The code z is then decoded into the network output y = g ( z )  X  R D by the nonlinear mapping from the hidden layer to the output layer. Note that we follow the custom to have both mappings share the same parameter  X  .
 For denoising, we desire y = g  X  h (  X  x ) = f  X  (  X  x ) to be as close as possible to the clean data x . To this end, we use a loss function ` ( x , y ) to measure the reconstruction error. Given a dataset D = { x 1 ,  X  X  X  , x n } , we optimize the parameter  X  by corrupting each x i m -times, yielding  X  x ,...,  X  x m i , and minimize the averaged reconstruction loss Typical choices for the loss ` are the squared loss for real-valued inputs, or the cross-entropy loss for binary inputs. 2.2. Infinite and Implicit Denoising via Marginalization The disadvantage of explicitly corrupting x and using its multiple copies  X  x 1 ,...,  X  x m is that the optimization algo-rithm has to cope with an m -fold larger training dataset. When m is large, this increase directly translates into in-creased computational cost and training time.
 Can we avoid explicitly increasing the dataset size yet still reap the benefits of training with corrupted inputs? Our key idea seems counterintuitive at the first glance: we will use as many copies of corrupted as possible, even infinite! The trick is to recognize that the empirical average in eq. (1) becomes the expected averaged loss under the cor-ruption distribution p (  X  x | x ) , as m  X  X  X  . In other words, we will attempt to minimize the following objective function While conceptually appealing, the expectation is not ana-lytically tractable in the most general case due to the non-linearity of the mappings and the loss function. We over-come this challenge with two approximations. These ap-proximations depend only on the first-order and second-order statistics of the corruption distribution p (  X  x | x ) and can be computed efficiently.
 Second-order expansion and approximation. We ap-proximate the loss function ` (  X  ) by its Taylor expansion with respect to  X  x up to the second-order. Concretely, we choose to expand at the mean of the corruption  X  x E where  X   X  x ` and  X  2  X  x ` are the first-order derivative (i.e. gra-dient) and second-order derivate ( i.e., Hessian) of ` (  X  ) with respect to  X  x respectively.
 The expansion at the mean  X  x is crucial as the next step shows, where we take the expectation with respect to the corrupted  X  x ,
E [ ` ( x ,f  X  (  X  x ))]  X  ` ( x ,f  X  (  X  x )) Here, the linear term in eq. (3) vanishes as E [  X  x ] =  X  substitute in the matrix  X  x = E [(  X  x  X   X  x )(  X  x  X   X  variance of the corrupting distribution, and obtain Note that the formulation in eq. (4) only requires the first and the second-order statistics of the corrupted data. While this approximation could in principle be used to formulate our new learning algorithm, we make a few more compu-tationally convenient simplifications.
 Scaling up. We typically assume the corruption is ap-plied to each dimension of x independently. This imme-diately simplifies  X  x to a diagonal matrix. Further, it also implies that we only need to compute the diagonal terms of the Hessian  X  2  X  x ` . This constitutes significant savings in practice, especially for high-dimensional data. The full Hessian matrix scales quadratic with respect to the data di-mensionality, while its diagonal scales only linearly. The d th dimension of the Hessian X  X  diagonal is given by through a straight-forward application of the chain-rule and the derivatives are backpropagted through the latent rep-resentation z . We follow the suggestion by LeCun et al. (1998) and drop the last term in (5). The remaining first term is in a quadratic form. Note that the matrix  X  2 z ` =  X  `/ X  z 2 is the Hessian of ` with respect to z , and is of-ten positive definite. For instance, for a classification task where the output layer is a softmax-multinomial, the Hes-sian is that of multinomial logistic regression and there-fore positive definite. We exploit the positive definiteness by further reducing the matrix to its non-negative diagonal terms, which gives rise to our final approximation Note that this approximation also brings up significant computational saving as most modern deep learning archi-tectures have a large number of hidden units  X  the Hessian  X  z ` would also have been expensive to compute and store without this approximation.
 Learning objective. Combining our results so far, we minimize the following objective function (using one train-ing example for notation simplicity) where  X  2 x d is the corruption variance of the d th input di-mension, i.e., the d th element of  X  x  X  X  diagonal. It is straightforward to identify that the first term in (7) represents the loss due to the feedforward  X  X ean X  (of the corrupted data). We postpone to later sections a detailed discussion and analysis of the intuition behind the second term. In short, the term R  X  (  X  x ) functions as a form of regularization, reminiscent of those used in the contractive auto-encoder (Rifai et al., 2011b) and the reconstruction contractive auto-encoder (Alain &amp; Bengio, 2013)  X  details in section 3. 2.3. Examples We exemplify our approach with a few concrete examples of the corrupting distributions and loss functions. Corrupting distributions. Table 1 summarizes two types of noise models and their corresponding statistics. In the case of additive Gaussian noise , we have p (  X  x | x ) = N ( x ,  X  ) where the covariance matrix is independent of x . Additive Gaussian noise is arguably the most common data corruption used to model data impurities in practical appli-cations (Bergmans, 1974).
 For mask-out/drop-out corruption, we overwrite each of the dimensions of x randomly with 0 at a probability of q . To make the corruption unbiased, we set uncorrupted dimen-sions to 1 / (1  X  q ) times its original value. That is, P (  X  x d = 0) = q, and P (  X  x d = 1 / (1  X  q ) x d ) = 1  X  q. (8) While the noise is unbiased, the variance is now a function of x , as shown in Table 1. This type of corruption has been shown to be highly effective for bag-of-words document vectors (Glorot et al., 2011; Chen et al., 2012), simulating the loss of some features due to e.g. other word choices by the document X  X  authors, and recently has become known as  X  X rop-out X  in the context of neural network regulariza-tion (Hinton et al., 2012).
 Loss. Table 2 highlights two loss functions and the cor-responding derivatives in eq. (7). The cross-entropy loss is best suited for binary inputs and the squared loss a typical choice for regression.
 We assume that in both cases the hidden representation is computed as where  X  () is the sigmoid function, W  X  R D h  X  D is the connection weight matrix between the input and the hidden layers and b the bias term. For the binary inputs scenario, the outputs are computed as y =  X  ( W &gt; z + b 0 ) and we use the cross-entropy loss to measure the reconstruction. For regression, the outputs are y = W &gt; z + b 0 and we use the squared loss. Table 2 summarizes the relevant derivatives with different reconstruction loss function. We leave the detailed derivation to the Supplementary Material. 2.4. Analysis of the Regularizer We gain further insight by examining the regularizer R  X  (  X  x ) in eq. (7) under specific combinations of corrup-tion distributions and reconstruction loss functions. For example, under the mask-out noise and the cross-entropy loss, we have
R  X  (  X  x )  X  X This form reveals several interesting aspects of the regular-izer.
 Our first observation is that the regularizer favors a binary hidden representation and penalizes if the hidden output z is ambiguous  X  the most extreme case being z h =1 / 2 . Secondly, the regularizer is adaptive to both the inputs and the outputs. For active values x d and y d 0 it penalizes all paths w hd ,w hd 0 that use x d for the reconstruction of x This observation is analogous to the adaptive regularization effect previously observed on the logistic regression (Wa-ger et al., 2013).
 Thirdly, in contrast to typical measuring model parameters with L 2 norms, our regularizer captures higher-order in-teractions. When d = d 0 , we see a penalty term of w 4 which grows faster than w 2 hd . Furthermore, there is a mu-tual competition and suppression for weights belonging to the same hidden unit. The regularizer prefers all w hd for the same h to different inputs (or outputs units) to be as orthogonal as possible: As our experiments will show later, this preference leads to a group of sparser weights (cf. fig. 2). When interpreting those weights as filters, we obtain sharply contrasted fil-ters. It is worth pointing out that this type of orthogonality regularization has been used in other settings of learning models with disjoint sets of features (Hwang et al., 2011; Zhou et al., 2011; Chen et al., 2011). Various forms of auto-encoders have been studied in the literature (Rumelhart et al., 1986; Baldi &amp; Hornik, 1989; Kavukcuoglu et al., 2009; Lee et al., 2009; Vincent et al., 2008; Rifai et al., 2011b). While originally intended as a technique for dimensionality reduction (Rumelhart et al., 1986), auto-encoders have been repurposed to learn sparse and distributed representation in the over-complete set-tings, where the learned representation has higher dimen-sions than the input space. To avoid learning an identity mapping (thus uninteresting features) under this setting, it is crucial to have regularization in those models. The sim-plest form is to use weight decay (Bengio &amp; LeCun, 2007), which favors small weights. The sparse auto-encoders pro-posed by (Lee et al., 2007; Ranzato et al., 2007) encour-age sparse activation of the hidden representation. Our work generalizes those ideas by suggesting more complex forms of regularization, for example, being adaptive to in-puts when using mask-out noise.
 Connection to DAE and its variants. Denoising auto-encoders (DAE) (Vincent et al., 2008) incorporate a new form of regularization to force the mapping between the inputs and the outputs to deviate from an identity mapping. That is achieved by corrupting the inputs (for instance, ran-domly setting a subset of input dimensions to zero) while demanding the corrupted dimensions be reconstructed at the outputs.
 Rifai et al. (2011b) asks the more direct question: what kind of representations we desire and thus what regulariz-ers do we need for a regular auto-encoder? Their contrac-tive auto-encoder (CAE) thus explicitly encourages learn-ing latent representation to be robust to small perturbation to the inputs. To this end, CAE penalizes the magnitude of the Jacobian matrix of the hidden units at the training examples: In contrast, our regularizer in eq. (7) takes also into consid-eration the curvature of the reconstruction loss function by weighting the Jacobian with  X  2 `  X  X  2 CAE, our regularizer is able to adapt to the inputs explicitly by scaling with input-dependent noise variance.
 Alain &amp; Bengio (2013) aims to understand the regulariza-tion property of the DAE by marginalizing the (Gaussian) noise. They arrive at a reconstruction contractive auto-encoder (RCAE) whose regularization term is the Jaco-bian of the reconstruction function . While RCAE cannot be seen as a direct replacement of CAE, it is interesting to note that our mDAE has the flavor of both RCAE and CAE  X  mDAE X  X  regularization encodes jointly the prop-erties of the loss (thus indirectly the regression function) and the hidden representations.
 Connection to other marginalized models. Wager et al. (2013) analyze the effect of dropout/mask-out on learning logistic regression models. In particular, they analyze the expected loss function of the learning algorithm with re-spect to the corruption distribution. An approximation to the expected loss is derived under small noise condition. They discover that the effect of marginalizing out the noise is equivalent to adding an adaptive regularization term to the loss function formulated with the original training sam-ples. A similar effect is also observed in our analysis, cf. section 2.4.
 While sharing in spirit with that line of work, our focus is also inspired by (Chen et al., 2012; van der Maaten et al., 2013) which see marginalization as a vehicle to ar-rive at fast and efficient computational alternative to ex-plicitly constructing corrupted learning samples. Because the hidden layers in our auto-encoders are no longer lin-ear, our analysis extends existing work in interesting di-rections, revealing novel aspects of adaptive regularization due to the need of learning latent representations and com-pounded (sigmoidal) nonlinearity. We evaluate mDAE on a variety of popular benchmark datasets for representation learning and contrast its per-formance to several competitive state-of-the-art algorithms. We start by describing the experimental setup, followed by reporting results. 4.1. Setup Datasets. Our datasets consist of the original MNIST dataset ( MNIST ) for recognizing images of handwritten digits, for the sake of comparison with prior work a sub-sampled version ( basic ) and its several variants (Larochelle et al., 2007; Vincent et al., 2010; Rifai et al., 2011b). The variants consist of five more challenging modification to the MNIST dataset, including images of rotated digits ( rot ), images superimposed onto random ( bg-rand ) or im-age background ( bg-img ) and the combination of rotated digits with image background ( bg-img-rot ). We also exper-imented on three shape classification tasks ( convex, rect, rect-img ). Each dataset is split into three subsets: a train-ing set for pre-training and fine-tuning the parameters, a validation set for choosing the hyper-parameters and a test-ing set on which the results are reported. More details can be found in (Vincent et al., 2010).
 Methods. We compare to the original denoising auto-encoder (DAE) (Vincent et al., 2010), the contractive auto-encoder (CAE) (Rifai et al., 2011b) and the marginalized linear auto-encoder (mLDAE) (Chen et al., 2012). The per-formance of these algorithm before and after fine-tuning the learned representation are both included. Our baseline is a linear SVM on the raw image pixels.
 We used cross-entropy loss and additive isotropic gaus-sian noise for DAE and mDAE throughout these ex-periments (similar trends was observed with mask-out noise). The hyper-parameters for these dif-ferent algorithms are chosen on the validation set. These include the learning rate for pre-training and levels in mLDAE, DAE and our method mDAE the regularization coefficient in CAE (candidate set has closed-form solutions for learning representations, all other methods use stochastic gradient descent for parame-ter learning. 4.2. Results Training speed. Figure 1 displays the testing error on all benchmark data sets as a function of the training epochs. The best results based on the validation set are highlighted with small markers. We can see that mDAE is able to match the performance of the DAE or CAE often with much fewer training epochs, thus significantly reducing the training time. In the most prominent case, bg-rand , it re-quires less than five training epochs (after 5 minutes of training time) to reach the same error as the DAE, which requires over 4 hours to finish training. Similar trends are observed on most datasets, with the exceptions of MNIST (where mDAE performs slightly worse than DAE).
 Better representations. If allowed to progress until the lowest error on the validation set is reached, mDAE is also able to yield better representations than DAE in 7 out of 9 data sets. Figure 1 shows that the features learned with mDAE quickly yield lower classification errors in these cases. Table 3 summarizes the classification errors of the linear SVMs (Fan et al., 2008) using representations learned (before fine-tuning) by all algorithms, as well as the errors after fine-tuning the learned representations us-ing discriminative labels. The test errors obtained with the raw pixel inputs are record in the baseline column. When trained with one hidden layer, mDAE often outperforms other approaches by significant margins. The table also shows the results of two hidden layers, learned through stacking (Vincent et al., 2010). With two layers, the bene-ficial effects of mDAE decrease slightly, however training one layer two layers
CAE is still significantly faster in most cases. Note that with-out fine-tuning two stacked layers often do not improve the feature quality across all approaches. A single-layer mDAE is able to outperform stacking two layers of DAE or CAE on several datasets, such as bg-rand and bg-img-rot . Representation learned by mDAE without fine-tuning is able to outperform DAE or CAE with fine-tuning on sev-eral datasets, such as basic and bg-rand .
 Analysis of the model parameters. The connection weights between neural network layers are often inter-preted as filters that transform lower-level inputs. Thus, it is often instructive to study the properties of those filters to understand the process of the learning.
 Figure 2 shows 100 randomly selected filters, from a total of 1000, learned by mDAE on three datasets. Exemplary inputs for the various data sets are shown on the very left. mDAE is able to discover interesting (visibly non-random and clearly structured) filters. On the basic (left) dataset, it is able to learn specialized feature extractors, detecting for example ink blobs, local oriented strokes and digit parts such as loops. On both bg-rand (middle) and bg-img (right) datasets, the model learns filters which are more sensitive to foreground digits as well as filters which capture the back-grounds.
 Figure 3 compares the filters learned by four different auto-encoder variants: an auto-encoder without denoising or regularization (AE), DAE, CAE and our mDAE. As shown in the figure, AE filters largely look random and fail to learn any interesting features, confirming the importance of ap-plying regularization to such models. Some of CAE X  X  fil-ters capture interesting patterns such as edges and blobs. Both DAE and mDAE seem to have highly specialized and well-structured feature detectors. In particular, mDAE seems to have sharply contrasted filters. The filters from mDAE have the tendency to be specialized towards smaller image regions. This may be an artifact of the regularization term, which penalizes reconstruction paths across differ-ent input dimensions. The strongest reconstruction signal is usually the pixel itself and its neighboring pixels (which are highly correlated) and the mDAE filters tend to focus on exactly those. Note that these filters with local activa-tion regions tend to have less overlap and are more likely to be orthogonal. Both observations are in tune with the analysis in section 2.4. Regularized auto-encoders are important building blocks for learning deep and rich representations of data. The stan-dard approach of denoising auto-encoder incorporates reg-ularization via learning reconstruction from partially cor-rupted samples. While effective, this is often a computa-tionally intensive and lengthy process. Our mDAE over-comes the limitation by marginalizing the corruption pro-cess, effectively learning from infinitely many corrupted samples. At the core of our approach is to approximate the expected loss function with its Taylor expansion. Our analysis yields a regularization term that takes into consid-eration both the reconstruction function X  X  sensitivity to the hidden representations and the hidden representation X  X  sen-sitivity to the inputs. Algebraically, those sensitivities are measured by the norms of the corresponding Jacobians. The idea of employing Jacobians to form regularizations has been studied before and has since resulted in several interesting models, including ones for regularizing auto-encoders (Rifai et al., 2011b). We plan to advance further in this direction by exploring high-order effects of corrupt. For instance, inspiring thoughts include injecting noise into a Jacobian-based regularizer itself (Rifai et al., 2011a) as well as approximating with higher-order expansions. In summary, this paper contributes to the deeper under-standing of feature learning with DAE and also proposes a novel practical algorithm. The modular structure of mDAE allows many different corruption distributions as well as reconstruction loss functions to be readily used in a plug-and-play manner, providing interesting directions for future research and analysis.
 KQW were supported by NSF IIS-1149882 and IIS-1137211. FS is partially supported by the IARPA via DoD/ARL contract # W911NF-12-C-0012. YB was sup-ported by NSERC, the Canada Research Chairs and CI-FAR. This work was supported in part by the Intelli-gence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD / ARL) contract number W911NF-12-C-0012. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of-ficial policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.

