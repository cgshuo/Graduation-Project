 Categories and Subject Descriptors: H.3.3 Information Systems: Information Retrieval Keywords: Music Recommendation, Geo-tag, Image We propose a music recommendation prototype named Pictune. Pictune utilizes location-based image retrieval and other Web services to recommend music for users virtual-ly located at any position where such services are available. Our study is theoretically supported by two psychological findings. First, the need for music is driven by diverse mo-tives, such as the leisure, informative, self-educational or experiential motives [2]. Interestingly, such motives are also spotted in photography. Second, the perception of the envi-ronment can significantly influence the expectation of music [4]. For example, when a person sees a landmark, its con-cept may be stimulated, evoking the expectation of other connection related to it, such as music and pictures. On the other hand, the melody of a song can facilitate learning and recall of the situation.

The main objective of this work is to develop a mobile Web application which acquires the user X  X  ambience and retrieves music by it. The ambience of a user, as she accesses the application, is defined by her location , time-of-day (TOD), day-of-year (DOY), and the weather . These elements can be easily acquired from either the terminal or the Web. The main challenge is to explore the correlation between user ambience and the online rich photos, which are associated with numerous tags describing not only the facts (such as the ambience and the object being shot) but also subjective feelings, sensings, perceptions, and intuitions.
Pictune contains the following components: (1) A music database where each music is associated with a set of tags. (2) An image database indexed by ambience vector. Each ambience is associated with a set of tagged images. These data are retrieved from Flickr API and an online weather service. The components of the ambience vector are repre-sented in discretized form for ease of computation. (3) A tag-by-ambience matrix M ta (precomputed from the image database) where each element indicates the weight of a tag for a particular ambience. Given the current ambience of a new query, we first compute a vector of relevant tags (de-noted by T )withweights. Thenweperforman emotion enhancement process on T , which uses an emotional Word-
