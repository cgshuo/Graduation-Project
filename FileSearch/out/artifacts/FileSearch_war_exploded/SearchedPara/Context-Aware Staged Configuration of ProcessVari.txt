 Aitor Murguzur 1 , Xabier De Carlos 1 , Salvador Trujillo 1 , and Goiuria Sagardui 2 In recent years, emerging technologies, s uch as Machine-to-Machine (M2M) com-munications, Cloud Computing, Service-oriented Computing (SOC), Business Process Management (BPM) and Big Data analytics, have been leveraged to support businesses achieving their goal s under changed marked conditions, e.g., reducing the time to market and costs. From the marriage of the latter technolo-gies, smart services are commonly deployed and extended into a variety of smart devices and elastic cloud platforms, to improve decision making, rapid provision-ing and deployment, and to provide greater flexibility. Atop of such service-based platforms, process-intensive and event-based applications offer a large number of processes as a catalyst for collaboration, integration and control, e.g., enabling the Business Process as a Service (BPaaS) concept [1].

Variability management for such processes is indeed becoming challenging, e.g., in smart logistics [2]. In this light, new techniques and tools are being de-veloped to address the shortcomings of standard solutions to deal with large sets of process variants and adequate process variants to meet new require-ments, context changes and intrinsic complexity. Process variability approaches [3,4] handle different process variants, which are entirely or partially common to several domain stakeholders and assets to which processes are applied. Process variants share a common part of a core process whereas concrete parts fluctuate from variant to variant. In dynamic conditions, such variants need to be con-text sensitive with the aim of adequately providing multiple stakeholders/assets configurations and reasoning [5], and thus, drive customization based on context information [6]. Therefore, context-awareness demands innovative solutions that allow process-based applications to change during runtime.
 This paradigm shift has imposed the emergence of Dynamic Software Product Lines (DSPLs) [7], which support late variability, i.e., defers product configura-tion to runtime, exploiting traditional Software Product Line (SPL) concepts. Regarding to the BPM field, a configurable process model is capable of dynam-ically (re-)binding variation points at runtime, considering context information. Once context data is detected from extern al sensors or new user requirements, the system decides which alternatives of the configurable process must be acti-vated or deactivated and executes the d ecision via runtime binding. At a glance, the key properties of DSPLs are: (i) support runtime variability, (ii) are able to handle unexpected and environmental changes, (iii) may change variation points at runtime, (iv) may support context-awareness and self-adaptive properties, and (v) may include an automated decision making.

Some of the above-mentioned properties are partially supported by existing work in the literature, such as the Worklets approach [8] which enables user-driven selection of self-contained sub-pr ocesses aligned to each activity depend-ing on the particular context at runtime, or the DyBPEL engine [9] which has the ability to adapt running and compliance Business Process Execution Lan-guage (BPEL) instances when the corresponding process variant schema evolves. However, there is a lack of deferral of the entire process varia nt customization and execution to perform an automated decision making at runtime. This would reduce the time to change from one process variant to another, as well as scaling-up and modifying process variant alternatives during operation.

In this paper, we aim to solve such problem by focusing on process models variability at runtime. The main contributions provided by this paper can be summarized as follows: c1 -we propose a novel methodology and a prototype toolkit called LateVa to automatically resolve process variability at runtime; and c2 -we demonstrate through an experimental smart logistics case study that our methodology is scalable and can be used in dynamic settings.

The paper is organized as follows: In Section 2, we present a detailed overview of the case study at the ACME Corp. and the problems associated with the complexity of its operational processe s. In Section 3, we present a methodology based on an automated customization of process variants using the late selection of fragments at runtime to address the issues raised by the case study. The results of our evaluation are detailed in Section 4. Section 5 discusses related work, while we conclude the paper with a summary and future next steps in Section 6. ACME Corp. is a leading innovative company that provides goods handling systems with a multiplicity of solutions for automated warehouses and storage, baggage handling, sorting systems and pic king facilities. ACME Corp. designs and develops Warehouse Management Systems (WMS) for each customer (i.e. offering an ad-hoc solution for each cust omer to satisfy their business needs) in four areas, namely healthcare, retail, industrial components and food.
In essence, a WMS is a key part of the supply chain which primarily aims to control the movement and storage of goods (also referred to as articles) within a warehouse. Each WMS is complex and comprises a large number of operational processes [2], such as storage, retrieval and picking.  X  Storage : The goods storage process allows goods to be stored based on dif- X  Retrieval : The retrieval process enables th e complete removal of goods from a  X  Picking : The picking process merges both retrieval and storage processes. It
Inside an automated warehouse, the aforementioned operational processes can be modeled and executed by a BPM platf orm in order to track and control all warehouse flows, and enable multi-agent interaction, such as physical devices (e.g. conveyor systems, transelevators, pick to light systems, RFID, presence sensors, etc.) and warehouse operators (e.g. maintenance manager, workstation agents, picking operator, etc.) [10]. Hence, logistics process automation provides a smart visualization of existing operational processes for each WMS solution and complex event triggering from dozens o f sensors; however, adopting a standard BPM platform in a smart logistics scenario presents four major issues: Large set of process variants. Processes may have common parts and de-Constantly changing context data. In each automated warehouse, installed Scalability. An initial warehouse layout can be enlarged to accommodate large High-availability. WMS execution may not be interrupted and 24/7 service In this section, we present a fragment-based re-use methodology used to man-age the variability of process models at runtime, that covers the modeling and execution phases of the process life-cycl e. In Section 3.1, we present a brief sum-mary of our foundations [11]. Due to space constraints, the formal definitions of LateVa foundations are provided as supplement 1 . We detail the different steps of our methodology in Section 3.2. In Sectio n 3.3, we describe the implementation of the methodology in our LateVa toolkit. 3.1 Foundations We follow the Base-Variation-Resolution (BVR) modeling approach [12] from the Software Product Line Engineering (SPLE), which states the separation of model commonality, variability and possible configurations into separate models. Base Model. The first input of our methodology is a base model .Itrepresents the commonality shared by a process family in a particular domain and place-holder activities (variation points) that are subject to vary. This configurable process model may be seen as the inters ection or Greatest Common Denomina-tor (GCD) of all related process variants. Variation points identify specific parts in a base model where variant binding occurs. In light of this binding time, we distinguish three types of variation points, as illustrated in Fig. 1: a ) static vari-ation point -resolved at configuration-time (design-time); b ) partial variation point -partially resolved at configuration-time, simplifying the spectrum of run-time fragment choices within a variation model; and c ) dynamic variation point -fully determined at runtime. The latter type of variation point may have two different behaviors: with-flag which indicates just-in-time resolution and with no-flag in which the resolution is performed at base model instance initialization. In this paper, as will be shown later, we only focus on those two.
 Process Fragment. A process fragment , or simply fragment, describes a single variant realization option for each variation point within a particular base model. Likewise in a base model specification, it may include different kind of variation points for upholding nested variation points and control flow elements. Variation Model. The third input of our methodology is a variation model which details all the particularities of a process variant that must be satisfied for valid process variant configuration. It offers abstraction for the base model and its variation points when enhancing a customization, in addition to deci-sion support. Fig. 1 contains a feature diagram for the variation model subtypes that are differentiated in our approach, using the notation proposed by Batory [13]: a ) Variability elements -stand for a family of process variants, their corre-sponding domain features and variation points. A feature captures a property of the domain that is relevant for a user. It is related to its parent as mandatory, optional, alternative (xor) and or relations [14]; b ) Fragments -characterize vari-ation points X  realization options; and c ) Constraints -represent constraints to valid process variant resolutions (comple x feature-feature, feature-variable and variable-variable cross-tree relationships). 3.2 Methodology We describe the methodology in two phases where each phase subsumes several sub-steps. An illustrative overview of the methodology is given in Fig. 2 (a). Process Variability Specification and Deployment ( LateVa Modeler).
 This is achieved via steps numbered 1-5 in Fig.2 (a). Following process family identification, a system engineer provides three inputs as described in Section 3.1: a ) a base model representing the commonality and variability of a process family (will be exposed as a business service) by employing the OMG standard Busi-ness Process Model And Notation (BPMN) version 2.0; b ) process fragments in BPMN2; and c ) a variation model for decision support exposed as a feature model given their common industrial adoption [15]. Variation points are modeled using custom BPMN2 activity constructs (e.g. for each type of variation point) supported in our Activiti plugin (see Fig. 3).
In Step 3, the variations for portraying a single variation model (shown in grey in Fig. 1) are: concrete domain feature names and variation points representing domain variability, features with the VP extension mapped to variation points in a base model, for fragments we use features with FR extension and cross-tree constraints between variability elements and fragments. We distinguish between two context data types, which can be directly mapped to domain features: static context data variable/value pairs for static preferences which rarely change over time and are known at base model initialization, and dynamic context data vari-able/value pairs which change and alter over time as they become unpredictable in practice. Therefore, our model could c ontain features capturing domain ab-straction and features asso ciated with domain data.

After all models (base models, fragments and variation models) are defined, they are compiled and deployed to the models repository . In this step, we make use of a variation model compiler (the Clafer compiler [16]) to check that pre-defined features and constraints are well-defined prior to deployment. Since fea-tures related to variation points and fragments use direct naming compounds for corresponding process model IDs (see patte rns below for creating variation point and fragment features), the compiler doe s not check if the inserted base model and fragment references already exist in the models repository. Still, such func-tionality is supported by the fragment engine which directly retrieves mapping names and threats exceptions in case of mismatch.
 Pattern for representing variation point features Pattern for representing fragment features
The resolution of process variants is context sensitive. Such resolution could differ from context to context depending on domain context data values and variation model constraints. Those relationships between features, variables, and context data variable/valu e pairs are represented by context model mapping in Step 5 (see Fig. 2 (b) mapping example for the smart logistics case study). Each context data row must define its contextVariableName -a concrete variable name in a domain context model, featureName -represents a feature or a variable in a variation model, contextValue -context information of a context variable, defaultValue -a valid value which can be assigned for a context variable, and parseType -represents the aforementioned static and dynamic data types. Staged Process Variants Configuration and Execution ( LateVa En-gine). Base models generated in the previous steps need to be resolved prior to execution. After Step 6, the engine takes system properties for granted. We can configure the engine to work in two different running modes:  X  allin mode (initialization/startup runtime resolution strategy): runs a two- X  staged mode (n-staged online/pure-runtim e resolution strat egy): performs
Both running modes start by handling messages, as represented in Step 7 of Fig. 2. When a JavaScript Object No tation (JSON) message is received an internal context object is created based on context model mapping. In addition to static and dynamic variable-value pairs, a JSON message includes three common values, namely mappingId -refers to a valid context model mapping identifier, service -describes a business service (base m odel) that should be executed, and instance -identifies a running base model instance. It could also contain extra data that will be ignored by the engine, but recognized by others (e.g. data visualization). If context model mapping and business service description are encountered, the engine follows a pre-established run strategy.
 Example of a JSON message for the smart logistics case study
Bearing in mind the two running strategies, steps 8-9 in Fig. 2 are executed differently for each configuration (see Fig. 4). In allin mode, the fragment se-lector loop starts by retrieving base model and variation model definitions for a given business service. Here, we automatically transform a variation model to a constraint satisfaction problem (CSP). Proposals using constraint solving to reason on feature modes have been studied over the past two decades [17]. In our case, every optional f eature becomes a boolean variable of the CSP with do-main { false , true } or { 0,1 } , whereas every mandatory domain feature becomes a { true } or { 1 } variable.
 The second activity in Fig. 4 (a) determines context data values in two-stages. Firstly, static context data is parsed for putting features into one: Example of static feature constraint Additionally, dynamic values are specified by setting Integer constraints: Example of dynamic feature constraint
After parsing all context values and setting up constraints to the variation model, the solver starts running propagation and search to derive possible valid configurations. We handle three situations:  X  No solution after allin: Apart from the functionality provided in Fig. 4 (a),  X  One solution after allin: The engine assigns fragments to applicable variation  X  Many solutions after allin: When the solver returns more than one valid solu-
The second run mode, namely the staged mode, may activate two different branches depending on whether the received context data is for a running in-stance or not. This is indicated by the instance variable.

In a first stage (the upper workflow in Fig. 4 (b)), both static and dynamic constraints for dynamic variation points with no-flag are set (with-flag indicates that a variation point is critical and thus needs just-in-time data for its proper resolution). In the event of many solutions, the get-first strategy is performed to assign fragments for dynamic variation points with no-flag and an interme-diate model is saved. Otherwise, one solution flow performs assignations for all dynamic variation points in order to ensure a valid customization.

The n-staged flow (the lower workflow in Fig. 4 (b)) is activated to handle  X  X ust-in-time X  context messages. For each dynamic variation point in a wait state (with staged flag = true ), the engine establishes constraints for an intermediate model which is restored from the models repository by the specified instance ID. The solver uses this altered model as an input, and concludes if a sound configuration exists. If just one exists, all with-flag dynamic variation points are determined by a suitable fragment. Many solutions after n-staged, however, implies the activation of a many-solution strategy (e.g. get-first) to assign a fragment for pending dynamic variation points with-flag. These are then re-activated by signal-catching to initiate a concrete fragment instance. 3.3 Implementation in LateVa Toolkit We implement our methodology in the LateVa toolkit to manage the variability of process models at runtime. The implementation is standalone and employs open source frameworks such as Activiti 2 for base model and process fragment modeling and execution, Clafer 3 for variability representation with its alterna-tive backend using Choco 4 constraint solver, ActiveMQ 5 as the engine broker and Camel 6 for integration. A prototype implementation of the toolkit encom-passes two modules: the LateVa-modeler for representing models (as an Activiti extension) and the LateVa-engine for executing late variability. In this section, we perform an experim ent to synthesize a storage process for the ACME Corp. case study and discuss th e experimental res ults and threats to validity of the proposed methodology. 4.1 Experimental Setup We developed a case scenario to automatically configure and enhance a storage process to test an automated warehouse operation in the Geneva apparel in-dustry. The warehouse layout consists of a single material entry point in which goods are packed in carton boxes (288x492x531mm), two corridors each contain-ing 2000 locations, 2 picking workstations and a single material retrieval point. Due to space limitations, the full description of the storage process example is given online at: http://aitormurguzur.com/projects/lateva/caise2014 4.2 Results of Discussion We generated 1 base model with 3 dynamic variation points (1 with no-flag: D VP Scanner , and 2 with-flag: D VP Checkpoint and D VP Decisionpoint ,as depicted by Fig. 3), 5 fragments and 1 variation model with 22 features and 8 constraints, covering 3x2x2 = 12 process variant customizations for the Geneva layout. These models were used to generate a test case for 157 storage oper-ations . We ran the experiment as a standalone application on a 13inch MacBook Air with 8GB 1600 MHz DDR3 RAM, and Core i7 running @2 GHz.

In this paper, we focus on understanding the performance of our approach in relation to the smart logistics case study. We use the non-intrusive perf4j li-brary to perform measurements. Dynamic variation point execution performance is measured by total processing time. Fig. 5 shows the minimum, maximum and average time taken by each with-flag dynamic variation point before fragment ex-ecution. Consequently, the average time-to-resolution (TTR) that a base model instance has to wait for using this kind of variation points is 192.2197 ms .The delay can be omitted by including events and exclusive gateways in the modeling phase, however, LateVa solves several issues raised at the beginning of the paper: Large set of process variants. This is achieved by separating operational pro-Constantly changing context data. The variation model may contain two Scalability. Our approach supports variability by extension [18], i.e., it allows High-availability. Unexpected situations are dea lt effectively and appropriate
Looking beyond the particulars of the case study, we lend to generalization by checking how our approach operates with increasing LateVa fragments, i.e., approach scalability. We added 50 extra fragments to D VP Checkpoint ,sothat the number of possible variant configurations increases to 312 (3x52x2). First results are encouraging which indicate that the engine suffers a minimal delay of 1.3503 ms when the number of applicable fragments grow for a particular dy-namic variation point with-flag, as illustrated in Fig. 6. All datasets are available at: http://git.io/3sUrCA 4.3 Threats to Validity Our experiments did not consider a cer tain number of factors that may affect our proposed methodology and generalized outcomes on scalability.  X  Correctness : Our approach guarantees the syn tactical correctness (correct  X  Dynamic context data : In this paper, we only employed Integer values for  X  Base model, fragment and variation model scalability : Although initial tests The work presented is related to other fie lds of research, such as process vari-ability, context-aware configuration of process variants, process flexibility and DSPLs. In this section, we briefly introduce related research in these areas and explain the novelty of our proposed approach.

Previous work on process variability [18,20] can be divided into two main groups: approaches adopting a single configurable process model [3,4,21] and fragment-based re-use approaches [6,9,8]. C-EPC [3] is an extension of the Event-driven Process Chain (EPC) to support multiple process families of EPC process variants by means of configurable nodes and configurable alternatives. Orthog-onally, the PESOA project [4] was proposed to provide mechanisms to capture variability of UML activity diagrams and BPMN, enriching them with stereo-type annotations using feature models in an abstract way (they do not transform variation points to selected variants). C-YAWL [21] is an extension of the Yet An-other Workflow Language (YAWL) which applies hiding/blocking operations to customize a configurable process model. They all provide useful methods to deal with process variability; however, they are merely focused on design-time process variability, rather than customizing process variants at runtime. Furthermore, they are based on conceptual modeling r ather than executable process models.
Context-aware process modeling and variability has been also studied in the past. A context-aware framework for the explicit modeling of context is provided in [22], which includes system stakeholders X  reasoning about business processes in appropriate manner. The importance of context sensitive process modeling has been also discussed in other studies [5], in order to deal with changing user requirements and the complex and dynamic nature of environments. In a similar vein, context-awareness has been translated to the process variability field. For instance, the Provop approach [6] provides five steps to customize base models based on context information. Although the latter allows for context-aware pro-cess variants customizati ons employing a base model, such customizations are user-supported rather than automated and they are not executable in practice.
Process variability and flexibility concepts are closely connected. Process flex-ibility is concerned not only with variability but also with runtime aspects of process models, as described by Reichert and Weber [23]. Hence, runtime vari-ability may be seen as a flexibility type (also referred to as late selection or late binding) which defers placeholder activity resolution to runtime. The work that is closer to our proposal is the Worklets approach [8], which enables a dynamic runtime selection of self-contained sub-pr ocesses aligned to each activity depend-ing on the context of the particular inst ance. When activities become enabled appropriate fragment selection is achieved by using Ripple Down Rules (RDR), which include hierarchically organized se lection rules. With respect to the men-tioned work, the main novelties of our approach are two-fold: we provide a staged configuration and execution of process variability at runtime, which can perform customizations in different ways (allin, staged). Secondly, all customizations are performed automatically while in Worklets the selection is realized interactively by end-users (user interaction).
 Context-awareness and intrinsic com plexity of environments has caused DSPLs to support late variability in systems in order to cater for changes at runtime. Baresi et al. [9] propose a methodology based on Common Variability Language (CVL) and DyBPEL for managing process reconfiguration at run-time using DSPLs. This proposal has been focused on handling process variants at design-time and supporting adaptation at runtime; however, our approach merely binds variation points at runtime. Despite the fact that DSPLs have been applied to other research areas suc h as, model-driven engineering [24] or service-oriented systems [25], to the best of our knowledge this is the first work tackling the issue of DSPLs in process variability. In this paper, we have addressed the problem of a smart logistics scenario and presented a novel fragment-based re-use approach for an automated manage-ment of process models variability at runtime. We introduced a methodology implemented in the LateVa toolkit, to manage large sets of variants that utilize context data and constraint solving for process variant customization. In the experiment, we developed a base model , 5 fragments and a variation model for a warehouse storage operation. The evaluation generated 157 tests and concluded that the approach provides an average TTR of 192.2197 ms for dynamic varia-tion point with-flag. The initial scalability tests for our approach have provided positive results for its adoption as an alternative in scenarios where: large set of process variants, dynamic context data, scalability and/or high-availability are the norm, not the exception. Our future work will involve a large-scale empirical evaluation using different real case studies while carefully collecting scalabili-ty/performance metrics and dealing with models complexity and maintainabil-ity. We also plan to concentrate on three parts: testing of other many-solution strategies when the solver gets many solutions, abstractions for enabling user-defined dynamic process configuration [26], and how to deal with data variability for the automated generation of context model mappings.

