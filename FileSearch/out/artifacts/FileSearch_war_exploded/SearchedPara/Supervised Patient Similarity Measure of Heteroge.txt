 Patient similarity assessment is an important task in the context of patient cohort identification for comparative effectiveness studies and clinical decision support applications. The goal is to derive clinically meaningful distance metric to measure the similarity be-tween patients represented by their key clinical indicators. How to incorporate physician feedback with regard to the retrieval re-sults? How to interactively update the underlying similarity mea-sure based on the feedback? Moreover, often different physicians have different understandings of patient similarity based on their patient cohorts. The distance metric learned for each individual physician often leads to a limited view of the true underlying dis-tance metric. How to integrate the individual distance metrics from each physician into a globally consistent unified metric? We describe a suite of supervised metric learning approaches that answer the above questions. In particular, we present Locally Su-pervised Metric Learning (LSML) to learn a generalized Maha-lanobis distance that is tailored toward physician feedback. Then we describe the interactive metric learning (iMet) method that can incrementally update an existing metric based on physician feed-back in an online fashion. To combine multiple similarity mea-sures from multiple physicians, we present Composite Distance Integration (Comdi) method. In this approach we first construct discriminative neighborhoods from each individual metrics, then combine them into a single optimal distance metric. Finally, we present a clinical decision support prototype system powered by the proposed patient similarity methods, and evaluate the proposed methods using real EHR data against several baselines. With the tremendous growth of the adoption of Electronic Health Records (EHR), various sources of information are becoming avail-able about patients. A key challenge is to identify the appropriate and effective secondary uses of EHR data for improving patient outcome without incurring additional effort from physicians. To achieve the goal of the meaningful reuse of EHR data, patient simi-larity becomes an important concept. The objective of patient sim-ilarity is to derive a similarity measure between a pair of patients based on their EHR data. With the right patient similarity in place, many applications can be enabled: 1) case-based retrieval of simi-lar patients for a target patient; 2) treatment comparison among the cohorts of similar patients to a target patient; 3) cohort comparison and comparative effectiveness research.
 One of the key challenges to deriving meaningful patient similar-ity measure is how to leverage physician input. In this work, we present a suit of approaches to encode physician input as super-vised information to guide the similarity measure to address the following questions: First, to incorporate physician feedback, we present an approach of using locally supervised metric learning (LSML) [20] to learn a generalized Mahalanobis measure to adjust the distance measure according to the target labels. The main approach is to construct two sets of neighborhoods for each training patient based on an initial distance measure. In particular, the homogeneous neighbor-close in distance measure to the index patient and are also consid-ered similar by the physician; the heterogeneous neighborhood of the index patient is the set of retrieved patients that are close in dis-tance measure to the index patient but are considered NOT similar by the physician. Given these two definitions, both homogeneous and heterogeneous neighborhoods are constructed for all patients in the training data. Then we formulate an optimization problem that tries to maximize the homogeneous neighborhoods while at the same time minimizing the heterogeneous neighborhoods. Second, to incorporate additional feedback to the existing similarity measure, we present the interactive Metric learning (iMet) method that can incrementally adjust the underlying distance metric based on latest supervision information [25]. iMet is designed to scale linearly with the data set size based on the matrix perturbation the-ory, which allows the derivation of sound theoretical guarantees. We show empirical results demonstrating that iMet outperforms the baseline by three orders of magnitude in speed while obtain-ing comparable accuracy on several benchmark datasets.
 Third, to combine multiple similarity measures (one from each physician), we develop an approach that first constructs discrimina-tive neighborhoods from each individual metrics, then we combine them into a single optimal distance metric. We formulate this prob-lem as a quadratic optimization problem and propose an efficient alternating strategy to find the optimal solution [24]. Besides learn-ing a globally consistent metric, this approach provides an elegant way to share knowledge across multiple experts (physicians) with-out sharing the underlying data, which enables the privacy preserv-ing collaboration. Through our experiments on real claim datasets, we show improvement of classification accuracy as we incorporate feedback from multiple physicians.
 All three techniques address different aspects of operationa lizing patient similarity in the clinical application: The first technique lo-cally supervised metric learning can be used to learn the distance metric in the batch mode where large amount of evidence first need to be obtained to form the training data. In particular, the train-ing data should consist of 1) clinical features of patients such as diagnosis, medication, lab results, demographics and vitals, and 2) physician feedback about whether pair of patients are similar or not. For example, one simple type of feedback is binary indicator about each retrieved patient, where 1 means the retrieved patient is similar to the index patient and 0 means not similar. Then the supervised similarity metric can be learned over the training data using LSML algorithm. Finally, the learned similarity can be used in various applications for retrieving a cohort of similar patients to a target patient. The second and third techniques address other re-lated challenges of using such a supervised metric, namely how to update the learned similar metric with new evidence efficiently and how to combine multiple physicians X  opinions.
 Obtaining high quality training data is very important but often challenging, since it typically imposes overhead on users, who are busy physicians in our case. An important benefit of our approaches is that the supervision required can come from various sources be-sides direct physician feedback, and could be implicitly collected without any additional overhead. For example, for some use case scenarios the training data could be simply information about pa-tients such as diagnoses, which physicians routinely provide in ev-ery encounter.
 We have conducted preliminary evaluation of all the proposed meth-ods using claims data consisting of 200K patients over 3 years from a healthcare group consisting of primary care practices. A target di-agnosis code assigned by physicians is considered as the feedback, while all other information (e.g., other diagnosis codes) are used as input features. The goal is to learn the similarity that push patients of the same diagnosis closer, and patient of different diagnosis far away from each other. Classification performance based on the tar-get diagnosis is used as the evaluation metric. Our initial results show significant improvements over many baseline distance met-rics.
 The rest of the paper is organized as the follows: Section 2 de-scribes the EHR and patient representation; Section 3 presents the locally supervised metric learning (LSML) method; Section 4 de-scribes an extension of LSML that enables incremental updates of an existing similarity metric based on physician feedback; Sec-tion 5 presents an extension of LSML that can combine multiple su-pervised similarity metrics learned using LSML; Section 6 presents the experiments; section 7 presents the related works, and we con-clude in section 8. We adopt a feature-based framework that serves as the basis for implementing different similarity algorithms. In particular, we sys-tematically construct features from different data sources, recog-nizing that longitudinal data on even a single variable (e.g., blood pressure) can be represented in a variety of ways. The objective of our feature construction effort is to capture sufficient clinical nu-ances of heterogeneity among patients. A major challenge is in data reduction and in summarizing the temporal event sequences in EHR data into features that can differentiate patients.
 We construct features from longitudinal sequences of observable measures based on demographics, diagnoses, medication, lab, vital signs, and symptoms. For the evaluation results presented in this paper, only diagnosis information is used. However other types of features can be generated and used in the similarity measure in a similar fashion.
 Different types of clinical events arise in different frequency and in different orders. We construct summary statistics for different types of event sequences based on the feature characteristics: For static features such as gender and ethnicity, we will use a single static value to encode the feature. For temporal numeric features such as lab measures, we will use summary statistics such as point estimate, variance, and trend statistics to represent the features. For temporal discrete features such as diagnoses, we will use the event frequency (e.g., number of occurrences of a ICD9 code). For other measures such as blood pressure, we construct variance and trend in value. For other variables, we construct counting statistics such as number of encounters or number of symptoms at different time intervals. For complex variables, like medication prescribed, we model medication use as a time dependent variable and also express medication usage (i.e., percent of days pills may have been used) at different time intervals.
 Essentially, each patient is represented by a feature vector, which serves as the input to the similarity measure. Our goal next is to design a similarity measure that operates on patient feature vectors and are consistent with physician feedback in terms of whether two patients are clinically similar or not. In this section, we present a supervised metric learning algorithm that can incorporate physician feedback as supervision information. We use X = [ x a set of patients, and y = [ y label vector with y C is the number of classes. In particular, x feature vector of patient i , and the label y information from a physician. More specifically, if two patients have the same label information, it means that they are considered similar.
 Our goal is to learn a generalized Mahalanobis distance as follows where  X   X  R d  X  d is a Symmetric Positive Semi-Definite ( SPSD ) matrix. Following [26], we define the Homogeneous Neighbor-hood and Heterogeneous Neighborhood around each data point as
D E FINIT ION 3.1. The homogeneous neighborhood of x noted as N o label.

D E FINIT ION 3.2. The heterogeneous neighborhood of x noted as N e labels.
 In the above two definitions we use | | to denote set cardinality. Intuitively, N o ered similar by both our algorithm and the physician (because of the label agreement). Likewise, N e patients, who are considered similar by the algorithm but not by the physician (because of label disagreement). The falsified similar patients are false positives that should be avoided by adjusting the underlying distance metric.
 In order to learn the right distance metric based on the label infor-mation, we need to first construct both neighborhoods N o Then we can define the local compactness and scatterness measures around a feature vector x Ideally, we want small compactness and large scatterness simulta-neously. To do so, we can want to minimize the following discrim-ination criterion: which makes the data in the same class compact while data in dif-ferent class diverse. As  X  is SPSD, we can factorize it using in-complete Cholesky decomposition as where tr ( ) is the matrix trace, and are the local Compactness and Scatterness matrices. Hence the distance metric learning problem can be formulated as Note that the orthogonality constraint W  X  W = I is imposed to reduce the information redundancy among different dimensions of W , as well as control the scale of W to avoid some arbitrary scal-ing. To further simplify the notations, let us define two symmetric square matrices
D E FINIT ION 3.3. (Homogeneous Adjacency Matrix) The ho-mogeneous adjacency matrix H o is an n  X  n symmetric matrix with its ( i, j ) -th entry
D E FINIT ION 3.4. (Heterogeneous Adjacency Matrix) The het-erogeneous adjacency matrix H e is an n  X  n symmetric matrix with its ( i, j ) -th entry We also define g o Likewise, we define g e Then we refer to as the Homogeneous Laplacian and Heterogeneous Laplacian , re-spectively..
No te that this is a trace difference criterion which has some ad-vantages over optimizing the trace quotient criterion as adopted in [26], such as easy to manipulate, convexity, and avoid the singular-ity problem. diag ( x ) creates a diagonal matrix with the entries in x With definition 3.3, we can rewrite Eq.(2) as Similarly, by combining definition 3.4 and Eq.(3), we can get Then the optimization problem becomes With the following Ky Fan theorem, we know that optimal solution of the above solution would be W  X  = [ w w 1 . . . , w d corresponding eigenvalues are negative.

T HE ORE M 3.1. (Ky Fan)[31]. Let H  X  R d  X  d be a symmetric matrix with eigenvalues and the corresponding eigenvectors U = [ u Moreover, the optimal P  X  = [ u mal transformation.
 The complete algorithm of Locally Supervised distance Metric Learn-ing ( LSML ) is summarized in Algorithm 1.
 Algorithm 1 LS ML AL GORIT HM Require: Data matrix X , Data label vector y , Homogeneous 1: Construct homogeneous Laplacian L o using Eq.(10) 2: Construct heterogeneous Laplacian L e using Eq.(11) 3: Find the number of columns k of W as the total number of 4: Set W as the k eigenvectors of X ( L o  X  L e ) X  X  with the There are some optimization tricks that can be applied to make A l-gorithm 1 more efficient, e.g., (1) when X ( L o  X  L e ) X we can resort to Lanczos iteration to accelerate it; (2) according to Ky Fan theorem, the optimal objective value of problem (14) is simply the sum of all negative eigenvalues of X ( L o  X  Therefore, we can automatically determine the number of columns of
W to be the number of negative eigenvalues of X ( L o  X  L LSML is particularly relevant for patient similarity, since it pro-vides a natural way to encode the physician feedback. However, to really make this patient similarity applicable, we have to be able to efficiently and effectively incorporate new feedback from physicians into the existing model. In other words, the learne d dis-tance metric needs to be incrementally updated without expensive rebuilding. We next present an efficient update algorithm that can adjust an existing distance metric when additional label informa-tion becomes available. In particular, we present the update algo-rithm which links changes to the projection matrix W to changes to the existing homogeneous and heterogeneous Laplacian matrices. The updates that we consider here are in the form of label changes of y , which consequently leads to changes to the homogeneous and heterogeneous Laplacian matrices L o and L e . The key idea here is to relate the metric update to eigenvalue and eigenvector updates of these Laplacian matrices.
 Definition and Setup: To facilitate the discussion, we define the Laplacian matrix as Next we introduce an efficient technique based on matrix perturba-tion [19] to adjust the learned distance metric according to changes of
L . Suppose that after adjustment, L becomes We define M = XLX  X  , and define (  X  eigenvector pair of matrix M . Similarly, we have f M = X and define ( e  X  Then we can rewrite ( e  X  Next we can obtain
X ( L +  X  L ) X  X  ( w i +  X  w i ) = (  X  i +  X   X  i )( w i +  X  w Now the key questions are how to compute changes to the eigen-value  X   X  Eigenvalue update: Expanding Eq.(15), we obtain
XLX  X  w i + X  X  Lx  X  w i + X  X  LX  X  w i + X  X  LX  X   X  w i =  X  i w i +  X  i  X  w i +  X   X  i w i +  X   X  i  X  w i In this paper, we concentrate on first-order approximation, i.e., we assume all high order perturbation terms (such as X  X  LX  X  and  X   X  using the fact that XLX  X  w equation Now multiplying both sides of Eq.(15) with w  X  symmetry of XLX  X  , we get Eigenvector update: Since the eigenvectors are orthogonal to each other, we assume that the change of the eigenvector  X  w subspace spanned by those original eigenvectors, i.e., where {  X  into Eq.(15), we obtain
XLX  X  which is equivalent to Multiplying w  X  get Therefore, To get  X  Discarding the high order term, and bringing in Eq.(17), we get  X  Require: Data matrix X , Initial label vector y , Learned optimal 1: Construct  X  L based on y and expert feedback 2: for i = 1 to k do 3: Compute  X   X  4: Compute  X  w 5: end for Th e above LSML algorithm and its extension on incremental up-date face a key challenge in distributed secure environments. For example in healthcare applications, different physicians or prac-tices may be responsible for different cohorts of patients, and all the information of these patients (demographic, diagnosis, lab tests, pharmacy, etc.) should be kept confidential. Typically in a health network we have a number of physicians or practices. If we want to learn an objective distance metric to compare pairwise patient sim-ilarity across all providers in the network, LSML cannot be applied as it needs to input all the patient features. How to learn a good distance metric in this distributed environment? In this section, we present a Composite Distance Integration ( Comdi ) algorithm to solve such problem. The goal of Comdi is to learn an optimal integration of those individual distance metrics on each group of patients. We follow the same framework as LSML to de-velop the Comdi algorithm.
 Now we present how to integrate neighborhood information from multiple parties. First, we generalize the optimization objective; second, we present an alternating optimization scheme; at last, we provide the theoretical analysis on the quality of the final solution. We still aim at learning a generalized Mahalanobis distance as in Eq.(1) but integrating the neighborhood information from all par-ties. Here the q -th party constructs homogeneous neighborhood i ( q ) point in it. Correspondingly, the compactness matrix  X  q scatterness matrix  X  q Similar to one party case presented in Eq.(6), we generalize the optimization objective as J = where the importance score vector constrained to be in a simplex as  X  is the number of parties. Note that by minimizing Eq.(19), Comdi actually leverages the local neighborhoods of all parties to get a more powerful discriminative distance metric. Thus Comdi aims at solving the following optimization problem. Here  X ( tions, and  X  &gt; 0 is the tradeoff parameter. In particular, when  X  = 0 , i.e., without any regularization, only  X  q = 1 for the best party, while all the others have zero weight. The best selected through cross-validation. It can be observed that there are two groups of variables Although the problem is not jointly convex with respect to both of them, it is convex with one group of variables with the other fixed. Therefore we can apply block coordinate descent to solve it. Specifically, if  X ( then the objective is convex with respect to convex with respect to W with Solving W with first solve the following optimization problem to obtain W  X  min W Note that the second term of the objective is irrelevant to fore we can discard it. For the first term of the objective, we can rewrite it as The optimal W is obtained by the Ky Fan theorem. In particular, we can solve problem (21), and set W ( t ) = [ w ( t ) whose eigenvalue is the i -th smallest. The worst computational complexity can reach O ( d 3 ) if E ( t  X  1) is dense.
 Solving by solving the following optimization problem. Here e is an all one vector. Now we analyze how to solve it with different choices of  X ( r L2 regularization: Here  X ( mon choice for regularization as adopted in SVM [17] and Ridge Regression [13] to avoid overfitting . In this case, the problem be-comes which is a standard Quadratic Programming (QP) problem which can be solved by many mature softwares (e.g., the function in MATLAB). However, solving a QP problem is usu-ally time consuming. Actually the objective of problem (24) can be reformulated as As the second term 1 discard it and rewrite problem (24) as tion problem under the simplex constraint, several researchers have proposed linear time approaches to solve this type of problem [7; 16]. We first present a use case demonstration of patient similarity, then present all the quantitative evaluation of the algorithm. In this section we present a prototype system that uses patient sim-ilarity for clinical decision support. Fig.1 shows two snapshots of the system, where there are three tabs on the left side. When the physician inputs the ID of a patient and clicks the  X  X atient Sum-mary X  tab, the system displays all the information related to the index patient as shown in Fig.1(a). Once the physician clicks the  X  X imilar Patient X  tab, the system automatically retrieves N similar patients and visualize them as shown in Fig.1(b) according to some underlying patient similarity metric. The physician can further see the details of these retrieved patients by clicking the  X  X etails X  and  X  X omparison X  tabs on the same page.
 The underlying patient similarity metric is initially learned with the supervised metric learning method described in section 3. Af-ter the physician is presented with the view of N similar patients as described above, he/she can provide feedback using the  X  X imi-larity Evaluation X  tab shown in Fig.2. The system then takes the input and updates the distance metric using the method described in section 4.
 Currently, the system supports the following types of physician feedback. Figure 2: The  X  X imilarity Evaluation X  tab under  X  X imilar Pati ents X , where the physician can input his own feedback on whether a spe-cific patient is similar to the query patient or not. In order to evaluate the performance of the update algorithm in a real world setting, we designed experiments that emulate physi-cians X  feedback using existing diagnosis labels in a clinical data set containing records of 5000 patients. First, diagnosis codes were grouped according to their HCC category ([2], which resulted in a total of 195 different disease types. We select HCC019 which is diabetes without complication as the target condition. We use the presence and absence in patients X  records of HCC019 code as the label and surrogates for physician feedback. That is, patients who had the same label were considered to be highly similar, and those who had different labels were considered to have low similarity. The experiments were then set up as follows. First, the patient pop-ulation was clustered into 10 clusters using Kmeans with the 194 dimensional features. An initial distance metric was then learned using LSML(described in section 3). For each round of simulated feedback, an index patient was randomly selected and 100 similar patients were retrieved using the current metric. Then 20 of these 100 similar patients were randomly selected for feedback based on the target label. These feedbacks were then used to update the dis-tance metric using algorithm described in section 4.
 The quality of the updated distance was then evaluated using the precision@position measure, which is defined as follows.
D E FINIT ION 6.1. (Precision@Position) . On a retrieved list, the precision@position value is computed as the percentage of the patient with the same label as the query patient before some specific position.
 We calculated the precision values at different positions over the whole patient population. Specifically, after each round of feed-back, the distance metric was updated. Then for each patient the 100 most similar patients were retrieved with the updated distance metric. we then computed the retrieval precision at different posi-tions along this list and then averaged over all the patients. Fig.3 illustrates the results on different diseases. From the figure we can see that with increasing number of feedback rounds, the retrieved precision becomes consistently higher. We next evaluate the distance integration method described in sec-tion 5 through the clinical decision support scenario. We partition all the patients based on their primary care physicians. Each parti-tion is called a patient cohort. We pick 30 patient cohorts to perform our experiments. We report the performance in terms of precision of different methods trained using all patients (shared version) and Figure 3: Precision variation at different positions with res pect to the number of feedback rounds. The x-axis is the number of physi-cian feedback rounds, which varies from 1 to 25. y-axis is the re-trieved precision averaged over the whole population. trained using only one patient cohort (secure version).
 Besides our Comdi method described in section 5, we also present the performance of LSML. We also include Principal Component Analysis ( PCA ) [14], Linear Discriminant Analysis ( LDA ) [8] and Locality Sensitive Discriminant Analysis ( LSDA ) [5] as additional baselines. Moreover, the results using simple Euclidean distance ( EUC ) is also presented as a baseline.
 For LSML, LSDA and Comdi, we fix |N o Comdi, we use Algorithm 1 with m =30, and  X  is set by cross val-idation. We report the classification performance for HCC019 in Fig.4 in terms of accuracy, recall, precision and F1 score, where the performance for secure version methods are averaged over 30 patient cohorts and we also show the standard deviation bars. From the figures we can see that Comdi significantly outperforms other secure version methods and can achieve almost the same perfor-mance as the shared version of LSML. Figure 4: Classification performance comparison with differe nt measurements on our data set with HCC019.
 Effect of distance integration: In the second part of the experi-ments, we test how the performance of Comdi is affected by the choice of individual cohorts. For the evaluation purpose, we also hold-out one fixed set of 2000 patients for testing. The idea is that because some cohorts represent well the entire patient distribution, which often leads to good base metric. On the other hand, some cohorts do not represent the entire patient distribution, which often leads to bad base metric. We call the former representative cohorts and the latter biased cohorts . What is the effect of incorporating other metrics learned from a set of mixed cohorts? In particular, we want to find out 1) whether the base metric learned from a bi-ased cohort will improve as incorporating other metrics; 2) whether the base metric learned from a representative cohort will improve as incorporating other metrics.
 From each HCC code, we select a representative cohort and a bi-ased cohort to build the base metric using LSML. Then we start adding other base metrics learned from other cohorts sequentially and check the accuracy changes during this process. We repeat the experiments 100 times and report the averaged classification ac-curacy as well as the standard deviation, which are shown in Fig.5. From the figure we clearly observe that by leveraging other metrics, the accuracy increases significantly for biased cohorts, and also still improves the accuracy for representative cohorts. Figure 5: The affect of Combi on specific physicians on HCC019. Th e x-axis corresponds to the number of patient cohorts integrated. The y-axis represents the classification accuracy: the accuracy in-creases significantly for biased cohorts, and also still improves the accuracy for representative cohorts. Distance Metric Learning ( DML ) [29] is a fundamental problem in data mining field. Depending on the availability of supervision information in the training data set (e.g., labels or constraints) , a DML algorithm can be classified as unsupervised [6][12][14], or semi-supervised [23][28] and supervised [8; 11; 27]. In particular, Supervised DML ( SDML ) constructs a proper distance metric that leads the data from the same class closer to each other, while the data from different classes far apart from each other.
 SDML can further be categorized as global and local methods . A global SDML method attempts to learn a distance metric that keep all the data points within the same classes close, while separat-ing all the data points from different classes far apart. Typical approaches in this category include Linear Discriminant Analysis ( LDA ) [8] and its variants [10][30]. Although global SDML ap-proaches achieve empirical success in many applications, generally it is hard for a global SDML to separate data from different classes well [22], because the data distribution are usually very compli-cated such that data from different classes are entangled together. Local SDML methods, on the other hand, usually first construct some local regions (e.g., neighborhoods around each data points), and then in each local region, they try to pull the data within the same class closer, and push the data in different classes apart. Some representative algorithms include Large Margin Nearest Neighbor ( LMNN ) classifier [27], Neighborhood Component Analysis ( NCA ) [11], Locality Sensitive Discriminant Analysis ( LSDA ) [5], as well as the LSML method described in section 3. It is empirically ob-served that these local methods can generally perform much better than global methods. Most of the methods are offline methods that require model building on training data. However, the iMet de-scribed in section 4 can incrementally update the existing metric when feedback becomes available.
 Another set of methods that closely related to Comdi is Mu ltiple Kernel Learning ( MKL ) [15][3][18], which aims to learn an inte-gration of kernel function from multiple base kernels. These ap-proaches usually suppose that there is a initial set of  X  X eak X  kernels defined over the whole data set and the goal is to learn a  X  X trong X  kernel, which is some linear combination of these kernels. In MKL, all the weak kernels as well as the final strong kernel are required to defined on the same set of data, which cannot be used in the distributed environment as Comdi.
 Comdi is also related to Ensemble Methods , such as Bagging [4] and Boosting [9]. What ensemble methods do is to obtain a strong learner via combining a set of weak learners, where each weak learner is learned from a sampled subset of the entire data set. At each step, the ensemble methods just sample from the whole data set according to some probability distribution with replacement and learn a weak learner on the sampled set. This is also different from the Comdi setting where the data in different parties are fixed. Comdi is related to the area of privacy preserving data mining [1]. Different from of data perturbation and encrypted database schemes, Comdi share only models instead of data. Comdi falls into the gen-eral category of private distributed mining [21], which focus on building local mining models first before combining at the global level. In this paper, we present a supervised patient similarity problem. The aim is to learn a distance metric between patients that are con-sistent with physician belief. We formulate the problem as a su-pervised metric learning problem, where physician input is used as the supervision information. First, we present locally supervised metric learning (LSML) algorithm that learns a generalized Maha-lanobis distance with physician feedback as the supervision. The key there is to compute local neighborhoods to separate the true similar patients with other patients for an index patient. The prob-lem is solved via the trace difference optimization. Second, we extend LSML to handle incremental updates. The goal is to enable online updates of the existing distance metric. Third, we general-ize LSML to integrate multiple physician X  X  similarity metrics into a consistent patient similarity measure. Finally, we demonstrated the use cases through a clinical decision support prototype and quan-titatively compared the proposed methods against baselines, where significant performance gain is obtained. It is worth noting that the algorithms should work equally well with other sources of super-vision besides direct physician input (e.g., labels derived directly from data).
 For future work, we plan to use the patient similarity framework to address other clinical applications such as comparative effective-ness research and treatment comparison. [1] C. Aggarwal and P. S. Yu. Privacy-Preserving Data Mining: [2] A. S. Ash, R. P. Ellis, G. C. Pope, J. Z. Ayanian, D. W. Bates, [3] F. R. Bach, G. R. G. Lanckriet, and M. I. Jordan. Multiple [4] L. Breiman. Bagging predictors. Machine Learning , [5] D. Cai, X. He, K. Zhou, J. Han, and H. Bao. Locality sen-[6] T. F. Cox and M. A. A. Cox. Multimensional Scaling . London, [7] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chandra. Effi-[8] R. O. Duda, P. E. Hart, and D. H. Stork. Pattern Classification [9] Y. Freund and R. E. Schapire. A decision-theoretic gener-[10] J. H. Friedman. Regularized discriminant analysis. Journal of [11] J. Goldberger, S. Roweis, G. Hinton, and R. Salakhutdinov. [12] G. Hinton and S. Roweis. Stochastic neighbor embedding. [13] A. E. Hoerl and R. Kennard. Ridge regression: Biased estima-[14] I. Jolliffe. Principal Component Analysis (2nd ed.) . Springer [15] G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, [16] J. Liu and J. Ye. Efficient euclidean projections in linear time. [17] B. Sch  X olkopf and A. J. Smola. Learning with Kernels: Sup-[19] G. Stewart and J.-G. Sun. Matrix Perturbation Theory . Aca-[20] J. Sun, D. Sow, J. Hu, and S. Ebadollahi. Localized su-[21] J. Vaidya, C. Clifton, and M. Zhu. Privacy preserving data [22] V. Vapnik. The Nature of Statistical Learning Theory . [23] F. Wang, S. Chen, T. Li, and C. Zhang. Semi-supervised met-[24] F. Wang, J. Sun, and S. Ebadollahi. Integrating distance met-[25] F. Wang, J. Sun, J. Hu, and S. Ebadollahi. imet: Interactive [26] F. Wang, J. Sun, T. Li, and N. Anerousis. Two heads better [27] K. Q. Weinberger and L. K. Saul. Distance metric learning [28] E. Xing, A. Ng, M. Jordan, and S. Russell. Distance metric [29] L. Yang. Distance metric learning: A comprehensive survey. [30] J. Ye and T. Xiong. Computational and theoretical analysis of [31] H. Zha, X. He, C. Ding, H. Simon, and M. Gu. Spectral re-
