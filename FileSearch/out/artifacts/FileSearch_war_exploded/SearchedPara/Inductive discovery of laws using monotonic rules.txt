 1. Introduction
Knowledge discovery from data describing a piece of real or abstract world is a field of computer science that concerns the process of automatically searching the data for patterns that can be considered knowledge about this piece of the world. The patterns are to evidence by induction some laws hidden in the data. The most natural representation of patterns-laws is by  X  X  if..., then...  X  X  decision rules relating some conditions with some deci-sions. The same representation of patterns is used in multi-attribute classification, thus the data searched for discovery of these patterns can be seen as classification data. In this paper, we adopt the classification perspective to present an original meth-odology of inducing general laws from data and representing them by so-called monotonic decision rules .

Classification concerns a set of objects described by a set of attributes. Commonly, in the set of attributes there is at least one called decision attribute (also called dependent variable, output variable or predictor), and others called condition attributes (also called independent variables, in put variables or features). The decision attribute makes a partition of the set of objects into classes, thus the value set of the decision attribute is composed of class labels. Analysis of classification data aims at discovering relation-ships between decision attribute and condition attributes, which can be seen as patterns or laws characterizing the world described by the data. The type of discovered relationships depends on the character of decision and condition attributes. The character of the attributes which is pertinent for our study concerns the presence or absence of an order in their value sets. Specifically, we distinguish ordinal and non-ordinal attributes, both decision and condition.
Moreover, the nature of the classification problem may require that discovered relationships show a monotonic dependency between values of some ordinal condition attributes and values of the ordinal decision attribute, e.g. the greater the mass (condition attribute), the greater the gravity (decision attribute). This was precisely a specific feature of the approach to knowledge discovery from data presented in a series of publications on Dominance-based Rough Set Approach (DRSA) (see, e.g. Greco et al., 2001 , 2007 ; S " owin  X  ski et al., 2009 ). Let us remember that
DRSA has been developed as a generalization of rough set theory (Pawlak, 1991) based on the concept of monotonicity for reason-ing about ordinal data.
 on non-ordinal classification. In fact, until now, monotonicity has been considered only in case t here is a clear and predefined correspondence between decision and condition attributes, such that we know a priori that the value of the ordinal decision attribute is consistently monotonically increasing or decreasing with respect to the value of a given ordinal condition attribute. Very often, however, the user does not know a priori if such a monotonic dependency is present, and if so, what type of monotonicity it is. For instance, investigating how a given substance is influencing a new disease, the medical doctor could not know how the amount of the substance in the blood is related to the gravity of this disorder. What is more, (s)he could not know a priori if the relationship between the amount of substance and the gravity of disorder is monotoni-cally positive or negative. In such a case, (s)he would like to discover from the data if such a monotonic relationship exists and if it is positive or negative. Moreover, one should not limit the interest to global monotonicity, which holds in all the space of variation of decision and condition attributes. We believe that monotonicity is something more than a relationship between quantities to be investigated. We claim that it is a universal category permitting to analyze any data, giving easily understandable laws explaining important aspects of the studied phenomena. In this sense, we consider the concept of monotonicity also when the monotonicity is not global, i.e. there are local relationships of monotonicity that can be positive in some part of the investigated space, and negative in other parts of the same space. For instance, investigating the effects of some medicines in treating a certain disease, we can have that until a certain point, the greater the dose the better the result, but after that point the further increase of the dose may have a negative effect. Such types of phenomena cannot be studied using the methodology supposing that a positive or negative monotonicity holds in all the space, and trying to discover relationships respecting this assumption. Therefore, to deal with classification data describ-ing such phenomena, we propose a new methodology that attempts to discover local monotonicity relationships, without assuming a priori a specific and constant d irection of this monotonicity. attributes, as well as presence or absence of monotonicity relationships, we can consider the following types of classification problems:  X  a  X  non-ordinal classification, where all condition attributes and  X  b  X  non-ordinal classification, where all condition attributes are  X  g  X  ordinal classification, where all condition attributes are non- X  d  X  ordinal classification, where at least one condition attribute is  X  e  X  ordinal classification, where at least one condition attribute is types of classification problems:  X  a  X  taxonomy of plants, where condition attributes are morpho- X  b  X  taxonomy of plants, where condition attributes are measures  X  g  X  rating of films, where condition attributes are characteristics of  X  d  X  classification of comfort states, where the room temperature  X  e  X  classification of students, where t he ordinal condition attributes because other classification problems use less background infor-mation than  X  e  X  , however, we shall show that any classification problem can be formulated in its terms, exploiting the concept of monotonicity also when it is neither predefined nor global. are particular for each classification problem type. We are inter-ested in relationships (patterns-laws) in the form of  X  X  if..., then...  X  X  decision rules. In the condition ( if ) part of the rules there is a conjunction of elementary conditions concerning the values taken by particular condition attributes, while in the decision ( then ) part of the rules there is a decision about the class label given to an object satisfying the condition part.
 classification table whose rows correspond to objects and columns to condition and decision attributes. To induce decision rules for the  X  e  X  classification problem, DRSA presented in Greco et al. rules are called monotonic for their syntax of the form: decision attributes are ordinal and monotonically related. In this paper, we want to show that it is advantageous to use DRSA and monotonic decision rules also in case of all remaining classifica-tion problems  X  a  X  2  X  d  X  , after a non-invasive transformation of classification data for these problems. In fact, DRSA was devel-oped and applied in case of supposed monotonicity relationship between values of condition and decision attributes. This is exactly the case of the  X  e  X  classification problem. In case of the other classification problems, monotonic relationships are not known a priori and may change from positive to negative in many points of the range of variation of condition attributes, thus one must be able to discover local monotonicity relationships . A local monotonicity relationship becomes global if it is positive or negative in the whole evaluation space. For example, considering room temperature as condition attribute, and comfort as decision attribute, instead of assuming that the higher (or the lower) the room temperature, the higher the comfort, it is reasonable to allow splitting this monotonicity relationship into two local relationships: until some value of the temperature the monotonic relationship is positive, and it is negative over this value. Even in case of binary attributes, corresponding to presence/absence of a property indicated by condition and decision attributes, the concept of monotonicity makes sense, because the presence of one property may be more credible when another property holds, or vice versa. For example, considering weather condition (sunny/rainy) as condition attribute, and playing golf (yes/no) as decision attribute, it is reasonable to expect that  X  X  X es X  X  decision is more credible under sunny than rainy weather, which corre-sponds to monotonicity relationship among 0 X 1 coded condition and decision attributes.

Adaptation of DRSA to discovery of local monotonicity rela-tionships in classification problems  X  a  X  2  X  d  X  is the main contribu-tion of this paper. Due to this adaptation, one can apply DRSA without declaring a priori where are the turning points of the monotonicity relationship in the condition attribute space, because the proposed method is able to discover them by itself. DRSA induction of decision rules with local monotonic relation-ships has the following advantages over the use of specific induction methods for problems  X  a  X  2  X  d  X  : it can handle monotonic relationships known a priori, as well as monotonic relationships that are not known a priori and have to be discovered, it can induce general laws involving local monotonicity rela-tionships, i.e. it is able to discover decision rules with  X  X  X nter-val X  X  elementary conditions:  X  X  X ttribute a i A  X  r 1 i , r 2 it can handle ordinal and non-ordinal condition and decision attributes, the non-ordinal attributes can be nominal, numerical or binary, it does not need transformation of the value sets (scales) of condition attributes, it does not need discretization of numerical condition attributes, it is able to discover rules with elementary conditions on nominal attributes of the type:  X  X  X ttribute a i A f v 1 i it can induce rules providing arguments pro and cons assign-ment of an object to a given class, the monotonic rules, together with a specially proposed classification scheme, have at least as good predictive ability as other well known predictors, while they are much more comprehensible than any other forms of relationships between condition and decision attributes.

Adaptation of DRSA to classification problems  X  a  X  2  X  d  X  needs a proper transformation of classification table. This transformation is non-invasive, i.e. it does not bias the matter of discovered relationships.

The intuition which stands behind this transformation is the following. In case of ordinal condition attributes, for which the presence and the sign of the monotonicity relationship between values of condition and decision attributes is known a priori, no transformation is required and DRSA can be applied directly. Each non-ordinal condition attribute, for which the presence or absence and the possible sign of the monotonicity relationship is not known a priori, is doubled and for the first attribute in the pair it is supposed that the monotonicity relationship is potentially positive, while for the second attribute, that it is potentially negative. Due to this transformation, using DRSA one will be able to find out if the actual monotonicity is global or local, and if it is positive or negative. The decision attributes are transformed such that: in case of a non-ordinal decision attribute, each value of this attribute representing a given feature is replaced by a new decision attribute with two values corresponding to the pre-sence and absence of this feature, respectively, in case of an ordinal decision attribute, each value of interest t , is replaced by a new decision attribute with two values corresponding to original values smaller than t and greater or qual to t , respectively.

More precisely, given a finite set of objects (universe) U described by condition and decision attributes, we assume that the decision attribute makes a partition of U into a finite set of attributes with class assignment, in case of non-ordinal classifica-tion problems, we have to consider n ordinal binary classification problems with two sets of objects: class X t and its complement : X t , t  X  1 , ... , n , which are number-coded by 1 and 0, respec-tively. We also assume, without loss of generality, that the value sets of all non-ordinal condition attributes are number-coded. While this is natural for numerical attributes, nominal attributes must be binarized and get 0 X 1 codes for the absence or presence of a given nominal value. In this way, the value sets of all non-ordinal attributes get ordered (as all sets of numbers are ordered). Now, to apply DRSA on a classification problem different from  X  e  X  , we transform the data table such that each number-coded attribute is cloned (doubled). It is assumed that the value set of each original number-coded attribute is positively monotonically dependent on the decision, i.e. the greater the value of the condition attribute, the higher the number code (rather 1 than 0) of the class assignment, and the value set of its clone is negatively monotonically dependent on the decision, i.e. the greater the value of the condition attribute, the lower the number code (rather 0 than 1) of the class assignment. Then, using DRSA, we get rough approximations of class X t and its complement : X t , t  X  1 , ... , n . These approximations serve to induce  X  X  if..., then...  X  X  decision rules recommending assignment to class X (argument pros) or to its complement : X t (argument cons). In this way, any classification problem  X  a  X  2  X  d  X  can be transformed to an ordinal classification problem with monotonicity constraints. Due to cloning of attributes with opposite monotonicity relation-ships, we can have rules that cover a subspace in the condition attribute space, which is bounded from the top and from the bottom. This leads (without discretization) to more synthetic rules than those resulting from induction techniques specific to classification problems  X  a  X  2  X  d  X  .

The plan of this paper is the following. In the next section, we recall DRSA designed for classification problem  X  e  X  . Section 3 is devoted to transformation of classification table in case of the remaining classification problems  X  a  X  2  X  d  X  . Then, in Section 4 ,we present the classification scheme which says how to use decision rules for ordinal and non-ordinal classification. In Section 5 ,we give an illustrative example which permits to follow all steps of the transformation of classification data, and shows the mono-tonic rules obtained from DRSA applied on the transformed data. Section 6 reports a computational experiment aiming at the comparison of the proposed approach with other predictors of classification. The last section includes conclusions and remarks on future research. 2. Dominance-based rough set approach
This section reminds the main concepts of the Dominance-based Rough Set Approach (DRSA) (for a more complete presenta-tion see, for example, Greco et al., 1999 , 2001 , 2005 , 2007 ; S " owin  X  ski et al., 2005, 2009 ). 2.1. Data representation  X  classification table
Information about objects (classification examples) is repre-sented in the form of an information table. The rows of the table are labeled by objects, whereas columns are labeled by attributes and entries of the table are attribute-values. Formally, an informa-tion table (system) is the 4-tuple S  X  / U , Q , V , f S , where U is a finite set of objects, Q is a finite set of attributes, V  X  V is the value set of the attribute q , and f : U Q -V q is a total function such that f  X  x , q  X  A V q for every q A Q , x A information function. The set Q is, in general, divided into set C of condition attributes and set D of decision attributes. When it is the case, S is called a classification table . Furthermore, it is supposed that the set of decision attributes D is a singleton { d }. ordinal attributes . Without loss of generality, for ordinal attribute q A C , f : U -R , for all objects x , y A U , f  X  x  X  Z evaluated at least as high as y on ordinal attribute q  X  X , which is denoted by x k q y . Therefore, it is supposed that k q is a complete preorder, i.e. a strongly complete and transitive binary relation, defined on U on the basis of evaluations f  X  X  . Ordinal attribute q may have positive or negative monotonic relationship with the decision attribute d (which is also ordinal). Positive relationship means that the greater the value of the condition attribute the higher the class label (i.e. the value of decision attribute), and negative relationship means that the greater the value of condi-tion attribute the lower the class label. For the sake of simplicity, we assume that all condition attributes in set C are ordinal. that each x A U belongs to one and only one class X t A X .Itis supposed that the classes are ordered, i.e. for all r , s such that r 4 s , the objects from X r are in higher class than the objects from X s . More formally, if k is a comprehensive weak order as high as y  X  X , it is supposed: [ x A X r , y A X s , r 4 s ) X  x not y k x ]. The above assumptions are typical for consideration of ordinal classification problems with monotonicity constraints ,also called multiple criteria sorting problems . 2.2. Rough approximations downward union of classes, respectively:
The statement x A X Z t means  X  X  x belongs to at least class X x A X r t means  X  X  x belongs to at most class X t  X  X . Let us remark that
X Z 1  X  X r n  X  U , X Z n  X  X n and X r 1  X  X 1 . Furthermore, for t  X  2, (approximation) of knowledge generated by decision attributes, using  X  X  granules of knowledge  X  X  generated by condition attributes.
In DRSA, where condition attributes are ordinal and decision classes are ordered, the represented knowledge is a collection of upward and downward unions of classes and the  X  X  X ranules of knowledge X  X  are sets of objects defined using a dominance relation .
Dominance relation is defined with respect to P D C . x dominates y , denoted by xDy , if for every ordinal attribute q A P , f  X  x , q  X 
The relation of dominance is reflexive and transitive, that is it is a partial preorder.
 of knowledge X  X  used for approximation in DRSA are: the form of upward (positive) and downward (negative) dom-inance cones in the evaluation space.
 requires that an object x dominating object y on all considered ordinal attributes (i.e. x having evaluations at least as high (good) as y on all considered attributes) should also dominate y on the decision (i.e. x should be assigned to at least as high (good) decision class as y  X  .
 w.r.t. dominance . Given P D C , the inclusion of an object x the upward union of classes X Z t , t  X  2, y , n , is inconsistent w.r.t. dominance if one of the following conditions holds: belongs to X Z t with some ambiguity . Thus, x belongs to X Z any ambiguity if x A X Z t and there is no inconsistency w.r.t. dominance. This means that all objects dominating x belong to X Z t , i.e. D  X   X  x  X  D X Z t .
 conditions holds:
X Z t with or without any ambiguity. Due to the reflexivity of the dominance relation, the above conditions can be summarized as follows: x possibly belongs to class X t or higher, if among the objects dominated by x there is an object y belonging to class X higher, i.e. D  X  x  X \ X Z t a | .
 approximation of X Z t , denoted by X Z t , are defined as follows  X  t  X  1 , ... , n  X  : X Z t  X f x A U : D  X   X  x  X  D X Z t g ,  X  3  X  X Z t  X f x A U : D  X  x  X \ X Z t a | g :  X  4  X  upper approximation of X r t as follows  X  t  X  1 , ... , n  X  : X r t  X f x A U : D  X  x  X  D X r t g ,  X  5  X  X r t  X f x A U : D  X   X  x  X \ X r t a | g :  X  6  X  following properties for all P D C : and X r t D X r t D X r t , t  X  1 , ... , n , and X Z t  X  U X r t 1 , t  X  2 , ... , n , and X r t  X  U X Z t  X  1 , t  X  1 , ... , n 1 : 2.3. Variable consistency rough approximations
In DRSA, lower approximation of a union of ordered classes contains only consistent objects. This definition of the lower approximation appears to be too restrictive in practical applica-tions. In the consequence, lower approximations may be even empty, preventing generalization of data in terms of decision rules. This observation has motivated research on generalizations of definition of lower approximation.

One of the possibilities is a generic definition of extended lower approximation, which is defined as Variable Consistency Dominance-based Rough Set Approach (VC-DRSA) ( B " aszczyn  X  ski et al., 2009 ; Greco et al., 2000b ). This definition allows to include the lower approximation objects with sufficient evidence for membership to approximated union of decision classes. The evidence is quantified by consistency measures .In B " aszczyn  X  ski et al. (2009) , we distinguished gain-type and cost-type consis-tency measures, and we specified conditions that must be satisfied by these measures. For P D C , y A U , given a gain-type (resp. cost-type) object consistency measure Y  X  y  X  and a gain-threshold (resp. cost-threshold) y , the lower approximation of t , and the lower approximation of X X t  X f y A X where p denotes Z in case of a gain-type object consistency measure and a gain-threshold, or r for a cost-type object consistency measure and a cost-threshold. In the above definition, y ing a limit degree of consistency of objects belonging to the corresponding lower approximation. 2.4. Decision rules induced from rough approximations
The lower approximations of upward and downward unions of classes can serve to induce  X  X  if..., then...  X  X  decision rules. In DRSA, such rules are called certain because their credibility is full. In VC-DRSA, decision rules induced from lower approximations are, in general, not fully credible, so they are characterized by a consistency measure. Using DRSA or VC-DRSA, one can induce decision rules with the following syntax: if q i 1  X  x  X  k t i 1 4 4 q i p  X  x  X  k t i p , then x A if q i 1  X  x  X  k t i 1 4 4 q i p  X  x  X  k t i p , then x A where q i 1 , ... , q i p denote ordinal attributes, and t taken from the value set of attribute q i j , i j A f i 1 We use symbols k and k to indicate weak order relation and inverse weak order relation w.r.t. the specified ordinal attribute, respectively.

Induction of decision rules is a complex problem and many algorithms have been introduced to solve it. Algorithms proposed specifically for DRSA and VC-DRSA have been described in Greco et al. (2000a) , Blaszczyn  X  ski and Slowin  X  ski (2003) , and B " aszczyn  X  ski et al. (2011) .

Once the rules are induced, they can be used to classify objects. The standard classification method used with DRSA and VC-DRSA has been presented in Greco et al. (2002) . In this procedure, an object covered by a set of rules is assigned to a class (or a set of contiguous classes) resulting from intersection of unions of decision classes suggested by the rules. In Blaszczyn  X  ski et al. (2007) , we presented a new classification method for DRSA and VC-DRSA. It is based on a notion of a class score coefficient associated with a set of rules covering the classified object. The object is assigned to a class getting the highest score. 3. Transformation of classification table
The transformation method which is described below allows application of DRSA to classification problems  X  a  X  2  X  d  X  . It should also be applied to all non-ordinal condition attributes present in classification problem  X  e  X  .

We assume, without loss of generality, that the value sets of both decision attribute (class labels) and condition attributes are number-coded. As in classification problems  X  a  X  ,  X  b  X  the complete ordering of classes X 1 , X 2 , ... , X n induced by number-coded class labels is not entering, in general, into some monotonic relation-ships with value sets of condition attributes, we have to consider n binary ordinal classification problems with two sets of objects: class X t and its complement : X t , t  X  1 , ... , n , which are number-coded by 1 and 0, respectively. This means that in the t -th ordinal binary classification problem, set X t is interpreted by DRSA as problems  X  g  X  ,  X  d  X  and  X  e  X  can be handled by DRSA without altering the original number codes of the class labels. In case of any classification problem (ordinal or not) with two classes only  X  X , X 2 , n  X  2  X  , we consider it as an ordinal binary classification problem, where union X Z 1 is composed of all objects belonging to X , and union X r 0 is composed of all objects belonging to X
As to non-ordinal condition attributes, we have to distinguish two kinds of them: numerical and nominal. While numerical attributes are obviously number coded, nominal condition attri-butes must be binarized and get 0 X 1 codes that represent absence or presence of a given nominal value.

To allow discovery of some local monotonic relationships between the values of condition attributes and the assignment of objects to union X Z 1 or to union X r 0 , we clone each of the number-coded condition attribute. Every cloned attribute is supposed to enter into one of the two possible monotonicity relations with the class assignment: positive or negative. Positive relationship means that the greater the value of the condition attribute, the higher the number code (rather 1 than 0) of the class assignment, and negative relationship means that the greater the value of the condition attribute, the lower the number code (rather 0 than 1) of the class assignment. As a result, we get pairs of number-coded attributes with supposed inverse monotonic relationships to the class assignment. The redundancy in description of objects by attributes is necessary because it is the monotonic rules that are to discover the correct direction of the monotonicity relationship.
Formally, the original classification table S including set U of objects described by set A of attributes is transformed into classification table S 0 including number-coded and cloned (possi-bly binarized) non-ordinal condition attributes. In case of classi-altering the original number codes of the class labels. In case of classification problems  X  a  X  and  X  b  X  , classification table S 0 under-goes one more transformation: it is replaced by n classification tables S t 0 , t  X  1 , ... , n , that represent each of the binary ordinal classification problems resulting from transformation of the original decision attribute.

In classification problems of type  X  a  X  2  X  d  X  each one of the condition attributes has to be transformed. In case of classifica-tion problem  X  e  X  , only non-ordinal condition attributes are to be transformed.

The transformation of each non-ordinal condition attribute from A is made individually, depending on its type: (1) numerical (number-coded), (2) nominal.
 Each numerical (number-coded) attribute a i is represented in S 0 (or in S t 0 , t  X  1 , ... , n  X  , as a pair of ordinal attributes q 0
The first one in the pair, q 0 i , is set to have positive monotonic relationship with (possibly transformed) decision attribute, while the second one, q 00 i , is set to have negative monotonic relationship with the decision attribute, i.e. the second one gets the opposite ordering. In other words, evaluation of each object x A U by numerical attribute a i is repeated twice in S 0 , and the first a i ( x ) is renamed to q 00 i  X  x  X  .
 presented in Fig. 1 . Note that the transformation does not introduce inconsistency w.r.t. dominance. For each object x , and set of transformed ordinal attributes P 0 D C 0 , the dominance cones
D  X   X  x  X  , and D  X  x  X  are composed of x and all objects that have exactly the same description by P 0 as x . Still, object x may be inconsistent w.r.t. dominance if there are some other objects that have the same description by P 0 as x and at least one of them has a different class label than x . Nevertheless, such inconsistency is also present in the original classification table S .
 distinct values is binarized, such that the presence or absence of the l -th value of this attribute is coded by a new ordinal attribute q jl taking value 1 or 0, respectively, l  X  1 , ... , k . Then, the binary each of the pairs, q 0 jl , is set to have positive monotonic relationship with the decision attribute, while the second one, q 00 jl negative monotonic relationship with the decision attribute. In other words, evaluation of each object x A U by nominal attribute a j , denoted by a j ( x ), is first described by k binary attributes q ,
Then, each binary evaluation q jl ( x ) is repeated twice in S 0 , and the first one is renamed to q 0 jl  X  x  X  , while the second one is renamed to q 00 jl  X  x  X  .
 presented in Fig. 2 . The transformation of the nominal attribute does not introduce new inconsistency w.r.t. dominance. 4. Classification classification problems  X  g  X  ,  X  d  X  , and  X  e  X  , the assignment of a (new) object x by a set of monotonic decision rules induced by
DRSA or VC-DRSA from the transformed classification table S 0 ,is performed according to the scheme presented in Blaszczyn  X  ski et al. (2007) . The classification scheme needs to be updated in case of transformed classification problems of type  X  a  X  and  X  b  X  ,if the number of decision classes n 4 2. In this section, we present the updated scheme.
 on a notion of class score coefficient associated with a set of rules covering the object to be classified. Let us remind three situations that may occur in case of classification by a given set of rules: 1. None of the rules cover object x . 2. Exactly one decision rule covers object x . 3. Several rules cover object x .
 decision classes.
 calculation of a score coefficient that reflects relevance between rules and the suggested class assignment. For rule r X t covering object x and having decision part  X  X  then x A X Z 1  X  X , a value of score r X score r X where : F r X part of rule r X t , and 9: F r X t :9 , 9 X t 9 and 9: F cardinalities of the corresponding sets: the set of objects verifying verifying F r X a product of confidence and coverage of all rules matching the description of object x and suggesting its assignment to class X From probabilistic point of view, coefficient score r X presented as a product of two conditional probabilities. The first conditional probability (coverage), Pr  X  : F r X probability of covering object x by a rule suggesting assignment to X , given that object x belongs to X t . The second one (confidence), X , given x is covered by a rule suggesting assignment to X coefficient score r X Pr  X  : F r the two events: covering of object x by a rule suggesting assign-ment to X t and object x belongs to X t are independent. Coefficient score r X events.

Analogously, for rule r : X t matching x and having decision part
If object x is covered by a rule suggesting the classification decision  X  X  then x A X Z 1  X  X , the final score for class X score  X  X t , x  X  X  score r X If, however, object x is covered by a rule suggesting the classifica-tion decision  X  X  then x A X r 0  X  X , the final score for class X x is score  X  X t , x  X  X  score r : X t  X : X t , x  X  :  X  13  X 
Situation 3 requires that we divide the set of rules covering object x into two subsets: those that suggest assignment of x to X and those that suggest assignment of x to : X t . Then, we calculate the value of score coefficient score  X  r x and having decision part  X  X  then x A X Z 1  X  X : We also calculate the value of score coefficient score r rules covering object x and having decision part  X  X  then x score r The value of the final score for class X t and object x is score  X  X t , x  X  X  score  X  r
Let us observe, that analogously to (14) and (15), we can calculate the score coefficients for the complement of class X score r
The value of the final score for class : X t is calculated analogously to (16): score  X : X t , x  X  X  score  X  r
Let us observe that, taking into account (14), (15), (17), (18), the following properties hold:
Moreover, according to definition (16), properties (20) and (21), we get score  X  X t , x  X  X  score  X  r
When classifying object x , the final score score  X  X t , x  X  is calcu-classification situation is different from situation 1, and at least one of the final scores is positive, the class with the highest value of the score is selected for the final assignment of x . Otherwise, the classification result is unknown for x . 5. Illustrative example
Let us consider the following illustrative classification problem, which is described by non-ordinal attributes only (classification problem of type  X  a  X  X  . The objects are patients after radical prosta-tectomy, and the decision attribute specifies if there is recurrence of the disease or not. Moreover, in case of recurrence it may be local (return of the cancer in the same place) or not (occurrence of the cancer in other places). Thus, the values of decision attribute describe patients are the following. The first two are integer valued attributes: Age and Gleason score. Tumor Volume is a nominal attribute with value set composed o f three values:  X  X  X mall X  X ,  X  X  X ed-ium X  X , and  X  X  X arge X  X . The values of PSA are continuous. Classification table with the exemplary set of patients after radical prostatectomy is presented in Table 1 . Observe that there are two patients in the table, whose description is inconsistent. Patient 5 and patient 6 have the same description by condition attributes, yet the first one had local recurrence, while the second one did not have.

To apply DRSA or VC-DRSA to this classification table, we need to transform Table 1 using the methodology presented in Section 3 . The classification tables resulting from this transformation are presented in Tables 2 X 4 . Table 2 concerns classification of objects  X  X  X ther X  X . The two classes are coded by 1 and 0, respectively, which corresponds to their order. Similarly, Tables 3 and 4 , concern binary and  X  X  : other X  X , which are also coded by 1 and 0, respectively. The inconsistencies found in Table 1 are also present in Tables 2 and 3 . This is not surprising because the inconsistencies in Table 1 have been stated for objects belonging to class  X  X  X o X  X  and to class  X  X  X ocal X  X . It is worth stressing that no new inconsistent objects occur after the transformation. As no inconsistencies existed for objects belonging to class  X  X  X ther X  X , Table 4 continues to be composed of consistent objects only. This means that the transformation has been non-invasive.

The set of transformed attributes P 0  X f Age 0 , Age 00 , Gleason Gleason 00 , PSA 0 , PSA 0 , V-s 0 , V-s 00 , V-m 0 , V-m 00 , V-l ordinal attributes V-s 0 , V-s 00 , V-m 0 , V-m 00 , V-l 0 transformation of nominal attribute Volume. For Table 2 , X r 0  X f 1 ; 2 , 3 g , while X Z 1  X f 4 ; 7 , 8 ; 9 , 10 g .
X Z 1 and X r 0 using DRSA are sufficient to cover all consistent objects from Table 2 . These rules are: 1 : if Gleason 00 Z 4 and V-s 0 r 0 , then R-no r 0 , 2 : if PSA 0 Z 0 : 4 and PSA 00 r 0 : 8 , then R-no Z 1 : covers all objects from X Z 1 . Remark that elementary condition V-s 0 r 0 from the first rule can be read as  X  X  X olume is not small X  X .
Thus, this elementary condition can be expressed in terms of the original attribute as: Volume A f medium , large g . Moreover, in the second rule, the elementary conditions based on the cloned numerical attribute, PSA 0 Z 0 : 4 and PSA 00 r 0 : 8, can be synthe-sized into an interval condition expressed in terms of the original rules become more readable: 1 : if Gleason Z 4 and Volume A f medium , large g , 2 : if PSA A  X  0 : 4 , 0 : 8 , then Recurrence is no : decision rules are also sufficient to cover all consistent objects from Table 3 . These rules are 3 : if Age 00 Z 25 and PSA 00 Z 0 : 4 , then R-local r 0 , 4 : if Age 00 r 40 and V-s 000 r 0 , then R-local Z 1 : covers all objects from X Z 1 . The rules can be expressed in terms of the original attributes as 3 : if Age Z 25 and PSA Z 0 : 4 , then Recurrence is : local , 4 : if Age r 40 and Volume A f medium , large g , then
Two decision rules are, as well, sufficient to cover all consis-tent objects from Table 4 . These rules are 5 : if PSA 0 r 1 : 2 , then R-other r 0 , 6 : if PSA 0 Z 2 , then R-other Z 1 :
The first rule covers all objects from X r 0 , while the second rule covers all objects from X Z 1 . The rules can be expressed in terms of the original attributes as 5 : if PSA r 1 : 2 , then Recurrence is : other , 6 : if PSA Z 2 , then Recurrence is other :
Note that the rules include elementary conditions of the type  X  X  X ttribute a i A  X  r 1 i , r 2 i  X  X  and  X  X  X ttribute a i A ble to discover such rules by DRSA due to the presented trans-formation of the classification table.

Let us suppose that a new patient (Id  X  11) is classified by the discovered rules. Description of patient 11 in terms of the transformed attributes from P 0 is presented in Table 5 .
Patient 11 is covered by the following rules: rule 2, suggesting assignment to class  X  X  X o X  X , rule 3, dissuading assignment to class  X  X  X ocal X  X  (i.e. suggesting assignment to  X  X  : local X  X ), rule 5, dissuading assignment to class  X  X  X ther X  X  (i.e. suggesting assignment to  X  X  : other X  X ).

Thus, according to the procedure described in Section 4 , patient 11 is assigned to class  X  X  X o X  X . This is because the three matching rules produce the following scores: score r no  X  no , x 11  X  X  5 score r score r which leads to the following final score: score  X  no , x 11  X  X  1 , score  X  local , x 11  X  X  1 , score  X  other , x 11  X  X  1 : 6. Results of a computational experiment
The main goal of the computational experiment was to assess the predictive accuracy of the rule classifier presented in Section 4 when applied to non-ordinal classification problems transformed according to the method described in Section 3 . All experiments were carried out on 20 data sets from the UCI repository. Characteristics of all these data sets are given in Table 6 . The sets of rules used in classification were induced using VC-DomLEM algorithm ( B " aszczyn  X  ski et al., 2011 ). VC-DomLEM is a sequential covering rule induction algorithm proposed for DRSA and VC-DRSA. Rough membership measure ( Wong and Ziarko, 1987 , and Pawlak and Skowron, 1994 ) was used with VC-DomLEM. The following non-ordinal classifiers were included in the compar-ison: support vector machine (SVM) with linear kernel ( Platt, 1998 ), decision rule classifier RIPPER ( Cohen, 1995 ), and decision tree classifier C 4.5 ( Quinlan, 1992 ). Moreover, MODLEM ( Stefanowski, 1998 ) was included. MODLEM is a rule classifier induced by sequential covering algorithm developed within the classical rough set approach.

The classification accuracy was estimated by the stratified 10-fold cross-validation, which was repeated five times to get reproducible results. Table 7 presents the average classification accuracy and its standard deviation for each data set and each classifier. Moreover, for each data set, we calculated the rank of the result obtained by a classifier in comparison with other classifiers. The rank is presented in brackets (the smaller the rank, the better). We show these ranks because they are used in statistical tests described further. The last row of each table shows the average rank obtained by a given classifier. Moreover, for each data set, the best value of the predictive accuracy measure, and those values which are within standard deviation of the best value, are marked as bold.
We used statistical tests to compare differences in predictive accuracy between considered classifiers. First, we applied Friedman test to globally compare performance of six different classifiers on multiple data sets ( Demsar, 2006 ; Kononenko and Kukar, 2007 ). The null-hypothesis in this test was that all compared classifiers perform equally well in terms of average c lassification accuracy. Unfortu-nately, we were not able to reject this hypothesis. This is mostly due to the fact that we applied the weak and conservative nonpara-metric test. The difference in ran ks must be very high in order to conclude by this test that one classifier is better than another.
We continued our experimental comparison with examination of importance of the difference in average classification accuracy for each pair of classifiers. We applied Wilcoxon test ( Kononenko and Kukar, 2007 ) with null-hypothesis that the medians of results on all data sets of two compared classifiers are equal. Let us remark that in the paired test, ranks are assigned to values of differences in average classification accuracy between two com-pared classifiers. We observed significant difference ( p -values smaller than 0.05) between Naive Bayes and any other classifier, and between VC-DomLEM and MODLEM.
 follows from the results of the experiment that VC-DomLEM is at least comparable to the other classifiers. When we consider the value of the average rank observed in our experiments, VC-DomLEM is better than any other classifier, except SVM.
However, according to the results of Friedman test the observed differences in ranks, calculated between all the classifiers, are not significant. On the other hand, the results of Wilcoxon test show that any classifier is performing better than Naive Bayes and that VC-DomLEM is performing better than MODLEM.
 classification patterns (laws). Remark that monotonic decision rules induced using our approach have the interesting property of showing pros and cons for assignment of an objet to each of the considered classes. This is because for each class, there are two kinds of rules: rules suggesting assignment to this class, and rules making an opposite suggestion (assignment to a complement of this class). These positive and negative arguments for the assign-ment give a better insight into the classification decision for domain experts. On the other hand, the number of induced rules may be too high to be read together. This may be avoided, however, since only a small subset of rules is usually covering a classified object and thus its analysis does not need a big cognitive effort. rules induced using our approach can cover multiple values of an attribute. For example, let us consider the set of the decision rules induced for the breast cancer data set from the University Medical
Center, Institute of Oncology, Ljubljana (which is labeled  X  X  X reast-cancer X  X  in Tables 6 and 7 ). For these data, the goal is to classify a patient into one of two classes  X  X  X o recurrence events X  X  or  X  X  X ecur-rence events X  X . In the set of rules induced by VC-DomLEM from the transformed classification table, one can find the following rule: if tumor size = 2 X  45 ; 49 and malignant degree  X  1 and breast quadrant A f central , right-low , right-up g , then no recurrence events : recurrence events. It is like a scenario or a law for no occurrence events. It says that if the tumor size attribute takes a value from outside the interval [45, 49], and the malignity degree is equal to 1, and the breast quadrant is central, right-low or right-up, then there is no recurrence event. The condition on the tumor size attribute shows two regions of local monotonicity: below 45 (negative) and above 49 (positive). Such a rule could not be induced by VC-DomLEM from the original breast-cancer data set. The two regions of local monotonicity were discovered by this algorithm due to the transformation proposed in this paper. 7. Conclusions
In this paper, we proposed a new approach to induction of laws from data in which we make use of the concept of mono-tonic relationships between values of condition and decision attributes, without assuming its direction a priori and allowing local monotonicity relationships in subregions of the evaluation space. Indeed, our method is able to discover local and global monotonicity relationships existing in data. The relationships are represented by monotonic decision rules which can be read as laws describing the analyzed phenomena. To enable the discovery of monotonic rules, we propose a non-invasive transformation of the input data, and a way of structuring them into consistent and inconsistent parts using the dominance-based rough set approach (DRSA) or its extension called VC-DRSA. The rule induction algorithm operates on this structure. The monotonic decision rules thus induced put in evidence easily understandable rela-tionships between values of condition and decision attributes that cannot be discovered by traditional data mining methodologies.
The distinctive features of the proposed approach which count for its advantage over other existing methods include: it accepts numerical, nominal and binary condition attributes, and does not need any discretization of numerical attributes, which is always arbitrary to some extend, it can be used for ordinal and non-ordinal decision attributes, it accepts ordinal and non-ordinal condition attributes, and does not need to transform the ordinal scales into cardinal ones, which would claim to say more than the data, it discovers regions of local monotonicity relationship between values of condition and decision attributes, i.e. decision rules involve  X  X  X nterval X  X  elementary conditions:  X  X  X ttribute a it is able to discover rules with elementary conditions on nominal attributes of the type:  X  X  X ttribute a i A f v 1 i due to the capacity of discovering local monotonicity and elementary conditions concerning subsets of nominal attribute values, the monotonic rules are compact and relatively stron-ger than traditional rules, it can induce rules providing arguments pros and cons a given decision. the monotonic rules, together with a specially proposed classification scheme, have at least as good predictive ability as other well known predictors, while they are much more comprehensible than any other forms of relationships between condition and decision attributes.

Thus, one can conclude that the presented approach provides a very general framework for inducing laws from heterogeneous data. Our future research will be focused on handling missing values of condition attributes, and on generation of the most attractive monotonic rules from the point of view of some pertinent interestingness measures.
 Acknowledgments
The first and the third authors wish to acknowledge financial support from the Polish Ministry of Science and Higher Education, Grant no. N519 314435.
 References
