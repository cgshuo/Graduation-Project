 Extensive games provide a general model for describing the interactions of multiple agents within an environment. They subsume other sequential decision making models such as finite horizon MDPs, finite horizon POMDPs, and multiagent scenarios such as stochastic games. This makes extensive games a powerful tool for representing a variety of complex situations. Moreover, it means that tech-niques for computing strategies in extensive games are a valuable commodity that can be applied in many different domains. The usefulness of the extensive game model is dependent on the avail-ability of solution techniques that scale well with respect to the size of the model. Recent research, particularly motivated by the domain of poker, has made significant developments in scalable solu-tion techniques. The classic linear programming techniques [5] can solve games with approximately 10 7 states [1], while more recent techniques [2, 9] can solve games with over 10 12 states. Despite the improvements in solution techniques for extensive games, even the motivating domain of two-player limit Texas Hold X  X m is far too large to solve, as the game has approximately 10 18 states. The typical solution to this challenge is abstraction [1]. Abstraction involves constructing a new game that is tractably sized for current solution techniques, but restricts the information or actions available to the players. The hope is that the abstract game preserves the important strategic structure of the game, and so playing a near equilibrium solution of the abstract game will still perform well in the original game. In poker, employed abstractions include limiting the possible betting sequences, replacing all betting in the first round with a fixed policy [1], and, most commonly, by grouping the cards dealt to each player into buckets based on a strength metric [4, 9].
 With these improvements in solution techniques, larger abstract games have become tractable, and therefore increasingly fine abstractions have been employed. Because a finer abstraction can rep-resent players X  information more accurately and provide a more expressive space of strategies, it is generally assumed that a solution to a finer abstraction will produce stronger strategies for the orig-inal game than those computed using a coarser abstraction. Although this assumption is in general not true [7], results from the AAAI Computer Poker Competition [10] have shown that it does often hold: near equilibrium strategies with the largest expressive power tend to win the competition. In this paper, we increase the expressive power of computable strategies without increasing the size of game that can be feasibly solved. We do this by partitioning the game into tractably sized sub-games called grafts, solving each independently, and then combining the solutions into a single strategy. Unlike previous, subsequently abandoned, attempts to solve independent sub-games [1, 3], the grafting approach uses a base strategy to ensure that the grafts will mesh well as a unit. In fact, we prove that grafted strategies improve on near equilibrium base strategies. We also empirically demonstrate this improvement both in a small poker game as well as limit Texas Hold X  X m. Informally, an extensive game is a game tree where a player cannot distinguish between two histories that share the same information set. This means a past action, from either chance or another player, is not completely observed, allowing one to model situations of imperfect information.
 Definition 1 (Extensive Game) [6, p. 200] A finite extensive game with imperfect information is denoted  X  and has the following components: In this paper, we exclusively focus on two-player zero-sum games with perfect recall , which is a restriction on the information partitions that excludes unrealistic situations where a player is forced to forget her own past information or decisions.
 To play an extensive game each player specifies a strategy. A strategy determines how a player makes her decisions when confronted with a choice.
 Definition 2 (Strategy) A strategy for player i ,  X  i , that assigns a probability distribution over A ( h ) to each h  X  H i . This function is constrained so that  X  i ( h ) =  X  i ( h 0 ) whenever h and h 0 are in the same information set. A strategy is pure if no randomization is required. We denote  X  i as the set of all strategies for player i .
 Definition 3 (Strategy Profile) A strategy profile in extensive game  X  is a set of strategies,  X  = {  X  1 , . . . ,  X  n } , that contains one strategy for each player. We let  X   X  i denote the set strategies for all players except player i . We call the set of all strategy profiles  X  .
 When all players play according to a strategy profile,  X  , we can define the expected utility of each according to  X   X  i and player i plays according to  X  i .
 The traditional solution concept for extensive games is the Nash equilibrium concept. Definition 4 (Nash Equilibrium) A Nash equilibrium is a strategy profile  X  where An approximation of a Nash equilibrium or  X  -Nash equilibrium is a strategy profile  X  where A Nash (  X  -Nash) equilibrium is a strategy profile where no player can gain (more than  X  ) through unilateral deviation. A Nash equilibrium exists in all extensive games. For zero-sum extensive games with perfect recall we can efficiently compute an  X  -Nash equilibrium using techniques such as linear programming [5], counterfactual regret minimization [9] and the excessive gap technique [2]. In a zero-sum game we say it is optimal to play any strategy belonging to an equilibrium because this guarantees the equilibrium player the highest expected utility in the worst case. Any deviation from equilibrium by either player can be exploited by a knowledgeable opponent. In this sense we can call computing an equilibrium in a zero-sum game solving the game.
 Many games of interest are far too large to solve directly and abstraction is often employed to reduce the game to one of a more manageable size. The abstract game is solved and the resulting strategy is presumed to be strong in the original game. Abstraction can be achieved by merging information sets together, restricting the actions a player can take from a given history, or a combination of both. Definition 5 (Abstraction) [7] An abstraction for player i is a pair  X  i =  X  I i ,  X  A i , where, The null abstraction for player i , is  X  i =  X  I i , A  X  . An abstraction  X  is a set of abstractions  X  i , one for each player. Finally, for any abstraction  X  , the abstract game ,  X   X  , is the extensive game obtained from  X  by replacing I i with  X  I i and A ( h ) with  X  A i ( h ) when P ( h ) = i , for all i . Strategies for abstract games are defined in the same manner as for unabstracted games. However, the strategy must assign the same distribution to all histories in the same block of the abstraction X  X  information partition, as well as assigning zero probability to actions not in the abstract action set. Though there is no guarantee that optimal strategies in abstract games are strong in the original game [7], these strategies have empirically been shown to perform well against both other com-puters [9] and humans [1]. Currently, strong strategies are solved for in one single equilibrium computation for a single abstract game. Advancement typically involves developing algorithmic im-provements to equilibrium finding techniques in order to find solutions to yet larger abstract games. It is simple to show that a strategy space must include at least as good, if not better, strategies than a smaller space that it refines [7]. At first glance, this would seem to imply that a larger abstraction would always be better, but upon closer inspection we see this depends on our method of selecting a strategy from the space. In poker, when using arbitrary equilibrium strategies that are evaluated in a tournament setting, this intuition empirically holds true.
 One potentially important factor for the empirical evidence is the presence of dominated strategies in the support of the abstract equilibrium strategies.
 Definition 6 (Dominated Strategy) A dominated strategy for player i is a pure strategy,  X  i , such that there exists another strategy,  X  0 i , where for all opponent strategies  X   X  i , and the inequality must hold strictly for at least one opponent strategy. This implies that a player can never benefit by playing a dominated strategy. When abstracting one can, in effect, merge a dominated strategy in with a non-dominated strategy. In the abstract game, this combined strategy might become part of an equilibrium and hence the abstract strategy would make occasional mistakes. That is, abstraction does not necessarily preserve strategy domination. As a result of their expressive power, finer abstractions may better preserve domination and thus can result in less play of dominated strategies.
 Decomposition is a natural approach for using larger strategy spaces without incurring additional computational costs and indeed it has been employed toward this end. In extensive games with imperfect information, though, straightforward decomposition can be problematic. One way that equilibrium strategies guard against exploitation is information hiding, i.e. , the equilibrium plays in a fashion that hinders an opponent X  X  ability to effectively reconstruct the player X  X  private informa-tion. Independent solutions to a set of sub-games, though, may not  X  X esh X , or hide information, effectively as a whole. For example, an observant opponent might be able to determine which sub-game is being played, which itself could be valuable information that could be exploited. Armed with some intuition for why increasing the size of the strategy space may improve the quality of the solution and why decomposition can be problematic, we will now begin describing the strategy grafting algorithm and provide some theoretical results regarding the quality of grafted strategies. First, we will explain how a game of imperfect information is formally divided into sub-games. Definition 7 (Grafting Partition) G = { G 0 , G 1 , . . . , G p } is a grafting partition for player i if Using the elements of a grafting partition, we construct a set of sub-games. The solutions to these sub-games are called grafts, and we can combine them naturally, since they are disjoint sets, into one single grafted strategy.
 Definition 8 (Grafted Strategy) Given a strategy  X  i  X   X  i and a grafting partition G for player i . For j  X  { 1 , . . . , p } , define  X   X  i ,j to be an extensive game derived from the original game  X  where for histories in G j and is forced to play according to  X  i elsewhere. Let the graft of G j ,  X   X  ,j , be an -Nash equilibrium of the game  X   X  i ,j . Finally, define the grafted strategy for player i  X   X  i as, We will call  X  i the base strategy and G the grafting partition for the grafted strategy  X   X  i . There are a few key ideas to observe about grafted strategies that distinguish them from previous sub-game decomposition methods. First, we start out with a base strategy for the player. This base strategy can be constructed using current techniques for a tractably sized abstraction. It is important that we use the same base strategy for all grafts, as it is the only information that is shared between the grafts. Second, when we construct a graft, only the portion of the game that the graft plays is allowed to vary for our player of interest. The actions over the remainder of the game are played according to the base strategy. This allows us to refine the abstraction for that block of the grafting partition, so that it itself is as large as the largest tractably solvable game. Third, note that when we construct a graft, we continue to use an equilibrium finding technique, but we are not interested in the pair of strategies  X  we are only interested in the strategy for the player of interest. This means in games like poker, where we are interested in a strategy for both players, we must construct a grafted strategy separately for each player. Finally, when we construct a graft, our opponent must learn a strategy for the entire, potentially abstract, game. By letting our opponent X  X  strategy vary completely, our graft will be a strategy that is less prone to exploitation, forcing each individual graft to mesh well with the base strategy and in turn with each other graft when combined. Strategy grafting allows us to construct a strategy with more expressive power that what can be computed by solving a single game. We now show that strategy grafting uses this expressive power to its advantage, causing an (approximate) improvement over its base strategy. Note that we cannot guarantee a strict improvement as the base strategy may already be an optimal strategy. Theorem 1 For strategies  X  1 ,  X  2 where  X  2 is an -best response to  X  1 , if  X   X  1 is the grafted strategy for player 1 where  X  1 is used as the base strategy and G is the grafting partition then, In other words, the grafted strategy X  X  improvement against  X  2 is equal to the sum of the gains of the individual grafts against  X  2 and this gain is no less than  X  3 p .
 P
ROOF . Define Z j as follows, By condition (3) of Definition 7, Z j =0 ,...,p are disjoint and therefore form a partition of Z . non-zero. Furthermore, since  X   X  ,j 1 and  X   X  ,j 2 are strategies of the -Nash equilibrium  X   X  ,j , Moreover, because  X  2 is an -best response to  X  1 , The main application of this theorem is in the following corollary, which follows immediately from the definition of an -Nash equilibrium.
 Corollary 1 Let  X  be an abstraction where  X  2 =  X  2 and  X  be an -Nash equilibrium strategy for the game  X   X  , then any grafted strategy  X   X  1 in  X  with  X  1 used as the base strategy will be at most 3 p worse than  X  1 against  X  2 . Although these results suggest that a grafted strategy will (approximately) improve on its base strat-egy against an optimal opponent, there is one caveat: it assumes we know the opponent X  X  abstraction or can solve a game with the opponent unabstracted. Without this knowledge or ability, this guaran-tee does not hold. However, all previous work that employs the use of abstract equilibrium strate-gies also implicitly makes this assumption. Though we know that refining an abstraction also has no guarantee on improving worst-case performance in the original game [7], the AAAI Computer Poker Competition [10] has shown that in practice larger abstractions and more expressive strategies consistently perform well in the original game, even though competition opponents are not using the same abstractions. We might expect a similar result even when the theorem X  X  assumptions are not satisfied. In the next section we examine empirically both situations where we know our opponent X  X  abstraction and situations where we do not. The AAAI Computer Poker Competitions use various types of large Texas Hold X  X m poker games. These games are quite large and the resulting abstract games can take weeks of computation to solve. We begin our experiments in a smaller poker game called Leduc Hold X  X m where we can examine several grafted strategies. This is followed by analysis of a grafted strategy for two-player limit Texas Hold X  X m that was submitted to the 2009 AAAI Poker Competition. 4.1 Leduc Hold X  X m Leduc Hold X  X m is a two player poker game. The deck used in Leduc Hold X  X m contains six cards, two jacks, two queens and two kings, and is shuffled prior to playing a hand. At the beginning of a hand, each player pays a one chip ante to the pot and receives one private card. A round of betting then takes place starting with player one. After the round of betting, a single public card is revealed from the deck, which both players use to construct their hand. This card is called the flop . Another round of betting occurs after the flop, again starting with player one, and then a showdown takes place. At a showdown, if either player has paired their private card with the public card they win all the chips in the pot. In the event neither player pairs, the player with the higher card is declared the winner. The players split the money in the pot if they have the same private card.
 Each betting round follows the same format. The first player to act has the option to check or bet . When betting the player adds chips into the pot and action moves to the other player. When a player faces a bet, they have the option to fold , call or raise . When folding, a player forfeits the hand and all the money in the pot is awarded to the opposing player. When calling, a player places enough chips into the pot to match the bet faced and the betting round is concluded. When raising, the player must put more chips into the pot than the current bet faced and action moves to the opposing player. If the first player checks initially, the second player may check to conclude the betting round or bet. In Leduc Hold X  X m there is a limit of one bet and one raise per round. The bets and raises are of a fixed size. This size is two chips in the first betting round and four chips in the second. Tournament Setup. Despite using a smaller poker game, we aim to create a tournament setting similar to the AAAI Poker Competition. To accomplish this we will create a variety of equilibrium-like players using abstractions of varying size. Each of these strategies will then be used as a base strategy to create two grafted strategies. All strategies are then played against each other in a round-robin tournament. A strategy is said to beat another strategy if its expected winnings against the other is positive. Unlike the AAAI Poker Competition, in our smaller game we can feasibly compute the expected value of one strategy against another and thus we are not required to sample.
 The abstractions used are J.Q.K , JQ.K , and J.QK . Prior to the flop, the first abstraction can distin-guish all three cards, the second abstraction cannot distinguish a jack from a queen and the third cannot distinguish a queen from a king. Postflop, all three abstractions are only aware of if they have paired their private card. These three abstractions were hand chosen as they are representative of how current abstraction techniques will group hands together. The first abstraction is the biggest, and hence we would expect it to do the best. The second and third abstractions are the same size. We chose to train two types of grafted strategies: preflop grafts and flop grafts . Both types consist of three individual grafts for each player: one to play each card with complete information. That is, Table 1: Expected winnings of the row player against the column player in millibets per hand (mb/h) Table 2: Each strategy X  X  number of wins, losses, and exploitability in unabstracted Leduc Hold X  X m in millibets per hand (mb/h) each graft does not abstract the sub-game for the observed card. These two types differ in that the preflop grafts play for the entire game whereas the flop grafts only play the game after the flop. For preflop grafts, this means G 0 is empty, i.e., the final grafted strategy is always using the probabilities from some graft and never the base strategy. For flop grafts, the grafted strategy follows the base strategy in all preflop information sets. We use  X  -Nash equilibria in the three abstract games as our base strategies. Each base strategy and graft is trained using counterfactual regret minimization for one billion iterations. The equilibria found are  X  -Nash equilibria where no player can benefit more than  X  = 10  X  5 chips by deviating within the abstract game. We measure the expected winnings in millibets per hand or mb/h. A millibet is one thousandth of a small bet, or 0 . 002 chips. Results. We can see in Table 1 that the grafted strategies perform well in a field of equilibrium-like strategies. The base strategy seems to be of great importance when training a grafted strategy. Though JQ.K and J.QK are the same size, the JQ.K strategy performs better in this tournament setting. Similarly, the grafted strategies appear to maintain the ordering of their base strategies either when considering the expected winnings in Table 1 or the number of wins in Table 2 (though JQ.K flop grafts switches places with JQ.K preflop grafts in the ordering). Although the choice of base strategy is important, the grafted strategies do well under both evaluation criteria and even the worst base strategy sees great relative improvement when used to train grafted strategies. There are also a few other interesting trends in these results. First, our intuition that larger strategies perform better seems to hold in all cases except for J.QK flop grafts . Larger abstractions also perform better for the non-grafted strategies as J.Q.K is the biggest equilibrium strategy and it performs the best out of this group. Second, it appears that the preflop grafts are usually better than the flop grafts. This can be explained by the fact that the preflop grafts have more information about the original game. Finally, observe that the grafted strategies can have worse exploitability in the original game than their corresponding base strategy. Although this can make grafted strategies more vulnerable to exploitive strategies, they appear to perform well against a field of equilibrium-like opponents. In fact, in our experiment, grafted strategies appear to only improve upon the base strategy despite not always knowing the opponent X  X  abstraction. This suggests that exploitability is not the only important measure of strategy quality. Contrast the grafted strategies with the strategy that always folds, which is exploitable at 500 mb/h. Although always folding is less exploitable than some of the grafted strategies, it cannot win against any opponent and would place last in this tournament. Table 3: Sampled expected winnings in Texas Hold X  X m of the row player against the column player in millibets per hand (mb/h). 95% confidence intervals are between 0 . 8 and 1 . 6 . Relative size is the ratio of the size of the abstract game(s) solved for the row strategy and the base strategy. 4.2 Texas Hold X  X m Two-player limit Texas Hold X  X m bears many similarities to Leduc Hold X  X m but is much larger in scale with respect to the parameters: cards in the deck, private cards, public cards, betting rounds and bets per round. Due to the computational cost 2 needed to solve a strong equilibrium, our experiments consist of a single grafted strategy. Table 3 shows the results of running this large grafted strategy against equilibrium-like strategies using a variety of abstractions.
 The 20x32 strategy is the largest single imperfect recall abstract game solved to date. It is approxi-mately 2 . 53 times larger than the base strategy used with grafting, 20x8 . The 20x7 (imperfect recall) and 12 (perfect recall) strategies were the entrants put forward by the Computer Poker Research Group for the 2008 and 2007 AAAI Computer Poker Competitions, respectively. The 14 strategy was considered for the 2008 competition, but it was ultimately superseded by the smaller 20x7 . For a detailed description of these abstractions and the rules of Texas Hold X  X m see A Practical Use of Imperfect Recall [8].
 As evident in the results, the grafted strategy beats all of the players with statistical significance, even the largest single strategy. In addition to these results against other Computer Poker Research Group strategies, the grafted strategy also performed well at the 2009 AAAI Computer Poker Competition. There, against a field of thirteen strong strategies, it placed second and fourth (narrowly behind the third place entrant) in the limit run-off and limit bankroll competitions, respectively. These results demonstrate that strategy grafting is competitive and allows one to augment their existing strategies. Any improvement to the quality of a base strategy should in turn improve the quality of the grafted strategy in similar tournament settings. This means that strategy grafting can be used transparently on top of more sophisticated strategy-computing methods. We have introduced a new method, called strategy grafting, for independently solving and com-bining sub-games in large extensive games. This method allows us to create larger strategies than previously possible by solving many sub-games. These new strategies seem to maintain the features of good equilibrium-like strategies. By creating larger strategies we hope to play fewer dominated strategies and, in turn, make fewer mistakes. Against a static equilibrium-like opponent, making fewer mistakes should lead to an improvement in the quality of play. Our empirical results confirm this intuition and demonstrate that this new method can improve the performance of the state-of-the-art in both a simulated competition and the actual AAAI Computer Poker Competition. It is likely that much of the strength of these new strategies will be bounded by the quality of the base strategy used. In this regard, we are still limited by the capabilities of current methods.
 The authors would like to thank the members of the Computer Poker Research Group at the Univer-sity of Alberta for helpful conversations pertaining to this research. This research was supported by NSERC, iCORE, and Alberta Ingenuity. [1] Darse Billings, Neil Burch, Aaron Davidson, Robert Holte, Jonathan Schaeffer, Terance [2] Andrew Gilpin, Samid Hoda, Javier Pe  X  na, and Tuomas Sandholm. Gradient-based Algorithms [3] Andrew Gilpin and Tuomas Sandholm. A Competitive Texas Hold X  X m Poker Player via Auto-[4] Andrew Gilpin and Tuomas Sandholm. Expectation-Based Versus Potential-Aware Automated [5] Daphne Koller and Avi Pfeffer. Representations and Solutions for Game-Theoretic Problems. [6] Martin Osborne and Ariel Rubinstein. A Course in Game Theory . The MIT Press, Cambridge, [7] Kevin Waugh, David Schnizlein, Michael Bowling, and Duane Szafron. Abstraction Patholo-[8] Kevin Waugh, Martin Zinkevich, Michael Johanson, Morgan Kan, David Schnizlein, and [9] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret Mini-[10] Martin Zinkevich and Michael Littman. The AAAI Computer Poker Competition. Journal of
