 1. Introduction and motivation
Recommender systems have traditionally been a fertile research area due to the existence of a wide range of scenarios where users may benefit from automatic personalised recommendations. This research area has its roots in the eighties, and started to attract wider attention in the mid-1990 when the first works on collaborative filtering were published ( Hill, the three classical approaches to recommendation ( Adomavicius &amp; Tuzhilin, 2005 ): content-based recommendation , based on content-based recommendation and collaborative filtering.

In CF ( Herlocker, Konstan, &amp; Riedl, 2002 ), the input evidence about user preferences consists of data records collected from user interaction with items. In the simplest form, this evidence consists of explicit user ratings, which are graded rel-evance values assigned by end-users to items of interest. CF algorithms exploit the target user X  X  ratings to make preference predictions, and have the interesting property that no item descriptions are needed to provide recommendations, since the algorithms merely exploit information about past interaction between users and items. Moreover, CF has the salient advantage that a user benefits from others X  experience, being exposed to novel recommendations produced from the personal preferences of affine users.  X 
Two different types of CF approaches exist: model-based approaches, which learn user/item rating patterns to build statistical models that provide rating estimations, and memory-based approaches, which compute user/item similarities based on distance and correlation metrics ( Desrosiers &amp; Karypis, 2011 ). Memory-based approaches find either like-minded people for the target user (user-based approach), or pairs of items that are liked by common users. In the user-based approach, the set of similar-minded users are called neighbours, and their preferences are combined to pre-dict ratings for the active user. In the item-based approach, items similar to the ones the user has liked in the past are recommended.

The recommendation task has been traditionally formulated and evaluated as a rating prediction problem ( Adomavicius &amp; Tuzhilin, 2005 ). However, in practical terms, the effectiveness of recommendations depends on what items are presented to the user and in what order. Thus the ranking of recommended items, rather than the numeric system scores that deter-mine this ranking, is the essential problem in common recommendation scenarios, whereby recommendation can be seen as an IR task  X  one where there is no explicit query. Considering this, several proposals have been recently developed to for-malise and address the recommendation task as a relevance ranking problem ( Bellog X n, Wang, &amp; Castells, 2011b; Wang, is to take advantage of well-studied and highly-performing Information Retrieval (IR) techniques to achieve effectiveness enhancements  X  and a better theoretical understanding  X  in recommendation tasks, upon principles of ranking for relevance. tended Boolean model ( Bellog X n, Wang, &amp; Castells, 2011a ), the binary independence retrieval model (upon the probability ranking principle) ( Wang et al., 2008 ; Wang &amp; Robertson et al., 2008 ), and statistical Language Models ( Wang et al., 2006a ). However, to the best of our knowledge, no attempt has been made yet at a similar adaptation of so-called Rele-vance-Based Language Models ( Lavrenko &amp; Croft, 2001 ).

Relevance-Based Language Models (or Relevance Models for short, RM) are among the best-performing ranking tech-niques in text retrieval. They were devised with the aim of explicitly introducing the concept of relevance, intrinsic to the probabilistic model of IR, in statistical Language Models (LM). Relevance Models achieve state-of-the-art performance in
In IR, relevance is a relation between a query and a set of documents. In common IR settings, the exact and complete set of relevant documents is generally unknown. Relevance feedback techniques work with approximations to this set, which tial output of a well-performing IR system as a good guess (pseudo relevance feedback)  X  this is the case in RM. Given a query and such an approximation to the set of relevant documents, RM selects good expansion terms from those present in the pseudo-relevant documents in order to formulate and run a better query.

The adaptation of RM to recommendation is non-trivial as, to begin with, there are neither queries nor words in the gen-eric recommendation task. A first problem we therefore address is to find an analogy between the elements involved in RM as defined in text retrieval (documents, queries, words, pseudo-relevant documents, expanded terms), and the variables han-dled by a recommender system: users, (black-box) items, and records of interaction between them. In this paper we propose one such analogy under which the RM can be adapted to recommendation, leveraging the effectiveness of the Relevance
Models to estimate the probabilities of relevance, even when the probability distributions are not expressed in terms of words as originally proposed for text retrieval. Our approach involves, as we shall see, the selection of similar users as the equivalent of pseudo-relevant documents, resulting in a form of user profile expansion through the preferences of near-est neighbours.

A good approximation of the set of relevant documents is critical to the effectiveness of pseudo relevance feedback meth-ods. Analogously, a good selection of user neighbourhoods (as the equivalent of pseudo-relevant documents) can be ex-pected to heavily influence the effectiveness of our approach. In the context of a probabilistically formalised framework orous probabilistic basis for neighbourhood formation, based on Non-negative Matrix Factorisation (NMF). Besides the prob-abilistic interpretability of this method, the NMF family of algorithms has proved to have a very good performance in terms tering in recommender systems, both in isolation (as an enhancement of neighbour selection in CF recommendation), and in combination with the relevance modelling of the recommendation process.
 The main contributions of this paper thus include:
A new recommendation approach based on Relevance Modelling under the Statistical Language Modelling frame-work, where the recommendation process is modelled as a profile expansion process. We produce new estimations for RM under the i.i.d. sampling and conditional sampling assumptions in recommender systems. We develop the probabilistic framework into computable terms, resulting in a novel, empirically effective recommendation method.

The use of probabilistic clustering methods for the neighbour selection problem, in particular, the use of Posterior Prob-abilistic Clustering, for which we have produced the necessary document representation strategies to be able to use PPC for a task so different from that originally conceived (text clustering).

The combination of both contributions, further enhancing the performance of their separate application. We find perfor-mance improvements of over 300% with respect to the best tested method from the state-of-the-art.
 The remainder of the paper is structured as follows: in Section 2 we present a study of the works related to our proposal.
Section 3 presents the Relevance Modelling framework and its adaptation to the recommendation problem. In Section 4 we introduce our proposal for neighbour selection based on Posterior Probabilistic Clustering. Section 5 reports the empirical evaluation of the proposed approaches and analyses the results of different experiments. Finally, conclusions and future work directions are presented in Section 6 . 2. Related work
The use of probabilistic modelling from Information Retrieval in Collaborative Filtering has been research before by sev-eral authors. In ( Wang &amp; Robertson et al., 2008 ), the authors found interesting analogies between CF with implicit data (where the evidence of user interest for items consists of access frequencies, rather than explicit preference rating values) and IR, introducing the concept of binary relevance into CF and applying the Probability Ranking Principle of IR to CF. Sim-use of a language modelling formulation to propose a risk-aware ranking for implicit CF. The approach we propose here is much in tune with the spirit of this line of research on model unification. A fundamental difference is that the aforemen-tioned related work is restricted to recommendation settings where the user activity records provide frequency of (repeated) user interaction with items, and cannot be applied to explicit rating data  X  a very common source of groundtruth data in CF  X  as our approach does. Furthermore, as far as we know our approach is the first that fully adapts the Relevance Models as proposed in ( Lavrenko &amp; Croft, 2001 ).

Regarding rating-based CF, one of the first works which explicitly dealt with a generative probabilistic framework in a rating-based collaborative filtering scenario is ( Wang, de Vries, &amp; Reinders, 2006b ). In that work, together with ( Wang et al., 2008 ), the authors presented a probabilistic relevance framework, where three models are derived: one based on users, another based on items, and a unified relevance model. This modelling approach was based on the probabilistic interpretation of the Relevance Models for language modelling ( Lafferty &amp; Zhai, 2002 ). We share with this work the goal to model the recommendation problem as a relevance ranking task. The key difference is that Wang et al. seek the unifi-cation of probabilistic IR and recommendation principles in producing an initial ranking, while our proposal unifies query expansion and (a novel notion of) user profile expansion in the recommendation process. Furthermore, a comparative empirical evaluation of both proposals shows that our methods achieve better results in terms of precision-based metrics, whereas Wang X  X  methods perform well with error-based metrics such as Mean Absolute Error. Furthermore, the relevance models by Wang et al. require a considerably involved and expensive training phase (based on Expectation Maximisation) to learn the optimal parameter values (bandwidth h u in ( Wang et al., 2008 )), while the methods proposed herein only have two simple parameters (linear smoothing coefficient and number of clusters, as we shall see) for which very simple tuning approaches are sufficient, and even default values from other collections achieve a decent performance, as we shall show in our experiments.

Regarding the use of clustering for recommendation, some authors split the set of users or items in order to improve the proaches use classic clustering methods such as k -Means or hierarchical clustering, which, in general, produce good results but at the expense of lower coverage ( Xue et al., 2005 ). Furthermore, some approaches require external or additional infor-mation, such as the content data of the item (e.g. genres or tags, in the movie domain). In this line of research, we have re-cently studied the use of the Normalised-Cut algorithm for neighbour selection in ( Bellog X n &amp; Parapar, 2012 ), showing important improvements over classical clustering approaches but not reaching the performance of the presented PPC-based approach.
 Although there are no Posterior Probabilistic Clustering applications in the field of recommendation, Non-negative
Matrix Factorisation (NMF) methods have been previously used, mainly for the rating prediction task, as a model-based recommender similar to, for instance, SVD. In Gu, Zhou, and Ding (2010) , a unified model is proposed for collaborative filtering based on a type of non-negative matrix factorisation algorithm. While, in our case, Posterior Probabilistic
Clustering is only a better performing tool for locating good neighbourhoods, in that work the NMF algorithm also pro-duces recommendations itself, by combining both model-based and memory-based information to improve the recommendation effectiveness. The evaluation against existing methods exhibited however modest improvements in terms of Mean Absolute Error. Among other baselines, they compared the results with a previous work by
Zhang, Wang, Ford, and Makedon (2006) that also uses different types of NMF algorithms. The latter was a pioneering work on tackling the problem of incomplete ratings when applying recommendations based on weighted NMF, obtaining small improvements against user-based and matrix factorisation techniques, again in terms of Mean Absolute
Error. 3. Relevance-based language modelling for recommendation
We will first briefly review the Relevance Models in their original context, after which we shall present our proposal for the adaptation of relevance modelling to the recommendation problem. 3.1. Relevance Models in information retrieval
Blind feedback or pseudo relevance feedback is a local query expansion technique used for improving retrieval effective-ness. The basic assumption in pseudo relevance feedback is that a high number of top documents initially returned by a re-trieval system are relevant. Given that assumption, the idea is to choose from those documents good terms to expand the original query in order to improve the effectiveness in a second document ranking with the expanded version of the query.
In ( Lavrenko &amp; Croft, 2001 ), Relevance Models were presented under the Language Modelling framework and proved to be very successful to improve retrieval effectiveness. Relevance Models have not only been proposed as an effective method for pseudo relevance feedback but also as a robust one ( Lv &amp; Zhai, 2009 ). Moreover, Relevance Modelling has already been used for other tasks and in combination with other approaches such as the employment of query variants ( Collins-Thompson passage retrieval ( Li &amp; Zhu, 2008 ), constrained text clustering ( Parapar &amp; Barreiro, 2012 ), etc. In RM, the original query Q is seen as a short sample of words obtained from the relevance model ( R R are desired then it is reasonable to choose those words with the highest estimated probability when considering the words for the distribution already seen. So the terms in the lexicon of the collection are sorted according to that estimated probability. Lavrenko and Croft (2001) originally presented two different estimations for RM, namely RM1 and RM2.
First, in RM1 we assume that the query words q i 2 Q and the words w in the relevant documents are sampled identically and independently from a unigram distribution ( i.i.d. sampling ), thus, the probability p ( w j R renko &amp; Croft, 2001 ): where C is the set of all documents in the search space (the collection).

On the other hand, in RM2 ( conditional sampling ) the main assumption is that the query words are independent from each other but dependent on the words of the relevant documents. As a result of that, p ( w j R equation ( Lavrenko &amp; Croft, 2001 )
The final ranking is obtained in four steps: 1. Initially, the documents in the collection C are ranked under the LM framework using the query likelihood retrieval func-tion. This query likelihood is usually estimated with some form of smoothing. this pseudo relevance set or RS . 3. The relevance model probabilities p ( w j R Q ) are calculated using the estimation presented in Eq. (1) or Eq. (2) . 4. To build the expanded query, the e terms with highest estimated probabilities p ( w j R used to produce a second document ranking using the negative cross entropy retrieval function, as follows 3.2. Relevance modelling for recommendation
As we have seen in the previous section, RM in text retrieval operates on three main spaces: words, documents, and que-ries. Words are related to queries and documents by direct observation, which enable the estimation of conditional proba-bilistic relations between the three sampling spaces. Documents play two different roles: as objects to be ranked, and as pseudo-relevant objects. So do words, as elements defining the initial information need expression, and as terms for query expansion. Yet the general recommendation task considers just two tangible fundamental variables: users and items, and the direct observations only involve the interaction between them (e.g. users assign rating values to items). Some probabilistic consider this option here; we rather see ratings as an intrinsic property of the relation between users and items which is equivalent to the role of the term weights in the RM formulation for retrieval.

The adaptation of RM to recommendation thus involves a non-trivial transition from a triadic space (queries, documents, words) to a dyadic one (users and items). We propose to achieve this mapping as follows: first, the role of the query in the retrieval task is played by the user to whom we want to provide with item recommendations (target user). Now, as stated before, the objective in pseudo relevance feedback is to select from the pseudo relevant set good terms which are related to the original query terms. In the case of retrieval, the goodness of those selected terms is evaluated by how adding them to the original query produces a more effective second document ranking. In recommendation and, particularly, in collaborative filtering, the user is modelled as a set of previously scored items. In our approach, we propose to have those items play the role of the query words in IR relevance models. This is how in our adaptation of RM to recommendation, query expansion translates to a form of user profile expansion, where the objective is to expand the user need representation, embodied in the user profile, with further items related to her expressed interests. In this formulation, the recommendation process becomes a profile expansion problem, where items to be recommended play the role of the candidate expansion terms in the pseudo relevance feedback task. Finally, the role of the pseudo-relevant documents is played in our model by the set of similar users (the user neighbourhood, based on profile similarity with the target user). The same as the selec-key to the effectiveness of our proposed adaptation, which motivates the research of adequate neighbour formation tech-niques. We will assume for the moment the neighbourhood is given, and we will describe later in Section 4 how we address this part of the problem by a probabilistic clustering approach.

The set of analogies on which our approach is based is shown in Fig. 1 . The reader may have expected to find in our expla-nation a classical and natural equivalence between retrieved text documents and recommended items. This is intentionally missing in our approach because, differently from the application of RM in text retrieval, we propose to take the result of profile expansion itself as the final recommendation output, skipping the final, second ranking step in RM (Eq. (3) ). That is, the output of the resulting recommendation algorithm is the equivalent of the output from term selection in RM (Eqs. (1) and (2) ). Since the elements for expansion are items already (belonging to the final retrieval space), we omit the subse-quent re-ranking which in RM uses the selected terms as input (Eq. (3) ).
 The triadic/dyadic problem is thus addressed in our framework by:
Having users  X  or to be more precise, user profiles  X  play a dual role, as (a) a representation of user needs, equivalent to a query, (target user) and (b) a pseudo-relevant document, serving as a source for item selection in profile expansion (target user X  X  neighbours).

Omitting the retrieved document variable from our formulation, by equating expansion terms and retrieved items, and skipping the second ranking in RM.

The recommendation problem can be thus accommodated as an expansion process where the models for pseudo rele-vance feedback can be tested. In order to accomplish the proposed adaptation, we need to assume that for every target user u 2C and set of relevant users or neighbours ( V ), an underlying Relevance Model R can be estimated under the RM framework and, from this estimation, the ranking of best items to recommend to the user u different neighbour selection methods can be incorporated in a straightforward way. Indeed, we will go back to this point later on and show how different selection approaches can be integrated into our model.

Using neighbours as pseudo-relevant documents has an additional consequence, which we would like to stress: differ-ently from RM in text IR, our approach does entirely without an initial, first-step ranking  X  the ranking RM would require in text IR to select the top N documents as the pseudo-relevant set.

In the following two subsections we show how the two models RM1 and RM2 proposed in the IR field ( Lavrenko &amp; Croft, 2001 ) can be effectively adapted to the recommendation task, following the proposed analogies. 3.2.1. Method 1: i.i.d. sampling
Analogously to the RM1 estimation in IR, we produce RM1-based recommendations. In this context, we assume that the items in the user X  X  profile and the items rated by the user X  X  neighbours are sampled identically and independently from a uni-gram distribution. Eq. (4) defines the estimation of probabilities in the Relevance Model underlying u and V . For every the relevance model R u for user u is computed as: where I ( u ) is the set of items already rated by the user u .

Therefore, Q j 2 I  X  u  X  p  X  j j v  X  being the user X  X  profile likelihood for the neighbour as uniform, we can estimate the probability of an item under the Relevance Model for a given user, as the weighted average of the language model probabilities for the item in the neighbourhood of the user, where the weights are the user profile likelihood scores for her neighbours.

Given this scoring formula, the top items can be selected for recommendation by ranking the items according to the prob-users have a dual role: for items, retrieved items correspond to expansion terms i ? w and the items rated by the user cor-pseudo-relevant documents V ? RS . 3.2.2. Method 2: Conditional sampling
Alternatively, we can make use of the conditional sampling assumption as in the RM2 method. In this case, we assume that items in the user X  X  profile are independent from each other but dependent on the items present in the profiles of the user X  X  neighbours. In this situation, the item preference is computed as follows: where p ( v j i ) is estimated with Bayes as p ( i j v ) p ( is the same as the correspondence between Eqs. (1) and (4) for RM1 underlined in the previous sections. 3.2.3. Final estimation details
For both methods we can initially consider that the prior p ( ability of being sampled. The estimation of the probability of an item given a user will be computed by smoothing the max-imum likelihood estimate with the probability in the collection (background collection model), in this case using Jelinek X 
Mercer smoothing ( Zhai &amp; Lafferty, 2004 ): where I  X C X  is the set of items in the collection and p ml whole collection:
In the Language Modelling framework and retrieval tasks, Dirichlet smoothing outperforms Jelinek X  X ercer ( Zhai &amp; Lafferty, 2004 ). However, when modelling the recommendation problem, Dirichlet can suffer from the undesired effect of demoting those items that have been recently introduced in the system and so have very few recommendations. In fact, in ( Wang, 2009 ) the smoothing for the LM based recommendation with Dirichlet smoothing presents significantly worse performance than using Jelinek X  X ercer in one of the experiments reported there. For estimating p ( i ) we decided to keep it simple and a uniform distribution was chosen.

Finally, depending on the proposed methods, different strategies were used in this paper to compute the neighbourhood of a given user ( V ), as we present in the next section. 4. A probabilistic neighbour selection technique
A crucial step in order to rank the items according to the RM framework is to properly select the relevance set. In our adaptation of the RM framework to user-based collaborative filtering, this relevance set is composed by the target user X  X  neighbourhood, that is, the set of her most akin users. Next, we will define an alternative probabilistic approach to the com-putation of such neighbourhoods. This is not enforced by the RM approach itself, and other alternatives could thus be con-sidered as well, which we leave as future work. A probabilistic neighbour selection approach provides nonetheless for a smoother global user-based CF framework. In particular, the approach proposed here builds on the Posterior Probabilistic Clustering algorithm, as we present next.
 4.1. Posterior Probabilistic Clustering (PPC)
The lack of probabilistic interpretation of Non-negative Matrix Factorisation (NMF) ( Lee &amp; Seung, 2001 ) clustering meth-ods and their ad hoc document-to-cluster assignments motivated the development of the Posterior Probabilistic Clustering (PPC) method ( Ding et al., 2008 ). PPC provides with a posterior probability interpretation, removes uncertainty in the clus-tering assignment and has a very close relation to probabilistic latent semantic indexing when performing co-clustering of documents and words.

Given a collection of n documents and m words, let X =( X term frequency of the term w i in the document d j . The traditional formulation of the NMF method consists in solving the following optimisation problem, given a number of clusters j :
Once the solution ( G  X  , F  X  ) to the optimisation problem is obtained, every document d where z ranges from 1 to j .

PPC is a posterior probability interpretation of the NMF algorithm. PPC considers the rows of G  X  as the posterior proba-bilities that a given document belongs to the different clusters, i.e. p  X  d tribution, a PPC optimisation function is formulated as follows: which results, after using Lagrangian multipliers, in the next updating rules:
This alternative interpretation of the Non-negative Matrix Factorisation algorithm allows the classical hard clustering task based on the same cluster selection procedure as in NMF (Eq. (11) ). Furthermore, it also represents a probabilistic interpre-tation of the clustering problem supplying degrees of membership of documents to clusters. This information can also be exploited in the recommendation problem as we shall explain in the next section. 4.2. Neighbour selection based on PPC
As described before, we want PPC to find better neighbourhoods (clusters) for the users. Therefore, we have to adopt cer-tain decisions in order to model the neighbour selection problem in recommender systems with the PPC algorithm. Which representation fits better this particular problem determines our first decision. In the recommendation problem, the role of documents will be played by users and the role of terms will be played by items which, in collaborative filtering, are the constituent elements of the user representation. In this context, we apply the PPC algorithm under the following settings.
Having a collection of n users and m items, let X =( X ab the rating assigned by the user u b to the item i a , i.e., rat( u when no rating was produced by the user to the item.

Given this formulation of the clustering scenario, once the minimisation problem formulated in Eq. (12) is solved, the ele-ments of G  X  contain the posterior probabilities of the users given the clusters, i.e., p  X  u ditional neighbour selection can be done as in hard-clustering by assigning each user only to the cluster C k  X  argmax z  X  G bz  X  where z ranges from 1 to j .

Therefore, for each user u we obtain a neighbourhood V as the cluster to which the user belongs. Given this situation we can build a recommender which predicts the rating for user u and item i in the following way ( Adomavicius &amp; Tuzhilin, 2005 ): mate sim( u , v )as provided that the index of user v is c (that is, v = u c ) and that V = C
The only remaining decision is to choose the desired number of neighbours (in our case, the number of clusters that we want to obtain with PPC, i.e., j ). We discuss this point in the following section. 5. Experiments and results
In this section we present three different experiments and discuss the results by comparing the performance of our pro-posals presented in Sections 3.2 and 4.2 against standard recommendation techniques. 5.1. Evaluation methodology In the evaluation of the recommendation methods, we have used two publicly available datasets commonly named as
Movielens 100K and Movielens 1M 1 which are very popular in the evaluation of recommendation methods. Some characteristics emphasise this issue, we have incorporated information about the time span each dataset was collected. Furthermore, as we one to validate the results.

We performed a standard 5-fold cross-validation evaluation using the splits provided with the collections. This is a typical experimental approach in the recommender systems field, where in each split the 80% of the data is retained in order to pro-duce item recommendations which are evaluated with the 20% of the held out data. Note that this cross-validation has solely evaluation purposes and it is independent from the parameter training. We apply ranking oriented metrics which have re-cently started to be widely used to evaluate recommender systems. Besides, it is not possible to apply metrics such as MAE and RMSE to our approaches, since the proposed methods rank items, but do not generate rating predictions.
The methodology used in the evaluation corresponds to the TestItems approach described in ( Bellog X n, Castells, &amp; Canta-items already rated by the user (i.e., in training). We also tested alternative methodologies, such as the one proposed by Ko-ren (2008) where a ranking is generated for each item in the test set based on N additional not-relevant items. We observed similar trends to those reported herein with that methodology in preliminary experiments.

Once a ranking has been generated for each user, e.g., with the TestItems methodology, its performance can be measured precision at 5 (P@5), precision at 50 (P@50) and normalised discounted cumulative gain with cut-offs at 5 and 10 (nDCG@5 and underestimate the true metric values.

Regarding the experimental results, we tuned the values of the parameters k (amount of smoothing of the relevance mod-els) and j (number of clusters for PPC) involved in the different compared methods by optimising P@5 on the small Movielens mal parameter values for the same collection were previously reported in ( Wang et al., 2008 ), as we shall point out again in coverage , that is, the number of users for which the system is able to recommend at least one item. After tuning the param-eters k and j on Movielens 100K , we evaluate the methods in the larger Movielens 1M collection using the same evaluation methodology as before with the optimal parameters obtained for the first dataset. For this reason, sometimes we will refer to the first dataset as the training collection , whereas the second would be the test collection .

Finally, to analyse the statistical significance of the results, we performed Wilcoxon Signed-Rank Test ( Wilcoxon, 1945 ), where the performance at user level of two methods are compared. In this case the two paired samples are the concatenation of the user-level effectiveness values of the five different folds. 5.2. Baselines terms of the algorithmic strategy, or in terms of the performance. More specifically, we compared our proposals with a stan-dard User-Based collaborative filtering method (UB) ( Resnick et al., 1994 ) where the neighbourhood is selected among the state of the art method which does not use any neighbour selection but it is based on Matrix Factorisation through Singular
Value Decomposition (SVD) using 50 dimensions (MF) ( Koren, 2008 ) and that is generally among the best performing rec-ommendation methods to date (in terms of error metrics).
 Moreover, we also tested against other existing proposals based on modelling of the recommendation problem as an
Information Retrieval task, where the main differences to our proposals are discussed in Section 2 . We test our methods against the user-based formulation of the probabilistic interpretation of the relevance models for log-based CF proposed in ( Wang et al., 2006a ) (UIR-User) , formulated in Eq. (16) of that paper, that is: where the sum is over the set of users who have expressed interest for item i ( given the target user u assuming relevance ( r ) is estimated as follows:
And the probability of a user v assuming relevance is estimated by the count of items rated by the user:
Another included baseline is the user-based model presented in ( Wang et al., 2008 ) (User-basedRM) , which allows for intro-ducing ratings in the probability estimations. More specifically, we use the Eq. 40a from ( Wang et al., 2008 ) which goes as follows: where cos( u , v ) is a cosine kernel based similarity measure ( Liu, Lu, &amp; Ma, 2004 ) between the user u and vectors in the item space, where the missing ratings can be replaced by a constant value of 0 or by the average rating value.
As we have discussed in the related work section, this approach requires a prior learning of the value h width window parameter) based on an expectation X  X aximisation process ( Wang et al., 2008 ). In order to provide a fair com-parison, we shall use here the best value reported in ( Wang et al., 2008 ), which was tuned on the very same collection ( h u  X  0 : 79). 5.3. Results
We present now the conducted experimentation, along with the obtained results, in order to validate our contributions and answer the following research questions: (i) Are Relevance-Based Language Models effective as a framework for mod-elling the recommendation problem? (ii) Is it possible to achieve a better neighbourhood selection by applying probabilistic clustering techniques? And (iii) is it possible to achieve further improvements by the combination of both approaches?. 5.3.1. Experiment 1: Relevance-Based Language Models
In this experiment, we assess the validity of our relevance modelling of the recommendation problem. In order to do so, item recommendations are generated using Eqs. (4) and (6) , and the neighbourhoods are constructed with traditional near-est neighbours approach. Then, we compare the results obtained with these methods against the baselines presented in Sec-tion 5.2 . The results of the experiments are presented on Table 2 , denoting RM1 the results of the RM1 estimation based on the i.i.d. sampling assumption (Eq. (4) ) and RM2 the results of the RM2 estimation based on the conditional sampling assumption (Eq. (6) ). Furthermore, we present in Figs. 2 and 3 an analysis on the parameter stability of k (the amount of smoothing in Jelinek X  X ercer) in the Movielens 100K collection. In all cases, we use the parameter estimation approach de-scribed in Section 3.2.3 .

The results reported in Table 2 , validate our proposal for the relevance modelling of the recommendation process, show-ing considerable improvement. Both methods achieve a statistically significant advantage against every baseline. The perfor-mance enhancement is considerable over every baseline method (between 120% and 200% of improvement in terms of P@5, depending on the dataset). This clearly indicates that the estimates obtained through our relevance modelling of the recom-mendation problem are more suitable to obtain good effectiveness values. Profile-expansion style recommendation proves to be a better strategy than pure item ranking based recommendation. The poor behaviour of the UIR-User method was ex-pected because these methods does not exploit rating information but only co-rating. Meanwhile, the User-basedRM, which achieved good results in terms of Mean Absolute Error (MAE) in the original paper, does not perform well in precision oriented tasks. It only achieves comparable results with the other baselines for the P @50 metric. The large difference with respect to this method can thus be partly explained by the fact that in the original paper the method is optimised for a dif-ferent metric from the ones we use here, which are ranking-oriented rather than error-based, as corresponds to a retrieval task.

Overall, this experiment confirms that our proposal of combining neighbourhood information and relevance estimations under the same method is very beneficial to the recommendation task. Furthermore, when analysing the behaviour in terms of the parameter stability in the training collection, it can be observed that both methods are very robust over the parameter values. Meanwhile the optimal k for the RM1 method is achieved when the amount of applied smoothing is the maximum (in other words, when the background model is used, which just results in a pure popularity-based recommender). This last point is mainly explained by the poor quality of the neighbourhoods created by the nearest neighbour algorithm. This obser-vation is confirmed by the fact that with better neighbour selection algorithms, the best value for k is no longer the maxi-mum, as we will show in Experiment 3. In the case of the RM2 method, the optimal value is achieved for k = 0.1 which indicates that the estimation benefits both from the background model and the users X  models. In this case, the performance of the method based on the conditional sampling assumption is less sensitive than that of the RM1 method.
In this experiment, we used traditional neighbourhood selection techniques for user-based collaborative filtering, that is, based on Pearson X  X  correlation and nearest neighbours. In the next experiment, we assess if more elaborated approaches for such task based on probabilistic clustering can improve the performance of the recommendation process. 5.3.2. Experiment 2: Probabilistic clustering for neighbourhood selection The objective of this experiment is to evaluate the suitability of the PPC algorithm for the neighbourhood selection task.
We followed the experimental set-up described in Section 4.2 and the rating prediction was performed using Eq. (15) . The results of applying this method for the neighbourhood selection task instead of using a standard nearest neighbour selection (e.g., computing Pearson X  X  correlation) are presented in Table 2 denoted as PPC. The most important finding is that the neigh-bourhood selection based on applying probabilistic forms of clustering greatly enhances the performance of the recommen-dation. Particularly, this method beats every baseline in the training collection, achieving statistically significant improvements.

It is important to highlight, regarding the test collection, that our PPC method outperforms the UB approach for nDCG@10 and every baseline for P@50. We believe the different performance improvements observed for the two collections may be less, are very promising, and underline the fact that improvements of up to 30% for P@50 are possible by tuning on a separate  X  but not very different  X  collection and not using the optimal parameters.
 As explained before, only one parameter value has to be determined in this experiment, namely the number of clusters j .
In order to study the behaviour of this method when varying the number of clusters, we report the results over the training collection in Fig. 4 . Interestingly, when increasing the number of clusters the recommendation effectiveness tends to im-prove but at the expense of coverage. This is explained by the fact that when increasing the number of clusters and, at the same time, working with hard-clustering methods, clusters with very few users tend to appear. For very small clusters, it is not possible to produce a good recommendation for the users belonging to them. It can be observed that a value of j = 150 (which corresponds to the values reported for the training collection in Table 2 ) provides a good trade-off between coverage and effectiveness in this experiment. 5.3.3. Experiment 3: Probabilistic clustering and Relevance-Based Language Models
Once determined that both approaches, separately, are able to greatly improve the effectiveness of the baselines, we take into consideration the combination of both. In this combination, the neighbourhood selection phase is addressed by applying the PPC method, while the recommendation output is obtained by applying Eq. (4) (PPC + RM1) or Eq. (6) (PPC + RM2). In this case, we have to train two parameters, namely, the number of clusters for PPC ( j ) and the value of the Jelinek X  X ercer smoothing parameter ( k ). As in previous experiments, we trained and validated those values in the Movielens 100K collection and tested them in the Movielens 1M dataset. The results for both collections are summarised in Table 2 . The effectiveness of both methods clearly outperforms the four baselines, where these improvements are statistically significant.
Moreover, these combinations also outperform the isolated application of the two approaches  X  relevance modelling (RM1 and RM2) and probabilistic neighbour selection (PPC)  X  outperforming the results obtained for Experiments 1 and 2 in every analysed metric. Note that, in this situation, the variation in performance when using the different RM estimations one. Furthermore, the best value is obtained by the method PPC + RM2, which is slightly better than PPC + RM1, just the opposite to what was found in Experiment 1, for both datasets. Finally, the optimal neighbourhood size found in training was the same for both methods ( j = 50), and the performance decreases when more clusters are considered (see Figs. 5 and 6 for a sensitivity analysis in the training collection). Interestingly, in this experiment the best result is obtained without affecting the coverage, an interesting effect since although a user would be isolated in a singleton neighbourhood by means of the PPC, with the RM modelling it will still benefit from the background knowledge of the collection in the recommen-dation process.

As an additional checking, we show in Table 3 how these methods are sensitive to the value of the k parameter in the training collection. It can be observed that we can obtain effectiveness values close to the ones of the best performing k in a wide range of the parameter space for both methods, stressing the robustness of these approaches. 5.3.4. Discussion
When globally analysing the results of the three experiments, we can conclude that (i) the proposed relevance-based lan-guage modelling of the recommendation process performs better than other similar approaches which also capture the rel-evance notion for this problem, (ii) the probabilistic clustering for neighbourhood selection clearly outperforms traditional neighbourhood selection techniques based on Pearson X  X  correlation on nearest neighbours or matrix factorisation tech-niques, and (iii) the combination of both approaches enhances even further the recommendation results.

Our relevance model estimations for the recommendation problem have the capability of, depending on the amount of smoothing applied, producing a range of different recommendation strategies, from a pure popularity-based recommenda-tion to a (standard) neighbour-based recommender algorithm. As a result of this, in the first experiment, we obtained that the best performance of the RM1 method was produced by a popularity-based recommendation, once its optimal configu-ration of the parameters is analysed. We believe this fact indicates that the quality of the standard neighbourhood tech-niques is not good enough, and more emphasis on the collection statistics (popularity) should be taken into account. For that reason, we decided to test alternative neighbour selection techniques such as PPC.

From the results of the Experiment 2, we can conclude that PPC obtains better neighbourhoods than standard techniques, in terms of the resulting recommendation performance. In fact, if we compare the results obtained by the classic UB against our method, the precision may be multiplied up to a factor of 5x in the best situation (training collection), whereas a decent improvement of 30% for P@50 has been obtained for the test collection. This improvement is achieved at the expense of low-bled. Moreover, for the reported values the coverage is quite high, as we may observe in Table 2 .
Finally, analysing the results of Experiment 3, we may observe that now the method based on RM1 is not producing solely popularity-driven recommendations for its optimal parameters, but instead a combination of the background model and the neighbourhood information. This is additional evidence supporting the quality of the neighbourhoods obtained by the PPC method. As another consequence, we see in this experiment an important improvement in terms of effectiveness with re-spect to the results obtained in Experiments 1 and 2.

In summary, the combination of Relevance Modelling and PPC approaches leads to more robust techniques (since the sen-sitivity of k has decreased and coverage is now independent from the number j of clusters), more computationally efficient algorithms (because lower values for j are required), and better performing techniques in terms of precision and nDCG.
Moreover, since the optimal parameters found in the training collection have proved to be effective in the test collection, we may conclude that our methods are also flexible and general enough to be trained and tested in two collections with dif-ferent properties while showing good performance in both situations. 6. Conclusions and future work
In this paper, we have proposed a relevance modelling approach for the recommendation problem. Our proposal ad-dresses the item recommendation task as a profile expansion problem, using the mechanisms for query expansion provided by the Relevance-Based Language Models. The adaptation of this IR model to the recommendation task is non-trivial, given the different nature  X  and even the number  X  of the input data spaces the systems handle in each case. We devise an adap-tation where the recommendation variables (items and users) play different roles at different points in the model, thus resulting in a recommendation RM where the elements have a quite different meaning than intended in the original formu-we still inherit the practical and theoretical advantages of language models in IR, such as the avoidance of an explicit rele-vance variable, which makes the resulting probabilistic framework easier to develop and bring to computable statistical esti-mations (e.g. no need for explicit relevance judgements in the recommendation model), while retaining a clear formal underpinning.

The empirical evaluation of our proposal shows significant improvements in terms of effectiveness (measured by ranking quality metrics) against different related baselines. Furthermore, in order to obtain better neighbours for the memory-based recommendation, we proposed the application of the Posterior Probabilistic Clustering algorithm. This proposal by itself also achieves effectiveness improvements over traditional neighbour-based approaches, while at the same time it outperforms standard matrix factorisation algorithms and other probabilistic-based approaches. Furthermore, we show that the combi-nation of both proposals improves the results of their individual application, demonstrating in this way that the better the neighbourhood (which acts as the pseudo relevance set in the explicit search scenario), the better the estimations of the underlying relevance model, and therefore, better item recommendations are produced as expansions of the user profile. This fact is consistent with previous results obtained in the application of RM on text retrieval.

Several potential directions open up from this point to improve the recommendation effectiveness further. We plan to further study other options for the construction of the pseudo relevance set of users, not only techniques based on neigh-native estimations and smoothing approaches to be applied in our formulation of the problem. We envision additional refinements of our methods, such as only considering positively rated items in the user profile when computing the user the use of our approach as a basis to address the problem of recommendation diversification. We envision the diversification of the recommended items in the expanded profile, as an equivalent problem to promoting divergent terms in the estimation recommendation modelling corresponding to our user-based proposal. This technique is known to perform better than the user-based in some situations, and thus, the relevance model approach might find performance improvements also in those scenarios.
 Acknowledgements This work was funded by Secretar X a de Estado de Investigaci X n, Desarrollo e Innovaci X n from the Spanish Government under Projects TIN2012-33867 and TIN2011-28538-C02.
 References
