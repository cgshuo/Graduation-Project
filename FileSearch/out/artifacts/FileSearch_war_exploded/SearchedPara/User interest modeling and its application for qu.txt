 1. Introduction
With the development of Web 2.0 technologies, various applications have been emerging to help users exchange views, opinions and knowledge. Among these Web 2.0 platforms, the User-Interactive Question Answering (UIQA) system, also known as the Community-based Question Answering (CQA) system such as Yahoo! Answers ( Adamic, Zhang, Bakshy, &amp; information. In UIQA systems, users can obtain the information they need simply by asking a question and waiting for answers offered by other users. The data volume of the question X  X nswer (QA) pairs in UIQA systems has been growing exponentially. For instance, there were approximately 23 million questions in Yahoo! Answers in 2008 ( Adamic et al., 2008 ). The accumulated QA pairs can be viewed as a large knowledge base which stores the wisdom of crowds.
In this paper, we propose a new service in UIQA, question recommendation, which automatically recommends new askers may not be satisfied with the limited answers they obtained. By recommending new questions, they may track the encounter new questions similar to what they previously asked. Hence, we believe the recommendation is useful. Another when they encounter questions related to the knowledge.  X 
Forthepurposeofquestionrecommendation,itisnecessarytocapturethedifferentinterestsofusers.Inthefollowingpara-may not always have high term co-occurrence. For example, a computer game fan may ask several questions concerned with basedUserInterest(TUI)model,byintroducingalatenttopiclayertonarrowdownthesemanticgapbetweenterms.Thelatent est model, we rank all the questions in the UIQA system for each user and recommend the top ranked ones to the user. questions to those expert users. Whereas a good question recommendation system should provide each user with questions he might be interested. Hence, answerer recommendation approaches cannot be applied to solve the problem of question recommendation directly.

The rest of the paper is organized as follows: Section 2 introduces some prior research related to our work. Section 3 are shown in Section 6 . Finally, we conclude our work and look forward to future work in Section 7 . 2. Related work ysis, learning user interest for search engines and related work in the UIQA system. 2.1. Latent topic analysis ever, VSM leads to the problems of high dimension document representation and lack of semantic relationship between bilistic Latent Semantic Indexing (pLSI) model to leverage semantic between words in documents. Compared with LSI, the come the overfitting problem, namely the Latent Dirichlet Allocation (LDA) model. 2.2. User interest model for personalized search different user interest by a set of Open Dictionary Project (ODP) about the user such as documents and emails the user has read and created. 2.3. Related work in the UIQA system question retrieval, which can be seamlessly integrate into the existing retrieval models.
Cao, Duan, Lin, Yu, and Hon (2008) first propose the novel application of question recommendation. In their work, they recommending questions by two steps: (1) representing questions as trees of topic terms; (2) ranking of recommendation on modeling the user X  X  different interest in question recommendation.

In the UIQA systems, the number of questions posted every day can reach up to thousands. Such a huge number of data solved question to shorten the waiting time of the askers ( Guo et al., 2008; Qu et al., 2009 ). each user to improve recommendation performance. They present a tractable Bayesian network model, namely User-Ques-Semantic Analysis (PLSA) ( Hofmann, 1999 ) model to capture the underlying topics and represent the user interests. However, the UIQA system is a community based system, where users interact with each other by asking and answering. users) to extract user interest. 3. General framework Fig. 1 .
 cations, such as question recommendation and search.

When applying TUI model to question recommendation, we rank the questions in the UIQA system for each user, accord-to say, if q i ranks higher than q j for a given user u , the user u is more likely to ask q tions in detail. 4. Topic-based user interest model for the UIQA system tem. At last, we illustrate the parameter estimation algorithm for the TUI model. 4.1. Notation notation z to describe a topic, and z ui , w ui , c ui and a h ! is used to describe the multinomial distribution of the document d over topics. h tribution of the question profile of the user u over topics. / and understanding. 4.2. Generative models for the UIQA system
We discuss the following two generative models: the LDA model and the TUI model. 4.2.1. The LDA model
The graphic model representation of the LDA model is shown in Fig. 3 , where d and D represent a document and the cor-stochastic process in steps 5 and 7. 4.2.2. The topic-based user interest model
We describe a typical scenario when a user asks a question on the UIQA system as follows: (1) Consciously or uncon-
In the TUI model, the generation process of the historical question set Q are h u ! for each user u , and / z ! , w z ! and x z ! for each topic z . Intuitively, the parameter of h distribution of the user u over each latent topic. In our method, h probability the user u asks a question. The parameter / z he gives a best answer to the question topic z .

Compared with the LDA model, the TUI model has the following two characteristics. On one hand, the LDA model takes a ers, which is a special feature in the UIQA systems and should be helpful to enhance the precision of question recommendation.
 their work concentrates on recommending suitable answerers for certain questions, while this work aims to recommend to racy of question recommendation can be improved by importing the answerer factor. 4.3. Parameter estimation in the TUI model
In the TUI model, there are eight groups of parameters: the Dirichlet prior a Bian, Zheng, Zha, &amp; Giles, 2008 ).
 For each a k in a ! , k 2 X  1 ; N T , a k  X  a  X  50 = N T .
 For each b k in b ! , k 2 X  1 ; N W , b k  X  b  X  0 : 05.
 For each c k in c ! , k 2 X  1 ; N C , c k  X  c  X  0 : 05.
 For each r k in r ! , k 2 X  1 ; N U , r k  X  r  X  0 : 05.

Hence, we only estimate four sets of parameters, namely the user-topic distribution sets h bution of the hidden variables given a user X  X  information probability p  X  z ui j w ui ; c ui ; a ui ; w ui ; z ui ; c topic, category and answerer assignments to other tokens. In addition, w can be computed as 2 where l uz denotes the number of tokens in user u  X  X  questions are assigned to topic z . n w is assigned to topic z . m zc denotes the number of tokens in topic z belonging to the category c . k following formulas: 5. Questions ranking are illustrated as follow.
 5.1. Ranked by the BOW model
According to BOW model, the probability p ( q | u ) is calculated as as the inverse value of the length of q , and therefore (7) can be computed as respectively. 5.2. Ranked by the LDA model user u . In LDA model, the probability is computed by summing up on the condition of topics as tion of user u , l uz . Hence, the probability that the user u asks the question q is computed as 5.3. Ranked by the TUI model
Unlike the BOW and LDA model, we consider both the text feature such as question title and question detail, and other the condition of user u as
In addition, we assume the question, category and answerer in a question session is independent under the condition of asker. (11) can then be computed as we ignore the correlations among q , c and a and make the assumption of mutual independence between them. Our exper-iment results show that such approximation can also effectively help select appropriate questions. 5.4. Ranked by the BOW + Category + Answerer as category c and answered by a , respectively, in the historical questions of user u . n by u , respectively. 6. Experiments
We evaluate the performance of our user interest model on the application of question recommendation. In this paper, consider the recommendation to be correct; otherwise, we consider the recommendation to be wrong. 6.1. Datasets
We use the dataset collected from Yahoo! Answers to evaluate the performance of the proposed method. This dataset has been used by Liu, Bian, and Agichtein (2008) and is now available online. subset is presented in Table 5 .
 USER-15 : Each user in USER-15 has asked no less than 15 and less than 20 questions. USER-20 : Each user in USER-20 should have asked no less than 20 and less than 25 questions. USER-25 : Each user in USER-25 should have asked no less than 25 and less than 30 questions.
USER-30 : Each user in USER-30 should have asked no less than 30 questions. 6.2. Evaluation criteria experiment results.
 sion of a set of users. The average precision (AP) of a user u is computed as where N is the number of questions in the UIQA system, pos asked by the user u and p u ( j ) is the precision of top j ( j &gt; 0) results calculated by P @ N is defined as where U denotes all the users and N U is the number of users. 6.3. Stop condition and topic number selection
We discuss the stop condition of the training algorithm shown in Table 4 and illustrate the selection of the number of topics in LDA and TUI model.

To obtain the optimal setting of topic number, we tune the number of topics in both LDA and TUI model and stop the the TTrain subset and the rest as TEvaluation subset.

We train the LDA and TUI model using the TTrain subset with different sets of topic number and evaluate the recommen-and 6 .
 occurrences of words in the TUI model are richer than that in the LDA model.
 lect 350 as the topic number for both TUI model and LDA model for the rest of the paper. the topic number of LDA model and TUI model as 350 and increase the iteration number from 0 to 1000. The MAP value changes of LDA model and TUI model are shown in Figs. 7 and 8 respectively.
 number as 1000 for the rest of the paper, which is enough for training the TUI model. 6.4. Performance of different ranking methods question recommendation of the BOW model, LDA model, BOW + Category + Answerer (BCA) and TUI model are exhibited. the algorithms.

In Table 7 , firstly, the TUI model outperforms the other three methods in both Micro and Macro averaged MAP criteria, can outperform other models on the MAP criterion but may fail to perform best on other criteria occasionally. 6.5. Discussion on the usage of different data sources details), the category and the answerers. However, some people may wonder whether we need so many data. We evaluate p  X  z Content: We only take the asker information into consideration, and compute the two probabilities as
Content &amp; Category: We consider the information of asker as well as category, and compute the two probabilities as
Content &amp; Answerer: We consider the information of asker as well as answerer, and compute the two probabilities as abilities as (2) and (12) .
 the model considering only question content, whereas the TUI model is generally better than BOW and BCA. The askers in 7. Conclusion and future work In this paper, we propose a service called question recommendation to recommend questions to users. A Topic-based User to tackle the semantic relation between questions in the UIQA system.

We evaluate the proposed user interest model on the dataset collected from Yahoo! Answers. We first compare the TUI model with the BOW model and the LDA model. The experimental results show that the performance based on the TUI mod-el outperforms that based on the BOW model and the LDA model. We then evaluate the contribution of each data source in tents, question categories and answerers) are all involved.

Apart from the question recommendation service, the TUI model can be used in other applications, such as question ests of this kind of users from their sparse user profiles in future.
 Acknowledgments The author would like to thank the anonymous reviewers for their constructive comments. We also would like to thank
Eugene Agichtein and his group at Emory University for opening Yahoo! Answer dataset from their website. The work de-Science Foundation of China (under Grant Nos. 91024012, 60863001, 61073038, and 61073189). Appendix A tinomial distribution, we can simply integrate out the parameters h , / , w and x . The derivation is as follows:
The probability for topic z ui conditioned on all other word and topic assignment in user profile as follows:
And since C  X  x  X  1  X  X  x C  X  x  X  , it follows that References
