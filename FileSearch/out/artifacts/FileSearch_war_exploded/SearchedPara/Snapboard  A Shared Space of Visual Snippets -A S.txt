 Teerapong Leelanupab ( Although technology behind search engines such as Google, Yahoo! Search has advanced over the years, the designs of their web search interfaces have still largely remained for solitary information seeking; they are typically created for one person to use independently. Relatively, little support is available for a group of people, who share the same information need, to collaborate on search tasks. Examples of such tasks include planning a holiday with family members, organiz-ing a social event with friends, or working on an annual report with colleagues. Additionally, some search tasks are too complex or difficult to be completed by a sole person, such as finding possible areas where the MH370 crashed or listing past and ongoing missions of New Horizons space probe to Pluto. These tasks require input and expertise from others. In fact, information seeking is considered collaborative [ 16 ]; multiple users can carry out search by working together. Golovchinsky et al. [ 7 ] defined four dimensions of the collaboration model, i.e., intent (explicit vs. implicit), depth of mediation (from user-interface We created a web-based application, CoZpace, for collaborative web search-The type of collaboration, supported by CoZpace, is explicit in that the and allowed to communicate with other group members via integrated messag-ing. Similar to SearchTogether, CollabSearch [ 20 ] supports both implicit and explicit communication. It has an additional workspace where group members can share the saved whole web pages and textual snippets generated by Google API. CoSearch [ 1 ] leverages additional available devices such as extra mice and mobile phones for co-located collaborative web search. It assists users in control and division of labor while jointly searching the web by a single computer. It is designed to support co-located collaborative web search, browsing, and sense-making among a group of up to four people. Perez et al. [ 15 ]presenta CoFox system, which shows a live video stream of a remote user X  X  search screen to a local user to increase awareness of synchronous search collaboration. In multimedia retrieval domain, a grouping interface for video search, ViGOR [ 8 ], is built to assist asynchronous collaboration between users. The main feature of ViGOR is the provision of a workspace for creating and organizing groups of related videos. Each group can have multiple annotations and be used as a starting point for further search queries. 2.2 Studies of Search Habits Also referred to exploratory search [ 19 ], informational search is identified as a common web search activity that would benefit from collaboration [ 3 ]. In this class of searches 2 [ 5 ], a user aims to seek some information on one or more web pages. To achieve this, informational search potentially involves multiple refinements of query terms and often spans many search sessions, and those are what CoZpace is designed for. Yue et al. [ 20 ] analyzed transitions of user search actions under three different conditions by varying two search factors (i.e., collaborative vs. individual and with vs. without explicit communication.) 2.3 Summarization of Web Pages Presenting search results as a summarization of each web page is considered useful for information search, where users can quickly judge which ones of these results are of their interest [ 18 ]. For re-finding information, users can also use this similar summarization to access previously visited web pages, usually saved in the bookmarks of a web browser [ 6 ]. For simplicity and compactness, the summa-rization of web pages is typically represented as a textual snippet, consisting of its page title, URL and short text summary of web contents. Nevertheless, read-ing textual summarization is often time-consuming and difficult to comprehend its information if the textual snippet is very short.
 simply because images convey information that words cannot capture. As such, (i) relevance awareness, presenting three categories of judged web search results as indicated by any users in a group, i.e., relevant, non-relevant, and not sure 3 , (ii) Task Snapboard collecting all group-captured visual snippets, (iii) query awareness, showing a history of all used queries, and (iv) view list, displaying all web search results clicked to view by any users, respectively; queries and remind for the queries 4 that have already been used in the task; 3. The relevant buttons for marking search results considered relevant (thumbs-4. Per-document Snapboard showing multiple visual snippets captured from a 5. The comment bar for a user to leave comments about a website; 6. The project timeline showing real time stream of activities; and 7. The instant messaging for real-time discussion among the collaborators. actions of group members are recorded and instantly shown according to their types of summarization. Furthermore, any search results that had been clicked to view by any users in a group will be highlighted in yellow. Our aim of provid-ing the summarizations of different aspects is to facilitate awareness of a shared search task being pursued by other group members, so that unnecessary redun-dancy of effort can be avoided. For further details about the complete design and features of our CoZpace, we refer interested readers to [ 11 ]. 3.2 Snapboard Our Snapboard feature applies visual snippet which is an attractive represen-tation and summarization of a web page, used in Human-Computer Interaction (HCI) to share a relevant part of a web page. However, our visual snippet is different from visual snippets in HCI that are a part of a web page captured by system which might not be relevant to user X  X  information need. Our visual snippet allows a user, in a self-managed manner, to capture a part of focused or salient information in a web page by herself. Moreover, as Aula et al. [ 2 ] indi-cated that a thumbnail which shows the whole web page in a small picture can make users underestimate the relevance of the page and only textual summaries can make users overestimate, it makes us concern that using only a picture in visual snippet might face with the same problem as using thumbnail. Therefore, we allow to include both textual and visual information in our visual snippet. as a visual snippet (1) and its visual snippet (2) generated from a template given a salient snapshot and other metadata of its source/web page, i.e., title, common textual snippet from a search engine 5 , and URL of the page. Hovering a mouse over the upper part of the visual snippet (2A) will show a preview of its corresponding snapshot while clicking the lower part (2B) will open the link to the source of the visual snippet in a new web browsing tab within CoZpace. shares them among all members in the same group. There are two types of Snapboard, i.e., for the whole task and per-document. Task Snapboard demon-strates all visual snippets in a single tab (See Fig. 3 ). Per-document Snapboard displays all visual snippets created from an individual web page (See Fig. 1 (4)), implemented as part of search results where a user can expand or hide it. CoZpace by showing only web pages in English. The two systems are: (i) CoZpace with a Snapboard function (S1) as an experimental condition; and (ii) CoZpace without the Snapboard (S2) as a control condition. 4.2 Search Tasks All exploratory search tasks used in this study are selected from the top four search tasks on which people tend to cooperate as surveyed by Morris [ 12 ]. (T1) Travel Planning: All participants have to imagine that they are planning a trip to the Kansas City, USA. They want to search for information about how they will spend their vacation in USA. Their goal is to find where they will stay, what they will do, and how will they get there, etc. (T2) General Shopping: All participants have to imagine that they are given USD 30,000 to buy a car. Their goal is to find the technical specifications of cars, brands of cars, and stores which sell cars, etc. (T3) Literature Search: All participants have to imagine that they are assigned to write an article about the US civil war. Their task is to find causes of the civil war, economic causes, consequences of the civil war, civil war effects in the present, and weapons used during civil war, etc. (T4) Technical Information: All participants have to imagine that they want to reduce the use of air conditioner in their house. Their task is to find the best material to use if the purpose is cooling down the roof so that the house temperature remains low, and other solutions regarding roof coating, etc. 4.3 Participants All participants were 32 volunteers (12 males and 20 females); 12 participants were high school students in an English program from Nakhonnayok Wittayakom school, 10 participants were undergraduate students and the rest were graduate students from the Faculty of Information Technology, King Mongkut X  X  Institute of Technology Ladkrabang (KMITL). All of them are highly proficient in English and web searching. According to the entry questionnaire, they often search more than twice a day. Most of them used to collaborate with other people in web searching by using social networks. Besides, they searched together in a group of three people, on average. However, they have never used a search system that is specifically designed for collaborative search before. All participants are then paired into 16 groups that will asynchronously collaborate on given search tasks. In each pair, we call  X  X 1 X  a participant who firstly performs search tasks with fresh sessions that do not contain any summarizations and search histories, and call  X  X 2 X  the other participant who pursues search tasks formerly done by P1. Review session is a session that participants review the results from a previ-In total, our experiment lasted around three hours. The experiment started (i) open-ended questionnaires, and (ii) focused group discussions. We collect all logs from participants X  interactions and answers from close-ended questionnaires, and then analyze them to be quantitative data, such as, the number of submitted queries, the number of viewed web pages, the number of websites that are marked as relevant, the number of comments, the number of snapshots and the rating scores of user feedback in different aspects. 5.1 The Effectiveness of Snapshot in Individual and Asynchronous Table 1 presents a comparison of the performance between two systems in CoZ-pace, i.e., S1 and S2, operated in individual search (IN) and asynchronous col-laborative search (AC) conditions (Cond). The results show that the average number of visual snippets (Vsnip) made in S1 is obviously higher than that of comments (Comt) in S2 in both IN and AC. It can be interpreted that the par-ticipants prefer taking the snapshots as visual snippets rather than commenting to summarize the web pages. The average number of queries used in S1 is higher than that in S2 in both IN and AC. However, it is not necessary to be inferred that participants make more effort to formulate queries in S1 than in S2. The reason behind this outcome is that the feedback from our participants in Table 2 shows that all tasks are easy to formulate query.
 number of web pages marked as relevant (All Rel). In AC, the Rel Web are counted from only the web pages that are marked by both participants P1 and P2 in the same team to be more sure about the relevance of the websites. In addition, the difference between the average number of relevant unique web pages (Uniq Rel) and the All Rel, which is really high in IN and higher in AC. This result shows that many relevant web pages are marked by more than one participants in IN or more than one groups of participants in AC. As a result, we can be more confident that marking the relevant web pages by participants does not happen by chance.
 by participants (Uniq View) are unique relevant web pages (Uniq Rel). The  X % Uniq Rel per Uniq View X  in S1 is higher than that in S2 in both IN and AC, indicating that S1 is more effective than S2 in the support of users to find relevant web pages from the returned and clicked web pages. From the above results, we can answer RQ2 and RQ3 that the Snapboard support users in both individual and asynchronous collaborative search.
 in individual search between two systems (i.e., S1 and S2) and among activities (i.e., Vsnip vs. Comt, Query, All Rel, and All View), at p&lt; 0 . 1. The results showed better performance for S1 than that for S2 on average in Vsnip vs. Comt, All Rel, Query, and All View with statistical significance at p =0 . 035  X  , but not statistical significance at p =0 . 634, p =0 . 188, and p =0 . 966, respectively. A one-way ANOVA was also conducted to determine the statistical significant =0 . 395 and p =0 . 337, respectively.
 when using CoZpace with or without Snapboard. We analyzed the statistical significant differences (using a two-way ANOVA) between two systems (i.e., S1 and S2) and among search tasks (i.e., T1, T2, T3, and T4), at p&lt; 0 . 1. The analysis shows better feedbacks for S1 than that for S2 on average in Q1, Q2, Q3, p =0 . 0934  X  ,and p =0 . 0053  X  , respectively.
 can be considered. The main effect of system shows that the user X  X  satisfaction on average in Q1, Q2, Q3, Q4, and Q5 are better for S1 than for S2 in T1, T2, and T4. There is no main effect of task among T1, T2, and T4 but there is a little bit effect from T3. We also tried to determine the statistical significant differences (using a two-way ANOVA) between two systems (i.e., S1 and S2) and among questionnaires (i.e., Q1, Q2, Q3, Q4, and Q5), at p&lt; 0 . 1. The results show better feedbacks for S1 than that for S2 on average in T1, T2, T3 and T4 with statistical significance at p =0 . 0042  X  , p =0 . 0015  X  , p =0 . 0634  X  , and not statistical significance at p =0 . 1315, respectively. As the tasks T1 and T2 basically require users to find information better presented in a visual form (i.e., pictures better convey the content toward collaborators than text), the results seem to be pertinent to our scenario of using Snapboard feature that it is appropriate for any task that needs to share pictures, such as sharing attractions for travel planning.
 to finding text results might not take benefits from the Snapboard feature. As the difference in T4 is extremely not significant, the better feedbacks for S1 should not be claimed. However, it might be interpreted that the better feedbacks are not significant because T4 is a task that might not need to share pictures. The average feedbacks from Q1 in Table 2 can infer that all the four search tasks are quite difficult when using S2 but become easier when using S1 in T1, T2 and T4. This inference answers our RQ1 that Snapboard feature supports exploratory search tasks.
 were asked to rate their satisfaction to the interface of CoZpace as well as its three main features, i.e., retrieval, comment and snapshot functions. The satisfaction of Snapshot function on average is 4.41 with a low standard deviation showing a very high level of agreement. On the other hand, the comment feature got the lowest average score, 3.34. For the CoZpace interface, the results are very positive with a mean value of 4.03.
 pants. They provided open comments with respect to the feature of Snapboard. Some examples include:  X  X isual snippet helps me to easily share needed infor-mation with collaborators X  and  X  X napboard increases the awareness of how our tasks progress, and I can use it to identify relevant information in web pages or revisit them later X . Most of the participants agree that those benefits can help them to collaboratively complete the search tasks easier. For future work, we plan to conduct a user study to evaluate the effectiveness
