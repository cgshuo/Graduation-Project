 Politecnico di Milano Piazzale Leonardo 32 Milano (MI), 20133, We consider the problem of finding officially unrecognized side effects of drugs. By submitting queries to the Web involving a given drug name, it is possible to retrieve pages concerning the drug. However, many retrieved pages are irrelevant and some relevant pages are not retrieved. More relevant pages can be obtained by adding the active ingredient of the drug to the query. In order to eliminate irrelevant pages, we propose a machine learning process to filter out the undesirable pages. The process is shown experimentally to be very effective. Since obtaining training data for the machine learning process can be time consuming and expensive, we provide an automatic method to generate the training data. The method is also shown to be very accurate. The side effects of three drugs which are not recognized by FDA are validated by an expert. We believe that the same approach can be applied to many real life problems and will yield high precision. Thus, this could lead a new way to perform retrieval with high accuracy. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  selection process; I.2.6 [ Artificial Intelligence ]: Learning  X  Connectionism and neural nets. Algorithms, Measurement, Experimentation. Mining side effects of drugs , machine learning, accurate retrieval, precision. All medications have both benefits and risks. In the United States, drug companies conduct time-consuming and expensive clinical trials of new drugs before they are marketed to the public. The re sults of these studies are reviewed by the U.S. Food and Drug Administration (FDA). A drug is allowed to enter the market only if the FDA determines that its benefits outweigh its risks. Unfortunately, clinical trials, no matter how carefully they are conducted, cannot identify all potential problems [AH03]. Some events are simply too rare to be detected in trials that include, at most, a few thousand patients. Other risks become apparent only when certain kinds of patients take the drugs (e.g., children, pregnant women, people with multiple chronic problems, people taking other medications). These special cat egories of patients are often excluded from clinical trials, so their first exposure to the drug comes after it has been approved and marketed [LAWH02]. The FDA and the drug industry are well aware that pre-approval clinical trials routinely fail to detect significant safety problems and adverse drug effects [AH03]. A recent well-known example is Vioxx, which causes heart problems for certain patients, and the drug has to be withdrawn from the market [Couz04]. In fact, 13 drugs were withdrawn from the market by the US FDA between 1997 and 2001 [http://www.fda.gov/fdac/ features/2002/chrtWithdrawals.html]. The main purpose of this work is to develop a Web-mining system that can find online ev idence of side effects in approved drugs that are not yet officially acknowledged by the FDA or the drug manufacturers. In this paper, we introduce techniques which can find the officially unrecognized side effects of drugs. We argue in the conclusion that the techniques introduced here can be applied to various other problems requiring high precision retrieval. The main contributions of this paper are (a) We provide techniques for mining side effects of drugs, and our experimental results demonstrate that the techniques are extremely effec tive. This is a real life problem which has an impact to millions of people. (b) Since the mining process involves training data which can be time consuming and expensive to obtain, we provide an automatic process to obtain the desired training data and show that this process is highly effective. (c) We believe the same techniques, possibly with minor modifications, can be applied to various real life problems. This could lead to a new paradigm for high effective retrieval. The paper is organized as follows. In Section 2, the problem of mining side effects from the Web is defined. In Section 3, we describe the components of our system to solve the problem. In Section 4, experimental results are shown to demonstrate that our approach is very promising. The side effects of three drugs which are not recognized by FDA are validated by an expert. The conclusion is given in Section 5. Some research works on mining unrecognized side-effects of drugs have been reported[ HBL98, PBLLOE02]. There are some differences between our work and the earlier works. (1) The data used in [HBL98, PBLLOE02] are hospital data and are structured data, while we mine from unstructured text data. Clearly, the techniques employed are very different. (2) While patient data may be more reliable than unstructured Web data (note that PubMed which contains huge amount of bio-medical literature is accessible from the Web), the amount of Web data on side-effects of drugs is likely to be significantly more. Both types of data should be complementary for this type of research. It should be noted that government regulations (HIPAA) may prevent researchers from using hospital patient data for research (This applies to many hospitals including UIC.) There are some well-known web sites, such as www.yellowcard.gov.uk and www.drugs.com, which provide possible side-effects of drugs. The former site collects information of suspect side effects for quite a few drugs, which is based on case reports submitted by registered health professionals and patients . The latter site is one of the mining resources in our system, while we will try to incorporate the former site into our system. The solution we propose for the drug side effect mining problem involves learning from training data. This bears similarities to quite a few traditional information retrieval problems such as classification [LSCP96, YL99, NMTM99], routing [Harm95, Harm96] and relevance feedback [SALT89, BYRN99, van79]. However, there are significant differences. Classi fication is a process where there are a number of classes, each containing a set of example documents and each new document is to be classified into one of these given classes (or a new class). Routing may be considered as a type of classification where each class is defined by a query (or a set of queries) and each new document is routed to a class. This involves sending new documents to appropriate queries, which are given while our task is to retrieve documents for new queries. Relevance feedback can be roughly classified into two types. The first type consists of manually identifying some relevant and irrelevant documents and then modifying the query (possibly using machine learning algorithms) to retrieve more relevant documents for the same query. Our approach differs from it in two aspects. First, it is possible for our method to produce positive and negative examples automatically so as to avoid the manual identification process. Second, our method applies captured relationships among terms to new queries, not to the same query. The second type of feedback, known as pseudo-feedback, assumes the first few retrieved documents as relevant and utilizes them as training data. While the assumed relevant documents in a pseudo-feedback process are chosen in a rather na X ve manner (i.e. always pick the top n documents, for some n), the process of automatic generation of training examples in this paper is more elaborate. Although pseudo-feedback usually yields an improvement in average re trieval effectiveness, a significant deterioration for some queries is generally observed, as usually a substantial number of the first few retrieved documents are irrelevant. Similar to the traditional feedback process, the pseudo-feedback process is applied to the same initially submitted queries, not to different queries. Although training for some queries and then applying their results to other queries has been attempted before [YuMi88], the improvement in retrieval effectiveness for the new queries is relatively small. In contrast, the improvement due to the technique reported here is substantially higher. The problem is to find the side effects of drugs which have been approved by the Food and Drug Administration (FDA). For each such drug, FDA keeps a list of known side effects. Our task is to identify unknown side effects of FDA approved drugs from the Web, where an unknown side effect is one which is not listed on the official FDA pages . One way of finding unknown side effects of a drug is to submit a query of the following form to a search engine such as Google. And then from the retrieved pages find occurrences of symptoms/diseases. The Food and Drug Administration (FDA) keeps a list of side effects for each drug. If a symptom or a disease of the drug found in the retrieved page is outside the set of side effects of the drug as reported by FDA, then it is a potential unknown side effect of the drug. However, the above approach has the following problems: (a) There are quite a few relevant pages which cannot be (b) Many pages returned by the search engine are not (c) As a page can sometimes be very large and too time We now sketch our system which attempts to accomplish the above tasks. It should be noted that determining the relevance of a retrieved page automatically is a difficult task. Because if the relevance of a page could be determined, the search engine would retrieve it if it were relevant, and discard it, otherwise. However, for our problem, there is additional information we can utilize. Specifically, we can semi-automatically determine the relevance of retrieved pages for a set of drugs. First we mine the characteristics of th e words (features) in these pages, which make a page relevant or irrelevant. These characteristics are th en applied to determine the relevance of retrieved pages of other drugs. We now describe the components of the system as shown in Figure 1. A GUI accepts a drug name and a user-specified value n , which is the number of pages to be returned by the search engine. If the search engine retrieves fewer than n pages, then our system will process the retrieved pages, otherwise only the top n pages returned by the search engine will be processed. A query modifier takes the drug name, goes to a FDA site to find the active ingredients of the drug (which are the chemical compounds forming the drug) and then forms the query The query is then submitted to Google. We can also submit the query to other search engines such as Yahoo and PubMed. More and possibly better pages are returned when the active ingredients are added, as some relevant pages do not have the drug name but have its active ingredients only. A Web page which describes the side effects of a drug may not contain the actual phrase  X  X ide effect X  (for example, it may contain the phrase  X  X dverse reaction X ). A query containing the phrase  X  X ide effect X  and the drug name may also retrieve pages unrelated to the drug. For these reasons, we decide to drop the phras e  X  X ide effect X . To reduce response time, the file containing the active ingredients of drugs from FDA is actually loaded into our system so that an access to a local file is sufficient. Currently only HTML pages will be analyzed. Each page is parsed and the text data are extracted. In the future, pages in other formats will be analyzed. A dictionary containing adverse effects such as nausea, vomiting and liver damage is utilized. A small synonym dictionary is also included. This allows us to detect, for example, that side effects and adverse effects have the same meaning. The advantage is that our system can be used for different applica tions. Specifically, if the application is changed, then a different set of domain dictionaries will need to be supplied. For example, if we are interested in finding the advantages of cell phones, the synonym dictionary may contain phrases which have the same or similar meanings as cell phones, while another dictionary may contain various potential advantages such as convenience and portability. Some features which can be used to determine whether a page can be useful are as follows: (a) Presence of diseases/symptoms; (b) Distance between certain keywords such as  X  X ide-(c) Absence of expressions such as  X  X o side-effects X  or Currently, about 250 features are used. It is feasible to use all features and then apply f eature selection techniques (say based on information gain [HaKa00]) to eliminate unnecessary features. Distance features in (b) help to strengthen the casual relationships between drugs and side-effects. Note that if the di stance between  X  X ide effect X  and a disease is small, then the di sease is likely to be caused by the drug, while if the distan ce between  X  X afe X  and a disease is large, then the drug may not cause the disease. The training data is a set of retrieved pages and their relevance/irrelevance for a set of drugs. Each page in the set of training examples is manually determined to be relevant or irrelevant. In th e experiments, 223 pages from 7 drugs: Prozac, Aspirin, Paxil, Celebrex, Beclomethasone, Namenda are used as training examples. Quite a few machine learning methods can be used for this project and our impression is that there will not be drastic differences in accuracy for using one machine learning method versus another. In our experiment, we employ a neural network, Lamstar neural network [GK98]. The neural network can handle imprecise input data and even missing data. It is briefly described as follows. The network consists of several (23 in our experiments) sections in an input layer of neurons (which are self organizing maps) and 1 layer of output neurons. Associated with each input section of neurons is a set of closely related features. For example, one input section of neurons can be associated with the features which represent the phrases  X  X ide effects X ,  X  X dverse effect s X  and  X  X dverse reactions X . Another input section of neurons may be associated with a set of symptoms/diseases. The neurons in a section represent combinations of va lues of the features. For example, in the section for the phrases  X  X ide effects X ,  X  X dverse effects X  and  X  X dverse reactions X , a neuron may represent  X 001 X , indicating the absence of the first two phrases and the presence of the third phrase, while another neuron may represent  X 000 X , indicating the absence of all three phrases. When a page is retrieved, all values of the features will be extracted from the page and used as inputs to the neural network. Consider an input section, L, of neurons and the impact of the inputs (restricted to the features of the neurons in L) on those neurons. Either the inputs are close (as measured by some distance function, for example, input 011 may be considered to be close to the neurons representing 001) to the combinations of feature values as represented by some of the neurons in L or they are far away from those feature values as represented by all neurons in L. In the former cause, the neuron in L whose feature values are closest to the input is fired. In the latter case, a new neuron which represents the inputs (restricted to L) is added to L and is fired. In general, the entire input causes at most one neuron in each input section to fire. (If no input data is missing, then exactly one neuron in each input section is fired.) The output layer consists of two neurons only for this application (although in general there can be more neurons). The i th neuron ( i =1 or 2) in the output layer is connected to the j th neuron in the k th input section as represented by a input section fires, x ( i, j, k ) =1, i varying over the 2 neurons in the output layer; otherwise it is 0. In our application, the have two output neurons. Howeve r, the firing of the neuron may have different impacts on the two output neurons as training phase of the neural network, these weights w (1 , j, k ) and w (2 , j, k ) are automatically determined by the network, based on the relevance/irrelevance of the pages. In the testing phase, i.e. determining if a retrieved page is relevant or not, the network computes: where k ranges over all input secti ons and for each section, only one neuron (identified by j ) per section (identified by k ) is fired. Suppose the first neuron in the output layer denotes relevance and the sec ond one denotes irrelevance. Then the two sums, S 1 and S 2, are compared. The larger one of the two sums causes the corresponding output neuron to fire. Thus, a page is determined to be either relevant (containing side effects) or irrelevant. The bigger the difference between the tw o sums, the more confident the neuron network has in making the determination. Since each of the two sums is com puted by firing input neurons, and each input neuron is associat ed with the values of a set of features, it is easy to find out which feature values are significant in determining the relevance or irrelevance of a given page. A generalization w ould have three neurons in the output layer, representing severe side effects, mild side effects and no side effects. The neural network has a mechanism to determine whether a set of feature values as represented by a neuron in an input section are significant or not. Let the neuron be the contribution of the neuron towards determining the relevance of the pages is immaterial and therefore that specific neuron is not useful. Consider a feature f in the k th associated with the k th section. There are two sets of weights  X  over all neurons having identical values of the features in S but different values of f . If for each sum of weights in the former set, the corresponding sum in the latter set has approximately the same va lue, then the feature f has essentially no impact in determining the relevance of a page and therefore f can be safely deleted. Currently, we do not prune any feature; in the fu ture, useless features can be pruned to yield a more effi cient system. The difference between the two sums can be used to indicate the significance of the features: th e larger the difference, the higher significance the feature is. When a page is determined by the neural network to be relevant, we are interested in finding the  X  X ost important X  passage within the page. A window of a fixed number of words is initially set at the beginning of the page. The window is adjusted to make sure that complete sentences are included in the window. Within this window, the number of occurrences of the most significant features, namely the symptoms/diseases and phrases  X  X ide effects X  or its synonyms are counted, while the other features such as  X  X afe X  are ignored. Then the sum the number of occurrences of the i th significant feature and g is the degree of importance of the feature, is computed. The window is then moved to find the next passage and the above computation of sum is repeated. The passage which yields the largest sum is the passage which is considered most important for the page. An example passage extracted using our algorithm is shown below.  X ...headache with stiff neck severe nausea or vomiting yellowing of eyes or skin side effects that usually do not require medical attention (report to your prescriber or health care professional if they continue or are bothersome): constipation or diarrhea difficulty swallowing dizziness gas or heartburn minor upset stomach nausea or vomiting what should i watch for while taking rofecoxib? (back to top) let your prescriber or health care professional know if your pain continues; do not take w ith other pain-killers without advice. If you get flu-like symptoms (fever, chills, muscle aches and pains), call your prescriber or health care professional; do not treat yourself to reduce unpleasant effects on your stomach. ... X . It is likely that by examining this extracted passage of th e page, a human can determine whether the page contains information about the side effects of the drug. For each page which our system judges to be relevant, we extract the URL of the page so that a human can examine whether the page (or at least the extracted passage of the page) contains side effect information. Furthermore, the names of the side effects in the page are recorded. In addition, the number of occurrences of each disease is kept. The higher the number of times a side effect is mentioned the more likely that the drug causes the side effect. The Web may contain some erroneous materials. This step attempts to eliminate these erroneous materials by not taking into consideration side effects with very low frequencies of being mentioned. The side effects are arranged in descending number of times they were mentioned. We relied on two sites for known side-effects. One site is http://www.fda.gov/cder/index.html where the name of the drug is submitted to find the official side effects of the drug. Here , technical medical terms are used. Another site http://www.nlm.nih.gov/medlineplus/druginformation.html provides side-effects of drugs for consumers. Ordinary non-medical terms are used in that site. If a side-effect of a drug determined in the steps given above is outside the two sets of side-effects of the drug in the two sites, then it can be considered as a officially unrecognized side-effect of the drug. We first describe the setup of our experiments. Initially, queries involving 7 arbitrarily chosen drugs as described in Section 3 are submitted to Google, with each query representing a drug. The 7 drugs are Prozac, Advil, Aspirin, Paxil, Celebrex, Beclometha sone and Namenda. For each drug, the number of pages retrieved by Google is limited to 100. Each retrieved page related to a drug is examined manually by a user to identify whether it describes a side-effect of the drug. This forms the training data. The training data are fed to the neural network to obtain the various weights associated with the input neurons and the two output neurons. Then, for each drug in a set of drugs which have the empty intersection with the initial set of drugs, a query is formed and is submitted to Google. Each page retrieved by Google is fed into the neural network which classifies the page to be relevant (containing some actual side effect of the drug) or irrelevant (does not contain any side effect of the drug). Clearly such a classification needs not be accu rate and will need to be verified manually. We apply the classification technique to a set of 20 other drugs (Vioxx, Meridia, Crestor, Accutane, Serevent, Zithromax, Caduet, Avastin, Vidaza, Ketek, Sanctura, Apokyn, EstroGel, Alimta, Campral). The first 6 drugs were mentioned in recent FDA drug safety hearings; the next 5 drugs were most frequently prescribed in 2003 and the remaining drugs are approved by FDA in 2004. We show the side effects of these drugs as mined from the Web. We note that these results are obtained purely from a statistical point of view and actual verification of whether these side effects are reliably associated with exposure to the drugs needs to be caref ully examined by medical experts. Finally, we recognize that manually obtaining the training data is time consuming. Thus, we propose the following technique to construct training examples automatically. We perform experiments to find out the accuracy of the following pro cess to determine positive and negative examples of training data automatically. (1) Identify manually a set of drugs from FDA sites such that each such drug has a set of known side effects, say S1 and a set of known diseases it is used to treat, say S2 with the constraint that the intersection of S1 and S2 is empty. (2) Submit a query of the form &lt;d, s2&gt; to PubMed or Google, where d is one of the drugs given in step (1) and s2 is a disease in S2 of the drug d. (3) For each retrieved page, if it cannot find any disease in S1 in that page but some disease in S2 is found, then classify it as a "negative" example. (The underlying assumption is that if an unknown side effect is caused by d, then d also causes at least one known side-effect. Thus, if no known side effect is obtained, we assume that d does not cause any side effect.) (4) Submit a query of the form &lt;d, side effect, s1&gt; to PubMed or Google, where s1 is a known side effect in S1 of drug d. (5) For each retrieved page, if some disease s1 in S1 is found, and it cannot find words such as "safe" or "not" in the vicinity of s1, then classify it as a "positive" page ( That is, a side effect of the drug is found in the page.) (6) Obtain 50 classified "positive" pages and 50 classified "negative" pages. Manually identify which ones are classified correctly. Compute the precisions. The following sets of experimental results are shown below. (1) The precision of our system. This is given by two  X  X recision X  values. The first precision value is the number of pages retrieved by our system which describe actual side effects of the drug as judged manually/ the number of pages which are retrieved by our system. This will be referred to as precision-accept. Since this requires manual operation, we can afford to do this for 5 drugs only, with Google retrieving 100 pages for each drug. The second precision number is the number of pages rejected by our system (among the 100 pages) which do not describe any side effect of the drug/ the number of pages rejected by our system. This will be referred to precision-reject. Ideally, if our system is perfect, bot h precision-accept and precision-reject should be 1. The results for the 5 drugs are given in Table 1. Drug Name Precision-accept Precision-reject On the average, only 16.4 pages out of 100 pages are selected by our system. Thus, based on the results given in Table 1, the accuracy of accepti ng a relevant page by our system and that of rejecting an irrelevant page are high, in spite of the fact that most pages retrieved by Google are irrelevant. Another experiment we perform is as follows. We submit queries of the form &lt; drug name, side effect &gt; to Google ( instead of dropping the phrase  X  X ide effect X ) and for each drug, we retrieve the top 17 pages ( versus 16.4 pages our system accepts on the aver age for each drug.) The precision for each of the 5 drugs is shown in Table 2. The average precision by Google is 61.2% versus 90.3% by our method. (2) The side-effects of the following drugs which are retrieved by our system, but they are not recognized by FDA are given in Table 3. Asendin Breast cancer Paxil Breast cancer Anafranil Breast cancer Norpramin Breast cancer Surmontil Breast cancer Rhotrimine Breast cancer Prilosec Pneumonia Betaseron Dehydration, Hemorrhage Kaletra Inflammatory oedema of the Accutane Watery eye Vioxx Clot Meridia Increased sex drive Sanctura Tremor, Seizures Norvasc Nosebleed Boniva Influenza, Constipation Omacor Nausea (3) The accuracy of our t echniques to automatically generate positive and negative examples, which can be used as training data are reported. We use the algorithm given in Section 4.1 to generate 50 positive examples and 50 negative examples. The accuracy of the 50 positive examples is 98% i.e. among the 50 examples which our system classifies as positive examples, there is one error only. The accuracy of the 50 negative examples is 96%. The side effects of the drugs given in Table 3 are examined by Patricia M. West, a licensed pharmacist and drug information specialist. Various sources, including the following sources [E01, B05, M05, Mc05, T05], are used for the validation of the side e ffects. The side effects of the following drugs which are not recognized by FDA are confirmed by her. It should be noted that her validation of the side effects is conservative. For example, there was a study which indicates Asendin, Paxil, Anafranil, Norpramin, Surmontil and Rhotrimine may double the risk of breast cancer, but more recent data with larger populations have not found an increased risk. In this case, the side effects of these drugs are not validated. Any side effect discovered by the system but which can not be confirmed by any source available to the expert is assumed to be not validated. Furthermore, side effects obtained by our system which are closely related to known side effects are also assumed to be not validated. For example, nausea has been identified by our system to be a side effect of Omacor, but since vomiting is a known side effect of the drug, nausea is not an unrecognized side effect. The side effects of Vioxx are so well publicized that we do not consider them to be unrecognized. In this paper, we provide a methodology to mine unrecognized side effects of drugs. Our experiments show that the obtained results involving Vioxx are consistent with the recent reported news , namely they cause heart problems. We have also identified officially unrecognized side effects of several other drugs. Our methodology consists of capturing the relationships of features of a domain (in the drug domain, medical terms, diseases/symptoms, distances between certain content words are the features) with th e subject of interest (side effect) by submitting a few queries and determining the relevance of the retrieved pages. Since the determination of the relevance of the retrieved pages by humans can be time consuming, we propose an automatic process to generate the positive and the negative examples and show that the proposed process is highly accurate. In this paper, we utilize a neural network to capture the desired relationships. However, other machine learning techniques such as [LSCP96, Mit97, YL99, HaMa00] can be utilized. Based on the captured relationships, queries of the same domain but involving other entities (dr ugs) can be processed with high precision. Since some data from the Web are likely to contain errors, we eliminate the noise by discarding data involving low frequencies of occurrences. In order to present an overview of the results to the user, only aggregate data (data involving total frequencies of occurrences) and the  X  X ost important X  passage of each accepted page are presented. The side effects of three drugs which are not recognized by FDA are validated by an expert. Actually our system has identified quite a few additional unrecognized side effects of other drugs. However, the validation process is time consuming and these unrecognized side effects have not been validated by our expert, due to the lack of time. Traditionally, an information sy stem or a search engine retrieves documents based on a given query. As we all know, a lot of irrelevant documents are retrieved, in spite of various advances [Kwok03, LLYM04, RW99, KuLe04]. A key reason for the low precision is that relationships among content words in documents are not captured precisely. In contrast, our methodology of retrieval is a two step process. In the first st ep, our system attempts to capture relationships among content words by applying a machine learning algorithm to a set of training examples. In the second step, actual retrieval takes places by utilizing the captured relationships among the content words. We note that the captured relationships are likely to be domain specific and probably problem specific. In other words, for each type of problems or each domain type, the system has to be trained, since the semantic information conveyed by the relationships among content words may differ from one type of problems to another. Furthermore, the vocabulary used in one domain may differ from that in a different domain. In spite of the restrictions mentioned in the last passage, we believe our methodology to achieve  X  X ccurate retrieval X  is applicable to a large variety of problems. For example, if we are interested in finding the complications caused by medical procedures, we proceed in the same way as we have done for finding the side effects of drugs. Specifically, we train a classifier from th e training data of a set of medical procedures and then we apply Web search and the classifier to other medical procedures. As another example, suppose we are interested in finding the distance between any two planets. Then we can train the system for some specific pairs of planets, say (Jupiter, Mars) and apply the trained system to other pairs. Our plan is to demonstrate that this methodology can be a pplied successfully to a wide variety of real life problems. If this is successful, this may form a basis for highly effective retrieval, in which queries are classified into different types (possibly millions of types) and for each query type , some training is performed for some queries and then the trained system is applied to other queries of the same type. 
