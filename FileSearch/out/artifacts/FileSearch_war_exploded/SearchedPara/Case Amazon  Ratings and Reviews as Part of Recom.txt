 We studied user behavior in a recommender-rich environment, Amazon online store, to see what role the algorithm-based and user-generated recommendations play in finding items of interest. We used applied ethnography, on-location interviewing and observation, to get an accurate picture of user activity. We were especially interested in the role of customer ratings and reviews and what kind of strategies us ers had developed for such an environment. Our results underline the need to develop recommender systems as a whole. The way the recommendations are shown affects which items get picked, and for improving the interface, it is necessary to study the whole in addition to studying the parts in isolation. H.5.2 [User Interfaces] Design, Experimentati on, Human Factors. Recommender systems, Amazon, rating systems, reviews.  X  I X  X l just peak at the customer reviews quickly. You know, to see what they X  X e said about it. It X  X  not that it X  X  so expensive but it does take time to read it. That X  X  more expensive . X  -Participant 4 The growth of e-commerce has witnessed proliferation of various types of recommender systems. Recommender systems, if considered to simply be algorithms that produce hits based on vacuum. The purpose of any recommender system is to direct the users to the items that best satisfy them. As no recommender system can be 100% correct or produce systematically novel and serendipitous results [3], the presentation of the results has to be considered an integral part of the system and so the algorithm cannot be seen as be-all-end-all. Consequently, we need to look at the recommenders as a part of the whole, and consider them in the actual use context. Moreover, not all recommender sy stems are based on algorithms. For instance, Amazon X  X  customer reviews and ratings constitute a type of recommendation that is based on human input but that does not go through collaborative filtering before it is presented to the users. The problem of finding the desired item in an Internet store is compounded if the item cannot be shown in electronic form. Users can be allowed to listen to an mp3 song, but they cannot be given a book to see in its physi cal form. Under such circum-stances, users must make up thei r minds based on the information given to them in the list and item pages. Few recommender system studies ha ve focused on the effects of the interface on the use of reco mmendations, choosing instead to focus on the algorithms. While Cosley et al. [1] studied the effects of the interface on giving opinions for recommender systems, we studied its effects on selecting an item. We set out to understand user stra tegies for selecting an item to buy under the conditions where the item cannot be shown as it is in an online store. We were especially interested in how the users selected items from list pages for a closer look and how they chose which customer reviews to read. We picked books as item and Amaz on, the world X  X  biggest online has consistently been an early adopter and developer of new e-commerce approaches [5]. In particular, Amazon has used a wide array of recommender approaches , including customer reviews, for years. We chose applied ethnography, in this case a combination of observation with verbal protocol and interviewing at the participants X  homes using their ow n computers, as our method to get a true view of the real use and to avoid the say-do problem. People have a human tendency to describe what they do differently from what they actually do. [4] Our method limited us to having onl y six participants, and so we did not have the necessary mass for studying alternative approaches as the subgroups w ould have been too small for reliable conclusions. Furthermore, the participants used Amazon only for buying nonfiction books, and some even stated that for lighter reading their behavior might be different. We were, however, able to see some trends and examples of user behavior in a recommender-rich online store. We found that customer reviews a nd ratings are an important part of the selection process and thus part of the overall recommender system. Amazon X  X  star ratings we re commonly used in selecting especially striking as all six participants indicated both in interviews and observations that not all the reviews from which the ratings were drawn were relevant to them. Our study further shows how users approach the item page in real life and how it affects their ability to make the decision to purchase or move on. Consequen tly, we see the listing pages and item pages as integral parts of the recommendation system that either enhance or reduce its effectiveness in allowing the users find the desired items. After introducing our method in deta il, we discuss our results. We look at the role of the recommender systems in finding items, the role of star ratings in selecting ite ms for a closer look, and the role of reviews in the item page. We used a combination of interviewing and observation with verbal protocol. The participants were given four tasks and asked questions before, during, and afte r each task. Care was taken not to direct participants X  attention w ith the questions. After the tasks, a semi-structured inte rview was conducted. The tasks were given to the participants in a web site made for the study. Each task was on its own pa ge. Task 1 was to find and buy a book the participant had not chosen beforehand from Amazon.com or .co.uk. The choice of site was given to preserve normal conditions although there ar e differences between the two interfaces. Three used .co.uk, two used .com, and one used both. On average, 23 minutes were used on Task 1. Each participant was given 15  X  towards purchasing the book so that they would select a book they really wanted. Task 2 was to choose a digital photography guide from a list of seven books. A list page, constructed to look like a list page from Amazon.co.uk, was made to incl ude books with high rating, low rating, no rating and  X  X earch insi de X  function. A mock-up page was used to make sure that a ll the different conditions were present. Links led to actual item pages in the .co.uk site. On average, 11 minutes were used on Task 2. The analysis of the other tasks is beyond the scope of this paper. The participants were six Finnish males, aged between 33 and 44. We refer to Participant 1 as P1, Participant 2 as P2, etc. A book purchase from Amazon was a requirement for recruitment to make sure that all were actual users of Amazon. On average, participants had purchased 10 books (the smallest number purchased being 2 and the largest 30) from Amazon prior to the study. The common reason for using Amazon was the availability of books. Four participants had also bought other items from Amazon. Participants had used Amazon for 4.5 years on average. All were in working life, had at least polytechnic-level education, and were experienced Internet users. The interview-observation sessions, one per participant, were held where participants typically vi sited Amazon, using their own computer. In all cases, this turned out to be their home. The sessions lasted 2-3 hours. Because no problems emerged in the pilot study, it was also used in the analysis. The sessions were videotaped with the camera directed at the computer screen. The camera also recorded the talking. All sessions were transcribed and then contrasted for analyzing. No analysis software was used. Any recommender system needs some input to generate personalized recommendations that are not simply based on item popularity. Amazon uses two types of input: first, the user X  X  long term engagement with the site and second, the user X  X  current activities. Returning clients are recognized by cookies. Task 1 was used to study the book-finding strategies. P3 used recommendations after signing in but he already owned the only interesting book in them. He c ontinued with keyword search. Three participants used keyword searches directly while the last one started with categories but moved to keyword searching after failing to locate a book to buy. P1 found a book with keyword search but after putting it into the shopping basket, he saw a reco mmendation for another book and went to its item page. When seeing an offer to buy the book in the basket with the new book ( X  X erfect Partner X  recommendation) for  X 40 (slight discount), he decided to buy both even though he had earlier on mentioned wanting to get a book on the subject for about  X 10. P5 was also interest ed in the  X  X erfect Partner X  recommendation, but did not buy the second book because he already had it. P4 found the book to buy from  X  X ustomers who bought this item also bought X  list af ter a few searches. Thus, of the seven books bought in Task 1, three were found by recommendations and four by keywords. All participants used one or more recommender feature (Table 1). Interestingly, no feature was clearly more popular than others. All were used in different phase s of the item finding process. Table 1. Recommendation usage in Task 1 by participants. Task 1 P1 P2 P3 P4 P5 P6 Bought a book offered by algorithmic recommender X X X Used categories for searching X Used  X  X erfect Partner X  X X X Used personalized recommendations X X Used  X  X ustomers who When asked how normal the setting in Task 1 was, P1 said that in many cases, he already knew quite well which books he was going to buy, but that when he needed a book for a particular topic, he did use Amazon in this way. Both P2 and P3 said that they typically started with personalized recommendations. P3 considered the emailed recommendations a great way to stay up-to-date. P5 normally used his favorite authors as a starting point, as did P2 in addition to recommendations. P2, P4, and P6 said that they typically already knew something about the book they came to buy, which made this way of searching somewhat different from normal. However, all said that after getting on with the task they ended up using Amazon pretty much the way they normally did. Overall, our study shows that recommender systems can play an important part in item-finding wh en seeing all items individually is impossible. While keyword searches are the standard way, different recommender systems can complement the searches and potentially replace them as in the case of P3 and partially P2.  X  I must X  X e done it automatically bec ause of looking at those stars there. This one X  X  gotten five stars while the other one X  X  gotten three and a half. But when you go to the page, you see that there are only two reviews. So in that sense it X  X  humbug but that X  X  the reason why I went there.  X   X  P4 In Amazon, item list pages have recommendations in the form of average number of stars given by customers in the reviews. The list page only showed the stars but not on how many reviews they were based. While all participants felt that they must first read a review to decide if it is relevant for them, the stars on the list page had an impact on which books three participants chose to view at item page level. The other thr ee users claimed not to pay any attention to the stars before th e item page. Observation supports this as these participants only mentioned stars when on an item page. Surprisingly, no participant knew how the books were sorted in the list page. This gave rise to misconceptions. For instance, P1 went to the item page to see how many reviews had been written to see if the book had sold well even though the books were sorted by  X  X estselling X :  X  I checked how many people had commented the book, that is, how well it has sold. If there are no reviews, it probably hasn X  X  sold much.  X  Amazon does show the sorting prin ciple and allows the users to change it with a drop-down list but only P3 had used it. P6 even said that he wished to have a way to organize the items in the list page. In practice, both observation and interviews showed that the participants dealt with a large num bers of hits, most of them not very useful, by making more specific keyword searches. In addition, the fact that P2 and P4 complained about not being able to see the number of review s on the list page underlines the need to show the bases of r ecommendations. Five stars might appear attractive in the list page but if the star rating was based on one review, the participants gave it little weight unless its content was especially helpful. On the other hand, a book with four stars drawn from fifty reviewers would defi nitely be of interest to the participants. P4:  X  I don X  X  think that one Joe Blow X  X  say-so matters. You could say that the strength of Joe Blow reviews lies in the mass. And that X  X  it. If 200 Joe Blows give four stars on average, understand how the recommendations are made, the better they can process the recommendations and make logical choices. In general, it might turn out that users could be better able to choose, say, a movie from the recommended ones if they knew why a certain movie was included on the list. Is it there because of the main actor or director they have liked in the past or because other people who have liked the movies by a certain director have also liked movies by this director? The knowledge of the reasoning might enable users to look at the recommendation from the right perspective and thus im prove their chances of finding the right item. Findings by Herloc ker, Konstan, and Riedl [2] certainly support this conclusion.  X  You can X  X  take it at face value. ... And that X  X  why I somewhere earlier, when someone had given tw o stars, I didn X  X  really care because I immediately saw that he didn X  X  know what he was talking about. ... So I knew the guy was stupid and so his two stars were irrelevant. That X  X  what X  X  important; you have to figure out who X  X  this guy who X  X  reviewing.  X   X  P5 Customer reviews in the item page represented the most direct customer-to-customer recomme ndation in Amazon that was relevant to the participants. In terestingly, others, such as Listmania! lists, tags, and Search Suggestions, were not used at all. Part of the reason is probably that because the participants did not visit Amazon that often but had used it for a long time, on average four and a half years, they were used to the features that have been available for some time. All participants said that the cu stomer reviews played a role in deciding whether or not to buy a book but that the reviews were typically not the only factor. The customer reviews tended to have a more pronounced preventive than encouraging effect (Table 2). Table 2. Importance of customer reviews. (1: Has only bought two books from Amazon. 2: With other contributing factors.) Importance of customer reviews P1 P2 P3 P4 Do customer reviews play a part in your buying decisions? Have you decided not to buy a book due to negative customer reviews? Have you bought a book Reviews served the participants in two ways. First, they were seen as sources of information about th e contents of the book. For this, the stars and the positive or negative recommendation inherent to the review were irrelevant. The participants wanted to know what the book contained, and customer reviews were seen as a source for this together with  X  X ear ch inside X  and  X  X ynopses X . Second, the participants reflect ed the reviewers X  needs and expertise against their own. A negative review was typically not seen as a deterrent if the reviewer X  X  needs or level of expertise in the field were different from th e participant X  X . Likewise, a positive review did not count for much if the participant did not see the relevance of what the reviewer said in relation to himself. While four participants claimed to typically read about five reviews when available, observa tions did not support this. The common start-off strategy seemed to be to pick one to three reviews for more careful reading after a general glance. No participant went to the second page of reviews. This is in contrast to the list page, which could be scanned more quickly, and consequently it was not rare for the participants to view 2 X 3 pages. Interestingly, the particip ants did not know in which order the reviews were shown. Three guessed it but admitted not knowing for sure. The reviews that got read carefully were typically longer X  X ll participants said that the shorter ones cannot give proper reasoning for their conclusions X  X nd were written in a matter-of-fact style. In fact, two participants expressed clear dislike for emotional tone. Bad English a nd improper tone were also common turn-offs. However, as it appears that the short ones get glanced at, they do affect at least the overall impression. While the name the reviewer goe s by was important to five participants, none of them had noticed Amazon X  X   X  X eal Name X  X  badge for verifying the identity of the reviewer. Furthermore, only two had tried to look at other reviews written by the reviewers to get further informati on on them. P2 tends to seek for reviews by reviewers he knows pe rsonally or whose books he has read, but if he does not find any, he tends to read one or two reviews from the top. No participant had ever learned to recognize and trust any reviewers from reading the reviews and other means Amazon provides for getting to know more about the reviewers. P1, P5 and P6 compare the stars of the reviews to see if the reviewers have reached consensus. P3, P5, and P6 tend to check out the extreme views identified by high or low stars and do not find middle-of-the-road reviews useful. P4 considers negative reviews the most useful because they point out the potential problems. For P1 and P2, the positiveness or negativeness of the reviews does not really affect their choice. In Amazon, users can click Yes/No buttons to indicate if a review was helpful for them. The number of those who found the review useful is given above the review . However, P2 and P3 had never even noticed the feature, and the four others did not give it much consideration in selecting the reviews for reading. It appeared that the participants were looking for certain keywords from the reviews when selecting ones for careful reading. For instance, in Task 2, participants looked for words like  X  X eginner X  and  X  X rofessiona l X  from the reviews. Some wanted an elementary book, others a more advanced book, and so these words indicated for whom the book was written or the level of expertise of the reviewer. The process of selecting reviews for reading appeared only partially conscious, as P2 said:  X  It comes from somewhere deep from some random number generator, that X  X  where it pretty often comes from . X  The conscious factors were there, but the data from this study only partially illuminated the whole process and further research on this is necessary. The number of book reviews in Amazon can run in tens and even hundreds and span several pages. As this study indicates, the users can have strategies for sel ecting which reviews to read, and so the service should provide t ools for using these strategies effectively. Such tools could also help others to formulate strategies. Length, star rating, a nd use of reviewer X  X  real name appear to be among the factors that could be used for filtering or sorting the reviews. In addition, if the reviewer expertise level in the field was set by the reviewer for the review, it could be useful for the readers. Amazon.com has recently started to give the users tools for finding relevant review s, but Amazon.co.uk has not. Our study underlines the need for such tools. Our study stemmed from the wish to understand what kind of user strategies emerge in a comp lex online shopping environment, such as Amazon. Our data shows how recommender systems are actually used and affords us a glimpse at online shopping reality. By observing and interviewing six Finnish Internet shoppers using Amazon, we found that while keyword search was still the most common approach to finding products from a large number of possibilities, recommender systems played an important part in helping users find the books they wanted. Algorithmic recommender features helped the participants find three books out of seven while the more direct recommendations helped the users decide which items to view more closely and which items to buy. One interesting area for further research is how to give users an understanding of the internal workings of the recommender system to allow them to process the result sets more effectively. What information do users need and how can we help them to develop correct mental models even if they only use the services occasionally? Everything in the interface communicates, and we need to make sure that it leads to the right understanding of the system. We are also interested to further study the strategies used in the selection process: which items get picked from listings, be it review lists or item lis ts, for closer scrutiny. All in all, while we certainly need to develop recommender algorithms, we also need to keep in mind that any algorithm-based recommender system needs to communicate its results to the users in a meaningful manner, and so we need to study recommenders as parts of the integral whole as well. Studying the whole tells us how to improve its pa rts. Our study is a step in that direction. This work was supported by the Finnish Funding Agency for Technology and Innovation (project 40279/05). [1] Cosley, D., Lam, S. K., Albert, I., Konstan, J. A., Riedl, J., Is [2] Herlocker, J. L., Konstan, J. A., and Riedl, J., Explaining [3] Herlocker, J. L., Konstan, J. A., Terveen, L. G., and Riedl, J. [4] Jordan, B., and Dalal, B., Persuasive Encounters: [5] Kotha, S., Competing on the Internet: The Case of 
