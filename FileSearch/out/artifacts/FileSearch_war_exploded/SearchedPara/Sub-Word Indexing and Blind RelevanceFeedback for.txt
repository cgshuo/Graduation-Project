 JOHANNES LEVELING and GARETH J. F. JONES Dublin City University 1. INTRODUCTION Indian languages have a more complex morphology compared to English. Thus, information retrieval (IR) for Indian languages could profit from a more de-tailed analysis of stemming and sub-word extraction. In addition, blind rele-vance feedback (BRF) using sub-words has not been extensively discussed, yet. This article provides a comprehensive investigation of stemming, sub-word in-dexing, and BRF. Their effectiveness is evaluated by conducting monolingual information retrieval experiments for the Indian languages Bengali, Hindi, and Marathi on the FIRE 2008 ad hoc test collections. For comparison, English monolingual IR experiments are also performed.

Stemming is a means to conflate different word forms to the same index term and has become a standard method to increase accuracy in IR. However, non-English IR and natural language processing (NLP) suffer from a lack of resources and tools in quantity and quality. This is particularly the case for languages which have not been the focus of significant previous IR evalua-tion campaigns such as the languages of the Indian subcontinent. To explore stemming for languages without existing resources, a language-independent corpus-based stemmer was created by analyzing suffix and root frequencies. The stemming procedure was inspired by an algorithm for morpheme induction developed for a morphological analysis of English and Bengali documents [Das-gupta and Ng 2007]. The goal of our work was to establish a simple but effective experimental baseline against which other retrieval experiments on the FIRE data can be compared. In contrast, stemming approaches for other languages typically build on additional languages resources which are not available or portable to other languages and often require additional processing (e.g., dic-tionary extraction, document conversions, or multiple scans over the document collection).

Stemming can also be seen as a special case of sub-word identification. A sub-word is the result of rewriting or removing parts of a word. Depending on the sub-word identification method, there may be more than one sub-word cor-responding to the original word. Advantages of sub-word indexing over word or stem indexing include its robustness against spelling errors and orthographic variants and recall enhancement. Therefore, sub-word indexing has mostly been investigated for noisy data such as speech transcripts and in the form of decompounding for compound-rich European languages such as German. Sub-word indexing may also prove useful for Indian languages with compound-ing properties (e.g., Marathi) or for IR on Indian newspaper articles in general, where the written representation of a word may differ from region to region. Three different sub-word indexing methods are investigated and compared to IR on word forms and stems: word prefixes, overlapping word-internal charac-ter n -grams, and sequences of vowels and consonants. The sub-word identifi-cation methods used here for the IR experiments described require little or no morphological analysis and also require no additional external resources such as dictionaries.

The main contribution of this article is the investigation of blind relevance feedback in combination with sub-word indexing. To the best of the authors X  knowledge, a relation between sub-word indexing and the number of relevance feedback terms and differences in the optimum number of feedback terms be-tween different Indian languages have not been investigated previously. Blind relevance feedback (BRF, also called pseudo-relevance feedback) builds on the assumption that the top-ranked documents retrieved for a query contain infor-mation which can be employed to reformulate a query (e.g., expand the query with additional terms) and to re-weight query terms. If, in comparison to word stems, more but smaller indexing units such as sub-words are indexed, 1 the number of terms used in BRF should also be expected to be higher in com-parison with BRF on indexed stems if a similar number of features associated with assumed relevant documents are to be included in the expanded query. This assumption for BRF is investigated for the different sub-word indexing techniques and all languages in the FIRE document collection.

In summary, corpus-based stemming and different sub-word indexing meth-ods for robust retrieval on Indian languages are evaluated and compared. Fi-nally, it is demonstrated that using smaller and more indexing units (compared to indexing words) requires the use of more feedback terms.

The rest of this article is organized as follows: Sections 2 presents research and related work on stemming, sub-word indexing, and BRF, respectively. Section 3 describes the FIRE 2008 collection and processing steps for docu-ments and topics. Section 4 introduces the new methods used for stemming, sub-word identification, and BRF. Section 5 contains a description of the exper-imental setup for the retrieval experiments and discusses results. The article concludes with a summary and an outlook in Section 6. 2. RELATED WORK Related research on stemming, sub-word identification, and blind relevance feedback is introduced in the next subsections. Selected official experiments on the FIRE 2008 data are briefly discussed in the final subsection of this section. 2.1 Stemming The goal of stemming (affix removal) is to conflate different derivational or inflectional variants of the same word to a single indexing form. Stemming approaches can be classified into different categories (e.g., by the results pro-duced by the stemmer: light stemming [Savoy 1999] vs. aggressive stemming [Lovins 1968]) or by the resources used (corpus-based [Xu and Croft 1998] vs. dictionary-based [Krovetz 1993; Majumder et al. 2007]).

Affix removal is language-dependent and creating a new stemmer involves analyzing text resources to produce a representation of morphological word formation rules. Hence, stemmers have to be customized for new languages, incorporating the language-specific morphological rules to form words. This can be an expensive and time-consuming task if language-specific resources are scarce, native speakers of the language are not available, or texts have to be analyzed manually. For example, dictionaries for Bengali, Hindi, and Marathi may be too small to be of practical use or they require additional processing if their contents are encoded in a Romanized transliteration but the document collection is not.

Furthermore, adapting rule-based stemming manually or by rule transla-tion to languages with a rich morphology might be too simplistic. For example, the English noun mouse and mice and the verb forms wear , wore , worn illus-trate the so-called vowel mutation, which is a frequent effect in languages such as Arabic. These cases of word formation may be difficult to identify with auto-matic approaches.

Still, most stemmers are rule-based and are widely available only for English and other west European languages. There are three major stemmers in use for English IR: the Porter stemmer, the Lovins stemmer, and the Krovetz stemmer.
The Porter stemmer [Porter 1980] employs rules which are successively applied if contextual prerequisites are met. Typical prerequisites include the number of consonant-vowel-consonant sequences (CVC) and character context before the suffix to be removed. The successive removal of affixes means that words with a recursive morphological structure are reduced to their base form (e.g., words such as hopelessness can be reduced to hope by removing all suffixes).
 Lovins [1968] employs the most aggressive base form reduction strategy. The Lovins stemmer identifies word suffixes by a longest match strategy and ap-plies more than 290 suffix removal rules, noting many exceptions. The aggres-siveness of a stemming method is determined by the number of conflations it produces and is implied by the number of stemming rules or by the size and number of word clusters reduced to the same root form.

Krovetz [1993] introduced a stemmer which is known as Kstem. This stem-mer is dictionary-based and requires that potential root forms should be con-tained in the dictionary, too. Experiments with this approach show a small but significant increase in retrieval performance compared to indexing word forms.

Xu and Croft [1998] use a combination of aggressive suffix removal with co-occurrence information from small text windows to identify stemming classes. This technique is corpus-based and requires little knowledge about the docu-ment language. The original stemmer was developed for a Spanish document collection for which Xu and Croft report an increase in recall, but the stemmer could also be applied to other domains, corpora, or languages.

Goldsmith [2001] identified suffixes employing a minimum description length (MDL) approach. MDL reflects the heuristic that words should be split into a relatively common root part and a common suffix part. Every instance of a word (token) must be split at the same breakpoint, and the breakpoints are selected so that the number of bits for encoding documents is minimal.
Oard et al. [2001] apply the Linguistica tool by Goldsmith [2001] to create a statistical stemmer. Suffix frequencies are computed for a subset of 500,000 words in a document collection. The frequencies of suffixes up to a length of 4 were adjusted by subtracting the frequency of subsumed suffixes. Single-character suffixes were sorted by the ratio between their final position like-lihood and their unconditional likelihood. Suffixes were sorted in decreasing order of frequency, choosing a cutoff value where the second derivate of the frequency vs. rank was maximized.

Simple statistical stemmers typically take account of only the most frequent suffixes (e.g., -s , -er ) and remove only the most frequent and shortest composite suffixes (e.g., -ers ). A composite suffix such as -lessness is typically not recog-nized; instead, only the smaller, last suffix part -ness will be removed. Light stemming focuses on removing only the most frequent suffixes from word forms which are typically very few in number [Savoy 2006]. Recently, light stemming has been researched as a less aggressive means to reduce words to their root form. A well-known example for English is the s -stemmer, which removes only the -s , -es ,and -ies suffixes from words (see, for example, Harman [1991]).
YASS is a clustering-based suffix stripper which has been applied to lan-guages such as English, French, and Bengali [Majumder et al. 2007]. YASS identifies clusters of equivalence classes for words by calculating distance mea-sures between strings. The stemmer does not handle morphologic prefixes and relies on several dictionaries which have to be extracted from a text resource (i.e., all words starting with the same character are collected in the same word list during preprocessing of the document collection).

In conclusion, many stemming approaches are data-driven (i.e., their de-velopment involves or is based on an analysis of collections of words from a dictionary or from the document collection). However, if a dictionary is already present certain rules to obtain the lexical base form for the dictionary must already exist.

The corpus-based stemming approach developed for the experiments de-scribed in this article is considered to be language-independent, although there are some parameters which would require language-specific setting for best re-sults. It requires no additional dictionary, handles composite suffixes, and can be extended to identify morphological prefixes as well. Stemming serves to pro-vide experimental results which can be better compared to sub-word indexing. 2.2 Sub-Word Identification and Indexing The main idea behind sub-word indexing is to map word forms to one or more index terms. One objective of sub-word indexing is to overcome problems in IR which are caused by spelling and orthographic variants, morphological variants of the same word, or compound words. For example, the word form political may be represented by the sub-words poli, olit, liti, itic, tica, ical . Related words such as politician or politics share some of the sub-words, which allows for partial matches.

Decompounding a word into its constituent words is a special case of sub-word identification. For languages with a rich morphology (such as Finnish, Dutch or German), a linguistically motivated decomposition of words has been widely recognized as a method to improve IR performance [Hedlund 2002; Braschler and Ripplinger 2003; Chen and Gey 2004]. In languages such as Eng-lish, compounds are typically written as separate words and their constituents can be easily identified. For languages such as German or Marathi, compounds are written as single words and IR may benefit from linguistically motivated decompounding.

Glavitsch and Sch  X  auble [1992] and Sch  X  auble and Glavitsch [1994] extract consonant-vowel-consonant (CVC) sequences as indexing features for retrieval of speech documents to obtain a more robust approach for noisy speech tran-scriptions. They select features based on document and collection frequency, and discrimination value. This indexing method performed slightly better than one using stopword removal and stemming. Similarly, Ng [2000] performs ex-periments with CVC on spoken documents for English, achieving a 28% perfor-mance increase when combining sub-words indexing with error compensation routines. For Indian language texts, characters may alternatively be repre-sented by different glyphs which appear visually similar (see Figure 3), which poses an indexing problem similar to that caused by errors in optical character recognition of printed materials.

McNamee [2001] performs retrieval experiments using overlapping charac-ter n -grams as indexing units. He reports performance results for indexing a combination of 2-grams, 3-grams, and 4-grams for English, Chinese, Japanese, and Korean. Results show that n -grams can achieve similar or superior perfor-mance in comparison to standard indexing techniques (e.g., indexing words), even for non-compounding languages and for cross-lingual retrieval [McNamee and Mayfield 2007].

McNamee [2008] also performs BRF experiments for different sub-word identification techniques. He shows that these techniques have a different opti-mum number of feedback terms and states that 25 terms are optimal for word-based indexing and 200 terms are a good choice for n -grams in English and other languages. He also demonstrates that BRF on n -grams shows only 2-4% absolute improvement in MAP compared to 9% for BRF on indexed words. (Un-less noted otherwise, performance improvements in this article are reported relative to the baseline experiments.)
Braschler and Ripplinger [2003] give an overview of stemming and decom-pounding for German. They perform IR experiments on data from CLEF for the ad hoc retrieval track. A variety of approaches for stemming and decompound-ing are applied, including commercial solutions, resulting in a performance gain of up to 60.4% mean average precision (MAP) and 30.3% for the number of relevant retrieved documents in comparison to indexing raw word forms (not stems).

Hedlund [2002] investigates compound splitting for cross-language IR us-ing a dictionary-based approach. For experiments on German, Swedish, and Finnish based on CLEF data, it was found that compound processing (i.e., decompounding into sub-words) has in general a positive effect on retrieval performance.

In Asian languages with logographic script such as Chinese, text does not contain delimiters indicating word boundaries (e.g., whitespace between words). Hence, word segmentation and sub-word identification as a special case are important language processing tasks [Foo and Li 2004; Ogawa and Matsuda 1997; Chen et al. 1997]. Most Chinese words are character bigrams. On the Chinese TREC 5 collection, Chen et al. [1997] found that dictionary-less bigram methods perform similarly or better than dictionary-based methods.
Other approaches to sub-word indexing include dictionary-based lemmati-zation [Leveling and Hartrumpf 2005] and determining syllable-like character sequences using Knuth X  X  algorithm for hyphenation [Leveling 2009].
In summary, sub-word indexing has mostly been investigated for noisy data and for compound-rich European languages. In Indian texts, the same word can have multiple written variant forms, which means that texts may have some of the properties of transcribed speech or documents obtained via optical character recognition. This makes sub-word identification worth investigating for Indian languages. 2.3 Query Expansion by Blind Relevance Feedback Blind relevance feedback techniques for query expansion have been widely used in information retrieval to improve performance. Typical IR experiments compare BRF with different numbers of documents or terms extracted, or vary the term selection criterion.

Buckley et al. [1994] perform massive query expansion with the SMART retrieval system for ad hoc retrieval experiments at TREC 3. They employ Roc-chio feedback [Rocchio 1971] with 300 to 530 terms and phrases for each topic. An improvement of retrieval effectiveness between 7% and 25% in various ex-periments was observed.

Sparck-Jones et al. [2000] vary the number of allowed feedback terms de-pending on the query length. They tried to identify the optimum number of feedback terms depending on the query size. Supported by evidence from their results, they suggest using 16, 24, and 32 relevance feedback terms for short, medium, and long queries, respectively.

Lynam et al. [2004] compare six retrieval systems capable of BRF with de-fault system settings. They observed that the lowest performing method profits most from feedback. The system producing the initial result set with the high-est performance, the SMART system, showed the least increase in retrieval effectiveness.
 Billerbeck and Zobel [2004] question the usefulness of query expansion. They perform experiments using a simplified BM25 formula, appending 25 terms  X  X ith the smallest [sic!] TSVs X  (term selection values) to the query and downgrading the Okapi term weight by 1/3. They found that query expansion is in some cases not effective, but failed to provide a more detailed explanation as to why this is the case.

There are many other query expansion strategies including EVM [Gey et al. 2001], global analysis [Xu and Croft 1996], and implicit feedback [Shen et al. 2005], but in this article we focus on studies directly relevant to our retrieval experiments. 2.4 Experiments at FIRE 2008 The FIRE 2008 evaluation initiative has attracted various IR research teams. Table I shows results for the best performing experiments. McNamee [2008] employs n -grams and skipgrams as indexing units for IR on English, Bengali, Hindi, and Marathi documents using language modeling (LM) as a retrieval model. Skipgrams are n -grams with wildcards [Pirkola et al. 2002], and have been investigated by Guthrie et al. [2006] to overcome the data sparsity in n -gram modeling. McNamee experimented with different but fixed numbers of expansion terms for different indexing methods: 50 feedback terms for words, 150 for 4-grams and 5-grams, and 400 for skip-grams.

McNamee et al. [2009] conduct additional IR experiments on the FIRE 2008 data. They compute n -grams on running text, treating whitespace as part of the n -grams. They investigate different term indexing methods, including word-spanning n -grams, truncation, and word-internal n -grams. Significant im-provements for indexing sub-words compared to the baseline of indexing words are observed. The best effectiveness for Hindi and Bengali is achieved by 4-grams, for Marathi by word-internal 4-grams.

Paik and Parui [2008] use the Terrier system on the FIRE data. Their exper-iments make use of the title, description, and narrative field of topics (TDN). They redefine characters based on their context as dependent or compound characters. For stemming, they reduce word forms to their common prefixes in a single scan over a lexicon. The best performance achieved in their exper-iments was 0.4232 MAP for Bengali, 0.2709 MAP for Hindi, and 0.4239 MAP for Marathi, respectively.

Dolamic and Savoy [2008] use the Okapi IR model, divergence from random-ness (DFR) and language modeling (LM) for FIRE 2008 experiments on Ben-gali, Marathi, and Hindi documents. Their approach includes light stemming [Savoy 2006] and stopword removal based on small stopword lists (less than 200 words). They also apply Rocchio feedback (with  X  =  X  =0 . 75) using 3-10 feedback documents and 20-100 feedback terms and find that blind relevance feedback seems to be a useful techniques for enhancing retrieval effective-ness. The best performance is based on data fusion of results from different IR models. For Bengali, the best result was 0.4719 MAP using the TDN fields from the topics.
 Xu and Oard [2008] apply a Perl Search engine on the FIRE data for English-Hindi CLIR. In preliminary experiments on the FIRE data, they employ a stop-word list with 275 words for Hindi IR, using BM25 with default parameters ( b =1 . 2, k 1=0 . 75, k 3 = 7). The monolingual Hindi baseline in these ex-periments is 0.37 MAP, which was improved to 0.38 MAP when using query expansion.

In summary, different languages require different indexing and retrieval ap-proaches. No best practice for IR on Indian languages has been established yet, but there seems to be a trend towards simpler approaches (using fewer stopwords, light stemming, and knowledge-light processing). FIRE is the first attempt to provide test collections to form a retrieval benchmark for Indian language IR. 3. INDIAN LANGUAGE IR BASED ON FIRE DATA The Forum for Information Retrieval Evaluation (FIRE) provides large-scale document collections for Indian language information retrieval experiments. Similar to other IR evaluation initiatives such as TREC, 2 NTCIR, 3 or CLEF, 4 FIRE aims to compare the retrieval performance of different systems and ap-proaches and investigate evaluation methods for IR. FIRE started in 2008 with document collections for English, Bengali, Hindi, and Marathi. 3.1 Documents and Topics The FIRE document collection contains newspaper articles on various topics including sports, politics, business, and local news. The articles are repre-sented as structured XML documents in TREC format, using UTF-8 encoding. Figure 1 shows an excerpt from a FIRE document.

FIRE topics resemble those from other retrieval campaigns such as TREC in format and content. They comprise a brief phrase describing the information need (topic title, T), a longer description (topic description, D), and a part with information on how documents are to be assessed for relevance (topic narra-tive, N). Retrieval queries are typically generated from the title and description fields of topics (TD). Figure 2 shows a sample FIRE topic. For each language, 50 unique topics and the relevance assessments were provided together with the corresponding document collection. For all FIRE topics, relevant documents have been assessed by pooling submissions from systems participating in the FIRE retrieval track.

Statistics about the FIRE document collections are shown in Table II (Avg doclen: average document length in terms). Every document was pro-vided as a single file. Not all documents could be indexed properly: some files include invalid XML characters or contain otherwise invalid XML; others con-tain no valid text at all. These documents have not been indexed at all, but they make up only a small portion of each collection. In addition, some duplicate document identifiers (IDs) were identified in the document collections. Dupli-cate document IDs were discarded from the output of the retrieval system used for the experiments described in this article (i.e., document IDs occurring more than once were omitted). Table III shows statistics of the topics for FIRE 2008 (# Assessed: number of documents assessed for relevance; # Relevant: number of relevant documents; Avg relevant: average number of relevant documents per topic). 3.2 Language-Specific Preprocessing The stopword lists for English, Bengali, Hindi, and Marathi used for the ex-periments described in this article originate from different sources. The first source of stopwords is Jacques Savoy X  X  Web page on multilingual resources for IR at the University of Neuch  X  atel 5 , which contains links to files with stopwords in many languages. These stopword lists have been generated by the Neuch  X  atel group following an approach to obtain a general stopword list for a document collection [Fox 1992; Savoy 1999], in which the N most frequent words are ex-tracted from a document collection, numbers are removed from the list, and the resulting stopword list has been manually extended with additional word forms. The stopword lists from this Web page contain 571 words for English (the SMART stopword list), 119 for Bengali, 163 for Hindi, and 98 for Marathi.
Second, special characters and punctuation marks were compiled by us in a list. For example,  X  |  X  is used as an end-of-sentence marker in Bengali. Finally, a stopword list is created during our indexing experiments, containing the most frequent index terms. Terms occurring in more than 75% of all documents in the document collection are considered as stopwords.

For the IR experiments on the FIRE document collections, some minimal knowledge of Indian languages is essential. For example, text processing in IR typically involves case normalization, and some sub-word indexing methods require differentiating between vowels and consonants.

The English (Roman) writing system or script is based on 26 characters, of which six can be vowels. English uses a left-to-right writing system with cap-italization of characters in the initial position of a sentence and capitalization of proper nouns. Several punctuation marks (e.g.,  X ? X  ,  X ! X  ,  X ; X  ) are used.
The Bengali writing system employs eleven graphemes denoting the inde-pendent form of nine vowels and two diphthongs. There are 39 letters denoting consonants with so-called inherent vowels. Bengali has a left-to-right writing system and uses no capitalization. In addition to punctuation marks incorpo-rated from Western scripts, Bengali script defines a symbol for the full stop, that is,  X  |  X  .

Hindi and Marathi are written in Devanagari, a script consisting of 52 let-ters (16 vowels and 36 consonants). Devanagari is written from left to right and uses no capitalization. Marathi is a compounding language, that is, two words can be joined together by a morphological process to form a new word (written as a single word or combining the two words with a hyphen).
The set of vowels differs from language to language: In English, vowels are a, e, i, o, u, and y if preceded by a consonant. For the experiments described in this article, vowels are also determined by their character context (e.g., y ). Vowels in other European languages include letters with accents and diacritical marks such as the French letter  X  e or the umlaut character  X  a . InIndianscript,all consonants have an inherent vowel. A change to the inherent vowel is indicated by adding a vowel sign to the base consonant. The vowel sign can appear left, right, above, below, or on both sides of the base consonant. For example, the vowel AA appears to the right and the vowel I appears to the left of a consonant in Devanagari. Vowels independent of a consonant appear at the beginning of a word or directly after a vowel. Thus, vowels in Indian script do not depend on character context and are encoded by different characters.

Special attention has been given to character normalization. Larkey et al. [2003] normalize Hindi multi-byte characters using manually crafted rules for the TIDES (Translingual Information Detection, Extraction, and Summariza-tion) surprise language exercise. Unnormalized text encoded with UTF-8 may use different multi-byte character encodings for the same character. For exam-ple, the character  X  e in the Spanish name San Jos  X  e may be encoded as a single byte (for  X  e ), as the byte sequence for e +  X  or as the byte sequence for  X  + e . For the experiments described in this article, encoded text was normalized by following the guidelines for canonical decomposition followed by canonical com-position from the International Components for Unicode (ICU) implementing the standard normalization forms, which is described in the Unicode Standard Annex #15 -Unicode Normalization Forms. 6 These normalization steps guar-antee a fixed order of characters where multiple variants are allowed. The normalization of data for the IR experiments was motivated by the following reasons.  X  X ther researchers have reported inconsistencies or variations in encoding Indian documents [Larkey et al. 2003], news articles [Pal et al. 2006], and
Web pages [Pingali et al. 2006].  X  X he FIRE 2008 documents originate from different sources and are written in different languages. Newspaper agencies publishing articles and newswires are located in different regions and may use different encoding guidelines (or do not use any guidelines at all), even for the same language.  X  X roper nouns play an important role in IR. In Indian documents, foreign proper nouns may be transcribed or transliterated in different ways, similar to English variants of the name Gorbachev originating from transliteration (e.g., Gorbatschow ).  X  X dditional or external resources (e.g., stopword lists or dictionaries) may use a different character encoding which would make resources incompatible. Normalizing the FIRE documents affected about 13.6% of all tokens in Bengali, 2.7% in Hindi, and 6.1% in Marathi. The English documents were not changed at all by the normalization.

Incomplete or missing normalization of resources would result in many mis-matches in preprocessing (e.g., unrecognized stopwords) and retrieval (e.g., spelling variants in documents). In addition, text was processed by applying the following normalization rules, which are inspired by Larkey et al. [2003] and Pingali et al. [2006]. (1) Internal word space is removed (e.g., characters U+200C and U+200D). (2) Chandrabindu and Anusvara are special characters indicating nasaliza-(3) Chandrabindu followed by a vowel is mapped to the corresponding vowel. (4) Consonants in Indian languages typically have an inherent vowel sound. (5) Nukta is a combining character used to obtain additional consonants with (6) Long vowels are mapped to the corresponding short form, as has been (7) Some character sequences which are visually similar to a single glyph are (8) Accents are typically part of transcribed foreign names. They are removed (9) Digit symbols in Bengali and Devanagari are mapped to Arabic numeric 4. EXPERIMENT PREPARATIONS 4.1 Morpheme Induction for a Corpus-Based Stemmer Removing a fixed number of suffixes from words in different languages might result in a more or less aggressive stemming approach. The Porter stemmer for English applies approximately 50 rules roughly corresponding to a single simple suffix and is typically considered as moderately aggressive. Removing the same number of suffixes from words in a different language may result in very light stemming. For example, Bengali has a much richer morphology than English and has more complex word formation rules, which is indicated by the higher number of possible morphological suffixes.

A corpus-based, language-independent stemming approach was imple-mented following a morpheme induction approach which has been evaluated for English and Bengali and is described in Dasgupta and Ng [2007; 2006]. On a manually annotated set of Bengali words this approach achieved a substan-tially higher F -score than Linguistica [Goldsmith 2001].

For the retrieval experiments described in this article, the first steps of the morpheme induction were implemented to obtain a stemmer. The later morpheme induction steps described by Dasgupta and Ng [2007] mainly test the validity of composite suffix candidates and suffix attachments. The mor-pheme induction produces a list of candidate suffixes based on a frequency analysis of potential word roots and suffixes. For example, the word hopeful can be split into the root-suffix pairs hop + eful , hope + ful ,and hopef + ul . The middle variant is chosen, because its root and suffix frequency are highest. In a second step, suffix combinations (composite suffixes) are determined via the frequency of potential root forms, allowing for a recursive morphological word structure. A word is stemmed by removing the longest suffix found in the gen-erated suffix lists or by not removing a suffix, otherwise.

The list of candidate suffixes is produced using a method suggested by Ke-shava and Pitler [2006]. The top 20 suffixes for English are shown in Table IV. For readability and for a better comparison to suffixes removed by other stem-ming approaches, the examples are given in English. Note that all of the suf-fixes recognized by the s -stemmer are included in the lists generated by the morpheme induction. The top suffixes also contain some composite suffixes ( -ers and -ally ), which were identified as simple suffixes in the first step of morpheme induction. Possible improvements of the stemmer include calculat-ing the updated frequencies of suffixes (as suggested by Oard et al. [2001]), and removing proper nouns from the document collections before morpheme induction. While the examples given in Table IV were randomly selected from the set of root candidates, some suffixes seem to be representative for proper nouns only. For example, the suffix -a was identified as a probable suffix from the FIRE document collection, probably because the proper noun India is present in many newspaper articles. Goldsmith [2001] lists some er-roneous cases where proper nouns are incorrectly stemmed and assigned to word sets of the same morphological signature. However, no previous work has proposed that removing proper nouns from the training data or document collection might improve the accuracy of affix removal. As an obvious improve-ment of the morpheme induction, we suggest to apply named entity recognition to the document collection and exclude named entities from the training data. While named entities follow morphological rules like other words, it may be safe to assume that they morphologically behave like other nouns (but with different frequency patterns). Thus, identifying and removing proper nouns will likely improve the accuracy of stemming, because common word suffixes which are part of proper nouns are excluded. For example, first names and location names in newspaper articles may be specific to a region or culture (in this case India, see Table IV) and not specific to word formation rules of the document language (in this case English). However, the investigation of this approach is beyond the scope of this article.

After indexing the word forms in a document collection (as is done for each language in the baseline experiments described here), the index contains all terms and their surface frequency which is extracted for morpheme induction. All words w are analyzed by successively selecting all possible segmentation points, splitting them into a potential root form r and a suffix s . Thus, w is the concatenation of r and s . The morpheme induction method is also applicable to determine linguistic prefixes, but the stemmer described in this paper only removes word suffixes. However, most stemmers remove suffixes only, because removing a prefix may also change the meaning of a word to its antonym (e.g., legal vs. illegal ). It is presumed and it is usually the case that the collection vocabulary will not only contain forms corresponding to inflected or derived words, but also the uninflected root forms. If the potential root form r is con-tained in the set of index terms (e.g., it is part of the collection vocabulary and the root frequency is higher than 0), s is added to the list of suffix candidates and r is added to the list of root candidates. Candidate suffixes are filtered as follows. (1) In a minor variation of the approach proposed in Dasgupta and Ng [2007], (2) A score is assigned to each suffix by multiplying the suffix frequency and The suffix candidates are then ranked by their score to obtain the top K suf-fixes. Dasgupta and Ng [2007] state that the parameter K depends on the vocabulary size and use different values for English and Bengali (given a simi-lar collection size for different languages). For the experiments described here, a fixed value of K = 50 was used for all languages tested. Dasgupta and Ng [2007] used the same number of suffixes for morpheme induction for English. Considering that about 50 affix removal rules are defined by the Porter this seems a plausible setting for mildly aggressive stemming.

Composite suffixes are detected by combining all suffixes in the induced can-didate list (e.g., -less + ness in fearlessness where + denotes the concatenation of strings). For morphologically rich languages such as Arabic or Bengali, com-posite suffix detection plays an important role in base form reduction. The detection of composite suffixes s 1 + s 2 builds on the assumption that a root form r will also combine with part of the suffix ( s 1 ). This property typically does not hold for non-composite suffixes. The morpheme induction method presumes they can combine with. Specifically, s 1 + s 2 and s 1 are considered to be similar if their similarity value, which is calculated as shown in Equation 1, is greater than a threshold t s (specifically, t s &gt; 0 . 6 was used). and | W ij | is the number of distinct words that combine with s i + s j . These values correspond to the morphological family size of s i + s j and its intersection with s i , respectively.

The analysis of suffixes is performed after indexing word forms. All index terms are processed as described and the top-ranked suffix candidates and composite suffix candidates are extracted. For all tested languages, the mor-pheme induction process takes less than a minute to finish (using a standard PC), which is much less time than for indexing the document collections. The corpus-based stemmer reads the lists of suffixes and processes words which are longer than a given threshold t l ( t l = 3). All other words remain unstemmed. The stemmer determines the one longest suffix in the suffix lists (if any) and removes it from the word to produce a root form. 4.2 Sub-Word Identification Sub-word identification aims at breaking up long words into smaller units. These units are generated by methods such as decompounding words into lex-ical constituent words or by splitting words into character n -grams of a fixed size. Splitting a compound word and finding smaller indexing units will usually make a match more likely and yield a higher recall. Linguistically oriented ap-proaches restrict sub-words to constituent words. Other approaches to create sub-words do not require that sub-words must be valid words of the language (e.g., character n -grams [McNamee et al. 2009]).

In addition to corpus-based stemming, three different methods of sub-word indexing are investigated and compared in this article: n -prefixes, word-internal n -grams (short: n -grams), and CVC sequences. These methods were selected as they do not rely on extensive linguistic resources for Indian lan-guages and they aim to provide robust performance for potentially noisy data. Table V shows results of applying sub-word splitting techniques to the English phrase information retrieval . The following subsections provide a more detailed description of these sub-word indexing techniques.

Word truncation is a method which can be easily applied to processing text for writing systems with a fixed writing order. Word forms are truncated af-ter the n -th character. 7 McNamee et al. [2009] describe experiments using truncated words and n -grams in many languages, including Bengali, Hindi, and Marathi. In their experiments, word-spanning 5-grams outperform word-internal 5-grams for Bengali and Hindi. For Marathi, word-internal 5-grams perform better. For all languages, 5-prefixes perform slightly worse than word-spanning 5-grams. They conclude that word truncation (here called n -prefix) shows a significant increase in retrieval effectiveness and may be a viable alter-native to using a stemmer for resource-scarce languages. For the experiments described in this article, overlapping word-internal n -grams were employed.
Overlapping character n -grams (3-grams, 4-grams, and 5-grams) have been successfully used for monolingual and cross-lingual IR (see McNamee et al. [2009], McNamee [2001], McNamee and Mayfield [2007],and McNamee [2008]). Words can be broken up into sequences of characters of a fixed size n to form character n -grams. If n -grams are allowed to start at every character position (instead of one n -gram for every n characters), the n -grams will partially over-lap. Some variants of this method add an extra character as a special word boundary marker to n -grams from the beginning and end of a word. Following this approach and using the character  X  |  X  as a boundary marker, the set of 5-grams for the noun  X  X embership X  includes the gram  X  X hip |  X  from the ending of the word and allows us to distinguish it from n -grams for the noun  X  X hipping X  .
In another approach, the full text is regarded as a single string and not bro-ken down into words before calculating n -grams. Whitespace characters are not distinguished and become part of the character n -grams, which can span word boundaries (word-spanning n -grams). For languages with a writing sys-tem that rarely uses whitespace, such as Chinese, this is the default behavior.
Identifying consonant-vowel sequences requires classifying characters into vowels and consonants. A CVC sequence is the longest match of a sequence of zero or more consonants (C), followed by zero or more vowels (V), fol-lowed by one or more consonants in a word. Three variants of these character sequences can be defined accordingly (VCV, CV, and VC sequences) and are investigated in this article too. Consonant-vowel sequences (CV) and vari-ant methods, including vowel-consonant sequences (VC), consonant-vowel-consonant sequences (CVC), and vowel-consonant-vowel sequences (VCV) were often used for noisy data (e.g., in speech retrieval [Glavitsch and Sch  X  auble 1992]).
 4.3 Term Selection for Blind Relevance Feedback on Sub-Words Blind relevance feedback has been applied in many ad hoc IR experiments. To the best of the authors X  knowledge, the existence of a relationship between the size or number of indexing units and the preferred number of feedback terms has not yet been investigated.

Splitting words into sub-words will typically produce more but smaller in-dexing units (cf. Table V and Table VI). However, smaller indexing units can be more ambiguous, that is, they occur more frequently and they may orig-inate from different word forms and introduce ambiguity. The relationship between the number of feedback terms to be used and the type of the index-ing unit has not been thoroughly investigated because most IR experiments focus on retrieval on indexed stems. Furthermore, BRF on indexed words may expand a query with morphologic or spelling variants of a query term. For lan-guages with a rich morphology such as Bengali, the optimum number of useful feedback terms may be higher compared to English. However, the number of feedback terms can be expected to depend on the type of indexing unit, that is, sub-words may require additional feedback terms for implicit disambiguation and IR for languages with a rich morphology may also profit from additional feedback terms.

In consequence, the number of feedback terms used for BRF may have to be adjusted and optimized accordingly when the index contains sub-words. Oth-erwise, the combination of sub-word indexing and BRF might actually degrade performance.

Two sets of experiments using BRF are conducted by two methods of ad-aptation: QE i and QE ii .InQE i , the number of relevance feedback terms (T) extracted from the top ranked documents (D) is adapted by the increase in vocabulary size (the number of unique tokens) compared to the English doc-ument collection, for example, T = T  X  (# types L 1 / # types L 2 )for L 1= English and L 2  X  X  Bengali , Hindi , Marathi } with D =10and T = 20. In QE ii ,the number of relevance feedback terms is adapted relative to the change in the number of index terms compared to indexing word forms, for example, T = T  X  (# types T 1 / # types T 2 )for T 1= word and T 2  X  X  CVC , n-gram } .
The former experiments aim to find out if a larger vocabulary size in a differ-ent language would require a higher number of feedback terms. The latter set of experiments concentrate on finding out how the size and number of indexing units requires changes in the number of feedback terms. The BRF experiments in this article serve only to identify a general trend. Identifying the optimum number of feedback terms for each language and sub-word indexing method would require many more retrieval experiments and may be task-dependent.
In summary, the research question is to confirm that if more terms are in-dexed (e.g., sub-words instead of stems), more BRF terms have to be used. These experiments were performed only for indexing methods which affect the number of indexing terms, that is, n -grams and CVC variants. 5. EXPERIMENTS AND RESULTS For the experiments described in this article, the Lucene IR toolkit was em-ployed. 8 Lucene does not (yet) provide support for state-of-the-art IR models or for BRF. Support for the Okapi BM25 model [Robertson et al. 1995, 1998] and for the corresponding BRF approach (see Equation 2 and 3) was implemented for Lucene by one of the authors of this article. 9 The BM25 score for a document and a query Q is defined as: where Q is the query, containing terms t and w (1) is the RSJ (Robertson/Sparck-Jones) weight of t in Q [Robertson and Sparck Jones 1976]: where  X  k 1 , k 3 ,and b are model parameters. The default parameters for the BM25 model used are b =0 . 75, k 1 =1 . 2, and k 3 =7;  X  N is the number of documents in the collection;  X  n is the document frequency for the term;  X  R is the number of documents known or presumed to be relevant for a topic. (For BRF, the number of feedback documents is denoted by D .);  X  r is the number of relevant documents containing the term;  X  tf is the frequency of the term t within a document;  X  qtf is the frequency of the term in the topic;  X  K = k 1 ((1  X  b )+ b  X  doclen / avg doclen );  X  doclen and avg doclen are the document length and average document length in index terms, respectively.

For BRF, the number of documents D and the number of feedback terms T were by default set to 10 and 20, respectively. These are numbers in the typical range used in information retrieval experiments. The formula to compute the term selection value (TSV) for a term for the IR experiments described in this article was proposed by Robertson [1990] and is shown in Equation 4. The following subsections describe the results for IR experiments on the FIRE document collection for each language. The best results are set in bold face. The result tables contain the following columns.  X  X ndex type: Use words (i.e., word indexing using unprocessed raw word forms in inflectional forms), PBS (Porter-based stems), CBS (corpus-based stems), n -grams, n -prefixes, CVC (consonant-vowel-consonant sequences), or vari-ants as the index term type.  X  X E?: Employ query expansion by BRF, yes (Y) or no (N).  X  X : The number of relevance feedback documents.  X  X : The number of relevance feedback terms.  X  X el ret: The number of relevant and retrieved documents in the top ranked 1000 documents.  X  X AP: Mean average precision.  X  X MAP: Geometric mean average precision.  X  X @10: Precision at 10 documents.  X  X hg: Absolute change in MAP, compared to the corresponding baseline.
Significance testing on the IR results was performed by ANOVA (analysis of variance) tests per language, followed by Fischer X  X  least significant difference method, LSD) as a post hoc analysis. Significant changes for ( p &lt; 0 . 05) are indicated by  X  in the result tables. Note that the baseline of indexing raw word forms is chosen because experiments on corpus-based stemming and query ex-pansion are conducted with varying parameters. As a second, more competitive baseline, the corresponding experiments combining raw word indexing with BRF was selected ( D = 10, T = 20) for each language. Significant improve-ments over this baseline are indicated by + . For a fair comparison, absolute increase in MAP compared to the experiments without BRF is also reported in the tables. 5.1 English Results Results for the monolingual IR experiments on the English FIRE document collection are shown in Table VII. Both stemming approaches, the Porter stem-mer and the corpus-based stemmer, outperform the baseline of indexing words in combination with BRF (+12% and +7% MAP). Query expansion significantly increases IR performance in these cases (+25% and +23% MAP). The best per-forming method for English is indexing using the Porter stemmer. Indexing n -prefixes ( n  X  X  4 , 5 , 6 } ) significantly outperforms the baseline when combined with BRF and performs similar to applying a stemmer (+24% MAP for the best variant). An additional query expansion step improves the GMAP and the number of relevant retrieved documents for 6-prefixes beyond all other results (+5% more relevant retrieved documents and (+37% GMAP). The corpus-based stemmer has only a slightly worse MAP than the Porter stemmer in combi-nation with BRF (0.5763 vs. 0.5832 MAP). Blind relevance feedback increases MAP in all cases.

Adapting the number of feedback terms increases all performance measures for n -gram-based retrieval, but slightly decreases effectiveness for CVC and variants. 5.2 Bengali Results Results for the monolingual IR experiments on the Bengali FIRE document collection are shown in Table VIII. Indexing 5-prefixes in combination with query expansion yields the highest number of relevant and retrieved docu-ments for Bengali (1,799 out of 1,863 relevant documents, +13%), the highest MAP (0.4251, +59%, +15% absolute increase), and the highest GMAP (0.3146, +61%). Precision at 10 documents is highest for 4-prefixes in combination with query expansion (0.5080). The corpus-based stemmer combined with query expansion achieves a significantly higher MAP than the baseline experiment (0.4101 vs. 0.2669 MAP, +54%). A significantly higher MAP is achieved for CVC experiments using query expansion and query expansion with an adapted number of feedback terms.

Adapting the number of feedback terms relative to the increase in vocabu-lary size consistently increases all performance measures for n -gram retrieval, and increases retrieval effectiveness for most CVC variants. 5.3 Hindi Results Results for the monolingual IR experiments on the Hindi FIRE document col-lection are shown in Table IX. The highest MAP was achieved by indexing 5-prefixes (0.2704 MAP, +21%, +5% absolute increase), which also led to the highest number of relevant retrieved documents (2480, +5%). Precision at 10 documents was highest for 5-prefixes in combination with BRF. In comparison to the retrieval experiments in other languages, GMAP was very low for all experiments (in all experiments less than 0.04); the highest GMAP value was 0.0357 for indexing overlapping 3-grams. The corpus-based stemmer increases the number of topics with a higher AP than the baseline considerably, but not significantly.

For Hindi, query expansion by BRF always reduced the number of relevant and retrieved documents, and almost always decreased MAP. This effect may be caused by the very low initial AP for some topics, which is reflected in the low GMAP and results in expanding the query from noisy documents.

Also, the average document length (in terms) in the Hindi collection is much higher than for the other collections (cf. Table II). This might mean that query expansion could have less effect for longer documents, because more (poten-tially non-relevant) context from the document is considered for the feedback term extraction. The converse argument should also be true: less indexing terms and/or smaller documents provide a closer, more limited context for a better term extraction. Kwok and M. Chan [1998] explored a similar idea: They explore word co-occurrence in small windows of text for expanding short queries.

Adapting the number of terms for BRF typically further decreases perfor-mance values compared to the corresponding baseline experiment. Sometimes the MAP and precision at 10 documents are slightly improved.

A careful analysis of the feedback term selection and retrieval process re-vealed no obvious inconsistencies in the retrieval system used. The Hindi collection has the second highest total number of relevant documents (3,436 relevant documents, see Table III). However, there are several Hindi topics with zero relevant assessed documents, that is, 12 out of 50 topics have no rel-evant documents in the Hindi document collection. Six other topics have at least one but less than 10 relevant documents. This reduces the total number of useful topics (e.g., for significance testing) and introduces topics for which a performance increase with BRF is less likely, that is, when D = 10, some non-relevant documents are selected for blind relevance feedback. In compari-son, for all English topics there are more than 10 documents were assessed as relevant.

To further investigate the cause of this performance drop, two native Hindi speakers were asked to check retrieval log files generated on the Hindi data containing the all query terms and feedback terms with additional logged infor-mation (term frequency, id f , etc.). Neither identified any regular abnormalities or inconsistencies for the Hindi topics in general or for the badly performing topics.

Additional experiments were conducted to find out if spelling errors or ortho-graphic variants caused worse performance. Sometimes variant words are as-sociated with a high TSV, but do not contribute to finding relevant documents. For example, spelling errors occur rarely but will be assigned a high TSV due to ahigh id f factor. This will result in a top ranking for these terms which means that documents containing these spelling errors, which are not necessarily rel-evant, will obtain a high rank. To limit the effect of these cases, feedback terms all experiments using term filtering, MAP was slightly lower compared to not using BRF. A similar effect is observed for errors introduced by optical charac-ter recognition [Lam-Adesina and Jones 2006].

Experiments with the FIRE data described by participants give no clear in-dication why query expansion for Hindi should result in lower performance. Most participants did not apply BRF or used it in a different experimental setup. Additional experiments on the FIRE 2010 test set did not show similar results for Hindi, that is, query expansion for Hindi usually improved MAP for similar experiments [Leveling et al. 2010]. Hence, the high number of FIRE 2008 topics with zero or few relevant documents seems to prohibit obtaining meaningful results for IR experiments with query expansion. 5.4 Marathi Results Results for the monolingual IR experiments on the Marathi FIRE document collection are shown in Table X. Retrieval on 5-prefixes in combination with BRF returns the best performance for most retrieval measures: the highest number of relevant documents (1061 out of 1095 relevant documents, +20%), MAP 0.4253 MAP (+71%, +18% absolute increase), and 0.4340 P@10. GMAP is highest for 5-prefixes alone (0.2301, +90%).

The corpus-based stemmer performs significantly better than the word in-dexing baseline (+ 45% MAP). Query expansion increases MAP in general, but can decrease MAP for overlapping 3-grams. In contrast, adapting the number of BRF terms significantly increases the MAP (M N3QE vs. M N3QE ii ). Adapt-ing the number of feedback terms also tends to increase retrieval measures for n -prefixes and CVC variants. 6. CONCLUSIONS AND OUTLOOK This article presented monolingual IR experiments on the FIRE document collections in English, Bengali, Hindi, and Marathi. In particular, language-independent corpus-based stemming, sub-word indexing with n -grams, n -prefixes and CVC, and BRF on sub-words have been investigated in more than 140 retrieval experiments.

The highest MAP for the official FIRE 2008 experiments reported by the participants is 0.5572 MAP for English [Udupa et al. 2008], 0.4719 MAP for Bengali [Dolamic and Savoy 2008], 0.3487 MAP for Hindi [McNamee 2008], and 0.4575 MAP for Marathi [Dolamic and Savoy 2008]. The results for Bengali and Marathi were obtained by additionally using the narrative (N) part of the topics to formulate queries. In comparison, the best MAP for the experiments described in this article are 0.5832 for English, 0.4251 for Bengali, 0.2704 for Hindi, and 0.4253 for Marathi.

The corpus-based stemming approach produced significantly better results than the baseline of indexing words. It provides a knowledge-light baseline for IR in languages which have few resources.

Different methods perform best for different languages. Sub-word indexing produced significantly better results compared to the word indexing baseline and can achieve performance similar to stemming. Word prefixes of length 4 or 5 performed typically best for the Indian languages. However, in combina-tion with query expansion based on BRF, n -prefixes typically perform best for Indian languages and outperform the corpus-based stemming approach. These results confirm results reported by McNamee et al. [2009] for word-internal n -grams and word prefixes for European and Indian languages.

Blind relevance feedback increases MAP in most cases, but query expansion for Hindi mostly reduced IR performance, the number of relevant and retrieved documents, MAP, GMAP, and initial precision. However, additional IR exper-iments on the FIRE 2010 collection showed that query expansion for Hindi typically increases MAP compared to experiments without BRF.

Adapting the number of feedback terms depending on the vocabulary size showed a positive trend that retrieval effectiveness increases when more feed-back terms are used for larger vocabularies. This can be observed for exper-iments across languages (e.g., languages with a richer morphology) and for experiments employing multiple indexing units per word form (e.g., sub-words). The assumption that the number of BRF terms should be increased relative to changes in the indexed vocabulary is confirmed by the trend that MAP is mostly slightly higher for experiments on more and smaller indexing units (e.g., n -grams and CVC). Note that also the reverse assumption may be true: if more terms are indexed, for example, unstemmed word forms or all words with-out stopword removal, BRF may be likely to return morphological variants of the query terms or high-frequency words such as semi-stopwords. In order to improve performance, a larger set of relevance feedback terms in comparison with retrieval on indexed stems may be required to include more morphological variants of the same word and additional terms lowering the effects of semi-stopwords in the set of feedback terms. This can be seen as a problem similar to document length normalization: some IR models include a document length normalization factor to compensate for short and long documents. If sub-words are indexed, the document length normalization will also compensate for the generally increased document length. However, a similar factor for adjusting the number of BRF terms, compensating for the changes in the number of in-dex terms for different languages or caused by different indexing units, has not yet been introduced.

Future work will continue investigating indexing techniques and BRF for different languages. The stemmer implementation will be extended to become a more advanced morphological analysis tool, for example, by supporting prefix removal, internal vowel mutations, and determining morphological signatures or paradigms. For the IR experiments in this article, a fixed set of 50 suffixes was used for stemming. A more advanced approach will be to determine the best cut-off point for the suffix candidate list dynamically. An improved version of the stemmer might also ignore proper nouns in the document collection.
Further experiments on CVC indexing will be performed. CVC has been used to provide a robust indexing method (e.g., for speech transcripts). In the experiments described in this paper, all resources have been preprocessed and normalized, possibly decreasing the effect of CVC indexing. Additional experi-ments shall investigate performance differences between glyph-based CVC in-dexing and CVC indexing on phonetic transcriptions of Indian or Asian text.
Finally, different sub-word indexing techniques can be combined to improve retrieval effectiveness. For example, CVC indexing will be combined with in-dexing stems to obtain a higher MAP. Furthermore, the BM25 parameters ( b , k ,and k 3 ) should be optimized for retrieval on sub-words, and improved re-trieval models on sub-word indexing should be researched.

The blind relevance feedback experiments are based on expanding queries with a conservative number of terms (opposed to a massive query expansion). A relation between the number of relevance feedback terms and the type of indexing unit or indexed vocabulary size seems to be indicated. However, the relation might not be linear and it might not be the same for each language. Further retrieval experiments will explore the optimum number of feedback terms for different languages and types of indexing units.

