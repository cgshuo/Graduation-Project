 LinkedIn dynamically delivers update activities from a user X  X  inter-personal network to more than 300 million members in the person-alized feed that ranks activities according their  X  X elevance X  to the user. This paper discloses the implementation details behind this personalized feed system at LinkedIn which can not be found from related work, and addresses the scalability and data sparsity chal-lenges for deploying the system online. More specifically, we focus on the personalization models by generating three kinds of affinity scores: Viewer-ActivityType Affinity, Viewer-Actor Affinity, and Viewer-Actor-ActivityType Affinity. Extensive experiments based on online bucket tests (A/B experiments) and offline evaluation il-lustrate the effect of our personalization models in LinkedIn feed. H.4 [ Information Systems Applications ]: Miscellaneous Personalization; Feed Relevance; Large Scale Learning
More than 300 million people participate on LinkedIn 1 . By in-troducing the feed function, LinkedIn dynamically delivers update activities from a user X  X  interpersonal network, ensuring a user al-ways has fresh content to digest at login. Popular update activities include  X  X ember shares articles",  X  X ompany posts jobs",  X  X ember connects to member",  X  X ember likes another activity", leading to a classification of update activities as (actor, verb, object) triplets.
Due to the large volume of activities in feeds and the fact that the users have limited time to interact with their social network, many users experience information overload. To ensure delivering mean-ingful content to the user, LinkedIn has introduced a personalized feed that ranks activities according their  X  X elevance X  to the user. https://press.linkedin.com/site-resources/news-releases/2015/linkedin-announces-fourth-quarter-and-full-year-2014-results c  X 
Users can play two roles simultaneously in LinkedIn X  X  feed: ac-tors who are users that produce feed activities and viewers who are users that consume feed activities. The actor label also in-cludes other content producer entities such as companies, groups, schools, publishing channels, etc. Classic research work in person-alized feed recommendation represents and synthesizes a viewer X  X  profile from three aspects [13, 5]: the viewer-to-actor relation-ship strength, the correlation of activity content to viewer inter-ests, and the underlying social network. However, personalizing the LinkedIn feed brings new challenges because of the following reasons.  X  Scalability : Given the vast amount of users who visit LinkedIn  X  Data Sparsity : Not all LinkedIn members have significant his-
This paper describes our experiences in addressing these chal-lenges at LinkedIn and our work on the personalized production feed. Our previous work [4] has already shown that a simple feed ranking model that considers activity freshness, feed diversity, and viewer-actor connection relationships significantly outperforms the time feed (reverse chronological ordering of feed activities) and ranking by social popularity in terms of click-through rate (CTR)  X  the probability of a viewer clicks on an activity. In this paper, we describe our continued modeling efforts on the LinkedIn feed with a focus on personalized models.

We consider three types of signals for personalization in this paper: a) Viewer-ActivityType Affinity that models how likely a viewer tends to interact with an activity type, e.g. does an individ-ual working in IT industry like to click on job recommendations? b) Viewer-Actor Affinity which models how likely a viewer tends to interact with an actor. Note that although people tend to interact more with their close friends, sometimes they also like to inter-act with other types of actors, such as influencers (e.g. CEO of a company), big companies, or good publishing channels, etc. c) Viewer-Actor-ActivityType affinity which is the most granular sig-nal that models the three-way interactions among viewer, actor and the activity type.

Given the challenge of data sparsity, often simply using users X  past interactions in LinkedIn feed is not good enough. Therefore in this paper, we apply the feature-based approach which contains thousands of cold-start features from peoples X  profiles to model the above three affinity signals. Our experimentation in produc-tion shows this approach works pretty well in terms of CTR perfor-mance, however it raises a scalability challenge as described above: Scoring a sophisticated model with many features for a large scale of candidate activities in real-time with low latency might be tech-nically infeasible.

To address such scalability concern we divide our feature space into two parts: For features that are more dynamic, e.g. time of the day, they still remain in the online scoring system. For the fea-tures that are more stable and do not change rapidly over time, e.g. the three affinity scores mentioned above, we pre-generate them in Hadoop offline and then push them to production periodically. The online scoring system only needs to query by the viewer ID and ob-tain these scores for each (actor, activity-type) pair; no additional scoring needs to be done for generating these scores online, which saves a lot of computational time.

Though ideally the three affinity scores should be jointly trained, it is actually a significant challenge due to the high dimensionality of the parameter space and sparsity of the data. In this paper, we instead adopted a layman X  X  approach by modeling them indepen-dently: We train the Viewer-ActivityType affinity first since it has the richest data. Then, the learned Viewer-ActivityType affinity is treated as a single compound feature and is fixed in the downstream actor-level affinity training.
 Contributions: In this paper, we make the following contributions:
Personalized feeds attracted more user attention compared to the chronologically ordered feed lists [6, 7] or the global relevance or-dered feeds [4]. Hence major social networking sites including Facebook and LinkedIn provide users the personalized News feed as the main portal [1].

Early research in personalized feed recommendation is to rank homogeneous tweet feeds in Twitter [12, 2, 11, 13, 16, 26, 22, 10]. This line of work is essentially close to the earlier person-alized news article recommendation work [14], except that they used additional social network features like social voting, social tie strength etc. to model the activity relevance. They provided hints on how various features result in various user preferences to the Tweet feeds. For example, [12] reported that content sources, topic interest of users, and social voting on items are three major con-siderations corresponding to user interests; [11] examined thread length, topic relevance and social tie-strength contribute to the rel-evance. To implement a personalized recommendation system, [2, 16, 26, 22] enriched user profiles with their activities, text informa-tion of tweets and their neighbors through collaborative filtering, and [10] produced different rankers for different sub-communities of a user X  X  social network, where these rankers are described as top-ics so that the user can rank his/her social feeds by specific topics.
Researchers also studied the personalized recommendation for feeds with heterogeneous activity types [17, 25, 6, 7, 8, 28]. As dif-ferent activity types support different kinds of actions (e.g.,  X  X hare",  X  X omment" on activities), some work leveraged user-action inter-ests in the relevance of feed activities [17, 7, 6]. Researchers also investigated the personalized recommendation for heterogeneous enterprise network activity streams [19, 20]. They concluded that the activity stream based user profile is more productive than entity-based user profile for personalizing the stream.

All the above work paved the way for our studies in LinkedIn feed, enlightening our feature exploration and design. Our person-alization efforts in computing viewer X  X  affinity scores at activity type level and actor level essentially belong to user-to-content re-lationships and user-to-user relationships [5]. However, the above work has not been evaluated on top of large-scale production sys-tems. Instead, we always stick to the feasibility of deploying in production when planning personalization models.

Related work on top of LinkedIn feed includes our earlier work [4] and [21]. In [4], we presented an overview of the end-to-end feed recommendation system in LinkedIn, focusing on the infrastruc-ture and generic modeling framework. In [21], various machine learning techniques including linear models on features and latent factor models (matrix factorization and tensor factorization) were experimented in LinkedIn feed data, irregardless of the online de-ployment.

The novelty of this paper is to present the end-to-end personal-ization efforts on LinkedIn production feed and online bucket test results. Our product has been deployed in LinkedIn homepage to serve more than 300 million members for more than one year. One effort of this paper is to disclose the implementation details behind this real system, which can not be found from related work.
In this section we give a brief overview of the LinkedIn feed and show some interesting characteristics of user behaviors on the LinkedIn feed. Beginning by introducing the LinkedIn feed, we show how different users consume LinkedIn content and interact with other users in different ways. The insights that we gain in this section motivate our personalization models that are developed in the following sections.
Every activity in LinkedIn feed is represented as the triple: (ac-tor, verb, object). Accordingly, the type of an activity, named as activity type , is a triple of (actor type, verb type, object type). Ac-tor types include member, company, school, service, channel. Verb types are comment, connect, join, like, profile change, job change etc. Object types are article, job, member, picture etc. Various com-binations of them consist of around 50 activity types on Linked feed. For example, member connects to member, company pub-lishes article, and member updates the profile picture. More details about the taxonomy of LinkedIn feed activities can be found in [4].
Given a viewer, LinkedIn feed displays the activities that hap-pened in the professional network of the viewer, such as activities done by the user X  X  connections, activities done by the companies or the influencers followed by the viewer, and the news articles that the viewer would be interested in. The goal of LinkedIn feed is to provide a personalized activity stream for each viewer, and there can be many metrics to quantify how good the feed is, such as how often the viewer clicks, how fresh the feed is, or how diverse the feed is [4]. In this paper, among various metrics, we focus on click-through rate (CTR) because click is the most immediate user reaction and is straighforward to quantify.

In the rest of this section, we study how viewers tend to click on activities from the log data. We focus on how the CTR is af-fected by two different relationships between the viewer and the activity. First is the activity type analysis about how viewers have different levels of interest to different types of activities. Second is the viewer-actor analysis about how viewers interact with activities depending on who the actor is.
Viewers X  responses to different activity types vary for two rea-sons.  X  Global bias . Some activity types are inherently more popular  X  Personal preference . Individual viewers have different level This analysis suggests that, to personalize feed, not only should activity type be used as a feature to remove global bias, but also we must consider individaual affinities to different activity types.
Whether or not they have thousands of contacts in LinkedIn, peo-ple are only able to keep up close relationships with a handful of people. Here we study how viewers respond to different actors de-pending on a few notable features of the viewer-actor pairs.
We look at the past interaction features (e.g., number of past clicks, number of past impressions etc.) between viewer and ac-tor. Figures 3a and 3b illustrate the CTR between viewer and actor as a function of their number of past clicks/impressions. The plots are generated based on a set of random users for a few days on both mobile and desktop platforms. For both platforms, more past clicks between viewer and actor generally translate to higher CTR. However, for impressions, we observe different behaviors. On mo-bile, a viewer appears to be more tolerant to a repeat showing of the same actor, but on desktop, we observe CTR drop if the same actor showing up multiple times.
Considering the past interaction features are not ubiquitous be-tween viewer and actor, we also look at other features that are al-ways available. Examples of such features include the profile of the viewer and the actor, the interactions in other LinkedIn ser-vices outside the feed, and social network features like the number of common connections. In the following we take the number of viewers X  connections who have clicked on the actor in the past as the feature for analysis. This feature intuitively makes sense: for example, the more of your connections commented on an article, the more likely you would click on it (Homophily Principle). In fact, researchers have proved that using the connections X  responses can improve cold-start recommendation [24]. Figure 4 shows how the CTR between viewer and actor on 4 different activity types pos-itively correlates to the number of the viewer X  X  connections who have clicked on the same actor.

The above two features are just the tip of the iceberg. There are numerous features discoverable in LinkedIn for user-to-user rela-tionships, laying the foundations for the personalization between viewers and actors.
Our data analyses uncover that in LinkedIn feed, not only does the CTR vary on various activity types, but also the CTR should be personalized by actors. In the following sections, we model two kinds of personalized affinities for LinkedIn feed: one is Viewer-ActivityType Affinity that manifests the viewer X  X  topics of interests at the activity type level, and the other is Viewer-Actor Affinity that manifests the viewer X  X  preference to the activity producer. Our personalization strategies are in line with findings of [13] that the source of the activities and the recipient X  X  topics of interest are two major considerations which correspond to user interest.
There are about 50 different activity types 2 in LinkedIn feed. In this section, our objective is to compute an affinity score for each
This number varies slightly from time to time as LinkedIn keeps producing new types or retiring old types. Figure 2: Scatter plot of clicks from 500 random viewers on two different activity types. pair of viewer i and activity type k , which manifests the viewer X  X  topics of interests at the activity type level. In total, we need com-pute around 300M x 50 affinity scores. We leverage CTR to ap-proximate the affinity, which is defined as: Definition 1. Viewer-ActivityType Affinity  X  ik , the likelihood score of viewer i clicks on the activity type k in LinkedIn feed.
We describe how we compute the estimator  X   X  ik for  X  are given a set of historical activity impressions { e = ( y,i,k,m ) } where y is viewer i  X  X  click to impression m of activity type k . A Figure 4: Relations between the relative CTR lift and the number of viewer X  X  connections who have clicked on the same actor. naive approach to get  X   X  ik would be to use the CTR of viewer i for type k from a set of historical activity, i.e., we let  X   X  where S ik is the number of clicks and M ik is the number of im-pressions from the viewer i to the activities of type k . However, this CTR is reliable only for large sample sizes, which is not true for computing affinity between viewer and activity type where the majority of viewers are light users with only a few historical im-pressions. Hence we aim to estimate  X  ik by applying smoothing via hierarchical probabilistic models.
Denoting by p e the true CTR for activity impression e with co-variates x e , we assume the following decomposition: where b e is a probability estimate computed from a baseline model which is a function of covariates x e , and g ik is modeled as the CTR correction factor which is only a function of viewer and activity type pair ( i,k ) and does not depend on covariates x e . Logistic re-gression is a popular choice of the covariate-based baseline models in the literature [27], and is also applied in this paper: The covariates x e include features that can remove position bias, remove user interface bias, profile viewers, and profile activities etc. Since the baseline model is based on features at the impres-sion level, we have sufficient statistics to estimate b e regression.

Now, given the baseline model, we have the expected number of clicks: We assume that S ik | E ik ,g ik follows Gamma-Poission distribution S ik | E ik ,g ik  X  Poisson ( E ik g ik ) ,g ik  X  Gamma (1 , X  ) , since Pois-son assumption is reasonable and has been widely used in rare event estimations [15].

As the correction factor, intuitively the value of g ik depends on the O/E (observed-to-expected) ratio S ik /E ik : if S ik baseline model under-estimates the CTR, so g ik &gt; 1 can force the expected number of clicks equals to the numebr of observed clicks; if S ik /E ik = 1 , g ik = 1 as no need to correct; if S ik g ik &lt; 1 as the baseline model over-estimates the CTR. Accord-ing to the Gamma-Poisson conjugate property, the posterior of g also follows the Gamma distribution with mean  X  + S ik  X  + E of Gamma distribution:
Can we directly use  X  p e to model the personalized affinity  X  The answer is no because  X  p e is the estimated CTR binded to activ-ity impression e , yet by definition the Viewer-ActivityType Affinity  X  ik is impression independent. We extract a subset of the covari-ates x e by only keeping ( i,k ) -dependent features and rename it as x i,k . Finally, the affinity  X  ik is modeled as:
There are multiple advantanges of modeling  X  ik by combin-ing the CTR correction factor with the feature-based CTR. First is that, as we described above, CTR may not be reliable when data is sparse. Smoothing by Gamma-Poisson model mitigates the issues with data sparsity. Second, CTR may contain biases for several reasons: the same activity at different positions attracts different CTRs; the content information of an activity also affects the CTR. We use covariates x e to address the effect coming from these fac-tors. Third, it is impractical to discover all possible variates of the CTR function. Computing a baseline model based on covariates x first and then using g ik to model the residue inherited from data is thus easier to implement.
Many trail-blazing work has studied the strength of social ties in social media for many years [18]. As one kind of social tie strengths, we define Definition 2. Viewer-Actor Affinity  X  ij , the likelihood score of viewer i clicks on any activity produced by actor j in LinkedIn feed.
The Viewer-Actor Affinity manifests the relationships between the feed recipient (viewer) and activity producer (actor), which have played an important role in scoring feed activity relevance [11]. However, what are the remarkable characteristics of Viewer-Actor Affinity in LinkedIn feed?
Like other commercial social networks, LinkedIn provides a scal-able feed for more than 300 millions members to interact with their connections. Given a viewer can see more actors than activity types in feed, the dimension of the Viewer-Actor Affinity is about 40  X  50 times larger than the Viewer-ActivityType affinity on av-erage. Even the number of interactions generated by some viewers may be large, few of them impact a particular actor, making the actor-level interaction data sparse. Due to the absence of activities (zero or a few) between viewer and actor, rate estimates are often unreliable and noisy [3].

Another challenge of Viewer-Actor Affinity is the viewer only interacted with a tiny fraction of actors in the past, comparing to hundreds of millions of LinkedIn entities the viewer can interact. For example, in a one-week testing window, we observed that around half of actors are new to viewers (no past interactions). Hence the Viewer-Actor Affinity heavily suffers from the cold-start problem. We have designed Viewer-ActivityType Affinity and Viewer-Actor Affinity independently. However, an activity is interesting to the viewer often because of both. For example, assuming you like read-ing articles in general, you may not like reading articles published by sponsors or shared by recruiters. We denote by Definition 3. Viewer-Actor-ActivityType affinity  X  ijk , the likeli-hood score of viewer i clicks on the activity type k produced by actor j in LinkedIn feed.

The Viewer-Actor-ActivityType affinity can be seen as a context-aware affinity between viewer and actor, where the context is activ-ity type. It provides a finer-grained affinity between viewer and ac-tor. Undoubtedly, the interaction data of Viewer-Actor-ActivityType are sparser than Viewer-Actor and increase the difficulty of model-ing.
Modeling Viewer-Actor Affinities using a counting model like we do for Viewer-ActivityType Affinity is theoretically sound yet heavily suffers from the data sparsity, since the data intensity be-tween viewer and actor is about 40  X  50 times less than the data in-tensity between viewer and activity type. Modeling zero or few in-teractions is unreliable and noisy [3]. Hence, we adopt the feature-based regression to model Viewer-Actor Affinities due to simplic-ity.

Given an activity t from viewer i to actor j on activity type k , to predict the response Y which is 1 if there is a click and 0 other-wise, we use logistic regression where we compute a linear product between a coefficient vector  X  and a feature vector X ijkt where  X  is the sigmoid function.

We can exclusively classify features in the feature vector X into three parts: Viewer-Actor features X ij , Viewer-Actor-ActivityType features X ijk , and other activity-dependent features X t age of the activity and the type of activity which vary on activities and have to be scored online. Though X ijk can be a subset of X conceptually, we take it out of X ij for clarity.

We denote the part of  X  for X ij by  X  ij , the part of  X  for X by  X  ijk and the part of  X  for X t by  X  t . Accordingly, by linearity of inner product, the score  X X ijkt can be decomposed into three parts:
Since X ijk is about 40  X  50 times sparser than X ij , it may not exist for the activity t . Instead, X ij always exists given the relations between two users are ubiquitous. Our strategy is, by carefully de-signing indicator features, we can differentiate two scenarios: X exists and X ijk does not exists. If X ijk exists, we name  X   X   X 
X ij +  X  ijk X ijk as the Viewer-Actor-ActivityType Affinity. No matter X ijk exists or not, we always name  X   X  ij =  X  ij X Viewer-Actor Affinity.
When modeling Viewer-Actor Affinities, relation and past in-teractions between viewer and actor have been shown to be use-ful [29]. In this subsection, we design a set of past interaction features as  X  X arm-start" features and a set of relation features as  X  X old-start" features in order to overcome the data sparsity chal-lenge.
 Warm-start features: Two nature past interactions from the viewer to the actor are the number of past actions (e..g, clicks, shares, likes, comments, etc.), and the number of past impressions in LinkedIn. Intuitively, more past actions and less past impressions, higher CTR in the future, as shown in Figures 3a and 3b. To enrich the past in-teraction dynamics, we count the past interactions using multiple time windows. To enrich the past interaction intensity, we extend the time window up to half a year ago. Diverse and long past inter-actions reduce the data sparsity yet increase the data volume to be processed. This partially leads to our decision of offline computing the affiniy scores later.

The past interaction features can be available for either viewer-actor pairs or viewer-actor-activitytype triples. For example, the number of clicks between viewer and actor in the past 3 months is one feature; and the number of clicks between viewer and actor on  X  X rticles shared by the actor X  in the past 3 months is another feature.
 Cold-start features: The relationships between viewers and actors should be ubiquitous, not limited to viewer-actor pairs with past interactions. Considering the large fraction of new actors who just connected to viewers, we look for cold-start features that enrich relations between viewer and actor.

There are two major sources of cold-start features. One is from the structured member profile where we extract thousands of profile features including education, location, job experiences, and work-related skills etc. We then create millions of binary features by interacting viewer X  X  profile features with actor X  X  profile features. For textual properties like member summaries, we generate binary features by using bag-of-words representations. Top N features are selected by ordering the features using Mutual Information. As shown in Figure 5, we set N = 2 , 000 as the relative CTR lift converges after 2,000 features.

The other source is from the social network underlying the pair of viewer and actor. Graph feature examples considered by us in-
Figure 5: Relative CTR lift over Top N member profile features. clude the number of the viewer X  X  neighbors that took actions on the same actor, the number of common friends between viewer and actor, etc.

For simplicity, we only consider cold-start features for viewer-actor pairs, not viewer-actor-activitytype triples.
 Training large scale logistic regression: From the training data Y and X ijkt that we collect, we aim to learn  X  using logistic re-gression. The challenge here is the massive scale of regression, since our training data have billions of activities and we also con-sider thousands of features for each activity. It is thus not surpris-ing that our regression problem does not fit in a single machine. To overcome this scalability challenge, we solve logistic regression in a distributed fashion, by employing the Alternating Direction Method of Multipliers (ADMM) [9]. ADMM partitions the data and learns a local model from each partition, and then it aggregates all models from partitions and sends back the aggregation results to individual partitions. For more details about how we use ADMM for our regression, refer to [4]. In Section 4 and Section 5, we have modeled Viewer-ActivityType Affinity as the CTR estimate and Viewer-Actor Affinities as the par-tial scores of the CTR estimate respectively. To collectively model all the affinity scores together, we take the following approach: First, we compute Viewer-ActivityType Affinity alone. Then we use Viewer-ActivityType Affinity as one of the baseline features in the joint training of the Viewer-Actor Affinities and the other activity-dependent coefficients. Mathematically, the relevance score used in ranking for viewer i , actor j , activity type k , and activity t , with monotonic logit transformation removed, can be written as where X t is the feature vector that corresponds to the more dy-namic activity-dependent features,  X  ik is the Viewer-ActivityType Affinity,  X  ij is the Viewer-Actor Affinity,  X  ijk is the Viewer-Actor-ActivityType Affinity, and  X  t ,  X  ik are the learned coefficients. Note Table 1: Offline analysis on the frequency of updating Viewer-Actor Affinities reward lift at daily update hourly update 2-day update that  X  ijk or  X  ij do not have coefficients attached simply because these two are partial results computed from the same model (see Equation (6)). Also, when there is no data to support triple ( i,j,k ) such that  X  ijk does not exist, we fall back to  X  ij .

Ideally the affinities and  X  should be trained jointly. However, due to the complexity of each affinity scores, high-dimensional fea-ture spaces and data sparsity, we chose this simple yet effective approach for faster model training process. Also, since Viewer-ActivityType affinity has the richest data for warm-start, we choose to model it independently first and treat it as a single compound feature in the model for training Viewer-Actor Affinities.
How to determine the frequency of updating affinities is more an art than a science. We conducted offline analysis in Table 1 for Viewer-Actor Affinities using one week data, and found that in-creasing the updating frequency from daily to hourly did not change the reward at position 1 [23] significantly (only +0.1% lift). Thus, we choose to update the affinity scores daily in our production pipelines.

Figure 6 depicts the online deployment framework for affinities in LinkedIn feed. The flow starts by the URL request from a viewer i . LinkedIn feed service first fetches all the candidate activities from viewer i  X  X  interpersonal social network. Our scoring system then computes the relevance score for each activity and rank activ-ities based on these scores. For each activity t with actor j and ac-tivity type k , the online scoring system obtains activity-dependent features X t , and also fetches affinity scores from Voldemort stores which support distributed key-value storage and queries. The affin-ity scores are pre-computed offline in Hadoop and updated on the Voldemort store daily. The scoring system finally applies Equation (7) to score and return the top-ranked results to show in people X  X  feed.
 Every day we compute tens of billions of Viewer-ActivityType Affinities for all LinkedIn members and all possible activity types (300 millions times 50), and also tens of billions of Viewer-Actor Affinities for both desktop and phone platforms. Note that we only prepare Viewer-Actor Affinities for those pairs with interactions in the past half a year. This strategy largely reduces the dimen-sion of Viewer-Actor Affinities; otherwise, even the offline pre-computation is not feasible. Furthermore, for heavy viewers who interacted with hundreds of thousands of actors, we only store top K Viewer-Actor Affinities in the Voldemort store after offline com-putation. This strategy avoids the latency timeout when serving heavy viewers online. We set K = 10 , 000 such that it can keep the vast majority of the affinity scores and only lost 0 . 08% reward at position 1 [23] in the offline analysis for one week data. Online A/B tests: In LinkedIn, bucket tests (A/B tests) are con-ducted on a regular basis whenever we believe that we have a better model compared to existing models online (typically based on of-fline analysis). Once we decide to start testing a model, typically http://www.project-voldemort.com/voldemort/ Figure 7: Online CTR lift by Viewer-ActivityType Affinity on desktop. we launch it on 2%  X  3% random LinkedIn members. We ob-serve the performance of the model for about two weeks before making a decision to ramp the model to a larger population. Most importantly, we consider engagement, typically measured via CTR (click-through rate), as the evaluation metric. In addition, we also consider other metrics such as freshness of the feed based on the model, diversity of the feed, how many times items are repeated to a user etc. as well in making ramp decisions. However, for the purposes of this paper, we only report CTR metrics. Most of the results reported below are from online A/B tests with offline evalu-ations when appropriate.
 Offline replay analysis: In LinkedIn, after we train a model, we need to evaluate the model offline before deploying it in produc-tion. For this, we use a replay methodology for unbiased offline evaluation of online serving schemes [23], where the relative re-wards obtained from two different models are typically indicative of which model would perform better in production.

When launching a new model, we also retrain the model with the recent data. This is because, often new activity types are introduced on the feed and sometimes some types are retired. Typically, we retrain both the baseline model and the new model with recent data, and we then evaluate both models offline to decide whether or not the new model is launchable.

We do not always replace the baseline model in production by the baseline model retrained on the recent data, unless we believe retraining itself will create a big performance gap. Therefore, in some of the A/B experiments below, it is possible that the baseline model was not retrained on recent data but the new model was re-trained. In such situations, we also provide the offline comparisons.
In this section, we show results for the models that were launched to improve personalization on desktop.
We tested Viewer-ActivityType Affinity since late 2013. The baseline model consists of activity-dependent features such as age of an activity, type of an activity etc. and some raw connection strength features between a viewer and an actor. The affinity model applied the Viewer-ActivityType Affinity as a new feature on top of the baseline model. The A/B tests during 10 days between them are shown in Figure 7. The x-axis shows the day index and the y-axis shows the relative CTR lift of the affinity model comparing to the baseline model. Overall, the affinity model achieved a daily CTR lift of about +7.0%. Two models were trained using the same data and tested over the same percentage of LinkedIn members (2%). Hence the comparison is fair except for the bucket bias 4 We started testing a model based on Viewer-Actor Affinity since May 2014. Now, the Viewer-ActivityType affinity model in the previous section 7.2.1 becomes the baseline model. The compared affinity model applied the Viewer-Actor Affinity as a new feature on top of the baseline model. The A/B tests between them in Fig-ure 8 showed a CTR lift of about +2.9% on average.

One may wonder why we do not put comparisons in Figure 7 and Figure 8 together in a single plot. They are not numerically comparable simply because two bucket tests were conducted at different time. By the time we started the new bucket tests in May 2014, the baseline model had changed significantly from the Viewer-ActivityType affinity in the previous section 7.2.1. For in-stance, the new baseline had a few new activity type features, and LinkedIn feed had moved to a paradigm where we always served activities using a relevance model rather than a mixture of rele-vance feed and real-time feed. However, each bucket test alone is still meaningful because for each bucket test, two compared models have the same test settings and product environment.

Considering the Viewer-Actor Affinity model was trained on newer data, we also have the offline comparison results where both models
Completely removing the bucket bias is impossible because there will always be  X  X oise X  inherent to the populations since they X  X e simply not the same people.
Figure 8: Online CTR lift by Viewer-Actor Affinity on desktop. were trained and tested on the same data. Comparing to the base-line Viewer-ActivityType Affinity model, the Viewer-Actor Affin-ity model achieved +3.5% reward lift at position 1 for one week test data, where position 1 has the least position bias in offline replay analysis and is thus the most reliable [23]. We tested Viewer-Actor-ActivityType Affinity since June 2014. Similarly there were some product design changes since June 2014 in LinkedIn, e.g., showing fresher content on the feed. Thus, we Figure 9: Online CTR lift by Viewer-Actor-ActivityType Affinity on desktop. only look at the comparions in a single bucket test. The base-line model is the Viewer-Actor affinity model in the previous sec-tion 7.2.2. The compared affinity model applied the Viewer-Actor-ActivityType Affinity as a new feature on top of the baseline model. The 10-day A/B tests between them in Figure 9 showed an average CTR lift of about +4.3% for each day. During the offline replay analysis where two models were trained and tested on the same data, we found that the Viewer-Actor-ActivityType Affinity model achieved +6.6% reward lift at position 1 for one week test data.
Experimental results on desktop are promising  X  we proved that the more granular the affinity, the higher the CTR through both on-line bucket tests and offline replay analysis. By treating affinities as a compound feature or partial scores of the final response pre-diction, we only introduced 3 additional arithmatic operations and 1 additional query to the online production, which contributed to less than 10% of online service time.
In this section, we show similar results on mobile. Because of the great successfulness of Viewer-Actor-ActivityType Affinity on desktop, we decided to migrate from Viewer-ActivityType Affin-ity to Viewer-Actor-ActivityType Affinity directly on mobile. So, mobile results of Viewer-Actor Affinity model are skipped. The comparison has been conducted during one week period in April 2014. The baseline model is the simple model without any affinities described in Section 7.2.1. The compared affinity model applied the Viewer-ActivityType Affinity as a new feature on top of the baseline model. Both models were trained on the same data so no need to additionally provide offline replay analysis. The A/B tests between them in Figure 10 showed a CTR lift of about +3% on average. Figure 10: Online CTR lift by Viewer-ActivityType Affinity on mobile.

The comparison was conducted during one week period in De-cember 2014. The baseline model is the Viewer-ActivityType Affin-ity model in the previous section 7.3.1. The compared affinity model applied the Viewer-Actor-ActivityType Affinity as a new feature on top of the baseline model. Both models were trained on the same data so no need to additionally provide offline replay analysis. The A/B tests between them in Figure 11 showed a CTR lift of around +10% on average.
We studied how to personalize LinkedIn feed in this paper, with a focus on affinity modeling. We generated three kinds of affinity scores offline: Viewer-ActivityType Affinity, Viewer-Actor Affin-ity, and Viewer-Actor-ActivityType Affinity. All of them are easy to compute, easy to scale, and easy to be deployed in production. We did extensive experiments based on online bucket tests (A/B tests) and offline evaluation to illustrate the effect of these affinities in LinkedIn feed.

Personalizing LinkedIn feed is an open-ended problem given the fact that millions of new members join LinkedIn every month around the world. Our initial study demonstrates that personaliza-tion of finer granularity achieves higher CTR, which motivates our future work as below. [1] https://www.facebook.com/notes/facebook/new-views-for-[2] F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user Figure 11: Online CTR lift by Viewer-Actor-ActivityType Affinity on mobile. [3] D. Agarwal, R. Agrawal, R. Khanna, and N. Kota.
 [4] D. Agarwal, B.-C. Chen, R. Gupta, J. Hartman, Q. He, [5] S. Berkovsky and J. Freyne. Network activity feed: finding [6] S. Berkovsky, J. Freyne, S. Kimani, and G. Smith. Selecting [7] S. Berkovsky, J. Freyne, and G. Smith. Personalized network [8] S. Bourke, M. P. O X  X ahony, R. Rafter, and B. Smyth.
 [9] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. [10] M. Burgess, A. Mazzia, E. Adar, and M. Cafarella.
 [11] J. Chen, R. Nairn, and E. H. Chi. Speak little and well: [12] J. Chen, R. Nairn, L. Nelson, M. Bernstein, and E. H. Chi. [13] K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. [14] W. Chu and S.-T. Park. Personalized recommendation on [15] W. DuMouchel and D. Pregibon. Empirical bayes screening [16] G. D. Francisci, A. Gionis, and C. Lucchese. From chatter to [17] J. Freyne, S. Berkovsky, E. M. Daly, and W. Geyer. Social [18] E. Gilbert and K. Karahalios. Predicting tie strength with [19] I. Guy, I. Ronen, and A. Raviv. Personalized activity streams: [20] I. Guy, T. Steier, M. Barnea, I. Ronen, and T. Daniel. [21] L. Hong, R. Bekkerman, J. Adler, and B. D. Davison. [22] L. Hong, A. S. Doumith, and B. D. Davison. Co-factorization [23] L. Li, W. Chu, J. Langford, and X. Wang. Unbiased offline [24] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King.
 [25] T. Paek, M. Gamon, S. Counts, D. M. Chickering, and [26] Y. Pan, F. Cong, K. Chen, and Y. Yu. Diffusion-aware [27] M. Richardson, E. Dominowska, and R. Ragno. Predicting [28] P.-H. Soh, Y.-C. Lin, and M.-S. Chen. Recommendation for [29] I. Uysal and W. B. Croft. User oriented tweet ranking: a
