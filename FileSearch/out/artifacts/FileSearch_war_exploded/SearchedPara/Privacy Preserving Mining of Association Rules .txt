
We present a framework for mining association rules from transactions consisting of categorical items where the data has been randomized to preserve privacy of individual trans-actions. While it is feasible to recover association rules and preserve privacy using a straightforward "uniform" random-ization, the discovered rules can unfortunately be exploited to find privacy breaches. We analyze the nature of privacy breaches "and propose a class of randomization operators that are much more effective than uniform randomization in limiting the breaches. We derive formulae for an unbiased support estimator and its variance, which allow us to re-cover itemset supports from randomized datasets, and show how to incorporate these formulae into mining algorithms. 
Finally, we present experimental results that validate the algorithm by applying it on real datasets. 
The explosive progress in networking, storage, and proces-sor technologies is resulting in an unprecedented amount of digitization of in.formation. It is estimated that the amount of information in the world is doubting every 20 months [20]. In concert with this dramatic and escalating increase in digital data, concerns about privacy of personal informa-tion have emerged globally [15] [17] [20] [24]. Privacy issues are further exacerbated now that the internet makes it easy for the new data to be automatically collected and added to databases [10] [13] [14] [27] [28] [29]. The concerns over massive collection of data are naturally extending to ana-lytic tools applied to data. Data mining, with its promise to efficiently discover valuable, non-obvious information from large databases, is particularly vulnerable to misuse [11] [16] [20] [23]. .An interesting new direction for data mining research is the development of techniques that incorporate privacy con-cerns [3]. The following question was raised in [7]: since the *Department of Computer Science Corner University, Ithaca, NY 14853, USA personal or classroom use is granted without fee provided that copies are permission and/or a fee. SIGKDD 02 Edmonton, Alberta, Canada 
Copyright 2002 ACM 1-58113-567-X/02/0007/...$5.00. primary task in data raining is the development of mod-els about aggregated data, can we develop accurate mod-els without access to precise information in individual data records? Specifically, they studied the technical feasibility of building accurate classification models using training data in which the sensitive numeric values in a user's record have been randomized so that the true values cannot be estimated with sufficient precision. Randomization is done using the statistical method of value distortion [12] that returns a value z, + r instead of ~, where r is a random value drawn from some distribution. They proposed a Bayesian proce-dure for correcting perturbed distributions and presented three algorithms for building accurate decision trees [9] [21] that rely on reconstructed distributions} In [2], the au-thors derived an Expectation Maximization (EM) algorithm for reconstructing distributions and proved that the EM al-gorithm converged to the maximum likelihood estimate of the original distribution based on the perturbed data. They also pointed out that the EM algorithm was in fact identical to the Bayesian reconstruction procedure in [7], except for an approximation (partitioning values into intervals) that was made by the latter. 
We continue the investigation of the use of randomization in developing privacy-preserving data mining techniques, and extend this line of inquiry along two dimensions:  X  categorical data instead of numerical data, and  X  association rule mining [4] instead of classification. 
We will focus on the task of finding frequent itemsets in association rule mining, which we briefly review next. 
Definition I. Suppose we have a set 27 of n items: 27 --{al,a2,... ,an}. Let T be a sequence of N transactions 
T = (ix, t2,... , tN) where each transaction ti is a subset of 27. Given an itemset A C Z, its support suppZ(A) is defined 
An itemset A C 27 is called frequent in 7" ff suppT(A) /&gt; % where I-is a user-defined parameter. We consider the following setting. Suppose we have a server and many clients. Each client has a set of items (e.g., 
Once we have reconstructed distributions, it is straightfor-ward to build classifiers that assume independence between attributes, such as Naive Bayes [19] . books or web pages or TV programs). The clients want the server to gather statistical information about associations among items, perhaps in order to provide recommendations to the clients. However, the clients do not want the server to know with certainty who has got which items. When a client sends its set of items to the server, it modifies the set according to some specific randomization policy. The server then gathers statistical in.formation from the modified sets of items (transactions) and recovers from it the actual associations. 
The following are the important results contained in this paper: 
There has been extensive research in the area of statistical databases motivated by the desire to provide statistical in-formation (sum, count, average, maximum, minimum, pth percentile, etc.) without compromising sensitive informa-tion about individuals (see surveys in [1] [22].) The pro-posed techniques can be broadly classified into query re-striction and data perturbation. The query restriction farn-ily includes restricting the size of query result, controlling the overlap amongst successive queries, keeping audit trail of all answered queries and constantly checking for possi-ble compromise, suppression of data cells of small size, and clustering entities into mutually exclusive atomic popula-tions. The perturbation family includes swapping values between records, replacing the original database by a sam-ple from the same distribution, adding noise to the values in the database, adding noise to the results of a query, and sampling the result of a query. There are negative results showing that the proposed techniques cannot satisfy the con-flicting objectives of providing high quality statistics and at the same time prevent exact or partial disclosure of individ-ual information [1]. 
The most relevant work from the statistical database lit-erature is the work by Warner [26], where he developed the "randomized response" method for survey results. The method deals with a single boolean attribute (e.g., drug ad-diction). The value of the attribute is retained with prob-ability p and flipped with probability 1 ,COp. Warner then derived equations for estimating the true value of queries such as COUNT (Age = 42 &amp; Drug Addiction = Yes). The approach we present in Section 2 can be viewed as a gener-alization of Warner's idea. 
Another related work is [25], where they consider the problem of mining association rules over data that is ver-tically partitioned across two sources, i.e, for each transac-tion, some of the items are in one source, and the rest in the other source. They use multi-party computation techniques for scalar products to be able to compute the support of an itemset (when the two subsets that together form the item-set are in different sources), without either source revealing exactly which transactions support a subset of the itemset. In contrast, we focus on preserving privacy when the data is horizontally partitioned, i.e., we want to preserve privacy for individual transactions, rather than between two data sources that each have a vertical slice. 
Related, but not directly relevant to our current work, is the problem of inducing decision trees over horizontally partitioned training data originating from sources who do not trust each other. In [16], each source first builds a lo-cal decision tree over its true data, and then swaps values amongst records in a leaf node of the tree to generate ran-domized training data. Another approach, presented in [18], does not use randomization, but makes use of cryptographic oblivious functions during tree construction to preserve pri-vacy of two data sources. 
A straightforward approach for randomizing transactions would be to generalize Warner's "randomized response" me-thod, described in Section 1.2. Before sending a transaction to the server, the client takes each item and with probabil-ity p replaces it by a new item not originally present in this transaction. Let us call this process uniform randomization. 
Estimating true (nonrandomized) support of an itemset is nontrivial even for uniform randomization. Randomized support of, say, a 3-itemset depends not only on its true support, but also on the supports of its subsets. Indeed, it is much more likely that only one or two of the items are inserted by chance than all three. So, almost all "false" oc-currences of the itemset are due to (and depend on) high subset supports. This requires estimating the supports of all subsets simultaneously. (The algorithm is similar to the algorithm presented in Section 4 for select-a-size random-ization, and the :formulae from Statements 1, 3 and 4 apply here as well.) For large values of p, most of the items in most randomized transactions will be "false", so we seem to have obtained a reasonable privacy protection. Also, if there are enough clients and transactions, then frequent itemsets will still be "visible", though less frequent than originally. For instance, after uniform randomization withp = 80%, an itemset of 3 items that originally occurred in 1% transac-tions will occur in about 1%  X  (0.2) s = 0.008% transactions, which is about 80 transactions per each million. The op-posite effect of "false" itemsets becoming more frequent is comparatively negligible if there are many possible items: for 10,000 items, the probability that, say, 10 randomly in-serted items contain a given 3-itemset is less than 10-r%. 
Unfortunately, this randomization has a problem. If we know that our 3-itemset escapes randomization in 80 per million transactions, and that it is unlikely to occur even once because of randomization, then every time we see it in a randomized transaction we know with near certainty of its presence in the nourandomized transaction. With even more certainty we will know that at least one item from this itemset is "true": as we have mentioned, a chance insertion of only one or two of the items is much more likely than of all three. In this case we can say that a privacy breach has occurred. .Although privacy is preserved on average, personal information leaks through uniform randomization information the server obtains from a randomized transac-not contain, or the randomized transaction size. We also do not attempt to control breaches that occur because the server knows some other information about items and clients besides the transactions. For example, the server may know some geographical or demographic data about the clients. 
Finally, in Definition 4, we only considered positive breaches, i.e., we know with high probability that an item was present in the original transaction. In some scenarios, being confi-dent that an item was notpresent in the original transaction may also be considered a privacy breach. erators are per-transaction because they apply the same randomization algorithm to each transaction independently. 
They are also item-invariant since they do not use any item-specific information (if we rename or reorder the items, the outcome probabilities will not be affected). for different nonrandomized sizes. Assume also that a par-tial support sl = supp~(A) approximates the corresponding prior probability P [#(t N A) = l]. Suppose we know the following prior probabilities: 
Notice that sl = s~ + --F s~-simply because bility of a 6 t given A C_ t': 
Thus, in order to prevent privacy breaches of level 50% as defined in Definition 4, we need to ensure that always we know any supports. Also, we may not have the luxury of setting "oversafe" randomization parameters because then we may not have enough data to perform a reasonably ac-curate support recovery. One way to achieve a compromise is to: 
Since So + = 0, the most privacy-challenging situations occur when so is small, that is, when our itemset A and its subsets are frequent. have the maximum possible support sm~(l, ra). The partial supports for such a test-itemset are computed from the cu-mulative supports ~z using Statement 4. By it and by (12), we have (l &gt; O) since there are (~) j-subsets in A. The values of s~" follow if we note that all~/~subsets of A, with a and without, appear equally frequently as t N A: 
While one can construct cases that are even more privacy-challenging (for example, if a E A occurs in a transaction every time any nonempty subset of A does), we found the above model (15) and (16) to be suf~ciently pessimistic on our datasets. randomization parameters p,~ and K,~ as follows. Given m, consider all cutoffs from K,~ = 3 to some K~x (usually this 
Km~x equals the maximum transaction size) and determine the smallest randomization levels pm(K,~) that satisfy (14). 
Then select (K,~, p,~) that gives the best discoverability (by computing the lowest discoverable supports, see Section 5.1). given a set of randomized transactions. Although we use the 
Apriori algorithm [5] to make the ideas concrete, the mod-ifications directly apply to any algorithm that uses Apriori candidate generation, i.e., to most current association dis-covery algorithms. = The key lattice property of supports used by Apr~ori is that, for any two itemsets A C B, the true support of A is equal to or larger than the true support of B. A simplified version of Apriori, given a (nonrandom-ized) transactions file and a minimum support Stain, works as follows: rithm so that now it reads the randomized dataset, computes partial supports of all candidate sets (for all nonxandomized transaction sizes) and recovers their pre~cted supports and sigmas using the formulae from Statement 3. However, for the predicted supports the lattice property is no longer true. 
It is quite likely that for an itemset that is slightly above minimum support and whose predicted support is also above minimum support, that one of its subsets will have predicted support below minimum support. So if we discard all candi-dates below minimum support for the purpose of candidate generation, we win miss many (perhaps even the majority) 2The main class of algorithms where this would not apply are those that i~d only maximal frequent itemsets, e.g., [8]. 
However, randomization precludes finding very long item-sets, so this is a moot point. 
Figure 3: Lowest discoverable support for different transaction sizes. Five million transactions, breach level is 50%. nificant influence on support discoverability. In fact, for transactions of size 10 and longer, it is typically not possi-ble to make them both breach-safe and simultaneously get useful in.formation for mining transactions. Intuitively, a long transaction contains too much personal information to hide, because it may contain long frequent itemsets whose appearance in the randomized transaction could result in a privacy breach. We have to insert a lot of false items and cut off many true ones to ensure that such a long itemset in the randomized transaction is about as likely to be a false pos-itive as to be a true positive. Such a strong randomization causes an exceedingly high variance in the support predictor for 2-and especially 3-itemsets, since it drives down their probability to "tunnel" through while raising high the prob-ability of a false positive. In both our datasets we discard long transactions. The question of how to safely randomize and mine long transactions is left open. We experimented with two "real-life" datasets. The soccer dataset is generated from the clickstream log of the 1998 
World Cup Web site, which is publicly available at ftp ://reseaxehsmp2. cc. yr. edu/pub/.orldcup/4. We scan-ned the log and produced a transaction file, where each transaction is a session of access to the site by a client. Each item in the transaction is a web request. Not all web requests were turned into items; to become an item, the request must satisfy the following: 
I. Client's request method is GET; 2. Request status is Ol~; 3. File type is HTHL. 
A session starts with a request that satisfies the above prop-erties, and ends when the last click from this ClientID time-outs. The timeout is set as 30 minutes. All requests in a ses-sion have the same ClientlD. The soccer transaction file was then processed further: we deleted from all transactions the items corresponding to the French and English front page frames, and then we deleted all empty transactions and all transactions of size above 10. The resulting soccer dataset 4M. Arlitt and T. Jin, "1998 World Cup Web 
Site Access Logs", August 1998. Available at http : //www. acm. org/sigcomm/ITA/ 
Figure 4: Number of transactions for each transac-tion size in the soccer and mailorder datasets. consists of 6,525,879 transactions, distributed as shown in Fig. 4. The mailorder dataset is the same as that used in [6]. 
The original dataset consisted of around 2.9 million transac-tions, 15,836 items, and around 2.62 items per transaction. 
Each transaction was the set of items purchased in a single mail order. However, very few itemsets had reasonably high supports. For instance, there were only two 2-itemsets with support /&gt; 0.2%, only five 3-itemsets with support /&gt; 0.05%. 
Hence we decided to substitute all items by their parents in the taxonomy, which had reduced the number of items from 15836 to 96. It seems that, in general, moving items up the taxonomy is a natural thing to do for preserving privacy without losing aggregate in.formation. We also discarded all transactions of size/&gt; 8 (which was less than 1% of all trans-actions) and finally obtained a dataset containing 2,859,314 transactions (Fig. 4). We report the results for both datasets at a minimum support that is close to the lowest discoverable support, in order to show the resilience of our algorithm even at these very low support levels. We targeted a conservative breach level of 50%, so that, given a randomized transaction, for any item in the transaction it is at least as likely that someone did not buy that item (or access a web page) as that they did buy that item. We used cut-and-paste randomization (see Definition 8) that has only two parameters, randomization level and cut-off, per each transaction size. We chose a cutoff of 7 for our experiments as a good compromise between privacy and discoverability. Given the values of maximum supports, we then used the methodology from Section 4.4 to find the low-est randomization level such that the breach probability (for each itemset size) is still below the desired breach level. The actual parameters (Kin is the cutoff, P,n is the randomiza-tion level for transaction size m) for soccer were: m [ 1 2 3 4 5 6 7 8 9 10 Km I 7 7 7 7 7 7 7 7 7 7 pro% 4.7 16.8 21.4 32.2 35.3 42.9 46.1 42.0 40.9 39.5 and for mailorder were: m I 1 2 3 4 5 6 7 Km ] randomized and nonrandomized files and then compare the results. We can see that, even for a low minimum support of 0.2%, most of the itemsets are mined correctly from the randomized file. There are comparatively few false posi-tives (itemsets wrongly included into the output) and even fewer false drops (itemsets wrongly omitted). The predicted sigma for 3-itemsets ranges in 0.066 X :~0.07% for soccer and in 0.047 X :~0.048% for mailordsr; for 2-and 1-itemsets sigmas are even less. false positives. Since we know that there are many more low-supported itemsets than there are highly supported, we might wonder whether most of the false positives are out-lists, that is, have true support near zero. We have indeed seen outliers; however, it turns out that most of the false positives are not so far off. The tables 2 and 3 show that usually the true supports of false positives, as well as the predicted supports of false drops, are closer to 0.2% than to zero. This good news demonstrates the promise of random-ization as a practical privacy-preserving approach. 
Privacy Analysis We evaluate privacy breaches, i.e., the conditional probabilities from Definition 4, as follows. We count the occurrences of an itemset in a randomized transac-tion and its sub-items in the corresponding nonrandomized transaction. For example, assume an itemset {a, b, c) oc-curs 100 times in the randomized data among transactions of length 5. Out of these 100 occurrences, 60 of the corre-sponding original transactions had the item b. We then say that this itemset caused a 60% privacy breach for transac-tions of length 5, since for these 100 randomized transac-tions, we estimate with 60% confidence that the item b was present in the original transaction. causes the worst privacy breach. Then, for each combination of transaction size and itemset size, we compute over all frequent s itemsets the worst and the average value of this breach level. Finally, we pick the itemset size that gave the worst value for each of these two values. 
Table 4 shows the results of the above analysis. To the left of the semicolon is the itemset size that was the worst. For instance, for all transactions of length 5 for soccer, the worst average breach was with 4-itemsets (43.9% breach), and the worst breach was with a 5-itemset (49.7% breach). We can see that, apart from fluctuations, the 50% level is observed everywhere except of a little "slip" for 9--and 10-item trans-actions of soccer. The "slip" resulted from our decision to use the corresponding maximal support information only for itemset sizes up to 7 (while computing randomization parameters). 6 However, since such long associations cannot be discovered, in practice, we will not get privacy breaches above 50%. 
Summary Despite choosing a conservative privacy breach level of 50%, and further choosing a minimum support around the lowest discoverable support, we were able to successfully find most of the frequent itemsets, with relatively small num-bers of false drops and false positives. 51f there are no frequent itemsets for some combination, we pick the itemsets with the highest support. 
SWhile we could have easily corrected the slip, we felt it more instructive to leave it in. Transaction size: 1 2 3 4 5 6 7 8 9 10 [ 
In this paper, we have presented three key contributions toward mining association rules while preserving privacy. 
First, we pointed out the problem of privacy breaches, pre-sented their formal definitions and proposed a natural solu-tion. Second, we gave a sound mathematical treatment for a class of randomization algorithms and derived formulae for support and variance prediction, and showed how to incor-porate these formulae into raining algorithms. Finally, we presented experimental results that validated the algorithm in practice by applying it to two real datasets from different domains. 
We conclude by raising three interesting questions for fu-ture research. Our approach deals with a restricted (albeit important) class of privacy breaches; can we extend it to cover other kinds of breaches? Second, what are the theo-retical limits on discoverability for a given level of privacy (and vice versa)? Finally, can we combine randomization and cryptographic protocols to get the strengths of both without the weaknesses of either? [1] N. R. Adam and J. C. Wortman. Security-control [2] D. Agrawal and C. C. Aggarwal. On the Design and [3] R. Agrawal. Data Mining: Crossing the Chasm. In 5th [5] R. Agrawal, H. Marmila, R. Srikant, H. Toivonen, and [6] R. Agrawal and R. Srikant. Fast Algorithms for [7] It. Agrawal and R. Srikant. Privacy preserving data [8] R. Bayardo. Efficiently mining long patterns from [9] L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. [10] Business Week. Privacy on the Net, March 2000. [11] C. Clifton and D. Marks. Security and privacy [12] R. Conway and D. Strip. Selective partial access to a [13] L. Cranor, J. Reagle, and M. Ackerman. Beyond [14] L. F. Cranor, editor. Special Issue on Interact [15] The Economist. The End of Privacy, May 1999. [16] V. Estivill-Castro and L. Brankovic. Data swapping: [17] European Union. Directive on Privacy Protection, [18] Y. Linden and B. Pinkas. Privacy preserving data [19] T. M. Mitchell. Machine Learning, chapter 6. [20] Office of the Information and Privacy Commissioner, [21] J. R. Quinlan. Induction of decision trees. Machine [22] A. Shoshani. Statistical databases: Characteristics, [23] K. Thearling. Data mining and privacy: A conflict in [24] Time. The Death of Privacy, August 1997. [25] J. Vaidya and C. W. Clifton. Privacy preserving inates as its diagonal elements. Now it is easy to see that ~z_-,q[l,-3]) = ~ ~ s;(~ ~,,:~q[~'-l']~ 
PROOF. We prove the left formula in (13) first, and then show that the right one follows from the left one. Consider N. E~; it equals 
In other words, each transaction t~ should be counted as many times as many different /-sized subsets C C A it contains. From simple combinatorics we know that if j = #(A N t,) and j I&gt; l, then t, contains (~) different /-sized subsets of .A. Therefore, and the left formula is proven. Now we can check the right formula just by replacing the I]j's according to the left for-mula. We have: since the sum ~'~'~ ( X ~.i) ~' is zero whenever q X :~ &gt; O. To prove that matrix P becomes lower triangular after the transformation from ~'and ~" to E and ~,', let us find how E ~' depends on ~ using the definition (12). 
Now it is clear that only the lower triangle of the matrix can have non-zeros. [] 
