 Jeremy Jancsary jermyj@microsoft.com Sebastian Nowozin senowozi@microsoft.com Carsten Rother carrot@microsoft.com Discriminative training of structured prediction mod-els is a significant computational challenge that be-comes even more difficult if exact inference in the model is intractable. Yet, this situation is not uncom-mon at all: For instance, even plain grid-structured graphical models, as commonly used in computer vi-sion, can lead to NP-hard inference problems.
 Discriminative learning formulations such as CRFs (Lafferty et al., 2001) or M3Ns (Taskar et al., 2003) require that an inference problem be solved repeat-edly for each training example, at each step of an iterative solver. Consequently, approximate training objectives such as pseudolikelihood (Besag, 1975) or piecewise training (Sutton &amp; McCallum, 2009) have commonly been used to avoid inference during train-ing altogether. At test time, the prediction of the in-tractable model is then obtained approximately. More recently, several authors (Wainwright, 2006; Kulesza &amp; Pereira, 2007; Finley &amp; Joachims, 2008) have discussed the benefits of using the same approx-imate  X  X nference machine X  at test time and during training, to ensure compatibility. One well-understood approach towards this end relaxes the intractable MAP inference problem via a linear programming for-mulation due to Koval &amp; Schlesinger (1976). Although there has been steady progress in solving this LP (e.g. Ravikumar et al., 2010; Savchynskyy et al., 2012), it is still recognized as a difficult practical problem. For instance, some of the most efficient specialized solvers (Kolmogorov, 2006; Globerson &amp; Jaakkola, 2007) work on the dual of the LP relaxation and ensure monotonic descent, but do not guarantee global convergence. Here, we consider a different relaxation of MAP in-ference and explore its utility in learning discrimina-tive models. The quadratic programming relaxation (Ravikumar &amp; Lafferty, 2006) has several advantages over its LP counterpart: Its optimization involves fewer variables and a separable constraint set (  X  3.2); dense interaction matrices can be incorporated if they allow for efficient multiplication (  X  5.4); and it leads to a differentiable large margin parameter estimation objective (  X  4.2). On the downside, it is strictly dom-inated by the LP relaxation in theory (Kumar et al., 2009), though the practical impact is mostly unclear. Moreover, tractability of the QP relaxation is typically ensured by convexifying the problem post-hoc (  X  3.2), so it is not immediately clear how to use it for learning. We make the following contributions: a) We provide specific discriminative parameterizations that directly ensure convexity of the QP relaxation, avoiding the need for post-hoc  X  X onvexification X  and enabling its use in large margin learning. b) We provide, to our knowledge, the first empirical study of discriminative training using the QP relaxation, comparing it directly to related approaches (including the LP relaxation) on four difficult structured prediction problems. Our results show that the QP relaxation is highly efficient and provides competitive predictive performance. We are not aware of previous work that uses convex QP relaxations in learning; however, several authors have considered training of discriminative models when ex-act inference is intractable. Kulesza &amp; Pereira (2007) give technical conditions under which the use of LP-relaxed inference yields provably good results in stan-dard learning frameworks. Finley &amp; Joachims (2008) further show that large margin learning with relax-ations discourages fractional predictions at test time. While only the LP relaxation is actually considered in their paper, the results apply equally to the convex QP relaxation. Moreover, building on the aforemen-tioned work, Martins et al. (2009) derive even stronger guarantees for learning with relaxations.
 A number of authors have attempted to accelerate ap-proximate discriminative learning by dualizing the LP relaxation in the loss function, keeping the dual vari-ables of all examples in memory. Meshi et al. (2010) alternate block coordinate updates on these dual vari-ables and stochastic gradient descent on the model parameters. Hazan &amp; Urtasun (2010) devise a simi-lar approach; in addition, their model contains a one-parameter extension that interpolates between large margin learning and maximum conditional likelihood learning. Komodakis (2011) uses a dual formulation motivated by dual decomposition, and again updates model parameters and dual variables jointly. We do not follow the same strategy for the QP relaxation, but rather solve the inference subproblem exactly at each step, which is fast and requires less memory. A different approach to attaining tractability, which has been followed for binary output variables, is to enforce submodularity of the inference subproblem (Taskar et al., 2006; Franc &amp; Savchynskyy, 2008). The subproblem can then be solved efficiently using graph cuts, enabling exact training within this restricted family. Our approach is related in that the inference problem is restricted to belong to a particular class in which we can learn efficiently; but unlike graph cuts, our approach can handle multiple labels natively. Finally, several authors have attempted to minimize the empirical risk of arbitrary  X  X nference machines X  mapping from input to a labeling by directly comput-ing the loss on the prediction obtained from the model (Stoyanov et al., 2011; Domke, 2011). Among these methods, our approach is most closely related to the logistic random field (LRF) of Tappen et al. (2008). Unlike our approach, the logistic random field uses an unconstrained quadratic energy. Moreover, it is originally parameterized very restrictively and unfor-tunately leads to a non-convex learning problem. Consider an undirected graphical model defined over n nodes i  X  X  , each of which can be in one of k states y i  X  { 1 ,...,k } . The likelihood of a joint state y = ( y i ) i  X  X  is described in terms of an energy E , which is assumed to decompose over edges ( i,j )  X  X  : For training and prediction, we want to obtain the joint state that minimizes the energy, referred to as as the min-sum problem or MAP estimation. 3.1. LP Formulation of the Min-Sum Problem Observe that energy E can be defined equivalently using indicator vectors  X  ( y ) selecting the appropriate components of the exponential parameters  X  : The above optimization occurs over a finite number of discrete points. By standard results, it is equivalent to optimize over the convex hull M = conv {  X  ( y ) } y  X  X  , and any solution lies at one of the corner points of M , known as the marginal polytope (Wainwright &amp; Jordan, 2008). Due to the exponential nature of M , only special cases of the above LP can be solved. LP relaxation. Instead, one can always optimize over the local polytope L , an approximation ensuring only local marginal consistency (Wainwright &amp; Jor-dan, 2008). This can introduce fractional solutions, as shown in Fig. 1a. Moreover, the resulting LP has O ( k |V| + k 2 |E| ) variables and O (2 k |E| ) constraints. A dual formulation typically optimized by message passing algorithms (e.g. Kolmogorov, 2006) is uncon-strained, but still involves O (2 k |E| ) variables, which can be prohibitively expensive for dense graphs. 3.2. QP Formulation of the Min-Sum Problem In contrast, we will work with a different formulation of the min-sum problem involving only O ( k |V| ) variables and O ( k |V| ) separable constraints. In particular, by arranging all pairwise parameters  X  ij into a matrix  X , and all  X  i into a vector  X  , an alternative (but exact) definition of the min-sum problem is given by Here, the convex hull of all indicator vectors  X  ( y ), consists of n = |V| unit simplices; one per variable. Each  X  i can be thought of as encoding the marginal probabilities of the k states of a single node. QP relaxation. Similarly to the exact LP, it is known (Ravikumar &amp; Lafferty, 2006) that optimizing the quadratic energy over this set, yields corner points  X  ( y ) encoding exact solutions y . However, since the energy is generally non-convex, di-rect minimization is still difficult.
 Ravikumar &amp; Lafferty (2006) propose to convexify the energy by adding a diagonal term D such that the ma-trix  X  becomes diagonally dominant, and to subtract the same term from the unary potentials, This approximation can be justified by the fact that under the indicator formulation (5), equivalence is maintained. However, the guarantee does not carry over to continuous energy (7): Indeed, fractional solu-tions can be introduced in the process (see Fig. 1b). The QP relaxation is attractive due to its small num-ber of variables and constraints. But convexifying the energy post-hoc, akin to Ravikumar &amp; Lafferty (2006), is unsuitable for use in a learning framework. Instead, we aim at directly learning the best parameters within the class of convex quadratic energies. 4.1. Parameterization In a discriminative model, the exponential parameters are a function of the observed input x and the model parameters w . Hence, our energy is of the form
E (  X  | x ; w ) =  X  0  X  ( x ; w ) + Commonly, the model parameters w weight a matrix of features F derived from input x , such that For computational reasons, we want to ensure strict convexity of the energy. Towards this end, we first break up the energy into contributions by edges. Decomposition. From its definition, it follows that the energy can be decomposed as Each such pairwise term is of the form If  X 
 X  ii and  X   X  jj are zero, the QP formulation is exact, but the energy is non-convex. To ensure convexity of the global energy, it suffices that  X  ij ( x ; w ) 0. Convex forms. We now discuss, in increasing or-der of expressiveness, forms of  X  ij ( x ; w ) that lead to convex energies and moreover ensure convexity of our learning objective in the model parameters w . Form 1 : A natural approach, followed in the logistic random field (Tappen et al., 2008), is to define where w p  X  w is a component-wise positive weighting vector. By definition, we have  X  ij ( x ; w ) 0, and if rank { F ij ( x ) }  X  2 k , then  X  ij ( x ; w ) 0 holds. To en-sure w p &gt; 0, we can project onto the positive orthant by clipping; but there are only few degrees of freedom. Form 2 : A more powerful approach is to directly learn positive-definite matrices. Assuming { W p } X  w is a set of such matrices, we can use a linear combination This way, a strictly larger class of interactions can be modeled. To ensure W p 0, we can project it onto the cone of positive-definite matrices at the small cost of a single eigendecomposition.
 Form 3 : It is often gainful to further exploit the de-pendency on input x . To this end, we can define where F ij is a nonlinear function of the observed in-put mapping to one of the matrices W p 0. As an example, F ij might evaluate a decision tree on the in-put, and return the specific matrix W p stored at the selected leaf. This approach was followed before for Gaussian random fields by Jancsary et al. (2012). Form 4 : Finally, for some applications, fixed-form global interaction matrices Q exist that already model the right semantics, so one can define and learn the contribution relative to other terms via a positive scalar w q &gt; 0. Since Q only enters the energy in a matrix-vector product, even dense matrices can be used if they permit efficient multiplication (see  X  5.4). 4.2. Parameter Estimation Assume we are given i.i.d. labeled training examples examples as disconnected components of a single in-stance, denoted by ( x,y ? ) and comprising n nodes. Further, the cost of a misprediction  X   X  is measured by a loss function that decomposes. The loss relative to ground truth y ? can then be written as  X   X  0  X  ( y ? ), e.g. for Hamming loss. Direct minimization of such discon-tinuous loss functions is infeasible; but following the empirical risk formulation of large margin estimation (Ratliff et al., 2007), we can define the surrogate  X  ( y | x ; w ) = E (  X  ( y ) | x ; w )  X  min leading to a convex, regularized estimation problem: One can verify that  X  ( y | x ; w ) is an upper bound on the loss of the actual prediction obtained from the energy. Optimization. A convenient property specific to our approach is that for  X  ij 0, the surrogate loss  X  ( y | x ; w ) is differentiable in the model parameters w . To see this, consider the loss augmented inference problem solved in order to compute the surrogate: Since the energy is strictly convex, the minimum is attained uniquely. Then, by Danskin X  X  theorem, the subdifferential of the min function contains a single element (the gradient), obtained by differentiating the inner expression at point  X   X   X  : and while the gradient with respect to the actual model parameters w follows from the chain rule.
 In practice, we found projected quasi-Newton methods (Schmidt et al., 2009) to be effective at solving (17), since cheap closed-form projections ensuring positivity are available for the parameterizations we discussed. Because (17) is convex, we find the global optimum. 4.3. Inference At test time, given the estimated model parameters  X  w and input x , we determine the prediction as Since  X   X  can be fractional, we round to the nearest in-tegral point to find a discrete  X  y .
 For global minimization of (19), we use the spectral projected gradient method (SPG; Birgin et al., 2000), resulting in an efficient iterative scheme that depends only on matrix-vector products  X ( x ; w )  X  as its basic operation. The constraints  X   X   X  n,k are handled by independently projecting each  X  i onto a simplex  X  k , which takes expected linear time (Duchi et al., 2008). 4.4. Relation to Logistic Random Field The Logistic Random Field (LRF) of Tappen et al. (2008) uses a convex quadratic energy similar to (19), but without constraints  X  n,k . Its parameters w are es-timated by minimizing a logistic loss defined directly on the prediction. This can be viewed as a smoothed form of Hamming loss but leads to a non-convex prob-lem, even if the energy is convex in w . Though not used originally, all parameterizations we discussed for our approach are equally applicable to LRF, so we compare to such an extended version in the following. Data M3N LP-M3N QP-M3N LRF Scene 10 . 06  X  . 26 10 . 49  X  . 27 10 . 48  X  . 36 10 . 98  X  . 33
Yeast 20 . 23  X  . 53 20 . 49  X  . 54 20 . 19  X  . 45 29 . 05  X  . 48 We now assess the benefits of our approach on four structured prediction tasks that lead to intractable inference and training, comparing QP-M3N: large margin learning with convex quadratic programming relaxations (our approach); LP-M3N: large margin learning with linear programming relaxations; LRF: logistic random field of Tappen et al. (2008), with quadratic regularization of the model parameters; and finally M3N: exact max-margin Markov networks, which are only feasible for small instances.
 All experiments are performed on recent Intel Xeon machines with 16GB of main memory. Depending on the method and application, different iterative solvers are used for inference and parameter estimation, but we always tried to ensure that the convergence criteria lead to a fair comparison in terms of both predictive accuracy and computational efficiency. 5.1. Experiment 1: Multi-label Classification The problem of multi-label classification is to assign a subset of labels Y  X  X  1 ,...,k } to each example. This task can be expressed equivalently via k binary vari-ables y i  X  X  0 , 1 } that each encode whether or not label i shall be assigned to an example. These binary vari-ables are correlated since some label combinations are more likely than others. We follow Finley &amp; Joachims (2008) and encode the dependencies via a graphical model with dense pairwise connectivity (see Figure 2). We evaluate on the Scene and Yeast datasets, which were used by Finley &amp; Joachims (2008) without any pre-processing, allowing us to replicate the experiment exactly. Besides the positivity constraints on the pair-wise matrices in the QP-M3N and LRF systems, as in (13), our setup is equivalent to theirs: Single-node po-tentials are obtained as dot products of model parame-ters and input features, while the pairwise terms learn a co-occurrence bias for label combinations. For each dataset and learning method, we choose from 14 differ-ent settings of regularization parameter C via 10-fold cross validation on the training data. The best value of C is then used to train on the whole training data, and we report the average normalized Hamming loss on test examples (this is the loss all methods more or less directly try to minimize during training). Table 1 shows the new results obtained for QP-M3N and LRF, alongside the results of Finley &amp; Joachims (2008). The standard error of the mean is indicated next to the loss. Since the graphical models are tiny, it is possible to compare against an exactly trained M3N. As one can see, QP-M3N compares favorably on both datasets, achieving lower test loss than LP-M3N and even M3N on the Yeast dataset. LRF, on the other hand, fails on the Yeast dataset. It is unclear to us exactly why this is the case; we tried to tweak various implementation details of the method in order to achieve better results, to no avail. Presumably, non-convexity of the training objective used by LRF is to blame, although this was not in general a problem. 5.2. Experiment 2: PoS-Tagging and Chunking The multi-label classification problem uses very small graphical models, allowing for rigorous evaluation of the predictive performance, but preventing realistic comparisons in terms of computational efficiency. We now consider a different problem, joint Part-of-Speech tagging and phrase chunking, which already leads to inference problems of more realistic size and difficulty. The goal is to identify the lingustic category of each word in a sentence, often referred to as a  X  X art of speech X . Moreover, phrase boundaries and types shall be identified. This can be formulated as a tagging problem on two chains, as illustrated in Fig. 3. Again, the correlations between labels can be exploited. Our experiments are performed on the CoNLL-2000 shared task (Tjong Kim Sang &amp; Buchholz, 2000), com-prising 8,936 training sentences and 2,012 test sen-tences. As a baseline, we train two local SVM clas-sifiers predicting each label independently. We use sparse binary features similar to Sutton et al. (2004) that check for the occurrence of words in a window around the current token. The first classifier, called strong , uses a window size of  X  3 tokens, while the sec-ond one, weak , is restricted to a window of  X  1 tokens. These classifiers are trained on the training data us-ing crossvalidation and achieve an average normalized Hamming loss of 3.78 and 13.17 on the test data. In order to take into account correlations between the output variables, we specify a graphical model similar to Sutton et al. (2004), with a pairwise factor defined between adjacent words within each label chain, as well as a pairwise factor defined between the two chains for each word, resulting in a grid structure. Pairwise factors are specified as in (13), with factors of the same spatial type sharing the same model parameters. The unary factors are derived from the confidence scores predicted by either the strong or the weak local SVM classifier, creating two different scenarios.
 Exact inference in this model is still feasible by form-ing junction trees, which typically results in cliques in-volving no more than three variables. For moderately small values of regularization parameter C , this allows us to train exact M3N models using bundle methods (Teo et al., 2010). For LP-M3N, we follow Hazan &amp; Urtasun (2010) and slightly smooth the LP using a concave entropy approximation (  X  = 10  X  2 ), resulting in a differentiable training objective that can be solved efficiently for any value of C . Inference is done using convex belief propagation (Hazan &amp; Shashua, 2010). We use our own implementation of these methods. Let us first discuss the results obtained by using the weak local classifier. The test loss of models trained on the training data using a range of regularization parameters C is shown in Table 2. Here, LP-M3N per-forms comparably to an exact M3N, while QP-M3N is slightly worse but still improves significantly over the baseline classifier. LRF, on the other hand, achieves Train 58h 11h 12h 38h worse results than the baseline classifier. Moreover, regularization is less predictable than for the other models. The standard error of the test loss ranges from 0.1 to 0.2, so these results are rather conclusive. Using weak baseline unaries, bigger improvements can be expected from structured models. The results in Table 3 mostly follow the previous discussion, with the surprising exception that LRF achieves the strongest results. This suggests that the restriction to convex quadratic energies does not per se limit the expres-siveness of a model on this task. The slightly worse results achieved by QP-M3N must then stem either from interactions with large margin estimation or the additional simplicial constraints in the energy. Table 4 compares computation time. Inference in QP-M3N is very efficient, yielding predictions more than an order of magnitude faster than LP-M3N and even twice as fast as LRF, for which we use conjugate gra-dient. Exact inference in M3N is as fast as solving the LP relaxation using convex message passing, since the prediction can be readily obtained from a junc-tion tree. Training time is somewhat less informative; the inference subproblem does not strongly dominate the cost here, so it mostly depends on the number of iterations required to optimize the model parameters. 5.3. Experiment 3: Inpainting of Characters We now consider a task requiring conditional pairwise interactions that strongly depend on the observed in-put. The goal is to inpaint the occluded parts of Chi-nese characters (cf. Figure 4, occlusions in gray). This problem was first considered by Nowozin et al. (2011); the data consists of 300 training and 100 test images. Following the original experiment, we visualize predic-tions on a version of the data with larger occlusions and report predictive accuracy on smaller occlusions. The graphical model we use is identical to Nowozin et al. (2011). In particular, we instantiate pairwise factors according to 32 types of spatial offsets relative to each pixel, such that each variable is connected to 64 other variables in its neighborhood. The potentials of a pairwise factor are determined by its type: Each type has an associated decision tree that performs feature checks on the input image relative to the coordinates of the factor. Leaf nodes store the positive-definite interaction matrices, and so the path taken through the tree determines the effective interaction for each factor, as in (14). We also use one unary type. Learning follows a two-step iterative scheme that alter-nates between introducing new model parameters by splitting tree nodes, and optimization of the current model parameters according to the learning objective. Tree nodes are split with the goal of achieving the largest possible descent in the objective function. This approach was introduced by Jancsary et al. (2012) in order to train Regression Tree Fields (RTFs), but it is equally applicable to QP-M3N and LRF. We train unary trees to a depth of 10 and pairwise trees to a depth of 4. Deeper trees lead to overfitting. Besides Regression Tree Fields (RTFs), we compare against a random forest (RF), as well as Decision Tree Fields (DTF), introduced by Nowozin et al. (2011). RTFs are based on a Gaussian conditional random field while DTFs use a discrete random field. Both methods are trained by maximizing the pseudolikeli-hood (Besag, 1975) of the data. Predictions are ob-tained from RTF using conjugate gradient (CG), sim-ilarly to LRF. In contrast, DTF must solve an in-tractable min-sum problem. One option is to solve the LP relaxation instead; but, as shown in Table 6, this is still expensive. TRW-S (Kolmogorov, 2006), special-ized for binary problems, is over an order of magnitude slower than inference in QP-M3N and the approaches based on a Gaussian random field. While TRW-S is recognized as one of the most efficient solvers for gen-10  X  0 43.22 20.95 10  X  3 22.36 22.35 10  X  6 24.01 21.48 10  X  9 23.57 20.64 eral binary labeling problems, it must update O (2 k |E| ) variables, versus O ( k |V| ) variables in approaches based on a quadratic energy. This makes a big difference in these rather densely connected graphs. Even worse, while TRW-S aims to solve the LP relaxation, it of-ten gets stuck. Better results for DTF are obtained by using simulated annealing, which is even slower. End-to-end discriminative training using the LP relaxation, as in LP-M3N, is conceivable, but would be extremely expensive, since inference clearly dominates the com-putational cost of training in this task. Training of QP-M3N and LRF took 20 and 28 hours, respectively. Table 5 lists the predictive accuracy of the competing approaches, again measured in terms of average nor-malized Hamming loss. Both QP-M3N and LRF are competitive with the state of the art; LRF in particular improves considerably on previously published results. Again, this is rather surprising. In any case, Hamming loss is perhaps not the most appropriate performance measure on this task. Of equal interest is whether the predictions look like plausible Chinese characters. Typical predictions are shown in Figure 4. 5.4. Experiment 4: Semantic Segmentation Finally, we show how fixed-form interaction matrices can be employed in our model, as in (15). The goal in semantic segmentation is to correctly identify the parts and foreground objects of a scene, which can be formalized as assigning one of k labels to each pixel of an image (Fig. 5). It is desirable for segmentations to expose a certain level of connectedness. To this end, one can use an affinity matrix based on the pixels X  sim-ilarity in appearance. We use the matting Laplacian , defined by Levin et al. (2008) as a sum of matrices each of which stores the affinities among pixels inside a window of radius r . Since L is positive semi-definite, we can incorporate it into the quadratic energies of QP-M3N and LRF. Importantly, L allows for efficient multiplication at constant cost in its window radius r (He et al., 2010). Since inference in QP-M3N and LRF only requires such products, full connectivity in arbi-trarily large windows can be modeled. We do not know how to achieve this efficiently in the LP relaxation. In our experiment, we use the matting Laplacian to refine segmentations obtained from a random forest. We perform 5-fold crossvalidation on the 715 images in the scene understanding dataset of Gould et al. (2009). For each fold, a random forest is first trained on the training portion of the data. The QP-M3N and LRF models then incorporate the predictions of the ran-dom forest as weighted unary features and learn their relative importance versus a matting Laplacian term. Due to the small number of model parameters, the structured models are trained only on one third of the training portion of each fold, and we do not regularize. All models are evaluated on the test portion of each fold, and the results are then averaged over the folds. Table 7 shows that the gains of QP-M3N over the random forest grow with increasing window radius r , while the computational cost slightly decreases. In contrast, LRF even fails to improve over the baseline at r = 16. Empirically, we find that LRF over-smoothes its predictions (see Figure 5). It is also less efficient: Training takes 10 hours versus 2 hours for QP-M3N. Based on our findings, is it possible to recommend one method over the others? Perhaps most closely related to learning using convex QP relaxations (QP-M3N), which we proposed in this paper, is the Logistic Ran-dom Field (LRF) of Tappen et al. (2008). It achieved better results than QP-M3N in two cases; but it also failed completely in three scenarios, not even improv-ing on a trivial baseline. We believe that this is due to its non-convex learning objective, and also the fact that regularization of the model is more difficult. In contrast, QP-M3N always improved reliably on the baseline, and it is at least as efficient. For this reason, we would advise against the use of LRF in general. The closest competitor of QP-M3N is large margin learning with LP relaxations (LP-M3N). It achieved better results than QP-M3N in one of the two tasks where a direct comparison was possible. On the other hand, in our experiments, it was at least an order of magnitude faster to solve the convex QP relaxation. This is not surprising: The LP relaxation involves significantly more variables and a more difficult con-straint set. In practice, the computational efficiency of QP-M3N enables end-to-end discriminative train-ing where LP-M3N is simply too expensive. QP-M3N is also more flexible, in that it allows to incorporate dense interaction matrices efficiently.
 A drawback of our approach is that the limitations in the expressiveness of convex QP relaxations are not yet as well understood as those of other classes of energies that can be minimized efficiently, such as submodu-lar ones. Nonetheless, we hope to have demonstrated that convex QP relaxations are widely applicable in practice and computationally efficient. Furthermore, they can be trained in a principled manner in a large margin framework and yield competitive predictive ac-curacy. For these reasons, we believe that convex QP relaxations deserve further attention.
 We would like to thank Toby Sharp for sharing efficient code for multiplying by the matting Laplacian.
