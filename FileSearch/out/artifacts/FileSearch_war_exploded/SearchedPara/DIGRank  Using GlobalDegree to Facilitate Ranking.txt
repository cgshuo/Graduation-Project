 PageRank has been broadly applied to get credible rank se-quences of nodes in many networks such as the web, citation networks, or online social networks. However, in the real world, it is usually hard to ascertain a complete structure of a network, particularly a large-scale one. Some researchers have begun to explore how to get a relatively accurate rank more efficiently. They have proposed some local approxi-mation methods, which are especially designed for quickly estimating the PageRank value of a new node, after it is just added to the network. Yet, these local approximation methods rely on the link server too much, and it is difficult to use them to estimate rank sequences of nodes in a group. So we propose a new method called DIGRank , which uses global Degree to facilitate Ranking in an Incomplete Graph and which takes into account the frequent need for appli-cations to rank users in a community, retrieve pages in a particular area, or mine nodes in a fractional or limited net-work. Based on experiments in small-world and scale-free networks generated by models, the DIGRank method per-forms better than other local estimation methods on ranking nodes in a given subgraph. In the models, it tends to perfor-m best in graphs that have low average shortest path length, high average degree, or weak community structure. Besides, compared with an local PageRank and an advanced local approximation method, it significantly reduces the compu-tational cost and error rate.
 D.3.3 [ Information Search and Retrieval ]: Retrieval models; Information filtering Algorithm, Experimentation PageRank, Small-world, Scale-free, Online Social Network
Recently, PageRank [1] has been widely used in ranking retrieval results on the web, such as finding the top influen-tial papers in citation networks or valuable users in online social networks (OSNs). Although, in theory, PageRank is an excellent method to accomplish those jobs, in practice, there are some limitations. For instance, the webs and OSNs are continually expanding, it is not possible to know a net-work X  X  complete structure at any one time. Search engines must crawl through pages and update methods repeatedly to prevent rank values of nodes from being outdated. How-ever, repeatedly updating the value of all the nodes in the network is too costly. Besides, in many cases, it is sufficient to just quickly ascertain a new node X  X  approximate value. So a more efficient method is needed to estimate rank values.
To avoid performing a large-scale computation on the en-tire graph, Chen et al. proposed an in uence method [2]. This method focused on estimating the PageRank score of a particular webpage using only a small subgraph of the entire web. Then, Bar-Yossef et al. further investigated and gave a more advanced method by pruning [3]. These local PageR-ank methods can quickly and accurately estimate the global PageRank value of a target node by crawling its adjacen-t nodes, and do so with a relatively moderate convergence rate. Yet, they are not suitable for some other applications. First, they strongly rely on the accessibility to the adjacent nodes through a link server , and would become infeasible if the server is blocked. Second, they do not emphasize the accuracy of rank sequences among nodes, which is impor-tant in many applications. Third, it takes a long time to accomplish this type of ranking because there are a lot of high in-degree nodes that have to be crawled repeatedly.
Other researchers hope to estimate global rank values of nodes by their global in-degrees, which have been proven to have a high correlation to global PageRank when using a mean eld approach [4]. But Fortunato et al. [4] found that nodes with the same global degree may still differ in their ranking. Meanwhile, other researchers estimate the value of nodes only by computing PageRank of the local incom-plete network (PR*). But this method also produces skewed rankings because the local network doesn X  X  take into accoun-t the link structure of the network as a whole. Therefore, it is insufficient to use only a subgraph X  X  global degree or incomplete structure to make an estimation.

Motivated by the above investigations and analyses, we propose a new method called DIGRank , which exploits both global degree and incomplete structural information. Doing so avoids the aforementioned structural shortcomings and, Figure 1: A sample of node structure graphic. (a) is a complete graph, while (b) is a cloud graph. thus, is a more reliable method. To test the adaptability of DIGRank , we analyze its performance characteristics using different parameters based on several topological models, such as WS and BA . The results show our new method is suitable for scale-free [5] and small-world [6] graphs, both of which are present in most real world networks.

Compared with Bar-Yossef et al.  X  X  Local PageRank Ap-proximation LPRA , our method has several advantages. First, it relies on only the structure of a given local graph and glob-al degrees of local nodes, instead of running endless crawling through the link server . Second, compared with LPRA , our method reduces the computational cost by 50% and the er-ror rate by 56% in a data set on which LPRA performs well.
As mentioned above, it is necessary to find a method to rank nodes in an incomplete graph when the complete graph is hard to obtain. Figure 1(a) shows an example of a com-plete graph. Including all nodes and links. The complete graph consists of a detected part and an undetected part. The incomplete graph (only the detected part) contains n-odes a , b and c . The links are shown as solid lines.
To rank nodes in the incomplete graph, people usually use a simple local PageRank method. But, because the struc-ture of the complete and incomplete graphs differ, their final rankings will also differ.

In order to improve the consistency of such rankings, we are proposing a method called DIGRank which is used in a cloud graph as shown in Figure 1(b). In the cloud graph , we see the undetected part as a Cloud , and assume every undetected link end connects to the Cloud . Thus, there may be more than one link between the Cloud and a node. For example, both 8 and 11 are links from the Cloud to the node a . To decrease the redundancy of links, we replace multi-links as 8 and 11 by one weighted link (the weight of this weighted link equals to the number of multi-links from the Cloud to the node a ) . Fortunately, the number of links between the Cloud and each node equals the degree of the node in the incomplete graph minus the complete graph. Thus, we only need to know in-degrees of all nodes in the incomplete graph LI and the complete graph GI , and out-degrees of those in the incomplete graph LO and the complete graph GO , to count the weight of each link. Supposing that there are n nodes in an incomplete graph, based on the basic PageRank algorithm, we initiate the rank value of each detected node as 1 /N ( N is the number of PR 0.23 92 0.21 26 0.192 4 0.18 52 0.17 08 a &gt; b &gt; c PR* 0.23 80 0.42 87 0.333 3 --b &gt; c &gt; a
DR 0.29 42 0.24 70 0.223 6 0.235 2 a &gt; b &gt; c nodes in the complete graph) and that of the Cloud as the subtraction of n/N , the value of all detected nodes, from 1. Then we transform the incomplete graph into a weighted cloud graph , and compute the rank value of each detected node iteratively as Algorithm 1 shows.

Algo rithm 1: Ranking nodes by adding a Cloud 1 for i  X  [1 , n ] do 2 r i = 1 / N ; 3 if GI i &gt; LI i then 4 E (0 , i ) = GI i  X  LI i ; /*edge from 0 to i , 0 5 if GO i &gt; LO i then 6 E ( i, 0) = GO i  X  LO i ; /* edge from i to 0*/ 7 r 0 = 1  X  n/N ; 8 R =WeightedRank( E , R ); 9 delete r 0 from R ; 10 sort R by rank score; 11 return R ; 12 function WeightedRank( E , R ) 13 R = R , R = { 0 , ..., 0 } ; 14 while | R  X  R | &gt;  X ,  X   X  0 do 15 R = R , R = { 0 , ..., 0 } ; 16 for every E ( i, j ) in E do 17 r j = r j + r i  X  ( E ( i, j ) /GO i ); /* distribute 18 return R ;
In T able 1, we rank nodes of Figure 1 by PageRank ( PR ) in a complete graph, by simple local PageRank ( PR* ) in an incomplete graph, and by DIGRank ( DR ) in a Cloud Graph . We can see that PR*  X  X  ranking sequence is different with PR , while DR  X  X  ranking sequence is the same as PR .
Because most real networks contain small-world and scale-free characteristics, we generate two groups of such simulat-ed graphs and conduct measurements to test DIGRank  X  X  performance.
In the evaluation, we use unsortedness ratio U to measure correspondence between estimated sequences in a subgraph and real sequences by PageRank in the complete graph.
Bo olean variable P ij means coherence between two pair sequences. If matched, P ij is 0; otherwise, P ij is 1. U measures the unsortedness ratio , U  X  [0 , 1]. U = 0 mean-s the two sequences are identical, U = 1 means one is in reverse order of the other. For instance, in Table 1, the se-quences  X  b, a  X  ,  X  c, a  X  of PR* are different with that  X  a, c  X  of PR , which means P ab = 1, P ac = 1, P bc = 0 and U
P R = (1 + 1 + 0) / (3  X  (3  X  1) / 2) = 2 / 3.
We generate 250 WS graphs with different parameters, k (average degree), p (random reconnection coefficient), N (number of nodes). Then we extract 200 subgraphs by BFS from each WS graph: 50 in which the nodes amount to 5% of the whole WS graph, 50 at 10%, 50 at 15%, and 50 at 20%. The total number of subgraphs analyzed is 50,000. We apply local estimating methods to these data, compute unsorted-ness ratio of all subgraphs, and get the average value of every 50 subgraphs with the same r of each WS graph. In Figure 2, each box contains 5 ( N = 2000 , 4000 , 6000 , 8000 , 10000)*4 ( r = 5% , 10% , 15% , 20%) unsortedness ratio values. We find that the gaps among these values in each box are small, which means the graph scale N and extracting ratio r have little impact on the accuracy of DR .

The horizontal axis x represents different values of p = unsortedness ratio decreases as p increases, which means the lower average shortest path length 1 the graph has, the bet-ter accuracy the DIGRank has. We also find that, when k increases, the range of accuracy variation becomes larger.
Using these generated WS graphs, we test how the com-munity structure of a graph affects DIGRank X  X  accuracy. Module degree Q [7] is a value to indicate the tendency of a graph to be divided into different communities. A graph that is easily divided is said to have high modularity. Fig-ure 3 shows that unsortedness ratio increases as Q increases, which means the algorithm would have a better performance if the community characteristic of a graph is not notable.
We also generate a group of BA graphs with different pa-rameters, m (number of nodes to be linked by each added
In WS mo del, average shortest path length and cluster co-efficient has positive correlation with p Figure 3: Relationship between U and Community Structure node), N (number of nodes in the final graph). Then we extract 200 subgraphs by BFS at a different ratio r . Sim-ilar to WS graphs, the accuracy of DIGRank is relative to average degree of a graph rather than the graph scale N and extracting ratio r . Specially, in Figure 4, the accuracy of DIGRank behaves a power-law relationship with average degree. Thus, with the increase of average degree of the network, DIGRank would perform even better.
 In this section, we find some characteristics of our method. First, its performance is independent with the graph scale and extracting rate at some extent. Second, with increase of random reconnection coefficient and average degree, the error rate decreases. Moreover, compared with PR* , our method reduces the error rate by more than 70% in both small-world and scale-free graphs. Thus, we assume that DIGRank would be suitable for many real networks which contain small-world and scale-free characteristics.
Beyond the simple local PageRank , Chen et al. proposed an in uence method ; later on, Bar-Yossef et al. further researched on it and gave a more advanced method Local PageRank Approximation LPRA . This advanced method crawls all adjacent nodes of a target node layer by layer, and computes the influences of them on the target node. It has been used for quickly estimating global rank value of a target node. Yet, it still has some disadvantages.
First, LPRA strongly relies on the accessibility to the ad-jacent nodes of a target one through a link server . If not all the adjacent nodes are accessible to the crawler, accuracy will decrease. Second, they do not put an emphasis on the accuracy of sequences of nodes, which is important in many applications. Third, the cost of LPRA is still not low when dealing with local graphs.
We compare our method DR with LPRA based on a 280,000 page crawl of the www.stanford.edu domain performed in 2002 by the WebBase project 2 . The data is considered suit-able to test the LPRA and even able to represent large con-nected components of the web graph to some extent.
We randomly extract 100 subgraphs by BFS with size smaller than 20% of the whole graph. In each subgraph, we run the DR and LPRA with different threshold 3 value T range from 0.001 to 0.1.
Figure 5 shows unsortedness ratio comparison of the two methods in all subgraphs. T = 0 . 1 means using LPRA with threshold 0.1 to compute each subgraph. We see that with the decrease of T , the decrease of the error rate becomes slower. Yet, even when we choose a much lower threshold T = 0 . 001, the error rate of LPRA is still much higher than that of DR . We see that the median of the error rate of DR is reduced by 49% compared with T = 0 . 001, 56% compared with T = 0 . 01 and 78% compared with T = 0 . 1.
Figure 6 shows the comparison of computational cost for methods in all subgraphs whose numbers of nodes range from 100 to 45000. Computational cost is the sum number of times all the nodes are visited after a method completes all of its scans. LPRA prunes away and ignores some nodes after several scans, saving time and resources, but its com-putational cost is still high because many influential nodes are visited dozens or hundreds of times. To compute the cost of DR , we multiply 15 scans 4 by the number of nodes in the subgraph because in each iterative process, all these nodes are visited. In Figure 6, the cost of DR is a bit higher than that of LPRA with T = 0 . 1, but much lower than that of LPRA with T = 0 . 01 and T = 0 . 001. In addition, as T vlado .fmf.uni-lj.si/pub/networks/data/mix/mixed.htm.
Bar-Yossef et al.  X  X  local PageRank approximation used a pruning method to cut low influence nodes whose influences are below threshold value T . With decrease of the threshold, the error rate decreases while the cost increases. Chen et al.  X  X  in uence method also focused on the tradeoff between the error rate and the cost.
In most graphs, PageRank is convergent after 10 to 20 it-erations. decreases, the cost increases rapidly. For example, the cost of T = 0 . 001 is much higher than that of other thresholds.
In this section, we find that T = 0 . 01 is an acceptable tradeoff for LPRA which is similar to Chen et al.  X  X  result Compared with LPRA( T = 0 . 01), our approach reduces the cost by 50%, and error rate by 56%. In this paper, we propose a new algorithm called DI-GRank , which is specially designed for ranking the nodes in local graphs. Compared with the simple local PageRank, our method is very suitable for small-world and scale-free graphs which contain similar characteristics with many re-al networks. Compared with the advanced local PageRank approximation method, DIGRank significantly reduces the computational cost and error rate. The research was supported by the fund of the State Key Laboratory of Software Development Environment (SKLSDE-2011ZX-02).
Chen et al.  X  X  simple in uence method showed when the threshold below a certain value such as 0.005, the average error will decrease much slower than before and will keep stable after T=0.001 .
