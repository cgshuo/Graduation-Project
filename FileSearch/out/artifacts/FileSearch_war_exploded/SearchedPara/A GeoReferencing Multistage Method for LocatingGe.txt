 The geographic scope of Web pages is becoming an essen-tial dimension of Web search, especially for mobile users. This paper shows a multistage method for assigning a geo-graphic focus to Web pages (GeoReferencing) according to their textual contents. We suggest several heuristics for the disambiguation of toponyms and a scoring procedure for focus determination. Furthermore, we provide an experi-mental methodology for evaluating the accuracy. Finally, we obtained promising results of over 70% accuracy with a city-level resolution.
 Categories and Subject Descriptors: H.4[Information Systems Applications]: Miscellaneous; I.7.5[Document and Text Processing]: Document Capture General Terms: Algorithms, Design, Experimentation. Keywords: Georeferencing, GeoParsing, GeoCoding, GIR.
Web documents frequently contain geographic references and it is very common that users request geographically re-lated information. The importance of geographically-aware search engines is even greater for mobile internet users, for whom the spatial context is especially significant. There-fore, automatically obtaining the geographic location of Web pages is becoming an important matter [4]. This task is typ-ically split in three sub-tasks, namely GeoParsing, GeoCod-ing and focus determination [1].

The task of GeoParsing consists of detecting and ex-tracting the geographic names present in the text of a Web page and, in many cases, also includes the classification of these names according to their feature types, as a specific case of Named Entity Recognition (NER). The most com-mon techniques applied are:
Ontology based extraction is based on gazeteers or dictio-naries and one of the most popular techniques for GeoP-arsing [1, 4]. This approach is simple and allows efficient implementations [3], but with a loss of precision in toponym extraction.  X 
This work was partially supported by TIN2006-15071-C03-02 project, Ministry of Education and Science, and by the Government of the region of Castilla y Leon (Junta de Castilla y Leon) through the Agency for Economic Devel-opment (ADE), Spain.

Natural language processing is generally based in statisti-cal models. Various learning techniques like Max Entropy have been used for detecting toponyms with great success in the CoNLL [5], however these approaches require lots of training and are corpus dependent.

Hybrid techniques benefit from both techniques, obtaining promising results [2].

The task of GeoCoding assigns a specific geographic lo-cation to the tokens recognized in the previous step. This task is especially complex given the ambiguity of terms, which can be classified in two main groups:
Geo/Non-Geo ambiguity occurs when there is a geographic name that matches a common word. Many different heuris-tics can be applied to solve this problem [1, 3].
Geo-Geo ambiguity happens when we have the same term referring to different geographic names. Over 25% of the location names worldwide refer to more than one place.
The task of GeoFocus or focus determination consists in establishing a global geographic focus for the page [1, 3, 4]. This focus may not be unique. The GeoParsing stage first extracts plain text from the HTML, considering some special fields such as the title or meta-tags. After that, we apply a dictionary based toponym extraction, using the longest exact match. To deal with geo/non-geo ambiguities, we apply several filters: 1. Uppercase filter : removes toponyms that do not start with uppercase. 2. Stop-Word filter : removes the most frequent common words in English and Spanish. 3. Qualifier filter : a list of positive and negative qualifiers are used to detect if a word is a toponym or not [3]. toponyms including some basic information such as popu-lation or aliases. Populated places are classified hierarchi-cally (country, state, town) resulting in a geographic database (GDB) of almost 4 million names and over 2.5 million unique locations. To deal with geo/non-geo ambiguities, each name is marked as common if it is included in the Spanish or En-glish dictionaries 1 .

In GeoCoding , toponyms are organized as nodes in a directed k-partite graph, where each partition is associated with a level of the hierarchy and each edge represents a pos-sible part-of relation. This graph is created in three steps: 1. Node creation : the toponyms identified in GeoParsing are added to their corresponding level(s). http://wiki.services.openoffice.org/wiki/Dictionaries ODP Accuracy (%) Precision Recall England (EN) 63.88  X  1.61 86.25% 94.2% USA (EN) 72.89  X  1.5 93.41% 97.2% Spain (EN+ES) 77.34  X  1.45 92.20% 98.52%
Spain (ES) 73.44  X  1.48 89.18% 98.21% 2. Edge creation : nodes are connected according to their distance in text. The distance threshold is adjusted depend-ing on the toponym hierarchy level. 3. Pruning : edges are checked against the GDB to re-move non-existent geographic relations. When a real rela-tion is found, nodes are tagged with their a ccording location identifiers (GeoIDs). Toponyms that are common words, not positively qualified in GeoParsing and with no relation found are removed, thus reducing geo/non-geo ambiguity.
The process of GeoCoding is performed by a pipeline of domain-specific filters, reducing the ambiguity of toponyms progressively instead of relying on a single graph algorithm [4, 2]. The filters applied are: 1. Multiple path filter : redundant edges connecting to-ponyms are removed and only the longest path is kept. Some information may be lost, but it helps the disambiguation in most cases. The reason is that when a document references a location it should concern its sub-locations to some extent [4], especially when they are near in text. 2. Democratic disambiguation : co-occurring locations pro-vide good evidence for finding the correct sense of a location [2], therefore each parent node is disambiguated using the most popular one among its children. The process is re-peated from the lowest level to the top, resolving most of the geo-geo ambiguities. 3. Scoring : when there is a node with multiple possible parents, we decide which one to take by assigning each to-ponym a relevance score, based on frequency in text, and taking the one with highest score. Since locations concern their sublocations and vice versa, we define the following recursive two-step score propagation method: Where f n is the relative number of occurrences of the node n in the document, C i are each one of the l children of n , and P i are each one of the m parents of n . The attenuation factors  X  and  X  are calculated experimentally (  X  =0 . 2and  X  =0 . 65). Some additional score adjustments are made for nodes with a related postal code and toponyms tagged as common terms. 4. Population filter : population is used to resolve any re-maining ambiguities by taking the place with the biggest population. This heuristic provides excellent results [1, 3].
Finally in the GeoFocus stage, the scoring algorithm is applied again to obtain the final score, and the node with the best score is taken as the page focus. This solution is limited, but the possibility of multiple foci will be explored in further research.
To evaluate our georeferencing system, we performed a stratified systematic sampling of the Open Directory Project (ODP) corpus 2 , which provides over 1 million pages, each tagged with topic and geographic scope. We created four test corpora of 500 pages each, based on geographic region and language: Spain (ES), Spain (ES+EN), UK (EN) and USA (EN). Although the ODP provides a good starting clas-sification, some manual checking was necessary.

The most commonly used measure to evaluate complete georeferencing systems is the accuracy, but the typical IR measures can be applied as well. Table (1) presents the final results for the accuracy, providing a 95% confidence interval of the Bernoulli distribution. The correctness of the focus is determined with a town level resolution.

Furthermore, we classified errors in several categories and found that an average of 27% of them come from non-geo ambiguities, suggesting that enhancements in GeoParsing could improve the results. On the other hand, geo-ambiguities are less problematic, representing only 13% of the errors. Around 28% of the pages had no focus, but this could be improved by using focus propagation techniques. Finally 30% of the remaining errors are due to focus imprecision, which could be improved modifying the scoring function.
We have proposed a modular multistage GeoReferencing system with graph-based GeoCoding. Furthermore, an ex-perimental methodology for evaluating the GeoReferencing system has been proposed, obtaning promising results of around 70% accuracy at city level for English and Spanish.
Other authors are: Mario Arias (GRINBD, email: mar-ioarias2@gmail.com ), Jorge Cabrero (GRINBD, email: rey-bamba@gmail.com ), Guido Garc  X   X a (ITDeusto, email: ggar-ciab@itdeusto.com ), C  X  esar Llamas (GRINBD, email: clla-mas@infor.uva.es )andJes  X  us Vegas (GRINBD, email: jve-gas@infor.uva.es ). http://www.dmoz.org
