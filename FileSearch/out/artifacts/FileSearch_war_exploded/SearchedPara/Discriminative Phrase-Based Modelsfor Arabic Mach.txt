 CRISTINA ESPA  X  NA-BONET, JES  X  US GIM  X  ENEZ, and LLU  X  IS M ` ARQUEZ TALP, Universitat Polit ` ecnica de Catalunya 1. INTRODUCTION Nowadays, one of the most common paradigms for machine translation (MT) is the statistical approach, especially when there are a large number of paral-lel texts available, as in the case of the Arabic X  X nglish language pair. From the first works on statistical machine translation (SMT) by Brown et al. [1990, 1993], the field has experienced several enhancements. It was soon noticed that translation is not a word-to-word process, that the information of sur-rounding words would help, and that one word could be translated into more than one element. This motivated the usage of phrases 1 as translation units and consequently the birth of phrase-based SMT [Och and Ney 2004; Koehn et al. 2003]. Further enhancements involve the incorporation of syntactic structure. Syntax-Based SMT [Yamada and Knight 2001; Chiang 2005] is cur-rently an active field of research too, but we stick to phrase-based SMT in this work.
 able one, the target sentence e , and the probability is expressed as the sum of different components. The log-linear model [Och and Ney 2002], a generaliza-tion of the original noisy-channel approach, estimates the probability as the logarithmic sum of several terms. Two of them, the language model P ( e )and the translation model P ( f | e ), are the core of the approach. The former is a way to assign probabilities to word sequences in the target language which take care of the fluency of the output. The latter is the term taking into account the correspondence between the two languages, that is, the probability that a sentence f is translated into the sentence e , and it is usually splitted as the are calculated via frequency counts in a training corpus at the phrase level. Therefore, the probability score associated to the translation of a phrase f i into e i does not include any information on the context of the phrase or on the grammar of the sentence; it is just a lexical translation of the isolated phrase. The language model somehow takes care of the context in the target language but at a short distance (usually from three to five words), and independently from the translation model.
 text of each phrase should help the translation, so the first question to ask is how can this be included in the statistical approach. In that respect one may think of translation as a phrase selection , and treat it as a classification prob-lem instead of assigning a translation probability given by relative frequency counts. Machine learning techniques ca n then be used to score the transla-tions using various features that encode the information of the phrase context. One could understand the different translations of a phrase as different senses of that phrase, and try to identify which is the intended sense for each word in a sentence. This interpretation shows an analogy between treating phrase selection as a classification problem and word sense disambiguation (WSD) techniques, where classifiers are used to select the correct sense of a word. Several works exploit this idea for MT on different language pairs: see for in-stance Carpuat and Wu [2005], Vickrey et al. [2005], Carpuat and Wu [2007], Bangalore et al. [2007], Gim  X  enez and M ` arquez [2008], Stroppa et al. [2007], Specia et al. [2008], and references therein. Most important differences among these works are briefly outlined in Section 3.
 any language pair, those source languages with especially ambiguous seman-tics where words tend to have a larger number of lexical translations could benefit more from the procedure. The non-diacritization of Arabic written doc-uments is one of the major causes for the increment of the ambiguity with respect to other languages. Since short vowels, for instance, are written as di-acritics, its absence makes that sometimes the only way to know the meaning of a written word is by its context. Arabic is therefore an appropriate language to test the power of the discriminative phrase selection.
 to-English translation [Gim  X  enez and M ` arquez 2008], we have trained a ded-icated lexical selection model for Arabic-to-English translation. Our model deals with the translation of every source phrase as a multi-class classification problem, where every possible translation of the given phrase is a class. These local phrase translation classifiers re ly on support vector machines (SVM) as a learning paradigm. Local predictions are then softly integrated into an SMT architecture so they can interact with other models without modifying the ba-sic architecture.
 culiarities of Arabic that will be relevant for our system. Section 3 explains the discriminative phrase selection method, and Section 4 explains the data we use in the analysis and the pre-process we apply. Next, in Section 5, we study the local task of phrase selection, and afterward in Section 6 we explore its extension to the full task of translation. Finally, we draw our conclusions. 2. ARABIC LANGUAGE IN THE CONTEXT OF SMT The Arabic script is an alphabet with allographic variants, diacritics, and liga-tures. Each character has four allographs depending on its position within the word: initial, medial, final, or as stand-alone. The alphabet is composed by 25 consonants, 3 semi-consonants, 3 short vowels, 3 long vowels and 2 diphthongs. The short vowels, fatha , kasra ,and damma , are not letters themselves but di-acritics written above or below consona nts. Other diacritics are also used as a non-vowel mark ( sukun ), as a double consonant mark ( shadda ), or as a letter itself ( hamza ). For example, for the consonants .
 Koran, in some other religious texts, classical poetry, textbooks, or in complex texts to avoid ambiguity. In most cases, when pronunciation is not especially important, texts are non-vocalized and non-diacritized. This is mostly the case of the corpora used for MT and that increases the ambiguity of written texts. Interpreting the context is sometimes the only way of choosing among the dif-ferent meanings. The three possible vocalizations of seen before must be distinguished so that they can be translated as  X  X cience X  or  X  X nowledge X  ( ),  X  X lag X  ( ), or  X  X each X  ( ). These three words are perfectly distinguishable when speaking but not when reading. This kind of ambiguity due solely to vocalization is in addition to the usual ambiguity caused by homonyms in Arabic. Additionally, verbal declinations can further increase the number of meanings.
 Since we deal here with a language pair that mixes both scripts, it is useful to unify the codification. There exist several transliterations to convert Ara-bic characters to the Latin alphabet. In NLP, the original texts encoded in ISO-8859-6 or CP-1256, for example, are usually converted to the Buckwalter transliteration. 2 This is a one-to-one correspondence between Unicode and UTF-8 codification. Once all of our data are in UTF-8 they can be treated ho-mogeneously by machines. Besides, the romanization eases the understanding for those not familiar with Arabic phonetics. This way, the previous example can be read as Eilom ( ), Ealam ( ), or Eallama ( ).
 into account in our system is the fact that words are formed by a combination of several elements sometimes joined together by ligatures. A full word agglu-tinates to the root affixes and clitics. Affixes mark tense, gender, and number. Clitics are divided into proclitics (before the root) and enclitics (at the end of the word). Proclitics are prepositions, conjunctions, and determiners; enclitics are pronouns and possessives.
 Buckwalter X  X  transliteration) is translated into three English words:  X  X nd their knowledge X . It can be morphologically segmented as: where it is taken into account that Arabic is read from right to left. It is clear from this example that the segmentation of wElmhm in wElmhm will ease the translation by improving the alignments and reducing the original sparsity, since the number of occurrences in the corpus of every segment by itself will be higher than the occurrences of the full Arabic word. 3. DISCRIMINATIVE PHRASE TRANSLATION MODEL There are several recent methods in the literature to integrate discrimina-tive learning techniques into the translation process. In 2005, Carpuat and Wu [2005] used WSD predictions as a preprocess to constrain the possible translations available at decoding time. The same year, Vickrey et al. [2005] applied discriminative models for word selection but they were used in a blank-filling task instead of full translation. This work was first extended to the full translation task and afterward to translate phrases instead of words (see Carpuat and Wu [2007] and references therein).
 rithm and have been applied to different language pairs and developed with different evaluation metrics, being a difficult direct comparison. Carpuat and Wu [2007] used a WSD system which combined na  X   X ve Bayes, maximum en-tropy, boosting, and kernel PCA-based models. Simultaneously, Bangalore et al. [2007] relied on a maximum entropy model, Stroppa et al. [2007] applied memory-based learning, and a bit later [Specia et al. 2008] used inductive logic programming. Here we use the model of Gim  X  enez and M ` arquez [2008] based on SVMs to solve the multi-class classification problem where every possible translation is a class.

In that model, the phrases are extracted from the alignments estimated from the parallel corpus. Therefore, the candidate phrases to be used for the discriminative phrase selection a re not syntactic phrases but word n -grams, and are the same as the collection used in the translation model of the SMT system. The translation table obtained from the alignments is then our clas-sification problem being the translation of each source phrase a multi-class classification problem.

For the discriminative learning, each occurrence of a phrase is taken as a positive example for its current translation and negative for the rest of possible translations. This way the multi-class problem is binarized and converted into a one-vs-all decision. Let us see an example. The word Elm is found in the corpus together with the article: AlElm . This token is seen in 114 examples with 10 possible translations, with the following being the most frequent ones: 88 negative ones in the corpus, while there are six positive examples for the pair (AlElm, the flag), for instance (see Figure 1).
 which will be further considered in Section 6 to illustrate the full translation task. The word wqE appears in the corpus 289 times with 30 different trans-lations, such as: wqE :
Translations signed took place was signed occurred happened fell #examples 70 36 30 23 16 5 context of both translations should be different enough so that it can distin-guish the cases where the verb  X  X allen X  is more appropriate. This information can be encoded as features of the phrase.
 source sentence. That is, our vector of features is  X  ( f i ).Sinceweareinterested in including linguistic information in the learning process, the Arabic part of the parallel corpus must be annotated so that the feature set for each example can contain information of the source phrase. For this purpose we consider the part-of-speech (PoS), a coarser version of the PoS, and the BIO label resulting of a base phrase chunking for the phrase itself. 3 We also include information of the local context, five words to the left, and five to the right, by taking 3-grams of the linguistic information. A bag of words of the whole sentence is used to take into account the global context of the phrase. All of this collection of features make up  X  ( f i ). As an example, Table I shows the set of features to be used in the learning process for a case where AlElm is translated as  X  X nowledge X .
 previous set of features and the examples in the training parallel corpus. For instance, for the words AlElm and wqE discussed previously, 10 and 30 SVMs must be trained, respectively. When translating one phrase, the classifiers for every translation are considered, resulting into a collection of SVM scores that can be converted into probabilities using a softmax function [Bishop 1995]. We do not only obtain the most adequate translation but which is the probability of all of them. In other words, we do not select one translation but make all predictions available to the decoder as an alternative translation model. lation) prediction. We require a minimum number of examples in order to train the classifiers, let us say 100 in our experiments. For those phrases with fewer examples we extend the probability P DPT ( e | f ) with the standard MLE (Maximum Likelihood Estimation) pre diction. Even for a phrase with more than these 100 occurrences in the training corpus, there might be some of the translations with a representation in the corpus too small to be learned satis-factorily. As we will see in Section 6, we do not train a classifier for translation options that represent less than a 0 . 5% of the total number of examples of the given phrase; these cases are also completed with the MLE score. Whenever we combine both predictions, DPT and MLT, we normalize the probabilities to the percentage of examples estimated with each method so that the scores sum 1.
 of a log-linear model. A standard SMT system estimates the probability of a translation as the sum of several terms: where P ( e ) is the language model probability, lex ( f | e )and lex ( e | f )arethe generative and discriminative lexical translation probabilities respectively, P the phrase and word penalty models.
 our final translation probability to be: where P SMT ( e | f ) is the full sum of log-probabilities. As an alternative, we also In both cases, P DPT ( e | f ) interacts with the rest of components to select the final translation. 4. CORPUS AND PREPROCESSING We apply the discriminative phrase translation model to the Arabic-to-English translation task. In the following, we describe the data we use for that purpose and the preprocessing needed. 4.1 Corpus The training set is a compilation of six corpora supplied by the Linguistic Data Consortium (LDC) for the 2008 NIST Machine Translation Open Evaluation . 4 The sources for these corpora are the Agence France Press News Service, An Nahar, Assabah, Xinhua News Service, Language Weaver News, and Ummah Press Service. 100 words. A segment is the minimum aligned unit in the parallel corpus and corresponds to one or more sentences. The length ratio limit for obtaining the alignments with GIZA++ [Och and Ney 2003] forces us to discard segments that are more than nine times longer in one language than in the other. This filtering selects 123,662 lines, 99% of the total, resulting in a medium-sized corpus under the point of view of collecting alignments.
 lines from the same corpora proportionally to the training set. These small sets give us a fast development process. We use a larger test set with 1,357 sentences as subministrated for the 2008 NIST MT Evaluation Campaign to report our final analysis and results. 4.2 Preprocessing and Annotation The use of linguistic information in disambiguating the phrases makes it nec-essary to annotate the corpus beforehand. A minimal standard preprocessing in the corpus has been applied too, and it differs across languages. is no need to annotate the English part of the corpora. The only preprocessing has been to lowercase and tokenize the sentences.
 the codification of the texts. We romanize the original corpus with Buckwalter transliteration. As minor details, we alter the standard transliteration by us-ing the XML-friendly version which changes the characters &lt; , &gt; and &amp; to I, O, and W respectively. That allows us to generate the XML files necessary for the discriminative learning without problems. Note that actual presentation glyphs vary with context as well as entering into various ligatures. The liga-ture of the letters lam and alif ( + ) with the corresponding diacritics, , ,or , have not been detected in the automatic transliteration but converted afterward.

The standard Buckwalter transliteration has been a prerequisite necessary to annotate the Arabic part of the corpus using the AMIRA package [Diab et al. 2004]. This software uses the Yamcha SVM tools [Kudo and Matsumoto 2003] to apply the three steps we are interested in: tokenization, PoS tagging, and base phrase chunking of the input text. AMIRA includes models trained on news domain with the Arabic Penn TreeBank ATB 1 v3.0, ATB 2 v2.0, and ATB 3 v2.0. Finally, since the public version of AMIRA does not separate the determiner looked for all the words beginning with Al-in the Arabic WordNet 5 [Fellbaum et al. 2006], and when a word does not appear we segment out the determiner and adapt the chunk label as appropriate. Words and PoS remain the same. We have identified 309 words from the Arabic WordNet beginning with Al-.The Arabic WordNet contains word lemmas but we do not count with an Arabic lemmatizer. Therefore, we are comparing the stem and not the lemma with those words and there can be a loss in the precision of the segmentation. tence. Before any processing, the mean length of a sentence in our corpus has 27.4 tokens. The number increases to 31.8 when the clitics are segmented out, and goes up to 38.2 when also are the determiners. This has consequences when cleaning the corpus because the length of the English sentence remains the same, a mean of 34.5 tokens per sentence. The limit of GIZA++ for the ratio between the lengths of the sentences for calculating the alignments eliminates more sentences the more we segment the original text. In the case where both clitics and determiners have been separated from the stem, we have kept sen-tences shorter than 120 words instead of the 100 words limit of the other cases. With this we obtain three corpora in the NEWS domain differentiated by the level of segmentation with the main characteristics described in the left part of Table II. 5. DISCRIMINATIVE PHRASE SELECTION: THE LOCAL TASK Before approaching the full task of translation we show some details of the subtask of phrase selection. The strength of this method is its capability of us-ing the context of each phrase and the linguistic information available in order to select the best translation. And this is especially useful to solve ambiguities, as we have seen a very common semantic phenomenon in Arabic.
 features for training the classifier are extracted from both the source phrase and source sentence in Arabic but not from the target in English. From the phrase, we consider word, PoS, coarse PoS, and chunk label n -grams. The same features are extracted from the full sentence with the addition of the bag-of-words.
 alignments obtained with GIZA++. The input corpus is the same training set used for training the translation system (Section 4). From this corpus we ex-tract 588,220 phrase pairs, but most of them are not frequent enough to train a classifier based on their number of examples. If we restrict our analysis to phrases appearing more than 100 times in the training set and with more than one possible translation, a collection of 5,321 phrases is selected. Even if we are considering less than 1% of the total, we are keeping the most frequent ones and so they cover most of the corpus with more than half of the occurrences. For each of these phrases, we learn a binary SVM for every translation, unless for those which do not have a representative number of positive examples. A low number of examples of a given phrase translation can be evidence of a bad alignment, for instance. We minimize this effect by discarding translations that occur less than 0 . 5% of the phrase occurrences.

For training the SVMs we use the SVM light package [Joachims 1999] and for efficiency reasons we work with linear kernels. The regularization parame-ter of SVMs ( C ), the trade-off between the training error and the margin, is adjusted in the learning process for each phrase.
 obtained by SVMs and labelled as the discriminative phrase translation (DPT), and that given by the most frequent translation (MFT). Most of the phrases appear fewer than 500 times in the corpus, and for them an improvement in accuracy of 7 . 8 percentage points is obtained. The highest accuracies are for the most frequent phrases, but this already happens with the MFT. Besides, since the number of such phrases is small, the mean accuracy is not influenced much by them. The improvement in accuracy for all the phrases obtained with the DPT is of 7 . 5 percentage points, which is comparable to previous results on Spanish-to-English translation [Gim  X  enez and M ` arquez 2008].
 running example, AlElm . When training the classifiers with a set of features similar to that shown in Table I, we obtain after a 10-fold cross-validation an accuracy of 71 . 3%. The most frequent translation does it well 49 . 6% of the time. That is, it attains a 40% relative improvement on the selection of the phrase translation.
 Arabic phrase wqE . As before, the accuracy of the most frequent translation (30 . 6%) is beaten by the accuracy given by the SVMs (42 . 6%). Thisisthe general trend, the accuracy in the trans lation of phrases is improved with re-spect to that corresponding to the most frequent translation, but the amount of improvement depends on the phrase, the number of translations, and the number of examples. In the next section, we define a measure of phrase trans-lation accuracy for these phrases within translations given by the full machine translation system.
 6. FULL TRANSLATION TASK In the following, we investigate whether the improvement obtained for the local task of phrase selection has a positive repercussion on the global transla-tion task. 6.1 Baseline System Our baseline system follows the standard phrase-based SMT architecture, in which models are combined in a log-linear fashion. This architecture has the main advantage of allowing for considering additional feature functions further than the language and translation probability models typically used. Here, we use the standard features for an SMT system, that is, those in Equation (1). using the SRILM Toolkit [Stolcke 2002]. As for the translation models, we use the GIZA++ Toolkit to obtain the alignments, and the tools available with the Moses [Koehn et al. 2006, 2007] package for phrase extraction and estimations of maximum likelihood probabilities.
 candidate translations to 20 and set the distortion limit to six positions. Using these settings, the final search in the space of translations is accomplished by the Moses decoder.
 translation performance on a development set. For this optimization we use a minimum error rate training (MERT) [Och 2003] where BLEU [Papineni et al. 2002] is the reference score. 6.2 Segmentation in Arabic As a first step we determine which is the adequate degree of segmentation in the Arabic words. This is independent of the analysis of phrase selection, but will provide us with a higher baseline quality. For this, we use the three data sets introduced in Section 4.2 with three different levels of tokenization. With the coarser tokenization the sparsity of the vocabulary increases and the mean length of an Arabic sentence is 0.80 times the English one. The first level of clitic segmentation diminishes the sparsity and equals the ratio between lengths to 0.92. With the second level, Arabic sentences are already longer than the English ones with ratio 1.11. In all these cases we use a language model computed from each training set without the addition of out-of-domain data.
 when the sentence length in both languages is comparable, where punctua-tion marks and all the clitics except Al-are segmented. The additional sepa-ration of the determiner worsens the BLEU score by several possible reasons. First, because the method used to segment out Al-can be segmenting true full words. Second, because Arabic has some determiners which have no analogy in English such as those before adjectives that are added when the noun is de-termined as well. Finally, the difference in the sentence length and the errors on the Al-segmentation can worsen the quality of the alignments.
 ent segmentation methods and obtained the best results for the segmentation obtained with AMIRA, that is without separating Al-, for a corpus built from the corpora of the Arabic-to-English N IST task. The worst results in their case correspond to the method that most segmentates the corpus with a ratio between the mean Arabic sentence length and the English one of 1.20.
With these results in mind, we use in the following the Arabic part of the corpus with the clitic segmentation of AMIRA. 6.3 Discriminative Phrase Translation Finally, we integrate DPT predictions into the SMT system. To do this, we pre-calculate the DPT predictions for all possi ble translations of all source phrases appearing in the test (or development) set. Calculating these probabilities be-forehand allows us to use a standard decoder without any modification to es-timate them online, but a small trick is needed to distinguish every distinct instance of every distinct phrase. So, the input text is transformed by intro-ducing identifiers which correspond to the number of occurrences of the word seen in the test set before the current one. For instance, the second time the transliterated word AlElm appears in the set is annotated as AlElm 1 : For those words without DPT prediction there is not subindex.
 fied. Now each occurrence of every source phrase has a distinct list of phrase translation candidates with their DPT predictions. DPT predictions are only estimated for the phrases appearing in the test set. Still, indexing increments tremendously the size of the translation table,and we keep only the first 50 translations for every phrase. This is not a problem since, as we said when explaining the baseline system, we limit the decoder to use the first 20 trans-lations. Translations are sorted by weighting all the scores. Being the scores different, every system (baseline and D PT) already differs in the translation candidates list available to the decoder.
 have the minimum number of examples required (100 in our experiments), we complete the translation table by using the MLE prediction for that phrase. For those phrases with only some of the translation probabilities obtained with the DPT method (the others having less than a 0 . 5% of positive examples in our experiments), we normalize the probabilities of each method, MLE and DPT, to their number of examples with respect to the total.
 ond time it appears in the test set. In this case, the preferred translation would be the same both according to P DPT ( e | f )andto P MLE ( e | f ), but one can already see in the table that the distribution of the probability mass is different for both predictions and that can alter the best choice.
 decoder does not always use the DPT prediction as the best translation. DPT is competing with the MLE prediction and the remaining features shown in Equation (2). The weight of every score is determined during the MERT tuning process. In our results, the DPT prediction always has a larger weight than the MLE one, being  X  DPT  X  3  X  MLE . We checked another configuration as well, where the discriminative probabilities P DPT ( e | f )replace P MLE ( e | f )insteadof being added as an additional feature. We denote by DPT this last system where the DPT prediction replaces the MLE one, and by DPT + the system where the DPT prediction is added.
 by using an heterogeneous set of metrics for evaluation. In previous sections, we used a lexical metric to evaluate the quality of the translation, BLEU, which beside of being one of the standard approaches allows for a fast development process. Here, for the final analysis, we use the IQ MT package [Gim  X  enez and Amig  X  o 2006], which provides a rich set of metrics at different linguistic levels. We have selected a representative set of metrics based on different similarity criteria: (1) Lexical n -gram similarity on word forms (including the following indi-(2) Shallow-syntactic similarity on part-of-speech tags and base phrase (3) Syntactic similarity on dependency and constituent trees (Dependency (4) Shallow-semantic similarity on semantic roles (Semantic Roles  X  X R X  tic elements, where a linguistic element can be any of the constituents just mentioned: words, parts-of-speech, dependency relations, syntactic phrases, named enties, semantic roles, etc. We have also defined a phrase translation accuracy (A pt ) that measures the percentage of phrases with the demanded conditions to estimate a DPT prediction with a correct translation. By a cor-rect translation it is understood a translation that is found in the reference too or at least in one of them in case of having multiple references. Metrics beyond the lexical ones are named as follows. The first two letters denote the family, then it is shown an O for overlapping or an M for matching and the corresponding linguistic element. The symbol is added for averages over all the types of a given linguistic element. With this definition  X  X R-O r - X  X epre-sents the average lexical overlap among semantic roles of the same type. A more detailed description of the metric set may be found in the IQ MT technical manual [Gim  X  enez 2007].
 paign and evaluate the translations against four references so that the derived conclusions are reliable. The results of our automatic evaluation can be read in Table V, where we show the score for the preferred system in boldface. The set of metrics is calculated for the two systems with DPT prediction ( DPT and DPT + ) together with the baseline where there is no DPT prediction (indicated by SMT in the table). In general, improvements are obtained with the DPT systems at the three linguistic levels: lexical, syntactic, and semantic. DPT system than for the SMT system; the difference is of 1.1 percentual points if we consider the DPT + instead. This accuracy refers only to phrases with a DPT prediction, but there is a loss in the gain obtained in the isolated task due to the interaction of the DPT model with the rest, that is, translation and language models.
 tem over the baseline. The DPT + is of the same order or slightly better than the SMT system as well, but the substitution of the MLE predictions by the DPT ones seems to be more effective, probably because of the minor number of parameters to optimize. For this system, the BLEU score increases from 31.0 to 32.4 and the NIST one from 8.7 to 8.9.
 erate 1,000 sets by pair bootstrap resampling of the original test sets [Koehn 2004]. With the previous values, the DPT system shows to be statistically better than both DPT + and SMT systems, and DPT + statistically better than SMT .
 rics based on shallow parsing (SP) and constituent parsing (CP) behave as the lexical metrics and favor the DPT system. The only scores indifferent to the discriminative learning are those reflecting similarities among dependency trees (DP), since two out of six metrics prefer the baseline.
 tween the semantic roles (SR) of the translation and the target increases for the discriminative methods. The metrics which do not take into account the lexical realization of the linguistic element favour the DPT system, those con-sidering the lexical realization prefer the DPT + one. of the translations at the system level, that is, for all the test set, but one can also study the nature of the improvement by checking how concrete transla-tions are modified. Of course, there is not a one-to-one correspondence between a particular translation preferred by t he discriminative method and such mod-ification because all the components play a role in the final election of the full translation, but anyway one can extract some general ideas.
 of the phrases disambiguated by the discriminative method with a frequency  X  (100 &lt; X &lt; 500). As seen at the beginning of this section with the example sentence for the phrase AlElm , several phrases with DPT prediction coexist in a same sentence. We calculate all the set of metrics shown in Table IV at a sentence level for this small subset and analyse the results.
 ual sentences get both benefits and damages from the discriminative phrase translation. Tables VI, VII, and VIII show the translations of three of the sen-tences: Example A, B and C respectively. In those sentences, some general characteristics are outlined.
 a phrase that according to its frequency in the corpus has a probability one order of magnitude lower than the most frequent translation gets promoted due to the DPT prediction (the isolated task of this phrase selection has been analysed in Section 5). This way wqE is translated as  X  X ell X  instead of the MFT  X  X igned X  being in agreement with two of the four references. Lexical metrics are the ones that reflect better this type of improvements.
 to determine the translation of the whole sentence, the addition of the DPT prediction can alter the structure of the output. For instance, Example B in Table VII shows a case where the effect is a reordering of the phrases. In the given example, the reorder damages the final translation and the meaning of the original sentence is modified.
 tions. Articles and prepositions are more frequent in the translations obtained with the DPT method. In fact, the mean length of these translations is one word larger than the ones with the baseline. In the sentence of Table VIII that corrects the output from  X  X onday X  to  X  X n Monday X  and from  X  X trategy X  to  X  X he strategy X . In this case, this has a positive repercussion especially with the BLEU metric since the length of the matching n -grams is larger, but it dam-ages the translation of headlines which are common in news corpora such as the one we use. 7. CONCLUSIONS We have shown the positive impact of including a discriminative phrase trans-lation model in a SMT architecture designed for the Arabic-to-English trans-lation task.
 the full translation. By training a classifier to choose the adequate phrase translation for every instance of a phrase, we have obtained a gain of 7 . 5 percentual points in accuracy with resp ect to the answer that would give the most frequent translation. These classifiers are informed of the context of the source phrase and its part-of-speech and chunk label. Information on the tar-get phrase would further improve the results, but the integration in a SMT system would not be straightforward and one would need a new architecture. relative frequency counts, we study how the gain in accuracy achieved by the DPT predictions affects the translatio n quality according to automatic evalu-ation metrics. Improvements are obtained at the three linguistic levels ana-lyzed: lexical, syntactic and semantic. The DPT system that substitutes the probability score from the maximum likelihood estimate P MLE ( e | f )bythedis-criminative prediction P DPT ( e | f ) is preferred by a 74% of the calculated met-rics, that is, 28 out of 38. Just in five cases the baseline is not improved; for the remaining ones, the best system is that combining both P MLE ( e | f )and P language pair [Gim  X  enez and M ` arquez 2008], but as expected from the semantic ambiguities of Arabic, the gain is larger for this language. The Arabic phrases are translated locally with more accuracy (2 . 5 percentual points more) than the Spanish ones, and this is captured by all le xical metrics in the full translation. Contrary to the Spanish case, the improv ement in lexical selection in Arabic has a positive repercussion not only on semantics but on syntax as well. Also, corpus heterogeneity X  X everal source s in our case as compared to one source in our previous experiments on the case of Spanish-English (EuroParl) X  X ay have contributed positively. Recall that our methods have been designed to model lexical selection based on source context, thus, in principle, they should be far more robust to domain shifts.

