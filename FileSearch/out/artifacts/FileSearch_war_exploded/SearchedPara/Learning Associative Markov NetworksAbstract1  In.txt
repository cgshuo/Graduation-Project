 Ben Taskar btaskar@cs.stanford.edu Vassil Chatalbashev vasco@cs.stanford.edu Daphne Koller koller@cs.stanford.edu Computer Science Department, Stanford University, Stanford, CA oped for the principal machine learning problem of assigning to a single object one of K labels consis-tent with its properties. Many classification problems, however, involve sets of related objects whose labels must also be consistent with each other. In hypertext or bibliographic classification, labels of linked and co-cited documents tend to be similar (Chakrabarti et al., 1998; Taskar et al., 2002). In proteomic analysis, lo-cation and function of proteins that interact are often highly correlated (Vazquez et al., 2003). In image pro-cessing, neighboring pixels exhibit local label coher-ence in denoising, segmentation and stereo correspon-dence (Besag, 1986; Boykov et al., 1999a).
 joint distributions of the label variables by modeling their local interactions. Such models are encoded by a graph, whose nodes represent the different object la-bels, and whose edges represent direct dependencies between them. For example, a Markov network for the hypertext domain would include a node for each webpage, encoding its label, and an edge between any pair of webpages whose labels are directly correlated (e.g., because one links to the other).
 networks for the purpose of collectively classifying sets of related instances. The focus has been on dis-criminative training, which, given enough data, gen-erally provides significant improvements in classifica-tion accuracy over generative training. For example, Markov networks can be tra ined to maximize the con-ditional likelihood of the labels given the features of the objects (Lafferty et al., 2001; Taskar et al., 2002). Recently, maximum margin-based training has been shown to additionally boost accuracy over conditional likelihood methods and allow a seamless integration of kernel methods with Markov networks (Taskar et al., 2003a).
 inference in the underlying network, which is a core subroutine for all methods for training Markov net-works. Probabilistic inference is NP-hard in general, and requires exponential time in a broad range of practical Markov network structures, including grid-topology networks (Besag, 1986). One can address the tractability issue by limiting the structure of the un-derlying network. In some cases, such as the the quad-tree model used for image segmentation (Bouman &amp; Shapiro, 1994), a tractable structure is determined in advance. In other cases (e.g., (Bach &amp; Jordan, 2001)), the network structure is lea rned, subject to the con-straint that inference on th ese networks is tractable. In many cases, however, the topology of the Markov network does not allow tractable inference. In the hy-pertext domain, the network structure mirrors the hy-perlink graph, which is usually highly interconnected, leading to computationally intractable networks. sible for an important subclass of Markov networks  X  X etworkswith attractive potentials . This subclass, which we call associative Markov networks (AMNs) , contains networks of discrete variables with K labels each and arbitrary-size clique potentials with K pa-rameters that favor the same label for all variables in the clique. Such positive interactions capture the  X  X uilt by association X  pattern of reasoning present in many domains, in which c onnected ( X  X  ssociated X ) variables tend to have the same label. AMNs are a natural fit for object recognition and segmentation, webpage classification, and many other applications. approach to training Markov networks, presented by Taskar et al. (2003a). In this formulation, the learn-ing task is to find the Markov network parameteriza-tion that achieves the highest confidence in the target labels. In other words, the goal is to maximize the margin between the target labels and any other label assignment. The inference subtask in this formulation of the learning problem is one of finding the best joint (MAP) assignment to all of the variables in a Markov network. By contrast, other learning tasks (e.g., max-imizing the conditional likelihood of the target labels given the features) often require that we compute the posterior probabilities of different label assignments, rather than just the MAP.
 an integer programming problem. We show how we can approximate the maximum margin Markov net-work learning task as a quadratic program that uses a linear program (LP) relaxation of this integer program. This quadratic program can be solved in polynomial time using standard techniques. We show that when-ever the MAP LP relaxation is guaranteed to return integer solutions, the approximate max-margin QP provides an optimal solution to the max-margin op-timization task. In particular, for associative Markov networks over binary variables ( K = 2), this linear program provides exact answers. For the non-binary case ( K&gt; 2), the approximate quadratic program is not guaranteed to be optimal, but our empirical re-sults suggest that the solutions work well in practice. To our knowledge, our method is the first to allow training Markov networks of arbitrary topology. ables Y = { Y 1 ,...,Y N } , where each variable corre-sponds to an object we wish to classify and has K possible labels: Y i  X  X  1 ,...,K } .Anassignmentof values to Y is denoted by y . A Markov network for Y defines a joint distribution over { 1 ,...,K } N . graph over the nodes Y = { Y 1 ,...,Y N } . In general, a Markov network is a set of cliques C , where each clique c  X  X  is associated with a subset Y Y i in a clique c form a fully connected subgraph (a clique) in the Markov network graph. Each clique is accompanied by a potential  X  c ( Y c ), which associates a non-negative value with each assignment y c to Y c .The Markov network defines the probability distribution: where Z is the partition function given by Z = discussion on pairwise Markov networks. We extend our results to higher-order interactions in Sec. 3. A pairwise Markov network is simply a Markov network where all of the cliques involve either a single node or apairofnodes. Thus,inapairwiseMarkovnetwork with edges E = { ( ij ) } ( i&lt;j ), only nodes and edges are associated with potentials  X  i ( Y i )and  X  ij ( Y i ,Y A pairwise Markov net defines the distribution where Z is the partition function given by Z = features of the objects x i  X  d n and features of the re-lationships between them x ij  X  d e . In hypertext clas-sification, x i might be the counts of the words of the document i , while x ij might be the words surround-ing the hyperlink(s) between documents i and j .The simplest model of dependence of the potentials on the features is a log-linear combination: log  X  i ( k )= w k n and log  X  ij ( k, l )= w k,l e  X  x ij ,where w k n and w k,l label-specific row vectors of node and edge parameters, of size d n and d e , respectively. Note that this formula-tion assumes that all of the nodes in the network share the same set of weights, and similarly all of the edges share the same weights.
 dicators { y k i } ,where y k i = I ( y i = k ). With these defi-nitions, the log of conditional probability log P w ( y | x is given by: Note that the partition function Z w ( x ) above depends on the parameters w and input features x , but not on the labels y i  X  X .
 and edge weight vectors w n =( w 1 n ,..., w K n )and w a vector of all the weights, of size d = Kd n + K bels vectors, y n =( ...,y 1 i ,...,y K i ,... ) and y e vector of all labels y =( y n , y e )ofsize L = KN + K 2 | E | . Finally, we define an appropriate d  X  L matrix X such that The matrix X contains the node feature vectors x i and edge feature vectors x ij repeated multiple times (for each label k or label pair k, l respectively), and padded with zeros appropriately.
 MAP (maximum a posteriori) assignment  X  X heas-signment y that maximizes log P w ( y | x ). It is straightforward to formulate the MAP inference task as an integer linear program: The variables are the as-signments to the nodes y k i and edges y k,l ij which must be in the set { 0 , 1 } , and satisfy linear normalization and agreement constraints. The op timization criterion is simply the linear function wXy , which acorresponds to the log of the unnormalized probability of the as-signment y .
 and approximate it as a linear program by relaxing the integrality constraints on y k i , with appropriate con-straints. For example, Wainwright et al. (2002) pro-vides a natural formulation of this form that is guar-anteed to produce integral solutions for triangulated graphs. lems for which the above relaxation is particularly use-ful. These networks, which we call associative Markov networks (AMNs) , encode situations where related variables tend to have the same value.
 text of image processing, where nearby pixels are likely to have the same label (Besag, 1986; Boykov et al., 1999b). In this setting, a common approach is to use a generalized Potts model (Potts, 1952), which penalizes assignments that do not have the same label across the edge:  X  ij ( k, l )=  X  ij ,  X  k = l and  X  ij ( k, k )=1,where  X  show that the MAP problem can be formulated as a min-cut in an appropriately constructed graph. Thus, the MAP problem can be solved exactly for this class of models in polynomial time. For K&gt; 2, the MAP prob-lem is NP-hard, but a procedure based on a relaxed linear program guarantees a factor 2 approximation of the optimal solution (Boykov et al., 1999b; Kleinberg &amp; Tardos, 1999). Kleinberg and Tardos (1999) extend the multi-class Potts model to have more general edge potentials, under the constraints that negative log po-tentials  X  log  X  ij ( k, l ) form a metric on the set of la-bels. They also provide a solution based on a relaxed LP that has certain approximation guarantees. showed how to optimize energy functions containing binary and ternary interactions using graph cuts, as long as the parameters satisfy a certain regularity con-dition. Our definition of associative potentials below also satisfies the Kolmogorov and Zabih regularity con-dition for K = 2. However, the structure of our poten-tials is simpler to describe and extend for the multi-class case. We use a linear programming formulation (instead of min-cut) for the MAP inference, which al-lows us to use the maximum margin estimation frame-work, as described below. Note however, that we can also use min-cut to perform exact inference on the learned models for K = 2 and also in approximate inference for K&gt; 2asinBoykov et al. (1999a). in several ways. Importantly, AMNs allow different la-bels to have different attraction strength:  X  ij ( k, k )=  X  ij ,where  X  additional flexibility is important in many domains, as different labels can have very diverse affinities. For example, foreground pixels tend to have locally coher-ent values while background is much more varied. problem for these networks can be written as: max s . t .y k i  X  0 ,  X  i, k ; Note that we substitute the constraint y k ij = y k i  X  y by two linear constraints y k ij  X  y k i and y k ij  X  y This works because the coefficient w k,k e  X  x ij is non-negative and we are maximizing the objective func-tion. Hence,at the optimum y k ij =min( y k i ,y k j ),which is equivalent to y k ij = y k i  X  y k j .
 pairwise interactions between variables, with poten-tials over cliques involving m variables  X  ( y i 1 ,...,y In this case, the clique potentials are constrained to have the same type of structure as the edge poten-tials: There are K parameters  X  ( k,...,k )=  X  k ij and the rest of the entries are set to 1. In particular, using this additional expressive power, AMNs allow us to en-code the pattern of (soft) transitivity present in many domains. For example, consider the problem of pre-dicting whether two proteins interact (Vazquez et al., 2003); this probability may increase if they both in-teract with another protein. This type of transitivity could be modeled by a terna ry clique that has high  X  for the assignment with all interactions present. lem similar to Eq. (1), where we have a variable y k c for each clique c and for each label k , which represents the event that all nodes in the clique c have label k : max linear programs Eq. (1) and Eq. (2) are guaranteed to produce an integer solution when a unique solution exists.
 Theorem 3.1 If K =2 , for any objective wX ,the linear programs in Eq. (1) and Eq. (2) have an integral optimal solution.
 We omit the proof here due to lack of space. (See the longer version of the paper at http://cs.stanford.edu/~btaskar/ . ) This result states that the MAP problem in binary AMNs is tractable, regardless of network topology or clique size. In the non-binary case ( K&gt; 2), these LPs can produce fractional solutions and we use a rounding procedure to get an integral solution. In the longer version of the paper, we show that the approximation ratio of the rounding procedure is the inverse of the size of the largest clique (e.g., 1 2 for pairwise networks). Although artificial examples with frac-tional solutions can be easily constructed by using symmetry, it seems that in real data such symmetries are often broken. In fact, in all our experiments with K&gt; 2 on real data, we never encountered fractional solutions. weights w of a Markov network given a labeled train-ing instance ( x ,  X  y ). For simplicity of exposition, we assume that we have only a single training instance; the extension to the case of multiple instances is en-tirely straightforward. Note that, in our setting, a single training instance actually contains multiple ob-jects. For example, in the hypertext domain, an in-stance might be an entire website, containing many inter-linked webpages.
 The M 3 N Framework. The standard approach of learning the weights w given ( x ,  X  y ) is to maximize the log P w (  X  y | x ), with an additional regularization term, which is usually taken to be the squared-norm of the weights w (Lafferty et al., 2001). An alternative method, recently proposed by Taskar et al. (2003a), is to maximize the margin of confidence in the true la-bel assignment  X  y over any other assignment y =  X  y . They show that the margin-maximization criterion provides significant improv ements in accuracy over a range of problems. It also allows high-dimensional fea-ture spaces to be utilized by using the kernel trick, as in support vector machines. The maximum margin Markov network (M 3 N) framework forms the basis for our work, so we begin by reviewing this approach. is to maximize our confidence in the true labels  X  y rela-tive to any other possible joint labelling y . Specifically, we define the gain of the true labels  X  y over another possible joint labelling y as: In M 3 Ns, the desired gain takes into account the num-ber of labels in y that are misclassified,  X (  X  y , y ), by scaling linearly with it: max  X  s . t . wX (  X  y  X  y )  X   X   X (  X  y , y ); || w || 2  X  Note that the number of incorrect node labels  X (  X  y , y ) can also be written as N  X   X  y n y n . (Whenever  X  y i and y i agree on some label k ,wehavethat X  y k i =1and y i = 1, adding 1 to and adding a slack variable for non-separable data, we obtain a quadratic program (QP) with exponentially many constraints: This QP has a constraint for every possible joint as-signment y to the Markov network variables, resulting in an exponentially-sized QP. Taskar et al. show how structure in the dual of this QP can be exploited to al-low an efficient solution when the underlying network has low treewidth.
 we now derive a more generally applicable approach for exploiting structure and relaxations in max-margin problems. As our first step, we replace the exponen-tial set of linear constraints in the max-margin QP of Eq. (3) with the single equivalent non-linear con-straint: This non-linear constraint essentially requires that we find the assignment y to the network variables which has the highest probability relative to the parameter-ization wX  X   X  y n . Thus, optimizing the max-margin QP contains the MAP inference task as a component. problem as an integer program, and then relax it into a linear program. Inserti ng the relaxed LP into the QP of Eq. (3), we obtain: where Y is the space of all legal fractional values for y . In effect, we obtain a QP with a continuum of constraints, one for ever y fractional assignment to y . guaranteed to provide integ er solutions, the integer and relaxed constraint sets coincide, so that the ap-proximate QP is computing precisely the optimal max-margin solution. In the general case, the linear re-laxation strengthens the constraints on w by poten-tially adding constraints corresponding to fractional assignments y . Fig. 1 shows how the relaxation of the max subproblem reduces the feasible space of w and  X  . Note that for every setting of the weights w that produces fractional solutions for the LP relax-ation, the approximate constraints are tightened be-cause of the additional fractional assignments y .In this case, the fractional MAP solution is better than any integer solution, including  X  y , thereby driving up the corresponding slack  X  . By contrast, for weights w for which the MAP LP is integer-valued, the margin has the standard interpretation as the difference be-tween the probability of  X  y and the MAP y (according to w ). As the objective includes a penalty for the slack variable, intuitively, minimizing the objective tends to drive the weights w away from the regions where the solutions to the MAP LP are fractional.
 integer program within the QP with a linear program, the resulting QP does not app ear tractable. However, here we can exploit fundamental properties of linear programming duality (Bertsimas &amp; Tsitsiklis, 1997). Assume that our relaxed LP for the inference task has the form: for some polynomial-size A , B , b .(Forexample, Eq. (1) and Eq. (2) can be easily written in this com-pact form.) The dual of this LP is given by: When the relaxed LP is feasible and bounded, the value of Eq. (6) provides an upper bound on the pri-mal that achieves the same value as the primal at its minimum. If we substitute Eq. (6) for Eq. (5) in the QP of Eq. (4), we obtain a quadratic program over w ,  X  and z with polynomially many linear constraints: rect consequence of the co nnection between the max-margin criterion and the MAP inference problem. The transformation is useful whenever we can solve or ap-proximate MAP using a compact linear program. tion applies to any situation where the MAP problem can be effectively approxim ated as a linear program. In particular, the LP relaxation of Eq. (1) provides us with precisely the necessary building block to pro-vide an effective solution for the QP in Eq. (4) for the case of AMNs. As we discussed, the MAP problem is precisely the max subproblem in this QP. In the case of AMNs, this max subproblem can be replaced with the relaxed LP of Eq. (1). In effect, we are replacing the exponential constraint set  X  one which includes a constraint for every discrete y , with an infinite con-straint set  X  one which includes a constraint for every continuous vector y in
Y = { y : y k as defined in Eq. (1).
 rameters w ,werequirethat w k,l e =0 ,  X  k = l and w assume (without loss of generality) that x ij  X  0, and constrain w k,k e  X  0. Incorporating this constraint, we obtain our basic AMN QP: Eq. (7), by taking the dual of the LP used to represent the interior max. Specifically, max y  X  X  wXy  X   X  y n  X  y n is a feasible and bounded linear program in y ,witha dual given by: min s . t .z i  X  In the dual, we have a variable z i for each normaliza-tion constraint in Eq. (1) and variables z k ij ,z k ji for each of the inequality constraints.
 min s . t . wX X  y  X  N +  X   X  that Eq. (10) learns exact max-margin weights for Markov networks of arbitrary topology. For K&gt; 2, the linear relaxation leads to a strengthening of the constraints on w by potentially adding constraints cor-responding to fractional assignments y .Thus,theop-timal choice w , X  for the original QP may no longer be feasible, leading to a different choice of weights. How-ever, as our experiments show, these weights tend to do well in practice.
 structure of the problem: max s . t . X  k i  X  0 ,  X  i, k ; ables have an intuitive probabilistic interpretation. In the binary case, the set of the variables  X  k i , X  k ij cor-responds to marginals of a distribution (normalized to C ) over the possible assignments y .(Thisasser-tion follows from taking the dual of the original ex-ponential size QP in Eq. (3).) Then the constraints that  X  k ij  X   X  k i and  X  k ij  X   X  k j can be explained by the fact that P ( y i = y j = k )  X  P ( y i = k )and P ( y i = y j = k )  X  P ( y j = k ) for any distribution P ( y ). For K&gt; 2, the set of the variables  X  k not correspond to a valid distribution.
 One important consequence of these relationships is that the node parameters are all support vector ex-pansions. Thus, the terms in the constraints of the form w n x can all be expanded in terms of dot products x Therefore, we can use kernels K ( x i , x j ) to define node parameters. Unfortunately, the positivity constraint on the edge potentials, and the resulting  X  k e dual vari-able in the expansion of the edge weight, prevent the edge parameters from being kernelized in a similar way. tion domains, of very different structure.
 Reuters. We ran our method on the ModApte set of the Reuters-21578 corpus. We selected four cate-gories containing a substantial number of documents: crude, grain, trade ,and money-fx . We eliminated doc-uments labeled with more than one category, and rep-resented each document as a bag of words. The re-sulting dataset contained around 2200 news articles, which were split into seven folds where the articles in each fold occur in the same time period. The reported results were obtained using se ven-fold cross-validation with a training set size of  X  200 documents and a test set size of  X  2000 documents.
 bag of words as features. Since we train and test on articles in different time periods, there is an inherent distribution drift between our training and test sets, which hurts the SVM X  X  performance. For example, there may be words which, in the test set, are highly indicative of a certain label, but are not present in the training set at all since they were very specific to a particular time period (see (Taskar et al., 2003b)). ticles as an indicator of how likely they are to have the same label. The intuition is that two documents that have similar text are likely to share the same label in any time period, so that adding associative edges be-tween them would result in better classification. Such positive correlations are exactly what AMNs represent. In our model, we linked each document to its two clos-est documents as measured by TF-IDF weighted cosine distance. The TF-IDF sco re of a term was computed as: (1 + log tf )log N df where tf is the term frequency, N is the number of total documents, and df is the doc-ument frequency. The node features were simply the words in the article corresponding to the node. Edge features included the actual TF-IDF weighted cosine distance, as well as the bag of words consisting of union of the words in the linked documents.
 dict one category vs. all remaining categories. Fig. 2(a) shows that the AMN model achieves a 13.5% average error reduction over the baseline SVM, with improve-ment in every category. Applying a paired t-test com-paring the AMN and SVM over the 7 folds in each category, crude, trade, grain, money-fx , we obtained p-values of 0.004897, 0.017026, 0.012836, 0.000291 re-spectively. These results indicate that the positive in-teractions learned by the AMN allow us to correct for some of the distribution drift between the training and test sets.
 Hypertext. We tested AMNs on collective hy-pertext classification, using the variant of the We-bKB dataset (Craven et al., 1998) used by Taskar et al. (2002). This data set contains web pages from four different Computer Science departments: Cornell, Texas, Washington, and Wisconsin. Each page is la-beled as one of course, faculty, student, project, other . Our goal in this task is to exploit the additional struc-tured information in hypertext using AMNs.
 predicting categories based on the text content of the webpage. The words are represented as a bag of words. For the AMN model, we used the fact that a web-page X  X  internal structure can be broken up into dis-joint sections . For example, a faculty webpage might have one section that discu sses research, with a list of links to relevant research projects, another section with links to student webpages, etc. Intuitively, if we have links to two pages in the same section, they are likely have the same topic. As AMNs capture pre-cisely this type of positive correlation, we added edges between pages that appear as hyperlinks in the same section of another page. The node features for the AMN model are the same as for the multiclass SVM. pages from three of the schools in the dataset and test on the remaining one. The results, shown in Fig. 2(b), demonstrate a 30% relative reduction in test error as a result of modeling the positive correlation be-tween pages in the AMN model. The improvement is present when testing on each of the schools. We also trained the same AMN model using the RMN ap-proach of Taskar et al. (2002). In this approach, the Markov network is trained to maximize the conditional log-likelihood, using loopy belief propagation (Yedidia et al., 2000) for comput ing the posterior probabilities needed for optimization. Due to the high connectiv-ity in the network, the algorithm is not exact, and not guaranteed to converge to the true values for the poste-rior distribution. In our results, RMNs achieve a worse test error than AMNs. We note that the learned AMN weights never produced fractional solutions when used for inference, which suggest s that the optimization suc-cessfully avoided problematic parameterizations of the network, even in the case of the non-optimal multi-class relaxation. margin training of associative Markov networks, a subclass of Markov networks that allows only posi-tive interactions between related variables. Our ap-proach relies on a linear programming relaxation of the MAP problem, which is the key component in the quadratic program associated with the max-margin formulation. We thus provide a polynomial time algo-rithm which approximately solves the maximum mar-gin estimation problem for any associative Markov network. Importantly, our method is guaranteed to find the optimal (margin-maximizing) solution for all binary-valued AMNs, regardless of the clique size or the connectivity. To our knowledge, this algorithm is the first to provide an effective learning procedure for Markov networks of such general structure.
 the LP relaxation of the MAP problem provides exact solutions. In the non-binary case, we are not guar-anteed exact solutions, but we can prove constant-factor approximation bounds on the MAP solution re-turned by the relaxed LP. It would be interesting to see whether these bounds provide us with guarantees on the quality (e.g., the margin) of our learned model. to cover a large number of interesting applications. We have explored only two such applications in our exper-imental results, both in the text domain. It would be very interesting to consider other applications, such as image segmentation, extracting protein complexes from protein-protein interaction data, or predicting links in relational data.
 tive Markov networks, it is clear that many applica-tions call for repulsive potentials. For example, the best classification accura cy on the WebKB hypertext data set is obtained in a maximum margin frame-work (Taskar et al., 2003a), when we allow repulsive potentials on linked webpages (representing, for ex-ample, that students tend not to link to pages of stu-dents). While clearly we cannot introduce fully gen-eral potentials into AMNs without running against the NP-hardness of the general problem, it would be in-teresting to see whether we can extend the class of networks we can learn effectively.

