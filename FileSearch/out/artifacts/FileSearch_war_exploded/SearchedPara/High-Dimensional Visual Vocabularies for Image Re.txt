 In this paper we formulate imag e retrieval by text query as a vector space classification problem. This is achieved by creating a high-dimensional visual vocabular y that represents the image documents in great detail. We show how the representation of these image documents enables the application of well known text retrieval techniques such as Rocchio tf-idf and na X ve Bayes to the semantic image retrieval problem . We tested these methods on a Corel images subset and achieve state-of-the-art retrieval performance using the proposed methods. H.3.1 [ Content Analysis and Indexing ]: Abstracting methods. Algorithms, Measurement, Experimentation. Semantic image indexing, vector space model. When retrieving images by keyword, algorithms are required to, a priori, index images with a set W of query keywords. Such algorithms semantically analyse images and assign probabilities to the keywords. In this paper we show how, by carefully creating a high-dimensional visual vocabulary, we enable the application of text categorization algorithms to index images. Unlike Duygulu et al. [1], Lavrenko et al. [3] and others, who have explored the idea of visual vocabularies ba sed on image segmentation, our approach creates a high-dimensi onal visual vocabulary based on tiled regions and their colour and te xture. This approach is similar to a bag-of-words approach in image processing when considering a large set of words. Section 2 describes how to creat e the high-dimensional visual vocabulary that enables the application of text search techniques such as Rocchio text classifiers (Section 3), and na X ve Bayes text classifiers (Section 4). Section 5 presents experimental results. In the classic vector space model each document is represented as a vector d corresponds to the frequency of a given term vocabulary of T terms. In our formulation of semantic image retrieval as a vector space model we create a visual vocabulary where each term corresponds to a set of homogenous visual characteristics (colour and texture features). Since we are going to use a single vocabulary to represent all images, we need a set of visual terms that is able to represent them. Thus, we need to check which visual characteristics are more common in the dataset. For example, if there are a lot of images with a wide range of blue tones we require a larger number of visual terms representing the different blue tones. This draws on the idea that to learn a good high-dimensional visual voca bulary we would benefit from examining the entire dataset to look for the most common set of colour and texture features. The way we build the high-dimensional visual vocabulary is by clustering the entire dataset and representing each term as a cluster. We follow the approach presented in [4], where the entire dataset is clustered with a hierarchical EM algorithm using a Gaussian mixture model. This a pproach generates a hierarchy of cluster models that corresponds to a hierarchy of vocabularies with a different number of terms. The only difference between our formulation and the traditional vector space model is that we use ( ) | i Pt d instead of the classic term frequency ( ) | i TF t d . This is equivalent because all documents are represented by a high-dimensional visual vocabulary of length T and ( ) ( ) || ii Pt d T TFt d  X  X  X  . The Rocchio classifier is a classifier based on tf-idf, initially proposed as a relevance feedback algorithm [6] but also used in the area of text classification [2]. Both keywords and documents are represented as vectors, and the closer a document j d keyword vector j w document and the keyword in the vector space. A document j is represented as () 1 ,..., j T ddd = dimension is the probability of term i t in the document multiplied by the term X  X  inverse document frequency () i The inverse document frequency is de fined as the logarithm of the inverse of the probability of a term over the entire collection D , A keyword is then represented by a vector j w difference of the averages of the vectors wrt positive example documents For retrieval scenarios, documents are ranked according to their similarity to the queried keyword. We use the cosine similarity measure as a baseline, Experiments in section 5 illustrate the application of the Rocchio classifier to semantic image retrieval. The na X ve Bayes text classifier results from the direct application of Bayes law and from the use of strong independence assumptions between terms in a document, A document can be represented as an event model of term presence or term count, leading to the choice of a binomial or multinomial model respectively, see [5]. We choose the multinomial distribution as the binomial distribution is too limiting given the probabilistic nature of our terms. Using the multinomial model of ev ents, we express  X  X he number of times a term occurs in a document X  as ( ) | i T , the vocabulary size, is quite large we achieve enough granularity to represent the presence of visual keywords as integers. Given this, the probability of a document d given a keyword j w is expressed as a multinomial over all terms, where () Pd is the probability of document d having length d . Note that when plugging the multinomial distribution into Equation (1) the term ( ) ( ) 1|! i Pt dT is canceled. In addition to this, all documents are assumed to have the same length, meaning that T , ! d and () Pd are constants, which allow us to discard them and keep only the proportionality relation Now, we are left with the task of computing the probability of a term i t for a given keyword j w At this point the complete expression of the multinomial na X ve Bayes model can be written as In retrieval scenarios, documents are ranked according to their probability for the queried keyword. In annotation scenarios, documents are labelled with the set of keywords that maximize When formulating na X ve Bayes in the log-odds space, we see that it is a linear model, and in annotation problems we avoid decision thresholds. We used the same set of 4500 Corel images for training and 500 images for testing as in [1, 3]. E ach image is annotated with 1 to 5 keywords from a set of 179 keywords. For each single keyword we used both classifiers to rank all test images and then computed the corresponding Average Precision. The mean of all AP (MAP) versus the vocabulary size is depicted on Figure 1. As was expected, precision increases w ith the vocabulary size. Curve irregularities are caused by the way the visual vocabulary is obtained, see [4] for details. The Rocchio tf-idf and na X ve Bayes classifiers achieve a maximu m of 22.7% and 25.2% MAP respectively, which is comparable to the 24.8% obtained in [3]. This experiment shows that simple text based techniques, such as tf-idf, the Rocchio classifier and na X ve Bayes, can be successfully applied to semantic image retrieval when we use a high-dimensional visual vocabulary, opening the door to the application of other te xt based techniques. [1] P. Duygulu, K. Barnard, N. de Freitas, D. Forsyth, "Object [2] T. Joachims, "A probabilis tic analysis of the Rocchio [3] V. Lavrenko, R. Manmatha, J. Jeon, "A model for learning [4] J. Magalh X es, S. R X ger, "L ogistic regression of generic [5] A. McCallum, K. Nigam, "A comparison of event models for [6] J. Rocchio, "Relevance feedback in information retrieval," in 
