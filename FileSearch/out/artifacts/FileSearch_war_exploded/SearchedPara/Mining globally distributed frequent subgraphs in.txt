 1. Introduction
Graph structure data, such as Resource Description Framework (RDF) files, Extensible Markup Language (XML) files, and protein X  X rotein interaction data, are being accumulated in many application domains. The need is now critical to develop effi-cient and effective graph mining algorithms for analyzing such data. Towards this direction, there have been attempts for min-ing frequent substructures from a set of labeled graphs [1 X 9] , discovering important/frequent subgraphs from a network of applications such as designing database schemas [17], building database indexes [18], and modeling user profiles [19]. when we apply the existing graph mining algorithms to real-world applications, they would face the following practical challenges.

First, most of the existing algorithms are developed for finding frequent subgraphs in a set of labeled graphs only. These algorithms are able to effectively and efficiently discover all the frequent subgraphs and be scaled to large data sets.
However, they cannot be directly used to mine in a single labeled graph, despite the fact that the problem of finding fre-quent subgraphs in a single labeled graph is more general and applicable [11].

Second, the reason why we conduct frequent pattern mining is that the frequent patterns found are supposed to be the common structures in the data, which can clearly describe the general relationships among items of different classes in the data and effectively analyze the data. However, due to the difference between the graph model and other data models, simply finding frequent subgraphs in a single labeled graph may not fulfil our requirement. The identified subgraphs of high frequency could just include a small set of items of a particular class, which can be interpreted as that these found ally distributed subgraphs are more useful, as they provide global information about the whole graph. An illustration of this point is given in Fig. 1 , wherein we have found the two 2-edge graph patterns PA ( located globally ) and PB ( located regionally in the specified subarea ) in the input graph. If we merely consider the importance of the frequency, PB should ing graphical indices [18], PA would be more useful, as PA is the typical structure that all the instances of the class A have while PB is only held by one instance of A.

Third, being a critical property, the downward closure property enables the frequent pattern mining algorithms to effec-tively prune the search space. However, when mining a single labeled graph, simply counting the occurrence/frequency of a graph pattern in the input graph may not have the downward closure property. For example, given the two graph pat-
This indicates that the downward closure property no longer holds. As a result, the graph mining algorithms cannot utilize the downward closure property to prune the search space. They have to search the whole candidate space for finding all the frequent subgraphs. The mining process becomes extremely time-consuming.

In view of the above challenges, we introduce a new graph mining problem in this paper, i.e., finding globally distributed paper. Those identified G-Patterns can provide global information about the input graph and are extremely valuable for a
To find G-Patterns, the straightforward approach is divide and conquer . That is, to partition the input graph into smaller manageable segments, and to find frequent patterns within those segments. However, a large amount of noise may be cre-ated by splitting the input graph, rendering this approach ineffective.

Another approach of finding G-Patterns is to adopt a post-processing step which eliminates spurious patterns from the results of the existing mining algorithms. However, as finding such globally distributed subgraphs normally requires setting a lower support threshold, it often leads to the identification of many uninteresting graph patterns and the computation cost can be prohibitively high. For example, given the small synthetic graph V2E1N500L20A55 used in our experiments, Table 1 presents the frequency distribution of the multi-edge graph patterns found in this graph. We could see the distribution is rather skewed. Many patterns are with low frequency while only a few have frequency greater than 100. If we set a lower minimum support threshold, many more patterns would be extracted. It consequently requires much more time to validate whether these found subgraphs are globally distributed.

A better approach is to have a measure that can efficiently identify G-Patterns and automatically remove spurious pat-terns during the mining process. In this paper, we propose a new measure, named G-Measure , for mining G-Patterns in a single labeled graph. The basic idea behind the G-Measure takes the distribution of the graph patterns in the input graph into consideration. Graph patterns with a G-Measure value no less than the user specified minimum support threshold are the ones we are looking for.

Based on the proposed G-Measure, we develop an algorithm called G-Miner for finding G-Patterns. Specifically, G-Miner is implemented following the Depth-First Search (DFS) approach, since this approach has shown to have a computational advantage over the Breadth-First Search (BFS) for mining a single labeled graph [27,11] and works efficiently with the DFS code [3] used for graph isomorphism testing and candidate generation. We evaluate the performance of the G-Miner on both synthetic and real-world data sets and compare with the state-of-the-art graph mining algorithms. As demonstrated deed, G-Miner runs several orders of magnitude faster than the existing approaches. Finally, we show an application of the G-Patterns.

Overview. The rest of this paper is organized as follows. Section 2 provides the basic concepts related to this graph mining problem. Section 3 introduces the G-Measure. Section 4 elaborates the G-Miner algorithm. The experimental results are gi-ven in Section 5. Related work is presented in Section 6. Finally, we draw conclusions in Section 7. 2. Preliminary concepts In this section, we define the graph model used in this paper and introduce some related concepts.
 Definition 1 (Labeled graph). A labeled graph can be represented by a 4-tuple, G  X  X  V ; E ; L ; l  X  , where V is a set of vertices, E # V V is a set of edges,
L is a set of labels, l : V [ E ! L , l is a function assigning labels to the vertices and edges.
 the same as in G .

Note that we focus on undirected labeled simple graph in this paper. However, our developed algorithm can easily be modified for processing other kinds of graphs. For example, we can treat the direction of the edges as a label for processing directed graphs.
 A labeled graph extracted from the Biozon database (http://www.biozon.org ) and one of its subgraphs is shown in Fig. 3 . represents the ID of the corresponding vertex or edge stored in the database. With this graph, researchers can easily explore relationships between these biological resources. Note that the IDs of the vertices and the edges in the labeled graph are not considered during mining. They are presented here for illustration purpose. The frequent graph patterns 2 that we search for are like the one shown in Fig. 3c. is an instance of P in G if there exists an isomorphism between P and SG .

For example, we search for the graph pattern P shown in Fig. 4 a in the labeled graph G presented in Fig. 3 a. We can see there are four subgraphs of G isomorphic to P (see Fig. 4 b). They are called the instances of P in G . construct a new graph for P where the vertices represent P  X  X  instances in G and edges are added between two vertices if their corresponding instances share an edge in G . This new graph is called edge-disjoint based instance graph ,or instance graph for simplicity.

For the example pattern P shown in Fig. 4 , as its instance i 1 shares the edge DNA(ID:215) X  X ni _ contains(ID:62) X  X ro-tein(ID:103) with i 2 and i 3 shares the edge Protein(ID:78) X  Uni _ encodes(ID:31) X  X nigene(ID:150) with i 4, its edge-disjoint based instance graph is constructed as the one shown in Fig. 5 a. Note that the instance graph is an unlabeled graph. The la-responding instances.

Besides the edge-disjoint based instance graph, we can also form other types of instance graphs, for example, vertex-dis-joint based instance graph, i.e., edges are added between two vertices of the instance graph if their corresponding instances share vertices in the input graph (see Fig. 5 b), or even a distance l based instance graph, i.e., edges are added between two vertices if their corresponding instances are reachable with paths of length l in the input graph. Forming different instance graphs would be seen as a way of defining the global distributed property, since how patterns are called globally distributed where l is the preferred distance between the instances and h is the minimum support threshold. Given the same support joint based instance graph than those found with the edge-disjoint based instance graph.

In this paper, we only consider the edge-disjoint based instance graph. This setting specifies that graph patterns are called vations, methods, and conclusions to other conditions.

Definition 4 ( The downward closure property ). Given a measure f , downward closure property, also called the admissible property [28,29] or frequency anti-monotone property [30], requires that for every pair of patterns p and q in the data set the search space. 3. G-Measure
In this section, we present the motivation behind the G-Measure, the definition of the G-Measure, and its downward clo-sure property. 3.1. Motivation
We aim to find frequent subgraphs which are also globally distributed in a single labeled graph. To achieve our goal, the straightforward approach is divide and conquer . That is, to partition the input graph into smaller manageable segments, and to find frequent patterns within those segments. However, this approach will suffer from the following problems. 1. The quality of the obtained segments is not ensured, as we have no knowledge of the input graph in advance and may not set an optimal segment number. As a result, the subgraphs found are not the required G-Patterns. For example, if we adopt the k -way partition method [31] to split the input graph, too many regionally distributed patterns would be extracted due to a high k value. 2. A certain G-Patterns would be lost as their instances happen to occur across different segments. To guarantee the com-pleteness of the G-Patterns to be found, additional methods are required to recover these lost graph instances, which would make the mining task even harder.

Besides the divide and conquer approach, we would adopt a post-processing step which eliminates spurious patterns from computationally inefficient. It requires much time to validate whether these found frequent subgraphs are also globally distributed.

A better approach is to have a measure that can efficiently identify G-Patterns and automatically remove spurious pat-terns during the mining process. In this paper, we propose a new measure, called G-Measure , that can efficiently identify G-Patterns and automatically remove spurious patterns during the mining process.

The basic idea behind the G-Measure is based on the observations of forming the instance graph: when the instances of a graph pattern appear in the same regional area of the input graph, sharing edges, their corresponding vertices in the instance graph would be directly connected with edges. On the other hand, if these instances are located in different areas, their cor-composed of a set of disconnected vertices, since no common edges are shared by these instances. An illustration of our observations is shown in Fig. 6 , where we will build the instance graph of P with G . We can see that with a few connections.

Our observations are similar to those happening in the social network where humans of the same class closely connect while humans of different classes are with a few interactions. Therefore, we could change the G-Pattern mining problem to a community detection problem. By partitioning the instance graph, we could test whether a pattern is a G-Pattern, where the G-Measure is to count the number of partitions obtained from the instance graph.

Note that an incorrect impression could be made that we can count the number of disconnected components in the in-stance graph for finding G-Patterns. However, referring to the above example, we can see this approach may not correctly separate instances located in different areas from those in the same areas given some particular distance requirements, for example, edge-disjoint. 3.2. Definition
Before giving the formal definition of the G-Measure, we first present the criterion used for partitioning the instance graph.

Basically, to effectively find community structure in a social network, we assume that for the result obtained, there is a higher density of edges within the same partition than between different partitions. To quantify this requirement, people have proposed different quality measures such as the min cut [32] and the ratio cut [33]. In this paper, we adopt the mod-ularity measure [34], which is commonly used in the social network research field to tackle this problem.
The general principle of the modularity measure is presented as follows. Let A vw be an element of this network X  X  adjacency matrix where edges that connect vertices in the same partition, is where d P v ; P w  X  X  is 1 if P v  X  P w and 0 otherwise, and m  X  1 2 P vw A vw is the number of edges in the network. greater than that of a random graph. Otherwise, the two values will be the same. Therefore, the modularity measure, M ,is defined by A higher M value indicates the result is good.
 With the modularity measure, we give the formal definition of the G-Measure as follows: the modularity measure. If the instance graph is composed of disconnected components, the G-Measure is computed as the sum of the different partitions found in each component.
 The definition of the G-Pattern is as follows: Definition 6 ( G-Pattern ). Given a graph pattern P and a minimum threshold h , P is a G-Pattern if and only if G  X  P  X  P h . 3.3. The downward closure property of G-Measure
After defining the G-Measure, we now present its downward closure property. Particularly, we first introduce three types of operations occurring in the instance graph. We show that the instance graph of a graph pattern Q is constructed and can only be constructed under these operations on that of its ancestor P . Therefore, an instance graph based support measure, e.g., the G-Measure, is shown to have the downward closure property if its value is non-decreasing under the three types of operations.

Note that our defined operations are not the same as those given in [29]. Our operations are discovered independently by test the downward closure property of an instance graph based support measure on all kinds of instance graphs (i.e., edge-disjoint based instance graph, vertex-disjoint based instance graph, and distance based instance graph) while Vanetik et al. have claimed their operations are only proved correct for evaluating the downward closure property of a support measure on the edge-disjoint based instance graph [29]. 3.3.1. Operations on the instance graph
Given a graph pattern P and its child Q that is with a growth of one edge 4 , Q  X  X  instances cannot occur in the input graph three categories, namely forming clique, adding edge, and removing vertex.
 clique operation on k adds a clique K  X  X  V k ; E k  X  into G P , which results in the instance graph G Q  X  X  V Q ; E Q  X  where and
Fig. 8 presents an example of the forming clique operation, where a clique K 3 is added into the instance graph. It happens when several instances of Q are generated from the same instance of P . The sample patterns and the input graph correspond-ing to this example are given in Fig. 9 .
 the instance graph, which results in the instance graph G Q  X  X  V Q ; E Q  X  , where and instance graph, resulting in the graph G Q  X  V P ; E P S ff u ; v gg  X  X  .

The examples corresponding to the removing vertex operation and the adding edge operation are given in Figs. 10 and 11 , respectively. The former operation occurs if an instance of P cannot generate Q  X  X  instance with one edge growth and the lat-ter happens when the instances of Q share edges in the input graph. The sample patterns and the input graph corresponding to the adding edge operation shown in Fig. 11 are presented in Fig. 12 . 3.3.2. Constructing instance graphs with the three operations
After defining the three operations, we now present how the instance graph of Q can be and only be constructed from that of P under these operations.

First, we show that the instance graph of Q can be constructed from that of P with the three operations. An example is cannot generate instances of Q with one edge growth, we remove their corresponding vertices from the instance graph (see instance graph, obtaining the instance graph of Q (see Fig. 14 d). Note that the orders of these operations do not affect the final instance graph obtained. They can be arranged freely when building Q  X  X  instance graph.

Second, we prove that the instance graph of Q can only be constructed from that of P with the three operations. For dem-The two operations may also be supposed by people to happen when forming Q  X  X  instance graph. Therefore, if the two opera-tions do exist, our statement is incorrect.

Then, we show that the two operations cannot exist. For example, if the deleting edge operation happens (see Fig. 15 ), the that of P with the above three defined operations.

Theorem 1. An instance graph based support measure for mining frequent subgraphs in a single labeled graph has the downward closure property if its value is non-decreasing under the forming clique, removing vertex, and adding edge operations on the instance graph.

Proof. As demonstrated above, given a graph pattern P and its child Q , Q  X  X  instance graph can be and only be constructed
This measure therefore has the downward closure property. 3.3.3. Conditions for the downward closure property
To evaluate the downward closure property of G-Measure, the standard approach is to test whether G  X  P  X  P G  X  Q  X  . How-ever, it is well known that the problem of deciding the optimal partition number of a graph has no standard solutions yet [34]. Although we have many quality measures, the results are still with uncertainness because of many factors, which will further affect the evaluation. For example, two different partition results may be obtained given the same input graph (see Fig. 17 ), which can further ruin the downward closure property. Therefore, we design a new approach to compute the G-Measure values.
 The basic idea of the new approach is based on the fact that all the instances of Q are generated from those of its ancestor P with edge growth. If we have partitioned P  X  X  instance graph, we may not directly partition that of Q again. The vertices of into Par i . Such an approach can keep the downward closure property of the G-Measure with the following lemmas and The-orem 1 .
 the instance graph.
 v is deleted, i.e., G  X  P  X  X  G  X  Q  X  .
 instance graph.
 generated from v p 1 and v q 2 is generated based on v p 2 , a new partition or delete an existing partition of the instance graph, i.e., G  X  P  X  X  G  X  Q  X  . between v q 1 and v q 2 does not form a new partition or remove an existing partition either, i.e., G  X  P  X  X  G  X  Q  X  . ation is conducted on the instance graph. instance of Q can be generated based on p , v p should be removed from the instance graph. Specifically, If Par 1 has more vertices besides v p , Par 1 will still exist after removing v p , i.e., G  X  P  X  X  G  X  Q  X  . If Par 1 only contains v p , removing v p will also lead to deleting Par 1 , i.e., G  X  P  X  &gt; G  X  Q  X  . Therefore, G  X  P  X  P G  X  Q  X  when removing vertex from the instance graph.

Note that directly adopting above method can only produce an approximate G-Measure value. However, as all the in-stances of the graph pattern Q are generated from those of its ancestor P , the exact modularity value can actually be com-puted by merging these partitions obtained. Merging two neighbor partitions simply as if the modularity value increases 7 , which can be seen as a local optimization of the modularity value. A global optimization has to analyze all the partitions for maximizing the modularity value. Because the local optimization value is not less than the exact value, we can quickly prune many spurious patterns by doing local optimizations only.

With above observations, the new approach is designed for mining G-Patterns. Specifically, we only partition a few pat-terns X  instance graphs directly with the partition algorithm (in this paper only the 2-edge patterns). The instance graphs of the descendant patterns are firstly partitioned according to their ancestors. Then, the G-Measure value is computed by merg-carded directly.

If we map this approach to the input graph, we could find it actually follows the idea of divide and conquer . However, the new approach is based on the instance graphs to partition the input graph, which can be seen as a type of prior knowledge of the input graph. It thus avoids the problems mentioned in Section 3.1. 4. The G-Miner algorithm
In this section, we present the G-Miner algorithm which is designed for mining G-Patterns with G-Measure values not less than a user specified minimum threshold. Specifically, we first introduce the Depth-First Search (DFS) code based approach [3] for candidate generation and graph isomorphism testing. Then, we present the details of the G-Miner algorithm. 4.1. The DFS code
Graph isomorphism testing, subgraph isomorphism testing, and candidate generation are costly steps in the frequent sub-graph mining problems. In G-Miner, we use the DFS code based approach to solve these problems.

The basic ideas behind the DFS code based approach are given as follows. For a labeled graph G, for example, the one shown in Fig. 18 a, we have different DFS trees of this graph (see T1 in (b) and T2 in (c)). We call edges included in the
DFS tree are the forward edges and edges not in the DFS tree are the backward edges. A linear order of the edges in G of a and vj a is the end node of a according to T , With the , the edges in G can be arranged into a sequence for individual DFS trees, called DFS code of G . For example, the h v 1 ; v 2 ; A ; x ; C i ; h v 2 ; v 0 ; C ; y ; A i ; h v 1 ; v 3 ; A ; y ; B i X  .
 G.

Because two graphs are isomorphic if they have the same minimum DFS code, the problem of mining frequent subgraphs can be changed to mining frequent minimum DFS codes. Particularly, the edge sequence for generating a subgraph must be the minimum DFS code of this subgraph. As a result, only a few candidates would be explored, which reduces the total cost of subgraph isomorphism testing and candidate generation. 4.2. Algorithm details
G-Miner utilizes a Depth-First Search method to find G-Patterns, since this approach has shown to have a computational advantage over the Breadth-First Search for mining a single labeled graph [27,11] and works efficiently with the DFS code. with a growth of one edge. Graph patterns with G-Measure value not less than the minimum support threshold are selected.
Fig. 19 outlines the pseudo-code of the G-Miner algorithm. It is similar to the gSpan algorithm. The major differences between the two algorithms are that G-Miner will partition the instance graphs and use the G-Measure for finding frequent subgraphs. Explanations of this algorithm are presented as follows.

Step 1 (line 1 X 4): Scan the whole input graph G into the memory. Remove infrequent vertices and edges from the input graph. The remaining vertices and edges are relabeled in descending frequency for forming 1-edge graph patterns. These frequent 1-edge graphs are added into S 1 and sorted in the DFS lexicographic order. Note that in this paper we only con-sider the problem that the whole data set can be held into the main memory. For large scale data sets, we could adopt our developed technique on mining a set of graphs [4] with certain motivations. That will be our future work. Steps 2 X 4: Loops to generate qualified G-Patterns. It stops after all the elements of S 1 are explored.
Step 2 (line 6): For each 1-edge graph pattern, enumerate its potential 2-edge children. Note that only graph patterns satisfying the minimum DFS code are built.
 partition this graph. Each instance will be assigned into a particular partition according to the partition result.
Step 4 (line 11): Subgraph_mining recursively generates P  X  X  potential descendants with a growth of one edge (satisfying the minimum DFS code). Only graph patterns with G-Measure value greater than the minimum support are added to S tors ( line 21 ). Then, neighbor partitions are merged as new partitions (similar to the agglomerative clustering) if the mod-ularity value increases ( line 13 ). For patterns whose G-Measure values are already lower than the threshold before finishing the merge process, they are discarded immediately.
 Step 5 (line 12): Add the frequent 1-edge graph set S 1 to S .

Note that the reason why G-Miner starts from 2-edge patterns but not 1-edge patterns is because the instance graphs of the 1-edge patterns are all composed of a set of disconnect vertices. As a result, the G-Miner algorithm cannot separate in-stances that are located in the same area from those appearing in different areas, making poor performance for finding G-Patterns. 5. Experiments
In this section, we evaluate the performance of the G-Miner algorithm and the usefulness of the G-Patterns. Specifically, we evaluate: (1) the effectiveness of the G-Miner algorithm for mining G-Patterns. (2) the computational efficiency of the G-Miner algorithm for mining G-Patterns. 9 (3) the application of G-Patterns for text categorization.
 5.1. The performance of the G-Miner algorithm 5.1.1. The experimental setup We evaluate the performance of the G-Miner algorithm on both synthetic and real-world data sets.

Synthetic Data. We develop a synthetic data generator which is based on Barabasi X  X  evolving scale-free random graph model [35] to produce labeled power-law graphs, as we can easily observe the difference between the patterns mined by the existing frequent subgraph mining algorithms and those discovered by G-Miner on such graphs.

The procedure of this generator for producing a labeled graph is as follows: Firstly, by setting the initial vertex seed num-graph is generated. Then, each vertex is assigned a particular label, which is controlled by the number of labels in the graph quent patterns mined are given in Section 5.1.2. The summary of the parameter settings used to create the synthetic graphs is given in Table 2 .

Real-world Data. Seven real-world data sets are used in the experiments. The basic characteristics of these data sets are shown in Table 3 .

The credit and aviation data sets are downloaded from SUBDUE X  X  web site 10 . Among all, the aviation data set is the largest used in the experiments, with more than 100,000 vertices and 90,000 edges.

The citation50_15, citation50_20, and citation50_25 data sets are generated from the citation graph used in the KDD Cup labels. For the edges, we give them a common label, since they all represent the citation relation. As our experiments are as-sumed for processing undirected graphs only, the directions of the edges are ignored. Note that the original citation graph is very dense, containing 29,555 vertices and 352,807 edges. A simple graph pattern can have many instances in the data set (for example, the one shown in the Fig. 20 even has a frequency of 1,843,068), which can lead to the programs quickly run out of memory even just starting mining. Therefore, we only use a subgraph of the original graph for evaluation, which is cre-ated by removing vertices with degree greater than a threshold h and their associated edges from the original graph. In our experiments, we set the thresholds as 15, 20, and 25, respectively. 12 Such settings enable us to conduct a more comprehensive study and allow the computation to be finished in a reasonable amount of time.

The PPI data set is a protein X  X rotein interaction network 13 , in which each vertex represents a protein and an edge is added between two vertices if the corresponding proteins are detected to have an interaction in the experiments. For each vertex, we remove vertices whose degrees are greater than 10 and the incident edges from the original graph to guarantee the computation to be done in a reasonable mount of time.

The chemical data set 15 , provided for the Predictive Toxicology Evaluation Challenge [36], contains 340 chemical com-pounds (i.e., 340 labeled graphs) that has been used for evaluating the performance of FSG [2] and gSpan [3]. It is used by us to test whether G-Miner can also effectively find frequent subgraphs from a set of small graphs as we claim. Note that the 340 small graphs have to be merged into a large graph as the input and each becomes a disconnected component of the large graph.

Baseline Algorithms. In our experiments, we implement two algorithms, namely baseline-1 and baseline-2, as the base-lines for comparison. The details of the two algorithms are given as follows.

The baseline-1 algorithm is a standard algorithm for finding frequent subgraphs in a single labeled graph. The support value of a graph pattern is computed as the exact number of its instances in the input graph. Its pseudo-code is given in Fig. 21 .

As mentioned previously, the standard support measure, i.e., the one used in baseline-1, may not have the downward clo-sure property for mining a single labeled graph. To overcome this problem, a downward closure property holding measure is proposed by Vanetik et al. [28] that computes the maximum independent set of a pattern X  X  instance graph and assigns the sure). Programs with this support measure are supposed to quickly discover a set of frequent subgraphs from the input graph, although it cannot find all the frequent subgraphs. Here, the baseline-2 algorithm is implemented with Vanetik X  X  sup-port measure for finding frequent subgraphs. Its pseudo-code is given in Fig. 22 .

All the experiments are conducted on an Intel 64-bit Xeon CPU (2.0 GHz) PC with 4G main memory, running linux. When partitioning the instance graph, we use a fast community detection algorithm [34] with time complexity of O  X  md log n  X  , where n is the number of vertices, m is the number of edges, and d is the depth of the dendrogram. When computing the
MIS of the instance graph, we use a fast exact maximum clique algorithm wclique [37]. Note that the reason of using a 64-bit PC is because the 32-bit JVM can only support up to 1.5 Gigabyte memory while some data sets require more memory.
In our experiments, the maximum memory heap size is 3 G . Also, as our program is implemented using JAVA, it gives us a disadvantage when comparing with programs using C/C++. 5.1.2. Illustration of the global distribution of G-Patterns
Firstly, we evaluate the effectiveness of the G-Miner algorithm for mining G-Patterns. As the real-world data sets are too large for visualization, we only use the synthetic data sets here. For data sets V2E1N500L20A55 and V2E1N500L20A05, we set a lower a value to the latter so that the probability of two linked vertices sharing a common label is more random, which leads to fewer frequent patterns to be found. For data sets V2E1N550L10A65 and V2E1N550L100A65, assigning more labels to the latter also leads to fewer frequent patterns to be found.

The experimental results of the G-Miner algorithm on the synthetic data sets are given in Figs. 23 X 26 , respectively. We have highlighted vertices which are contained in the top 10 frequent multi-edge G-Patterns found in these data sets. Also, we mark the coverage of the top 10 frequent multi-edge patterns found by baseline-1 whose edge number is not greater than the maximal edge number of the frequent G-Patterns discovered.

We can see patterns found by baseline-1, as we expect, occur only in several particular areas of the input graphs (partic-ularly, these found patterns all occur around the vertices with high degrees), while patterns found by G-Miner distribute globally in the synthetic graphs. Table 4 lists the number of unique vertices found by the two algorithms. Although the num-ber of frequent subgraphs in each synthetic graph is different, G-Miner can always effectively find G-Patterns which cover more unique vertices of the input graphs.

To save space, we do not present the coverage of the frequent patterns by baseline-2 in this paper. The interested readers can find that patterns mined by baseline-2 seem globally distributed in the input graph as well. However, the G-Patterns a particular graph pattern is shown. If we use the G-Measure, the value of this pattern would be 1, since the vertices of the instance graph are closely connected. However, if we compute the maximum independent set of the instance graph, this pattern X  X  value will be 2. These closely connected instances cannot be identified as a whole. 5.1.3. Computational efficiency of mining G-Patterns
We evaluate the computational performance of the G-Miner algorithm for finding G-Patterns on the first six real-world results of the two algorithms for finding G-Patterns. If G-Miner outperforms baseline-1 and baseline-2 in the experiments, it certainly runs faster than the approaches that further adopt a post-processing step.

Table 5 shows the runtime (in seconds), the minimum support threshold used, and the number of frequent patterns found by the three algorithms. Entries marked with  X  X - X  represent experiments aborted for running more than one day or out of memory. We can see G-Miner runs greatly faster than baseline-1 and baseline-2 on these data sets. Given the same mini-mum support threshold and 24-hour slot, baseline-1 cannot work on any data sets and baseline-2 works only on three. Such results clearly demonstrate the computational efficiency of the G-Miner algorithm for finding G-Patterns. 5.1.4. Example G-Patterns
We use the G-Patterns found in the PPI data set to illustrate the type of subgraphs that G-Miner can discover. Recall that the PPI data set is a network recording the interactions between proteins. Therefore, the G-Patterns found are the common structures among proteins in the interaction network, which can be used to analyze these proteins.

Fig. 28 shows two representative G-Patterns found in the PPI data set. It can be immediately seen that vertices of the found G-Patterns belonging to the same functional class, same as the observations of the previous experiments that proteins of a frequent pattern perform the same biological function [25]. Furthermore, we see that proteins of Cell Transport function have a line structure (see Pattern A) while proteins of Cell cycle and DNA processing have a tree structure (see Pattern B). Therefore, the two patterns can be used to help classify unknown proteins of the two categories. 5.1.5. Performance comparison with existing algorithms
Comparison with SEuS. The SEuS algorithm [38] is designed for mining frequent subgraphs in a single labeled directed graph. Particularly, it first builds a data structure called data summary , which is a compressed representation of the input graph. Then, frequent subgraphs are found based on the data summary, in which the support values of the patterns are com-puted as their exact number of instances in the input graph, same as baseline-1. The advantage of such an approach is that the most frequent patterns in the data set can be easily found. However, it still needs to explore the whole candidate space for finding frequent patterns with support values no less than a predefined threshold.

Here, we only compare the computational performance of G-Miner with that of SEuS on the credit data set, as the other real-world data sets either cannot be treated as a directed graph or be processed by SEuS. Given the same minimum support threshold h  X  100, 11,696 patterns mined by G-Miner using 47 seconds, that is 36 frequent subgraphs per second. However, as SEuS sets a beam width parameter 17 to limit the number of possible candidates to be tested, only 5 frequent graph patterns found by SEuS with 2.1 seconds, that is 2.4 frequent patterns per second. We can see G-Miner runs much faster than SEuS for mining this graph.
 Comparison with SUBDUE. Different from G-Miner or SEuS which find frequent subgraphs in a single labeled graph, SUB-DUE [10,39] is to find subgraphs that can compress a single graph according to the minimum description length principle. Specifically, SUBDUE searches for patterns P s in the graph G that minimize G with respect to P . Such a requirement makes the patterns found by SUBDUE may not be the most frequent patterns. There-fore, we cannot directly compare G-Miner with SUBDUE because of the inherent difference between the two algorithms.
Here, we only evaluate the computational performance of the SUBDUE system on the first six real-world data sets. Be-cause SUBDUE employs a heuristic beam search to keep limited candidates for further exploration, only a few patterns are mined from these data sets. 18 The results are given in Table 6. We can see SUBDUE generally requires more time than spending one day. Such results clearly indicate the computational inefficiency of SUBDUE for processing large graphs.
Comparison with gSpan and FSG. One of the reasons why the problem of mining a single labeled graph is more general and we employ the G-Miner to find frequent subgraphs from the chemical data set, where gSpan 19 and FSG 20 are used for comparison.

Note that we modify the setting of the G-Miner algorithm by forming reachable based instance graphs instead of edge-corresponding instances are reachable through certain paths in the input graph. In this case, a pattern X  X  G-Measure value can actually be computed by counting the number of disconnected components in the instance graph. G-Miner X  X  output will thus be the same as those of gSpan and FSG.

The experimental results of G-Miner, gSpan, and FSG, in terms of the runtime (in seconds) and the number of frequent subgraph patterns found on the chemical data set, are given in Table 7 . The reasons why G-Miner runs slowly may be attrib-uted to the difference between JAVA and C/C++ for computation and the time required for identifying whether two instances are reachable in the input graph. Nevertheless, we can see G-Miner extracts the same number of frequent subgraphs from the chemical data set as gSpan and FSG.
 5.2. The application of G-Patterns for text categorization
Here, we present an application of G-Patterns for classifying text documents. 5.2.1. Basic principle
Different from the common text classification methods that only utilize the document content, approaches of classifying hypertext could further use the links between the documents to tackle this problem. For example, a relaxation labeling prob-the document and the labels of its neighbors. An illustration of such a problem is given in Fig. 29 , where we have known certain documents X  labels (i.e., nodes presented with rectangle and triangle) and want to infer the left documents X  labels (i.e., nodes marked with ?).

The basic solution of the relaxation labeling problem is presented as follows. Given a document d , the probability of assign-ing a label c to d is computed by d are the documents linked to d in the data set. As there is no direct dependence between the content of a document and the labels of its neighbors, we can simplify the solution as: Finally, a document d will be assigned a label c if U c ; d is the maximal value.

Here, we propose using G-Patterns to resolve this relaxation labeling problem. Specifically, we assign the label to an un-known node based on the possible G-Patterns it matches. For example, the unknown node marked with red color in Fig. 29 this node could satisfy the G-Pattern shown in Fig. 30 , it may be assigned the label triangle as well. The G-Pattern based approach of the relaxation labeling problem can be presented as: maximal value. 5.2.2. Results We conduct experiments to evaluate the performance of the G-Pattern based solution for the relaxation labeling problem.
For evaluation, we would compare the performance of labeling documents using Eq. (7) with that of using Eq. (6). However, as the content of the documents would not affect this evaluation, we simplify the evaluation as the comparison between and
The Wikipedia 21 data set is used for this experiment, which contains 5360 documents crawled from the Wikipedia dump links kept for the experiment.

The details of this experiment are as follows: First, a set of documents are selected from the data set as the testing doc-are labeled with Eqs. (8) and (9) , respectively.
Two hundred documents that have at least one link with other documents are selected for testing. The performance of the two methods is evaluated by the precision and the F-measure of the testing documents labeled, which is presented in Table 8. We can see the G-Pattern based approach indeed increases the performance of classifying documents. The improvement in precision obtained is 15% (from 0.53 to 0.61) and the improvement in F-Measure obtained is 7%. Such results validate our approach of using G-Patterns to resolve the relaxation labeling problem. 6. Related work
Given the population of the graph structure data, a large number of graph mining algorithms have been developed for ana-ing algorithms into two categories, namely mining frequent/important patterns in a set of labeled graphs and mining frequent/ important patterns in a single labeled graph. The G-Miner algorithm presented in this paper belongs to the second category.
Between the two classes of algorithms, algorithms belonging to the first category [1 X 7] are more mature. Most existing graph mining algorithms are of this category. These algorithms can efficiently and effectively discover all the frequent sub-graphs in the data and be scaled to large data sets. However, algorithms of the second category have received much less rithms that mine a single labeled graph can be directly used to find subgraphs in a set of labeled graphs. However, algorithms that mine in a collection of graphs have to be modified before working on a single labeled graph.

Besides the G-Miner algorithm, there are only a few attempts for finding frequent/important subgraphs in a single labeled graph [10,40,28,27,38] . As a major difference, G-Miner targets on finding globally distributed frequent subgraphs while these existing mining algorithms usually lead to the appearance of the identified frequent subgraphs regionally in the input graph.
The SUBDUE system [10,39] is a well-known algorithm which selects qualified patterns for compressing the input graph under the minimum description length principle. Specifically, SUBDUE searches for patterns P s in the input graph G that minimize respect to P . This requirement makes the patterns found by SUBDUE may not be the most frequent patterns in the graph. Furthermore, to avoid the problem of exploring the whole search space, a heuristic beam search is employed to narrow the search space. Only limited candidates are kept for further exploration. As a result, SUBDUE cannot find the complete set of important/frequent subgraphs in the input graph. The similar approach is adopted by GBI [40] for finding typical sub-graphs in a single labeled graph.

The SEuS algorithm [38] aims at finding frequent subgraphs in a directed labeled graph. In particular, SEuS first uses a data structure called data summary to construct a compressed representation of the input graph, similar to DataGuides [41] for semi-structured data. Then, the frequencies of the graph patterns are estimated based on the built data summary . SEuS can quickly find the most frequent patterns in the input graph. However, it still needs to explore the whole search space SEuS algorithm is not efficient if the input graph contains a large number of frequent subgraphs with low frequency and is useful only when there are a few frequent subgraphs with high frequency in the input graph. This limitation greatly affects its ability for mining G-Patterns, since G-Patterns are normally with relatively low frequencies.

Given the fact that the standard support measure does not guarantee the downward closure property for finding frequent subgraphs in a single labeled graph, Vanetik et al. [28] propose a downward closure property holding measure instead. Spe-cifically, this proposed measure computes the maximum independent set (MIS) of a graph pattern X  X  instance graph. Only pat-terns with MIS size not less than the minimum support threshold are selected. Because of the downward closure property, algorithms implemented with this support measure may quickly find a set of frequent subgraphs. However, computing the maximum independent set of a graph has proved to be a NP-hard problem [42]. Algorithms with this support measure can even perform worse than those with the standard approach. 22 Also, as shown in [27,11] , algorithms implemented with this measure are only efficient for mining large sparse graphs due to the high cost of computing the maximum independent set. ants of Vanetik X  X  support measure are proposed [43,44] , these new measures only reduce the number of MIS to be computed and do not change the problem substantially.
 7. Conclusion
In this paper, we have formalized the problem of finding G-Patterns, a type of globally distributed frequent subgraphs, in a single labeled graph. As a measure of association for graph data, G-Measure is proposed to find G-Patterns. It is conse-quently exploited to develop a G-Miner algorithm for efficiently identifying G-Patterns in a single labelled graph. Experimen-tal results from both synthetic and real-world data sets demonstrated the efficacy of the G-Miner for discovering G-Patterns. Finally, we present an application of the G-Patterns.

References
