 Internet provides a revolutionary way to access geographical data. Significant efforts, such as Microsoft X  X  TerraServer [1] and NASA X  X   X  X orld Wind X  project [2], have been put into the development of core technologies of web-base GIS. It is more accessible than ever before with increasing data availability, client pro-cessing power and network bandwidth. However, the large size of terrain data remains a major challenge. The size of a data repository, such as the Digital Elevation Model of America (available from U.S. Geological Survey [3]), is mea-sured in terabyte. The size of accessible dataset is increasing quickly as the data collection continues. The  X  X huttle Radar Topography Mission X  by NASA [4] is collecting the data of most land on earth.
 resolution can be unnecessarily high in many cases. Figure 1(a) shows an small terrain model with only 10,000 triangles, but the top-right part already appears to be unnecessarily dense. Multiresolution (or multi-scale ) techniques are in-troduced to address this problem [5]. The intuition is to construct a simplified terrain approximation ( mesh ) as the substitute of the original model with guar-anteed accuracy according to application requirements. Therefore, the resource requirement can be significantly reduced without sacrificing necessary quality. A simplified terrain with 1,000 triangles is shown in Figure 1(c). For visualization purpose, the difference is hardly noticeable after texture is applied (Figure 1(b) and 1(d)).
 the data of the original model, which is usually extremely large, and intermediate data generated during simplification. The possible benefit of using a mesh can be overcomed by its expensive construction. In order to reduce the cost, we need to represent it as a Multiresolution Triangular Mesh (MTM) -a terrain represen-tation that supports the reconstruction of meshes with variable resolutions with acceptable overhead. The fact that terrain data can be used at any resolution and that data of different resolutions may be used together to construct a single mesh means that it is not feasible to pre-generate terrain data at a fixed number of res-olutions. Instead, most MTM methods adopt a tree-like data structure, and each node stores a lower resolution approximation of its child nodes data. The con-struction of a mesh starts from the root, which contains the least detailed data, and refines this coarse mesh progressively by replacing it with the data stored at its children nodes until the desired resolution is achieved (details are provided in Section 2). Since the data with low resolution is substantially less than the original terrain model, such MTM can significantly reduces the mesh construc-tion cost. Such structure also can provide large number of possible meshes and mesh with changing resolution, because the initial coarse mesh can be refined to any resolution available and each part can have different resolutions. it possible to perform visualization and analysis on large dataset in an online environment. Recently, a number of work has been published for visualizing large terrain over network [6, 7, 8, 9, 10, 11]. These methods focus on  X  X ompress-ing MTM X , i.e., using compact MTM data structure to reduce the amount of data transfer. However, none of them considers the role of database sys-tem. There are also signification research attention on multiresolution terrain database [12, 13, 14, 15, 16, 17]. These methods employ various multiresolution access methods to improve the performance of multiresolution query , i.e., effi-ciently identify and retrieve data required for mesh construction. Unfortunately these methods do not take into account any constrains imposed by network environment.
 server end, is a critical to the performance of online GIS applications. Such query is quite resource intensive because it involves large amount of data. Large number of simultaneous queries can easily exceed server capacity. Since the available bandwidth is increasing much faster than that of server processing power, it is possible that the query processing will replace the bandwidth as the bottleneck of online GIS applications.
 line environment. We started with examining existing work, and a cost model for current multiresolution query processing is proposed. An optimal cost, which serves as a bound for possible improvement, is derived from this framework. Three optimization strategies are proposed to address different problems iden-tified from performance analysis. The details of these strategies are discussed when applying them to existing methods, which also confirms the feasibility of our strategies in real applications.
 an brief overview on multiresolution query processing. The cost model is intro-duced in Section 3. In Section 4, the optimal cost is derived, followed by three optimization strategies, whose application to existing methods is also included. The paper is concluded in Section 5. A multiresolution query retrieves a mesh within given area with required res-olution, i.e., it can be specified by two parameters: the Level Of Detail (LOD) condition and the Region Of Interest (ROI) condition . For a mesh polygon t , the LOD condition returns a value e ( t ), which is the required LOD value for polygon t . In a mesh m , we denote the resolution of a polygon t as l ( t ). We say t is LOD feasible with respect to e if l ( t )  X  e ( t ). A LOD feasible polygon implies it is detailed enough for current application, and no further refinement is required. There are two types of LOD conditions: uniform LOD , where e ( t ) is a constant, i.e., the LOD of every polygon t is at least a constant value; or variable LOD , where e ( t ) is a function of polygon attribute(s). An example is that a LOD condition can be a function of the distance from the viewpoint, i.e., the further away from the viewpoint the less LOD value.
 mesh location, size and shape. It is specified by a collection of two-dimensional spatial objects (points, lines and/or polygons). Given a ROI condition r , a poly-gon t is ROI feasible if its two-dimensional projection P ( t ) has at least one point in common with r , i.e., r  X  P ( t ) =  X  . For multiresolution query, a polygon that is not ROI feasible means it is irrelevant. Therefore, only the polygons that are ROI feasible are checked against the LOD condition; whereas the LOD of polygons that are not ROI feasible can be arbitrarily low.
 minimal number of polygons that satisfies both. Formally, given a MTM M a multiresolution query Q ( M, r, e ) returns a mesh m from M that satisfies both the ROI condition r and the LOD condition e with minimal number of polygons. A multiresolution query is a uniform-LOD query if its LOD condition is a constant; a variable-LOD query if its LOD condition is a function of polygon attribute(s). explain multiresolution query processing. The structure of a progressive meshes is an unbalanced binary tree (Figure 2(a)). The fundamental step in mesh con-struction is vertex split , i.e., one point is replaced by its two children (Figure 2(b)). To answer a multiresolution query, a mesh that contains the root only is created first; then it is refined by applying vertex split progressively follow-ing the tree structure, until both the ROI and LOD conditions are met. In the progressive meshes, each node has the following information: where ID is the unique ID of the point, ( x, y, z ) is the three-dimensional coordi-nates, l is the LOD, parent , child 1, child 2 are the IDs of its parent, left and right child node, wing 1 and wing 2 are the IDs of the left and the right point connect-ing to both children, and MBR is the minimal bounding rectangle that encloses this node and all its descendants. The wing points (i.e., wing 1 and wing 2) are essential to form a correct triangulation after vertex split ( v 4 and v 7 for v 9 in Figure 2(b)). The MBR is for identifying ancestors of ROI feasible nodes. Due to the progressive refinement process of mesh construction, all ancestor nodes are necessary if a point exists in the final mesh. While this point is ROI feasible, some of its ancestor nodes may not. With MBR , all such nodes can be identified because their MBR intersects with ROI. The fact that the necessity of every node (except the root) depends on its predecessor makes it difficult to retrieve all necessary data together. In fact, the data for every vertex split (two child nodes) has to be fetched individually. Therefore, the data fetch of a multires-olution query is composed of many retrievals with every small amount, which makes it intrinsically inefficient for query processing. The I/O cost of a multiresolution query Q ( M, r, e ) has two major components: the cost of retrieving the index and the cost of retrieving data. In other words, the total I/O cost D ( Q ) of a multiresolution query Q ( M, r, e ) is the sum of index retrieving cost C i and data retrieving cost C d : The cost of index retrieving depends on two factors: the average cost of one index scan i 0 and the number of index scans N s . The value of i 0 depends on the indexing method used, while the value of N s is decided by the query processing method. The total cost of index retrieving ( C i ) is the product of i 0 and N s : Ideally, data retrieval costs ( C d ) should only include the cost of retrieving data necessary for multiresolution query. However, in many cases redundant data is also retrieved during query processing (this is further explained in the next section). Therefore, the value of C d is the sum of the cost of retrieving necessary data C n and unnecessary data C u : Combining previous equations, we have a cost model for multiresolution query: Based on the discussion in last section, the I/O cost of multiresolution query on the progressive meshes is: Here C u = 0 because it only retrieves required data. Without any caching strat-egy, the number of index scan ( N s ) depends on the number of retrievals ( N r ), i.e., one index scan is required for each retrieval: As mentioned, each retrieval fetches two child nodes; all data is fetched this way, except the root, which is retrieved by itself at the very beginning. Therefore, given the total number of nodes needed ( N p ), the number of retrieval ( N r ) is: The cost of necessary data retrieval ( C n ) is determined by the number of re-trievals ( N r ) and the number of disk page access in each retrieval ( N d ), i.e., where t 0 is the cost of retrieving one disk page. Since there are two nodes involved in each refinement and each node has little associated data, it is unlikely that the data for one refinement exceeds disk-page size. If we assume nodes for one refinement are always stored together in one disk page (can be achieved by clustering progressive meshes nodes on disk), the number of disk page access for each retrieval ( N d ) is one, i.e., Combining Equation 5, 6, 7, 8 and 9, the I/O cost of multiresolution query on the progressive meshes is: model to more general multiresolution query, where a node can have more than two children. If each internal node has F child nodes, the number of retrievals ( N r )isnow: Therefore, the total cost of index scan C i is Similarly, the cost of necessary data retrieval C n is: Combine Equation 12 and 13, the total cost D ( Q ) is: The cost model for general multiresolution query (Equation 14) has a configu-ration similar to that for the progressive meshes (Equation 10): 1. The total cost of is proportional to the number of required nodes ( N p ) since 2. The cost of index scan accounts for a large portion of total cost. From Equa-These observations lead to our strategies for multiresolution query optimization. There are several possible approaches to reduce the cost of multiresolution query processing. For simplicity, we use the cost model for the progressive meshes instead of the general one since they share similar structure. From Equation 10, we know that the cost of index scan and data retrieval are i 0  X  N m and t 0  X  N m respectively. We think neither of them is optimal. In ideal case, one index scan should identify necessary data, i.e., Regarding data retrieval cost, the optimal case is that all required data is stored continuously on the disk, i.e. it can be as small as: where B is the number of points each disk page can hold. Therefore, the optimal I/O cost of a multiresolution query is: Comparing the minimal cost and the cost of current processing method (Equa-tion 10), we can say that there is significant gap between the two, in other words, considerable potential for improvement. 4.1 Optimization Strateg y 1 -Reducing Retrieval Number Our first strategy aims to decrease the number of index scan to reduce total cost. A possible solution is to retrieve all necessary data before mesh construction, which can avoid data fetch during mesh construction and thus reduce index scan numbers. Moreover, it has the potential to improve data retrieval efficiency since all data is fetched together instead of bit by bit during construction. With this strategy, it possible to complete data retrieval with one index scan, which is the optimal value as shown in Equation 17. However, there are a few challenges: 1. It is difficult to identify the spatial extent. Among the data needed by a 2. It is difficult to identify the LOD interval. The requirement to support ( C u ), i.e., unnecessary data may also be retrieved in order to include all required data. However, the overall performance can be better if the amount of redundant data is acceptable. The I/O cost of this strategy methods can be described as: where 1. The value of i 0 varies depends on the multiresolution access method used, 2. It is difficult for the value of C n to be as small as the optimal value ( N p /B ) 3. As a side effect, such method may incur unnecessary data retrieval. In some there is no method that exactly implements our strategy, we choose similar approach to illustrate the idea. The secondary-storage progressive meshes [12] is one of the first attempts to employ multiresolution access method in MTM. It builds a two-dimensional quadtree [19] into the progressive meshes (Figure 3). The bottom-up construction starts by dividing the terrain into blocks, which serves as the leaf level of quadtree. Every four simplified blocks are merged to form larger blocks (serve as the internal nodes of quadtree), which are further simplified. This process repeats until only one block is left. The LOD-R-tree [13] and the HDoV-tree [15] adopt a similar approach, but they adopt a R-tree instead. For these methods, a multiresolution query is translated into a range query whose query window is the ROI. During processing, it traverses down the index tree from the root, retrieves nodes that intersects with ROI, and stops at the level where the resolution is sufficient. The performance improvement reported in the test results of these methods confirms that reducing retrieval number can considerably improve overall performance even if it may introduce some redundant data. It is reasonable to expect similar enhancement if applied in an online environment. 4.2 Optimization Strateg y 2 -Balancing Retrieval Number and Besides the difficulty of identifying data extent, there is another factor that contribute to redundant data fetch, the  X  X oundary effect X : the boundary of ROI intersects with some data blocks (nodes of index tree); these blocks need to be retrieved because they contain required data; but they also includes unnecessary data outside ROI. The boundary-effect is inevitable since it is unusual that the query window matches the data block perfectly. However, its negative impact can be reduced by using smaller data block. Most spatial access methods use one disk page, which is the minimal possible value, as the block size to reduce redundant data. However, the block size of previous methods that are based on MTM partitioning can not be small: extra edges are generated at the block edge when partitioning; it will introduce too many edges if the block size is very small. The fact that boundary-effect happens at every level when traversing down the MTM tree worsens the problem.
 retrieval number and redundant data. This strategy retrieves most data before mesh construction and leaves the rest during construction if this can reduce redundant data. Obvious candidates are those nodes that are outside ROI but still necessary. Excluding such nodes also makes it possible to applying well-studied spatial access methods, which incurs a much less boundary effect, directly to MTM because MBR was a major hurdle but it is no longer needed.
 recently proposed by Xu [16]. A MTM is indexed in a x -y -LOD space using a modified three-dimensional quadtree. Multiresolution query is translated into a three-dimensional range query that retrieves nodes within ROI and whose resolution is between minimal LOD (the root) and the LOD conditions. The LOD-quadtree treats every node in a MTM as a point, and extra queries are needed during mesh construction to find missing nodes. The cost of this strategy can be modeled as: Experiment results show that the number of index scan ( N s ) is usually small, and the value of C u is much less than that of previous methods (first strategy), thus even better performance in most cases. We think the reason is that this method achieves a better balance between number of index scan and amount of redundant data: current query processing method, which retrieves all data during mesh construction, is one end; whereas our first strategy, which fetches all data before mesh construction, is the opposite end; the second strategy is somewhere in between and manages to ease the problems of both. The ability to use spatial access method also helps to reduce boundary effect.
 4.3 Optimization Strateg y3-In tegrating MTM and Query The cost of the second strategy (Equation 19) is considerably better than that of current processing method (Equation 10), but still not close to the optimal cost (Equation 17). It is rather difficult to further reduce the cost because of the two challenges inherited in MTM (mentioned in first strategy). Therefore, our third optimization strategy takes a different perspective and try to integrate MTM and query processing, i.e., including query processing information in MTM node, to preclude the inherent problems. For instance, the progressive refinement of mesh construction is well known for not suitable to query processing, if this can be avoided totally, it can significantly reduce processing cost.
 [17], by Xu et al. . It encodes topological data in every node of a MTM, which makes it possible to start mesh construction from the level specified by the LOD condition. This avoids fetching any ancestor nodes and substantially reduces the amount of data required, and thus I/O cost. To avoid introducing too much topological data, direct mesh only encodes relations among nodes with  X  X imilar X  LOD, which means it can not solve the problem completely for variable-LOD query, which may have nodes whose LOD changes dramatically. The cost of this strategy can be modeled as: where For uniform-LOD query, the direct mesh only retrieves nodes that appear in the mesh, and the total cost is: This is very close to the optimal value, or even better in some case because the number of nodes here ( N m ) is much less than that in Equation 17 ( N p ) because the ancestors are no longer needed. However, this does not mean that Equation 17 is not optimal. The reason is that the direct mesh breaks the assumption that all the ancestors of mesh nodes are also required. According to the test results of the direct mesh, the cost of this strategy significantly outperforms others for both uniform-and variable-LOD queries.
 cessing qualitatively rather than quantitatively, which requires more detailed ex-amination of specific indexing structure. In many cases this is essentially range query based on spatial access methods. The cost of such queries have been well studied in the literature. Interested reader please refer to [20, 21, 22] for range query on Quadtree family and [23, 24, 25] for range query on R-tree family. In this paper, we proposed a cost model for multiresolution query processing in an online environment and three strategies for its optimization, among them 1. Reducing retrieval number is an effective method to reduce the total I/O 2. Balancing retrieval number and redundant data seems to a more sensible ap-3. The limitation of MTM, especially the progressive refinement routine of mesh We think there is no simple best strategy among the three. Adopting which one should be based on the specific application. Our optimization strategies are proposed based on theoretical analysis. Their feasibility in practice is confirmed by applying them to existing methods. It is reasonable to expect that they can significantly improve performance if employed to real online GIS applications.
