 We investigate how time intervals of interest to a query can be identified automatically based on pseudo-relevant docu-ments, taking into account both their publication dates and temporal expressions from their contents. Our approach is based on a generative model and is able to determine time in-tervals at di  X  erent temporal granularities (e.g., day, month, or year). We evaluate our approach on twenty years X  worth of newspaper articles from The New York Times using two novel testbeds consisting of temporally unambiguous and temporally ambiguous queries, respectively.
 Time has been recognized as an important dimension in Information Retrieval [2], and recent years have seen an in-creased interest in making use of temporal information as-sociated with documents or information needs. Tasks that have been tackled include retrieving recent relevant docu-ments [10] as well as documents relevant to implicitly [11] or explicitly [3, 4] temporal queries. Beyond that, also web search engines have meanwhile deployed features to keep up with the changing Web, indexing recently published docu-ments, and filter results based on their publication dates.
In this work, we address the problem of automatically identifying time intervals of interest to a given keyword query. For instance, when presented with the keyword query bill clinton presidency , a good time interval to determine would be [1993 , 2001], which covers the years of Clinton X  X  presi-dency. This is a useful building block in temporal informa-tion retrieval with applications such as (i) temporal query reformulation and expansion  X  by adding time intervals of interest to the query, (ii) temporal diversification of search results  X  by making sure that the result covers diverse time intervals of interest to the query, and (iii) providing more structured query results to users  X  organized by important time intervals they refer to.

While ours is not the first e  X  ort in this direction, it dif-fers from previous ones [4, 9] in several important aspects. First, our focus is on time intervals (e.g., [1993 , 2001]) as opposed to time points at a fixed temporal granularity (e.g., the years 1993 and 2001). Second, we make use of both doc-uments X  publication dates, as part of their meta data, as well as temporal expressions from their contents. Third, our ap-proach is not restricted to a fixed temporal granularity but can determine time intervals of interest at di  X  erent temporal granularities (e.g., day, month, and year). Finally, we also consider temporally ambiguous queries for which more than one time interval is of interest  X  say george bush presidency or san francisco earthquake .

This work builds on prior research [3], which aims at im-proving retrieval e  X  ectiveness for explicitly temporal queries such as summer olympics 2004 . Borrowing their formal model for representing temporal expressions contained in docu-ments (e.g., in the summer of 2004 ) and capturing their inherent uncertainty, we put forward a generative model for identifying time intervals of interest to a given keyword query. Our model is based on the intuition that a time interval of interest should be often referred to in relevant documents. More specifically, it considers the top-k docu-ments retrieved by a unigram language model, treating them as pseudo-relevant, and analyzes their contents, specifically the temporal expressions therein, for often referred to time intervals. We describe the design space and consider di  X  er-ent concrete instantiations of our model. To evaluate their performance, we compile two novel testbeds, consisting of temporally unambiguous and temporally ambiguous queries obtained from high-quality web sources.

Contributions made in this work are: (i) a novel ap-proach to identify time intervals of interest to a given key-word query, (ii) two testbeds consisting of temporally (un) ambiguous queries which are made publicly available, (iii) an experimental evaluation of our approach on The New York Times Corpus [1], as a publicly-available document collec-tion, on the aforementioned query testbeds.

Organization. The rest of this paper is organized as follows. We put our work in context with prior research in Section 2. Section 3 then describes our approach, including a discussion of the design space and details on our concrete instantiation. Following that, we describe our experimental evaluation in Section 4, before concluding in Section 5.
In this section, we put our work in context with existing prior work. Kanhabua et al. [9] is the work closest to ours. In contrast to the approach put forward in this work, their method focuses on identifying years of interest to a keyword query and does so only based on documents X  publication dates. Their method is thus restricted to time points at year granularity and cannot identify time intervals at other granularities. Dakka et al. [4] as well as Diaz and Jones [7], as one building block in their respective research, describe methods that identify time points of interest to a query. Their methods, though, are solely based on the publication dates associated with documents and do not consider tempo-ral expressions from their contents. Again, no time intervals are considered and the granularity is limited to that of doc-uments X  publication dates. Str  X  otgen et al. [13] look into the related problem of identifying salient temporal expressions from a document. Other work has looked into improving the result quality of implicitly or explicitly temporal queries. For the former, this includes Metzler et al. [11], who iden-tify implicitly temporal queries within the query log of a web search engine, and Dakka et al. [4], who analyze the distribution of publication dates to identify implicitly tem-poral queries. Peetz et al. [12] is a recent related work that leverages bursts in the temporal distribution of publication dates to improve retrieval e  X  ectiveness. Berberich et al. [3], as the work mentioned in the introduction, targets explicitly temporal queries and leverages both documents X  publication dates and temporal expressions. Our work is orthogonal and the time intervals that we identify can be used to augment the query and obtain better results with one of the afore-mentioned approaches. Finally, there has been work on at-taching a time point or time interval to an entire document. Thus, de Jong et al. [5] determine the likely publication time of a document based on its language; Kanhabua et al. [8] make use of temporal expressions from documents X  contents to the same end. Jatowt et al. [6], even in the absence of any temporal expressions, determine a so-called focus time for a document, which delimits the time period the docu-ment predominantly refers to. For all of these approaches, the focus is on identifying a single time point or time in-terval (as opposed to possibly more than one) for a given document (as opposed to a query in our case).
In this section, we describe our approach for identifying interesting time intervals for a given keyword query.
We largely adopt the formal model and notation intro-duced by [3]. Our document collection is denoted D .A document d 2 D consists of a multiset of keywords d text and a multiset of temporal expressions d time .Welet tf ( v,d ) and tf ( T,d ) denote the term frequency of the keyword v and the temporal expression T in document d , respectively. We use | d text | and | d time | to denote the multiset cardinalities of the textual and temporal part, respectively. In the remainder, when it is clear from the context, we simply write d to refer to either of them. Keywords are drawn from a vocabulary V . A temporal expression is a four-tuple with components from a time domain T (usually N ). Such a temporal expression can refer to any time interval [ tb,te ] 2 T  X  T with tb l  X  tb  X  tb u and te l  X  te  X  te u ,i.e., tb and tb u ( te u ) mark the earliest and latest begin (end) of such times intervals. This representation treats time intervals as having a precise meaning and captures the uncertainty in-herent to temporal expressions such as in the 1990s , which at year-granularity would be mapped to h 1990 , 1999 , 1990 , 1999 i , thus potentially referring to any time interval com-pletely within the decade. Alternatively, a temporal expres-sion T can be regarded as a set of time intervals, namely all of the time intervals that it can refer to. We will use this interchangeably and, for instance, use | T | as the number of time intervals the temporal expression refers to.
As mentioned above, our approach determines time in-tervals of interest to a query based on pseudo-relevant doc-uments. To determine those, we use a unigram language model with Dirichlet smoothing and thus estimate the query likelihood of a given keyword query q as Here, D is the document collection, treated as a single doc-ument, for the purpose of smoothing probability estimates.
Having identified documents believed to be relevant to the keyword query q , our approach analyzes their contents to determine time intervals of interest. We next describe the high-level components of our approach, before discussing possible instantiations.

Intuitively, a time interval [ tb,te ] is considered interesting for a keyword query q , if it is frequently referred to by highly relevant documents. We cast this intuition into the following generative model:
According to this model, first a document d is selected from top ( q,k ) as the set of k documents having highest like-lihood of generating the keyword query q . Second, a time interval [ tb,te ] is generated from the temporal expressions contained in document d . For each of the two steps, we consider di  X  erent design alternatives.
 In the simplest case, in the first step, a document is selected at uniform random among the top-k results, yielding Here, the query likelihood P ( q | d ) is thus not taken into ac-count. While this may not be a problem for small choices of k , we expect it to deteriorate performance for larger choices. As an alternative, we consider which estimates the probability of selecting a document in the first step as proportional to its query likelihood esti-mated according to Equation 1. For the second step, we can estimate the probability of gen-erating the time interval [ tb,te ] from document d as
P ([ tb,te ] | d )= 1 | d
The time interval [ tb,te ] can thus only be generated from documents containing temporal expressions that exactly map to it. To illustrate this, the time interval [1992 , 1998] can only be generated from documents that contain from 1992 until 1998 but not from documents containing only in the 1990s . As a more relaxed advanced alternative, building on the generative model introduced in [3], we also consider which takes into account the uncertainty inherent to tem-poral expressions. With this model, also a document con-taining in the 1990s , formally represented as h 1990 , 1999 , 1990 , 1999 i , could generate the time interval [1992 , 1998]. At query time, our method first determines the set top ( q,k ) of documents having highest query likelihoods. It then an-alyzes the temporal expressions therein, determining t min and t max corresponding, respectively, to the earliest and lat-est time mentioned in any of the result documents. Fol-lowing that, it enumerates all valid time intervals [ tb,te ]  X  [ t min ,t max ] and determines their probability P ([ tb,te ] | d ). For this last step, combining the two design alternatives for each of the two steps of our generative model, we obtain four possible instantiations, which we experimentally evaluate in the following section. We will use N and A to refer to the na  X   X ve and advanced design alternative for each of the two steps. The method combining Equation 4 and Equation 5, for example, will be referred to as AN .
We now describe our experimental evaluation of the ap-proach put forward in this work.
Document Collection. As a document collection, we use The New York Times Annotated Corpus [1], which con-sists of about 2 million news articles published between 1987 and 2007. Publication dates are readily available. Tempo-ral expressions are obtained from the data provided by [3]  X  they used TARSQI [14] to annotate temporal expressions augmented by a handful of handcrafted regular expressions to go after range expressions (e.g., from 1980 until 1984 ). Publication dates of documents are taken into account as ad-ditional temporal expressions  X  thus a document published on March 13, 1988 virtually contains the temporal expres-sion on March 13, 1988 .

Queries. We use two sets of test cases: (i) temporally unambiguous queries obtained from the  X  X n this Day X  web-site of The New York Times 1 . For each day of the year, this website lists an event of historic significance, including a concise description. For example, for July 1st, the event is described as  X  X n 1997, Hong Kong reverted to Chinese rule http://learning.blogs.nytimes.com/on-this-day/ after 156 years as a British colony. X  . We extract the indi-cated year (here: 1997) for each date to obtain a precise date at day granularity and keep the rest of the description as a query. This leaves us with a total of 366 temporally un-ambiguous queries; (ii) temporally ambiguous queries from the domains of Sports, Music, Movies, Politics, and History, which we compiled manually. For each of them, we con-sult Wikipedia to find out the associated time intervals at day granularity. The obtained set of 20 queries is given in Table 3. Here, the number of associated time intervals is given in parentheses, indicating the degree of ambiguity of each query. In the interest of repeatability, both query sets, including associated time intervals are made available at: http://www.mpi-inf.mpg.de/~kberberi/data/cikm2014
Methods under comparison are the four combinations of the na  X   X ve and advanced models delineated in Section 3, referred to as NN , AN , NA , and AA . We can not sensi-bly compare against [9] as a baseline, since their method is based on publication dates and year granularity. For each of the methods under comparison, we set the smoothing pa-rameter of the unigram language model as  X  = 1000 and vary the number of pseudo-relevant documents retrieved as k = { 25 , 50 , 100 } . We consider three di  X  erent temporal granularities (day, month, year) in our experiments. When going for a coarser granularity (e.g., year), temporal expres-sions, which are natively stored at day granularity, are sys-tematically coarsened. As a concrete example, the tempo-ral expression h 19980101 , 19981231 , 19980101 , 19981231 i would be converted into h 1998 , 1998 , 1998 , 1998 i at year granularity. The same procedure is applied to the ground-truth time intervals of our query test cases.

Measures. We use Precision@ k (P@ k ) as a measure of retrieval e  X  ectiveness. For the sake of comparability, we re-port P@1 and P@5 for both the unambiguous and ambigu-ous queries  X  instead of using mean reciprocal rank (MRR) for the unambiguous case.
Table 1 shows values of P@1 and P@5 obtained for un-ambiguous queries. We observe relatively higher precision values for NA and AA , which rely on the advanced ap-proach to estimate P ([ tb,te ] | d ). Both achieve similar per-formance, indicating that our advanced method to estimate P ( d | q ), taking into account query likelihoods, is not e  X  ec-tive. This is substantiated by the performance of NN and AN  X  while the latter uses the advanced method to estimate P ( d | q ), its precision values are as low as those obtained by the completely na  X   X ve NN . It can also be seen that meth-ods X  performance varies with temporal granularity, peeking at month granularity. Finally, we observe that considering more pseudo-relevant documents only pays o  X  to a point  X  for none of the methods performance increases consistently as we go beyond k =50.

Results for ambiguous queries are shown in Table 2. All four methods consistently achieve higher values of P@1 and P@5 than for the unambiguous case. Comparing NN and AN , we again observe that the advanced method of estimat-ing P ( d | q ) is not very e  X  ective. In contrast, we see good improvements for NA and AA , indicating that the more advanced handling of temporal expressions pays o  X  . For am-biguous queries, as a di  X  erence from the unambiguous case, we observe that all methods achieve their best performance for year granularity. However, again we do not see consis-tent improvements as more pseudo-relevant documents are considered for larger choices of k .
 Our experiments, using temporally unambiguous and tem-porally ambiguous queries as test cases, have shown that NA and AA perform similarly and are ahead of the other two configurations. Thus, the advanced method to handle temporal expressions and estimate P ([ tb,te ] | d )ise  X  ective; the advanced method to estimate P ( d | q ), on the other hand, has no e  X  ect.
We have proposed a novel approach to identify time inter-vals of interest for a given keyword query. Our approach is based on a generative model and we considered four possible instantiations of it. Experiments on temporally unambigu-ous queries and temporally ambiguous queries as test cases showed that there are e  X  ective instantiations of our approach  X  considering temporal expressions and their inherent uncer-tainty pays o  X  ; factoring in query likelihoods does not. As part of our future research, we plan to investigate (i) how users perceive the interestingness of the determined time in-tervals and (ii) how retrieval e  X  ectiveness is a  X  ected when using the determined time intervals in query expansion. [1] The New York Times Annotated Corpus [2] O. Alonso, M. Gertz, and R. A. Baeza-Yates. On the [3] K. Berberich, S. Bedathur, O. Alonso, and [4] W. Dakka, L. Gravano, and P. G. Ipeirotis. Answering [5] F. M. G. de Jong, H. Rode, and D. Hiemstra.
 [6] A. Jatowt, C. Man Au Yeung, and K. Tanaka.
 [7] R. Jones and F. Diaz. Temporal profiles of queries. [8] N. Kanhabua and K. N X rv  X ag. Using temporal language [9] N. Kanhabua and K. N X rv  X ag. Determining time of [10] X. Li and W. B. Croft. Time-based language models. [11] D. Metzler, R. Jones, F. Peng, and R. Zhang. [12] M.-H. Peetz, E. Meij, and M. de Rijke. Using [13] J. Str  X  otgen, O. Alonso, and M. Gertz. Identification of [14] M. Verhagen, I. Mani, R. Sauri, J. Littman,
