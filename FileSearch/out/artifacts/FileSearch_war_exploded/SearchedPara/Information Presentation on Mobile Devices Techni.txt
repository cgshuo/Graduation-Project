 Mobile devices have gained increasingly popularity due to its portability nature. People use these small mobile devices to manage personal information, do simple work with poor processing requirement, or remotely control PCs and computer-ized appliances [1]. Nowadays, the use of mobile devices has penetrated into the domains of education, business, military, etc. [1].

Compared with traditional desktop co mputers, mobile devices have many lim-itations in terms of 1) small-sized display with poor resolution, fewer colors, and different width/height ratio from the normal 4:3; 2) limited CPU processing and memory capacities; 3) slow connection with fluctuated bandwidth; and 4) non-user-friendly input facilities (ordinarily used keyboard and handwriting de-manding lots of screen space, resulting in quite inaccurate results) [2,3]. Table 1 gives some quantitative indicators.

Due to these large differences, the classi c desktop solutions have limited ap-plicability to mobile user interface design. In this paper, we survey research ef-forts on the design of mobile device interfaces, focusing on information presenta-tion through diverse channels including visual, audio, and tactile channels. The remainder of the paper is organized as follows. Section 2 describes the guidelines for mobile device interface design. Following these guidelines, some recently devel-oped techniques and approaches for mobile device interface design are presented in Section 3. We also describe our experiences of virtually presenting database query results on PDAs in Section 4, and conclude the paper in Section 5.
 [4,5] identified several main challenges in mobile human-computer interaction, leading to the following design considerations for mobile device interfaces.  X  Small devices with limited input/output facilities. Considering the small  X  Mobility. Environments may change drastically as users move. The mobile  X  Widespread population . Simple user interface should be designed, because  X  Multi-tasking with limited and split attention . Due to the mobile environ-Many human-interface researchers are trying new methods to enable and enhance information presentation, utilizing visual, audio, and tactile channels of mobile devices, respectively. 3.1 Visual Channel of Mobile Devices Different types of information (such as Web pages, texts, images, maps, and structured data) are visually pr esented in different ways [2].
 1) Web Page Presentation Mobile Web search receives great attentio n nowadays. Web contents, mostly de-signed for desktop computer s, are badly suited for mobile devices [6,7]. Currently, the majority of commercially available mobile web browsers use single-column viewing mode to avoid horizontal scroll [7]. But this approach tends to have much more vertical scroll and destroys the layout of original view [7].
Based on small-and large-scaled user studies, [8] provided a list of devel-opment principles for Web page display. They are: 1) developing phone-based applications that provide d irect, simple access to focused valuable contents; 2) trimming the page-to-page navigation down to a minimum; 3) providing more rather than less information for each search result; 4) using simple hierarchies which are similar to the phone menus that users are already familiar with; 5) adapting for vertical scrolling or reducing the amount of vertical scrolling by sim-plifying the text to be displayed; 6) reducing the number of users X  keystrokes; 7) providing a quick way for users to know whether a search result points to a conventional HTML page or a small screen optimized page; 8) pre-processing conventional pages for better usability in small screen contexts; and 9) combining theoretical and empirical evaluation to provide further insights [8].
Google X  X  PDA interface is similar to Google X  X  XHTML interface [9]. However, the diversity of queries in mobile environments was far less than in desktop [9]. This might be due to the enormous amount of efforts (in terms of time and key presses) needed for users to enter que ry terms, so that each session on mobile devices had significantly fewer queries tha n sessions initiated on the desktop [9]. Users for the most part tended to search similar content as desktop queries, and the percentage of adult queries was vastly larger [9].

To deliver adaptive Web contents on mobile devices, researchers also consid-ered to re-author web pages, which can be done at server side, intermediate side , or client side [10].
 A. Re-authoring Web pages at server-side. Server-side adaptation provides the Web page author maximum control over content delivery for mobile devices [10]. [11] reported a system which used the W3C X  X  Document Object Model (DOM) API to generate an XML tree-like structure, and Extensible Style Sheet Lan-guage Transformations (XSLT) to generate Wireless Markup Language (WML) or HTML content for display on mobile devices. This system also adapted to the users X  dynamic context. [12] presented another system which could adapt multi-media Web documents to optimally match the capabilities of the client device. In a scheme called InfoPyramid, content items on a Web page were transcoded into multiple resolution and modality versions, so that they could be rendered on different devices [12]. On the other hand, a customer could select the best parameters from the InfoPyramids to meet the resource constraints of the client device while still delivering the most  X  X alue X  [12].

B. Re-authoring Web pages at intermediate-side. Proxies typically apply inter-mediate adaptations [10]. Today, many of web page visualization efforts fall into this category. Without changing the layout of original web pages, [13] reduced the size of images which were larger than that of mobile screens and removed media which mobile devices did not support. [6] described a scaled-down version to fit the mobile devices screen. Images embedded in a web page and the Internet address bar were removed; and the font size of tex tual contents was adjusted by the user [6]. The focus + context visualization was also employed in the display of Mobile Web. Users could choose what they are int erested in with a large font size, while other information in the surrounding area was displayed in a reduced font size [6]. [14] splited a Web page X  X  structure into smaller but logically related units. A two-level hierarchy was used with a thumbnail representation at the top level to provide a global view and an index to a set of subpages at the bottom level for de-tailed information. [15] introduced heuristics for structure-aware Web transcod-ing which considered a Web page X  X  stru cture and the relative importance of its components. [7] proposed to display a web page as a thumbnail view, but preserving the original page layout, so that users can identify the overall page structure and recognize pages they previously viewed. [16,17] also proposed to show pages in a modified original layout.

C. Re-authoring Web pages at client-side. A client device can use style sheets to format contents in a browser [10]. For instance, the font size of textual con-tents can be adjusted by users [6]. Together with the above intermediate-side approaches, by storing user X  X  operations with the DOM tree in a profile, the system automatically generated a DOM-tree with branches expanded or hidden based on the user X  X  interest [6]. 2) Text (Lengthy Document) Presentation Two popular ways to view lengthy docum ents on small screens in the literature are Rapid Serial Visual Presentation (RSVP) and Leading Format Presentation (LFP) [18]. 1) RSVP presents one or more text words at a time at a fixed loca-tion on the screen [19]. Two variants of RSVP, i.e., Adaptive RSVP and Sonified RSVP, were detailed in [20]. Adaptive RSVP adjusts each text chunk exposure time with respect to content (e.g., the number of characters and words to be exposed) as well as to context (e.g., the result of content adaptation, the word frequencies of the words in the chunk, and the position of the chunk in sen-tence being exposed). Sonified RSVP plays appropriate sound when a certain text chunk is displayed. 2) LFP method scrolls the text in one line horizon-tally/vertically across the screen [18,19,20]. Considering that sentence boundary is important in reading, a sentence-orie nted presentation manner was developed for a small window, which presented complete sentences one at a time [19].
In general, sentences are read more accurately and more natural in the RSVP format than in the LFP format [20,21], since when the eye processes information during fixed gazes, it is more comfortable that the text moved successively rather than continuously [20]. However, the experiments of [22] showed that compre-hension for smooth scrolling Times Square was at least as high as that for RSVP at presentation rates ranging from 100 to 300 words per minute. 3) Image Presentation To visualize data-intensive images on mobile devices, an intuitive solution is to compress and transcode images to reduce data transmission and processing. JPEG 2000 [23] detailed a progressive transmission mechanism which allowed images to be reconstructed by different pix el accuracy or spatial resolution and be delivered for different target devices with different capabilities. [24] introduced an non-uniform resolution presentation method, in which resolution was the highest at the fovea but falls off away from the fovea. [25] classified images into image type and purpose, and transcoded images in order to adapt to the unique characteristics of the devices with a wide range of communication, processing, storage, and display capabilities, thus improving the delivery.

In addition to treating an image as a whole, [26,27] proposed to separate region-of-interest and deliver the most important region to the small screen ac-cording to human X  X  attention model. They used RSVP presentation technique to simulate the attention shifting process, and noticed that there was an impor-tant psycho physiological activity -visual attention shifting. Image browsing on small devices could be improved by simulating the fixation and shifting process in a way similar to RSVP. An image was decomposed into a set of regions which were displayed serially, each for a brief period of time. [26] further introduced a generic and extensible image attentio n model based on three attributes (i.e., region of interest, attention value, and mi nimal perceptible size) associated with each attention object. [27] tried to find an optimal image browsing path based on the image attention model to simulate the human browsing behavior. 4) Map Presentation Maps play an important role in mobile location-based services. However, they are often too large to be fully displayed on mobile device screens [2]. To this end, [28] used 3D arrows to point towards the objects and by the side of the arrows the information about distance and name of point object was provided with text. The 3D arrows were semi-transparent for comfortable visual.  X  X alo X  [29] represented off-screen locations as abstr act  X  X treetlamps X  with their lights on the map. The map was overlayed with translucent arcs, indicating the location of off-screen places. Each arc was part of a circular ring that surrounds one of the off-screen locations. The arcs on the map allowed viewers to recognize the missing off-screen parts, and let viewers understand its position in space well enough to know the locatio n of the off-screen targets. 5) Structured Data Presentation There are also some interesting visuali zed methods developed for structured data, such as relational databases, 3D objects, and calendar, etc.
 Database. [30] designed a graphical databas e interface for mobile devices. In this method, as soon as a connection was made, the relations in the database were displayed on their interface. Initially, only  X  X op-level X  relations were shown, and for the sake of conserving sc reen space, a nested relat ion structure was imposed on non-nested database systems. On the i nterface, users could select any number of relations, and display all the possible join paths between them. The resulting join was displayed on an auxiliary screen, which showed the actual SQL query and the actual answer set for that query [30]. 3D Object. To visualize 3D model on mobile devices, Virtual Reality Modeling Language (VRML) and Extensible 3D(X3 D) allow a content developer to re-use a large collection of exist ing Web-Based 3D worlds in the mobile context and develop content for different platforms with the same tools [31]. For location-aware presentation of VRML content on mobile devices, the user interface was divided into two parts: an upper area where the actual 3D world was visualized and a lower area providing status information and tools for users to navigate the 3D world, setting the system and moving the viewpoint [31].
 Calendar. [32] showed an interesting fisheye c alendar interface called DataL-ens on PDAs. On the interface, first, users could have an overview of a large time period with a graphical representation of each day X  X  activities. Then, users could tap on any day to expand the area representing that day and reveal the list of appointments in context [32]. The  X  X emantic zooming X  approach used in DataLens was utilized to visually repres ent objects differently depending on how much space is available for displaying. The graphical views were scaled to fit the available space, while the textual views u sed a constant-sized font, and the text was clipped to fit in the available space [32]. 3.2 Audio Channel of Mobile Devices With the hard handling and limited screens, it is beneficial to make use of the speech channel of mobile devices for the following reasons [33]. First, voice is por-trayed as the most naturalistic way to interact with a system, so speech interface is more natural for interaction. Second, sp eech interface helps increase interac-tion efficiency, because speech is faste r than any other common communication method like typing and writing. Third, voice interaction avoids  X  X and-busy X  and  X  X yes-busy X  operations which happen with the visual interface. Fourth, people think that telephony network is often more trustworthiness than Web. Finally, speech interface can also serve as a good input manner, where speech recognition avoids password input [33]. Ease-of-use and the speed of interaction are the two most important requirements for the voice interface, and voice interface must be an integral part of the whole user interface of the device, but should not be overused due to the misrecognition [34]. [34] designed a multi-lingual speaker-dependent voice dialing user interface, which could support speech recognition a nd speech synthesis. Users don X  X  need to train the voice tag, and the interface system can generate the tag automatically. [35] offered a speech interface model, wh ere users can use a single personalized speech interface to access all services and applications. 3.3 Tactile Channel of Mobile Devices Apart from visual and audio channels, tactile sensation can also be explored throughout mobile user interaction. By tactile feedback, we can reduce possible mobile interaction mistakes, since audio feedback is difficult to apply when the environment is noisy, and visual feedback is also difficult as users have to pay much attention to others and the screen is small [36]. Users can feel the vibration with their fingers as they press the screen . [36] did text entry experiments and showed that users with tactile feedback us er interface entered significantly more text, made fewer errors, and corr ected more errors they did make. [37] used paper metaphor to design the switching of scrolling and editing operations, where a touch sensor is attached on the PDA. In map or Web browser, when a user does not touch sensor, the s creen scrolls according to the movement of the pen when dragging, and when touching, the screen does not scroll and edit while dragging. In the photograph browser, when the user does not touch the sensor, the screen also scrolls the photograph, but when touching, if dragging the pen upward, the photograph is zoomed in; and if downward, the photograph is zoomed out. Dragging the pen left to right invokes clockwise rotation, and right to left invokes counter clockwise rotation [37]. In this section, we describe our experience of virtually presenting database query results on a small PDA, focusing on presentation style and presentation content. We use Microsoft SQL server X  X  sample Northwind relational database as an example. It has an employee table, containing 16 attributes named employee -ID , LastN ame , FirstName , BirthDate , Title ,andsoon. 4.1 Dynamic Presentation Style The commonly used visual database interface on desktop PCs is form-based [38], containing all the database query results that satisfy a user X  X  query re-quest. However, for mobile PDA users, it will be too heavy and even unreadable to showing all the result records once only on the small screen. Hence, we follow the dynamic text presentation principle, and adopt the two well-developed meth-ods, i.e., leading format and serializing format [19], for dynamically displaying database query resul ts on small screens.

Leading display of query results. The leading can be either tuple -wise or attribute -wide. Tuple-wise leading presentation, as its name implies, is to present result tuples one by one from right to the left side of the screen; while attribute-wise leading presentation is to display result attribute values one by one from right to left, as illustrated in Figure 1 and Figure 2 respectively, where symbol  X  ||  X  is used to separate different attribute values.

Here, two closely related important factors that affect reading are display speed and jump length . The former measures the amount of words presented per minute; while the latter measures the continuity of leading display characters movement. The speed setting must take human X  X  eye fixation time for reference. Performance study in [21] showed that the slow speed of 171 wpm (Words Per Minute) and the fast speed of 260 wpm mak es non-evident difference on reading accuracy. However, with the same speed setting, the shorter the jump length is, the smoother the movement of chara cters looks on the screen. [21] showed that reading accuracy declines as jump le ngth decreases from 3 characters to 1 character. Another study [39] also demonstrated that when the jump length is setto1or2characters,re ading accuracy is very poor, but when jump length increases, the reading a ccuracy increases. Any jump length setting between 4 and 10 characters h as the same effect.

In our experimental setting, considering a query result is multi-lined moving, making the understanding more difficult than single-lined moving, we set the jump length to 5 characters, and the display speed to 260/ n wpm, where n is the number of lines to be output on the screen, dynamically determined upon each user X  X  query request.

Besides display speed and jump length, the color difference between text and background also influences the reading comprehension [40]. According to [40], for Video Display Terminals, the color difference between text and background colors is preferably not less than a threshold value, and red-on-white , blue-on-yellow ,and white-on-black are all favorable options complying to this requirement [41]. Our test shows that readers are mostly comfortable with their familiar combination of black texts on white background.

Serially display of query results. The above leading display inevitably incurs human X  X  eye movement during reading. To decrease the amount of eye move-ment, we adopt the serial display meth od [19] to present a query result page by page, with the latter one covering the previous one. This method simulates human X  X  normal reading experience (like turning pages of a book). It enables to visualize the structure of a database tuple. Figure 3 presents a page containing one complete result tuple. According to [ 42], we set the display speed to 250 wpm for better reading comprehension. The jump length parameter is not applicable for this method. We compare the effect of leading display and serially display in Table 2.

Some other considerations during our presentation design are as follows. 1) Pause/continue/stop functions. During dynamic display, it is desirable to permit mobile users to interrupt information moving at will and to continue or stop later. 2) Fast page turning . To be efficient, anytime, the presenter should allow mobile users to quickly turn the page up and down for their interested contents. 3) Enlarged display. To enhance readability on small screens, mobile users sometimes may want to have a bigger view about some important contents. The presenter shall provide a larger vers ion of information, selected by users. 4.2 Presentation Content While making efforts to dynamically pres ent query results on small screens, we also try to adapt the result contents, aiming to present the most potential important and useful results on the screen.

Observing that users often need some as pects of query results depending on query context, we propose to select the most potentially useful attributes to be displayed on the screen. To do this, we apply three strategies. 1) Method 1: Considering that users X  similar interest usually last for a certain period, we select attributes based on the access history. Tha t is, each time the most frequently used attribute w ill be selected for display. Let F j i denote the probability that the j th attribute is selected for display for the i th query. As-sume each database query is independent. According to the Maximum likelihood estimate, the possibility that the j th attribute is interesting for the k+1 th query 2) Method 2: The classical least recentl y used (LRU) strategy is also a simple decision making method utilizing the access history. That is, each time the least recently used attribute will no t be selected for display. 3) Method 3: Considering that user X  X  interested attributes usually depend on query context, like user X  X  profession, query intention, time and place of the query, query duration, etc., we do context-aware attribute selection. We first let users identify their query context elements such as their  X  duty  X ,  X  month  X ,  X  place  X ,  X  query intention  X , and  X  time spent on query  X , etc., with which we build a decision tree by training the historic d atabase access log, using the classical decision-tree arithmetic C4.5. We then make selection decision upon every new query request. 4) Method 4: Considering similar query contexts lead to similar user X  X  inter-ested attributes, we cluster similar q uery contexts. When a new query comes, we choose the most similar cluster according to the distance between the clus-ter X  X  center and the new query context s. Then, we vote the user X  X  interested attributes among the chosen cluster. We use k-means arithmetic to cluster the query contexts.

Of course users can always add their interested attributes or delete the sug-gested ones.
We conducted a small-scaled case study among the undergraduate university students inside the campus to let them point out the commonly interested at-tributes in the employee table under different query situations. Totally we have 2946 such records, 60% of which was used for training, and 40% of which was used for testing. Assume that at most five a ttributes values will be presented on PDAs at one time. Figure 4 shows the performance result, where the horizontal axis represents the total 16 attributes. As illustrated, the third context-aware attribute selection approac h performs consistently t he best among the three. This is obvious since it takes into acco unt both the access history and current access context, while the second LRU met hod makes the least use of the historic knowledge, thus performing the worst, and the first method -the most frequently used approach stays in the middle.
 The growing popularity of mobile computing devices presents new challenges to mobile device interface designers. I n this paper, we surveyed related work on information presentation through the visual, audio, and tactile channels of mobile devices. Our preliminary experiments with virtually presenting database query results on PDAs were also reported.
 The work is jointly supported by the Ministry of Education of China (Changjiang Scholar Program), Tsinghua University (Hundred-Talent Program), and Faculty of Information Science and Technology (Teaching and Research Starting Fund).
