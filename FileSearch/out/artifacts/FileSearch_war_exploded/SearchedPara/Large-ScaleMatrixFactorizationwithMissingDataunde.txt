 Man y computer vision problems such as SfM [26 ], non-rigid SfM [3] and photometric stereo [11 ] can be formulated as a matrix factorization problem. In all these problems, the measured data are observ ations of the elements of an m n measurement matrix M of kno wn rank r . The objecti ve is to factorize this measurement matrix M into factors A and B of dimensions m r and n r , respecti vely such that the error jj M AB T jj is minimized. When all the elements of M are kno wn, by the singular value decomposition (SVD) of M . Ho we ver, in most real applications man y of the elements of M will be missing and we need to solv e a modied problem given by: where is the Hadamard element-wise product, W is a weight matrix with zeroes at indices corre-sponding to the missing elements of M , and jj A jj 2 data overtting. Matrix factorization with missing data is a dif cult non-con vex problem with no kno wn globally con vergent algorithm. The damped Ne wton algorithm [4], a variant of Ne wton' s high computational comple xity and memory requirements and so cannot be used for solving lar ge scale problems.
 We formulate the matrix factorization with missing data problem as a LRSDP [6], which is es-sentially a rank constrained semidenite programming problem (SDP) and was proposed to solv e lar ge SDP in an efcient way. The adv antages of formulating the matrix factorization problem as a LRSDP problem are the follo wing: 1) it inherits the efcienc y of the LRSDP algorithm. The LRSDP algorithm is based on a quasi-Ne wton method which has lower computational comple xity and memory requirements than that of Ne wton' s method, and so is ideally suited for solving lar ge thographic SfM, can be easily incorporated into the LRSDP-based factorization formulation; this is possible because of the exible frame work of the LRSDP (see section 2).
 Prior Work Algorithms for matrix factorization in the presence of missing data can be broadly algorithms [26 , 13, 10, 18, 25] generally minimize an algebraic or approximate cost of (1) and are solutions for the other factor . Though the alternation-based algorithms minimize the cost in each iteration, the y are essentially a coordinate descent approach and suf fer from atlining, requiring an excessi ve number of iterations before con vergence [4]. To solv e this problem, damped Ne wton and hybrid algorithms between damped Ne wton and alternation were proposed in [4]. Although these algorithms give very good results, the y cannot be used for solving lar ge-scale problems be-cause of their high computational comple xity and memory requirements. Other algorithms based on Ne wton' s method have been proposed in [7, 21], which also cannot be used for solving lar ge-scale problems.
 lem [9]. The goal of matrix completion is to nd a low-rank matrix which agrees with the observ ed entries of the matrix M . Recently , man y efcient algorithms have been proposed for solving this problem [8, 17, 19, 16, 15, 20]. Some of them [16 , 15, 20] are formulated as matrix factoriza-tion problems. Ho we ver, we note that these algorithms, by themselv es, can not handle additional from man y users, for example in a mo vie recommendation system. In [24 ], collaborati ve ltering is formulated as a matrix completion problem and solv ed using a semidenite program. Later a fast version, using conjugate gradient, was proposed in [22 ], but it also cannot handle additional constraints. we briey dene the SDP and LRSDP problems, and discuss the efcient algorithm used for solving the LRSDP problem.
 SDP is a subeld of con vex optimization concerned with the optimization of a linear objecti ve function over the intersection of the cone of positi ve semidenite matrices with an afne space. The standard-form SDP is given by: where C and A matrix variable, which is required to be symmetric and positi ve semidenite, as indicated by the constraint X 0 . The operator denotes the inner product in the space of n n symmetric matrices dened as A B = trace ( A T B ) = P n lar ge scale problems.
 In LRSDP a change of variables is introduced as X = RR T , where R is a real, n r matrix with r n . This has the adv antage that it remo ves the non-linear constraint X 0 , which is the most be a con vex problem. The LRSDP formulation is given by: Note that the LRSDP formulation depends on r ; when r = n , (3) is equi valent to (2) . But the intention is to choose r as small as possible so as to reduce the number of variables, while the problem remains equi valent to the original problem (2) .
 A non-linear optimization technique called the augmented Lagrangian method is used for solving grangian function with respect to the variable R which is done by a limited memory BFGS method. BFGS, a quasi-Ne wton method, is much more efcient than Ne wton' s method both in terms of com-putations and memory requirement. The LRSDP algorithm further optimizes the computations and storage requirements for sparse C and A further details on the algorithm, see [6, 5]. In this section, we formulate the matrix factorization with missing data as an LRSDP problem. We do this in the follo wing stages: in section 3.1, we look at the noiseless case, that is, where the measurement matrix M is not corrupted with noise, follo wed by the noisy measurement case in section 3.2, and nally in section 3.3, we look at how additional constraints can be incorporated in the LRSDP formulation. 3.1 Noiseless Case When the observ ed elements of the m n dimensional measurement matrix M are not corrupted with noise, a meaningful cost to minimize would be: dimensions m r and n r respecti vely . To formulate this as a LRSDP problem, we introduce a ( m + n ) r dimensional matrix R = A B . Then We observ e that the cost function jj A jj 2 as ( RR T ) i;j + m = M i;j . Thus, (4) is equi valent to: This is already in the LRSDP form, since we can express the abo ve equation as where C is an ( m + n ) ( m + n ) identity matrix, and to simplify the notations we have introduced the inde x l with ( l ) = ( i; j ) l = 1 ; : : : ; j j . A indices ( i; j + m ) and ( j + m; i ) equal to 1 = 2 and b the matrix factorization problem as an LRSDP problem for the noiseless case. Ne xt we look at the noisy case. 3.2 Noisy case When the observ ed entries of M are corrupted with noise, an appropriate cost function to minimize would be: where is the Hadamard element-wise product and W is a weight matrix with zeros corresponding to the missing entries and 1 to the observ ed entries in M . To formulate this as an LRSDP problem, we introduce noise variables e (8) can be expressed as Ne xt, we aim to formulate this as a LRSDP problem. For this, we construct an augmented noise vector E = [ e T 1] T and dene R to be R is a `block-diagonal' matrix, where the blocks are of sizes ( m + n ) r and ( j j + 1) 1 respecti vely . With this denition, RR T is a block-diagonal matrix given by We can now express (8) in the follo wing LRSDP form: with This is because the last constraint is used to set E b and b is a simple extension of the original LRSDP problem [5]. This completes the LRSDP formulation for the noisy case. Ne xt, we look at incorporating additional constraints in this frame work. 3.3 Enf orcing Additional Constraints Man y additional constraints can be easily incorporated in the LRSDP formulation. We illustrate this using the specic example of orthographic SfM [26 ]. SfM is the problem of reconstructing the the cameras. Suppose that m= 2 cameras are looking at n 3 -D points, then under the afne camera model, the 2 -D imaged points can be arranged as an m n measurement matrix M with columns corresponding to the n 3 -D points and rows corresponding to the m= 2 cameras ( 2 consecuti ve rows per camera) [26 ]. Under this arrangement, M can be factorized as M = AB T , where A is a m 4 camera matrix and B is a n 4 structure matrix with the last column of B , an all-one vector . Thus, M is a rank 4 matrix with a special structure for the last column of B . Further , under the orthographic camera model, A has more structure (constraints): pair of 'rows' that corresponds to the same camera is ortho-normal. To state this constraints precisely , we decompose the A matrix as A = [ P t ] where P is a m 3 sub-matrix consisting of the rst three columns and t is the last column vector . We can now express the camera ortho-normality constraint through the P P T matrix, whose diagonal elements should be 1 (normality constraint) and appropriate off-diagonal elements B = [ X 1 ] , where X is a n 3 matrix. Thus, AB T = P X + t 1 T and the observ ation error can be expressed as e solv e here would be to minimize the observ ation error subject to the ortho-normality constraints: To formulate this as an LRSDP problem, we introduce the augmented translation variable T = [ t T 1] T , and propose the follo wing block-diagonal matrix R : With this denition of R , we can express (14) as a LRSDP problem; follo wing steps similar to the pre vious sections, it is should be straight forw ard to gure out the appropriate C and A required in this LRSDP formulation (3) . This completes our illustration on the incorporation of the ortho-normality constraints for the orthographic SfM case. This example should con vince the reader that man y other application-specic constraints can be directly incorporated into the LRSDP formulation; this is because of the underlying SDP structure of the LRSDP . for the matrix factorization problem. 4.1 Matrix Completion Theory Matrix completion theory considers the problem of reco vering a low-rank matrix from a few samples of its entries: More specically , it considers the follo wing questions: 1) when does a partially observ ed matrix have a unique low-rank solution? 2) Ho w can this matrix be reco vered? The answers to these reco ver, has row and columns spaces incoherent with the standard basis and 2) we are given enough (16) . Further , the solution can be obtained by solving a con vex relaxation of (16) given by: where jj X jj is the nuclear norm of X , given by the sum of its singular values. 4.2 Relation with Matrix Factorization and its Implications In matrix completion the objecti ve is to nd a minimum rank matrix which agrees with the partial observ ations (16) , whereas in matrix factorization we assume the rank r to be kno wn, as in the problems of SFM and photometric stereo, and we use the rank as a constraint. For example, in our LRSDP formulation, we have imposed this rank constraint by xing the number of columns of the factors A and B to r . Ho we ver, though the matrix completion and factorization problems are de-This fact has been used in solving the matrix completion problem via matrix factorization with an question raised in [4]: when is missing data matrix factorization unique (up to a gauge)? And from ations (see next section), we have found that the LRSDP formulation, though a non-con vex problem in general, con verges to the global minimum solution under these conditions. We evaluate the performance of the proposed LRSDP-based factorization algorithm (MF-LRSDP) on both synthetic and real data and compare it against other algorithms such as alternation [4], damped Ne wton [4] and OptSpace [15 ], which is one of state-of-the-art algorithms for matrix com-pletion. 5.1 Ev aluation with Synthetic Data The important parameters in the matrix factorization with missing data problem are: the size of the matrix M characterized by m and n , rank r , fraction of missing data and the variance 2 of the observ ation noise. We evaluate the factorization algorithms by varying these parameters. We consider two cases: data without noise and data with noise. For synthetic data without noise, we generate n n matrices M of rank r by M = AB T , where A and B are n r random matrices with is then revealed randomly according to the missing data fraction. For synthetic data with noise, we add independent Gaussian noise N (0 ; 2 ) to the observ ed entries generated as abo ve. Exact Factorization: a first comparison. We study the reconstruction rate of dif ferent algorithms by varying the fraction of revealed entries per column ( j j =n ) for noiseless 500 500 matrices of rank 5 . We declare a matrix to be reconstructed if jj M ^ M jj the reconstructed matrix and jj : jj and OptSpace. MF-LRSDP gives the best reconstruction results as it needs fewer observ ations for tively . MF-LRSDP also tak es the least time, follo wed by OptSpace and alternation. For similar comparison to other matrix completion algorithms such as ADMiRA [16 ], SVT [8] and FPCA [17 ], the interested reader can look at [15 ], where OptSpace was sho wn to be consistently better than these algorithms. For the remaining experiments on synthetic data, we mostly compare MF-LRSDP against OptSpace. Note that we have not included the damped Ne wton algorithm in this comparison because it is very slo w for matrices of this size. column j j =n for dif ferent sizes n of rank 5 square matrices by MF-LRSDP and OptSpace. Figure 2(a) sho ws that MF-LRSDP reconstructs matrices from fewer observ ed entries than OptSpace. Exact Factorization: vary rank. We study the reconstruction rate vs. j j =n as we vary the rank r of 500 500 matrices. Figure 2(b) again sho ws that MF-LRSDP gives better results than OptSpace. Noisy Factorization: vary noise standard deviation. For noisy data, we use the root mean square error RMSE = 1 = p mn jj M ^ M jj deviation of the additi ve noise for rank 5 , 200 200 matrices and study the performance by MF-LRSDP , OptSpace, alternation and damped Ne wton. Figure 2(c) sho ws that all the algorithms perform equally well.
 For timing comparisons, please refer to the supplementary material. 5.2 Ev aluation with Real Data We consider three problems: 1) afne SfM 2) non-rigid SfM and 3) photometric stereo. Affine SfM. As discussed in section 3.3, for afne SfM, the m n measurement matrix M is a rank 4 matrix with the last column of matrix B an all-one vector . M is generally an incomplete matrix because not all the points are visible in all the cameras. We evaluate the performance of MF-LRSDP on the `Dinosaur' sequence used in [4, 7], for which M is a 72 319 matrix with 72% missing entries. We perform 25 trials and at each trial we pro vide the same random initializations to MF-LRSDP , alternation and damped Ne wton (OptSpace has its only initialization technique). We use the root mean square error over the observ ed entries, jj W ( M ^ M ) jj measure. Figure 3 sho ws the cumulati ve histogram over the RMS pix el error . MF-LRSDP gives the best performance follo wed by damped Ne wton, alternation and OptSpace. We further tested the algorithms on a 'longer Dinosaur', the result of which is pro vided in the supplementary material. Non-rigid SfM. In non-rigid SfM, non-rigid objects are expressed as a linear combination of b basis shapes. In this case, the m n measurement matrix M can be expressed as M = AB T , where A is an m 3 b matrix and B is an n 3 b matrix [3]. This mak es M a rank 3 b matrix. We test the performance of the algorithms on the 'Giraf fe' sequence [4, 7] for which M is a 240 167 matrix with 30% missing entries. We choose the rank as 6 . Figure 3 sho ws the cumulati ve histogram of 25 trials from which we conclude that MF-LRSDP , alternation and damped Ne wton give good results. Photometric Ster eo. Photometric stereo is the problem of estimating the surf ace normals of an object by imaging that object under dif ferent lighting conditions. Suppose we have n images of normals) and we arrange them as an m n measurement matrix M . Then under Lambertian as-sumptions, we can express M as M = AB T , where A is an m 3 matrix representing the surf ace normals and reectance and B is an n 3 matrix representing the light-source directions and in-shado ws and specularities and those pix els should not be included in the M matrix as the y do not obe y the Lambertian assumption. This mak es M , an incomplete matrix. We test the algorithms on the `Face' sequence [4, 7] for which M is a 2944 20 matrix with 42% missing entries. The cumulati ve histogram in gure 3 sho ws that MF-LRSDP and damped Ne wton gives the best results follo wed by alternation and OptSpace. Additional constraints: Orthographic SfM. Orthographic SfM is a special case of afne SfM, sequence and the tracks are supposed to be circular). Thus, incorporating all the constraints of a problem leads to better solution and MR-LRSDP pro vides a very exible frame work for doing so. We have formulated the matrix factorization with missing data problem as a low-rank semidenite programming problem MF-LRSDP . MF-LRSDP is an efcient algorithm that can be used for solv-such as the ortho-normality constraints of orthographic SfM. Our empirical evaluations on synthetic and it gives very good results on the real problems of SfM, non-rigid SfM and photometric stereo. We note that though MF-LRSDP is a non-con vex problem, it nds the global minimum under the conditions of matrix completion theory . As a future work, it would be interesting to nd a theo-retical justication for this. Also, it would be interesting to nd out how MF-LRSDP performs on collaborati ve ltering problems.

