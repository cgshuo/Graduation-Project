
Boris Galitsky n 1. Introduction about circumstances a person was given a camera as a gift ( Fig. 1 a).

What kind of syntactic and/or semantic properties can separate these two sentences into distinct classes? We assume that the be turned into a meaningful one by referring to its particular feature (e.g., by saying  X  observe that in this example belonging to positive and negative classes constitutes somewhat stable patterns. represented as values.

Inthispaperwewillbefindingasetofmaximalcommonsub-treeforapairofparsetreefortwosentencesasameasureofsimilarity aligned and subject to generalization.
 nevertheless deliver satisfactory classification results.
 sensitive or more cautious, after we confirm that our measure of syntactic similarity between texts is adequate.
The computational linguistics community has assembled large data sets on a range of interesting NLP problems. Some of these is defined starting from the level of lemmas to chunks/phrases and all the way to paragraphs/texts. problem domains, search engine description and a brief review of other studies with semantic inference. classes), solving a number of practical problems for the virtual forum platform. 2. SG in search and relevance assessment ( Section 6 ).

We focus on four following problems which are essential at various phases of the above application: 1. Differentiating meaningful from meaningless sentences in opinion mining results; currently with her product choice; 4. Classifying search results in respect to being relevant and irrelevant to search query. finding plentiful examples for respective classes is quite easy. We now outline each of these four problems. significantly backs up review-based recommendations by comparative shopping sites. for building highly trusted opinion mining applications.
 between meaningful and meaningless sentence with respect to expressed opinion is frequently subtle. A short sentence can be demonstrate how a very weak semantic signal concealed in a syntactic structure of sentence can be leveraged; obviously, using keyword-based rules for this problem does not seem meaningful.
 suitable to form an advert.
 For example, from the content like why we pledge to pay the difference if you X  X e offered a better deal elsewhere. We want to generate the following ads traditional keyword-based IE approach.
 determine what kind of response a user is expecting: general recommendation, advice on a series of products, a brand, or a particular product, response and feedback on information shared, and others.
 (epistemic states are italicized),  X  X  X  keep in mind no brand in particular but I have read that Canon makes good cameras X  X  lot of reviews but still have some questions on what camera is right for me X  X  be determined by syntactically closest representative sentence.
 among these sentences.
 however make sense only if occur within a certain natural language expression.
Intermsofsearchimplementation,thiscanbedoneintwosteps: 1) Keywords are formed from query in a conventional manner, and search hits are obtained by TF popularity of hits, page rank and others. generalization comes into play here.
 assumes to be relevant and returned to a user.
 document popularity, TF n IDF, and learning which answers were selected by other users for similar queries previously).
For the following example http://www.google.com/search?q=how  X  to  X  pay  X  foreign  X  business  X  tax  X  if  X  I  X  live  X  in  X  the  X  US out. 3. Generalizing portions of text more general one that covers both rather than a more specific one as in unification. Let E of E and E 2 if there exist two substitutions s 1 and s 2 such that s in the result. If lemmas are the same but POS is different, lemma stays in the result. produces a syntactic expression that can be semantically interpreted as a common meaning shared by two sentences. formulas. Some words (entities) are mapped into predicates, some are mapped into their arguments, and some other words do not commonality between the expressions? camera with digital zoom camera with zoom for beginners of arguments), and zoom( type_of_zoom ). The above NL expressions will be represented as: camera ( zoom ( digital ) , AnyUser ) camera ( zoom ( AnyZoom ) , beginner ) , ization, camera ( zoom ( AnyZoom ) , AnyUser ).

At syntactic level, we have generalization of two noun phrases as: {NN-camera, PRP-with, [digital], NN-zoom [for beginners]}.
 { NN-camera, PRP-with, NN-zoom ]} , which is a syntactic analog as the semantic generalization above. avoid ambiguity.
 3.1. Generalizing at various levels: From words to paragraphs operation occurs on the following levels: Text Paragraph Sentence Phrases (noun, verb and others) Individual word a set of sets which are the results of pair-wise generalization of these expressions. operations on trees we could follow along the lines of Kapoor and Ramesh (1995). semantically interpreted as a common meaning shared by two sentences. information is contained in the node label. We also have an arc to the other node. The sub-trees are coded so that information about occurrence in the full tree is retained. 3) All sub-trees are grouped by phrase types. 4) Extending the list of phrases by adding equivalence transformations ( Section 3.2 ). 5) For the set of the pairs of sub-trees for both sentences for each phrase type. (generalization results), calculate the score. 7) For each pair of sub-trees for phrases, select the set of generalizations with the highest score (least general). 8) Form the sets of generalizations for each phrase types whose elements are sets of generalizations for this type. of generalization for given pair of phrases.
 empty.
 of words is retained. In the following example To buy digital camera today, on Monday Digital camera was a good buy today, first Monday of the month phrases. Buy -digital -camera is not a generalization phrase because buy occurs in different sequence with the other generalization nodes.

As one can see, multiple maximum generalizations occur depending how correspondence between words is established, multiple generalization as the operation of anti-unification of syntactic trees .
 parameters fixed). As a result of this optimization performed in ( Galitsky et al., 2010 ), we obtained W W CD  X  0.64, W VB  X  0.83, W PRP  X  0.35 excluding common frequent verbs like get/take/set/put for which W
W o POS, n 4  X  0.2 (different words but the same POS), and W
Generalization score (or similarity between sentences sent sum through words score(sent 1 , sent 2 )  X  P {NP, VP, y } P W POS word_generalization(word sentences and paragraphs.
 sentence is added. Notice that such associativity is not implied by our definition of generalization. 3.2. Equivalence transformation on phrases system, for our setting we do not need a complete transformation system as long as we have sufficiently rich set of examples.
Transformation rules were developed under the assumption that informative sentences should have a relatively simple structure ( Romano et al., 2006 ).
 sub-trees of the source tree ( Table 1 ), see also ( Zanzotto and Moschitti, 2006 ). used annotation rules to mark negation and modality of predicates (mainly verbs), based on their descendent modifiers. sometimes the resultant meaning might be distorted by otherwise we would miss important commonalities between expressions containing noun phrases. An expression  X  X P 1 o of or for 4 NP modifier role, and arbitrary sort for adjectives. 3.3. Simplified example of generalization of sentences We present an example of generalization operation of two sentences. Intermediate sub-trees are shown as lists for brevity. I am curious how to use the digital zoom of this camera for filming insects.
 How can I get short focus zoom lens for digital camera? Can I get auto focus lens for digital camera? We first draw the parsing trees for these sentences and see how to build their maximal common sub-trees: sentences.
 (interrupted) path of the tree ( Fig. 1 c): { MD-can, PRP-I, VB-get, NN-focus, NN-lens, IN-for JJ-digital NN-camera }. At the phrase level, we obtain: Fig. 1 (c) Generalization results for second and third sentence.
 modifiers for  X  X ens X  which are different in these two sentences (shown as NN-focus NN-chunking (Abney, 1991), using the format / position (POS  X  phrase)
Now we group the above phrases by the phrase type [NP, VP, PP, ADJP, WHADVP. Numbers encode character position at the beginning. Each group contains the phrases of the same type, since the match occurs between the same type. Sample generalization between phrases: aligning verb, prepositional and other types of phrases ( Fig. 2 ).
 each phrase type. Six mapping links between phrases correspond to six members of generalization result links. The resultant their syntactic occurrence is different.
 phrase  X  X  be some-kind-of zoom camera  X  X  which expresses the common meaning for the above sentences. Notice the occurrence of similar way (but with preposition for ) from the second sentence with the same head noun camera . We present more complex generalization examples in Section 4 . 3.4. From syntax to inductive semantics
To demonstrate how the SG allows us to ascend from syntactic to semantic level, we follow Mill X  X  Direct method of agreement instances agree, is the cause (or effect ) of the given phenomenon. X  X  ( Ducheyne, 2008 ). absent in the sentence. Obviously, any linguistic properties which are absent when the meaning is present cannot be necessary conditions for this meaning of a phrase.

For example, the method of agreement can be represented as a phrase f formally expressed as o wxyz 4 . Consider also another phrase f ignore the syntactic structure of f 1 and f 2 ). Therefore, here we can see that word A is the cause of w (has meaning w ). a class: instead we derive semantic features from syntactic according to above inductive framework. 3.5. Nearest-neighbor learning of generalizations classes. The following conditions hold when a sentence U is assigned to a class R  X  and not to the other class R : graph is similar to both positive and negative examples). 2) For any negative example R ,if U is similar to R (i.e., U similarity between U and each negative example.

Condition 2 is important to properly handle the nonmonotonic nature of such feature as meaningfulness of an opinion-related that the parse tree overlap with the foreign class is covered by the parse tree overlap with the true class. 4. Syntactic generalization-based search engine and its evaluation The search engine based on SG is designed to provide opinions data in an aggregated form obtained from various sources.
Conventional search results and Google sponsored link formats are selected as most effective and already accepted by the vast community of users. 4.1. User interface of search engine opinions (review portals, vendor-owned reviews, forums and blogs available for indexing) are combined. snapshot of multiple opinions from multiple sources, dynamically linked to match user request.
Automatically generated product advertisement compliant with Google sponsored links format are shown on the right. Phrases in appeal to potential users. There is a one-to-one correspondence between products in opinion hits on the left and generated usability opinions respectively.
 provides as linked search hits: the fly. 4.2. Qualitative evaluation of search high sensitivity comparison of query and search results allows finding semantic relevancy between them. either Metropolitan Museum of Art or National Museum of Catholic Art &amp; History . what other people ended up clicking through).

We perform our quantitative evaluation of search re-ranking performance with two settings: score. We increase the query complexity and observe the contribution of SG by manually constructed templates, help to improve search relevance.
 4.3. Evaluation of web search relevance improvement than an average one (3 keywords); and significantly more complex queries of 5 X 7 keywords respectively. and should not be used. However, for longer queries the results are encouraging (almost 4% improvement), showing a visible multi-sentence queries as well. 4.4. Evaluation of product search evaluation was conducted by the authors, based on proprietary search quality evaluation logs. products, than Mean Reciprocal Rank (MRR), calculated as 1 /n S answer, whereas a product search might include multiple valid answers.
 (SG score). The results are shown in Table 3 .
 the war in IRAQ? X  X  answered by  X  X  X he rabbit is in the bush X  X .  X  a false negative in case it is not available or SG operation with the correct answer failed. proper matching with popular questions which are relatively complex, such as PRP], to match questions with phrases Recommend me a movie which got academy award for best director Cannes Film Festival Best director award movie Give me a movie with National Film Award for Best Producer Academy award for best picture Movies of greatest film directors of all time are shown in Table 3 column 6.

One can observe that for rather complex queries, we have 64 X 67% relevance improvement, using manually coded templates, over baseline for simpler question, 39% for more complex phrases and 36% for multi-sentence queries. using manual templates in product searches further increase search relevance for complex multi-phrased questions. be reduced to common phrases) such as president-NN (very specific) and (VP(VBD)(NP)(PP(IN)(NP)))(very broad). 4.5. Comparison with other means of search relevance improvement relevance.

This taxonomy is used by matching both question and answer to a taxonomy tree and relying on the cardinality of the set of since the features of various nature are leveraged (pragmatic, syntactic/semantic and hybrid respectively. each of these scores work and how they correlate with the best order of answers for relevance. 5. Evaluation of text classification problems 5.1. Comparative performance analysis in text classification domains For digital camera reviews, we classify each sentence with respect to sensible/meaningless classes by two approaches: A baseline WEKA C4.5, as a popular text classification approach SG-based approach.
 classification, we do not expect as dramatic improvement (not shown).
 variability of acceptable ad lines ( X  X ales pitches X ) which have not been captured by the training set. would be hard to obtain at the level of keywords or superficial parsing. 5.2. Example of recognizing meaningless sentences not even a crack or scratch. X  did not have a chance to use this nice camera X : { [for  X  DT  X  trip], [camera ]} use]} which gives a new meaning of meangless sentences, where an entity was not used and therefore sentiment is irrelevant. have time to use the Canon camera which is my friend X  X  with the above negative hypothesis is not a subsumption of (empty) generalization with the above positive hypothesis.
 Panasonic camera as a gift of my friend because of nice zoom X  is meaningful again since nice zoom is informative. 5.3. Commercial evaluation of text similarity improvement We subject the proposed technique of taxonomy-based and SG-based techniques in the commercial main of news analysis at taxonomy and SG-based technique is applied.
 the web for mining.
 events and found media.
 on SG) use different sources of relevance information, so they are indeed complementary to each other. not as important for web mining assuming there is an unlimited number of resources on the web, and we need to identify the relevant ones.
 learning of SVM. Moschitti (2009 ) compares performances of bag-of-words kernel, syntactic parse trees and predicate argument
TREC dataset. Structured learning methods are better suited for performance-critical production environments serving hundreds maintained and tracked which assures required performance as system evolves in time and text classification domains change. 6. Related work
Most work in automated semantic inference from syntax deals with much lower semantic level that semantic classes we manage in approach proposed in the current study.
 same meaning in a more unified and automated manner.
 text to formal meaning representations, obtained via generalization.
 this work.
 search results ranking can be solved based on semantic generalizations based on local data  X  just queries and hit snapshots. and statistical decoding can be used to find the most likely semantic representation. between two syntactic trees in terms of their sub-structures (e.g., Collins and Duffy, 2002 ). These approaches use embedded tree, the bag-of-words tree, the bag-of-POS-tags tree and the predicate argument tree 1. (SBARQ (WHNP (WP What))(SQ (AUX does)(NP (NNP S.O.S.))(VP (VB stand)(PP (IN for))); approaches will give a more explicit insight on important featured of syntactic parse trees. correlation with human judgment. 7. Conclusions the possibility of linking low level but detailed syntactic level with high-level pragmatic and semantic levels directly . the high semantic level required for practical application.
 cases too.
 subtrees. Table 6 performs the further comparative analysis of tree kernel and SG approaches: two-three decades ago.
 keyword-based methods. In real time application components, such as search, we use conventional TF allvoices.com, zvents.com and ebay.com.
 parsings with lower confidence levels provide a higher match score, we select them. address syntactic complexity and variability. We believe the current study is a next step in that direction. contract to general linguistic resources designed for horizontal domains.

Complexity of SG operation is constant. Computing relation G classifications in projected pattern structures are related to those in original ones. ( Moschitti, 2008 ) O(m  X  n), where m and n are number of nodes in a first and second trees. Acknowledgements their suggestions.
 Appendix. Implementation of OpenNLP Similarity component
This component does text relevance assessment, accepting two portions of texts (phrases, sentences, paragraphs) and returns a similarity score. https://svn.apache.org/repos/asf/opennlp/sandbox/opennlp-similarity
Similarity component can be used on top of search to improve relevance, computing similarity score between a question and all search results (snippets).
 calculated as the size of all maximal common sub-trees for sentences from a pair of texts. need to understand computational linguistics or machine learning.
 First use case of Similarity component: Search
To start with this component, please refer to SearchResultsProcessorTest.java in package opennlp.tools.similarity.apps public void testSearchOrder() runs web search using Bing API and improves search relevance.
Look at the code of public List o HitBase 4 runSearch(String query) and then at private BingResponse calculateMatchScoreResortHits(BingResponse resp, String searchQuery) which gets search results from Bing and re-ranks them based on computed similarity score. The main entry to Similarity component is
SentencePairMatchResult matchRes  X  sm.assessRelevance(snapshot, searchQuery)
To run this test you need to obtain search API key from Bing at www.bing.com/developers/s/APIBasics.html and specify it in public class BingQueryRunner in protected static final String APP_ID.
 Solving a unique problem: Content generation
To demonstrate the usability of Similarity component to tackle a problem which is hard to solve without a linguistic-based technology, we introduce a content generation component: RelatedSentenceFinder.java
The entry point here is the function call hits  X  f.generateContentAbout(Albert Einstein);  X  X raduate X ,  X  X nvented X  etc.).
 result like  X  X  X lbert Einstein College of Medicine 9 Medical Education www.einstein.yu.edu/ Albert Einstein College of Medicine is one of the nation X  X  premier institutions for medical education, and filter out irrelevant search results.

This is done in function public HitBase augmentWithMinedSentencesAndVerifyRelevance(HitBase item, String originalSentence, List o String 4 sentsAll) SentencePairMatchResult matchRes  X  sm.assessRelevance(pageSentence  X  title, originalSentence); You can consult the results in gen.txt, where an essay on Einstein bio is written.
These are examples of generated articles, given the article title www.allvoices.com/contributed-news/9423860/content/81937916 and www.allvoices.com/contributed-news/9415063 Solving a high-importance problem: Filtering out meaningless speech recognition results.
Speech recognitions SDKs usually produce a number of phrases as results, such as  X  X  X emember to buy milk tomorrow from trader joes X  X ,  X  X  X emember to buy milk tomorrow from 3 to jones X  X  query understanding system such as Siri for iPhone can be costly).

SpeechRecognitionResultsProcessor.java does the job: public List o SentenceMeaningfullnessScore 4 runSearchAndScoreMeaningfulness(List re-ranks the phrases in the order of decrease of meaningfulness.
 Similarity component internals are in the package opennlp.tools.textsimilarity.chunker2matcher
ParserChunker2MatcherProcessor.java does parsing of two portions of text and matching the resultant parse trees to assess similarity between these portions of text.

To run ParserChunker2MatcherProcessor private static String MODEL_DIR  X  resources/models; needs to be specified
The key function public SentencePairMatchResult assessRelevance(String para1, String para2) takes two portions of text and does similarity assessment by finding the set of all maximum common subtrees of the set of parse trees for each portion of text
It splits paragraphs into sentences, parses them, obtained chunking information and produces grouped phrases (noun, evrn, prepositional etc.): public synchronized List o List o ParseTreeChunk 44 formGroupedPhrasesFromChunksForPara(String &gt;para) and then attempts to find common subtrees: in ParseTreeMatcherDeterministic.java
List o List o ParseTreeChunk 44 res  X  md.matchTwoSentencesGroupedChunksDeterministic(sent1GrpLst, sent2GrpLst) Phrase matching functionality is in package opennlp.tools.textsimilarity; ParseTreeMatcherDeterministic.java:
Here X  X  the key matching function which takes two phrases, aligns them and finds a set of maximum common sub-phrase public List o ParseTreeChunk 4 generalizeTwoGroupedPhrasesDeterministic
Package structure is as follows: opennlp.tools.similarity.apps: 3 main applications opennlp.tools.similarity.apps.utils: utilities for above applications opennlp.tools.textsimilarity.chunker2matcher: parser which converts text into a form for matching parse trees opennlp.tools.textsimilarity: parse tree matching functionality.

Comparison with bag-of-words approach // we first demonstrate how similarity expression for DIFFERENT cases have // too high score for bagOfWords
String phrase1  X  How to deduct rental expense from income String phrase2  X  How to deduct repair expense from rental income.;
List o List o ParseTreeChunk 44 matchResult  X  parser.assessRelevance(phrase1, phrase2).getMatchResult(); assertEquals( matchResult.toString(),  X  X  [[ [NN-expense IN-from NN-income ],[JJ-rental NN-n ],[NN-income ]], [ [TO-to VB-deduct JJ-rental NN-n ],[VB-deduct NN-expense IN-from NN-income ]]]);
System.out.println(matchResult); double matchScore  X  parseTreeChunkListScorer .getParseTreeChunkListScore(matchResult); double bagOfWordsScore  X  parserBOW.assessRelevanceAnd
GetScore(phrase1, phrase2); assertTrue (matchScore  X  2 o bagOfWordsScore);
System. out . println(MatchScore is adequate (  X  X  matchScore  X  ) and bagOfWordsScore  X  X  bagOfWordsScore  X  is too high); // we now demonstrate how similarity can be captured by POS and cannot be // captured by bagOfWords phrase1  X  Way to minimize medical expense for my daughter phrase2  X  Means to deduct educational expense for my son; matchResult  X  parser.assessRelevance(phrase1, phrase2).getMatchResult(); assertEquals( matchResult.toString(),  X  X  [[ [JJ-n NN-expense IN-for PRP$-my NN-n ],[PRP$-my NN-n ]]]);
System. out .println(matchResult); matchScore  X  parseTreeChunkListScorer .getParseTreeChunkListScore(matchResult); bagOfWordsScore  X  parserBOW.assessRelevanceAndGetScore(phrase1, phrase2); assertTrue (matchScore 4 2 n bagOfWordsScore);
System.out.println(MatchScore is adequate (  X  X  matchScore  X  ) and bagOfWordsScore  X  X  bagOfWordsScore  X  is too low); References
