 In many practical machine learning problem s, such as class imbalance learning and cost-sensitive learning, in order to gain better performance, some subjective and aprior knowledge about applications, such as class distribution and misclassification cost, are necessary. Recently, these kinds of learning problems have been recognized as a crucial problem in machine learning and data mining because such problems are encountered in a large number of domains, such as fraud detection [1], medical diagnosis [2] and text classification [3]. In some cases, the absence of consideration of the subjective knowledge causes seriously negative effects on the performance of machine learning methods. In order to introduce the subjective and aprior knowledge into machine learning, many learning methods have been developed [4], [5], [6]. However, most of the research efforts are devoted to making decision trees, neural networks and SVM subjective [7], [8], [9]. 
Rough set theory, proposed by Pawlak [10], has shown powerful capability dealing with inconsistent information in attribute dependence analysis, knowledge reduction subjective knowledge in rough set. Through assigning each attribute an appropriate weight in the reduction process, Xu C.-Z. introduced some subjective knowledge about attributes into attribute reduction [11]. But the subjective knowledge about objects related with class distribution and misclassification costs can X  X  be considered object was associated with a probability p ( x ), which may include some subjective knowledge about objects. However, how to determine the probability under the subjective knowledge was not given. What X  X  more, specific knowledge acquiring algorithms were not presented and systemic experimental analyses were not carried out in their works. 
In order to make rough set subjective, we propose a weighted rough set approach in this paper. The rest of the paper is organized as follows. Weighted rough set learning is proposed and discussed in section 2. Experimental studies of class imbalance learning and cost-sensitive learning based on weighted rough set are carried out in section 3. Section 4 concludes this paper. In this section, we will introduce weights as a representation of the subjective knowledge and proposed a weighted rough set learning method. 
A weighted information system is formally denoted by &gt; =&lt; f V A W U WIS , , , ,, of U Y  X  and ) ( Y X w U be the weight of Y X U , if  X  = Y X I , then objects X , Y and Y X U . 698 J. Liu, Q. Hu, and D. Yu 
When the weight of each object of U is equal, the weighted quality of classification will degenerate into the classical quality of classification. 
Attribute reduction is a core problem in rough set. Based on the weighted quality of classification, we design a heuristic attribute reduction algorithm under the subjective knowledge as Algorithm 1. This algorithm adds the attribute with the greatest weighted quality of cla ssification to attribute subset C B  X  in sequence process this algorithm checks whether B is a minimal subset that has the same knowledge representation ability as C , i.e. whether the elimination of any attribute a the noise, a threshold  X  is introduced to stop the reduction process in the above Algorithm 1. Weighted attribute reduction Input: &gt; = =&lt; f V D C A W U WIS , , , , U and a threshold  X  . 2. compute the maximal weighted quality of classification ) ( D W C  X  ; 3.  X   X  B  X  4. while C B  X  do 6. for each B C a  X   X  do 9. } { max a B B U  X  ; 10. if  X   X   X   X   X  ) ( ) ( D D W B W C then exit the loop; Another important problem which can be solved using rough set is rule extraction. be represented as an assertion of the form where ) , ( B X Des is the condition part of r and ) , ( D Y Des is the decision part of r . 
Nowadays, there are many known rule extraction algorithms inspired by the rough set theory. Among these algorithms, LEM2 algorithm, proposed by Grzymala in [14], is one of the most used rough set based rule induction algorithm. In LEM2, a generalized decision is defined firstly, which may be a decision, or may be the conjunction of more than one decision. Acco rding to the generalized decisions, the objects is partitioned into a family of disjoint subsets of objects, denoted by Y of Y Y ~ set Y K
On the basis of LEM2, we design a rule extraction algorithm under the subjective knowledge as Algorithm 2. In Algorithm 2, c is an element of the description of class set of elements currently considered to be added to the conjunction  X  and ] [  X  denotes the cover of  X  . 
In order to evaluate discovered rules and predict the unseen objects, the weighted of a decision rule r :) , ( ) , ( D Y Des B X Des  X  , are defined as support coefficient of rules with decision k d is computed as 700 J. Liu, Q. Hu, and D. Yu 
According to the principle of majority vo ting, the decision algorithm can give the decision of an unseen object with the following guideline Algorithm 2. Weighted rule extraction experimental studies of class imbalance learning and cost-sensitive learning based on weighted rough set. 
In the experiments, 20 UCI data sets[15], which consist of 10 two-class data german) and 10 multi-class data sets(zoo, lymphography, wine, machine, glass, audiology, heart, solar, soybean, anneal), ar e used. In these data sets, class distribution ratio of the maximum class to the minimum class is from 1.48 to 85.5, and the size of most minimum class is less than 10 objects. In order to perform the experiment based on weighted rough set, the preprocessing on data sets is done at first. In each data set, discretized via entropy (MDLP) [16]. 3.1 Class Imbalance Learning For class imbalance learning, the introduction of the subjective knowledge of class classification accuracy of minority classes, we need assign greater weights to the objects of minority classes. Here we use the inverse class probability as the weight of each object. Formally, the inverse class probability weight of x is computed by 
Via 10-fold cross-validations, the experimental results obtained by classical rough weighted rough set learning improves evidently the accuracy of the minimum class by averagely 0.0689 on all data sets. At the same time, the accuracy of the maximum class decreases by averagely 0.0463 and the overall accuracy decreases by averagely 0.0140. The AUC is a popular classification performance measure for class imbalance learning. In the experiment, the AUC achieved by WRS is bigger than that achieved by RS on most of data sets and increases by averagely 0.0161 on all data sets. Through the consideration of the subjective knowledge of class distribution, WRS improves greatly the accuracy of the minimum class and increases the AUC. 702 J. Liu, Q. Hu, and D. Yu 3.2 Cost-Sensitive Learning Many practical classification problems have different costs associated with different types of errors. For example, in medical diagnosis, the error committed in diagnosing someone as healthy when they have a life-threatening disease is usually considered to be far more serious (thus, higher cost) than the opposite type of error. In such applications, cost-sensitive learning is necessary. 
In order to perform cost-sensitive learning using weighted rough set, it is necessary to know the weight of each object associated with misclassification cost. This can be solved according to [7], where misclassifi cation cost matrix is divided into three misclassification cost, then ) ( i w is defined respectively as follows: for all i j  X  , then ) , ( ) ( J i Cost i w = for J j  X  and 0 . 1 ) ( = J w . Cost matrix type Number of errors 2. Japkowicz N., Stephen S.: The Class Imbalance Problem: A Systematic Study. Intelligent 4. Japkowicz N.: Learning from Imbalanced Data Sets: A Comparison of Various Strategies. 6. Maloof M.A.: Learning When Data Sets are Imbalanced and When Costs Are Unequal and 11. Xu C.-Z., Min F.: Weighted Reduction for Decision Tables. Fuzzy systems and knowledge 
