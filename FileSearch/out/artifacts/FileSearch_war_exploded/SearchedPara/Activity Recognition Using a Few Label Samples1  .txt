 Sensor-based human activity recognitio n has received considerable attention due to its diverse applications such as healthcare systems [1], pervasive and mobile computing [5], and smart homes [10] etc. For example, in the healthcare appli-cations, understanding elderly people X  X  activities can not only provide real-time useful information to caregivers, but also facilitate a monitoring system to take proper actions (e.g. alert clinicians) in emergency cases (e.g. falling down).
While privacy and complexity are major issues in video-based activity recog-nition [11], different supervised learning approaches have been applied to activity recognition based on body-worn sensors. For example, Na  X   X ve Bayes (NB) [23], Hidden Markov Model (HMM) [12, 27], Conditional Random Field (CRF) [27] and Support Vector Machine (SVM) [23] etc. These approaches require suffi-cient labeled samples to train accurate cla ssifiers. However, sample labeling is the most labor intensive and time consuming process in activity recognition [11] as different classes of related activities could have nondeterministic natures  X  some steps of the activities can be perform ed in arbitrary order, and the starting and ending points of activities are difficult to define due to the overlaps among different activities, leading to activities could be concurrent or even interwoven [11]. As such, it would be extremely hard to get sufficient training samples.
Semi-supervised learning approaches, on the other hand, have been designed to build a classification model using a small training set L and a large unlabeled set U . Particularly, an initial classifier can be built from L by using NB, SVM or another classifier. Then the classifier can be used to classify U to assign a (probabilistic) class label to each sample in U [14, 15], which can be in turn used to refine the classifier, using Expectation-Maximization (EM) [22] or other classifiers (like SVM) iteratively [13, 16 X 19]. The combination of NB and EM, and transductive Support Vector Machine (TSVM) [8] are two well known semi-supervised learning methods. In addition, Guan et al [7] designed En-Co-training algorithm for activity recognition based on co-training algorithm [2] which trains two independent classifiers based on two views of data. Stikic et al [26] compared two semi-supervised techniques, namely s elf-training [4] and co-training, and showed co-training can be applied to activity recognition by using sensors with different modalities, i.e. accelerometers a nd infra-red sensors. While a few semi-supervised learning algorithms have been pr oposed, they still need sizable labeled samples for training to achieve accurate results. The reason is that these methods will encounter a cold-start issue when v ery few labeled samples are present for learning a decent initial classifier. Its p oor performance subsequently affects the iterative model refinement process. As such, directly applying semi-supervised learning techniques may not always produce accurate prediction results. In this paper, we address the challenging issue by proposing a novel Dynamic Temporal Extension (DTE) algorithm. Particularly, based on a few labeled sam-ples, we automatically infer some reliable labeled samples from U in temporal space [21]. For each labeled sample, we e xtend it to include its near neighbors along its time axis, if these neighbors are predicted mostly to have a same label with the labeled sample. In effect, our DTE algorithm tries to fill the gap be-tween the limited available labeled samples and sizable labeled samples required for semi-supervised learning. With our inferred reliable labeled samples, we can thus build a more robust and accurate semi-supervised learning model. Exten-sive experiments demonstrate that our proposed technique outperforms existing 7 state-of-the-art supervised learning a nd semi-supervised learning techniques. In this section, we present o ur proposed technique. First, section 2.1 provides our overall algorithm. Then, we introduce how to build a classifier using our designed semi-supervised learning approach in section 2.2. Finally, section 2.3 elaborates how to extend limited labeled samples using our proposed DTE technique. 2.1 Overall Algorithm Fig. 1 shows an overall algorithm of our proposed technique. Step 1 is a prepro-cessing that deals with missing value problem as well as faulty sensors. Missing value problem can be caused by some faulty sensors or unreliable communica-tion channels. We first eliminate sensors which have more than 30% missing values as they can not provide useful and sufficient information for accurate ac-tivity recognition. We then apply cubical s pline interpolation for replacing those missing values in our data sets [3] and eliminate samples with no activity label.
In order to prepare for labeled sample extension, we want to estimate the median size of continuous same-label activity sequences in L + U ,asthisis useful information that indicates how far we should extend each labeled sample. Since we do not have the label information for all the samples in U ,wefirst design a semi-supervised learning method to build an initial classifier IC in step 2  X  we provide its detailed description in section 2.2. Then, we apply IC to classify the unlabeled samples in U in step 3. Given that sensor sampling rates are usually significantly higher than the rates of change between different human activities, we thus perform smoothing step to improve the prediction accuracy by removing impulse noises. Our smoothing process moves a sliding window on predicted labels of U and chooses the labels with majority as the label of all the samples in that window. Step 4 computes the median continuous same-label segment size SS of activities based on the predicted labels in U . Step 5 extends all the labeled samples into the inferred reliable labeled set E based on our designed DTE techniques using the prediction results from IC as well as the estimated segment size SS . We have provided the details of step 5 in section 2.3.
Finally, we build the final classification model M using our semi-supervised learning method, based on labeled set L , the extended set E , and the remaining unlabeled set U  X  E in step 6, and perform final classification in step 7. Note the same method is used for both initial classifier IC and final classifier although the final one is more accurate due to additional reliable labeled sample E . 2.2 Classifier Building Based on Semi-supervised Learning First, labeled set L and unlabeled set U are defined as follows:
A k =( a k 1 ,a k 2 ,...,a kn )isa n -dimensional feature vector where a ki ( i =1 , 2 , ...,n )isthe i  X  X h feature of A k and C k  X  C ( C = { C 1 ,C 2 ,...,C | C | } )isthe associated activity/class label of A k . The objective of this research is to learn a classification model M that can be used to classify any test sample.
We adopt a mixture model to generate each activity A k as mixture models are very useful to character ize heterogeneous data or multiple types of activities.
Where  X  parameterized a mixture model. Given any class C j , assuming that the probabilities of the features are independent as well as normal distribution (based on the central limit theorem) for each attribute in C j ,wehave and the mean and standard deviation of feature i in class j respectively.
In order to perform classification, we compute the posterior probability of class C j for a given example A k :
Where  X  =[  X  1 , X  2 ,..., X  | C | ]and  X  =[  X  1 , X  2 ,..., X  | C | ]. The class C k with k = arg its predicted class label.Note in formula (6), the denominator P ( A k |  X , X  )isa constant, i.e. same for all classes. We now elaborate how to calculate P ( C j |  X , X  ). Based on formula (3), the probability of both labeled and unlabeled training set ( S = L  X  U ) can be written as: Local maximum of log likelihood indicated by (7) can be found using Expected Maximization (EM) in an iterative manner [6]. It can be shown that parameters in M-step of EM algorithm can be computed as follow: Finally, the class prior probability can be calculated:
Note that we have modified the original EM algorithm by setting the posterior class probabilities of initially labeled samples in L as their original labels, at the start of each iteration. This guarantees our classification model is built using correct labeled examples during its iterative training process. 2.3 Dynamic Temporal Extension for Labeled Samples In section 2.2, we have proposed a semi -supervised method to learn a classifi-cation model from a small labeled set L and a large unlabeled set U .Inour case, since L is very small, say a few training examples for each class, the semi-supervised learning method will not capture the characteristics for each class. As such, we have proposed a novel dynamic temporal extension algorithm DTE to extend the initial labeled samples into an extended reliable labeled set E by exploring the dependencies between samples in time domain to effectively boost the performance of semi -supervised learning.
 The proposed DTE algorithm for labeled example extension is shown in Fig. 2. After we initialize the extended set E into an empty set in step 1, a confidence table CfTable [ ][ ] is created and initialized in step 2 which records the support of an unlabeled example to a given class, e.g. CfTable [ p ][ C j ] indicates how likely and the degree of confidence that an example p belongs to a class C j . From steps 3 X 15, we extend each labeled sample one by one and compute the confidence table correspondingly. Particularly, for each seed labeled sample s with class label C j , we extend it to include its neighbor samples to form ExtS along a time line (left/ right hand sides of s ) if we judge these samples in ExtS belong to the same class, i.e. C j , by calling a function ExtendSample() that will be described in Fig 4 later.

Steps 6 to 14 is a loop, which computes the support for each extended sample in ExtS by updating the confidence table CfTable [ p ][ C j ]. When selected sample p does not exist in the table, it is inserted to the set E (step 8) and CfTable with the initial value 1 (steps 9 to 10); otherwise our algorithm increases its respective support value by 1. Finally, steps 16 to 18 assign each sample in E with a label with a maximal class support score wrt to its associated classes in CfTable .
Now, we are ready to introduce the function ExtendSample() that is used in Fig. 2. We first illustrate the key intuition behind it in Fig. 3. As the sampling frequency of sensors is much higher than the change frequency between different human activities, given an initial labeled sample s at time point t 0 , the neighbor samples at its near left time points and at its near right time points are highly likely to share the same label with s , as long as these left/right time points are not too far away from t 0 . However, one challenging problem is how long/far we should extend s to its left/right hand side.

In this paper, we use a sliding window to estimate right and left label-consistent neighbor samples of s . Two base sliding windows (left/right sliding window LBaseWin/RBaseWin) are moved forward from both sides of s indi-vidually and our algorithm decides whether the extension should be continued or stopped based on the analysis of the neighbor samples X  labels inside both sliding windows (Fig. 3). Two important information sources have been used as a stop criteria, namely, 1) neighbor label consistency with s where the labels of s  X  X  neighbors are predicted by our initial classification model IC ,and2)the distance of neighbor samples to s . We design a membership function MF based on a distance measure to s as follows: where x is a current neighbor sample inside in a left/right window; s and SS are the center and width of membership function respectively (Fig 3) where SS is estimated in our overall algorithm by computing the median size of continuous same-label activity sequences. The membership function defined in (11) is a bell shaped fuzzy membership function. As sliding windows move forward from s to left/right side, membership value decreases corrspondingly. The bigger this distance x  X  s , the less likely the neighbor sample x should be included. We also take the label-consistency into consideration by computing a support score Support Score C j for all the predicted class labels C j  X  C in current base window (LBaseWin/RBaseWin):
Score Support Score C j defined in (12) basically calculates the label support inside current (right) base window based two information sources mentioned. We will continue our extending process if these labels in the base window are consistent with s  X  X  label and they are not too far away from s . Depending on the two factors, we extend s dynamically , and the numbers of extended examples are different for each initial labeled sample as well as for the left and right extension.
The detailed description of function ExtendSample() is shown in Fig 4. Note we only show how to extend right samples from s as extending left samples is the same except the extension d irection. After initializing the extended sample set ExtS as empty set in step 2, we perform a loop from steps 3 to 18. Particularly, steps 5 to 9 sum up all the class membe rship scores for each example in the current base window. Steps 10 to 11 get the Winner score and Winner Label from all the classes. Steps 12 to 17 decide if we want to repeat our loop. If the Winner Label is consistent with s and the Winner score &gt; =50%, then the samples inside the current window are reliable, and we thus add them into ExtS and shift the right window to continue our extension process; Otherwise, we stop the loop from here. Finally, step 1 9 returns our extension results. In this section, we evaluate our propo sed DTE technique. We compare it with 7 existing state-of-the-art techniques, including 3 supervised learning techniques , namely, 1NN (which performs best for time series data) [9], SVM [23], NB (Na  X   X ve Bayes)[23],aswellas4 semi-supervised learning techniques , namely, Transduc-tive Support Vector Machine (TSVM) [8], NB+EM (NB+Expected Maximiza-tion) [22], Self-training [20] and En-Co-training [7] etc. 3.1 Datasets For evaluation, we used 3 datasets from Opportunity Challenge [24, 25]. Each dataset represents 1 subject/person who performed various activities with at-tached on-body sensors. Particu larly, each subject performed one Drill session which is 20 predefined atomic activities and 5 Activities Daily Life (ADLs) ses-sions where the subject performed hig h level activities with more freedom on sequence of atomic activities. Datasets contain 4 locomotion activities/classes, namely, stand , walk , sit ,and lie . All the experiments are performed across 3 different datasets. Drill and first 3 ADLs (ADL 1, ADL2, ADL3) are used for training while the last 2 ADLs (ADL4, ADL5) are used for testing.

Table 1 shows the details of the 3 datasets that we used in our experiments after the preprocessing step introduced in section 2.1. To simulate the challenging scenario of learning from limited training samples, for each dataset we randomly select only 3 samples from Training Set for each of the 4 classes, i.e. 12 (3  X  4) samples to serve as the labeled set L . We then randomly select 1000 training samples as unlabeled set U which are used by all the semi-supervised learning methods after ignoring their labels. We have also tested how the sizes of U affect the final classification performance. In addition, the base window size (RBaseWin) is set to 10 (Fig 4) and we will report its sensitivity study results. Finally, to make the evaluation reliable, all the experiments are repeated for 10 times and the performances of all the 8 techniques are evaluated on the same test sets in terms of average Accuracy and F-measure , which are typically used for evaluating the performance of classification models. Note that locomotion activities/classes is moderately imbalanced [3] so we use Accuracy and F-measure as performance measurements.
 3.2 Experimental Results The experimental results are shown in Table 2. The first 3 rows show the per-formance of 3 supervised classification models, i.e. 1NN, SVM, NB, where only initial labeled set ( L ) is used for training. We observe that SVM performs badly compared to 1NN and NB as SVM can not build accurate hyperplanes based on 12 labeled samples for 4-class classification problem.

The next 4 rows illustrate the experimental results of 4 semi-supervised meth-ods, which have used unlabeled set U to boost their performance. Compared with supervised learning methods, we observe that TSVM is much better than SVM for all datasets, and NB+EM outperforms NB for datasets 1 and 2, while it is slightly worse in dataset 3 according to F-measure only. In general, NB+EM works better than TSVM, Self-training and En-Co-Training most of times.
The last two rows in Table 2 show the performance of DTE method and the effect of smoothing for test results. We observe DTE method consistently works better than all the other 7 techniques across all the datasets. Especially for dataset 3, DTE method achieves 11.2% and 12.5% better results than the second best technique NB+EM in term s of average Accura cy and F-measure respectively. We also perform the post-processing by applying smoothing (choose majority labels inside a sliding window) on our predicted test results to remove the impulse prediction errors, which further improve our method in all cases.
Recall that our proposed DTE method has dynamically extended initial la-beled samples to left/right windows to include those neighbor samples that have consistent-label and are not too far away from the labeled samples. For com-parison, we have also used a fixed extension size (FES) which is obtained by averaging the segments sizes of activities based on the actual labels in U .We observe that our proposed DTE perform much better than those semi-supervised methods (e.g. TSVM and NB+EM) that use the FES to include neighbor sam-ples, indicating our method is very effect ive to automatically extend initial la-beled samples dynamically to include those reliable labeled samples so that it can boost the performance of semi-s upervised learning significantly.
Fig. 5 shows the comparison between the performance of proposed DTE sam-ple extension and FES sample extension. From Fig. 5(a), the proposed DTE algorithm can produce much more accurate labeled samples than FES, i.e. more than 15% better in terms of both Accura cy and Precision. While FES produces more samples (Fig. 5(b)), they are not accurate and thus bring noisy labels for the subsequent training process, leading to inferior classification results.
Fig. 6 illustrates the performance of proposed DTE method for different datasets in terms of the number of unlabeled samples used. From Fig. 6, with the increase of unlabeled samples, the performance of classification increases in the beginning and it becomes stable, with at least 1000 unlabelled samples, indicating our method is not sensitive to the number of unlabelled samples used.
Finally, Fig. 7 shows the effect of changing base window size on DTE approach performance (Accuracy/F-measure). As we can be observed, by increasing the base window size, the performance of our approach only changes slightly across all the datasets in terms of both average Accuracy and F-measure, indicating that our method is not sensitive to the base window size. Learning from a few labeled samples beco mes crucial for real-world activity recognition applications as it is labor-intensive and time-consuming to manu-ally label large numbers of training examples. While semi-supervised learning techniques have been proposed to enhance supervised learning by incorporat-ing the unlabelled samples into classifier building, it still can not perform very well. In this paper, we propose a novel dynamic temporal extension technique to extend the limited training examples into a larger training set which can fur-ther boost the performance of semi-supe rvised learning. Extensive experimen-tal results show that our proposed technique significantly outperforms existing 7 state-of-the-art supervised learning a nd semi-supervised learning techniques. For our future work, we will investigate how to select the initial labeled samples intelligently so that they can benefit our classification models more effectively. Acknowledgements. This work is supported in part by a grant awarded by a Singapore MOE AcRF Tier 2 Grant (ARC30/12).

