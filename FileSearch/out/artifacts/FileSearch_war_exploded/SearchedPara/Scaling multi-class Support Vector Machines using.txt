 Support vector machines (SVMs) excel at two-class discrim-inative learning problems. They often outperform genera-tive classifiers, especially those that use inaccurate genera-tive models, such as the naive Bayes (NB) classifier. On the other hand, generative classifiers have no trouble in handling an arbitrary number of classes efficiently, and NB classifiers train much faster than SVMs owing to their extreme sim-plicity. In contrast, SVMs handle multi-class problems by learning redundant yes/no (one-vs-others) classifiers for each class, further worsening the performance gap. We propose a new technique for multi-way classification which exploits the accuracy of SVMs and the speed of NB classifiers. We first use a NB classifier to quickly compute a confusion ma-trix, which is used to reduce the number and complexity of the two-class SVMs that are built in the second stage. Dur-ing testing, we first get the prediction of a NB classifier and use that to selectively apply only a subset of the two-class SVMs. On standard benchmarks, our algorithm is 3 to 6 times faster than SVMs and yet matches or even exceeds their accuracy. 
Support Vector Machines (SVMs) [14] are a kind of dis-criminative classifier which have shown superb performance for classifying text and other data. They are accurate, ro-bust, and quick to apply to test instances. Inducing a lin-ear SVM over training data {(:~,yi),i = 1,...,n},xi E R m, yi E {-1, 1} involves estimating a vector ~ and a scalar b to maximize the distance of any training point from the hyperplane defined by ~. ~ + b; this can be written as: The distance of any training point from the optimized hy-perplane (called the margin) will be at least 1/llwll. that there can be only two class labels. This holds for non-linear SVMs as well. The elegant theory behind the use of large-margin hyper-bear this notice and the full citation on the first permission and/or a fee. SIGKDD '02 Edmonton, Alberta, Canada Copyright 2002 ACM 1-58113-567-X/02/0007 ...$5.00. planes to separate two classes cannot be extended easily to separate N mutually exclusive classes. A number of meth-ods have been proposed for reducing a multi-class problem to a collection of two-class problems and combining their predictions in various ways [1, 12, 7]. The most popular amongst these is the "one-vs-others" approach where, for each of the N classes, we construct a one-vs-others SVM which makes a yes/no judgment for that class alone. Given a test instance, some of these N SVMs will say yes, and the rest will say no. The winning SVM is the one which says yes, and whose decision hyperplane is farthest from the test instance amongst all competing SVMs. 
The one-vs-others technique requires each of the N clas-sifters to be built on the entire training data, causing each document to be processed N times. Each test instance has to be evaluated w.r.t, each SVM as well. Apart from the ef-ficiency issue, it is unclear that a comparison of the discrim-inant functions of different classification problems is mean-ingful in any way, although this technique seems to work reasonably well in practice. 
Another technique is to construct SVMs between all pos-sible pairs of classes [10]. During testing, each of the N(N-1) classifiers votes for one class. The winning class is the one with the largest number of accumulated votes. In this tech-nique, even though the number of training instances per classifier is limited, the number of classifiers is quadratic in the number of classes and each document gets processed (N-1) times. A number of other proposed methods [5, 3, 1] fall somewhere in between these two methods. We will discuss these in Section 4. The one-vs-others method is the most widely used in practice and found to offer high accu-racy [7]. We will use this approach when using multi-class SVMs in our experiments. 
Regardless of specific details, these ad-hoc techniques be-come impractical with a large number of classes, especially because SVMs, while accurate and quick to apply, are not the fastest learners to train: on an n-instance problem the time taken by recent, clever implementations ranges from n 1'7 to n 2"1 [8, 4]. Together, these factors make it quite difficult to scale up SVM-based systems to large Web direc-tories like the Open Directory Project (http://dmoz. org/) and Yahoo! (http://~nn~.yahoo.com/), which have tens of thousands of classes and millions of documents. 
Generative classifiers, in contrast, are essentially indepen-dent of the number of classes as far as training time is con-cerned. A popular generative classifier for text data is the naive Bayes (NB) classifier. NB classifiers trivially scale with the number of classes as they process each document only once independent of the number of classes. Also, NB classifiers train much faster than SVMs owing to their ex-treme simplicity. On the other hand, in terms of accuracy, the linear SVM has decisively outperformed the NB clas-sifter owing to the latter's high bias in assuming attribute independence. the best of both worlds: scalability of NB classifiers w.r.t. number of classes and accuracy of SVMs. In the first stage we use the fast multi-class NB classifier to compute a con-fusion matrix, which is used to reduce the number and com-plexity of two-class SVMs that are built in the second stage using the one-vs-others approach. During testing, we first get the prediction of a NB classifier and use that to selec-tively apply only a subset of the two-class SVMs, as indi-cated by the confusion matrix. On standard benchmarks, our algorithm is 3 to 6 times faster than multi-class SVMs, and has superior scalability in terms of memory require-ments and training set size. In terms of accuracy, the method is 3% better than NB classifiers and comparable or superior to SVMs. requires negligible coding. It can be of substantial utility while dealing with very large classifiers like those that would be required for Web directories. derived from a confusion matrix, easily generated from a fast classifier like NB. This can be obtained using a held-out validation dataset. ~.~.p~.~-,~ o io 0 "C 2I 0 ............ ~ S;2e i~q2i3 "i~ 'o~ o fusion matrix built on the 20-newsgroup dataset (details in 
Section 3.1). The rows show actual classes and the columns show predicted classes. ferent degrees of confusion with other classes. Some classes, like rec.sport.hockey, are well separated from the rest, whereas others like comp. oe. ms-vindovs, m~sc are easily con-fused with others. The mis-classifications of a class are usu-ally limited to a small subset of classes. In fact, in most cases, the rows and columns of a matrix can be rearranged manually as shown in Figure 2 so as to'reveal clusters of classes that confuse with each other. These appear as blocks along the diagonal of the confusion matrix. Not surpris-ingly, in many cases, these clusters are formed of classes whose names can be immediately recognized as forming nat-ural hierarchies. The confusion matrix provides a domain-independent method of deriving this relationship. 
For automating this re-organization of classes into clusters of similar classes, we use the technique used in [6] to auto-matically generate topic hierarchies from a given fiat set of classes. Each class is represented by a row in the confusion matrix. For each class, it's respective row is converted to a normalized N dimensional vector that denotes how much the class confuses with other classes. We then use a distance measure like the Euclidean L, or the KL-distance measure to compute distance between the classes. These distances are used to cluster the classes using a hierarchical agglomer-ative clustering (HAC) algorithm. The output of HAC is a dendrogram that we analyze to determine the clusters that provide the maximum inter-class separation. The dendro-gram is scanned bottom-up to find the distances at which successive clusters get merged. We clip the dendrogram at the point where the cluster merge distances begin increasing sharply. The number of clusters left after clipping form the clusters of our two-level hierarchy. For the 20-newsgroups dataset, this method gives clusters very similar to those in Figure 2. i~,,,~h~:.: ~' O'O"OiO O" fi"O'O"O i~ 0i"2 '0 t~.~s~ ..... ~ o ~ o o i ~ i o o co~.~nd~., ........... ..!...i.! ............ 2 ~ oi2 2 2 ~.~ i~lO~ o ~ o 2 ~!!!~ff?~i~if~ ~ifio~ ~e~ .......... ii iio ..... 0 o 'o ~ : ~ 0 To" ~ ~ i 
Figure 2: 20-newsgroups re-organized confusion ma-trix. 2.1 Hierarchical Approach 
We propose to exploit the clustering of classes to prune the number and complexity of two-class classifiers needed for multi-class SVMs. An obvious approach is to arrange the clusters in a two-level tree hierarchy and train a classi-fier at each internal node. If we restrict to NB classifiers, 
Mitchell [11] has shown that if the same feature space were used for all the classifiers and no smoothing is done, the ac-tice, each classifier has to deal with a more easily separable problem, and can use a independently optimized feature set; this should lead to slight improvements in accuracy, apart from the gain in training and testing speed. We propose to use a combination of NB and SVM classifiers at the two levels. 
We first build a top-level classifier to discriminate amongst the top-level clusters of labels, called the Level 1 (L1) clas-sifter. This top-level classifier could be either a NB or SVM classifier. Even with SVM, the training time will be smaller since the number of classes is reduced, although each two-514 and as we expected in Section 2.1. Even though NB-L2 has an accuracy of 89.01%, combining with the NB-L1 accuracy of 93.56% leaves us with a resultant accuracy of Hier-NB of 83.28%. Although NB-L1 and NB-L2 are both individually better than MCNB (85.27%), we see that compounding of classification errors leaves Hier-NB worse off than MCNB. Similarly, SVM-L2 with a NB classifier at L1 (Hier-SVM) has an accuracy of 92.04%. The accuracy of Hier-SVM still drops down to 86.12% which is slightly better than MCNB, but is worse than the MCSVM accuracy of 89.66%. If we replace NB-L1 with SVM-L1 having 95.39% accuracy, the overall accuracy for both Hier-NB and Hier-SVM improves slightly, but the training time gets worse. 
There is no conclusive comparison in [2, 9] which deci-sively states whether a hierarchical classification scheme is better than a flat one for NB classifiers. These previous studies have either restricted the number of features at each node in the hierarchy or have tried to equalize the num-ber across the flat and hierarchical schemes. It is not clear whether by attempting to equalize the number of features, one of the classification schemes is getting compromised. 
The main reason for the low accuracy of the hierarchical approaches is the compounding of errors at the two levels. Even though the accuracy at both levels is higher than that of a flat classifier, the product of their accuracies falls short of the accuracy of a flat classifier. Increasing the levels be-yond two is expected to worsen this compounding effect. 
This led us to design a new algorithm GraphSVM, that at-tempts to ensure that the first-stage classification will make the overall process fast, but inaccuracy of the first-stage clas-sifter will not jeopardize overall accuracy. 
In this algorithm, we represent class confusion in a more general way using a graph, which may connect a class with any other class, instead of restricting confusion to a hierar-chy of disjoint groups as in the previous approach. 
As in the previous approach, we start with the confusion matrix obtained by a fast multi-class NB classifier Mi. For each class i, we find the set of classes F(i) such that more than a threshold (t) percentage of documents from each class in 
F(i) gets mis-classified as class i. For example, for the confusion matrix in Figure 1, we find that for the class alt. atheism and with a threshold of 3%, F(alz.atheism) = {talk. religion, misc, soc. religion, christian}. 
Next, for each node i with non-empty F(i), we train a multi-class classifier M2 (i) to distinguish amongst the classes in {i}UF(i). These classifiers are constructed using a more accurate and possibly slower method like SVMs. During testing, we first classify a document d using Mi. If the predicted class for d is i, we feed it to and get a refined prediction j. 
In the above example, when a test instance is predicted as alc. atheism by Mi, we get the prediction refined by a one-vs-others SVM, M2(i), between the classes air,atheism, talk.religion.mist and see.religion.christian. The prediction of M2(i) is returned as the final answer for the test instance. 
GraphSVM partitions a classification task between NB and SVMs such that SVMs are only invoked on small subsets of classes that get mis-classified by the NB classifiers. 
Figure 7: Training time vs. Number of classes for 20NG Figure 8: Training time vs. Number of classes for Reuters Figures 9 and 10 show that in all cases GraphSVM con-tinues to maintain the high accuracy vis-a-vis MCSVM and 
MCNB. For the 20NG dataset (Figure 9), GraphSVM main-tains an accuracy of within 1% of MCSVM and for the 
Reuters dataset (Figure 10) GraphSVM is on an average, 3% better than MCSVM. We notice a large dip in Figure 10 for 
MCNB and MCSVM. The Reuters dataset is highly skewed in the distribution of instances per class. Figure 10 addition-ally shows the total number of test instances over which the micro-averaged accuracy values are reported. For 25 classes there are only 166 test instances. The 7% difference be~ tween GraphSVM and MCNB and MCSVM is due to only 11 additional instances correctly classified by GraphSVM. 
Since these 25 classes are thinly populated, most of the mis~ classifications seen in the confusion matrix are larger than the threshold and contribute to edges in the GraphSVM algorithm. These mis-classifications are corrected by the more focused SVMs in the GraphSVM method. The graph smoothens out after 30 classes when there are a larger num-ber of instances and the accuracy of GraphSVM is consis-tently better. 
Figure 9: Accuracy vs. Number of classes for 20NG Training time: In Figure 11, the size of the training set was varied from 10% to 70% of the whole data, while keeping the relative train-test ratio constant at 70:30. We observe Figure 10: Accuracy vs. Number of classes for 
Reuters that the training time of GraphSVM is nearly linear in the training set sizes, while for multi-class SVMs the training time increased super-linearly with training set size. This causes the gap between the two methods to become more prominent for larger datasets. Accuracy: In Figure 11 we show the corresponding ac-curacy values against varying percentages of training set sizes for 20NG. We observe that as the accuracy of MCSVM increases with increasing number of training instances and 
GraphSVM closely tracks the increase and is always more accurate than MCNB. Maximum memory: In Figure 11 the percentage of training documents is plotted against the maximum mem-ory required to train any SVM model in the GraphSVM and MCSVM approaches. In both cases, multiple one-vs-others 
SVMs are learned, but the size and heterogeneity of the neg-ative ('others') class varies largely leading to different mem-ory requirements. In MCSVM, this negative class contains the entire dataset apart from the positive class, whereas .it is greatly pruned in the GraphSVM approach. We notice that GraphSVM requires less than one-fourth the memory required by MCSVM. 
Figure 11: Training time, accuracy and maximum model memory with varying training set sizes for the 20NG dataset An important parameter of GraphSVM is the threshold used to decide what SVMs to create in the second stage. In Table 2 we show the accuracy and training time for different values of the threshold (t). We see that a threshold of 3% to 7% is appropriate for both these datasets because of the base accuracy of the NB classifier chosen to get the confusion matrix. 
