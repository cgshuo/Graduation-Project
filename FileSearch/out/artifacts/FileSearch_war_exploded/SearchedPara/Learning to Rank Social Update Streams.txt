 As online social media further integrates deeper into our lives, we spend more time consuming social update streams that come from our online connections. Although social update streams provide a tremendous opportunity for us to access information on-the-fly, we often complain about its relevance. Some of us are flooded with a steady stream of information and simply cannot process it in full. Ranking the incoming content becomes the only solution for the overwhelmed users. For some others, in contrast, the incoming in-formation stream is pretty weak, and they have to actively search for relevant information which is quite tedious. For these users, augmenting their incoming content flow with relevant information from outside their first-degree network would be a viable solution. In that case, the problem of relevance becomes even more promi-nent.

In this paper, we start an open discussion on how to build effec-tive systems for ranking social updates from a unique perspective of LinkedIn  X  the largest professional network in the world. More specifically, we address this problem as an intersection of learning to rank, collaborative filtering, and clickthrough modeling, while leveraging ideas from information retrieval and recommender sys-tems. We propose a novel probabilistic latent factor model with regressions on explicit features and compare it with a number of non-trivial baselines. In addition to demonstrating superior perfor-mance of our model, we shed some light on the nature of social up-dates on LinkedIn and how users interact with them, which might be applicable to social update streams in general.
 H.4 [ Information Systems Applications ]: Miscellaneous; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Theory  X 
P art of this work was done when the first author was on an intern-ship at LinkedIn Corp.
 Social network, Social Stream, Learning to rank, Collaborative fil-tering
In the current Web ecosystem, social media services are ubiq-uitous. With the rise of websites like Facebook, Twitter, and LinkedIn, millions of users are connecting and communicating with each other over rich multimedia content, including text, images, video, and audio. The content forms streams of social updates, which allow users to get instantly informed on the latest news. When aggregated, the social update streams become a powerful tool for monitoring the geopolitical situation in various regions. For instance, social update streams have been heavily used to dis-seminate information during the  X  X rab spring X . In addition, social update services become the ultimate platform for collecting infor-mation in natural disasters, such as earthquakes and tsunamis [20].
Although social update streams provide a unique opportunity for users to obtain fresh information, users commonly acknowledge two issues that prevent current social streams from being suffi-ciently relevant, which causes deterioration of user experience and engagement. First of all, while facing a large number of updates from their social connections, users simply cannot consume them in an effective and efficient way. This is known as the problem of information overload (see, e.g., [3, 12]). Furthermore, social up-dates for a user are usually limited in scope to their social circle, induced from their connections. Thus, it is very difficult for a user to obtain information distributed outside of their circle, even though it might match their interests. In order to obtain relevant informa-tion, users spend long hours searching social media (see, e.g., [2, 21]). We call this problem information shortage . To address both these problems, social media monitoring systems are being built, which filter and recommend social updates to users based on nu-merous signals. This area has recently attracted close attention of academic and industrial research communities.

The task of filtering and recommending social updates can be approached from various perspectives. From the Information Re-trieval (IR) perspective, constructing personalized social streams can be cast into the classic ranking problem: the task is to rank social updates by descending order of user interest. It may be true that some existing IR techniques could be potentially applied to social stream ranking. However, user X  X  interests in social streams are not represented in terms of a search query. Instead, queries are implicit and have to be inferred. The absence of a search query distinguishes the social stream ranking problem from many classic IR tasks. In addition, social information needs are more diversified compared to traditional IR scenarios. Although traditional IR tools do not appear to be directly applicable to ranking in social streams, some of recently developed l earning to rank approaches are very appealing to be used in the new setting.

From the perspective of Recommender Systems (RecSys), build-ing a list of relevant social updates can be viewed as recommend-ing relevant items to users. Thus, many collaborative filtering tech-niques are applicable to the task of social stream ranking. However, social stream systems are much more dynamic than traditional rec-ommender systems: many new updates can be pushed into the sys-tem every second. Therefore, the cold start problem becomes even more severe in social stream systems. The traditional collaborative filtering paradigm needs to be adjusted to ranking social streams.
Surprisingly, little prior research work has been done to tackle the problem of social stream ranking from the point of view of building an effective system. This is partially due to the fact that no real-world dataset of social updates is openly available to the re-search community  X  due to obvious reasons related to user privacy. Most commercial ranking algorithms (e.g., the one used by Face-book) are proprietary. Indeed, a successful content ranking system on social streams will not only provide more relevant information to users and improve user engagement, but also shed the light on patterns of user behavior and social trends, which might be strong signals for behavioral targeting in computational advertising  X  the driving power of most Web 2.0 venues.

In this paper, we start an open discussion on how to build ef-fective systems for social stream ranking (SSR). To the best of our knowledge, we are the first group of researchers to elaborate tech-nical details for such a system. More specifically, we address the problem as an intersection of learning to rank, collaborative filter-ing and clickthrough modeling, while leveraging ideas from infor-mation retrieval and recommender systems. Our contributions are three-fold: 1. Analyze social streams (based on LinkedIn data) and provide 2. Propose a novel probabilistic latent factor model with regres-3. Demonstrate the superior performance of our model by com-
The rest of the paper is organized as follows. In Section 2, we compare SSR with other related research areas. As we will point out, SSR is a unique setup to which existing techniques cannot be applied directly. In Section 3, we review the problem of social stream ranking in the context of LinkedIn. In Section 4, we in-troduce our ranking model step by step and compare it with some existing IR and collaborative filtering techniques. In Section 5, we evaluate our model against a number of non-trivial baselines. We conclude our paper in Section 6.
In this section, we briefly overview three research directions re-lated to social stream ranking: (a) learning to rank, (b) recom-mender systems, and (c) clickthrough models. Some of the ap-proaches to tackle these problems are relevant to SSR and can be adapted. Along with their similarities to SSR, we also reveal their significant differences from SSR, and discuss the uniqueness of SSR as a new research field.

Learning to Rank (LtoR): In IR, a generic task is to construct a ranked list of documents relevant to a query issued by a user. Although ranking is a fundamental problem in IR and has been studied for decades, it still remains challenging. Instead of propos-ing carefully designed ranking models based on heuristics or tra-ditional probabilistic principles, a recent trend is to apply machine learning techniques to learn ranking functions automatically, i.e., LtoR [19]. In the standard LtoR setting, a typical training set con-sists of queries with their associated documents represented by fea-ture vectors as well as corresponding relevance judgements. A ma-chine learning algorithm is employed to learn the ranking model, which can predict the ground truth label in the training set as accu-rately as possible  X  in terms of a loss function. In the test phase, when a new query comes in, the learned model is applied to sort the documents according to their relevance to the query, and re-turn the corresponding ranked list to the user as the response to the query. Depending on different hypotheses, input spaces, out-put spaces and loss functions, approaches to LtoR can be loosely grouped into three categories: point-wise, pairwise, and list-wise.
Although the goal of LtoR is to provide a ranked list of docu-ments (items) for users  X  a similar aim as of SSR  X  it is different from SSR in three aspects. First, social stream systems usually do not have explicit queries and users do not have to specify any ex-plicit input in order to obtain relevant output from the systems. Sec-ond, each user X  X  social stream is highly dependent on their social context. Therefore, compared to IR, social streams are intrinsically personalized. The second difference leads to the third fundamen-tal distinction between SSR and LtoR: relevance judgements are difficult to obtain in SSR and the notion of relevance can be hard to define. Nevertheless, some strategies and insights developed in LtoR can be borrowed for SSR.

Recommender Systems (RecSys): As we will see, RecSys plays a key role in many online services, improving user experi-ence and engagement. In the simplest form, RecSys aim to present a user with a list of items in the hope that these items would match the user X  X  interests to some extent. Content-based methods and neighborhood methods are widely used in RecSys. Content-based methods convert the problem of recommendation into an IR prob-lem by constructing user profiles and item profiles. A user profile serves as a query to an index of item profiles. Similarity measures (e.g., cosine similarity, Jaccard coefficient) are utilized to match users and items. In contrast, neighborhood methods usually ex-plore the notion of topical locality , assuming that the interaction between users and items can be predicted solely upon observations of  X  X eighboring X  users or items. That is, a user X  X  interest in an item is approximated by the average of neighboring observations. Al-though content-based methods and neighborhood methods are pop-ular due to their simplicity, they cannot exploit hidden interactions between users and items. Recently, another class of methods called latent factor models has gained increasing attention. These meth-ods are highly accurate and can easily incorporate various biases. However, compared to content-based methods and neighborhood methods, latent factor models are more vulnerable to the appear-ance of new items and new users, i.e., to the cold-start problem. Therefore, these three approaches are complementary to each other in practice (e.g., [17]). In a general sense, SSR may be considered as RecSys, however, SSR usually does not have item ratings, and user feedback to SSR is often implicit.
 Click-through Model (CM): both IR (see, e.g., [14, 9]) and RecSys [25, 31] researchers have noticed that users X  feedback is vital for learning a high-quality model. In order to derive users X  preferences and model users X  clickthrough data, a variety of CMs have been proposed. The most common approach to clickthrough modeling is to construct a generative model aiming to explain the training data (see, e.g., [33, 13]). Other models that derive users X  preferences have been proposed as well (see, e.g., [25, 5, 31, 18]). While generative models are specifically designed to understand clickthrough data, it is difficult to incorporate them into current IR or RecSys frameworks, partially due to the fact that generative models are hard to adapt to optimizing a non-probabilistic objec-tive. Indeed, it is easier to first obtain user preferences from click-through data analysis and then adapt existing IR/RecSys tools to using these preferences (e.g., [25, 5, 31]). Our paper is inspired from this idea.

In addition to these three directions, some efforts have been made to directly tackle the problem of SSR. For instance, Chen et al. [8] discussed the problem of recommending content on Twitter by con-sidering many dimensions, including content sources, topic inter-ests of users and social voting. However, their study focused on empirical validations of several features (signals) and the dataset used is significantly smaller than ours. Their later work [7] goes beyond single Tweet recommendation to conversation recommen-dation. Duan et al. [11] noticed that the ranking problem of Twitter can be treated as an application of learning to rank. Their dataset is also small and relationships between recipients and senders are not explored. As we have discussed, SSR is not simply a LtoR problem. Choudhury et al. [10] argued that SSR should consider the problem of  X  X iversity X  and they tested their greedy algorithm on 67 employees from a large technology corporation. Our work differs from all this related work in three significant ways: 1) we test our proposed method on a large-scale, real-world dataset; 2) we propose a principled way to address SSR in the context of LtoR, CF and CM; and 3) we conduct comprehensive evaluation of our model against several models that underlie state-of-the-art recommender systems and report a consistent improvement in performance. Founded in December 2002 and launched in May 2003, LinkedIn 1 is primarily used for online professional networking. As of March 2012, LinkedIn has more than 160 million registered users in more than 200 countries and territories. On LinkedIn, user profiles play a central role for establishing professional existence and personal brand. Users can update their professional profiles to include a spectrum of content types (e.g., position descriptions, publications, patents, open source projects, skills, etc.). In addi-tion, LinkedIn offers collaborative platforms to help users consume relevant news stories (e.g., LinkedIn Today 2 ), seek answers to ques-tions on professional issues (e.g., LinkedIn Groups 3 ), and share useful content (e.g., LinkedIn Signal 4 ). On the left-hand side of LinkedIn X  X  homepage, a typical user will see a list of content items that come from their professional connections. This update stream consists of a wide range of types of updates including changes on their profiles (e.g., changes in their employment), shares of infor-mation (e.g., news articles, blog posts), and Twitter updates. These updates compose a social stream for the user. A snapshot of a user X  X  homepage is shown in Figure 1.

As we have discussed in previous sections, delivering truly rel-evant social updates to users is a very difficult task. Information overload is certainly a serious problem for users who have hun-dreds of connections. In contrast, for newly joined users who do not have a sufficient number of connections, a system could rec-ommend potentially useful updates to make the user adapt to the service more smoothly and quickly. h ttp://www.linkedin.com https://www.linkedin.com/today/ https://www.linkedin.com/myGroups https://www.linkedin.com/signal/ Figure 1: A typical example of LinkedIn homepage where the s ocial stream of a user is highlighted by a red rectangle, shown on the left hand side of the screen.

From the LinkedIn point of view, it is important to attract users to consume their social content and interact with their social streams as it is a clear indicator of a healthy engagement pattern. A steady, but badly delivered social stream may distract the user and make them lose interest in the service. A weak social stream for new users may make them question the benefits of the service. On the other hand, if a user interacts with the social stream frequently, clicking  X  X ike X  buttons or making comments to others X  updates, the user is likely to become more and more engaged.
In this section, we will discuss the ingredients of our proposed model step by step, from a simple linear model to a much more involved tensor factorization based latent factor model. We start our discussion from why the problem of SSR cannot simply be treated as a rating prediction problem, which is a classic setting in RecSys.
In traditional RecSys settings where the entities are users and items (e.g., the famous Netflix competition 5 ) forming a matrix of users by items, the main goal is to predict or recover missing values in this matrix  X  if we treat existing ratings as observed values and non-existing ratings as missing values of the matrix. The perfor-mance of recommender systems is evaluated by how accurately a system can predict these values. For instance, in the Netflix Prize, Rooted Mean Squared Error (RMSE) is used to measure the accu-racy of rating predictions. RMSE is defined as q 1 N P n i w here x i is the ground-truth rating for rating i ,  X  x i value and N is the total number of ratings to be tested. Although it h ttp://www.netflixprize.com/ might be an appropriate evaluation metric for movie recommen da-tion tasks where multiple levels of ratings are available, two crucial issues will arise while using it as an evaluation metric to SSR.
First of all, as we see in Figure 1, the final presentation of a so-cial stream is a list of items shown on the computer screen. Due to the limited space on the screen, users can only see a portion of the list which usually only consists of a handful of updates. Al-though users can always scroll down the list and even go to ad-ditional pages, not all of them do that in practice. Thus, even if the accuracy of predictions is important, we certainly wish to have higher-accuracy items on the top of the list rather than to have the whole list slightly more accurate. This ordering information cannot be easily captured in accuracy-based metrics, like RMSE. In addi-tion to the reason that accuracy-based metrics may not be appropri-ate, in the practical sense, a system optimizing accuracy might fail to produce reasonable results. As we will see, the users rarely inter-act with the majority of the updates. In other words, users are only interested in a small number of items. An accuracy-optimized sys-tem may overfit non-interacted items and yield good performance overall but might not match the small portion of clicked updates. Indeed, this drawback of accuracy-based metrics is also discussed in the collaborative filtering literature (e.g., [25, 18, 31]).
Based on this discussion, we adopt rank-based metrics to eval-uate the effectiveness of SSR systems. Rank-based metrics are widely used in the IR community. In this paper, we borrow Mean Average Precision from the traditional IR. We define the  X  X recision X  at position k (Precision@k) of a social stream as (# of clicks in top positions ) /k . Then, an average measure across all top m positions (Average Precision) for user u is defined as ( P m k =1 Precision@k  X  l k ) / ( # of clicks for ranked list of user u ) where l k is a binary indicator whether the position k has been clicked or not and m is the total number of positions evaluated. Note that the Average Precision is evaluated per user. We can av-erage it across all users, resulting in the Mean Average Precision (MAP) measure.
Before discussing the details of our dataset, we introduce the concept of impression . Every time a user logs in LinkedIn X  X  home-page, the system generates a list of candidate social updates from many sources, mainly based on the user X  X  social connections. This list of updates can be small or large, depending on the user X  X  so-cial circle. If the number of updates in the list exceeds a certain threshold (e.g., 10  X  15 ), these updates cannot be shown on a sin-gle screen, and the user will need to scroll down. An impression is a list of updates that a user has actually seen on the screen. Given historical data, we can  X  X eplay X  the users X  activity while analyzing impressions. Note that social updates are not distinct: one specific update produced by a user or a company can be shown to many users.

Since our experimental setting is  X  X imulation X  (details will be discussed in Section 4.1), we discard all impressions without any clicks because these impressions do not change our experimental results (as measured by MAP). Note that there is a deeper argument on this decision. Remember that one issue associated with social streams is their sparsity. Indeed, only a small number of impres-sions attract users and a handful of clicks is performed on such im-pressions, compared to the large amount of impressions produced in total. Thus, it might be useless for any model to fit these non-interacted impressions. Focusing on impressions that actually mat-ter reduces the training set significantly and produces better results, which we saw in our empirical studies. Thus, only impressions with Table 1: The basic statistics about the dataset. X  X  X  means mil -lion. The numbers are obfuscated due to commercial reason. at least one click remain in our dataset. In our experiments, we also filter out impressions with less than five items.
 We report on two datasets of LinkedIn X  X  social update stream. Both are subsamples of the actual social stream collected by LinkedIn X  X  engineering team. The first dataset was taken from April, 2011 stream, while the second was taken from September, 2011 stream. The basic statistics on the two datasets are shown in Table 1. The reason why we take two datasets that are not conse-quent in time is to demonstrate that the performance of different algorithms is indeed consistent over different time periods.
In this section, we will discuss several simple linear models to tackle the problem of SSR. Given a social update, a user can choose to respond to this update or not. For simplicity, we treat all kinds of responses as a  X  X lick X  event and no response as a  X  X on-click X  event. Thus, we focus on binary responses in this work. We denote y as a vector of responses to all social updates, across all impressions. This way, we concatenate updates from all impressions together and drop the notion of an impression. The ordering of elements in y does not matter as we only care about the correspondence: the response y i corresponds to the i -th update in the entire dataset and f i represents the estimation of y i from the models described later. In addition, we define the following auxiliary functions: r ( i ) type of update i , and c ( i ) is the sender type. Let R be the set of recipients, S be the set of senders, T be the set of types, I be the set of social updates.

Feature Model (FM) : One straightforward model is linear es-timation, which predicts the response by a linear combination of features. For a specific update i , we collect their corresponding features. Let  X  be a feature vector  X  we use subscript to indicate its corresponding type. For instance,  X  r ( i ) represents the feature vector (e.g., profile) for the recipient user of update i . A simple prediction of y i  X  a linear combination of user features and update features  X  can be defined as: where  X  u and  X  u are per-user coefficients to be learned from the training set. This model is essentially equivalent to the one where user features and update features are combined into a single feature vector and a per-user coefficient to be learned. Note, an even more simpler model could be also considered where a universal coeffi-cient is used, instead of per-user coefficients. However, this model would be too restricted and personalization cannot be applied.
Latent Bias Model (LBM) : Here, we introduce a linear model to explain the clicks on items. We start with an assumption that whether a new item i will be clicked by a user depends on the av-erage click rate: f i =  X  where  X  is the average click rate across all items and all users. Certainly, this estimation is too coarse and inaccurate because, as we mentioned before, the majority of i tems are not clicked. We can extend this base estimation by incorporat-ing a wide range of biases: 1) type (category) bias, 2) item bias, 3) recipient bias, 4) sender type bias and 5) sender bias. Adding these biases is very intuitive. Certain types of updates (e.g., notifications about changes in user profiles, including changes in job titles etc.) receive more attentions than others. Users tend to respond (e.g., click  X  X ike X  button or make comments) more often on these types of updates than on others. In addition, some individual items are more popular than others as their content might be more interest-ing (e.g., breaking news, unexpected stories). From the perspective of senders and recipients, biases are also significant. For instance, some updates are coming from companies that inform their follow-ers about their new products and services  X  those updates are far more popular than status updates from individual users. Moreover, certain users are more engaged than others which introduces user biases. Therefore, all these biases (i.e., prior knowledge) can cap-ture a wide range of effects of interactions. Let b denote biases and the subscript to indicate the type of biases. Also, the subscript can be an index for a feature. Therefore, we can have the following linear estimation: Note that these biases are generally unknown. We treat them as latent variables to be learned from the dataset. Comparing with LR, which depends on feature vectors some of which might be dif-ficult to calculate and update (e.g., graph-based features, content based features), this model is appealing since no extra information is needed for learning, besides requiring indicators.

Combining FM and LBM : It is straightforward to consider combining FM and LBM together. Thus, the combined model will enjoy the freedom that different parts of the model will explain a variety of user behaviors. The combined model is simply: Note, this is essentially a linear feature model with biases decom-posed into many aspects.

Incorporating Temporal Effects : Social streams are tempo-rally sensitive in nature. Users focus on fresh information and interact with them while they often do not bother to look at old updates. We model the temporal effects of updates by a simple fea-ture: t recency = t imp  X  t upt where t imp is the numerical time when a user sees a particular impression and t upt is the numerical time when an update is produced. These feature values would be differ-ent for different updates. Even for the same update, depending on when recipients access their update streams, the feature value can vary greatly. Incorporating this feature into our estimation can be as follows: where f (  X  ) i can be any estimator defined in Equations (1, 2 and 3) and  X  is a free parameter, indicating the importance of recency of updates. Note that  X  can be learned from the training set and can also be treated as another personalized parameter. However, we fix it across all users and manually tune this parameter mainly be-cause of two reasons. Firstly, since not all users interact with social streams regularly and new users are coming all the time, we need to provide reasonably relevant social updates for these users. Under these circumstances, explicit features might not be available (e.g., new users) and biases are not learned reliably from the training set (e.g., not enough interactions before). Therefore, a safe choice is to rank items chronologically. In addition to that, users who are heavily engaged with their social streams are familiar with existing ranking schemes which are primarily based on recency. We do not want to suddenly change their expectations on their future impres-sions. Hence, we set  X  such that the temporal effect can always be an important factor and indeed the learned coefficients and biases will dominate the estimation only when it is necessary.

Since responses are binary, we impose a logistic loss on predic-tions and true values, yielding learning procedures of the logistic regression flavor. All these linear models can be learned effectively by minimizing the following objective function for each update i : where y i  X  { X  1 } is the ground-truth response and f  X  i mated response from the models defined above. In common prac-tice, in order to avoid overfitting the training set, we also use L regularizer to shrink all parameters towards zero. Taking Equation (4) as an example, the final objective function is: where  X  1 and  X  2 are two regularization parameters to be manu-ally tuned. Many methods are available to optimize the objective function above. Here, we adopt the Stochastic Gradient Descent (SGD) method, a widely used learning method for large-scale data, to learn parameters. SGD requires gradients, which can be effec-tively calculated as follows: where b  X  represents any bias terms,  X  r ( i ) ,k and  X  i,k element of coefficient for user r ( i ) and update i respectively. Note
Although linear models are efficient, they are usually oversim-plified and cannot capture interactions between different effects. Latent Factor Models (LFM) are widely used in recommender sys-tems (e.g., [17, 29, 31, 30]) and have proven effective in many scenarios (e.g., [17]). Specifically, LFM can model the interactions between different types of entities such as user-user and user-item, discovering their latent relationships. In this section, we discuss two types of LFM: matrix factorization and tensor factorization, and see how they can be applied to the task of SSR.

Matrix Factorization : In traditional CF, matrix factorization techniques are used to exploit user-item interactions. A straightfor-ward idea would be to directly apply matrix factorization methods to user-update matrix. However, this idea is not practical. As dis-cussed above, social streams have new updates arriving all the time, and existing updates are only consumed by a small number of users. Thus, cold-start problems are much more severe here, compared to traditional CF where the user base and the item base are relatively stable. Here, we impose a latent factor  X  u  X  R k for each recipient and producer and factorize the recipient-producer matrix to predict Figure 2: CANDECOMP/PARAFAC decomposition of a ten-s or, a three-way array. The dimensionality of three latent fac-tors is the same. the actions on updates. We describe the model in a probabilistic way: where b  X  is any biases introduced in Section (4.3), R and S are the set of recipients and producers respectively. For P (  X  u is usually assumed to be Gaussian or Laplace, corresponding to L or L 1 regularization on latent factors respectively. Here, we use a multivariate Gaussian assumption. For P ( y i |  X  r ( i ) we assume: y i  X  P ( y i | f i ) where  X  allows a Gaussian distribution. Thus, the final generative process also follows a Gaussian distribution. This formalism is similar to the one introduced in [17]. The model described here is very intuitive. Whether a user u 1 is going to click on an update from a user/company u 2 depends on u 1  X  X  and u 2  X  X  affinity.
Tensor Factorization : As social streams have different enti-ties like recipients, producers and categories, it would be natural to directly model the multi-way data interaction, rather than con-centrating on two-way relationships. It has been shown that high-order relational modeling can improve the performance of CF sys-tems in many scenarios, for instance in social tag recommendations [24, 26].Here, we focus on one particular three-way relationship: recipient-producer-category of the update. We associate latent fac-tors  X  x  X  R k for these three types of entities. Similar to the matrix case, we define the following generative procedures: where f i is defined as: f where  X   X  ,k represents the k -th element in the vector and  X  again follows a Gaussian distribution. This particular form of tensor de-composition is known as CANDECOMP/PARAFAC (CP) decom-position [16], depicted in Figure 2. There are two important prop-erties about CP decomposition. Firstly, it is a direct analogue to factorization methods in two-way array (matrix) data where latent factors share the same latent space. Secondly, CP decomposition has a nice yet surprising property that it has a unique solution of decomposition where matrix factorization does not enjoy this re-sult [16]. This property indeed provides a theoretical guarantee to the decomposition and may be a reason for better performance.
We are aware of other forms of tensor factorization as well. For instance, Tucker decomposition [16], where the dimensionality of different latent factors varies, is widely used in many applications Figure 3: A graphical representation of regression-based te n-sor factor model. Square nodes represent features and circled nodes represents unknown variables. The response y in the middle is observed in the training set but to be predicted in the test set. and applied to social media as well (e.g., [24, 29]). However, we do not choose the Tucker decomposition for our settings because not only it requires to pre-specify the dimensionality of all factors sepa-rately, but also does not guarantee uniqueness of the decomposition result.

Incorporating Features : Both matrix factorization and tensor factorization discussed above do not directly incorporate explicit features. Here, we introduce features into the model by employ-ing two levels of regression models. The basic idea is that latent features will depend on explicit features and final responses are de-rived from latent features. The first level regression models are defined as: where  X  x (  X  ) represents a feature vector for entity x and M transformation matrix to be learned. If  X   X  follows a zero-mean k -dimensional Gaussian distribution, latent factors  X   X  indeed follow multivariate Gaussian distribution with the mean of a transforma-tion of explicit feature vectors. This way, explicit feature space is mapped to latent feature space.

In addition to binding latent factors to explicit features, other biases may also have the same prior distributions: where  X  x is a regression coefficient for entity x . If the error term  X  x follows a Gaussian distribution, biases b x (  X  ) will also follow a Gaussian distribution centered at a transformation from explicit features. Note that this two-level regression scheme can be applied to matrix factorization as well as tensor factorization. The idea to use regression priors for matrix factorization has been explored by [1, 30] but not yet discussed on multi-way data relations like tensors. The final graphical representation of the model is shown in Figure 3.

In addition to the method described here to incorporate features, we are aware of other possibilities, such as [23] where latent factors and explicit features are treated as same set of features.
Like linear models from Section 4.3, LFM (with features) can also be learned through a Maximum A Posterior (MAP) estima-tion. Taking Tensor Factorization with Features as an example, the problem of minimizing the negative log posterior of the model boils down to the following objective:
L + X + X where all constant terms are ignored and all  X  terms are manually tuned regularization parameters. For both matrix factorization and CP decomposition, a number of techniques are available to solve the objective function. For instance, the alternating least squares (ALS) method is the  X  X orkhorse X  [16] for both matrix and tensor factorization. However, here, we still adopt a SGD method, which can scale to the dataset with which we are working. In order to use SGD, the gradients of latent factors can be derived. Firstly, we focus on latent factors: where  X   X  ,k is the k -th element of the vector and M  X  [ k ] row of the matrix. For all biases, gradients  X  X  2  X  X  where  X  means a particular type of bias and i  X  b  X  ( i ) updates those bias type match the type of interests. The gradients 2  X  x X where M x [ k,m ] is the ( k, m ) -th element in the matrix M finally, the gradients for regression coefficients  X  X  2  X  puted as:
So far, we have demonstrated two different types of models: lin-ear models and latent factor models. Both of them minimize cer-tain errors in the learning process. As discussed in Section 4.1, a ranking-based evaluation metric, MAP is used in our experiments. Thus, it is more reasonable to directly optimize this ranking met-ric. However, it is difficult to optimize ranking measures directly [32, 6, 22] due to their discrete nature. Although some techniques (e.g., [6, 22]) have been developed to derive smoothed surrogate functions to approximate these ranking measures, including MAP, they are usually complicated and expensive to apply to large scale scenarios. Here, we use a much simpler approach: derive pairwise preferences from users X  impressions and learn a pairwise ranking function.

First, let O i be the set of updates in the impression i , O set of updates clicked by the user and O i,  X  be the set of updates not clicked by the user. Remember that we eliminate impressions with-out any clicks (see 4.2). Therefore, we guarantee that the method described here can be applied to all impressions in our dataset. For any pair of updates ( m, n ) where m  X  O i, + and n  X  O i,  X  always construct a preference label l m,n = 1 , meaning that update m is favored over update n in impression i . Under this setting, we have the new objective function for impression i : where  X  is a logit function. This new objective function is no longer to fit a single observed label (click or not) but to optimize a pair-wise preference induced from impressions. Similar ideas are also explored in [25, 31, 18]. With this new objective function, we can replace the original loss function defined in Equation (5) in both lin-ear model learning and factor model learning. Gradients are omit-ted due to space limits.
We discussed several issues related to our proposed methods in this sub-section: 1) parameter tuning, 2) scalability and 3) feature treatment. For parameter tuning, while it is not a significant prob-lem for Linear Models, as they can be trained efficiently, it might be prohibitively expensive to tune a Latent Factor Model. In this work, we do not heavily tune parameters and only wish to see whether these proposed approaches work in principle. One way to deploy a  X  X arameter-free X  model might be to consider a Bayesian treatment of Latent Factor Models, like [27, 29]. However, the sheer amount of data and its continuous nature prevent us to explore Bayesian treatment in this work and leave it to the future work. In terms of scalability, we conduct experiments on a single machine in this work but we do notice that SGD can be paralleled [34]. Thus, we can scale our model to even larger datasets. The way we integrate explicit features and latent factors is through regression models. However, this is not the only way to deal with this kind of prob-lem. For instance, matrix co-factorization (see, e.g., [28]) and ten-sor co-factorization can be another paradigm of combining explicit features and hidden features.
In this section, we demonstrate the effectiveness of our model, through a comprehensive comparison with non-trivial baselines. The dataset used in our experiments is described in Section 4.2. Before we go into the details of the experimental results, we first discuss our experimental setting in Section 5.1 and then all devel-oped models in Section 5.2.
Two standard settings are available to evaluate the effectiveness of systems for SSR. One is to test each model against an existing system in a online setting where both systems run in parallel for a similar audience in a reasonable period of time. After this, the effectiveness of both systems can be calculated using certain mea-surements, like error rate or ranking metrics. This is a classic A/B testing scenario. The advantage of A/B testing is obvious: it pro-vides a real comparison between models. However, it might be t ime-consuming and even impossible to compare many models in a batch. In addition, some models require tuning parameters, which may risk the business of the service a company offers. Thus, we do not use A/B testing in this paper and leave it to the future work.
In this paper, we simulate real settings of SSR, conducting off-line experiments. More specifically, we gather historical data from LinkedIn user logs, which capturing all impressions users have con-sumed. Since we know which updates are clicked in each impres-sion, it is easy to replay all these impressions and reorder the up-dates. Thus, we can produce a  X  X ew X  impression for users in the dataset. The drawback of this approach to experiments is that we cannot show  X  X ew X  ordering of impressions that are not clicked by users at all because whether users would have clicked them or not is impossible to test. This is another reason why we drop all im-pressions without any clicks (Section 4.2).

The dataset for one month is divided into weeks. We train our models on one week and test them on the following week. This setting results in more than 70% items being new in test data each week, which is an evidence to the fact that SSR is different from RecSys and IR.
We compare several models in our experiments. All models used in the following experiments are shown in Table 2. The baseline is a proprietary system currently deployed in the product of LinkedIn homepage. FM , LBM and their combination ( FBM ) are examples of simple linear models while MF , TF with their feature enhanced ex-tensions ( MF2 and TF2 ) are examples of latent factor models. For all models, a point-wise loss function (Equation (5)) and a pair-wise loss function (6) are both tested. Without stating it explicitly, all models include the temporal effect feature discussed in Section (4.3) while the parameter  X  , the balance between recency and rele-vance, is manually tuned. All regularization parameters are simply set to 1 . We understand that this may not be an optimal choice. For tuning a reasonable learning rate in SGD and  X  , we use the first day in the test week as a  X  X alidation X  day and choose the parameter setting that can provide the optimal performance on the day. We fix the parameters for the remaining days in the test week.

Some of linear models and latent factor models require explicit features. In this paper, we include several important features to en-hance our models. Note that we are aware of many other possible Table 4: The comparison between linear models. The best per-f ormance is shown in bold.
 f eatures. However, it is not our goal to study the effectiveness of a particular feature in this work. All features are shown in Table 3.  X  X eniority X  measures the seniority level of a user X  X  job title.  X  X is-iting X  measures how well engaged a user is (our assumption is that a frequent visitor is likely to interact with his/her social stream).  X  X ageRank X  (details in [4]) and  X  X onnectedness X  measure how a user connects with other users. Presumably, a highly respected and well connected user can attract others to interact with their up-date streams.  X  X ocial strength X  is a proprietary product used in LinkedIn, measuring the connection closeness between two users.  X  X rofessional X  measures how likely an update is similar in its lan-guage to professional profiles of LinkedIn users (i.e. how profes-sional an update is). The assumption is that users may favor profes-sional updates over non-professional updates on LinkedIn because it is a professional social network.
In this sub-section, we focus on the comparison between the baseline and all linear models. In this Subsection, we focus on the comparison between the baseline and all linear models. The results are shown in Table 4. The first column indicates how models are trained and tested. For instance, the first number  X 4_01 X  means the models are trained on the week of April 1st and tested on the week of April 8th (8-th is the date for validation of parameter tuning) where  X  X r. X  and  X  X e. X  are shorthand for  X  X raining X  and  X  X esting X , respectively. We conduct experiments on two separate months to avoid some seasonal fluctuations on the data. The numbers shown on the right part of the table are MAP scores.

Our first observation is that the baseline of MAP in September is lower than its in April, implying that updates in the lower positions in the lists get clicked more often over time. One possible explana-tion is that users become familiar with their social streams and start to find interesting updates manually, looking at more items down the list. The second observation is that all linear models, including FM , LBM and FBM , perform better than the baseline, consistently on two-month datasets. However, for FM , which only depends on ex-plicit features, the performance is very close to the baseline. This is reasonable because only a handful of features are used in our experiments and we do expect that these features are not likely dis-criminative. On the other hand, LBM , a model only depending on implicit feedback, has consistently 5%  X  6% absolute improve-ments on MAP over the baseline. This confirms that it is vital Table 6: The comparison between latent factor models. The b est performance is shown in bold. to exploit different aspects of users X  feedbacks and capture them through bias modeling (e.g., [17, 15]). Indeed, FBM gives the most improvements over the baseline in all our experiments. The idea is simple and easy to implement. For the combination of a pure feature-based model FM and a pure implicit-feedback-based model LBM , FBM does perform as someone might expect. It is signifi-cantly worse than LBM and almost identical to FM , which might in-dicate that simply integrating explicit features with biases may not be a good choice and more sophisticated approaches are needed.
LBM can also reveal some interesting patterns from the dataset, which might not be easily identified by other methods. For in-stance, we can figure out the effective popularity of different types of updates by looking at the values of b t . The positivity or negativ-ity of these values indicate whether a particular type of update cor-relates with clicks or non-clicks, while the magnitude of these val-ues means how strongly this correlation might be. We show some samples of top ranked types in Table 5, which are positively corre-lated with clicks. From the table, we see that job related updates, company-related updates are comparatively attractive. In addition, users pay attention to profile changes of their connections and new connections established by their friends. Note that the value shown in the table is  X  X utomatically X  normalized in the sense that SGD only updates corresponding parameters when the algorithm meets such type of updates. Also, the ratio of positive examples of a par-ticular type will drive the parameter to strong positive numbers. Thus, no post-processing steps are required. This is an example of how our model can be used in simple data analysis tasks.
As we discussed earlier, latent factor models are widely used and have been proven to be superior to linear models. We conduct the same experiments as linear models and show their results in Ta-ble 6. Here, we compare between pure factorization-based models ( MF and TF ) and feature-enhanced factor models ( MF2 and TF2 ). Note that all these models are built upon LBM and therefore the performance should at least match LBM . The second column of the table shows the results from MF , which is essentially to factorize the recipient-sender matrix and uncover latent structures. Unfor-tunately, the gain of performance of MF over LBM is marginal and even not observable. On the other hand, TF offers significant im-provements and leads another 3%  X  4% absolute boost for MAP on average. As we discussed before, social stream data is much more complex than traditional recommender system data (in various CF scenarios). Users may interact with certain updates because their senders are famous people or because the type of updates (e.g., news or twitter updates) is of a particular interest. Thus, tensor factorization can model multi-way relationships better than matrix factorization models them via a decomposition to multiple two-way relationships. Indeed, bias terms of recipients and senders in LBM might capture the basic relationship between them and a matrix fac-torization does not provide any additional benefits. Furthermore, we have already discussed why we do not employ the user-item Figure 4: Parameter Sensitivity Analysis: 1) the effect of  X  ( top) and 2) # of dimensions in latent factor models (bottom). Table 7: The effects of pair-wise learning. The best perfor-m ance is shown in bold. matrix in our setting: new items are much more common in social streams, compared to other recommender system setups. Thus, it is very interesting to see that well-established matrix-based factor models do not work equally well on social streams as they do in traditional CF scenarios. We believe that a more thorough investi-gation on this issue is desired.

For latent factor models with features, it is noticeable that MF2 failed to outperform LBM again while TF2 has gained additional 2%  X  3% absolute improvement over TF consistently. This is a yet another signal that matrix factorization does not work well in SSR. For TF2 , the increase of MAP can be explained by the two-level regression structure, that explicit features will help create la-tent features when new items or new users come into the system, effectively mitigating the cold-start problem. The performance of TF2 also validates that regression-based latent factor models are an effective approach to integrate explicit features with latent features.
We also study the sensitivity of parameters, especially the tem-poral balance weight  X  and the number of dimensions in latent fac-tor models. Taking the first week of September as an example, the effects of both parameters are shown in Figure 4. The first ob-servation is that both parameters are vital to the final performance and they are very sensitive if they are out of certain ranges. For  X  , the optimal performance is achieved when it is around 250  X  300 while for dimensionality, the results suggest that a reasonable num-ber ( 20  X  50 ) is the key to success.
The results demonstrated so far focus on point-wise learning pro-cedure. In other words, the objective function imposed by mod els is still error-based loss function. Here, we focus on how to im-prove performance by switching the objective function to pairwise preferences learning. More specifically, we conduct similar exper-iments as previous ones and report results on LBM , MF , TF MF2 and TF2 , shown in Table 7. Other models are omitted due to their poor performance. First of all, we notice that almost all models can benefit from pairwise learning, even for the methods which did not show significant gains in previous experiments, such as MF and MF2 . However, on another perspective, the overall improvement of a pairwise learning is not huge, usually yielding 1 . 5%  X  2% improvement on MAP. One possibility is that the pairwise learn-ing here is still na X ve. More sophisticated session enabled learning procedures (e.g., [31]) are to be investigated in the future.
In this paper, we investigate the problem of ranking social up-dates from a unique perspective of LinkedIn, the largest profes-sional social network in the world. More specifically, we address the task as an intersection of learning to rank, collaborative filtering and click-through modeling, leveraging ideas from information re-trieval and recommender systems. We propose a novel probabilistic latent factor model with regressions on explicit features, compar-ing a number of non-trivial baselines and gaining an approximately 10% improvement on MAP over the baseline. In addition to su-perior performance demonstrated in the paper, we shed some light on social updates on LinkedIn and how users interact with them, which might be applicable for social streams in general. For fu-ture work, it is interesting to see whether it is possible to develop efficient Bayesian treatment of latent models. In addition, other models might be explored as we demonstrate that state-of-the-art CF models do not provide comparable success in SSR. We also wish to extend our work by considering the diversity of informa-tion users wish to consume.
 This material is based upon work supported in part by the National Science Foundation under Grant Numbers IIS-0545875 and IIS-0803605.
