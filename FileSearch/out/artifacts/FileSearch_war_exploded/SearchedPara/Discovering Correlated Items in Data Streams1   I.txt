 A data stream [2,3] is a sequence of items that arrive at a rapid rate. Nowa-days, many applications require to process high volume of data streams, such as telecom call records, network traffic me asurements, web click-streams, and time-stamped data from sensor networks.

Finding frequent items in data streams is regarded as one of the important research problems in streaming data management. While the task is simply to find the items with the frequency above a sp ecified threshold, it is very useful in many applications. For example, in network traffic monitoring, it is of great im-portance to track IP addresses that generate the considerable amount of traffic in the network. The challenge of this research is that the total number of items could be so large (considering the number of valid IP addresses) that it is impos-sible to keep exact information for each item. Many approaches [4,5,6,7,8,9,10,1] have been proposed to use a fixed small amount of memory for dynamically maintaining the information of items, such that the frequent items can still be identified but only with bounded error on their frequencies.

While all the above mentioned studies focus on finding frequent single items, there is also a need to analyze the dependency among those frequent items in a data stream. A motivating application of such analysis is to detect  X  X n-detectable Hit Inflation (UHI) X , which is recently described in [11]. UHI is a type of click fraud in Internet advertising. Briefly, in the click-through payment program ( X  X ay-per-click X ), for claiming more revenue, two dishonest web sites collaborate together to inflate the clicks to the advertising web site. Due to the space limit, please refer to [12,11] for details of UHI.

In [11], the above-mentioned fraud ac tivity can be detected by mining the strong dependency between two dishonest web sites in a stream of HTTP re-quests, which is available from the Internet Service Provider (ISP). The task is to find any two web sites x and y such that x is frequently requested in the data stream and a large proportion of x requests are followed by y requests in a specified time interval T . Such a problem is modelled as: finding any association ( x T  X  X  X  y ) between two items x and y from the data stream by one scan.
In [11], the support and confidence model (with slight difference) is adopted for discovering the dependency of two web sites (items). However, it is known that in some cases, the support and confidence may be misleading as interestingness measures. For example, let us consider two independent web sites W 1 and W 2 , both of which are frequently requested. Suppose that the requests of the web site W 2 are so frequent that even without the dependency with W 1 , it can still be expected that within some time interval T ,arequestof W 1 is likely followed by a request of W 2 . In this case, based on the interestingness measure defined in [11], W 1 and W 2 will be regarded as dishonest web sites by mistake. In general, the frequencies of different items can vary significantly, failing to consider the intrinsic frequencies of these items may provide the misleading result in the dependency analysis.

To rectify the identified shortcoming, we evaluate the dependency of items in terms of  X  X nexpectedness X , i.e., a pattern/rule is interesting if it is unexpected to prior knowledge. Particularly, we introduce a more general problem, discovering correlated items in data streams, as stated below: Givenadatastreamandatime interval T, two items x and y are correlated if 1) both items are frequent, and 2) their actual number of co-occurrences (related to the interval T) in the data stream is significantly greater than the expected value, which is derived based on the assumption that occurrences of x and the occurrences of y are independent.
The first condition regulates that the potentially interesting items should be of statistical significance. The second co ndition specifies the correlation based on the unexpectedness. Because we compute t he expected number of co-occurrences of two items based on the assumption that these two items are independent, the level of  X  X nexpectedness X  can reflect their c orrelation. Our task is to discover all correlated item pairs with possible bounded errors by scanning the data stream only once. The discovered item pair ( x, y ) can be interpreted as: x and y are likely to occur together. Note that in thi s problem, we do not consider the order between item x and y . However, the discussions can be extend to the ordered case readily.

Since finding frequent items has been well studied, our research focuses on 1) computing the expected number of co-occurrences for two given items x and y , and more importantly, 2) finding the actual number of co-occurrences with a bounded error. In this paper, we define the co-occurrence of x and y based on the concept of minimal occurrence (MO) [13]. Given the interval T ,anyco-occurrence of two items x and y in a stream refers to a MO of the un-ordered item pair ( x, y ) with constraint T .

When computing the expected numb er of co-occurrences of two items x and y , we assume that the occurrences of x and the occurrences of y are independent. In addition, we assume that for any type of item, its occurrences in data stream follow the Poisson process . This assumption is realistic in various applications. For example, it is well known that the number of requests on an IP address follows the Poisson distribution. So, in HTTP log analysis, the occurrences of a given item (i.e., the requests on an IP address) can be well modelled by a Poisson process. Based on this assumption and the definition of MO, we derive the formula for computing the expected number of co-occurrences of two items x and y , which is a function of the frequencies of x and y , and the parameter T .
Considering the task of finding the actual number of co-occurrences, obviously, it is not possible to maintain a counter for every item pairs. We propose a data structure, Correlation-Summary , to dynamically organize a bounded number of counters for item pair. On top of the Space-Saving algorithm [1], we develop a one-pass algorithm, Stream-Correlation, to approximately count the number of co-occurrences for all potentially frequent item pairs. The proposed algorithm can efficiently find the results with bounded error by using limited memory space. The rest of this paper is organized as follows. Section 2 gives the related work. In Section 3, we formulate the problem of discovering correlated item pairs. In Section 4, our algorithm is presented follo wed by the theoretica l analysis. Section 5 shows the experiment results. Fina lly, we conclude the paper in Section 6. The problem of finding frequent items in data streams can be described as: Given a data stream S of length N , a frequency parameter  X   X  (0 , 1), an error parameter  X , and a probabilistic parameter  X , at any time, with a small bounded memory, find the items with their estimate frequency such that 1) all items with true frequency greater than (  X   X  ) N are output, and 2) the estimated frequency is higher th an the true frequency by at most N with high probability  X . Substantial work [4,5,6,7,8,9,10,1] has been done to handle the problem of finding frequent items and its variations, e.g., top-k frequent items. The proposed techniques can be classified a s counter-based approaches [10,6,9,1] and sketch-based (or hash-based) approaches [8,7,5,4]. Please refer to [1] for details.

In our problem, we apply the Space-Saving , a counter-based algorithm pro-posed in [1], to find the frequent items. In the algorithm, a fixed number of counters are dynamically allocated to items. When an item is observed, if there exists a counter for this item, its counter is increased; otherwise, counters will be reallocated based on cer tain techniques. The Space-Saving algorithm only uses 1 counters to guarantee the error bound N (i.e.,  X  = 1). We will give the algorithm description in later section.

The most relevant research to our work is [11], which discusses the associa-tions between two items in the data stream. A rule ( x T  X  X  X  y ) is interesting if x is frequent (w.r.t. support) and a large proportion (w.r.t. confidence) of x occur-rences are followed by y occurrences in the specified time interval T . However, in our work, we deal with the problem of correlation analysis. Instead of using a support and confidence model, we define the interestingness measures based on the unexpectedness. Due to this key diffe rence, we need to compute the expected number of co-occurrences based on the probability theory. Also, when counting the number of co-occurrences of items, we propose different data structure and algorithm procedures.

In [14], correlation is discussed in the transaction database. Given two items x transaction database resp ectively. The occurrences of x and the occurrences of y are defined as independent if P ( x, y )= P ( x ) P ( y ) . Otherwise, the occurrences In a data stream, it is hard to define  X  X ransactions X . So, we need to use the unexpectedness as our interestingness measure. Let us consider a finite set E of item s. An event is a pair ( a, t ), where a  X  E and t is the timestamp of the event. A stream S of length N is a sequence timestamps. Given a data stream S ,its duration Dur ( S ) is the time span of S , namely, Dur ( S )= t N  X  t 1 .Leta window w be [ t s ,t e ], where t s and t e are the starttimeandtheendtimeof w respectively. The window size of w is ( t e  X  t s ).
Given a stream S ,the frequency of an item x, denoted as F ( x ) , is the number of occurrences of x in S .Fortwoitems x and y , we define the co-occurrence of the item pair ( x, y ) based on the concept of minimal occurrence (MO). Note that we do not consider the order between x and y , i.e., ( x, y )=( y, x ).
In [13], Mannila et al. have proposed the concept of minimal occurrence (MO) to represent an episode that occurs in a sequence. According to their definition, a window w is a minimal occurrence of an item pair ( x, y ) iff 1) the window contains ( x, y ), and 2) there does not exist a subwindow w  X  w (i.e., t s  X  t s , t  X  t we add the condition 3): Size ( w )  X  T ,where T is a predefined window size. Here we give an example of minimal occurrence of an item pair in a stream. Astream S is visualized in Figure 1. Suppose that T is 3. For a non-ordered item pair ( b, c ), the MOs of ( b, c )in S are [1 , 2] , [8 , 10] , and [10 , 12]. Definition 1 (co-occurrence frequency). Given a stream S and a window size T , we define the co-occurrence frequency of an item pair ( x, y ) as the number of minimal occurrences of ( x, y ) with constraint T , and we denote it as F ( x, y ) . Definition 2 (expected co-occurrence frequency). Given a stream S, a window size T , and two items x and y with the frequency F ( x ) and F ( y ) re-spectively, let us assume that 1) x and y occur independently in S and 2) both occurrences of x and occurrences of y follow the Poisson process . The expected co-occurrence frequency of x and y, E ( x, y ) , is defined as the expected number of MOs of ( x, y ) with constraint T , which is computed under the above two as-sumptions.
 Theorem 1. Let the frequencies of two items x and y in a stream S be F ( x ) and F ( y ) respectively. Given the window size T , the expected co-occurrence frequency Proof. When the occurrences of an item x follow the Poisson process, the formula P ( k, t )= (  X  x t ) k k ! e  X   X  x t gives the probability that x occurs exactly k times in a given time interval t . In addition, the density function for the interval t between two successive x occurrences is f x ( t )=  X  x e  X   X  x t . In the above formulas,  X  x is the expected number of x occurrences per time unit. To our problem, we have  X 
Let us first discuss a single occurrence of x at t 0 in the stream. Now we consider the following four situations. A 1 : the next x occurs after t 0 + T ; A 2 : y occurs in the interval ( t 0 ,t 0 + T ) at least once; A 3 : the next x occurs at t 0 + t where 0 &lt;t  X  T ; A 4 : y occurs in the interval ( t 0 ,t 0 + t ) at least once.
Because we assume that the occurrences of x and the occurrences of y are independent, according to the definition of MO, the probability that the event ( x, t 0 ) can contribute to an MO of ( x, y ) with the later occurrence of y is E  X  = P ( A 1 ) P ( A 2 )+ T 0 P ( A 3 ) P ( A 4 ) dt.
 Since the occurrences of both x and y follow the Poisson process, we know that  X  e  X   X  x t , and P ( A 4 )=1  X  P y (0 ,t )=1  X  e  X   X  y t . Therefore, we can compute that E Considering the occurrences of y before t 0 as well , the expected number of MOs of ( x, y ) contributed by a single occurrence of x is 2 E  X  . Also, because there are F ( x ) occurrences of x , the expected co-occurrence frequency of ( x, y ) Problem Definition: Given a stream S of length N , a window size T ,two threshold 0 &lt; X &lt; 1and  X &gt; 1, the problem of discovering correlated items in the stream is to find any un-ordered item pair ( x, y ) that satisfies the following conditions: (i) x is a frequent item, F ( x ) &gt;  X N , (ii) y is a frequent item, F ( y ) &gt;  X N , (iii) x and y are positively correlated , F ( x,y ) E ( x,y ) &gt; X  . To discover correlated item pairs in a data stream, we propose the Stream-Correlation algorithm. According to the problem definition in Section 3, by scan-ning the stream once, we need to complete the following three tasks: 1) approximately find all frequent items from the stream, and meanwhile 2) for any two frequent items x and y , count the co-occurrence frequency for ( x, y ) with possible bounded error, and finally 3) approximately output the correlated item pairs. Section 4.1, 4.2, 4.3 will discuss these three tasks respectively. 4.1 Finding Frequent Items We apply the Space-Saving algorithm, proposed in [1], to fulfil this task. For the completeness of the representation, we briefly introduce the algorithm. In the algorithm, a data structure, called Stream-Summary , is used to dynamically maintain the fixed number ( m ) of counters for items. Each counter consists of three fields: the corresponding item e i , the estimated frequency of the item Count ( e i ), and the maximum possible over-estimation of the frequency, ( e i ). For brevity, we can regard the Stream-Summary as a list of counters for m items e ,...,e m , which are always decendingly ordered by their estimated frequencies.
Algorithm 1 is the pseudocode for the Space-Saving algorithm. When an event ( a I , t I )inthestream S arrives, if the item a I is monitored in the Stream-Summary , the counter of a I is incremented. Otherwise, a I takes the place of e m , which is the item that currently has the least estimated frequency min ;also,we set Count ( a I )as min + 1 and the over-estimation ( a I )as min .

In [1], it is proved that regardless of the data distribution and user-supplied frequency threshold, to find all frequent items with the maximal possible error  X  (0 , 1), the Space-Saving algorithm only requires to maintain 1 number of counters, i.e., m = 1 . For any item e with the true frequency F ( e ) &gt;N is guaranteed to be in the Stream-Summary . Also, for any item e i in the Stream-Summary , we always have Count ( e i )  X  N  X  F ( e i )  X  Count ( e i ). 4.2 Finding Co-occurrence Frequency for Frequent Item Pairs In this section, based on the Spacing-Saving algorithm, we propose our key algorithm, Stream-Correlation , to find the co-occurrence frequency for item pairs. Algorithm 1. The Space-Saving Algorithm (Counters m ,Stream S ) Considering that the volume of stream is very high and the number of items is large, obviously, it is impossible to maintain a counter for each item pair. Naturally, the following principle is applied: We count the co-occurrence of x and y only when both x and y are potentially frequent. In other words, a co-occurrence counter Count ( x, y ) is allocated to item pair ( x, y ) iff both x and y are currently stored in the Stream-Summary.
 Once the principle is set, it is clear that if the number of items in the Stream-Summary is m , we need to maintain at most m ( m  X  1) 2 co-occurrence counters. The challenge now becomes how to organize t hese co-occurrence counters such that they can be incrementally maintained in an efficient way. In the remainder of this section, we first design a data structure, Correlation-Summary , to effectively organize the co-occurrence counters. Based on the Correlation-Summary ,we develop our algorithm Stream-Correlation to efficiently count the co-occurrence frequency for item pairs. Finally, we discuss the complexity of the algorithm. Correlation-Summary data structure. Figure 2 shows the data structure, which consists of two levels. The top level is the Stream-Summary data struc-ture which has been introduced in Section 4.1. At any moment, the items are decendingly ordered by their estimated count, denoted as e 1 ,e 2 ,...,e m .Atthe second level, for each item e i in the Stream-Summary , we maintain a group of co-occurrence counters which are associated with e i , denoted as G e i .Consid-ering an item pair ( e i ,e j ), intuitively, the co-occurrence counter Count ( e i ,e j ) could be put either in group G e i or in group G e j . However, in our data struc-ture, we enforce the constraint that a co-occurrence counter Count ( e i ,e j ) always associates with the item that has lower estimated frequency. That is, know that for any item e i (1  X  i  X  m )inthe Stream-Summary ,thereareat As a result, when the least frequent item e m in the Stream-Summary is replaced, all the co-occurrence counters that contain the item e m can be dumped by simply removing G e m . This guarantees that co-occurrenc e counters are only maintained for items which are currently in the Stream-Summary . To facilitate the update on co-occurrence counters, for any item e i , we adopt the B + tree structure to organize the co-occurrence counters in G e i . We call this B + tree a CCTree (co-occurrence counter tree) of e i , denoted as CT e i . An item e i and its CCTree CT e i are linked with a pointer pointing to the root of the tree. Note that without loss of generality, each item can be map ped into an integer. So, a leaf node in the CCTree of e i is in the form of &lt;e j ,Count ( e i ,e j ) &gt;, 1  X  j  X  i  X  1, where e j is the key of the node and Count ( e i ,e j ) gives the co-occurrence frequency for item pair ( e i ,e j ). With this data structure, given two items e i and e j , their co-occurrence counter can be quickly located in the Correlation-Summary . Incremental update algorithm. Now we present the complete algorithm Stream-Correlation , as shown in Algorithm 2. Essentially, this algorithm is to in-crementally maintain the structure Correlation-Summary when a new event oc-curs. For any event ( a I ,t I ) in the data stream, we update Correlation-Summary in two steps. First, the Stream-Summary is updated. Note that according to the constraint , this update may lead to the change on the structure of CC-Trees as well. Second, we check the events occurred in [ t I  X  T,t I ) and increment co-occurrence counters if the minima l occurrences (MOs) are detected.
In the first step, we follow the Space-Saving algorithm to update the counter of a I . Under the following two circumstan ces, the CCTree(s) needs to be updated as well. First, when the least frequent item e m is replaced by a I , the CCTree of a m is dumped and the CCTree of a I is initialize as empty. Second, due to the increase of Count ( a I ), a I may swap position with other item(s), say e i .To enforce the constraint , the CCTree of a I , CT a I , and the CCTree of e i , CT e i , should be updated as follows: remove the node with the key e i from CT a I , change the key of this node from e i to a I ,andinsertthenodeinto CT e i .

In the second step, for any event ( a I ,t I ) , we update the co-occurrence coun-ters as follows. At the moment t I , we always buffer the events occurring in the k is the number of events in the current window. According to the Space-Saving algorithm, the new arriving item a I is guaranteed to be included in the Stream-Summary , so we check previously occurred event ( a J ,t J )(where J from I  X  1 to I  X  k ) to see whether item pair ( a J ,a I ) needs to be counted. According to the principle , we only consider the event ( a J ,t J )where a J is currently in the Stream-Summary .If a J = a I , Count ( a J ,a I ) is increased by one because events ( a J ,t J )and( a I ,t I )formanMOof( a J ,a I ). Otherwise (in the condition a
J = a I ), we need to 1) remove ( a J ,t J ) from window [ t I further checking the rest events occurred in the window [ t I  X  T,t J ). Let us first explain the operation 2). For any event ( a J ,t J ) occurring earlier than ( a J ,t J ) where t I  X  T  X  t J &lt;t J , according to the definition of MO, events ( a J ,t J )and ( a
I ,t I ) cannot form an MO for item pair ( a J ,a I ) because of the existence of event ( a J ,t J ). Considering the operation 1), due to similar reason, for any event ( a cannot be matched as an MO for item pair ( a J ,a I ) . So, ( a J ,t J )willnotbe considered any more and should be removed. Algorithm 2. The Stream-Correlation Algorithm (Counters m ,Stream S )
When a co-occurrence counter Count ( a J ,a I ) requires an update, to locate the Count ( a J ,a I )inthe Correlation-Summary , we first find the item (from a J and a I ) with the lower rank in the Stream-Summary . Suppose that such item is a I , i.e., Count ( a I )  X  Count ( a J ) . We search the no de with key a J from the CCTree of a I . If such a node exits, Count ( a J ,a I ) is incremented. Otherwise, it means that the co-occurrence of ( a J ,a I ) is counted at the first time, then a new node, with key a J and Count ( a J ,a I ) = 1, is initialized and inserted into CT a I . Complexity. Now we discuss the space and time complexity of the Stream-Correlation algorithm.

According to the structure of Correlation-Summary , it is straightforward that given the size of Stream-Summary m ,the Stream-Correlation algorithm requires
Let us consider the time complexity in terms of processing time per event. As mentioned in previous part, for each event, the algorithm updates the Correlation-Summary in two steps. For the first step, it has been proved in [1] that the up-date on the Stream-Summary takes O (1) amortized cost. N ow we consider the cost related to updating the struct ure of CCTrees. When the last item e m is re-placed by a I , updating CCTrees requires O (1) time. For the situation that two items need to swap their positions in the Stream-Summary , the cost for this op-eration is O (log m ), which is the complexity for removing / inserting a node from a B + -tree of size m . So, updating the counter for a single item in Correlation-Summary requires O ( c 0 log m ) 3 amortized cost per event. Considering the second step, updating a co-occurrence counter Count ( e i ,e j ) in the co-occurrence counter tree requires at most O (log m ) cost. For each event ( a I ,t I ) in the data stream, the Stream-Correlation algorithm needs to update at most k co-occurrence counters associate with a I , where k is the number of events in the interval [ t I  X  T,t I )and k&lt;T. So, the time complexity for second step is at most O ( T log m ). By combin-ing the above analysis, we know that the Streaming-Correlation algorithm has at most O (( T + c 0 )log m ) processing time per event in the data stream. 4.3 Error Bound Analysis and Computing Correlated Item Pairs Recall that given the size of Stream-Summary m, the error bound for the fre-quency of a single item is 1 m . That is, for any item e i in the Stream-Summary ,we item e i . Now, we discuss the error bound for the co-occurrence frequency. Theorem 2. For any two items e i and e j in the Stream-Summary, let F ( e i ,e j ) be the true value of co-occurrence frequency for item e i and e j in a stream of length N. Given the error bound for the single item, the Stream-Correlation algorithm guarantees that the condition Count ( e i ,e j )  X  F ( e i ,e j )  X  Count ( e i ,e j )+2 N always holds. This is true regardless of the item distribution in the stream. Proof. Because both e i and e j are currently recorded in the Stream-Summary (with their error ( e i )and ( e j ) respectively), there must exist a moment t such that 1) since t ,both e i and e j are in the Stream-Summary , and 2) t &lt;t and t satisfies the condition 1). According to the principle , Count ( e i ,e j ) is the true F ( e i ,e j ) . Suppose that e i is the item which is not recorded in the Stream-Summary until the moment t. From the Space-Saving algorithm, we know that e i can be maximally overestimated ( e i )timesbefore t . Note that according the definition of MO, one occurrence of e i can lead to two occurrences of ( e i ,e j )atmaximum. So, the number of co-occurrences of ( e i ,e j )before t cannot be greater than 2 ( e i ) . Count ( e i ,e j )+2 N .
 Theorem 3. Given the error bound  X  (0 &lt; X  &lt; 1) for the co-occurrence frequency, the Stream-Correlation algorithm requires 2  X  ( 2  X  +1) 2 counters.
 Proof. First, according to Theorem 2, the error bound  X  equals to 2 . Second, we know that m = 1 . Third, the Stream-Correlation algorithm requires at most Finally, we discuss the procedures of appr oximately generating correlated item pairs from the Correlation-Summary . For any two items x and y, we have F ( x )  X  [ Count ( x, y ) ,Count ( x, y )+2 Max { ( x ) , ( y ) } ]. The approximate correlation dis-covery can take two approaches, i.e., false positive oriented and false negative ori-ented. The former may include some item pairs which are not correlated in terms of the given threshold, while the latter may miss some correlated item pairs. Let E + ( x, y )( E  X  ( x, y ) respectively) be the approxim ate expected co-occurrence fre-quency computed by the upper (lower respectively) bounds of F ( x )and F ( y ). The e that is frequent, we need to traverse its co-occurrence counter tree CT e i . For any node corresponding to e j , if the condition (either false positive or false negative) is satisfied, the item pair ( e i ,e j ) is output. In this section, we show the effectiveness and the efficiency of the Stream-Correlation algorithm by comparing it with the naive approach , which maintains a counter for every item and item pair. Although the naive approach guarantees the accurate result for the problem of correlation analysis, it is not practical for the dataset with a large number of item types because the required size of memory will be too large. We implement the algorithms by Java and all exper-iments are conducted on a PC with 3 GHz CPU and 1 gigabytes memory, run-ning Microsoft Windows XP. The dataset used in the experiments is a sequence of URLs fetched from the web proxy servers of an university. Due to privacy issue, there is no timestamp information f or each HTTP request, and the URLs are truncated. The number of URLs in the dataset is 10 6 ,whichmeans Dur ( s )= N =10 6 .

For finding the positive correlated item pairs from the dataset, we always set the thresholds as  X  =0 . 005 and  X  =1 . 5 . The number of single counters in the Stream-Correlation is 500, which indicates that the maximal possible error for the item frequency and co-occurrence frequency are 1 500 and 1 250 respectively.
We test the Stream-Correlation algorithm and the naive algorithm with differ-ent window size T (from 10 to 100). Let us fist evaluate the effectiveness of the Stream-Correlation by comparing its output with the accurate result (the output of the naive approach). In all the conducted experiments, the Stream-Correlation algorithm achieves both recall and precision equal to 1, which means that there is no accuracy loss in terms of the item pairs discovered in the data.

The efficiency of the algorithm is measured by 1) the number of counters used in the algorithm and 2) the runtime of the algorithm. Figure 3(a) shows that the number of counters maintained by the Stream-Correlation is far less than that of the naive approach. This is because in the real dataset, the number of items (dif-ferent URLs) are very large. As a result, it is very memory-consuming to maintain a counter for every item and item pair. We do have some experiments in which the naive approach can not work due to running out of memory. In Figure 3(b), we can see that the Stream-Correlation algorithm is much faster than the naive approach in terms of the runtime because it maintains and processes significantly smaller number of counters. In this paper, we have investigated the problem of finding correlated item pairs in a data stream. We define that two items x and y are correlated if both items are frequent, and their actual number of co-occurrences in the data stream is sig-nificantly different from the expected value. By modelling the occurrences of each type of item as a Poisson process, we give the expected number of minimal occur-rences of ( x, y ), which is computed based on the frequencies of x and y .Aone-pass algorithm has been proposed with the focus on estimating the actual number of co-occurrences of item pairs. The algorithm can efficiently discover the correlated item pairs with a bounded error by using limited memory space. The experiment results on the real data show that compared with the naive approach, our algo-rithm can significantly reduce the runtime and the memory usage, but without the loss of accuracy on the discovered item pairs.

