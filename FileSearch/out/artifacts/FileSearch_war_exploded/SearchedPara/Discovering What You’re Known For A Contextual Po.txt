 Discovering what people are known for is valuable to many important applications such as recommender systems. Un-like an individual X  X  personal interests, what a user is known for is reflected by the views of others, and is often not eas-ily discerned for a long-tail of the vast majority of users. In this paper, we tackle the problem of discovering what users are known for through a probabilistic model called Bayesian Contextual Poisson Factorization. Moving beyond just modeling user X  X  content, it naturally models and inte-grates additional contextual factors, concretely, user X  X  geo-spatial footprints and social influence, to overcome noisy online activities and social relations. Through GPS-tagged social media datasets, we find that the proposed method can improve known-for prediction performance by 17.5% in pre-cision and 20.9% in recall on average, and that it can capture the implicit relationships between a user X  X  known-for profile and her content, geo-spatial and social influence.
Discovering what people are known for is valuable to many important applications, including recommender systems and question-answering sites. For example, item-based recom-menders can be augmented to customize recommendations based on what knowledgeable users prefer, rather than rely-ing on all users [2]. While an individual X  X  personal interests are often reflected in the media she consumes and generates, what a user is known for is reflected by the views of others and is often not easily discerned. A few high-profile peo-ple are easily recognized  X  for example, a researcher may be interested in basketball, biking, and recommender systems, though mainly known for recommender systems. But there is a long-tail of the vast majority of users for whom we have only limited insight into what they are known for.

And yet accurate identification of a user X  X  known-for pro-file is challenging. First, the content that a user chooses to post on social media is often noisy and ambiguous. What users are truly known for can be buried among posts about daily routines and personal interests. Second, many users post only infrequently, meaning extreme sparsity for the vast majority of all users. Third, while a natural step to overcom-ing this sparsity is the integration of additional contextual factors (e.g., social links between users), it is not clear how different contextual factors correlate with users X  known-for profiles and how we can model these contextual influence and integrate them together.

Hence, in this paper, we tackle the problem of discovering what users are known for through a probabilistic factoriza-tion model called Bayesian Contextual Poisson Factorization (BCPF). Three of the key features of the proposed BCPF model are: (i) It is jointly learned on a small fraction of users whose known-for profiles are already known and the vast majority of users for whom we have little (or no) infor-mation. (ii) Moving beyond just modeling the content a user generates, it naturally models and integrates additional con-textual factors that provide implicit linkages between users for improved known-for profile estimation. Concretely, we investigate the impact of geo-spatial footprints and social in-fluence as additional contextual signals. (iii) It inherits the strengths of Bayesian Poisson factorization (BPF), a variant of probabilistic matrix factorization recently proposed in [9, 10], which demonstrates scalable inference for sparse data and outperforms traditional matrix factorization [9].
In summary, this paper makes the following contributions:  X  First, we define the problem of discovering user X  X  known-for profile in social media, and propose a probabilistic method called Bayesian Contextual Poisson Factorization. This model can capture the implicit relationships between user X  X  known-for profile and her content, geo-spatial and social influence. We then develop an efficient approximate variational infer-ence to learn the latent parameters of BCPF.  X  Second, we evaluate the proposed method over two Twitter datasets and against several alternative baselines. Overall, we see a significant improvement of 17.5% in precision and 20.9% in recall on average over the next-best method.  X  Finally, we study the inferred geo-spatial and social influ-ence latent factors, and observe that the geo-spatial factors are able to capture the underlying distributions of user X  X  known-for profile at different locations. We also show that friends have different social influence on users with respect to different topics, and that our model is able to learn this fine-grained social influence.
 Problem Formulation. We assume there exist a set of users U in a social network, and a set of tags T used to describe what users are known for with respect to differ-ent topics or aspects. The known-for profile p u of a user u  X  U is defined to be a subset of tags from T which can best describe what this user is known-for by others, instead of what u is personally interested-in . To give an example: suppose Alice is known by others as a chef and frequently posts many food recipes, but she also posts news and per-sonal related stories now and then as her personal interest. We associate Alice with tags  X  X hef X  and  X  X ecipe X  instead of  X  X ews X  to best describe her perceived image by others, and treat  X  X hef X  and  X  X ecipe X  as the known-for profile for Alice.
With the above definition, we can define the task of dis-covering user X  X  known-for profile in social media as follows: User Known-For Profile Discovery. Given the users U old whose known-for profiles are already known (labeled users), identify the known-for profiles for the rest of the users U new (unlabeled users) based on U old . Equivalently, the task is the same as identifying the top-n tags from T for unlabeled users as their known-for profiles.

However, discovering user X  X  known-for profile is a classic cold-start problem. Since unlabeled users do not have any identified tags in their profile, collaborative filtering tech-niques fail to infer the profiles of unlabeled users since the corresponding rows of the user-profile matrix are all zeros for unlabeled users. Thus, to overcome the cold-start situation, we propose to leverage a user X  X  contextual information to extract implicit relationships between their profile and the context for the task as described in the following.
As a first pass, we can attack the problem of known-for profile discovery with Bayesian Poisson factorization (BPF), a variant of probabilistic matrix factorization recently pro-posed in [9, 10] to model implicit feedback for recommenda-tion. Due to the assumption of Poisson distribution instead of traditional Gaussian distribution in modeling the discrete data, BPF can capture the long-tailed distribution of user behavior, enjoy scalable inference for sparse data and out-perform traditional matrix factorization [9]. In our setting, since a user X  X  known-for profile is inherently of discrete na-natural choice to adopt a Poisson distribution instead of a Gaussian distribution to model user X  X  contextual influence.
Specifically, given the binary occurrence r ut of tag t in the known-for profile for user u , BPF assumes that r generated according to: where  X  u  X  R K is the latent factor of u representing what u is known for in a latent space, and  X  t  X  R K is the latent attribute of t . Each component of these latent parameters is drawn according to a Gamma distribution as follows: where  X  a and  X  b are the shape and rate parameter of the Gamma distribution, respectively. Given a binary matrix of known-for profiles, BPF can find each user X  X  latent factors over the tag X  X  latent attributes. These inferred latent factors can be further used to identify other related tags which may fit the user X  X  known-for profile.
While BPF is able to reveal the latent factors for users whose known-for profiles are already known or partially known, it will fail to infer the known-for profiles of unlabeled users, since these users are  X  X ero rows X  in the user-tag matrix. Hence, a natural approach to extend BPF to these missing users is through the integration of additional contextual in-formation that may provide implicit linkages between users.
We refer to this extended framework as Bayesian Con-textual Poisson Factorization since it inherits the strengths of BPF and is extended to integrate valuable contextual in-formation. Intuitively, BCPF is designed to learn the in-fluence of each contextual feature individually and combine them together for overall representation. Under the assump-tion of Poisson factorization, since the sum of Poisson ran-dom variables is still a Poisson distribution, we can linearly add different contextual influence together without changing the underlying probabilistic assumption.

In the rest of this section, we present how several impor-tant contextual factors can be modeled under BCPF  X  user content, geo-spatial impact, and social influence  X  and how these factors can be integrated into BCPF. Note that the proposed model is generalizable and other contextual factors could be incorporated as well. Concretely, we model users in a heterogeneous graph G = ( V , E ), consisting of four types of nodes V = ( U,C,L,P ). Each user u has a sample of the textual content that she posts online, denoted as c and a pair of geographical coordinates ( l lat u ,l lng u cating the approximate location of this user X  X  posting activ-ities. The known-for profile of a labeled user from U old denoted as p u  X  P . All of the above relations are directly relevant to users themselves, and can be regarded as user attributes. Furthermore, users may also have social rela-tions with each other. Together, user attributes and social relations constitute all edges V between different entities. Content factor. The first baseline factor is a user X  X  content  X  that is, we assume that a user X  X  known-for profile can be reflected by the usage of words in posts. Let R c be a sparse matrix describing the usage of words from all users, where each element r uw is the count of word w adopted by user u . We then choose to model every count r uw using a Poisson distribution, with the intensity parameter factorizing over u  X  X  latent factor  X  u and w  X  X  latent factor  X  w as follows: where  X  u and  X  w are both K -dimensional non-negative vec-tors with Gamma priors specified in Equation 2.

Factorizing over the word matrix R c gives us an unsuper-vised version of users X  latent preference over words. How-ever, for labeled users U old ,  X  u should also reflect their known-for profiles. For instance, if both users are labeled with  X  X ports X , it is likely that they may share some common words in their sports-related posts. Thus, to capture this intuition,  X  u should also be constrained by users X  known-for profiles. Let R p be a binary matrix describing known-for profiles for all users, where each element r ut represents if user u is la-beled with tag t . Similarly, we model each binary r ut with a Poisson distribution, with its intensity parameter factorizing over  X  u and t  X  X  latent factor  X  t as follows: where  X  t is a K dimensional non-negative vector parametrized with Gamma priors. By sharing user X  X  latent factor for both factorization 3 and 4, the model can not only reflect user X  X  latent preference over common use of words, but also en-sure that users with similar profiles have similar  X  u . Note however that a user X  X  posts may be intertwined with other F igure 1: Geo-spatial distribution of users who are known for  X  X ntrepreneur X  (left) and  X  X olitics X  (right). non-revealing texts, and thus can be noisy. To enhance the representation for unlabeled users, we also incorporate each user X  X  geo-spatial footprints and social connections to fur-ther refine the model.
 Geo-spatial factor. To demonstrate how geo-spatial loca-tion may reflect what a user is known for, we first show heat maps of users in US who are known for  X  X ntrepreneur X  and  X  X olitics X  in Figure 1 based on a sample of crowd-generated Twitter lists (described more fully in Section 3). As we can observe, for both topics, these well-known users are mostly distributed in a few areas, with a majority focused in San Francisco for  X  X ntrepreneur X  and in Washington D.C. for  X  X olitics X . This suggests that (i) for a specific tag, users do not distribute evenly across the entire geo-scope and may concentrate in a few areas; (ii) geo-spatial distributions of well-known users may vary by different topics.

Given the above observations, how can we use geo-spatial coordinates to enhance the representation of users? We no-tice from Figure 1 that users known for certain topical tags often appear in clusters, i.e., they concentrate in several discrete regions. In light of this, we introduce a region-dependent variable to represent a region X  X  affinity over tags.
Concretely, we assume that the geographical space is par-titioned into I regions. Each user can then be assigned into the region where she belongs, which gives a matrix R Each region corresponds to a K -dimensional location latent factor, denoted  X  l , indicating the region X  X  affinity over tags. If we consider that each r ut in the matrix R p is only depen-dent on user X  X  location, then r ut can be generated through the following Poisson distribution: where l u represents the region where user u belongs, and the intensity parameter is determined by the inner product of the corresponding location and tag latent factor. Simi-larly, each component of  X  l has a conjugate Gamma prior as specified in Equation 2. Thus, through the explicit han-dling of tag X  X  dependence over locations, it is expected that  X  could indicate which tags are mostly dominant for the corresponding region.
 Social influence factor. Homophily in social networks [22] suggests that people tend to connect with others who are similar to themselves. Indeed, there already exists some works [19, 21] exploiting social relations for item recommen-dations. Here, we would like to explore how social relations may benefit user known-for profile discovery. An immediate problem is that user X  X  social relations are often noisy, i.e., if a friend of a user is known for a tag, it does not necessarily mean that the user is also known for the tag. In Figure 2, we randomly select two Twitter users who are known for eight tags, and examine the proportion of followers who have the same tag in their known-for profiles. We can see that even F igure 2: Proportion of followers who have the same tag in their known-for profile as the users. user1: red; user2: blue. though user1 is known for  X  X d X , very few followers of the user are also known for  X  X d X . On the contrary, a significant por-tion of followers of user2 are known for  X  X d X . This indicates that users may have different degree of social influence.
Thus, to capture this observation, we introduce a social influence parameter  X  f for each friend f of all users, indicat-ing the degree of social influence of this friend on any user who follows her. Thus, if we have a total of M friends, the influence parameters constitute a vector of  X  f with dimen-sion M . Then, given user u  X  X  friends N u , if we consider that each r ut in the matrix R p is only dependent on user X  X  friends X  known-for profiles, then r ut could be generated through the following Poisson distribution: where r ft is the element in the matrix R ft indicating if friend f has the tag t . The intensity parameter is obtained by aggregating all of the friends X  latent influence for the user.
However, since each friend may be labeled with multiple tags, it is very likely that this friend has different levels of influence for different tags, as shown in Figure 2. In the figure, many people following user2 have the tag  X  X r mar-keting X  and  X  X d X . Thus, although user2 is also known for  X  X ntertainment X , it is obvious that this user is more influen-tial on  X  X r marketing X  and  X  X d X . As a result, if a new user starts to follow her, it is very likely that this user follows her because she is also known for  X  X r marketing X  or  X  X d X .
Hence, to capture this intuition, we assume that for each friend f of all users X  friends, there is a latent factor  X  each tag t . This parameter is used to capture the degree of influence that f has over t . Thus, if we have a total of N tags, the influence parameters constitute a M by N matrix  X  ft . Thus, given user u  X  X  friends N u , similarly as above, r can be generated through the following: where the intensity parameter is obtained by aggregating all of the friends X  latent influence for this user and the corre-sponding tag. Consequently, Equation 7 is able to model the above scenario where the new user is more likely to have the tag  X  X r marketing X  or  X  X d X  instead of  X  X ntertainment X  if she follows user2. Similarly, each nonzero component of  X  is put on Gamma priors for inference.
 Integrating contextual factors. So far, we can generate independent known-for profiles through user X  X  content, ge-ographical coordinates and social relations. However, it is Algorithm 1: Generative Process for BCPF
Input: hyper-parameter  X  w a ,  X  w b ,  X  u a ,  X  u b ,  X  l for each word w in the vocabulary, draw for each user u , draw user content factor for each word w used by user u , draw for each discretized region l , draw region factor for each friend tag pair ( f , t ), draw for each tag t , draw tag factor associated with for each tag t in user u  X  X  known-for profile, draw natural to combine all types of contextual influence to form a better representation for users. Since the sum of Poisson distributions is still a Poisson distribution, we can combine the generative process specified by Equation 4, 5 and 7 to-gether to obtain the overall intensity parameter of the sum Poisson distribution as: where  X  ,  X  and  X  are the tradeoff weights for content, geo-spatial and social contributions, respectively. The entire generative process of BCPF is described in Algorithm 1.
We have specified a Bayesian probabilistic model over the latent parameters  X  u ,  X  w ,  X  l ,  X  ft and  X  t , and the ob-served discrete data matrix R p , R c , R ul and R ft . To pre-dict the known-for profiles for new users, we need to es-timate the posterior distributions of the latent parameters p ( X  u ,  X  w ,  X  l ,  X  ft ,  X  t | R p , R c , R ul , R ft data. Once we have the posterior distributions of the la-tent factors, we can predict the known-for profiles for new users with the expectation of the sum of weighted Poisson distributions. This leads to computing the expectation of the intensity parameter  X  ut , which gives: E ( r ut ) =  X E (  X  u ) T E (  X  t )+  X E (  X  l u ) T E (  X  where all expectations are with respect to the posterior dis-tributions. By making use of a new user X  X  contextual infor-mation, we can predict the ranking of the tags for this user by their expected occurrence.
Since it is not tractable to compute the exact posterior of the latent factors  X , we propose to use variational methods [15] for approximate inference. Variational inference casts the approximation process as an optimization problem. By defining a freely parameterized family of distributions over latent variables, variational methods seek to fit its parame-ters so as to minimize the KL-divergence between the defined distribution and the posterior distribution. In our case, vari-ational inference solves the following minimization problem: q  X  ( X ) = argmin q KL ( q ( X ) || p ( X  | R p , R c , R ul , R where q  X  ( X ) is the optimized variational distribution that is used as the proxy for the exact posterior. To facilitate the inference, we first introduce several auxiliary latent vari-ables [9] for Equation 3 and 8. Specifically, let X  X  assume z uwk  X  Poisson (  X  uk  X  wk ), where P k z uwk = r uw , and z Poisson (  X  X  uk  X  wk ), z l utk  X  Poisson (  X  X  l u k  X  tk Poisson (  X  X  ft r ft ), where P k z c utk + P k z l utk + P r . Since the sum of a set of Poisson random variables is still a Poisson distribution, these auxiliary variables can still preserve the marginal distribution of r uw and r ut marginalized out. Thus, our latent variables include latent parameters  X  and auxiliary latent variables Z uw , Z ut .
Before solving Equation 9, we need to derive the complete conditionals, i.e., the conditional distributions of a latent variable given all other variables, for each of  X , Z Z ut . Since each of  X  has conjugate Gamma priors, the com-plete conditionals for  X  are also Gamma distributions. For auxiliary latent variables, we follow the conclusion from [14] that given a vector Z ut of Poisson distributed count, Z ut distributed as a multinomial conditioned upon the observed sum r ut . Similarly, Z uw is also a multinomial given r Thus, all complete conditionals can be derived.

Variational inference assumes q ( X  ,Z uw ,Z ut ) is in the same exponential family with the complete conditionals [10]. Thus, we employ the following mean field variational family, where each latent variable is independent with each other and gov-erned by its own variational parameters: where  X  a  X  and  X  b  X  are the shape and rate parameter of the variational Gamma distributions; and  X  ut  X  is the parame-ter of the variational Multinomial distributions. To obtain optimal values for  X  a  X  ,  X  b  X  ,  X  uw  X  and  X  ut  X  , we need to solve the minimization in Equation 9. Since variational inference requires that the natural parameter of each q (  X  ) is the expec-tation of the natural parameter of the corresponding com-plete conditional under q (  X  ) [11], we just need to compute the expectation of the natural parameters of each complete conditional. To give an example, we show how to compute parameter  X  a tk and  X  b tk . The expectation of the natural pa-rameters on the complete conditional of  X  tk gives: where we have applied the fact that the expectation of a Gamma random variable is equal to the ratio of the shape parameter over the rate parameter. Similarly, we can de-rive the formula to compute other latent parameters. For auxiliary latent variable Z ut , the expectation of its natural Algorithm 2: Variational inference for BCPF
Input: hyper-parameter  X  w a ,  X  w b ,  X  u a ,  X  u b ,  X  l repeat until Converge parameter of the complete conditional leads to  X  c utk  X   X  exp(  X  (  X  a uk )  X  ln(  X  b uk ) +  X  (  X  a tk  X  l utk  X   X  exp(  X  (  X  a l u k )  X  ln(  X  b l u k ) +  X  (  X  where  X  (  X  ) is the digamma function; and we have applied the fact that E (ln( X )) =  X  (  X  a )  X  ln(  X  b ) when X  X  Gamma (  X  Similarly, we could obtain the formula for Z uw . We then use coordinate ascent to update each variational parameter by turns to obtain the locally optimal values. The overall up-date algorithm is shown in Algorithm 2.

The complexity of Algorithm 2 is largely determined by the product of K and the maximum number of non-zeros of the matrix R c , R p and R ft . Thus, learning is quite efficient for a sparse data matrix. Here, we omit detailed complexity analysis due to the space limit.
In this section, we conduct several experiments to evaluate the proposed BCPF for user known-for profile discovery. Data. Our data is based on a sample of about 12 million Twitter lists collected from 2013 to 2014. Twitter lists [3, 8] are crowd-generated, for which a labeler can put a user on a tagged list, if the labeler thinks the user is known for the topic indicated by the tags. Thus, if a user is labeled by different labelers with certain tags, for example,  X  X hef X  and  X  X ecipe X , then we consider this user is known for these topics. In our experiments, we use the threshold of three labelers to determine the existence of a tag in user X  X  known-for profile. In addition, we also filter out infrequent tags with fewer than 20 users to focus on quality tags. We randomly sample two Loc # of users # of tweets # of following links US 10,552 317,436 24,676 World 19,776 594,929 30,853 Loc # of tags # of records sparsity US 1,011 85,994 0.81%
World 1,456 136,625 0.47% datasets (see Table 1), one in the US and one across the world. We also crawled about 30 recent tweets for each user and sampled her social relations.
 Experimental Setup. For evaluation, we randomly par-tition all users into 60% for training, 30% for testing, and 10% for cross-validation. For the dimension K of the latent factors, we empirically select 100 for all methods. For the tradeoff weights  X  ,  X  and  X  in Equation 8 for BCPF, we set them to 1, 1 . 2 and 0 . 2 via cross-validation. To initialize the hyper-parameters of the Gamma priors in BCPF, we fol-low [10] and set them to 0.3 plus a small random variations on geo-spatial and social latent factors for sparse solutions; for user content and word variational parameters, we adopt LDA [5] and use document topic distribution and topic word distribution to initialize  X  uk and  X  wk , respectively. In the modeling of geo-spatial influence, it is assumed that the ge-ographical space is partitioned into discrete regions. Here, we adopt k -means clustering instead of a simple gridding by clustering users X  geo-coordinates. We choose a clustering-based approach because the geo-spatial distribution of users exhibits a clustering effect, as shown in Figure 1. For evalua-tion metrics, we adopt Precision@ k (Prec@ k ) and Recall@ k (Rec@ k ). Prec@ k measures the percentage of the correctly identified tags over the top k predicted tags. Rec@ k rep-resents what percentage of true tags can emerge in top k predicted tags. Both measures are averaged over all testing users. In our experiments, we select k to be 5 and 10. Baselines. We compare BCPF with the following baselines:  X  k-Nearest Neighbors . In this baseline, we extract content features from user X  X  sampled tweets, and apply kNN to find n most similar users to the testing user u . We then com-pute tag X  X  score according to s ut = P n i w ui r it , where w the similarity between user u and i , and select top k tags for prediction. We use two approaches to compute textual similarity, one with the bag-of-words model (kNN-BoW), another with the topic model (kNN-LDA) [5].  X  One-Vs-Rest multi-label ranking [4]. We train a One-Vs-Rest multi-label classifier with bag-of-words on user X  X  tweets. Logistic regression is used as the classification method to have a probabilistic output for ranking tags.  X  Wsabie [29]. Wsabie is an embedding-based model which learns a mapping from a feature space to the joint space with the tags. Here, we train the model with WARP loss on bags-of-words of user X  X  tweets, and use the learned user and tag embeddings for ranking tags.  X  Content-based Poisson Factorization (C-PF) . This is the method where we only keep the content factor in BCPF. It can be considered a form of CTPF proposed in [10] where we treat user X  X  tweets as documents, and user X  X  known-for profiles as binary ratings. We also ignore the topic offsets since the testing users are in complete cold-start situation.  X  Geo-spatial CPF (GC-PF) . This is the method in which we keep both content and geo-spatial factor in BCPF.  X  Social influenced CPF (SC-PF) . This method keeps both content and social influence factor in BCPF.
How well does the proposed BCPF perform compared to alternative baselines? In Table 2, we report Prec@ k and Rec@ k for all methods. Overall, BCPF gives the best re-sults for all metrics and both datasets. Specifically, it gives an average improvement of 17.5% in precision and 20.9% in recall over the best content based method C-PF. This indi-cates the superiority of BCPF by exploiting geo-spatial and social influence factors other than user X  X  content.
In content-based methods, neighborhood-based methods generally provide the worst performance of all since only lo-cal information can be used in prediction. Here, LDA based kNN performs better than BoW based kNN, since LDA can take advantage of the global topic information in users X  posts. Supervised methods, however, give relatively better performance than neighborhood methods, as shown by One-Vs-Rest multi-label ranking and Wsabie. Both methods are trained with multiple labeled tags for each user on the BoW features, where Wsabie obtains embeddings for each user and tag. However, One-Vs-Rest clearly outperforms Wsa-bie, although Wsabie is more efficient and requires less com-putation time. C-PF, however, gives the best performance of all content-based methods, indicating the superiority of joint modeling by learning labeled users X  profiles on content features and unlabeled users X  texts.
 Furthermore, we can see from the table that both GC-PF and SC-PF provides better performance against only content-based C-PF, respectively. Specifically, GC-PF gives an average improvement of 8.07% in precision and 11.1% in recall, respectively. SC-PF gives an average improvement of 10.9% in precision and 11.2% in recall, respectively. This in-dicates that geo-spatial features and parameterized social in-fluence can both improve the identification of user X  X  known-for profile. Given the overall improvement of the combina-tion of these features, we can also conclude that these factors are able to complement each other.
In the modeling of geo-spatial influence on user X  X  known-for profile, we discretize the US/world area into geograph-ical regions, and treat user X  X  location as the region where she belongs. An important question here is how to select the number of regions I . As we can imagine, if I is too small, the model may not be able to reflect the geo-spatial distribution of user X  X  known-for profile; if it is too large, re-gions may be too small, thus leads to sparse observations. To that end, we select I for k -means clustering from 10 to 200, and run GC-PF with each value for ten random initial-izations of parameters. In Figure 3, we show how precision and recall changes with respect to the number of regions for both datasets. We can see that as I goes up, precision generally also increases. However, the performance plateaus when it is large. We attribute this to: first, when the num-ber of regions increases, we obtain finer-grained geo-spatial characterization of tags; second, when it is large enough, a finer-grained discretization does not help distinguish tag X  X  local distributions. It may even result in sparse counts in regions and also increases model complexity, thus degrading the final performance. Note that it requires less number of Figure 3: Box plot for precision@5 with respect to the num-ber of regions. Left: US; Right: world.
 Table 3: Top ranking tags for different areas obtained from latent location factors and tag factors.

Los Angeles D.C. SF Chicago famous people government startup marketing entertainment politico software marketer regions, i.e., larger partition of areas, for the US dataset than world to get to the best average performance. The reason is that the world data may be more diverse in terms of the geo-spatial distribution of user known-for profiles, thus requiring finer-grained geo-segments to reach the best performance. To further examine the inferred region factors, we show in Table 3 the top ranking tags associated with selected areas. In particular, we compute the affinity score between a loca-tion and a tag by taking the expected inner product of the latent factor of the location and the tag, denoted as E (  X  We can see from the table that, generally, the top ranking tags can reflect the common knowledge of the characteris-tics of those selected areas. For example, it is very likely that a user from the Washington D.C. area is well known for her political activities/comments. Thus, these inferred region factors are capable of nudging user X  X  known-for profile toward her region characteristics.
We have seen from the previous experiments that social influence plays an importance role in representing user X  X  known-for profile by looking at her connections. In order to get a further understanding of how social influence varies for different friends and tags, we consider the following meth-ods using social influence: (i) naive SC-PF (nSC-PF), where we replace  X  f with a single parameter  X  naive in Equation 6 for all friends and tags; (ii) user weighted SC-PF (uSC-PF), which models social influence by a vector of dimension M , with each element indicating the level of a friend X  X  social in-fluence for all tags (see Equation 6); and (iii) SC-PF, which models each friend X  X  social influence for every tag of hers by matrix  X  ft . We compare these methods with C-PF to see which method models social influence the best. Note that we also include the content factor as a basic representation for users since not all users have social connections. F igure 4: Comparative performance of the methods mod-eling social influence. SC-PF performs best by making it dependent on both friends and tags. Left: US; Right: world. Table 4: User X  X  inferred social influence  X  f by uSC-PF and social influence  X  ft for top ranking tags by SC-PF. @U nderTheBar 0.00290 entrepreneur health 0.0230 0.0226
A s we can see from Figure 4, overall, social connection is able to improve the performance for predicting user X  X  known-for profile. Specifically, we can make the following two con-clusions: (i) it is generally better to differentiate social in-fluence for different friends, rather than treating all friends with the same influence; (ii) it is generally better to differen-tiate social influence for different tags of each friend, rather than treating all tags of each friend with the same influence.
Table 4 shows the inferred social influence for different users and their top-ranking tags, which further exemplifies the observation that users may have different social influence on their followers with respect to different tags. In particu-lar, user @UnderTheBar shows little influence on his follow-ers X  known-for profiles even if he may have tens of thousands of followers. This indicates that users who follow @Under-TheBar are not necessarily also known for  X  X ntrepreneur X  or  X  X ealth X . On the contrary, @mollyblock has much larger social influence on her followers for her tag  X  X arketer X , in-dicating that users following @mollyblock are more likely to also be known for  X  X arketer X , even if @mollyblock has fewer followers than @UnderTheBar. One explanation for this observation is that people connect with others for dif-ferent reasons on social media, and that popularity itself is not necessarily an indicator of one X  X  social influence.
User profiling is an important task, with many efforts building user X  X  topic interests for personalized search [7, 24], targeted advertising [1] and social media systems [6, 27, 34]. For example, Dou et al. [7] built user interest profile by pre-defined topic categories for personalized webpage re-ranking. Ahmed et al. [1] proposed a statistical framework to ex-tract user X  X  dynamic interest profile for behavioral targeting. Chen et al. [6] built topic profiles of users with bag-of-words model to recommend conversations in Twitter. Zhao et al. [34] improved user X  X  topic interest profile by joint factoriza-tion of user X  X  topic matrix and behaviors. User profiles are also used to provide recommendations for online activities such as commenting on news stories [25] and mentions in micro-blogging systems [27]. Besides user X  X  topic interest profile, other works [16, 17, 23] focus on inferring user X  X  at-tribute and demographics profile such as gender and educa-tion. For example, Mislove et al. [23] proposed community detection based approaches to infer user X  X  college and ma-jor. Li et al. [16] presented a weakly-supervised approach to extract user X  X  job and education. Our work is different from the above works in that we tackle the problem of discovering what users are known for instead of user X  X  topic interests.
Contextual information in social media has been widely used in previous works [10, 13, 19, 21, 26, 28, 31, 33] to learn better user profiles and improve task performance. A seminal work by Singh and Gordon [26] proposed collective matrix factorization to simultaneously factor several matri-ces encoding contextual information for better prediction of user-movie ratings. Wang and Blei [28] proposed collabora-tive topic regression to learn latent user preference by mod-eling both ratings and content. Similarly, Gopalan et al. [10] also modeled both user X  X  ratings and content but with Poisson factorization. Jamal et al. [13] proposed a context dependent factor model to learn general latent factors of entities in social networks for better recommendation. Tem-poral information has also been used in [31] to learn both user-oriented topics and time-oriented topics. Other con-textual information used to learn user preference includes domain-specific communities [33] and social relations [19, 21] which are used to regularize latent factors between so-cially connected users. In our work, instead of using social regularization for latent factors, we learn both user and tag dependent social influence from the data with Poisson dis-tribution for fine-grained modeling of social relations.
Geographical footprints have also been widely explored in many location-based applications [12, 18, 20, 30, 32, 35]. One of the most popular applications is POI recommen-dation, where geographical influence is combined with user preference for better performance [18, 30]. Other works have used geographical influence for rating prediction in Yelp [12], activity recommendation with GPS history [35], expert rec-ommendation [20] and event-based group recommendation [32]. In contrast, we are focused on geo-spatial influence for user known-for profile discovery in social media.
In this paper, we tackled the problem of discovering what users are known for in social media. By integrating user X  X  textual, geo-spatial and social influence, we proposed Bayesian Contextual Poisson Factorization to overcome the noisiness of user X  X  posting activities and social relations. Experimen-tal results showed that BCPF can improve known-for pre-diction by 17.5% in precision and 20.9% in recall on aver-age. We also showed that user X  X  connections have varying so-cial influence for different topics, confirming our fine-grained modeling of social influence by making it dependent on both users and topics. In our future work, we are interested in exploring the impact of additional contextual signals beyond the textual, geo-spatial and social influence studied here. Acknowledgment. This work was supported in part by NSF grant IIS-1149383 and Google Research Award. Any opinions, findings and conclusions or recommendations ex-pressed in this material are the author(s) and do not neces-sarily reflect those of the sponsors. [1] A. Ahmed, Y. Low, M. Aly, V. Josifovski, and A. J. [2] X. Amatriain, N. Lathia, J. M. Pujol, H. Kwak, and [3] P. Bhattacharya, S. Ghosh, J. Kulshrestha, [4] C. M. Bishop. Pattern Recognition and Machine [5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [6] J. Chen, R. Nairn, and E. Chi. Speak little and well: [7] Z. Dou, R. Song, and J.-R. Wen. A large-scale [8] S. Ghosh, N. Sharma, F. Benevenuto, N. Ganguly, and [9] P. Gopalan, J. M. Hofman, and D. M. Blei. Scalable [10] P. K. Gopalan, L. Charlin, and D. Blei. Content-based [11] M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley. [12] L. Hu, A. Sun, and Y. Liu. Your neighbors affect your [13] M. Jamali and L. Lakshmanan. Heteromf: [14] N. Johnson, A. Kemp, and S. Kotz. Univariate [15] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and [16] J. Li, A. Ritter, and E. H. Hovy. Weakly supervised [17] R. Li, C. Wang, and K. C.-C. Chang. User profiling in [18] B. Liu, Y. Fu, Z. Yao, and H. Xiong. Learning [19] X. Liu and K. Aberer. Soco: a social network aided [20] H. Lu and J. Caverlee. Exploiting geo-spatial [21] H. Ma, H. Yang, M. R. Lyu, and I. King. Sorec: social [22] M. McPherson, L. Smith-Lovin, and J. M. Cook. [23] A. Mislove, B. Viswanath, K. P. Gummadi, and [24] F. Qiu and J. Cho. Automatic identification of user [25] E. Shmueli, A. Kagian, Y. Koren, and R. Lempel. [26] A. P. Singh and G. J. Gordon. Relational learning via [27] B. Wang, C. Wang, J. Bu, C. Chen, W. V. Zhang, [28] C. Wang and D. M. Blei. Collaborative topic modeling [29] J. Weston, S. Bengio, and N. Usunier. Wsabie: Scaling [30] M. Ye, P. Yin, W.-C. Lee, and D.-L. Lee. Exploiting [31] H. Yin, B. Cui, L. Chen, Z. Hu, and Z. Huang. A [32] W. Zhang, J. Wang, and W. Feng. Combining latent [33] X. Zhang, J. Cheng, T. Yuan, B. Niu, and H. Lu. [34] Z. Zhao, Z. Cheng, L. Hong, and E. H. Chi. Improving [35] V. W. Zheng, Y. Zheng, X. Xie, and Q. Yang.

