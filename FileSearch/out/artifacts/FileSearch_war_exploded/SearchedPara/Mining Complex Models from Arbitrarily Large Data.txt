
In this paper we propose a scaling-up method that is applica-ble to essentially any induction algorithm based on discrete search. The result of applying the method to an algorithm is that its running time becomes independent of the size of the database, while the decisions made are essentially iden-tical to those that would be made given infinite data. The method works within pre-specified memory limits and, as long as the data is iid, only requires accessing it sequen-tially. It gives anytime results, and can be used to produce batch, stream, time-changing and active-learning versions of an algorithm. We apply the method to learning Bayesian networks, developing an algorithm that is faster than previ-ous ones by orders of magnitude, while achieving essentially the same predictive performance. We observe these gains on a series of large databases "generated from benchmark net-works, on the KDD Cup 2000 e-commerce data, and on a Web log containing 100 million requests. 
H.2.8 [Database Management]: Database Applications--data mining; 1.2.6 [Artificial Intelligence]: Learning--in-duction; 1.5.1 [Pattern Recognition]: Models--statistical; 1.5.2 [Pattern Recognition]: Design Methodology--clas-
Scalable learning algorithms, subsampling, Hoeffding bounds, discrete search, Bayesian networks ing and statistical algorithms to large databases. The goal is generally to obtain algorithms whose running time is linear (or near-linear) in the size of the database, and that only ac-cess the data sequentially. So far this has been done mainly permission and/or a fee. SIGKDD 02 Edmonton, Alberta, Canada 
Copyright 2002 ACM 1-58113-567-X/02/0007 ...$5.00. for one algorithm at a time, in a slow and laborious process. 
We believe that this state of affairs can be overcome by de-veloping scaling methods that are automatically (or nearly automatically) applicable to broad classes of learning algo-rithms, and that scale up to databases of arbitrary size by limiting the quantity of data used at each step, while guar-anteeing that the decisions made do not differ significantly from those that would be made given infinite data. This paper describes one such method, based on generalizing the ideas initially proposed in our VFDT algorithm for scaling up decision tree induction [3]. The method is applicable to essentially any learning algorithm based on discrete search, where at each search step a number of candidate models or model components are considered, and the best one or ones are selected based on their performance on an iid sample from the domain of interest. Search types it is applicable to include greedy, hill-climbing, beam, multiple-restart, looka-head, best-first, genetic, etc. It is applicable to common al-gorithms for decision tree and rule induction, instance-based learning, feature selection, model selection, parameter set-ting, probabilistic classification, clustering, and probability estimation in discrete spaces, etc., as well as their combina-tions. up Bayesian network learning [8]. Bayesian networks are a powerful method for representing the joint distribution of a set of variables, but learning their structure and parameters from data is a computationally costly process, and to our knowledge has not previously been successfully attempted on databases of more than tens of thousands of examples. 
With our method, we have been able to mine millions of examples per minute. We demonstrate the scalibility and predictive performance of our algorithms on a set of bench-mark networks and on three large Web data sets.  X  classifiers A and B, and an infinite database of iid (inde-pendent and identically distributed) examples. We wish to determine which of the two classifiers is more accurate on the database. If we want to be absolutely sure of making the correct decision, we have no choice but to apply the two classifiers to every example in the database, taking infinite time. If, however, we are willing to accommodate a prob-ability 5 of choosing the wrong classifier, we can generally make a decision in finite time, taking advantage of statis-e, where E =  X  ~ Let ~ be the difference in ac-
The only case in which this procedure does not yield a 
The Hoeffding bound has the very attractive property 
Suppose now that, instead of two classifiers, we wish to 
Suppose now that we wish to find the best classifier by a 
In general, we do not know in advance how many examples 
Notice that nothing in the treatment above requires that 
The key properties of this method are summarized in the = c~, and U be the first terminating condition of the 
THEOREM 1. If ts~l &gt; teen and ITI &gt; c~xn, the time 
In other words, the running time of the modified algorithm Table 1: Method for scaling up learning algorithms. of the search steps, the model produced is, with probability 1 ~*, the same that would be produced with infinite data. 
An alternative use of our method is to first choose a maxi-mum error probability ~ to be used at each step, and then re-port the global error probability achieved, 5" = 5 ~i~=1 cciai (bi ai), where ci is the number of goal checks performed in step i, bl is the number of candidates considered at that step, and ai is the number selected. Even if 5 is computed from c, b, a and the desired J* as in Table 1, reporting the actual achieved 5" is recommended, since it will often be much better than the original target. 
Further time can be saved by, at each step, dropping a candidate from consideration as soon as its score is lower than at least a others by at least f(n,5*/[cda(b 
SelectCandidates(.h4) is an anytime procedure in the sense that, at any point after processing the first An examples, it is ready to return the best a candidates according to the data scanned so far (in increments of An). If the learning algorithm is such that successive search steps progressively refine the model to be returned, L* itself is an anytime pro-cedure. 
The method in Table 1 is equally applicable to databases (i.e., samples of fixed size that can be scanned multiple times) and data streams (i.e., samples that grow without limit and can only be scanned once). In the database case, we start a new scan whenever we reach the end of the database, and ensure that no search step uses the same ex-ample twice. In the data stream case, we simply continue scanning the stream after the winners for a step are chosen, using the new examples to choose the winners in the next step, and so on until the search terminates. 
When learning large, complex models it is often the case that the structure, parameters, and sufficient statistics used by all the candidates at a given step exceed the available memory. This can lead to severe slowdowns due to re-peated swapping of memory pages. Our method can be easily adapted to avoid this, as long as m &gt; a, where m is the maximum number of candidates that fits within the available RAM. We first form a set .Mr composed of any add another m a candidates to the a selected, yielding way until .M is exhausted, returning the a candidates se-lected in the last iteration as the overall winners. As long as all calls to SelectCandidates 0 start scanning S at the same example and ties are broken consistently, these win-ners are guaranteed to be the same that would be obtained by the single call SelectCandidates(J~). If k iterations are carried out, this modification increases the running time of SelectCandidates(/~4) by a factor of at most k, with k &lt; b. Notice that the "new" candidates in each .A41 do not need to thus they never need to be swapped to disk. 
The running time of an algorithm scaled up with our method is often dominated by the time spent reading data from disk. When a subset of the search steps are indepen-dent (i.e., the results of one step are not needed to perform the next one, as when growing the different nodes on the fringe of a decision tree), much time can be saved by us-ing a separate search for each independent model compo-nent and (conceptually) performing them in parallel. This means that each data block needs to be read only once for all of the interleaved searches, greatly reducing I/O require-ments. When these searches do not all fit simultaneously into memory, we maintain an inactive queue from which steps are transferred to memory as it 'becomes available (be-cause some other search completes or is inactivated). 
The processes that generate massive data sets and open-ended data streams often span months or years, during which the data-generating distribution can change significantly, violating the iid assumption made by most learning algo-rithms. A common solution to this is to repeatedly apply the learner to a sliding window of examples, which can be very inefficient. Our method can be adapted to efficiently ac-commodate time-changing data as follows. Maintain ~(M) throughout time for every candidate M considered at ev-ery search step. After the first w examples, where w is the window width, subtract the oldest example from ~2(M) whenever a new one is added. After every An new exam-ples, determine again the best a candidates at every previ-ous search decision point. If one of them is better than an old winner by J*ls (s is the maximum number of candidate 527 comparisons expected during the entire run) then there has probably been some concept drift. In these cases, begin an alternate search starting from the new winners. Periodically use a number of new examples as a validation set to compare the performance of the models produced by the new and old searches. Prune the old search when the new models are on average better than the old ones, and prune the new search if after a maximum number of validations its models have failed to become more accurate on average than the old ones. If more than a maximum number of new searches is in progress, prune the lowest-performing ones. This ap-proach to handling time-changing data is a generalization of the one we successfully applied to the VFDT decision-tree induction algorithm [11]. 
Active learning is a powerful type of subsampling where the learner actively selects the examples that would cause the most progress [1]. Our method has a natural exten-sion to this case when different examples are relevant to different search steps, and some subset of these steps is in-dependent of each other (as in decision tree induction, for example): choose the next An examples to be relevant to the step where U is currently farthest from being achieved (i.e., where f(n,~*/[cda(b a)]) minij{max(r,E(Mi,T') E(Mj, T')}} is highest). 
In the remainder of this paper we apply our method to learning Bayesian networks, and evaluate the performance of the resulting algorithms. 
We now briefly introduce Bayesian networks and meth-ods for learning them. See Heckerman et al. [8] for a more complete treatment. A Bayesian network encodes the joint probability distribution of a set of d variables, {xl .... , as a directed acyclic graph and a set of conditional probabil-ity tables (CPTs). (In this paper we assume all variables are discrete.) Each node corresponds to a variable, and the CPT associated with it contains the probability of each state of the variable given every possible combination of states of its parents. The set of parents of xl, denoted par(xi), of nodes with an arc to xi in the graph. The structure of the network encodes the assertion that each node is condition-ally independent of its non-descendants given its parents. Thus the probability of an arbitrary event X = (xl,..., xd) eral, encoding the joint distribution of a set of d discrete variables requires space exponential in d; Bayesian networks reduce this to space exponential in maxie(1,...,d} 
In this paper we consider learning the structure of Bayesian networks when no values are missing from training data. A number of algorithms for this have been proposed; perhaps the most widely used one is described by Heckerman et al. [8]. It performs a search over the space of network struc-tures, starting from an initial network which may be ran-dom, empty, or derived from prior knowledge. At each step, the algorithm generates all variations of the current network that can be obtained by adding, deleting or reversing a sin-gle arc, without creating cycles, and selects the best one al. [8]). The search ends when no variation achieves a higher score, at which point the current network is returned. This algorithm is commonly accelerated by caching the many re-dundant calculations that arise when the BD score is applied to a collection of similar networks. This is possible because the BD score is decomposable into a separate component for each variable. ]In the remainder of this paper we scale up Heckerman et aL's algorithm, which we will refer to as HGC throughout. 
At each search step, HGC considers all examples in the training set T when computing the BD score of each candi-date structure. Thus its running time grows without limit as the training set size ITI increases. By applying our method, HGC's running time can be made independent of ITI, for ITI &gt; f l(r,a), with user-determined r and 6. In order to do this, we must first decompose the BD score into an average of some quantity over the training sample. This is made possible by taking the logarithm of the BD score, and discarding terms that become insignificant when n ~ oo, be-cause the goal is to make the same decisions that would be made with infinite data. This yields (see Hulten &amp; Domin-gos [10] for the detailed derivation): where xi, is the value of the ith variable in the eth example, and P(xi,lpar(xi,)) is the maximum-likelihood estimate of the probability of xi~ given its parents in structure S, equal to nljk/nlj if in example e the variable is in its kth state and its parents are in their jth state. Effectively, when n ~ co, the log-BD score converges to the log-likelihood of the data given the network structure and maximum-likelihood pa-rameter estimates, and choosing the network with highest BD score becomes equivalent to choosing the maximum-likelihood network. The quantity ~ia=x log P(xi~ IS, par(xl,)) is the log-likelihood of an example X~ given the structure S and corresponding parameter estimates. When comparing two candidate structures $1 and $2, we compute the mean difference in this quantity between them: Notice that the decomposability of the BD score allows this computation to be accelerated by only considering the com-ponents corresponding to the two or four variables with dif-ferent parents in $1 and $2. We can apply either the normal bound or the Hoeffding bound to ~xL(S1, Sz). In order to ap-ply the Hoeffding bound, the quantity being averaged must have a finite range. We estimate this range by measuring the minimum non-zero probability at each node P~ and use 
After the structure is learned, the final nljk and must be estimated. In future work we will use the bound  X  from [6] to determine the needed sample size; the current al-gorithm simply uses a single pass over training data. Togeth-er with the parameters of the Dirichlet prior, these counts induce a posterior distribution over the parameters of the network. Prediction of the log-likelihood of new examples is 3A value may have zero true probability given some parent state, but this is not a problem, since such a value and parent combination will never occur in the data. better than VFBNi's by at least an order of magnitude in each experiment. This was caused by VFBNi's redundant search forcing it to remake many decisions, thus requiring that many more statistical bounds hold. We also ran HGC on a random sample of 10,000 training examples. This vari-ation always had worse likelihood than both VFBN1 and 
VFBN2. It also always spent more time learning structure than did VFBN2. nificantly on the initial networks, and to learn networks with likelihoods similar to those of the true networks. Not sur-prisingly, we found that many more changes were required to learn large networks than to learn small ones (on these, 
VFBN2 made between 566 and 7133 changes to the prior networks). Since HGC and VFBN1 require one search step for each change, this suggests that even with sufficient RAM they would learn much more slowly compared to VFBN2 than they did on the small networks. We watched the ac-tive set and inactive queue during the runs on the large data sets. We found the proportion of searches that were active was high near the beginning of each run. As time progressed, however, the size of the CPTs being learned tended to in-crease, leaving less room for searches to be active. In fact, during the majority of the large network runs, only a small fraction of the remaining searches were active at any one time. Recall that VFBN1 and HGC can only run when all remaining searches fit in the active set. For these networks the 200 MB allocation falls far short. For example, on a typ-ical run on a large network we found that at the worst point only 1.31% of the remaining searches were active. Assuming they all take about the same RAM, HGC and VFBN1 would have required nearly 15 GB to run. 
Web Applications In order to evaluate VFBN2's perfor-mance on large real-world problems, we ran it on two large Web traces. The first was the data set used in the KDD 
Cup 2000 competition [12]. The second was a trace of all requests made to the Web site of the University of Wash-ington's Department of Computer Science and Engineering between January 2000 and January 2002. collected from an e-commerce site. Each request is anno-tated with a requester session ID and a large collection of attributes describing the product in the requested page. We focused on one of the fields in the log, "Assortment Level 4", which contained 65 categorizations of pages into product types (including "none"). For each session we produced a training example with one Boolean attribute per category -"True" if the session visited a page with that category. 
There were 235,000 sessions in the log, of which we held out 35,000 for testing. from a log of every request made to our department's Web site between late January 2000 and late January 2002. The log contained on the order of one hundred million requests. 
We extracted the two training sets from this log in a manner very similar the KDD Cup data set. For the first we iden-tiffed the 80 most commonly visited level two directories on 
For the second we identified the 400 most commonly vis-ited Web objects (excluding most images, style sheets, and scripts). In both cases we broke the log into approximate sessions, with each session containing all the requests made 
Table 2: Empirical results. Samples is the total number of examples read from disk while learn-ing structure, in millions. Times in bold exceeded our five day limit and the corresponding runs were stopped before converging. by a single host until an idle period of 10 minutes; there were 8.3 million sessions. We held out the last week of data for testing. 
HGC. HGC ran for nearly five days on the other two data sets, while VFBN2 took less than 20 minutes for each. The systems achieved similar likelihoods when they could run, and always improved on their starting network. Examining the networks produced, we found many potentially interest-ing patterns. For example, in the e-commerce domain we found products that were much more likely to be visited when a combination of related products was visited than when only one of those products was visited. analysis [17], which determines at runtime the number of examples needed to satisfy a given quality criterion. Other recent examples of this approach include Maron and Moore's 
