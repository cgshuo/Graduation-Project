 Recent years, more and more shopping websites have employed recommender systems to help improve shopping experience for customers. A functional recom-mendation algorithm should tell sellers whether or not a user prefers an item, and it is more valuable if the algorithm can discover the reason for users X  preferences. Traditional recommendation techniques usually only based on rating scores. For example, a recommender system may recommend a new movie to a certain user considering the ratings the user given to other movies previously, but the review texts the user wrote are typically ignored. Although this approach have gained success to some extend, due to the ignorance of review information, it cannot give reasonable explanations for users X  behavior. Especially, it cannot tell us the interaction between user X  X  preferences and item X  X  features.
 Customers always express mixed emotions at items due to their attitude towards different items X  features. For example, maybe a user likes the size of a telephone X  X  screen, and prefers the brand but has no interest in the color. This diverse meaning cannot be digged out by rating information simply. A rating score can only reflect a customer X  X  overall impression on a product, but the subtle emotion beneath the rating information cannot be revealed, so this is a big drawback of recommendation algorithms that only based on rating scores. benefits of leveraging review texts to promote recommendation performance. However, due to the complexity of natural language and the rich information the review texts may contain, it is still a challenging task to extract effective information from review texts for recommendation task. Different from other text processing fields, review comments usually contain much emotional infor-mation, and customers always express their opinions on products by writing comments. Therefore, understanding the subjectivity of the review texts is the main point for such approach. Most existing works try to combine latent topic factors found by topic models such as Latent Dirichlet Allocation (LDA) [ 3 ], but the improvements are modest.
 log-bilinear document model [ 8 ]. Specifically, we state the following two points: First, we assume the review texts and ratings are consistent and both of them are determined by users X  or items X  latent space. Then the review texts and rating information can be directly linked together through users X  and items X  dimensions. Second, we adopt a modified log-bilinear document model to exploit the coher-ence of topics in each comments. This is a probabilistic model with log-bilinear energy function to model the bag of words distribution of a document. Previous experiments [ 8 ] proved that the log-bilinear document model is more powerful than LDA in capturing word semantic and sentiment features.
 items X  latent space into the semantic space. By this correlation, the latent fac-tors can have a correspondence with the topics revealed by review texts. Different from other methods, we assume each user and item has a sentiment space respec-tively, and we map the latent factor space to the semantic word space directly and causally, making the model more effective and explainable. The experimental results on 9 real-world datasets show that our algorithm gains real improvement on prediction performance comparing to the state-of-the-art models. Recommender techniques can be roughly classified into two categories: content-based filtering systems try to use content information such as users X  profiles, review texts and item tags. The methods based on collaborative filtering can be classified into neighborhood based algorithms and latent factor models [ 4 ]. Neighborhood based methods usually recommend an item to a user based on the behavior of similar users, and it is common to use rating information to find people who have the same interest. The latent factor based models denote users X  and items X  latent factors as vectors, and the product of certain element of the user X  X  vector and item X  X  vector reflects the user X  X  preference for the corresponding item X  X  feature. The most popular methods to learn the latent vectors are matrix factorization [ 10 ] and non-negative matrix factorization methods [ 6 ]. In order to provide more flexible models, more and more works try to combine contend-based methods and collaborative filtering techniques for better recom-mendation performance. Among them, the combination of rating information and review texts receives more and more attentions. In the early work, [ 12 ]pro-poses a probabilistic graphical model called CTR, which first defines a document as the set of all reviews of an item and then uses the LDA model to learn the topic similarity between each document.
 Inspired by CTR, two related models (i.e., HFT and RMR) try to combine the topic factors with the latent user factors or latent item factors in different ways. Different from CTR, HFT [ 9 ] supposes that the latent factors are directly mapped to the topic vectors in LDA rather than by a sampling process. RMR [ 7 ] assumes users X  latent space is correspondent to a mixture of Gaussian distri-butions and the ratings are sampled from a Gaussian mixture model.
 To give each user or item a semantic space, researchers recently treat each review text as a document. SUIT [ 13 ] supposes user, item and topic latent factors co-determine each rating and then uses tensor factorization to learn the model. However, since all three factors are at the same level, it ignores the causal rela-tionships among them and the model is hard to explain. In another work [ 2 ], the authors propose a model called topicMF. Like HFT and our work, it maps users X  and items X  latent space to the semantic space. The difference is that it uses nonnegative matrix factorization to learn topic factors, a primary drawback of this approach is the time complexity, hence it does not scale well and is not suitable for real-world large datasets. In this section, we first give the notations, then briefly address latent factor models. 3.1 Notations We assume that there are N users and M items in the datasets. U V  X  R M  X  K and  X   X  R K  X  L are user, item and topic factor matrix respectively, where K denotes the number of latent dimensions of each user, item and review text. K is a free parameter and can be set manually, a larger K means the user and item latent factors can carry richer information, and meanwhile each review text can be represented by a more detailed topic weightings.
 We denote each user and item as u and i , meanwhile the corresponding latent vector is denoted by U u and V i respectively (i.e., the row vector of U and V ). The rating score that user u gives to item i is R ui . The review text given by user u to item i is represented as d ui and the review texts collection is denoted as D . The topic distribution vector of a particular review text is  X  corresponding vector in  X  .
 text contains is represented as N ui .Weuse k to denote words X  index in the corresponding review text. And  X   X  R K  X | W | is a word representation matrix denotes the words X  association strength with respect to each latent topic dimen-sion, where | W | is the vocabulary size. The notations are shown in Table 1 . 3.2 Latent Factor Models Latent factor models use the low dimensional latent factors of users and items to approximate the rating matrix and then use the latent factors to predict ratings that are missed in the original rating matrix. It assumes that the preference of a user u for an item i can be denoted as a product of their latent factors: U Then the rating matrix can be estimated by the product of the two low-rank latent matrices: R = UV T . Many latent factor models further add user bias term b and item bias term b i to offset local effects. The optimization function is where  X  is the global mean rating value and the regularization term  X  is  X  ization parameters for the purpose of avoiding over-fitting. Various optimization algorithms have been developed to find optimal solutions of U and V [ 5 ]. In this section we introduce a new model called Log-Bilinear Matrix Factoriza-tion (LBMF). It is based on the log-bilinear document model, however these two methods have some intrinsic differences in modeling review texts. LBMF integrates rating scores and review texts simultaneously and naturally, thus this approach enables the latent dimensions have clearer interpretations, meanwhile this implication can have some practical meanings which we will analyze in detail. 4.1 Log-Bilinear Document Model Log-bilinear document model [ 8 ] is a probabilistic model for learning semantic word vectors. It maps  X  d to each word w in the corresponding document and assumes that words in a document are conditionally independent given the mix-ture variable  X  d . Here  X  d is the semantic space and can be regarded as a weighting over topics. Different from LDA,  X  d is not sampled from Dirichlet distribution. Log-bilinear document model [ 8 ] uses a Gaussian prior on  X  text d ui , it assumes each word w k  X  d ui is conditionally independent of other words in d ui given  X  ui and w k depends on  X  ui directly. The probability of the review text is given by: where d ui denotes the review text of user u given to item i . N of words in d ui and w k is the k -th word in d ui . Here p ( w log-linear model. It has two parameters:  X   X  R K  X | W | is a semantic-word matrix like LDA, and b w  X  R is bias for the word w in the vocabulary W , which captures local features of each word.
 The energy assigned to a word w given these model parameters is: where  X  w =  X w is a K dimensional vector related to the corresponding word X  X  column in  X  . w is represented as a one-on vector, where for the k -th word w Then it uses softmax to represent p ( w |  X  ui )as: direction of  X  ui better, then its occurrence probability is higher in the corre-sponding review text. The log-bilinear document model aims to capture word representations and further to discover semantic and topic information. It can be employed in the field of sentiment analysis and subjectivity detection. 4.2 LBMF In LBMF, we try to mine features and preferences information buried in review texts and utilize the information to enforce better learning of user latent dimen-sions and item latent dimensions. Different from previous works, we use direct mappings from user and item latent dimensions to the topic dimensions, and meanwhile the topic dimensions of each review text have a direct correlation with each word in the corresponding review text as the log-bilinear document model, hence the user and item latent dimensions can be more interpretable. The review texts information serves as a regulariser for the rating values, each word given by user u for item i can regularize the latent factor models, thus the latent user and item dimensions can embody textual information.
 or item latent space. It is based on the fact that the users X  preferences or items X  features determine both ratings and review texts, which is more reasonable than CTR and HFT. The mapping function needs to be monotonic, since a large U uk or V ik should corresponds to a larger  X  kui , which means the corresponding feature or preference is talked more frequently in the review text. So we define it as a softmax function: Specifically, | U uk | describes the user X  X  level of interest at the dominant proper-ties of the item and | V ik | denotes that whether or not the item possesses the corresponding property. To consider the negative values is critical, a large neg-ative value may indicates that the user talks certain features of the item a lot in the review text but in a negative attitude. By this transformation,  X  weighting of topic k .And k 1 and k 2 are introduced to moderate the proportions of users X  and items X  affect.
 mapping topic dimensions into latent user space or latent item space separately. We propose two new algorithms called LBMFu and LBMFi. The mapping rela-tions are defined as: We can regard LBMFu and LBMFi as special cases of LBMF.
 Different from the log-bilinear document model, by Eqs. 4 and 5 , we correlate each word distribution to user latent dimensions { U u } N sions { V the log-bilinear document model, we confine  X  in the unit simplex, hence  X  can be regarded as a distribution over topics, thus endow  X  with a clearer interpreta-tion. Our model aims at learning semantic and topic information in review texts rather than sentiment information directly as the log-bilinear document model does. To capture the rating coherence, we use probabilistic matrix factorization proposed in [ 10 ]. Given the rating set { R ui } and review texts collection D ,we assume each document and rating is i.i.d sampled, then we wish to learn the parameters { U u } N 1 , { V i } M 1 , { b u } , { b i } , In LBMF, { U u } N 1 and { V i } M 1 determine rating values and word distributions simultaneously, thus the latent user or item vectors correspond to features or preferences information. Since word distributions in the corresponding review text reflect this inexplicit features or preferences information exactly, it is sen-sible to use word distributions information to regularize the rating prediction models. The word distributions embody the textual information, which endow the latent user or item dimensions with clearer implications. This intuition moti-vates LBMF to substitute the log-likelihood of the review collection for the  X  in the latent factor models to promote better recommendation results. The objec-tive optimization function is defined as: tion of the review collection.
 Since  X  ui is directly determined by U u and V i , we can substitute integral. Then Eq. 8 can be approximated as where  X  is introduced to balance the affect of the two components. A larger  X  means the word distributions regularize the latent factor models more heavily. In the following derivations, we set  X  to 1 for clarity. Since  X  mine by U u and V i , we substitute Eq. 5 into Eq. 9 . Hence the optimization para-meters here are U , V ,  X  , k 1 , k 2 and bias parameters. We optimize LBMF based on gradient descent (GD) by computing the corresponding gradients given Eq. 9 : Where w k is a one-hot vector indicating the selected word representation vec-tor and we add a regularization term for  X  . The optimization procedures for LBFMu and LBMFi are similar to LBMF so we omit them, and the optimiza-tion equations of user and item bias parameters are also omitted due to space limitation.
 LBMF regards each review text as a document which is more sensible than CTR and HFT, in which review texts are combined for each users or items. Since users have inherent bias towards different features of items, it is not reasonable to com-bine all the review texts of a item to model a given user X  X  preferences. This can account for our model X  X  effectiveness over CTR and HFT partly. Furthermore, the mapping relation we adopted link  X  ui and latent user or item dimension is more reasonable than CTR and HFT.
  X  ui defines a distribution over a variety of topics. Meanwhile,  X  by latent user and item factors, hence this transformation can bridge the gap between review texts and rating scores. On the one hand, word distributions indicates topics diversity and the variety of individual preferences information, and on the other hand each word in review texts can shape the latent user and item factors, in other words, the user and item latent dimensions correlate with the word distributions via the features and preferences information, thus the learned latent user and item factors are robust and interpretable. The utilization of the log-bilinear document model rather than LDA is critical. Since most of the review texts are short and sparse, we doubt about the effectiveness of LDA for such learning task. Compared with SUIT, we presume that topics and preferences information are determined by the latent user dimensions and item dimensions rather than a tensor outer product approach. In this section, we investigate the performance of our model for recommendation task. We train our model on several large real-world datasets collected from Amazon.com to tune the parameters. The description of the datasets can be found in [ 9 ] and we omit it due to the space limitation. 5.1 Compared Algorithms We implement several baseline models for comparison. We list the models below and give simple summaries.
 PMF: This is the traditional matrix factorization model which only models ratings.
 HFT: This is the state-of-the-art method that models ratings and reviews simultaneously. HFT combines matrix factorization model with LDA to explore the rich information in review texts that can enhance the performance of the rating prediction.
 CTR: This model focuses on recommending scientific articles to potential readers. CTR utilizes rating scores and review texts simultaneously. The key property of CTR lies in how the item vector is generated. By adjusting the pre-cision parameter c , CTR can solve the one-class collaborative filtering problem. SUIT: SUIT is a new supervised user-item based topic model, which utilizes the textual topics and latent user-item factors simultaneously. The model uses tensor outer product of text topic proportion vector, user latent factor and item latent factor to model the sentiment label generalization.
 TopicMF-AT: This model is proposed in [ 2 ]. It incorporates the nonnegative matrix factorization with the standard matrix factorization model. It adopts the NMF to uncover hidden topics information in review texts. Both user latent vectors and item latent vectors are correlated with the topic factors via an expo-nential transform function analogous to the one adopted by HFT.
 RMR: This method is recently proposed in [ 7 ]. It employs a model similar to LDA to explore interpretable topics to improve performance of rating prediction. It uses a mixture of Gaussian distributions rather than matrix factorization based methods. The item is modeled as a distribution of topics, together with the user-topic specific Gaussian distributions, determine how a user would rate an item.
 5.2 Evaluation We first evaluate rating prediction performance of various models. For each dataset we randomly select 80 % as training set and the remaining parts are evenly split into validation set and testing set. We adopt mean squared error (MSE) to evaluate our model and baseline models, a lower MSE on the test set indicates better rating prediction performance. We report the MSE of the test set which has the lowest MSE on the validation set. The initial parameters are randomly assigned. For all the models, across various datasets, the latent dimension K is set to 5. To assess the parameter sensitivity, we assign the latent dimension K to a variety of values later. We set all the regularization parameters to 0.01 and the learning rate to 0.001. The training of compared baseline models follow the same parameter settings. For our results, the balance parameter is set to 1. Other choices are also considered for the purpose of parameter sensitivity analysis. 5.3 Rating Prediction Rating prediction task is to predict the rating values that users have not rated yet on the test set. Experimental results in terms of MSE are shown in Table 2 , where the best performance result is in bold font. The main points and observations from the performance comparison include: (1) The last eight models (CTR, HFT, TopicMF, SUIT, RMR, LBMF, LBMFu, (2) LBMF achieves the most accurate rating prediction on almost all the 5.4 Parameter Sensitivity We also examine the parameter sensitivity of our model on three datasets: Arts , Jewelry , Industrial &amp; Scientif ic . The two important parameters of our model are the latent dimension k and the balance parameter  X  . First we keep  X  fixed, ferent k s, which indicates our method is insensitive to different dimensions. This is different from conventional latent factor models, which tend to perform better The results of Fig. 1 (b) show that although we set  X  to different values, the model performance is consistent on different datasets, indicating that our algorithm is not sensitive to  X  . In this paper, we have presented a novel recommendation algorithm called Log-Bilinear Matrix Factorization (LBMF). LBMF can predict ratings that users have not yet conducted on relative products. LBMF also suits other tasks such as word representation learning, alleviating the cold-start problem and find-ing helpful reviews. Extensive experiments show the effectiveness and efficiency of our approach comparing to the state-of-the-art methods. Future works are needed in capturing personalization information and exploring other application scenarios.

