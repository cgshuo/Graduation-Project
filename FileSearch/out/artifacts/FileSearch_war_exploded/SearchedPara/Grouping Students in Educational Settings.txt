 Given a class of large number of students, each exhibiting a different ability level, how can we group them into sec-tions so that the overall gain for students is maximized? This question has been a topic of central concern and de-bate amongst social scientists and policy makers for a long time. We propose a framework for rigorously studying this question, taking a computational perspective. We present a formal definition of the grouping problem and investigate some of its variants. Such variants are determined by the desired number of groups as well as the definition of the gain for each student in the group.

We focus on two natural instantiations of the gain func-tion and we show that for both of them the problem of identifying a single group of students that maximizes the gain among its members can be solved in polynomial time. The corresponding partitioning problem, where the goal is to partition the students into non-overlapping groups appear to be much harder. However, the algorithms for the single-group version can be leveraged for solving the more complex partitioning problem. Our experiments with generated data coming from different distributions demonstrate that our al-gorithm is significantly better than the current strategies in vogue for dividing students in a class into sections. H.2.8 [ Database Management ]: Database Applications-Data Mining Clustering; Partitioning; Teams; Groups; Large Classes; Mas-sive Courses; MOOC
That good education is critical for enhancing societal growth and individual prosperity is a widely accepted tenet [18, 33]. While the problem of providing high quality education is multi-faceted and complex [8, 14], one particu-lar problem that has vexed social scientists and policy mak-ers for a long time is how to create groupings of students so that they can augment their learning from the teacher with cooperative learning from each other [3, 30, 32]. Two pop-ular strategies are to group students either homogeneously (stratified by ability level, so low-ability students are in one section, high-ability students in another) or heterogeneously (students of all ability levels in one section) [11, 27]. The verdict from the empirical studies on which of these is more effective is inconclusive [15, 20, 29]. The public sentiment toward these strategies has also swayed back and forth over the years [7, 24].

We endeavour to rigorously study the problem of grouping students in a class, by taking a computational perspective. We consider a setting in which groupings are decided on per subject basis for students within a class. Each student i is associated with ability  X  i  X  [0 , 1] in the corresponding subject. The ability  X  i can be estimated by administering a test designed using modern practices such as those based on item response theory [9, 16]. Students are able to increase their abilities through interactions and collaborations with more capable peers [19, 31]. The higher ability members also gain as teaching others and giving help has been shown to be positively correlated to increase in ability [5, 32]. We thus strive to form groups such that the overall gain for students is maximized.

We present a formal definition of the grouping problem and describe several of its variants. More specifically, we consider two high-level problems: the 1-Group and the  X  -Groups problem. In the former, the goal is to identify a single group from a large set of students such that the gains of the students constituting the group is maximized. In the latter, the goal is to partition a large set of students into smaller groups of approximately the same size such that the sum of the gains of all groups is maximized. Clearly, dif-ferent definitions of  X  X ain X  lead to different instantiations of the 1-Group and the  X  -Groups problems.

We consider two types of gain functions  X  each formal-izing different viewpoint. The first maximizes the number of students who improve their abilities by interacting with the higher ability students, while the second incorporates the extent of these improvements. Thus, the former maxi-mizes the number of students that benefit, while the latter is geared towards pulling up the weakest students as much a s possible. Depending upon the social goal the school is pursuing, it can accordingly choose the gain function.
For both these functions, we show that the 1-Group prob-lem can be solved optimally in polynomial time. For lack of optimum algorithms for the  X  -Groups version, we provide effective heuristics. Our experimental evaluation with gen-erated data demonstrates that our design yields groupings that beat the current strategies. The experiments with dif-ferent distributions of abilities of students demonstrate that this superior performance is independent of the underlying distribution of the abilities of the students.
 Roadmap: The rest of the paper is organized as follows. After reviewing the related work in Section 2, we formally define our framework in Section 3. In Sections 4 and 5, we describe the two problem variants we study and their corre-sponding algorithms. In Section 6, we describe our experi-ments. Finally, we conclude with a summary and directions for future work in Section 7.
Although their importance in the educational process has been identified by educators and social scientists alike, to the best of our knowledge we are the first to introduce the formulations for computationally addressing the problem of grouping students. Naturally, the nature of our problem is related to a large body of work both in the domain of education as well as computer science. We review some of this work below.
 Cooperative learning: The origins of the cooperative learning theory can be traced back to at least as early as the 1937 work of May and Doob who found that people who worked together were more successful in attaining the same goals than those who worked independently [26]. Mod-ern cooperative learning theory is heavily influenced by the Vygotsky X  X  idea of co-construction, central to which is the notion of the zone of proximal development (ZPD)  X   X ... the distance between the actual developmental level as de-termined by independent problem solving and the level of potential development as determined through problem solv-ing under adult guidance or in collaboration with more ca-pable peers X  [31]. In our formulation, ZPD for a student can be thought of as the distance between the student X  X  ability and that of the group. One of our objective is striving to maximize the number of students who are able to increase their ability to the group level, while the other maximizes the total increase in the ability of the group members. Forming teams of experts: Recently, there has been a lot of work on the formation of teams of experts whose goal is to complete a given project task [1, 2, 12, 21, 22, 25]. In these settings, experts are viewed as multi-dimensional vec-tors describing the expertise of individuals across different aspects. Then the goal is to select a team that best fits the task at hand. In contrast, our students are described by 1-dimensional values  X  namely their ability in the subject. Moreover, our goal is not to find a single team that can com-plete a specific task, but to partition the given set of students into teams from which their performance can benefit. These differences in the respective settings lead to different compu-tational problems as well, and therefore the algorithms used for existing team-formation formulations cannot be used for our setting.
 Clustering: At a high level, the  X  -Groups version of our problem can be also viewed as a classical clustering prob-lem [17]; afterall, in both cases the goal is to partition an input set of objects. Although in many of these clustering problems each cluster is represented by the average of the points in the cluster (exactly as in our setting) their goal is to find a partitioning that minimizes the sum of the distances of each points to its corresponding average. On the other hand, in our  X  -Groups problem the goal is to maximize the number of students that are below the corresponding aver-age. This difference in the objective functions makes our problem distinct from existing work on clustering. Specifi-cally, many of the existing clustering problems are solvable in polynomial time for dimensionality 1, while some ver-sion of our  X  -Groups problems appear to be NP-hard even though our input consists of 1-dimensional points.
Assume there is a population of n students S = { 1 , . . . , n } , studying a particular subject. Each student i is associated with ability  X  i  X  [0 , 1] (determined using techniques such as item response theory [9, 16]). For simplicity, we will assume that the students have distinct abilities and they are ordered in decreasing order of their abilities, i.e.,  X  1 &gt;  X  2
We will be interested in forming groups of students T  X  S , such that students on average benefit by their participation in T . In order to quantify the benefit that a group provides to its members, we need to define the collective ability b of a group T . Following [28], we assume that the collective ability of a group T  X  S is the average ability level of its members. That is, b  X  T = 1 / | T |
We consider the collective ability b  X  T of a group as being an important characteristic of the group. More specifically, the collective ability b  X  T of a group T partitions the members of T into two sets: the leaders and the followers . The set of leaders L T of group T are all the members of T with ability above b  X  T . That is, Similarly, the set of followers F T of group T are all the mem-bers of T with ability below b  X  T . That is, When the group T is clear from the context, we drop the subscript T when referring to the set of leaders and followers of T .

The participation in a group amplifies both the leaders and the followers. If we use function A f ( i, T ) (resp. A to denote the gain of a follower (resp. leader) i by partici-pating in group T , then we define the gain of a group T as the sum of the gains of its members. That is,
The gain of the followers may be a result of the fact that they are able to increase their abilities through interactions and collaborations with more capable peers [19, 31]. The leaders also gain as teaching others and giving help has been shown to be positively correlated to increase in ability [5, 32].
In this work, we will only focus on the gain of the followers and leave incorporating the gain of leaders for future work. That is, the gain of a group T
We consider two instances of the A ( T ) function, namely the count-based gain Ac and the value-based gain Av . The count-based gain function: Given a group T with leaders L T and followers F T , we define the count-based gain Ac ( T ) as: where Ac f ( i, T ) = 1 for every i  X  F T . In other words, the count-based gain of group T is simply the number of fol-lowers in the class. These are the students who are able to increase their ability through collaboration with more capa-ble peers [19, 31].
 The value-based gain function: A limitation of the count-based gain function is that it considers all followers gaining the same by their participation in T . The value-based gain function takes into consideration the actual val-ues of the followers X  abilities as well as the collective ability of the group. More specifically, given a group T with leaders L
T and followers F T , the value-based gain Av ( T ) is defined as: where Av f ( i, T ) = ( b  X  T  X   X  i ) for every i  X  F T . In other words, students with abilities that are further from b  X  T more by their participation in T .
 The problems: In this paper we are interested in two prob-lems: the 1-Group and the  X  -Groups problems. The for-mer takes as input the set of students and their abilities and aims to identify a single group T that maximizes the value of A ( T ). The latter focuses on partitioning the input set of students into groups such that the total gain across groups is maximized. The formal definitions of these two problems are given below. We give these definitions in terms of the generic gain functions, but we also discuss their instantia-tions for the count and value-based functions.

Problem 1 (1-Group). Given a set of n students S = { 1 , . . . , n } , identify a group T  X  S of at most k students such that A ( T ) is maximized.
 When we use the count-based (resp. value-based) gain func-tion for computing the gain of the group T , then we refer to the 1-Group problem as the Count1G (resp. Value1G ) problem. When the form of the gain function is not impor-tant we use the generic 1-Group term.

Problem 2 (  X  -Groups). Given an integer k and a set of n students S = { 1 , . . . , n } (with n = k X  ) find a partition of S into groups T 1 , . . . T  X  , where each group is of size k and P i =1 A ( T i ) is maximized.
 As before, when we use the count-based (resp. value-based) gain function for computing the gain of the group T , then we refer to the  X  -Groups problem as the Count  X  G (resp. Value  X  G ) problem. When the form of the gain function is not important we use the generic  X  -Groups term.
In this section we study the computational complexity of the Count1G and the Count  X  G problems and we give algorithms for solving them.
Clearly, the desired group will consist of a set of leaders L of highest ability who will pull up the group X  X  overall ability and a set of followers F whose abilities will be below the group X  X  ability yet their abilities will not be as low so as to decrease the overall ability of the group.

Example 1. Consider a set of five students with the fol-lowing ability scores:  X  1 = 0 . 9 ,  X  2 = 0 . 8 ,  X  3 = 0 . 6 ,  X  and  X  5 = 0 . Imagine that we need to create a group of three students with maximum possible gain. If students 1 and 2 are picked together (with any other student as the third member), only the third member of this group will be a follower. On the other hand, if we pick students 1, 4 and 5 which makes only student 5 a follower. Alternatively, group-ing student 2, 3 and 4 leads to a collective group ability of followers. This example shows that grouping the strongest and weakest students together does not necessarily leads to the maximum possible gain.

Our algorithm for the Count1G problem, which we call the L&amp;F algorithm, finds an optimal group composition by efficiently identifying the best sets L and F of leaders and followers that will compose the group T = L  X  F . The pseudocode of the L&amp;F algorithm is shown in Algorithm 1. Algorithm 1 L &amp;F 1: T =  X  2: for i = 1 . . . k do 3: L = top-i ability students 4: for j = i + 1 . . . n  X  ( k  X  i ) + 1 do 5: F = students with abilities  X  j ,  X  j +1 , . . . , 6: if F and L satisfy feasibility constraint then re-
In order to see the intuition behind L &amp;F and also under-stand why it is optimal, we start with the following lemma: Lemma 1 (Feasibility Constraint).

Proof. Observe that b  X  T should be larger than the high-est ability score of a student in the set F . Thus, if  X  F resents the highest ability in set F , the following condition should be satisfied: A simple rewrite of the above inequality yields the lemma.
 We do not know a priori the number of leaders in set L . However, since the gain for a group T is defined to be A c ( T ) = k  X  | L ( T ) | , the optimal solution will have the minimal number of leaders. Our algorithm therefore tries increasing number of leaders, starting with the student of highest ability. The reason for preferring higher ability lead-ers is that the sum of their abilities appears as a negative term in the right hand side of the inequality in the feasibility constraint. Note that for any fixed set L , all possible sets of followers that satisfy the feasibility constraint lead to the same value of Ac . A computationally efficient way to pick the followers is to look for them in k  X  | L | consecutive po-sitions starting with the first student who is not in L . And that is what our algorithm does.

Example 2. To clarify the details of Algorithm 1, we re-visit the students of Example 1. The algorithm starts by placing a single student (i.e., student 1) in the set of leaders. Then, the inner loop (lines 4-5) searches for the consecutive group of students that satisfy the feasibility constraint. First, students 2 and 3 are considered for the followers set, but they do not pass the feasibility test. Next, the algorithm tries stu-dents 3 and 4, who pass the test. Thus, the algorithm returns the group consisting of students { 1, 3, 4 } , having Ac = 2 . Complexity: With a preprocessing step of complexity O ( n ) for computing the cumulative sums of all the ability levels of all the students sorted in decreasing ability level, L&amp;F algorithm has complexity O ( nk ). If we take a closer look at Algorithm 1, we can observe that the outer loop (line 2) searches for the smallest possible number of students that should be placed in set L to lift students in set F . This linear search, however, can easily be replaced by a binary search. Based on this observation, a more efficient implementation of L&amp;F runs in time O ( n log k ).
 Remark 1: Problem 1 is defined so that the formed group T is of specific size k . A natural question is whether we can form a group T of any size. We can observe that the L&amp;F algorithm can be used for this problem as well. For example, one can simply run the L&amp;F algorithm for all values of k  X  { 1 , . . . , n } and output the group with the best Ac score among all those reported for the different values of k . Remark 2: As stated in Algorithm 1, L&amp;F selects the fol-lower set in such a way that the relatively high ability fol-lowers are grouped with the highest ability leaders. We will sometime refer to this version of L&amp;F as max-L&amp;F to empha-size that amongst all the feasible follower sets, the group formed by this algorithm has the highest-ability follower. One can easily modify Algorithm 1 to select the follower set to contain the lowest highest-ability follower or for that matter select a random set amongst all the feasible follower sets. We will refer to these versions as min-L&amp;F and any-L&amp;F respectively.
In this section, we first show that the Count  X  G problem is NP-complete and then discuss heuristics for solving it.
Lemma 2. When k = n/ 2 then the Count  X  G is NP-complete.

Proof. We prove that Count  X  G is NP-complete by re-ducing the Subset Sum problem [13] to this problem. The Subset Sum problem asks whether a given set of positive integers W = { w 1 , w 2 ,  X   X   X  , w N } can be partitioned into two groups W 1 , W 2 such that the sum of numbers in W 1 equals the sum of numbers in W 2 . In other words, if we use z = want the sum of the elements in W 1 to be equal to the sum of the elements in W 2 and thus equal to z 2 .

N ow, given an instance of the Subset Sum problem we create an instance of the Count  X  G problem with n = 2 N +6 students which we want to partition into 2 groups each of size k = ( N + 3). We create the instance of the Count  X  G problem as follows: for each number w i in W , we create a student with ability  X  i =  X  w i . Beside these low ability students, we create n + 4 students with abilities equal to a small value. We claim that (under this construction) the answer to the decision problem of Subset Sum is  X  X es X  iff the optimal solution to the Count  X  G would have a total Ac of (2 N + 4).
 First, assume that there is a perfect partitioning of W into W 1 and W 2 . Now, we can create two groups T 1 and T 2 in the Count  X  G problem as follows. First, we place a strong student with ability z 2 +  X  i n both T 1 and T 2 . Then, we place the low ability students that correspond to the numbers in set W 1 (resp. W 2 ) in T 1 (resp. T 2 ). Finally, we distribute the normal students (i.e., those with ability equal to zero) over T 1 and T 2 to make both groups of the same size. Note that the size of each group must be N + 3 and Since the collective ability levels of both groups are positive, all students except the two strongest students are below the mean. Thus Ac ( T 1 ) + Ac ( T 2 ) = N + 2 + N + 2 = 2 N + 4.
Now, assume that there is an optimal grouping of students into groups T 1 and T 2 each of size ( N +3) and total Ac equal to (2 N + 4) for Count  X  G problem. Let z 1 and z 2 denote the sum of the negative abilities in T 1 and T 2 respectively. We would like to show that z 1 = z 2 which further implies a perfect partitioning of the set W . First, observe that due to the pigeon-hole principle, both groups should have at least one student with ability equal to zero. Moreover, one can be in different groups. This is simply because these are the highest abilities and they can never be below the mean of any group. Thus, if they are placed together there would be at least 3 student above the group average (i.e., the two strong students and the strongest student of the other group).
Given that each group has exactly one student with ability +  X  a nd at least one student with ability equal to 0, the collective ability of both groups must be positive in order to guarantee an overall Ac equal to 2 N + 4. Formally, This implies that Now, it is easy to see that by picking a small value of  X  one can guarantee z 1 and z 2 to be equal. As mentioned earlier, this further implies that the students with negative abilities in group T 1 and T 2 define a perfect partitioning of the elements in set W . Finally, to guarantee that our reduction take polynomial time, we would like to point that  X  does not require to be arbitrary small, it can simply be smaller than the precision in which the ability scores are reported.

Given that the ability scores in an instance of Count  X  G problem are bound to be between zero and one, it might seem that our reduction is incomplete as it creates students with negative ability scores. However, one can see that the optimal solution to an instance of Count  X  G problem would not change if all the ability scores are shifted (i.e., incre-mented by a constant) or scaled (i.e., multiplied by a con-stant). Thus, one can simply renormalize the ability scores to be between zero and one without affecting the value of the optimal solution.
 IterL&amp;F : G iven there is no polynomial-time algorithm for solving Count  X  G , we propose IterL&amp;F , which is an iterative heuristic. In every iteration of IterL&amp;F , one group of size k is formed. The selection of the group is done using the L&amp;F algorithm and using as input only those students that have not yet been assigned to any group. Clearly, there are n/k iterations of IterL&amp;F , each taking time O ( n log k ). Therefore, the overall running time is O ( n 2 log k k ) .
Depending upon the version of L&amp;F algorithm employed (see Remark 2 in Section 4.1), we get three versions of IterL&amp;F , namely max-IterL&amp;F , min-IterL&amp;F and any-IterL&amp;F . Our experiments indicate that they obtain simi-lar overall value of the Ac objective, but the structure of the groups built by them exhibit differences. Intuitively, max-IterL&amp;F groups the highest ability leaders with rela-tively high ability followers, whereas min-IterL&amp;F groups them with the lowest ability followers, while any-IterL&amp;F groups them with mixed ability followers.
We next study the Value1G and Value  X  G problems.
We first show that the Value1G problem can be solved in polynomial time with an algorithm, which we call End-points . Algorithm 2 provides the pseudo-code of End-points .
 Algorithm 2 E ndpoints 1: for i = 1 . . . k  X  1 do 2: L i = { 1 , ..., i } 3: F i = { ( n  X  i + 1) , ..., n } 4: b  X  i = ((  X  1 + ... +  X  i ) + (  X  n  X  i +1 + ... +  X  n 6: T i = L i  X  F i 7: else 8: T i =  X  9: return arg max T We start with the following lemma:
L emma 3. Given a group T that maximizes Av ( T ) and consists of x leaders and y = k  X  x followers, it must be the case that L = { 1 , ..., x } and F = { ( n  X  y + 1) , ..., n } .
Proof. We definitely need to pick as followers the y stu-dents with the lowest ability since Av ( T ) will be strictly worse for any other choice of y students. We also need to se-lect the top-x ability students as the leaders; this is because the top-x ability students maximize the value of b  X  T and as a result also the value of our objective Av ( T ).
However, since the values of x a nd y are not known a pri-ori, Endpoints iterates over all possible values of x and y that satisfy x + y = k and reports the optimal solution in time O ( k ). The IF condition ensures that the set F under consideration satisfies the constraint imposed by the defini-tion of a follower set.

Example 3. For the students of Example 1, Endpoints returns L = { 1 , 2 }  X  F = { 5 } . Contrast this group with the group formed by L&amp;F in Example 2 for the same set of students. The latter uses the top student 1 to lift up the stu-dents 3 and 4, whereas Endpoints uses the two top students to lift up the very weak student 5.
Determining the exact complexity class of the Value  X  G is still unresolved. Meanwhile, we propose two iterative heuristics for solving the problem: IterEndpoints and RoundRobin . Their performance characteristics is empiri-cally studied later in the paper.
 IterEndpoints : This heuristic builds upon the Endpoints algorithm. In each iteration, it identifies a group of size k by applying Endpoints to the remaining body of students. The running time of IterEndpoints is O ( n ), since there are n/k iterations, each requiring time O ( k ).
 RoundRobin : Clearly, IterEndpoints does a perfect job of maximizing the gain for the first group. However, the gains for the subsequent groups can decrease considerably. RoundRobin tries to balance the gain across all the groups. It works off the sorted list of student abilities and creates the first group consisting of k students at positions 1, k + 1, (2 k + 1), etc. The i th group is formed by students at posi-tions i , k + i , (2 k + i ), etc. The running time of RoundRobin for a sorted input consisting of n students is O ( n ). Intu-itively, this heuristic mimics how groups are often formed (particularly in recreational team sports) by first selecting the leaders and then letting the leaders take turn in adding members to their respective groups.
 Observe that RoundRobin can also be used for solving the Count  X  G problem. In fact, we use it as a baseline algorithm in our experiments with the Count  X  G problem as well.
Our experimental evaluation focuses on studying the per-formance of our algorithms for the Count  X  G and the Value  X  G problems. Moreover, we present some illustra-tive partitions created by different algorithms and highlight their characteristics.
 Datasets: For all the experiments we report here, we ex-periment with a set of n = 1024 students with ability val-ues randomly sampled from ( a ) normal, ( b ) uniform and ( c ) pareto distributions. We refer to the resulting datasets as members of the group; dark points are group abilities. for the pareto dataset. normal , uniform and the pareto datasets respectively. The abilities of students in the normal dataset are sampled from a normal distribution with mean 0 and standard deviation 1. For the uniform dataset the abilities are sampled uniformly from the interval [0 , 1]. Finally, the abilities of the students in the pareto dataset are samples from a pareto distribution, having the shape parameter set to 3. After the datasets are sampled from their respective distributions, we normalize all values to be in [0 , 1]. This normalization is only done for consistency and plays no role in the conclusions we draw. Baseline algorithms: In addition to the algorithms we discussed in Sections 4 and 5, we also experiment with two baseline algorithms: Stratified and Random .

The Stratified algorithm sorts the students in decreas-ing order of their abilities. Then, the first group is created by considering the first k students with the highest abilities and putting them in a group by themselves. The second group is created with the subsequent k students, and so on. The run-ning time of this algorithms for a sorted input consisting of n students is O ( n ). This algorithm can be thought of as an idealized version of the oft-used, ability-based homogeneous grouping of students [20, 24].

The Random algorithm creates  X  groups of size k by ran-domly assigning students to groups. The running time of the Random algorithm is O ( n ), since it is adequate to create a random permutation of the students and then create the  X  groups by considering consecutive members of this permuta-tion. Note that some approximation of Random is often used for partitioning a class into heterogeneous sections [27]. We study the performance of different algorithms for the Count  X  G problem by computing the total gain Ac due to the groups they form. We use the max-IterL&amp;F version of IterL&amp;F as well as Random , Stratified and RoundRobin in this evaluation. Figure 1 shows their Ac values as a function of the group size k  X  { 2 , 4 , 8 , . . . , 512 } for each one of the three datasets ( normal , uniform and pareto ).

The results (which are averages over 20 random datasets drawn from the respective distribution) demonstrate that for all values of k (except for k = 2), IterL&amp;F is significantly better than any other algorithm. In fact, there are values of k (e.g., k = 32) for which the IterL&amp;F achieves total Ac of more than 950, while the maximum possible value is less than 1024. This means that more than 90% of the students are assigned into groups in which the group ability is higher than their ability.

For k = 2, all algorithms have the same total Ac , which is equal to n/ 2 = 1024 / 2 = 512. The reason is that in groups of size 2 inevitably there is one student who is above and one who is below the group average and therefore the group is beneficial for exactly half of the students, independently of how the group assignment is performed. As k increases, the ability of IterL&amp;F to make conscious and judicious use of the high ability students to pull up as many lower ability students as possible starts to shine and the performance gap between IterL&amp;F and other algorithms starts to increase. Beyond some value of k (around 32), the law of diminishing return sets in and the performance gap starts to reduce. Note, however, that the x -axis in Figure 1 is in logarithmic scale and the decrease in performance gap is more gradual than it might appear from a cursory glance at the plots. Turning our attention to the baseline algorithms (i.e., Random , Stratified , and RoundRobin ), we observe that for normal and uniform datasets the performance of these al-gorithms is almost constant allowing about half of the stu-dents to benefit from group participation. The landscape is different for the pareto dataset. In this case, Random and RoundRobin are better than Stratified  X  yet again signifi-cantly worse than IterL&amp;F . In order to understand that one has to remember that the pareto dataset has a small num-ber of exceptionally high-ability students. The Stratified algorithm by definition puts these students together in one group and therefore their high abilities cannot be leveraged to lift up the average abilities of other groups. This phe-nomenon is not observed in the groups formed by Random and RoundRobin since these algorithms distribute the high-ability individuals into different groups allowing more groups to benefit from them.
 Characteristics of groups in Count  X  G : Although the plots in Figure 1 demonstrate the superiority of IterL&amp;F with respect to the objective function (i.e., total Ac ), they do not provide intuition on the types of students that are brought together into groups by different algorithms. We do that in Figure 2 for groups of size 32 using the normal , the uniform and the pareto datasets. The x -axis of all the plots in this figure corresponds to ability values and the y -axis takes values { 1 , 2 , . . . , 32 } ; these y -values correspond to the group IDs. Thus the points on the same horizontal line in a plot represent the abilities of the students that are assigned to the group with ID equal to the value of the y -axis to which this horizontal line corresponds to. The group ID is the same as the order in which the group was output by the corresponding algorithm. For example, the group with ID equal to 1 is the the first group that was built by IterL&amp;F , and group with ID equal to i w as built by IterL&amp;F at its i -th iteration. The gray triangles correspond to the members of each group while black dots represent the mean of the abilities within each group. Keep in mind that we are using the max-IterL&amp;F version of IterL&amp;F in this experiment. Several interesting observations emerge from this figure. First of all, there is a clear separation between the  X  X eaders X  and the  X  X ollowers X  in the groups built by IterL&amp;F . We see that IterL&amp;F judiciously puts together in each group few strong leaders with followers that are clearly weaker than them, yet they are not as weak as the followers grouped with relatively less strong leaders. The groups formed by Random have a mix of students from all ability levels, with no clear separation between leaders and followers. The groups formed by RoundRobin are a more deterministic version of the groups built by Random . Finally, the groups formed by Stratified clearly exhibit ability grouping, where the students with the same ability levels are grouped together. These differences in group composition underlie the superi-ority of IterL&amp;F we see in Figure 1.

Finally, we remark that we found that all three versions of IterL&amp;F , namely max-IterL&amp;F , min-IterL&amp;F and any-IterL&amp;F , had similar performance but the structure of the groups they formed differed somewhat. We illustrate in Fig-ure 3 the composition of the groups built by them for k = 32 for the pareto dataset. As in max-IterL&amp;F , there continues be a separation between the  X  X eaders X  and the  X  X ollowers X  in the groups constituted by the other two. However, while max-IterL&amp;F groups strongest leaders with strongest follow-ers, min-IterL&amp;F initially groups the weakest followers with the strongest leaders. Subsequently, it groups decreasingly strong leaders with relatively stronger weak followers until in the final groups the abilities of the leaders and the follow-ers converge. The groups built by any-IterL&amp;F are similar to those yielded by min-IterL&amp;F , but the followers now have relatively more mixed abilities.
Here, we describe our experiments for the Value  X  G prob-lem. Our experimental methodology is identical to the one we followed for the Count  X  G problem. We study the perfor-mance of IterEndpoints , Random , RoundRobin and Strati-fied with respect to the total Av of the groups they form. We again use normal , uniform and pareto datasets and group sizes k  X  { 2 , 4 , 8 , . . . , 512 } .
 Figure 4 shows the results. We see that IterEndpoints , Random and RoundRobin consistently outperform Strati-fied . To understand this phenomenon, recall that the goal of Value  X  G is to maximize the gain for the students in the follower sets. The gain for followers in a particular group de-pends on the gap between the their abilities and the group ability; the larger the gap the larger will be the value of Av . Thus, an algorithm that forms groups in such a way that the ability of leaders is relatively high compared to the abil-ities of followers will perform better. Finally, since Value  X  G aims to maximize the sum of the Av values of all the groups, the above property needs to hold only in aggregate.
Examine now Figure 5 that illustrates the abilities of stu-dents in each group formed by the different algorithms for the normal , the uniform and the pareto datasets for k = 32. As before, the x -axis of all the plots in this figure corresponds to ability values and the y -axis takes values { 1 , 2 , . . . , n/k } , which correspond to the group IDs. Clearly, Stratified forms homogeneous groups such that in every group there is very little difference in the abilities of the group members and the individual ability of each of the member is quite close to the collective ability of the group. Thus, the total gain for this algorithm is small.

In contrast, the groups formed by Random have greater di-versity of abilities. It brings together students of varying abilities that has the effect of creating groups having leaders and followers at quite different levels of ability. RoundRobin can be viewed as a deterministic version of Random and hence its performance characteristics is similar. However, it is in-teresting to contrast the composition of groups these two heuristics form with those built by IterEndpoints . Though they all achieve roughly similar total Av values, particu-larly for groups of reasonable size, they form very different types of groups. In some of the groups formed by IterEnd-points , there is significant difference in the abilities of the leaders and the followers, while in others the difference is small. There is some empirical evidence in support of such structures [23].
We proposed a formal framework for studying the socially important problem of grouping students in a large class into sections so that the gain aggregated over all the students is maximized. Using two different definitions of gain for students, we studied two distinct optimization problems: Count  X  G and Value  X  G . Intuitively, Count  X  G aims to maximize the number of students who can do better by inter-acting with the higher ability students, while Value  X  G in-corporates the extent of these improvements. From the com-putational viewpoint, we studied the computational com-plexity of these grouping problems and provided novel poly-nomial time heuristics for them.

Our experiments indicate that by appropriately choosing the definition of the gain function, it is possible to achieve different social goals. For example, the groups reported as solutions to Count  X  G , put strong students together with students who are weaker than them, yet they are not as weak as the students grouped with less strong students. Thus, the group members can learn in their zones of proximal de-velopment [19, 31]. On the other hand, groups reported as solutions to Value  X  G put together the weakest with the strongest students aiming to maximize diversity of the groups. Such groups may provide larger motivation/benefit to the weak students while giving room to the strongest stu-dents to learn by teaching and become role models [5, 23, 32]. It is really up to the school to decide its social goals and philosophy and as a result its choice of objective.
The gain functions we studied in this paper are just two of many functions admitted by our framework. In the future, we would like to study other functions particularly those incorporating the gains of strong students and non-linear gains. We would also like to enrich our problem formulation with constraints due to socio-emotional factors such as in-terpersonal relations [4, 10]. The group dynamics that sets in once a group is formed can have major impact on the outcomes [6]. We would like to explore how to apply com-putational perspective to studying the group interactions in an educational setting. Finally, we would like to partner with some educational institutions to study the performance characteristics of our work in real-life.
T his research was partially done when E. Terzi was vis-iting Microsoft Research. The research was also partially supported by: NSF CAREER #1253393, NSF grants: CNS #1017529, III #1218437, IIS #1320542 and gifts from Mi-crosoft and Hariri Institute of Computing. [1] Anagnostopoulos, A., Becchetti, L., Castillo, C., [2] Anagnostopoulos, A., Becchetti, L., Castillo, C., [3] Ashman, A., and Gillies, R. Cooperative learning: The [4] Azmitia, M., and Montgomery, R. Friendship, [5] Bargh, J., and Schul, Y. On the cognitive benefits of [6] Barron, B. When smart groups fail. Journal of the [7] Boaler, J., Wiliam, D., and Brown, M. Students X  [8] Chimombo, J. P. G. Issues in basic education in [9] Crocker, L., and Algina, J. Introduction to classical [10] Da Silva, F. E. D. O., Motta, C. L., Santoro, F. M., [11] Esposito, D. Homogeneous and heterogeneous ability [12] Gajewar, A., and Sarma, A. D. Multi-skill [13] Garey, M., and Johnson, D. S. Computers and [14] Gillies, J., and Quijada, J. Opportunity to learn: A [15] Grossen, B. How should we group to achive excellence [16] Hambleton, R. K., and Jones, R. W. Comparison of [17] Hand, D., Mannila, H., and Smyth, P. Principles of [18] Hanushek, E. A., and Woessmann, L. The role of [19] Hertz-Lazarowitz, R., and Miller, N. Interaction in [20] Kulik, J. A. An analysis of the research on ability [21] Lappas, T., Liu, K., and Terzi, E. Finding a team of [22] Li, C.-T., and Shan, M.-K. Team formation for [23] Lou, Y., Abrami, P. C., Spence, J. C., Poulsen, C., [24] Loveless, T. The resurgence of ability grouping and [25] Majumder, A., Datta, S., and Naidu, K. V. M.
 [26] May, M. A., and Doob, L. W. Competition and [27] McPartland, J. M., Coldiron, J. R., and Braddock, [28] Mislevy, R. J. Item response models for grouped data. [29] Richer, S. Reference-group theory and ability [30] Slavin, R. E. Learning to cooperate . Springer, 1985. [31] Vygotsky, L. S. Mind in society: Development of [32] Webb, N. M. Peer interaction and learning in small [33] World-Bank. Knowledge for Development: World
