 The paper describes a maximum entropy based story seg-mentation system for Arabic, Chinese and English. In ex-periments with broadcast news data from TDT-3, TDT-4, and corpora collected in the DARPA GALE project we ob-tain a substantial performance gain using multiple overlap-ping windows for text-based features.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval Algorithms, Experimentation Story Segmentation
Automatic identification of story boundaries in broadcast news (BN) is important in processing large volumes of un-structured data, where it is essential to identify topically homogeneous units of material to be indexed. A recent overview can be found in [7]. The paper describes our ex-periments to develop algorithms for application in a near-real-time system for processing Arabic and Chinese BN in the DARPA GALE project.
We treat story segmentation as a binary classification problem, where the model is trained to estimate the likeli-hood of a story boundary occurring at an utterance bound-ary given the surrounding context and other features. For our purpose we define utterances as intervals of speech di-vided by occurrences of non-speech material (typically si-lence.) The classifier is a maximum entropy model [2], using the following categories of features:
Lexical features include unigrams, bigrams and trigrams of tokens found in the text windows surrounding the pro-posed story boundary. For Arabic and English we convert words into tokens using stemmers ([4, 5], respectively), while the Chinese tokens are formed as overlapping character bi-grams.

Text similarity features are based on similarity of the text windows surrounding the proposed boundary. The sim-ilarity scores are computed using a symmetrized version of the Okapi [6] formula.

For the above mentioned text-based features we experi-ment with various lengths of the text windows, as well as with a combination of multiple windows of different lengths.
Prosody features include features based on the dura-tion of non-speech signal at the proposed boundary, utter-ance duration and word count, and the rate of speech in the material surrounding the proposed boundary.

Position in the show features reflect the time of the proposed boundary relative to the beginning of the program-ming block.

For the data collected in the GALE project, we also in-cluded speaker and video shot change features .
To measure segmentation performance, we use a sliding window metric established in Topic Detection and Tracking (TDT) project [1]. In contrast with TDT we do not distin-guish between NEWS, TEASER, and MISCELLANEOUS material, except in the experiments where we follow the con-ditions of the TDT-3 segmentation task.

Selecting an operating point (OP) on the system X  X  ROC curve is an application specific decision. We report the Miss and False Alarm (FA) rates at the OP in which the average story length matches the ground truth average story length of the test data, and C seg values [1] at the lowest C seg
The English subset of the TDT-4 [8] corpus consists of 450 files, each based on a news program 30 or 60 minutes long. In our experiments we use the chronologically first 350 files (248 hours) as a training set, and the last 50 files (30 hours) as a test set.

Figure 1(a) and Table 1 show performance indicators for various versions of the system. The baseline system uses only the silence duration, left/right similarity feature win-dows of 20 tokens, and lexical feature windows of 50 tokens. The rest of the results show the cumulative effect of addi-tional features. We obtain substantial performance improve-points where the average story length matches the test data. (c) TDT-3 Table 1: TDT-4, Miss, FA, and C seg values for base-line (B) and full (F) system.
 B .26 .045 .062 .20 .020 .042 .30 .061 .071
F .18 .041 .044 .15 .018 .029 .21 .041 .048 ment with similarity and lexical features based on multiple windows. Adding the features based on the position in the show and sentence duration obtains modest improvement.
Additionally, to show the effect of multi-window features, we test the system with the following changes from the base-line: For the text similarity features, we use window lengths of 20, 50, 100 and 200 tokens, and the C seg values range from 0.066 to 0.080; using all 4 window lengths yields C seg of 0.063. For the lexical features, we use window lengths of 10, 20 and 50 tokens, and the C seg values range from 0.069 to 0.075; using all 3 window lengths yields C seg of 0.060.
In experiments with Arabic and Chinese TDT-4 data, we used the Voice of America (VOA) subset of the corpus. The training and test sets contain 44 and 24 shows for Arabic and 45 and 19 shows for Chinese, each show being an hour long. Figure 1(b) compares the baseline system with the sys-tem including the multi-window, position in the show, and sentence duration features. We observe similar improvement over the baseline as in the English TDT-4 data.

To compare the performance with previously published results, we test our segmenter under the conditions of the TDT-3 [1] segmentation task. Figure 1(c) compares a base-line system, using a set of features similar to the state of the art system in TDT-3 [3], with a full system using the multi-window features. The lowest C seg values for the full version of our system are 0.0593 for English and 0.0528 for Chinese, compared with the 0.0810 and 0.0670 reported by the state of the art system in TDT-3 (also shown on Figure 1 (c)).
For the GALE project we trained segmentation models using data from multiple news programs from Al Arabiya and Al Jazeera (Arabic), and Phoenix Infonews (Chinese). For each source we collected and annotated approximately 50 hours of data, spanning a month of programming. In addition to the features used on the TDT data, we included features based on speaker and video shot changes, but they did not yield consistent performance improvement. Tested on the most recent 20% of the annotated sets, the C seg val-ues range between 0.034 and 0.067 for Arabic and between 0.042 and 0.061 for Chinese.
Our story segmentation algorithm shows competitive per-formance on Arabic, Chinese and English data, primarily due to the use of multi-window features. The performance gain is consistent in the three languages. Future work will focus on investigating additional audio and video features. This work was partially supported by the Defense Advanced Research Projects Agency under contract No. HR0011-06-2-0001. The vie ws and finding s contained in this material are those of the authors and do not neces-sarily reflect the position or policy of the U.S. government and no official endorsement should be inferred. [1] The 1999 topic detection and tracking TDT-3 [2] A. Berger, S. Della Pietra, and V. Della Pietra. A [3] M.Franz,J.S.McCarley,T.Ward,andW.J.Zhu.
 [4] Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and [5] M. Porter. An algorithm for suffix stripping. Program , [6] S. E. Robertson, S. Walker, M. Hancock-Beaulieu, [7] A. Rosenberg and J. Hirschberg. Story segmentation of [8] S. Strassel and M. Glenn. Creating the annotated
