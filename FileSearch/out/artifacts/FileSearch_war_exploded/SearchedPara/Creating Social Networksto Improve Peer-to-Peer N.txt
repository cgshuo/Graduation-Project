 } We use knowledge discovery techniques to guide the cre-ation of efficient overlay networks for peer-to-peer file shar-ing. An overlay network specifies the logical connections among peers in a network and is distinct from the physical connections of the network. It determines the order in which peers will be queried when a user is searching for a specific file. To better understand the role of the network over-lay structure in the performance of peer-to-peer file sharing protocols, we compare several methods for creating over-lay networks. We analyze the networks using data from a campus network for peer-to-peer file sharing that recorded anonymized data on 6,528 users sharing 291,925 music files over an 81-day period. We propose a novel protocol for over-lay creation based on a model of user preference identified by latent-variable clustering with hierarchical Dirichlet pro-cesses (HDPs). Our simulations and empirical studies show that the clusters of songs created by HDPs effectively model user behavior and can be used to create desirable network overlays that outperform alternative approaches.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining ; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Measurement, Performance peer-to-peer networks, hierarchical dirichlet processes, so-cial networks, distributed hash tables, overlay networks
As peer-to-peer (P2P) file-sharing systems such as KaZaa and Gnutella increase in popularity, the efficiency of simple search methods, such as flooding, necessarily decreases. As the name implies, peers that utilize flooding search forward queries to all neighboring peers  X  X looding X  the network with requests. Many researchers have attempted to increase ef-ficiency with content-based overlay networks, including dis-tributed hash tables (e.g., [1, 10]) and other semantic ap-proaches (e.g., [4, 5, 12]). An overlay network specifies the logical connections between peers in a network and is dis-tinct from the physical connections of that network. It de-termines the order in which peers are queried when a user is searching for a specific file.

In this paper, we present a new method for creating over-lay networks that are based on a learned model of user pref-erence and the musical styles of user libraries. Previous approaches depended on specific content already present in a user X  X  library and provide no learned model to generalize the types of files users might prefer. By generalizing the files a user shares into a model of the types of files that a user prefers, we are able to build an overlay network connecting users who are likely to share files with each other. This al-lows us to create and capitalize on file locality specific to an individual user with particular preferences without relying on complex search methods or overly detailed user charac-teristics. We chose to identify styles (i.e., groups of files which people tend to prefer together) by clustering the files available in the network with hierarchical Dirichlet processes (HDPs). The only information needed to determine cluster assignments using an HDP is a list of filenames present in each users X  shared library, information which is readily avail-able in current P2P systems.

Our experiments and simulations show that by creating overlay networks based on social characteristics we are able to improve the performance of P2P networks. We demon-strate that clustering the MP3 audio files shared in an actual P2P network with HDPs captures our intuitive sense of mu-sical styles and can be used to create an effective model of user download behavior. We then use that model to create overlay networks that connect users who prefer the same styles of music and demonstrate the overall effectiveness of those overlays when compared to random graphs, random cluster graphs, and direct file similarity graphs. We also demonstrate the utility of these new overlay networks when combined with a distributed hash table approach.
The data were collected from a campus network for P2P file sharing based on the OpenNap server. The data con-sist of records of all the files shared by and transferred be-tween users during an 81-day period between February 28, 2003 and May 21, 2003. Users are uniquely identified by an anonymous MD5 hash. No personal information was col-lected during this study and users gave explicit consent to anonymous collection of the data. Files are uniquely identi-fied by a filename and extension and are not limited to any particular filetype. In the raw data there were over 2 million distinct files. We chose to focus only on files with the MP3 extension, reducing the raw number of files to 466,221.
Rudimentary consolidation was performed by making all filenames lowercase, converting spaces and punctuation to dashes, and doing simple artist-name recognition. Most of the filenames contained some combination of the track name of the song, the song X  X  artist, the track number and al-bum name. The most common form of the filename was &lt; artist &gt; -&lt; songname &gt; .mp3. Using this information and some hand labeling, we were able to generate a list of the most prevalent artists in the database and use that informa-tion to help determine if two files should be consolidated. Through consolidation we reduced the number of files to 291,925. We did minimal consolidation on misspelled or al-ternate spellings of artist names or track names. By limiting the files to MP3s and performing simple name consolida-tion we were able to decrease the number of unique files by approximately 90% while only reducing the number of transfers and queries by 50% and the number of users by approximately 20%. Exact counts are shown in Figure 1. Figure 1: The P2P data schema showing counts of the objects and links after limiting the data to MP3 files and performing name consolidation.

User data were recorded twice daily at 12:00 am and 12:00 pm . Unfortunately, not all users were online when these snapshots of the network were taken. For example, there were 145 users who served files but never appeared in any snapshot. Transfers were recorded after a transaction was completed. To find a file, users queried a central database which returned an HTML page with links to files matching the query term. If a link was clicked, the time of the trans-action, users involved, query term, and file transferred were all recorded. Chu et al. [3] provide a summary of statistics and trends present in the data. Due to the inconsistency of information found in filenames, ID tags, industry labels, and music information sites on the web, it is difficult to determine the style or genre of a par-ticular MP3 file, and more importantly, whether a user will download any given song. In place of labels and ID tags, we used clusters defined by a knowledge discovery algorithm to determine the styles of files in the system.

By representing user libraries as a document and files as terms, we can apply techniques from document clustering and topic detection to identify latent groups of files in user libraries. To find these latent groups, we chose to use a hier-archical Dirichlet process (HDP) [13] [14], a non-parametric extension to latent Dirichlet allocation [2], because it mod-els each document as a mixture of latent topics. HDP is non-parametric in that the number of groups does not need to be provided a priori . Unlike text documents, where mul-tiple occurances of words are meaningful, multiple instances of a single file appearing in a shared library should be disre-garded. Also, the size of user libraries has a power law dis-tribution (i.e., a small number of users have many files and many users have only a few files). Previously published ex-periments using HDPs cluster sets of documents with more uniform sizes. Despite these differences we were still able to use HDPs to identify desirable clusters, as described in Section 3.2.
An HDP is a non-parametric hierarchical Bayesian model involving multiple groups of data. The number of clusters is governed by a random variable that grows at a rate logarith-mic in the number of data points. This model is generative and is based on the Dirichlet process mixture model. It is designed to generate groups of data where the individual items in each group are drawn from a mixture of distribu-tions. A graphical model representation of an HDP is given in Figure 2.
 Figure 2: We model user libraries as a collection of files, F , labeled with a style descriptor, S . The dis-tributions of the style parameters in user libraries is governed by a hierarchical Dirichlet process (HDP), the graphical model shown here.

We model U users each with a group or library of n files denoted by ` u = ( F ( u,j ) ) | ` | j =1 . We assume each file F drawn with conditional independence from a mixture model of genres with parameters set once for the group. Each user has a mix of musical tastes and each song in their li-brary is taken from a style of music where the distribution of styles remains constant for each file in a user X  X  library. Because each file is drawn independently, we can associate a genre or mixture component for each file. We use S ( u,j ) to denote the parameter specifying the genre for each file. In an HDP, each user is modeled with a Dirichlet process, G u  X  DP (  X  0 , G 0 ), where the actual distribution over the parameters S ( u,j ) deviates from the base distribution G with variability determined by some real number  X  0 . The distribution G 0  X  DP (  X , H ) is also a Dirichlet process with base probability measure H and concentration parameter  X  . The prior distribution for the parameters ( S ( u,j ) ) U termined by the baseline H . It is important to note that the values of the parameters S ( u,j ) are shared between the users and within users X  libraries.
The HDP identified 99 clusters ranging in size from 239 files to 15 files. To reduce the size of our space, we clustered a limited set of 7888 files that were present in the first week of the data and appeared 3 or more times in the network. We assigned songs to their most probable cluster and used these clusters to define styles of groups of files . Representative styles are displayed in Table 1. While many of the clusters correspond to typical music industry genre labels (e.g., rock, hip hop, country, etc.), other clusters are best labeled with other categories. For example, Cluster 9 is a  X  X opular songs X  or  X  X reatest hits X  cluster. The cluster contains a broad range of popular artists and songs, including many classic artists such as Elvis and Van Morrison. Cluster 54 is dominated by female artists with no preference for a particular style or genre of music. Because of these types of clusters, we have chosen the term  X  X tyle X  instead of  X  X enre X  to describe the groups.
If we assume that styles are representative of true groups of files, then we would expect (1) songs from a given style to appear together in user libraries and (2) users to prefer songs from a small number of styles. For comparison, we also assigned files into 99 random clusters with the same precise probabilities of a file occurring in an HDP cluster. More than 80% of pairs of files drawn from the same HDP cluster co-occur in 1 or more user libraries. In contrast, ap-proximately 80% of pairs of files drawn from random clusters of the same size do not co-occur in any user library. The his-tograms of these counts are shown in Figure 3. This verifies our expectations about the network and the correctness of the model. Figure 3: Co-occurrences of 1000 pairs of files in user libraries drawn from clusters and drawn at random. Pairs of songs drawn from HDP clusters co-occur many more times than pairs drawn from random clusters.

Figure 4 shows the distributions of the number of clusters per user. Figure 4(a) shows that for the majority of users 80% of their shared files can be described by only 20% of the HDP clusters. Most users, however, still own a small num-ber of files from many clusters as is shown in Figure 4(b). Random clusters do not have the same descriptive power as the HDP clusters. These evaluations show that the HDP clusters match our expectations for successful clusters and we therefore use these clusters to build overlay networks that can connect users who prefer music files from the same clusters. Figure 4: The distribution of clusters needed to de-scribe user libraries. Fewer clusters per user mean that the clusters are more indicative of user tastes.
Overlay networks specify the logical connections between users in a P2P network. Each user maintains a list of neigh-bors (or peers) whom they are able to contact. When a user wants to search for a file, they send a query to their neigh-bors, who pass it on to their neighbors and so on. These connections are easily represented as a graph. The original overlays for P2P networks were random graphs. Because no attempt was made to connect similar users, query perfor-mance varied from user to user depending on the type of users within a few hops. To introduce more consistency in the network, some content-based overlay networks been at-tempted (e.g., [4, 5, 12]). While these approaches have had moderate success, we believe that learned models of user behavior are necessary for major performance gains.
A plausible content-based alternative to random overlay networks is to build a network based on a measure of sim-ilarity between users X  libraries. Unfortunately, this kind of direct file similarity does not capture important aspects of download behavior in a P2P network. Consider the patho-logical case. Imagine two users who both deeply enjoy lis-tening to the music of the Rolling Stones. By coincidence, each of these two users owns exactly half the Rolling Stones catalog and do not share any files in common. They have zero songs in common but should still be linked together in the network based on the fact that they both like the Rolling Stones and would likely download many files from each other. At the other extreme, with direct file similar-ity two users with exactly the same library would be linked even though there would be very few transactions between these users. To balance these extremes, an efficient overlay network would connect users who share similar style prefer-ences but do not already share many of the same files.
We propose creating overlay networks that connect users with similar distributions of the styles identified by the HDP clusters. Each user is identified by a vector denoting the probability of sharing a file of each style. We calculated this probability by counting the number of shared files in each style and dividing by the total library size. These cal-culations are described in Section 4.2. Because this is an abstraction over files, we can solve the problem experienced by the Rolling Stones fans by connecting users with many files of the same style even though they may not have many files in common. Also, we can factor out files in common and only connect users who have similar style distributions but not many files in common, solving the second patholog-ical condition. In the next sections, we show that the styles found in user libraries and the styles of downloads by that user are similar and can be used to design efficient overlay networks.
We designed a test based on the chi-square statistic to de-termine whether the style distribution of user downloads are statistically similar to the style distribution of their libraries. First, we determined the background probability of a song being drawn from a given style based on the style distribu-tions of the entire network. This background probability is calculated in Equation 1. Figure 5: The distribution of similarity scores from Day 52 -81 of the P2P data. Positive scores indicate a user X  X  downloads are more like his/her library than the background network distribution.
 We can calculate a similar probability for a user sharing a song in a given style.
 Given a user X  X  downloads, we can calculate the number of expected songs downloaded in each cluster by a user for both the background probability and the library probability. Using these expected values, we can calculate two chi-square statistics to determine how similar a user X  X  downloads are to the background style distributions and to their shared library distributions. Using the difference between these two statistics, we can determine if users are more like the network or more like their libraries. Figures 5 and 6 show the distributions of these statistics in the data. Because the majority of the non-zero scores are positive, we can conclude that users tend to download in proportion to the styles present in their shared libraries. The negative scores are problematic, how-ever, as this indicates there are some users whose downloads are much more like the overall network and less like their own libraries. We explored this phenomenon by comparing the number of files shared and the number of downloads for each user. As is evident in Figure 6, the users with nega-tive scores tend to download proportionally more songs than they share compared to the rest of the population. These users, called freeloaders , abuse the network by download-ing many files without sharing those files and allowing other users to download files from them. This is evident in Fig-ure 6. Because we would like to discourage freeloading, we will not consider freeloaders when designing our networks.
Because users X  downloads are similar to their libraries we can design an overlay network to connect users to sharers most likely to satisfy the anticipated queries of the down-loader, making the music they prefer easier to find. We define the expected number of files that a sharer provides to a downloader as where P d ( s i ) is the probability of style i being downloaded by downloader d and S u ( s i ) is the set of songs shared by user Figure 6: Comparison of downloads and files shared for a given style distribution score. Users with pos-itive scores download files from the same styles that are present in their libraries. Users with negative scores are primarily freeloaders who download many times without making those files available to the net-work. The x-axis is the same in both (a) and (b) and there is a 1:1 correspondence between the points. u in style i not already owned by d . For each downloader we can rank every other user based on the expected num-ber of new songs they might provide. As desired, users who share many files will likely have a large number of expected downloads for other users. However, having too many users connecting to a single other user causes an unbalanced dis-tribution of work among all of the users. Using these ranked lists, we can create overlay networks with logical connections between the set of users and the top n other users in their ranked list. It is also possible to consider a hybrid approach where given a degree limit, l , a user selects k users from their ranked list and l  X  k additional random links. This hybrid approach increases the connectivity of the resulting graph and leads to some important performance trade-offs, as described in the next section.
We compared four different types of overlay networks: (1) networks using HDP styles; (2) networks using random styles; (3) networks using direct file similarity; and (4) ran-dom networks. To avoid edge effects and other anomalies, we analyzed a 30 day period from the middle of the data. We examined how performance was affected by the num-ber of connections to other users (i.e., out degree) and the number of random connections. To better understand the effect of network size on performance, we analyzed 1, 2, 3, and 4-week samples from the original 30 days. The actual file downloads recorded in each sample time period were re-played over a simulated overlay network.

For each of the four types of overlay networks, we con-sidered out degrees for each user ranging between 3 and 10. Each user was allowed the same number of connections. Users were connected to the top users in their ranked list for each of the non-random methods. Experiments using the hybrid approach described above varied the number of random links between 0 and the out degree. For example, if a user was allowed 5 outgoing connections, we simulated networks with between 0 and 5 random links.

As the networks increase in size and in the number of attempted queries, HDP begins to outperform the other ap-proaches. As shown in Figure 7(a), the overlay networks based on the HDP styles satisfy more queries within one hop Figure 7: Performance of network overlays on 1250 transfers from Days 22-51 of the P2P data with users connecting to 5 other users. (a) Number of hops needed to satisfy queries. Hops are measured by the shortest path in the overlay network (b) Nodes vis-ited if the search stopped after satisfying the query. Totals are averages over 10 runs. than than the equivalent random styles, similarity graph and random graph of the same degree. After one hop, the other approaches begin to catch up. In Figure 7, overlays followed by 3,2 represent a graph with 3 links chosen from the cluster and 2 random links. The best overall strategy with degree 5 is the hybrid HDP. After 2 hops, it performs equivalently to Similarity 3,2, but due to larger number of queries sat-isfied in one hop, the hybrid HDP approach bothers fewer users overall. Figure 7(b) demonstrates the total number of users needed to satisfy all the queries in days 22-51, if we were able to stop the search process at the level that sat-isfies the query. As one might expect, satisfying queries in a fewer number of hops causes an exponential reduction in the number of users queried. Even more difficult queries re-quiring a larger number of hops using the HDP styles never bother more users than the other overlay networks.
There are two factors that lead to increased performance of a single hop in the HDP and random style approaches. First, the HDP approach is attempting to connect users with similar music preferences. If the approach is working, then users are likely to find files they wish to download within a smaller number of hops than other approaches. Second, both the HDP approach and the random style approach fa-vor connections to users with many shared files. This makes a large number of files available within a very few number of hops. If the requested file is not shared in one of these large libraries, then it may very difficult or even impossible to search the entire network for that file.

The hybrid approach is designed to counteract imbalanced work loads and the difficulties of finding rare songs. By al-lowing a small number of random links, the overall connec-tivity of the network increases as users are randomly con-nected to other users regardless of preference. This causes a small decrease in the number of queries satisfied within a sin-gle hop in exchange for satisfying many more of the queries for rare songs. The intuitions of small world network could explain the results of the hybrid approaches shown in Fig-ure 7. According to Watts and Strogatz [15], nodes in small world networks are connected to many nodes within their cluster with a few long range or random links connecting the clusters. This also suggests an alternative method for searching in overlay networks. By maintaining multiple sets of connections, it would be possible to first search just the HDP style connections one hop away, and then, if the file Table 2: Summary of performance on 1051 queries from day 22 through day 51. HDP, Random, and Random Cluster results indicate success within a single hop. An asterisk (*) denotes significant im-provements from the DHT. ( p  X  0 . 02) isn X  X  found, query a set of random connections. This ap-proach has the benefits from the availability of large shared libraries without sacrificing ability to find rare files.
Recently, Loo et al. [10] described an approach for query-ing P2P networks that combines a distributed hash table (DHT) with a pre-existing P2P network. Because DHTs only utilize O (log( n )) nodes per query, where n is the num-ber of users, rare files are easily found without the exponen-tial work typical with flooding search. For popular queries on sufficiently large networks, however, DHTs are outper-formed by P2P networks with random overlays. Due to the large increase in single hop performance using the HDP over-lays, we are able to demonstrate significant improvements using the combination of an HDP overlay (out degree=3) and a DHT. These results are summarized in Table 2.
We chose HDPs to model musical styles. HDPs come from a family of soft-clustering techniques for topic detection in documents. The first of these approaches, probabilistic latent semantic indexing (pLSI), [7], has some difficulties with the generative semantics of the model making it very difficult to apply the model to new data. Latent Dirichlet allocation (LDA) [2] was designed to correct the generative semantics of the pLSI model and provide a more formal statistical model. HDPs were designed to be a hierarchical version of LDA that removed the requirement of specifying the number of latent topics a priori . Lavrenko presents an alternative approach to topic detection based on kernels [9]. He claims that HDPs and LDA are not desirable because they tend to lump outliers into existing clusters rather than creating new clusters. We experienced this with classical MP3 files; however, the amount of traffic due to these files was negligible when compared to the entire network.
Newman provides an overview of work analyzing graph structure and an understanding of how structure influences the function of the graph [11]. The work of Domingos and Richardson [6] and Kempe, Kleinberg and Tardos [8] provide insight into how people can be placed in a social network to maximize the influence they have on their surrounding neighbors. While our work does not seek to provide rec-ommendations for files, these approaches could be used to determine how central a particular user should be in the net-work. This could be used to create overlay networks that account for popularity trends of files in the system by plac-ing users sharing popular files at the center of the network.
This research is supported by NSF and DARPA under contract numbers IIS0326249 and HR0011-04-1-0013. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation hereon. The views and conclusions con-tained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements either expressed or implied, of NSF, DARPA, or the U.S. Government. [1] The Chord Project , [2] D.M. Blei, A.Y. Ng, and M.I. Jordan. Latent Dirichlet [3] J. Chu, K. Labonte, and B. N. Levine. Evaluating the [4] E. Cohen, A. Fiat, and H. Kaplan. Associative search [5] A. Crespo and H. Garcia-Molina. Semantic overlay [6] P. Domingos and M. Richardson. Mining the network [7] T. Hofmann. Probabilistic Latent Semantic Indexing. [8] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [9] V. Lavrenko. A Generative Theory Of Relevance . PhD [10] B.T. Loo, J.M. Hellerstein, R. Huebsch, S. Shenker, [11] M.E.J. Newman. The structure and function of [12] K. Sripanidkulchai, B. Maggs, and H. Zhang. Efficient [13] Y.W. Teh, M.I. Jordan, M.J. Beal, and D.M. Blei. [14] Y.W. Teh, M.I. Jordan, M.J. Beal, and D.M. Blei. [15] D. J. Watts and S. H. Strogatz. Collective dynamics of
