 Personalized article recommendation is important for news portals to improve user engagement. Existing work quan-tifies engagement primarily through click rates. We sug-gest that quality of recommendations may be improved by exploiting different types of  X  X ost-read X  engagement signals like sharing, commenting, printing and e-mailing article links. Specifically, we propose a multi-faceted ranking problem for recommending articles, where each facet corresponds to a ranking task that seeks to maximize actions of a particular post-read type (e.g., ranking articles to maximize sharing actions). Our approach is to predict the probability that a user would take a post-read action on an article, so that articles can be ranked according to such probabilities. How-ever, post-read actions are rare events  X  enormous data sparsity makes the problem challenging. We meet the chal-lenge by exploiting correlations across different post-read ac-tion types through a novel locally augmented tensor (LAT) model, so that the ranking performance of a particular ac-tion type can be improved by leveraging data from all other action types. Through extensive experiments, we show that our LAT model significantly outperforms a variety of state-of-the-art factor models, logistic regression and IR models. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information filtering General Terms: Algorithms Keywords: Multi-faceted, post-read, tensor model
Publishing links to news articles has become important to facilitate information discovery on the Web. Users visit-ing a news website do not have a specific objective in mind and simply want to be informed about news stories that are important to them, or learn about topics of their interest.  X 
This work was conducted when all authors were affiliated with Yahoo! Quality of recommended links is crucial to ensure good user engagement in both short and long terms. But the explicit signals about what the user truly wishes to see is typically weak. Thus, it is important to consider a broad array of complementary indicators of users X  interests  X  novel tech-niques which can effectively leverage these weak signals are desired.

The primary indicator of user engagement used in most existing work is click-through rate or CTR, i.e., the proba-bility that a user would click an article when a link to the article is displayed, and articles are usually ranked to op-timize for it [6, 2, 12]. We argue that merely using CTR to rank news articles is not sufficient since user interaction with online news has become multi-faceted. Users no longer simply click on news links and read articles  X  as shown in Figure 1, they can share it with friends, tweet about it, write and read comments, rate other users X  comments, email the link to friends and themselves, print the article to read it thoroughly offline, and so on. These different types of  X  X ost-read X  actions are indicators of deep user engagement from different facets and can provide additional signals for news recommendations. We will use facet and post-read ac-tion type interchangeably. For example, news articles can be ranked for individual facets based on the predicted ac-tion rates. We can also consider using combinations of both CTR and those post-read action rates together to blend news articles so that such a ranking can be potentially useful for users not only clicking on the articles, but also sharing or commenting them after reading.

However, to the best of our knowledge, little prior work provides a thorough analysis of these post-read actions and our understanding of them is very limited. For example, how indicative is the CTR of an article to those post-read actions? Do users in different age groups have different pref-erences for those post-read action types? How difficult is it to predict the post-read action rates? To answer these ques-tions, we collected and analyzed a large dataset from an major online news portal. Interestingly, we found that post-read actions are mostly orthogonal to CTR. For example, the kinds of articles that users like to share are quite different from those they like to read, suggesting two distinct types of users X  news consumption: private reading and public shar-ing. A good news recommendation system should provide ranking capabilities for both. Furthermore, our analysis shows that different users prefer different post-read actions but the signal-to-noise ratios of those post-read actions are much lower than clicks, suggesting the need for advanced modeling techniques.
The main challenges in modeling post-read actions are due to data sparsity which is more severe than the sparsity of CTR estimation because a post-read action can only hap-pen after a user clicks. To our knowledge, little work in news recommendation has considered the use of such signals de-spite the availability of post-read behavioral data on many online news sites. In fact, an increasing number of users are using social media to actively promote/demote news ar-ticles through their circles and are freely expressing their opinions through comments. The focus of this paper is on machine learning techniques that can mitigate data sparsity and provide reliable estimates of post-read action rates that is essential to incorporate such signals into news recommen-dation.

Fortunately, our analysis also shows positive correlations among different types of post-read actions. Exploiting such correlations helps in borrowing or transferring information across action types and thus reduce data sparsity. We model such correlations among post-read action types through a tensor product of latent factors of a user, an item (i.e., ar-ticle) and an action type. The tensor product is further augmented by local user and item factors that are specific to the action type, in order to capture unique patterns in the action type.
 Our contributions are as follows: (1) Our data analysis in Section 2 unveils interesting post-read behavior that has not been reported in the literature. (2) Based on the analysis, we propose a new problem of predicting the probabilities that a user would take actions of different types after reading an article, which provide a principled approach to ranking articles according to different action types (i.e., facets). (3) To solve the problem, we propose a novel Locally Augmented Tensor model (LAT) in Section 3 that effectively exploits the correlations in noisy and sparse post-read data. (4) We then empirically show that LAT outperforms a variety of state-of-the-art matrix factorization methods, logistic regression and baseline IR models in Section 4. These contributions open the door to effective use of multi-faceted ranking to improve news recommendation on websites.
We study post-read behavior based on data collected from a major news site in the US that has millions of visitors on a monthly basis. Although this does not represent the en-tire news reading population in the US and elsewhere in the world, it has a large enough market share to study online news consumption behavior in the US. The site provides var-ious functionalities for users to act after reading an article. Figure 1 shows a portion of a typical news article page. On top are links/buttons that allow a user to share articles on Figure 2: Distribution of news articles over cate-gories various social media websites such as Facebook, Twitter and LinkedIn. The user can also share the article with others or herself via email or by printing a hard copy. At the bot-tom portion of the page, the user can leave comments on the article or rate other users X  comments by thumb-up or thumb-down votes.

In addition to links/buttons that facilitate post-read ac-tions, most article pages on this site publish a module that recommends interesting article links. This module is an im-portant source to create page views on the site and hence rec-ommends article links that maximize overall click-through rates. To estimate the CTR of each article unbiasedly, a small portion of the user visits are shown a random list of articles and the CTR estimated from this small portion of traffic is used to perform our CTR analysis. Source of Data: The data used in our analysis was col-lected from Feb to May in 2011. We collected two kinds of data  X  (1) all article page views on the news site to study post-read actions (these page views are generated via clicks on links to news articles published by the site on the web); and (2) click logs from the module as described earlier. To distinguish link views on the module from page views of news article pages (after clicking article links), we shall refer to the former as  X  X inkview X  while the latter is referred to as  X  X ageview X . For instance, using this terminology, pre-read article click-through rate (CTR) is computed as the number of clicks divided by the number of linkviews on the mod-ule and post-read Facebook share rate (FSR) is computed as the number of sharing actions divided by the number of pageviews. Post-read action rates of other types can be computed similarly. We focus on the following post-read ac-tions: Facebook share, email, print, comment, and rating. Note that LinkedIn and Tweeter sharing actions are very rare in the period of our data.
 Data Diversity: We selected articles that were shown on the module and were clicked at least once, received at least one comment and one post-read action type out of Facebook share, email and print. This gives us approximately 8K arti-cles that were already classified into a hierarchical directory by the publishers. We use the top three levels of the hier-archy in our analysis. The first level of the hierarchy has 17 categories; the distribution of article frequency in these categories is shown in Figure 2. As evident from this figure, news articles published on the site are diverse in nature and provides a good source to study user interaction with online news. We also obtain user demographic information which Figure 3: Correlation between different action types (diagonals cells are not of interest) includes age, gender and geo-location (identified through IP address). All user IDs are anonymized. In total, we have hundreds of millions of pageview events in our data which are sufficient for us to estimate the post-read action rates.
In this section, we investigate the relationship between pre-read clicks and post-read actions. For example, is a highly clicked article also highly shared or commented by users? For each article, we compute the article X  X  overall click-through rate (CTR) on the module and post-read ac-tion rates of different types. In Figure 3, we show the corre-lation between clicks and other actions types using Pearson X  X  correlation (the left most column or the bottom row). We observe very low correlation between click rates and other post-read action rates. We also computed the correlations after stratifying articles by categories and found that the correlations are still very low. This lack of correlation is per-haps not surprising: clicks are usually driven by user X  X  topi-cal interest in certain articles versus others, while post-click behaviors are inherently conditioned on clicks and hence top-ical interest. Thus, ranking articles using CTR and other post-click indicators would likely lead to different rankings. For instance, if the goal of a news website is to maximize CTR but also ensure a certain minimum number of sharing actions, then the ranking method should take both CTR and share rates into consideration.
In Figure 3, we also show all pairwise Pearson X  X  correla-tions among post-read action types, computed using article-level action rates. We observe positive correlations among various post-read action types; Mail has high correlation with Facebook and print, but not with comment and rat-ing. There is high correlations among Facebook, mail, and print. Not surprisingly, comment and rating are also highly correlated. These provides evidence of being able to lever-age correlations among post-read action types to improve post-read action prediction.

A word of caution: it is not necessary that correlations will hold when the data is disaggregated at the (user, item) level since our data is observational and subject to various sources of bias. It is not possible to study correlations at the (user, item) level through exploratory analysis due to lack of replicates; we will study this problem rigorously through a modeling approach described in Section 3. The exploratory analysis is shown to provide a flavor of our data and to gain some insights at an aggregate level.
We now compare users X  reading behavior with their post-read behavior. Specifically, is post-read behavior uniform across different article types or user types? Does Joe, a typical young male from California comment and share most of the articles he reads?
To understand this, we use a vector of the fractions of pageviews in different article categories to represent the read-ing behavior. One can think of this vector as a multinomial probability distribution over categories; i.e., the probability that a random pageview is in a given category. Similarly, post-read behavior of an action type is represented as a vec-tor of fractions of post-read actions of that type in different categories. To compare a post-read behavior vector with the reading behavior vector, we compute the element-wise ratio between the two vectors. Figure 4(a) shows these ra-tios on the log-scale using the top 10 most viewed categories, where the categories are ordered according to the numbers of pageviews they received (highest on the left). All the sample sizes are sufficiently large (with at least tens of thousands of post-read actions) to ensure statistical significance. To help understand this plot, let us consider the green color (i.e., negative value) in the (mail, conflicts) cell for instance. It indicates that a typical user is more likely to read an article about conflicts than email it. In general, if post-read action behavior of users were the same as reading behavior or uni-form across news types, the ratios (on log-scale) should be all close to 0. Obviously this is not the case for all action types as we see both  X  X ot X  and  X  X old X  cells in the plot.
Some interesting tidbits. Users are more likely to read ar-ticles about crime, politics and conflicts than to share them with friends via email or on Facebook; they are more likely to read about disaster and science &amp; technology but reluc-tant to comment on them. When it comes to science and religion, they are eager to share more. They are also more open to leave comments and engage in discussions in a public forum on matters of politics.
 We observe an interesting pattern in news consumption: Reading news articles is a private activity, while sharing (Facebook and mail) or expressing opinions (comment and rating) on articles is a public activity and there is difference in a typical user X  X  public and private activity. Users tend to share articles that earn them social prestige and credit but they do not mind clicking and reading some salacious news in private.
The previous subsection showed interesting differences in read and post-read behavior across different article types. In this section, we study variation in post-read action rates by slicing and dicing the data at different resolutions. We note that analysis at some coarse resolution for data ob-tained through a non-randomized design may not reveal the entire picture; ideally such inferences should be drawn af-ter adjusting for data heterogeneity at the finest, i.e, (user, item) resolution. It is impossible to study variation at this fine resolution through exploratory analysis due to lack of replicates. Our goal in this section is to study variation at resolutions where enough replicates exist. Such an analysis also provide insights into the hardness of predicting action rates and whether sophisticated modeling at fine resolutions is even necessary. For instance, if all science articles behave rates of different types by article categories Figure 5: Post-read action rate variation over age-gender segments similarly, it is not necessary to model data at the article level within the science category.
 Variation across article categories: To study variation in post-read action rates across article categories, we com-pute the ratio between the category-specific post-read action rates (i.e., #actions in the category divided by #pageviews in the category) and the global action rate (i.e., total #ac-tions divided by total #pageviews) using the top 10 most viewed categories for each action type. Interestingly, this is exactly what Figure 4(a) and Figure 4(b) show. As we noted earlier, there is variation in action rates at this resolution as evident from the  X  X ot X  and  X  X old X  cells.
 Variation across user segments: We segment users by age and gender and show post-read action rates for the two genders across different age-groups in Figure 5. Once again we see variation. Some interesting observations: Facebook share rates are highest among young and middle aged users. Users in older age groups tend to mail more but young users tend to share more on Facebook. We see females to have sur-prisingly high share rates and male users tend to comment more on articles. We also include pre-read click actions in this figure and observe that users in older age groups tend to click more; males across all age-groups are more active clickers than females.
 Variation within categories and segments: We now dig deeper and analyze variation at the article resolution after stratifying our data by article categories and user seg-ments. High within-category/segment variations at the arti-cle level indicate excessive heterogeneity with categories and (a) on article categories segments and suggest the need to model the rates at finer resolutions. To study such variation, we leverage the coef-ficient of variation defined as  X / X  , where  X  is the standard deviation of article action rates within a given category (or category  X  user segment) and  X  is the average article action rate in the category (or category  X  user segment).  X / X  is a positive number; smaller values indicate less variation. In general, values above 0 . 2 are indicative of high variation.
In Figure 6(a) and Figure 6(b), we show the distribution of coefficient of variation with respect to article categories and the cross-product of categories with user age-gender. From these two figures, we can see that all post-read actions have much larger coefficients of variation than click. This means that although there is variation in average post-read behav-ior across categories and user segments, the variation at the article resolution within each such stratum is high making it difficult to predict article post-read action rates than article click rates based on the category information. Comparing the two figures, we can see that adding user features helps little in terms of reducing coefficients of variation indicat-ing that stratification by user segments does not help in explaining article level variation within each category. Per-haps users with a given (age, gender) segments have different news consumption behavior at the article level.

Our exploratory analysis suggests that predicting post-read actions of any type is harder than estimating CTR. We also see that while using features like article category and user demographics are useful, there is heterogeneity at the article and user resolution that has to be modeled. We also see evidence of positive correlations among post-read action types; it is interesting to study if such correlations can make the estimation task any better. We explore such an approach by modeling all post-read action types simultaneously at the finest (user, item) resolution in section 3.
Because post-read actions have low correlations with clicks, rankings of articles according to CTR would be likely to be different from rankings of articles according to different post-read action rates. It is useful for news portals to have rankings according to different criteria, in order to enrich user experience or serve users depending on the criteria that they prefer. As a first step, here we study how to effectively rank articles for each post-read type, and defer the problem of how to effectively combine rankings of different types to improve user experience to future work.

In this section, we present our locally augmented tensor (LAT) model for predicting users X  post-read rates, based on which articles can be ranked. Given a user, an item (i.e., article) and a post-read action type (e.g., comment, Face-book share), we want to predict the probability that the user would take the action after reading the item. The main challenges are:  X  Data sparsity: Post-read actions are rare events. Most  X  Diverse behavior across action types: As we saw in Sec-To handle data sparsity, an attractive approach is to appro-priately pool the action data of a user from all types, so that the action data of one type can be used to improve the pre-diction performance for another type. However, naive ways of pooling action data that ignore the differences between action types may lead to poor performance, especially for our sparse post-read data.
 Problem definition: Consider an online news system with M users, N items and K post-read action types. Let y ijk denote whether user i takes a post-read action of type k on item j . If the user takes the action, y ijk = 1; if the user reads the item and does not take the action, y ijk = 0; if the user does not read the item, y ijk is unobserved. We also call y ijk the observation or response of user i to item j of type k . Each user is associated with a feature vector (e.g., age, gender, geo-location). Each item is also associated with a feature vector (e.g., content categories, words and entities in the item). Because i always denotes a user and j always denotes an item, we slightly abuse our notations by using x to denote the feature vector of user i and x j to denote the feature vector of item j . Given user features, item features and a set of training observations, our goal is to predict the response of a set of (user, item, action type) triples that do not appear in the training data.

We model the data using variants of factor models. We begin with a review of baseline matrix factorization models and then extend them to address the above challenges.
Matrix factorization is a popular method for predicting user-item interaction. User-item interactions can be repre-sented through a M  X  N matrix Y , where the value y ij of the ( i, j ) th entry is the response of user i to item j . Notice that this is a matrix with many unobserved (i.e., missing) entries because a user typically does not interact with many items. The main idea of matrix factorization is to obtain two low rank matrices U M  X  F and V N  X  F such that Y is close to the product UV  X  measured in terms of a loss function l ( Y , UV  X  ) (e.g. squared-error, logistic). Here F is much smaller than M and N . Such a decomposition enables us to predict the unobserved entries in the response matrix.
Each row u i of matrix U is called the factor vector of user i , representing his/her latent profile. Similarly, each row v j of matrix V represents the latent profile of item j . Intuitively, the inner product u  X  i v j is a measure of similarity between the profiles of user i and item j , representing how much i likes j . It is common to also add a bias term  X  i each user i to represent his/her average response to items, and a bias term  X  j for each item j to represent its popularity. Then, the response y ij of user i to item j is predicted by  X  y
Let  X  X  X  ( y, x ) =  X  log(1 + exp { X  (2 y  X  1) x } ) denote the logistic log-likelihood for a binary observation y . The loss function is given by Optimizing the loss function in Equation 1 tends to give es-timates that overfit sparse data since the number of param-eters is too large even for small values of F . It is customary to impose penalty (regularization) to avoid overfitting, the most commonly used penalty is to constrain the L 2 norm of parameters. Thus, we obtain parameter estimates by mini-mizing where the  X  2  X  s are tuning constants. Stochastic gradient descent (SGD) is a popular method to perform such op-timization. However, our models involve several tuning con-stants that are hard to estimate using procedures like cross-validation. Further, SGD also requires tuning learning rate parameters. Thus, we pursue a different estimation strategy for fitting our models by working in a probabilistic frame-work and using a Monte-Carlo Expectation Maximization (MCEM) procedure. The MCEM approach we follow is both scalable and estimates all parameters automatically through the training data. Observation model: Matrix factorization can also be in-terpreted in a probabilistic modeling framework [18]. The given y ij s are the observations, based on which we want to estimate the unobserved latent factors  X  i ,  X  j , u i and v numerical response, it is common to use a Gaussian model. where N (  X ,  X  2 ) denote a Gaussian distribution with mean  X  and standard deviation  X  2 . For binary response, it is common to use a logistic model. For ease of exposition, we use y ij  X   X  i +  X  j + u  X  i v that y ij is predicted based on  X  i +  X  j + u  X  i v j either using the Gaussian model or the logistic model.
 Regression priors: Although u i and v j are low dimen-sional, there are still a large number of factors to be esti-mated from sparse data, which can similarly lead to over-fitting. A common approach is to shrink the factors toward zero; i.e., if a factor is not supported by enough data, it X  X  estimated value should be close to zero. When features are available, we can achieve better performance by shrinking the factors toward values predicted by features [1], instead of zero. For example, if user i has very few activities in the training data, instead of ensuring u i to be close to zero, we predict u i using a regression function G x i , where G is the regression coefficient matrix learned from training data through linear regression. Notice that u i is a vector; thus, G is a matrix, instead of a vector. If features are predictive, then we can obtain good u i estimates even for users with-out any training data. Specifically, we assume the following priors. Training and prediction: We defer the training algorithm to Section 3.4. Here, we note that this model is a generative model that specifies how the observations y ij are generated according to the latent factors  X  i ,  X  j , u i and v j , which in turn are generated according to the prior parameters ( g , G , d , D and the  X  2  X  s). Given a set of observations, we first obtain the maximum likelihood estimate (MLE) of the prior parameters. Then, based on the MLE of prior parameters and the observations, we obtain the posterior mean of  X  i u i and v j , which then can be used to predict the response of an unseen ( i, j ) pair by  X  i +  X  j + u  X  i v j . Baseline models: Two straightforward ways of applying matrix factorization to our problem are as follows: Notice that SMF is a strong baseline because for users and items with large number of training samples, their factors can be estimated accurately. For users and items without much training data, their factors can still be predicted by features. Compared to CMF, SMF has K times more factors to be estimated from data and is more sensitive to data sparsity. Although CMF is less sensitive to data sparsity, it ignores the behavioral differences across different action types, which may lead to bias and poor performance.
We now introduce the locally augmented tensor (LAT) model, which addresses data sparsity through tensor factor-ization, augmented with SMF to model the residuals locally for each action types. We first specify the model and then discuss how it works.
 Model specification: The action y ijk that user i takes on item j of type k is modeled as: where h u i , v j , w k i = uct of three vectors u i , v j and w k , and u i [  X  ] denotes the  X  th element in vector u i . The intuitive meaning of the factors are as follows.  X   X  ik is the type-specific bias of user i .  X   X  jk is the type-specific popularity of item j .  X  h u i , v j , w k i measures the similarity between user i  X  X   X  u  X  ik v jk also measures the similarity between user i and To contrast the global factors u i , v j , we call the type-specific factors u ik , v jk local factors . Since we augment the tensor product with the inner product of local factors, the resulting model is called the locally augmented tensor model. The priors of the factors are specified as follows.  X  ik  X  N ( g  X  k x ik + q k  X  i ,  X  2  X ,k ) ,  X  i  X  N (0 , 1) (4)  X  jk  X  N ( d  X  k x jk + r k  X  j ,  X  2  X ,k ) ,  X  j  X  N (0 , 1) (5) u ik  X  N ( G k x i ,  X  2 uk I ) , v jk  X  N ( D k x j ,  X  2 where g k , q k , d k , r k , G k and D k are regression coefficient vectors and matrices similar to those discussed in Section 3.1. These regression coefficients are to be learned from data and provide the ability to make predictions for users or items that do not appear in training data. The factors of these new users or items will be predicted based on their features through regression.
 Training and prediction: Given training data y = { y ijk } , the goal of the training process is to learn the latent factors  X  = {  X  ik ,  X  jk ,  X  i ,  X  j , u i , v j , w k , u ik , v eters  X  = { g k , d k , q k , r k , G k , D k , the  X  2  X  of regression coefficients and variances) from the data y . The training algorithm will be given later. After train-ing, given an unobserved (user i , item j , action type k ) triple, we predict the response as follows. If both user i and item j have some type-k observations in the training data, we just use their learned factors to make a prediction training data but has no type-k observation (  X  i and u i available from training but not  X  ik and u ik ), then we first predict  X  ik as g  X  k x ik + q k  X  i and u ik as G k x i , and then use Equation 3 to predict the response y ijk . Other cases can be handled in a similar manner. Relation to prior work  X  SMF and BST: If we set  X  ,  X  j , u i , v j and w k to zero, we obtain the SMF model (defined in Section 3.1). If we set u ik and v jk to zero, we obtain the bias-smoothed tensor (BST) model proposed in [4] for a multi-context comment-rating prediction problem: Although LAT is a conceptually simple combination of SMF and BST, it significantly improves the ranking performance over SMF and BST (see Section 4), and also impose a model training challenge. Notice that LAT has many latent factors and parameters to be learned. It may be sensitive to over-fitting. However, because of the regularization provided by the priors (Equation 4 to 7), overfitting can be prevented when the prior variances are appropriately learned.
Since SMF, CMF and BST are special cases of LAT, we only discuss the training algorithm for LAT. Based on Equa-tions 3 to 7, the joint log-likelihood of y and  X  given  X  is where  X  y ijk =  X  ik +  X  jk + h u i , v j , w k i + u  X  i training is to obtain MLE of  X  ; i.e., which can be obtained using the MCEM algorithm [3]. The MCEM algorithm iterates between an E-step and an M-step until convergence. Let  X   X  ( t ) denote the current estimated value of the set of prior parameters  X  at the beginning of the t th iteration.  X  E-step: We take expectation of the complete data log  X  M-step: We maximize the expected complete data log Note that the actual computation in the E-step is to generate sufficient statistics for computing arg max  X  f t (  X  ), so that we do not need to scan the raw data every time when we need to evaluate f t (  X  ). At the end, we obtain the MLE of  X  modulo local maximums and Monte Carlo errors. We can then use the estimated  X   X  to obtain the posterior mean of the factors (  X  | y ,  X   X  ) again through Gibbs sampling. See [1] for an example of such an MCEM algorithm.
 Computational complexity: We use a Gibbs sampler in the E-step, which is actually highly parallelizable. Take user and item factors for example. Conditional on global factors u , v j , the local factors u ik , v jk for each action type can be sampled in parallel since they are only connected to each other through the global factors. When sampling local fac-tors for each action type, we note that given v jk s, the u are conditionally independent and can be sampled in parallel (similar assertion holds for v jk s). Conditional on local fac-tors, the global factors can also be sampled efficiently since the u i s and v j s are conditionally independent. The com-plexity of sampling a factor vector is at most O ( F 3 ) and since F is typical small, the E-step is computationally effi-cient. The major computation in the M-step involves fitting standard linear regressions, which can also be parallelized. Thus, our MCEM algorithm is computationally efficient. We note that this training algorithm is similar to [4, 1] and lo-gistic response can be handled by variational approxima-tion [10]. Thus, we omit the details and will provide links to our code and detailed derivations.
We evaluate the models presented in Section 3 using post-read data collected from a major online new site. We col-lected post-read actions from 13,739 users, each of whom has at least 5 actions for at least one facet, to 8,069 items, each of which received at least one post-read action for each type. As a result, we obtain 2,548,111 post-read action events, where each event is identified by (user, facet, item). If the user took an action on the item in the facet, the event is pos-itive or relevant (meaning that the item is relevant to the user in the facet); if the user saw the item but did not take an action in the facet, the event is negative or irrelevant . In this setting, it is natural to treat each (user, facet) pair as a query ; the set of events associated with that pair defines the set of items to be ranked with relevance judgments coming from user actions. Notice that it is difficult to use editorial judgments in our setting since different users have different preferences for their news consumption.
 Evaluation metrics: We use mean precision at k (P@k) and mean average precision (MAP) as our evaluation met-rics, where mean is taken over the test (user, facet) pairs. P@k of a model is computed as follows: For each test (user, facet) pair, we use the model predictions to rank the items seen by the user in that facet and compute the precision at rank k , and then average the precision numbers over all the test pairs. MAP is computed in the similar way. To help comparison among different models, we define P@k Lift and MAP Lift over SMF of a model as the lift in P@k and MAP of the model over the SMF model, which is a strong baseline defined in Section 3.1. Take P@k for example; if P@k of a model is A and P@k of SMF is B , then the lift is A  X  B B Experimental setup: We create a training set, a tuning set and a test set as follows. For each user, we randomly select one facet in which he/she took some action and put all of the events associated with this (user, facet) pair into set A (for tuning and testing). The rest of the (user, facet) pairs form the training set . Different facets may be selected for different users. Recall that each (user, facet) pair rep-resents a query as in standard retrieval tasks. We then put 1/3 of set A into the tuning set and the rest 2/3 into the test set . The tuning set is used to select the number of latent dimensions of the factor models (i.e., the numbers of dimen-sions of u i , v j , w k , u ik , v jk ). Notice that the EM-algorithm used in our paper automatically determines all the model parameters except for the number of latent dimensions. For each model, we only report the test-set performance of the best number of dimensions selected using the tuning set.
The user features used in our experiments consist of age, gender and geo-location identified based on users X  IP ad-dresses. We only consider logged-in users; their user IDs are anonymized and not used in any way. The item features consists of article categories tagged by the publishers and the bag of words in the article titles and abstracts. Models: We compare there classes of models: (1) Latent factor models:  X  LAT: Locally augmented tensor model (Section 3.3).  X  BST: Bias-smoothed tensor model, which is a special  X  SMF: Separate matrix factorization (Section 3.1).  X  CMF: Collapsed matrix factorization (Section 3.1). Note that, for our experimental setup, a test event (user i , item j , facet k ) has no training data to determine factor vector u ik directly, but it will be predicted based on user features x ik . However, it is not the case for v jk , because events of item j in facet k may appear in training data. We also note that the Gaussian version gives better MAP values on the tuning set than the logistic version; so, we report the performance of the Gaussian version. (2) Logistic regression: This model called Bilinear uses the user features x i and item features x j to predict whether a user would take an action on an item. Specifically, where W k is the regression coefficient matrix for facet k . Notice that this model has a regression coefficient for ev-ery pair of an individual user feature and an individual item feature, which is fitted using Liblinear [8] with L 2 regulariza-tion, where the regularization weight is selected using 5-fold cross-validation. (3) IR models: We also consider a set of baseline IR mod-els. For these models, we build a user profile based on the training data by aggregating all the text information of the items on which the user took positive actions. We treat such user profiles as queries and then use different retrieval functions to rank the items. The IR models include:  X  COS: Vector space model with cosine similarity.  X  LM: The Dirichlet smoothed language model [23].  X  BM25: The best variant of Okapi retrieval methods [17]. Performance of IR Models: We first compare the base-Table 1: Overall performance of different models Table 2: Paired t-test result. Note that smaller level values represent stronger significance.
 line IR models in Figure 7. In this figure, we vary parameter  X  for LM and parameter k 1 for BM25. The other two param-eters are set at the recommended default values k 3 = 1000 and b = 0 . 75 in all the experiments. From this figure, we can see that both LM and BM25 can outperform COS, but the difference is not large. In the following, we use the BM25 with k 1 = 1 as the IR model to compare with other learning-based methods.
 Overall performance: The precision-recall curves aver-aged over all (user,facet) pairs in the test data of different models are shown in Figure 8(a), and P@1, P@3, P@5 and MAP are reported in Table 1. Notice that as k increases, the precision drops. It is because post-read actions are rare events; many users do not have 3 or 5 post-read actions in the test set. For example, if a user only had one action and saw at least five items in the test set, his/her P@5 is at most 1/5. To test the significance of the performance difference between two models, we look at P@k and MAP for each in-dividual (user, facet) pair and conduct paired t-test for the two models over all test (user, facet) pairs. The test result is shown in Table 2. In particular, LAT significantly outper-forms all other models. We find that the difference between BST and SMF and the difference between CMF and BM25 are insignificant.

We defer the comparison between LAT, BST and SMF to the breakdown analysis below. Here, we note that Bilin-ear outperforms CMF because CMF completely ignores the behavioral differences among action types. The fact that Bi-linear outperforms CMF shows that user and item features have some predictive power, but compared to SMF, these features are not sufficient to capture the behavior of indi-vidual users or items. We also note that BM25 is one of the worst performing models probably because it is the only model without supervised learning.
 Breakdown by facets: In Table 3, we break the test data down by facets and report P@1 for different models; the results for other metrics are similar. Here, we focus on the comparison between LAT, BST and SMF. Starting with BST vs. SMF, we see that BST outperforms SMF for the first three facets but underperforms for the last two facets. We note that the first three facets have more events in our dataset than the last two. The advantage of BST over SMF is that it has global factors; thus, the training actions in one facet are utilized to predict the test actions in other facets through the correlation among facets. However, BST is less flexible than SMF. In particular, it is not flexible enough to capture the differences among facets; thus, it is forced to fit some facets better than others. As expected, it fits the actions in facets with more data better than those with less data. LAT addresses this problem by adding facet-specific factors ( u ik and v jk ) to model the residuals of BST. As can be seen, LAT uniformly outperforms BST. It also outper-forms SMF except for Mail. The fact that SMF and Bilinear have the same performance for Mail suggests the difficulty of using latent factors to improve accuracy. Since LAT has more factors than SMF, it has a higher chance of overfitting. Breakdown by user activity levels: In Figure 8(b) and 8(c), we break test users down by their activity levels in terms of the numbers of post-read actions that they took in the training data. Here, our focus is also on comparing LAT and BST to SMP. Each curve represent the P@1 Lift or MAP Lift of each model over the SMF model as a function of the user activity level specified on the x-axis. As can be seen, LAT almost uniformly outperforms all other models. For users with low activity levels (0-5), there is almost no difference between LAT, BST and SMF because they all lack data and the predictions are mostly based on features. For users who took 5-50 post-read actions, we see the largest advantage of using LAT.
 Perceived differences among facets: In Table 4, we show some examples of the result of multi-faceted news rank-ing. On the top half of the table, we show top-ranked ar-ticles for an average user. On the bottom half, we show top-ranked articles for males with ages between 41 and 45. From this table, we can see that different facets have very different ranking results. For example, in the Facebook and Mail facets, many health-related articles are highly ranked. But for the Comment facet, political articles are usually pre-ferred. Furthermore, if we compare the males in the middle age with the overall population, we also see notable differ-ences. For example, although both populations have health-related articles in the Mail facet, middle-age males tend to mail more cancer-related articles. These differences confirm the need for personalized multi-facet ranking and our pro-posed method can address this need in a principled way.
Algorithmic news recommendation has received consid-erable attention recently. Traditional recommendation ap-proaches include content-based filtering and collaborative fil-tering techniques [25, 19, 11]. These techniques have been successfully applied to applications like movie or product recommendation [19, 14]. In particular, matrix factoriza-tion based collaborative filtering, which belongs to the fam-ily of latent factor models, have achieved the state-of-the-art accuracy [11]. Recently, these methods have been adapted for news recommendation. For example, [9] studied infor-mation novelty using content-based methods. In [6], col-laborative filtering was leveraged in an online news recom-mendation system. Hybrid approaches which combine both content-based and collaborative methods are also studied in news recommendation recently [13]. In the news domain, the existing work mainly ranks articles using clicks as the metric. Some recent work starts looking into other metrics such as social sharing [5]. To the best of our knowledge, little prior work has studied the news recommendation in a multi-faceted view, which becomes natural along with the popularity of Web 2.0. In our work, we define facets ac-cording to post-read actions and provide detailed analysis which shows the importance of multi-faceted news ranking. Furthermore, a novel matrix factorization based method to jointly model multi-type post-read actions is proposed.
Our work is related to faceted search [22, 24, 7]. The goal of faceted search is to use facet metadata of a domain to help users narrow their search results along different dimensions. In the most recent TREC Blog track 2009 [15], a special track of  X  X aceted blog distillation X  is initiated and the task of this track is to find results relevant to a single facet of a query such as  X  X pinionated X  X rticles in the blog collection. In these types of work, facets are metadata related to contents. The facets in our definition are based on user post-read actions and our multi-faceted ranking is to help users quickly get interesting news articles according to their preferred actions. Thus our work provides a novel angle to define facets.
The technique used in our paper is closely related to latent factor models such as matrix factorization or tensor decom-position. For example, singular value decomposition (SVD) based methods [11], tensor-based methods [16], and collab-orative competitive filtering [21] all belong to this family. All these methods did not consider post-read actions. In particular, our technique is related to the collective matrix factorization (CMF) [20] and bias-smoothed tensor (BST) model [4]. As compared in our experiments, our models are better than these existing ones in exploring the correlations among different post-read facets.
Jointly mining and modeling post-read actions of multiple types has not been previously studied in the literature. We conducted a rigorous study on post-read behavior on a ma-jor news portal with action types like facebook share, com-menting, rating that users engage in after reading an article. Through data analysis, we found some interesting patterns in news consumption when it comes to read and post-read behavior. Reading articles is private, post-read behavior like sharing and commenting are more public. Users tend to dif-fer in interesting ways in their public and private behavior when interacting with news. We found positive correlations among different action types and were able to exploit these through a tensor product of global user, item and facet fac-tors  X  the facet factors capture the correlations by a low-rank approximation. The tensor product is augmented using local factors to capture the local residuals to improve rank-ing performance of post-read action types. This opens the door to incorporate post-read engagement behavior in cre-ating new products/modules on news sites online. We plan to explore such possibilities in the future.
