 Picture an intense match point at the Wimbledon tennis championship, Nadal on the defense from Federer X  X  powerful shots. Nadal returns three straight hits to his forehand side. In the split second before the ball is back in his court, he forms an expectation about where Federer will hit the ball next X  X ill the streak of forehands continue or will there be a switch to his backhand. As the point continues, Nadal gains the upper ground and begins making Federer alternate from forehand to backhand to forehand. Now Federer finds himself trying to predict whether or not this alternating pattern will be continued with the next shot. These two are caught up in a high-stakes game of sequential effects X  X heir actions and expectations for the current shot have a strong dependence on the past few shots. Sequential effects play a ubiquitous role in our lives X  X ur actions are constantly affected by our recent experiences.
 In controlled environments, sequential effects have been observed across a wide range of tasks and experimental paradigms, and aspects of cognition ranging from perception to memory to language to decision making. Sequential effects often occur without awareness and cannot be overriden by instructions, suggesting a robust cognitive inclination to adapt behavior in an ongoing manner. Sur-prisingly, people exhibit sequential effects even when they are aware that there is no dependence structure to the environment. Progress toward understanding the intricate complexities of sequential effects will no doubt provide important insights into the ways in which individuals adapt to their environment and make predictions about future outcomes.
 One classic domain where reliable sequential effects have been observed is in two-alternative forced-choice ( 2AFC ) tasks (e.g, Jentzsch and Sommer, 2002; Hale, 1967; Soetens et al., 1985; Cho et al., 2002). In this type of task, participants are shown one of two different stimuli, which we denote as X and Y, and are instructed to respond as quickly as possible by mapping the stimulus to a corresponding response, say pressing the left button for X and the right button for Y. Response time (RT) is recorded, and the task is repeated several hundred or thousand times. To measure sequential effects, the RT is conditioned on the recent trial history. (In 2AFC tasks, stimuli and responses are confounded; as a result, it is common to refer to the  X  X rial X  instead of the  X  X timulus X  or  X  X esponse X . In this paper,  X  X rial X  will be synonymous with the stimulus-response pair.) Consider a sequence such as XY Y XX , where the rightmost symbol is the current trial ( X ), and the symbols to the left are successively earlier trials. Such a four-back trial history can be represented in a manner that focuses not on the trial identities, but on whether trials are repeated or alternated. With R and A denoting repetitions and alternations, respectively, the trial sequence XY Y XX can be encoded as ARAR . Note that this R/A encoding collapses across isomorphic sequences XY Y XX and Y XXY Y . The small blue circles in Figure 1a show the RTs from Cho et al. (2002) conditioned on the recent trial history. Along the abscissa in Figure 1a are all four-back sequence histories ordered according to the R/A encoding. The left half of the graph represents cases where the current trial is a repetition of the previous, and the right half represents cases where the current trial is an alternation. The general pattern we see in the data is a triangular shape that can be understood by comparing the two extreme points on each half, RRRR vs. AAAR and RRRA vs. AAAA . It seems logical that the response to the current trial in RRRR will be significantly faster than in AAAR ( RT RRRR &lt; RT AAAR ) because in the RRRR case, the current trial matches the expectation built up over the past few trials whereas in the AAAR case, the current trial violates the expectation of an alternation. The same argument applies to RRRA vs. AAAA , leading to the intuition that RT RRRA &gt; RT AAAA . The trial histories are ordered along the abscissa so that the left half is monotonically increasing and the right half is monotonically decreasing following the same line of intuition, i.e., many recent repetitions to many recent alternations. Many models have been proposed to capture sequential effects, including Estes (1950), Anderson (1960), Laming (1969), and Cho et al. (2002). Other models have interpreted sequential effects as adaptation to the statistical structure of a dynamic environment (e.g., Jones and Sieck, 2003; Mozer, Kinoshita, and Shettel, 2007). In this same vein, Yu and Cohen (2008) recently suggested a rational explanation for sequential effects such as those observed in Cho et al. (2002). According to their Dynamic Belief Model ( DBM ), individuals estimate the statistics of a nonstationary environment. The key contribution of this work is that it provides a rational justification for sequential effects that have been previously viewed as resulting from low-level brain mechanisms such as residual neural activation.
 DBM describes performance in 2AFC tasks as Bayesian inference over whether the next trial in the sequence will be a repetition or an alternation of the previous trial, conditioned on the trial history. If R t is the Bernoulli random variable that denotes whether trial t is a repetition ( R t = 1 ) or alternation ( R t = 0 ) of the previous trial, DBM determines P ( R t | preceding trial t , i.e., ~ R t  X  1 = ( R 1 ,R 2 ,...,R t  X  1 ) .
 DBM assumes a generative model, shown in Figure 2a, in which R t = 1 with probability  X  t and R t = 0 with probability 1  X   X  t . The random variable  X  t describes a characteristic of the environment. According to the generative model, the environment is nonstationary and  X  t can either retain the same value as on trial t  X  1 or it can change. Specifically, C t denotes whether the environment has changed between t  X  1 and t ( C t = 1 ) or not ( C t = 0 ). C t is a Bernoulli random variable with success probability  X  . If the environment does not change,  X  t =  X  t  X  1 . If the environment changes,  X  t is drawn from a prior distribution, which we refer to as the reset prior denoted by p (  X  )  X  Beta ( a,b ) .
 Before each trial t of a 2AFC task, DBM computes the probability of the upcoming stimulus condi-tioned on the trial history. The model assumes that the perceptual and motor system is tuned based on this expectation, so that RT will be a linearly decreasing function of the probability assigned to = 1 -P ( R t = R | ~ R t  X  1 ) on alternation trials.
 The red plusses in Figure 1 show DBM X  X  fit to the data from Cho et al. (2002). DBM has five free parameters that were optimized to fit the data. The parameters are: the change probability,  X  ; the imaginary counts of the reset prior, a and b ; and two additional parameters to map model probabilities to RTs via an affine transform. 2.1 Intuiting DBM predictions Another contribution of Yu and Cohen (2008) is the mathematical demonstration that DBM is ap-proximately equivalent to an exponential filter over trial histories. That is, the probability that the current stimulus is a repetition is a weighted sum of past observations, with repetitions being scored as 1 and alternations as 0 , and with weights decaying exponentially as a function of lag. The ex-ponential filter gives insight into how DBM probabilities will vary as a function of trial history. Consider two 4-back trial histories: an alternation followed by two repetitions ( ARR  X  ) and two alternations followed by a repetition ( AAR  X  ), where the  X  indicates that the current trial type is unknown. An exponential filter predicts that ARR  X  will always create a stronger expectation for an R on the current trial than AAR  X  will, because the former includes an additional past repetition. Thus, if the current trial is in fact a repetition, the model predicts a faster RT for ARR  X  compared to AAR  X  (i.e., RT ARRR &lt; RT AARR ). Conversely, if the current trial is an alternation, the model predicts RT ARRA &gt; RT AARA . Similarly, if two sequences with the same number of R s and A s are compared, for example RAR  X  and ARR  X  , the model predicts RT RARR &gt; RT ARRR and RT RARA &lt; RT ARRA because more recent trials have a stronger influence.
 Comparing the exponential filter predictions for adjacent sequences in Figure 1 yields the expecta-tion that the RTs will be monotonically increasing in the left two groups of four and monotonically decreasing in the two right groups. The data are divided into groups of 4 because the relationships between histories like AARR and RRAR depend on the specific parameters of the exponential fil-ter, which determine whether one recent A will outweigh two earlier A s. It is clear in Figure 1 that the DBM predictions follow this pattern. 2.2 what X  X  missing in DBM however, we see two significant pairs of sequence histories for which the monotonicity prediction does not hold. These are reliable aspects of the data and are not measurement error. Consider the circle on the left, in which RT ARAR &gt; RT RAAR for the human data. Because DBM functions approximately as an exponential filter, and the repetition in the trial history is more recent for ARAR than for RAAR , DBM predicts RT ARAR &lt; RT RAAR . An exponential filter, and thus DBM, is unable to account for this deviation in the data.
 To understand this mismatch, we consider an alternative representation of the trial history: the first-order sequence, i.e., the sequence of actual stimulus values. The two R/A sequences ARAR and RAAR correspond to stimulus sequences XY Y XX and XXY XX . If we consider an exponen-tial filter on the actual stimulus sequence, we obtain the opposite prediction from that of DBM: RT XY Y XX &gt; RT XXY XX because there are more recent occurrences of X in the latter sequence. The other circled data in Figure 1a correspond to an analogous situation. Again, DBM also makes a prediction inconsistent with the data, that RT ARAA &gt; RT RAAA , whereas an exponential filter on stimulus values predicts the opposite outcome X  RT XY Y XY &lt; RT XXY XY . Of course this analysis leads to predictions for other pairs of points where DBM is consistent with the data and a stimulus based exponential filter is inconsistent. Nevertheless, the variations in the data suggest that more importance should be given to the actual stimulus values.
 In general, we can divide the sequential effects observed in the data into two classes: first-and second-order effects. First-order sequential effects result from the priming of specific stimulus or response values. We refer to this as a first-order effect because it depends only on the stimulus values rather than a higher-order representation such as the repetition/alternation nature of a trial. These effects correspond to the estimation of the baserate of each stimulus or response value. They are observed in a wide range of experimental paradigms and are referred to as stimulus priming or response priming. The effects captured by DBM, i.e. the triangular pattern in RT data, can be thought of as a second-order effect because it reflects learning of the correlation structure between the current trial and the previous trial. In second-order effects, the actual stimulus value is irrelevant and all that matters is whether the stimulus was a repetition of the previous trial. As DBM proposes, these effects essentially arise from an attempt to estimate the repetition rate of the sequence. DBM naturally produces second-order sequential effects because it abstracts over the stimulus level of description: observations in the model are R and A instead of the actual stimuli X and Y . Because of this abstraction, DBM is inherently unable to exhibit first-order effects. To gain an understanding of how first-order effects could be integrated into this type of Bayesian framework, we reformulate the DBM architecture. Figure 2b shows an equivalent depiction of DBM in which the generative process on trial t produces the actual stimulus value, denoted S t . S t is conditioned on both the repetition probability,  X  t , and the previous stimulus value, S t  X  1 . Under this formulation, S t = S t  X  1 with probability  X  t , and S t equals the opposite of S t  X  1 (i.e., XY or Y X ) with probability 1  X   X  t . An additional benefit of this reformulated architecture is that it can represent first-order effects if we switch the meaning of  X  . In particular, we can treat  X  as the probability of the stimulus taking on a specific value ( X or Y ) instead of the probability of a repetition. S t is then simply a draw from a Bernoulli process with rate  X  . Note that for modeling a first-order effect with this architecture, the conditional dependence of S t on S t  X  1 becomes unnecessary. The nonstationarity of the environ-ment, as represented by the change variable C , behaves in the same way regardless of whether we use the model to represent first-or second-order structure. The complex contributions of first-and second-order effects to the full pattern of observed sequential effects suggest the need for a model with more explanatory power than DBM. It seems clear that individuals are performing a more sophisticated inference about the statistics of the environment than proposed by DBM. We have shown that the DBM architecture can be reformulated to generate first-order effects by having it infer the baserate instead of the repetition rate of the sequence, but the empirical data suggest both mechanisms are present simultaneously. Thus the challenge is to merge these two effects into one model that performs joint inference over both environmental statistics. Here we propose a Bayesian model that captures both first-and second-order effects, building on the basic principles of DBM. According to this new model, which we call the Dynamic Belief Mixture Model (DBM2), the learner assumes that the stimulus on a given trial is probabilistically affected by two factors: the random variable  X  , which represents the sequence baserate, and the random variable  X  , which represents the repetition rate. The combination of these two factors is governed by a mixture weight w that represents the relative weight of the  X  component. As in DBM, the environment is assumed to be nonstationary, meaning that on each trial, with probability  X  ,  X  and  X  are jointly resampled from the reset prior, p 0 (  X , X  ) , which is uniform over [0 , 1] 2 . Figure 2c shows the graphical architecture for this model. This architecture is an extension of our reformulation of the DBM architecture in Figure 2b. Importantly, the observed variable, S , is the actual stimulus value instead of the repetition/alternation representation used in DBM. This architecture allows for explicit representation of the baserate, through the direct influence of  X  t on the physical stimulus value S t , as well as representation of the repetition rate through the joint influence of  X  t and the previous stimulus S t  X  1 on S t . Formally, we express the probability of S t given  X  ,  X  , and S t  X  1 as shown in Equation 1.
 DBM2 operates by maintaining the iterative prior over  X  and  X  , p (  X  t , X  t | ~ S t  X  1 ) . After each observa-likelihood of the most recent observation, as shown in Equation 2. The iterative prior for the next trial is then a mixture of the posterior from the current trial, weighted by 1  X   X  , and the reset prior, weighted by  X  (the probability of change in  X  and  X  ). The model generates predictions, P ( S t | ~ S t  X  1 ) , by integrating Equation 1 over the iterative prior on  X  and  X  t . In our simulations, we maintain a discrete approximation to the continuous joint iterative prior with the interval [0,1] divided into 100 equally spaced sections. Expectations are computed by summing over the discrete probability mass function.
 Figure 1b shows that DBM2 provides an excellent fit to the Cho et al. data, explaining the combina-tion of both first-and second-order effects. To account for the overall advantage of repetition trials over alternation trials in the data, a repetition bias had to be built into the reset prior in DBM. In DBM2, the first-order component naturally introduces an advantage for repetition trials. This occurs because the estimate of  X  t is shifted toward the value of the previous stimulus, S t  X  1 , thus leading to a greater expectation that the same value will appear on the current trial. This fact eliminates the need for a nonuniform reset prior in DBM2. We use a uniform reset prior in all DBM2 simulations, thus allowing the model to operate with only four free parameters:  X  , w , and the two parameters for the affine transform from model probabilities to RTs.
 The nonuniform reset prior in DBM allows it to be biased either for repetition or alternation. This flexibility is important in a model, because different experiments show different biases, and the biases are difficult to predict. For example, the Jentzsch and Sommer experiment showed little bias, but a replication we performed X  X ith the same stimuli and same responses X  X btained a strong alternation bias. It is our hunch that the bias should not be cast as part of the computational theory (specifically, the prior); rather, the bias reflects attentional and perceptual mechanisms at play, which can introduce varying degrees of an alternation bias. Specifically, four classic effects have been reported in the literature that make it difficult for individuals to process the same stimulus two times in a row at a short lag: attentional blink Raymond et al. (1992), inhibition of return Posner and Cohen (1984), repetition blindness Kanwisher (1987), and the Ranschburg effect Jahnke (1969). For example, with repetition blindness, processing of an item is impaired if it occurs within 500 ms of another instance of the same item in a rapid serial stream; this condition is often satisfied with 2AFC. In support of our view that fast-acting secondary mechanisms are at play in 2AFC, Jentzsch and Sommer (Experiment 2) found that using a very short lag between each response and the next stimulus modulated sequential effects in a difficult-to-interpret manner. Explaining this finding via a rational theory would be challenging. To allow for various patterns of bias across experiments, we introduced an additional parameter to our model, an offset specifically for repetition trials, which can serve as a means of removing the influence of the effects listed above. This parameter plays much the same role as DBM X  X  priors. Although it is not as elegant, we believe it is more correct, because the bias should be considered as part of the neural implementation, not the computational theory. With its ability to represent both first-and second-order effects, DBM2 offers a robust model for a range of sequential effects. In Figure 3a, we see that DBM2 provides a close fit to the data from Experiment 1 of Jentzsch and Sommer (2002). The general design of this 2AFC task is similar to the design in Cho et al. (2002) though some details vary. Notably we see a slight advantage on alternation trials, as opposed to the repetition bias seen in Cho et al.
 Surprisingly, DBM2 is able to account for the sequential effects in other binary decision tasks that do not fit into the 2AFC paradigm. In Experiment 1 of Maloney et al. (2005), subjects observed a rotation of two points on a circle and reported whether the direction of rotation was positive (clockwise) or negative (counterclockwise). The stimuli were constructed so that the direction of motion was ambiguous, but a particular variable related to the angle of motion could be manipulated to make subjects more likely to perceive one direction or the other. Psychophysical techniques were used to estimate the Point of Subjective Indifference (PSI), the angle at which the observer was equally likely to make either response. PSI measures the subject X  X  bias toward perceiving a positive as opposed to a negative rotation. Maloney et. al. found that this bias in perceiving rotation was influenced by the recent trial history. Figure 3b shows the data for this experiment rearranged to be consistent with the R/A orderings used elsewhere (the sequences on the abscissa show the physical stimulus values, ending with Trial t  X  1 ). The bias, conditioned on the 4-back trial history, follows a similar pattern to that seen with RTs in Cho et al. (2002) and Jentzsch and Sommer (2002). In modeling Experiment 1, we assumed that PSI reflects the subject X  X  probabilistic expectation about the upcoming stimulus. Before each trial, we computed the model X  X  probability that the next stimu-lus would be P, and then converted this probability to the PSI bias measure using an affine transform similar to our RT transform. Figure 3b shows the close fit DBM2 obtains for the experimental data. To assess the value of DBM2, we also fit DBM to these two experiments. Table 1 shows the com-parison between DBM and DBM2 for both datasets as well as Cho et al. The percentage of variance explained by the models is used as a measure for comparison. Across all three experiments, DBM2 captures a greater proportion of the variance in the data. DBM2 proposes that subjects in binary choice tasks track both the baserate and the repetition rate in the sequence. Therefore an important source of support for the model would be evidence for the psychological separability of these two mechanisms. One such line of evidence comes from Jentzsch and Sommer (2002), who used electroencephalogram (EEG) recordings to provide additional insight into the mechanisms involved in the 2AFC task. The EEG was used to record subjects X  lateralized readiness potential (LRP) during performance of the task. LRP essentially provides a way to identify the moment of response selection X  X  negative spike in the LRP signal in motor cortex reflects initia-tion of a response command in the corresponding hand. Jentzsch and Sommer present two different ways of analyzing the LRP data: stimulus-locked LRP (S-LRP) and response-locked LRP (LRP-R). The S-LRP interval measures the time from stimulus onset to response activation on each trial. The LRP-R interval measures the time elapsed between response activation and the actual response. To-gether, these two measures provide a way to divide the total RT into a stimulus-processing stage and a response-execution stage.
 Interestingly, the S-LRP and LRP-R data exhibit different patterns of sequential effects when condi-tioned on the 4-back trial histories, as shown in Figure 4. DBM2 offers a natural explanation for the different patterns observed in the two stages of processing, because they align well with the division between first-and second-order sequential effects. In the S-LRP data, the pattern is predominantly second-order, i.e. RT on repetition trials increases as more alternations appear in the recent history, and RT on alternation trials shows the opposite dependence. In contrast, the LRP-R results exhibit an effect that is mostly first-order (which could be easily seen if the histories were reordered under an X/Y representation). Thus we can model the LRP data by extracting the separate contributions of  X  and  X  in Equation 1. We use the  X  component (i.e., the second term on the RHS of Eq. 1) to predict the S-LRP results and the  X  component (i.e., the first term on the RHS of Eq. 1) to predict the LRP-R results. This decomposition is consistent with the model of overall RT, because the sum of these components provides the model X  X  RT prediction, just as the sum of the S-LRP and LRP-R measures equals the subject X  X  actual RT (up to an additive constant explained below).
 Figure 4 shows the model fits to the LRP data. The parameters of the model were constrained to probabilities in DBM2 to durations, we used the same scaling factor used to fit the behavioral data but allowed for new offsets for the R and A groups for both S-LRP and LRP-R. The offset terms need to be free because the difference in procedures for estimating S-LRP and LRP-R (i.e., aligning trials on the stimulus vs. the response) allows the sum of S-LRP and LRP-R to differ from total RT by an additive constant related to the random variability in RT across trials. Other than these offset terms, the fits to the LRP measures constitute parameter-free predictions of EEG data from behavioral data. (a) In the second experiment reported in Maloney et al. (2005), participants only responded on every fourth trial. The goal of this manipulation was to test whether the sequential effect occurred in the absence of prior responses. Each ambiguous test stimulus followed three stimuli for which the direction of rotation was unambiguous and to which the subject made no response. The responses to the test stimuli were grouped according to the 3-back stimulus history, and a PSI value was computed for each of the eight histories to measure subjects X  bias toward perceiving positive vs. negative rotation. The results are shown in Figure 4c. As in Figure 3b, the histories on the abscissa show the physical stimulus values, ending with Trial t  X  1 , and the arrangement of these histories is consistent with the R/A orderings used elsewhere in this paper.
 DBM2 X  X  explanation of Jentzsch and Sommer X  X  EEG results indicates that first-order sequential effects arise in response processing and second-order effects arise in stimulus processing. Therefore, the model predicts that, in the absence of prior responses, sequential effects will follow a pure second-order pattern. The results of Maloney et al. X  X  Experiment 2 confirm this prediction. Just as in the S-LRP data of Jentzsch and Sommer (2002), the first-order effects have mostly disappeared, and the data are well explained by a pure second-order effect (i.e., a stronger bias for alternation when there are more alternations in the history, and vice versa). We simulated this experiment with DBM2 using the same value of the change parameter (  X  ) from the fit of Maloney et al. X  X  Experiment 1. Additionally, we set the mixture parameter, w , to 0, which removes the first-order component of the model. For this experiment we used different affine transformation values than in Experiment 1 because the modifications in the experimental design led to a generally weaker sequential effect, which we speculate to have been due to lesser engagement by subjects when fewer responses were needed. Figure 4c shows the fit obtained by DBM2, which explains 91.9% data variance. Our approach highights the power of modeling simultaneously at the levels of rational analysis and psychological mechanism. The details of the behavioral data (i.e. the systematic discrepancies from DBM) pointed to an improved rational analysis and an elaborated generative model (DBM2) that is grounded in both first-and second-order sequential statistics. In turn, the conceptual organization of the new rational model suggested a psychological architecture (i.e., separate representation of baserates and repetition rates) that was borne out in further data. The details of these latter findings now turn back to further inform the rational model. Specifically, the fits to Jentzsch and Sommer X  X  EEG data and to Maloney et al. X  X  intermittent-response experiment suggest that the statistics individ-uals track are differentially tied to the stimuli and responses in the task. That is, rather than learning statistics of the abstract trial sequence, individuals learn the baserates (i.e., marginal probabilities) of responses and the repetition rates (i.e., transition probabilities) of stimulus sequences. This division suggests further hypotheses about both the empirical nature and the psychological representation of stimulus sequences and of response sequences, which future experiments and statistical analyses will hopefully shed light on. M. Jones and W. Sieck. Learning myopia: An adaptive recency effect in category learning. Journal of Experimental Psychology: Learning, Memory, &amp; Cognition , 29:626 X 640, 2003.
 M. Mozer, S. Kinoshita, and M. Shettel. Sequential dependencies offer insight into cognitive control. In W. Gray, editor, Integrated Models of Cognitive Systems , pages 180 X 193. Oxford University Press, 2007.
 A. Yu and J. Cohen. Sequential effects: Superstition or rational behavior? NIPS , pages 1873 X 1880, 2008.
 L. Maloney, M. Dal Martello, C. Sahm, and L. Spillmann. Past trials influence perception of am-biguous motion quartets through pattern completion. Proceedings of the National Academy of Sciences , 102:3164 X 3169, 2005.
 I. Jentzsch and W. Sommer. Functional localization and mechanisms of sequential effects in serial reaction time tasks. Perception and Psychophysics , 64(7):1169 X 1188, 2002.
 D. Hale. Sequential effects in a two-choice reaction task. Quarterly Journal of Experimental Psy-chology , 19:133 X 141, 1967.
 E. Soetens, L. Boer, and J. Hueting. Expectancy or automatic facilitation? separating sequential effects in two-choice reaction time. Journal of experimental psychology. Human perception and performance , 11:598 X 616, 1985.
 R. Cho, L. Nystrom, E. Brown, A. Jones, T. Braver, P. Holmes, and J. Cohen. Mechanisms under-lying dependencies of performance on stimulus history in a two-alternative forced-choice task. Cognitive, Affective, &amp; Behavioral Neuroscience , 4:283 X 299, 2002.
 W. Estes. Toward a statistical theory of learning. Psychological Review , 57:94 X 107, 1950. N. Anderson. Effect of first-order conditional probability in a two-choice learning situation. Journal of Experimental Psychology , 59(2):73 X 83, 1960.
 D. Laming. Subjective probability in choice-reaction experiments. Journal of Mathematical Psy-chology , 6:81 X 120, 1969.
 J. Raymond, K. Shapiro, and K. Arnell. Temporary suppression of visual processing in an rsvp task: an attentional blink? Journal of experimental psychology. Human perception and performance , 18:849 X 860, 1992.
 M. Posner and Y. Cohen. Components of visual orienting. In H. Bouma and D. G. Bouwhuis, editors, Attention and Performance X: Control of language processes , pages 531 X 556. Erlbaum, Hillsdale, NJ, 1984.
 N. Kanwisher. Repetition blindness: Type recognition without token individuation. Cognition , 27: 117 X 143, 1987.
 J. Jahnke. The ranschburg effect. Psychological Review , 76:592 X 605, 1969.
