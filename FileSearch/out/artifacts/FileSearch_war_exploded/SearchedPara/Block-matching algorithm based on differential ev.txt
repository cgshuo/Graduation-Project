 1. Introduction
Virtually, all applications of video and visual communication deal with an enormous amount of data. The limited storage capacity and transmission bandwidth available has made digital video coding an important technology. In video coding, the high correlation between successive frames can be exploited to improve coding efficiency, which is usually achieved by using motion estimation (ME). Many ME methods have been studied in an effort to reduce the complexity of video coding, such as block-matching (BM) algorithms, parametric-based models ( Dimitrios Tzovaras and Michael, 1999 ), optical flow ( Barron et al., 1994 ), and pel-recursive techniques ( Skowronski, 1999 ).
Among these methods, BM seems to be the most popular method due to its effectiveness and simplicity for both software and hardware implementations. BM is also widely adopted by various video coding standards, such as MPEG1 (1993) , MPEG2 (1994) , MPEG4 (2000) , H261 (1993) , and I.-T.R., H.263 (2000) .
In a BM algorithm, the current frame is divided into non-overlapping macro blocks (MB) of N N pixel dimension. For each block, in the current frame, the best-matched block within a search window of size (2 W  X  1) (2 W  X  1) in the previous frame is determined, where W is the maximum allowed displacement. The position difference between a template block in the current frame and the best-matched block in the previous frame is called the motion vector. A commonly used matching measure is the sum of absolute differences (SAD), which is computationally expensive and represents the most consuming operation in the BM process.
The full search algorithm (FSA) ( Jain and Jain, 1981 ) is the simplest BM algorithm that can deliver the optimal estimation solution regarding the minimal matching error, because it checks all candidates one at a time. However, such exhaustive search and full-matching error calculation at each checking point yields an extremely computational-expensive FSA method that seriously constraints real-time video applications.

To decrease the computational complexity of the BM process, several BM algorithms have been proposed, which are based on the following three techniques: (1) Using a fixed pattern, which means that the search operation is conducted on a fixed subset of the total search window, and some famous examples include, the three step search (TSS) ( Jong et al., 1994 ), the new three step search (NTSS) ( Renxiang Li et al., 1994 ), the simple and efficient
TSS (SES) ( Jianhua Lu and Liou, 1997 ), the four step search (4SS) ( Lai-Man and Wing-Chung, 1996 ), and the diamond search (DS) ( Shan and Kai-Kuang, 2000 ). Such approaches have been algor-ithmically considered as the fastest. However, they are eventually not able to match the dynamic motion-content delivering false motion vectors (image distortions). (2) Reducing the search points signifies that the algorithm chooses only such locations as search points, which iteratively minimize the error-function (SAD values). In this category, some examples include the adaptive rood pattern search (ARPS) ( Yao Nie and Ma, 2002 ), the fast block matching using prediction (FBMAUPR) ( Yi-Ching et al., 2009 ), the block-based gradient descent search (BBGD) ( Liu and Feig, 1996 ), and the neighbourhood elimination algorithm (NE) ( Saha et al., 2011 ). These approaches assume that the error-function behaves monotonically, which holds well for slow-moving sequences; however, such properties do not hold true for other kind of movements in video sequences ( Chow and Liou, 1993 ), yielding that the algorithms may get trapped into local minima. (3) Decreasing the computational overhead for each search point means that the matching cost (SAD operation) is replaced by a partial or simplified version with less complexity. Some examples of this category are new pixel-decimation (ND) ( Saha et al., 2008 ), the efficient block matching using multilevel intra and inter-sub-blocks ( Renxiang Li et al., 1994 ), and the successive elimination algorithm ( Song et al., 2007 ). These techniques are based on the assumption that all pixels within each block move by the same amount, while a good estimate of the motion could be obtained by using only a fraction of the pixels. However, as only a fraction of the pixels enters into the matching computation, the use of these regular sub-sampling techniques can seriously affect the accuracy of the detection of motion vectors due to noise or illumination changes.

Alternatively, evolutionary approaches, such as genetic algo-rithms (GA) ( Holland, 1975 ) and particle swarm optimization (PSO) ( Kennedy and Eberhart, 1995 ) are well known for locating potential global optimum within an arbitrary search space.
However, only a few evolutionary approaches have specifically addressed the problem of BM, such as the light-weight genetic block matching (LWG) ( Chun-Hung and Ja-Ling, 1998 ), the genetic four-step search (GFSS) ( Wu and So, 2003 ), and the
PSO-BM ( Yuan and Shen, 2008 ). Although these methods support an accurate identification of the motion vector, their spending times are very long, when compared with other BM techniques.
Differential evolution (DE), introduced by Storn and Price (1995) , is a novel evolutionary algorithm, which is used to optimize complex continuous nonlinear functions. As a population-based algorithm, DE uses simple mutation and crossover operators to generate new candidate solutions, and applies one-to-one competi-tion scheme to greedily decide whether the new candidate or its parent will survive in the next generation. Owing to its simplicity, ease of implementation, fast convergence, and robustness, the DE algorithm has gained much attention, reporting a wide range of successful applications in the literature ( Babu and Munawar, 2007 ; Mayer et al., 2005 ; Kannan et al., 2003 ; Chiou et al., 2005 , 2004 ; Ursem and Vadstrup, 2003 ; Babu et al., 2003 ; Zelinka et al., 2008 ; Cuevas et al., 2010 ).

For many real-world applications, the number of calls to the objective function needs to be limited, e.g., because an evaluation is very time consuming or expensive, or the approach requires user interaction. However, DE does not seem to have such problems, because it usually requires many evaluations before producing a satisfying result.

The problem of excessively long fit ness function calculations has already been faced in the field of evolutionary algorithms (EA), which is known as evolution control ( Jin, 2005 ). In an evolution control approach, the idea is to replace the costly objective function evalua-tion for some individuals by fitness estimates, based on an approx-imate model of the fitness landscape. The individuals to be evaluated, and those to be estimated, are determined based on some fixed criteria, which depend on the speci fic properties of the used approx-imate model ( Yaochu, 2011 ). The models, used in the estimation, can be built during the actual EA run, because EA repeatedly sample the search space at different points ( Branke and Schmidt, 2005 ). There are certainly many possible approxi mation models, and several have already been used in combination with EA (e.g., polynomials ( Zhou et al., 2005 ), the Kriging model ( Ratle, 2001 ), the feedforward neural networks, including multi-layer perceptrons ( Lim et al., 2010 ), and radial basis-func tion networks ( Ong et al., 2008 )). These models can be either global, which make use of all available data, or local, which make use of only a small set of data around the point where the function is to be approximated. Local models, however, have a number of advantages ( Branke and Schmidt, 2005 ): they are well-known and established techniques, relatively fast, and take into account the intuitively most important information, the closest neighbors.

In this work, a new algorithm based on DE is proposed to reduce the number of search locations in the BM process. The algorithm uses a simple fitness calculation approach, which is based on the nearest neighbor interpolation (NNI) algorithm to estimate the fitness value (SAD operation) for several candidate solutions (search locations). As a result, the approach can sub-stantially reduce the number of function evaluations, preserving the good search capabilities of DE. In comparison with other fast BM algorithms, the proposed method deploys more accurate motion vectors, yet delivering competitive time rates.
The paper is organized as follows: Section 2 holds a brief description about the differential evolution algorithm. In Section 3 , the fitness calculation strategy for solving the expensive optimiza-tion problem is presented. Section 4 provides the background about the BM motion estimation issue, while Section 5 exposes the final BM algorithm as a combination of DE and the NNI estimator. Section 6 demonstrates the experimental results for the proposed approach over standard test sequences, and some conclusions are discussed in Section 7 . 2. DE algorithm
The DE algorithm is a simple and direct search algorithm, which is based on population and aims for optimizing global multi-modal functions. DE employs the mutation operator to provide the exchange of information among several solutions.
There are various mutation-based generators to define the algorithm type. The version of DE algorithm used in this study is known as DE/best/l/exp or  X  X  X E1 X  X  ( Storn and Price, 1995 ). DE algorithms begin by initializing a population of N p and D -dimen-sional vectors, considering parameter values that are randomly distributed between the pre-specified lower initial parameter bound x j , low and the upper initial parameter bound x j , high as follows: x j  X  1 , 2 , ... , D ; i  X  1 , 2 , ... , N p ; t  X  0 :  X  1  X 
The subscript t is the generation index, while j and i are the parameter and particle indices, respectively. Hence, x j , i , t parameter of the i th particle in generation t . To generate a trial solution, DE algorithm first mutates the best solution vector x from the current population by adding the scaled difference of two vectors from the current population. v r , r 2 A 1 , 2 , ... , N p  X  2  X  where v i , t is the mutant vector. Indices r 1 and r 2 are randomly selected with the condition that they are different and have no relation to the particle index i whatsoever (i.e., r 1 a r mutation scale factor F is a positive real number, typically less than 1. Fig. 1 illustrates the vector-generation process defined by Eq. (2) .

To increase the diversity of the parameter vector, the crossover operation is applied between the mutant vector v i , t and the original individuals x i , t . The result is the trial vector u is computed by considering element to element as follows: u  X  trols the fraction of parameters that the mutant vector is contribut-ing to the final trial vector. In addition, the trial vector always inherits the mutant vector parameter according to the randomly chosen index j rand , assuring that the trial vector differs by at least one parameter from the vector to which it is compared ( x
Finally, a greedy selection is used to find better solutions. Thus, if the computed cost function value of the trial vector u than or equal to the cost of the vector x i , t , then such trial vector replaces x i , t in the next generation. Otherwise, x i , t population for at least one more generation. x
Here, f () represents the cost function. These processes are repeated until a termination criterion is attained or a predeter-mined generation number is reached. 3. Fitness approximation method
EA based on fitness approximation aim to find the global minimum of a given function, considering only a very few number of function evaluations. To apply such approach, it is necessary that the objective function portraits the following conditions ( Luoa et al., 2011 ): (1) it must be very costly to evaluate and (2) it must have few dimensions (up to five). Recently, several fitness estimators have been reported in the literature ( Zhou et al., 2005 ; Ratle, 2001 ; Lim et al., 2010 ; Ong et al., 2008 ), where the function evaluation number is considerably reduced (to hundreds, dozens, or even less). However, most of these methods produce complex algorithms whose performance is conditioned to the quality of the training phase and the learning algorithm in the construction of the approximation model.

In this study, we explore the use of a local approximation scheme, based on NNI to reduce the function evaluation number.
The model estimates the fitness values based on previously evaluated neighboring individuals, stored during the evolution process. In each generation, some individuals of the population are evaluated with the accurate (real) objective function, while the remaining individuals X  fitness is estimated. The individuals to be evaluated accurately are determined based on their proximity to the best fitness value or uncertainty. 3.1. Updating individual database
In our fitness calculation approach, during de-evolution pro-cess, every evaluation or estimation of an individual produces a data point (individual position and fitness value) that is poten-tially taken into account for building the approximation model.
Therefore, we store all the evaluations made so far in a history array T , and then just select the closest neighbor to estimate the fitness value of a new individual. Thus, all the data are preserved and potentially available for use, while the construction of the model is still fast because only the most relevant data points are actually used to construct the model. 3.2. Fitness calculation strategy
In the proposed fitness calculation scheme, most of the fitness values are estimated to reduce the calculation time in each genera-tion. In the model, those individuals that are near the individual with the best fitness value contained in T (Rule 1) are evaluated (using the real fitness function). Such individuals are important, because they will have a stronger influence on the evolution process than the other individuals. Moreover, individuals in regions of the search space with few previous evaluations (Rule 2) are also evaluated. However, the fitness values of these individuals are uncertain, because there is no close reference (close points contained in T ) to calculate their estimates.
 The rest of the individuals are estimated using NNI (Rule 3).
Thus, the fitness value of an individual is estimated by assigning it the same fitness value as that of the nearest individual stored in T .
Thus, the estimation model follows three different rules to evaluate or estimate the fitness values: 1. If the new individual (search position) P is located closer than the distance d with respect to the nearest individual location
L whose fitness value F L q corresponds to the best fitness value stored in T , then the fitness value of P is evaluated using the real fitness function. Fig. 2 a draws this rule procedure. 2. If the new individual P is located far from the distance d with respect to the nearest individual location L q whose fitness value F L q has been already stored in T , then its fitness value is evaluated using the real fitness function. Fig. 2 b outlines this rule procedure. 3. If the new individual P is located closer than the distance d with respect to the nearest individual location L q whose fitness value F q has been already stored in T , then its fitness value is estimated (using the NNI approach) by assigning it the same
The d value controls the tradeoff between the evaluation and estimation of search locations. Typical values of d range from 1 to 4; however, in this study, the value of 2.5 has been used. Thus, the proposed approach favors the expl oitation and exploration in the search process. For the exploration, the estimator evaluates the true fitness function of new search locations that have been located far from the positions already calculated. Meanwhile, it also estimates those that are closer. For the exploitation, the proposed method evaluates the effective fitness function of those new searching locations that are placed near to the position with the minimum fitness value observed so far, aiming to improve its minimum.
The three rules show that the fitness calculation strategy is simple and straightforward. Fig. 2 illustrates the procedure of fitness computation for a new solution (point P ) considering the three different rules. In the problem, the objective function f is the individual database array T contains five different elements ( L , L 2 , L 3 , L 4 , L 5 ) with their corresponding fitness values ( F F , F L 3 , F L 4 , F L 5 ). Fig. 2 (a) and (b) shows the fitness evaluation ( f  X  x , x 2  X  ) of the new solution P , following Rule 1 and 2, respectively, whereas Fig. 2 (c) presents the fitness estimation of P using the NNI approach, considering Rule 3. 3.3. Proposed optimization DE method
In this section, a fitness calculation approach to accelerate the DE algorithm has been proposed. Only the fitness calculation scheme shows a difference between the conventional DE and the enhanced one. In the modified DE, only some individuals are actually evaluated (Rules 1 and 2) in each generation. The fitness values of the rest are estimated using the NNI approach (Rule 3). The estimation is executed using the individual database (array T ).
Fig. 3 shows the difference between the conventional DE and the modified one. In the figure, it is clear that two new blocks have been added, the fitness estimation and the updating indivi-dual database. Both the elements, together with the actual evolu-tion block, represent the fitness calculation strategy presented in this section. As a result, the DE approach can substantially reduce the number of function evaluations, preserving the good search capabilities of DE. 4. Motion estimation and BM
For motion estimation, in a BM algorithm, the current frame of an image sequence I t is divided into non-overlapping blocks of N N pixels. For each template block in the current frame, the best-matched block within a search window of size (2 W  X  1) (2 W  X  1) in the previous frame I t 1 is determined, where W is the maximum allowed displacement. The position difference between a template block in the current frame and the best-matched block in the previous frame is called the motion vector (MV) (see Fig. 4 ). The most commonly used criterion for BM algorithms is the
SAD, defined in Eq. (5) , between a template block at position ( x , y ) in the current frame and the candidate block at position Initialization
Actual evaluation (rule 1 and 2) (Array T ) population generator (DE operators)  X  x  X  ^ u , y  X  ^ v  X  in the previous frame I t 1 .
 SAD  X  ^ u , ^ v  X  X  where g t  X  U  X  is the gray value of a pixel in the current frame I g t 1  X  U  X  is the gray level of a pixel in the previous frame I
Therefore, the MV in  X  u , v  X  can be defined as follows:  X  u , v  X  X  arg min position I t 1 g .
 The FSA is the most robust and accurate method to find the
MV. It tests all possible candidate blocks from I t 1 within the search area to find the block with minimum SAD. For the maximum displacement of W , the FSA requires  X  2 W  X  1  X  2 points. For instance, if the maximum displacement W is 7, then the total search points are 225. Each SAD calculation requires 2 N additions because the total number of addition for the FSA to match a 16 16 block is 130,560. However, the computational requirement makes the application of FSA in real-time applica-tions difficult. 5. BM algorithm based on DE with the estimation strategy
FSA finds the global minimum (the accurate MV), considering all locations within the search space S . Nevertheless, this approach has a high computational cost for practical use. To overcome such a problem, many fast algorithms have been developed, despite the fact that their precision is poorer than the FSA. A better BM algorithm should spend less computation time on searching and obtaining accurate MVs.

The BM algorithm, proposed in this study, has the velocity of the fastest algorithms and a precision similar to the FSA approach.
As most of the fast algorithms use a regular search pattern or assume a characteristic error function (unimodal) for searching the motion vector, they may get trapped into local minima, considering that for many cases (complex motion sequences), the unimodal error assumption is no longer valid. Fig. 5 shows a typical error surface (SAD values) that has been computed around the search window considering a fast-moving sequence. On the other hand, the proposed BM algorithm uses a nonuniform search pattern for locating global minimum distortion. Under the effect of the DE operators, the search locations vary from generation to generation, avoiding getting trapped into a local minimum. Besides, as the proposed algorithm uses a fitness calculation strategy to reduce the evaluation of the SAD values, it utilizes few search positions.

In the algorithm, the search space S consists of a set of 2-D motion vectors ^ u and ^ v representing the x and y components of the motion vector, respectively. The particle is defined as P  X   X  u i , ^ v i W r  X  u i , ^ v i r W g  X  7  X  where each particle i represents a possible motion vector. In this study, the maximum offset is W  X  7 pixels. 5.1. Initial population
The first step in DE optimization is to generate an initial group of particles. The standard literature of EA generally suggests the use of random solutions as the initial population, assuming the lack of knowledge about the problem ( Goldberg, 1989 ). On the other hand, Li and Xiao (2011) ) and Xiao (2008) demonstrated that the use of solutions generated through some domain knowl-edge (i.e., non-random solutions) to set the initial population can significantly improve its performance. To obtain appropriate initial solutions (based on knowledge), an analysis over the motion vector distribution should be conducted. After considering several sequences (see Table 1 and Fig. 9 ), it could be noted that 98% of the MVs lie at the origin of the search window for a slow-moving sequence, such as the one at Container , whereas complex motion sequences, such as the Carphone and the Foreman exam-ples, have only 53.5% and 46.7% of their MVs in the central search region, respectively. The Stefan sequence, showing the most complex motion content, was found to have only 36.9% of the MVs. Fig. 6 shows the surface of the MV distribution for the F oreman and the Stefan . On the other hand, although it is less evident, the MV distribution of several sequences shows small peaks at some locations lying away from the center, because they are contained inside a rectangle, as shown in Fig. 6 (b) and (d) by a white overlay. Real-world moving sequences concentrate most of the MVs under a limit due to the motion continuity principle ( Ratle, 2001 ). Therefore, in this study, the initial solutions were selected from five fixed locations that represent locations showing the higher concentration in the MV distribution, as shown in Fig. 7 . 5.2. The DE-BM algorithm
The goal of our BM approach is to reduce the number of evaluations of the SAD values (real fitness function) without losing performance in achieving an acceptable solution. In the following, the DE-BM method is presented: Step 1: Set the DE parameters ( F  X  0.25, CR  X  0.8, see Section 2 ).
Step 2: Initialize the population of five individuals using the pattern shown in Fig. 7 and the individual database array T , without elements.

Step 3: Compute the fitness values of each individual using the fitness calculation strategy presented in Section 3 . As all the individuals of the initial population fulfill the conditions of
Rule 2, they are evaluated with the real fitness function (calculating the real SAD values).

Step 4: Update the new evaluations in the individual database array T. Density motion vector
Step 5: Generate a new population of five individuals (trial population), considering the DE operators of mutation, Eq. (2) , and crossover, Eq. (3) .

Step 6: Compute the fitness values of each individual using the fitness calculation strategy presented in Section 3 .

Step 7: Update the new evaluations (Rule 1 and 2) or estima-tions (Rule 3) in the individual database array T.

Step 8: Select the fittest element between each individual and its corresponding trial counterpart according to Eq. (4) to obtain the final individual for the next generation.

Step 9: If seven iterations have not been reached, then go back to Step 5; otherwise, the best individual ( ^ u best , ^ v population is considered as the MV.

The proposed DE-BM algorithm uses 40 different individuals (search locations) during the complete optimization process.
However, only 7 X 18 search locations are evaluated using the real fitness function (SAD evaluation), while the remaining positions are just estimated. Fig. 8 shows two search-patterns examples that have been generated by the DE-BM approach. Such patterns exhibit the evaluated search locations (Rules 1 and 2) in white cells, whereas the minimum location is marked in black. The gray cells represent the cells that were estimated (Rule 3) or not visited during the optimization process. 6. Experimental results
This section presents the results of the comparison of the proposed DE-BM algorithm with other existing BM algorithms.
The simulations have been performed over the luminance com-ponent of popular video sequences listed in Table 1 . Such sequences consist of different degrees and types of motion, including QCIF (176 144), CIF (352 288), and SIF (352 240). The first four sequences are Container , Carphone , Foreman , and
Akiyo in QCIF format. The next two sequences are Stefan in CIF format and Tennis in SIF format. Among these sequences,
Container has gentle, smooth, and low motion change, and consists mainly of stationary and quasi-stationary blocks.
Carphone , Foreman , and Akiyo have moderately complex motion, obtaining a  X  X  X edium X  X  category regarding its motion content. Rigorous motion, which is based on camera panning with transla-tion and complex motion content, can be found in the sequences of Stefan and Tennis . Fig. 9 shows a sample frame from each sequence.

Each picture frame is partitioned into MB with the size of 16 16 ( N  X  16) pixels for motion estimation, where the max-imum displacement within the search range is 7 7 pixels in both the horizontal and vertical directions.

To compare the performance of the DE-BM approach, different search algorithms, such as FSA, TSS ( Jong et al., 1994 ), 4SS ( Lai-Man and Wing-Chung, 1996 ), NTSS ( Renxiang Li et al., 1994 ), BBGD ( Liu and Feig, 1996 ), DS ( Shan and Kai-Kuang, 2000 ), NE ( Saha et al., 2011 ), ND ( Saha et al., 2008 ), LWG ( Chun-Hung and Ja-Ling, 1998 ), GFSS ( Wu and So, 2003 ), and PSO-BM ( Yuan and Shen, 2008 ) have been implemented in our simulations. For comparison purposes, all six video sequences, shown in Fig. 9 , were used. All simulations were performed on a Pentium IV 3.2 GHz PC with 1 GB of memory.

In the comparison, two relevant performance indices were considered: the coding quality and the search efficiency. 6.1. Coding quality
First, all algorithms were compared in terms of their coding quality. The coding quality is characterized by the peak-signal-to-noise-ratio (PSNR) value, which indicates the reconstruction quality when the motion vectors, computed by a BM approach, are used. In PSNR, the signal is the original data frames, whereas the noise is the error introduced by the calculated motion vectors. The PSNR is defined as PSNR  X  10 log 10 255 where MSE is the mean square between the original frames and those compensated by the motion vectors. Additionally, as an alternative performance index, the PSNR degradation ratio ( D is used in the comparison. This ratio expresses the level of mismatch between the PSNR of a BM approach and that of the FSA, which is considered as reference, in percentage (%). D defined as D
Table 2 shows the comparison of the PSNR values and PSNR degradation ratios ( D PSNR ) among the different algorithms, con-sidering the six image sequences presented in Fig. 9 . As it can be seen in the case of the slow-moving sequence Container , the PSNR values (the D PSNR ratios) of all BM algorithms are similar. For the medium motion content sequences, such as Carphone , Foreman , and Akiyo , the approaches consistent of fixed patterns (TSS, 4SS, and NTSS) that exhibit the worst PSNR values (high D PSNR except for the DS algorithm. On the other hand, the BM methods that use EA (LWG, GFSS, PSO-BM, and DE-BM) present the lowest D
PSNR ratios, only one step under the FSA approach, which is considered as reference. Finally, the approaches based on error-function minimization (BBGD and NE) and pixel-decimation (ND) exhibit a medium performance. For the high motion sequences, such as Stefan and Tennis , conclusions similar to the medium motion content sequences could be observed. As the motion content of these sequences is complex (producing error surfaces with more than one minimum), the performance, in general, becomes worst for most of the algorithms. However, the PSNR values (or D PSNR ratios) of the DS and the DE-BM approaches maintain a better performance. As a summary of the coding quality performance, the last column of Table 2 presents the average PSNR degradation ratio ( D PSNR ) obtained over all sequences. According to these values, the proposed DE-BM method is superior to any other approach (due to the computation complexity, the FSA is consid-ered just as a reference).

Fig. 10 (a) and (b) shows the comparison of the frame-wise coding performance for the Akiyo and Tennis sequences. As the algorithms
FSA, DE-BM, LWG, BBGD, NE, and DS obtained good PSNR values in the coding performance analysis, they were considered in the com-parison. According to these graphs, the coding quality of the DE-BM is better than the other algorithms (FSA, LWG, BBGD, NE, and DS) whose PSNR values fluctuate heavily for some regions in the video sequences. The PSNR values of the DE-BM algorithm are only slightly under the FSA approach, which is used as a reference. For a high-motion sequence, such as Tennis ,wehavepresentedacomparative result for frame-wise PSNR in Fig. 10 b. The results exhibit a similar pattern as the one discussed for the Akiyo sequence.
 6.2. Search efficiency
In this study, the search efficiency has been used as a measurement of computational complexity, and has been calcu-lated by counting the average number of search points (or the average number of SAD computations) for an MV estimation.
Table 3 shows the comparison of the search efficiency. Only a step above the FSA, the EA LWG, GFSS, and PSO-BM hold the highest number of search points per block. On the contrary, the proposed DE-BM algorithm maintains a performance similar to BBGDS and DS, representing the fastest approaches. From the data shown in
Table 3 , it can be noted that the average number of search locations, corresponding to the DE-BM method, represents the number of SAD evaluations (the number of SAD estimations is not considered). Additionally, in the last two columns of Table 3 , the number of search locations averaged over the six considered sequences and the rank occupied for each approach are presented.
According to these values, the proposed DE-BM method is ranked in the second place, a step under BBGDS. The average number of search points checked by the DE-BM algorithm is only from 9.2 to 16.8, which is 4% and 7.4% less than that of the FSA method. These results demonstrate that our approach can significantly reduce the number of search points. Hence, the DE-BM algorithm is at least equal to the other fast methods in terms of the reduction of the number of search points. 7. Conclusions
In this paper, a new algorithm based on DE has been proposed to reduce the number of search locations in the BM process. To save computational time, the approach combines the traditional DE with a fitness estimation strategy to decide which search locations (individuals) can be estimated or actually evaluated. As a result, the approach has substantially reduced the number of function evaluations, yet preserving the good search capabilities of DE.
The proposed fitness calculation strategy estimates the SAD (fitness) value of search locatio ns by using previous evaluated neighboring locations that have been visited during the evolution process. In the strategy, the posit ions emplaced close to the location holding the best fitness value (seen so-far) are evaluated by using the actual fitness function. Similarly, the strategy also evaluates the positions established in regions of the search space with no previous evaluations. The remaining search positions are estimated by assign-ing the same fitness value from the nearest known location to such positions. By the use of this fitness estimation method, the SAD value of only very few search positions is actually evaluated, whereas the rest are just estimated.

As the proposed algorithm does not consider any fixed search pattern or any other movement assumption, a high probability for finding the true minimum (accurate motion vector) is expected, regardless of the movement complexity contained in the video sequence. Therefore, the chance of being trapped into a local minimum is reduced, when compared with other BM algorithms.
The performance of DE-BM has been compared with other existing BM algorithms (FSA, TSS ( Jong et al., 1994 ), 4SS ( Lai-Man and Wing-Chung, 1996 ), NTSS ( Renxiang Li et al.,, 1994 ), BBGD ( Liu and Feig, 1996 ), DS ( Shan and Kai-Kuang, 2000 ), NE ( Saha et al., 2011 ), ND ( Saha et al., 2008 ), LWG ( Chun-Hung and Ja-Ling, 1998 ), GFSS ( Wu and So, 2003 ), and PSO-BM ( Yuan and Shen, 2008 )), considering the different sequences that present a great variety of formats and movement types. The experimental results demonstrate the high performance of the proposed method in terms of computational complexity and coding efficiency, redu-cing the number of search points by about 95% and preserving a negligible degradation ratio D PSNR of 1.13.
 References
