 China and Japan are producing a large amount of scientific journals and patents in their respective languages. The World Intellectual Property Orga-the first country for patent applications in 2013. Japan was the first country for patent grants in 2013. Much of current scientific development in China or Japan is not readily available to non X  X hinese or non-Japanese speaking scientists. Additionally, China and Japan are more efficient at converting research and development dollars into patents than the U.S. available in Japanese, and Japanese patents available and in Chinese is a key issue for increased econom-ical development in Asia.

In recent years, Chinese X  X apanese machine trans-lation of patents or scientific papers has made rapid progress with the large quantities of parallel cor-pora provided by the organizers of the Workshop on of WAT 2015, in (Sonoh and Kinoshita, 2015), a Chinese to Japanese translation system is described that achieves higher BLEU scores by combination of results between Statistical Post Editing (SPE) based on their rule-based translation system and SMT system equipped with a recurrent neural lan-guage model (RNNLM).

In the research by Li et al. (2012), they improved a Chinese X  X o X  X apanese patent translation system by using English as a pivot language for three different purposes: corpus enrichment, sentence pivot trans-lation and phrase pivot translation. Still, the avail-ability of patent bilingual corpora between Chinese and Japanese in certain domains is a problem.
In this paper, we propose a simpler way to im-prove Chinese to Japanese phrase-based machine translation quality based on a small size of avail-able bilingual patent corpus, without exploiting ex-tra bilingual data, or using a third language, with no complex approach. Patents or scientific papers contain large amounts of domain-specific terms in words or multi-word expressions. Monolingual or bilingual term extraction is an important task for the fields of information retrieval, text categoriza-tion, clustering, machine translation, etc. There ex-ist work on monolingual or bilingual term extrac-tion in different languages. In (Kang et al., 2009), multi-word terms in Chinese in the information tech-nology (IT) domain and the medicine domain are extracted based on the integration of Web informa-tion and termhood estimation. Frantzi et al. (2000) describes a combination of linguistic and statisti-cal information method (C-value/NC-value) for the automatic extraction of multi-word terms from En-glish corpora. In (Mima and Ananiadou, 2001), it was showed that the C-/NC-value method is an effi-cient domain-independent multi-word term recogni-tion not only in English but in Japanese as well.
Some work consider the case of bilingual term ex-traction. In (Fan et al., 2009), Chinese X  X apanese multi-word terms are extracted by re-segmenting the Chinese and Japanese bi-corpus and combining multi-word terms as one single word based on ex-tracted monolingual terms. The word alignments containing terms are smoothed by computing the associations between pairs of bilingual term candi-dates.

In this paper, we propose a method to ex-tract Chinese X  X apanese bilingual multi-word terms by extracting Chinese and Japanese monolingual multi-word terms using a linguistic and statistical technique (C-value) (Frantzi et al., 2000) and the sampling-based alignment method (Lardilleux and Lepage, 2009) for bilingual multi-word term align-ment. We filter the aligned candidate terms by setting thresholds on translation probabilities. We perform experiments on the Chinese X  X apanese JPO patent corpus of WAT 2015. We pre-mark the extracted bilingual terms in the Chinese X  X apanese training corpus of an SMT system. We compare the translation system which uses our proposed method with a baseline system. We obtain a significant im-provement in translation accuracy as evaluated by BLEU (Papineni et al., 2002).

The paper is organized as follows: in Section 2, we introduce the experimental data sets used in our experiments. Section 3 gives our proposed method to extract Chinese X  X apanese bilingual multi-word terms using the C-value and the sampling-based alignment method. In Section 4, we describe our experiments and their results based on the data in-troduced in Section 2, and an analysis of the exper-imental results. Section 5 gives the conclusion and discusses future directions. The Chinese X  X apanese parallel sentences used in this paper are randomly extracted from the Chinese X  consists of about 1 million parallel sentences with four sections (Chemistry, Electricity, Mechanical engineering, and Physics.). It is already divided into training, tuning and test sets (1 million sentences, 4,000 sentences and 2,000 sentences respectively). For our experiments, we randomly extract 100,000 parallel sentences from the training part, 500 paral-lel sentences from the tuning part, and 1,000 from the test part. Table 1 shows the basic statistics on our experimental data sets.

In Section 3, monolingual and bilingual multi-word terms will be extracted from the training data. In Section 4, these data (train, tune and test) will be used in the baseline SMT system. This section presents our bilingual multi-word term extraction method that uses C-value (Frantzi et al., 2000) combined with the sampling-based alignment method (Lardilleux and Lepage, 2009). We also de-scribe how we use these extracted bilingual multi-word terms in SMT experiments. 3.1 Monolingual Multi-word Term Extraction The C-value is a commonly used domain-independent method for multi-word term extraction. This method has a linguistic part and a statistical part. The linguistic part constrains the type of terms extracted. In our experiments, we extract multi-word terms which contain a sequence of nouns or adjectives followed by a noun for both Chinese and Japanese. This linguistic pattern can be ( Adjective | N oun ) + N oun
The segmenter and part-of-speech tagger that we for Japanese. Examples of outputs are shown in Ta-ble 2.

The statistical part, the measure of termhood, called the C-value, is given by the following for-mula: C X  X alue(a) = where a is the candidate string, f(.) is its fre-quency of occurrence in the corpus, T a is the set of extracted candidate terms that contain a, P ( T a ) is the number of these candidate terms. In our ex-periments, we follow the basic steps of the C-value approach to extract monolingual multi-word terms from the monolingual part of the Chinese X  X apanese training corpus. Then, we mark the extracted mono-lingual multi-word terms in the corpus by enforcing them to be considered as one token (aligned with markers). 3.2 Bilingual Multi-word Term Extraction To extract bilingual multi-word terms, we use the open source implementation of the sampling-based approach, Anymalign (Lardilleux and Lepage, 2009), to perform phrase alignment from the above marked Chinese X  X apanese training corpus. We filter out any alignment ( N  X  M -grams) that is greater our experiments, we identify the multi-word term to multi-word term alignments between Chinese and Japanese by using the markers. We filter the aligned multi-word candidate terms by setting some thresh-old P for both translation probabilities of term align-ments (0 &lt;P  X  1). 3.3 Bilingual Multi-word Terms Used in SMT We train the Chinese X  X apanese translation mod-els on the training parallel pre-marked corpus with the extracted filtered aligned bilingual multi-word terms. A language model is trained with the orig-inal Japanese corpus without pre-marking annota-tion. We remove the markers from obtained phrase tables before performing tuning and decoding pro-cesses. We compare such a systems with a standard baseline system. We extract monolingual multi-word terms from a Chinese X  X apanese training corpus of 100,000 lines as indicated in Table 1 (Section 2). Table 3 shows the number of monolingual multi-word terms ex-tracted in Chinese and Japanese respectively using C-value and the linguistic pattern given in Section 3.1. The extracted monolingual multi-word terms were ranked by decreasing order of C-values. We mark the training corpus with the same size of Chi-nese and Japanese monolingual multi-word terms. They are the first 80,000 monolingual multi-word terms with higher C-value in both languages.
Follow the description given in Section 3.2. Ta-ble 4 gives the number of bilingual multi-word terms obtained for different thresholds from the marked 100,000 training corpus. We randomly extract 100 bilingual multi-word terms respectively and roughly check how well they correspond/match manually. The precision (good match) of the extracted bilin-gual multi-word terms is over 70%, while threshold becomes greater than 0.4. Table 5 shows sample of bilingual multi-word terms we extracted. 4.1 Translation Accuracy in BLEU We pre-mark the original Chinese X  X apanese train-ing corpus with the extracted bilingual multi-word terms filtering by several thresholds (Table 4) and train several Chinese to Japanese SMT systems us-ing the standard GIZA++/MOSES pipeline (Koehn et al., 2007). The un-pre-marked (original) Japanese corpus is used to train a language model using KenLM (Heafield, 2011). After removing mark-ers from the phrase table, we tune and test. In all experiments, the same data sets are used, the only difference being whether the training data is pre-marked or not with bilingual multi-word terms fil-tered by a given threshold. Table 4 shows the evalua-tion of the results of Chinese to Japanese translation in BLEU scores (Papineni et al., 2002). Compared with the baseline system, we obtain significant im-provements as soon as the threshold becomes greater than 0.3. A statistically significant improvement of one BLEU point (p-value is 0.001) is observed when the threshold is greater than 0.6. In that case, the training corpus is pre-marked with roughly 20,000 bilingual multi-word terms. 4.2 Analysis of the Content of Phrase Tables We further compare a system based on a pre-marked training corpus using bilingual multi-word terms (threshold of 0.6) with a baseline system. We in-vestigate the N (Chinese)  X  M (Japanese)-grams in translation. In Tables 6 and 7, the statistics (Chinese  X  Japanese) show that the total number of potentially useful phrase pairs used in translation with the pre-marked corpus is larger than that of the baseline system. Considering the correspondence between lengths in Chinese X  X apanese patent transla-tion, we compare the number of entries, the number of phrase pairs with different lengths (like 2 (zh)  X  1 (ja), 2 (zh)  X  3 (ja), 2 (zh)  X  4 (ja) and 3 (zh)  X  4 (ja)) and observe a significant increase for these categories.

We also investigate the number of phrase align-ments which the Chinese source language part con-taining multi-word terms in the reduced phrase ta-ble obtained when pre-marking the training corpus. There exists 8,940 phrase alignments in this case. A sample is shown in Table 8. Compared with the re-duced phrase table used in the baseline system, there exist 2,503 additional phrase alignments. They con-tain multi-word terms that did not exist in the re-duced phrase table of the baseline system. Table 9 shows examples of more potentially useful phrase alignments obtained with our proposed method. We presented an approach to improve Chinese X  Japanese patent machine translation performance by pre-marking the parallel training corpus with bilingual multi-word terms. We extracted mono-lingual multi-word terms from each monolingual part of a corpus by using the C-value method. We used the sampling-based alignment method to align the marked parallel corpus with monolingual multi-word terms and only kept the aligned bilingual multi-word terms by setting thresholds in both di-rections. We did not use any other additional cor-pus or lexicon. The results of our experiments in-dicate that the bilingual multi-word terms extracted have over 70% precision (the thresholds P  X  0.4). Pre-marking the parallel training corpus with these terms led to statistically significant improvements in BLEU scores (the thresholds P  X  0.3).

In this work, we considered only the case where multi-word terms can be found in both languages at the same time, e.g.,  X   X   X   X   X  (zh)  X  X  X   X   X   X   X  (ja)  X  X emiconductor chip X . However, we found many cases where a multi-word term is recog-nized in one of the languages, while the other side is not recognized as a multi-word term, although they may be correct translation candidates. This mainly is due to different segmentation results in Chinese and Japanese. E.g.,  X   X   X  (Chinese)  X   X   X  (Japanese)  X  X ompressor X , and  X   X   X  (Chinese)  X   X   X   X  X  X   X   X  (Japanese)  X  X low chart X . In a future work, we thus intend to address this issue and expect further improvements in translation results. We also intend to do experiments with our proposed method using a larger size of experimental training data.
