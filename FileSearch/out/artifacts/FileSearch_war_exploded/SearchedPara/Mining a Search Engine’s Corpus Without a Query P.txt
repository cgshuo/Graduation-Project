 Many websites (e.g., WedMD.com, CNN.com) provide keyword search interfaces over a large corpus of documents. Meanwhile, many third parties (e.g., investors, analysts) are interested in learn-ing big-picture analytical information over such a document cor-highly restrictive web search interface. In this paper, we study how to enable third-party data analytics over a search engine X  X  corpus without the cooperation of its owner -specifically, by issuing a small number of search queries through the web interface.
Almost all existing techniques require a pre-constructed query pool -i.e., a small yet comprehensive collection of queries which, if all issued through the search interface, can recall almost all doc-uments in the corpus. The problem with this requirement is that a  X  X ood X  query pool can only be constructed by someone with very specific knowledge (e.g., size, topic, special terms used, etc.) of the corpus, essentially leading to a chicken-and-egg problem. In this paper, we develop QG-SAMPLER and QG-ESTIMATOR, the first practical pool-free techniques for sampling and aggregate (e.g., SUM, COUNT, AVG) estimation over a search engine X  X  corpus, respectively. Extensive real-world experiments show that our al-gorithms perform on-par with the state-of-the-art pool-based tech-niques equipped with a carefully tailored query pool, and signifi-cantly outperforms the latter when the query pool is a mismatch. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search process Search Engine; Sampling Keyword Search Interface: Many websites provide keyword search interfaces which allow users to key in queries consisting of one or a few words, in order to retrieve the documents of their interests. Ex-amples include CNN.com for retrieving news (including archived news) articles, WebMD.com for retrieving medical documents, as well as many enterprise websites for retrieving product or service related descriptions. These search engines usually enforce the top-k limitation (where k is a small constant such as 50 or 100) -i.e., when a user-specified query is too broad and matches (i.e., is con-tained in) more than k documents, the search engine preferentially selects k of them according to a proprietary ranking function, and returns only these top-k results to the end user.
 Third-Party Analytics Over a Search Engine X  X  Corpus: For a given website, many third parties (e.g., competitors, analysts, in-vestors or even customers of the website) may be interested in learning analytical information over its search engine X  X  corpus -i.e., the set of documents that can be retrieved through the search engine X  X  keyword search interface. For example, learning the fre-quency of CNN X  X  coverage on different topics may help a com-peting news agency better attract audience away from CNN.com. On the other hand, learning the average length of documents in an enterprise website which make references to a product may reveal information about product quality, popularity, etc., as well as future directions of the enterprise.

Despite of the numerous potential interests, many website own-ers are not interested in, or simply unwilling to, publicly disclose such aggregate information to a third party (often for understand-able reasons such as business competitions). Specifically, it is im-possible to directly issue aggregate queries through the keyword-search interface provided by the search engines. While a potential solution is to first crawl all documents from a search engine and then enable analytics over their local copies [4], the top-k restric-tion coupled with the limit placed by many search engines on the number of queries per IP address per day (e.g., Google Search API allows only 100 free queries [3]) makes the solution impractical for a large document corpus.

In this paper, we address the problem of enabling third-party ana-lytics over a search engine X  X  corpus by only issuing queries through the search engine X  X  public keyword-search interface. Specifically, we consider the following two analytical tasks:
One can see that the two problems are related yet have differ-ent applications. Sampling is more versatile -one can use the retrieved samples to estimate any AVG queries, without the need of specifying such queries at the time of sampling. The prob-lem with sampling, however, is (1) it cannot efficiently estimate SUM and COUNT aggregates without knowing the corpus size, and (2) indeed because of its versatility, the sampling distribution cannot be  X  X ailored X  to an aggregate query as much as an aggregate-estimation solution can, leading to a higher query cost. Aggregate estimation, on the other hand, supports COUNT, SUM, and AVG queries, while achieving a lower query cost by tailoring to the in-put aggregate. Nonetheless, the aggregate to be estimated must be known before-hand, making it less versatile than sampling. Problems of Existing Solutions: Almost all existing techniques [5, 6, 23] assume prior knowledge of a rich collection of queries known as the query pool . The only technique which does not was designed as a theoretical solution and shown to be prohibitively expensive in practice [5]. The pool-based techniques issue to the search engine queries randomly selected from the pool in order to either retrieve sample documents or generate aggregate estima-tions. The problem with the query-pool assumption, however, is the hardness of designing a well-performing query pool in practice be-cause such a design must satisfy two requirements simultaneously: Unfortunately, it is difficult to satisfy both requirements without knowing a  X  X ig picture X  of the underlying corpus. Intuitively, the proper construction of a query pool has to take into account at least the size and content topic(s) of the underlying corpus -e.g., a well-performing query pool for a medical corpus is likely to perform poorly over a collection of computer science textbooks. This leads to a chicken-and-egg problem because the objective of third-party analytics is precisely to learn such a  X  X ig picture X . In the experi-mental results, we shall show that failing to customize a query pool -e.g., using a general-purpose query pool [23] for corpora of spe-cific topics -yields extremely poor performance.
 Outline of Our Technical Results: In this paper, we develop the first practical pool-free third-party sampling and aggregate estima-tion techniques over a search engine X  X  corpus, by issuing queries through its restrictive, web-based, keyword-search interface. To do so, we first introduce a novel concept of  X  X irtual X  query graph in which each node is a query (i.e., one or a few words) matching at least one document in the corpus; and two nodes q 1 and q 2 are con-nected iff at least one document returned by q 1 matches q versa. The word  X  X irtual X  is important here -note that we never fully materialize (i.e., completely crawl) the query graph because of its extremely large size. Instead, our key idea is to design an efficient, on-the-fly, random walk process over such a query graph to sample queries -which in turn enables the efficient sampling of documents in the search engine X  X  corpus.

While this query-graph-based approach enables the efficient sam-pling of a search engine X  X  corpus without the need of a query pool, there is one more challenge remaining for the aggregate estimation problem. Specifically, to enable SUM and COUNT estimations over the document corpus, we also need to know the total number of documents in the corpus and, in turn, the total number of queries in the graph. A straightforward solution is mark-and-recapture [18], which collects two random query samples and then use their in-tersection size to estimate the population size. Unfortunately, this solution is prohibitively expensive for our purpose because it re-quires a sample size of at least queries, to have (expectedly) just one intersection.

To address this problem, our main idea for aggregate estima-tion is a novel collect-and-sample technique which stems from two important observations: First, for the  X  X ecapture X  idea to work, one does not actually need to have two random samples. Instead, given any large subset of queries  X  S and a random sample R ,an (asymptotically) unbiased estimation of the total number of queries is |  X  S | X | R | / |  X  S  X  R | . Second, as we shall demonstrate in real-world experiments, while crawling all queries in the graph is pro-hibitively expensive, it is actually easy to collect a large number of them through bootstrapping -i.e., by simply issuing any arbitrary query, collecting all queries appearing in the documents returned by the initial query, and repeating this process. Our technique lever-ages both observations by first collecting a large subset of queries, and then drawing a small query sample. Finally, we estimate the total number of queries based on the intersection size between the two. This enables the efficient estimation of SUM and COUNT queries without requiring a query pool.
 Summary of Contributions: Search Engines: Consider a keyword search engine which accepts keyword queries and returns documents matching them. Let the search engine X  X  corpus, i.e., the set of documents retrievable through keyword search. A user may search for documents in by specifying a search query consisting of one or a few words. A document D matches a query q (i.e., D  X  Sel ( q ) )if D contains q as a subsequence. The interface is restricted to return up to k docu-ments, where k is a pre-determined small constant, e.g., 100 Sel ( q ) can be returned in its entirety only if | Sel ( |
Sel ( q ) | &gt;k , we say that q overflows -i.e., only k documents in Sel ( q ) are selected according to a proprietary ranking function and returned. At the other extreme, if q is too specific to match any document, we say that an underflow occurs. If q neither over-flows nor underflows, we call it a valid query. For the purpose of this paper, we consider deterministic query processing over a static corpus, i.e., a query executed again produces the same results.
For the purpose of this paper, we assume that the interface does not allow users to  X  X croll through X  Sel ( q ) when q overflows. In-stead, the user must pose a new query by reformulating the search keyword. We argue that this is a reasonable assumption because many real-world top-k interfaces (e.g., Google) only allow  X  X age turns X  for limited (resp. 100) times.
 Running Example: Figure 1 depicts a running example which we shall use throughout the paper. The example reflects a simplistic search engine with k =2 and only includes single-word queries. Objectives of Sampling and Aggregate Estimation: The objec-tive of sampling is to retrieve i.i.d. sample documents from the cor-pus according to a pre-determined distribution  X  (  X  ) , where  X  the probability for a document D to be sampled, and D  X   X  1 . The objective of aggregate estimation, on the other hand, is to estimate aggregate queries of the form SELECT AGGR( f ( FROM  X  WHERE g ( D )=1 , where g ( D )  X  X  0 , 1 } indicates whether a document D  X   X  satisfies the selection conditions, f is the measure of interest (e.g., document length, the number of times a word appears in the document), and AGGR(  X  ) represents the aggregate function which can be SUM, AVG or COUNT.

Since many search engines impose limits on the number of queries from a user (e.g., Google offers only 100 free queries per day), a common objective for both sampling and aggregate estimation is to reduce the query cost -i.e., to minimize the number of queries issued through the keyword search interface.
In this subsection, we briefly review two existing techniques used later in the paper -simple random walk for sampling an undi-rected graph, and mark-and-recapture for estimating the size of a population through sampling.
 Simple Random Walk: Given a graph, a simple random walk starts from any arbitrary node, chooses a neighbor of it uniformly at random, and moves to this neighbor. If the graph is non-bipartite, then by repeating this process, the simple random walk eventually converges to a stationary distribution with which each node is vis-ited with probability proportional to its degree [14] -i.e., the prob-ability for a node v to be selected is  X  ( v )= d ( v ) / is the degree of v and m is the total number of edges in graph. Mark-and-Recapture: Originally designed in ecology, mark-and-recapture estimates a population size through sampling [18]. With this method, one picks r simple random samples from a population and counts the number of tuples appearing more than once in the sample, denoted by C . Then, the population size can be estimated as r ( r  X  1) / 2 C . A variation of this estimator can be used when the samples are drawn according to a non-uniform distribution -e.g., [13] shows how mark-and-recapture can be used for estimating graph size based on samples generated from simple random walks.
In this section, we first define the query graph and describe our key ideas for enabling efficient simple random walks on it. We then instantiate the ideas in QG-SAMPLER, our query graph based algorithm for sampling documents in a search engine X  X  corpus, and discuss its effectiveness through theoretical analysis. Nodes: Recall from the introduction that the key idea of our pool-free sampler is to perform random walks on a  X  X irtual X  graph formed by queries. For the purpose of this paper, we consider a query graph consisting of h -grams, each returning at least u ( 1  X  u uments when issued through the keyword search interface. Here h and u are input parameters. While our algorithms are generic to any h and u , we briefly discuss here their settings in real-world scenar-ios: As pointed out in prior work [23, 24], single-word queries (i.e., h =1 ) often suffice for enterprise-level search engines containing fewer than a million documents. We tested both h =1 and h&gt; in our experiments. On the other hand, the value of u has a signifi-cant impact on the graph size. We found through experiments that a small u (e.g., u =3 ) often works well in balancing the needs of a high recall and a small graph size.

One can see from the definition that it is impossible to fully  X  X a-grams in the documents -a process that is obviously too expensive to be practical. Thus, our usage of the graph for sampling has to be in a  X  X irtual X  manner -i.e., by enabling on-the-fly random walks without ever knowing the graph in its entirety. We shall show in the following discussions that this  X  X irtuality X  requirement is an important factor in our definition of edges for the graph. Edges: The definition of an edge has to serve two purposes: (1) It must allow an on-the-fly random walk on the graph -i.e., given a query node, we can randomly pick a neighbor of it with a small query cost; (2) The degree of each node should be maximized, so as a random walk on the query graph can quickly converge to its stationary distribution (and be ready for providing a node sample). Note that to avoid problems of random walk in a directed graph, (e.g., deadlock states and diamond-like structures [14, 16, 17]), we focus on undirected edges in this paper.

To understand the subtleness of edge definition, we start by con-sidering two baseline ones and their problems: The first definition is that there is an edge between two queries if both match a docu-ment in the corpus. Unfortunately, this definition disables on-the-fly random walks because it is impossible to determine whether two overflowing queries are connected -i.e., there might be a document that matches both queries but is returned by neither.

The second baseline is to define an edge between two queries if both return a document in the corpus. With this definition, one can randomly pick a neighbor of a query node by examining all docu-ments returned by the query, extracting from them all h -grams, and issuing a randomly selected h -gram until finding one that returns at least u documents. Unfortunately, this definition may not pro-duce many edges in the graph. Note that even for two very popular (overflowing) queries, the probability of them returning the same document in top-k results can be small. Thus, this definition may lead to an inefficient random walk over the graph.

To address these problems, we define an edge between two query nodes q and q iff q matches at least one document q returns , and vice versa. As we shall show later in the paper, our definition not only enables on-the-fly random walks by allowing the efficient se-lection of a neighboring node, but also generates more edges than the second baseline definition described above. As a result, it en-ables random-walk-based sampling over the dense graph. Query Graph Definition: Based on our definition for nodes and edges, a formal definition for a query graph can be stated as follows.
D EFINITION 1. Given a search engine with corpus  X = { D 1 D ,...,D n } . Let R ( q ) be the set of documents returned by query q over  X  . Let W ( D i ) be the set of h -grams q which appear in D i and have | R ( q ) | X  u . The query graph for  X  is G = V,E , where V = n i =1 W ( D i ) , and  X  q,q  X  V , e ( q,q )  X  E iff q
Figure 2 depicts the query graph for the running example when h = u =1 . For example, there is an edge between query  X  X S X  and query  X  X indows X  because (1) a document returned by  X  X S X  , X , contains word  X  X indows X  , and (2) a document returned by  X  X indows X  , X 4 , contains the word  X  X S X  .
To generate query samples through random walks on a query graph, we need to enable two basic operations: (1) Select a neigh-boring node uniformly at random, so we could move to the next step in a random walk; (2) Calculate the degree of a node, so we could compute the probability for it to be sampled.

To complete the first operation, for a given query node q ,we first issue q to the search engine and collect R ( q ) , the set of all documents returned by q . Let Q ( q ) be the set of h -grams other than q which are extracted from R ( q ) . We select a query q uniformly at random from Q ( q ) , issue q and examine (1) whether the number of returned documents is at least u , and (2) whether q  X  both conditions are satisfied, we choose q as the next step in the random walk. Otherwise, we select a new q from Q ( q ) and restart this process. Algorithm 1 depicts this next-step generation process. Algorithm 1 Basic Operation 1: Select the Next Step 1: Input: a query q 2: Issue q to the search engine; 3: R ( q ) := docs returned by q ; 4: Q ( q ) := queries extracted from R ( q ) ; 5: while true do 6: q := a query chosen from Q ( q ) uniformly at random; 7: R ( q ) := docs returned by q ; 8: if | R ( q ) | X  u then 9: Q ( q ) := queries extracted from R ( q ) ; 10: if q  X  Q ( q ) then 11: return q . 12: end if 13: end if 14: end while
To calculate the degree of a node q , a naive method is to is-sue each query q i in Q ( q ) and count the number of q |
R ( q i ) | X  u and q  X  Q ( q i ) . Nevertheless, issuing each query in Q ( q ) may incur an extremely high query cost when the documents required by q are long. To address this problem, our method is to is-sue queries from Q ( q ) uniformly at random with replacement until finding a query q  X  Q ( q ) for which | R ( q ) | X  u and q If q is the m -th query we issued, an unbiased estimation for the degree of node q is | Q ( q ) | /m , i.e., where | Q ( q ) | is the number of queries in Q ( q ) , d query node q , and the expected value is taken over the randomness of m . Algorithm 2 depicts this degree-estimation process. [6] used a similar process to estimate the cardinality of a document. Algorithm 2 Basic Operation 2: Calculate a Node X  X  Degree 1: Input: a query q 2: Issue q to the search engine; 3: R ( q ) := docs returned by q ; 4: Q ( q ) := queries extracted from R ( q ) ; 5: counter :=0; 6: while true do 7: counter ++; 8: q := a query chosen from Q ( q ) uniformly at random; 9: R ( q ) := docs returned by q ; 10: if | R ( q ) | X  u then 11: Q ( q ) := queries extracted from R ( q ) except q ; 12: if q  X  Q ( q ) then 13: return | Q ( q ) | /counter . 14: end if 15: end if 16: end while
We combine the idea of query graph with a variation of a re-cent query-pool-based sampler [23] to produce QG-SAMPLER, a novel query-pool-free sampler. Recall the bipartite graph depicted in Figure 1, our objective here is to pick samples from the docu-ment corpus on the right hand side of the bipartite graph by issuing queries from the left hand side. Specifically, QG-SAMPLER has two steps: 1. Make a simple random walk on the query graph to generate a sample query; 2. Use the sample query to generate a sample document.
 Step 1: This step starts from any arbitrary query. We repeatedly pick a random neighbor to continue the simple random walk pro-cess. After a burn-in period (the length of which is dynamically determined according to the Geweke convergence monitor [19]), we obtain a query sample which follows simple random walk X  X  sta-tionary distribution. We calculate the degree of the sample query (which is proportional to its probability of being sampled), and save the degree for future reference.
 Step 2: Our main objective here is to eliminate the sampling bias favoring documents that are returned by more queries -either be-cause such a document matches more queries, or because it is highly ranked and therefore appear in the top-k results of more overflow-ing queries. To do so, we use the following sub-steps: (a) Given a sample query q , for probability | R ( q (b) This sub-step is where we combine our method with a varia-Pseudocode: Algorithm 3 depicts the pseudocode for QG-SAMPLER. Algorithm 3 QG-SAMPLER 1: Input: a starting point query sq 2: q = the node a simple random walk stops after a sufficient burn-3: d ( q ) = the degree of q in the query graph; 4: Issue q to the search engine; 5: R ( q ) = docs returned by q ; 6: Goto line 2 with probability 1-| R ( q ) | /k ; 7: D = a doc chosen from R ( q ) uniformly at random; 8: q = designated query of D ; 9: Goto line 2 if q = q ; 10: Save doc D and d ( q ) for future reference.
 Running Example: We now illustrate the above two steps using the running example depicted in Figures 1 and 2 when h = u and k =2 . Suppose that in Step 1, we start from  X  X indows X  and perform 4 steps of random walk through  X  X S X  ,  X  X ernel X  ,  X  X inux X  and  X  X andbook X  before the Geweke convergence monitor indi-cates convergence. At this time, we use q =  X  X andbook X  as a sample query. The next task is to compute the degree of  X  X and-book X  . To do so, we extract all h -grams (other than "Handbook" ) from X 2 and X 3 , the documents  X  X andbook X  returns. They are Q ( q ) ={  X  X indows X  ,  X  X S X  ,  X  X inux X  }. We select one of them uni-formly at random, assumed to be  X  X indows X  . We then issue it to validate that  X  X indows X  returns at least u =1 document, and at least one document returned by  X  X indows X  (i.e., X 2 ) matches  X  X andbook X  . Since we only attempted m =1 h -gram before find-ing a positive result, we estimate the degree of query  X  X andbook X  in the query graph to be | Q ( q ) | /m =3 / 1=3 .

In Step 2(a), since query  X  X andbook X  returns 2 documents and the k =2 , we proceed to select each of X 2 and X 3 with proba-bility 1 / 2 . Assume that we select D = X 2 . Then, in Step 2(b), suppose that we use the alphabetic-order-based designated query definition. We will order the queries in X 2 as "Handbook" , "OS" and "Windows" . With this order, we will first issue query  X  X and-book X  .As  X  X andbook X  returns X 2 , we confirm that it is indeed the designated query for X 2 . Thus, we will accept X 2 as a sample document.
 Usage of Samples: An important note here is that QG-SAMPLER does not follow the uniform distribution on sampling documents. Instead, the probability for a document to be sampled is propor-tional to the probability that its designated query is sampled by a simple random walk in Step 1. Specifically, according to the sta-tionary distribution of simple random walk, a query q is selected with probability  X  ( q )= d ( q ) / (2 | E | ) , where d of q in the query graph and | E | is the total number of edges in the graph. Thus, the probability for a document D to be sampled by QG-SAMPLER is proportional to the degree of its designated query.

There are two ways to use these non-uniformly-sampled docu-ments: rejection sampling and importance sampling. If we do need uniform random samples, we can perform an acceptance/rejection procedure. In this procedure, we accept a sample document D with probability 1 /d ( q ) (i.e., reject sample D with probability 1 /d ( q ) ), where q is the designated query for D -recall that d mate certain aggregate query answers based on the samples, then we can resort to importance sampling and generate estimations without any rejection. For example, given x sample documents D ,...,D x generated by QG-SAMPLER and their respective des-ignated queries q 1 ,...,q x , an (asymptotically) unbiased estimation for the answer to Q AGG : SELECT AVG( f ( D ) )FROM  X  is: Unlike rejection sampling, importance sampling takes advantage of all original samples, leading to an estimation variance much smaller than that of rejection sampling [6]. Connectivity of Query Graphs: The connectivity of a query graph is important for the effectiveness of QG-SAMPLER. While the ex-act connectivity depends on many factors such as the underlying data distribution (e.g., document length, word/phrase frequency), the following theorem illustrates that the probability for  X  X opular X  queries (e.g., overflowing ones) to be disconnected in the query graph is fairly small.

T HEOREM 3.1. For a search engine with a corpus containing n documents and a top-k interface, if each document can be re-turned by l queries and each query returns k documents chosen uniformly at random from the corpus, then the probability for this search engine X  X  query graph to be disconnected satisfies Sketch of Proof : Since each document can be recalled by l queries, the smallest disconnected component which can ever appear in the query graph has size l . The probability for such a disconnected component to appear is 1 / n k disconnected component is smaller. On the other hand, we have n  X  l/k queries in the query graph. As such, the size of the smallest disconnected component is at most n  X  l/ 2 k . Thus, the probability for this search engine X  X  query graph to be disconnected is less than (( n  X  l/ 2 k )  X  l +1) / n k
According to the theorem, for a search engine with n = 300 documents, k =10 and l = 200 , the probability for the query graph to be disconnected is less than 10  X  9545 . Even when k 1 , the probability of a disconnected the query graph is less than Comparison with Existing Query-Pool-Free Approach: Before concluding this section, we would like to briefly compare our pro-posed techniques with the only existing pool-free sampler [5], which we refer to as the document graph sampler (DG-SAMPLER). Note that DG-SAMPLER was mainly designed as a theoretical approach [5]. Our focus here is to explain why our technique can outperform DG-SAMPLER by orders of magnitude, even though both use a graph-based data structure to enable sampling.

Unlike our query graph, DG-SAMPLER directly samples a doc-ument graph -i.e., each node is a document, and two nodes are connected if both are returned by the same query. At first glance, a document graph might seem like the dual graph of our query graph, and thus would yield similar performance. It is important to under-stand that this is indeed far from the truth -mainly because of the ranking functions used by real-world search engines.

To understand why, consider as an illustrative example two closely related queries -e.g.,  X  X Phone X  and  X  X ndroid X . Since almost all search engines take into consideration the relevance between query and documents (e.g., through the TF-IDF measure) in the ranking function, it is often the case that the top-k answers for  X  X Phone X  and  X  X ndroid X  have no intersection at all, yet almost every document returned by  X  X Phone X  also mentions  X  X ndroid X  (and vice versa). If only these two queries are considered, the document graph is dis-connected between the documents returned by  X  X Phone X  and those returned by  X  X ndroid X . On the other hand, our query graph directly connects the two queries because of the co-mentionings and there-fore supports the sampling (and recall) of all documents. One can see from this simplistic example that our query graph construction leads to a much  X  X enser X  graph which achieves higher recall and shorter burn-in period.

Our real-world experiments confirm the above intuitions. Specif-ically, we set k =10 for a corpus consisting of 1000 real-world documents, and draw its query graph and document graph, respec-tively. We find that the query graph is densely connected while the document graph is disconnected. Besides the main component, the document graph contains two separate (yet small) connected com-ponents -with sizes 3 and 1, respectively. A more detailed discus-sion of the comparison is available in the experimental evaluations in Section 5.
In this section, we turn our attention to the second task, third-party aggregate estimation over a search engine X  X  corpus. The key challenge here is to estimate the total number of nodes (i.e., queries) in a query graph, so as to enable the estimation of SUM and COUNT queries. In the following, we first introduce our key ideas for esti-mating the query graph size, and then describe QG-ESTIMATOR, our algorithm for pool-free aggregate estimation.
The mark and recapture technique [18] has been extensively used for graph size estimations -specifically, the estimations are generated by counting the number of collisions among nodes drawn as samples [13, 22]. The key difference between our approach and these previous work is that, instead of waiting for collisions in random walks, we first collect an arbitrary (i.e., not-randomly-sampled) startup query collection which contains a significant num-ber of nodes in this graph, and then start a random walk to seek collisions with this startup collection. This way, the number of random walk steps required to reach a collision is substantially re-duced, leading to a faster and more accurate graph size estimation. Specifically, we describe the two steps, 1) construct a startup col-lection, and (2) seek collisions with a random walk and generate a graph size estimation, respectively as follows.
 Step 1: A key observation here is that, although it is extremely difficult to crawl all queries in a query graph, it is actually easy to collect a large number of them. Specifically, we start by making a simple random walk on a query graph. Instead of trying to draw node samples, our goal here is to simply extract all h -grams from every document returned by every query encountered during the random walk. We then use these extracted h -grams as our startup query collection V C . We shall demonstrate in the experimental re-sults in Section 5.2 that a small number of queries suffice to collect a large percentage of queries in the graph.
 A subtle issue here is that not all h -grams we include in V tually return u or more documents -i.e., some of them may not qualify as a node in the query graph. Fortunately, the correction for this is straightforward -we only need to estimate the percentage of queries in V C that qualify, denoted by  X  ( V C ) . We do so by drawing a uniform random sample from the collection and issuing them to test their qualifications. The percentage computed from the sample, denoted by  X   X  ( V C ) , serves as an unbiased estimation of  X  Step 2: Once V C is collected, we simply use the simple random walk process depicted in Step 1 of QG-SAMPLER to sample the query graph. Let the sample queries drawn be S . Recall that the probability for a query q to be sampled is proportional to its degree d ( q ) in the query graph. Thus, we can adopt importance sampling to estimate the number of nodes in the query graph G : V,E as follows.
Before concluding this subsection, we would like to note that our graph size estimator not only enables query-pool-free aggre-gate estimation, as we shall show in the following subsection, but may be of independent interest to problems unrelated to search en-gine analytics -e.g., for estimating the size of a social network. While a complete evaluation of this idea for various applications is out of the scope of this paper, we will nevertheless demonstrate its superiority over a state-of-the-art graph size estimator [13] in the experimental evaluation.
We now describe QG-ESTIMATOR, the first query-pool-free es-timator to be able to answer COUNT and SUM queries over a search engine X  X  corpus. For the ease of discussion, we first fo-cus our discussions on one aggregate query: SELECT COUNT(*) FROM  X  , i.e., the total number of documents in the corpus, and then extend the results to other COUNT, SUM and AVG queries (with or without selection conditions) at the end of this subsection. Description: Like QG-SAMPLER, QG-ESTIMATOR enables ag-gregate estimation by combining query graph sampling with a vari-ant of the state-of-the-art pool-based estimators [6, 23]. Specifi-cally, once the startup query collection V C is built according to Section 4.1, we start a simple random walk over the query graph and use each selected sample for two purposes: One is to seek col-lision with V C to estimate the query graph size. The other is to use it in a variation of the query-pool-based estimator for aggregate estimations -as if the query were drawn from a query pool. We elaborate this second usage in the following discussions.
Recall the bipartite graph depicted in Figure 1. For each (solid) edge e connecting a query with a document, assign it a weight w ( e )=1 / X  ( D ( e )) , where  X  (  X  ) is the number of queries that re-turn a document, and D ( e ) is the document associated with e . One can see that the sum of weights for all edges in the bipartite graph is exactly COUNT(*), the number of documents in the corpus. Thus, given a sample query, our objective is reduced to estimate  X  each returned document D . This can be done in a way similar to (1) -i.e., we first find all h -grams which match D , denoted by Then, we issue queries selected from  X ( D ) uniformly at random with replacement until finding a query which returns at least u doc-uments, one of which is D . At that time, if we have issued m queries, then an unbiased estimation for  X  ( D ) is |  X ( D
In summary, given a startup query collection V C and a query sample set S , we can estimate the answer to COUNT(*) as Pseudocode: Algorithm 4 depicts the pseudocode for the second step of QG-ESTIMATOR -i.e., once a sample query q is drawn from a random walk on the query graph.
 Algorithm 4 QG-ESTIMATOR Step (2) 1: Input: a query sample q 2: Issue query q to the search engine; 3: d ( q ) := the degree of q in the query graph; 4: Check whether q exists in the startup pool or not, save this info 5: R ( q ) = docs returned by q ; 6: for each doc D in R ( q ) do 7: Find and randomly issue queries matching D to compute 8: end for Running Example: Again, we focus on demonstrating what hap-pens after a sample query, say  X  X andbook X  is drawn. Consider the first document returned, X 2 . The edge e connecting  X  X and-book X  and X 2 in the bipartite graph in Figure 1 has a weight of w ( e )=1 / 3 because there are 3 queries,  X  X S X ,  X  X indows X  and  X  X andbook X , which return X 2 . We consider the estimation of w in QG-ESTIMATOR. First, we find all h -grams which match X  X (
X 2 ) = { X  X S X ,  X  X indows X ,  X  X andbook X  X , and select one of them uniformly at random to issue. Since the selected query returns at least u =1 results which include X 2 , our estimation for w |  X ( D ) | /m ( D )=3 / 1=3 .
 Extensions to Other Aggregate Queries: We now discuss the ex-tension of the above results to any SUM, COUNT and AVG queries defined in Section 2.1, with or without selection conditions. To un-derstand how a simple extension works, consider query SELECT AGGR( f ( D ) )FROM  X  WHERE g ( D )=1 . Note that if only we change the above-described edge weight in the bipartite graph from w ( e )=1 / X  ( D ( e )) to w ( e )= f ( D ( e ))  X  g ( D ( e )) sum of all edge weights in the bipartite graph becomes exactly the SUM query answer. As such, the only change required to (5) is the change of m ( D ) / |  X ( D ) | to f ( D )  X  g ( D )  X  m ( COUNT is a special case of SUM, and AVG can be computed as SUM/COUNT, our results can be easily extended to process SUM, COUNT and AVG queries.
In this section, we first introduce our experimental setup, and then test QG-SAMPLER against the only existing pool-free sam-pler, DG-SAMPLER. After that, we compare the performance of our QG-SAMPLER and QG-ESTIMATOR with the state-of-the-art samplers and aggregate estimators which do require a query pool. Finally, we test two detailed design issues -the parameter settings for h and u in the query-graph definition. 1) Hardware and Platform: All of our experiments were per-formed on two computers with Intel Core 2 2.4GHz CPU, 4GB RAM and 32bit Windows 7 operating system. We implemented all algorithms in C#. 2) Search Engine: We adopted the preloaded Windows Search in Windows 7 as our search engine in all experiments. We used Win-dows Search X  X  default ranking function and set the default value of k (as in top-k limitation) to be 10. 3) Document Corpus: To set up the document corpus to be ana-lyzed, we followed the same technique as the existing work [5,6,23, 24]. Specifically, for the purpose of this paper, we constructed two document corpora -(1) Corpus G ENERAL which contains 271,147 web pages extracted from the ODP project [2]. Specifically, we first crawled 1 million webpages from ODP, and then sampled without replacement from them 300,000 web pages which have format htm, html or txt. At last, we deleted all webpages with fewer than 20 words (as most of them represent HTTP status like 404) to get the 271,147 web pages in Corpus G ENERAL . (2) Corpus M EDICAL which contains 30040 medical records sampled without replace-ment from the raw medical file in the DISP project [1]. 4) Algorithms: We tested a total of 7 algorithms for analytics over a search engine X  X  corpus. Four are for sampling: our QG-SAMPLER in this paper, DG-SAMPLER [5] which is the only ex-isting pool-free technique, as well as POOL-SAMPLER [5] and UNBIASED-SAMPLER [23], both of which require a query pool. The remaining three algorithms are for aggregate estimations: our QG-ESTIMATOR, as well as the pool-based POOL-ESTIMATOR [6] and STRATIFIED-ESTIMATOR [23].

Our QG-SAMPLER and QG-ESTIMATOR are parameter-free for a given query graph -which is defined by two parameters h and u . We set h =1 and u =3 by default, and test other values at the end of this section. The key input to the previous pool-based tech-niques is a query pool, the setup of which shall be described next. Note that in addition to the query pool, UNBIASED-SAMPLER and STRATIFIED-ESTIMATOR also require knowledge of (ap-ments, we consider the best-case scenario for these approaches and provide them with the exact frequencies of all queries in the cor-pus. For STRATIFIED-ESTIMATOR, we only stratify queries ac-cording to frequency and we don X  X  consider query correlation. For QG-ESTIMATOR, since query graph size doesn X  X  change for a spe-cific search engine and its estimation process can be piggybacked in multiple runs of aggregates estimations, we amortize the cost of query graph size estimation and assume a well pre-estimated query graph size value is available when we are testing a new ag-gregate. For all other parameters used in the existing techniques, we follow the default settings described in the respective original work [5, 6, 23].

In addition to these 7 algorithms, we also tested RW-ESTIMATOR [13], a state-of-the-art general-purpose graph-size estimator. The purpose of this test is to demonstrate the superiority (and neces-sity) of our special-designed size-estimation component in QG-ESTIMATOR. Again, we follow the default settings (as described in [13]) of RW-ESTIMATOR, with our query graph (with filter u =3 ) serving as the input. 5) Query Pool: In order to test whether how the performance of existing pool-based techniques may be affected by failing to cus-tomize the query pool (according to the corpus), we constructed two query pools from Corpus G ENERAL and M EDICAL , respec-tively. Specifically, similar to the query-pool construction proce-dure used in [5, 6, 23], we first extracted all queries from Cor-pus G ENERAL and M EDICAL , then discard the ones which ap-Figure 3: QG-SAMPLER vs DG-SAMPLER, Corpus G EN -Figure 7: Corpus G ENERAL ,
Pool M EDICAL pear fewer than 3 times in the corpus. The results are 455,901 and 41,798 queries for Pool G ENERAL and M EDICAL , respectively. 5) Performance Measures: Since the main challenge for sam-pling and aggregate estimation is the small query allowance im-posed by search engines, we used the number of issued queries as the efficiency measure for all algorithms being tested. To measure the accuracy of sampling (i.e., whether the actual sampling distri-bution follows the input -e.g., uniform -distribution), we resorted to an indirect measure -the relative error of AVG estimations gen-erated from the samples. We tested various AVG queries -e.g., the average document length and the average number of times word  X  X ootball X  is included in a document. For an AVG query of answer v , we measured the relative error as | (  X  v  X  v ) /v | estimation generated from samples. 1) Sampling: We start by testing the sampling algorithms. Fig-ures 3 and 4 compare the performance of our QG-SAMPLER against the existing pool-free sampler, DG-SAMPLER, over Corpus G ERAL and M EDICAL , respectively. Specifically, the figures depict the change of query cost vs the average document size estimated from samples generated by the two samplers. Figure 5 shows the same comparison, this time measuring the accuracy of samples on estimating another average query: the average number of times  X  X ootball X  is mentioned in a document over those documents in Corpus G ENERAL which contain the word  X  X ootball X . Here we don X  X  directly show the number of samples we can generate vs the number queries we use, the reason is that the sample qualities of QG-SAMPLER and DG-SAMPLER are quite different, we will show this in Figure 10.

One can see from all three figures that, over both corpora, for both AVG queries, the samples generated by QG-SAMPLER pro-duces far more accurate estimations with a query cost orders of magnitude smaller than that of DG-SAMPLER -indicating the su-periority of our sampler. We dug deeper into the experimental re-sults to identify three main reasons why QG-SAMPLER performs walk one step in the query graph than in the document graph. Sec-ond, compared with the document graph, the query graph has a higher average node degree (3,198 vs 520) and a higher graph den-to a much shorter burn-in period of the random walk. Third, in the document graph, there are a number of small and dense sub-graphs (usually formed by very long documents). When making random walks, it becomes extremely difficult to jump out of these dense sub-graphs -adversely affecting DG-SAMPLER X  X  efficiency in a significant manner.

Figures 6 and 7 compare QG-SAMPLER with two state-of-the-art samplers which do require a query pool, POOL-SAMPLER and UNBIASED-SAMPLER, again over Corpus G ENERAL in the same setting as Figure 3. The difference between these two figures is that in Figure 6, we used Pool G ENERAL -i.e., the perfectly tailored query pool for Corpus G ENERAL ; while in Figure 7, we used the Pool M EDICAL , an ill-aligned query pool. One can see from Fig-ure 6 that our QG-SAMPLER actually performs better than POOL-SAMPLER, though not as well as UNBIASED-SAMPLER, when both pool-based samplers are given the  X  X erfect X  query pool. On the other hand, in Figure 7, our QG-SAMPLER significantly out-performs both pool-based samplers -the main reason being that the ill-aligned Pool M EDICAL , being a more specialized query pool, is much more likely to recall longer documents in Corpus G ENERAL than the shorter ones. The rationale behind this is Heap X  X  Law -i.e., the longer a document, the larger a distinct vocabulary element set the document contains. As such, both pool-based samplers gener-ate severe overestimations when given the ill-aligned query pool. Figures 8 and 9 are the counterparts of Figures 6 and 7 for Corpus M
EDICAL . Specifically, the pool-based samplers were given the perfect Pool M EDICAL in Figure 8, and the ill-aligned Pool G ERAL in Figure 9. One can see that the two figures lead to similar conclusions as the Corpus-G ENERAL ones. The only difference is
Figure 11: QG-ESTIMATOR vs Pool-Based Estimators
Figure 15: AVG of frequency of mentioning for  X  X ootball X  that pool-based estimators, POOL-ESTIMATOR and STRATIFIED-ESTIMATOR perform better in Figure 9 than in Figure 7. The rea-son is that the variance of medical record size in Corpus M is much smaller than that of document size in the Corpus G
Figure 10 compares the query cost and skewness of samples gen-erated by QG-SAMPLER and DG-SAMPLER while varying the number of (uniform random) samples produced. Specifically, the skewness is measured by the accuracy of these (uniform random) samples on estimating the average document length. One can see from the figure that QG-SAMPLER not only produces sample doc-uments faster, but also generates samples with smaller skew. 2) Aggregate Estimation: Since our QG-ESTIMATOR is the first pool-free technique for SUM and COUNT estimations, we start by comparing QG-ESTIMATOR with the state-of-the-art pool-based estimators, POOL-and STRATIFIED-ESTIMATOR, when all are called upon to estimate SELECT COUNT(*) FROM  X  . Similar to Figures 6 and 7 for sampling, we provide the pool-based estima-tors with either a  X  X erfect X  query pool or a misaligned one. Figure 11 depicts the case when Pool G ENERAL is provided for Corpus G
ENERAL . One can see that QG-ESTIMATOR performs on-par with pool-based estimators. Figure 12 depicts the misaligned case when Pool M EDICAL is given for Corpus G ENERAL . One can see that both pool-based estimators generate severely underestimated results in this case, demonstrating the fragility of pool-based tech-niques.

To test our QG-ESTIMATOR over different types of aggregate queries, we considered a SUM query, the total number of  X  X oot-ball X  words appeared in Corpus G ENERAL , as well as a conditional AVG query (as described in the sampling experiments), the aver-age number of  X  X ootball X  words appeared in the documents which contain the word  X  X ootball X  in Corpus G ENERAL . Figure 13 and 14 depicts the results for the SUM query when Pool G ENERAL M
EDICAL are provided to the pool-based estimators, respectively, while Figure 15 depicts the results for the AVG query when Pool G
ENERAL is given to the pool-based estimators. One can see from these figures that, once again, our QG-ESTIMATOR performs on par with the pool-based ones when the perfect query pool is given to the latter, and performs significantly better when the pool-based estimators are given a misaligned query pool. 3) Graph Size Estimation: Figure 16 demonstrates the neces-sity of our custom-designed query-graph-size estimator by compar-ing its performance with a state-of-the-art general-purpose graph-size estimator, RW-ESTIMATOR [13]. One can see from the fig-ure that our size-estimation component, GS-ESTIMATOR signifi-cantly outperforms the direct usage of RW-ESTIMATOR. The rea-son for this is illustrated in Figure 17, which demonstrates how quickly our algorithm is capable of collecting the startup pool . Specifically, it shows that after issuing only 1,000 queries, we are capable of collecting 35.87% of all queries in the query graph -i.e., 163,532 out of 455,901 queries. This figure also shows that the speed of query collection decreases quickly with the increase of query cost -justifying our design rationale that, while it is pro-hibitively expensive to crawl the entire query graph, we can easily collect a significant portion of the queries with a small query cost. 4) Query Filter u : Recall that parameter u was used to define nodes (queries) in a query graph -specifically, we only accept as nodes those queries which return at least u documents. Figure 18 shows the effect of different values of u on (1) the total number of queries in the query graph, and (2) the percentage of documents in the corpus these queries can recall. One can observe from this figure a nice property of a small u (e.g., u  X  3 ) -while the number of queries decreases sharply with the increase of u , the recall is only slightly reduced. Thus, a small u can maintain a relatively high recall while keeping the size of the query graph small, enabling efficient random walks. This result justifies our selection of u in the experiments. 5) Query Length h : Although single word queries (i.e., h perform well over the two corpora we tested, to show that our tech-niques adapt well to other values of h , we tested the case where h =3 -i.e., queries are 3-grams (three consecutive words) in doc-uments. In Figure 19, we compare the performances of pool-based estimators with a perfectly constructed 3-gram query pool and our QG-ESTIMATOR with a 3-gram query graph, both over Corpus M EDICAL . As one can observe from the graph, once again, QG-ESTIMATOR performs on-par with the pool-based estimators. Third-Party Crawling and Sampling of a Search Engine X  X  Cor-pus: Several papers have considered crawling/downloading infor-mation from a search engine X  X  corpus [4, 9, 15]. Most existing techniques for third-party sampling and aggregate query processing over a search engine X  X  corpus require prior knowledge of a query pool. Among them, [9] presented a method to measure the relative sizes between two search engines X  corpora. [6] and [5] achieved significant improvement on quality of samples and aggregate es-timation. [23] introduced the concept of designated query, based on sampling bias can be completely removed. [8] discussed how to estimate a new aggregate metric ImpressionRank. Sampling on-line suggestion databases were discussed in [7]. [24] addressed the problem from the perspective of a search engine owner -i.e., how to prevent sensitive aggregates from being inferred through the key-word search interface.
 Mining a Search Engine X  X  Corpus without a Query Pool: The only existing technique for mining a search engine X  X  corpus with-out a query pool was proposed in [5]. To retrieve document sam-ples, this technique first builds a document graph, and then makes Metropolis-Hastings random walks on the graph. This technique was designed as a theoretical approach since it severely underper-forms query-pool-based samplers and lacks the ability to estimate SUM and COUNT aggregates [5].
 Estimating the Size of a Graph via Sampling: A common method in ecology for estimating population size is mark-and-recapture [18]. The mark-and-recapture method has generated quite a few variants -[13, 22] are good references for the most recent database-related developments.
 Crawling and Sampling from Hidden Databases: Analytics over structured hidden web databases is a related area. [20,21] discussed crawling. Sampling over hidden databases was proposed in [10, 12], and aggregate estimation techniques in [11], all based on a random drill down technique that differs significantly from the sam-pling techniques for search engines.
In this paper, we addressed the problem of enabling third-party analytics over a search engine X  X  corpus only by issuing queries through its keyword search interface. Almost all previous tech-niques assumed prior knowledge of a rich collection of queries known as the query pool. We started by illustrating why it is dif-ficult to create an appropriate query pool without extensive knowl-edge about the underlying corpus -creating a chicken-and-egg prob-lem. Then, to enable pool-free sampling and aggregate estimations, we proposed a novel concept called the query graph. By making random walks on the query graph, we are able to retrieve query samples and estimate SUM, COUNT, and AVG queries over the document corpus efficiently. We presented theoretical analysis and extensive experimental results over real-world document corpora to demonstrate the effectiveness of our query-pool-free techniques. [1] Data intensive semantics and pragmatics project [2] Open directory project http://www.dmoz.org . [3] https://developers.google.com/ [4] E. Agichtein, P. G. Ipeirotis, and L. Gravano. Modeling [5] Z. Bar-Yossef and M. Gurevich. Random sampling from a [6] Z. Bar-Yossef and M. Gurevich. Efficient search engine [7] Z. Bar-Yossef and M. Gurevich. Mining search engine query [8] Z. Bar-Yossef and M. Gurevich. Estimating the [9] K. Bharat and A. Broder. A technique for measuring the [10] A. Dasgupta, G. Das, and H. Mannila. A random walk [11] A. Dasgupta, X. Jin, B. Jewell, N. Zhang, and G. Das. [12] A. Dasgupta, N. Zhang, and G. Das. Leveraging count [13] L. Katzir, E. Liberty, and O. Somekh. Estimating sizes of [14] L. Lov X sz. Random walks on graphs: A survey, 1993. [15] A. Ntoulas, P. Zerfos, and J. Cho. Downloading textual [16] R. Pel X nek, T. Han X l, I.  X  Cern X , and L. Brim. Enhancing [17] B. Ribeiro, P. Wang, F. Murai, and D. Towsley. Sampling [18] D. S. Robsom and H. A. Regier. Sample size in petersen [19] K. Sahlin. Estimating convergence of markov chain monte [20] C. Sheng, N. Zhang, Y. Tao, and X. Jin. Optimal algorithms [21] P. Wu, J.-R. Wen, H. Liu, and W.-Y. Ma. Query selection [22] S. Ye and F. Wu. Estimating the size of online social [23] M. Zhang, N. Zhang, and G. Das. Mining a search engine X  X  [24] M. Zhang, N. Zhang, and G. Das. Aggregate suppression for
