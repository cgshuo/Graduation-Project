 Many real-world objects described by multiple attributes or features can be decomposed as multiple  X  X iews X  (e.g., an image can be described by a color view or a shape view), which often provides complementary information to each other. Learning a metric (similarity measures) for multi-view data is primary due to its wide applications in prac-tices. However, leveraging multi-view information to pro-duce a good metric is a great challenge and existing tech-niques are concerned with pairwise similarities, leading to undesirable fusion metric and high computational complex-ity. In this paper, we propose a novel M etric F usion tech-nique via cross-view graph R andom W alk, named MFRW ,re-garding a multi-view based similarity graphs (with each sim-ilarity graph constructed under each view). Instead of using pairwise similarities, we seek a high-order metric yielded by graph random walks over constructed similarity graphs. Ob-serving that  X  X utlier views X  may exist in the fusion process, we incorporate the coefficient matrices representing the cor-relation strength between any two views into MFRW ,named WMFRW . The principle of WMFRW is implemented by ex-ploring the  X  X ommon latent structure X  between views. The empirical studies conducted on real-world databases demon-strate that our approach outperforms the state-of-the-art competitors in terms of effectiveness and efficiency. I.2.6 [ Artificial Intelligence ]: Learning Metric fusion; Cross-view based graph random walk
In many real-world applications, data objects are natu-rally decomposed as multiple views. For instance, images can be described by different kinds of low-level features, such as color histogram, texture feature; web pages can be described by their content or the content of pages linking to them. As a result, learning on multi-view data has at-tracted great attentions due to their appealing property of leveraging complementary information from multiple views, leading to the emerging of many paradigms [5, 12, ? , 15, 4] for multi-view learning. In the study of these approaches, metric learning plays an important role as it poses heavy influence on learning performance specialized in the tasks of multi-view based image retrieval [16], video annotation [15], and image clustering [17]. A crucial issue is how to obtain a good metric regarding multi-view data, and More efforts have been paid on how to obtain a good metric over multi-view data to achieve satisfactory learning results. To this end, a lot of approaches are proposed. For instance, Huang et al. [6] made a linear combination of the metrics with equal weight on each view, and obtained the image ranking results based on the fused metric. Wang et al. [15] performed another linear combination of the metrics corre-sponding to different graph layers but with different weights. Moreover, Zhai et al. [18] proposed to learn the combined metric by regulating each metric to be learnt under the global consistency and local smoothness. All these  X  X ne-combo-fits-all X  methods are able to achieve promising re-sults, and significantly outperform single view based learning methods. However, the similarities between objects may be manifested differently for different views. In such cases, the one-combo-fits-all methods may not work well, and worse still, the learning results may be poor especially when there exist outlier views, that is, one or some views are remote from others. Motivated by this, a diffusion based method is proposed in [13], where the authors fused the metric from each graph-layer with equal importance. Although it does achieve some better results, the following limitations still exist. First, it suffers from high computational complexity of fusing the large size similarity matrix derived from each graph layer. Second, they only consider the pair-wise based neighborhood relationship between data points, resulting in the undesirable performance from pair-wise based metrics. Third, they still fail to effectively handle the issues of outlier views. To overcome the above drawbacks, in this paper, we propose a novel metric fusion technique via cross-view based graph random walk, named MFRW . Specifically, MFRW has the following novel features.

Lower computational complexity. Asmallnumberof anchor points (cluster centers) are obtained by employing K-Mean clustering algorithm [2] with a finite number itera-tions. Then, for each graph layer, we generate a high-order based data-cluster similarity matrix which figures the similarity between data points and anchors (refer to sec-tion 2.1). It is worth highlighting an excellent property of the novel high-order similarity matrix, that is, the matrix is high-order, smaller-sized and low-rank, which avoids the high computational complexity in pair-wise data similarity matrix [13].

Higher-order similarity. To compute more accurate data-cluster similarity matrix, we go beyond pair-wise sim-ilarity manner by proposing a cross-view based graph ran-dom walk. For each graph layer, a similarity value between data point and anchor is computed by propagating the sim-ilarity values of its nearby points. This process is formally formulated as a graph random walk. We perform this cross-view dynamic process over multi-layer graphs iteratively un-til convergence, and the convergence property is proved (re-fer to section 2.2).

Robustness to  X  X utlier views X . Observing that some  X  X utlier views X  may exist, we devise an effective strategy by introducing a correlation strength matrix between views to avoid the influence of outlier views, which can further improve the performance (refer to section 2.4).

Enhanced by the aforementioned innovations, the algo-rithm of MFRW can achieve better performance on metric fusion over multi-view data. Finally, we summarize our ma-jor contributions as follows. 1. We develop a novel metric fusion method, named MFRW , 2. Instead of fusing the data similarity matrix with a 3. To tackle the problem of outlier views, we develop an
The rest of our paper is structured as follows. Our pro-posed method is introduced in Section 2, followed by the complexity analysis in Section 3. Section 4 reports the experimental results, and we conclude this paper in Section 5.
In this section, we present our proposed method, MFRW , for metric learning over multi-layer graphs [3]. The fused metric aims at incorporating the complementary informa-tion from all graph layers. MFRW is an unsupervised paradigm by jointly performing graph random walk and metric learn-ing over multi-layer graphs, to achieve the high-order based similarity measure among data points.
The basic idea of computing the high-order similarity be-tween data points, is to firstly yield a high-order data-cluster similarity measure, which describes the similarity between data points and the corresponding clusters of the dataset. Instead of computing the similarity value by a pair-wise com-putation between a data point and its nearest anchor, our high-order data-cluster similarity measure considers the con-tribution from the data-cluster similarity from all its neigh-borhood points (See Fig. 1), which is implemented by the graph random walk. We define data-cluster similarity as follows.

Data-cluster similarity .The data-cluster similarity is the similarity between the data point and the center of clus-ter. Like [9], we name the cluster centers as anchors .
The clustering result and corresponding anchors are ob-tained by employing K-Mean Clustering algorithm [2]. As-sume the number of anchors is r ,thenweconstructthe data-cluster similarity matrix as U  X  R n  X  r ,witheachentry defined as Eq. (1) holds if j th anchor z j is within the s nearest anchors between x i and z j . U ( x i ,z j ) may be different for different views. Then the data-similarity matrix deriving from data-cluster similarity matrix is calculated as W = UU T .Intu-itively, W is obtained by considering the high-order data-cluster similarity matrix U . There have been some work (e.g., [9]) on calculating the data-cluster similarity, how-ever they only consider the pair-wise similarity between data point and its nearest anchors as Eq. (1), while overlooking the edge similarity over data graph G , which should also make a contribution to form a high-order data-cluster simi-larity matrix. Motivated by this, we propose to make a more desirable high-order data-cluster similarity matrix via graph random walk, as illustrated in next section.
We perform an iterative model to yield high-order data-cluster matrix, which is formulated as where 0 &lt; X &lt; 1, and U (0)  X  R n  X  r represents the initial data-cluster similarity matrix, with each entry defined as Eq. (1). S ( t ) is varied along time stamp t due to the var-ied data-cluster similarity matrix. Intuitively, the iterative model described as Eq. (2) propagates the data-cluster sim-ilarity matrix of each data point to other data points via S ( t ) as a graph random walk. Eq. (2) is iteratively per-formed until convergence. As such, we obtain a more de-sirable high-order data-cluster similarity matrix rather than a pair-wise fashion. We illustrate the difference between high-order data-cluster similarity (for any time stamp t in Eq. (2)) and pair-wise data-cluster similarity in Fig. 1.
In this section, we present the proposed method, MFRW , a metric fusion method for metric learning on multi-view graphs via graph random walk. To make the proposed method easy to understand, we first deliver MFRW on the two-layer graphs via a cross-view based graph random walk approach, then extend it to multi-layer graphs.
We take two-layer graphs as example to show the intuition of
MFRW . The basic idea of MFRW is to fuse the high-order data-cluster matrix U regarding each graph layer during the graph random walk process based on Eq. (2). The fi-nal learning metric specialized as data similarity matrix is ( a) ( b) Figure 1: (a) illustrates the pair-wise data-cluster similarity between x i and z j in existing methods; (b) illustrates our strategy for a high-order data-cluster similarity between x i and z j implemented by graph random walk technique at one time stamp.
 Specifically, it fuses both similarity between x j ( j = i ) and x i and x j ( j = i ) and z j . calculated as W = UU T . U is a low-rank and smaller-sized matrix compared to W ,whichmakes MFRW efficient as demonstrated in experimental part. The iterative form of calculating high-order based data-cluster similarity matrix regarding each graph layer performs as where U i ( t ) represents the data-cluster matrix regarding i th graph layer at time stamp t ,and S i ( t )= D i ( t )  X  1
Generating anchor set . We generate the same anchor set for different graph layers. Particularly, we adopt the K-Means algorithm off-line associated with the average metric distance regarding all graph layers. To be efficient, we only run a few number of iterations (four iterations are enough in our experiments).

Formally, MFRW performs the metric fusion process over two-layer graphs as where I n  X  r is a n  X  r matrix with all entries to be 1, r is the number of clusters or anchors. U 2 ( t ) T is the transpose of U ( t );  X I n  X  r is incorporated into Eqs. (4) and (5) to ensure the fusion process robust to noise. U i ( i, j )= U i ( i,j )(0) is the row normalized form of data-cluster matrix at initial time stamp with t = 0. Adopting the row normalized form is to avoid the different scales for metric distance on various graph layers.
 Intuition . We provide the intuition of Eq. (4) about the fusion of data-cluster similarity over the first graph layer. Similar intuition holds for Eq. (5) over the second graph layer. We capture the intuition by splitting the right-hand side of Eq. (4) into two parts, as U 1 U 2 ( t ) T and U 1 spectively. U 1 U 2 ( t ) T ( i, j )= r k =1 U 1 ( i, k ) U resents the cross-view based fusion similarity between x i x .Thus, U 1 U 2 ( t ) T U 1 ( i, m )= n j =1 U 1 U 2 ( t ) represents data-cluster similarity between x i and z m . Straight-forwardly, such similarity for the first graph layer is yielded by fusing both data-cluster similarity from two graph lay-ers. Besides, as will be discussed in section 3, fusing a low-rank and small-sized data-cluster similarity matrix is more efficient than that on a large-sized pair-wise data similarity matrix.

For the first graph layer, we alternatively perform graph random walk illustrated as Eq. (3)( i =1)and metric fusion illustrated as Eq. (4). Likewise, for the second graph layer, Eq. (3)( i = 2) and Eq. (5) are alternatively performed until convergence. S i ( t ) is the normalized form of W i calculated as Eq. (6) during the fusion process of MFRW . As mentioned above, the graph studied in this paper has no self-loop edges, therefore, we simply set all the diagonal elements of W i ( t ) to be 0. The basic idea of MFRW is to perform a cross-view based data-cluster similarity matrix fu-sion rather than data similarity. The high-order data-cluster similarity matrix for each view is effectively yielded by graph random walk. We summarize the MFRW for two layers in Algorithm 1.

Algorithm 1: The algorithm of MFRW for two-layer graphs Input : initial data-cluster similarity matrix
Output : The convergent data similarity matrix W  X  1 W 1 (0) = U 1 (0) U 1 (0) T 2 W 2 (0) = U 2 (0) U 2 (0) T 3 t =1 4 while MFRW is not convergent do 5 U 1 ( t  X  1) =  X S 1 ( t  X  1) U 1 ( t  X  1) + (1  X   X  ) U 1 6 U 2 ( t  X  1) =  X S 2 ( t  X  1) U 2 ( t  X  1) + (1  X   X  ) U 2 7 U 1 ( t )= U 1 U 2 ( t  X  1) T U 1 +  X I n  X  r 8 U 2 ( t )= U 2 U 1 ( t  X  1) T U 2 +  X I n  X  r 9 W 1 ( t )= U 1 ( t ) U 1 ( t ) T 10 W 2 ( t )= U 2 ( t ) U 2 ( t ) T 11 t = t +1 12 U = similarity matrix for i th view. 13 W  X  = UU T
Remark 1. Different from Eq. (4) and Eq. (5) ,inlines 6-7, the time stamps for both U i ( i =1 , 2) isthesameafter graph random walk updating the high-order data-cluster sim-ilarity matrix. In Algorithm 1, we update the time stamp when carrying out fusing process identified by lines 8-9. In lines 5-6, S i ( t )( i =1 , 2) is updated by W i ( t ) in lines 9-10, which is formed by fusing the data-cluster similarity ma-trix in lines 7-8 from different views. Thus, we refer the graph random walk process in lines 5-6 as, cross-view based graph random walk .
Basedonthe MFRW for two layer graphs, the multi-layer case of MFRW is proposed as alternatively performing the following equations.

U i ( t )=  X S i ( t ) U i ( t )+(1  X   X  ) U i (0)( i =1 , 2 , where M is the total number of graph layers or views. Fol-lowing Remark 1, we will not increase the time stamp for U ( t )onbothsideofEq.(7),despiteweupdate U i ( t )via graph random walk in Eq. (7). The time stamp will increase when running the data-cluster similarity fusion process for-mulated as Eq.(8). The final fused data-cluster similarity matrix is obtained as U = M i =1 U i M ,where U i represents the converged data-cluster matrix regarding i th graph layer, which further leads to the converged data similarity matrix computed as UU T for multi-layer graphs.

Remark 2. One important problem in MFRW is the ex-istence of outlier views that are significantly inconsistent to other views during the process at involving time stamps. Simply fusing all views with the same weight will deteriorate the overall performance of MFRW . To this end, we devise an effective strategy of identifying the correlation strength between any two views at each iteration. Then, the correla-tion strength is incorporated into MFRW . Consequently, we extend MFRW to WMFRW , which will be presented in the next section.
The basic idea of learning correlation parameters between two graph layers is to explore the  X  X ommon latent structure X  shared by different views. We assume a coefficient matrix to represent the common latent structure. The coefficient ma-trix is enforced to drive clusters from different graph layers to reach a common census, which reflects the latent cluster-ing structure shared by different views.

Specifically, for MFRW , we aim to compute a coefficient strength matrix between different views for the data-cluster similarity matrix. As a result, the coefficient strength matrix can be regarded as a map from one data-cluster anchors set in one feature space to the anchor sets from another feature space. Without loss of generality, we take i th and j th graph layers (1  X  i, j  X  M ) as example. For data points set X under the i th view, there exists a m  X  n matrix denoted by F i . Likewise, there exists a l  X  n matrix denoted by a F j regarding the j th view. We select r cluster centers to be r anchors by running K-Mean algorithm. Thereafter, the correlation matrix between i th and j th graph layers is represented by a r  X  n matrix denoted by H [ ij ] . Then, we have the following approximations in Eq. (9) regarding F i and F j , respectively.
 where B i  X  R m  X  r and B j  X  R l  X  r are the bases of data-cluster similarity matrices regarding i th and j th view, re-spectively. U i and U j can be simply obtained as r clusters in i th and j th view, respectively. Then H [ ij ] can be calcu-lated by minimizing the following objective function, which is a linear combination of two least squares problems.
P where  X  is the parameter (0  X   X   X  1) that balances the approximation error for different views, and H 0. We then achieve the fix point iteration of H as follows. H where is the element-wise multiplier. With the availabil-ity of H at each step, for the i th view, the fusion strategy performed by WMFRW is as follows.
 Finally, the algorithm of WMFRW issummarizedinAlgo-rithm 2.

Algorithm 2: The algorithm of WMFRW for multi-layer graphs Input : Initial data-cluster similarity matrix
Output : The convergent data-similarity matrix W  X  1for i =1 , 2 ,  X  X  X  ,M do 2 W i (0) = U i (0) U i (0) T 3 t =1 4 while WMFRW is not convergent do 5for i =1 , 2 ,  X  X  X  ,M do 11 U = 2 i =1 U i 2 ;// U i is the convergent data-cluster 12 W  X  = UU T
Note that we initialize all the entries of H [ ij ] ( H [ ij ] be positive values sampled from Gaussian distribution. For any view i ,itcancheckwhether j th view is the outlier view at time stamp t according to H [ ij ] ( t ). Thereby, below we provide the formal definition on outlier views.

Definition 1. For the i th view, j th ( 1  X  j = i  X  M )view is the outlier view at time stamp t , provided that H [ ij ] Based on definition 1, for i th view regarding time stamp t , we assign the small weight to its outlier views (e.g., H [ ij ] for j th view), to avoid the negative affect from outlier views during the fusion process indicated by line 7 of Algorithm 2. Besides, we only initialize the bases of data-cluster sim-ilarity matrices B i ( i =1 , 2 ,  X  X  X  ,M ) once at the beginning of Algorithm 2, by carrying out K-Means clustering with a limited number of iterations (four iterations are sufficient for our method as demonstrated in the experimental part).
The time complexity of our algorithm mainly comes from two parts (1) the time complexity of generating anchor set via K-Mean clustering algorithm costs O ( Tnmr ), where T is the iteration number for K-Means clustering, n is the num-ber of data points, m is the dimension of the features, and r is the number of cluster numbers or anchors. Besides, the anchors set is only generated once at the beginning of the algorithm. The construction of the initial data-cluster similarity matrix U i (0)( i =1 , 2  X  X  X  ,M )costs O ( snmr ), the number of anchors r determines the efficiency. Therefore, it is O ( nmr ), and (2) U i ( i =1 , 2  X  X  X  ,M )inEq. (8)is constant during fusion process, therefore, the time complex-ity of the data-cluster similarity matrix fusion mainly comes from the calculation regarding single matrix U i ( t )  X  R n  X  r for i th graph layer with time stamp t . It X  X  time complexity is O ( nr ).
 Overall, the total time complexity is O (4 nmr )+2 O ( nr )= O ( nmr ) such that T = 4. For memory space cost, we only need to store the data-cluster similarity matrix U  X  R n  X  r rather than the similarity matrix W  X  R n  X  n .
In this section, we evaluate our method by comparing our method with state-of-the-art paradigms for shape retrieval in Section 4.1.1, and image retrieval in Section 4.1.2. Both our method and competitors are listed as follows. Note that for all experiments, we tuned the value of  X  in Eq. (7) to be 0.99 to be consistent in [19]. s for Eq. (1) is set to be 800, as we observe that the performance of MFRW is stable when s  X  800. As discussed in section 2.3.1, we generate the same anchor set for all views.
We first test our algorithm on a commonly used MPEG-7 database [7], which contains 1400 silhouette images from 70 classes and each class has 20 different shapes. The per-formance is measured by the bull X  X  eye score :everyshape is treated as a query and the accuracy of a retrieval win-dow size of 40 is accumulated and reported [13]. Three dif-ferent feature descriptors including Shape Context ( SC )[1], SIFT with Locality-constrained Linear Coding ( siftLLC ) [14] and SIFT with Spatial Pyramid Matching ( siftSPM ) [8] are considered to generate similarity matrix on MPEG-7 shape database. These three features are utilized to construct three similarity graphs. We employ L 2 norm for metric dis-tance d (  X  ,  X  ) in Eq. (1).

The performance of comparison between our method and other state-of-the-art approaches is reported in Table 1 where we can observe that our approach improves the performance over other competitors. We also observe that early fusion performs well in the combination of siftLLC+siftSPM .This is because early fusion non-selectively integrates all the sim-ilarity metrics before the fusion starts, which can get higher accuracy scores in the case of less views. If we fuse the met-rics from more layers, e.g. three feature descriptors, MFRW and WMFRW are superior over other methods due to the fact that our algorithm adopts the technique of graph ran-dom walk, which calculates the long-distance similarity be-tween data points via possible transitions. Table 2: Retrieval accuracy over the N-S database. Figure 2: Retrieved items in N-S database by LBP and SIFT. In each row, the most left one is issued as the query, followed by three retrieved items pro-vided by different methods.

In this experiment, we conduct the evaluation on nor-mal image retrieval over the Nister and Stewenius (N-S) database, which is composed of 2550 image classes, and each contains 4 images. Moreover, we adopt two image descrip-tors: GIST [11] and LBP [10]. Chi-Square distance [13] is deployed for d (  X  ,  X  ) in Eq. (1).

The retrieval accuracies are reported in Table 2, which are measured by the average number of images among the first four image returned. It can be observed that WMFRW performs better than other methods over the N-S database which contains natural but complex scenarios. This is be-cause unlike existing techniques ( e Fusion, l Fusion, and CrDP) that consider the pair-wise neighborhood similarity, the multi-layer fusion of our algorithm, enhanced by the random walks over anchor points, is able to reach long-distance relationship among data points. Thus, the beyond pair-wise similarity is coupled with higher-order association, yielding to more accurate similarity metrics, accordingly. A portion of re-trieved examples are shown in Fig. 2. Another observation from Table 2 is that simply fusing multiple metrics in a linear combination like e Fusion and l Fusion is unable to improve learning performance greatly. This is because they either fail to make use of graph structures (e.g., e Fusion) or over-look the correlations between different layers (e.g., l Fusion). Table 1: Bull X  X  eye scores on the MPEG-7 database. SC denotes the shape contexts; siftLLC and siftSPM refer Thereby, in the following experiments, we mainly focus on the comparisons over view-fusing fashions (e.g., CrDP).
Running time comparison. We also conduct the evalu-ation over running time by comparing with e Fusion, l Fusion, and CrDP, which are shown in Table 3. The data size is ranged from 1k to 10k. It can be observed that our WM-FRW is more efficient than CrDP. As we discussed, WMFRW constructed the similarity graphs using the anchors rather than the whole data set, besides, it fuses the matrix with a small rank.
In this paper, we propose a novel metric fusion strat-egy, named MFRW , for metric learning regarding multi-layer graphs. Instead of considering the pair-wise based large size data similarity matrix, we focus on a high-order data-cluster similarity matrix, which is low-rank with small size, imple-mented by cross-view based graph random walk technique. By fusing high-order data-cluster matrix, it saves compu-tational complexity a lot while achieve the better results than existing related techniques. The experimental results demonstrate that our method outperforms the state-of-the-art methods observed by real-world database in terms of effectiveness and efficiency.
 Acknowledgements. XueminLinissupportedbyARC DP120104168, DP110102937, DE120102144 and NSFC61021004. [1] S. Belongie, J. Malik, and J. Puzicha. Shape matching [2] C.M.BISHOP. Pattern Recognition and Machine [3] B.Boden,S.G  X  l  X znnemann, H. Hoffmann, and T. Seidl. [4] N. Chen, J. Zhu, and E. Xing. Predictive subspace [5] J. He and R. Lawrence. A graphbased framework for [6] Y. Huang, Q. Liu, S.Zhang, and D. N. Metaxas. Image [7] L. J. Latecki and R. Lakamper. Shape similarity [8] S. Lazebnik and C. Schmid. Beyond bags of features: [9] W. Liu, J. He, and S.-F. Chang. Large graph [10] T. Ojala, M. Pietikainen, and T.Maenpaa.
 [11] A. Oliva and A. Torralba. Modeling the shape of the [12] V. Sindhwani and D. Rosenberg. An rkhs for [13] B. Wang, J. Jiang, W. Wang, Z.-H. Zhou, and Z. Tu. [14] J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and [15] M. Wang, X. Hua, R. Hong, J. Tang, G. Qi, and [16] Y. Wang, M. Cheema, X. Lin, and Q. Zhang.
 [17] H. H. F. K. Xiao Cai, Feiping Nie. Heterogeneous [18] D. Zhai, H. Chang, S. Shan, X. Chen, and W. Gao. [19] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and
