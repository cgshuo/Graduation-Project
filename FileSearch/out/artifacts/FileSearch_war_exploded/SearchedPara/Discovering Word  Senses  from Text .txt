 Each enttry shows the clusters to which the headword belongs. 
Nq34, Nq137 .... are automatically generated names for the clusters. The number after each cluster name is the similarity between the cluster and the headword (i.e. suit, plant and heart). 
The lists of words are the top-4 most similar members to the cluster centroid. Each cluster corresponds to a sense of the headword. For example, Nq34 corresponds to the clothing sense of suit and Nq137 corresponds to the litigation sense of suit. In this paper, we present a clustering algorithm, CBC (Clustering 
By Committee), in which the centroid of a cluster is constructed by averaging the feature vectors of a subset of the cluster members. The subset is viewed as a committee that determines which other elements belong to the cluster. By carefully choosing committee members, the features of the centroid tend to be the more typical features of the target class. 
We also propose an automatic evaluation methodology for senses discovered by clustering algorithms. Using the senses in 
WordNet, we measure the precision of a system's discovered senses and the recall of the senses it should discover. 
Clustering algorithms are generally categorized as hierarchical and partitional. In hierarchical agglomerative algorithms, clusters are constructed by iteratively merging the most similar clusters. 
These algorithms differ in how they compute cluster similarity. In single-link clustering, the similarity between two clusters is the similarity between their most similar members while complete-link clustering uses the similarity between their least similar members. Average-link clustering computes this similarity as the average similarity between all pairs of elements across clusters. 
The complexity of these algorithms is (n~logn), where n is the number of elements to be clustered [6]. 
Chameleon is a hierarchical algorithm that employs dynamic modeling to improve clustering quality [7]. When merging two clusters, one might consider the sum of the similarities between pairs of elements across the clusters (e.g. average-link clustering). 
A drawback of this approach is that the existence of a single pair of very similar elements might unduly cause the merger of two clusters. An alternative considers the number of pairs of elements whose similarity exceeds a certain threshold [3]. However, this may cause undesirable mergers when there are a large number of pairs whose similarities barely exceed the threshold. Chameleon clustering combines the two approaches. 
K-means clustering is often used on large data sets since its complexity is linear in n, the number of elements to be clustered. 
K-means is a family of partitional clustering algorithms that iteratively assigns each element to one of K clusters according to the eentroid closest to it and recomputes the centroid of each cluster as the average of the cluster's elements. However, K-means has complexity (Kx xn) and is efficient for many clustering tasks. Because the initial centroids are randomly centroids lead to poor convergence rates or poor cluster quality. CBC consists of three phases. In Phase I, we compute each element's top-k similar elements. In our experiments, we used k = 10. In Phase II, we construct a collection of tight clusters, where the elements of each cluster form a committee. The algorithm tries to form as many committees as possible on the condition that each newly formed committee is not very similar to any existing committee. If the condition is violated, the committee is simply discarded. In the final phase of the algorithm, each element e is assigned to its most similar clusters. Computing the complete similarity matrix between pairs of elements is obviously quadratic. However, one can dramatically reduce the running time by taking advantage of the fact that the feature vector is sparse. By indexing the features, one can retrieve the set of elements that have a given feature. To compute the top similar elements of an element e, we first sort the features according to their pointwise mutual information values and then only consider a subset of the features With highest mutual information. Finally, we compute the pairwise similarity between e and the elements that share a feature from this subset. Since high mutual information features tend not to occur in many elements, we only need to compute a fraction of the possible pairwise combinations. Using this heuristic, similar words that share only low mutual information features will be missed by our algorithm. However, in our experiments, this had no visible impact on cluster quality. The second phase of the clustering algorithm recursively finds tight clusters scattered in the similarity space. In each recursive step, the algorithm finds a set of tight clusters, called committees, and identifies residue elements that are not covered by any committee. We say a committee covers an element if the element's similarity to the centroid of the committee exceeds some high similarity threshold. The algorithm then recursively attempts to find more committees among the residue elements. The output of the algorithm is the union of all committees found in each recursive step. The details of Phase II are presented in Figure 1. In Step 1, the score reflects a preference for bigger and tighter clusters. Step 2 gives preference to higher quality clusters in Step 3, where a cluster is only kept if its similarity to all previously kept clusters is below a fixed threshold. In our experiments, we set 0] = 0.35. Step 4 terminates the recursion if no committee is found in the previous step. The residue elements are identified in Step 5 and if no residues are found, the algorithm terminates; otherwise, we recursively apply the algorithm to the residue elements. Each committee that is discovered in this phase defines one of the final output clusters of the algorithm. in the following way: between e and c are removed from e. This allows CBC to discover the less frequent senses of a word and to avoid discovering duplicate senses. UNICON [13] also constructs cluster centroids using a small set of similar elements, like the committees in CBC. One of the main differences between UNICON and CBC is that UNICON only guarantees that the committees do not have overlapping members. However, the centroids of two committees may still be quite similar. UNICON deals with this problem by merging such clusters. In contrast, Step 2 in Phase II of CBC only outputs a committee if its centroid is not similar to any previously output committee. Another main difference between UNICON and CBC is in Phase III of CBC. UNICON has difficulty discovering senses of a word when this word has a dominating sense. For example, in the newspaper corpus that we used in our experiments, the factory sense of plant is used much more frequently than its life sense. Consequently, the majority of the features of the word plant are 30 most similar words of plant. facility, factory, reactor, refinery, power plant, site, manufacturing plant, tree, building, complex, landfill, dump, project, mill, airport, station, farm, operation, warehouse, company, home, center, lab, store, industry, park, house, business, incinerator All of the above, except the word tree, are related to the factory sense. Even though UNICON generated a cluster ground cover, perennial, shrub, bulb, annual, wildflower, shrubbery, fern, grass, ... the similarity between plant and this cluster is very low. On the other hand, CBC removes the factory related features from the feature vector of plant after it is assigned to the factory cluster. As a result, the similarity between the {ground cover, perennial, _.} cluster and the revised feature vector of plant becomes much higher. To evaluate our system, we compare its output with WordNet, a manually created lexicon. WordNet [15] is an electronic dictionary organized as a graph. Each node, called a synset, represents a set of synonymous words. The arcs between synsets represent hyponym/hypernym (subclass/superclass) relationships =. Figure 2 shows a fragment of WordNet. The number attached to a synset s is the probability that a randomly selected noun refers to an instance of s or any synset below it. These probabilities are not included in WordNet. We use the frequency counts of synsets in the SemCor [9] corpus to estimate them. Since SemCor is a fairly small corpus (200K = WordNet also contains other semantic relationships such as meronyms (part-whole relationships) and antonyms, however we do not use them here. Suppose a clustering algorithm assigns the word w to cluster c. We say that c corresponds to a correct sense ofw if In our experiments, we set k = 4 and varied the 0 values. The WordNet sense ofw that corresponds to c is then: It is possible that multiple clusters will correspond to the same WordNet sense. In this case, we only count one of them as correct. We define the precision of a word w as the percentage of correct clusters to which it is assigned. The precision of a clustering algorithm is the average precision of all the words. The recall (completeness) of a word w measures the ratio between the correct clusters to which w is assigned and the actual number of senses in which w was used in the corpus. Clearly, there is no way to know the complete list of senses of a word in any non-trivial corpus. To address this problem, we pool the results of several clustering algorithms to construct the target senses. For a given word w, we use the union of the correct cluster of w discovered by the algorithms as the target list of senses for w. a relative ranking of the algorithms used to construct the pool of The F-measure [18] combines precision and recall aspects: where is the recall and is the precision. F weights low values of precision and recall more heavily than higher values. It is high when both precision and recall are high. In this section, we describe our experimental setup and present evaluation results of our system. We used Minipar 2 [10], a broad-coverage English parser, to parse about 1GB (144M words) of newspaper text from the TREC collection (1988 AP Newswire, 1989-90 LA Times, and 1991 San Jose Mercury) at a speed of about 500 words/second on a PIII-750 with 512MB memory. We collected the frequency counts of the :Available at www.cs.ualberta.ca/~lindek/minipar.htrn. 
Table 2. Comparison of manual and automatic evaluations of a I random sample of the data set. x 17 + 0 .4: The list of top-4 words describes a sense of the word +: The list of top-4 words describes a sense of the word  X : The list of top-4 words does not describe a sense of the The noun senses of all of these words in WordNet are not similar. 
Therefore, the cluster has a very low 2.6% precision. In hindsight, we should have removed the verb and adjective usage features. 
Secondly, CBC outputs some clusters of proper names. If a word that first occurs as a common noun also has a proper-noun usage it will not be removed from the test data. For the same reasons as the part-of-speech confusion problem, CBC discovers proper name clusters but gets them evaluated as if they were common nouns (since WordNet contains few proper nouns). For example, the following cluster has an average precision of 10%: 
Finally, some concepts discovered by CBC are completely missing from WordNet. For example, the following cluster of government departments has a low precision of 3.3% because 
WordNet does not have a synset that subsumes these words: 
Somewhat surprisingly, all of the low-precision clusters that we inspected are reasonably good. At first sight, we thought the following cluster was bad: 
By looking at the features of the centroid of this cluster, we realized that it is mostly a cluster of company names. 
We presented a clustering algorithm, CBC, that automatically discovers word senses from text. We first find well-scattered tight clusters called committees and use them to construct the centroids of the final clusters. We proceed by assigning words to their most similar clusters. After assigning an element to a cluster, we remove their overlapping features from the element. This allows 
CBC to discover the less frequent senses of a word and to avoid discovering duplicate senses. Each cluster that a word belongs to represents one of its senses. 
We also presented an evaluation methodology for automatically measuring the precision and recall of discovered senses. In our experiments, we showed that CBC outperforms several well known hierarchical, partitional, and hybrid clustering algorithms. 
Our manual evaluation of sample CBC outputs agreed with 88.1% of the decisions made by the automatic evaluation. 
The authors wish to thank the reviewers for their helpful comments. This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP 121338 and scholarship PGSB207797. 
