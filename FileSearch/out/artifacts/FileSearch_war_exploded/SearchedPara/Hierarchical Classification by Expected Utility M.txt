
Hierarchical classification refers to an extension of the standard classification problem, in which labels must be chosen from a class hierarchy. In this paper, we look at hi-erarchical classification from an information retrieval point of view. More specifically, we consider a scenario in which a user searches a document in a topic hierarchy. This sce-nario gives rise to the problem of predicting an optimal entry point, that is, a topic node in which the user starts searching. The usefulness of a corresponding prediction strongly depends on the search behavior of the user, which becomes relevant if the document is not immediately found in the predicted node. Typically, users tend to browse the hi-erarchy in a top-down manner, i.e., they look at a few more specific subcategories but usually refuse exploring com-pletely different branches of the search tree. From a clas-sification point of view, this means that a prediction should be evaluated, not solely on the basis of its correctness, but rather by judging its usefulness against the background of the user behavior. The idea of this paper is to formalize hi-erarchical classification within a decision-theoretic frame-work which allows for modeling this usefulness in terms of a user-specific utility function. The prediction problem thus becomes a problem of expected utility maximization. Apart from its theoretical appeal, we provide first empirical re-sults showing that the approach performs well in practice.
Classifying objects into hierarchical structures is a task that is needed in a growing number of applications, for ex-ample in maintaining ontologies or keyword hierarchies in web-based systems. This includes, e.g., classifying web pages into a web directory or a hierarchy defined by groups of users. As an example of such groups we mention social web communities such as, e.g., the open directory project [8]. Despite the possibility of creating such hierarchies manually and assigning documents by hand, automatic clas-sification and hierarchy extension would be beneficial for many domains as the number of documents to classify has become huge.

Hierarchical structures are used to help locating informa-tion of value to the user. When searching for information in a hierarchy, the user has some idea about the topic this in-formation belongs to. This knowledge is used to browse the hierarchy labels in a top-down manner until a subclass is found which is expected to contain the information. Once the user reaches the most specific class describing his infor-mation need, he starts scanning the documents. If none con-tains the information, he might also browse more general classes. However, it is very unlikely that he would browse other specific classes in branches of the hierarchy that deal with different topics.

What does this search behavior imply for a classifica-tion method? Each object that is classified in a wrong sub-class will most likely not be retrieved by the user. Each object that is classified into a class that is a generalization of the correct class might still be retrieved, depending on how much time the user is willing to spend on his search. Furthermore, a specific class might not yet exist for a docu-ment. Here, classification in one of the most specific classes would prevent the user from retrieving the document as he would not look so deep down the hierarchy. In this case, predicting a more general class is the only way of making retrieval possible.

In our approach, we formalize these assumptions about user behavior in terms of a utility function . Roughly speak-ing, predicting a class that is on the path from the root of the hierarchy to the true class should receive a positive utility since, starting from the former, the user has a good chance to find the latter. As opposed to this, predicting a class that is not on this path should be punished by a low (negative) utility, since it makes finding the true node very unlikely. Assuming information about the true node to be given in terms of probability degrees, we consider the problem of class prediction as a problem of decision making under un-certainty. More specifically, referring to the well-founded decision-theoretic principle of expected utility maximiza-tion, we predict the class with the highest expected util-ity. This decision principle is closely related to and com-pletely in agreement with optimal classification policies in cost-sensitive learning [10].

Our paper is structured as follows. In the next section, we review related work on hierarchical classification and provide a succinct background on decision theory and cost-sensitive learning. Our decision-theoretic approach to hi-erarchical classification is then introduced in Sect. 3 and evaluated empirically in Sect. 4. Conclusions and a discus-sion of future work are given in Sect. 5.
This section provides a brief review of related work on hierarchical classification. Since our approach is developed within a decision-theoretic framework, we also make some remarks on statistical decision theory. Finally, a close con-nection to cost-sensitive learning will be pointed out.
Most of the related work for hierarchical classifica-tion deals with integrating the hierarchy information into the classification process by adapting existing methods or building new classifiers. The authors of [3] try to inte-grate hierarchy information directly into a support vector machine (SVM) classifier by integrating a hierarchical loss function, which is motivated by a document filtering setting. Their motivation is similar to ours. Different SVM classi-fiers for each hierarchy node are learned by the authors of [21] and [9] to find a suitable node in the tree. However, an inner node can only be predicted, when data is assigned to it. We discuss this issue in more detail in Sect. 3.
The authors of [16] applied shrinkage to the estimates of a Bayes classifier to improve the probability estimates. They reported large improvements. As estimating class probabilities is one step of our algorithm, this method could be applied to improve the estimates. In [5], an incremen-tal algorithm with performance close to SVM and also a new loss function for evaluation is presented. The authors propose to learn linear threshold classifiers for each node to decide whether a document should be classified into the node or further down the hierarchy.

In [7], a greedy probabilistic hierarchical classifier is used to determine the most suitable path in the hierarchy from the root to a leaf. In a second step, another classifier is used to determine the best class along this path. The authors also suggest some criteria to create a new category. In [14], the performance of two Boosting algorithms, BoosTexter and CentroidBooster, is compared to the performance of support vector machines.

The influence of different training sets (with and with-out using hierarchy information) is examined in [4] using Na  X   X ve Bayes and centroid learning for different numbers of extracted features. The author of [12] adapts the determined weights for each category for a certain document in a post-processing step by integrating the weights of all other cate-gories according to their proximity (the distance in the cat-egory tree/graph) to this category. However, he makes no differences concerning the relation between two nodes.
In summary, three main approaches to hierarchical clas-sification can be distinguished. Firstly, the original training data can be reinterpreted in a pre-processing step, which is mostly done by assigning it not only to one class but also to parent and/or child classes in the hierarchy. This approach is critical in our context, since we do not assume the class associated with a node to be the union of the classes of the successor nodes (e.g. a document may belong to an inner node but not to any of the more specific topics associated with the successor nodes).

Secondly, the hierarchy could be used directly in the classifier design, which means developing completely new classification methods. Some examples of this approach have been mentioned above.

Our approach belongs to a third category, in which the class hierarchy is exploited in a post-processing step. More specifically, this step consists of reinterpreting basic prob-ability assignments, which typically come from a standard (non-hierarchical) classifier, in terms of a user-specific util-ity function. In other words, the hierarchical structure of the problem is exploited via this utility function. As an advan-tage of this class of methods let us mention that it allows for using well-established standard classifiers in the first step (this advantage is of course shared by the first class of meth-ods).
Statistical decision theory is concerned with decision making under uncertainty and has been developed to a fairly advanced level. Classical contributions in this field have been made by Ramsey [18], de Finetti [11], von Neumann and Morgenstern [17], and Savage [19]. One of the most fa-mous results, which has first been shown by von Neumann and Morgenstern, concerns the characterization of a rational agent in terms of expected utility maximization. Roughly speaking, it is shown that, in a context where uncertainty is represented in terms of a probability measure over a set of potential world states, an agent who obeys some (reason-able) rationality postulates behaves like an expected utility maximizer. More specifically, there is a utility function (on outcomes of action/world state combinations) such that the agent prefers one action over a second one if and only if the expected utility of choosing the former is higher than the expected utility of the latter, where the expectation is taken with respect to the aforementioned probability measure.
It is important to mention that expected utility theory (EUT) not only provides an axiomatic foundation of a par-ticular decision behavior, but also offers a formal frame-work for modeling decision problems in a systematic way. The basic EUT setup (in the finite case) can simply be illus-trated in the form of a table as follows: Here,  X  1 . . .  X  n denote the world states that are not under the control of the decision maker. Each state  X  j is assumed to occur with probability  X  j . The a i define the set of actions the decision maker can choose from. Choosing action a i in world state  X  j yields a utility of u ij . In this simple setting, the expected utility of action a i is hence given by
As a normative theory of rational behavior, statistical decision theory has played an essential role in fields like economics or the social sciences for a long time. Mean-while, however, ideas and concepts from decision theory are also used in other research areas, notably in artificial in-telligence. In fact, a large number of problems has already been formalized and successfully solved within a decision-theoretic framework, including generic ones like search and planning [1] as well as concrete applications such as, e.g., database selection in networked information retrieval [13].
The approach proposed in this paper can also be seen as a special type of cost-sensitive classification, where the cost matrix is determined by the hierarchical structure of the classes. Cost-sensitive classification generalizes the com-mon classification setting by assuming that misclassifica-tion errors may incur different penalties. More specifically, if c j is the true class, then predicting class c i produces a cost of c ij . These misclassification costs are typically sum-marized in the form of a cost matrix: This matrix is obviously a special case of (1), except that utility values are replaced by cost values. Moreover, given probability estimates for the different classes, the recom-mended prediction in cost-sensitive learning is the one with minimum expected cost [10]. Thus, cost-sensitive learning can indeed be seen as a special case of EUT, where actions correspond to predictions and world states to classes.
We nevertheless prefer a decision-theoretic perspective as it is more general and allows for several interesting exten-sions. For example, even the simple EUT setting (1) gives more freedom with respect to defining actions and world states. Regarding the problem of hierarchical classification more generally as one of maintaining a document hierarchy, one might allow, e.g., for an action  X  X reating a new subcate-gory X . We shall come back to this point in the conclusions.
The main idea of our approach is motivated by the re-trieval scenario described in the introduction, in which a user tries to locate information in a hierarchy. To this end, probability estimates of classes are combined with utility values of each class, and the final (classification) decision is guided by the principle of expected utility maximization.
In the following, we first discuss the definition of a suit-able utility function and then turn to the problem of decision making.
From our scenario at hand we derive the notion of the retrieval path , which starts at the correct node and goes up the hierarchy until the root node. I.e. the retrieval path rp associated with a node n contains each node n i from the hierarchy H , which is either the node itself or a parent node thereof (denoted by n i  X  h n ): In Fig. 1, the retrieval path of node 4 is marked in bold as an example. Please note that the child nodes of node 4 (here nodes 6 and 7) do not belong to the retrieval path.
We denote by dist H ( c 1 , c 2 ) the number of edges on the path between c 1 and c 2 in the tree, e.g., dist H (4 , 4) = 0 and dist H (1 , 4) = 2 .

As motivated by our retrieval scenario, nodes, which do not belong to the retrieval path, are of no benefit to the user. Therefore, such nodes should be penalized in terms of a low utility value. For classifications along the retrieval path, the utility of corresponding nodes depends on the distance to the correct class. The highest utility should get of course the correct node, as this class represents the optimal entry point for a document search (most likely, the user will find the requested document quickly). The higher a document is classified along the retrieval path, the more steps the user will need, i.e., the more effort he has to invest to find the document. Therefore, the utility should decrease on the way from the correct node to the root.

The above requirements are fulfilled by a large number of utility functions. Here, we propose the following con-crete measure: This utility function has two parameters: L represents a penalty (loss) term and punishes a deviation from the re-trieval path. This parameter will usually be non-positive and should at least be smaller than the utility of the root node. The parameter  X  models the  X  X aziness X  of the user: The higher  X  , the smaller the utility of a node with a certain distance from the correct class, hence the more important it becomes to predict a node, which is close to the true class. In particular, it is worth considering two extreme parameter configurations:  X  With L = 0 and  X   X   X  , the utility becomes 0 for  X  The other extreme is obtained for  X  = 0 . Now, the
We assume to be given a class hierarchy together with a set of training data in the form of documents with associ-ated classes. As an aside, we note that some classes might well be empty, i.e., there might be no instances of that class among the training data. As will be seen later on, our ap-proach still allows to choose such classes as optimal predic-tion for new query documents.

In a first step, we train a (standard, possibly flat) clas-sifier on the training data. Given a new query document d , we assume this classifier to output posterior probabilities  X   X  = P ( c i | d ) for each potential class c i . In our implementa-tion, we employed two classifiers, namely a standard Na  X   X ve Bayes (NB) classifier and a SVM (based on the libSVM implementation [6]). However, any other classifier could be used instead, as long as it produces a probability distribution over the set of classes.

From a decision making point of view, we thus obtain a special EUT scenario as defined in (1), in which actions correspond to class predictions, the unknown world state corresponds to the true class, and the utility degrees u ij given by util( c i | c j ) as defined in Eq. (4):
Given the above decision scenario, EUT prescribes to predict the class with highest expected utility, where the ex-pected utility of predicting class c i for document d is given by
The complete algorithm, which we call HUClass ( H ierarchical expected U tility based Class ification), is sum-marized in Fig. 2.

Let us again note that the matrix in (5) in principle cor-responds to what is called the cost-matrix in cost-sensitive learning, with the only exception that we consider utility in-stead of cost values. Besides, as already indicated in Sect. 2.3, the above strategy of first estimating class probabilities from the training data set as given, and then making maxi-mal expected utility (minimal expected loss) predictions is HUClass( d , classif ier ,  X  , L ) completely in agreement with the recommended policy in cost-sensitive learning [10].

To understand the basic principle underlying the deci-sion-theoretic approach to hierarchical classification as out-lined above, it is useful to consider the classification itself as a hierarchical process: Starting at the root of the tree, the user has to decide whether he should start exploring the hierarchy at this node or further specialize, that is, immedi-ately proceed to one of the successor nodes. The expected utility of specializing will be high only in relatively unam-biguous situations, i.e., in situations where most of the prob-ability mass is located in one of the subtrees. Otherwise, it might be better to stop at the current node, which will then have a higher expected utility than any successor. Please note that this situation may occur even if the current node itself has a rather low probability, perhaps even 0. As a con-crete example, imagine a 2-level hierarchy with a root node having probability 0 and 3 successor nodes, each of which has a probability of 1 / 3 . The expected utility of the root is then given by exp(  X   X  ) which, depending on  X  , might be bigger than the expected utility of the three leaf nodes ( 1 / 3 ). Roughly speaking, selecting one of the successor nodes is simply too dangerous in this situation, as it is quite likely to make a wrong decision and, hence, to incur a high penalty. A random decision in favor of any of the leaf nodes will ap-pear preferable only for a very lazy user characterized by a high  X  (more concretely,  X  &gt; ln(3) ).
In order to evaluate predictions in our experimental stud-ies in Sect. 4 below, we shall use the utility function (4) with L = 0 and  X  = 1 / 2 : Thus, we assume that this is the  X  X rue X  utility function of the user. Nevertheless, for making predictions, we shall al-low the classifier to use any member of the parameterized class (4) of utility functions. In other words, in the training phase,  X  and L will be used as tuning parameters for the classifier. Of course, using different utility functions (pa-rameters) inside and outside the classifier, one for optimiz-ing performance and the other for evaluation, might appear weird at first sight. One should recognize, however, that the probabilities P ( c i | d ) are only estimations of the true probabilities. Thus, what we compute in (6) is not the true expected utility of a prediction, but only an approximation thereof. More correctly, our classifier is hence an estimated expected utility maximizer.

Having the freedom to tune the parameters L and  X  , the learner possesses a means to react to poor probability es-timates. Roughly speaking, the lower the quality of the estimates, the more conservative the classifier should be-come, for example by decreasing L . To illustrate, consider a situation, in which the flat classifier is extremely mislead-ing: It predicts a probability close to 1 for a randomly se-lected class and distributes the remaining probability mass uniformly over the other classes. Computing the expected utility according to (7), the optimal prediction of the hierar-chical classifier will be the class with probability close to 1. However, as this class is chosen at random by the flat clas-sifier, the true performance of the hierarchical classifier will be very poor. By making L small enough, the hierarchical classifier can achieve that the root node does always have the highest (estimated!) expected utility. The correspond-ing decision strategy of always predicting the root node is extremely cautious but will definitely have a higher (exter-nal) performance.

It is quite interesting to note that the above strategy of op-timizing performance by adapting the utility function used inside the classifier is somewhat comparable to using a util-ity function in order to model the risk-aversion of a decision maker in economic applications. Generally speaking, the utility function in EUT can be seen as a means for control-ling the decision behavior of an agent, and it is exactly used for this purpose in our application.

To find optimal parameters L and  X  , our current imple-mentation follows a rather simple strategy: We optimize these parameters on a training set, doing exhaustive search on a finite two-dimensional grid. Needless to say, this strat-egy is not efficient and shall hence be replaced by more so-phisticated optimization techniques in the future.
We evaluated our algorithm with two datasets. The first is the banksearch dataset [20], consisting of 11000 web pages in a 3 level hierarchy (see Fig. 3). The second is a part of the Open Directory [8], consisting of 8132 web pages in a hierarchy of depth up to 5 (see Fig. 4). The number of child nodes varies from 2 to 17. We crawled the data in April 2006 and selected the categories presented in Fig. 4. Small subcategories were merged into their parent category. Our two datasets have quite different characteristics. The banksearch dataset has a rather shallow hierarchy and its classes can be separated quite well (in a classification sense). It was created by researchers for evaluation pur-poses only. On the other hand, the Open Directory data set is far more difficult. The data was structured by different people without any intention to provide a dataset which is easy to classify (by machine learning methods). In other words, it is truly a  X  X eal world X  dataset, which makes it clearly more interesting from a practical point of view.
All documents were preprocessed. After parsing the doc-uments, we filtered out terms that occurred in less than five documents, in almost all documents ( &gt; | D | X  5 ), stop words, terms with less than four characters, and terms con-taining numbers. After that, we selected out of these the 100 most distinctive features per class as described in [2]. Each document that had an empty feature vector after this preprocessing was ignored.
 We trained different classifiers to compare their results. Each classifier was evaluated five times on five randomly chosen training sets. The mean values and standard devia-tion over these five runs are presented. Each classifier was learned with the same five training sets for better compa-rability of the results. For the banksearch data, we have chosen 300 randomly selected documents from each class to form a training set. For the Open Directory data, we have randomly chosen two third of the data in each class. The classifiers were tested with the remainder of the data.
As baseline of the evaluation of our algorithm, we used two standard flat algorithms, a Na  X   X ve Bayes classifier and a SVM classifier. However, we like to emphasize again that the use of any classifier that provide probability estimates for class assignments is possible. More specifically, it is also possible to use a hierarchical classifier and further en-hance its classification by our method. The SVM imple-mentation was done based on the libSVM [6] tool. We used the linear kernel with its default settings. The Na  X   X ve Bayes implementation computes the (not normalized) prob-abilities P ( c | d ) for a class c given the document d by the following formula: P ( c | d ) = P ( d | c )  X  P ( c ) where w t,d is the boolean term weight of term t from the dictionary dict for document d . The probability of a class P ( c ) is estimated by the percentage of documents from the collection belonging to this class. The probability of a term given the class P ( t | c ) is estimated with the percentage of documents from the class that contain the term.
To compare results between different algorithms, it is necessary to define appropriate performance measures. For standard (flat) classification, evaluation is mostly done by precision and recall [15]. The precision of a class c is the fraction of all documents retrieved for this class that are correctly retrieved (see Eq. 8), while the recall of c is the fraction of all documents belonging to this class that are actually retrieved (see Eq. 9). The combination of the two, the F-Score, is usually used to evaluate overall per-formance and describes the trade-off between precision and recall (see Eq. 10). Furthermore, the accuracy is often de-termined, which gives the percentage of correctly classified documents (see Eq. 11).
These measures treat all classes equally. There is just one correct class and all others are wrong. However, as we al-ready argued, in hierarchical classification, not all  X  X rong X  classifications are equally  X  X ad X . Therefore, as indicated in Sect. 3.3, we reutilize our utility definition to better describe the quality of a prediction. This idea is combined with the -Fitness (124) -Society (0) of documents directly assigned to this category. standard measures presented to get a performance measure that can take the hierarchy information and user preferences into account.

The performance measures given above can be inter-preted as measuring a very simple notion of the utility of a prediction. A correct prediction has the utility of 1, while every other prediction receives a utility of 0. However, this is not appropriate in our setting. Instead, we want to in-tegrate the utility function defined in Eq. (7), as this cor-responds to the user X  X  notion of the utility of a prediction. With it, the standard performance measures can be general-ized to equations (12) -(14). In general, every utility func-tion producing values between 0 and 1 could be used. Nev-ertheless, we use for our evaluation the utility defined by Eq. (7).
Other researchers also proposed hierarchical perfor-mance measures, e.g. in [21]. However, their focus is more on evaluating the classifier performance itself, e.g. by tak-ing category similarities or tree distances into account. Our focus is on the usefulness of the classification from a user X  X  point of view, which is based on user behavior in the de-scribed application scenario.

Besides these performance measures, we further deter-mined some statistics which allow for distinguishing dif-ferent types of misclassification and, hence, to get an idea about the behavior of the different classification methods. The following statistics were determined: (a) # n c  X  number of predictions in the correct node (b) # n c  X  predictions in a node that is a parent node of the (c) ml ( n c )  X  average number of hierarchy levels between (d) # n c  X  predictions of nodes not on the retrieval path, (e) ml ( n c )  X  average number of hierarchy levels between
Tables 1 and 2 summarize our results in terms of the above evaluation measures. Given are the results for the standard classifiers and our expected utility-based ap-proach (HUClass). As can be seen, our approach generally achieves significant improvements for all performance mea-sures on both data sets.

Interestingly, the parameter settings providing the best results are quite different for each combination of classifier and data set. Noticeable, an extremely large penalty term L was used in the combination with Na  X   X ve Bayes. This can be attributed to the quality of the probability estimates of the Na  X   X ve Bayes classifier which is known to be rather poor (including many estimates very close to 0). As already ex-plained above, implementing a cautious strategy by increas-ing the penalty for leaving the retrieval path is reasonable in this situation. And indeed, looking at the misclassification statistics, it can be seen that HUClass(NB) often stops at higher-level nodes. As an aside, note that poor probability estimates do not imply a low classification rate, as the clas-sification remains correct as long as the true class receives the highest probability. In fact, the classification rate of the Na  X   X ve Bayes is not so bad, even though it is significantly lower then the rate of the SVM.

As an example of the effect of the expected utility-based classification, the classification tree of documents from the Sport class of the Banksearch dataset is shown in Fig. 5. As can be seen, most documents that had been classified in too specific classes by the pure Na  X   X ve Bayes approach (87 documents in Soccer and MS ) were correctly moved up the hierarchy by the HUClass(NB) approach and only 15 doc-uments remained in the too specific classes. Furthermore, 8 out of 25 documents classified in nodes not on the re-trieval path had been moved up to the root node. This effect occurs for all classes as can be seen by the # n c values in Tab. 1. Furthermore, accuracy as well as precision and f-measure could be improved. If we assume the search strat-egy of a user as discussed in the introduction, a user would now be able to retrieve on average 713.2 documents more ( # n c ( N B )  X  # n c ( N B + EU ) = 1376 . 4  X  594 . 6 = 713 . 2 ). This is 9 . 4% of the whole data. However, this absolute num-ber only indicates the number of documents that are now on the retrieval path, but neglects the additional effort of a user to find them as considered by our measures defined in equa-tions (12) -(14). The improvement for the SVM classifier is not as significant, but also here all measure show a slight performance improvement.

By comparing the performance on the Open Directory data in Table 2 to the results on the banksearch data, one can find that the improvements gained by the HUClass method are larger for all evaluated settings. This was also expected by us as this dataset is a lot more difficult. In specific, the Figure 5. Classification of the Banksearch Sport Documents with Na  X  X ve Bayes / HU-
Class(NB). statistics show, e.g., that with HUClass(NB) 29 . 1% more of the data can be retrieved, in comparison to the 9 . 4% for the banksearch data. In general, double or more performance gain compared to the banksearch data set can be noted.
In this paper, we presented a user-oriented hierarchi-cal classification approach, which is based on a decision-theoretic framework. More specifically, we make use of a utility function to capture the user X  X  search behavior. This function assigns a utility degree to every node of the class hierarchy that depends on the true classification. Given probability estimates for the different classes, our final pre-diction is then guided by the principle of expected utility maximization. The empirical evaluation in the previous section has shown significant improvements over standard (flat) classification methods.

Since the performance of our approach strongly depends on the quality of the class probabilities estimated in the first step, an important aspect of future work concerns the im-provement of this part of the method.

As mentioned before, our algorithm has a close connec-tion to cost-sensitive classification. Nevertheless, we prefer viewing information retrieval as a decision making process, since decision theory provides a more general framework that allows for several interesting extensions. We conclude the paper by outlining some examples of such extensions.
First, instead of using a fixed utility function (as we have done in the experimental part), one might think of  X  X er-sonalizing X  this function by adapting the parameters to a specific user. For example, the  X  X aziness X  of a user, as ex-pressed by the parameter  X  , could be derived from his in-teraction with the hierarchy. Does the user only look at the entry node or also explore higher level nodes? If so, how many? Our method could then maximize the performance based on the specific  X  value learned for the user, allowing for adaptivity in the classification process. This possibility shall be explored in future work.
 over 5 runs) tion over 5 runs)
As the utility function is a modular component of our approach, it can easily be replaced by other types of func-tions capturing other types of user behavior. In future work, we plan to identify corresponding user strategies and extract suitable utility functions.

A more far reaching extension concerns modelling the retrieval of a document as a sequential decision process, that is, a process, in which several decisions have to be made in succession: From a user perspective, the first decision con-cerns the entry node in the hierarchy and essentially corre-sponds to what we studied in the current paper. What we did not consider, however, is the continuation of the search process: At every node, the user must decide whether or not to continue the search, and if so, in which direction. These decisions are made on the basis of the respective search his-tory, i.e., the nodes that have been visited so far, and hence are not independent of each other. In particular, for making the ( i + 1) -st decision, the user has more information than for the i -th decision.

