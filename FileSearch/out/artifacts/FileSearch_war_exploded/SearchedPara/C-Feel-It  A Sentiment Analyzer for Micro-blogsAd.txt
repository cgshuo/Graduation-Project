
Figure 2: Tweet Sentiment Predictor: Version 1 and 2 Figure 3: Lexicon-based Sentiment Predictor: C-Feel-It Version 1 Figure 4: Lexicon-based Sentiment Predictor: C-Feel-It Version 2 posscore [ r ] = negscore [ r ] = objscore [ r ] = posscore [ r ] = Positive score for search string r negscore [ r ] = Negative score for search string r objscore [ r ] = Objective score for search string r w pi , w ni , o oi = Weights for respective classes derived We normalize these scores to get the final positive, neg-ative and objective pertaining to search string r . These scores are represented in form of percentage. Sentiment-based lexical resources annotate words/concepts with polarity. The completeness of these resources individually remains a question. To achieve greater coverage, we use four different sentiment-based lexical resources for C-Feel-It. They are described as follows. 1. SentiWordNet (Esuli and Sebastiani, 2006) assigns 2. Subjectivity lexicon (Wiebe et al., 2004) is a re-3. Inquirer (Stone et al., 1966) is a list of words 4. Taboada (Taboada and Grieve, 2004) is a word-list The system is implemented in JSP (JDK 1.6) using Net-Beans IDE 6.9.1. For the purpose of tweet annotation, an internal interface was written in PHP 5 with MySQL 5.0.51a-3ubuntu5.7 for storage. For the purpose of evaluation, a total of 7000 tweets were downloaded by using popular trending topics of 20 domains (like books, movies, electronic gadget, etc.) as keywords for searching tweets. In order to download the tweets, we used the API provided by Twitter 4 that crawls latest tweets pertaining to keywords.

Human annotators assigned to a tweet one out of 4 classes: positive, negative, objective and objective-spam. A tweet is assigned to objective-spam category if it con-tains promotional links or incoherent text which was pos-sibly not created by a human user. Apart from these nom-inal class labels, we also assigned the positive/negative tweets scores ranging from +2 to -2 with +2 being the most positive and -2 being the most negative score re-spectively. If the tweet belongs to the objective category, a value of zero is assigned as the score.

The spam category has been included in the annotation as a future goal of modeling a spam detection layer prior to the sentiment detection. However, the current version of C-Feel-It does not have a spam detection module and hence for evaluation purpose, we use only the data be-longing to classes other than objective-spam. In this section, we perform a qualitative evaluation of ac-tual results returned by C-Feel-It. The errors described in this section are in addition to the errors due to mis-spellings and informal language. These erroneous results have been obtained from both version 1 and 2. They have been classified into eleven categories and explained henceforth.
Tweet : Hoge, Jaws, and Palantonio are brilliant to-gether talking X X  X  and O X  X  on ESPN right now.
 Label by C-Feel-It : Positive Label by human annotator : Negative
The sarcasm in the above tweet lies in the use of a pos-itive word  X  brilliant  X  followed by a rather trivial action of  X  talking Xs and Os  X . The positive word leads to the pre-diction by C-Feel-It where in fact, it is a negative tweet for the human annotator.
Tweet : If your tooth hurts drink some pain killers and place a warm/hot tea bag like chamomile on your tooth and hold it. it will relieve the pain Label by C-Feel-It : Negative
This tweet is objective in nature. The words  X  X ain X ,  X  X illers X , etc. in the tweet give an indication to C-Feel-It that the tweet is negative. This misguided implication is because of multiple senses of these words (for example,  X  pain  X  can also be used in the sentence  X  symptoms of the disease are body pain and irritation in the throat  X  where it is non-sentiment-bearing). The lack of understanding of word senses and being unable to distinguish between them leads to this error.
Tweet : Casablanca and a lunch comprising of rice and fish: a good sunday Keyword : Casablanca Label by C-Feel-It : Positive Label by human annotator : Objective
In the above tweet, the human annotator understood that though the tweet contains the keyword  X  Casablanca  X , it is not Casablanca about which sentiment is expressed. The system finds a positive word  X  good  X  and marks the tweet as positive. This error arises because the system cannot find out which sentence/parts of sentence is ex-pressing opinion about the target entity.
Tweet : I X  X  done with this bullshit. You X  X e the psycho not me.
 Label by SentiWordNet : Negative Label by Taboada/Inquirer : Objective Label by human annotator : Negative
On manual verification, it was observed that an entry for the emotion-bearing word  X  bullshit  X  is present in Sen-tiWordNet while Inquirer and Taboada resource do not have them. This shows that the coverage of the lexical resource affects the performance of a system and may in-troduce errors.
Tweet : @user I don X  X  think I need to guess, but ok, close encounters of the third kind? Lol Entity : Close encounters of the third kind Label by C-Feel-It : Positive
The words comprising the name of the film  X  Close en-counters of the third kind  X  are also looked up. Inability to identify the named entity leads the system into this trap.
Tweet : The soccer world cup boasts an audience twice that of the Summer Olympics.
 Label by C-Feel-It : Negative
To judge the opinion of this tweet, one requires an un-derstanding of the fact that larger the audience, more fa-vorable it is for a sports tournament. This world knowl-edge is important for a system that aims to handle tweets like these.
Tweet : oh but that last kiss tells me it X  X  goodbye, just like nothing happened last night. but if i had one chance, i X  X  do it all over again Label by C-Feel-It : Positive
The tweet contains emotions of positive as well as neg-ative variety and it would in fact be difficult for a human as well to identify the polarity. The mixed nature of the tweet leads to this error by the system.
Tweet : I X  X l have to say it X  X  a tie between Little Women or To kill a Mockingbird Label by C-Feel-It : Negative Label by human user : Positive
The tweet has a sentiment which will possibly be clear in the context of the conversation. Going by the tweet alone, while one understands that an comparative opinion is being expressed, it is not possible to tag it as positive or negative. Tweet : To Kill a Mockingbird is a #goodbook.
 Label by C-Feel-It : Negative
The tweet has a hashtag containing concatenated words  X  goodbook  X  which get overlooked as out-of-dictionary words and hence, are not used for sentiment prediction. The sentiment of  X  good  X  is not detected. Tweet : Oooh. Apocalypse Now is on bluray now.
 Label by C-Feel-It : Objective Label by human user : Positive
The extended interjection  X  Oooh  X  is an indicator of sentiment. Since it does not have a direct prior polar-ity, it is not present in any of the resources. However, this interjection is an important carrier of sentiment.
Tweet : The more years I spend at Colbert Heights..the more disgusted I get by the people there. I X  X  soooo ready to graduate.
 Label by C-Feel-It : Positive Label by human user : Negative
The comparatives in the sentence expressed by  X  ..more disgusted I get..  X  have to be handled as a special case because  X  more  X  is an intensification of the negative senti-ment expressed by the word  X  disgusted  X . In this paper, we described a system which categorizes live tweets related to a keyword as positive, negative and objective based on the predictions of four sentiment-based resources. We also presented a qualitative evalua-tion of our system pointing out the areas of improvement for the current system.
 A sentiment analyzer of this kind can be tuned to take in-puts from different sources on the internet (for example, wall posts on facebook). In order to improve the qual-ity of sentiment prediction, we propose two additions. Firstly, while we use simple heuristics to handle exten-sions of words in tweets, a deeper study is required to decipher the pragmatics involved. Secondly, a spam de-tection module that eliminates promotional tweets before performing sentiment detection may be added to the cur-rent system. Our goal with respect to this system is to de-ploy it for predicting share market values of firms based on sentiment on social networks with respect to related entitites.
 We thank Akshat Malu and Subhabrata Mukherjee, IIT Bombay for their assistance during generation of evalua-tion data.
 Go Alec, Huang Lei, and Bhayani Richa. 2009a. Twit-ter sentiment classification using distant supervision. Technical report, Standford University.
 Go Alec, Bhayani Richa, Raghunathan Karthik, and Huang Lei. 2009b. May.
 Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWord-
Net: A publicly available lexical resource for opinion mining. In Proceedings of LREC-06 , Genova, Italy. Andreas M. Kaplan and Michael Haenlein. 2010. The early bird catches the news: Nine things you should know about micro-blogging. Business Horizons , 54(2):05  X  113.
 Julie B. Lovins. 1968. Development of a Stemming Al-gorithm. June.
 Bo Pang and Lillian Lee. 2004. A sentimental edu-cation: sentiment analysis using subjectivity summa-rization based on minimum cuts. In Proceedings of the 42nd Annual Meeting on Association for Compu-tational Linguistics , ACL  X 04, Stroudsburg, PA, USA. Association for Computational Linguistics.
 Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of ACL-05 . Vladimir Prelovac. 2010. Top social media sites. Web, May.
 Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith, and Daniel M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis . MIT Press.
 Maite Taboada and Jack Grieve. 2004. Analyzing Ap-praisal Automatically. In Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in
Text: Theories and Applications , pages 158 X 161, Stan-ford, US. 2000. Enriching the knowledge sources used in a maxi-mum entropy part-of-speech tagger , Stroudsburg, PA, USA. Association for Computational Linguistics.
 Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew
Bell, and Melanie Martin. 2004. Learning subjec-tive language. Computional Linguistics , 30:277 X 308,
September.
