 Many data mining algorithms, for example, k -means clustering algorithm and k -nearest neighbor classifier, work by relying on a distance metric. In order to deliver satisfactory results, finding a good distance metric for the problem at hand often plays a very crucial role. As such, metric learning [Xing et al. 2002] has received much attention in the research community [Chang and Yeung 2004; Chen et al. 2007; Davis and Dhillon 2008; Davis et al. 2007; Hastie and Tibshirani 1996; Hoi et al. 2008, 2010; Jin et al. 2009; Weinberger et al. 2005; Xing et al. 2002; Yeung and Chang 2007; Yeung et al. 2008; Zhan et al. 2009]. Many metric-learning methods have been proposed. From the perspective of the underlying learning paradigm, these methods can be grouped into three categories, namely, supervised metric learning, unsupervised metric learning, and semi-supervised metric learning. Supervised metric learning learns a metric for some supervised learning tasks, such as classification, so that data points from the same class are kept close while those from different classes are far apart [Davis and Dhillon 2008; Davis et al. 2007; Hastie and Tibshirani 1996; Jin et al. 2009; Weinberger et al. 2005; Zhan et al. 2009]. It has also been used for regression by exploiting the manifold structure contained in the labeled data [Xiao et al. 2009]. Unsupervised metric learning utilizes some information contained in the data to learn a metric for some unsupervised learning task, such as clustering [Chen et al. 2007]. Semi-supervised metric learning, which can be viewed as a combination of the supervised and unsupervised paradigms, utilizes both label information from the labeled data and geometric information from the unlabeled data to learn a good metric for classification or clustering. The need for semi-supervised metric learning arises from the fact that the labeled data available in a number of real-life applications is scarce, because labeling data is very laborious and costly. With only limited labeled data, the metrics learned are often unsatisfactory. Semi-supervised metric learning tries to exploit additional information from the unlabeled data to alleviate this problem, which is known here as the labeled data deficiency problem.

In this article, we consider situations similar to those for semi-supervised metric learning in which there is deficiency in labeled data. While the amount of labeled data available in one learning task is limited, it is not uncommon that there exist other related learning tasks with labeled data available. Unlike semi-supervised learn-ing [Chapelle et al. 2006] which exploits unlabeled data, multitask learning [Caruana 1997; Hastie and Tibshirani 1996; Thrun 1996] and transfer learning [Pan and Yang 2010] seek to alleviate the labeled data deficiency problem by utilizing some related learning tasks to help improve the learning performance. In some sense, they mimic human learning activities in that people may learn faster when several related tasks are learned simultaneously, for example, playing different games. In essence, people often apply the knowledge gained from some previous learning tasks to help learn a new task. Even though both multitask learning and transfer learning utilize informa-tion from other related learning tasks, there exist some differences between them in both the problem setting and the objective. In transfer learning, the learning tasks are usually classified into two types: source task and target task. It is assumed that there is enough data in the source tasks but not in the target task. The objective of transfer learning is to utilize the information in the source tasks to help learn the target task with no need for improving the performance of the source tasks. On the other hand, there is no distinction between the tasks in multitask learning, and the objective is to improve the performance of all tasks simultaneously.

Even though there exist differences between multitask learning and transfer learn-ing, a central issue common to both is to accurately characterize the relationships between tasks. Given the training data for multiple tasks, there are two important aspects that distinguish between different methods for characterizing the task rela-tionships. The first aspect is on how to obtain the relationships, either from the model assumption or automatically learned from data. Many multitask and transfer-learning methods make some prior assumptions. For example, the latent data representation is shared by different tasks [Argyriou et al. 2008; Caruana 1997] or the learning models in different tasks have similar model parameters [Evgeniou and Pontil 2004; Kienzle and Chellapilla 2006]. Obviously, learning the task relationships from data automat-ically is the more favorable option, because the model assumption adopted may be incorrect and, worse still, it is not easy to verify the correctness of the assumption from data. The second aspect is on what task relationships can be represented by a method. Generally speaking, there are three types of task relationships: positive task correlation, negative task correlation, and task unrelatedness. 1 Positive task cor-relation is a useful task relationship to characterize because similar tasks are likely to have similar model parameters. For negative task correlation, knowing the model parameters of one task will reduce the search space for the model parameters of a negatively correlated task. As for task unrelatedness, identifying outlier tasks can prevent them from impairing the performance of other tasks since outlier tasks are unrelated to other tasks.

In this article, we study metric learning under the transfer-learning setting in which some source tasks are available in addition to the target task. Based on a method called regularized distance metric learning (RDML) [Jin et al. 2009], we propose an extension for transfer learning called transfer metric learning (TML). Different from conventional transfer-learning methods, we first propose a convex formulation for mul-titask metric learning by modeling the task relationships in the form of a task covari-ance matrix which can model positive, negative, and zero task correlations. Then we regard transfer learning as a special case of multitask learning in that the source tasks are equally important and independent and adapt the formulation of multitask met-ric learning to the transfer-learning setting for the formulation of TML. In TML, we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation. As in multitask metric learning, the task covari-ance matrix can also model positive, negative, and zero task correlations. To solve the convex optimization problem, we use an alternating method in which each subprob-lem has an efficient solution. Moreover, in many applications, some unlabeled data is also available in the target task, and so we propose a semi-supervised extension of TML called STML to further improve the genera lization performance by exploiting the unlabeled data based on the manifold assumption [Belkin et al. 2006]. Experimental results on some commonly used transfer learning applications demonstrate the effec-tiveness of our method.

The remainder of this article is organized as follows. We first briefly introduce some background for metric learning and the rel ated work in Section 2. We then present our multitask metric learning and TML algorithms in Sections 3 and 4, respectively. Section 5 proposes a semi-supervised extension of TML and Section 6 reports exper-imental results on some transfer-learning applications. Finally, some concluding re-marks are given in the last section. 2 and its class label y i  X  X  1 ,..., C } . In RDML [Jin et al. 2009], the learning problem is formulated as where  X  is the regularization parameter which balances the empirical loss and the regularization term;  X  F denotes the Frobenius norm of a matrix; y j , k is equal to 1when y j and y k are identical and  X  1otherwise; 0 means that is a positive which is similar to the hinge loss used in the support vector machine (SVM). Here b is a constant satisfying 0  X  b  X  1, which denotes the classification margin. In Jin et al. [2009], b is set to 0.

In Jin et al. [2009], an online method is used to learn the optimal ,andsomeprop-erties of RDML (such as the generalization error) are studied. Moreover, theoretical analysis shows that RDML is robust against the number of feature dimensions.
To the best of our knowledge, Zha et al. [2009] is the only previous work on transfer metric learning. Zha et al. assume that there exist labeled data points for the target task, as well as some prior information from the source tasks in the form of a metric matrix learned from each source task. The authors extended information-theoretic metric learning (ITML) Davis et al. [2007] to tr ansfer metric learning by treating the metric matrices learned from the source tasks as prior information to regularize the learning of the target task. The optimization problem for transfer metric learning in Zha et al. [2009], which is called L-DML, is formulated as where tr(  X  ) denotes the trace of a square matrix, and  X  2 denotes the two-norm of a vector. Here S = y 1 ,..., K ) is the available metric matrix for the k th source task. The first and second terms in the objective function of Problem (2) are derived from the log-determinant the utility of the metric of the k th source task. The third term is to keep the data points in the same class as close as possible, and the fourth term is to keep the data points from different classes far apart. The last term is to penalize the complexity of  X  .Here  X  plays an important role in this formulation, since there may exist outlier tasks in real applications and by learning  X  , L-DML can identity them. However, each element of the vector  X  is nonnegative, and so it cannot model the negative transfer situation [Rosenstein et al. 2005]. Moreover, the constraint K k =1  X  k =1isnotvery reasonable. Consider a special case in wh ich there is only one source task. Then  X  1 = 1, even if this source task is an outlier task. When there are multiple source tasks and all of them are outlier tasks, we should set all  X  i to zero, but then the constraint easy to get trapped in (bad) local minima during the optimization procedure.
There exist some methods for transfer dimensionality reduction [Pan et al. 2008, 2009; Wang et al. 2008], where dimensionality reduction can be viewed as a special case of metric learning in that the metric learned is not of full rank. However, transfer dimensionality reduction is different from transfer metric learning, and these methods are not applicable here. For example, Wang et al. [2008] used a transformation matrix of the dimensionality reduction in the source tasks for subspace clustering in the target task, and so the target task is an unsupervised learning task. Also, Pan et al. [2008, 2009] proposed dimensionality reduction methods for domain adaption in which the target task has no labeled data, and so it is different from the setting here where we utilize the metric matrices learned from the source tasks to help the learning of the target task from labeled data. In this section, we propose a multitask metric-learning method that can learn the task relationships between all pairs of tasks.
 index, and the subscript denotes the instance index in each task.

The optimization problem for multitask metric learning is formulated as follows: 3 which converts a matrix into a vector in a columnwise manner; and  X  1 and  X  2 are the regularization parameters. is a task covariance matrix which describes the relation-ships between tasks, so it is a PSD matrix. The first term in the objective function of Problem (3) measures the empirical loss for the training sets of the m tasks; the second term penalizes the complexity of each i ; and the last term measures the task relationships between all pairs of tasks based on each i . The last constraint in (3) is to restrict the scale of to prevent it from reaching a degenerate solution.
From a probabilistic viewpoint, RDML can be seen as obtaining the maximum a posteriori (MAP) solution of a probabilistic model where the likelihood corresponds to the first term in the objective function of Problem (1) and the prior on the metric is a Gaussian prior corresponding to the second term. Similar to RDML, our multitask metric learning is also a MAP solution of a probabilistic model where the likelihood is the same as that in RDML for each task, and the prior on the metrics of all tasks is a matrix-variate normal distribution [Gupta and Nagar 2000].

We will prove next that Problem (3) is a convex optimization problem by proving that each term in the objective function is convex, and that constraint is also convex. T HEOREM 3.1. Problem (3) is convex with respect to { i } and .

P ROOF . It is easy to see that the first two terms in the objective function are convex with respect to all variables and that the constraints in (3) are also convex. We have proven in our previous work [Zhang and Yeung 2010a] that the third term in the ob-jective function is convex with respect to a ll variables, but we repeat it here to make this paper self-contained. We rewrite the third term as tion as in Example 3.4 on page 76 of Boyd and Vandenberghe [2004], it is convex with respect to  X  ( t , :) and when is a PSD matrix (which is satisfied by the convex with respect to { i } and . Because the summation operation can preserve convexity according to the analysis on page 79 of Boyd and Vandenberghe [2004], function and the constraints in Problem (3 ) are convex with respect to all variables, and hence Problem (3) is jointly convex.

Even though Problem (3) is convex with respect to { i } and jointly, it is not easy to optimize it with respect to all the variables simultaneously. Here we propose an alter-native method to solve the problem more efficiently. Specifically, we first optimize the are fixed, and then optimize it with respect to when { i } are fixed. This procedure is repeated until convergence. Since the original optimization problem is convex, the solution found by this alternating procedure is guaranteed to be the globally optimal solution [Bertsekas 1999].

Because multitask metric learning is not the focus of this article, we leave the de-tailed optimization procedure to Appendix A. Based on the multitask metric-learning problem formulated in the previous section, we propose a transfer metric-learning formulation as a special case which can learn the task relationships between all source tasks and the target task.
 transfer learning, it is assumed that each source task has enough labeled data and can learn an accurate model with no need to seek help from the other source tasks. So the source tasks are considered to be independent since each source task does not need help from other source tasks. So, similar to the setting in Zha et al. [2009], we assume that the metric matrix i for the i th source task has been learned independently. We hope to use the metric matrices learned to help the learning of the target task, because the labeled data there is scarce. Based on Problem (3), we formulate the optimization problem for TML as follows. Since we assume that the source tasks are independent of each other and that each source task is of equal importance, we can express as where I a denotes the a  X  a identity matrix,  X  m denotes the task covariances between the target task and the source tasks (implying that the target task and the source tasks are not independent), and  X  denotes the variance of th e target task. According to the last constraint in Problem (4), we can get From Theorem 1, it is easy to show that Problem (4) is also jointly convex with respect to all variables. Moreover, from the block matrix inversion formula, we can get
Let  X  s =(vec( 1 ) ,..., vec( m  X  1 )), which is a constant matrix here, denote the pa-rameter matrix of the source tasks. Then we can get tr(  X   X  1  X  T ) =tr  X  s , vec( m )  X  1 =tr = =
Moreover, according to the Schur complement [Boyd and Vandenberghe 2004], we have which is equivalent to Then Problem (4) can be simplified to where the last term in the objective function can be simplified, as in Eq. (5).
Compared with the L-DML method in Zha et al. [2009], our method has some advan-tages. First, the formulation of TML is convex, so there is a guarantee of finding the globally optimal solution. Second, similar to the multitask metric learning proposed in the previous section, TML can model positive, negative, and zero task correlations in a unified formulation, but L-DML cannot model negative task correlation. As an ex-treme case, we can deal with the situation in which all source tasks are outlier tasks, butL-DMLcannothandleitduetotheconstraint K k =1  X  k = 1 in Problem (2).

Moreover, compared with Problem (4), there is no PSD constraint on in Problem (6), making it simpler than Problem (4). In the next section, we will discuss how to solve Problem (6). As in multitask metric learning, Problem (6) is a convex problem, and we still use an alternating method to solve it. Specifically, we first optimize the objective function with respect to m when  X  m and  X  are fixed, and then optimize it with respect to  X  m and  X  when m is fixed. This procedure is repeated until convergence. As before, the solution found by this alternating procedure is globally optimal [Bertsekas 1999]. In what follows, we will present the two subproblems separately.

Optimizing with respect to m when  X  m and  X  are fixed. Utilizing Eq. (5), the optimization problem with respect to m is formulated as where M is a matrix such that vec( M )=  X  s  X  m . It is easy to show that M is a combination of ( i =1 ,..., m  X  1), as M = m  X  1 i =1  X  mi i where  X  mi is the i th element of  X  m . Similar to Jin et al. [2009], we can use an online learning method to solve Problem (7), and the algorithm is depicted in Table I. This algorithm is similar to tial value for (0) m is a zero matrix, but here it is  X  2  X  the metrics learned from the source tasks w here each combination weight is the task covariance between a source task and the target task. This agrees with our intuition that a positively correlated source task will have a large weight on the initial value for m , an outlier task has negligle contribution, and a negatively correlated task even has the opposite effect.

Optimizing with respect to  X  m and  X  when m is fixed. Utilizing Eq. (5), the optimization problem with respect to  X  m and  X  is formulated as Using the Schur complement, we can get By using the Schur complement again, we get We write  X  T  X  = 11 12 T Then  X  t  X  T  X  0 is equivalent to Let U and  X  1 ,..., X  m  X  1 denote the eigenvector matrix and eigenvalues of 11 with  X  and Combining the previous results, Problem (8) is formulated as Problem (9) is reformulated as Since and
Problem (10) is a second-order cone programming (SOCP) Problem [Lobo et al. 1998] with O ( m ) variables and O ( m ) constraints. In many applications, m is very small, and we can use a standard solver to solve Problem (10) very efficiently.

We set the initial value of  X  to 1 m and that of  X  m to a zero vector which corresponds to the assumption that the target task is unrelated to the source tasks.

After learning the optimal values of m , we can make a prediction for a new data between x m and all training data points in T m based on the learned metric m and then in our experiments. Setting the regularization parameters  X  1 and  X  2 to suitable values plays a crucial role in our method in order to deliver good performance. In the transfer-learning setting, however, the labeled data available in the target task is so scarce that model-selection techniques, such as cross-validation, cannot be used to determine the values of  X  1 and  X  2 . On the other hand, Bayesian regularization [Cawley et al. 2006; Foo et al. 2009; Williams 1995] is usually very effective under this setting by integrating out the regularization parameters. We next propose a Bayesian regularization scheme for our model.

Based on the probabilistic interpretation in Section 3, Problem (4) defines a proba-bilistic model. where X m =( x m 1 ,..., x m n ( y in Eq. (12). Similar to Foo et al. [2009], we impose Gamma priors on  X  1 and  X  2 . where G (  X ,  X  ) denotes the Gamma distribution with probabilistic density function with (  X  ) denoting the Gamma function. In general, the parameters of the Gamma priors for  X  1 and  X  2 can be assigned different values. Here, for simplicity, we use the same parameter values for both  X  1 and  X  2 as Foo et al. [2009] did. By integrating out  X  1 and and so The maximum a posterior (MAP) solution can be obtained by solving the following optimization problem.
Since Problem (13) is non-convex due to the non-convexity of the logarithm func-tion, we use a majorization-minimization (MM) algorithm [Lange et al. 2000] to solve it. An MM algorithm, which can be viewed as a generalization of the expectation-maximization (EM) algorithm [Dempster et al. 1977], is an iterative algorithm which derives an upper bound of the objective function as a surrogate function in each iter-ation based on the solution obtained in the previous iteration and then minimizes the surrogate function instead of the original objective function. The solution found by an MM algorithm can be proved to be the locally optimal solution. Since the logarithm b due to the first-order property of a concave function. In the ( k + 1)th iteration of an MM algorithm, we have and ln  X  + ( k + 1)th iteration, the optimization problem can be formulated as where Problem (14) is almost identical to Problem (4) with the exception of the regulariza-tion parameters. In Problem (4), the regularization parameters  X  1 and  X  2 are set by the user, but the regularization parameters  X   X  1 and  X   X  2 are automatically determined by the solution obtained in the previous iteration. Since Problems (14) and (4) have the same formulation, we can still use the optimization procedure developed in the previous sections with the only modification in the values of the regularization pa-rameters. Thus, this model selection technique can be incorporated into the learning procedure easily. Moreover, the experiments in Foo et al. [2009] show that the system performance is not sensitive to the values of  X  and  X  , and hence, their values are easy to set. In many applications, even though the labeled data available in the target task is scarce due to the costly labeling effort required, large quantities of unlabeled data are available at very low cost. Semi-supervised learning [Chapelle et al. 2006] is an increasingly popular learning paradigm that seeks to exploit the unlabeled data, es-pecially under situations in which the labeled data is scarce. When some conditions about the data are satisfied, it has been demonstrated by many researchers that the generalization performance of learning systems can be improved by learning under the semi-supervised setting. In this section, we investigate a semi-supervised exten-sion of transfer metric learning that explicitly exploits unlabeled data in the target task.

The manifold assumption [Belkin et al. 2006] is widely adopted by many semi-supervised learning algorithms. Under this assumption, nearby points are more likely to have the same class label for classification problems and similar low-dimensional representation for dimensionality reduction problems. Similarly, for metric learning, we want nearby points to remain near to each other in the new space after learning the metric. This is the central idea on which our semi-supervised extension of transfer metric learning is based.
 neighbor graph G =( V , E ) in a way called local scaling [Zelnik-Manor and Perona 2004], with the vertex set V = { 1 ,..., n m } corresponding to the labeled and unlabeled data points and the edge set E  X  V  X  V representing the relationships between data points. Each edge is assigned a weight w ij which reflects the similarity between points x i and x where  X  2 denotes the two-norm of a vector, N K ( x m i ) denotes the neighborhood set nearest neighbor.

Then we define a new regularization term based on the manifold assumption as follows. D  X  W is the Laplacian matrix [Chung 1997] of W ,and X matrix for the target task T m .
 Adding the new regularization term in Eq. (15) into the objective function of Problem (6), we get the optimization problem for semi-supervised transfer metric learning as follows. where  X  3 is the regularization parameter for the newly added regularization term. Since the new regularization term is linear with respect to m , Problem (16) is still a convex optimization problem, and hence we still use an alternating method to solve it.

When  X  m and  X  are fixed, the optimization problem with respect to m is formu-lated as
Similar to Problem (7), we still use the online algorithm in Table I with the only modification being that the initial value for m is set to 1  X  is fixed, the optimization problem with respect to  X  m and  X  is identical to Problem (10) which is an SOCP problem. These two steps iterate until convergence to the optimal solution. Similar to Section 4.3, we use Bayesian regularization to address the model selection problem for the regularization parameters  X  1 ,  X  2 ,and,  X  3 . The likelihood is also de-fined, as in Eq. (11), and the change lies in the prior on m . Similar to the supervised version, we impose Gamma priors on  X  1 ,  X  2 ,and  X  3 . Then, by integrating out all the regularization parameters, we get an irrelevant term with respect to m . The detailed derivation for Eq. (19) is presented in Appendix B. The MAP solution can be obtained by solving the following problem. We also use an MM algorithm to solve Problem (21). In the ( k + 1)th iteration, the optimization Problem is identical to Problem (16), with the only difference lying in the definition of the regularization parameters. We study TML and STML empirically in this section.
 We compare TML with two metric-learning methods, ITML 4 [Davis et al. 2007] and RDML [Jin et al. 2009] and another metric-learning method for transfer learning, L-DML [Zha et al. 2009]. We use the CVX solver [Grant and Boyd 2009] 5 to solve Problem (10). We set the learning rate  X  in Table I to 0.01. For ITML, RDML and L-DML, the best parameters reported in Davis et al. [2007], Jin et al. [2009], and Zha et al. [2009] are used. For classification, we use a 1-Nearest-Neighbor classi-fier. The distance metric matrices of the source tasks are learned using the RDML method. 6.1.1. Wine Quality Classification. Thewinedataset 6 is about wine quality, including red and white wine samples. The features include objective tests (e.g., PH values), and the output is based on sensory data. The labels are given by experts with grades between 0 (very bad) and 10 (very excellent). There are 1,599 records for red wine and 4,898 for white wine, and so there are two tasks X  X ne for red wine classification and the other for white wine classification. So the two tasks are both multiclass classification problems. Since both RDML and our proposed method in Table I formulate the multi-class classification problem as a binary classification problem by assigning a point pair a positive label if these two data points are from the same class and a negative label otherwise, there is no difference to process the task with a multiclass classification problem or binary classification problem for our method. Each task is treated as the target task and the other task as the source task. To see the effect of varying the size of the training set, we vary the percentage of the training data used from 5% to 20%. Each configuration is repeated ten times. The mean and standard deviation of the classification accuracy are reported in Figures 1(a) and 1(b). From the results, we can see that the performance of L-DML is comparable to that of ITML and RDML, and TML is always the best one for both tasks.

Moreover, to demonstrate the ability of our method to detect outlier tasks, we add a synthetic task as a source task. The synthetic task is an XOR classification task and its two-dimensional representation obtained by principal component analysis (PCA) is illustrated in Figure 2. We use our method to perform transfer metric learning with the settings similar to those previously defined. The mean task correlation matrix derived from the task covariance matrix is when the red wine classification task is treated as the target task. When the white wine classification task is treated as the target task, the mean task correlation matrix is
From the results, we can see that the correlation between the target and synthetic of task relationships learned to detect outlier tasks. Moreover, the correlation between the white and red wine tasks is much higher, indicating that the two tasks are similar to each other.

To test the sensitivity of the performance of our method to the values of  X  and  X  used in the Gamma prior, we try different values of  X  and  X  in a setting with 20% of the data points used for training. The resu lts are reported in Figures 3(a) to 3(b). We can see that our method is not very sensitive to the choice of  X  and  X  . consists of seven tasks where each task is a binary classification problem. The corre-sponding letters for each task are c/e, g/y, m/n, a/g, a/o, f/t, and h/n. Each data point has 128 features corresponding to the pixel values of the handwritten letter images. For each task, there are about 1,000 positive and 1,000 negative data points. The ex-perimental settings are the same as those for the previous wine quality classification. The results are plotted in Figures 4(a) to 4(g). From the results, we find that the per-formance of L-MDL is worse than that of ITML and RDML on some tasks (4th, 6th, and 7th tasks). This may be due to the fact that the objective function of L-MDL is non-convex, and hence it is easy to get trapped in bad local minima. TML gives the best performance on almost every task. 6.1.3. USPS Digit Classification. The USPS digit dataset 8 contains 7,291 examples each of 255 features. There are nine classification tasks, each corresponding to the classification of two digits. The experimental settings are the same as those for hand-written letter classification. The results are reported in Figures 5(a) to 5(i). Similar to handwritten digit classification, L-MDL is worse than ITML and RDML on some tasks, and TML is better than other methods on almost all tasks. In this section, we empirically study STML under the semi-supervised setting. We compare STML with TML to demonstrate how unlabeled data can improve the gen-eralization performance. Similar to the previous experimental settings, each task is treated as the target task and the other task as the source task. We select 80% of the data as training data, which includes both labeled and unlabeled data, and we vary the percentage of the labeled data used from 5% to 20% at intervals of 5% to see the effect of varying the size of the labeled dataset. Each configuration is repeated ten times, and the results are in the form of the mean and standard deviation of the classification accuracy. The results on the unlabeled train ing data of the three datasets are recorded in Figures 6, 7, and 8, and the results on the test data are recorded in Figures 9, 10, and 11. From the results, we can see that the performance of STML is comparable to or even better than that of TML. 6.2.1. Sensitivity Analysis. We also perform sensitivity analysis with respect to  X  and  X  on the wine dataset. We use 20% of the data as labeled data and 60% of the data as unlabeled data in the training set. The results reported in Figures 12 and 13 again show that our method is not very sensitive to the parameter values used. In this article, we have proposed a transfer metric-learning method to alleviate the labeled data deficiency problem in the target learning task by exploiting useful information from some source tasks. The l earning of the distance metrics from the source tasks and the relationships between the source tasks and the target task is formulated as a convex optimization problem which can be solved efficiently. We have also proposed an extension of TML to the semi-supervised setting by exploiting useful information contained in the unlabeled data. In our future research, we will apply our method to a wider range of supervised and semi-supervised learning applications. We present here the optimization procedure for solving Problem (3). We use an alter-nating method with two subproblems to be presented separately.
 Then the third term in the objective function of Problem (3) can be rewritten as where  X  2 denotes the two-norm of a vector, and M is a matrix such that vec( M )=  X   X  i  X  i . Note that the third term in the preceding equation is independent of i .Itis easy to show that M is a symmetric matrix. The optimization problem with respect to i becomes It is easy to see that this problem is a convex semidefinite programming (SDP) problem, since the objective function is convex with respect to i ,andtheconstraint is a PSD constraint on i . Even though solving an SDP problem is computationally demanding with poor scalability, we can adopt the technique of Weinberger and Saul [2008] to use gradient projection to solve it. Moreover, we can also use the online algorithm in Jin et al. [2009] to solve this problem.

Optimizing with respect to when { i } are fixed. When { i } are fixed, the optimization problem for finding becomes Then we have and the last inequality holds because of the Cauchy-Schwarz inequality for the Frobe-nius norm. Moreover, tr(  X  1 A ) attains its minimum value (tr( A 1 2 )) 2 if and only if for some constant a and tr( ) = 1. So we can get the following analytical solution.
