 The present article serves as an erratum to our paper of the same title, which was presented and published in the KDD 2014 conference. In that article, we claimed falsely that the objective function defined in Section 1.4 is non-monotone submodular. We are deeply indebted to Debmalya Mandal, Jean Pouget-Abadie and Yaron Singer for bringing to our attention a counter-example to that claim.

Subsequent to becoming aware of the counter-example, we have shown that the objective function is in fact NP-hard to approximate to within a factor of O ( n 1  X  ) for any &gt; 0.
In an attempt to fix the record, the present article com-bines the problem motivation, models, and experimental re-sults sections from the original incorrect article with the new hardness result. We would like readers to only cite and use this version (which will remain an unpublished note) instead of the incorrect conference version.
 [ Human-centered computing ]: Social networks Influence Maximization, Uncertainty, Noise, Submodular Op-timization, Robust Optimization
The processes and dynamics by which information and be-haviors spread through social networks have long interested scientists within many areas. Understanding such processes has the potential to shed light on human social structure, and to impact the strategies used to promote behaviors or products. While the interest in the subject is long-standing, recent increased availability of social network and informa-tion diffusion data (through sites such as Facebook, Twit-ter, and LinkedIn) has raised the prospect of applying social network analysis at a large scale to positive effect. Con-sequently, the resulting algorithmic questions have received widespread interest in the computer science community.
Among the broad algorithmic domains, Influence Maxi-mization has been repeatedly held up as having the potential to be of societal and financial value. The high-level hope is that based on observed data  X  such as social network infor-mation and past behavior  X  an algorithm could infer which individuals are likely to influence which others. This infor-mation could in turn be used to effect desired behavior, such as refraining from smoking, using superior crops, or purchas-ing a product. In the latter case, the goal of effecting desired behavior is usually termed viral marketing .

Consequently, both the problem of inferring the influence between individuals [11, 12, 13, 14, 23] and that of maximiz-ing the spread of a desired behavior have been studied ex-tensively. For the Influence Maximization problem, a large number of models have been proposed, along with many heuristics with and without approximation guarantees [5, 8, 9, 17, 18, 20, 22, 25, 26]. (See the monograph [7] for a recent overview of work in the area.)
However, one crucial aspect of the problem has  X  with very few exceptions discussed in Section 1.6  X  gone largely unstudied. Contrary to many other algorithmic domains, noise in social network data is not an exception, but the norm . Indeed, one could argue that the very notion of a  X  X ocial link X  is not properly defined in the first place, so that any representation of a social network is only an approxi-mation of reality. This issue is much more pronounced for a goal such as Influence Maximization. Here, the required data include, for every pair ( u,v ) of individuals, a numerical value for the strength of influence from u to v and vice ver-sa. This influence strength will naturally depend on context (e.g., what exact product or behavior is being spread); fur-thermore, it cannot be observed directly, and must therefore be inferred from observed behavior or individuals X  reports; all of these are inherently very noisy.

When the inferred influence strength parameters differ from the actual ground truth, even an optimal algorithm is bound to return suboptimal solutions, for it will optimize the wrong objective function: a solution that appears good with respect to the incorrect parameters may be bad with respect to the actual ones. If relatively small errors in the in-ferred parameters could lead to highly suboptimal solutions, this would cast serious doubts on the practical viability of al-gorithmic influence maximization. Therefore, in the present paper, we begin an in-depth study of the effect of noise on the performance of Influence Maximization algorithms.
We study this question under two widely adopted models for influence diffusion [17]: the Independent Cascade (IC) Model and the Linear Threshold (LT) Model . Both of these models fit in the following framework: The algorithm selects a seed set A 0 of k nodes, which begin active (having adopt-ed the behavior). Starting with A 0 , the process proceeds in discrete time steps: in each time step, according to a prob-abilistic process, additional nodes may become active based on the influence from their neighbors. Active nodes never become inactive, and the process terminates when no new nodes become active in a time step. The goal is to maxi-mize the expected number of active nodes when the process terminates; this expected number is denoted by  X  ( A 0 ).
To illustrate the questions and approaches, we describe the IC model in this section. (A formal description of the LT model and general definitions of all concepts are given in Section 2.) Under the IC model, the probabilistic process is particularly simple and intuitive. When a node u becomes active in step t , it attempts to activate all currently inactive neighbors in step t + 1. For each neighbor v , it succeeds with a known probability p u,v . If it succeeds, v becomes active; otherwise, v remains inactive. Once u has made all these attempts, it does not get to make further activation attempts at later times. It was shown in [17] that the set of nodes active at the end can be characterized alternatively as follows: for each ordered pair ( u,v ) independently, insert the directed edge ( u,v ) with probability p u,v . Then, the active nodes are exactly the ones reachable via directed paths from A .
Suppose that we have inferred all parameters p u,v , but are concerned that they may be slightly off: in reality, the influence probabilities are p 0 u,v  X  p u,v . Are there instances in which a seed set A 0 that is very influential with respec-t to the p u,v may be much less influential with respect to the p 0 u,v ? It is natural to suspect that this might not occur: when the objective function  X  varies sufficiently smoothly with the input parameters (e.g., for linear objectives), smal-l changes in the parameters only lead to small changes in the objective value; therefore, optimizing with respect to a perturbed input still leads to a near-optimal solution.
However, the objective  X  of Influence Maximization does not depend on the parameters in a smooth way. To illustrate the issues at play, consider the following instance of the IC model. The social network consists of two disjoint bidirect-ed cliques K n , and p u,v =  X  p for all u,v in the same clique; in other words, for each directed edge, the same activation probability  X  p is observed. The algorithm gets to select ex-actly k = 1 node. Notice that because all nodes look the same, any algorithm essentially chooses an arbitrary node, which may as well be from Clique 1.

Let  X  p = 1 /n be the sharp threshold for the emergence of a giant component in the Erd  X os-R  X enyi Random Graph G ( n,p ). It is well known [4, 10] that the largest connected component of G ( n,p ) has size O (log n ) for any p  X   X  p  X   X (1 /n ), and size  X ( n ) for any p  X   X  p +  X (1 /n ). Thus, if unbeknownst to the algorithm, all true activation probabilities in Clique 1 are p  X   X  p  X   X (1 /n ), while all true activation probabilities in Clique 2 are p  X   X  p +  X (1 /n ), the algorithm only activates O (log n ) nodes in expectation, while it could have reached  X ( n ) nodes by choosing Clique 2. Hence, small adversarial perturbations to the input parameters can lead to highly suboptimal solutions from any algorithm. 1
The example of two cliques shows that there exist unsta-ble instances , in which an optimal solution to the observed parameters is highly suboptimal when the observed parame-ters are slightly perturbed compared to the true parameters. Of course, not every instance of Influence Maximization is unstable: for instance, when the probability  X  p in the Two-Clique instance is bounded away from the critical threshold of G ( n,p ), the objective function varies much more smooth-ly with  X  p . This motivates the following algorithmic question, which is the main focus of our paper: Given an instance of Influence Maximization, can we diagnose efficiently whether it is stable or unstable?
To make this question precise, we formulate a model of perturbations. We assume that for each edge ( u,v ), in addi-tion to the observed activation probability p u,v , we are given an interval I u,v 3 p u,v of values that the actual probability p u,v could assume. The true values p 0 u,v are chosen from the intervals I u,v by an adversary; they induce an objective func-tion  X  0 which the algorithm would like to maximize, while the observed values induce a different objective function  X  which the algorithm actually has access to.

An instance ( p u,v ,I u,v ) u,v is stable if |  X  ( S )  X   X  for all objective functions  X  0 induced by legal probability settings, and for all seed sets S of size k . Here,  X  X mall X  is defined relative to the objective function value  X  ( A  X  0 optimum set.

When |  X  ( S )  X   X  0 ( S ) | is small compared to  X  ( A  X  S , a user can have confidence that his optimization result will provide decent performance guarantees even if his input was perturbed. The converse is of course not necessarily true: even in unstable instances, a solution that was optimal for the observed input may still be very good for the true input parameters.
Trying to determine whether there are a function  X  0 and a set S for which |  X  ( S )  X   X  0 ( S ) | is large motivates the fol-lowing optimization problem: Maximize |  X  ( S )  X   X  0 ( S ) | over all feasible functions  X  0 and all sets S . For any given set S , the objective is maximized either by making all proba-bilities (and thus  X  0 ( S )) as small as possible, or by making all probabilities (and thus  X  0 ( S )) as large as possible. denote the resulting two objective functions by  X   X  and  X 
The example reveals a close connection between the sta-bility of an IC instance and the question whether a unifor-m activation probability p lies close to the edge percolation threshold of the underlying graph. Characterizing the perco-lation threshold of families of graphs has been a notoriously hard problem. Successful characterizations have only been obtained for very few specific classes (such as d -dimensional grids [19] and d -regular expander graphs [2]). Therefore, it is unlikely that a clean characterization of stable and unstable instances can be obtained. The connection to percolation also reveals that the instability was not an artifact of hav-ing high node degrees. By the result of Alon et al. [2], the same behavior will be obtained if both components are d -regular expander graphs, since such graphs also have a sharp percolation threshold.
This observation relies crucially on the fact that each p can independently take on any value in I u,v . If the adversary were constrained by the total absolute deviation or sum of respectively. The following definition then captures the op-timization goal.
 Definition 1 (Influence Difference Maximization).
 Given two instances with probabilities p u,v  X  p 0 u,v for all u,v , let  X  and  X  0 be their respective influence functions. Find a set S of size k maximizing  X  ( S ) :=  X  ( S )  X   X  0 ( S ) . In this generality, the Influence Difference Maximization problem subsumes the Influence Maximization problem, by setting p 0 u,v  X  0 (and thus also  X  0  X  0).

While Influence Difference Maximization subsumes Influ-ence Maximization, whose objective function is monotone and submodular, the objective function of Influence Dif-ference Maximization is in general neither. To see non-monotonicity, notice that  X  (  X  ) =  X  ( V ) = 0, while generally  X  ( S ) &gt; 0 for some sets S .

The function is also not in general submodular, a fact brought to our attention by Debmalya Mandal, Jean Pouget-Abadie and Yaron Singer, and in contrast to the main result claimed in a prior version of the present article. The follow-ing example shows non-submodularity for both the IC and LT Models.

The graph has four nodes V = { u,v,x,y } and three edges ( u,v ) , ( v,x ) , ( x,y ). The edges ( v,x ) and ( x,y ) are known to have an activation probability of 1, while the edge ( u,v ) has an adversarially chosen activation probability in the interval [0 , 1]. With S = { u } and T = { u,x } , we obtain that  X  ( S + v )  X   X  ( S ) = | X  X  X  X { v,x,y }| =  X  3, while  X  ( T + v )  X   X  ( T ) = | X  X  X  X { v }| =  X  1, which violates submodularity.

In fact, we establish a very strong hardness result here, in the form of the following theorem, whose proof is given in Section 3.
 Theorem 1. Under the Independent Cascade Model, the Influence Difference Maximization objective function  X  ( S ) cannot be approximated better than n 1  X  for any &gt; 0 unless NP  X  ZPP.
Next, we investigate how pervasive instabilities are in real data. We evaluate frequently used synthetic models (2D grids, random regular graphs, small-world networks, and preferential attachment graphs) and real-world data sets (computer science theory collaborations and retweets about the Haiti earthquake). We focus on the Independent Cas-cade Model, and vary the influence strengths over a broad range of commonly studied values. We consider different rel-ative perturbation levels  X , ranging from 1% to 50%. The adversary can thus choose the actual activation probability to lie in the interval [(1  X   X ) p u,v , (1 +  X ) p u,v ]. To calculate a value for the maximum possible Influence Difference, we use the random greedy algorithm of Buch-binder et al. [6]. This choice of algorithm was motivated by the false belief that the objective function is submodular, in which case the algorithm would have provided a 1 /e ap-proximation. Notice, however, that the algorithm can only underestimate the maximum possible objective function val-ue. Thus, when the Random Greedy algorithm finds a set with large influence difference, it suggests that the misesti-mations due to parameter misestimates may drown out the squares of deviations of parameters, this would no longer be the case. This issue is discussed in Section 5. objective value, rendering Influence Maximization outputs very spurious. On the other hand, when the objective val-ue obtained by the Random Greedy algorithm is small, no positive guarantees can be provided.

Our experiments suggest that perturbations can have sig-nificantly different effects depending on the network struc-ture and observed values. As a general rule of thumb, per-turbations above 20% relative to the parameter values could significantly distort the optimum solution. For smaller er-rors (10% or less relative error), the values obtained by the algorithm are fairly small; however, as cautioned above, the actual deviations may still be large.

Since errors above 20% should be considered quite com-mon for estimated social network parameters, our result-s suggest that practitioners exercise care in evaluating the stability of their problem instances, and treat the output of Influence Maximization algorithms with a healthy dose of skepticism.
One may question why we choose to study adversarial instead of random perturbations. This choice is for three reasons: Theoretical: Worst-case analysis provides stronger guar-Practical: Most random noise models assume independence Modeling Interest: Perhaps most importantly, most nat-
The social network is modeled by a directed graph G = ( V,E ) on n nodes. All parameters for non-existing edges are assumed to be 0. We first describe models of influence diffusion, and then models of parameter perturbation.
Most of the models for Influence Maximization have been based on the Independent Cascade Model (see Section 1.1) and Linear Threshold Model studied in [17] and their gener-alizations. Like the Independent Cascade Model, the Linear Threshold Model also proceeds in discrete rounds. Each edge ( u,v ) is equipped with a weight c u,v  X  [0 , 1], satisfying P u  X  v c u,v  X  1 for all nodes v . (By u  X  v , we denote that there is a directed edge ( u,v ).) Each node v initially draws a threshold  X  v independently and uniformly at random from [0 , 1]. A set A 0 of nodes is activated at time 0, and we use A to denote the set of nodes active at time t . In each discrete round t , each node v checks if P u  X  A v becomes active at time t , and remains active subsequently.
Any instance of the Influence Maximization problem is characterized by its parameters. For the LT model, the pa-rameters are the n 2 edge weights c u,v for all edges ( u,v ). Similarly, for the IC model, the parameters are the edge activation probabilities p u,v for all edges ( u,v ). To unify notation, we write  X  = (  X  u,v ) ( u,v )  X  E for the vector of all parameter values, where  X  u,v could be either c u,v or p u,v
Both the IC and LT model define random processes that continue until the diffusion process quiesces, i.e., no new activations occur. Let  X   X  n be the (random) time at which this happens. It is clear that  X   X  n always, since at least one more node becomes active in each round. We denote the stochastic process by P Mod  X  ( A 0 ) = ( A t )  X  t =0 { IC , LT } denoting the model. The final set of active nodes is A . We can now formally define the Influence Maximization problem:
Definition 2 (Influence Maximization). The Influ-ence Maximization problem consists of maximizing the ob-jective  X  ( A 0 ) := E [ | A  X  | ] (i.e., the expected number of ac-tive nodes in the end 3 ), subject to a cardinality constraint | A 0 | X  k .
Our results carry over unchanged if we assign each n-ode a non-negative value r v , and the goal is to maximize P v  X  A  X  r v . We focus on the case of uniform values for nota-tional convenience only.

The key insight behind most prior work on algorithmic In-fluence Maximization is that the objective function  X  ( S ) is a monotone and submodular function of S . This was proved for the IC and LT models in [17], and subsequently for a gen-eralization called Generalized Threshold Model (proposed in [17]) by Mossel and Roch [22].
To model adversarial input perturbations, we assume that for each of the edges ( u,v ), we are given an interval I [ ` u,v ,r u,v ]  X  [0 , 1] with  X  u,v  X  I u,v . For the Linear Thresh-old Model, to ensure that the resulting activation functions are always submodular, we require that P u  X  v r u,v  X  1 for all nodes v . We write  X  =  X  ( u,v )  X  E I u,v for the set of all allowable parameter settings. The adversary must guaran-tee that the ground truth parameter values satisfy  X  0  X   X  ; subject to this requirement, the adversary can choose the actual parameter values arbitrarily.

Together, the parameter values  X  determine an instance of the Influence Maximization problem. We will usually be explicit about indicating the dependence of the objective function on the parameter setting. We write  X   X  for the objective function obtained with parameter values  X  , and only omit the parameters when they are clear from the con-text. For a given setting of parameters, we will denote by A  X   X  argmax S  X   X  ( S ) a solution maximizing the expected influence under parameter values  X  .
In order to capture to what extent adversarial changes in the parameters can lead to misestimates of any set X  X  influ-ence, we are interested in the quantity where  X  denotes the observed parameter values. For two parameter settings  X  ,  X  0 with  X   X   X  0 coordinate-wise, it is not difficult to show using a simple coupling argument that  X  ( S )  X   X   X  0 ( S ) for all S . Therefore, for any fixed set S , the maximum is attained either by making  X  0 as large as possible or as small as possible. Hence, solving the following problem is sufficient to maximize (1).

Definition 3. Given an influence model and two param-eter settings  X  ,  X  0 with  X   X   X  0 coordinate-wise, define Given the set size k , the Influence Difference Maximization (IDM) problem is defined as follows: In this section, we prove Theorem 1.
 Proof of Theorem 1. We establish the approximation hard-ness of Influence Difference Maximization without any con-straint on the cardinality of the seed set A 0 . From this version, the hardness of the constrained problem is inferred easily as follows: if any better approximation could be ob-tained for the constrained problem, one could simply enu-merate over all possible values of k from 1 to n , and retain the best solution, which would yield the same approximation guarantee for the unconstrained problem.
 We give an approximation-preserving reduction from the Maximum Independent Set problem to the Influence Dif-ference Maximization problem. It is well known that Max-imum Independent Set cannot be approximated better than O ( n 1  X  ) for any &gt; 0 unless NP  X  ZPP [16].
Let G = ( V,E ) be an instance of the Maximum Indepen-dent Set problem, with | V | = n . We construct from G a directed bipartite graph G 0 with vertex set V 0  X  V 00 . For each node v i  X  V , there are nodes v 0 i  X  V 0 and v 00 i  X  V edge set is E 0  X  E 00 , where E 0 = { ( v 0 i ,v 00 j ) | ( v E 00 = { ( v 0 i ,v 00 i ) | v i  X  V } . All edges of E 0 are known to have an activation probability of 1, while all edges of E 00 have an activation probability from the interval [0 , 1].

The difference is maximized by making all probabilities as large for one function (meaning that all edges in E 0  X  E are present deterministically), while making them as small as possible for the other (meaning that exactly the edges in E 0 are present).
 First, let S be an independent set in G . Consider the set S 0 = { v 0 i | v i  X  S } . Each node v 00 i with v i  X  S is reachable from the corresponding v 0 i in G 0 , but not in ( V 0  X  V because S is independent. Hence, the objective function value obtained in Influence Difference Maximization is at least | S | .

Conversely, consider an optimal solution S 0 to the Influ-ence Difference Maximization problem. Without loss of gen-erality, we may assume that S 0  X  V 0 : any node v 00 j  X  V be removed from S 0 without lowering the objective value. Assume that S := { v i  X  V | v 0 i  X  S 0 } is not independent, and that ( v i ,v j )  X  E for v i ,v j  X  S . Then, removing v from S 0 cannot lower the Influence Difference Maximization objective value of S 0 : all of v 0 j  X  X  neighbors in V 00 0, as they are reachable using E 0 already; furthermore, v also does not contribute, as it is reachable using E 0 from v Thus, any node with a neighbor in S can be removed from S , meaning that S is without loss of generality independent in G .

At this point, all the neighbors of S 0 contribute 0 to the In-fluence Difference Maximization objective function (because they are reachable under E 0 already), and the objective val-ue of S 0 is exactly | S 0 | = | S | .
While we saw in Section 1.2 that examples highly suscep-tible (with errors of magnitude  X ( n )) to small perturbations exist, the goal of this section is to evaluate experimentally how widespread this behavior is for realistic social networks. We carry out experiments under the Independent Cascade Model, for six classes of graphs  X  four synthetic and two real-world. In each case, the model/data give us a simple graph or multigraph. Multigraphs are converted to simple graphs by collapsing parallel edges to a single edge with weight c e equal to the number of parallel edges; for simple graphs, all weights are c e = 1. The observed probabilities for edges are p e = c e  X  p ; across experiments, we vary the base The resulting parameter vector is denoted by  X  .

The uncertainty interval for e is I e = [(1  X   X ) p e , (1 +  X ) p e ]; here,  X  is an uncertainty parameter for the estima-tion, which takes on the values { 1% , 5% , 10% , 20% , 50% } in our experiments. The parameter vectors  X  + and  X   X  de-scribe the settings in which all parameters are as large (as small, respectively) as possible.
We run experiments on four synthetic networks and two real social networks. Synthetic networks provide a controlled environment in which to compare observed behavior to ex-pectations, while real social networks may give us indica-tions about the prevalence of vulnerability to perturbations in real networks that have been studied in the past.
Synthetic Networks. We generate synthetic networks according to four widely used network models. In all cas-es, we generate undirected networks with 400 nodes. The network models are: (1) the 2-dimensional grid, (2) random regular graphs, (3) the Watts-Strogatz Small-World (SW) Model [27] on a ring with each node connecting to the 5 closest nodes on each side initially, and a rewiring probabil-ity of 0.1. (4) The Barab  X asi-Albert Preferential Attachment (PA) Model [3] with 5 outgoing edges per node. For all synthetic networks, we select k = 20 seed nodes.

Real Networks. We consider two real networks to eval-uate the susceptibility of practical networks: one ( STOC-FOCS ) is a co-authorship network of theoretical CS papers; the other ( Haiti ) is a Retweet network.

The co-authorship network, STOCFOCS , is a multigraph extracted from published papers in the conferences STOC and FOCS from 1964 X 2001. Each node in the network is a researcher with at least one publication in one of the con-ferences. For each multi-author paper, we add a complete undirected graph among the authors. As mentioned above, parallel edges are then compressed into a single edge with corresponding weight. The resulting graph has 1768 nodes and 10024 edges. Due to its larger size, we select 50 seed nodes.

The Haiti network is extracted from tweets of 274 users on the topic Haiti Earthquake in Twitter. For each tweet of user u that was retweeted by v , we add a directed edge ( u,v ). We obtain a directed multigraph; after contracting parallel edges, the directed graph has 383 weighted edges. For this network, due to its smaller size, we select 20 seeds.
In all experiments, we work with uniform edge weight-s p , since  X  apart from edge multiplicities  X  we have no evidence on the strength of connections. It is a promising direction for future in-depth experiments to use influence strengths inferred from real-world cascade datasets by net-work inference methods such as [11, 14, 23].
Our experiments necessitate the solution of two algorith-mic problems: Finding a set of size k of maximum influence, and finding a set of size k maximizing the influence differ-ence . The former is a well-studied problem, with a monotone submodular objective function. We simply use the widely known 1  X  1 /e approximation algorithm due to Nemhauser et al. [24], which is best possible unless P=NP.

For the goal of Influence Difference Maximization, we es-tablished (in Section 3) that the objective function is hard to approximate better than a factor O ( n 1  X  ) for any &gt; 0. For experimental purposes, we use the Random Greedy algorith-m of Buchbinder et al. [6], given as Algorithm 1 below. It is a natural generalization of the simple greedy algorithm of Nemhauser et al.: Instead of picking the best single element to add in each iteration, it first finds the set of the k indi-vidually best single elements (i.e., the elements which when added to the current set give the largest, second-largest, third-largest, ... , k th -largest gain). Then, it picks one of these k elements uniformly at random and continues.
This particular choice of algorithm was motivated by an incorrect claim included in a prior version of this work, namely, that the Influence Difference Maximization objec-tive is (non-monotone) submodular. For such functions, the Random Greedy algorithm guarantees at least an 0.266-approximation, and the guarantee improves to nearly 1 /e when k n . Furthermore, the Random Greedy algorith-m is simpler and more efficient than other algorithms with slightly superior approximation guarantees. We stress that these guarantees are not obtained for our objective function, as submodularity does not hold.
 Algorithm 1 Random Greedy Algorithm 1: Initialize: S 0  X  X  X  2: for i = 1 ,...,k do 3: Let M i  X  V \ S i  X  1 be the subset of size k maximizing 4: Draw u i uniformly at random from M i . 5: Let S i  X  S i  X  1  X  X  u i } . 6: end for 7: Return S k The running time of the Random Greedy Algorithm is O ( kC | V | ), where C is the time required to estimate g ( S  X  { u } )  X  g ( S ). In our case, the objective function is #P-hard to evaluate exactly [25, 9], but arbitrarily close approximations can be obtained by Monte Carlo simulation. Since each simulation takes time O ( | V | ), if we run M = 2000 iterations of the Monte Carlo simulation in each iteration, the overall running time of the algorithm is O ( kM | V | 2 ).

A common technique for speeding up the greedy algorithm for maximizing a submodular function is the CELF heuris-tic of Leskovec et al. [21]. When the objective function is submodular, the standard greedy algorithm and CELF ob-tain the same result. However, when it is not, the results may be different. In the previous version of this article, we had used the CELF heuristic due to the incorrect belief that the objective function was submodular. In this revised version, we instead report the results from rerunning all the experiments without the use of the CELF heuristic. The sin-gle exception is the largest input, the STOCFOCS network. (Here, the greedy algorithm without CELF did not finish in a reasonable amount of time.) For all networks other than STOCFOCS, the results using CELF are not significantly different from the reported results without the CELF op-timization. For STOCFOCS, we instead report the result including the CELF heuristic. In all our experiments, the results for the Grid and Small-World network are sufficiently similar that we omit the re-sults for grids here. As a first sanity check, we empirically 200 nodes with I e = [1 / 200  X  (1  X   X ) , 1 / 200  X  (1 +  X )] and k = 1. According to the analysis in Section 1.2, we would expect extremely high instability. The results, shown in Ta-ble 1, confirm this expectation.
Next, Figure 1 shows the (approximately) computed val- X  max A 0 : | A 0 | = k  X   X  ( A 0 ) for all networks and parameter set-tings. Notice that the result is obtained by running the Ran-dom Greedy algorithm without any approximation guaran-tee. However, as the algorithm X  X  output provides a lower bound on the maximum influence difference, a large value suggests that Influence Maximization could be unstable. On the other hand, small values do not guarantee that the in-stance is stable, as the algorithm provides no approximation guarantee.

While individual networks vary somewhat in their suscep-tibility, the overall trend is that larger estimates of baseline probabilities p make the instance more susceptible to noise, as do (obviously) larger uncertainty parameters  X . In par-ticular, for  X   X  20%, the noise (after scaling) dominates the Influence Maximization objective function value, mean-ing that optimization results should be used with care.
Next, we evaluate the dependence of the noise tolerance on the degrees of the graph, by experimenting with ran-dom d -regular graphs whose degrees vary from 5 to 25. It is known that such graphs are expanders with high prob-ability, and hence have percolation thresholds of 1 /d [2]. Accordingly, we set the base probability to (1 +  X  ) /d with  X   X  { X  20% , 0 , 20% } . We use the same setting for uncer-tainty intervals as in the previous experiments. Figure 2 shows the ratio between Influence Difference Maximization { X  20% , 0 , 20% } . It indicates that for random regular graph-s, the degree does not appear to significantly affect stability, and that again, noise around 20% begins to pose a signifi-cant challenge. Moreover, we observe that the ratio reaches its minimum when the edge activation probability is exactly at the percolation threshold 1 /d . This result is in line with percolation theory and also the analysis of Adiga et al. [1].
As a general takeaway message, for larger amounts of noise (even just a relative error of 20%)  X  which may well occur in practice  X  a lot of caution is advised in using the results of algorithmic Influence Maximization.
We began a study of the stability of Influence Maximiza-tion when the input data are adversarially noisy. We showed that estimating the susceptibility of an instance to pertur-bations can be cast as an Influence Difference Maximiza-tion problem. Unfortunately, the Influence Difference Max-imization problem under the Independent Cascade Model is as hard to approximate as the Independent Set prob-lem. While we do not at present have a comparable approx-imation hardness result for the Linear Threshold Model, we consider it unlikely that the Influence Difference Maximiza-tion objective could be much better approximated for that model.

We used the Random Greedy algorithm of Buchbinder et al. to gain an empirical understanding of the prevalence tion under random regular graphs with different degree. of instability on several synthetic and real networks. The results suggest that 20% relative error could lead to a signif-icant risk of suboptimal outputs. Given the noise inherent in all estimates of social network data, this suggests applying extreme caution before relying heavily on results of algorith-mic Influence Maximization.

The fact that our main theorem is negative (i.e., a strong approximation hardness result) is somewhat disappointing, in that it rules out reliably categorizing data sets as stable or unstable. This suggests searching for models which re-main algorithmically tractable while capturing some notion of adversarially perturbed inputs. The issue of noise in so-cial network data will not disappear, and it is necessary to understand its impact more fundamentally.

While we begin an investigation of how pervasive suscep-tibility to perturbations is in Influence Maximization data sets, our investigation is necessarily limited. Ground truth data are by definition impossible to obtain, and even good and reliable inferred data sets of actual influence probabili-ties are currently not available. The values we assigned for our experimental evaluation cover a wide range of parame-ter values studied in past work, but the community does not appear to have answered the question whether these ranges actually correspond to reality.

At an even more fundamental level, the models themselves have received surprisingly little thorough experimental val-idation, despite having served as models of choice for hun-dreds of papers over the last decade. In addition to verifying the susceptibility of models to parameter perturbations, it is thus a pressing task to verify how susceptible the opti-mization problems are to incorrect models. The verification or falsification of sociological models for collective behav-ior likely falls outside the expertise of the computer science community, but nonetheless needs to be undertaken before any significant impact of work on Influence Maximization can be truthfully claimed.
 We are deeply indebted to Debmalya Mandal, Jean Pouget-Abadie and Yaron Singer for bringing to our attention a counter-example to a theorem incorrectly claimed in the pre-vious version of this article.

Furthermore, we would like to thank Shaddin Dughmi for useful pointers and feedback, Shishir Bharathi and Mahyar Salek for useful discussions, and anonymous reviewers for useful feedback on prior versions. Xinran He was supported in part by the grant ONR MURI W911NF-11-1-0332 and DARPA SMISC W911NF-12-1-0034. [1] A. Adiga, C. J. Kuhlman, H. S. Mortveit, and [2] N. Alon, I. Benjamini, and A. Stacey. Percolation on [3] A.-L. Barab  X asi and R. Albert. Emergence of scaling in [4] B. Bollob  X as. Random Graphs . Cambridge University [5] C. Borgs, M. Brautbar, J. T. Chayes, and B. Lucier. [6] N. Buchbinder, M. Feldman, J. S. Naor, and [7] W. Chen, L. V. Lakshmanan, and C. Castillo.
 [8] W. Chen, Y. Wang, and S. Yang. Efficient influence [9] W. Chen, Y. Yuan, and L. Zhang. Scalable influence [10] P. Erd  X os and A. R  X enyi. On the evolution of random [11] M. Gomez-Rodriguez, D. Balduzzi, and B. Sch  X  olkopf. [12] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. [13] M. Gomez-Rodriguez and B. Sch  X  olkopf. Submodular [14] A. Goyal, F. Bonchi, and L. V. S. Lakshmanan. [15] A. Goyal, F. Bonchi, and L. V. S. Lakshmanan. A [16] J. H  X astad. Clique is hard to approximate within n [17] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [18] D. Kempe, J. Kleinberg, and E. Tardos. Influential [19] H. Kesten. Asymptotics in high dimension for [20] S. Khanna and B. Lucier. Influence maximization in [21] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [22] E. Mossel and S. Roch. Submodularity of influence in [23] S. A. Myers and J. Leskovec. On the convexity of [24] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An [25] C. Wang, W. Chen, and Y. Wang. Scalable influence [26] Y. Wang, G. Cong, G. Song, and K. Xie.
 [27] D. J. Watts and S. Strogatz. Collective dynamics of
