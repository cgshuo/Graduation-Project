 Luke K. McDowell lmcdowel@usna.edu David W. Aha david.aha@nrl.navy.mil Collective classification (CC) often substantially in-creases classification accuracy when the class labels of inter-related objects are correlated (Jensen et al., 2004; Sen et al., 2008). Most work with CC performs learning using a fully-labeled training graph. However, acquiring such labels can be very difficult, and learn-ing a classifier with only a few such labels can lead to very poor performance (Shi et al., 2011).
 In response, a few researchers have recently examined the CC task where a classifier must be learned from a partially-labeled training graph, using some form of semi-supervised learning (SSL) to leverage the unla-beled portion of the graph. However, they have re-ported inconsistent or weak results, even when using the same datasets and similar algorithms. This in-cludes Bilgic et al. (2010), who found moderate gains from SSL, whereas Shi et al. (2011) reported otherwise. In this paper, we examine how to improve SSL learn-ing for within-network CC when the provided graph is only sparsely labeled. We focus on traditional CC al-gorithms that learn a relational model of the data and then apply a collective inference algorithm such as the Iterative Classification Algorithm (ICA) or Gibbs sam-pling (Sen et al., 2008). Given the substantial number of recently proposed CC algorithms, we do not attempt here to establish the  X  X est X  CC algorithm for sparsely-labeled data. Rather, we ask: given a sparsely-labeled graph, can some form of SSL significantly improve the accuracy of traditional CC? If not (as argued by Shi et al. 2011), then these approaches may need to be en-tirely replaced with alternatives such as latent feature models (Tang &amp; Liu, 2009) or label propagation (Shi et al., 2011). However, if SSL can be effective in this domain, then many challenges remain, but a substan-tial amount of existing research on CC can continue to be used and adapted.
 In our studies, we confirm that the simplest forms of SSL do not perform consistently well for sparsely-labeled CC. However, we introduce two new techniques that are simple and computationally efficient, yet can significantly increase accuracy.
 Our contributions are as follows. First, we show how the most relevant prior work can all be generalized into a single parameterized algorithm for semi-supervised CC, facilitating comparison. Second, we explain how to transform the node classifier used by an algorithm like ICA or Gibbs sampling into a  X  X ybrid X  classifier that uses one classifier for the non-relational features (i.e., the attributes of each node) and a different clas-sifier for the relational features (i.e., those that de-pend on the links in the graph). This change enables novel combinations of classifiers with better perfor-mance. Third, we extend the idea of label regulariza-tion (Mann &amp; McCallum, 2007) to support such hybrid classifiers. This technique uses predictions over the un-labeled data to induce models that better account for class distribution priors. Fourth, we demonstrate, us-ing three standard datasets, that combining a hybrid classifier with label regularization leads to significant accuracy gains compared to existing SSL methods and other baselines. Finally, we use our results to explain the conflicting conclusions from previous studies. Assume we are given a graph G = ( V,E,X A ,Y,C ) where V is a set of nodes, E is a set of edges, each x
A  X  X A is an attribute vector for a node v i  X  V , each Y i  X  Y is a label variable for v i , and C is the set of possible labels. We are also given a set of  X  X nown X  values Y K for nodes V K  X  V , so that Y K = { y i | v i  X  V
K } . Then the within-network classification task is to infer Y U , the values of Y i for the remaining nodes V U with  X  X nknown X  values ( V U = V \ V K ).
 For example, consider predicting whether a web page belongs to a professor or a student. Conventional ap-proaches ignore the link relations and classify each page using the attributes x A derived from its content (e.g., words in the page). In contrast, methods for col-lective classification (Jensen et al., 2004) explicitly use the link structure by constructing additional relational features x R based on the labels of neighboring pages. For instance, one relational feature might count the number of pages labeled Student that are linked to each page. However, using such features is challeng-ing, because some of the labels are initially unknown, and thus typically are estimated and then iteratively refined in some way. This can be done using algorithms such as belief propagation, Gibbs sampling, relaxation labeling, or ICA (Sen et al., 2008).
 We focus on ICA, one of the simplest and most popu-lar CC algorithms. ICA first predicts a label for every node in V U (the  X  X nknown X  nodes) using only the attributes X A . Next, ICA constructs additional re-lational features X R using the known and predicted node labels ( Y K and Y U ), then re-predicts labels for V
U using both X A and X R . This process of computing feature values and re-predicting labels is then repeated until convergence or for a fixed number of iterations. 2.1. Semi-supervised Collective Classification Many CC variants, including ICA, use a classifier that predicts a node X  X  label based on its attributes and (via relational features) the labels of linked nodes. In par-ticular, ICA uses one  X  X ootstrap classifier X  that uses only the attributes ( M A ) and one  X  X ode classifier X  that uses both attributes and relational features ( M AR ). Most CC approaches assume that these classifiers are learned from a separate, fully-labeled training graph. For our within-network task, however, we assume that there is a single sparsely-labeled graph. In this case, learning the classifiers M A and M AR is challenging be-cause of label sparsity. Learning M AR is especially problematic, since relational features can only be used for learning in the rare case where both node endpoints of a link have known labels. For instance, if 10% of nodes are labeled, perhaps only 1% of links will qualify. Given a large set of nodes but only a small set of pro-vided labels, it is natural to consider some sort of semi-supervised learning (SSL). A few researchers have in-vestigated this scenario, and Table 1 summarizes the most relevant studies, which all use some variant of semi-supervised ICA. We observe that all of these SSL variants can be generalized into a single SSL algorithm (see Figure 1), which we explain below.
 These variants first learn an attribute-only classifier M
A from the known labels, then predict labels for the unknown nodes V U with M A (steps 1-2). The known and predicted labels are then used to compute rela-tional feature values (step 4). The variants then differ in how they use these values and in how many steps each variant takes. The simplest approach, taken by Shi et al. (2011), is to learn the classifier M AR using all of the labels, attributes, and relational feature values (step 5). Step 6 then uses M A and M AR to predict new labels (by executing ICA), and step 7 returns the set of predicted labels ( n = 1). Bilgic et al. (2010) use the same approach, except that during step 5, they per-form learning using only the known nodes V K . This approach is still semi-supervised because the relational feature values for V K (as computed in step 4) are influ-enced by the predicted labels for the unknown nodes V
U . We call this latter variant Known-OnePass , since it uses only the known nodes X  labels for the ac-tual learning and does one step of relational learning, and naturally call the former variant All-OnePass . Alternatively, more complex variants perform a form of EM where the algorithm repeatedly estimates new labels given the current models (i.e., step 6 is the E-step) and then maximizes the probability of a new model given the current label estimates (i.e., steps 4-5 are the M-step). Based on the learning choice in step 5, this yields the variants All-EM and Known-EM , which are approximately the approaches of Lu &amp; Getoor (2003) and Xiang &amp; Neville (2008), respec-tively. Lu &amp; Getoor repeat based on a convergence condition, while Xiang &amp; Neville use a fixed number of iterations (e.g., n = 10). Xiang &amp; Neville also perform inference in step 6 (and learning) with a  X  X oft X  variant of ICA that uses probability estimates of the predicted labels, rather than choosing the most likely label for each node in V U (the  X  X ard X -labeling approach used by the other variants). We use hard labeling; future work should compare these alternatives.
 This prior work leaves three key problems unad-dressed. First, there are conflicting results for whether semi-supervised ICA improves accuracy, with reports of no improvement (Shi et al., 2011), moderate im-provement (Bilgic et al., 2010), or mixed results (Xiang &amp; Neville, 2008). Lu &amp; Getoor (2003) report substan-tial gains, but only consider graphs with at least 20% of the nodes labeled. Second, there is almost no com-parison between the four SSL variants (or even discus-sion of the choices involved). One exception is Bilgic (2010), which finds Known-OnePass to be superior to All-OnePass on two datasets, but does not in-vestigate why. In contrast, we have generalized these algorithms in Figure 1, and study their relative per-formance in Section 5. Such comparisons aid under-standing of the choices involved, and also establish the best baseline for future studies.
 Finally, we find that none of the variants perform con-sistently well. Sections 3 and 4 describe the two key steps that we propose for improving their performance. 2.2. Other Approaches to Semi-supervised CC Two additional relevant studies are Taskar et al. (2001) and Chu et al. (2006). However, these methods cannot handle cyclic graphs or have time complexity at least quadratic in the number of nodes ( N ), and thus do not scale to large, realistic graphs. The methods we use are only linear in N (assuming realistic link densities), even with our improvements in Sections 3 and 4. Others have explored how to perform within-network CC without needing to learn an explicit model for link-based features (the challenge for ICA discussed in Sec-tion 2.1). For instance, Tang &amp; Liu (2009) use the links to create latent features that enable node classification without collective inference. Shi et al. (2011) propose label propagation based on derived latent links. A few authors have proposed  X  X elational-only X  meth-ods that perform no learning but use some label prop-agation or random walk to classify the nodes (e.g., Macskassy &amp; Provost 2007). These variants can in-crease accuracy, but only for graphs that match their assumptions and have enough known labels.
 As noted in Section 1, we do not attempt to compare against all of these methods but do use that of Mac-skassy &amp; Provost, a common CC baseline. Prior work with CC using ICA or Gibbs sampling has usually used a single node classifier (often logis-tic regression or Naive Bayes) to predict a label y for each node based on the node X  X  attributes ( x A ) and relational features ( x R ). Instead, we propose to use two distinct classifiers that make separate predictions based on x A and x R . If we assume that x A and x R are conditionally independent given the class label y , we can then compute the combined prediction where  X  is a normalizing constant independent of y . Using such a  X  X ybrid X  classifier has two main advan-tages. First, this method allows us to choose different types of classifiers for the attributes vs. the relational features. For instance, most prior work (e.g., Sen et al. 2008) has found that logistic regression (LR) performs best overall for CC. However, McDowell et al. (2009) found that  X  X ultiset X  relational features usually per-formed best, but are incompatible with the vector-based representation of LR. Combining LR with at-tributes plus Naive Bayes (NB) with multiset rela-tional features yields a new LR+NB classifier that re-solves this representational conflict and may increase accuracy. Second, hybrid classifiers may increase ac-curacy, even when the two classifiers are the same type (e.g., LR+LR ), as we show and explain in Section 5. Combining two different classifiers to make a single prediction is a special case of an ensemble. A few papers have considered how to apply some type of ensemble for CC. For instance, Preisach &amp; Schmidt-Thieme (2008) use an ensemble to combine predictions based on different link types, while Eldardiry &amp; Neville (2011) use an ensemble after each step of collective in-ference. These studies combine multiple classifiers us-ing voting, stacking, or averaging, rather than via a probabilistic rule like Equation 1. Also, they do not use the unlabeled data for SSL; instead, they use fully-labeled training data or relational-only algorithms. The work most closely related to ours is Lu &amp; Getoor (2003), which uses an ensemble of two LR classifiers, combined similarly to Equation 1. They informally state that this approach outperformed a single LR clas-sifier with SSL, but did not explain why or report com-parisons. In contrast, our paper is the first to specifi-cally demonstrate that a hybrid LR+LR classifier can often improve accuracy dramatically, and Section 5 ex-plains why. In addition, this paper is the first to pro-pose the LR+NB combination, and we show that it can perform particularly well for some datasets. Label regularization (Mann &amp; McCallum, 2007) is designed to make SSL more robust by encouraging a learned LR classifier (or other exponential family model) to produce probability estimates on the un-labeled data so that the resultant class distribution resembles an expected distribution. More specifically, let  X  p ( y ) be the expected label distribution, which can be computed from the training data. Let  X  p  X  ( y ) be the empirical distribution, which is computed over the unlabeled part of the training data, given the current parameter settings  X  , as follows: Mann &amp; McCallum then augment the traditional LR objective function with an additional term  X   X (  X  p,  X  p based on the KL-divergence between  X  p and  X  p  X  : They (and we) set the tuning parameter  X  = 10  X | V K | . The new term  X   X (  X  p,  X  p  X  ) penalizes parameter settings where there is a large difference between the expected distribution and empirical distribution. Thus, it uses the unlabeled data to help choose more plausible pa-rameter values and avoid degenerate cases (e.g., where most nodes are assigned to the same class label). Label regularization could be directly applied to CC classifiers based on non-hybrid LR (though to our knowledge this has not been done previously). How-ever, this would not exploit the advantages we later demonstrate for hybrid classifiers. Given a hybrid LR+LR classifier, we could apply label regularization separately to each classifier. However, this would not ensure that the combined predictions given by Equa-tion 1 resemble the desired label distribution, nor would this work for hybrid combinations not based on LR, such as LR+NB . Instead, we use the following strategy to adapt label regularization to hybrid classi-fiers. First, we learn p ( y | x R ) (the relational classifier) ignoring the attributes and label regularization. Then, we treat p ( y | x R ) as fixed and define  X  y =  X  p ( y | x which allows us to simplify Equation 1 to Next, we assume that the attribute-based classifier is a standard multinomial logistic regression model, so where  X  y is a parameter vector for class y . Combining the previous two equations and normalizing yields where, since P y p  X  ( y | x ) = 1, Z = P y 0  X  y 0 exp ( x Gradient methods can now be used to optimize the log-likelihood of the training data, with the term  X (  X  p,  X  p in the objective providing label regularization. Thus, we now compute the gradient of this term. For each node v i , let x A be the values of v i  X  X  attributes, and x k be the k th such attribute value. Then the gradient with respect to  X  y,k (the parameter associated with the k th attribute for class y ) is  X   X   X  X  This approach can work for any hybrid classifier that includes LR in the combination, including LR+LR and LR+NB . In contrast, recent work (Mann &amp; McCallum, 2010) extended label regularization to support condi-tional random fields, but did not consider the kind of hybrid classifiers that we examine here. 5.1. Datasets and Features Prior studies used at most two non-synthetic datasets with semi-supervised ICA; we used the union of their datasets (see Tables 1 &amp; 2). We removed all nodes with no links, but we did not (like some others did) use only the largest connected component of the graphs. Cora (see Sen et al. 2008) is a collection of machine learning papers. Citeseer (see Sen et al.) is a collec-tion of research papers drawn from the Citeseer collec-tion. For both datasets, the attributes represent the presence or absence of particular words, and citations provide links between the documents. We ignored link direction, as with Bilgic et al. (2010). They also report substantially higher accuracies using principal compo-nent analysis (PCA) to reduce the dimensionality of the attributes, so to provide a stronger baseline we mimic their setup and use the 100 top attribute fea-tures after applying PCA to the entire graph.
 Gene (see Jensen et al. 2004) describes the yeast genome at the protein level; links represent protein interactions. We mimic Xiang &amp; Neville (2008) and predict protein localization using four attributes: Phe-notype, Class, Essential, and Chromosome. We bina-rized these attributes, yielding 54 binary attributes. For relational features, LR classifiers used  X  X ropor-tion X  features, which compute the fraction of a node X  X  neighbors that have label y , as done by Bilgic et al. (2010). NB classifiers instead used  X  X ultiset X  features which record the distribution of labels in each node X  X  neighborhood, then use conditional independence as-sumptions to update the estimated probabilities based on each such label. Previous work found such features to perform best for NB (McDowell et al., 2009). 5.2. Node Classifier and Regularization Prior work has usually found LR to be superior to NB for CC (Sen et al., 2008; Bilgic et al., 2010) and there-fore we always use LR for (at least) the attribute-based classification. For the node classifier M AR , we evaluate five options: LR is a single (non-hybrid) classifier that uses logistic regression. LR+LR is a hybrid classifier that uses two LR classifiers, while LR+LR+Reg adds label regularization. LR+NB is a hybrid classifier that uses LR for the attributes and NB for the relational features, and LR+NB+Reg adds label regularization. For standard regularization (separate from label regu-larization), we used a Gaussian prior with LR param-eters, with variance  X  2 chosen as described below. For NB, we used a Dirichlet prior on each feature with  X  chosen as described below (McDowell et al., 2009). Of the four studies listed in Table 1, none specify how regularization parameters (if any) were chosen. For sparsely-labeled data, we observed that these choices can have a large impact on accuracy. To ensure fair comparisons, we used five-fold cross-validation on the labeled data (learning also had access to the unlabeled data), selecting the value that maximized accuracy on the held-out labeled data. For LR+LR classifiers, we normalized all features, which allowed us to use a sin-gle value of  X  2 for both classifiers. For LR+NB , we first found  X  2 for LR, then estimated  X  for NB. 5.3. Learning Algorithms We evaluate four variants of semi-supervised ICA (see Section 2): All-EM , All-OnePass , Known-EM , and Known-OnePass . For each, step 6 of the al-gorithm executes ICA with 10 iterations, and the EM-variants use n = 10 iterations of the main loop. We compare against three baselines. The first, No-SSL , is like Known-OnePass in applying ICA one time using both attributes and relational features, but No-SSL learns the node classifier without using any unlabeled data (i.e., with no SSL). The second, Attr-Only , predicts the unknown labels only once, using an attribute-only classifier that ignores unlabeled data while learning. The third, Relat-Only , is a stan-dard relational-only baseline (the wvRN+RL classifier of Macskassy &amp; Provost 2007) that repeatedly esti-mates labels based on the labels of all linked neighbors. These three baselines never use label regularization. 5.4. Evaluation Procedure We report accuracy averaged over 15 trials. For each trial, we randomly selected some fraction of the nodes (the  X  X abel density X ) to be  X  X nown X  nodes V K . The remaining nodes V U have unknown labels and form the test set part of graph G . We focus on the sparsely-labeled case where the density is less than 10%. To assess significance, we use paired t-tests with a 5% significance level. However, the test sets are not dis-joint across the 15 trials, and thus a traditional paired t-test may yield false conclusions. To compensate for this effect, we use the recently described methodology of Wang et al. (2011), which was shown to reduce false positives to the expected level. This makes our results more conservative compared to uncorrected t-tests. 5.5. Results We first consider the best learning algorithm ( All-EM , as shown later) with various classifiers, then com-pare different learning algorithms with the best node classifier ( LR+NB+Reg ). Finally, we use our findings to explain the results of previous studies.
 Result 1: Using a hybrid classifier and la-bel regularization each increases accuracy, and combining the two techniques yields the best overall results . Figure 2 shows the average accu-racy, for All-EM , as label density is varied from 1% to 50%. Below, we discuss results only for the sparse case (density less than 10%). Each line represents a different node classifier, and symbols indicate (some of the) significant differences (see caption).
 The hybrid LR+LR almost always outperforms LR , with especially large gains for Cora. Likewise, chang-ing the classifier to LR+NB almost always yields some additional gain, even when the label density is as high as 9%. Furthermore, adding label regularization (with LR+LR+Reg or LR+NB+Reg ) always outper-forms LR+LR , and always matches or exceeds the ac-curacy of LR+NB . The gains from label regularization are sometimes substantial, especially when the label density is low, but remain large even at a density of 9% for Gene. For instance, for Citeseer when the den-sity is 1%, label regularization improves LR+LR by 13.1% and LR+NB by 9.6% (both significantly). 1 Overall, LR+NB+Reg performs best and its accuracy is never lower than the alternatives. It significantly outperforms LR , and often substantially outperforms the other classifiers, especially vs. those without label regularization and/or when the label density is lower. Without label regularization, some learning runs con-verged on degenerate distributions, with one class dis-proportionately represented. Adding label regulariza-tion substantially reduced this problem, as intended. We also found that, compared to LR , LR+LR learned much more reasonable weights  X  for the relational fea-tures (e.g., that match our knowledge of the actual link-based correlations). When there are few labeled nodes, the LR optimization routine may find a model where the attributes alone explain the data well, with small weights for the relational features. Placing these features in a separate model (as with LR+LR ) ensures that they will be more heavily used, increasing accu-racy since both attributes and relational features are informative for these datasets.
 Result 2: All-EM outperforms the baselines and usually the other SSL variants. Table 3 com-pares the four SSL algorithms and the three baseline algorithms, using LR+NB+Reg . All-EM is the most consistent, and is always one of the best algorithms (with one exception for Gene). In many cases, All-EM  X  X  gains are significant vs. the other methods. All-OnePass and Known-OnePass outperform No-SSL by varying degrees, but Known-EM is much worse, never matching the best accuracy and often under-performing No-SSL . For this data, the repeated EM iterations seem to be a poor choice when the ac-tual learning is performed over only the small number of  X  X nown X  nodes; Known-OnePass performs better. Result 3: Without hybrid classification and la-bel regularization, accuracy decreases substan-tially. Table 4 compares the same SSL algorithms shown in Table 3, but now using the simpler LR clas-sifier. This setting is closest to that of Bilgic et al. (2010) and Shi et al. (2011). To save space, we show only Cora; trends are similar with Citeseer and Gene. Compared to Table 3 X  X  results with LR+NB+Reg , per-formance with LR usually drops substantially (as al-ready partly seen in Figure 2). The All variants suffer the biggest drops, especially All-EM , because with-out a good hybrid classifier and label regularization, learning may be based on estimated labels with a de-generate distribution. The Known variants are more insulated from this effect because poor label estimates only affect the relational feature values (not the labels directly seen by the learning algorithm).
 Discussion: Table 4 showed that using LR changes the relative performance of the SSL algorithms com-pared to when using LR+NB+Reg . These results help us explain the previously discussed conflicting find-ings related to Table 1. First, with a simple LR clas-sifier, Known-OnePass outperforms All-OnePass (and provides reasonable gains over No-SSL )  X  consis-tent with Bilgic et al. (2010). Second, All-OnePass behaves similarly to No-SSL  X  the same poor behavior that led Shi et al. (2011) to reject semi-supervised ICA. Note that both of these conclusions change when a bet-ter classifier like LR+NB+Reg is used (see Table 3). Third, Known-EM behaves reasonably well but not the best; this may explain why Xiang &amp; Neville found gains for this algorithm only in some cases. Finally, Lu &amp; Getoor reported strong results with All-EM and a classifier like LR+LR , tested for label densities of at least 20%. For lower densities, our results (see Figure 2) show that this combination is not as strong. Overall, our results show that, while the simplest forms of semi-supervised ICA do not perform well, using a hybrid classifier with label regularization enables the most sophisticated learning algorithm ( All-EM ) to work well, leading to significant accuracy gains. To quantify the overall impact of our changes, the bottom row of Table 3 shows results with a natural benchmark: the basic LR algorithm with Known-OnePass . This SSL algorithm worked best with LR and mimics the setup of Bilgic et al. (2010), who reported spend-ing considerable effort to improve their performance. Comparing vs. the top row of Table 3 ( LR+NB+Reg with All-EM ), we find consistent and mostly signifi-cant gains, ranging from 4.3-26.8% for Cora, 0.9-12.7% for Citeseer, and 2.7-3.4% (with one loss of -0.8%) for Gene. Thus, we find consistent gains for our new meth-ods compared to this benchmark method. We have generalized the algorithms of multiple pre-vious studies of semi-supervised ICA, explained their performance trends, and demonstrated that a hybrid classifier with label regularization can significantly in-crease accuracy compared to alternative approaches. For our data, the LR+NB combination performed best, though this will not hold for every dataset. How-ever, our hybrid approach enables any combination of probabilistic classifiers to be selected based on the data characteristics. Moreover, our extension of label reg-ularization can also be used to increase accuracy, as long as one of the classifiers is in the exponential fam-ily (like LR). Such hybrid classifiers with label regular-ization may be useful in many other tasks, including across-network CC or non-relational classification. Our results need to be confirmed with additional datasets, and we will explore alternatives to ICA such as Gibbs sampling and soft-labeling methods, and the use of other hybrid combination rules such as stack-ing. Moreover, the best algorithms should be com-pared against other methods discussed in Section 2.2. However, our results already show that there is more potential for semi-supervised learning based on ICA than was suggested by earlier studies, and we have pre-sented two techniques that improve its performance. Thanks to Alexandra Olteanu, Li Pu, Majid Yazdani, and the anonymous referees for comments that helped to improve this work. Portions of this analysis used Proximity, an open-source software environment from the Univ. of Massachusetts, Amherst. This work was supported in part by NSF award number 1116439.
