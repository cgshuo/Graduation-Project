 A number of techniques have been developed for dealing with high dimensional data sets that fall on or near a smooth low dimensional nonlinear manifold. Such data sets arise whenever the number of modes of variability of the data are much fewer than the dimension of the input space, as is the case for image sequences. Unsupervised manifold learning refers to the problem of recovering the structure of a manifold from a set of unordered sample points. Manifold learning is often equated with dimensionality reduction, where the goal is to find an embedding or  X  X nrolling X  of the manifold into a lower dimensional space such that certain relationships between points are preserved. Such embeddings are typically used for visualization, with the projected dimension being 2 or 3. Image manifolds have also been studied in the context of measuring distance between images un-dergoing known transformations. For example, the tangent distance [20, 21] between two images is computed by generating local approximations of a manifold from known transformations and then computing the distance between these approximated manifolds. In this work, we seek to frame the problem of recovering the structure of a manifold as that of directly learning the transformations a point on a manifold may undergo. Our approach, Locally Smooth Manifold Learning ( LSML ), attempts to learn a warping function W with d degrees of freedom that can take any point on the manifold and generate its neighbors. LSML recovers a first order approximation of W , and by mak-ing smoothness assumptions on W can generalize to unseen points.
 We show that LSML can recover the structure of the manifold where data is given, and also in regions where it is not, including regions beyond the support of the original data. We propose a number of uses for the recovered warping function W , including embedding with a natural out-of-sample extension, and in the image domain discuss how it can be used for tasks such as computation of tangent distance, image sequence interpolation, compression, and motion transfer. We also show examples where LSML is used to simultaneously learn the structure of multiple  X  X arallel X  manifolds, and even generalize to data on new manifolds. Finally, we show that by exploiting the manifold smoothness, LSML is robust under conditions where many embedding methods have difficulty. Related work is presented in Section 2 and the algorithm in Section 3. Experiments on point sets and results on images are shown in Sections 4 and 5, respectively. We conclude in Section 6. Related work can be divided into two categories. The first is the literature on manifold learning, which serves as the foundation for this work. The second is work in computer vision and computer graphics addressing image warping and generative models for image formation.
 A number of classic methods exist for recovering the structure of a manifold. Principal component analysis ( PCA ) tries to find a linear subspace that best captures the variance of the original data. Traditional methods for nonlinear manifolds include self organizing maps, principal curves, and variants of multi-dimensional scaling ( MDS ) among others, see [11] for a brief introduction to these techniques. Recently the field has seen a number of interesting developments in nonlinear manifold learning. [19] introduced a kernelized version of ( PCA ). A number of related embedding methods have also been introduced, representatives include LLE [17], I SOMAP [22], and more recently SDE [24]. Broadly, such methods can be classified as spectral embedding techniques [24]; the embed-dings they compute are based on an eigenvector decomposition of an n  X  n matrix that represents geometrical relationships of some form between the original n points. Out-of-sample extensions have been proposed [3]. The goal of embedding methods (to find structure preserving embeddings) differs from the goals of LSML (learn to traverse the manifold).
 Four methods that we share inspiration with are [6, 13, 2, 16]. [6] employs a novel charting based technique to achieve increased robustness to noise and decreased probability of pathological behav-ior vs . LLE and I SOMAP ; we exploit similar ideas in the construction of LSML but differ in motiva-tion and potential applicability. [2] proposed a method to learn the tangent space of a manifold and demonstrated a preliminary illustration of rotating a small bitmap image by about 1  X  . Work by [13] is based on the notion of learning a model for class specific variation, the method reduces to com-puting a linear tangent subspace that models variability of each class. [16] shares one of our goals as it addresses the problem of learning Lie groups, the infinitesimal generators of certain geometric transformations.
 In image analysis, the number of dimensions is usually reduced via approaches like PCA [15], epit-omic representation [12], or generative models like in the realMOVES system developed by Di Bernardo et al . [1]. Sometimes, a precise model of the data, like for faces [4] or eyes [14], is even used to reduce the complexity of the data. Another common approach is simply to have instances of an object in different conditions: [5] start by estimating feature correspondences between a novel in-put with unknown pose and lighting and a stored labeled example in order to apply an arbitrary warp between pictures. The applications range from video texture synthesis [18] and facial expression extrapolation [8, 23] to face recognition [10] and video rewrite [7]. Let D be the dimension of the input space, and assume the data lies on a smooth d -dimensional manifold ( d D ). For simplicity assume that the manifold is diffeomorphic with a subset of R d , meaning that it can be endowed with a global coordinate system (this requirement can easily be relaxed) and that there exists a continuous bijective mapping M that converts coordinates y  X  R d to points x  X  R D on the manifold. The goal of most dimensionality reduction techniques given a set of data points x i is to find an embedding y i = M  X  1 ( x i ) that preserves certain properties of the original data like the distances between all points (classical MDS ) or the distances or angles between nearby points ( e.g . spectral embedding methods).
 Instead, we seek to learn a warping function W that can take a point on the manifold and return any neighboring point on the manifold, capturing all the modes of variation of the data. Let us use W ( x , ) to denote the warping of x , with  X  R d acting on the degrees of freedom of the warp according to the formula M : W ( x , ) = M ( y + ) , where y = M  X  1 ( x ) . Taking the first order approximation of the above gives: W ( x , )  X  x + H ( x ) , where each column H  X  k ( x ) of the matrix given small enough, hence we speak of W being an infinitesimal warping function.
 We can restate our goal of learning to warp in terms of learning a function H  X  : R D  X  R D  X  d parameterized by a variable  X  . Only data points x i sampled from one or several manifolds are given. For each x i , the set N i of neighbors is then computed ( e.g . using variants of nearest neighbor such Figure 1: Overview . Twenty points (n=20) that lie on 1D curve (d=1) in a 2D space (D=2) are shown in (a). as k NN or NN), with the constraint that two points can be neighbors only if they come from the same manifold. To proceed, we assume that if x j is a neighbor of x i , there then exists an unknown ij such that W ( x i , ij ) = x j to within a good approximation. Equivalently: H  X  ( x i ) ij  X  x j  X  x i . We wish to find the best  X  in the squared error sense (the ij being additional free parameters that must be optimized over). The expression of the error we need to minimize is therefore: Minimizing the above error function can be interpreted as trying to find a warping function that can transform a point into its neighbors. Note, however, that the warping function has only d degrees of freedom while a point may have many more neighbors. This intuition allows us to rewrite the error in an alternate form. Let  X  i be the matrix where each column is of the form ( x j  X  x i ) for each neighbor of x i . Let  X  i = U i  X  i V i &gt; be the thin singular value decomposition of  X  i . Then, one can show [9] that error 1 is equivalent to the following: Here, the matrices E i are the additional free parameters. Minimizing the above can be interpreted as searching for a warping function that directly explains the modes of variation at each point. This form is convenient since we no longer have to keep track of neighbors. Furthermore, if there is no noise and the linearity assumption holds there are at most d non-zero singular values. In practice we use the truncated SVD, keeping at most 2 d singular values, allowing for significant computational savings.
 We now give the remaining details of LSML for the general case [9]. For the case of images, we present an efficient version in Section 5 which uses some basic domain knowledge to avoid solving a large regression. Although potentially any regression technique is applicable, a linear model is particularly easy to work with. Let f i be f features computed over x i . We can then define H  X  ( x i ) = [ X  1 f i  X  X  X   X  D f i ] &gt; , where each  X  k is a d  X  f matrix. Re-arranging error 2 gives: Solving simultaneously for E and  X  is complex, but if either E or  X  is fixed, solving for the remaining variable becomes a least squares problem (an equation of the form AXB = C can be rewritten as B &gt;  X  A  X  vec( X ) = vec( C ) , where  X  denotes the Kronecker product and vec the matrix vectorization function). To solve for  X  , we use an alternating minimization procedure. In all experiments in this paper we perform 30 iterations of the above procedure, and while local minima do not seem to be to prevalent, we randomly restart the procedure 5 times. Finally, nowhere in the construction have we enforced that the learned tangent vectors be orthogonal (such a constraint would only be appropriate if the manifold was isometric to a plane). To avoid numerically unstable solutions we regularize the error: For the features we use radial basis functions ( RBF s) [11], the number of basis functions, f , being an additional parameter. Each basis function is of the form f j ( x ) = exp(  X  X  x  X   X  j k 2 2 / 2  X  2 ) where the centers  X  j are obtained using K-means clustering on the original data with f clusters and the width parameter  X  is set to be twice the average of the minimum distance between each cluster and its The parameter f controls the smoothness of the final mapping H  X  ; larger values result in mappings that better fit local variations of the data, but whose generalization abilities to other points on the manifold may be weaker. This is exactly analogous to the standard supervised setting and techniques like cross validation could be used to optimize over f . We begin with a discussion on the intuition behind various aspects of LSML . We then show exper-iments demonstrating the robustness of the method, followed by a number of applications. In the figures that follow we make use of color/shading to indicate point correspondences, for example when we show the original point set and its embedding.
 LSML learns a function H from points in R D to tangent directions that agree, up to a linear combina-tion, with estimated tangent directions at the original training points of the manifold. By constraining H to be smooth (through use of a limited number of RBF s), we can compute tangents at points not seen during training, including points that may not lie on the underlying manifold. This general-ization ability of H will be central to the types of applications considered. Finally, given multiple non-overlapping manifolds with similar structure, we can train a single H to correctly predict the tangents of each, allowing information to be shared. Fig. 1 gives a visual tutorial of these different concepts.
 LSML appears quite robust. Fig. 2 shows LSML successfully applied for recovering the embedding of the  X  S -curve X  under a number of sampling conditions (similar results were obtained on the  X  X wiss-roll X ). After H is learned, the embedding is computed by choosing a random point on the manifold Figure 3: Reconstruction . Reconstruction examples are used to demonstrate quality and generalization of and establishing a coordinate system by traversing outward (the same procedure can be used to embed novel points, providing a natural out-of-sample extension). Here we compare only to LLE and I SOMAP using published code. The densely sampled case, Fig. 2(a), is comparatively easy and a number of methods have been shown to successfully recover an embedding. On sparsely sampled data, Fig. 2(b), the problem is more challenging; LLE had problems for n&lt; 250 (lowering LLE  X  X  regularization parameter helped somewhat). Real data need not be uniformly sampled, see Fig. 2(c). In the presence of noise Fig. 2(d), I SOMAP and LLE performed poorly. A single outlier can distort the shortest path computed by I SOMAP , and LLE does not directly use global information necessary to disambiguate noise. Other methods are known to be robust [6], and in [25] the authors propose a method to  X  X mooth X  a manifold as a preprocessing step for manifold learning algorithms; however a full comparison is outside the scope of this work.
 Having learned H and computed an embedding, we can also backproject from a point y  X  R d to a point x on the manifold by first finding the coordinate of the closest point y i in the original data, then traversing from x i by j = y j  X  y i j along each tangent direction j (see Fig. 1(d)). Fig. 3(a) shows tangents and an embedding recovered by LSML on the Swiss-roll. In Fig. 3(b) we backpro-ject from a grid of points in R 2 ; by linking adjacent sets of points to form quadrilaterals we can display the resulting backprojected points as a surface. In Fig. 3(c), we likewise do a backprojection (this time keeping all the original points), however we backproject grid points well below and above the support of the original data. Although there is no ground truth here, the resulting extension of the surface seems  X  X atural X . Fig. 3(d) shows the reconstruction of a unit hemisphere by traversing outward from the topmost point. There is no isometric mapping (preserving distance) between a hemisphere and a plane, and given a sphere there is actually not even a conformal mapping (pre-serving angles). In the latter case an embedding is not possible, however, we can still easily recover H for both (only hemisphere results are shown). Before continuing, we consider potential applications of H in the image domain, including tangent distance estimation, nonlinear interpolation, extrapolation, compression, and motion transfer. We re-fer to results on point-sets to aid visualization. Tangent distance estimation: H computes the tangent and can be used directly in invariant recognition schemes such as [21]. Compression: Fig. 3(b,d) suggest how given a reference point and H nearby points can be reconstructed using d numbers (with distortion increasing with distance). Nonlinear interpolation and extrapolation: points can be generated within and beyond the support of given data ( cf . Fig. 3); of potential use in tasks such as frame rate up-conversion, reconstructing dropped frames and view synthesis. Motion transfer: for certain classes of manifolds with  X  X arallel X  structure ( cf . Fig. 1(f)), a recovered warp may be used on an entirely novel image. These applications will depend not only on the accuracy of the learned H but also on how close a set of images is to a smooth manifold. The key insight to working with images is that although images can live in very high dimensional spaces (with D  X  10 6 quite common), we do not have to learn a transformation with that many parameters. Let x be an image and H  X  k ( x ) , k  X  [1 ,d ] , be the d tangent images. Here we assume that each pixel in H  X  k ( x ) can be computed based only on the information in s  X  s patch centered on the corresponding pixel in x . Thus, instead of learning a function R D  X  R D  X  d we learn a function R s 2  X  R d , and to compute H we apply the per patch function at each of the D locations in the image. The resulting technique scales independently of D , in fact different sized images can be used. The per patch assumption is not always suitable, most notably for transformations that are based only on image coordinate and are independent of appearance.
 The approach of Section 3 needs to be slightly modified to accommodate patches. We rewrite each image x i  X  R D as a s 2  X  D matrix X i where each row contains pixels from one patch in x i (in training we sub-sample patches). Patches from all the images are clustered to obtain the f RBF s; each X i is then transformed to a f  X  D matrix F i that contains the features computed for each patch. The per patch linear model can now be written as H  X  ( x i ) = ( X  F i ) &gt; , where  X  is a d  X  f matrix (compare with the D  X  s needed without the patch assumption). The error function, which is minimized in a similar way [9], becomes: We begin with the illustrative example of translation (Fig. 4). Here, RBF s were not used, instead F i = X i . The learned  X  is a 2  X  s 2 matrix, which can be visualized as two s  X  s images as in Fig. 4(b). These resemble derivative of Gaussian filters, which are in fact the infinitesimal generates for translation [16]. Computing the dot product of each column of  X  with each patch can be done using a convolution. Fig. 4 shows applications of the learned transformations, which resemble translations with some artifacts.
 Fig. 5 shows the application of LSML for learning out-of-plane rotation of a teapot. On this size problem training LSML (in M ATLAB ) takes a few minutes; convergence occurs within about 10 iterations of the minimization procedure. H  X  ( x ) for novel x can be computed with f convolutions (to compute cross correlation) and is also fast. The outer frames in Fig. 5 highlight a limitation of the approach: with every successive step error is introduced; eventually significant error can accumulate. Here, we used a step size which gives roughly 10 interpolated frames between each pair of original frames. With out-of-plane rotation, information must be created and the problem becomes ambiguous (multiple manifolds can intersect at a single point), hence generalization across images is not expected to be good.
 In Fig. 6, results are shown on an eye manifold with 2 degrees of freedom. LSML was trained on sparse data from video of a single eye; H  X  was used to synthesize views within and also well outside the support of the original data ( cf . Fig. 6(c)). In Fig. 6(d), we applied the transformation learned from one person X  X  eye to a single image of another person X  X  eye (taken under the same imaging conditions). LSML was able to start from the novel test image and generate a convincing series of This work was funded by the following grants and organizations: NSF Career Grant #0448615, Alfred P. Sloan Research Fellowship, NSF IGERT Grant DGE-0333451, and UCSD Division of Calit2. We would like to thank Sameer Agarwal, Kristin Branson, Matt Tong, and Neel Joshi for valuable input and Anna Shemorry for helping us make it through the deadline.

