 Data mining is a crucial tool for identifying risk signals of potential adverse drug reactions (ADRs). However, mining of ADR signals is currently limited to leveraging a single data source at a time. It is widely believed that combining ADR evidence from multiple data sources will result in a more accurate risk identification system. We present a methodology based on empirical Bayes modeling to combine ADR signals mined from 5 million adverse event reports collected by the FDA, and healthcare data corresponding to 46 million patients X  X he main two types of information sources currently employed for signal detection. Based on four sets of test cases (gold standard), we demonstrate that our method leads to a statistically significant and substan-tial improvement in signal detection accuracy, averaging 40% over the use of each source independently, and an area under the ROC curve of 0.87. We also compare the method with alternative supervised learning approaches, and argue that our approach is preferable as it does not require labeled (training) samples whose availability is currently limited. To our knowledge, this is the first effort to combine signals from these two complementary data sources, and to demonstrate the benefits of a com-putationally integrative strategy for drug safety surveillance. J.3 [ Computer Applications ]: Life and Medical Sciences; H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms, Performance Empirical Bayes, signal detection, pharmacovigilance
After a drug has been approved and is used on large, diverse populations, and for more varied periods of time, unanticipated adverse drug reactions (ADRs) may occur, which alter a drug X  X  risk-benefit ratio enough to require remedial action. Post-approval ADRs are a major global health concern accounting for more than 2 million poten-tially preventable injuries, hospitalizations, and deaths each year in the US alone[15, 8], and associated costs estimated at $75 billion annually[6]. Pharmacovigilance, also known as drug safety surveillance, refers to the science and activi-ties relating to the detection, assessment, understanding and prevention of ADRs in the post-approval period.

Data mining approaches that empower drug safety evalua-tors to analyze large volumes of data and to identify risk sig-nals of potential ADRs, have proven to be a critical compo-nent in pharmacovigilance. Also known as signal detection methodologies, these data mining approaches are designed to compute measures of statistical association between pairs of drugs and clinical outcomes recorded in an underlying database. In a knowledge discovery scenario, the associa-tion statistics computed by data mining are interpreted as signal-scores, with larger values representing stronger asso-ciations, which are assumed more likely to represent true ADRs. Rankings of signal-scores or signal-score-thresholds are then used to flag associations worthy of further expert evaluation.

The US Food and Drug Administration (FDA) has main-tained the Adverse Event Reporting System (AERS)[1] since 1968, which to date contains over 5 million spontaneous re-ports of suspected ADRs collected from healthcare profes-sionals, consumers, and pharmaceutical companies. Each report includes one or more adverse events that appear to be associated with the administration of a drug, as well as indications and limited demographic information. Sponta-neous reporting systems such as AERS communicate gen-uine health concerns, cover large populations, and are gen-erally accessible for analysis. Since its inception AERS has supported regulatory decisions for a long list of marketed drugs[22]. Notwithstanding, AERS suffers from a range of recognized limitations including: reporting biases, misattri-bution of causality in reported ADRs, missing and incom-plete data, duplicated reporting, and lack of true exposure information[7, 20].

Pharmacovigilance has predominantly relied on sponta-neous reporting systems such as AERS. However, given their limitations, and the expanding availability and tremendous potential of healthcare data to advance pharmacovigilance, research efforts are now shifting towards the secondary use of large healthcare databases[10] such as electronic health records and administrative claims that typically contain: time-stamped interventions, procedures, diagnoses, medica-tions, medical narratives, and billing codes. Unlike spon-taneous reports, healthcare data reflect  X  X eal-world X  routine clinical care recorded over long periods of time. As such, they contain a more complete record of the patient X  X  medical history, treatments, conditions, and potential risk factors.
US Food and Drug Administration Amendments Act of 2007 requires the FDA to develop a national system for mon-itoring medical product safety based on diverse healthcare data[2]. In 2008 the FDA launched the Sentinel Initiative[16] to meet this requirement. As part of this effort the Obser-vational Medical Outcomes Partnership (OMOP)[19, 18, 4] was established to conduct methodological research to sup-port the development of a national risk identification and analysis system, and a similar research initiative called the EU-ADR project was initiated in Europe[9].

The FDA routinely applies data mining to AERS in order to monitor and identify new safety signals of ADRs that war-rant further attention. Similar surveillance strategies can be applied to healthcare data as demonstrated through pilot studies by the OMOP and the EU-ADR project. Although both AERS and healthcare data present unique challenges in its use, a common belief is that they may complement each other along several dimensions that will improve phar-macovigilance.

This paper presents a methodology to combine signals generated from spontaneous reports and healthcare data, and importantly aims to demonstrate that signal detection accuracy can be improved by such an integrative strategy. To our knowledge, this work is the first to explicitly and computationally combine signals from the two sources. We further argue that the proposed methodology is preferable to alternative approaches based on supervised learning that may be employed.

The proposed methodology draws parallels from statisti-cal meta-analysis, and is based on empirical Bayes model-ing where ADR signal-scores mined from each data source are modeled concomitantly using a Bayesian two-stage nor-mal/normal model whose two hyper-parameters are esti-mated from the data using the expectation maximization (EM) algorithm. The output of the method is compos-ite (combined) signal-scores consolidating the statistical ev-idence supplied by the source-dependent signal-scores. The methodology is applied to signals mined from 5 million public domain AERS reports, and healthcare data corre-sponding to 46 million patients captured in the  X  X MOP results set X . The performance of the method (i.e., the signal detection accuracy of the combined signal-scores) is mea-sured based on a validated gold standard created by the OMOP, totaling 380 positive and negative ADR test cases, and spanning four clinical outcomes.

The remainder of the paper is organized as follows: Sec-tion 2 provides background on signal detection methodolo-gies and the specific methods used in this paper. Section 3 presents the proposed method to combine signals. Section 4 describes the experiments performed including data sources and the evaluation process. Section 5 provides the results and discussion, and Section 6 presents the conclusion. The term  X  X ignal-score X  (or just signal) will be used to refer to a statistic that represents the strength of statistical associ-Table 1: Contingency table used to compute associ-ation statistics for SRS-based signal detection reports w drug a b reports wo drug c d ation between a drug-outcome combination recorded in an underlying database.
Due to inherent differences between spontaneous report-ing systems (SRS) and healthcare databases, different data mining (signal detection) approaches are usually applied to each.
Currently, the main driving force behind SRS-based sig-nal detection is an approach referred to as disproportional-ity analysis , which aims to quantify the degree to which a reported drug-outcome combination co-occurs in the data  X  X isproportionally X  as compared with what would be ex-pected if there were no statistical association between the drug and the outcome. All signal detection methodologies based on disproportionality analysis use the entries of Table 1 (or stratified versions thereof) to derive surrogate measures of statistical association. The table is computed for every drug-outcome combination being considered. The method-ologies may differ with respect to the exact association mea-sure that is used and the statistical adjustments that may be applied to the measure. The most widely cited measure is the relative reporting ratio (RRR), defined as the ratio between the number of reports in a SRS mentioning a spe-cific drug-outcome combination to an expected number of reports under the assumption that the drug and outcome occur independently. The expected number of reports is calculated using all the reports in the SRS mentioning the drug or outcome as a proxy for the true value. Specifically, based on Table 1 where Pr(o utcome j drug)/Pr(outcome) can be viewed as the probabilistic interpretation of RRR. A RRR=3, for example, would indicate that there are three times as many sponta-neous reports mentioning a specific drug-outcome combina-tion than would be expected by chance, which in turn may support the hypothesis of an ADR relationship between the drug and outcome. A true value of RRR close to 1 supports the hypothesis that there is no association between the drug and outcome.

The Multi-item Gamma Poisson Shrinker (MGPS)[12] used in this work to generate signals from AERS, is a leading SRS-based signal detection algorithm, which has been en-dorsed by the FDA as well as other regulatory agencies and pharmaceutical companies world-wide. MGPS computes a Bayesian regularized and stratified RRR designed to guard agai nst false positive signals due to sampling variance, as well as account for biases due to temporal reporting trends and confounding by age and sex. It uses a Gamma-Poisson model to compute a centrality measure of the posterior dis-tribution of the true RRR in the population. The measure is called empirical Bayes geometric mean (EBGM), and can be interpreted as the observed stratified RRR shrunken to-wards a prior when less data is available about the specific drug-outcome association being estimated. The prior is as-sumed to follow a bimodal Gamma distribution that models the RRRs of all distinct drug-outcome combinations in the SRS.

Drugs in AERS are entered verbatim, but are then usu-ally mapped to their generic names or their active ingre-dients. Outcomes in AERS are coded using MedDRA[3] (a controlled vocabulary developed for ADR applications) usually at the  X  X referred term X  level of the MedDRA hierar-chy. AERS currently includes about 4,000 mapped drugs, about 15,000 MedDRA preferred terms, and about 5 mil-lion distinct drug-outcome combinations appearing at least once that may be considered for analysis and for which as-sociations statistics need to be computed. Signal detection methods such MGPS are usually applied to compute asso-ciations for all reported drug-outcome combinations in the SRS, typically on a quarterly basis whenever a new batch of spontaneous reports becomes available.
Unlike SRS that are oriented towards pharmacovigilance, the secondary use of healthcare data requires special care to properly account for potential confounding biases (e.g., pre-existing risk factors) that may distort the estimation of a drug-outcome association. Although methods originally developed for SRS may be applied, an alternative class of approaches that are better equipped to deal with confound-ing is usually employed. This class of approaches is based on epidemiologic study designs that aim to control con-founding by seeking to ensure that the two groups of sub-jects used to study an association (e.g., exposed/unexposed, cases/controls) are comparable with respect to potential confounding factors, which therefore cannot be the reason for an association. Another key distinguishing feature of this class of methods is their systematic use of temporal infor-mation, which is generally unavailable in SRS. The temporal information is used to establish various time frames, known as surveillance windows, drug/condition eras, or hazard pe-riods, which are used to identify and count drug and out-come co-occurrences used in subsequent calculations, e.g., number of outcomes recorded within 30 days of drug expo-sure. Each method belonging to this class follows a different analytic paradigm and has multiple parameter settings cor-responding to various study design choices, such as: length of surveillance window, type of comparator group, counting strategy, and confounding adjustment strategy.

Observational Screening (OS)[4] is a method developed by the OMOP that was used in this work to compute signals from healthcare data. Its preference over other methods will be made clear in Section 4.2 (greater signal detection accu-racy). Under the parameter setting used in this work, OS represents a  X  X elf-controlled X  study design, wherein subjects serve as their own controls by comparing outcome rates for periods when a subject is exposed to a drug to periods when the subject is unexposed to the drug. Therefore, implicitly controlling for all time-invariant and subject-invariant con-founders (e.g., comorbidities, smoking status, and chronic use of drugs) without the need for the confounders to be identified and measured. The core measure calculated by OS is a Screening Rate (SR) defined as The  X  X ime at Risk X  for a drug is the length of exposure to the drug and an additional time period added to the end of the exposure (in this work Time at Risk=length of expo-sure+30 days). The  X  X otal Time at Risk X  is an accumulated Time at Risk over all exposures. The number of outcomes counted towards SR is a count of outcomes occurring during the Time at Risk. The association statistic output by OS is a Screening Rate Ratio (SRR), defined as In this case (self-controlled design) the SR of the un-exposed group is calculated by specifying a Time at Risk period prior to each drug exposure, whose length is the same as for the exposure period, and counting out-comes during that period. Fig. 1 provides an illus-tration of the components used in the calculation per-formed by OS for a specific drug-outcome pair and a pop-ulation consisting of two patients. In this example  X  X R of exposed group X =(1+1+2)/(2+3+5),  X  X R of unexposed group X =(0+1+1)/(2+3+5), and SRR=(4/10)/(2/10)=2. Figure 1: Illustration of the components used in the calculation performed by the Observation Screening signal detection method.

Regardless of the method or data source used, the out-put of a signal detection method for a specific drug-outcome pair is an association statistic (e.g., SRR, EBGM), and its lower and upper bound confidence interval (or alternatively its variance). The lower bound association statistic is often used as a signal-score instead of the point estimate as a sug-gested adjustment to reduce false signaling. A more detailed overview of pharmacovigilance data mining approaches can be found in ref. [14].
The empirical Bayes approach (EB) is often viewed as a compromise between classical (frequentist) and fully Bayesian approaches to statistical inference, borrowing ideas from eac h. EB starts by specifying a hierarchical model as do all Bayesian techniques. Hierarchical models in turn de-pend on a sequence of priors that must stop at some point with the remaining prior parameters assumed known. This is where EB separates from the fully Bayesian approach. Rather than assuming and specifying these final-stage prior parameters, the EB approach uses the observed data to es-timate these parameters, and then proceeds as though they were known substituting them into the original Bayes quan-tities. This attribute was the main reason for employing EB in the current application. Namely, enjoying the flexibility and benefits of Bayesian modeling, but not having to spec-ify prior parameters, which in the current application would have been based on nothing other than a  X  X ood guess X .
Suppose we have J pairs of signal-scores, where each pair corresponds to a unique drug-outcome association and each element in the pair corresponds to a signal originating from a different data source (e.g., AERS or healthcare data) that is computed by a possibly different signal detection method. The signals need not be based on the same statistic but are on approximately the same scale, and are assumed log-normally distributed.

Let y jk denote the log of the j th signal-score computed from the k th data source, where j = 1 ;:::;J and k = 1 ;:::;K . Further, let s 2 jk = Var( y jk ) be the accompany-ing observed variance of each signal-score, computed along with the signal. The goal is to estimate the unknown pa-rameter j denoting the combined (composite or pooled) signal-score of the j th drug-outcome association, by observ-ing Y = f y jk g and S = f s 2 jk g . In the current application K = 2, but we use a more general formulation to emphasize that the framework allows for more than just two sources to be considered without a need to modify the methodology.
The two-stage hierarchical model describing Y and used to estimate j is given by where ; 2 are hyper-parameters to be estimated from the data (discussed below). The model assumes that each tuple of observed signal-scores ( y j 1 ;:::;y jK ) are random mani-festations of normal process centered around the true but unknown combined signal-score j , which itself is normally distributed (prior) around  X  X  grand mean allowing for J related signals (e.g., signals related to the same clinical out-come) to borrow statistical support from one another.
Based on Eq. 1 the goal can be stated as com-puting the posterior distribution j j Y;S;; 2 and using E[ j j Y;S;; 2 ] as the estimate of j . Further, according to Eq. 1 the joint density (data likelihood) is given by f ( Y; j ; 2 ;S ) = We denote by  X  y j a statistic that is meant to summarize the information (signal-scores) provided by each data source for a given drug-outcome association, and consider two common possibilities  X  y j = The summary statistic provided in Eq. 3(a) assumes that the information contributed by each data source is weighted equally, whereas 3(b) assumes that the contribution is pro-portional to the uncertainty (variance) associated with the signal-score supplied by each data source, i.e., more weight is assigned to a signal whose variance is smaller.
Having defined  X  y j (whether based on Eq. 3(a) or Eq. 3(b)) we approximate the joint density given in Eq. 2 by
Based on Eq. 4 it can be shown[13] that the posterior distribution of interest is where Therefore, our estimate of j is given by Eq. 6 shows that the estimated combined signal-score of the j th drug-outcome association equals a weighted average of the prior mean and the statistic  X  y j summarizing the signal-scores ( y j 1 ;:::;y jK ). The weights B j and (1 B are functions of the uncertainty (variance) associated with the two weighted extremes. That is, when the summary statistic  X  y j has smaller variance ( s 2 j ) more weight will be put on  X  y j . Conversely, larger uncertainly will shrink  X  y the prior mean . In this way, we are not only pooling associations across data sources, but are also allowing for the pooled signals j to  X  X orrow strength X  from each other within similar groups to provide potentially more accurate estimates. This borrowing of strength is especially useful, as discussed later, when estimating ADR signals related to the same outcome or drug class.
To apply Eq. 6 we need to estimate the hyper-parameters and 2 . Conditioned on j the observations  X  y j are inde-pendently distributed. Based on this, the empirical Bayes approach uses the marginal likelihood in Eq. 7 to estimate the hyper-parameters ; 2 of the model.
 Because a closed form solution does not exist, we use the EM algorithm to obtain the maximum likelihood estimates of ; 2 in Eq. 7. The EM algorithm, which in this situation offers a relatively simple alternative to other optimization techniques, can be applied by considering j as a latent or missing variable, Eq. 7 as a missing-data likelihood, and Eq. 4 as the complete-data likelihood. Dempster et al. [11] showed that when the distribution of the complete-data (e.g., Eq. 4) belongs to an exponential family, or alter-natively when the complete-data log-likelihood is linear in some sufficient statistic T (as in this case), then the E-step in the EM algorithm reduces to computing the posterior conditional expectation of T given the observed data, and the M-step reduces to substituting the expectation computed in the E-step in the expression for the complete-data maximum likelihood of the parameters to estimate. Therefore, given that T 1 = sufficient statistics for and 2 respectively, and using t to index the current iteration, the EM steps can be stated as: E-step : M-step : To summarize, the whole process for estimating the com-bined signal-scores  X  j , j = 1 ;:::;J , requires iteratively com-puting Eqs. 8 X 9 until convergence, and substituting the final estimates  X  ;  X  2 into Eq. 6. Crude estimates for and that can be used to seed/initialize the EM algorithm are given by: Having estimated  X  j , lower bound signal-scores can be com-puted using the posterior variance B j s 2 j given in Eq. 5, e.g.,  X  Tabl e 2: Distribution of OMOP test cases used in the evaluation Outcome Cases Cases Total Acute Renal Failure 22 58 80 Upper GI Bleed 24 66 90 Acute Liver Injury 77 36 113 Acute Myocardial Infarction 34 63 97
Tota l 157 223 380
The proposed methodology was evaluated on the basis of its ability to correctly signal (classify) a total of 380 posi-tive and negative test cases (drug-outcome pairs), which are part of a gold standard created and thoroughly validated by the OMOP, and for which both AERS and healthcare data was available. Positive test cases are true ADR asso-ciation asserted from drug labeling (mention of an outcome as an adverse reaction) and/or prior published research sug-gesting an association. Conversely, negative test cases are associations that lack this level of evidence in their label-ing or the literature. The entire gold standard includes 181 drugs and is divided into four sets each associated with a unique outcome X  acute myocardial infarction , acute renal failure , acute liver injury , and upper gastroin-testinal bleeding , which represent four of the most signif-icant and actively monitored drug safety outcomes[21]. A cross tabulation of the test cases by outcome is provided in Table 2.
The  X  X MOP results set X  is based on five medical databases comprised of administrative claims and electronic health records, which reflect the healthcare experience of about 74 million patients. To each of these databases the OMOP ap-plied seven unique and commonly used methods to compute signal-scores of each drug-outcome pair in their gold stan-dard. Each method follows a different analytic paradigm and has multiple parameter settings, as described in Sec-tion 2.2. In total, the OMOP results set contains 6 million signal-scores (and associated statistics) representing every combination of database, method, parameter setting, and drug-event pair in the gold standard. The result set is pub-licly available at http://omop.fnih.org/research.
As the set of signal-scores used in our evaluation, we selected from the OMOP results set signal-scores corre-sponding to the largest database X  X  X arketScan Commercial Claims and Encounters X , which contains claims data corre-sponding 46 million patients and is abbreviated X  X CAE. The signals were computed by the OS method (parameter setting referenced by Analysis-ID: 403002), which uniformly provided the best diagnostic accuracy across the four out-comes given data from CCAE, and explains the preference of the OS method over other methods (Section 2.2).
Using the public-release version of AERS we extracted a total of 4,784,337 spontaneous reports covering the pe-riod from 1968 through 2011Q3. The data was preprocessed (as sug gested in the literature) to remove duplicate reports and correct terminological errors. To facilitate interoper-ability of terms and definitions used to describe drugs and outcomes in AERS and the OMOP results set, we mapped drug names in AERS to their ingredient level specification. MedDRA preferred terms used to specify outcomes in AERS were mapped to the four outcomes in the gold standard us-ing broad MedDRA group definitions supplied by OMOP. The preprocessed AERS data was then loaded into the Em-pirica Signal V7.3 system (ESS) X  X  drug safety data mining application from Oracle Health Sciences[5].
 Within ESS we applied the Multi-item Gamma Poisson Shrinker (Section 2.1) based on its standard parameter set-tings to generate signal-scores for each of the 380 tests cases in the gold standard.
Given pre-computed AERS and healthcare signal-scores corresponding to each of the 380 test cases, the proposed methodology to combine the signal-scores was applied in-dependently to each of the four outcome sets of test cases. That is, each outcome was modeled separately X  X ssuming that signals associated with the same outcome are statis-tically related and can therefore borrow support from each other, but are unrelated to signals associated with other out-comes and should not borrow support from them.

Based on OMOP X  X  set of test cases, the performance (sig-nal detection accuracy) of the resulting system (combined signal-scores) was compared against the performance of sig-nals generated by each data source independently. Per-formance was measured using the threshold-independent measure X  X rea under the receiver operating characteristic (ROC) curve (AUC), which is the most widely used index for measuring diagnostic accuracy.

The methodology was also compared against linear and non-linear supervised classification/prediction algorithms as potential competing approaches to combine signals. These can be applied by treating the signal-scores y 1 ;y 2 as two features/predictors, interpreting the decision/predicted val-ues as combined signal-scores, and by using subsets of the OMOP test cases as training and testing samples. In this ap-plication, a linear classifier will have the form f ( w 0 w y 2 ), where f is a strictly monotonic function that maps a linear combination of signal-scores to a decision/predicted value. Since a ROC curve is invariant to monotonic trans-formations, Therefore, is an upper bound to the AUC attainable by any specific linear classifier. So instead of evaluating a specific set of linear classifiers (e.g., logistic regression, LDA, perceptron, linear SVM) we cast our evaluation to computing the AUC in Eq. 11, and refer to the hypothetical method producing this AUC as the X  X ptimal Linear Classifier X . The maximiza-tion of Eq. 11 was performed using a 1D grid search (in-tervals=0.01, -10 &lt;w&lt; 10). Because the same generalization does not hold for non-linear classifiers we used the radial ba-sis kernel SVM (in the e1701 R package) as a representative. Both approaches were evaluated using 5-fold cross-validation based on class-stratified samples. The results were averaged to produce a single AUC.
The main results of our evaluation are summarized in Ta-ble 3, which displays a comparison of AUC-based signal de-tection accuracy across the data sources/methods evaluated. We define  X  X elative Improvement X  as
AUC(Combined) max(AUC(AERS) ; AUC(Healthcare)) i.e, the proportion of error reduction gained by using the combined signal-scores over the better performing individual data source signal-scores.

Overall, Table 3 demonstrates that combining signals across AERS and healthcare data using the proposed methodology leads to an overall substantial improvement. The results also demonstrate that the improvement is repli-cated across analysis of different outcomes. Since the method is unlikely to transform two strong signals into a weak signal, nor is it expected to transform two weak signals into a strong composite signal, the success of the method can be linked to cases where the two data sources provide incon-sistent or conflicting statistical information that is resolved by the method X  X  ability to consolidate statistical informa-tion. The table also shows that the performance of signal detection varies across outcomes X  X upporting the design and modeling decision to treat each outcome separately. The rel-ative improvement ranges from 20% for the outcome X  X cute myocardial infarction, to an improvement of 56% for acute renal failure, with an average improvement of 40%. Signal detection accuracy ranges from AUC=0.76 for acute myocar-dial infarction to AUC=0.94 for acute renal failure, with an average AUC=0.87 X  X  level of accuracy considered sufficient in other widely used clinical diagnostic tests (e.g., prostate cancer, and breast cancer)[18]. Similar performance pat-terns were observed (not displayed) when using the lower bound signal-scores (Section 2), with performance ranging from AUC=0.78 (myocardial infarction) to AUC=0.96 (re-nal failure), and an improvement ranging from 9% (myocar-dial infarction) to 62% (acute renal failure).

The summary statistic  X  y j underlying the results displayed in Table 3 is the one proposed in Eq. 3(b) (inverse-variance weighting), as it resulted in greater signal detection accuracy than the alternative possibility (equal weighting of the data sources), which averaged a 35% improvement over each data source . We note however that this type of weighting (Eq. 3(b)) could pose a problem when one of the data sources be-ing considered is much larger than the others, in which case it may dominate the weighting for certain associations. We also note that using  X  j as the combined signal-score resulted in greater accuracy by an average of 5% over using just  X  y (also a possibility), showing that the modeling approach, the notion of Bayesian shrinkage and that of allowing signals to borrow support from each other, is beneficial.

To test if the improvements were statistically significant we computed a one-sided p-value for the hypothesis that the difference between the performance (AUC) of the com-bined signals and those of the individual data sources was is greater than 0. The tests were computed using the R pack-age pROC[17], which uses a non-parametric test for corre-lated ROCs or bootstrapping. To ensure the p-values were computed based on a large enough sample of signal-scores, and to get a single answer representing all outcomes, we pooled the signal associated with each outcome into a single set of signal-scores, producing three sets of signals-scores for the three signal detection approaches that were tested against each other. The p-value for the difference between the combined signals and those of AERS was 0.001, and for healthcare was 5.9e-08, demonstrating that the improve-ments were statistically significant at the standard levels commonly used (e.g. p-value &lt; 0.05).

Given that there are currently no pharmacovigilance guidelines recommending appropriate thresholds or appro-priate sensitivity-specificity tradeoffs, we do not provide threshold-dependent performance metrics, as those would currently carry little value. Nonetheless, the information provided through Fig. 2 X  X  comparison of ROC curves X  may be used as a substitute from which point-wise perfor-mance values may be extracted. Importantly, Fig. 2 depicts a general pattern of containment between the ROC curves of the combined signal-scores and those of the individual sources (with the exclusion of acute myocardial infarction), suggesting that the combined signal-scores provide greater accuracy at any single point of sensitivity, specificity, or signal-threshold that may be chosen in practice. It appears that for the case of myocardial infarction a lower tolerance for false positives will lead at a certain point to no improve-ment over the healthcare-based signal-scores. However, for the region of false positive rates likely to be tolerated in practice (discussed next) the performance of the combined signal-scores for acute myocardial infarction is still greater.
The partial-AUC is often used as an alternative measure to the full AUC when the goal is to consider only certain ranges of sensitivity or specificity which are deemed clini-cally relevant. The partial-AUC is simply the area under a portion of the ROC curve, often defined as the area between two false positive rates. A partial-AUC at 0.3 false positive rate (PAUC30), i.e., partial-AUC when specificity &gt; 0.7, has been previously suggested as a potential region of clinical rel-evancy for signal detection assessment[18]. Table 4 provides a comparison of signal detection accuracy among the indi-vidual and combined signal-scores based on PAUC30. The table shows that also in this restricted ROC space the pro-posed method provides greater accuracy across all outcomes, and similar levels of improvement, averaging 33%. The rel-ative improvement is defined as for the full AUC, but in this Figure 2: ROC curves of signal-scores generated from AERS, healthcare data, and the combined methodology. case the largest possible AUC is 0.3 so the denominator in Eq. 12 is changed accordingly (0.3 replaces the value 1). The p-values for the partial-AUC improvement (computed as for the full AUC) over AERS and healthcare were 0.001 and 2.171e-09 respectively.

Another important finding demonstrated through Table 3 is that the performance of the proposed methodology is comparable and on average slightly better than the poten-tially competing classification/prediction algorithms evalu-ated, which unlike the proposed methodology require labeled examples to train (fit) a model. Given the difficulty associ-ated with identifying large sets of drug-outcome pairs with validated causative relationships that would be necessary to apply these alternative methods, we argue that approaches such as the proposed, that may be perceived as unsupervised learning, would be advantageous.

Similar to other applications that require optimization, the success of the proposed methodology depends on the ability of the EM algorithm to identify the correct solu-Table 4: Comparison of signal detection accuracy based on partial-AUC at 0.3 false positive rate Outcome AERS Healthcare Combined Improv.
 ARF 0 .17 0.17 0.24 51% GIB 0.22 0.07 0.25 39% ALI 0.12 0.16 0.20 34% AMI 0.09 0.06 0.11 10% Avg. 0 .15 0.11 0.20 33% tions (hyper-parameters of the model) and on its conver-gence properties. Fig. 3 displays the solution spaces (sur-face plots) of the hyper-parameters ; to be estimated by the EM algorithm for each outcome. The figure sug-gests that the solution space is concave across all outcomes, and therefore that the solutions identified by the EM al-gorithm should correspond to a global maxima, and also should not be sensitive to the initial EM values (the concav-ity of the solution space is data dependent and cannot be proved analytically). Using arbitrary initial EM values set to = 0 ; = 1, Fig. 4 demonstrates that convergence is rapid, with at most 11 steps required to arrive at a solution (convergence tolerance=10 9 ). Although convergence does not appear to be an issue with the current data, using the initial EM values suggested in Eq. 10 resulted in a faster convergence by a factor of almost 2. Figure 3: Surface plots of the hyper-parameters' ( ; ) solution space, estimated by the EM algorithm. The color pallet and contours re ect varying values of log likelihood with `hotter' colors corresponding to larger likelihood. Figure 4: Convergence of the EM algorithm used to estimate the hyper-parameters ; for each outcome.
The synthesis of evidence from multiple streams of infor-mation has been an integral part of pharmacovigilance. Yet, it is currently carried out by human experts on an ad hoc basis, in a rather qualitative manner, and usually after a signal is generated. Most signal detection strategies are cur-rently based on data associated with a single source. Given the relative maturity of surveillance based on spontaneous reporting, the recent progress made in the use of healthcare data, and the expectation that the two sources may com-plement each other along different dimensions, it appears that the time is ripe to consider computational approaches to combine information from these two types of information sources and possibly other sources.

This paper presents the first effort to explicitly and com-putationally combine ADR signals from spontaneous report-ing systems and healthcare data to improve the accuracy of uninformed hypothesis-free signal detection. Improving the accuracy of ADR signal detection is paramount to data min-ing for pharamcovigilance.

The methodology was applied to signals generated by es-tablished methods from two large databases of high qual-ity, and is evaluated using a large thoroughly validated gold standard; thus minimizing concerns related to the reliability of data and resources used in this work. Through different analyses we demonstrated that the proposed methodology leads to a statistically significant and substantial improve-ment of signal detection accuracy over the use of each source independently. We also showed that the improvement is replicated over analysis of different outcomes, and therefore may generalize to other clinical outcomes. The methodology is relatively simple and efficient to compute, and is gener-alizable to the inclusion of additional data sources with no modification. Its performance was shown to be compara-ble to alternative approaches based on supervised learning, which unlike our approach, have the limitation of requiring labeled training samples, whose availability is limited. The methodology can be used to analyze specific outcomes, or it can be used as an add-on to routine data mining runs cur-rently performed by various organizations that have access to both types of data sources, e.g., the FDA through the sen-tinel network. The public availability of SRS such as AERS also mak e this methodology available to a wider range of entities that specialize in, and process, large quantities of healthcare data.

Finally, it is possible that the use of different combina-tions of data and signal generation algorithms will lead to different performance characteristics or possibly a different conclusion. Therefore further research is needed to fully un-derstand the dependence of the performance, and the suc-cess of the paradigm, on the variety of data and methods that can be used. Likewise, additional research is required to investigate methodological extensions and the potential inclusion of other healthcare databases into the framework. This research was supported in part by NIH grant U54-HG004028 for the National Center for Biomedical Ontol-ogy, the FDA X  X  ORISE Fellowship and by the Department of Medicine at Stanford University. We extend our gratitude to Oracle X  X  Health Sciences Division for supplying us with the AERS data and analysis software, and to David Madi-gan and Patrick Ryan from the OMOP for providing con-structive suggestions and guidance on the use of the OMOP results set. [1] Adverse Event Reporting System. [2] Food and Drug Administration Amendments Act [3] Medical Dictionary for Regulatory Activities [4] Observational Medical Outcomes Partnership [5] Oracle Health Sciences. [6] S. Ahmad. Adverse drug event monitoring at the food [7] A. Bate and S. Evans. Quantitative signal detection [8] D. Classen, S. Pestotnik, R. Evans, J. Lloyd, and [9] P. Coloma, M. Schuemie, G. Trifiro, R. Gini, [10] P. M. Coloma, G. Trifiro, V. Patadia, and [11] A. P. Dempster, N. M. Laird, and D. B. Rubin. [12] W. DuMouchel. Bayesian data mining in large [13] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. [14] R. Harpaz, W. DuMouchel, N. H. Shah, D. Madigan, [15] J. Lazarou, B. Pomeranz, and P. Corey. Incidence of [16] R. Platt, M. Wilson, K. Chan, J. Benner, [17] X. Robin, N. Turck, A. Hainard, N. Tiberti, [18] P. B. Ryan, D. Madigan, P. E. Stang, [19] P. Stang, P. Ryan, J. Racoosin, J. Overhage, [20] W. Stephenson and M. Hauben. Data mining for [21] G. Trifiro, A. Pariente, P. M. Coloma, J. A. Kors, [22] D. Wysowski and L. Swartz. Adverse drug event
