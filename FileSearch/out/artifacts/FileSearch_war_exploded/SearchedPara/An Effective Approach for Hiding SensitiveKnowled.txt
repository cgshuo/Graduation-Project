 With the wide application of computer and the Internet, data publishing is easier than before. However, privacy concerns have limited the data publishing. Recent efforts have been made to address the problem of privacy preservation in data publishing. But they mainly focus on preserving data privacy, i.e., preventing the disclosure of raw data.

Some studies consider to limit the disclosure of raw data, meanwhile attempt-ing to minimize the impact on knowledge minable from the published database. These studies maintain the data privacy by perturbing raw data with some kind of random noise. At the same time, they allow to reconstruct the data distribu-tion at an aggregate level, and thus retain the accuracy of mining results [2, 9, 11]. Other studies [7, 8] aim at preventing from re-identification of individuals or en-tities when the published data contains sensitive information of individuals or entities. These studies mainly preserve the anonymity of individuals or entities by applying generalizations and suppressions on quasi-identifiers in raw data, before the data are published.

In this paper, we address another aspect of privacy preservation in data pub-lishing. That is, we consider some of the knowledge implied by a dataset as sen-sitive information, instead of data themselves. These sensitive knowledge need be hidden before publishing the dataset. For example, consider a data owner publishes his data on the Internet. A malicious user may acquire the sensitive knowledge by mining the published data, while the data owners do not want to open those knowledge to the public.

In particular, we consider that the data are stored in a transaction database, and the knowledge is represented in the form of patterns. Some of the patterns contain sensitive information, which cannot be disclosed. We propose an effec-tive approach, called SanDB , for protecting the sensitive patterns during data publishing. SanDB hides sensitive patterns by a procedure of data sanitization. We assign a threshold for each sensitive pattern, and let the data owner con-trol the degree of sensitive pattern protection. At the same time, we attempt to minimize the impact on non-sensitive patterns in the published dataset. The ex-perimental results show that our approach is much more effective than previous research.

The remainder of this paper is organized as follows. We introduce related work in Section 2, and define the problem of our research in Section 3. Then, we present a special data structure, called Weak Pattern Tree (or WPTree in short) in Section 4, and describe the details of our SanDB algorithm in Section 5. With the help of WPTree , SanDB can fast identify appropriate transactions and items, sanitize them from database, thus hide sensitive knowledge. Finally, we conclude our work in Section 7. Studies closely related to our work can be classified into two categories: sanitization-based approaches and obscurity-based approaches.

Sanitization-based approaches prevent the disclosure of sensitive rules through removing or adding data items in raw data. Data sanitization was first proposed by Atallah [3]. They proved that finding an optimal solution for data sanitiza-tion was NP-Hard by reducing the data sanitization problem to the hitting-set problem. Dasseni [4] addressed the problem of hiding association rules by san-itizing the data to modify the support and confidence of rules. Oliveira and Za  X   X ane [10, 12] further proposed some better heuristics of data sanitization for protecting from the discovery of sensitive frequent itemsets. Their best algorithm is called SWA , which sanitizes a transaction database by removing items from transactions. These removed items have higher frequencies in the set of sensitive frequent itemsets.

Obscurity-based approaches were proposed by Saygin [5, 6]. Instead of re-moving or adding data items, obscurity-based approaches selectively replace the values of data items with unknowns to obscure the sensitive rules, thus to hide sensitive rules from the published data. The rationale underlying obscurity-base approaches is to increase the uncertainty of the supports and confidences of sensitive rules. However, obscurity-based approaches may have the risk of dis-closing sensitive knowledge. A malicious attacker may reconstruct the raw data from the published data, then obtain sensitive rules by mining on the data reconstructed. 3.1 Basic Concepts ( T id , T items ), where T id is the unique identifier associated with the transaction T ,and T items is a set of items from I , i.e., T items  X  I . A transaction database D is a set of transactions.

An itemset X is a subset of items I , X  X  I .Ifthereare k items in X ,wesay that the length of itemset X is k ,or X is a k -itemset .Atransaction T contains itemset X if and only if X  X  T items .The support of itemset X is the percentage of transactions in database D that contain X , denoted SUPP X . For facility, we an itemset is also called pattern in this paper. 3.2 The Problem We consider some of the knowledge implied by a dataset as sensitive information in this paper. These sensitive knowledge need be hidden before publishing the dataset. At the same time, there are some important non-sensitive knowledge we may want to release in the published dataset.

Particularly, we consider the data are stored in a transaction database, and the knowledge is represented in the form of patterns. Our problem is stated as follows. Let D be a transaction database, P S and P K are two sets of patterns in D . When publishing D , we need hide P S and release P K . Specifically, we transform D to D by data sanitization, and release database D , meanwhile attempting to minimize the impact on SUPP q ( q  X  P K ).

For each p  X  P S ,weprovideathreshold  X  p , which is controlled by the data owner. Let SUPP p and SUPP p be p  X  X  support in D and D , respectively. When SUPP p  X  (  X  p  X  SUPP p ), we say p is hidden from D .Thethreshold  X  p ex-presses the degree of sensitive knowledge hiding. When  X  p = 0%, the pattern p is completely hidden from D .When  X  p = 100%, p is not any longer required to be hidden.

For facilitating our discussion, we call P S sensitive pattern set , P K released pattern set ,and  X  p disclosure threshold of pattern p . We assume that P S , P K and  X  p are identified by domain experts, according to the requirements of specific applications. Furthermore, we assume that P S and P K are disjoint. That is, p, p  X  ( P S  X  P K ).

We focus on a special form of data sanitization in this paper. That is, we get the published database D by removing some items from transactions in D . Intuitively, for hiding  X  p  X  P S , we only need consider the transactions con-taining p (called sensitive transactions ), and remove from them the items also contained in p (called sensitive items ). We give the formal definitions of sensitive transactions and sensitive items below.
 Definition 1 (Sensitive transaction). Let T be a transaction in D .If p  X  P S and p  X  T items ,then T is a sensitive transaction of p .Thesetof p  X  X  all sensitive is SUPP p .
 Definition 2 (Sensitive item). Let p  X  P S ,and T  X  T S p .Foritem s  X  p ,if s  X  T The goal of our research is to hide  X  p  X  P S , meanwhile attempting to minimize the impact on SUPP q ( q  X  P K ) after data sanitization. Therefore, it is important to identify appropriate sensitive transa ctions, and remove appropriate sensitive items from them. We show this with an example given below.
 Example 1. In Fig. 1, we have a transaction database D shown at the left hand, P
S and P K at the right hand. Let p 1 = bc, p 2 = be ,and  X  p 1 =  X  p 2 = 50%. The good choice is to remove item b from T 8 .Thathidesboth p 1 and p 2 ,andthere is no impact on SUPP q ,where q  X  P K .

Before giving the details of our approach, we first introduce a special data structure, called Weak Pattern Tree ,or WPTree in short. We use it to organize the patterns, and thus fast identify appropriate sensitive transactions and items. 4.1 Definition Given a transaction database D , our approach hides a sensitive pattern by re-moving its sensitive items from the transactions in D . For example, let p = xy be a sensitive pattern. We hide p by removing item x or y from p  X  X  sensitive transactions in D . An observation is that except for p , only the supports of the patterns containing x or y may be affected. We call them weak patterns .The formal definition of weak pattern is given below.
 Definition 3 (Weak pattern). Let p be a pattern in D .If  X  p  X  P S and p  X  p =  X  , we say that p is a weak pattern. Theorem 1. Given sensitive pattern set P S , database D is sanitized by re-moving sensitive items of p  X  P S .Let D be the result database, SUPP p and SUPP p be p  X  X  support in D and D respectively. If p is not a weak pattern, then SUPP p = SUPP p .
 Proof. Since p is not a weak pattern, then  X  p  X  P S ,p  X  p =  X  . Therefore, p does not contain any sensitive item. The data sanitization considered only removes sensitive items from D .Thus, SUPP p = SUPP p .
 According to Theorem 1, we only need consider weak patterns when sanitizing D . For q  X  P K ,if q is not a weak pattern, we filter it from P K .Noticethat  X  p  X  P S is a weak pattern. Furthermore, we can determine a set of weak patterns just according to P S .Weuseadatastructure,called weak pattern tree , to organize the weak patterns. The definition of weak pattern tree is given below.
For facility, we order the set of items I ascendingly, denoted I O .  X  i, j  X  I O ,i  X  j if and only if (1) i is a sensitive item, and j is not; or (2) Both i and j are sensitive or non-sensitive items, and i  X  j in ascending lexicographic order. Definition 4 (Weak Pattern Tree (WPTree)). Each node in a WPTree is labelled by an item. The root of a WPTree is labelled by a special item  X  .The children of a WPTree node are sorted in the order of I O .EachWPTreenode N represents a weak pattern p N , where items are in the order of I O . The weak pattern p N can be obtained by concatenating the label items of nodes along the path from root to node N (except for item  X  ).
 Definition 5 (S-node, R-node). Let N be a WPTree node. If the path from root to node N represents a sensitive pattern, we say that node N is a sensitive node, or S-node in short. Similarly, if the path from root to node N represents a released pattern, we say that node N is a released node, or R-node in short. WPTree has some nice properties, which can help us to prune the tree during traversing a WPTree. We give the properties below, and describe how to prune a WPTree during tree traverse in Section 5.2.
 Property 1. Let N i be a WPTree node (labelled by item i ). If a WPTree node N j (labelled by item j ) is a descendant of N i ,then i Property 2. Let N i be a WPTree node (labelled by item i ). If a WPTree node N j (labelled by item j ) has the same parent as N i ,and N j is one of the right siblings of N i ,then i  X  j .
 For facilitating the traverse of WPTree, we augment each node with parent-link . The parent-link of a node points to its parent. With parent-link, we can easily get the weak pattern represented by a WPTree node. If a WPTree node is labelled by a sensitive item, we also argument it with node-link .The node-link points to next node labelled by the same sensitive item. For a WPTree, we keep a header table of node-links, denoted HLink . Each entry of the header table has two fields: a sensitive item, and a node-link to the first WPTree node labelled by that item. For an item i , its entry in the header table is denoted as HLink i . 4.2 Constructing Weak Pattern Tree Given sensitive pattern set P S and released pattern set P K , the algorithm for constructing weak pattern tree is shown in Fig. 2.

In algorithm Construct WPTree , we first filter non-weak patterns from P K , since they are not impacted by our data sanitization. Then, we initialize the WPTree by constructing a root node labelled by  X  , and an empty head table of one by one. For an item i  X  p , if we cannot find its corresponding WPTree node, we then create a new node N i ,andadd N i as a child of the current WPTree node. If item i is a sensitive item, we also insert N i into the node-link HLink i . Finally, if p  X  P S (or p  X  P K ),theWPTreenodecorrespondingtoitem i n is a S-node (or R-node).
 Example 2. Continue with Example 1. Consider the database D , sensitive pat-tern set P S and released pattern set P K in Fig. 1. The weak pattern set is { ab,ac,bc,bd,be,ce,de,ef,eg,efg } ,and I O =( b, c, e, a, d, f, g ) in ascending or-der. Its weak pattern tree is shown in Fig. 3. The black nodes in the tree are S-nodes, and the square nodes are R-nodes. For hiding  X  p  X  P S , we first find its sensitive transaction set T S p ,thenremove appropriate sensitive items from transactions in T S p , thus decrease SUPP p be-low disclosure threshold  X  p . The key steps of our algorithm are described below. 5.1 Finding Sensitive Transaction Set we read each transaction from D , and represent it in the form of n -dimensional vector. Suppose there are m transactions in D ,then D can be represented in a m  X  n matrix, denoted Mat Mat D [ k, j ]=1.Otherwise, Mat D [ k, j ] = 0. For example, for the transaction database in Fig. 1, its matrix representation is shown in Fig. 4.
The matrix representation of transaction database can facilitate us to find the sensitive transaction set of a pattern p  X  P S . Consider a sensitive pat-i 5.2 Identifying Victim Item When the length of a sensitive pattern p is larger than one, there are more than one sensitive items in transaction T  X  T S p . For sanitizing T , it is enough to remove only one of the sensitive items from T .Wecallthatitem victim item .
In order to identify victim item, we assign a score for each sensitive item of p in T . The definition of item score is given below.
 Definition 6 (Gain, Loss, and Item score). Let p  X  P S ,and T  X  T S p .For T 1) . The sensitive item with the highest score is T  X  X  victim item for p . The algorithm for identifying victim item is shown in Fig. 5. Given sensitive pattern p ,and T  X  T S p sorted in the order of I O , algorithm Identify VItem calculates the score of each sensitive item in T , and chooses the one with the highest score as T  X  X  victim item for p . For a sensitive item i m ,welocateWPTree node N m labelled by i m with node-link HLink m , and use the parent-link to get the pattern p m represented by N m .If p m  X  T items ,wethencalculate i m  X  X  gain and loss by calling algorithm Calc GainLoss , which is shown in Fig. 6. In algorithm Calc GainLoss ,if N m is a S-node, we increase the gain by one. Otherwise, if N m is a R-node, we increase the loss by one. Then, we recursively traverse the sub-WPTree rooted at node N m , and accumulate the values of gain and loss. When traversing the WPTree, we do tree pruning according to WPTree X  X  properties in Section 4. At line 4 of algorithm Calc GainLoss ,we prune a WPTree node X  X  children according to Property 1. At line 6, we prune a WPTree node X  X  right siblings according to Property 2. 5.3 The SanDB Algorithm in T S p . Given disclosure threshold  X  p , we just need meet SUPP p  X  (  X  p  X  SUPP p ), where SUPP p and SUPP p are p  X  X  support in D and D , respectively. Sanitizing more transactions may have greater impact on the support of q  X  P K .
Particularly, we select transactions from T S p according to transaction score , and remove the corresponding victim item in a chosen transaction. The definition of transaction score is given below.
 Definition 7 (Transaction score). Let p  X  P S , T  X  T S p ,and i v be T  X  X  victim item for p . The score of transaction T is the score of item i v , that is, Score T = Score v .
 In practice, a database may have so many transactions that the whole database cannot be held in memory. Therefore, our algorithm reads k trans-actions each time. We call k transaction buffer size . The details of our SanDB Algorithm is shown in Fig. 7.

SanDB first constructs a WPTree according to P S and P K , then reads k transactions from D each time, and represents the k transactions in a matrix. k transactions, and calculate the victim item and the score for each transaction T  X  T S k may have different victim items. We then sanitize (1  X   X  p )  X | T S k p | transactions from T S k p in the descending order of transaction score. Finally, we write the k transactions into D .
 In this section, we evaluate the performance of our algorithm SanDB ,andcom-pare it with SWA . Because as reported in [10], SWA is better than other algo-rithms in previous related work. SWA chooses an item with higher frequency in sensitive patterns as victim, and sanitizes sensitive transactions in ascending order of transaction size. All the experiments are performed on a 733MHz Intel Pentium III PC with 512MB main memory, running Red Hat Linux 9.0.

We use a synthetic dataset, T40I10D100K, which is generated by IBM data generator. The generation procedure is described in [1]. In the synthetic dataset, there are 1000 different items, and 100 K transactions. The average size of trans-actions is 40 items. We choose 10 patterns from T40I10D100K as sensitive pat-tern set P S , and measure the effectiveness of algorithms by varying transaction buffer size k , disclosure threshold  X  p , and the size of released pattern set P K . We cho ose P K by applying Apriori [1] on T40I10D100K with some minimum support threshold  X  ,and  X  p  X  ( P S  X  P K ) is removed from P K .
 The effectiveness of algorithm is measured as follows. We first use SanDB or SWA to transform the synthetic dataset into the published database D . Then, we mine on D by Apriori with the same  X  as the one for generating P K .The mined result is denoted P K ,and  X  p  X  P S  X  P K is removed from P K .Wemeasure algorithm X  X  effectiveness with the metric P attLoss = |{ p | p  X  P K ,p /  X  P K }| , i.e., the number of patterns in P K but not in P K . An algorithm with smaller P attLoss is more effective.
 In the first set of experiments, we measure the effectiveness of SanDB and SWA with different transaction buffer size k . We fix disclosure threshold  X  p = 20% for each p  X  P S . The released pattern set P K is generated by applying Apriori on T40I10D100K with minimum support threshold  X  =1%.Thereare 65236 patterns in P K . We vary transaction buffer size from 1000 to 20000, and measure P attLoss for SanDB and SWA , respectively. The results are shown in Fig. 8(a). As it can be seen, the P attLoss of SanDB is roughly half of that of SWA in various settings of transaction buffer size.

In Fig. 8(b), we report the experimental results when varying the size of released pattern set. The disclosure threshold is fixed as  X  p = 20% for each p  X  P released pattern sets by applying Apriori on T40I10D100K with different  X  . Specifically, we set  X  =1% , 1 . 2% , 1 . 4% , 1 . 6%, and the corresponding sizes of released pattern sets are 65236 , 19412 , 8293 , 4591, respectively. As the size of released pattern set decreases, the P attLoss is reduced for both SanDB and SWA . However, for a large released pattern set, the performance of SanDB is much better than that of SWA .

The effect of disclosure threshold on P attLoss is shown in Fig. 8(c). In this set of experiments, we fix the transaction buffer size k = 10000. The released pattern set P K is generated by applying Apriori with  X  =1%.Thesizeof P
K is 65236, fixed in this set of experiments. We let all p disclosure threshold  X  p , but vary the value of  X  p from 0% to 30% in different experiments. A smaller disclosure threshold means higher degree of sensitive knowledge protection. That is, more sensitive transactions need be sanitized. Particularly, for sensitive pattern p with  X  p =0%, p will be completely hidden from the published dataset. The experimental results in Fig. 8(c) show that the P attLoss of SanDB is dramatically less than that of SWA for each settings of disclosure threshold. In this paper, we address the problem of privacy preservation in data publishing, where some of the knowledge implied by a dataset are regarded as private or sensitive information. In particular, we consider that the data are stored in a transaction database, and the knowledg e is represented in the form of patterns. We have presented an effective data sanitization algorithm, called SanDB ,for hiding a set of sensitive patterns, meanwhile attempting to minimize the im-pact on the released patterns in data publishing. The experimental results have shown that SanDB can achieve significant improvement over the best approach presented in the literature.

