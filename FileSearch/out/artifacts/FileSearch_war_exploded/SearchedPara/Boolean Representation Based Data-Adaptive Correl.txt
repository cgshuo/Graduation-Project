 Correlation analysis is a basic problem in the field of data stream mining. Typical approaches add s liding window to data streams to environment. We propose a Bool ean representation based data-adaptive method for correlation an alysis among a large number of time series streams. The periodical trends of each stream series to are monitored to choose the most suitable window size and group the series with the same trends together. Instead of adopting processing is realized by simple Boolean operations. Both the theory analysis and the experime ntal evaluations show that our method has good computation efficiency with high accuracy. H.2.8 [ Database applications ]: Data mining General Terms : algorithms, theory, performance Keywords : Data-adaptive, correlation analysis, Boolean representation, time series streams Data streams have received considerable attention in various streams [4, 6, 8, 11, 17, 20, 21]. Here we focus on fast correlation analysis among a large number of time series streams. Correlation analysis is an important technology in the field of time processing techniques which analy ze the series online and updates the data dynamically. Current research focuses on how to add stream features to previous anal ysis technology. Especially in the rapidly and efficiently is highly concerned. challenging task because the data stream is always burst and endless. Lots of work has been done about how to monitor thousands of data streams [16, 17, 18, 20]. But all of these methods are based on complex transformation which transforms the original sequence into simple summarization, then computes the correlation by pair-wise way which leads to tremendous pairs of series have correlations at some certain time. Typical approaches use sliding wi ndow on data streams to get the However, in practice, users have no prior knowledge about the correlations in a certain window size may have no correlative advance may lose some useful re sults with different window sizes. How to choose the optimal window size to capture the hidden correlations is a very challenging job. Figure 1. Stock data (open price from several companies) example. Figure 1 shows the open price data of some companies from stock exchange in China. A stock broker may register many requests such as  X  X otify the client which two stocks are correlated with a correlation value above 0.9 during the recent one-hour pairs of series to give the results whenever the corresponding conditions are evaluated true. However, from Figure1, we can see that most pairs of series have no correlations at all. There will be have different periodical trends, fo r example, two stocks may have correlation in certain half an hour which will never be detected by one-hour period. Sometimes, such co rrelations in other time scales will be much more valuable than the ones with fixed window length given by users, who ha ve no prior knowledge about the stream feature. We solve these problems by adopting the data-adaptive method, which choose the optimal window sizes by the stream series Boolean sequences. By simple Boolean operations we can get the main periodical trends and then we group some stream series together with similar periods. With each group, we can quickly pair-wise method. Our major contributions are: gives a brief conclusion. the DFT (Discrete Fourier Transform) to extract features for indexing. Follow-up work examin ed several related problems, including subsequence matching [2], the Adaptive Piecewise Constant Approximation (APCA) [3], the Piecewise Vector Quantized Approximation (PVQA) [4], Discrete Wavelet Transform (DWT) [5] and DAWA [6]. Feature extraction, summarization and compression are cl osely related, with powerful random projections [10]. Ratanama hatana et al. [11] proposed a new technology for time series presentation, which transforms the original series into binary sequences for similarity search and clustering, but it X  X  just suitable fo r time series without considering stream processing Much of stream mining work ha s focused on finding interesting Domingos et al. [13] presented an algorithm for constructing online and offline components. Statstream [16] uses the DFT to summarise streams within a finite discovering lag correlations among multiple streams. The focus is highest peak in the cross-correlation functions between all pairs of first doing dimensionality reducti on with random projections, and then periodically computing the SVD. MUSCLES[19] applies multi-variation linear regression on multiple co-evolving time sequences to do forecasting. SPIRIT [20] focus on finding patterns, series. A very recent and interesting application of the same principles is on correlation analysis of complex time series through change-mining includes approaches for periodic pattern discovery [24]. A number of the above methods usually require fixed sliding window, meanwhile, they compute all pairs of streams with complex operation. In conclusi on, none of the above methods satisfy the requirements in the introduction: no pair-wise way and data-adaptive window size. In this section we give intuitive definitions of the problems we are trying to solve. We also introduce some definitions needed later. Time series streams can be re garded as continuous, equal time interval, infinite sequences. In pr actice, we just compare the recent window will be updated continuously. Our goal is to monitor m stream time series, X streams should satisfy the following requirements. 1. No pair-wise way: Lots of jobs are done to compute the 2. Data-adaptive: Many appro aches assume a fixed-length solve is the following (addressed in Section 4.1): 
Problem 1 . Given m stream series X 1 , X 2 ... , X at this window length without complex pair-wise calculations. In practice, however, we do not have a prior knowledge about the requirement, we want to solve the following problem (addressed in Section 4.2): 
Problem 2 . Given m stream series X 1 , X 2 ... , X m window sizes for each series, then analyze the correlations among the series with simila r optimal window sizes. traditional Pearson formula. 
Definition 1 (Correlation). Given two stream series X and Y are { x correlation coefficient of these two series is: correlation threshold be  X  , if |  X  | &gt;  X   X  correlation. follows in order to compute the  X  incrementally by maintaining the sum, square sum and inner product of each series. where, auto-correlation function (ACF), which examines how similar a sequence is to its previ ous values for different k lags: In practice, we also use auto-correlation coefficient (ACC) to represent the standard auto-correlation: where know that -1 X  ACC( k )  X 1 , when k =0, ACC( k )=1. 
Definition 2 (Period detected by ACC). A sequence X has a period k , if ACC ( k ) is above a threshold  X  x , for example and is actually the earliest local maximum. Figure 2. Periodic detection by auto-correlation coefficient From Figure 2, we can see that multiples of the basic periods will need to discover the earliest local maximum which is above some We restrict the maximum lag k to be n/ 2. Fourier Transform ( FFT ), it will also be unrealistic for time series streams. In the next section, we will propose a novel method which transforms the complex calculations into simple Boolean complexity with high accuracy. Table 1 gives the symbols and defi nitions used in this paper. In many applications, only a few pa rts of series have correlations. There will be huge computation cost by na X ve method which compares every two series. To address the problem 1 in Section 3, we propose a new technique calle d HBR (Hierarchical Boolean Representation) for time series st reams. This method transforms every stream series into the Macro-Boolean series and the Micro-Boolean series two levels, and a smaller candidate set which includes correlation pairs of series can be easily gained by simple bit operations. HBR can not only save huge storage space, but also large. works by replacing each real valued data with a single bit. Boolean series representation occupies less space memory because very efficient and effective. For the purpose of accommodating the characteristic of data streams, Boolean representation provides processing. First, we use the clipping technology [11] to transform the original stream series into Macro-Boolean series which can reflect the main trend of the original data streams. { w 1 ,..., w t ,..., w n }, where From Figure 3 we can see that the Macro-Boolean series can only reflects the main trend of original stream series without any Boolean series representation method. { b , b 2 ,..., b l }, where where T denotes the sampling period. Micro-Boolean representation mainly reflects the change trend of the original series. As illustrated in Figure 4, we can transform the fluctuation in certain duration into one bit, so the change trend of small, the result may be affected greatly by lots of noises, detailed information. 
Definition 3 . Given two stream series B are then the Boolean correlation coefficient of these two series is: We assume the Macro-threshold and the Micro-threshold is  X  respectively, if (, ) two series have Boolean correlation. transformed into simple binary numbers. Without complex pair-wise comparison of original streams series, we just need to operate on the corresponding Boolean sequences with simple Boolean eliminated. which have Boolean correlation will be added into Macro-candidate. Then, we transform every series in Macro-candidate into Micro-Boolean sequences to get the detailed information, and calculate the Boolean correlation to compose the Micro-candidate. the correlation set. The detailed algorithm of HBR is given in Figure 5. 
Figure 5. Algorithm for Hierarchical Boolean Representation In this section, we propose a novel approach based on Boolean behavior of time series streams. The original stream series is period can also be easily gained by simple calculations. { x corresponding Boolean series W is{ w 1 ,..., w t ,..., w From Figure 6 we know that the Macro-Boolean series can be easily gained by comparison operation with the mean of the the detailed information of the stream series as every tick is just 0 auto-correlation method. 
Figure 6. Macro-Boolean representation of periodical time Definition 4 (Period detected by BAC). A Boolean series W has a earliest local maximum. We can see that BACC curve has almost the same shape with the approximate the according period point discovered by ACC . can reflect almost the same trends as the AC especially about the periodical trends. Figure 7. Comparison of ACC and BACC with sunspot dataset method by Boolean representation (DCBR). Given m stream series X by BAC method. Then, we divide the whole series into several overlapping groups by their periods. similar series together. In one group, each sequence has the adjacent period and one sequence may appear in two groups. We Algorithm: HBR Input: m stream series X 1 , X 2 , ... , X m , with length of n Output: correlation set C. 
Procedure: 1. for i=1 to m do compute the mean value of each series, generate end for 2. Compute the Boolean correlations of m Macro-if (, ) ij w WW  X  &gt;  X  then add  X  X i , X j  X  into Macro-candidate D end if 3. Compute the Micro-Boolean series ( B i , B j ) from all if (, ) ij b BB  X  &gt;  X  then add ( X i , X j  X  into Micro-candidate E 4. Compute the Pearson correlation coefficient if (, ) ij XX  X   X  &gt; then add  X  X i , X j  X  into the correlation set C will make sure that two different sequences in two groups have no correlations because they lack the same period trends. as the optimal window size. In this way, we just need to compare algorithm of DCBR is given in Figure 8. 
Figure 8. Algorithm for data-adaptive correlation analysis In this section we give a theoretical analysis to show the accuracy of the BAC method. Again, we focus on a sequence X . To BAC has very excellent precision. Theorem 1 Let { X t } be standard normal distribution series, E(X t )= 0, D(X t )= 1, u is an arbitrary real number, { W corresponding Boolean series of { X t }, let x assume  X  k =P(W t =1|W t-k =1) and E(W t )=p , then we have: 
Proof. We know that: ()(, ) 21()
EWW P X u X u = X  [()] [()] = X  +  X  X  =+ where 2 2 1 () () exp()
E WW p dt Because E ( W t )= p , D( W t )= p (1-p ), we have 2(1 ) 1 1  X  = X   X   X  = From Theorem 1, we know that  X  k w ,  X  k x have the same monotony interval, and  X  k w has a linear relation with  X  the same trend especially at the period points which are shown as approximate value of  X  k .
 normal distribution series, { W t } is Boolean series of { X arbitrary time t , let W t =w t , V t =v t , we assume is  X   X   X   X  + X  + X  = Proof. From the definition of  X  k , we know that: P(W t = 0 )= 1 -p , P(W t = 0 |W t-k = 1 )= 1 - X  k , we have: (0| 0) 12 1 1 1(1) PW W = + X + X  X  X   X   X  = X   X  From above all, we can obtain: Algorithm: DCBR Input: m stream series X 1 , X 2 , ...,X m , with length of n Output: correlation set C. 
Procedure: 1. for i=1 to m do compute the period P i of each series X end for 2. Divide X 1 , X 2 , ... , X m into s groups G 3. for i=1 to s do compute the mean value end for (| )() (1 ) [1 (1 ) ]
PW w W w  X  X  X   X   X  We assume (,...) ( ) ( | ) ww PW w PWwW w q  X  = X  X  X  X  Then, the maximum likelihood function is:  X  X  X  X + Thus, we have:  X   X   X + X + X  = When ux = , we have p=q =0.5, from (11) we have:  X   X   X  X  X  + = calculation into simple bit operations as follows: thus : 1  X  () 1 From (12) we can see that  X  k  X  is exactly the Boolean auto-can almost get the exact period from the BACC curve by picking the obvious peak points because they reflect the same trends corresponding to the period points in the ACC curve. We can transform complex calculations into simple Boolean operations by (12), which is very efficient in stream environment. binary numbers. This method can yield compression ratios from technique in Micro-Boolean repres entation, HBR is a very simple and efficient representative method in space complexity. HBR also has excellent performance in response time. Given a collection of m series, with each length of n . Time requirement of na X ve method is O ( m 2 n ) by computing each pair of all series, and applications, the main cost is the computation of huge amount pairs with no correlations among th e whole series. HBR transform between Boolean series is just simple bit operations which can be neglected and the correlation co mputation in candidate is just very small after filter operations by bit comparison, the time complexity of HBR is approximately O ( mn ). Then we need k times XOR operation between binary sequences which can be neglected. Moreover, we can also speed up the operation to sum the bits. The al gorithm to count the bits is O ( n ). However, we can reduce the calculation cost by using shift using a lookup table to find the number. This mechanism makes the calculation much faster than ordinary counting. Therefore, the BAC method for periods detection just need O(n) time. performed experiments on real and synthetic datasets on a 2.4GHz Pentium IV PC with 512 MB of main memory. The experiments were designed to answer the following questions: 1. How well does HBR spot the correlations for different 2. How successful is BAC is it in detecting the periodical 3. How does BAC scale with the sequence length in terms of The sequences are composed by the following two datasets: z Random : the dataset consists of 1000 sequences generated z Stock : daily open price of 500 companies from the stock We will evaluate the speed and the precision of HBR by the exact method will be compared with different number of streams. Then, we will show the precision and the execution time of HBR with different threshold. Figure 9 shows the number of streams vs. the wall clock time with the response time of HBR is much faster than the exact pair-wise two parts: transformation and correlation detection. The time We can see that HBR is much more suitable for stream processing in an approximately linear way. 
Figure 9. Comparison of execu tion time between HBR and 
Figure 10. Execution time of transformation and correlation The wall clock time is the aver age of the execution time to grow, the execution time also increases. Instead of the O(m exact pair-wise method requires, HBR can achieve a dramatic reduction in computation time. This experimental result shown in compute the correlations. From the previous section, we know that the correlation threshold such as  X  w and  X  b are very important for the precision of the HBR calculating correlations among 500 seri es with different thresholds. From Figure 11, we know that H BR can obtain a precision of response time is almost the same with the exact method in Figure 12. There will be a tradeoff between the precision and the suitable threshold range to get e fficient processing time with high accuracy in terms of the intrinsic f eature of the original time series. The datasets used are the following: z Synthetic : the dataset consists of sin waves of length z Sunspots : average number of sunspots per month from 1945 z TAO (Tropical Atmosphere Ocean): this dataset contains the Figure 13 shows the estimation of our proposed method for all correlation coefficient and Boolean auto-correlation coefficient approximates the main trends of AC curve for all the datasets. We While the data values fluctuate dramatically with time ticks in real data sets, our method successfully captures the exact periods. Figure 13. Comparison of periods detected by AC and BAC Table 2 shows the precision of the periods captured by BAC in all the datasets. We assume the period captured by ACC is the exact value and the precision will be obtained by making a comparison with the periods between AC and BAC. The results are so perfect that all the precision are above 96%. The above experiments clearly de monstrate that BAC detects the correct periods perfectly. Next we will discuss the processing performance because BAC replaces complex real value calculation with efficient bit operations. Figure 14. Execution time as a function of sequence length Figure 14 compares BAC with th e auto-correlation (AC) method in terms of execution time under different sequence lengths n . We use synthetic and sunspots datasets for this experiment. The period. As the sequence length con tinues to grow, the computation our theoretical discussion in S ection 5.2.2. Theoretically, BAC just requires time O ( n ) to capture the period. We focus on correlation analysis in a large number of time series characteristics: z It discovers correlation among multiple streams in a data-z It efficiently computes the correlations among a large z It completes all the above function by simple Boolean The theoretical analysis shows that our method has high precision and perfect computation complex ity. Moreover, we evaluated our method on several typical datasets , which indicate it can discover correlation much more efficiently and effectively. The authors would like to thank Guoren Wang and Bin Wang for their suggestions in improving the presentation. The research was partially supported by NSF of China under Grants Nos. 60473073, 60503036, 60573090, 60673139, the Fok Ying Tong Education Foundation Award No. 104027, the Program for New Century Excellent Talents in Universities (NCET), and the 973 Program of China under Grant No.2006CB303003. [1] R. Agrawal, C. Faloutsos, A. Swami. Efficient similarity [2] C. Faloutsos, M. Ranga nathan, Y.Mandoponlos. Fast [3] E. J. Keogh, K. Chakrabarti, S. Mehrotra, and M. J. Pazzani. [4] V. Megalooikonomou, G. Li, Q. Wang. A dimensionality [5] K.P. Chan, A.W.C. Fu. Efficient time series matching by [6] M. J. Hsieh, M. S. Chen, P. S. Yu. Integrating DCT and [7] A. C. Gilbert, Y. Kotidis , S. Muthukrishnan, and M. [8] S. Guha, C. Kim, and K. Shim. Xwave: optimal and [9] F. Korn, H. Jagadish, C. Fal outsos. Efficiently supporting ad [10] A. Dobra, M. N Garofalakis, J. Gehrke, and R. Rastogi. [11] C. Ratanamahatana, E. Keogh, A. Bagnall, S. Lonardi. A [12] S. Guha, A. Meyerson, N. Mishra, R. Motwani, and L. [13] P. Domingos and G. hulten. Mi ning high speed data streams. [14] H. Wang, W. Fan, P. S. Yu and J. Han. Mining concept-[15] C. C. Aggarwal, J. Han, and P. S. Yu. A framework for [16] Y. Zhu, D. Shasha. StatStr eam: Statistical monitoring of [17] Y. Sakurai, S.Panadimitriou, J. Sun, C. Faloutsos. Braid: [18] S. Guha, D.Gunopulos, N.Kouda s. Correlating synchronous [19] B. K. Yi, N. Sidiropouls, T. Johnson, H. Jagadish, C. [20] S. Papadimitriou, J. Sun, C. Faloutsos. Stream pattern [21] S. Papadimitriou, P. S. Yu. Optimal multi-scale patterns in [22] T. Ide and K. Inoue. Knowledge discovery from [23] D. D. Muresan and T. W. Parks. Adaptive principal [24] M. G. Elefky, W. G. Aref, and A. K. Elmagarmid. Using 
