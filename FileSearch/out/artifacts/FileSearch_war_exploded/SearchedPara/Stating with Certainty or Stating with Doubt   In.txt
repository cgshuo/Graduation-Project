 1.1 Epistemic Modality, or Certainty Text conveys more than just a writer X  X  proposi-tional context of assertions (Coates, 1987), e.g., X is true . Text can also transfer the writers X  attitudes to the propositions, assessments of possibilities, and the writer X  X  certainty, or lack thereof, in the validity of the truth of the statements, e.g., X must be true, Y thinks that X is true, or perhaps X is true. A statement is qualified in such a way (be-yond its mere referential function) is modal, or epistemically modalized (Coates, 1987; Westney, 1986). a linguistic expression of an estimation of the like-lihood that a certain state of affairs is, has been, or will be true (Nuyts, 2001). Pragmatic and dis-course literatures are abundant in discussions of epistemic modality (Coates, 1987; Nuyts, 2001); mood (Palmer, 1986); evidentiality and evidentials (Mushin, 2001); expressions of doubt and certainty (Holmes, 1982; Hoye, 1997) and hedging (Lackoff, 1972) and hedging in news writing (Hyland, 1999; Zuck &amp; Zuck, 1986). Little at-tempt, however, has been made in natural language computing literature to manually annotate and con-sequently automate identification of statements with an explicitly expressed certainty or doubt, or shades of epistemic qualifications in between. This lack is possibly due to the complexity of comput-ing epistemic interpretations in different pragmatic contexts; and due to unreliability of variety of lin-guistic expressions in Eng lish that could explicitly qualify a statement. Another complication is a lack of agreed-upon and easily identifiable discrete categories on the continuum from certainty to doubt. Several annotation projects have success-fully addressed closely related subjective issues such as private states in news writing (Wiebe, Wil-son, &amp; Cardie, 2005) and hedging in scientific writing (Light, Qiu, &amp; Srinivasan, 2004; Mercer, DiMarco, &amp; Kroon, 2004). Having access to the opinion holder X  X  evaluation of how true a state-ment is valuable in predicting reliability of argu-ments and claims, and stands to benefit the tasks of opinion and sentiment analysis and extraction in natural language computing. 1.2 Certainty Level Scales While there is an on-going discussion in pragmatic literature on whether epistemic modality markers should be arranged on a continuum or in discrete categories, there seems to be an agreement that there are at least three articulated points on a pre-sumed continuum from certainty to doubt. Hoye (1997) suggested an epistemic trichotomy of CER-with Holmes X  (1982) scale of certainty of asser-tions and negations where the writer asserts WITH CERTAINTY that a proposition is true or not true; or that the proposition is PROBABLY or POSSIBLY true or not true. In attitude and affect computational analysis literature, the context of extracting opin-ions from news article corpora, Rubin and col-leagues (2004; 2005) extended Hoye-Holmes models by adding two extremes on the epistemic continuum scales: ABSOLUTE CERTAINTY (defined as a stated unambiguous indisputable conviction or reassurance) and UNCERTAINTY (defined as hesi-tancy or stated lack of clarity or knowledge), and re-defined the middle categories as HIGH CER-TAINTY (i.e., high probability or firm knowledge), MODERATE CERTAINTY (i.e., estimation of an aver-age likelihood or reasonable chances), and LOW CERTAINTY (i.e., distant possibility, see Fig. 1). While Rubin X  X  (2006) model is primarily con-cerned with identification of certainty levels en-coded in explicit certainty markers in propositions, it also takes into account three contextual dimen-sions relevant to news discourse. Perspective at-tributes explicit certainty either to the writer or two types of reported sources  X  direct participants and experts in a field. Focus separates certainty in facts and opinions. Time is an organizing principle of news production and presentation, and if relevant, is separated into past, present, or future. This study uses the above-described conceptual certainty categorization model to annotate a news dataset, and produce a typology of syntactic, se-mantic and lexical classes of certainty markers that map statements into 5 levels of certainty ranging from absolutely certain to uncertain. The dataset consisted of 80 randomly selected articles (from the AQUAINT Corpus of English Texts, distributed by The New York Times Ser-vices in 2000). It constituted a total of 2,243 sen-tences, with 866 sentences in the editorials and 1377 sentence in the news reports (Rubin, 2006). A subset of 10 articles (272 sentences, about 12% of the full dataset) was analyzed by 4 independently trained annotators (excluding the author). The agreement results were evaluated in 2 consecutive intercoder reliability experiments. 2.1 Annotation Process The manual annotation scheme was defined in the codebook instructions that specified the procedures for determining certainty-qualified statements, the order of assigning categories, and exemplified each certainty category (Rubin, 2006). In Experiment 1, three coders received individual one-hour training regarding the use of the annotation scheme, and were instructed to use the original codebook writ-ten in a general suggestive tone. In Experiment 2, the fourth annotator went through a more thorough five-hour training and used a revised, more rigidly-specified codebook with an alphabetized key-word index mapped certainty markers into 5 levels. 
Each statement in a news article (be it a sentence or its constituent part such as a clause) was a po-tential locus of explicit certainty. In both experi-ments coders were asked to decide if a sentence had an explicit indication of a certainty level. If so, they then looked for explicit certainty markers that contributed to that indication. If a sentence con-tained a certainty marker, the annotators were in-structed to consider such a sentence certainty-qualified. The statement was assigned a certainty level and placed in its pr agmatic context (i.e., into one of the categories) within the perspective, fo-cus, and time dimensions (see D2  X  D4, Fig. 1) relevant to the news discourse. Each marker was only assigned one category from each dimension. 2.2 Intercoder Agreement Measures. Each pair of coders were evaluated on whether they agreed regarding 1) the sentences that contai-ned explicit certainty markers; 2) the specific cer-tainty markers within agreed upon certainty-qualified sentences; and 3) classification of the agreed upon markers into one of the categories within each dimension (i.e., level, perspective, fo-cus and time). The sentence and marker agreement measures were calculated with percent agreement. Partial word string matches were considered a marker match but were weight-adjusted. The agreed-upon marker category assignments were assessed in each pair of independent coders with Cohen X  X  kappa statistic (Cohen, 1960), averaged, and compared to the author X  X  annotation. 3.1 Typology of Certainty Markers The content analysis of the dataset generated a group of 1,330 explicitly certainty-qualified sen-tences with 1,727 occurrences of markers. The markers were grouped into a typology of 43 syn-tactico-lexical classes; each class is likely to occur within one of the 5 levels of certainty. The typol-ogy will become a basis for an automated certainty identification algorithm. Among the most fre-quently used certainty markers are central modal auxiliary verbs (e.g., must, could ), gradable adjec-tives in their superlative degree, and adverbial in-tensifiers (e.g., much and so ), while adjectival downtoners (e.g., feeble + NP) and adverbial value disjuncts (e.g., annoyingly, rightly ) are rarely used to express explicit certainty. 3.2 Intercoder Reliability Test Results In Experiment 1, 1) three coders agreed on whether a sentences was modalized by an explicit certainty marker or not 71% of the time with 0.33 Cohen X  X  kappa, on average. 2) Within agreed-upon cer-tainly-qualified sentences, three coders agreed on actual certainty markers 54% of the time, on aver-age, based on a combined count of the full and weight-adjusted partial matches. 3) In the categori-zation task for the agreed-upon markers, the three coders, on average, were able to reach a slight agreement in the level and focus dimensions (0.15 and 0.13 kappa statistics, respectively), and a fair agreement in perspective and time dimensions (0.44 and 0.41 kappa) according to the Landis and Koch (1977) agreement interpretation scale. 
The subsequent Experiment 2 showed promising results in agreement on explicit certainty markers (67%) and overall ability to distinguish certainty-qualified statements from unmarked statements (0.51 kappa), and in the relatively intuitive catego-rization of the perspective dimension (0.65 kappa). 
Although stricter instructions may have imposed a more orderly way of looking at the epistemic continuum, the 5 level certainty boundaries are still subject to individual perceptions (0.41 kappa) and may present difficulties in automation. In spite of its large inventory of certainty markers, English may not be precise enough to reliably distinguish multiple epistemic shades between certainty and doubt. Alternatively, people might be using same expressions but underlying categorization systems for different individuals do not overlap accurately. Recent pragmatic, discourse, and philosophy of language studies in mood and modality call for more comprehensive and tr uer to natural language description of epistemic modality in English refer-ence grammar materials (Hoye, 2005). The latest modality scholarship will undoubtedly contribute to natural language applications such as opinion extraction and sentiment analysis. 
Time categorization in the context of certainty remained a challenge in spite of more vigorous training in Experiment 2 (0.31 kappa). The inter-pretation of the reference point of  X  X he present X  in the reported speech and nested events can be am-biguous in the certainty identification task. Distin-guishing facts versus opinions in combination with certainty identification also presented a particularly puzzling cognitive task (0.16 kappa), possibly due to necessity to evaluate closely related facets of a statement: whether the statement is purely factual, and how sure the author is about the proposition. The possibility of epistemically modalized facts is particularly intriguing. 
This study reported the results of the manual an-notation of texts in written news discourse, and identified the most prominent patterns and regu-larities in explicitly stated markers occurrences in modalized statements. The linguistic means of ex-pressing varying levels of certainty are docu-mented and arranged into the typology of syntactico-semantic classes. This study implies that boundaries between shades of certainty in epis-temically modalized statements (such as probabil-ity and possibility) are highly subjective and present difficulties in manual annotation. This con-clusion may warrant a simplification of the exist-ing 5 certainty levels to a basic binary distinction between certainty and doubt. A baseline for future attempts to improve the calibration of levels and their boundaries was established. These modest intercoder reliability results attest to the complex-ity of the automation of the epistemically modal-ized statements ranging from certainty to doubt. 
In the future studies, I intend to revise the num-ber of the discrete categories on the epistemic con-tinuum and further re-define certainty levels conceptually. I plan to further validate the collec-tion of agreed-upon certainty markers on a much larger dataset and by using the typology as input data to machine learning algorithms for certainty identification and extraction. 
