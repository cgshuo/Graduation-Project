 Although recommendation system resear ch has seen the development of tech-niques about rating prediction , the majority of commercial recommender sys-tems aims to generate a list of recommended items, which is the task of Top-N recommendation [9].

Various techniques have been proposed for Top-N recommendations. Most of them are based on the modelling of user rating patterns by analysing the user  X  item rating matrix. These methods show improved performance, but their abilities in Top-N recommendations are still limited by the availability of user ratings. Specifically, most of the available ratings are given to a small fraction of items, and this is known as the long tail effect [2].AsshowninFig.1c, 33% of ratings are observed from only around 5 . 5% of items in the MovieLens data set. These items are referred as popular items, while the other 94 . 5% are referred as unpopular or long tail items [4]. Thus, the long tail effect indicates that ratings on long tail items are much fewer. Consequently, these analysing methods for rating patterns are naturally limited by the long tail effect .
In this work, we observe that each user has a preference pattern that is different from his/her rating pattern, and the preference pattern tends to change over time. For example, Fig. 1a and 1b show the user preference patterns and the temporal dynamics observed on a real movie recommender system, MovieLens . Specifically, Fig. 1a shows that fresh users tend to rate movies from a larger range of genres than experienced users. Fig. 1b shows that, about 80% of users rated movies that spread over at least 3 . 5 genres on average during every two consecutive weeks. These observations i ndicate the existence of patterns on user preference styles, as well as their dyna mics. In this paper, we name this new effect as the preference dynamic effect . Please note that the temporal characteristic in user preference patterns is different from the one observed by Koren [12], which is the temporal dynamics in user rating patterns .

In this paper, we focus on the modelling of the preference dynamic effect with the Preference Pattern Subspace . The basic idea is to model the user prefer-ence styles and their temporal dynamics by constructing a low-rank subspace. Firstly, a low-rank subspace is built to capture the global preference patterns for all users; then, the projection for each personal preference pattern on the sub-space is individually refined based on his/her own preference styles. After that, the refined user projections on the subspace are used to improve the modelling of the global preference patterns . Iteratively, we can obtain a well-trained low-rank subspace to model both the user preference styles and their temporal dynam-ics. Based on the model, we formulate Top-N recommendation as a pairwise preference learning process, and propose a PrepSVD-I algorithm. Experimental results show that PrepSVD-I significantly outperforms the state-of-the-art Top-N recommendation techniques, e specially when recommending long tail items. The contributions of this paper are as follows:  X  For the first time, the preference dynamic effect is proposed to capture the  X  We propose a novel Preference Pattern model and a subspace approach,  X  Based on the Preference Pattern Subspace ,weformulateTop-N recommen-The rest of this paper is organized as follows. In Section 2, the Preference Pattern is proposed. In Section 3, we present Preference Pattern Subspace .Wepresent the results of the experiment in Sectio n 4, and the conclusion in Section 5. In this section, we propose a novel Preference Pattern model to capture the pref-erence dynamic effect . Notations used in this paper are summarized in Table 1. Definition 1. A preference pattern is a sequence of personal preference styles aligned in a time order. Precisely, for user u x ,the preference pattern is denoted time i on c j .
 The preference pattern has two key characteristics, personalization and time . All preference styles within a preference pattern come from the same user, and are sorted in a time order. For a particular user u x ,a preference style refers to his/her preferences over a range of categories (e.g. genre in movies/songs) of items at a particular time. The preference style at time i can be represented as a q -D vector p xi , which is defined as a preference pattern vector . Its value at the value of p j xi , we approximate it as a function of the implicit rating history of user u x . Formally, p j xi is defined as follows: where n is the number of items, and where r xl = # denotes that r xl is available, C l denotes a set of categories to which t l belongs, and t l  X  c j denotes that item t l belongs to category c j . Please note that there is an inverse relationship between b j xl and |C l | in Eq. 2.
The preference pattern is defined for each user in a way to naturally integrate a user X  X  various needs with the corresponding dynamics. The preference pattern vectors within a preference pattern captures the user X  X  corresponding preference styles , and the differences in two consecuti ve preference pattern vectors imply the dynamics of a user X  X  preference styles . If all values in each preference pattern vector are available, the preference pattern is complete , otherwise it is incomplete . In a real recommender system, as many missi ng values exist within the preference patterns, the modelling of preference patterns is a challenge. In this section, we build a Preference Pattern Subspace to model the preference patterns for each user, then propose the PrepSVD-I algorithm by formulating the task of Top-N recommendation as a pairwise preference learning process. 3.1 Learning the Preference Pattern Subspace To model the user preference patterns, we propose a Preference Pattern Subspace by applying the Singular Value Decomposition (SVD). Conventionally, the SVD of the preference patterns P is the factorization of the form: P = U X   X   X V T ,where U is an m  X  m orthogonal matrix,  X  is an m  X  n diagonal matrix containing the singular values of P on the diagonal, V is an n  X  n orthogonal matrix.
Accordingtothe Eckart-Young theorem [7], it is well-known that the best rank-k approximation of matrix P can be achieved by SVD. However, con-ventional SVD is defined without considering the existence of missing values. Therefore, as P is highly incomplete, SVD can not be directly applied to analyse preference patterns P . To overcome this problem, we propose an EM-like learn-ing algorithm to capture as much as possible the main variance of the highly incomplete pref erence patterns P . Specifically, p x can be divided into two parts, p x and p tively. We estimate P using SVD to construct a low rank k subspace: where U k contains the first k columns of U ,  X  k is a k  X  k diagonal matrix that contains the first k singular values of P ,and V k contains the first k columns of V . Consequently, the reconstruction  X  p x of p x is defined as: where v x is the x th row of V k , and denotes the projection of p x for user u x on the low rank k subspace. Similarly, the reconstruction  X  p x can also be divided tively. The SVD guarantees to produce the best k -rank approximation of P with minimal reconstruction errors. However, as P is highly incomplete, we change the modelling objective to minimize the reconstruction error on the available preferences in P . This is defined as the squared distance between the original available part of P and their reconstructions: where m is the number of users.
To build the representative subspace, an EM-like algorithm is introduced as follows: first, the missing values of P are replaced with their corresponding values in  X  = 1 m m x =1 p x . Then, in the j -th iteration, the standard SVD algorithm is applied to calculate a low-rank subspace defined by U k and  X  k .Afterthat,the reconstruction  X  p x of p x can be calculated with Eq. 4. However, as only a small fraction of preferences are available in p x  X  X  , its projection v x can not be directly estimated from Eq. 3. Pl ease note that we can estimate v x from part of p ,e.g,the available part p a x , and this estimation method has been widely used in the field of multimedia research [6]. Thus, we estimate v x as the least squares solution for the following equation: where [ p x ] a denotes p x in the current iteration step but only has values on the positions corresponding to p a x .After v x is estimated, the reconstruction  X  p x of p x can be calculated using Eq. 4. p m x will then be updated with  X  p m x ,andthe new  X  ( j +1) in the next ( j + 1)-th iteration will be calculated with the updated p x accordingly. With the updated algorithm is once again applied to calculate U k and  X  k . This iterative process will continue until the reconstruction error  X  a is below a pre-defined threshold. The proof for the convergence of this training algorithm is provided as follows. (
U  X  p x obtained with ( the data in the next iteration, p j +1 x , share values on missing part of p x ,thusthe reconstruction error on p j x is represented as: where d (  X  ,  X  )isthe Euclidean distance between two vectors.

If we use ( U k  X   X  k ) j to calculate the reconstruction of p j +1 x ,weobtain because the orthogonal property of ( U k  X   X  k ) j makes it sure that f j +1  X  p and p j +1 x have the minimum Euclidean distance.

In the ( j + 1)-th iteration, after applying SVD to the updated training data p x , we observe the minimum reconstruction error by obtaining ( For the reconstruction error in the ( j + 1)-th iteration, we obtain Thus, the algorithm will converge to minimize  X  a .
 The modelling process is an iterative refinement of the global and the personal preference patterns. One advantage of this EM-like learning algorithm is that the well-trained Preference Pattern Subspace can model both the personal preference patterns and the global preference patterns simultaneously. 3.2 Recommendation Generation After learning the well-trained Preference Pattern Subspace ,weproposea PrepSVD-I algorithm to generate Top-N recommendations. In this paper, we apply the latent factor model to estimate the ratings  X  r xl for user u x on item t l : where  X  x and  X  l are the user factors and the item factors, and can be learnt with stochastic gradient descent method by looping through available ratings.
Given the user factors and the item factors, T N ( u x ) can be generated by estimating ratings for un-known items with Eq. 12, then formed with the Top-N pattern vector p xi , and a tentatively changed preference pattern vector  X  p xi is available. Please note th atbecauseweonlywanttomeasurethedegreetowhich the recommendations match u x  X  X  preference styles captured by the Preference Pattern Subspace , we initialize  X  p xi as empty while keeping the other part the same as p x . The value at the j th position of  X  p xi is then defined as: where C l denotes a set of categories that t l belongs to, t l  X  c j denotes that t belongs to category c j . The reconstruction error for t l to u x at time i is defined as the squared distance between the changed preference pattern and its reconstruction: calculated with Eq. 6 and Eq. 4, while  X  p a x is the available part of  X  p x .
Moreover, the observed preference dynamic effect implies one constraint to the objective function of recommendation generations. It can be formulated as: where  X   X  a u Following this, we formulate the Top-N recommendation generation as a pairwise preference learning problem [8], and utilize the user average reconstruction  X   X  a u as the negative preference: where  X  x is a non-negative value measuring the degree of violating the constraint in Eq. 15,  X  is the regularization weight determined by cross validation.
We apply a simple gradient descent algorithm to optimize the objective func-tion defined in Eq. 16. Moreover, as there is an inverse relationship between b j xl and |C l | in the approximation of preference values in Eq. 2, we name this pro-posed algorithm as the PrepSVD-I algorithm. It loops on all T N ( u x ) ,  X  u x  X  X  , and updates the user factors and the item factors by following the negative gradient: where  X  is the learning rate, h =  X  | T N ( u x ) |  X   X  1 | T and H ( z )=1if z&gt; 0and0otherwise,denotingthe Heaviside function [1]. When the training process is completed, we c an calculate the predicted rating  X  r xl for each unknown item t l to user u x , then recommend the top ranked N items to u x with Eq. 12. Here the proposed PrepSVD-I algorithm takes both the personal preference patterns and the global preference patterns into consideration. The datasets we experimented with were the popular MovieLens dataset and Netflix dataset. MovieLens includes around 1 million ratings collected from 6 , 040 users on 3 , 900 movies. Following literature [13], the Netflix dataset is a subset extracted from the Netflix Priz e dataset, in which each user rated at least 20 movies, and each movie was rated by 20  X  250 users. For each dataset, we split it into two subsets, the training set and the test set . Following the work of [3, 4, 11], we reasonably assume that 5-star rated items are relevant to the active user, and adopt a similar strategy to conduct experiments. Specifically, we randomly select 2% of ratings and use all 5-star selected ratings to form the test set , and make sure that at least one 5-star rating exists for each individual user. The remaining ratings in the data set form the training set . After training the model on the training set , we randomly select 1000 additional items that are not rated by the active user, then predict ratings on the test item and addi-tional 1000 selected items. These items are then ranked and the top ranked N items are selected as Top-N recommendations for the active user. This testing strategy is common for Top-N recommendations researc h and has been adopted by [3,4,11]. To examine the algorithm performance thoroughly, we set up a series of configurations with different data sparsity levels. Specifically, on MovieLens data set, we keep the test set the same, but vary the percentage of observed rat-ings for each user in the training set , from 10% to 100% with a 10% step. These configurations are called as Given 10% to Given 100% accordingly. Moreover, as recommending popular items is trivial [4], we will focus on recommending long tail items and all items that include both popular and unpopular items. 4.1 Comparison and Evaluation We examine the performance of the proposed PrepSVD-I algorithm by compar-ing it with 7 other Top-N recommendation algorithms, including PureSVD [4], SLIM [13], BPTF [14], itemKNN [5], NNcosNgbr [4], Top Popular ( TopPop )[3, 4] and Movie Average ( MovieAvg )[11].Pleasenote BPTF considers the time information [14]. In PureSVD , the number of factors is set to 50. In SLIM ,we set  X  =0 . 1and  X  =0 . 1. The number of the nearest neighbors in NNcosNgbr is set to 200, and the number of neighbors in itemKNN is set to 20. For BPTF ,we set lrate =0 . 001, D = 200 and the number of samples to 50. For our method, to train the Preference Pattern Subspace ,weset k = 50,  X  =  X  1, and set the max iteration of training to 50, the error threshold to 10  X  6 .For PrepSVD-I ,  X  =0 . 0001,  X  =0 . 03, and the factors for both users and items are set to 50. The quality of Top-N recommendations is measured by the recall (or Hit Rate), the precision and the fall-out [4,5,10]. For the active user, if the Top-N recommendation list contains the test item, we call this a hit . Therefore, recall , precision and fall-out are defined as follows: where X is the test set and | irrelevant | is the number of all non-relevant items. A higher recall or precision value indicates better Top-N recommendations, while alower fall-out value means better recommendations. 4.2 Performance on Different Datasets To fully examine the performance of the proposed model, we conduct experi-ments on two well-known data sets, MovieLens and Netflix . Table 2 shows the results on these datasets when N = 20. It is observed that PrepSVD-I outper-forms all the compared algorithms on both data sets for both long tail and all items recommendations in all the measure ment metrics. Specifically, on Movie-Lens for long tail item recommendations, when measuring in recall , PrepSVD-I obtains a recall at 0 . 5389, which outperforms the best result 0 . 4987 (from PureSVD )by8 . 06%; when measuring in precision , PrepSVD-I achieves a pre-cision at 0 . 0269 that also outperforms all the other compared algorithms; for all items recommendations, PrepSVD-I also achieves better performance in re-call and precision .On Netflix , when measuring in recall , PrepSVD-I achieves a better recall at 0 . 6361 and 0 . 7526 for long tail and all items recommendations, respectively. When measuring in fall-out , it seems that, PrepSVD-I , PureSVD and SLIM show similar performance. The mai n reason behind this is that, ac-cording to the definition of fall-out , when the number of irrelevant items is large, the fall-out value tends to be small, and this diminishes the difference be-tween the performance of compar ed algorithms. Nevertheless, PrepSVD-I still achieves comparable performance to the compared algorithms. This indicates that the proposed Preference Pattern model can benefit Top-N recommenda-tions for both long tail and all items recommendations. This is mainly because the Preference Pattern is based on users X  personal preference styles, and also be-cause it takes the global preference patterns into consideration. Therefore, it can lead to better recommendations regardless of whether the target item is popular or not. 4.3 Performance on long tail Item Recommendations As recommending popular items is trivial [4], here we examine the proposed PrepSVD-I by comparing it with 7 other state-of-the-art recommendation algo-rithms under various data sparsity levels on long tail recommendations.
Table 3 shows the recall performance of the examined algorithms when N equals 10 and 20. It is clear that the proposed PrepSVD-I algorithm signifi-cantly outperforms all of the compared algorithms under all sparsity conditions except on Given 10% when N = 10 with BPTF obtaining a slightly higher re-call . However, BPTF performs badly on all other sparsity levels. For example, on Given 90% when N = 20, BPTF only obtains a recall at 0 . 1824, which is much worse than all the other personalized algorithms, e.g. PrepSVD-I , itemKNN , NNcosNgbr and SLIM .Moreover, PrepSVD-I performs steadily through var-ious sparsity levels, and always achiev es better performance. Specifically, on Given 50%, when N = 20, PrepSVD-I achieves a recall of 0 . 3147, which out-performs the best compared result of 0 . 2751 (from PureSVD )by14 . 39%. This is, as expected, because the proposed Preference Pattern Subspace is capable of capturing user preference styles and the corresponding dynamics, and is not affected by whether the item is popular or not. Moreover, it is also observed that the sparser the training data set, the larger the improvements. For exam-ple, when N = 10, the improvement on Given 100% is 12 . 66%, and increases to 29 . 76% on Given 40% data set. The reason behind this is that when the training set is sparser, the long tail effect indicates that available ratings on long tail items will be much more limited. Consequently, the user rating patterns will be extremely incomplete, and solely modelling them does not lead to good recom-mendations. In this case, the preference dynamic effect becomes more valuable to predict users X  preferences on it ems. Therefore, the proposed Preference Pattern Subspace will show high effectiveness for recommendation purposes.

To thoroughly examine the performance of PrepSVD-I ,wevarythe N value from 1 to 20, and report the results on Given 40%, Given 60% and Given 80% as shown in Fig. 2. We observe that PrepSVD-I outperforms all compared al-gorithms at all N values on all the data sets. This indicates that PrepSVD-I is effective in recommending the desired items at the top of the recommenda-tion list. The experiment results show that, when recommending long tail items, PrepSVD-I is robust to the data sparsity issue, and can significantly outperforms state-of-the-art Top-N recommendation algorithms in terms of accuracy. 4.4 Performance on all items Recommendations we also conduct experiments on recommending all items , including both popular and long tail items. Table 4 shows the recall performance of all compared algo-rithms across various sparsity levels on all item recommendations. We can ob-serve that PrepSVD-I achieves the best recall on all data sets, except Given 10%, Given 20% and Given 30% (on N = 10). It is unexpected that TopPop achieves the highest recall values on Given 10% and Given 20% (on N = 10). This is mainly because when the training set is very sparse, the majority of available ratings are given for popular items. Therefore, the popularity of items will bias the performance of algorithms. This is consistent with the findings in [4]. SLIM achieves the best recall on Given 20% (on N = 20) and Given 30% (on N = 10). However, both TopPop and SLIM become almost useless in recommending long tail items on the same data sets, as shown in Table 3, which confirms the popularity-related bias.

On the other hand, it is also clear that PrepSVD-I outperforms all com-pared algorithms on 7 out of 10 data sets, including TopPop and SLIM . Specif-ically, when N =20on Given 40% data set, PrepSVD-I achieves a recall at 0 . 4165 which outperforms the best compared results of 0 . 3960 (from SLIM ); on Given 100% data set, PrepSVD-I obtains a recall at 0 . 6928 that outperforms the best compared results of 0 . 6794 (from SLIM ). This indicates that the Preference Pattern Subspace can also benefit all items recommendations, including popular items.

In terms of accuracy on recommending both all items and long tail items, it is clear that PrepSVD-I performs better than all compared state-of-the-art Top-N recommendation algorithms. Although TopPop and SLIM achieve a slightly better recall values on Given 10%, Given 20% and Given 30% when recommend-ing all items , they perform badly on the same data set when recommending long tail items, as shown in Table 3. This will limit their recommendation abilities. However, PrepSVD-I can perform very well on both all items and long tail item recommendations. This means PrepSVD-I possesses a better recommendation
