 Hashing has enjoyed a great success in large-scale similarity search. Recently, researchers have studied the multi-modal hashing to meet the need of similarity search across di ff erent types of media. How-ever, most of the existing methods are applied to search across multi-views among which explicit bridge information is provided. Given a heterogeneous media search task, we observe that abundant multi-view data can be found on the Web which can serve as an auxiliary bridge. In this paper, we propose a Heterogeneous Trans-lated Hashing (HTH) method with such auxiliary bridge incorpo-rated not only to improve current multi-view search but also to en-able similarity search across heterogeneous media which have no direct correspondence. HTH simultaneously learns hash functions embedding heterogeneous media into di ff erent Hamming spaces, and translators aligning these spaces. Unlike almost all existing methods that map heterogeneous data in a common Hamming space, mapping to di ff erent spaces provides more flexible and discrimina-tive ability. We empirically verify the e ff ectiveness and e ffi ciency of our algorithm on two real world large datasets, one publicly available dataset of Flickr and the other MIRFLICKR-Yahoo An-swers dataset.
 Categories and Subject Descriptors: H.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.4 [Information Systems Applications]: Miscellaneous.
 Keywords: Hash Function Learning; Heterogeneous Translated Hashing; Scalability.
With the explosive growth of data on and o ff the Web, hetero-geneity arising from di ff erent data sources has become ubiquitous. There exist numerous interactions among a diverse range of het-erogeneous media: summarizing a piece of video with textual key-words, displaying advertisements by understanding the content of a mobile game, and recommending products based on social ac-tivities including sending messages, checking in at places, adding friends, and posting pictures. Figure 1 shows a simple example of leveraging images to provide more accurate answers in Question-Answering systems. All these applications boil down to a funda-Figure 1: An example of using images to help better question-a nswering. With a specific poster of  X  X ight of Champions X , the answer to where to buy can be more precise. mental problem: similarity search across heterogeneous modali-ties .

The challenges of similarity search across heterogeneous modal-ities are two-fold: 1) how to e ffi ciently perform the computation to meet the large amount of data available; and 2) how to e ff ec-tively compare the similarity with the existence of heterogeneity. A brute force similarity comparison between the examples from di ff erent media is prohibitively expensive for large-scale datasets. Traditional space partitioning methods which accelerate similar-ity search, such as KD-trees [2] and Metric trees [24], have poor performance in high dimensional spaces [26]. Due to their con-stant or sub-linear query speed and low storage cost, hashing based methods initiated by locality sensitive hashing (LSH) [1, 7], have aroused more and more interest and become a main-stream tech-nique for fast approximate nearest neighbour (ANN) search. The key principle of hashing is to learn compact binary codes that can preserve similarity. In other words, similar points in the original feature space are projected to similar hash codes in the Hammming space. However, these methods all work with homogeneous data points.

To apply hashing across heterogeneous media is a non-trivial task. First, data from di ff erent media sources have incommensu-rable representation structures. Second, besides preserving homo-geneous media similarity in the way as traditional hashing does, heterogeneous media similarity should be preserved simultaneously. Heterogeneous media similarity is defined as semantic relatedness between a pair of entities in di ff erent modalities. For instance, a query image and a document in database are similar if they derive from the same topic, e.g.,  X  X ports X . Such heterogeneous correspon-dence data that are labelled as similar or dissimilar are the  X  X ridge X  to search across heterogeneous media. However, in the task of illustrating questions with pictures as Figure 1 shows, questions as queries do not have any correspondence with the pre-defined database of images. Thus, the third challenge is that in most of practical applications, the explicit relationships between query en-tities (in one domain) and the database entities (in another domain) p robably do not apparently exist.

So far limited attempts have been made towards hashing across heterogeneous media. The existing works such as [4, 12, 32, 15] all focus on the situation where explicit relationships are given. For ex-ample, the method proposed in [12] assumes that the data is format-ted in a multi-view fashion, i.e., each data instance in the database should have a representation in each view. Therefore, explicit re-lationship is clearly given for each data instance. Particularly, the method proposed in [15] even relies on the explicit relationships between queries and the database in the testing phase.

Moreover, most existing approaches embed multiple media data into a common Hamming space, thus generating hash codes with the same number of bits for all modalities. However, such an em-bedding is unreasonable because di ff erent media types usually have di ff erent dimensionality and distributions. In fact, researchers have argued that in uni-modal hashing using the same number of bits for all projected dimensions is unsound because dimensions of larger variances carry more information [8, 13]. Analogously, heteroge-neous media data with incommensurable representations and dis-tributions also carry di ff erent amounts of information so that they should not be collectively hashed into binary codes of the same length. Otherwise, the equal treatment of di ff erent modalities can deteriorate the hashing performance. To the best of our knowl-edge, the work of [15] is among the first to adopt di ff erent bits for di ff erent modalities and correlating these bits with mapping func-tions. However, as mentioned above, it re-learns hash codes for out-of-sample data highly reliant on the given relationships between queries and the database, which is neither practical nor e ffi cient.
In this paper, we propose a novel learning method to enable translation-based hashing across heterogeneous media called Het-erogeneous Translated Hashing (HTH) to address these limitations. Given a heterogeneous media search task, we observe that some multi-modal data are available on the Web which can serve as a bridge to preserve heterogeneous media similarity, while massive uncorrelated examples in each individual modality can be incor-porated to enhance homogeneous media similarity preservation. Learning from such auxiliary heterogeneous correspondence data and homogeneous unlabelled data, HTH generates a set of hash functions for each modality that can project entities of each me-dia type onto an individual Hamming space. All of the Hamming spaces are aligned with a learned translator. In practice, we for-mulate the above learning procedure as a joint optimization model. Despite the non-convex nature of the learning objective, we express it as a di ff erence of two convex functions to enable the application of the concave-convex procedure (CCCP) [29] iteratively. Then we employ the stochastic sub-gradient strategy [20] to e ffi ciently find the local optimum in each CCCP iteration. Finally, we conduct extensive experiments on two real-world large scale datasets and demonstrate our proposed method to be both e ff ective and e ffi cient.
The remainder of this paper is organized as follows. We review the related work in Section 2. In Section 3, we present the formula-tion and optimization details of the proposed method. Experimental results and analysis on two real-world datasets are shown in Section 4. Finally, Section 5 concludes the paper.
In this section, we briefly review the related work in two cate-gories. We first introduce the recently developed learning to hash methods, which is the background of our approach. Then we re-view several current state-of-the-art hashing methods across het-erogeneous modalities.
LSH [1, 7] and its variations [6, 10, 11, 17] , as the earliest ex-ploration of hashing, generate hash functions from random projec-tions or permutations. Nevertheless, these data-independent hash functions may not confirm to every application, and hence require very long hash codes, which increases costs of storage and on-line query, to achieve acceptable performances. Recently, data-dependent learning to hash methods attempt to alleviate the prob-lem via learning hash functions from data. Unsupervised learning (spectral hashing (SH) [27], self-taught hashing (STH) [31], anchor graph hashing (AGH) [13]), supervised learning (Boosting [19], semantic hashing [18], LDAHash [23]) and semi-supervised learn-ing (semi-supervised hashing [25]) have been explored since then. These approaches have significantly improved the hashing results for many specific tasks.
To the best of our knowledge, only a few research attempts to-wards multi-modal hashing have been made to speed up similarity search across di ff erent feature spaces or modalities.
Bronstein et al. [4] first explored the cross-modality similar-ity search problem and proposed cross-modal similarity sensitive hashing (CMSSH). It embeds multi-modal data into a common Hamming space. Later, several works [12, 28, 30, 32, 33, 34] were proposed. Both cross-view hashing (CVH) [12] and inter-media hashing (IMH) [22] extend spectral hashing to preserve intra-media and inter-media similarity simultaneously. Nevertheless, CVH en-ables cross-view similarity search given multi-view data whereas IMH adds a linear regression term to learn hash functions for e ffi -cient code generation of out-of-sample data. Zhen et al. [32] ex-tended label-regularized max-margin partition (LAMP) [14] to the multi-modal case. Multimodal latent binary embedding (MLBE) [33] presents a probabilistic model to learn binary latent factors which are regarded as hash codes in the common Hamming space. Parametric local multimodal hashing (PLMH) [30] extends MLBE and learns a set of local hash functions for each modality. Recently, Zhu et al. [34] and Wu et al. [28] presented two new techniques for obtaining hash codes in multi-modal hashing. [34] obtains k -bit hash codes of a specific data point via thresholding its distances to k cluster centres while [28] thresholds the learned sparse coe ffi cients for each modality as binary codes.

All these methods assume that the hashed data reside in a com-mon Hamming space. However, this may be inappropriate espe-cially when the modalities are quite di ff erent. Relational-aware het-erogeneous hashing (RaHH) [15] addresses this problem by gener-ating hash codes with di ff erent lengths (one for each modality) to-gether with a mapping function. Unfortunately, RaHH has to adopt a fold-in scheme to generate hash codes for out-of-sample data, which is time-consuming, because it learns codes directly instead of explicit hash functions. In the next section, we elaborate our approach to eliminate these restrictions.
In this section, we present our approach in detail. We first in-troduce the general framework which consists of an o ffl ine training phase and an online querying phase. After introducing the nota-tions and problem definitions, we show that HTH can be achieved by solving a novel optimization problem, and we develop an e ff ec-tive and e ffi cient algorithm accordingly. The whole algorithm and the complexity analysis are given at the end of this section.
We illustrate the HTH framework in Figure 2. HTH involves two phases: an o ffl ine training phase (left) and an online querying phase (right). For the simplicity of presentation, we focus on two heterogeneous media types, namely, images and text documents. Nevertheless, it is straightforward to extend HTH to more general cases with three or more types of media. During the o ffl ine train-ing phase, HTH learns: 1) the hash functions for each media type to map the data to their individual Hamming space, which has di-mensions of the number equalling the code length; and 2) a trans-lator to align the two Hamming spaces. Since e ff ective hash codes should simultaneously preserve homogeneous and heterogeneous media similarity, the correspondence between di ff erent domains is needed. In this work, we use auxiliary tagged images crawled from Flickr as the  X  X ridge X  shown in the central pink bounding box in Figure 2 which encloses images, documents and their relationships. Meanwhile, a proportion of queries, e.g., images, are incorporated to enhance intra-similarity preservation together with auxiliary im-ages as the left blue bounding box which encloses all images shows. The same applies to text documents. With hash functions, simi-lar homogeneous instances of each media type should be hashed into the same or close bucket in its Hamming space as displayed in Figure 2. Moreover, hash codes of one media type can be trans-lated into the other Hamming space so that mutually correlated data points across di ff erent domains are expected to have small Ham-ming distances.

In the online querying phase, the database, e.g., a pile of text doc-uments, is pre-encoded into a hash table via applying correspond-ing learned hash functions. When a new query instance comes, we first generate its hash codes using the domain specific hash func-tions. Subsequently, the hash codes are translated to the Hamming space of the database via the learned translator. Using existing hardware techniques such as bit operations, we can compute the Hamming distances between the query and all database instances, and retrieve its nearest neighbours e ffi ciently.
Suppose we are given a few query data instances  X  X q = {  X  x and a large database  X  Y p = {  X  y j } M j = 1 , where  X  x sional feature vector in the query domain and  X  y j  X  R d p represents a d p -dimensional vector in the feature space of the database. In addition, we are given a set of auxiliary data points from both modalities and their relationships which are expressed as a triple randomly sample n instances from  X  X q and select all auxiliary data points corresponding to the query domain, i.e., N x = n + N sets of hash functions and a translator from the training set A and T y . The two sets of hash functions, F q ( x ) = { f k d imensional and a k p dimensional Hamming space respectively. manner. Based on the hashing functions and the translator, we can perform accurate nearest neighbour retrieval across di ff erent media types. For brevity, we summarize these notations in Table 1.
In this section, we introduce the objective function of our pro-posed HTH integrating both the homogeneous similarity preserva-tion term and the heterogeneous similarity preservation term.
A core criterion to preserve homogeneous media similarity is that similar data points in the original space should share similar hash codes within each single media type. To meet this criterion, in this work we first define the k th ( l th) bit hash function of the query which has been widely adopted in existing related works [22, 31, 32]: where sgn (  X  ) is the sign function, and w q k and w p l vectors for the k th and l th bit hash codes in the query and database domain respectively.

In each domain, we can treat each hash function above as a bi-point as a binary class label. The goal is to learn binary classi-fiers f q 1 ,  X  X  X  , f q k item x . Moreover, we train binary classifiers for all the bits inde-pendently because di ff erent bits h q 1 ,  X  X  X  , h q k We propose to learn the hash function for the k th bit by solving the following optimization problem: where  X  (  X  ) denotes the loss function on one data point and  X  is a regularization term about functional norm k w q k k H in Hilbert spaces. Inspired by the large-margin criterion adopted by Support Vector Machine (SVM), we define  X  using the hinge loss function  X  (( w wise.  X  is commonly defined as the L 2 -norm 1 2 k w q k k 2 . Note that h k = f rewritten as: J where  X  q is a balancing parameter controlling the impact of the regularization, and the last term is to avoid a trivially optimal solu-tion which assigns all N x data points to the same bit. Without the last constraint, the data points may be classified into the same side with large | ( w q k ) T x i | value so that [1  X  X  ( w q k N x data points which is meaningless in hashing. Thus we enforce  X   X   X  1 N
Similarly, we can learn the hash functions for the database do-main by minimizing the following objective function: J where  X  p controls the impact of regularization. To learn hash func-tions from both query and database domains that preserve the ho-mogeneous similarity, we combine (3) and (4) and derive the fol-lowing objective function: where W q = { w q 1 ,  X  X  X  , w q k the Frobenius norm.
In the last subsection, we learn the hash codes that can preserve homogeneous media similarity for each media type. For the sake of flexibility and discrimination between two modalities, we adopt hash codes with di ff erent numbers of bits for di ff erent domains. To perform similarity search across di ff erent Hamming spaces, in codes from a k q -dimensional Hamming space to a k p -dimensional Hamming space or vice versa. We also show that C can be learned from auxiliary heterogeneous pairs A xy =  X  N 1 i = 1  X  N
A good translator should have the following three properties: 1) semantically related points across di ff erent domains should have similar hash codes after translation; 2) semantically uncorrelated points across di ff erent domains should be far away from each other in the translated Hamming space; 3) it should have good gener-alization power. To obtain such a good translator, we propose to minimize the following heterogeneous loss function: tance in the Hamming space of the database between the i th trans-lated hash code from the query domain and the j th code string from the database domain.  X  (  X  ) is the SCISD [16] function specified by two parameters a and  X  : Note that if two data points are semantically similar, that is, s we require that they have small d i j ; if they are semantically dissim-ilar, we require that they have small SCISD value which implies that they are far apart in the Hamming space.
Combining the objective functions introduced in the previous two subsections, the overall optimization problem of HTH can be written as follows: where  X  is a trade-o ff parameter between homogeneous and hetero-geneous loss functions.
P roblem (8) is non-trivial to solve because it is discrete and non-nating algorithm to solve this problem which converges to a local minimum very quickly.

We first describe how to learn the projection vector w q k bit while fixing other variables. Note that projection vectors for dif-ferent bits can be learned independently using the same algorithm. The objective function w . r . t . w q k is:
Although (9) is not convex, it can be expressed as the di ff erences of two convex functions, and hence can be minimized e ffi ciently using constrained concave-convex-procedure (CCCP) [29].
We briefly introduce the idea of CCCP here. Given an optimiza-tion problem in the form of min x f ( x )  X  g ( x ) where f and g are real-valued convex functions, the key idea of CCCP is to iteratively evaluate an upper bound of the objective function by replacing g with its first-order Taylor expansion around the current solution, x i.e., R ( g ( x t )) = g ( x t ) +  X  x g ( x t )( x  X  x t convex solvers. The solution sequence { x t } obtained by CCCP is guaranteed to reach a local optimum.
 Specifically, the upper bound of (9) in the t th CCCP iteration is: w here f 1 ( w q k ) = 1 + [ | ( w q k ) T x i | X  1] + , g d The Taylor expansion of g 1 (  X  ) and  X  2 (  X  ) around the value of w t th iteration are R ( g 1 ( w q ( t ) k )) = | ( w q ( t ) w k ) and R (  X  2 ( d Note that
However, minimizing (10) is time-consuming if the data dimen-sionality is high. As a result, we employ Pegasos [21] which is a sub-gradient based solver and reported to be one of the fastest gradient-based solvers, to solve the problem. In each Pegasos iter-ation, the key step is to evaluate the sub-gradient of J ( t ) from l 1 random homogeneous data points and l 2 random heteroge-neous pairs: Algorithm 1 H eterogeneous Translated Hashing (HTH) Input: Output: 1: Initialize W q , W p with CVH and C = I ; 2: while W q , W p and C are not converged do 3: Fix W p and C , optimize W q : 4: for k = 1  X  X  X  k q do 5: for t = 1  X  X  X  t max do 7: end for 8: end for 9: Fix W q and C , optimize W p 10: for k = 1  X  X  X  k p do 11: for t = 1  X  X  X  t max do 13: end for 14: end for 15: Fix W q and W p , optimize C : 16: for t = 1  X  X  X  t max do 18: end for 19: end while where  X 
Similarly, the objective function and sub-gradient w . r . t . w t th CCCP iteration are : a nd where Note that both  X  d them here due to space limitations.

To update the translator C , we also use CCCP. The objective function and sub-gradient w . r . t . every element C kl in the t th CCCP iteration:
J a nd
C where The overall procedure of the HTH method, alternating learning W q , W p and the translator C with CCCP and Pegasos, is presented in Algorithm 1.
The computational cost of the proposed algorithm comprises three parts: updating W q , W p and C . Hence, the total time complexity of training HTH is O ( k q d q ( l 1 + l 3 ) + k p d p ( l 2 l are the numbers of stochastically selected training data points in the query domain and database domain by the Pegasos solver. l is the number of randomly sampled auxiliary data pairs from N auxiliary heterogeneous co-occurrence data pairs. Clearly, the time complexity for our algorithm scales linearly with the number of training data points and quadratic with the length of hash codes. In practice, the code length is short, otherwise, the technique of  X  X ashing X  will be meaningless. Hence our algorithm is very com-putationally e ffi cient.

During the online query phase, given a query instance  X  x we apply our learned hash functions for the query domain to it by performing two dot-product operations, H q i = x i  X  W q and translation H i  X  C , which are quite e ffi cient. The translated query hash codes are then compared with the hash codes of the database by quick XOR and bit count operations. These operations enjoy the sub-linear time-complexity w . r . t . the database size.
In this section, we evaluate the performance of HTH on two real world datasets and compare it with the state-of-the-art multi-modal hashing algorithms. MIRFLICKR-Yahoo Answers.

NUS-WIDE is a Flickr dataset containing 269,648 tagged im-ages [5]. The annotation for 81 semantic concepts is provided for evaluation. We prune this dataset via keeping the image-tag pairs that belong to the ten largest concepts. For image features, 500 dimensional SIFT vectors are used. On the other side, a group of tags for an image composes a single text document. For each text document, we use the probability distribution of 100 Latent Dirich-let Allocation (LDA) [3] topics as the feature vector. Therefore, NUS-WIDE is a multi-view dataset. Each data instance has an im-age view and a text view. When searching images using text query or searching text documents using image query, the groundtruth is derived by checking whether an image and a text document share at least one of the ten selected largest concepts.

MIRFLICKR-Yahoo Answers is a heterogeneous media dataset consisting of images from MIRFLICKR-25000 [9] and QAs from Yahoo Answers. MIRFLICKR-25000 is another Flickr collection consisting of 25,000 images. We utilize 5,018 tags provided by NUS-WIDE to filter irrelevant pictures in MIRFLICKR-25000 by cross-checking tags of each image with these 5,018 tags. The 500 dimensional sift feature vector is also applied. Yahoo Answers are 5,018 tags are taken as keywords to search relevant QAs on Yahoo Answers. For each keyword, we extract top 100 results returned by YQL. Finally, we obtain a pool of about 300,000 QAs, each of which is regarded as a text document in the experiment. Each QA is represented in a 100 dimensional LDA based feature vector. For the task using image query to retrieve QAs in the database, those QAs which share at least two words with tags corresponding to the image query (images in MIRFLICKR-25000 are also tagged) are labelled as the groundtruth. The groundtruth for the task using QA as query to retrieve the image database is obtained similarly. More importantly, we randomly select a number of multi-view instances, e.g., 2,000, in the NUS-WIDE dataset as the  X  X ridge X . As a result, we obtain 2 , 000 2 = 4  X  10 6 auxiliary heterogeneous pairs.
We compare our method with the following four baseline algo-rithms.

Cross-modality similarity-sensitive hashing (CMSSH) [4], to the best of our knowledge, is the first approach that tackles hash-ing across multimodal data. CMSSH uses Adaboost to construct a group of hash functions sequentially for each modality while only preserving inter-modality similarity.

Cross-view hashing (CVH) [12] extends spectral hashing to the multi-view case via a CCA (canonical correlation analysis) alike 1 h ttp: // lms.comp.nus.edu.sg / research / NUS-WIDE.htm 2 http: // developer.yahoo.com / yql / Precision = 1 6 Precision = 1 6 procedure. In our implementation, CVH learns two hash functions which can directly be applied to out-of-sample data.

Co-regularized hashing (CRH) [32] proposes a boosted co-regularization framework to learn two sets of hash functions for both the query and database domain.

Relation-aware heterogeneous hashing (RaHH) [15] adopts uneven bits for di ff erent modalities and a mapping function be-tween them. During testing we add no heterogeneous relationship between queries and the database in our setting. In [15], however, they used the explicit relationship and attained higher accuracies.
In this paper, Mean Average Precision (MAP), precision and re-call are adopted as our evaluation metrics of e ff ectiveness.
MAP stands out among performance measures in virtue of its competitive stability and discrimination. To compute MAP, Aver-age Precision (AP) of top R retrieved documents for a single query of groundtruth in the R retrieved set, P ( r ) indicates the precision of top-r retrieved documents and  X  ( r ) = 1 denotes whether the r th retrieved document is a true neighbour otherwise  X  ( r ) = 0. MAP is then averaged over all queries X  APs. The larger the MAP score, the better the retrieval performance. In our experiments, we set R = 50. The precision and recall scores reported in this paper are averaged over all queries. The larger the area under the curves, the better the achieved performance.
We perform two kinds of tasks on the NUS-WIDE dataset: 1) retrieving text documents by using images as queries; 2) retrieving images by using text documents as queries. In either task, we ran-domly select 300 2 = 90 , 000 image-tag pairs from the NUS-WIDE dataset to be our training pairs. For the task of retrieving texts by image queries (retrieving images by text queries), we select 2,000 images (text documents) as queries and 10,000 text documents (im-Image  X  T ext Text  X  I mage ages) to be the database. We perform our experiment on four such r andomly sampled datasets and the average MAP results for all the compared algorithms are reported in Table 2. To be comparable F igure 4: Study of parameter sensitivity on NUS-WIDE dataset. Parameter settings in our experiments are labelled in red dots and correspond to the best performances. with CVH, CMSSH and CRH, HTH adopts the same code length for di ff erent domains. From Table 2, we have the following obser-vation. HTH outperforms all state-of-the-art methods in almost all settings at most 30%. Precision = 1 6 Precision = 1 6 The precision-recall curves for 8, 16 and 24 bits are plotted in Figure 3. The superior performance of HTH in precision-recall curves agrees with the results of MAP in Table 2. F igure 6: Time cost of training and testing on NUS-WIDE dataset with di ff erent code lengths. The time is measured in seconds. Y-axis in (a) is the natural logarithm of training time.
We also study the e ff ect of di ff erent parameter settings on the performance of HTH. We fix the code lengths of both modalities to be 16. There are four trade-o ff parameters,  X  ,  X  q ,  X  as shown in objective function (8). We perform grid search on  X   X  . HTH gains the best MAP at  X  = 1 , 000,  X  C = 1 as Figure 4(a) shows. When fixing the  X  and  X  C , grid search of  X  q and  X  forms the best. We adopt  X  C = 1 , X  = 1 , 000 , X  q = 0 . 01 , X  in our experiments.

The time costs of HTH and other baselines are shown in Figure 6 as the code length changes. Since the training complexity of HTH is quadratic with respect to the code length, it takes more training time when the codes are longer. However, hashing with less bits is expected, thereby HTH is practical. In online querying phase, since CVH, CMSSH and CRH have the same time complexity as HTH, we only compare HTH with RaHH. The average query search time of HTH is much less than RaHH because RaHH does not learn explicit hash functions and has to adopt the fold-in scheme for out-of-sample data.
We also report the results of the two tasks (using images to search text documents and using text documents to search images) on the MIRFLICKR-Yahoo Answers dataset which contains a larger num-ber of images and text documents.
 In this experiment, N xy = 2 , 000 2 = 4  X  10 6 image-tags pairs from NUS-WIDE dataset, 500 randomly selected images from MIRFLIC -KR as well as 500 sampled QAs from Yahoo Answers are chosen for training. In this case, these image-tag pairs from NUS-WIDE serve as the auxiliary bridge while queries and the database have no direct correspondence since MIRFLICKR images and Yahoo An-swers are obtained independently.
 Table 3: MAP comparison on MIRFLICKR-Yahoo Answers.
 Image  X  Q A QA  X  I mage
To apply CVH, CMSSH, CRH to this dataset, we simply train h ash functions for images and texts using the image-tag pairs from NUS-WIDE and generate hash codes of images from MIRFLICKR and QAs from Yahoo Answers by directly applying corresponding hash functions. For RaHH, in the training phase, the data is the same as those used in CVH, CMSSH and CRH. In the testing phase, w e do not add any relationships between queries and database enti-ties when applying the fold-in algorithm to generate hash codes for out-of-sample data. For HTH, we train the hash functions with the auxiliary heterogeneous pairs and unlabelled homogeneous data. In the testing phase, it is easy to apply the learned hash functions to out-of-sample data without any correspondence information. Table 4: MAP of RaHH and HTH on MIRFLICKR-Yahoo An-swer with di ff erent combinational code length.
The MAP results are summarized in Table 3 with various code le ngth settings. It shows that HTH outperforms all the other al-gorithms under all settings. This demonstrates that HTH shows more superiority in situations where queries and the database do not interrelate. Similarly, the precision-recall curves are plotted in Figure 5.
 Figure 7: The influence of varying N x y , the number of auxiliary heterogeneous pairs, and n , the number of added unlabelled images / QAs, on MAP performance.

More importantly, our proposed HTH method adopts uneven bits for di ff erent modalities so that it discriminates between the query and database domain flexibly. In Table 4, we compare HTH with RaHH, which also supports di ff erent code lengths. The row repre-sents code length of images while the column is for that of QAs. HTH and RaHH both attain the best MAP results at k q = 16 and k p = 24. This code length combination is regarded as the best trade-o ff between e ff ective translator learning and original infor-mation preservation. Moreover, images require less bits to achieve comparable performance compared to QAs because instances in text domain are more dispersed so that more bits are called for en-coding all the instances.

The influence of N xy , the number of auxiliary heterogeneous training pairs, and n , the number of added unlabelled images / QAs, on MAP performance is investigated in Figure 7. Reasonably, larger n and N xy result in better MAP performance. In practice, we choose N xy = 4  X  10 6 and n = 500, which is competitive with N xy and n = 2 , 000, to be more e ffi cient during training.
The time costs of HTH on MIRFLICKR-Yahoo Answers dataset is also reported in Figure 8. The results are similar to Figure 6 except that HTH is more e ffi cient by contrast. This demonstrates that HTH is less sensitive to the size of the training data, which can be further proved in Figure 9. CVH and CMSSH rely on eigen-decomposition operations which are e ffi cient especially when the dimensions of the dataset are comparatively low. However, they do not consider homogeneous similarity or the regularization of pa rameters, thus resulting in less accurate out-of-sample testing per-formance. Although HTH takes more training time than CRH and RaHH when the number of auxiliary heterogeneous pairs, N xy F igure 8: Time cost of training and testing on MIRFLICKR-Yahoo Answers dataset with code lengths. The time is mea-sured in seconds. Y-axis in (a) is the natural logarithm of train-ing time. small, it shows more e ffi ciency compared with CRH and RaHH as N xy increases. Therefore, HTH has good scalability and can be ap-plied to large-scale datasets. Note that we do not report results of CMSSH when N xy = 2 . 5  X  10 7 , 10 8 since the algorithm has  X  X ut-of-memory X  at these scales. Figure 9: Scalability of training on MIRFLICKR-Yahoo An-s wers dataset as the number of auxiliary heterogeneous pairs, N xy , increases. The time is measured in seconds. X-axis is in logarithmic scale. Y-axis is the natural logarithm of training time. Figure 10: Given a picture in the MIRFLICKR dataset as q uery, we retrieve top-5 nearest questions from the Yahoo An-swers dataset by HTH and CVH. Whether there exist corre-sponding keywords in a retrieved question to the labels of the picture indicates the relevance of this question to the picture.
We finally provide a similarity search example in Figure 10 to vi-sually show the e ff ectiveness of HTH. Given an image from MIR-FLICKR, we compare the relevance of top-5 nearest questions to more relevant to this picture as shown in Figure 10.
I n this paper, we propose a novel heterogeneous translated hash-ing (HTH) model to perform similarity search across heteroge-neous media. In particular, by leveraging auxiliary heterogeneous relationship on the web as well as massive unlabelled instances in each modality, HTH learns a set of hash functions to project in-stances of each modality to an individual Hamming space and a translator aligning these Hamming spaces. Extensive experimen-tal results demonstrate the superiority of HTH over state-of-the-art multi-modal hashing methods. In the future, we plan to apply HTH to other modalities from social media and mobile computing, and to devise a more appropriate scheme to translate between di ff erent Hamming spaces, thereby further improving HTH.
We thank the reviewers for their valuable comments to improve this paper. The research has been supported in part by China Na-tional 973 project 2014CB340304 and Hong Kong RGC Projects 621013, 620812, and 621211. [1] A. Andoni and P. Indyk. Near-optimal hashing algorithms for [2] J. L. Bentley. Multidimensional binary search trees used for [3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [4] M. Bronstein, A. Bronstein, F. Michel, and N. Paragios. Data [5] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. [6] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. [7] A. Gionis, P. Indyk, and R. Motwani. Similarity search in [8] Y. Gong and S. Lazebnik. Iterative quantization: A [9] M. J. Huiskes and M. S. Lew. The mir flickr retrieval [10] B. Kulis and K. Grauman. Kernelized locality-sensitive [11] B. Kulis, P. Jain, and K. Grauman. Fast similarity search for [12] S. Kumar and R. Udupa. Learning hash functions for [13] W. Liu, J. Wang, S. Kumar, and S.-F. Chang. Hashing with [14] Y. Mu, J. Shen, and S. Yan. Weakly-supervised hashing in [15] M. Ou, P. Cui, F. Wang, J. Wang, W. Zhu, and S. Yang. [16] N. Quadrianto and C. Lampert. Learning multi-view [17] M. Raginsky and S. Lazebnik. Locality-sensitive binary [18] R. Salakhutdinov and G. Hinton. Semantic hashing.
 [19] G. Shakhnarovich, P. Viola, and T. Darrell. Fast pose [20] S. Shalev-Shwartz, Y. Singer, and N. Srebro. Pegasos: Primal [21] S. Shalev-Shwartz, Y. Singer, N. Srebro, and A. Cotter. [22] J. Song, Y. Yang, Y. Yang, Z. Huang, and H. T. Shen. [23] C. Strecha, A. Bronstein, M. Bronstein, and P. Fua. Ldahash: [24] J. K. Uhlmann. Satisfying general proximity / similarity [25] J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised [26] R. Weber, H.-J. Schek, and S. Blott. A quantitative analysis [27] Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In [28] F. Wu, Z. Yu, Y. Yang, S. Tang, Y. Zhang, and Y. Zhuang. [29] A. L. Yuille, A. Rangarajan, and A. Yuille. The [30] D. Zhai, H. Chang, Y. Zhen, X. Liu, X. Chen, and W. Gao. [31] D. Zhang, J. Wang, D. Cai, and J. Lu. Self-taught hashing for [32] Y. Zhen and D. Y. Yeung. Co-regularized hashing for [33] Y. Zhen and D. Y. Yeung. A probabilistic model for [34] X. Zhu, Z. Huang, H. T. Shen, and X. Zhao. Linear
