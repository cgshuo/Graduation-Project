 Information networks, such as social media and email net-works, often contain sensitive information. Releasing such network data could seriously jeopardize individual privacy. Therefore, we need to sanitize network data before the re-lease. In this paper, we present a novel data sanitization solution that infers a network X  X  structure in a differentially private manner. We observe that, by estimating the connec-tion probabilities between vertices instead of considering the observed edges directly, the noise scale enforced by differen-tial privacy can be greatly reduced. Our proposed method infers the network structure by using a statistical hierarchi-cal random graph (HRG) model. The guarantee of differen-tial privacy is achieved by sampling possible HRG structures in the model space via Markov chain Monte Carlo (MCMC). We theoretically prove that the sensitivity of such inference is only O (log n ), where n is the number of vertices in a net-work. This bound implies less noise to be injected than those of existing works. We experimentally evaluate our approach on four real-life network datasets and show that our solution effectively preserves essential network structural properties like degree distribution, shortest path length distribution and influential nodes.
 K.6.5 [ Management of Computing and Information Systems ]: Security and Protection Network data; differential privacy; structural inference
Information networks are invaluable assets for exploratory data analysis in a wide range of real-life applications. For in-stance, online social networks (e.g., Facebook and Twitter) are studied by sociologists to understand human social re-lationships; co-author networks are explored to analyze the degree and patterns of collaboration between researchers; voting and election networks are used to expose different views in the community; trust networks like Epinions are great resources for personalized recommendations. However, many of such networks contain highly sensitive personal in-formation, such as social contacts, personal opinions and private communication records. To respect the privacy of in-dividual participants in the networks, network data cannot be released for public access and scientific studies without proper  X  X anitization X .

Previously, a great deal of work has investigated anonymi-zation techniques [27, 16, 8, 13, 28, 5] to ensure network data privacy. However, it has been shown that anonymization is susceptible to several newly discovered privacy attacks and might lead to further privacy breaches. Recently, differen-tial privacy [9] has been proposed to solve such vulnerabil-ity. In this paper, we study the problem of releasing network data under this emerging privacy standard. Given a network dataset, our goal is to release its sanitized differentially pri-vate version to hide each participant X  X  connections to others while preserving essential structural information to support data analysis.

To ensure differential privacy, the standard technique is to add Laplace noise to query answers. However, network data can be very sensitive to relatively small changes in the network structure. Direct perturbation in the data domain (e.g., adding noise to a subgraph counting query in order to obscure the presence or absence of an edge) normally incurs excessive noise, which makes it impossible to conduct any effective data mining on the sanitized data. An alternative solution is to first project the data to other domains (e.g., the graph spectral domain [25], which is analogous to the classical frequency domain, or some parametric model space that describes the observed network, such as dK -2 series [21, 24]). While this idea is appealing, the resultant data utility of the existing works in this line is still undesirable for many graph mining algorithms. For example, Wang et al. [25] propose to perturb the eigenvalues and eigenvectors of the corresponding adjacency matrix. This approach requires to impose noise of magnitude proportional to O ( is the number of vertices in the input network, and therefore massive noise has to be injected in large real-life network datasets. As another example, the works [21, 24] consider to approximate the original network by the dK -series. To achieve -differential privacy, the global sensitivity of this scheme is O ( n ) even for dK -2 series, which also demands excessive noise to be added.
In this paper, we advocate a different approach that can offer better data utility. Broadly, we propose to encode a network X  X  structural information in terms of connection probabilities between vertices, rather than the presence or absence of the observed edges. The fundamental advantage of adopting such a perspective is that we can capture the generally understandable and statistically meaningful prop-erties of the network while  X  X iluting X  the impact of a single edge. In the context of differential privacy, this means that we can significantly lower the magnitude of noise added to mask the change of a single edge.

In essence, connection probabilities can be estimated by a set of edge-counting queries (i.e., a query that counts the number of edges between two given sets of vertices). There-fore, our problem can be converted to find a strategy that identifies a good set of edge-counting queries in order to truthfully represent a network X  X  structure. This can be done in many possible ways. In particular, in this paper, we use a statistical hierarchical random graph (HRG) model [7] for this purpose. This HRG model carefully maps all partic-ipants of a network into a hierarchical structure (called a dendrogram ) and records connection probabilities between any pair of vertices in the network. This allows us to draw a sample model from the model X  X  space, which essentially con-sists of a set of good edge-counting queries. Moreover, the model itself is paired with a likelihood score, which makes it possible to observe the quality of released data.
Technically, we make the following contributions. Unlike existing studies, we propose to infer a network X  X  structure via connection probabilities. We further identify that the HRG model can be used to encode a network in terms of a set of such connection probabilities. Generating a good HRG under differential privacy requires careful design. We do not directly perturb the best-fitting HRG of the input network (i.e., the HRG generated by the non-private algo-rithm), but rather, we infer the HRG by learning in the en-tire HRG model space and sampling an HRG by a Markov chain Monte Carlo (MCMC) method while satisfying differ-ential privacy. Given a sampled HRG, we propose a care-fully designed thresholding strategy coupled with the Erd  X os-R  X enyi model to calculate the noisy connection probabilities.
We adopt such a methodology for two reasons. First, rely-ing on the best-fitting HRG itself will incur a high sensitivity. Changing even one edge in the network may result in a great number of changes in both the dendrogram X  X  structure and the set of its associated connection probabilities. This is un-desirable since it may alter many of the HRG X  X  parameters in the worst case. In contrast, we design an MCMC method to iteratively learn a reasonably good HRG from the entire HRG space. By construction, with a single edge difference, only one probability in the HRG would be influenced. Sec-ond, it is non-trivial to sample a good HRG in our setting be-cause it is computationally challenging to compute the scores of all possible HRGs even for a small network. It can be seen that there are a total of (2 n  X  3)!!  X  ble dendrograms for a network with n vertices. Hence, it is computationally infeasible to directly apply the exponential mechanism. We side-step this problem by using an MCMC method, which is in a similar spirit to the idea in [23]. How-ever, our problem and challenges are quite different from those in [23]. Our goal is to publish the entire graph, not frequent subgraphs. A direct consequence is that we have to harness the large sensitivity in our problem, while it is always 1 in [23].

From the perspective of utility, we rigorously prove that the sensitivity of our proposed approach is O (log n ) for fit-ting the dendrogram structure, which reaps the benefit of preserving good data utility in theory. We conduct exten-sive experiments on four real-life datasets to evaluate the effectiveness of our solution. We demonstrate that our ap-proach significantly outperforms the state-of-the-art com-petitors [24, 25].
In this section, we briefly introduce the hierarchical ran-dom graph (HRG) model and differential privacy.
In this study, we follow the convention to model an input network dataset as a simple undirected graph G = ( V,E ), where V is the set of vertices and E  X  V  X  V is the set of edges. Let A  X  { 0 , 1 } n  X  n be the adjacency matrix that represents a graph G , where A i,j = 1 if there is an edge between vertices i and j in G and A i,j = 0, otherwise.
The HRG model is based on the intuition that the con-nection probability between two vertices depends on their degree of relatedness, which can be modelled mathemati-cally via statistical inference. Specifically, the HRG model represents a graph G in terms of its hierarchical structure and a set of connection probabilities [6, 7]. The hierarchical structure of G in an HRG is captured by a dendrogram T , which is a rooted binary tree with n leaf nodes correspond-ing to the n vertices of G . Each internal node r of T is associated with a probability p r . For any two vertices i , j of G , their probability of being connected p i,j = p r , where r is their lowest common ancestor in T . Formally, an HRG is defined by a pair ( T, { p r } ).

Let L r and R r be the left and right subtrees of r respec-tively, and n Lr and n Rr be the numbers of leaves in L r R r respectively. Let e r be the number of edges in G whose endpoints are leaves of each of the two subtrees of r in T . The likelihood of an HRG for a given graph G measures how plausible this HRG is to represent G , which can be calcu-lated, by Bayes X  theorem, as follows:
For a fixed dendrogram T , the maximum likelihood esti-mator of p r = e r n edges between the leaves of L r and R r that actually exist in G . In our scheme, we work with the logarithm of the likelihood (referred to as log-likelihood in the sequel): where h ( p r ) =  X  p r log p r  X  (1  X  p r ) log(1  X  p r ) is the Gibbs-Shannon entropy function. Essentially, a dendrogram paired with a higher likelihood is a better representation of the network X  X  structure than those with lower likelihoods. We denote log L ( T, { p r } ) by log L ( T ) from now on when no con-fusion arises.

Example 1. Figure 1(b) and (c) give an example of two possible dendrograms, T 1 and T 2 , for an original graph in Figure 1(a). We first calculate the set of { p r dendrogram. For example, to compute p r 2 associated with the root r 2 of T 2 , we first obtain the two groups of leaf nodes in r 2  X  X  left and right subtrees, that is, { a,b,c } and { d,e,f } . Since there is only one edge between these two sets of leaf nodes (i.e., the edge { c,d } ), we have e p 2 = 1 / (3  X  3) = 1 / 9 . Similarly, we can calculate all { p and compute the likelihoods of the dendrogram T 1 and T Specifically, L ( T 1 ) = (1 / 3)(2 / 3) 2 (1 / 4) 2 (3 / 4) and L ( T 2 ) = (1 / 9)(8 / 9) 8  X  0 . 0433 . Since L ( T larger than L ( T 1 ) , T 2 is a more plausible hierarchy to de-scribe the original graph.
Differential privacy [9] has emerged as a prevalent pri-vacy model to quantify the notion of  X  X ndistinguishability X  of neighboring databases. The privacy guarantee of differ-ential privacy in the context of network data depends on the interpretation of neighboring graphs. In this paper, we define two graphs G 1 = ( V 1 ,E 1 ) and G 2 = ( V 2 ,E 2 neighbors if V 1 = V 2 , E 1  X  E 2 and | E 1 | +1 = | E 2 -differential privacy for network data is defined below.
Definition 1 ( -Differential privacy). A random-ized algorithm A is -differentially private if for any two neighboring graphs G 1 and G 2 , and for any output O  X  Range ( A ) ,
Our definition of differential privacy is also known as edge differential privacy [12]. Intuitively, it hides the existence of any single edge from an adversary. The smaller is, the better the privacy protection is. Normally, is a small value (e.g.,  X  1).

Differential privacy can be achieved by two standard mech-anisms, the Laplace mechanism [9] and the exponential mech-anism [18]. Both mechanisms are based on the concept of global sensitivity of a function f . For any two neighbor-ing graphs G 1 and G 2 , the global sensitivity of a function f : G  X  R d is defined as  X  f = max G 1 ,G 2 k f ( G 1 )  X  f ( G
The Laplace mechanism is mainly used for queries which return real values. It adds properly calibrated noise to the true answer to a query. More precisely, given a function f and the privacy parameter , the noise is drawn from a Laplace distribution with the probability density function p ( x |  X  ) = 1 2  X  e  X  X  x | / X  , where  X  =  X  f/ .

Theorem 1 (Laplace mechanism [9]). For any func-tion f : G  X  R d , the mechanism A gives -differential privacy, where Lap i (  X  f ) are i.i.d Laplace variables with scale parameter  X  f .

The exponential mechanism is mainly used for functions whose outputs are not real numbers. Its general idea is to sample an output O from the output space O accord-ing to a utility function u . It assigns exponentially greater probabilities of being selected to outputs of higher scores so that the final output would be close to the optimum with respect to u . Let the global sensitivity of u be  X  u = max O,G 1 ,G 2 | u ( G 1 ,O )  X  u ( G 2 ,O ) | .

Theorem 2 (Exponential mechanism [18]). Given a utility function u : ( G  X O )  X  R for a graph G , the mech-anism A that samples an output O with probability propor-tional to exp(  X  u ( G,O ) 2 X  u ) satisfies -differential privacy.
Before presenting the details, we first give an overview of our method. Our goal is to release a sanitized network e that matches the structural properties of the original net-work G as closely as possible while satisfying -differential privacy. Our general idea is to identify the hierarchical ran-dom graph (HRG) that best fits G and then generate e G from the identified HRG.

Recall that an HRG consists of a dendrogram T and a set of associated probabilities { p r } . This means that we need to not only identify a good fitting dendrogram but also calculate its associated probabilities. In this process, we face several major technical challenges: (1) How to find a good dendrogram from a factorial number of candidates while satisfying -differential privacy, and (2) how to calcu-late the probabilities that might be dominated by injected noise. We address the first challenge by designing a Markov chain Monte Carlo (MCMC) procedure, which samples a good dendrogram according to its likelihood. We cope with the second challenge by developing an effective thresholding strategy that is backed up by the Erd  X os-R  X enyi model. After generating a representative HRG for G , we generate e G by placing edges according to { p r } .
We now formally describe our solution (referred to as HRG in the sequel). Our solution is composed of three steps: (1) differentially privately sample a good dendrogram T sample from the entire dendrogram space (Algorithm 1); (2) given the sampled dendrogram T sample , compute the probabilities { p r } associated with T sample (Algorithm 2); (3) generate the sanitized graph according to the identified HRG (Algo-rithm 3). We divide the total privacy parameter into 2 portions, 1 and 2 , each being used in one of the first two
Algorithm 1: Differentially Private Dendrogram Fit-ting Input : Input graph G , privacy parameter 1
Output : Sampled dendrogram T sample
Initialize the Markov chain by choosing a random starting dendrogram T 0 ; for each step i of the Markov chain do 3 Randomly pick an internal node r in T i  X  1 ; 4 Pick a neighboring dendrogram T 0 of T i  X  1 by 5 Accept the transition and set T i = T 0 with end return the sampled dendrogram T sample = T i ; steps. Note that the third step does not require any privacy parameter.
 Differentially Private Dendrogram Fitting. Since, for an input graph G with n vertices, each of its dendrograms T is associated with a log-likelihood log L ( T ), which measures its goodness of representing G , a straightforward attempt to achieve differential privacy is to employ the exponential mechanism. Let the utility function be u ( T ) = log L ( T ). The exponential mechanism samples T with probability pro-space (i.e., the set of all possible dendrograms of G ). Unfor-tunately, this simple idea is computationally infeasible be-cause it requires to enumerate a total of |T| = (2 n  X  3)!!  X   X  2(2 n ) n  X  1 e  X  n possible dendrograms. In our solution, we overcome the issue by designing an MCMC process, which simulates the exponential mechanism by a sequence of lo-cal transitions in T . Our differentially private dendrogram fitting algorithm is summarized in Algorithm 1.

Algorithm 1 is based on the Metropolis algorithm [2]. It starts by choosing an arbitrary dendrogram T 0  X  T as the initial state of the Markov chain (Line 1). It then iteratively performs the following procedure (Lines 2-6): randomly pro-pose a neighboring dendrogram T 0 of the dendrogram T i  X  1 in the previous iteration and update the current state in the following way: and  X  u is the global sensitivity of the utility function u . We show how to calculate  X  u in Section 4.2.

To draw a neighbor T 0 of T i  X  1 uniformly at random, we first randomly choose an internal node r in T i  X  1 (other than the root) and then permute the three subtrees associated with r to generate two alternative configurations of r  X  X  sub-trees, as illustrated in Figure 2. One of these two configura-tions is chosen to be the neighboring candidate T 0 . Let the state space of this Markov chain be T . It is easy to verify that the transitions based on this permutation scheme are both reversible and ergodic (i.e., any pair of dendrograms can be connected by a finite sequence of such transitions). Hence, such an MCMC procedure has a unique stationary distribution after it converges to equilibrium. We run the above Markov chain until equilibrium is reached, which indi-cates that the desired distribution has already been reached. Therefore, the sampled dendrogram T sample is indeed drawn from the stationary distribution (Line 8).

In practice, there are many approaches to diagnose MCMC convergence. Here we follow the method used in [6, 7]. Specifically, we use the heuristic of the average log-likelihood to judge whether the Markov chain has converged to the stationary distribution. We will elaborate more details of MCMC convergence time in Section 5.2. Additional discus-sion about the convergence and its mixing time can be found in [6, 7].
 Noisy Probability Calculation. In the second step, we calculate the noisy probabilities associated with T sample internal nodes. Recall that, for an internal node r , its as-sociated probability p r = e r n easy to observe that the probabilities of the internal nodes rooted in smaller subtrees (i.e., in lower levels of T are generally more sensitive to Laplace noise injected. In-deed, according to our experiments, the direct application of the Laplace mechanism to these nodes X  probabilities results in poor utility. To relieve such negative effects, we propose a carefully designed thresholding strategy coupled with the Erd  X os-R  X enyi model, which is presented in Algorithm 2.
The general idea is that if a probability p r cannot be  X  X eliably X  estimated by applying the Laplace mechanism to the probability. To measure the reliability of a noisy prob-ability, we set up the sentinel  X  b . For an internal node r measures the noise scale of the potential noisy probability f p  X  . If  X  b is relatively large with respect to a threshold value  X  1 (that is, the probability cannot be reliably calcu-lated by the Laplace mechanism), we model the subgraph induced by all leaf nodes of the subtree rooted at r an Erd  X os-R  X enyi random graph. With this model, the con-nection probability of any pair of vertices in this subgraph the Laplace mechanism (Line 5). Otherwise, we can ex-pect that e r n noise. Hence we directly generate the noisy probability as cedure on r  X   X  X  children (Lines 11-14).

In Algorithm 2, we calculate the noisy probabilities in a top-down manner over T sample . During this process, the ap-proximated probabilities based on the Erd  X os-R  X enyi model also become less accurate due to added Laplace noise. Here, we would also like to guarantee the accuracy of the per-turbed approximated probabilities. For this reason, we in-Algorithm 2: CalculateNoisyProb ( G,T sample ,r  X  , 2 )
Input : Input graph G , sampled dendrogram T sample ,
Output : A vector of noisy probabilities { e p r } , where if  X  b  X   X  1 and  X  c  X   X  2 then 4 e c ( r  X  )  X  number of edges in the subgraph induced 5 e p = min { 1 , 6 for each r in { r  X  , all internal nodes below r  X  } do 7 e p r = e p ; 8 end else 11 r L  X  r  X   X  X  left child; 12 r R  X  r  X   X  X  right child; end troduce another sentinel  X  c (Line 2), which is compared with a threshold value  X  2 to indicate whether the noise scale of the approximated probabilities is acceptable. In summary, we employ the Erd  X os-R  X enyi model when (1) the probability can-not be accurately estimated by e r  X  + Lap ( and (2) injecting noise to e c ( r  X  ) ( n not seriously affect its accuracy (guarded by  X  c ). This ex-plains our condition in Line 3. In this case, the probabilities of r  X  and all internal nodes below r  X  will be approximated by the Erd  X os-R  X enyi model (Lines 6-8). In our experiments, we observe that setting  X  1 = 0 . 05 and  X  2 = 0 . 01 gives good results over different real-life datasets. Note that the choices of these thresholds are data-independent : the tuning of  X  and  X  2 only relies on 2 .
 Sanitized Graph Generation. With the sampled den-drogram T sample and the set of noisy probabilities { e p generate the sanitized graph as follows (Algorithm 3). For each pair of vertices i,j  X  V , we find their lowest common ancestor r in T sample (Line 4), and then place an edge be-tween them in e G with probability e p r (Line 5).
In this section, we formally analyze the privacy guarantee of our algorithm HRG .
We first show that the MCMC-based Algorithm 1 can satisfy differential privacy. Recall that the main purpose of applying the MCMC method is to draw a random sam-ple from the desired distribution. Essentially, the standard exponential mechanism for achieving differential privacy is Algorithm 3: Generate Sanitized Graph e G
Input : Input graph G , sampled dendrogram T sample ,
Output : Sanitized graph e G for each pair of vertices i,j  X  V do 4 Find the lowest common ancestor r of i and j in 5 Place an edge in e G between i and j with end return sanitized graph e G ; also a method to sample an output x  X  X  in the target dis-tribution with probability proportional to exp( u ( x ) / 2 X  u ), where u ( x ) is the utility function and  X  u is its sensitivity. Hence we see that, by matching the stationary distribution of MCMC with the target distribution required by the ex-ponential mechanism, MCMC can be used to realize the exponential mechanism.

In our setting, we set the utility function u ( T ) of a den-drogram T to be log L ( T ), the log-likelihood of T , and the Therefore, when the Markov chain converges to the station-ary distribution  X  , we indeed draw a sample T from  X  with the probability mass function: This is equivalent to the exponential mechanism which out-puts T with probability proportional to exp( 1 2 X  u  X  log L ( T )). Therefore, we can conclude that Algorithm 1 satisfies differential privacy.

We refer interested readers to [23] in which the idea of applying MCMC to achieve the exponential mechanism was first proposed for more discussion about how MCMC X  X  sta-tionary distribution perfectly matches the required distribu-tion under the exponential mechanism.
We now formally analyze the global sensitivity  X  u . In this section, we will first derive how the utility function u (i.e., log L ( T )) varies in neighboring databases. After that, we will formulate  X  u and show that  X  u monotonically increases as n grows. Lastly, we prove that  X  u is O (log n ).
In this work, we consider each possible output to be a dendrogram T in the output space T . From the definition of global sensitivity, we have the following.

Definition 2 (Global sensitivity  X  u ). where G and G 0 are neighboring graphs.

Intuitively,  X  u is the maximum change in the log-likelihood of any dendrogram in the output space if one edge is miss-ing. It is easy to observe that missing one edge will influence exactly one internal node X  X  probability p r in a dendrogram. Thus, we have:
Lemma 1.  X  u = max We now analyze how  X  u varies as parameters change. Let N = n Lr  X  n Rr . It is easy to see that there are two indepen-dent variables in  X  u , the number of all possible connections N and the number of the observed edges e r .

Theorem 3.  X  u monotonically increases as n  X  +  X  , and is odd.

Proof. To analyze  X  u , we first fix N . Let f ( e ) = h ( p )  X  h ( p 0 ) and  X  u = max | f ( e ) | . Figure 3(a) plots the entropy value h ( p ) as p varies. Since f ( e ) has the format of discrete derivative of h ( p ), we can analyze the monotonicity of f ( e ) by computing the second order derivative of h ( p ). We have concave function and h 0 ( p ) (or the acceleration) monotoni-cally decreases. Therefore, f ( e ) monotonically decreases.
Since  X  u = max | f ( e ) | , we just need to derive the ex-treme values of f ( e ). Note that f ( e ) &gt; 0 when p is in [0,0.5] and f ( e ) &lt; 0 when p is in (0.5,1]. Hence,  X  u = max(  X  min( N  X  f ( e )) , max( N  X  f ( e ))). Due to the symmet-ric property of h ( p ), we can get max( f ( e )) =  X  min( f ( e )). With the monotonic property of f ( e ), we can derive the value of  X  u when e = 1 or e = N max . Next we fix e = 1 and vary N . Let  X  u = max The first order derivative of f ( N ), f 0 ( N ) = log(1  X  0. Hence f ( N ) is a decreasing function. Since f ( N )  X  0 for N in [1 , +  X  ], we conclude that  X  u =  X  min( f ( N )) =  X  f ( N max ). Hence, This completes the proof.

Next we show that  X  u is O (log n ), where n is the number of vertices in the input network.

Theorem 4. The global sensitivity of a dendrogram X  X  log-likelihood,  X  u , is O (log n ) .

Proof. Based on Theorem 3, we first analyze the second term of  X  u , that is, log(1 + 1 N ) x . We have 1 + 1 Since, for each k  X  X  2 , 3 ,...,x } , which increases with x , we learn that y = (1 + 1 x increases with x . As x  X  X  X  , we have lim x  X  X  X  1 + 1 x x = e . Therefore we have: This completes the proof.

Figure 3(b) plots the value of  X  u as n increases. We see that  X  u increases slowly when n becomes larger. Thus we expect that applying the exponential mechanism in terms of MCMC in this setting would guarantee good data utility even for large-scale networks.
Finally, we prove that our solution HRG is -differentially private based on the sequential composition property. Theorem 5 (Sequential Composition [17]). Let each A i provide i -differential privacy. A sequence of A i ( D ) over the database D provides P i -differential privacy.

Taken with the above theorem, we can derive that our scheme ensures -differential privacy.
 Theorem 6. HRG satisfies -differential privacy.

Proof. We use 1 in Algorithm 1 for sampling the den-drogram and 2 in Algorithm 2 for calculating the prob-abilities associated with the sampled dendrogram. From the analysis in above sections, we learn that Algorithm 1 is 1 -differentially private. In Algorithm 2, we employ the Laplace mechanism to obtain the noisy answers to a set of counting queries . Since, by construction of a dendrogram, a single edge change will affect only one counting query by 1, Algorithm 2 is 2 -differentially private. Since Algorithm 3 is based on the differentially private HRG generated by Algorithm 1 and Algorithm 2, it does not consume any privacy budget. Hence, based on Theorem 5, we can con-clude that our solution satisfies -differential privacy, where
In this section, we experimentally study the equilibrium of our MCMC method and evaluate the utility of HRG over four real-life datasets, namely polblogs , wiki-Vote , ca-HepPh and ca-AstroPh 1 . polblogs is a network of hyperlinks be-tween weblogs on US politics recorded in 2005. wiki-Vote is a social network containing Wikipedia voting information for adminship elections. An edge is created between two partic-ipants if one voted on or was voted by the other. ca-HepPh and ca-AstroPh are collaboration networks which cover sci-entific collaborations between authors submitted to High Energy Physics and Astro Physics categories, respectively. An edge is created if two authors co-authored a paper. The statistics of these datasets are given in Table 1. All datasets are pre-processed to be undirected without self-loops. All experiments were done on Intel Xeon E5607 servers with 2.27G CPU and 32GB RAM.
In our first set of experiments, we fix = 1 . 0. Specifi-sampling the dendrogram and computing noisy connection probabilities, respectively (see Figures 5-8). In the second set of experiments, we study the influence of different pri-vacy parameters on data utility. Due to space constraint, we only report the results on wiki-Vote (Figures 9 and 10). We do observe similar trends on other datasets. In the figures, we denote our solution HRG with the legend hrg-1 -e-2 .
For comparison purposes, we implemented two state-of-the-art competitors, spectral [25] and dk2 [24]. Since no systematic approach of choosing parameter values is pro-vided in [25], we tune the parameters in spectral and report the best performance we obtain. More specifically, let k be the number of eigenvalues chosen in the scheme, 1 be the privacy budget for computing noisy eigenvalues and 2 for computing noisy eigenvectors. The literature [26] referred by Wang et al. in [25] suggests that k is usually in [2, 9]. Hence we vary k from 2 to 9 and report the best case. In the figures, spectral is denoted by the legend spec-k -1
Due to the poor performance of dk2 under -differential privacy, we compare with the scheme under a more relaxed privacy notion, that is, ( , X  )-differential privacy. We follow the parameter settings in [24] and set  X  = 0 . 01. Unfortu-nately, even under ( , X  )-differential privacy, we still need to use relatively large values (e.g., 200) to obtain compara-ble results. Moreover, the sensitivity in this case is data-polblogs is available at http://www-personal.umich.edu/ ~mejn/netdata/ ; wiki-Vote , ca-HepPh and ca-AstroPh are available at http://snap.stanford.edu/data/index.html . dependent. It depends on the maximum degree pair in the networks (see Table 1). So we choose values proportional to the maximum degree pair in each network. The choice of parameters for dk2 is denoted by the legend dk2-- X  .
From a privacy X  X  perspective, spectral requires the number of edges in the input network to be known, whereas our scheme HRG and dk2 do not require so. In addition, dk2 is not able to remap the nodes to the observed network, so the experiments on influential node analysis is not applicable to dk2 .
In practice, we diagnose MCMC X  X  convergence by trac-ing the log-likelihood , log L ( T ), of the sampled dendrograms. The diagnostic takes down consecutive non-overlapping win-dows of the Markov chain (each window consists of 65536 MCMC steps in our experiments) and compares the means of log L ( T ) within these windows. We use the difference of the means to judge whether the means of log L ( T ) within the windows have stabilized. In our experiments, we contin-uously examine whether the difference falls into the range the number of nodes in the network.

In Figure 4, we plot the trace of log L ( T ) as a function of the number of MCMC steps, normalized by n . We ob-serve that the Markov chains mix well over all datasets (i.e., log L ( T ) becomes stable soon after the initial state), indicat-ing the convergence to the stationary distributions. Even though the mixing time can be exponential in the worst case [19], we observe that, in practice, the Markov chain in HRG usually can converge within 1000 n steps on networks of around ten thousand nodes. Figure 4 also shows that the integration of differential privacy actually speeds up the movement of the Markov chains and makes them mix even faster. Roughly, the running time of n MCMC steps in our experiments is 0.18s for polblogs , 4.1s for wiki-Vote , 9.5s for ca-HepPh and 22.9s for ca-AstroPh . More details about the mixing time can be found in [6].

Figure 4 also shows the comparison of the sampled den-drograms X  log L ( T ) in different parameter settings, including that of the dendrogram sampled in the non-private manner. We can observe that, for networks with around ten thousand vertices, log L ( T ) of the dendrogram sampled under a rela-tively small privacy parameter (e.g., 1 = 0 . 5) is still compa-rable with that under a relatively large privacy parameter (e.g., 1 = 0 . 9). Hence, we expect that even assigning a relatively small 1 for sampling the dendrogram will not sig-nificantly harm the data utility of the released network. To validate this, we further conduct experiments with smaller , such as 0.2 and 0.4. The performance shown in Fig-ures 9 and 10 confirm that our scheme preserves reasonably good data utility even under a stringent privacy parameter (see Section 5.3 for the explanation of the utility metrics in Figures 9 and 10).
To show the utility of the released networks, we compare their degree distributions, shortest path length distributions and influential node ranking with those of the original net-works. Due to the randomness of our algorithm, we examine the variance of its performance by running the algorithm ten times on each network for each parameter setting. We ob-serve that the variance in all cases is small. Degree Distribution. Figure 5 shows the degree dis-tributions of the released data under different sanitization schemes, with y -axis in log-scale. It can be seen that, in all cases, HRG preserves well the right-skewness of the origi-nal networks, meaning that it preserves good distance scale between  X  X ubs X  (i.e., nodes having high degrees) and the majority of low-degree nodes.
 Shortest Path Length Distribution. Figure 6 depicts the shortest path length distribution of each network. We observe that, in general, the released networks preserve the shapes of the distributions with respect to those of the origi-nal networks. However, we also observe the increase of paths of small lengths (e.g., 1-3). We believe this is due to the ex-tra edges added to the low levels of the sampled dendrogram, which corresponds to the local structures in a network. But this does not have a big influence on the network X  X  global structure.
 Influential Node Analysis. Identifying the most influen-tial nodes in social networks is a key problem in social net-work analysis. In our experiments, we consider the eigen-vector centrality (EVC) score as the measure to rank the nodes in networks. EVC scores correspond to the values of the first leading eigenvector of the graph X  X  adjacency ma-trix (the one with the greatest eigenvalue). Intuitively, EVC measures the nodes X  influence by virture of their positions in a network, that is, the sum of the geodesic distances from each node to all others. The eigenvector approach attempts to find the most central nodes (i.e., those with the small-est geodesic distance to others) in terms of the  X  X lobal X  or  X  X verall X  structure of the network. The first eigenvector usu-ally captures the  X  X lobal X  aspects of distances among nodes, while the second and subsequent ones capture more specific and local structures.

In our experiments, we first test the percentage of common nodes in top-k most influential nodes of the original graphs and those of the sanitized graphs. We examine top 10, 20, 50 influential nodes as well as top 1% and 5% nodes in the networks. The results are presented in Figure 7. We see that HRG guarantees a consistent 25%-75% overlap of common nodes in all the cases.

We then calculate the mean absolute error of the top-k most influential nodes X  EVC scores. Let the set of top-k nodes in the original graph be  X  and that of the sani-tized graph be  X  . To show that nodes in  X  have similar centralities to those in  X  , we use the mean absolute error (MAE) to compare the EVC scores in  X  with those in  X  . Formally, the MAE value is formulated by: MAE (  X , X  ) =
P k i =1 EV C ( v i  X  )  X  EV C ( v i  X  ) , where v i  X  and v top-i nodes in  X  and  X  , respectively. In Figure 8 , we observe that the MAE of HRG with 1 = 0 . 5 and 0 . 9 is reasonably low (e.g., less than 25% in most cases). The overlaps in top-k nodes and the low MAE together indicate that HRG well preserves the hub nodes, which represent the global struc-ture of the sanitized graph.
Early works on privacy-preserving network data publish-ing [16, 27, 28, 5] mainly focus on developing anonymization techniques for specific types of privacy attacks. Most of them employ privacy models derived from k -anonymity [22] by assuming different types of adversarial knowledge. Unfor-tunately, all these anonymization techniques are vulnerable to attackers with stronger background knowledge than as-sumed, which has stimulated the use of differential privacy for more rigorous privacy guarantees.

The recent research on applying differential privacy to net-work data roughly falls into two directions. The first direc-tion aims to release certain differentially private data min-ing results, such as degree distributions, subgraph counts and frequent graph patterns [12, 14, 11, 23]. However, our problem is substantially more challenging than publishing certain network statistics or data mining results. Our goal is to publish the entire graph, which incurs a much larger global sensitivity. Note that the sensitivity in the problem setting of [23] is only 1. In contrast, our key technical contri-bution is to achieve a smaller sensitivity in releasing a graph (i.e., O (log n ) as opposed to O ( n ) and O ( of-the-art competitors [21, 24, 25]). In addition, some latest studies [4, 1, 15] attempt to answer graph queries under a more stringent instantiation of differential privacy known as node differential privacy [12]. In spite of the significant progress, it is still difficult to develop practical solutions un-der node differential privacy in our problem setting.
The second direction aims to publish a sanitized graph, which is also the objective of this paper. Most research in this direction [21, 20, 24] projects an input graph to dK -series and ensures differential privacy on dK -series statis-tics. These private statistics are then either fed into graph generators or used by MCMC to generate a fitting synthetic graph. While the general idea is appealing, the current tech-niques are still inadequate to provide desirable data utility for many graph mining tasks unless the privacy parameter is unreasonably large (e.g.,  X  100), as demonstrated in Section 5. Wang et al. [25] propose to project a graph to the spectral domain and inject noise to the eigenvalues and eigenvectors. This approach successfully reduces the sensi-tivity to O ( achieve good data utility. Comparing with all these stud-ies based on the idea of projection, our approach takes an important step to achieve desirable data utility on real-life datasets in many practical settings. Gupta et al. [10] give an iterative database construction algorithm to generate syn-thetic graphs for answering cut queries. However, it requires an input graph to be dense, which is unlikely to be satisfi-able on real-life network data and leaves finding an efficient algorithm as an open problem. Very recently, Chen et al. [3] propose a data-dependent solution by identifying and recon-structing the dense regions of a graph X  X  adjacency matrix. Though it achieves reasonable utility on some datasets, its performance heavily relies on the fundamental assumption that most edge information must be captured by the dense regions of the adjacency matrix. In addition, this solution involves multiple ad-hoc parameters, which are difficult for a data publisher to tune.
In this paper, we address the privacy concerns in network data release by proposing a novel data sanitization method under differential privacy. Our solution is based on struc-tural inference over the hierarchical random graph (HRG) model. Compared with the existing works, we theoretically prove that the sensitivity of our solution is much smaller, only logarithmic in the order of the network size(i.e., the number of vertices), implying a significant utility improve-ment. Extensive experiments on four real-life datasets con-firm that our solution outperforms the state-of-the-art com-petitors. [1] J. Blocki, A. Blum, A. Datta, and O. Sheffet.
 [2] S. Brooks, A. Gelman, G. L. Jones, and X.-L. Meng. [3] R. Chen, B. C. M. Fung, P. S. Yu, and B. C. Desai. [4] S. Chen and S. Zhou. Recursive mechanism: towards [5] J. Cheng, A. W. C. Fu, and J. Liu. K-isomorphism: [6] A. Clauset, C. Moore, and M. E. J. Newman.
 [7] A. Clauset, C. Moore, and M. E. J. Newman.
 [8] G. Cormode, D. Srivastava, T. Yu, and Q. Zhang. [9] C. Dwork, F. McSherry, K. Nissim, and A. Smith. [10] A. Gupta, A. Roth, and J. Ullman. Iterative [11] M. Hardt and A. Roth. Beating randomized response [12] M. Hay, C. Li, G. Miklau, and D. Jensen. Accurate [13] M. Hay, G. Miklau, D. Jensen, D. F. Towsley, and [14] V. Karwa, S. Raskhodnikova, A. Smith, and [15] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, [16] K. Liu and E. Terzi. Towards identity anonymization [17] F. McSherry. Privacy integrated queries: an extensible [18] F. McSherry and K. Talwar. Mechanism design via [19] E. Mossel and E. Vigoda. Phylogenetic MCMC [20] D. Proserpio, S. Goldberg, and F. McSherry. A [21] A. Sala, X. Zhao, C. Wilson, H. Zheng, and B. Y. [22] P. Samarati. Protecting respondents X  identities in [23] E. Shen and T. Yu. Mining frequent graph patterns [24] Y. Wang and X. Wu. Preserving differential privacy in [25] Y. Wang, X. Wu, and L. Wu. Differential privacy [26] L. Wu, X. Ying, X. Wu, and Z.-H. Zhou. Line [27] B. Zhou and J. Pei. Preserving privacy in social [28] L. Zou, L. Chen, and M. T. Ozsu. K-automorphism: a
