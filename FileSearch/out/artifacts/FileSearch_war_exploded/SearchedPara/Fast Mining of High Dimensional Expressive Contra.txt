 Patterns of contrast are a very important way of comparing multi-dimensional datasets. Such patterns are able to capture regions of high difference between two classes of data, and are useful for hu-man experts and the construction of classifiers. However, mining such patterns is particularly challenging when the number of di-mensions is large. This paper describes a new technique for min-ing several varieties of contrast pattern, based on the use of Zero-Suppressed Binary Decision Diagrams (ZBDDs), a powerful data structure for manipulating sparse data. We study the mining of both simple contrast patterns, such as emerging patterns, and more novel and complex contrasts, which we call disjunctive emerging patterns. A performance study demonstrates our ZBDD technique is highly scalable, substantially improves on state of the art mining for emerging patterns and can be effective for discovering complex contrasts from datasets with thousands of attributes.
 Categories and Subject Descriptors: H.2.8 [Database Manage-ment]: Database Applications-Data Mining General Terms: Algorithms, Design, Performance Keywords: Contrast Patterns, Disjunctive Emerging Patterns, Zero-Suppressed Binary Decision Diagrams
The discovery of distinguishing characteristics and contrasts be-tween classes of data is an important objective in data mining. Such patterns are very useful for human experts and can also be used to build powerful classifiers [18, 20]. In this paper, we propose a new technique for mining contrast patterns in high dimensional space. It is able to mine both simple contrasts, such as emerging patterns [8] and also more complex types of contrasts, whose descriptions allow disjunction, as well as conjunction.

A novel feature of our contrast mining technique is that it is based on the use of Zero-Suppressed Binary Decision Diagrams Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. (ZBDDs) [23] as the core data structure. Binary decision diagrams [6] are a graph based data structure which allow efficient represen-tation and manipulation of boolean formulae, and they have proved extremely effective in diverse fields of computer science, such as SAT solvers [7, 2], VLSI and reliability [29]. ZBDDs are an im-portant variation of binary decision diagrams and are particularly appropriate for compactly representing sparse data.
 Challenges: A key focus of our study is the mining of contrasts for high dimensional data, such as gene expression datasets, where the number of dimensions can be in the thousands and the search space is huge. Previous techniques for mining contrasts in such datasets, e.g. [12, 9, 18], have been unable to handle more than about 60 dimensions. Another challenge arises when contrast pat-terns are allowed to be expressed using disjunction, as well as con-junction. This means the pattern search space is considerably larger and therefore, mining becomes even more challenging.
 Contributions: We make several important contributions in the paper. Organisation: An outline of the remainder of this paper is as fol-lows. Some basic definitions and terminology are given in Section 2. The ZBDD method for mining emerging patterns is described in Section 3. We show in Section 4 how the mining technique gener-alises to more complex types of emerging patterns, which we call disjunctive emerging patterns. This is followed by a performance analysis in Section 5, a discussion in Section 6 and a description of related work in Section 7.
Assume we have a dataset D defined upon a set of k attributes (also referred as dimensions) { A 1 ,A 2 ,...,A k } . Assume a parti-tion of D into two sets, D p (the positive class) and D n ative class). These are the classes that will be contrasted. For every attribute A i , the domain of its values (or items) is denoted by dom ( A i ) . We require domains to be discrete, but they may or may not be ordered. Let | A i | denote the number of elements in dom ( A i ) .Let I be the aggregate of the domains across all the at-tributes, i.e. I = and q be two itemsets. We say p contains q if q is a subset of p ,i.e. q  X  p . The complement of an itemset p , p , is the itemset ( I A dataset is a collection of transactions, where each transaction T is an itemset and we require T to contain exactly one value from the domain of each attribute. The support of an itemset p in dataset D , support ( p, D ) , is the fraction of the transactions in D which contain p ( 0  X  support ( p, D )  X  1 ). We next recall the definition of emerging patterns [8] 1 , a special type of contrast patterns.
Definition 1. Given a positive dataset D p , a negative dataset D and support thresholds  X  and  X  .An Emerging Pattern (EP) is an itemset p satisfying two support constraints, i ) support  X  and ii ) support ( p, D p )  X   X  .Furthermore, p is a minimal EP if p does not contain any other itemset that satisfies constraints i-ii. e.g. Consider Table 1 and suppose  X  =0 . 25 and  X  =0 .The minimal emerging patterns include { a, e } , { i } , { c, h
Emerging patterns have proved to be very useful for building accurate classifiers, as well as providing intuitive descriptions of sharp differences between classes of data [10]. They have also been used for bioinformatics applications, such as understanding leukaemia [18]. Indeed, their popularity is evidenced by the fact that over 50 papers have so far been published in the area. Tech-niques for finding emerging patterns can be found in [9, 12, 4, 3].
In this section, we will describe our approach for mining emerg-ing patterns using Zero-suppressed Binary Decision Diagrams (ZB-DDs). Firstly, we need to present some background material.
In [8], emerging patterns were defined using an  X  threshold and a minimum growth rate  X  .Weuse  X  and  X  thresholds instead, believing it to be more intuitive.
Binary Decision Diagrams (BDDs) are canonical directed acyclic graphs which are efficient representations of boolean formulae, and they allow logical operations (AND, OR, XOR, etc.) to be per-formed in polynomial time with respect to the number of nodes. A Zero-suppressed BDD (ZBDD) is a special type of BDD, in-troduced by Minato in [23] for set-manipulation in combinatorial problems. In particular, this structure has been shown to be very efficient for manipulating sets of sparse combinations. ZBDDs are popular in boolean satisfia bility solvers [7, 2] and in the field of reliability engineering for fault-tree analysis [29]. However, they have received very little attention in data mining (to be discussed more in Section 7). A survey on ZBDD applications can be found in [24].

More formally, a BDD is a canonical directed acyclic graph con-sisting of one source node, multip le internal nodes, and two sink nodes sink-0 and sink-1 . Nodes in a BDD are labelled, and they are ordered. An internal node N with a label x , denoted N node ( x, N 1 ,N 0 ) , encodes the boolean formula N =( x ( x  X  N 0 ) . N 1 (resp. N 0 ) is called the 1 -child (resp. 0 The edge connecting a node to its 1 -child (resp. 0 -child) is called the true-edge ( false-edge ). In the illustrations shown shortly, the solid lines correspond to true-edges and dotted lines correspond to false-edges. Each path from the root node to sink-1 (resp. sink-0) gives a true (resp. false) assignment for the boolean formula.
Two important properties of a BDD which account for the effi-ciency of its operations include: 1. identical subtrees are shared, 2. intermediate results from past computations are stored and can be recalled as needed. Moreover, most BDD operations have a poly-nomial worst-case complexity with respect to the number of nodes.
A ZBDD is a special type of BDD for set combinatorial prob-lems which employs two reduction rules (see Fig.1): 1. Merging rule : equivalent subtrees are shared (to obtain canonicity); 2. Zero-suppression rule : nodes whose true-edge points to These rules al-low a high compression of boolean formulae, i.e. for an n -variable formula, the space of possible truth values is 2 n , the corresponding (Z)BDD can have exponentially fewer nodes.

We follow the ZBDD encodings for representing a collection of itemsets using a strategy similar to work in [23]. An itemset p can be represented by a n -bit binary vector X = ( x 1 ,x where x i =1 if item i is contained in p .Aset S of itemsets can be represented by a characteristic function X S : { 0 { 0 , 1 } ,where X S ( p )=1 if p  X  S and 0 otherwise. In ZBDD semantics, a node N =( x, N 1 ,N 0 ) represents a set S of itemsets such that S = S 0  X  ( S 1  X { x } ) ,where S 1 and S 0 are the sets of itemsets encoded by N 1 and N 0 , respectively. An itemset p in S is interpreted as a conjunction of the items contained in p and yields a true assignment for the boolean formula encoded by N . A ZBDD consisting of only the sink-0 node encodes the empty set (  X  ), and a ZBDD consisting of only the sink-1 node encodes Figure 2: ZBDD representations of a set of itemsets {{ a, b, c, e } , { a, b, d, e } , { b, c, d }} the set of empty itemsets ( { X  X  ). Basic set operations for ZBDDs which will be used in our algorithm include set-union ( A set-difference ( A \ B ), and set-intersection ( A been defined in [23, 26] and are polynomial in the number of nodes in the ZBDD. They are listed in Table 2.

Example 1. The possible ZBDD encodings for set {{ a, b, c, e { graphic ordering, whilst Fig.2(b): c&lt;d&lt;a&lt;e&lt;b . In Fig.2(a), itemsets { a, b, d, e } , { a, b, c, e } shareacommonprefix a common suffix { e } . In Fig.2(b), itemsets { d, a, e, b share a common suffix { a, e, b } , and the suffix { b } is shared among all the itemsets. This set can also be expressed as a DNF formula: ( a  X  b  X  c  X  e )  X  ( a  X  b  X  d  X  e )  X  ( b  X  c  X  d ) Variable Ordering: Depending on the function being represented, the number of nodes in a ZBDD may be highly sensitive to its vari-able ordering. Figure 2 illustrates the different compression that can be achieved by using different variable orderings. The ZBDD in Figure 2(b) contains only 6 non-sink nodes as opposed to the ZBDD using lexicographic ordering which contains 8 nodes. Work in [24] shows that a good variable ordering for compact BDDs (and ZBDDs) has two properties: i. groups of inputs that are closely re-lated should be kept near to each other; ii. inputs that greatly affect the function should be located at hi gher positions in the structure. A number of works have investigated various variable orderings. One approach is based on heuristics and find the appropriate order-ing before the BDD is constructed [13, 1, 32]. Another approach decides an ordering initially, and allows the variables to be per-muted during the construction of the BDD [31]. The latter approach is usually more effective than the former but it may be longer to compute. In this paper, we employ heuristics which are based on the frequency of the variables in the input dataset.
This section describes our algorithm for mining EPs. ZBDDs al-low compression of sparse itemsets and they also allow efficient set operations. Here we use ZBDDs for generating pattern candidates, and also for storing the output patterns. This is similar to exist-ing methods which use structures such as FP-trees[14] and Pattern trees[12].

The search space of EPs is dictated by the contents of the nega-tive dataset and patterns are grown bottom-up in a depth-first fash-ion. Figure 3 shows an example of pattern lattice for a given set of items I = { a, b, c, d } . A bottom-up depth-first enumeration begins with the empty set {} , and the subsequent candidates are the longer patterns as prefixes . The output ZBDD stores the minimal EPs and it is constructed incrementally. To further optimise the algorithm, a number of pruning strategies are employed.
 Early pruning of invalid candidates: In principle, our algorithm could examine a search space covering all possible item combina-tions. However, this is unnecessary and instead we traverse a search space which avoids generating candidate patterns which could never satisfy the  X  constraint. For any given prefix p (candidate), we can partition D n into the set of transactions not containing p (labelled by D p n ) and transactions which contain p (labelled by D needs growing, then it only needs to be extended by an item which plement of one of the transactions in D p n (otherwise a non minimal pattern will result). It is therefore profitable for the input ZBDD to consist of the complements of the transactions in D n (i.e. D Traversing D n ensures that the candidate generation space is much smaller, which is particularly effective if | D n | is relatively small, as is often the case for biological data. Algorithm 1 mineEP( P , prefix , D p , D n ,  X  ,  X  ) 1: if P is a sink node, then 2: // The end of the search space for growing pref ix is reached; 3: // return pref ix as a minimal EP if it passes  X  constraint 5: return 1 6: else 7: return 0 // Remove pref ix from the output ZBDD 8: end if 9: else 11: // Grow pref ix with the next item in the search space 15: zOut x =0 18: zOut x =1 19: else 21: // contain x 23: end if 24: 25: // Mine patterns not containing x from the remaining search space 27: 28: // Non-minimal pattern elimination 31: end if  X  constraint pruning : This strategy is based on the well-known anti-monotonicity, or a-priori principle. Any prefix which doesn X  X  satisfy the  X  constraint should have its supersets pruned. Also, as a pre-processing step, any item whose support ( D p ) &lt; X  can be deleted from D p and D n .  X  constraint pruning: This strategy is based on the monotonicity of the  X  constraint. If a prefix satisfies the  X  constraint, it is not extended any further, since a non minimal pattern would result. Non minimal pattern pruning: Due to the recursive decompo-sition aspect of the algorithm, the generated patterns are locally minimal for each recursion, but they may be non-minimal globally. Hence, it is profitable to immediately prune any non-minimal pat-terns after the completion of each decomposition.

Our algorithm for finding minimal EPs, namely mineEP ,isshown in Algorithm 1, which we will explain line by line. The first in-put parameter, P , is a ZBDD which dictates the remaining candi-dates. prefix is a partially grown pattern, which satisfies the  X  constraint but fails the  X  constraint. D p and D n correspond to the bitmaps from the respective datasets, and are used for computing support . Note: the bitmap of itemset q in dataset D is denoted bitmap ( q, D ) ; support ( q, D ) = num. of ones in bitmap
Mining is invoked by calling mineEP ( D n , {} ,D p ,D n , X , X  and then called upon recursive projections of D n . Lines 1-8 state the terminal condition of the recursion. When it reaches a sink node, it has reached the end of the search space for growing the given prefix .If prefix passes the  X  constraint, it is a satisfy-ing minimal EP and the ZBDD sink-1 node is returned. Otherwise, prefix cannot be part of the output ZBDD, so the sink-0 node is re-turned. The core routines in the algorithm are: 1) compute zOut which grows prefix with the next item x found in the candidates; 2) compute zOut x , which contains the patterns not containing x . They will be the two subtrees of the ZBDD output (line 30).
Before attempting to grow prefix with the next item, x ,theal-gorithm first tests whether the  X  and  X  prunings can be performed. Line 15 prunes prefix new (= prefix  X  X  x } ) and its supersets by the  X  -constraint pruning. The support of prefix new is calcu-lated incrementally using bitmap ( prefix ) which has been com-puted in the previous recursion, i.e. bitmap ( prefix  X  X  x bitmap ( prefix )  X  bitmap ( { x } ) .Line18uses  X  -constraint prun-ingtostop prefix from being grown. Finally, if none of these two cases is applicable, x is appended to the prefix and instances of P which do not contain x are explored, storing the output in zOut
Line 26 computes zOut x from a projection of the database by excluding x . Some itemsets in zOut x may be contained by some itemsets in zOut x . The non-minimal patterns are pruned using a primitive ZBDD operation notSupSet (line 29).
 Optimisations: For the special case where  X  =0 , which cor-responds to the jumping emerging patterns, the EPs must have at least one item in common with each instance in D n . Thus, D its projections can sufficiently be represented using their minimal itemsets. This allows the computation of zOut x (line 26) to be op-timised by processing ( P 0 only contains patterns which may be non-minimal by the item x . Non-minimal pattern elimination (line 29) can thus be computed using ( zOut x \ zOut x ) which is a simpler, thus faster, operation. Optimal variable ordering: We investigated a number of heuris-tics for finding the optimal variable ordering for efficient compu-tation of mineEP , based on the item frequencies in D p and D Three alternative strategies were worthy of consideration.
The first heuristic places the least frequent item in D p of the ZBDD, with subsequent items being ordered by increasing support in D p . This aims to achieve early  X  -constraint pruning which reduces the depth of the recursions, and in turn reduces the number of database projections that are constructed.

The second heuristic places the least frequent item in D n most frequent in D n ) at the top, with other items being ordered by increasing frequency in D n . This can be justified on two levels. Firstly, consider line 22 in the algorithm. Having a smaller P is likely to be advantageous, particularly when the ZBDD at that point is large. Using the most frequent item in D n at the top level means that P 0 is likely to be small for the early recursive calls. Secondly, this heuristic gives higher preference to the  X  constraint, in a similar manner to that for the  X  constraint in the first heuristic, the aim being to achieve early  X  -constraint pruning.

The third heuristic clusters items from the same attribute domain because any emerging pattern contains at most one item from any one attribute, allowing early pruning. Moreover, this ordering can be combined with the other heuristics by ordering the items within each attribute by increasing support in D p (based on the first heuris-tic), or by increasing support in in D n (based on the second heuris-tic). The attributes are then ordered by increasing minimum support of its items.
We now investigate a more general type of contrast patterns, which we will hereafter refer to as a disjunctive emerging patterns .
Recall that emerging patterns correspond to conjunctions of items that have high support in D p and low support in D n ., e.g. a was an EP for Table 1, given  X  =0 . 25 and  X  =0 . Disjunc-tive emerging patterns (disjunctive EPs) generalise EPs by allow-ing disjunctions as well as conjunctions for pattern descriptions. They essentially correspond to a restricted class of CNF formulae, which use items as variables and are a conjunction of disjunctions, where each disjunction contains only items coming from the same attribute domain. No negation is allowed and there must exist at least one item from each attribute domain in the formula. e.g. Given a dataset having three attributes A 1 ,A 2 ,A 3 mains { a 1 ,a 2 ,a 3 } , { b 1 ,b 2 ,b 3 } , { c 1 ,c 2 ,c EP may be represented by a formula f ,where f =( a 1  X  a 3 ( b 1  X  b 2 )  X  ( c 1  X  c 2  X  c 3 ) . Without any ambiguity, we can alter-nately represent f as an itemset { a 1 ,a 3 ,b 1 ,b 2 ,c 1 it is implicitly understood that conjunctions exist across attributes and disjunctions exist within attributes. Henceforth, we will blur the distinction between disjunctive formulae and their itemset rep-resentations.

Given a formula describing a disjunctive emerging pattern, we need to be able to calculate its support.

Definition 2. Let s be a disjunctive emerging pattern. The sup-port of s in a dataset D , support ( s, D ) , is the number of instances from D which are contained in (the itemset representation of) s .
Using this revised definition of support , we can define appro-priate  X  and  X  support thresholds for disjunctive EPs.
 Definition 3. Given D p , D n and support thresholds  X  and  X  . A disjunctive emerging pattern is an itemset d such that i) d contains at least one item from the domain of every attribute, ii) support ( d, D p )  X   X  , and iii) support ( d, D n )  X   X  . d is said to be maximal if there does not exist another disjunctive emerging pattern d such that d  X  d .

Observe that a disjunctive EP corresponds to a region of high contrast, i.e. a subspace which contains at least  X  instances from D p and at most  X  instances from D n . (see Figure 4 for illustra-tion of the geometric representation of itemsets given three attribute domains { a 1 ,a 2 ,a 3 } , { b 1 ,b 2 ,b 3 } , { c 1 ,c 2 again Table 1 and suppose  X  =0 . 5 and  X  =0 . The maximal dis-junctive EPs include { a, c, d, e, f, h, i } and { a, b, d, e, g, i a classification perspective, an unknown data instance seems more likely to be from the positive class if is contained in one of these itemsets.

It is possible to define variants of disjunctive EPs. One impor-tant case arises for datasets with ordered domains. and effectively corresponds to disjunctive EPs having contiguous ranges on each attribute. Suppose an attribute A i has an ordered domain of items. We define a contiguous subset of dom ( A i ) as a collection of items which appear consecutively in the order of dom ( A i ) . An itemset is contiguous if it does not contain any non-contiguous subsets from the domain of each attribute. Consider again Figure 4, s 1 contiguous, whilst s 2 is contiguous.

Definition 4. Given datasets D p and D n , an itemset S is a max-imal contiguous disjunctive emerging pattern if i) S is contigu-ous, ii) support ( S, D p )  X   X  , iii) support ( S, D n )  X  There is no proper superset of S satisfying conditions i-iii.
Compared to disjunctive EPs, contiguous disjunctive EPs might be considered more meaningful to humans, since their correspond-ing regions are connected, i.e. do not contain any gaps or holes. We now examine the relationship between disjunctive EPs and EPs in more detail. Broadly speaking, disjunctive EPs can be viewed as generalisations of EPs, allowing more expressive contrasts.
T HEOREM 1. Let p be an emerging pattern. Then p is con-tained in some disjunctive emerging pattern using the same  X  and  X  support thresholds.

Observe that the converse of this theorem does not hold. It is often true that a disjunctive EP does not contain any EP. e.g. There is no EP in Table 1 if  X  =0 . 5 and  X  =0 , yet there exist several disjunctive EPs satisfying these constraints.

Also observe that multiple EPs of lower support can be merged together to form a disjunctive emerging pattern. e.g. Again looking at Table 1, both { a, d } and { a, e } are EPs when  X  =0 . 0 . They correspond to the boolean formulae a  X  d and a  X  e , each having support ( D p )=0 . 25 . These two EPs can be  X  X nioned X  to yield a  X  ( d  X  e ) , which is equivalent to the disjunctive EP a e having support ( D p )=0 . 5 and support ( D n )=0 .

An interesting special case exists when the cardinality of the do-main for every attribute is exactly two. In this circumstance, the two types of EPs coincide.

To summarise, the key differences between emerging patterns and disjunctive emerging patterns are:
Being more expressive, disjunctive EPs are more complex to compute. However, it turns out we can still accomplish this effi-ciently using a technique similar to the algorithm in Section 3.2.
We now describe how our mineEP algorithm can be adapted for mining maximal disjunctive EPs. The algorithm is called mineDEP (shown in Algorithm 2). Being similar to mineEP , we will only point out their main differences.
Because of the generality of disjunctive EPs, they are likely to contain many items. Our approach for mining disjunctive EPs ex-plores the pattern lattice in a depth-first top-down manner, rather than the bottom-up manner that was used for mining EPs. A top-down enumeration of the patterns begins with the most general itemset (i.e. containing all the items) and at each step, generate shorter itemsets as candidates (refer to Figure 3 for illustration). For efficiency purposes, it is better to work with pattern comple-ments, which are likely to contain fewer items, rather than the pat-terns themselves. So, candidates are generated by growing prefixes in this complemented pattern space. The initial input ZBDD is built from D n . Again, this aims to eliminate the generation of invalid candidates, but D n is used here instead of D n which was used in mineEP since the enumeration of the maximal disjunctive EPs is proceeding top-down, rather than bottom-up.

Pruning based on the  X  and  X  constraints is similar to that used in mineEP . Support checking, however, must be done using pat-tern complements and so intersection tests, rather than containment tests are performed on the bitmaps. e.g. If a disjunctive EP p is re-quired to have support ( p, D n )  X   X  , then its complement p must satisfy cover 2 ( p, D n )  X  (1  X   X  ) . Similarly, the  X  constraint can be translated to cover ( p, D p )  X  (1  X   X  ) .

The conditions for  X  and  X  pruning are also different to that of the previous algorithm. These conditions for  X  and  X  pruning are inverted from mineEP , since maximal, rather than minimal pat-terns are being computed. More precisely, exploration of the search space stops if one of the following conditions is satisfied: 1) if support ( prefix new ,D p ) &lt; X  ,i.e. cover ( prefix (1  X   X  ) ,thendo  X  constraint pruning (line 15); 2) if support ( prefix new ,D n )  X   X  ,i.e. cover ( prefix (1  X   X  ) ,thendo  X  constraint pruning (line 18).
 Finally, the terminal case tests whether support ( prefix cover ( prefix, D n )  X  (1  X   X  ) (line 1-8). The algorithm is ini-tialised by passing the negative dataset D n to its first parameter, i.e. mineDEP ( D n , {} ,D p ,D n , X , X  ) .

Finally, the ZBDD variable ordering locates the item which most frequently occurs in D n at the top and items are ordered decreas-ingly by their frequency in D n thereafter. This is essentially the inverse of the second ordering heuristic that was used for mineEP , again due to the top-down nature of the search strategy.
As we have seen, contiguous disjunctive EPs are subclass of dis-junctive EPs. We now define another more general subclass of dis-junctive EPs, namely g -contiguous disjunctive EPs , and describe a technique for mining them.

Suppose an attribute A i has an ordered domain of items. We define a g -contiguous subset of dom ( A i ) as a collection of items which appear in the same order in dom ( A i ) and the gap between any two consecutive items is not larger than g . An itemset is g -contiguous if it does not contain any non-g -contiguous subsets from the domain of each attribute. Furthermore, an itemset p is a maxi-mal g -contiguous disjunctive EP if: i) p is a disjunctive EP, ii) p is g -contiguous, iii) none of its proper supersets satisfies conditions i-ii. When g =0 , p is a contiguous disjunctive EP.

We propose a post-processing operation, contigSplit ,toderive the maximal g -contiguous disjunctive EPs from the disjunctive EPs found using mineDEP . It complements each of the input itemsets and splits it into maximal subsets satisfying the given g and  X  con-straints (it is guaranteed that they satisfy the  X  constraint). The pseudo code is shown in Algorithm 3. It begins mining by calling cover ( p, D ) = the fraction of the transactions in D which contain some item in p ; cover ( p, D )=1  X  support ( p, D ) .
 Algorithm 2 mineDEP( P , prefix , D p , D n ,  X  ,  X  ) 1: if P is a ZBDD sink node, then 2: // The end of the search space for growing pref ix is reached 3: // pref ix is a satisfying pattern if it passes  X  constraint 5: return 1 6: else 7: return 0 // Remove pref ix from the output ZBDD 8: end if 9: else 11: // Grow pref ix with the next item in the search space 15: zOut x =0 18: zOut x =1 19: else 21: // contain x 23: end if 24: 25: // Explore candidates from the remaining search space 27: 28: // Non-minimal patterns elimination 31: end if contigSplit ( Z dEP , attrDomains, g ) ,where Z dEP is a ZBDD of the complement of maximal disjunctive EPs, attrDomains is a vector of ZBDDs, each of which contains the domain items from each attribute, g is the gap size threshold. Conceptually, every dis-junctive EP has a set of maximal g -contiguous subsets induced in each dimension, computed using a splitComplement subroutine which we will explain shortly, and these subsets across dimen-sions are pair-wise unioned using an efficient ZBDD operation, DotP rod .The  X  constraint is pushed inside the routines in a sim-ilar manner to that in the mineDEP algorithm.

The subroutine splitComplement complements a given item-set Q with respect to a set of domain items D , and simultaneously splits it into maximal subsets satisfying a g constraint. prefix is the output candidate. Two ZBDDs containing Q and D , respec-tively, are traversed in parallel, and prefix is grown by appending items in D which do not occur in Q (line 13-14). The parame-ter gapSize indicates the number of items that have been skipped since the last item that was inserted to prefix ( gapSize when prefix = {} ). Thus, every sequential item occurring in Q increments gapSize by 1 (line16). If gapSize has reached the threshold, then prefix is a maximal g -contiguous subset, and a new empty prefix is grown using the remaining items (line 18). Fi-nally, if there are no items in Q , D gives the complement of Q and it is a maximal contiguous subset of Q . Thus, the union of the respective itemsets D and prefix is returned (line 3). Algorithm 3 contigSplit( P , attrDomains , g ) 1: zOut = {} // initialisation 2: for all itemsets p in P do 3: // Compute projection of p in the domain of each attribute 5: 6: // Compute split-complement of p in the dimension of each attribute, 7: // and conjugate the g -contig. subsets from across dimensions 8: pref ixes = {{}} 9: for all i in 1 ,.. k do 11: pref ixes = DotProd( pref ixes, splits i ) 12: end for 13: zOut = zOut 14: end for 15: return zOut 1: if ( Q is a ZBDD sink node ) then 2: // Q contains an empty itemset; Q = D and it has no gap 3: zOut = DotProd( D , pref ix ) 4: else 7: 9: // otherwise, increment gapSize ,or,if gapSize = g , 10: // pref ix is fully grown and a new empty prefix is grown. 11: if ( x has higher index than y ) then 12: // y is not in Q , turn on the bit of y in pref ix 15: else if ( gapSize &lt; g ) then 17: else if ( gapSize = g ) then 18: zOut = pref ix 19: end if 20: end if 21: return zOut
In this section we assess the performance of our techniques for mining emerging patterns and disjunctive emerging patterns.
Our algorithms were implemented in C++ using the ZBDD li-brary functions in the CUDD package [34] and EXTRA library [26]. All experiments were conducted on a IBM eServer pSeries 650 (eight POWER4+ 1.45GHz CPU, 16 GB RAM) running AIX 5L 5.2 with a cpu-time limit 100,000 seconds. The ordering used for our ZBDD algorithms was decreasing frequency in D n , based on the second heuristic. This section will conclude with a study comparing the performance of mining disjunctive EPs using differ-ent variable ordering heuristics.

We carried out experiments on two gene-expression datasets the Leukaemia dataset ALL-AML, previously studied in [18] and lung cancer. Table 3 shows their characteristics. Column 1 (resp. http://research.i2r.a-star.edu.sg/rp/ Column 2) shows the class which was chosen as positive (resp. negative) class and its corresponding number of instances. These datasets were chosen due to their challenging characteristics. As is common for biological data, they contain a huge number of di-mensions but only have a few instances. Work in [19, 20, 18] have studied mining minimal emerging patterns for these datasets.
Both datasets have continuous attribute domains. The values were discretised using an entropy discretisation method, which had the effect of removing some of the attributes. After discretisation, the ALL-AML dataset is reduced to 865 attributes, lung cancer is reduced to 2172 attributes. The discretised attributes are ordered by decreasing entropy value.
We study the scalability of our ZBDD technique for mining (min-imal) emerging patterns and compare it against a state of the art technique based on a variant of frequent pattern trees [12] (here-after referred to as Pattern-Tree EP-miner). The authors of this pa-per provided us with an implementation of their algorithm. Other techniques for mining emerging patterns exist (e.g. [4, 3]), but have similar, or inferior running behaviour to that of [12] and so we do not include them in our comparison.

The first scenario uses the ALL-AML data with constraints  X  90% and  X  =0 , and an increasing number of dimensions. Look-ing at Figure 5a and Figure 5b, the mining time of ZBDD EP-miner is substantially faster than Pattern-tree EP-miner by a factor of ap-proximately 100 times for between 40 and 68 attributes (the ZBDD miner running time is very close to the x -axis in this region). For more than 68 attributes, mining was impossible for the Pattern-Tree EP-miner due to memory limits being exceeded, whereas the ZBDD EP-miner was able to run effectively for up to 800 attributes. This is in line with previously published results from [18, 9], where EPs were only mineable for datasets with no more than around 70 attributes. For the Lung Cancer dataset which appears to be an eas-ier dataset due to the smaller number of patterns, the Pattern-Tree miner is able to mine EPs for a larger number of attributes. The ZBDD EP-miner is substantially superior in running time to the Pattern-Tree miner, giving speedups of over 100 times, and it was able to run effectively for up to 1700 attributes.
We now study the scalability of our ZBDD algorithm for mining (maximal) disjunctive EP. In particular, we focus on its behaviour as we vary number of attributes and the value of  X  . No comparison is made against other systems, since we are not aware of any other work that is suitable for mining these patterns.
 Varying the number of dimensions . Figure 5c and Figure 5d show the time for mining maximal disjunctive emerging patterns as the number of attributes is varied for both datasets. Support con-straints  X  = 90% and  X  = 10% are used. The number of patterns output is shown in Figure 5e and Figure 5f. Not surprisingly, in-cluding more dimensions increases the search space, the size of the output patterns, and also the running time, exponentially.
Importantly though, the ZBDD technique is able to mine this complex kind of patterns even when there are a very large num-ber of attributes. The maximal disjunctive EPs for the lung cancer dataset are mined in around 60000 seconds using all its attributes (2172 attributes). For the ALL-AML dataset, up to 700 attributes can be handled in around 1000 seconds. Mining beyond this at-tribute limit was proved impossible because of memory limits be-ing exceeded, due to the very large number of output patterns.
Since the output patterns are stored in a ZBDD, it is interesting to reflect on the compression being achieved. Figure 5g shows the number of ZBDD nodes in the output, for the lung cancer data with respect to varying the number of attributes, given  X  = 90%  X  = 10% . When there are 2172 attributes, the ZBDD requires 1236100 nodes, to store the 2080960 maximal disjunctive emerg-ing patterns. Figure 5h gives a more detailed picture, presenting a histogram of the pattern lengths. We can see that most of the patterns are close to the maximum length of 4371 items having an average length of around 4367 items.
 Varying the support thresholds. Figure 5i and Figure 5j show the output patterns in ALL-AML dataset (using 1000 items) and in lung cancer dataset (using 3500 items) according to an increasing  X  constraint (given  X  =0 ). We can see that for both datasets, the number of patterns output is highly sensitive to  X  up to a certain limit (around 45%), with its sensitivity thereafter decreasing. Comparative pattern volumes and mining time: Finally, we compare the volumes of the different kinds of EP in a given dataset. Figure 5k looks at the lung cancer dataset, using 230 items and  X  =0 , allowing  X  to vary. The figure shows the number of i) min-imal emerging patterns, ii) maximal disjunctive emerging patterns, and iii) maximal contiguous disjuncti ve emerging patterns. For this scenario, it is clear that there exist fewer EPs than the disjunctive EPs and their contiguous variants. This is expected, since EPs are more specific versions of the disjunctive patterns. Though it is not shown here, in our experience, it can often be the case that under given support thresholds, a dataset may contain zero EPs, but may contain hundreds of (possibly contiguous) disjunctive EPs.
The corresponding mining times for this dataset is shown in Fig-ure 5l. The mining times for mining EPs and disjunctive EPs lie on the x -axis, and the times for mining contiguous EPs are higher due to the postprocessing splitting operation. It can be seen that the splitting time is constant with respect to a varying number of patterns from varying  X  . Indeed, all the algorithms have a roughly constant time with respect to  X  for this scenario. We also study the effect of using various variable orderings in the ZBDD for mining disjunctive EPs. Figures 5m, 5n, and 5o show a comparison between the different heuristics we considered. The first heuristic is employed by ordering the variables by decreasing frequency in D p . The second heuristic is employed by ordering the variables by decreasing frequency in D n . Lastly, the third heuristic is employed by arranging items from the same attribute close to each other and two-level ordering is used, i.e. items within each attribute are ordered by decreasing support in D n and the attributes are ordered by decreasing maximum support of its items. Figure 5m shows that employing the second ordering on the ZB-DDs achieves the fastest mining time as it reduces the complexity of the decomposed subtasks. Shown in Figure 5n, the correspond-ing input ZBDDs have similar sizes using either the second or the third ordering, but the mining times for the third ordering grow ex-ponentially as  X  decreases. The first ordering produces larger input ZBDDs, which explains its mining time being the slowest. Fur-thermore, Figure 5o shows that the output ZBDDs are the smallest when the second and the third orderings are used.
The results in the previous section are only a snapshot of the experiments we performed. We also tested our techniques on a number of other biological datasets, with performance being simi-larly pleasing overall. A general conclusion from our work is that ZBDDs can be used for very effective mining of both emerging pat-terns and disjunctive emerging patterns. A natural question to ask is, what advantages does a ZBDD technique have over a frequent-pattern tree (fp-tree) technique for mining contrasts? Here we pro-vide some preliminary observations.

Both fp-trees and ZBDDs are tree-like structures for storing trans-actions using a variable ordering. A structural difference between the two is that ZBDDs allow sharing of transactions via fan-in, whereas fp-trees do not allow fan in. The use of fan-in allows not only prefix sharing but also suffix sharing, resulting a high com-pression of both input and output. Furthermore, ZBDDs also allow sharing between all structures throughout mining since it uses a global variable ordering. In particular, it is possible for the input ZBDD (the transactions), the input projection in the intermediate mining steps, and the output ZBDD, to share subtrees even though each of them represents different kinds of data! This provision of increased opportunities for sharing a nd compression is particularly important for high dimensional datasets, where the number of can-didates can be very large and mining practicality may be dependent on memory consumption considerations.

Another significance of our technique is in the recursive decom-positions. When a ZBDD is recursively decomposed, its decompo-sitions are able to share substructures with one another. A shared structure is constructed only once and results from past manipula-tions are re-used as needed. This is different from fp-trees, whose recursive decompositions (conditional fp-trees) are created afresh and do not share with one another.

A final important aspect of ZBDD is the existence of polynomial time operations, such as set (minimal/maximal) union, set differ-ence, etc, especially when there is a large amount of sharing within the structure. One implication of this is an efficient removal of non-maximal patterns. Considerable work has gone into develop-ing efficient library implementations of these and our algorithms make considerable use of them. It is an open question as to whether provably efficient counterpart operations exist for fp-trees.
We have already referred to the general work in the area of ZBDD in Section 3.1. However, we are only aware of one paper [25] where ZBDD is used for pattern mining. They propose a method for finding frequent patterns. Their approach is different from ours in the sense that they explicitly store the support information by constructing multiple shared-ZBDDs which groups itemsets based on their (binary-encoded) supports. It enumerates every pattern oc-curring at least once in the dataset, regardless of the input threshold value  X  supplied by the user, making it inefficient for high values of  X  or for mining in high dimensional data since millions of patterns may exist. On the other hand, our proposal stores the input transac-tions in a single ZBDD, reducing its overall memory consumption, and pushes constraints deep inside the ZBDD operations. Addition-ally, we use a secondary data structure such as bitmaps for counting support, instead of storing support information inside the ZBDD.
Emerging patterns were introduced in [8], and have been suc-cessfully used for constructing highly accurate classifiers [17]. In particular, work in [10] have proposed a strong EP-based classi-fier using an  X  support constraint and a minimum growth rate con-straint. Moreover, emerging patterns have also been used for pre-dicting the likelihood of diseases such as leukaemia [18] using gene expression data [19]. A recent method for mining emerging patterns with zero support in the negative dataset appears in [12], based on modifications to fp-tree [14]. Fp-trees have also been used as the basis for mining contrasts given other types of con-straints, such as risk and odds ratio [16]. Connections between the computation of certain kinds of emerging patterns and hypergraph transversals are identified in [4].

Emerging patterns are closely related to association rules with large confidence [37] and also to work on detecting group differ-ences [5]. Quantitative association rules [36] aim to find contigu-ous regions containing a minimum number of points. Moreover, contiguous disjunctive em erging patterns are similar to quantitative association rules having high confidence and a single item conse-quent. Another related notion is version spaces [27, 15], which cor-respond to emerging patterns with constraints  X  =1 and  X  =0 disjunctive version space [33] is a disjunction of version spaces, as opposed to the disjunctive emerging patterns presented here, which are a conjunction of disjunctions on attribute values. Several pa-pers have examined the computation of empty regions or  X  X oles X  in datasets [11, 21]. A contiguous disjunctive emerging pattern with  X  =0 corresponds to a hole in D n .

Recent work have examined mining of closed patterns from high dimensional datasets using row, instead of column (item), enumer-ation [28, 30, 22]. The emphasis on closed patterns, as opposed to minimal patterns means this is not directly applicable for finding minimal contrasts. However, alternative variants of emerging pat-terns based on closure properties can certainly be defined, e.g. see [35]. In contrast to the row enumeration work, our paper seeks to investigate the limits of column-wise mining and indeed our results showed that column-wise mining of contrasts in high dimensional datasets is feasible using ZBDDs.
In this paper, we have developed efficient algorithms for mining contrast patterns in high dimensional data. We presented an algo-rithm based on the use of Zero Suppressed BDD as a data struc-ture and demonstrated how mining constraints could be integrated with the standard ZBDD library routines. Our experimental results showed the technique scales well for a number of high dimensional biological datasets and allows the computation of both simple con-trasts such as emerging patterns, and also more complex type of contrasts which use both disjunction and conjunction. We showed our method substantially improves on a state of the art EP-mining technique [12]. We are not aware of other work suitable for com-puting the complex contrasts considered. As future work, we intend to explore the use of ZBDDs for mining other types of patterns, and also their use in row enumeration mining approaches.

