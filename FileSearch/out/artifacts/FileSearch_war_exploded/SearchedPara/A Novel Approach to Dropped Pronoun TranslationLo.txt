 In pro-drop languages, certain classes of pronouns can be omitted to make the sentence compact yet comprehensible when the identity of the pronouns can be inferred from the context (Yang et al., 2015). Figure 1 shows an example, in which Chinese is a pro-drop language (Huang, 1984), while English is not (Haspelmath, 2001). On the Chinese side, the subject pronouns {  X  ( you ),  X  ( I ) } and the object pronouns {  X  ( it ),  X  ( you ) } are omitted in the di-alogue between Speakers A and B . These omis-sions may not be problems for humans since peo-ple can easily recall the missing pronouns from the context. However, this poses difficulties for Sta-tistical Machine Translation (SMT) from pro-drop languages (e.g. Chinese) to non-pro-drop languages (e.g. English), since translation of such missing pro-nouns cannot be normally reproduced. Generally, this phenomenon is more common in informal gen-res such as dialogues and conversations than oth-ers (Yang et al., 2015). We also validated this finding by analysing a large Chinese X  X nglish dialogue cor-pus which consists of 1M sentence pairs extracted from movie and TV episode subtitles. We found that there are 6.5M Chinese pronouns and 9.4M English pronouns, which shows that more than 2.9 million Chinese pronouns are missing.

In response to this problem, we propose to find a general and replicable way to improve translation quality. The main challenge of this research is that training data for DP generation are scarce. Most works either apply manual annotation (Yang et al., 2015) or use existing but small-scale resources such as the Penn Treebank (Chung and Gildea, 2010; Xi-ang et al., 2013). In contrast, we employ an un-supervised approach to automatically build a large-scale training corpus for DP generation using align-ment information from parallel corpora. The idea is that parallel corpora available in SMT can be used to project the missing pronouns from the target side (i.e. non-pro-drop language) to the source side (i.e. pro-drop language). To this end, we propose a sim-ple but effective method: a bi-directional search al-gorithm with Language Model (LM) scoring.

After building the training data for DP genera-tion, we apply a supervised approach to build our DP generator. We divide the DP generation task into two phases: DP detection (from which position a pronoun is dropped), and DP prediction (which pronoun is dropped). Due to the powerful capac-ity of feature learning and representation learning, we model the DP detection problem as sequential labelling with Recurrent Neural Networks (RNNs) and model the prediction problem as classification with Multi-Layer Perceptron (MLP) using features at various levels: from lexical, through contextual, to syntax.

Finally, we try to improve the translation of missing pronouns by explicitly recalling DPs for both parallel data and monolingual input sentences. More specifically, we extract an additional rule ta-ble from the DP-inserted parallel corpus to produce a  X  X ronoun-complete X  translation model. In addi-tion, we pre-process the input sentences by insert-ing possible DPs via the DP generation model. This makes the input sentences more consistent with the additional pronoun-complete rule table. To allevi-ate the propagation of DP prediction errors, we feed the translation system N -best prediction results via confusion network decoding (Rosti et al., 2007).
To validate the effect of the proposed approach, we carried out experiments on a Chinese X  X nglish translation task. Experimental results on a large-scale subtitle corpus show that our approach im-proves translation performance by 0.61 BLEU points (Papineni et al., 2002) using the additional translation model trained on the DP-inserted cor-pus. Working together with DP-generated input sen-tences achieves a further improvement of nearly 1.0 BLEU point. Furthermore, translation performance with N -best integration is much better than its 1-best counterpart (i.e. +0.84 BLEU points).

Generally, the contributions of this paper include the following:  X  We propose an automatic method to build a  X  Benefiting from representation learning, our  X  To decrease the negative effects on translation The rest of the paper is organized as follows. In Section 2, we describe our approaches to building the DP corpus, DP generator and SMT integration. Related work is described in Section 3. The exper-imental results for both the DP generator and trans-lation are reported in Section 4. Section 5 analyses some real examples which is followed by our con-clusion in Section 6. The architecture of our proposed method is shown in Figure 2, which can be divided into three phases: DP corpus annotation, DP generation, and SMT in-tegration. 2.1 DP Training Corpus Annotation We propose an approach to automatically annotate DPs by utilizing alignment information. Given a parallel corpus, we first use an unsupervised word alignment method (Och and Ney, 2003; Tu et al., 2012) to produce a word alignment. From observ-ing of the alignment matrix, we found it is possi-ble to detect DPs by projecting misaligned pronouns from the non-pro-drop target side (English) to the pro-drop source side (Chinese). In this work, we fo-cus on nominative and accusative pronouns includ-ing personal, possessive and reflexive instances, as listed in Table 1.
We use an example to illustrate our idea. Figure 3 features a dropped pronoun  X   X   X  (not shown) on the source side, which is aligned to the second  X  I  X  (in red) on the target side. For each pronoun on the tar-get side (e.g.  X  I  X ,  X  you  X ), we first check whether it has an aligned pronoun on the source side. We find that the second  X  I  X  is not aligned to any source word and possibly corresponds to a DP I (e.g.  X   X   X ). To determine the possible positions of DP I on the source side, we employ a diagonal heuristic based on the observation that there exists a diagonal rule in the local area of the alignment matrix. For ex-ample, the alignment blocks in Figure 3 generally follow a diagonal line. Therefore, the pronoun  X  I  X  on the target side can be projected to the purple area (i.e.  X   X   X   X   X   X ) on the source side, according to the preceding and following alignment blocks (i.e.  X  you - X   X  and  X  want - X   X ).

However, there are still three possible positions to insert DP I (i.e. the three gaps in the purple area). To further determine the exact position of DP I , we generate possible sentences by inserting the corre-Then we employ an n -gram language model (LM) to score these candidates and select the one with the lowest perplexity as final result. This LM-based pro-jection is based on the observation that the amount and type of DPs are very different in different gen-res. We hypothesize that the DP position can be determined by utilizing the inconsistency of DPs in different domains. Therefore, the LM is trained on a large amount of webpage data (detailed in Section 3.1). Considering the problem of incorrect DP in-sertion caused by incorrect alignment, we add the original sentence into the LM scoring to reduce im-possible insertions (noise). 2.2 DP Generation In light of the recent success of applying deep neu-ral network technologies in natural language pro-cessing (Raymond and Riccardi, 2007; Mesnil et al., 2013), we propose a neural network-based DP gen-erator via the DP-inserted corpus (Section 2.1). We first employ an RNN to predict the DP position, and then train a classifier using multilayer perceptrons to generate our N -best DP results. 2.2.1 DP detection
The task of DP position detection is to la-bel words if there are pronouns missing be-fore the words, which can intuitively be re-garded as a sequence labelling problem. We expect the output to be a sequence of la-given a sentence consisting of words are two labels L = { N A, DP } (corresponding to
Word embeddings (Mikolov et al., 2013) are used where d is the dimension of the representation vec-tors. In order to capture short-term temporal depen-dencies, we feed the RNN unit a window of context, as in Equation (1): where k is the window size.

We employ an RNN (Mesnil et al., 2013) to learn the dependency of sentences, which can be formu-lated as Equation (2): where f ( x ) is a sigmoid function at the hidden layer. U is the weight matrix between the raw input and ID. Description 1 S surrounding words around p 2 S surrounding POS tags around p 3 preceding pronoun in the same sentence 4 following pronoun in the same sentence 5 pronouns in preceding X sentences 6 pronouns in following X sentences 7 nouns in preceding Y sentences 8 nouns in following Y sentences 9 path from current word ( p ) to the root 10 path from preceding word ( p  X  1 ) to the root the hidden nodes, and V is the weight matrix be-tween the context nodes and the hidden nodes. At the output layer, a softmax function is adopted for labelling, as in Equation (3): weight matrix. 2.2.2 DP prediction
Once the DP position is detected, the next step is to determine which pronoun should be inserted based on this result. Accordingly, we train a 22-class classifier, where each class refers to a distinct Chinese pronoun in Table 1. We select a number of features based on previous work (Xiang et al., 2013; Yang et al., 2015), including lexical, contextual, and syntax features (as shown in Table 2). We set p as the DP position, S as the window size surrounding p , and X, Y as the window size surrounding cur-rent sentence (the one contains p ). For Features 1 X  4, we extract words, POS tags and pronouns around p . For Features 5 X 8, we also consider the pronouns and nouns between X / Y surrounding sentences. For Features 9 and 10, in order to model the syntactic relation, we use a path feature, which is the com-bined tags of the sub-tree nodes from p / ( p  X  1) to the root. Note that Features 3 X 6 consider all pro-nouns that were not dropped. Each unique feature is treated as a word, and assigned a  X  X ord embedding X . The embeddings of the features are then fed to the neural network. We fix the number of features for the variable-length features, where missing ones are tagged as None. Accordingly, all training instances share the same feature length. For the training data, we sample all DP instances from the corpus (anno-tated by the method in Section 2.1). During decod-ing, p can be given by our DP detection model.
We employ a feed-forward neural network with four layers. The input x p comprises the embeddings of the set of all possible feature indicator names. The middle two layers a (1) , a (2) use Rectified Linear function R as the activation function, as in Equation (4) X (5): where W p (1) and b (1) are the weights and bias con-necting the first hidden layer to second hidden layer; and so on. The last layer y p adopts the softmax function g , as in Equation (6): 2.3 Integration into Translation The baseline SMT system uses the parallel cor-pus and input sentences without inserting/generating DPs. As shown in Figure 2, the integration into SMT system is two fold: DP-inserted translation model ( DP-ins. TM ) and DP-generated input ( DP-gen. In-put ). 2.3.1 DP-inserted TM
We train an additional translation model on the new parallel corpus, whose source side is inserted with DPs derived from the target side via the align-ment matrix (Section 2.1). We hypothesize that DP insertion can help to obtain a better alignment, which can benefit translation. Then the whole trans-lation process is based on the boosted translation model, i.e. with DPs inserted. As far as TM combi-nation is concerned, we directly feed Moses the mul-tiple phrase tables. The gain from the additional TM is mainly from complementary information about the recalled DPs from the annotated data. 2.3.2 DP-generated input
Another option is to pre-process the input sen-tence by inserting possible DPs with the DP gen-eration model (Section 2.2) so that the DP-inserted input (Input ZH+DPs) is translated. The predicted DPs would be explicitly translated into the target language, so that the possibly missing pronouns in the translation might be recalled. This makes the in-put sentences and DP-inserted TM more consistent in terms of recalling DPs. 2.3.3 N-best inputs
However, the above method suffers from a major drawback: it only uses the 1-best prediction result for decoding, which potentially introduces transla-tion mistakes due to the propagation of prediction er-rors. To alleviate this problem, an obvious solution is to offer more alternatives. Recent studies have shown that SMT systems can benefit from widening the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013). In the same direction, we propose to feed the decoder N -best prediction results, which allows the system to arbi-trate between multiple ambiguous hypotheses from upstream processing so that the best translation can be produced. The general method is to make the in-put with N -best DPs into a confusion network. In our experiment, each prediction result in the N-best list is assigned a weight of 1 /N . There is some work related to DP generation. One is zero pronoun resolution (ZP), which is a sub-direction of co-reference resolution (CR). The dif-ference to our task is that ZP contains three steps (namely ZP detection, anaphoricity determination and co-reference link) whereas DP generation only contains the first two steps. Some researchers (Zhao and Ng, 2007; Kong and Zhou, 2010; Chen and Ng, 2013) propose rich features based on different machine-learning methods. For example, Chen and Ng (2013) propose an SVM classifier using 32 fea-tures including lexical, syntax and grammatical roles etc., which are very useful in the ZP task. How-ever, most of their experiments are conducted on mance drops correspondingly when using a system-parse tree compared to the gold standard one. No-vak and Zabokrtsky (2014) explore cross-language differences in pronoun behavior to affect the CR re-sults. The experiment shows that bilingual feature sets are helpful to CR. Another line related to DP generation is using a wider range of empty cate-gories (EC) (Yang and Xue, 2010; Cai et al., 2011; Xue and Yang, 2013), which aims to recover long-distance dependencies, discontinuous constituents treebanks (Xue et al., 2005). This work mainly focus on sentence-internal characteristics as opposed to contextual information at the discourse level. More recently, Yang et al. (2015) explore DP recovery for Chinese text messages based on both lines of work.
These methods can also be used for DP transla-tion using SMT (Chung and Gildea, 2010; Le Na-gard and Koehn, 2010; Taira et al., 2012; Xiang et al., 2013). Taira et al. (2012) propose both sim-ple rule-based and manual methods to add zero pro-nouns in the source side for Japanese X  X nglish trans-lation. However, the BLEU scores of both systems are nearly identical, which indicates that only con-sidering the source side and forcing the insertion of pronouns may be less principled than tackling the problem head on by integrating them into the SMT system itself. Le Nagard and Koehn (2010) present a method to aid English pronoun translation into French for SMT by integrating CR. Unfortunately, their results are not convincing due to the poor per-formance of the CR method (Pradhan et al., 2012). Chung and Gildea (2010) systematically examine the effects of EC on MT with three methods: pat-tern, CRF (which achieves best results) and parsing. The results show that this work can really improve the end translation even though the automatic pre-diction of EC is not highly accurate. 4.1 Setup For dialogue domain training data, we extract around 1M sentence pairs (movie or TV episode create both development and test data with DP an-notation. Note that all sentences maintain their con-textual information at the discourse level, which can be used for feature extraction in Section 2.1. The de-tailed statistics are listed in Table 3. As far as the DP training corpus is concerned, we annotate the Chi-nese side of the parallel data using the approach de-scribed in Section 2.1. There are two different lan-guage models for the DP annotation (Section 2.1) and translation tasks, respectively: one is trained on while the other one is trained on all extracted 7M English subtitle data (Wang et al., 2016).
 Corpus Lang. Sentents Pronouns Train Dev Test
We carry out our experiments using the phrase-based SMT model in Moses (Koehn et al., 2007) on a Chinese X  X nglish dialogue translation task. Fur-thermore, we train 5 -gram language models using the SRI Language Toolkit (Stolcke, 2002). To ob-tain a good word alignment, we run GIZA++ (Och and Ney, 2003) on the training data together with an-other larger parallel subtitle corpus that contains 6M ing (Och, 2003) to optimize the feature weights.
The RNN models are implemented using the com-mon Theano neural network toolkit (Bergstra et al., 2010). We use a pre-trained word embedding via a lookup table. We use the following settings: win-dows = 5, the size of the single hidden layer = 200, iterations = 10, embeddings = 200. The MLP classi-fier use random initialized embeddings, with the fol-lowing settings: the size of the single hidden layer = 200, embeddings = 100, iterations = 200.
 For end-to-end evaluation, case-insensitive BLEU (Papineni et al., 2002) is used to measure translation performance and micro-averaged F-score is used to measure DP generation quality. 4.2 Evaluation of DP Generation We first check whether our DP annotation strategy is reasonable. To this end, we follow the strategy to automatically and manually label the source sides of the development and test data with their target sides. The agreement between automatic labels and man-ual labels on DP prediction are 94% and 95% on development and test data and on DP generation are 92% and 92%, respectively. This indicates that the automatic annotation strategy is relatively trustwor-thy.

We then measure the accuracy (in terms of words) of our generation models in two phases.  X  X P De-tection X  shows the performance of our sequence-labelling model based on RNN. We only consider the tag for each word (pro-drop or not pro-drop be-fore the current word), without considering the exact pronoun for DPs.  X  X P Prediction X  shows the perfor-mance of the MLP classifier in determining the ex-act DP based on detection. Thus we consider both the detected and predicted pronouns. Table 4 lists the results of the above DP generation approaches. The F1 score of  X  X P Detection X  achieves 88% and 86% on the Dev and Test set, respectively. How-ever, it has lower F1 scores of 66% and 65% for the final pronoun generation ( X  X P Prediction X ) on the development and test data, respectively. This indi-cates that predicting the exact DP in Chinese is a re-ally difficult task. Even though the DP prediction is not highly accurate, we still hypothesize that the DP generation models are reliable enough to be used for end-to-end machine translation. Note that we only show the results of 1-best DP generation here, but in the translation task, we use N -best generation can-didates to recall more DPs.
 Systems Dev Set Test set
Baseline 20.06 18.76 +DP-ins. TM 20.32 (+0.26) 19.37 (+0.61) +DP-gen. Input Manual Oracle 24.27 (+4.21) 22.98 (+4.22) Auto Oracle 23.10 (+3.04) 21.93 (+3.17) 4.3 Evaluation of DP Translation In this section, we evaluate the end-to-end transla-tion quality by integrating the DP generation results (Section 3.3). Table 5 summaries the results of trans-lation performance with different sources of DP in-formation.  X  X aseline X  uses the original input to feed the SMT system.  X +DP-ins. TM X  denotes using an additional translation model trained on the DP-inserted training corpus, while  X +DP-gen. Input N X  denotes further completing the input sentences with the N -best pronouns generated from the DP gener-ation model.  X  X racle X  uses the input with manual ( X  X anual X ) or automatic ( X  X uto X ) insertion of DPs by considering the target set. Taking  X  X uto Oracle X  for example, we annotate the DPs via alignment in-formation (supposing the reference is available) us-ing the technique described in Section 2.1.

The baseline system uses the parallel corpus and input sentences without inserting/generating DPs. It achieves 20.06 and 18.76 in BLEU score on the de-velopment and test data, respectively. The BLEU scores are relatively low because 1) we have only one reference, and 2) dialogue machine translation is still a challenge for the current SMT approaches.
By using an additional translation model trained on the DP-inserted parallel corpus as described in Section 2.1, we improve the performance consis-tently on both development (+0.26) and test data (+0.61). This indicates that the inserted DPs are helpful for SMT. Thus, the gain in the  X +DP-ins TM X  is mainly from the improved alignment qual-ity.

We can further improve translation performance by completing the input sentences with our DP gen-eration model as described in Section 2.2. We test N -best DP insertion to examine the performance, where N = { 1, 2, 4, 6, 8 } . Working together with  X  X P-ins. TM X , 1-best generated input already achieves +0.43 and + 0.74 BLEU score improve-ments on development and test set, respectively. The consistency between the input sentences and the DP-inserted parallel corpus contributes most to these further improvements. As N increases, the BLEU score grows, peaking at 21.61 and 20.34 BLEU points when N =6. Thus we achieve a final improve-ment of 1.55 and 1.58 BLEU points on the devel-opment and test data, respectively. However, when adding more DP candidates, the BLEU score de-creases by 0.97 and 0.51. The reason for this may be that more DP candidates add more noise, which harms the translation quality.

The oracle system uses the input sentences with manually annotated DPs rather than  X  X P-gen. In-put X . The performance gap between  X  X racle X  and  X +DP-gen. Input X  shows that there is still a large space (+4.22 or +3.17) for further improvement for the DP generation model. We select sample sentences from the test set to fur-ther analyse the effects of DP generation on transla-tion.
 In Figure 4, we show an improved case (Case A), an unchanged case (Case B), and a worse case (Case C) of translation no-/using DP insertion (i.e.  X +DP-gen. Input 1-best X ). In each case, we give (a) the original Chinese sentence and its translation, (b) the DP-inserted Chinese sentence and its transla-tion, and (c) the reference English sentence. In Case A,  X  Do you  X  in the translation output is compen-sated by adding DP  X  (you) in (b), which gives a better translation than in (a). In contrast, in case C, our DP generator regards the simple sentence as a compound sentence and insert a wrong pronoun  X  (I) in (b), which causes an incorrect translation output (worse than (a)). This indicates that we need a highly accurate parse tree of the source sentences for more correct completion of the antecedent of the DPs. In Case B, the translation results are the same in (a) and (b). This kind of unchanged case always occurs in  X  X ixed X  linguistic chunks such as prepo-sition phrases ( X  X n my way X ), greetings ( X  X ee you later X  ,  X  X hank you  X ) and interjections ( X  My God X ). However, the alignment of (b) is better than that of (a) in this case.
 Figure 5 shows an example of  X +DP-gen. Input N-best X  translation. Here, (a) is the original Chi-nese sentence and its translation; (b) is the 1-best DP-generated Chinese sentence and its MT output; (c) stands for 2-best, 4-best and 6-best DP-generated Chinese sentences and their MT outputs (which are all the same); (d) is the 8-best DP-generated Chinese sentence and its MT output; (e) is the reference. The N -best DP candidate list is  X  (I),  X  (You),  X  (He),  X   X  (We),  X  X  X  (They),  X   X  (You),  X  (It) and  X  (She). In (b), when in-tegrating an incorrect 1-best DP into MT, we obtain the wrong translation. However, in (c), when con-sidering more DPs (2-/4-/6-best), the SMT system generates a perfect translation by weighting the DP candidates during decoding. When further increas-ing N (8-best), (d) shows a wrong translation again due to increased noise.
 We have presented a novel approach to recall miss-ing pronouns for machine translation from a pro-drop language to a non-pro-drop language. Experi-ments show that it is crucial to identify the DP to im-prove the overall translation performance. Our anal-ysis shows that insertion of DPs affects the transla-tion in a large extent.

Our main findings in this paper are threefold:  X  Bilingual information can help to build mono- X  Benefiting from representation learning, neural  X  N -best DP integration works better than 1-best
In future work, we plan to extend our work to dif-ferent genres, languages and other kinds of dropped words to validate the robustness of our approach. This work is supported by the Science Foun-dation of Ireland (SFI) ADAPT project (Grant No.:13/RC/2106), and partly supported by the DCU-Huawei Joint Project (Grant No.:201504032-A (DCU), YB2015090061 (Huawei)). It is partly supported by the Open Projects Program of Na-tional Laboratory of Pattern Recognition (Grant 201407353) and the Open Projects Program of Cen-tre of Translation of GDUFS (Grant CTS201501).
