 An ever increasing number of social services offer thousands of diverse events per day. Users tend to be overwhelmed by the massive amount of information available, especially with limited browsing options perceived in many event web ser-vices. To alleviate this information overload, a recommender system becomes a vital component for assisting users select-ing relevant events. However, such system faces a number of challenges owed to the the inherent complex nature of an event. In this paper, we propose a novel hybrid approach built on top of Semantic Web. On the one hand, we use a content-based system enriched with Linked Data to over-come the data sparsity, a problem induced by the transiency of events. On the other hand, we incorporate a collabora-tive filtering to involve the social aspect, an influential fea-ture in decision making. This hybrid system is enhanced by the integration of a user diversity model designed to de-tect user propensity towards specific topics. We show how the hybridization of CB+CF systems and the integration of interest diversity features are important to improve predic-tions. Experimental results demonstrate the effectiveness of our approach using precision and recall measures.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Algorithms, Experimentation Event recommendation, Linked Data, LODE ontology, user diversity
Recommendation in online social services have gained mo-mentum over the past years as a key factor to deliver person-RecSys X 13 , October 12 -16, 2013, Hong Kong, China. Copyright 2013 ACM 978-1-4503-2409-0/13/09... $15 . 00 . alized content and enhance the user experience. Reducing the information overload and assisting customers to make decision become part of primary concerns in the e-service area. In this sense, recommender systems attempt to pro-vide efficient filters that decode the users X  interests, and op-timize accordingly the information perceived. To help these systems predict items of interest, various clues are available, ranging from a user profile, explicit ratings, to past activities and social interactions. More specifically, integrating such systems in an event-based web service is a key advantage to attract people for attending diverse events, and to promote face-to-face social interactions. Indeed, the event recom-mendation can draw on different information sources such as the user preferences (ratings, likes, etc.), the attended events (visited places, involved artists), or even the social co-participation. Broadly speaking, the decision making upon attending events depends on some restrictions such as time, location, category, popularity and which friend will attend. However, the existing collaborative and content-based tech-niques cannot cope at all with this complex inherent nature of such decision. In addition, attended events are often top-ically diverse inducing a significant variety of topics in the user profile. This diversity will obviously affect the similar-ity between the new events and the prior ones, which can decrease the accuracy of content-based recommendation.
To tackle these issues, we propose a hybrid event recom-mender system by means of Semantic Web technologies. Our belief is that a structured event model presents one solution to cope with the complexity of event-specific characteris-tics. This modeling will ensure a more straightforward way to explore and reason over the data. It makes possible to ask complex queries, for example, to retrieve events involv-ing the same artist within a specific geographical area. In addition, the semantic model empowers the enrichment of event descriptions with additional information from Linked Data [1], a set of connected and distributed RDF datasets. Such enrichment could potentially provide valuable inputs for the content-based recommender system [5].

In the second step of our approach, we propose to quantify the user interests based on topic modeling technique. This model detects the user propensity towards specific topics. It will be integrated in the recommender system to control the impact caused by the diversity of a user profile. Finally, we exploit the collaborative participation assuming that the social information about  X  X hich friend will attend an event X  plays an important role in decision making. In this paper, we mainly investigate the influence degree that could have the data enrichment, the social information and the user diversity to improve the system performance.

The remainder of this paper is organized as follows: Sec-tion 2 describes our event model and details how to build a recommender system using semantic metadata from Linked Data. Section 3 outlines our hybrid method for event rec-ommendation. In Section 4 and 5, we describe some based techniques to train the system and we evaluate the proposed approach. We review related work in Section 6, and we con-clude in Section 7.
The principle of the content-based recommender system is to suggest new items similar to those a user liked in the past. The similarity between items is computed using the internal structure of the item profile by means of a variety of distance measures such as Cosine similarity, Pearson corre-lation or Latent Semantic Analysis. The most common rep-resentation of the item profile is the keyword-based model, in which attributes are represented by weighted vectors of keywords usually computed using TF-IDF scheme (term fre-quency/inverse frequency). To build such a profile from un-structured data, feature extraction techniques are needed to shift the item description from the original representa-tion to a structured form suitable for next processing (e.g. keyword vectors). This task becomes straightforward by the use of Semantic Web technologies thanks to data structuring into ontologies known as machine understandable format. In fact, one principle of Semantic Web is to use common vocab-ularies for the integration of fragmentary information into a logically coherent knowledge. This huge and distributed knowledge, also called Linked Data, contains growing set of public and linked RDF datasets, covering diverse domains such as government, media, geography or more generally en-cyclopedic data. A content-based recommender system can greatly benefit from the ease of ontology-enabled feature ex-traction, and the availability of connected data in different domains to enrich the item profile. In order to fully leverage the assets of Linked data, we published in a previous work a RDF dataset of events and linked it with relevant open datasets [10]. In the following, we provide an overview of our RDF dataset of events and we explain how to compute the similarities between items based on Linked Data.
In their daily life, people naturally organize their personal data according to occurring events: wedding, birthday party, concert, etc. In this paper, the events considered are a nat-ural way for referring to any observable occurrence group-ing persons, places, times and activities. To represent the events as structured data, we use LODE ontology 1 , a mini-mal model that encapsulates the most useful properties. The goal of this ontology is to enable an interoperable modeling of the  X  X actual X  aspects of events, where these can be char-acterized in terms of the four Ws: What happened, Where did it happen, When did it happen, and Who was involved. Figure 1 depicts the metadata attached to the event iden-tified by 1380633 on Last.FM 2 . More precisely, it indicates that this concert has been given on the 21th of May 2012 at 12:45 PM in the The Paramount Theatre featuring the http://linkedevents.org/ontology/ http://www.last.fm Figure 1: The Snow Patrol Concert described with LODE ontology Snow Patrol rock band, and attended by the user earth-capricor .

The dataset was collected from three large event web di-rectories (Eventful, Last.FM and Upcoming) and published in the Linked Data Cloud 3 . Using our SPARQL (RDF query language) endpoint 4 , we can easily retrieve meaningful and semantic relationships about users. For instance, the follow-ing query extracts the list of attendees co-participating with a specific user along with the number of common events. A set of filters can simply be incorporated to target a specific geographical area or a period of time.
 SELECT ?coattendee COUNT(DISTINCT ?event) as ?NB WHERE { } ORDER BY DESC (?NB) In order to compute the similarity between items from Linked Data, we decided to apply the approach proposed by Di Noia et al [5]. The inceptive idea is that seman-tically similar items from RDF graph are the subject of two RDF triples having the same property and the same object (where a triple= &lt; subject,property,object &gt; ). This approach is based on an adaptation of the classic Vector Space Model (VSM) [16], a well known technique in infor-mation retrieval. In this model, similarity between docu-ments and queries is computed between their representa-tive t-dimensional weighted vectors assigned to index dis-criminating terms. The application of VSM to RDF graph projects the Linked Data to 3-dimensional tensor, where each of its slices represents an adjacency matrix for one ontology property. In fact, the Semantic Web graph can be defined as a graph G = ( V,E ), where V is a set of RDF resources and E is the set of properties between re-sources in V . For each existing property p in E , the adja-cency matrix models the linkage between subjects (on the rows) and objects (on the columns) from V by this prop-erty p . Hence, a non null weight is assigned to each entry http://linkeddata.org/ http://eventmedia.eurecom.fr/sparql Figure 2: Tensor slices of some event properties X ijp in the tensor for each existing triple &lt;i-th subject, p-th property, j-th object&gt; . Figure 2 shows a small ex-ample of tensor slices related to some properties, namely: lode:atPlace , lode:involvedAgent and dc:subject .

Considering the data sparsity and the independent prop-erties, we would be able to apply the approach above and compute the similarity between events with respect to each property separately. The representation of an event e i ac-cording to the property p is a t-dimensional vector indexing the terms/resources related to e i via p . The TF-IDF weight of each resource r is computed as: where f r,i,p = 1 if a link exists between the node e i to the resource r via the property p , otherwise f r,i,p = 0. N is the total number of events in the dataset. m r,p is the number of events linked to the resource r via the property p . Then, the similarity between two events e i and e j with respect to the property p is calculated using Cosine distance between their representative vectors as following:
The approach described above can be simply applied to detect similarity between subjects or objects of RDF triples. It has been successfully used to recommend movies and to improve the quality of content-based system [5]. Nev-ertheless, it is still limited when the adjacency matrix is very sparse such as the case of matrices associated with lode:atPlace and lode:involvedAgent properties. In fact, such predicates are considered as discriminant properties in RDF, which are characterized by the diversity of its object values. For instance, the t-dimensional vector related to lode:atPlace property has only one non null weight since an event always takes place in one venue.
In order to mitigate the sparsity of the adjacency matrix, we decided to interpolate fictitious values based on the simi-larity between objects. First, we introduce a discriminability metric [17] to gain insights into the properties concerned by the similarity-based interpolation. The metric is defined via the following formula: where G is the RDF graph, t is the triple representing the link between the subject s and the object o via the property p . From this formula, it is trivial to see that having high discriminability means that many instances have different object values on this property. For instance, from a set of 1700 events (related to 10,323 agents, 627 places and 5,758 subjects), we found a discriminability score of 0.64 for the lode:involvedAgent , and 0.45 for the lode:atPlace , while it is only 0.10 for the dc:subject predicate. This is also reflected by the sparsity measures of the related adjacency matrices. Moreover, we intuitively know that similar events are not necessary occurred in the same venue or featuring the same performers. As a solution for such typical items, we propose to interpolate the similarity scores between objects in the adjacency matrix. More precisely, if the resource r similar to the resource r h , and both f r h ,i,p = 1 and f 0, then f r k ,i,p = sim ( r k ,r h ). Note that f r k ,i,p strength of the fictitious link which associates event e i the resource r k via the property p . If r k is similar to more than one resource originally linked with e i via the property p , the weight f r k ,i,p will be equal to the highest similarity score. For each resource r k , the equation 1 becomes more generally: where H is the set of objects originally linked with the event e i . In this context, we do not pay attention to how similarity between objects is computed. In fact, this mea-sure depends on the structure of the object itself and there exist several existing distances that can be used. In our case, we have been based on the similarity scores between agents provided by third party services such as Last.FM, and we computed the normalized geographical distance between venues. A key advantage of the similarity-based interpola-tion is that the discriminability and the sparsity rates are 3 times reduced. Finally, the similarity between two events e and e j is a normalized combination of their similarities according to each property p .
Different from a classic item, events occur at a specific place and during a period of time to become worthless for recommendation. Moreover, while the classic items continu-ously receive useful feedbacks, the user ratings about events are very sparse due to their transiency. In our dataset, these ratings are represented by the binary user-event attendance matrix with 98% sparsity rate (a set of users only attend a very limited number of all the available events). As a solu-tion, one can address event recommendation using content-based algorithm relating event metadata to user preferences. This perfectly complies with the constraints a person consid-ers to decide whether or not to attend an event. Metadata such as distance, time, topics and performers are important and influential factors in such decision. Nevertheless, the content-based recommendation might suggest items with a limited diversity, and it does not consider the social informa-tion that answers to the question:  X  X hich friend is going? X . To fill this gap, we first analyze the pure content-based rec-ommendation where a weight value is assigned to each of metadata fields. We attempt to improve its performance by enriching descriptions from Linked Data. Then, we incor-porate the social dimension (collaborative-filtering) and the topical user diversity by means of weighted hybrid recom-mendation.
The underlying principle of content-based system is to rec-ommend future events similar to ones a user has attended in the past. We assume that there is a sufficiently num-ber of past attended events to avoid the cold-start problem, which is out of the scope of the present work. Similarity values between events are then used to obtain a ranked list of recommended items, as following: where e i is the event to recommend, P is the set of proper-ties shared between two events, E u is the set of past events attended by the user u , and  X  p is the weight assigned to each property reflecting its contribution to respect the user profile. In the next section we describe some methods how to learn these weights  X  . The selected properties to compute the similarity between events are those which are related to the location, subjects (tags) and involved agents (artists). Note that we do not deal with the temporal property at the moment. We mainly focus our analysis on the topic enrich-ment, the social factor and the user diversity. We believe that temporal property could be harnessed to index only re-cent and future events in a specific period of time. This will reduce the computational processing time and increase the scalability. However, as this method reduces the knowledge about the user past ratings, there is a need to investigate its impact on the recommendation accuracy, an analysis left for further studies.
 Geographic Closeness . Roughly speaking, users tend to attend nearby social events, thus the location is always con-sidered as a valuable feature in event recommendation [15]. In our approach, to measure the similarity between events according to the lode:atPlace property, we need to nor-malize it according to a specific threshold  X  . Since the lo-cation of the user home is missing in our data, we analyzed the distance between attended events for each user and we reported results for all users in Figure 3. Note that the at-tendance rate becomes extremely low from  X  = 80 Km. This value is considered as the threshold from which the similar-ity between events equals to zero according to the location property.
 Enrichment with Linked Data . One method to enrich the item profile from Linked Data lies in the exploitation of DBpedia, the RDF version of Wikipedia. The key advantage of this dataset is the availability of semantically rich infor-mation in various domains. In a previous study [9], we have automatically interlinked our dataset with DBpedia. As a result, a significant number of high quality mappings has been obtained between the artists of both datasets. Conse-quently, we decided to enrich the topics of an event using the DBpedia topics of the involved artists. More precisely, Figure 3: Normalized average attendance rates per distance KM we retrieve the categories associated with the property dc-terms:subject of artists by simply querying the DBpedia SPARQL endpoint 5 . The reason behind our interest in DB-pedia categories is their classification into a well defined hi-erarchical structure with highly consistent labeling.
In the recommender system, one fundamental goal is to suggest items in compliance with the user interests. This aim is particularly difficult to achieve in event recommenda-tion due to the presence of topically diverse events. In fact, the real-world social events can be classified into large set of categories, ranging from large festivals and conferences to small concerts and social gatherings. When attending an event, the user might be interested in a specific show or artist, or might have broad interests. In consequence, re-lying on events similarity in content-based recommendation can be influenced by the topical diversity of past attended events. To alleviate this impact, we decided to put an em-phasis on the role of interesting events to predict the un-known ratings. This means that we assign different weights to the events included in the peaks of interest, and to those which are out of these peaks (equation 8). These weights  X  are then estimated using training methods. The formula 5 becomes: where  X  p = 1 if the property p is different from dc:subject , otherwise the  X  subject is an estimated value depending on whether the event e j corresponds to a peak of interest or not. In order to detect these peaks of interest, we propose to quantify the interest diversity using Latent Dirichlet Al-location (LDA) [2], a topic modeling technique based on the co-occurrence of terms. Inspired by the method in [19], we consider that the interest diversity of each user is reflected by the previously attended events, where each event is consid-ered as a document represented by a set of terms. For each event e i , LDA generates a T-dimensional vector of topic pro-Then, we calculate the variance of each topic dimension t of all the events E attended by a user  X  t = [  X  t 1 , X  t 2 ,... X  diversity score of a user is the mean of the variances of all topics dimensions (mean of  X  1 ,  X  2 ...  X  T ). The normalized http://dbpedia.org/sparql Figure 4: Distribution of topical diversity scores with T = 30: (a) for all the users; (b) for one specific user. scores obtained from a sample of 1,000 Last.fm users are depicted in Figure 4. From the histogram, it is shown that most of diversity scores range from 0.3 to 0.5 indicating users with relatively high interest in specific topics. The diversity scores near to 1 represent a very strong interest in some top-ics such as the user plotted in Figure 4(b) having a strong bias towards topic 9. Finally, the diversity score of zero rep-resents the users associated with few attended events (the cold-start problem).
A form of social interaction is the collaborative participa-tion such as co-authoring a paper or co-attending an event. In [12], Liu et al. highlight the existence of an offline social network built by means of co-attending the social events. Such network seems cohesive but still less denser than an on-line social network. Accordingly, we consider that two users involved in the same event can potentially have a stronger tie than others users. The involvement could be offline by directly attending the event, or online by sharing media and comments about it. This let us assume that the more events in which the users involve, the more strongly their tie is. Thus, the sufficiently similar consumptions could probably provide information at first glance about which  X  X riends X  will attend an event. Since our dataset contains users intentions upon attending upcoming events, we exploit them to predict unknown ratings. However, unlike the traditional user-based collaborative filtering (CF), we would like in our approach to not only consider the similarity between users, but also the contribution of a group of friends. We define the fol-lowing formula as the prediction that a user u i will attend an event e based on the intentions of his co-attendees (users who have attended past events with the user u i ): where C is the set of co-attendees of the user u i will attend the event e , E i is the set of attended events by the user u i , and a i,j represents the fraction of common events between the users u i and u j by the cardinality of E . Note that the weight a i,j reflects whether the most of events which are attended by the user u j are also attended by the user u i . The rationale behind this formula is two-fold: (1) in the first part, the contribution of each co-attendee is considered individually; (2) in the second part, we consider the co-attendees as a group of friends, and we assume that the more events they attended together with the user u i , the more strongly is their relationship.
To combine the features of both content-based and col-laborative filtering algorithms, we propose a weighted hy-bridization using a linear combination of recommendation scores. Taking into account the user diversity and combin-ing the equations (6) and (7), we propose the following rank function: where  X  cf is the weight of collaborative filtering feature, estimated in conjunction with the weights of content-based features using different approaches to train the system.
To learn the weights of our prediction function, we first test the linear regression with gradient descent that mini-mizes the least-squares cost function. Then, we use two evo-lutionary computation methods motivated by their success in a wide range of tasks. Results are reported in Section 5.
Genetic Algorithms (GAs) [20] are stochastic methods in-spired from the mechanism of natural evolution and genetic inheritance. They have been applied to various domains in-cluding information retrieval, image processing and machine learning. In GAs, a population is a set of chromosomes (candidate solutions) and each chromosome denotes a set of genes. A fitness criterion is a function which provides an esti-mation of the quality of each solution. An initial population of candidate solutions (chromosomes) are evaluated using the fitness function. The solutions having higher fitness val-ues than others are stochastically selected, recombined and randomly mutated to produce a new population for the next generation. The algorithm stops iterating when the optimal solution is produced or a maximal number of iterations is reached. To apply GA in our approach, a chromosome is represented by a vector of the coefficients  X  (the genes). Each chromosome is then evaluated using a fitness function that maximizes the precision@N on the training data. We set the following GA parameters: population size=30, iter-ations=80, crossover rate=0.9 and mutation rate=0.01.
Particle Swarm Optimization (PSO) [7] is a population based stochastic optimization technique inspired by the so-cial behavior of bird flocking or fish schooling. The algo-rithm initializes a population of random solutions called swarms (particles), and searches for optima of a fitness func-tion by updating generations. Compared with GA, PSO is easy to implement with few parameters to adjust, and has no evolution operators such as crossover and mutation. In each generation, each particle accelerates in the direction of its own personal best solution found so far, as well as in the direction of the global best position discovered so far by any of the particles in the swarm. Each particle i in the swarm has the following attributes: a current position x a current velocity v i , and a personal best position p i search space, and the global best position p gbest among all the p i . In each iteration, the velocity and the position of each particle is updated as following: v ( t + 1) = w.v i ( t ) + c 1 r 1 ( p i  X  x i ( t )) + c 2 where c 1 and c 2 are the acceleration coefficients, r 1 and r are random numbers uniformly distributed within [0,1], and w is the inertia weight. The velocity and acceleration are re-sponsible for changing the position of the particle to explore the space of all possible solutions, instead of using existing solutions to reproduce. The personal and the global best positions are the optima of a fitness function respectively in each iteration and for all past iterations. Following the same setting in GAs, a particle is represented by a vector of the weights  X  , and the fitness function aims at maximizing the precision results. We set the following PSO parameters: population size=30, iterations=80, c 1 =1.494, c 2 =1.494 and w=0.729 (more details in [7]).
We carried out a set of experiments measuring the pre-cision and recall metrics to assess the contribution of each step and the quality of our recommendation compared with existing approaches.
As described in Section 2, our RDF dataset is obtained from three large public event directories (Last.fm, Eventful and Upcoming). In particular, we have been interested in Last.fm directory containing a large number of active users, that explicitly announce their participation to future events. Using SPARQL, we collected 2,436 events, 481 active users whose the attendance rates are within [15,50] generating 12,729 distinct consumptions. This set of events are related to 14,748 different artists, 897 different locations and 4265 distinct tags (music domain). For evaluation purpose, we used a test set containing the most recent 30% of the con-sumptions and a training test with the remaining 70% con-sumptions. Then, we calculated two metrics used in top-N recommendation task: Precision is the ratio of correctly rec-ommended items and the length of the recommendation N; Recall is the ratio of correctly recommended items and the total number of future consumptions. Precision and recall were computed at different N values.

Task location agent subject Table 1: Sparsity rates of the similarity matrix for each property before (1) and after the similarity-based interpolation and linked data enrichment (2) Figure 5: Recall and Precision based on different approaches to estimate the vector  X 
To highlight the importance of the similarity-based inter-polation and linked data enrichment, we report the sparsity rates in Table 1. We see that our method succeed to discover latent similarities between items attributes especially for dis-criminant properties. This similarity was not considered in keyword-based recommender system, and its interpolation becomes straightforward thanks to the ontology-based mod-eling.

As a second step of our evaluation, we assess the perfor-mance of the training methods to learn the coefficients  X  in the hybrid recommendation algorithm. Note that, for this experiment, we do not include the user diversity and set the  X  subject = 1 since our aim is rather to compare the behav-ior of our training methods. Figure 5 shows the Precision and Recall curves computed using different approaches. It is evident that setting all the coefficients equal to 1 achieves the worst performance because no adaptive optimization was considered. Moreover, it is shown that precision optimiza-tion methods (GA and PSO) deliver considerably better top-N results compared with error (RMSE) minimization method (LR). This also confirms recent works [4] showing that methodologies based on error metrics do not necessarily improve the accuracy of top-N recommendation task. One given explanation is that the RMSE-oriented methods ac-count only for known ratings to train the system, and do not consider the unrated items. Finally, Figure 5 highlights the better performance of PSO compared with GA algorithm. We observed a faster convergence to the optimal solution in PSO compared with GA which may need more iterations. This owed to the inherent behavior of PSO where the evolu-Figure 6: Evolution of the recommendation accu-racy by incorporating the DBpedia enrichment, user diversity (CB-based++) and collaborative filtering (CF) tion is only guided by the best particle, while it is guided by a group of solutions in GA (in which even weak candidates continue to survive after some iterations). In the following, we rely on PSO algorithm to compute the coefficients  X  and
To gain insights into the influence of the different steps in our recommendation, we decided to examine the evolution of the system performance by adding in each experiment (by order) the Linked Data enrichment, the user diversity and the collaborative filtering. Results are illustrated in Fig-ure 6. We can observe that enriching data with DBpedia categories slightly improves both precision and recall. In-deed, introducing more coherent and qualitative data is one solution to reduce the noise that can be found in the col-lective knowledge of crowd tagging. Then, the integration of the user diversity model also enhances the system per-formance. For this experiment, we fixed the coefficients  X  obtained with PSO, and trained the system to compute the coefficient  X  subject which depends on the peaks of the user interests. We obtained  X  subject =0.4 when the past event is not included in an interest peak, and  X  subject =1.6 (4 times more) otherwise. This confirms the importance to account for the peaks of interest when recommending items, espe-cially for the users who have strong propensity towards spe-cific topics and when items are topically diverse. Finally, combining these results with the collaborative filtering no-tably increases the recommendation accuracy. We believe that this improvement is perfectly tangible with the use of a real world dataset. Indeed, according to the user-centric study in [18], social aspects such as people and friends who are attending an event have strong priority and influence on decision making.

In the last part of our evaluation, we assess to which ex-tent a hybrid event recommendation outperforms the ex-isting pure collaborative filtering. We compared our algo-rithm with the traditional user-based CF and the Proba-bility based Extended Profile Filtering (UBExtended) pro-posed for event recommendation in [14]. This method em-Figure 7: Comparison of hybrid event recommenda-tion with pure CF algorithms ploys a cascade of user-based CF systems attempting to rec-ommend popular (most consumed) events among the users. The rationale behind is that the probability to consume an event is proportional to the current popularity of the event, an important aspect that will be considered in a future study. The comparison results are depicted in Figure 7. It is shown that the UBExtended improves the outcome of the system compared with the pure user-based CF algorithm. We can also observe that our hybrid algorithm exhibits the best accuracy in terms of precision and recall. This owed to the benefits of hybridization technique which have been extensively highlighted in several recommender systems.
In the research area of recommender systems, many ap-proaches have been proposed to recommend movies, but few are the studies that deal with event recommendation. Con-sidered as one-and-only items, events are particularly hard to recommend due to their short life time and the system often suffers from highly sparse data. Some works have been proposed to overcome these issues and improve the recom-mendation accuracy. Cornelis et al. [3] build a hybrid ap-proach within a fuzzy relational framework which allows to reflect the uncertain information in the domain. The ra-tionale behind is to recommend future events if they are similar to past ones that similar users have liked. However, this framework was not evaluated and there is no clear in-sight about its performance especially for large scale dataset. Minkov et al. [13] follow the same rationale and propose a low rank collaborative method to predict the ratings of fu-ture events. They highlight the performance of the collab-orative filtering over the pure content based system. Nev-ertheless, their approach has mainly focused on the recom-mendation of scientific talks in the same building, and there is no consideration of the user location. Some other systems have been also developed such as  X  X ittcult X  [11] and  X  X ven-ter X  [8] which position the user within a social network and leverage the trustworthiness between users, a valuable infor-mation that is not available in many systems. Finally, a user-centric evaluation [6] showed that the straightforward com-bination of CF and CB recommendations outperforms both individual algorithms on almost qualitative metrics such as accuracy, novelty, diversity, satisfaction and trust.
Another innovative direction also interesting in our re-search is the recent studies proposed to harness Linked Data in recommender systems. In [5], Di Noia et al. use the Linked Data as the only background knowledge to recom-mend movies. They highlight the performance of the system compared to the keyword-based methods. However, there is no deep exploitation of latent similarities that may exist be-tween movies attributes. In event recommendation and to the best of our knowledge, our system is one of the first ini-tiative that combines the benefits of the hybrid algorithms and Linked Data.
In this paper, we have presented an event recommenda-tion approach which combines the CB and CF methods, and utilizes Linked Data to enrich the item profile. We have also employed a statistical model of user interests to over-come the topical diversity of rated items and improve the system performance. The evaluation particularly highlights the importance of social information and the user diversity model to improve the event recommendation. In the future, we plan to involve other significant features such as event popularity and temporal indexing of recent consumptions to enhance the scalability. Moreover, we want to utilize some advanced similarity techniques such as tensor factorization in Linked Data, which has shown excellent performance in sparse and high dimensional domains.
 This work was supported by the project AAL-2009-2-049  X  X daptable Ambient Living Assistant X  (ALIAS) and the project  X  X ocial Annotations and eXperiences X  (S-MAX). [1] C. Bizer, T. Heath, K. Idehen, and T. Berners-Lee. [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] C. Cornelis, X. Guo, J. Lu, and G. Zhang. A fuzzy [4] P. Cremonesi, Y. Koren, and R. Turrin. Performance [5] T. Di Noia, R. Mirizzi, V. C. Ostuni, D. Romito, and [6] S. Dooms, T. D. Pessemier, and L. Martens. A [7] R. C. Eberhart and Y. Shi. Particle swarm [8] M. Kayaalp, T.  X  Ozyer, and S. T.  X  Ozyer. A [9] H. Khrouf, V. Milicic, and R. Troncy. Eventmedia [10] H. Khrouf and R. Troncy. Eventmedia: a LOD dataset [11] D. H. Lee. Pittcult: trust-based cultural event [12] X. Liu, Q. He, Y. Tian, W.-C. Lee, J. McPherson, and [13] E. Minkov, B. Charrow, J. Ledlie, S. J. Teller, and [14] T. D. Pessemier, S. Coppens, K. Geebelen, [15] D. Quercia, N. Lathia, F. Calabrese, G. Di Lorenzo, [16] G. Salton, A. Wong, and C. S. Yang. A vector space [17] D. Song and J. Heflin. Automatically generating data [18] R. Troncy, A. T. S. Fialho, L. Hardman, and [19] H. Wu, V. Sorathia, and V. Prasanna. When diversity [20] J. yuan Yeh, J. yi Lin, H. ren Ke, and W. pang Yang.
