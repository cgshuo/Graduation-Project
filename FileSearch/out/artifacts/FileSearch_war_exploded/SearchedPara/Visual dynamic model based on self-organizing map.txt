 1. Introduction
Traditionally, the modeling of industrial processes is based on analytical methods ( Isermann and Ball e, 1997; Frank, 1990 ), so the models are built from knowledge about the physical nature of processes and assumptions about their behavior. Nevertheless, in most real cases, it is unfeasible or too expensive to define a comprehensive model, due to the complexity of the system or the lack of knowledge about the physical laws that describe it. In these cases, the available process data may be used as the starting point of the modeling process, using a process history based method ( Venkatasubramanian et al., 2003 ). These methods, which are included in the field of data mining, are being increasingly used in contemporary automation systems. Despite a great amount of data is often available, it is usually difficult to interpret the implicit knowledge. Data mining (DM) ( Fayyad et al.,1996 )isa field of knowledge management aimed to extract the knowledge from databases in order to provide guidelines for decision-making. DM makes a non-trivial extraction of implicit, previously unknown and potentially useful knowledge, which remains hidden among the vast amounts of data.
 Recently, visual data mining (Keim, 2002; de Oliveira and
Levkowitz, 2003 ) has received considerable interest as a data mining strategy. Visual data mining is an approach where the traditional mining methods are combined with information visualization techniques to explore large data sets. The algorithms for information visualization help to clarify the data and the relationships between measurements and parameters. Unlike the completely automatic approaches, visualization techniques at-tempt to transform information into graphical representations, without a significant loss, to exploit the human ability for pattern recognition and visual reasoning, and facilitate the incorporation and reutilization of prior knowledge. The main aim of these tools is to provide a snapshot of the whole data set and help process analysts to extract knowledge from data.

A kind of visualization techniques are the dimension reduction techniques ( Carreira-Perpin  X  an, 1996 ), which define a mapping from a high dimensional input space onto a low dimensional output space (2D or 3D) that can be graphically represented. Since the amount of data available for process supervision is often huge and information may be redundant (there are correlations between variables), it seems reasonable to apply dimension reduction techniques to capture the intrinsic low dimensionality that results from the existing relationships among the variables. Particularly, the self-organizing map ( Kohonen et al., 1996 ), a neural architecture proposed by Kohonen, can be used for system process condition monitoring by means of the projection of the state onto a 2D plane, where maps of different variables of the system can be represented in order to show different features of the system in 2D. Knowledge about the process can be presented in form of rules, correlations, mathematical models, etc. ( D  X   X az Blanco et al., 2005 ). These 2D maps present information in a similar way as pressure and rainfall maps, so that available knowledge and data can be efficiently used for process monitoring and visual data exploration. In the field of supervision of industrial processes, SOM has been used for steel industry ( D  X   X az Blanco et al., 2005 ), pulp and paper industry ( Alhoniemi et al., 1999 ), metallurgical processes ( Jamsa-Jounela et al., 2003 ), chemical processes ( Abonyi et al., 2003 ), power distribution (Kang and Birtwhistle, 2003 ), or remote supervision via the Internet ( Dom  X   X nguez et al., 2007 ).

On most of these applications, self-organizing maps have mainly been used to visualize nonlinear static relationships among the features or variables of industrial processes. However, the SOM is also a powerful tool to visualize dynamic behaviors. (2008) the SOM is used to model the process dynamics by means of local linear models associated to the SOM units for different purposes such as controller design, time series prediction or exploratory analysis of process dynamics. Another approach which focuses on the exploration of dynamic features using the SOM is based on the analysis of the trajectories, defined on the 2D visualization space by the successive projection of the BMU that represent the time-variable state of a process ( Kasslin et al., 1992; Kohonen et al., 1996; Tryba and Goser, 1991 ). The interpretation of this trajectory leads to the definition of models associated to the dynamic behavior of the process. A suitable learning mechanism must be selected in order to transform the unstructured information that is implicit in the trajectory, such as velocity, acceleration, direction changes and transitions among process conditions, into useful knowledge.

This approach is the one analyzed in this paper. We present a method to model the dynamics of industrial processes using self-organizing maps and trajectory analysis. The resulting dynamic model provides new visualization tools to monitor the current state of the process and, in addition, may be used to improve the residual computation algorithm ( D  X   X az Blanco and Hollm en, 2002 ) to properly detect the fault trends. A multivariable sample of the process is approximated to the best matching unit (BMU), according to the model, and it is projected on the transition map or the corresponding condition of the equivalent Petri net. Simultaneously, the residual computation and its subsequent graphical representation report whether a possible fault exists, or not. They also help in the identification of the variables associated to the fault.

This paper is organized as follows. In Section 2, the self-organizing maps are reviewed. The proposed model is presented in Section 3 and the results obtained in the application of this approach to a real industrial system are discussed in Section 4. Finally, conclusions are presented in Section 5. 2. Self-organizing maps
The self-organizing map ( Kohonen, 1990, 2001 ) is an unsu-pervised and self-organized neural network where the neurons are arranged in a low dimensional (generally, 2D or 3D) grid. Each neuron is represented by a d -dimensional weight vector (code-book vector) in the d -dimensional input space and a position vector in the low dimensional grid of the output space. The neurons are connected to the adjacent ones according to a neighborhood relationship that defines the map topology . The most common topologies are the rectangular and hexagonal ones.
The main objective of the SOM is to perform a smooth mapping from the high dimensional input space onto the low dimensional output space that preserves the topology of the input data, so that close points in the input space are mapped on close points in the output space according to the defined neighborhood relationship.
During the SOM training, input vectors are fed to all the neurons in the network. A distance measure (generally Euclidean distance) between the input data sample and the codebook vectors is calculated to select the BMU. The BMU at time t , denoted as c  X  t  X  , is the unit whose codebook vector m c minimizes the distance to a given input vector x  X  t  X  and it is formally defined as c  X  t  X  X  argmin When the BMU is found, the d -dimensional coordinates of the neurons are updated, using the following algorithm: m  X  t  X  1  X  X  m i  X  t  X  X  a  X  t  X  h ci  X  t  X  X  x  X  t  X  m i  X  t  X  X  2  X  where a  X  t  X  is the learning rate (monotonically decreasing with time), t denotes time, and h ci  X  t  X  is a non-increasing neighborhood function around the winner unit.

As a result of the training stage, the SOM grid folds onto the input data sets, like a flexible net, placing a larger number of neurons in areas with a higher density of data. The neurons divide the space into a finite collection of Voronoi regions.
Several visualization tools can be applied to self-organizing maps ( Himberg et al., 2001 ) to represent any scalar property of the input space. The value of a given property for a certain neuron, m i , is linked to the corresponding node, g i , in the lattice. Therefore, the values of scalar properties can be shown using a color level for each node to obtain an image where the distribution of that property is depicted for the different process states. Most of the visualization tools used to represent the process nature are based on this approach, such as component planes ( Vesanto, 1999 ), distance maps ( Ultsch and Siemon, 1990), histograms ( Vesanto, 1999 ), model maps, fuzzy maps, correlation maps ( D  X   X az Blanco et al., 2005 ), just to mention a few. To visualize the process state , however, other kinds of visualizations have also been described, such as the projected trajectory ( Kohonen et al., 1996 ) and the residual vector visualization ( D  X   X az Blanco and Hollm en, 2002 ). 3. Dynamic model of a process based on SOM 3.1. Model generation provides a static view of the process by means of the visualization maps. These maps describe the static nature of the process (cluster structure, correlations among variables, degree of com-pliance with a given model, etc.). Nevertheless, the self-organizing map is also a valuable tool to describe dynamic behaviors. The proposed method to analyze the process dynamics is described in this section. This method is based on the analysis of the trajectory created by the projection of the temporal sequence of process states on the 2D SOM grid.
 from a clustered SOM model of the industrial process data. Each of the neurons of the grid has information about the cluster (process condition) that it belongs to. The analysis of the trajectory makes it possible to determine which process conditions are reachable from a certain cluster and which are not. To build the dynamic model of transitions, the transition probability between a given pair of process conditions, i and j , is computed, using (3): p  X  where n ij is the number of transitions of the trajectory which exist from the process conditions i to j and n t is the number of conditions determined in the SOM clustering.

The resulting model can be interpreted as a Petri net ( Murata, 1989 ) or a Markov chain ( Norris, 1997 ) (see Fig. 1 ): the process conditions are the places (represented by a circle) whereas the transitions describe the reachable conditions from a given one.
This representation, similar to a flowchart, is useful to show the system evolution and to make the analysis of the model easier.
From a mathematical point of view, the process is described by the pair of places, T is a set of transitions, a : P T -N is the forward incidence function and b : T P -N is the backward incidence function. L  X f l 1 ; ... ; l n g is defined as the set of probabilities associated to the transitions. Similarly, a Markov chain is process conditions and a  X  X  a ij  X  n n is the matrix of transitions among those conditions, where a ij is the probability of transition from conditions i to j .

Fig. 1 shows a trivial example, where the most important steps for the creation of the dynamic model of transitions are displayed.
In order to simplify the interpretation, the input space of the example is considered to be 3D, although this concept should be extended to situations with a larger number of variables. Indeed, this method reaches its full potential when the number of variables is large. The trajectory can be used to label all neurons as belonging to a certain process condition and to establish the probability of transition among them. The model is presented, in the same figure, along with the Petri net and the Markov chain.
Fig. 1 presents the dynamic map of transitions , which shows the process conditions on the neural lattice and uses lines to represent transition probabilities among clusters on a distance matrix. The landscape of the distance maps shows  X  X  X ountain ranges X  X  (long distances), which represent cluster boundaries and divide the map into  X  X  X alleys X  X  (representing clusters) ( Ultsch and Siemon, VARIABLE Y 10 0 5 10 0 5 10 15 20 25 0 5 10 15 20 25 p1 1 t 0 1990 ). Most neurons belonging to the cluster boundaries spread over the complementary state space of the process. However, within this set, there are neurons that are part of the process state space, because they are BMUs of the trajectory. These neurons are part of the transition paths between process conditions and are useful to identify the variables that cause a fault in a multivariable industrial process because they are used to compute residuals, as described in Section 3.2.

The simultaneous visualization of the dynamic map of transitions and the current state exploits available knowledge about the process dynamics contained in the sequence of states reached by the process. This facilitates online monitoring, and helps to forecast future behaviors as well as to detect fault or deviations. Faults can make the system enter non-reachable conditions or follow transition paths between conditions which are not consistent with the ones defined by the model. The deviations from the normal behavior are usually caused by a breakage of the signal line, mechanical or electrical faults, non-calibrated instrumentation, etc. In Section 4, the behavior of a model under some sample faults is described. 3.2. Residual computation
The approximation to the current state obtained by the SOM model may differ from the actual process state when the process reaches non-modeled states. This difference is called quantization error (Kohonen et al., 1996; Kohonen, 2001 ), and it is closely related to concepts such as residuals or analytical redundancy errors (Patton and Chen, 1993 ) since it expresses a difference between the real value and its estimation using an analytical model. The residual vector is defined as the difference between an input sample and the resulting point associated to its BMU: c  X  t  X  X  argmin r  X  t  X  X  x  X  t  X  m c  X  4  X  for each process variable, which represent the individual devia-tions of the variables from their expected values. Following this idea, the residual analysis using SOM models can be used for fault detection ( D  X   X az Blanco and Hollm en, 2002 ).

However, under some circumstances, in anomalous situations, the residual computation, as explained in (4), can produce residuals that represent variables not involved in the fault or can produce even null residuals, which represent a normal behavior. The root of this problem is the static interpretation of the SOM model: the BMU, from which the computation is done, is selected according to its geometric proximity, but it may not correspond to the dynamic evolution of the process states. In these cases, residual components do not faithfully characterize the process deviations from the expected behavior. What they actually represent are the process deviations from the closest state approximated by the model (in a Euclidean metric sense) to the fault state. If the fault state is very close to any state approximated by the model, the residual may even be null. Fig. 2 represents this problem using two basic simulated examples in a 2D input space. In the first case, a fault in the variable Y , when the system is in condition 1, is induced. The fault state is marked with a black square. The residual vector (represented in red color in the input space and calculated as in Eq. (4)) makes a wrong association of the fault to the variables X and Y . In the second case, the fault is induced in both variables and the state just after the fault is marked with a black triangle. The residual vector is null, because the fault state is very close to a neuron of the boundary, so the fault is not detected.

It is possible to use the dynamic information provided by the model of transitions to solve the problem of inaccurate identifica-tion of the variables associated to the fault, making possible to generate interpretable residuals not only for stationary situations but also for transitory states. As stated in Section 3.1, the dynamic model identifies the reachable process conditions from a given one and also the possible transition paths that may be followed. When the BMU of the current state belongs to an unreachable condition from the one where the BMU of the immediately previous state was projected, or when the current BMU is a neuron of the cluster boundary not included in any valid transition path from the previous condition, there is a fault. Nevertheless, the current BMU cannot be used for residual computation since, although it is the closest neuron to the input sample in a Euclidean metric sense, this neuron is not consistent with the modeled transition dynamics. On the contrary, the residual should be computed from a neuron that agrees with the obtained model.
We propose to delimit the set of candidate neurons from which the residual can be computed. The suitable neurons are the BMU of the immediately previous state and the neurons of the transition paths identified by the dynamic model which start in the condition which contains that BMU. For instance, in the fault 1 shown in Fig. 2 , where the process is in condition 1, the residual computation should not be made from neurons of condition 4, since the probability of transition from condition 1 to condition 4 is null, as can be seen in the Petri net. Although the closest neuron belongs to condition 4, the residual vector should be computed regarding only the neurons of conditions 1 and 2 and the ones belonging to the transition path between these conditions, because it is what the dynamic model has determined.

A heuristic algorithm must be used to select, among the suitable ones, the neuron that will be used to compute the residual vector. In the experiments performed, the proposed heuristic algorithm selects the minimum of a distance measure, which relies on the single-variable-fault assumption. We assume the fault provokes a deviation only in one variable, producing a high value on the associated component of the residual vector. For each residual vector, the component with the highest value (the hypothetical faulty variable) is excluded to calculate the distance measure.

In the example in Fig. 2 , the neuron selected to compute the residual vector is the active BMU immediately before the fault. The correct residual vectors, when the dynamic behavior is considered, are shown in green color in the input space.
Although visualization of the residuals is easy when the input space dimension is low, as in the example, it becomes more difficult when the dimension is higher. In D  X   X az Blanco and Hollm en (2002) , an efficient representation is presented, where deviations of variables (values of the residual vector components) are shown using a color code (e.g., blue tones for negative values, green tones for null values and red tones for positive ones). The vertical axis of the graph corresponds with the vector components and the horizontal axis represents time. This graphical represen-tation of residual has been used in this paper and can be seen in Figs. 2 and 7 . 4. Experimental results
Some experiments were performed to test both the method used to obtain dynamic models from the self-organizing map and its application to process supervision. The tests were run on an industrial process plant ( Dom  X   X nguez et al., 2004 ) (see Fig. 3 ), developed by the Instituto de Autom atica y Fabricaci  X  on (Automatics and Manufacture Institute) at the University of Le  X  on for research and educational purposes. This industrial plant is composed of a process main circuit and two utility circuits, which are associated to the temperature variable:
The process circuit was designed to control four physical variables (pressure, flow, level and temperature) with recircula-tion. The circuit is adaptable so that variables can be indepen-dent or can interact among themselves. It is composed of two cascade tanks of 5 and 6.5l each, which are associated to the level control loops. Recirculation is effected by a pumping circuit fed by a centrifugal pump (an AC drive converter transforms the water pump AC motor into a high-accuracy variable-speed drive). The circuit includes the necessary instrumentation to implement the control loops for the four variables.

The heating circuit is used to produce and store hot water, employing electric resistors with static, adjustable drives. The heat transfer to the process is managed by a high-performance plate heat exchanger, which provides high heat-transfer rates as well as considerable size reduction, compared with the traditional tube heat exchangers. The hot water flow is controlled in split-range by a motor-driven three-way valve, so that the heat can be transferred to the process.

The cooling circuit makes possible to reduce the process temperature, using water from the supply network. Heat-transfer from the process is made by a plate heat exchanger, similar to the one in the heating circuit. The control is performed by a motor-driven two-way valve.
 -15 0 15 5 1 2 4 The manageable variables with the instrumentation that is currently installed in the plant are also shown in Fig. 4 . The control and data acquisition system is a DCS (distributed control system) operating on a standard Ethernet network. The DCS comprises an Optomation M4RTU/DAS controller and a Ethernet B3000ENET I/O &amp; communications processor. Process data are sampled every 150ms and stored, in a Microsoft SQL Server 2000 database, by a link service. A sequence of operation was defined for the experiments. The sequence of stages followed by the industrial plant with this cycle of operation is shown in Table 1 .
The names of the stages correspond with the most significant actions carried out during their execution. The control loops that take part in this sequence are the level, temperature, flow and pressure loops. In each case, the corresponding actuators are used: variable frequency converter (SZ21), electric two-and three-way control valves with split-range positioner (TV21, TV22), electric two-way control valve with positioner (FV21) and pump (P02).
Fig. 5 represents the temporal behavior of some of the most significant variables involved in the process. These variables are used as the input space during the model generation.

The dynamic model of transitions and the visualization maps were generated after clustering of a self-organizing map. The SOM was trained, using the batch training algorithm, with an input space formed by the 26 variables of the industrial process. The training length was 50 epochs. The SOM had a 40 40 grid with a rectangular topology and a Gaussian neighborhood h 1. The SOM was clustered by means of visual inspection of the distance map. Nevertheless, algorithms for agglomerative or partitive clustering may be used ( Vesanto and Alhoniemi, 2000 ). After clustering, 17 different process conditions were identified. The matrix of transitions, which presents the transition prob-abilities among the process conditions was automatically gener-ated using (3) over all units. The matrix of transitions along with the equivalent Petri net and the dynamic map of transitions are shown in Fig. 6 .

After training the model, the sequence of operation of the plant was executed again to obtain a test data set. When working with this data set, the residual vectors were near zero for all the process variables. This situation reveals that the test execution is very similar to the modeled one. Therefore, the model is self-consistent.

The dynamic model obtained from the training of the self-organizing map was used to supervise the industrial plant by means of the direct projection of new input data on the map of transitions. Fig. 6 shows the progression of the pilot plant through the three first process conditions. As all those conditions are accessible, according to the dynamic model, the evolution of the process during this period is considered normal.

In order to assess the usefulness of the dynamic model for visualization of the process behavior and fault detection, a sequence of faults was induced in the industrial scale model.
Next, some selected faults, which are characteristic of the three different possible situations, are described. The main difference among these faults is related to the state of the process after each one. Thus, after the first fault, the process moves to an unreachable process condition, the second one makes the process move to the cluster boundary, and the last one makes the process stay in the same process condition. The selected faults are: Fault A: Heating circuit pump fault (stage 4).
 Fault B: Heating resistor fault (stage 6).
 Fault C: Tank-4 switch fault (stage 1).

For each fault, information about the reachable process conditions from a given one, according to the dynamic model, is visualized (see Fig. 7 ). The results indicate that the transition model facilitates not only fault detection, but also the identification of the variables involved in the fault. Therefore, the transition model solves the problems that appear when only the static algorithm is considered. 4.1. Fault A: transition to an unreachable process condition
In fault A of Fig. 7 , the state of the process can be seen immediately before (green dot) and immediately after (red dot) a fault in the recirculation pump of the heating circuit (stage 4). The closest BMU after the fault belongs to a different condition, since the process condition before the fault was the 5th and, after the fault, the process has moved to the 3rd condition. In this example, the probability of transition from condition 5 to condition 3, according to the probability matrix, is null so, therefore, the transition between them is not possible and there is a fault.
The computation of the residual vector without considering the dynamic model detects the fault, but residuals appear wrongly associated to variables FT21 and TT22 (see Fig. 7 ). This situation, where the static residuals are not useful to correctly identify the variables associated to the fault, is caused because estimation is done using a modeled state that is close, in a Euclidean metric sense, to the fault state but it is not consistent with the dynamic evolution of the process. This problem illustrates, again, that it is necessary to take the dynamic model of transitions into consideration, in order to correctly detect the faults and identify which variables are involved in them. So knowledge about the process dynamics and the unreachability of process conditions from a given one is included in the residual calculation, as described in Section 3.2.

The improved algorithm for computation of residuals only considers the following neurons (marked with a white  X  X   X   X  X  in Fig. 7): the neuron corresponding to the process state immediately previous to the fault (which belongs to condition 5); neurons belonging to the possible transition paths from condition 5 to all the reachable conditions (6 and 7). All these neurons have been identified by the dynamic model of transitions.

The improved algorithm determines that the fault was caused in pump P01. Fig. 7 shows both the correct and the incorrect representation of the residual vector for the fault. 4.2. Fault B: transition to the cluster boundary
It can be inferred, from the performed experiences, that the most common situation after a fault is the one where the new state approximated by the model belongs to a cluster boundary. This statement is supported by the definition of cluster boundary, since it is composed of SOM neurons with high distances and spreads over all the complementary state space of the process. Visualization of this situation allows the detection of the fault.
The same procedure that was used to compute residuals in the previous experience, is followed to analyze this fault, produced in stage 6 in the heating resistor (see Fig. 7 , fault B). The residual vectors computed using the static algorithm (with regard to the closest BMU) are also wrong, since they show traces in variables R1, FT21, TT22 and JZ21. These are inaccurate residuals without a physical meaning. Nevertheless, if the dynamic knowledge is used and the residual vector is computed only from neurons that are reachable (marked with a white  X  X  X  X  X  in the dynamic map of transitions), the result is correctly identified: fault due to a deviation in variable R1. 4.3. Fault C: not involving change of condition
Finally, in Fig. 7 , C is a fault in the level switch of tank D04, during stage 1. In this case, the process state stays in the same p8 p10 0.5 a p9 = condition after the fault (condition 1) and the computation of the residual vector with regard to the closest BMU determines precisely that the fault is caused by variable LSH22. As the faulty state does not contradict the transition matrix, the residual vectors are already calculated from the correct neuron (marked with a white star) and, therefore, it is not necessary to use the dynamic model of transitions. 5. Conclusions
This paper is focused on knowledge acquisition for industrial process supervision, using a data visualization approach by means of self-organizing maps. Visualization tools make possible to manage a great deal of information by transforming it into 2D visual representations, where the human ability to recognize patterns can be used.

Although these tools are normally used to visualize the static characteristics of the industrial processes, they have proven to be very useful to provide knowledge about the dynamics which are implicit in the trajectory followed by the process state. In this paper, a dynamic model of transitions, based on the analysis of the trajectory in the 2D visualization space, has been defined.
The dynamic model stores the process history, identifying the working conditions and the probabilities of transition among them. It can be seen as a Petri net or a Markov chain. This analogy with two well-known tools can make the analysis easier. The resulting dynamic models describe the divergence between the real process evolution and its approximation in order to detect faults.

In addition, this model makes possible an improvement in residual calculation. When the process history is not considered, an incorrect neuron may be selected as the reference to compute residuals. Thus, even though a neuron is the closest one to the current state, this proximity does not imply a correspondence with the process behavior. This incorrect selection may cause an erroneous classification of abnormal behaviors as normal ones and vice versa. This problem of inaccurate identification of the variables associated to a fault can be solved using the available information about the dynamic behavior of the process. For that purpose, the implicit process history in the dynamic model of transitions is used to approximate the current state, according to the expected process behavior.

The proposed method has led to good results. It was applied to a real industrial plant, where several types of faults were induced. The dynamic model of transitions was automatically obtained and the induced faults were detected and made easily identifiable using the visualization tools provided by the model: both the dynamic map of transitions and the visual representation of residuals, computed taking into consideration the dynamic behavior of the system.

These dynamic models, based on the analysis of the trajectory projected by the industrial process in a 2D visualization space, provide useful tools for supervision and fault detection, as shown in this paper. Further work in new approaches for 2D-trajectory learning would be interesting. Particularly, some 2D-trajectory learning methods, such as finite state machines, hidden Markov models (HMM) or non-deterministic finite automata, which have already been successfully used on the visual surveillance field, may lead to interesting results in this field.
 Acknowledgments This research has been funded by the Spanish Ministerio de Educaci  X  on y Ciencia under Grant DPI2006-13477-C02-02/01. References
