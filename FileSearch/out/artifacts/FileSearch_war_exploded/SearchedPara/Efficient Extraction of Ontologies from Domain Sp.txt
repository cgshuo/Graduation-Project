 Extracting ontological relationships (e.g., isa and hasa ) from free-text repositories (e.g., engineering documents and in-struction manuals) can improve users X  queries, as well as benefit applications built for these domains.

Current methods to extract ontologies from text usually miss many meaningful relationships because they either con-centrate on single-word terms and short phrases or neglect syntactic relationships between concepts in sentences.
We propose a novel pattern-based algorithm to find onto-logical relationships between complex concepts by exploit-ing parsing information to extract multi-word concepts and nested concepts. Our procedure is iterative: we tailor the constrained sequential pattern mining framework to discover new patterns. Our experiments on three real data sets show that our algorithm consistently and significantly outperforms previous representative ontology extraction algorithms. H.4 [ Information Systems Applications ]: Miscellaneous Ontologies, Ontology extraction
An ontology is a specification of conceptualizations in a specific domain [2]. An ontology typically includes, at a min-imum, concepts and hierarchical relationships among them. Two of the fundamental hierarchical relationships are isa , which asserts a class-subclass or a class-instance relation-ship, and hasa , which asserts a whole-part relationship.
Building an ontology from unstructured text can bridge the gap between human-readable data and machine-readable knowledge. However, general-purpose ontologies (e.g., Word-Net) have limited coverage, particularly in specialized fields, where jargon and terminology can have different meanings from their senses in a more general domain. For example, in the architecture domain, X  X oreign materials X  X sually refers to external substances on the surface of a piping system; Quite different from the meaning of foreign in  X  X oreign nationals X  which may be found in a legal document.

Extracting rich and complex concepts along with ontolog-ical relationships among them as accurately as possible is the main goal of this work. We develop an iterative pattern-based algorithm called Laser (for LArge ScalE Relation ex-traction system). The central paradigm used by Laser is an iterative framework of starting with seed patterns that signal an occurrence of ( isa or hasa ) relations, which are used to extract instances of relations in the corpus. They are in turn used to induce more patterns from the corpus and so forth. At every stage, the extracted patterns and instances are scored, reflecting their degree of reliability. In summary, we make the following contributions:  X  A novel algorithm to extract complex concepts having isa / hasa relationships from parsed text and to deal with nested noun phrases.  X  Starting with a list of seed patterns from the ontology extraction literature [8, 1, 7].  X  Adaptation of a sequential pattern mining framework to find frequent patterns that signal isa / hasa relationships.  X  A detailed set of experiments over three real datasets.
The rest of this paper is structured as follows: Section 2 describes the related work. We discuss the Laser approach and the algorithms in Section 3 and discuss our experiments and lessons learned in Section 4. Finally, Section 5 concludes and discusses future work.
This paper focuses on automatically building terminolog-ical ontologies from domain-specific text corpora. Many ap-proaches build ontologies consisting of single words [3, 15] or short common compounds [17, 4]. Indeed, few works allow for longer and complex terms to be concepts, generally be-cause they have a very low frequency of occurrence compared to short ones. Drymonas et al. [6] allow more complicated noun phrases using statistical measures and agglomerative clustering. Navigli and Velardi [12, 13] proposed Word-Class L attices (WCLs) which can be used to iteratively extract a set of class-subclass relationships, resulting in a Hypernym Graph (WCL-HG) from which a domain taxonomy is in-duced. Compared to our approach, WCLs require manual tagging of definition sentences and use POS tagging, which does not perform well on identifying boundaries of complex and nested phrases.

There exist clustering-based ontology extraction algorithms that produce prototype-based ontologies (E.g. Caraballo [3]). Pantel and Ravichandran [15] first cluster words from a text corpus; each cluster forms a concept. They extract concept names by searching for syntactic patterns such as  X  concept apposition-of instance  X  and  X  concept such as instance  X . Fi-nally, they assign labels to each cluster according metrics such as to the co-occurrence frequencies of concepts and in-stances. . They create isa relationships between the concept and all instances in the cluster. However, this kind of isa re-lationship is necessarily confined to one level hierarchy, while our work produces a complex multi-level concept hierarchy.
Pure pattern-based methods such as Pantel and Pennac-chiotti [14], often iteratively interleave pattern discovery and instantiation until the reliability drops below a threshold. These methods suffer from low recall. ESPRESSO [14] is a system that given a small set of seed instances for a particu-lar relation, learns lexical patterns, applies them to extract new instances, and then uses the web to filter and expand the instances. We adapt their scoring mechanism in the it-erative process, but instead of starting with seed instances, we bootstrap from seed patterns. Also, we extract instances from patterns substantially differently from ESPRESSO as well: we rely on deep parsing information to get richer con-cepts that cannot be identified by regular expression match-ing over data obtained from shallow parsing. Our pattern finding is also generalized to be less restrictive and more ex-pressive than ESPRESSO. Additionally, we provide a novel formulation of pattern discovery as a constrained sequential pattern mining problem.

Guided Hierarchical Clustering (GHC) [4] is a hybrid ap-proach that first calculates the similarity between a set of given input terms based on syntactic dependency features in the corpus. Then, using an agglomerative clustering algo-rithm, it picks the most similar pair of terms in the remain-ing list of pairs to be clustered, and uses WordNet, Hearst patterns in the corpus, and the world wide web to position them in the growing ontology. Unlike GHC, our approach finds relationships before concepts. We start from patterns that indicate relations, and then get concepts from there, thus not requiring terms as input.
Laser uses an iterative process. It takes as input the pre-processed corpus consisting of a set of text documents, with each word tokenized. Additionally, it takes in a set of seed patterns , i.e., lexico-syntactic templates such as Hearst pat-terns [8] that imply isa / hasa relationships. We define a Sub-sumption Candidate Instance Pair (SCIP) as a pair of noun phrases x, y such that they are involved in a class-subclass or class-instance ( isa ) or a whole-part ( hasa ) relationship, and denote it SCIP( x, y ). In this section, we provide a descrip-tion of modules in the architecture of Laser . More detailed description of these modules can be found in [10].
This module takes a list of known patterns suggesting isa or hasa relationships and applies the patterns to the input corpus to find sentences matching the patterns. Previous works [4, 14] usually find pattern instances by matching each POS tagged sentence with regular expressions. Such a strategy has the following limitations: (1) simple POS tag rules may identify the wrong noun phrase because the context is not considered. (2) Strict application of pattern matching may fail to capture some patterns that contain the proposed patterns. (3) Simple POS tag rules cannot iden-tify some noun phrases that have complex structures using modifiers.

To overcome these limitations, we perform pattern match-ing by first matching sentences containing lexical connectors, and then extracting the corresponding noun phrases from the text segments either surrounding those connectors or in between them, by analyzing the constituent parse tree struc-ture for the sentences. The idea is that a well-trained parser like the Stanford Parser can be more effective at determin-ing noun phrases than simply matching regular expressions over POS tags.

One challenge in ontology extraction is that noun phrases may be nested in other noun phrases. In this case it is difficult to identify the appropriate noun phrases in the ex-tracted relationship. As an example, in the sentence  X  X rovi-sions of shading devices, such as overhangs or vertical fins. X  the noun-phrase  X  X hading devices X  inside  X  X rovision of shad-ing devices X  is a nested noun phrase and the correct parent concept of the isa relationship, not  X  X rovision of shading devices. X  To solve this challenge, we employ a linguistically based heuristic approach that uses hints from an external source, e.g., a general thesaurus like WordNet. A useful cue about the type of a noun phrase can be obtained from its head word. A head word is the word that determines the syntactic type of the noun phrase of which it is a member.
Algorithm 1 extracts the best choice for a parent concept given a nested noun phrase (for the parent) and a list of noun phrases (for the child). Lines 4 X 12 calculate the sum of the similarity between each candidate parent X  X  head word and head words of all children. M axSimSum indicates the simi-larity sum for the candidate parent with maximum similarity sum. . The function Similarity in line 4 is an invocation of the semantic similarity measure defined in [16]. If two candidates have the same sum, we will choose the shortest one (Line 9 X 11), because the head word of a parent phrase tends to be closer to the child phrases that specify this par-ent. When the maximum similarity sum is zero, meaning head words are not found in WordNet (which is possible when we are dealing with a domain-specific corpus), we will try to find the shortest noun phrase, with the head word in plural form if it exists, as a default behavior (Line 13 X 15). We can extend the set of pairs derived by generating more SCIPs that exploit the inherent isa relationship between a complex phrase and its head word and the transitivity of isa relationship. E.g., consider the SCIP isa (plumbing equip-ment, ductile iron pipe). We can extend this by generating the SCIP isa (equipment, ductile iron pipe). Many exist-ing algorithms make the assumption, that if isa ( NP 1 , NP then necessarily isa ( head(NP 1 ), head(NP 2 ) ).
We observed on real data sets that this assumption results Algorithm 1 P arent NP Resolution in Nested NP 1: P arentList  X  Recursively extract a list of noun phrases con-2: MaxSimSum =  X  1 3: CurrentCandidate = null 4: for all Candidate  X  P arentList do 6: if SimSum &gt; MaxSimSum then 7: CurrentCandidate = Candidate 8: MaxSimSum = SimSum 9: else if SimSum == MaxSimSum and 10: CurrentCandidate = Candidate 11: end if 12: end for 13: if MaxSimSum == 0 then 14: Return P arentNP  X  shortest Candidate in P arentList , 15: end if 16: Return P arentNP  X  CurrentCandidate in many erroneous relationships or trivial relationships tha t can be found in a general ontology. This is because in many cases, the sense of the head word cannot be disambiguated without modifiers. For example, following this assumption on isa (points of penetration of the vapor barrier jacket, raw edges) yields isa (points, edges), which is meaningless!
In summary, we extend every extracted pair isa ( NP 1 , NP from a SCIP by generating the additional pair isa ( head(NP head(NP 2 ) ). Then we calculate reliability scores for all ex-tracted and extended pairs based on the scoring mechanism described in Section 3.4. Finally, we filter those pairs with scores smaller than average and pick the top ones as seed SCIPs for discovering new patterns in the next iteration.
We use the seed isa / hasa relationships to find new pat-terns. We adopt a Frequent-Substring-based Pattern Extrac-tion approach to achieve this. The idea is to find substrings that frequently occur in between the parent concept and the child concept of a SCIP in the corpus. Using seed instances in the form of SCIP( NP 1 , NP 2 ) as input, and we find co-occurrences of NP 1 and NP 2 in the corpus where the text in between NP 1 and NP 2 is shorter than a pre-defined limit. After collecting text sequences for each SCIP, we find fre-quent substrings from them. To solve the above problem, we tailor the Generalized Sequential Patterns (GSP) algorithm in [18]. For brevity, we omit the details of this algorithm and refer the reader to the full version of this paper [10].
We need a scoring mechanism to select seed SCIPs and seed patterns to identify new patterns and new concept pairs respectively, and decide the stopping criteria for the iterative process. We follow the Point-wise Mutual Information[5] (PMI) framework for scoring patterns and instances. Using the PMI framework, we use the following formulation: in which P  X  is the set of patterns in the current iteration and I is the set of instances used to find new patterns. In the above equation, we divide the frequency value in the numer-ator and the denominator with corresponding sum values, namely the sum of co-occurrence frequency for all pairs of instance and pattern, the sum of frequencies of all instances, and the sum of frequencies of all patterns, respectively. Here,  X  i ranges over instances, i.e.,  X  i = ( N P 1  X  i , N P 2  X  i
In the first iteration of pattern instantiation, we estimate the precision of the initial set of pre-defined patterns by manual validation on a sampled output, and use those es-timates as initial scores. The algorithm runs until no more new SCIPs can be found or the average score of patterns produced in the current iteration is smaller than 50% of the average score of patterns from the previous iteration.
We evaluated our results on the following three real web datasets: (1) an archive of Architecture, Engineering, and Construction (AEC) scheduling data, design data, meeting notes, and reports used in the construction of a medium medical references from MEDLINE [9] (MED).

We compare Laser with three other algorithms as follows: (1) ESPRESSO [14], (2) GHC [4], and (3) WCL-HG [13]. These algorithms were briefly described in Section 2. Laser and ESPRESSO find isa / hasa relationships while GHC and WCL-HG are only able to produce isa relationships.
We would like to measure and compare the precision as well as recall for the above algorithms. However, given that it is infeasible to fully find all ontological relationships in a large text repository, we measured relative recall  X  the num-ber of valid relationships found by the algorithm divided by the total number of valid relationships found by all algo-rithms [11]. This allows us to also define relative F-score by replacing recall with relative recall . A more detailed descrip-tion of the datasets, measures and algorithms is presented in the full version of this paper [10].
Using the stopping criterion in Section 3.4, Laser ran two isa Pattern Instantiation iterations on all datasets, while ESPRESSO ran one before it reached its stopping criterion.
Table 1 shows the total number of all output isa relation-ships for each algorithm and the corresponding precision. We manually validated all relationships produced for AEC. For the other two corpora, we validated random 100 results if there were more than 1,000 relationships, otherwise we did complete validation. Laser 1 and Laser 2 represent the re-lationships directly extracted from patterns during iteration 1 and 2; Laser is the total result from all iterations. HW denotes the results containing extended relationships found by the SCIP Extension step (Section 3.2). HW+W rep-resents the result with both head word extension and web extension. Finally, DEF indicates expanded results using web definitions (Merriam-Webster dictionary in this case). Table 1: Precision and Total Number of i sa Results In this scenario, for every definition h D EF i found for the input phrase h TARGET i , we add the following to the set of candidate sentences:  X  h TARGET i is a h DEF i  X .
ESPRESSO achieves the best precision on the two smaller d atasets and Laser achieves the best precision on MED. Head word extension increases the number of relationships found by both Laser and ESPRESSO, with precision re-maining about the same or decreasing a little bit because of errors in finding head words. ESPRESSO X  X  web expansion produces many additional relationships, but it markedly de-grades precision.
 The two numbers in each precision column of ESPRESSO HW+W and WCL-HG+DEF measure precisions on rela-tionships found in the domain and relationships valid in any domain, respectively. For example, isa (accessories, neck-lace) is extracted by ESPRESSO on the AEC dataset. This is not valid in the architecture domain because necklace is not a concept in this domain  X  in this domain, accessories stands for construction or mechanical equipment.

GHC relies heavily on isa relationships between a term and its head word, e.g., isa (system, heat recovery system), which are fairly trivial. Neither Laser , nor ESPRESSO output these relationships. The input terms extracted for MED contain a higher percentage of multi-word terms (32%) than those of AEC (23%), so GHC performs much better on the MED corpus: more  X  X rivial X  relationships can be found.
The relatively poor performance of WCL-HG compared to the results in the initial publications [12] may be due to the following reasons. (1) Lacking access to a good set of input domain terms, (2) Patterns learned by WCLs over Wikipedia definition sentences are not effective over complex and technical corpuses such as AEC. (3) As noted in [12], in many cases WCLs are only able to match a substring of the complete match phrase. E.g., over AEC, they return Table 3: Precision and Total Number of hasa Results isa ( furring, application) as a match, which is too general and is a substring of the correct match isa (furring, application of thin wood).

Table 2 gives the relative recall and F-score for algorithms on all corpuses. Testing the validity of all relationships from the two larger datasets is impractical, so for those, we esti-number of valid relationships produced by an algorithm is estimated by the product of sample precision and the num-ber of all generated SCIPs. Summing the estimated valid relationships for all competing algorithms, yields the num-ber of all valid relationships from all systems X  output, which is an overestimate of the real value. Therefore, the esti-mated relative recall is an under estimate but still reflects the difference between systems.

Laser HW outperforms the other algorithms and corre-sponding extensions in terms of relative recall and F-score, thanks to the large output and stable precision. In con-trast, ESPRESSO suffers from low relative recall. Although Espresso X  X  set of SCIPs are valid, the distribution of these seeds in the corpus is unknown beforehand, leading to pos-sibly re-discovering the same pattern repeatedly and hence a consistently low recall. GHC has better relative recall and F-score than ESPRESSO on AEC even when its precision is low on AEC. On the large corpus, GHC has worse relative recall mainly because the agglomerative clustering algorithm does not scale well. As we show later, even running GHC with 5000 terms took more than two days. WCL-HG has its largest relative recall on AEC dataset. The reason is that the algorithm is able to find a large number of web defini-tions for the input seed target phrases. As a result, it finds almost all its matches from web definitions. However, most of these matches are either not complete or are not relevant in the given domain, which results in a low precision. Laser ran one hasa Pattern Instantiation iteration on AEC and two iterations on other two datasets. ESPRESSO still ran only one hasa Pattern Instantiation iteration. Ta-ble 3 shows that both the precision and number of hasa relationships are worse than isa relationships for all algo-rithms. This is because in a corpus, hasa relationships are not as frequent as isa relationships.

Laser outperforms ESPRESSO in every case over the above datasets. One thing to note is that Laser only ex-tends isa SCIPs in the SCIP Extension step (Section 3.2), but ESPRESSO extends both isa and hasa SCIPs. We made this choice because hasa has different semantic mean-ings from isa and contains many subtypes [7]. For example, hasa (treatment of occlusive disease, endarterectomy) is a valid relationship from MED, but its head word extension hasa (treatment, endarterectomy) does not make sense be-cause  X  X reatment X  is too abstract that  X  X ndarterectomy X  is n ot part of  X  X reatment X  in the general sense. ESPRESSO X  X  drop in precision when it applies hasa headword extension also reflects this.

The relative recall and F-scores on the three corpora are presented in Table 4. Laser dominates both measurements consistently while ESPRESSO still suffers from low recall.
Table 5 shows the running times for extracting isa rela-tionships. Laser and Laser HW have the same running time because both versions of Laser require headword ex-tension for seed generation. This is also true for ESPRESSO and ESPRESSO HW. Laser is the most efficient algorithm and is between 1.4 times and two orders of magnitude faster than other algorithms. Laser  X  X  sequential pattern mining approach is more efficient than ESPRESSO X  X  frequent sub-string finding using a suffix tree. ESPRESSO HW+W takes even longer because search engines constrain the query rates. The running time for GHC is quadratic in the number of in-put terms because agglomerative clustering requires pairwise term similarity. Thus, it takes GHC more than two days to finish on an input of 5,000 terms! The bottleneck for WCL-HG is matching each input sentence against all WCLs to find the potential matches. The running time for extracting hasa relationships is similar to the isa case, and we omit the results for lack of space.
 Table 5: isa extraction running time (in seconds)
M any state-of-the-art algorithms for learning ontologies from free text confine themselves to concepts represented as single-word terms or common compounds. In contrast, we find a richer ontology by covering multi-word terms. We extend previous pattern-based iterative frameworks [8, 14], and make the following contributions: (1) We identify con-cepts in isa / hasa relationships by analyzing parse trees in-stead of simple POS tags, and use an efficient parse-once-use-many-times strategy. (2) We develop a novel algorithm to determine the appropriate noun phrases from nested noun phrases present in the corpus. (3) We tailor sequential pat-tern mining to find constrained frequent patterns consisting of words, POS tags, and wildcards.

We empirically show on three real web datasets that Laser stably extracts rich and complex concepts and isa / hasa re-lationships between them, regardless of the size of corpus or data sparsity. In terms of precision, it is comparable to or better than the competitors while in terms of relative re-call and F-score it significantly and consistently outperforms them. Finally, we show that Laser has a significantly bet-ter running time compared to the competing algorithms and better scales.

An interesting future challenge is to post-process concepts found by Laser with statistical methods to boost the pre-cision even further while maintaining scalability.
This research was supported by the NSERC (Natural Sci-ences and Engineering Research Council) Business Intelli-gence Network.
