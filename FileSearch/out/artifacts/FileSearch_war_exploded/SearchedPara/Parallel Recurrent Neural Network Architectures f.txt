 Real-life recommender systems often face the daunting task of providing recommendations based only on the clicks of a user session. Methods that rely on user profiles  X  such as matrix factorization  X  perform very poorly in this set-ting, thus item-to-item recommendations are used most of the time. However the items typically have rich feature rep-resentations such as pictures and text descriptions that can be used to model the sessions. Here we investigate how these features can be exploited in Recurrent Neural Network based session models using deep learning. We show that obvious approaches do not leverage these data sources. We thus in-troduce a number of parallel RNN (p-RNN) architectures to model sessions based on the clicks and the features (images and text) of the clicked items. We also propose alternative training strategies for p-RNNs that suit them better than standard training. We show that p-RNN architectures with proper training have significant performance improvements over feature-less session models while all session-based mod-els outperform the item-to-item type baseline.
 deep learning; recurrent neural networks; gated recurrent units; recommender systems; training strategies
In traditional recommender systems algorithms it is of-ten assumed that user history logs (e.g. clicks, purchases or views) are available. We show that this assumption does not hold in many real-world recommendation use cases: (1)  X 
The author worked at Telefonica Research as an intern dur-ing the time of this research.
 many e-commerce sites do not require user authentication even for purchase; (2) in video streaming services users also rarely log in; (3) many sites have a small percentage of re-turning users; (4) or the user intent can change between dif-ferent sessions, typical for e.g. classified sites. User tracking can partly solve the user identification problem across ses-sions (e.g. through fingerprinting technology, cookies), but this is often unreliable and also raises privacy concerns. So, in such cases the typical solution is to resort to item-to-item recommendations. Here we investigate how we can exploit session data to improve recommendations.

Given the absence of user profiles, it is vital to draw as much information as possible from the session clicks. Besides the click-stream data of the session (clicked item-IDs), one can also take into account the characteristics of the items that have been clicked. Items often come with rich feature representation such as detailed text description or (thumb-nail) image. One can expect that e.g. users shopping for a particular type of item will click on items that have similar text descriptions and similar visual features. Images, text or potentially even richer features such as animated gifs are eventually what the user sees and what will determine the appeal of an item to a user. Features become particularly important in a session modeling setting where historical user specific data is missing or has no importance. Such features should be utilized to aid the session modeling process. Item features are also a very good way to deal with item cold start i.e. when a new item enters the pool of selectable items. The joint modeling of the sequence of clicked item-IDs and item features poses some interesting problems.

The algorithms in this work utilize deep learning tech-niques both to extract high quality features from visual in-formation and to model the sessions. (We also extract fea-tures from text via bag-of-words.) Individual user sessions can be seen as sequence of clicks. We use Recurrent Neural Networks (RNNs) to model the session data. RNNs have been shown to perform excellent in modeling sequence data [15]. We introduce a number of parallel 1 RNN (p-RNN) ar-
Note that we use the term  X  X arallel X  to indicate that for each aspect/feature of the clicked item (e.g. the item-ID, text description, image features) there is a separate RNN processing the input.  X  X arallel X  refers to the fact that we have multiple RNNs rather than distributed processing of the data or the algorithm computations. While distributed chitectures to model the session clicks concurrently with the features (text or images) of the clicked items.

Instead of using a single RNN where all the data is used at the input in a concatenated form, we apply parallel architec-tures because of the very different nature of the data: image features tend to be much denser than the one-hot represen-tation of the item-ID or the bag-of-words representation of text. Parallel training also allows us to fine-tune the individ-ual networks with respect to their hyper-parameters while also maintaining a connection between the networks through shared parameters and optimization. We introduce 3 differ-ent architectures of p-RNNs that combine the ID-click data with the features of the clicked items. The architectures vary with regards to the shared model parameters and in-teractions of the hidden states (Section 3).
 We also point out that training p-RNNs is not trivial. Standard simultaneous training can waste the capacity of the network, because different parts of the same network may learn the same relations from the data. Therefore we devise 3 alternative optimization procedures to train p-RNNs. We thoroughly evaluate the proposed p-RNN archi-tectures on (1) video recommendations using the thumbnail and (2) product recommendations using text description on a classified site. We compare against the industry standard session-based solution, that is today the item-kNN.
Deep neural networks have been employed with tremen-dous success in image recognition, segmentation and retrieval tasks. Deep learning techniques have been used in tasks such as image and speech recognition [5, 10, 20] where unstruc-tured data is processed through several convolutional and standard layers of (usually rectified linear) units.
Neural models for RecSys. Most of the work on deep models and recommendations focus on the classical collab-orative filtering (CF) user X  X tem setting. Restricted Boltz-mann Machines (RBM) were one of the first neural networks to be used for classical CF and recommender systems [22]. More recently denoising autoencoders have been used to per-form CF in a similar manner [30]. Deep networks have also been used in cross-domain recommendation whereby items are mapped to a joint latent space using deep neural net-works [4].

Recurrent Neural Models. RNNs are the deep models of choice when dealing with sequential data (see [15] for a comprehensive review). RNNs have been used in image and video captioning, time series prediction, natural language processing, conversational models, text and music genera-tion, and much more. Long Short-Term Memory (LSTM) [11] networks are a type of RNNs that have been shown to work particularly well, it includes additional gates that reg-ulate when and how much to take the input into account and when to reset the hidden state. This helps with the vanishing gradient problem that often plagues the standard RNN models. Slightly simplified version of LSTM  X  that still maintains all their properties  X  are Gated Recurrent Units (GRUs) [2] which we use in this work.

Session-based recommendations. Classical CF meth-ods (e.g. matrix factorization) break down in the session-based setting when no user profile can be constructed from past user behavior. A natural solution to this problem is the versions of RNNs exist [21] this is not the focus of this work. item-to-item recommendation approach [24, 14]. In this set-ting an item-to-item similarity matrix is precomputed from the available session data, items that are often clicked to-gether in sessions are deemed to be similar. These similari-ties are then used to create recommendations. While simple, this method has been proven to be effective and is widely employed. Though, these methods only take into account the last click of the user, in effect ignoring the information of the previous clicks.

Markov Decision Processes (MDP) [25] are the only other approach that aims to provide recommendations in a session-based manner while taking into account information be-yond the last click. MDPs are models of sequential stochas-tic decision problems. An MDP is defined as a four-tuple  X  S,A,Rwd,tr  X  where S is the set of states, A is a set of ac-tions Rwd is a reward function and tr is the state-transition function. In recommender systems the set of actions are es-sentially the recommendations that can be shown. The sim-plest MPDs boil down to first order Markov chains where the next recommendation can be simply computed through the transition probabilities between items. A major issue with applying Markov chains in the session-based recom-mendation setting is that the state space quickly becomes unmanageable when trying to include all possible sequences of potential user selections over all items.

The first application of neural models in session-based rec-ommendation used RNNs to model the session data [7]. The recurrent neural network is trained with a ranking loss on a one-hot representation of the session (clicked) item-IDs. The RNN is then used to provide recommendations on new user sessions. This work only focused on the clicked item-IDs while here we aim at modeling a much richer representation of the clicked items.

Feature-rich recommendations. Deep models have been used to extract features from unstructured content such as music or images [3, 26]. In recommender systems these features are then typically used together with more con-ventional collaborative filtering models. Convolutional deep network have been used to extract features from music files that are then used in a factor model [28]. More recently [29] introduced a more generic approach whereby a deep network is used to extract generic content-features from items, these features are then incorporated in a standard CF model to enhance the recommendation performance. This approach seems to be particularly useful in settings where there is not sufficient user X  X tem interaction information. Image features that have been extracted using convolutional networks have been used in classical matrix factorization-type CF in [6, 16] to enhance the quality of recommendations. In this section we describe the proposed parallel RNN (p-RNN) architectures that utilize item representations (fea-tures) for session modeling. A p-RNN consists of multiple RNNs, one for each representation/aspect of the item (e.g. one for ID, one for image and one for text). The hidden states of these networks are merged to produce the score for all items. We also introduce baseline architectures, naive approaches for using the different item representations. As a basis, we take the best RNN setting from [7]: a single GRU layer without feedforward layers and the TOP1 pair-wise loss function along with session-parallel mini-batching. The input of the networks is the item ID of a transaction. The input then translates to either (a) a one-hot ID vector or (b) a precomputed dense image feature vector; or (c) a sparse unigram + bigram text feature vector. See details on feature extraction in Section 4. The proposed architectures use a subset of the above 3 item representations. The output is a score for every item indicating the likelihood of being the next item in the session. During training scores are com-pared to a one-hot vector created from the item ID of the next event in the session to compute the loss. In order to reduce computational costs, only the score of the target item and that of a small subset of  X  X egative X  items  X  sampled in each step (see [7])  X  are computed during training.
The TOP1 loss is the regularized approximation of the relative rank of the relevant item. The relative rank of the relevant item is given by 1 N is the sample size,  X  r s,i is the predicted score of the target item,  X  r s,j is the score of negative (other) items in the sample and I { X } is approximated with a sigmoid. Optimizing for this loss modifies the parameters so that the score for i is high. This loss though is unstable as some positive items also act as negative examples and so scores tend to become increasingly higher. To avoid this, the scores of the negative examples are pushed towards zero through a regularization term. The loss function thus takes the following form: L set in recommender systems is in the 100 , 000s, evaluating this loss over all items is computationally prohibitive. We thus use a sampling procedure whereby the loss is evaluated on a sample of the items. For a given session we use the items in the other sessions of the mini-batch as negative samples. This is computationally cheap and also allows us to get samples from the real distribution of the data.
We devised the following architectures (see Figure 1). Due to limited space, we only present architectures with ID and image features; for text features one can proceed analogously as with image ones. The parallel architectures can also deal with ID, image and text features simultaneously. The archi-tectures can be separated into two groups: 1. Baseline architectures: ID only: This architecture only uses the one-hot ID vectors and is identical to the one used in [7]. It serves as a baseline in our experiments.
 Feature only: The input of this variant is one of the con-tent feature vectors (image or text). Otherwise it works similarly to the previous network.
 Concatenated input: The easiest way to combine differ-ent item representations is to concatenate them. This net-work uses the concatenated representations as its input. 2. p-RNN architectures: Parallel: The first parallel architecture trains one GRU net-work for each of the representations. Outputs are computed from the concatenation of the hidden layers of the subnets. Training can be done in different ways (see training strate-gies below).
 Parallel shared-W: This architecture differs from the pre-vious one by having a shared hidden to output weight ma-trix. Scores are not computed for each subnetwork sepa-rately. Instead, the weighted sum of the hidden states is
Also referred to as 1-of-N encoding. The length of the vector equals to the number of items and only the coordinate corresponding to the ID is 1, the others are 0.
Equivalent to computing output scores separately, weight-ing them and applying through the final activation function. multiplied by a single weight matrix to produce the output. Having a shared weight matrix greatly reduces the number of parameters and thus decrease training times and overfit-ting. This model is also analogous to the pairwise model from context-aware factorization research. 4 Parallel interaction: In this architecture, the hidden state of the item feature subnet(s) is multiplied by the hidden state of the ID subnet in an element-wise manner before computing the score of the subnet(s). Mixing different as-pects of the session to compute item scores is analogous to context-aware preference modeling. For that task [9] found that the interaction model , i.e. the sum of the user X  X tem and user X  X ontext X  X tem interaction to perform the best. This ar-chitecture mimics that model with the ID subnet being pro-moted to the primary representation of the session. The main difference to the context-aware task is that all of our representations are session representations and not (mostly) independent dimensions. Also note that contrary to the orig-inal interaction model, the output weight matrix (item fea-ture matrix) is not shared in our model.
Training parallel architectures is not trivial. Standard backpropagation across the whole architecture can produce suboptimal results due to different components of the archi-tecture learning the same relations from the data. This can be avoided by pretraining some parts of the network and training the rest afterwards. This cycle can be done several times, motivated by the success of alternating methods like ALS for matrix factorization. Note that while the param-eters of fixed networks remain unchanged they still partic-ipate in the forward pass and they are only excluded from the backpropagation. We developed the following training strategies for p-RNNs: Simultaneous: Every parameter of every subnet is trained simultaneously. Serves as the baseline.
 Alternating: Subnets are trained in an alternating fashion per epoch. For example, the ID subnet is trained in the first epoch, while the others are fixed; then we fix the ID subnet and train the image subnet for one epoch; and so on. The cycle restarts after each subnet was trained.
 Residual: Subnets are trained one after the other, on the residual error of the ensemble of the previously trained sub-nets. The cycle does not start over, but the individual train-ing of a subnet is longer compared to the alternating method. For example, the ID subnet is trained for 10 epochs, then the image subnet is trained on the residual error of the ID subnet and so on.
 Interleaving: Alternating training per mini-batch. For each mini-batch of training examples, the first subnet is trained, the second subnet is trained on the residual error for the current mini-batch and so on. The more frequent al-ternation allows for a more balanced training across subnets without the drawbacks of the simultaneous training.
In this Section we describe the feature extraction process The hidden to output matrix is the item feature matrix. The hidden states are different representations of the session, i.e. different context dimensions. used to create item representations from images and text. Image features were extracted from video thumbnails, while text features are based on product descriptions.

Encoding images. Recently, deep learning research on convolutional neural networks (CNNs) achieved breakthroughs in a variety of different image-related tasks, like object recog-nition, image segmentation, video classification, etc. [12, 13] even surpassing human performance on the task of ob-ject recognition [5]. Unlike other approaches, CNNs don X  X  require prior feature extraction, since they are capable of working on the raw image data. CNNs trained on millions of images produce image features that can then be used as input in other algorithms e.g. clustering [3, 26]. These mod-els generalize well and also perform well on images that the CNN has never encountered during training and can thus be used as generic feature extractors. This makes CNNs ideal for extracting high quality image features.

We used the GoogLeNet [27] implementation of the Caffe deep learning framework [12] to extract features from the thumbnails of the videos. The network was pre-trained as an image classifier on the ImageNet ILSVRC 2014 dataset [19] that contains 1.2M images organized into 1000 cate-gories. The video thumbnails first had to be scaled down and cropped in order to fit the input of the network. Fea-tures were extracted from the last average pooling layer. The feature vectors were normalized to an l 2 norm of 1. The image feature representation we end up with is a real-valued vector of length 1024.

Figure 2 demonstrates the feature quality by showing the 3 most similar images to two query images, where similarity is defined as the cosine similarity between the image feature vectors. Given the good quality, we do not plug the CNN di-rectly into the RNN, as it would introduce unnecessary com-plexity to the training and is also unpractical, because (a) this network would converge much slower as it needs to learn the model on incomplete/changing item representations; (b) the network would not be suitable for datasets with lower number of items, as 10,000s of items are not enough to lever-age the full potential of the CNN; (c) retraining would take much longer. Another possibility is to use the pretrained network and fine tune the item representations during the training of the RNN. This did not make much difference in our experiments, therefore we did not use fine tuning.
Extracted as the value of the pool5 7x7 s1 layer. Figure 2: Top3 similar images to query images, based on cosine similarity of image feature vectors.
Encoding text. Given the strict limitation on the length of the descriptions imposed by online classified advertise-ment platforms, advertisers usually provide rather concise text for their items. The main goal of the description is to attract the attention of potentially interested users. There-fore, descriptions often contain only the main characteristics of the item and use syntactically incorrect sentences. More-over, it is not rare to have descriptions written in multiple languages to capture a broader audience. The majority of descriptions of our dataset used a subset of 3 main languages with a handful of less frequent ones also present.

Given the inherent noise in user generated, unstructured text and multiple languages in our data, we adopted the clas-sical bag-of-words representation to encode product descrip-tions. First we concatenated the title and the description of the items. 6 We filtered stopwords and extracted unigrams and bigrams from text, and discarded all the entries that appear only once. Finally, the resulting bag-of-words was weighted using TF-IDF [23]. The item representation is a sparse vector of length 1 , 099 , 425 with an average of 5.44 non-zero coordinates.

We tried other methods to extract features from unstruc-tured text, e.g. distributed bag-of-words [18] and Language Modeling with RNNs [17]. However the classical bag-of-words with TF-IDF was found to work best with our data. We attribute this to the noisiness of user generated con-tent. The lack of English text and the presence of multiple languages prevented us from using pre-trained word repre-sentations, e.g. from word2vec. 7
Experiments with adding an embedding layer between the features and the network resulted in worse performance, therefore, the classical bag-of-words/TF-IDF features were used as item representations and were used directly as the input of the RNNs.
The evaluation was done on two proprietary datasets. The first dataset  X  coined VIDXL  X  was collected over a 2-month period from a Youtube-like video site, and contains video watching events having at least a predefined length. During the collection item-to-item recommendations were displayed next to the featured video, generated by a selection of differ-ent algorithms. The second dataset consists of product view events of an online classified site. We refer to this dataset as CLASS. The site also had recommendations displayed with different algorithms during the collection period.

During the preprocessing of the raw event streams we fil-tered out unrealistically long sessions as these are likely due
We explicitly avoided to repeat the title if this was already written at the beginning of the text https://code.google.com/p/word2vec to bot traffic. We removed sessions of one (single click) event because they are not useful for session-based recommenda-tions and also removed items whose support is below five, as items with low support are not ideal for modeling. The sessions of the last day of each dataset are put into the test set. Each session is assigned to either the training or the test set, we do not split the data mid-session. We also filter items from the test dataset if they were not in the train-ing set. This affects only a tiny fraction of the items. The datasets are summarized in Table 1.

We evaluate wrt. the (sequential) next-event prediction task, i.e. given an event of the session how well can the al-gorithms predict the next event of the session. The trained model is fed with the events of a session one after another and we check the rank of the selected item of the next event. The hidden state of the network is reset to zero after a ses-sion ends.

As recommender systems recommend only a few items at once, the relevant item should be amongst the first few items of the list. Therefore, our first evaluation metric is recall@20 that is the proportion of cases having the desired item amongst the top-20 items of all test cases. Recall does not consider the actual rank of the item as long as it is below 20. This is an accurate model for certain practical scenarios where no recommendation is highlighted and their absolute order does not matter. Recall also usually corre-lates well with important online KPIs, such as click-through rate (CTR)[8]. The second metric used in the experiments is MRR@20 (Mean Reciprocal Rank). MRR is the average of the reciprocal ranks of the desired items. The reciprocal rank is set to zero if the rank is above 20. MRR takes the rank of the item into account, which is important in cases where the order of recommendations matters (e.g. the lower ranked items are only visible after scrolling).
We extracted image features from the thumbnails of the videos, see Section 4 for the details of the feature extraction. We experimented with different architectures and training strategies described in Section 3 to see how image data can contribute to recommendation accuracy.

Similarly to [7], the networks optimize for TOP1 loss using adagrad. The parameters  X  such as dropout, learning rate, momentum, batch size, etc.  X  of the ID only and the feature only networks were optimized on a hold out validation set. Then the networks were retrained on the full training set (validation set included) and the final results were measured on the test set. Due to the size of the VIDXL dataset, the more complex networks used the optimal parameters of the ID and image networks in their corresponding subnets. The weights of the subnets were set to be equal as we did not get significantly different results until either of the subnet weights was set to zero.

To speed up evaluation, we computed the rank of the rel-evant item compared to the 50,000 most supported items. While this evaluation methodology somewhat overestimates the rank and thus the evaluated metrics are a little bit higher, the comparison of the algorithms remains fair [1].
Table 2 summarizes the results with different architectures and training methods. In this experiment the number of hid-den units was set to 100 for the baseline architectures and 100 per subnetwork for p-RNNs. The networks are trained for 10 epochs as there is no significant change in the loss after that. The networks are compared to the item-kNN algorithm, the de-facto solution for item-to-item and item-to-session recommendation tasks in the industry. p-RNNs with 100+100 hidden units can easily outperform the ID only network with 100 units, due to the additional infor-mation source and the increase of the overall capacity of the network. Therefore we also measured the accuracy of the ID only network with 200 units. Note that this is a very strong baseline, because having 200 hidden units increases the ca-doubles it. Also, the doubled capacity of p-RNN is split between two information sources, therefore it is clearly in disadvantage to even an RNN with doubled capacity. Nev-ertheless we show that p-RNNs can often beat this strong baseline as well, while they are typically better than the ID only network with 100 units.
 Table 2: Results on VIDXL, using image features extracted from thumbnails. The best results are typeset in bold. p-RNNs use 100+100 hidden units, others use 100 unless stated otherwise. Performance gain over item-kNN is shown in parentheses.

Similar to [7], the RNN outperforms the item-kNN base-line by a large margin. The recall for the RNN on this task is very high, therefore it is very hard for the more advanced architectures to significantly improve on this result. The network that is trained on the image features only is signifi-cantly worse than the ID only network and even worse than the item-kNN, demonstrating that the sequence of item fea-tures in and of itself is not enough to model the session well. Feeding the network with the concatenated input of IDs and image features, because the stronger input dominates during the training, thus the performance hardly differs from that of the ID only network. It is hard for a single GRU layer to handle two types of inputs at once, resulting in a perfor-mance very similar to that of the ID only network. Adding item features using the naive approach has no observable benefits. Therefore we propose to use p-RNNs instead.
Moving on to the proposed p-RNN architectures, one can see that several configurations perform significantly better than the strong ID only baseline. Due to the originally high recall of the network, these novel architectures mostly in-crease the MRR, i.e. they don X  X  find more relevant items, but they rank them better. The best performing architec-ture is the classic parallel one. With the naive simultaneous training it is significantly better than the strong ID only baseline wrt. MRR, but slightly worse wrt. recall. With simultaneous training, different components of the p-RNN learn the same relations from the data, thus the full capacity of the network is not leveraged. Therefore we propose using alternative training strategies.

The best of the alternative training methods is residual training, closely followed by the interleaving one, but the alternating training is also not far behind. The p-RNN with residual training outperforms the strong ID only baseline by 14 . 07% in MRR, while achieving similar recall. The im-provement is even greater over the industry de facto item-kNN solution: 12 . 21% in recall and 18 . 72% in MRR. Table 3: Results on VIDXL, using image features extracted from thumbnails. The best results are typeset in bold. p-RNN architectures use 500+500 hidden units, others use 1000. Performance gain over item-kNN is shown in parentheses.

By increasing the number of hidden units, the capacity of the RNN increases, thus this parameter has a large effect on performance. However this parameter also obeys the law of diminishing returns. We found that results do not im-lem. We ran experiments with 1000 units on non-parallel and 500+500 units on the best performing p-RNN architec-ture (i.e. classic parallel) to confirm that adding item fea-tures can also benefit session modeling when increasing the network capacity and/or the number of epochs has dimin-ishing returns. Table 3 depicts the results.

With more hidden units, the performance increases and even the feature only network outperforms the item-kNN baseline as the capacity of the network is enough to leverage the information in the image features. But otherwise the relation between the results is similar to that of the previ-ous experiments. This further underpins that p-RNNs with alternative training strategies are vital for efficiently incor-porating item features into learning session models. Further increasing the number of hidden units and/or the number of epochs did not increase the performance of any network sig-nificantly, but p-RNN architectures significantly outperform the ID only network with more than 2 times larger capac-have similar recall. This means that the proposed architec-tures with the proposed training strategies can significantly increase performance, even when increasing the capacity of the network has diminishing returns. In other words, adding additional data sources (item features) can increase the ac-curacy of recommendations beyond the maximum achiev-able just from item IDs. However handling multiple sources requires special architectures and training: p-RNNs and al-ternative training strategies.
We repeated the last experiment  X  i.e. baseline RNNs had 1000 hidden units; the classic p-RNN had 500 per subnet  X  on the CLASS dataset with features extracted from product descriptions instead of images. See the detailed feature ex-traction process in Section 4. The experimental setup was the same as before, except that we opted for ranking all items during evaluation, because it is possible to do the full evaluation within reasonable time due to the significantly smaller size of this dataset (compared to VIDXL).
 Table 4: Results on CLASS, using textual features extracted from product descriptions. The best re-sults are typeset in bold. p-RNN architectures use 500+500 hidden units, others use 1000. Perfor-mance gain over item-kNN is shown in parentheses.

The results (see Table 4) concur with that of the earlier experiments with image features. The text only network significantly outperforms the item-kNN baseline in terms of MRR. This confirms that textual features can be effectively exploited to generate better rankings. However it falls short when compared with the ID only network. This suggests that text features alone are not enough. With concatenated input, the network performs similarly to the ID only network analogously to previous experiments.

The proposed alternative training strategies are of cru-cial importance when training p-RNNs, the simultaneous training is clearly suboptimal wrt. recommendation accu-racy. The classic p-RNN with alternative training strategies significantly outperformed both the ID only RNN and item-kNN in both recall and MRR. Residual training proved to ment in recall and  X  6 . 5% in MRR over the ID only network. Note that further increasing the number of hidden units or number of epochs for the baseline RNNs did not improve the results any further. Thus using text based item features in p-RNNs with proper training can also increase recommen-dation accuracy beyond what is achievable from IDs only. Figure 3: Comparing best performing p-RNN against the ID only RNN and item-kNN.

We demonstrate the power of the proposed solution (500 units per subnet) by comparing it to item-kNN and the ID only network with 1000 hidden units on Figure 3.
In this paper we examined the use of item features (image data and text) in RNN-based session modeling to improve session-based recommendations. We pointed out that using item features in and of themselves is not enough to prop-erly model the session and combining multiple data sources efficiently (e.g. ID and image) is not trivial. We proposed p-RNN architectures that can leverage the added value of mul-tiple item representations. We devised alternative training strategies (alternating, residual and interleaving training) that fit these architectures better than backpropagating the error through the whole network. The proposed architec-tures and training methods significantly outperformed both RNNs with ID only input and the industry de facto solu-tion for this problem, item-kNN. Finally, we showed that by using p-RNNs with alternative training, recommenda-tion accuracy can be increased beyond the maximum that is achievable by RNNs with ID only input by increasing their capacity and/or the number of training epochs.
 The work leading to these results has received funding from the European Union X  X  Seventh Framework Programme (FP7/2007-2013) under CrowdRec Grant Agreement n  X  610594. [1] A. Bellogin, P. Castells, and I. Cantador.
 [2] K. Cho, B. van Merri  X  enboer, D. Bahdanau, and [3] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, [4] A. M. Elkahky, Y. Song, and X. He. A multi-view deep [5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual [6] R. He and J. McAuley. VBPR: Visual Bayesian [7] B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. [8] B. Hidasi and D. Tikk. Fast ALS-based tensor [9] B. Hidasi and D. Tikk. General factorization [10] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-R.
 [11] S. Hochreiter and J. Schmidhuber. Long short-term [12] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, [13] A. Krizhevsky, I. Sutskever, and G. E. Hinton. [14] G. Linden, B. Smith, and J. York. Amazon.com [15] Z. C. Lipton, J. Berkowitz, and C. Elkan. A critical [16] J. McAuley, C. Targett, Q. Shi, and A. van den [17] T. Mikolov, M. Karafi  X at, L. Burget, J.  X  Cernock  X y, and [18] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and [19] O. Russakovsky, J. Deng, H. Su, J. Krause, [20] O. Russakovsky, J. Deng, H. Su, J. Krause, [21] H. Sak, O. Vinyals, G. Heigold, A. Senior, [22] R. Salakhutdinov, A. Mnih, and G. Hinton. Restricted [23] G. Salton and C. Buckley. Term-weighting approaches [24] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [25] G. Shani, R. I. Brafman, and D. Heckerman. An [26] A. Sharif Razavian, H. Azizpour, J. Sullivan, and [27] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. E. Reed, [28] A. Van den Oord, S. Dieleman, and B. Schrauwen. [29] H. Wang, N. Wang, and D.-Y. Yeung. Collaborative [30] Y. Wu, C. DuBois, A. X. Zheng, and M. Ester.

