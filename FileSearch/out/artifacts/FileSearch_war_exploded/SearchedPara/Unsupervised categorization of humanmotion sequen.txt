
School of Management, La Trobe University, Melbourne, Australia
National Lab of Pattern Recognition, Chinese Academy of Sciences, Beijing, China
School of Engineering, University of Melbourne, Melbourne, Australia School of Mathematical Sciences, Monash University, Melbourne, Australia 1. Introduction
There has been recently growing interest in algorithms that can extract useful information from non-traditional data (such as images and videos) [1]. Human motion analysis [2] aims to detect, track and understand human movements from image sequences. The importance of pattern discovery in motion time series data has been recognized in many research communities including computer vision, pattern recognition, data mining and machine learning. In particular, clustering has been heavily used for as-sisting event trajectory classification or prediction and analysis of video sequences [3]. One of the key challenges in the interpretation of human motions is how to transform semantically agnostic signals to meaningful feature representations in a way that provides sufficient encoding of the structure of motions of different kinds. The resulting outputs or new data representation can then be used as inputs to higher-level recognition processes. Another key challenge is how to improve the efficiency and robustness of the clustering algorithms and classifiers when they are used on video sequences problems. This paper fo-cuses on devising an efficient method to find similar human motion patterns using clustering algorithms that can address both challenges.

The size and dimensionality of motion sequences data can vary widely because it is highly dependent on various collection factors, for instance, input device, tracking method, motion model, relevant degree of freedom, etc. [4]. We focus on the analysis of short video clips including single individual actions. Silhouettes is one a popular visual cue that has been widely used in recent video mining to extract useful motion information from raw video data [5]. Human activities can be regarded as temporal variations of human silhouettes over time. Human silhouettes through the duration of an activity may generally be considered as points, and these points can be expected to lie on a low-dimensional manifold embedded in the high-dimensional image space. Various dimensional reduction methods can be used to represent the images in a compact subspace, such as multivariate time series which is a common form of the mo-tion sequence in the transformed compact subspace. Time series clustering has attracted great attention in data mining and has also been recognized as an essential tool in process control, intrusion detection and character recognition, etc. [6]. Given the rapid growth of data collected from motion videos, the computational and memory efficiency of algorithms for clustering, classification and indexing such mo-tion time series data becomes an issue. Recent research has proposed many approaches for dealing with the considerable lengths and large number of objects now appearing in time series data. Some popular methods include applying Fourier and wavelet transformations, as well as statistical parameter extraction for models such as the Auto-Regressive Moving Average. Typically, the transformed series or extracted parameters are clustered using conventional clustering algorithms such as k -means clustering [7]. How-ever, there is evidence that some of these methods are inappropriate for massive multivariate time series. They are either undefined and very expensive to compute on high-dimensional data, or restricted to data that satisfies strong linearity assumptions.

In this paper, we propose a new cluster analysis method based on KPCA (Kernel principal component analysis) and time series structure for human motion sequences recognition. The key step of the method involves two dimensional reduction procedures: one transforms high-dimensional video silhouette to low-dimensional space as multivariate time series; the other transforms the multivariate time series into vector space. In the rest of the paper: Section 2 provides related work. Section 3 explains our approach in detail. Some special attention is given to the time series features extraction and selection as explained in Section 4. In Section 5, we demonstrate the empirical results of applying our method on three popular clustering methods with real human motion sequences. 2. Related work
Motion representation and recognition are central to the interpretation of human motions. Various visual cues have been examined in current studies on human motion analysis, for example, Schuldt et al. [8] constructed video representations in terms of local space-time features. Efros et al. [9] proposed a spatio-temporal descriptor based on blurred optical flow measurements to recognize actions. Although feature tracking in 2D or 3D space can be difficult due to the great variability in the appearance and artic-ulation of the human body, human motions can be regarded as temporal variations of human silhouettes over time. Silhouette extraction from video is relatively easier for current imperfect vision techniques. Blank et al. [5] utilized properties o f the solution to the Poisson equati on to extract features from space-time silhouettes for action recognition and detection. A sensor-based human activities recognition in which the activity data are collected using wearable sensors has been shown effective in detecting ab-normal human activities [10]. In this paper, our focus is not on the visual cues or on the collection or selection of type of motion data, so we used (probably imperfect) space-time silhouettes as basic cues to derive effective motion feature representation. We proposed to convert a sequence of silhouette images associated with a motion video into a form of multivariate time series first, using a traditional dimen-sionality reduction method, Principle Component Analysis [11] (PCA), which is an eigenvector method designed to model linear variation in high-dimensional data. The multivariate time series can then be used in a further step to extract structural statistical features that summarize motion pattern. We have done some preliminary study on how to extracting the features from motion sequence in [12].

Cluster analysis on time series data has been widely applied in many challenging research contexts, from similarity search of medical and astronomical sequences to recognizing dynamic changes in time series [13]. In current research on clustering multivariate time series, PCA has been reported to suc-cessfully split large multivariate time series clusters into smaller clusters [14]. Singhai and Seborg [15] demonstrated the effectiveness of combining a factor based on Mahalanobis distance between datasets with PCA to cluster multivariate time series using the k -means algorithm. HMMs is another commonly used method to cluster multivariate time series [16], Yin and Yang [17] proposed to integrate spectral analysis as a noise and dimensionality reduction technique on the HMM transformed data, and empiri-cally showed that their approach outperformed other model-based clustering algorithms for time series data. Another approach by Wang and McGreavy [18] unfolded each multivariate time series into a long row vector composed by concatenating all univariate time series in each dimension of the multivariate time series. When the length of the time series increases or varies and the dimension increases, this method could become computationally infeasible, and many typical applications of time series pattern matching do involve large databases consisting of long time series of different lengths [19]. Among many approaches for dealing with the considerable lengths and large number of objects in clustering time se-ries datasets, feature-based methods have drawn great attention. Motion data sets commonly appear as massive multivariate time series. The feature-based approach can manipulate high-dimensional data ef-ficiently without any assumptions of data linearity, and feature selection provides both cost-effective predictors and a better understanding of the underlying process that generated the data [20]. A num-ber of features extracted from the time series using various statistical models have been employed in clustering algorithms in time series clustering and applications. Nanopoulos extracted four basic statis-tical features from Control Chart Pattern data and used them as input in a multi-layer perception neural network for time series classification [21]. In a classification setting, parameters of an AutoRegression Moving Average (ARMA) model can be estimated and used as a limited dimensional representation for the original time series [22]. Ge and Smyth [23] used an approach for time series pattern matching based on segmental semi-Markov models. Based on our pr evious study on employing clustering on human motion sequences [24], we aim to provide a group of features that is more flexible with wider coverage in conditions and domains, then adapt the unfolding method as the principle approach for transforming the multivariate time series to vectors, so that our approach is more flexible, manageable and efficient. 3. Our method: Cluster analysis based on KPCA and timeseries structure
As shown in Fig. 1, our method framework consists four main phases:  X  Extract space-time video silhouettes sequences of the human motion video and images consist- X  Embed high-dimensional silhouette inputs into a more compact and low-dimensional feature space.  X  Convert each multivariate time series into a feature-vector format based on the structure of the time  X  Apply unsupervised learning (clustering algorithms) on the vector space to identify similar activities 3.1. Silhouette representation
Informative features are critical to the success of activity characterization. We select silhouettes as our basic inputs. Thus, an important problem is how to segment the moving human region from the back-ground image. This can usually be done by motion detection techniques (e.g., an adaptive background model for moving object segmentation based on pixel-wise mixtures of Gaussians in RGB color space). It should be noted that the data sets to be used in our experiments have been provided together with the segmented silhouette masks, thus we do not, and need not, consider the problem of silhouette extraction here. For readers who are interested in silhouette representation, the techniques discussed in previous Section on related work can be used.

Given an original activity video V including T image frames, i.e., V =[ I 1 ,I 2 ,...,I T ] , our basic as-sumption is that the associated sequence of moving silhouettes M =[ M 1 ,M 2 ,...,M T ] can be obtained from the original video. The size and position of the foreground human region vary with the distance of the human from the camera, the size of the human and the activity being performed. The silhouette images are thus centered and normalized on the basis of keeping the aspect ratio property of the sil-houette so that the resulting images do not distort the motion shape, and are of equal dimensions. Establishing correspondences between landmarks on the silhouettes is not always feasible because of the temporal changes in topology and self-occlusions, so the normalized images, namely the raw silhouette representation, are directly used as inputs for tensor space learning. 3.2. Kernel principle component analysis on video silhouette sequences
Since the original silhouette is noisy and also expensive to analyze, in our approach, the KPCA al-gorithm [25] is used for a nonlinear dimensionality reduction. KPCA provides an efficient subspace learning method to discover the nonlinear structure of the  X  X ction space X , and compared to other dimen-sionality reduction techniques, it also may be simpler to apply on both training and new data [26].
Given a set of high-dimensional training samples T x = x 1 ,...,x M in R D with M elements, the sub-space learning is to find an embedding set E y = y 1 ,...,y M in a low-dimensional space R d , ( d&lt;D ) . After obtaining the embedding space  X  the first d principal components  X  the video silhouette sequences can be projected into an associated trajectory in d-dimensional feature space in temporal order, which is presented in multivariate time series format, Y = { Y 1 ,...,Y d } .The d can be determined by the  X  X est X  eigenvectors of the covariance matrix. In Fig. 2, an example of the activity representation of running is shown in a sequence of silhouette. Then it is transformed into a multivariate time series representation as shown in Fig. 3. An example of an action  X  X unning X  represented in multivariate time series format is illustrated in Fig. 2. 3.3. Vector space construction from multivariate time series
After transforming the video silhouette into a multivariate time series format, we propose a novel approach to construct the vector space from the multivariate time series data. We aim to vectorize each multivariate time series data matrix as input for the clustering algorithms. The intuition behind our approach is that if a fixed number of features based on structure characteristics can be used to represent a univariate time series effectively for clustering, as demonstrated in [27], then a vector obtained from these features by unfolding all dimensions in a multivariate time series should be able to measure the similarity between multivariate time series data. Here are the notations and steps to construct the vector space. Let Y = { Y 1 ,..., Y n } represent a collection of n multivariate time series Y i . Each multivariate time series Y = { Y 1 ,...,Y d } consists of d -dimensions of univariate time series Y t . Y is often written as Y = y 1 ,...,y t for a series with t observations. The vector space can be produced from multivariate time series with following steps. 1. Treat each Y as a univariate time series, regardless of the variation in length t . A finite vector 2. Apply a search algorithm (e.g. feed-forward search) over all metrics on a data set with known class 3. Each V in multivariate time series Y is unfolded, so that all d dimensions of V are concate-4. Finally, the original multivariate time series data Y is represented as: Y = { V 1 ,..., V n } .
The original multivariate time series data, with dimension d  X  n  X  t , could be very large. It could make the computation quite unmanageable by many clustering algorithms, especially when the t for each multivariate time series varies. For example, k -means using Euclidean distance cannot handle such data directly as input for a clustering process. The vectorization of the multivariate time series can dra-matically reduce the input size for clustering algorithms and normalize the input size from multivariate time series with various dimensions. For example, for data of dimension 1000( d )  X  100( n )  X  5000( t ) , clustering will be performed on a data set with 1000( d ) matrices of dimension 100( n )  X  5000( t ) ,as opposed to on a single matrix of dimension 1000( d )  X  1000( i ) ,where i is the length of the constructed vector. i can change depending on the domain or application, but it will be much smaller than the original n  X  t . This vectorized matrix will be utilized in the subsequent clustering algorithms. 3.4. Clustering algorithms
Clustering is a descriptive task that seeks to identify homogeneous groups of objects based on the values of their attributes [28]. In time series clustering research, both k -means and hierarchical cluster-ing have been commonly used. Some limitations of these two algorithms are: i) they require the time series length to be identical (that is, all series have the same temporal dimensions), ii) they are inef-fective in dealing with lengthy time series due to poor scalability, and iii) they are not capable to deal with time series contain missing values. Unfortunately, these scenarios are very common characteris-tics of time series data and hard to avoid in real-world applications. Even in the situation when time series have moderate length without any missing values, the efficiency of these algorithms is restricted when some common distance measure is used, (for example, Euclidean distance). As such, spectral clustering has been introduced recently for time series clustering for its superior performance in many applications [29]. However, compared to the classic clustering algorithms (e.g. k -means and hierarchical clustering), spectral clustering involves a non-trivial task when constructing the similarity graph matrix. The computational cost in constructing the similarity matrix in spectral clustering could be expensive when the dimension and size of multivariate time series increase.

In this paper, the focus is on construction of a new vector space from the multivariate time series that reduces the input data dimension for various clustering algorithms. The transformation also solves the potential problems identified above in the original algorithms for time series clustering. The original time series, regardless of varying lengths, missing values, or lengthy, are all converted to a single vector con-sisting a small and fixed number of metrics. The benefit of applying our proposed structure-based feature vectors as inputs for conventional fast clustering algorithm (e.g., k -means clustering) and as inputs to form the similarity matrix in spectral clustering are: i) the computing cost can be reduced with dimension reduced inputs, and ii) it allows the simple distance Euclidean distance (rather than other sophisticated distance function, e.g. Hausdorff distance) to be used in all three clustering algorithms ( k -means, Hier-archical and Spectral), which requires less computing effort. To this end, we aim to demonstrate that our proposed method is algorithm independent and efficient theoretically.

Hierarchical clustering algorithms [30] have a long and successful history as well-known clustering methods applied in many domains. It subdivides into two types of methods: agglomerative and divi-sive, of which the agglomerative method is most commonly used. Single-linkage, complete-linkage and average-linkage clusterings [31] are three different algorithms in the agglomerative method family, defined by three different techniques used as distance measures in clustering process. We used Ward distance [32], which is a weighted group average criterion that keeps the within cluster variance as small as possible at each of the agglomerative steps [33]. Note that many of these methods have efficient al-gorithms, both for distance matrix input [34], and for points in low dimensional Euclidean spaces [35]. However, with the best known time bound being O ( n 3 ) as the faster of these methods, it is too slow for employing on a data set consisting of millions of points in moderate to high dimensional Euclidean spaces. k -means clustering has been recognized as a fast method compared to other clustering algorithms [36]. k -means also overcomes the inflexibility of the agglomeration process over individual objects by reshuf-fling them [33]. Given a set of patterns P 1 ,P 2 ,...,P n , where each P has d describing features, the computational complexity of each iteration is O ( nkd ) . As the number of patterns n , the number of describing features d , and the clusters k increases, k-means becomes less practical [37].

In spectral clustering, a set of n time series can be considered as an undirected edge-weighted graph with n nodes. The problem of discovering clusters can be viewed as searching for edge-weighted maxi-mal cliques in the graph based on the eigenvectors of the Laplacian matrix derived from pairwise similar-ity matrix between all objects in a data set. The Ng-Jordan-Weiss algorithm [38] has been implemented in the experimental evaluation. The advantage of spectral clustering is that it allows great flexibility in forming the affinity matrix based on pairwise distance measures regardless of the difference in cardinal-ities among data sets. For instance, Hausdorff-based distance can be used for series in different lengths where Euclidean distance is not applicable. The use of spectral clustering has, however, been mainly restricted to small-scale problems because of its high computational complexity. Spectral clustering first performs an eigenvalue decomposition, and then some heuristics such as k-means are applied to the eigenvectors to obtain the discrete clusters. Unfortunately, eigenvalue decomposition is computationally expensive ( O ( n 3 ) ,where n is the size of the matrix in the eigenvalue problem [39].) 4. Features extraction and selection
There are three common data characterization methods: i) statistical and information-theoretic charac-terization, ii) model-based characterization, and iii) landmarking concepts [40]. We adapted the features proposed in a study that used characteristic metrics to represent univariate time series [27]. The extracted statistical features should carry summarized information of time series data, capturing the structure of the time series. If a time series can be represented as an ordered set of n real-valued variables v 1 ,...,v n , as seasonal, trending, noisy, etc. Many of these features have been reported in human motion and pat-tern recognition litera ture recently [41,42]. The se t of metrics includi ng conventional f eatures and many advanced features could serve well as the generic set for us to perform a selection, to find an optimal subset of features to represent the structures of the time series extracted from human motion sequences.
In practice, we need to create the selection of the features with special attention to the domain knowl-edge and with expert assistance if possible. Alternatively, for certain applications, we can use supervised learning on data sets with known class labels to select an optimal set of features. In this paper, we adapt a greedy forward search algorithm as a searching mechanism to select features for the human motion sequences recognition. Forward search is a powerful general method for detecting multiple influences in a model [43]. The forward procedure of selecting the subsets of observations is: i) an initial subset of the smallest possible size is selected by fitting the statistical model to a large number of subsets of that size and evaluating the goodness of the fit; ii) then all observations are ordered by their closeness to this fitted model. For a regression model, the residuals determine closeness, and for multivariate models other measures such as values of normal density function (since the data may be assumed to have a multivariate normal distribution, so that we can expect outlying observations have small values), play a similar role. The subset size is increased by one based on the closeness measure and the model is refitted to the observations of the increased subset size. iii) the process continues until all the observations are included in the subset. As the result of this forward search we have an ordering of the observations by the closeness to the assumed model.

Given that the data set to be used in the evaluation in our experiments has been collected with known class labels, or semantic activity descriptions for each video sequences, we are able to consider the su-pervised learning procedure to guide the search process. The idea is to do the search on a small subset of the data, for which labels are known, in order to learn the feature subset that can then be applied to a larger unlabeled dataset. Using labeled data we use simple one nearest neighbor classification as the quality measure. We begin from an empty set of features, and augment the feature set one by one, at each step adding the best single feature found at that step. After selecting this feature, we then individ-ually consider adding each of the remaining features, continuing the process until all features have been added (to guard against local minima). After all features have been added we select the feature subset that gave the maximum value for the measure of quality. We conducted a forward search process on a total of thirteen measures, using a subsample of 100 time series for the feature selection using FS. We decided to train on half the data for feature selection, and the training examples were equally spread between all of the act ivities. As shown in Table 1, classification accuracy reaches its peak after adding the top 10 metrics based on FS using the training dataset with known class labels. From the 11th metric (Skewness-TSA), the accuracy decreases. Thus, a subset composed of these 10 metrics are selected to be used in vector space construction and each feature is listed in the order in which it is added. In our study, although the classification accuracy using the optimal set of metrics provided a higher level of accuracy than using the default (all features) without search, the improvement of accuracy is not great. In the experiments in Section 5, we included a validation step on the selection of these 10 metrics using three hierarchical clustering algorithms on the single-person data set. After the test, the final selection of 10 metrics are: Hurst parameter, Frequency parameter, Kurtosis, Seasonal factor, Trend factor, Se-rial correlation parameter on both original data and adjusted data with de-trending and de-seasonlizing (indicated with a  X  X SA X ), Nonlinearity test, Skewness and Lyapnov exponent. 4.1. Review on the selected features
To provide a better understanding of the features selected, we briefly review these features in this section and more details can be referred to [27]. Trend and seasonality are common features of time series, and it is natural to characterize a time series by its degree of trend and seasonality. In addition, once the trend and seasonality of a time series has been measured, we can de-trend and de-seasonalize the time series to enable additional features such as noise or chaos to be more easily detectable. A trend pattern exists when there is a long-term change in the local mean value. Given an original time series Y t , Y  X  t denotes the series after a Box-Cox transformation from the original data Y t . Makridakis X  X  decomposition model [44] can be used to extract the metrics for trend and seasonality: Y  X  t = T t + S remainder component. X t = Y  X  t  X  T t ,where X t is the de-trended data after Box-Cox transformation. Z T
Skewness is a measure of symmetry, or more precisely, the lack of symmetry, in a distribution. For univariate time series, Y t , the skewness coefficient is M skewness = 1 n X  3 n t =1 ( Y t  X  mean,  X  is the standard deviation, and n is the number of data points (or observations) in the series. Kurtosis is a measure of whether the data are peaked or flat, relative to a normal distribution. A data set with high kurtosis tends to have a distinct peak near the mean, declines rather rapidly, and has heavy tails. For a univariate time series, Y t , the kurtosis coefficient is: 1 n X  4 n t =1 ( Y t  X 
Serial correlation is the correlation of a variable with itself over successive time intervals. In practice, it can be used to determine how well the past of a scenario predicts its future, to detect non-randomness in data, or to identify an appropriate time series model if the data are not random. We use Box-Pierce statistics [45] to estimate the serial correlation feature: M BP = n s k =1 r 2 k where s is the number of coefficients to test autocorrelation and r k is the autocorrelation coefficient for lag k .

Periodicity is very important for determining the seasonality and for examining the cyclic pattern of the time series. A time series is called cyclic if there is some fixed period after which a pattern repeats itself. Seasonal time series are a subset of cyclic time series in which the cycle time belongs to a special family such as one day, one week, one month or one year. Cyclic data have varying frequency length, but seasonality is of fixed length over each period. For time series with no seasona l pattern, the frequency is 1 .

Non-linear autoregressive structure and associated problems have gained great interests from physi-cists and mathematicians because most physical systems are inherently nonlinear in nature. The weather is famously nonlinear, where simple changes in one part of the system produce complex effects through-out. The Neural Network test has been reported to have better reliability [46] compared to other models in finding the nonlinear structure of time series. The Ter X svirta X  X  neural network test [47] is used to measure the nonlinearity feature of a time series.
 Chaos was introduced since early 1980s when the nonlinearity and its equations are difficult to solve. Recognizing and quantifying chaos in time series is important for understanding the nature of random behavior, and reveals the dynamic features of the data [48]. Nonlinear dynamic systems often exhibit chaos, which is characterized by sensitive dependence on initial values, or more precisely by a posi-tive Lyapunov exponent. The Lyapunov exponent is a measure of the divergence of nearby trajectories which can be used to qualify the notion of chaos. Self-similarity is a concept associated with chaos. It is a processes with long-range dependence which attracted attention from theoretical physicists. The first review of second-order statistical time series analysis was presented by Cox [49] in 1984. The sub-ject of self-similarity (or long-range dependence) and the estimation of statistical parameters of time series in the presence of long-range dependence have also become more common in several fields of science. The Hurst exponent parameter is recognized as a common metric to present the existence of self-similarity [50]. 4.2. Computational discussion The computations for calculating all features on each time series all share linear complexity O ( n ) . Given our method only require basic Euclidean distance for measuring the similarity between time series, if each series has identical length t , the computational cost for constructing the (dis)similarity matrix for the clustering algorithm is O ( tn 2 ) ,where n denotes the number of time series in the data. Given the same clustering algorithm, the computational cost difference between our method using feature vectors as input compared to using the original data is: O ( cn 2 ) ,where c is the number of features or statistical metrics to be used in constructing the vector.

Remark Assume a multivariate time series data set is extracted from the image silhouette using KPCA and it is the original data to be deployed in the clustering process. If we use a fast clustering algorithm (e.g. k -means clustering) and Euclidean distance, then our method involving a dimensional reduction procedure is faster and less expensive when compared to a clustering process without our dimensional reduction.

We have tested the computational time for different time series in various lengths ranging from 500 to 100 000 in each series in Matlab and R, and the time to extract feature metrics over more than 50 runs are all less than 2 seconds.
 5. Experimental evaluation on real-world human motion sequences data
To evaluate the effectiveness and efficiency of our proposed method, we use two human motion time series data sets that were previously used for classification problems with known class labels as ground-truth. Our experiments benefited from this by using the class labels to calculate the accuracy of clustering results in evaluation. The measure of accuracy P is the averaged purities of resulting clusters. The cluster purity p is defined as the ratio of the number of the dominant class within a detected cluster to the total number of objects in the cluster. In the first experiment on single-person data set [51], we explain the details on how to transform the silhouette sequences to multivariate time series. We have also tested the selected features with three hierarchical clustering methods on this data set before they are employed for other evaluation experiments including k -means and spectral clusterings. The second experiment was on a multi-person data set [5] in which different motions have different lengths in time series representations because they are collected from multiple persons with different performing speeds. Note that the single-person data set contains time series in identical lengths for different motions. 5.1. Experiment on the single-person data set
In the single-person data set, 10 different motion videos were recorded and each motion was per-formed ten times by a single-person . The human motions are labeled as  X  X ick up X ,  X  X og in place X ,  X  X ush X ,  X  X quat X ,  X  X ave X ,  X  X ick X ,  X  X end to side X ,  X  X hrow an object X ,  X  X urn around X  and  X  X alk on cell phone X  .Inthis data set, a total of 100 video sequences were collected. Previously, this data was used to systematically examine the effect of the temporal rate of execution on motion recognition. The video image examples for the 10 motions are shown in Fig. 4.

Given an action video with n time frames, our basic assumption is that the associated sequence of moving silhouettes can be obtained from the original video. The size and the position of the foreground region vary with the distance of object to camera and the size of object and the performed activity. The silhouette images are centered and normalized on the basis of preserving the aspect ratio of the silhouette so that the resulting images contain as much foregr ound as possible, do not distort the motion shape, and are of equal dimension for all input frames. For silhouette extraction, we directly use the silhouette masks obtained from [51], even though these silhouette images are not very satisfactory, consisting of leaks and intrusions due to imperfect segmentation. Then, we center and normalize all silhouette images into the same dimension (i.e., 48  X  32 pixels). Figure 5 illustrates the process from a motion image sequence to an associated sequence of normalized silhouette images. To obtain a compact description and efficient computation, we use the Kernel Principal Component Analysis algorithm (KPCA) [25] to perform nonlinear dimension reduction. KPCA significantly reduces the dimensionality number of the input features that l eads to a lower computational cost, while achiev-ing high accuracy. Note that these parameter settings were normally found empirically in a series of experiments. After obtaining the embedding space including the first d principal components, any single motion video can be projected into an associated trajectory in a d -dimensional feature space as shown in Fig. 3 [52]. All 100 videos in the data set were pre-processed by KPCA to transform them into mul-tivariate time series representation as discussed earlier. We chose the first 25 principal components in the dimension reduction process and each motion was performed by the same person within the same time frame consisting of 80 time stamps. Therefore, after transformation from videos to multivariate time series, this data set contains 100 objects with 25 indexed sequences recorded in 80 time stamps (or intervals).

In the feature selection learning process as explained in previous Section 4, although the classifica-tion accuracy using the optimal set of metrics provided a higher level of accuracy than using the default (all features) without a searching process involved, the improvement in accuracy is not extremely large, (i.e. 56.8% vs. 45.6%). So, we decided to test the selected set using three hierarchical clustering algo-rithms to compare empirically all available metrics and decide which should be used finally in vector construction. We implemented three algorithms: Average-linkage hierarchical using Ward X  X  minimum variance method, that aims at finding compact, spherical clusters; the complete-linkage hierarchical, and the single-linkage. The clustering results on both the selected self of 10 feature metrics and the default collection of 13 feature metrics are shown in Table 2. Comparing the results between default feature vectors (consisting of 13 metrics) and optimized subset feature vectors (consisting only 10 metrics), it is clear that feature selection after the search process has improved the clustering accuracy on average for hierarchical clustering algorithms except complete-linkage clustering. As such, we note that the response to feature selection is not uniform for all algorithms. However, the selection of 10 metrics is confirmed after this experiment and they were used in all further experiments.

To evaluate our proposed method, we conducted more clustering experiments on k -means clustering algorithms and the spectral clustering algorithm. In k -means clustering, we used both Hartigan and Wong X  X  algorithm [53] and MacQueen X  X  [54] algorithm. Ground-truth knowledge of the class labels in this dataset suggested that k =10 . Since the initial start of the cluster centers can affect the clustering result, we employed multiple runs with different random restarts to achieve a more reliable result. We used the Ward average-linkage hierarchical clustering algorithm [32] in the experiment with a cut of the dendrogram tree where 10 clusters were obtained. For spectral clustering, Ng et al. [38] suggested selecting  X  empirically by running their algorithm repeatedly for a number of values of  X  and selecting the one which provides the least distorted clusters of the rows of F . To set the range of  X  to be tested, we use the distance histogram based on the fact that if the data form clusters, then the histogram should be multi-modal. The first mode should correspond to the average intra-cluster distance and other modes to between-cluster distances. By choosing  X  around the first mode, the affinity values of points forming a cluster are expected to be significantly larger than others. In our experiments  X  = 0.13 empirically achieved the best result. As mentioned in the beginning of this section, the quality of each clustering algorithm is measured by the average cluster purity P over all p values of each cluster identified. A summary of clustering performances ( P %) and experimental run time (in seconds) on the single-person data set is illustrated in Table 3. As we can see in Table 3, using the structure based vectors as input clearly improved the accuracy on both k -means and hierarchical clusterings, which demonstrates the effectiveness of our proposed method for recognizing similar human motion sequences.Only the spectral clustering using feature vectors was not able to outperform using original multivariate time series data as input. The reason is that in spectral clustering, a dimension reduction process is embedded which normally works well on data sets with high dimensions. In our study, after we transform the high-dimensional data into a low-dimensional vector space, the advantage of clustering could actually be harmful if a further dimensional reduction process is applied. However, the result of 92% accuracy is still very high and still serves well to demonstrate the effectiveness of our method empirically.
To examine and analyze which motion sequences are incorrectly identified and to investigate the underlying reason, the experimentation results on each motion activity and their accuracy P is illustrated in Table 4. Comparing these 10 activities across all methods, they can be divided into three groups based on the average clustering accuracy.  X  X og in place X  ,  X  X end X  and  X  X alk on cell phone X  are the easiest activities to be identified, with 100% accuracy. It is most likely that the types of movement in these activities are more central and stabilized compared to others. For instance, the motion sequences for activity labeled as  X  X og in place X  do not change much over the temporal dimension, neither are there many changes involved in spatial dimension. In contrast, the activities  X  X ave X  and  X  X hrow an object X  are the most difficult motions to recognize among all examined motions. Both activities involve big movements of human arms, which could result in more noise in the video recording. In addition, when the KPCA was applied to reduce dimension from image silhouette, more information could have been lost compared to other activities. Rest activities including  X  X ick up X ,  X  X ush X ,  X  X quat X ,  X  X ick X ,  X  X end to side X  and  X  X urn around X  are sharing clustering accuracy close to the average. It appears that the extracted structure-based features tend to be inadequate for describing the  X  X ave X  object, which caused poor clustering results. On the other hand, our proposed features are suitable for summarizing activities like  X  X og in place . This analysis provides us with an understanding of the strengths and weaknesses of our approach, both of which we will address in future. From Table 4, it can be seen that the MacQueen k -means and Complete-linkage hierarchical clustering performed poorer than the average, but most clustering algorithms from Hartigan-Wong k -means to single-linkage and spectral clustering have demonstrated promising and similar results. The results demonstr ate that our features are not model-or algorithm-dependent, which shows their generality and adaptability. 5.2. Experiment with the multi-person data set
In the experiment on single-person , we demonstrated the advantage of using our method in clustering algorithms which provided better clustering results compared to benchmarking method (e.g. k -means clustering on original data). The single-person is a simplified case of real-world data, in which the temporal dimension is identical within the set. When the temporal uniformity is not present, or when the lengths of the time series vary within the data set, then most conventional clustering algorithms (e.g. k -means) with Euclidean distance are no longer capable to handle the clustering tasks on original data points. In this case, other types of distance measures are required (e.g. Hausdorff distance can be used instead of Euclidean distance to form the pairwise similarity matrix) or more sophisticated algorithm must be employed (e.g. spectral clustering in case of varying lengths). In the second experiment using the multi-person data set, we focus on demonstrating the flexibility, robustness and efficiency of using our feature vectors in dealing with more complex motion sequences applications.

The multi-person data set is more complex than the single-person data set in both temporal and spatial dimensions (or perspectives). In the collected video sequences, the same activity has been performed by different people with different performance speeds. For example, activity  X  X ick up an object X  has been recorded with person  X  X all and Fat X  who is tall and fat for 70 seconds and also with person  X  X hort and Slim X  who is short and slim for 50 seconds . So the silhouettes based on video images for the same activity could appear differently in space due to the different body outlines from different persons. Furthermore, the number of time frames for the same activity is also different, as  X  X all and Fat X  has 70 time stamps and  X  X hort and Slim X  only has 50 time stamps. The data set we used in the experiment consists of 90 low-resolution videos collected from 9 different people and each person performed 10 different activities. As in the single-person data set, this data set has also been used for classification problems and the ground-truth class labels are known [5]. The semantic labels for 10 activities are:  X  X end X ,  X  X umping jacks (jack) X ,  X  X ump-forward-on-two-legs (jump) X ,  X  X ump-in-place-on-two-legs (pjump) X ,  X  X un X ,  X  X allop-sideways (side) X ,  X  X kip X ,  X  X alk X ,  X  X ave-one-hand (wave1) X  and  X  X ave-two-hands (wave2) X  . Compared to the single-person data set, the image examples for these 10 activities provide a more realistic scenario for algorithm evaluation with respect to the variations and complexities in both temporal and spatial scales. From these 90 original videos, 198 image sequences were extracted for our experiments, each of which includes a complete activity. We picked a different number of image sequences for different activities. For activity  X  X end X ,  X  X ack X ,  X  X ump X ,  X  X jump X ,  X  X un X ,  X  X ide X ,  X  X kip X ,  X  X alk X ,  X  X ave1 X  and  X  X ave2 X  , the number of image sequences are 9, 23, 24, 27, 14, 22, 25, 16, 19 and 19 respectively. Then, all 198 image sequences were pre-processed using KPCA to transform them into 198 multivariate time series sequences. Just as explained in the experiment with single-person data set, the first 25 principal components were chosen in the dimensional reduction procedure. Since the activities were performed by different people and recorded in different time frames, the total of 198 multivariate time series consisted of 25 indexed sequences for each series of varying length. The lengths of the time series are in the range of [17,63].

As demonstrated in the experiment on single-person data, among three clustering algorithms, spec-tral clustering performed best as shown in Table 3. As such, in the multi-person experiment, we only implemented spectral clustering with and without our proposed method. For comparison, we evaluated the performances of spectral clustering algorithms using original data points as inputs versus our pro-posed feature vectors, and Euclidean distance measure as inputs in the similarity matrix construction. We empirically found that  X  =0 . 19 achieved the best result. The target we try to achieve with our approach is to ensure a reasonable accuracy level to be maintained while reducing the computational cost. The clustering accuracy using spectral clustering with original data point is 85% versus 81% if using the extracted features, which demonstrated a fairly promising result, which is very close to the accuracy using spectral clustering on the original data points using much less run time. The confusion matrix illustrated in Fig. 6 shows that most sequences are correctly identified. The elements in each row in the confusion matrix represent the probability that a certain kind of motion activity is classified as other kinds of motions. 6. Conclusion
In this paper, we proposed an effective method for human activity representation and analysis in monocular videos. The novelty of the method is two-fold: a) in feature extraction, we select simple but easy-to-extract space-time silhouettes as inputs, and embed them into a low-dimensional space (multi-variate time series) using KPCA for more compact feature representation; and b) in activity analysis, we present a new approach using statistical feature vectors to cluster multivariate time series sequences.
Our experimental results, based on state of the art data sets of human activity analysis, have shown the capability of our approaches in human activity pattern discovery. The competitive experiments showed promising results in obtaining high accuracy in either supervised or unsupervised manners. In the future, more techniques can be applied in our experiments. For example, a backward procedure can be used instead of forward procedure for feature selection. we plan to improve our dimensionality reductions for both steps: i) from image silhouette to low-dimensional space (e.g. multivariate time series) and ii) from the multivariate time series to selecting each identified feature before forming the final vectors. If we focus more on motion time series applications, we could conduct more experiments on motion video data sets to identify the specific features which contribute the most toward accurate and efficient clustering. As a result, our method could become more flexible in practice, and reach higher accuracy in finding clusters for pattern discovery in motion time series data.
 References
