 Google Google
Long queries often suffer from low recall in Web search due to conjunctive term matching. The user query logs to learn rewrites of query terms into terms from the document space. We show between queries and documents by translating from a source language of user queries into a target language of Web documents. We train a state-of-the-art statistical machine translation model on query-snippet pairs from user query logs, and extract expansion terms from the query a query language model achieves improved contextual query expansion compared to a state-of-the-art query expansion model that is trained on the same query log data. 1. Introduction
Information Retrieval (IR) applications have been notoriously resistant to improvement attempts by Natural Language Processing (NLP). With a few exceptions for specialized nouns or verbs has been inconclusive. In this article, instead of deploying NLP tools or ontologies, we apply NLP ideas to IR problems. In particular, we take a viewpoint that looks at the problem of the word mismatch between queries and documents in
Web search as a problem of translating from a source language of user queries into a target language of Web documents. We concentrate on the task of query expansion by query rewriting. This task consists of adding expansion terms with similar statistical properties to the original query in order to increase the chances of matching words in relevant documents, and also to decrease the ambiguity of the query that is inherent in natural language. We focus on a comparison of models that learn to generate query rewrites from large amounts of user query logs, and use query expansion in Web search for an extrinsic evaluation of the produced rewrites. The experimental query expansion expansion terms are extracted and added as alternative terms to the query, leaving the ranking function untouched.
 mexican cooking using AND and OR operators. Conjunctive matching of all query terms is the default, and indicated by the AND operator. Expansion terms are added using the OR operator. The example in Figure 1 illustrates the key requirements to successful query expansion, namely, to find appropriate expansions in the context of the query.
While remedies , medicine ,or supplement are appropriate expansions in the context of the first query, they would cause a severe query drift if used in the second query. In the context of the second query, spices is an appropriate expansion for herbs , whereas this expansion would again not work for the first query.
 sources of the translation model and the language model to expand query terms in context . The translation model proposes expansion candidates, and the query language combination, the incessant problems of term ambiguity and query drift can be solved. applicable to this task. We apply SMT to large parallel data of queries on the source side, and snippets of clicked search results on the target side. Snippets are short text instead of the full documents makes our approach efficient, it introduces noise because text fragments are used instead of full sentences. However, we show that state-of-the-art statistical machine translation (SMT) technology is in fact robust and flexible enough
We evaluate our system in a comparative, extrinsic evaluation in a real-world Web that is trained on the same user logs data and has been shown to produce significant improvements over the local feedback technique of Xu and Croft (1996) in a standard evaluation on TREC data. Our extrinsic evaluation is done by embedding the expansion systems into a real-world search engine, and comparing the two systems based on show that the combination of translation and language model of a state-of-the-art SMT model produces high-quality rewrites and outperforms the expansion model of Cui et al. (2002).
 570 state-of-the-art SMT and describe how to adapt an SMT system to the query expansion task (Section 4). Results of the extrinsic experimental evaluation are presented in Sec-tion 5. The presented results are based on earlier results presented in Riezler, Liu, and
Vasserman (2008), and extended by deeper analyses and further experiments. 2. Related Work
Standard query expansion techniques such as local feedback, or pseudo-relevance feed-back, extract expansion terms from the topmost documents retrieved in an initial re-trieval round (Xu and Croft 1996). The local feedback approach is costly and can lead to query drift caused by irrelevant results in the initial retrieval round. Most importantly, though, local feedback models do not learn from data, in contrast to the approaches described in this article.
 query logs for query reformulations (Huang, Chien, and Oyang 2003; Fonseca et al. 2005; Jones et al. 2006), query clustering (Beeferman and Berger 2000; Wen, Nie, and
Zhang 2002; Baeza-Yates and Tiberi 2007), or query similarity (Raghavan and Sever 1995; Fitzpatrick and Dent 1997; Sahami and Heilman 2006). The advantage of these ap-proaches is that user feedback is readily available in user query logs and can efficiently be precomputed. Similarly to this recent work, our approach uses data from user query logs, but as input to a monolingual SMT model for learning query rewrites.
 (1999) and Berger et al. (2000), who proposed to bridge the  X  X exical chasm X  by a retrieval model based on IBM Model 1 (Brown et al. 1993). Since then, ranking models based on monolingual SMT have seen various applications, especially in areas like Question
Answering where a large lexical gap between questions and answers has to be bridged (Berger et al. 2000; Echihabi and Marcu 2003; Soricut and Brill 2006; Riezler et al. 2007;
Surdeanu, Ciaramita, and Zaragoza 2008; Xue, Jeon, and Croft 2008). Whereas most applications of SMT ideas to IR problems used translation system scores for (re)ranking purposes, only a few approaches use SMT to generate actual query rewrites (Riezler,
Liu, and Vasserman 2008). Similarly to Riezler, Liu, and Vasserman (2008), we use SMT to produce actual rewrites rather than for (re)ranking, and evaluate the rewrites in a query expansion task that leaves the ranking model of the search engine untouched. expedient for paraphrasing, that is, the task of reformulating phrases or sentences into semantically similar strings (Quirk, Brockett, and Dolan 2004; Bannard and Callison-
Burch 2005). Although the use of the SMT in paraphrasing goes beyond pure ranking to actual rewriting, SMT-based paraphrasing has to our knowledge not yet been applied to IR tasks. 3. Query Expansion by Query X  X ocument Term Correlations
The query expansion model of Cui et al. (2002) is based on the principle that if queries containing one term often lead to the selection of documents containing another term, then a strong relationship between the two terms can be assumed. Query terms and document terms are linked via sessions in which users click on documents in the retrieval result for the query. Cui et al. define a session as follows:
According to this definition, a link is established if at least one user clicks on a document in the retrieval results for a query. Because query logs contain sessions from different users, an aggregation of clicks over sessions will reflect the preferences of multiple users.
Cui et al. (2002) compute the following probability distribution of document words w given query words w q from counts over clicked documents D aggregated over sessions: the clicked document, and the second term is the relative cooccurrence of the clicked document and query term.
 Cui et al. (2002) introduce the following cohesion formula that respects the whole query Q by aggregating the expansion probabilities for each query term: algorithm allows us to precompute term correlations off-line by collecting counts from
On the one hand it allows for efficient non-iterative estimation, but on the other hand it makes the implicit assumption that data sparsity will be overcome by counting from huge data sets. The only attempt at smoothing that is made in this approach is shifting the burden to words in the query context, using Equation (2), when Equation (1) assigns zero probability to unseen pairs. Nonetheless, Cui et al. (2002) show significant improvements over the local feedback technique of Xu and Croft (1996) in an evaluation on TREC data. 4. Query Expansion Using Monolingual SMT 4.1 Linear Models for SMT
The job of a translation system is defined in Och and Ney (2004) as finding the English string  X  e that is a translation of a foreign string f using a linear combination of feature functions h m ( e , f ) and weights  X  m as follows:
As is now standard in SMT, several complex features such as lexical translation models and phrase translation models, trained in source-target and target-source directions, are combined with language models and simple features such as phrase and word counts.
In the linear model formulation, SMT can be thought of as a general tool for computing string similarities or for string rewriting. 572 4.2 Word Alignment
The relationship of translation model and alignment model for source language string from source position j to target position a j :
The alignment a J 1 contains so-called null-word alignments a to the empty word.
 translation models used are based on a sequence of word alignment models, whereas in our case three Model-1 iterations and three HMM iterations were performed. Another important adjustment in our approach is the setting of the null-word alignment proba-bility to 0 . 9 in order to account for the difference in sentence length between queries and snippets. This setting improves alignment precision by filtering out noisy alignments and instead concentrating on alignments with high support in the training data. 4.3 Phrase Extraction
Statistical estimation of alignment models is done by maximum-likelihood estimation of sentence-aligned strings { ( f s , e s ): s = 1, ... , S by a hidden alignment variable a = a J 1 ,theoptimal  X   X  is found using unlabeled-data log-likelihood estimation techniques such as the EM algorithm:
The (Viterbi-)alignment  X  a J 1 that has the highest probability under a model is defined as follows:
Because a source X  X arget alignment does not allow a source word to be aligned with two or more target words, source X  X arget and target X  X ource alignments can be combined via various heuristics to improve both recall and precision of alignments.
 snippets. In order to achieve this, we symmetrize Viterbi alignments for source X  X arget and target X  X ource directions by intersection only. That is, given two Viterbi alignments
A fined as A = A 1  X  A 2 . Phrases are extracted as larger blocks of aligned words from the alignments in the intersection, as described in Och and Ney (2004). 4.4 Language Modeling
Language modeling in our approach deploys an n -gram language model that assigns the following probability to a string w L 1 of words:
Estimation of n -gram probabilities is done by counting relative frequencies of n -grams in a corpus of user queries. Remedies for sparse data problems are achieved by various smoothing techniques, as described in Brants et al. (2007).
 language model trained on queries. Although this approach may seem counterintuitive would be interpreted as a language model on the source language, in the linear model directionality of translation is not essential. Furthermore, the ultimate task of a query
SMT model that assigns the identity translation as most probable translation to each phrase. Descending the n -best list of translations, in effect the language model picks alternative non-identity translations for a phrase in context of identity-translations of the other phrases.
 non-identity translations of source phrases, the SMT model can effectively abstain from generating any expansion terms. This will happen if none of the candidate phrase assessed by the language model. 5. Evaluating Query Expansion in a Web Search Task 5.1 Data
The training data for the translation model and the correlation-based model consist of pairs of queries and snippets for clicked results taken from query logs. Representing documents by snippets makes it possible to create a parallel corpus that contains data of roughly the same  X  X entence X  length. Furthermore, this makes iterative training feasible.
Queries and snippets are linked via clicks on result pages, where a parallel sentence pair is introduced for each query and each snippet of its clicked results. This yields a data set of 3 billion query X  X nippet pairs from which a phrase-table of 700 million query X  X nippet phrase translations is extracted. A collection of data statistics for the training data is shown in Table 1. The language model used in our experiment is a trigram language frequency of 4. Data statistics for resulting unique n -grams are shown in Table 2. 574 5.2 Query Expansion Setup
The setup for our extrinsic evaluation deploys a real-world search engine, google.com, for a comparison of expansions from the SMT-based system, the correlation-based sys-tem, and the correlation-based system using the language model as additional filter. All expansion systems are trained on the same set of parallel training data. SMT modules source directions are combined in a uniform manner in order to give the SMT and correlation-based models the same initial conditions.
 systems. For each system, expansion terms were extracted from the 5-best rewrites, and stored in a table that maps source phrases to target phrases in the context of the full queries. For example, Table 3 shows unique 5-best translations of the SMT system for the queries herbs for chronic constipation and herbs for mexican cooking . Phrases that are newly introduced in the translations are highlighted in boldface . These phrases are extracted for expansion and stored in a table that maps source phrases to target phrases in the context of the query from which they were extracted. When applying the expansion table to the same 150,000 queries that were input to the translation, expansion phrases are included in the search query via an OR-operation. An example search query that uses the SMT-based expansions from Table 3 is shown in Figure 1.
 required the system to assign expansion terms to particular query terms. The best results were achieved by using a linear interpolation of scores in Equation (2) and Equation (1). query score calculated by Equation (2). Our reimplementation uses unigram and bigram phrases in queries and expansions. Furthermore, we use Okapi BM25 instead of tfidf in the calculation of Equation (1) (see Robertson, Walker, and Hancock-Beaulieu 1998). the query language model to rescore the rewrites produced by the correlation-based model. The intended effect is to filter correlation-based expansions by a more effective context model than the cohesion model proposed by Cui et al. (2002).
 underlying search engine, we can abstract away from interactions with the underlying system. Rewrite scores or translation probabilities were only used to create n -best lists for the respective systems; the ranking function of the underlying search engine was left untouched. 5.3 Experimental Evaluation
The evaluation was performed by three independent raters. The raters were presented with queries and 10-best search results from two systems, anonymized, and presented randomly on left or right sides. The raters X  task was to evaluate the results on a 7-point
Likert scale, defined as:  X  1.5: much worse  X  1.0: worse  X  0.5: slightly worse 0: about the same 0.5: slightly better 1.0: better 1.5: much better sult lists for both systems is randomly selected from the basic set of 150,000 queries.
The mean item score (averaged over queries and raters) for the experiment that com-pares the correlation-based model with language model filtering (corr+lm) against the correlation-based model (corr) shows a clear win for the experimental system. 576
An experiment that compares SMT-based expansion (SMT) against correlation-based expansions (corr) results in a clear preference for the SMT model. An experiment that compares the SMT-based expansions (SMT) against the correlation-based expansions filtered by the language model (corr+lm) shows a smaller, but still statistically signifi-cant, preference for the SMT model. Statistical significance of result differences has been computed with a paired t-test (Cohen 1995), yielding statistical significance at the 95% level for the first two columns in Table 4, and statistical significance at the 90% level for the last column in Table 4.
 The first five examples show the five biggest wins in terms of mean item score for the
SMT system over the correlation-based system. The second set of examples shows the five biggest losses of the SMT system compared to the correlation-based system. On inspection of the first set, we see that SMT-based expansions such as henry viii restaurant portland, maine ,or ladybug birthday ideas ,or top ten restaurants, vancouver , achieve a change in retrieval results that does not result in a query drift, but rather in improved retrieval results. The first and fifth result are wins for the SMT system because of non-sensical expansions by the baseline correlation-based system. A closer inspection of the second set of examples shows that the SMT-based expansion terms are all clearly related by reboot or restart which causes a demotion of the top result that matches the query exactly. In the second example, passport is replaced by the related term visa in the SMT-replacement of the specific term debian by the more general term linux . The correlation-based expansions how many tv 30 rock in the fourth example, and lampasas county sheriff home in the fifth example directly hit the title of relevant Web pages, while the SMT-based expansion terms do not improve retrieval results. However, even from these negative examples it becomes apparent that the SMT-based expansion terms are clearly contrast, the terms introduced by the correlation-based system are either only vaguely related or noise.
 for the comparison of the SMT model with the corr+lm model are listed. The wins for the SMT system are achieved by synonymous or closely related terms ( make-build, create; layouts -backgrounds; contractor -contractors ) or terms that properly disambiguate ambiguous query terms: For example, the term vet in the query dr. tim hammond, vet is expanded by the appropriate term veterinarian in the SMT-based expansion, whereas the correlation-based expansion to vets does not match the query context. The losses of the SMT-based system are due to terms that are only marginally related. Furthermore, the expansions of the correlation-based model are greatly improved by language model filtering. This can be seen more clearly in Table 7, which shows the five best and worst results from the comparison of correlation-based models with and without language model filtering. Here the wins by the filtered model are due to filtering non-sensical expansions or too general expansions by the unfiltered correlation-based model rather than promoting new useful expansions.
 pansions over correlation-based expansions to the fruitful combination of translation model and language model provided by the SMT system. The SMT approach can be viewed as a combined system that proposes already reasonable candidate expansions certain amount of non-sensical expansion candidates at the phrase translation level of the SMT system. However, a comparison with unfiltered correlation-based expansions quality, yielding overall better results after language model filtering. This can be seen 578 applicable to the queries herbs for chronic constipation and herbs for mexican cooking .The phrase tables include identity translations and closely related terms as most probable translations for nearly every phrase. However, they also clearly include noisy and non-related terms. Thus an extraction of expansion terms from the phrase table alone would not allow the choice of the appropriate term for the given query context. This can be attained by combining the phrase translations with a language model: As shown in
Table 3, the 5-best translations of the full queries attain a proper disambiguation of the senses of herbs by replacing the term with remedies , medicine ,and supplements for the first query, and with spices for the second query. Table 9 shows the top three correlation-based expansion terms assigned to unigrams and bigrams in the queries herbs for chronic constipation and herbs for mexican cooking . Expansion terms are chosen by overall highest weight and shown in boldface . Relevant expansion terms such as treatment list; however, the cohesion score promotes general terms such as interpret or com as best whole-query expansions. Although language model filtering greatly improves the quality of correlation-based expansions, overall the combination of phrase translations and language model produces better results than the combination of correlation-based expansions and language model. This is confirmed by the pairwise comparison of the
SMT and corr+lm systems shown in Table 4. 6. Conclusion
We presented a view of the term mismatch problem between queries and Web doc-get language of Web documents. We showed that a state-of-the-art SMT model can and showed improvements over state-of-the-art probabilistic query expansion. Our experimental evaluation showed firstly that state-of-the-art SMT is robust and flexible enough to capture the peculiarities of query X  X nippet translation, thus questioning the need for special-purpose models to control noisy translations as suggested by Lee et al. (2008). Furthermore, we showed that the combination of translation model and lan-guage model significantly outperforms the combination of correlation-based model and language model. We chose to take advantage of the access the google.com search engine to evaluate the query rewrite systems by query expansion embedded in a real-word search task. Although this conforms with recent appeals for more extrinsic evaluations (Belz 2009), it decreases the reproducability of the evaluation experiment. as query suggestions. Also, we hope that our successful application of SMT to query 580 expansion might serve as an example and perhaps open the doors for new applications and extrinsic evaluations of related NLP approaches such as paraphrasing.
 References
