
New applications of data mining, such as in biology, bioinformatics, or sociology, are faced with large datasets structured as graphs. We present an ef fi cient algorithm for mining associations between tree queries in a large graph. Tree queries are powerful tree-shaped patterns featuring ex-istential variables and data constants. Our algorithm ap-plies the theory of conjunctive database queries to make the generation of association rules ef fi cient. We propose a prac-tical, database-oriented implementation in SQL, and show that the approach works in practice through experiments on data about food webs, protein interactions, and citation analysis.
The problem of mining graph-structured data has re-ceived considerable attention in recent years, as it has ap-plications in such diverse areas as biology, the life sciences, the World Wide Web, or social sciences. At KDD 2005, we presented an ef fi cient algorithm for mining tree queries in a large graph [12], but we considered only a trivial form of associations between such queries. In the present paper, we present an ef fi cient algorithm to mine fully fl edged tree-query associations in a large graph.

Tree queries are powerful tree-shaped patterns, inspired by conjunctive database queries [28]. In comparison to most other graph mining approaches, tree queries have two powerful extra features in that they allow variables in the pattern to be existential or parameterized . Existential vari-ables must be matched in the graph just like any other variable, but their different matchings are not counted as contributing towards the overall frequency of the pattern. So, only the matchings of the non-existential variables are counted. Parameterized variables, on the other hand, can be matched only by one speci fi c data constant (node in the data graph).

By mining for tree-query associations we can discover quite subtle properties of the graph. Figure 1(a) shows a very simple example of an association that our algorithm might fi nd in a social network: a graph of persons where there is an edge x  X  y if x considers y to be a close friend. The tree query on the left matches all pairs ( x 1 ,x 2 ) of  X  X o-friends X : persons that are friends of a common person (rep-resented by an existential variable). The query on the right matches all co-friends x 1 of person #5 (represented by a parameterized variable), and pairs all those co-friends to 5. Now were the association from the left to the right to be discovered with a con fi dence of c , with 0  X  c  X  1 , then this would mean that the pairs retrieved by the right query actually constitute a fraction of c of all pairs retrieved by the left query, which indicates (for nonnegligible c ) that 5 plays a special role in the network. 1
Figure 1(b) shows quite a different, but again simple, ex-ample of a tree-query association that our algorithm might discover in a food web: a graph of organisms, where there is an edge x  X  y if y feeds on x . With con fi dence c , this association means that of all organisms that are not on top of the food chain (i.e., they are fed upon by some other or-ganism), a fraction of c is actually at least two down in the food chain.

The two examples we just saw are didactical examples, but in Section 11 we will see examples of associations mined in real-life datasets.

The three main features of our algorithm are the follow-ing. 1. As in classical association rules over itemsets [3], our
Figure 1. Simple examples of association rules over tree queries. 2. We apply the theory of conjunctive database queries 3. A fundamental notion in our approach is that of con-
The primary purpose of this paper is to present our al-gorithm. Concrete applications to discover new knowledge about scienti fi c datasets are the topic of planned future re-search. Yet, the algorithm is already fully implemented, and we can already show that our approach works in prac-tice, by showing some concrete results mined from a food web, a protein interactions graph, and a citation graph. We will also give performance results on random graphs (as a worst-case scenario) which show that the generation of as-sociations is very fast.
Approaches to graph mining, especially mining for fre-quent patterns or association rules, can be divided in two major categories which are not to be confused. In trans-actional graph mining, e.g., [8, 14, 15, 16, 19, 30, 31], the dataset consists of many small graphs which we call transactions, and the task is to discover patterns that oc-cur at least once in a suf fi cient number of transactions. (Approaches from machine learning or inductive logic pro-gramming usually call the small graphs  X  X xamples X  instead of transactions.) In contrast, in single-graph mining, e.g., [7, 11, 17, 20, 29], the dataset is a single large graph, and the task is to discover patterns that occur suf fi ciently often in the dataset. Our approach falls squarely within the single-graph category. Note that single-graph mining is more dif-fi cult than transactional mining, in the sense that transac-tional graph mining can be simulated by single-graph min-ing, but the converse is not obvious.

Within single-graph mining, not much previous work ex-ists on association rules. Jeh and Widom [17] consider pat-terns that are, like our tree queries, inspired by conjunctive database queries, and they also emphasize the tree-shaped case. A severe restriction, however, is that their patterns can be matched by single nodes only, rather than by tuples of nodes. Moreover, they mention association rules only in passing. Their work is still interesting in that it presents a rather nonstandard approach to graph mining, quite differ-ent from our own incremental, levelwise approach, and in that it incorporates ranking.
 The related work that was most in fl uential for us is Warmr [8, 9]. Based on inductive logic programming, pat-terns in Warmr also feature existential variables and param-eters. While not restricted to tree shapes, the queries in Warmr are restricted in another sense so that only trans-actional mining can be supported. Association rules in Warmr are de fi ned in a naive manner through pattern exten-sion, rather than being founded upon the theory of conjunc-tive query containment. The Warmr system is also Prolog-oriented, rather than database-oriented, which we believe is fundamental to mining of single large graphs, and which allows a more uniform and parallel treatment of parameter instantiations, as we will show in this paper. Finally, Warmr does not seriously attempt to avoid the generation of du-plicates. Yet, Warmr remains a pathbreaking work, which did not receive suf fi cient follow-up in the data mining com-munity at large. We hope our present work represents an improvement in this respect. Many of the improvements we make to Warmr were already envisaged (but without con-crete algorithms) in 2002 by Goethals and the second author [13].

Finally, we note that parameterized conjunctive database queries have been used in data mining quite early, e.g., [27, 26], but then in the setting of  X  X ata mining query lan-guages X , where a single such query serves to specify a fam-ily of patterns to be mined or queried for, rather than the mining for such queries themselves, let alone associations among them.
In this section we de fi ne the problem formally. We basi-cally assume a set U of data constants from which the nodes of the graph to be mined will be taken. Graphs are always directed, so basically, for the purposes of the present paper, a graph is simply a fi nite set of ordered pairs of elements from U . We assume familiarity with the notion of a tree as a special kind of graph, and with standard graph-theoretic concepts as supplied by any algorithms textbook.
 Tree Patterns A tree pattern P is a tree whose nodes are called variables , and where additionally:  X  Some variables may be marked as being existential ;  X  Some other variables may be marked as parameters ;  X  The variables of P that are neither existential nor pa-We will denote the set of existential variables by  X  , and the set of parameters by  X  . To make clear that these sets belong to some tree pattern P we will use a subscript as in  X  P or  X 
A parameter assignment  X  , for a tree pattern P , is a map-ping  X   X  U which assigns data constants to the parame-ters.

An instantiated tree pattern is a pair ( P,  X  ) , with P a tree pattern and  X  a parameter assignment for P . We will also denote this by P  X  .

When depicting tree patterns, existential nodes are indi-cated by labeling them with the symbol  X   X   X  and parameters are indicated by labeling them with the symbol  X   X   X . When depicting instantiated tree patterns, parameters are indicated by directly writing down their parameter assignment.
Figure 2 shows an illustration.
Figure 2. (a) is a tree pattern, and (b) is an instantiation of (a).
 Matching Recall that a homomorphism from a graph G 1 to a graph G 2 is a mapping f from the nodes of G 1 to the nodes of G 2 that preserves edges, i.e., if ( i, j )  X  G 1 ( f ( i ) ,f ( j ))  X  G 2 .Wenowde fi ne a matching of an instan-tiated tree pattern P  X  in a graph G as a homomorphism f from the underlying tree of P to G , with the constraint that for any parameter  X  ,if  X  (  X  )= a , then f (  X  ) must be the node a .
 Frequency of a tree pattern The frequency of an instan-tiated tree pattern P  X  in a graph G ,isde fi ned as the number of matchings of P  X  in G , where we identify any two match-ings that agree on the distinguished variables. Foragiven threshold k (a natural number) we say that P  X  is k -frequent if its frequency is at least k . Often the threshold is under-stood implicitly, and then we talk simply about  X  X requent X  patterns and denote the threshold by minsup .
 Tree Queries A tree query Q is a pair ( H, P ) where: 1. P is a tree pattern, called the body of Q ; 2. H is a tuple of distinguished variables and parameters
A parameter assignment for Q is simply a parameter as-signment for its body, and an instantiated tree query is then again a pair ( Q,  X  ) with Q a tree query and  X  a parameter assignment for Q . We will again also denote this by Q  X  .
When depicting tree queries, the head is given above a horizontal line, and the body below it. Two illustrations are given in Figure 3.
 Containment of tree queries The fi nal step towards our formal de fi nition of tree-query association is the notion of containment among queries.

First, we de fi ne the answer set of an instantiated tree query Q  X  , with Q =( H, P ) , in a graph G as follows:
Figure 3. Simple examples of instantiated tree queries. Query (b) is contained in query (a) We then say that an instantiated tree query Q  X  2 2 is contained in an instantiated tree query Q  X  1 1 ,if Q  X  2 2 ( G )  X  for all graphs G . In shorthand notation we write this as Q
Containment as just de fi ned is a semantical property, referring to all possible graphs, and it is not immediately clear how one could decide this property syntactically. The required syntactical notion for this is that of containment mapping , which we next de fi ne in several steps. Con-sider again two instantiated tree queries Q  X  1 1 and Q  X  Q i =( H i ,P i ) for i =1 , 2 . 1. A containment mapping from P 1 to P 2 is a homomor-2. A containment mapping from P  X  1 1 to P  X  2 2 is a con-3. Finally, a containment mapping from Q  X  1 1 to Q  X  2 2
A classical result [5, 28, 2] now states that Q  X  2 2 is con-tained in Q  X  1 1 precisely when there exists a containment mapping from Q  X  1 1 to Q  X  2 2 . Checking for a containment mapping is evidently computable, and although the problem for general database conjunctive queries is NP-complete, our restriction to tree shapes allows for ef fi cient checking, as we will see later.
 Example. Consider the instantiated tree queries shown in Figure 3. In the example graph shown in Figure 4(a), the frequency of query (a) is 10 and that of query (b) is 2. A moment X  X  re fl ection should convince the reader that (b) is contained in (a), and indeed a containment mapping from (a) to (b) can be found as follows: 0  X  0 ; x 1  X  x ; x 2  X  1  X  X  X  ;  X  2  X  X  X  ; 8  X  8 ; x 3  X  6 . For a good understand-ing, note that were we to change the head of (b) to ( x, x, 8) , then this new query (b) would still be contained in (a), be-cause we can alternatively map x 3  X  8 and still have a containment mapping from the body of (a) to the body of (b).
 Association Rules A potential association rule (AR) is of the form Q  X  1 1  X  Q  X  2 2 , with Q  X  1 1 and Q  X  2 2 instantiated tree queries. The AR is legal if Q  X  2 2  X  Q  X  1 1 . We call Q left-hand side (lhs), and Q  X  2 2 the right-hand side (rhs).
The con fi dence of the AR in a graph G is de fi ned as the frequency of the rhs in G , divided by the frequency of the lhs in G . If the AR is legal, we know that the answer set of the rhs is a subset of the answer set of the lhs, and hence the con fi dence equals precisely the proportion that the rhs answer set takes up in the lhs answer set. Thus, our notion of legal AR and con fi dence is very intuitive and natural.
For a given threshold c (a rational number, 0  X  c  X  1 ) we say that the AR is c -con fi dent in G if its con fi dence in G is at least c . Often the threshold is understood implicitly, and then we talk simply about  X  X on fi dent X  ARs and denote the threshold by minconf .

Furthermore, the AR is called frequent in G if the body of the rhs is frequent in G . Note that if the AR is legal and frequent, then also the body of the lhs is frequent, since the rhs is contained in the lhs.
 Example. Continuing the previous example, we can see that we can form a legal AR from the queries of Figure 3, with (a) the lhs and (b) the rhs. The con fi dence of this AR in the graph of Figure 4(a) is 2 / 10 . Many more examples of ARs are given in the next Section.
 Association Rule Mining We are fi nally ready to formu-late the problem we want to solve: Input: A graph G ; a threshold minsup ; an instantiated tree Output: All instantiated tree queries Q  X  such that
In theory, however, there are in fi nitely many legal and con fi dent association rules for a fi xed lhs, and even if we set an upper bound on the size of the rhs, there may be ex-ponentially many. Hence, in practice, we want an algorithm that runs incrementally, and that can be stopped any time it has run long enough or has produced enough results.
In this section, we show that it is not necessary to attack the problem in its full generality. We will show that, without loss of generality, we can focus on the case where the given lhs query Q left is  X  X ure X  in a sense that we will make precise. We will also show that this restriction cannot be imposed on the rhs queries to be output. We also make a remark regarding  X  X ree constants X  in the head of a query. Pure tree queries To de fi ne this formally, assume that all possible variables (nodes of tree patterns) have been ar-ranged in some arbitrary but fi xed order. We then call a tree query Q =( H, P ) pure when H consists of the enu-meration, in order and without repetitions, of all the dis-tinguished variables of P . In particular, H cannot contain parameters. As an illustration, the lhs of rule (a) of Figure 3 is impure, while the lhs of rule (b) is pure.

An AR with an impure lhs can always be rewritten to an equivalent AR with a pure lhs, with the same con fi dence and frequency. Indeed, take a legal AR Q  X  1 1  X  Q  X  2 2 , with Q not pure. We know that Q 1  X  X  head is mapped to Q 2  X  X  head by some containment mapping. Hence, we can purify Q 1 by removing all constants and repetitions of distinguished variables from Q 1  X  X  head, sort the head by the order on the variables, and perform the corresponding actions on Q 2  X  X  head as prescribed by the containment mapping. An illus-tration is given in Figure 5.

We can conclude that it is suf fi cient to only consider ARs with pure lhs X  X . The rhs, however, need not be pure; impure rhs X  X  are in fact interesting, as we will demonstrate next.
Figure 5. Rule (a) has a non-pure lhs. Rule (b) is the puri fi cation of rule (a), and expresses precisely the same information.
Figure 6. (a) and (b) are ARs with impure rhs. (c) is an ill-advised attempt to purify (b) on the rhs. Impure rhs X  X  Consider the AR in Figure 6(a). The rhs is impure since x 2 appears twice in the head. The AR ex-presses that a suf fi cient proportion of the matchings of the lhs pattern, are also matchings of the rhs pattern, which is the same as the lhs pattern except that x 2 is equal to x The con fi dence of this AR is m/ x deg 2 x , where m is the number of edges, x ranges over the nodes in the graph, and deg x is the outdegree of (number of edges leaving) x . Since m = x deg x , an easy calculation shows that this con fi dence is much larger than 1 /m . Hence, the sparser the graph (with the number of nodes remaining the same), the higher the con fi dence, and thus the AR is interesting in that it tells us something about the sparsity of the graph. As an illustration, on the graph of Figure 4(a) the con fi dence is 0 . 4 , but on the the graph of Figure 4(b), it is 0 . 6 .
Also consider the AR in Figure 6(b). Again the rhs is impure since its head contains a parameter. With con fi dence c , the AR expresses that a fraction of c of all edges point to node 8, which again would be an interesting property of the graph.
 The knowledge expressed by the above two example ARs cannot be expressed using ARs with pure rhs X  X . To illustrate, the AR of Figure 6(c) may at fi rst seem equiva-lent (and has a pure rhs) to that of Figure 6(b). On second thought, however, it says nothing about the proportion of edges pointing to 8, but only about the proportion of nodes with an edge to 8.

Of course, we are not implying that ARs with pure rhs X  X  are uninteresting. But all they can express are statements about the proportion of matchings of the lhs that can be specialized or extended to a matching of the rhs (another example is in Figure 7, which says something about the proportion of edges that can be extended); they cannot say anything about the proportion of matchings of the lhs that satisfy certain equalities in the distinguished variables. Free Constants Most treatments of conjunctive database queries [2, 28] allow arbitrary constants in the head. In our treatment, a constant can only appear in the head as the value of a parameter. This restriction is justi fi ed, since we can show that for the sake of legal association rules among conjunctive queries, constants appearing in the head but not in the body do not buy us anything. We defer the easy argu-ment (based on the existence of a containment mapping) to the full paper. minconf and minsup , an outline of our algorithm for the association rule mining problem is that of four nested loops: 1. Generate, incrementally, all possible trees of increas-2. For each new generated tree T , generate all frequent 3. For each tree pattern P , generate all containment map-4. For each f , generate all instantiated tree queries Q  X 
This approach is complete, i.e., it will output everything that must be output. In proof, consider a legal, frequent and con fi dent AR Q  X  left left  X  Q  X  , with Q =( H Q ,P Q ) . The tree T is the underlying tree of P Q ; the tree pattern P in loop 2 is P
Q ; the containment mapping f in loop 3 is a containment mapping from Q  X  left left to Q  X  ; and  X  in loop 4 is  X  .
As to loop 1, it is already well known how to ef fi ciently generate all trees uniquely up to isomorphism, in increasing number of nodes [6, 21, 25, 31]. We present loops 2 , 3 and 4 in detail in Sections 6, 7 and 8.

The reader may wonder whether loop 3 cannot be or-ganized in a levelwise fashion as well as loop 2. This is not obvious, however, since any two queries of the form same frequency, namely that of P  X  . Loop 4, however, is levelwise because it is based on loop 2 which is levelwise.
In Section 9, we will show how our overall approach must be re fi ned so that the generation of equivalent asso-ciation rules is avoided.
Loop 2 of our algorithm, the generation of all frequent instantiated tree patterns P  X  based on a fi xed tree, in a lev-elwise fashion, has already been solved in our earlier work [12]. We recall here the details that are needed further on.
The levelwise search is based on a natural specialization relation that is suggested by an alternative notation for the instantiated tree patterns under consideration. Concretely, since the underlying tree is fi xed, any tree pattern is char-acterized by two parameters: the set  X  of existential nodes, and the set  X  of parameters. Thus, an instantiated tree pat-tern P  X  , with P =( X  ,  X ) is completely characterized by the triple ( X  ,  X  , X  ) .

We now say that P  X  1 1 =( X  1 ,  X  1 , X  1 ) specializes P  X  ( X  2 ,  X  2 , X  2 ) if  X  1  X   X  2 ;  X  1  X   X  2 ; and  X  1 agrees with  X  on  X  2 . We also say that P  X  2 2 generalizes P  X  1 1 .
Clearly, if P  X  1 1 specializes P  X  2 2 , then the frequency of P  X  1 1 is at most that of P  X  2 2 . Furthermore if Q (( H 1 ,P 1 ) , X  1 ) and Q  X  2 2 =(( H 2 ,P 2 ) , X  2 ) are instanti-ated tree queries such that AR1: Q  X  left left  X  Q  X  1 1 and AR2: Q will be at most that of AR 2 . So we can use this relation to guide a levelwise search for the frequent and con fi dent association rules.

Our algorithm outputs the frequent patterns in the form of frequency tables , which are de fi ned as follows:
FreqTab  X  ,  X  = { (  X , k ) | ( X  ,  X  , X  ) is frequent So, a frequency table FreqTab  X  ,  X  contains all parameter as-signments  X  for which P  X  , with P =( X  ,  X ) , is a frequent instantiated tree pattern.

Technically, the table has columns for the different pa-rameters, plus a column freq . Note that when  X =  X  , i.e., P has no parameters, this is a single-column, single-row table containing just the frequency of P . Of course in prac-tice, all frequency tables for parameterless patterns can be combined into a single table. All frequency tables are kept in a relational database.
In this section, we discuss loop 3 , the generation of all containment mappings from P left to P . So, we need to solve the following problem: Given two tree patterns P 1 and P 2 fi nd all containment mappings from P 1 to P 2 .

Since the patterns are typically small, a naive algorithm suf fi ces. For a node x 1 of P 1 and a node x 2 of P 2 ,we say that x 1  X  X atches X  x 2 if there is a containment mapping f from the subtree pattern of P 1 rooted at x 1 to the sub-tree pattern of P 2 rooted at x 2 such that f ( x 1 )= x 2 a fi rst phase, we determine for every node y of P 2 sepa-rately whether the root r of P 1 matches y . While doing so, we also determine for every other node x 1 of P 1 , and ev-ery node x 2 below y at the same distance as x 1 is from r , whether x 1 matches x 2 . We store all these boolean values in a two-dimensional matrix.

This fi rst phase compares every possible pair ( x 1 ,x 2 with x 1 a node in P 1 and x 2 a node in P 2 , at most once. Indeed, if x 1 is at distance d from r , then x 1 will be com-pared to x 2 only during the matching of r with the node y that is d steps above x 2 in P 2 (if existing). We thus have an O ( n 1  X  n 2 ) algorithm, where n 1 ( n 2 ) is the number of nodes in P 1 ( P 2 ).
 In a second phase, we output all containment mappings. Initially, by a synchronous preorder traversal of P 1 and P we map each node of P 1 to the fi rst matching node of P 2 In each subsequent step, we look for the last node x 1 (in preorder) of P 1 , currently matched to some node x 2 , with the property that x 1 can also be matched to a right sibling x of x 2 , and now map x 1 to the fi rst such x 3 . The mappings of all nodes of P 1 coming after x 1 are reinitialized. Every such step takes time that is linear in n 1 and independent of n . Of course, the total number of different containment mappings may well be exponential in n 1 .

We can thus easily generate all containment mappings f from P left to P as required for loop 3 of our overall al-gorithm. Note, however, that in loop 4 these mappings are used to produce the head f ( H left ) of query Q .For Q to be a legal query, this head must contain all distinguished vari-ables of P . Hence, we only pass to loop 4 those f whose image contains all distinguished variables of P .
In loop 4 , our task is the following. Given a contain-ment mapping f : P left  X  P , generate all instantiated tree queries Q  X  =(( f ( H left ) ,P ) , X  ) such that f : Q  X  left respects the parameter assignments; Q  X  is frequent; and the con fi dence of Q  X  left left  X  Q  X  exceeds minconf .
Since Q =( f ( H left ) ,P ) is determined, the only problem is to generate the parameter assignments,  X  . This happens in a parallel database-oriented fashion.

Indeed, recall from Section 6 that the frequency tables for P left and P are available in a relational database. Our crucial observation is that we can compute precisely the re-quired set of parameter assignments  X  , together with the frequency and con fi dence of the corresponding association rules, by a single relational algebra expression. 3 This ex-pression has the following form:  X  Here,  X  denotes projection,  X  denotes selection, and de-notes join. The join condition  X  , the selection condition  X  and the projection list plist are de fi ned as follows. Let  X  be the set of parameters of P left . Then  X  is the conjunction: The selection condition  X  left is de fi ned as the conjunction: Furthermore, plist consists of all attributes P. X  , with  X   X   X  , together with the attributes FreqTab P . freq and FreqTab P . freq / FreqTab P
Referring back to our overall algorithm (Section 5), we thus generate, for each pattern P generated in loop 2 and each containment mapping f in loop 3 , all association rules with the given Q  X  left left as lhs in parallel, by one relational database query (which can be implemented by a simple SQL select-statement).

Moreover, we now see that we not actually have to limit ourselves to one given instantiation  X  left of Q left ! Indeed, simply by omitting the selection  X   X  by adding the parameters of P left to the projection list, we obtain in parallel all legal and con fi dent association rules for all possible instantiations of Q left as lhs. Example. Consider Q left and P as shown in Figures 8(a) and Figure 8(b). We have  X  left = { x 1 ,x 4 } and  X  left = { and  X  P = { x 1 ,x 4 ,x 5 } and  X  P = { x 3 } . Take the fol-lowing containment mapping f from P left to P : x 1  X  x 1 x x 7  X  x 4 . Then the rhs query Q equals (( x 2 ,x 2 , X  4 ) ,P ) , and the relational algebra expression for computing all pa-rameter assignments  X  for all instantiations  X  left of Q left looks as follows:  X  with plist equal to and  X  equal to
FreqTab P .x 1 = FreqTab P In SQL, we get:
In this section, we make a number of modi fi cations to the algorithm described so far, so as to avoid duplicate work on equivalent queries.

From our previous work [12] we already know how to make sure that the tree patterns that are generated in loop 2 of the overall approach (Section 5) are never equiv-alent to a previously generated one. Thus, we can focus on ARs AR1: Q left  X  Q 1 and AR2: Q left  X  Q 2 , with Q 1 =( f 1 ( H left ) ,P ) and Q 2 =( f 2 ( H left ) ,P ) and f f 2 containment mappings from P left to P , and we want to know when these two ARs are equivalent.

A tricky example of two ARs that convey precisely the same information and should thus be considered equivalent, is shown in Figure 9. We formalize equivalence as fol-lows: the structures ( P left ,P,f 1 ) and ( P left ,P,f 2 morphic. Speci fi cally, there must exist isomorphisms (ac-tually automorphisms) g : P left  X  P left and h : P  X  P such that f 2  X  g = h  X  f 1 . In the fi gure, where f 1 (for (a)) and f 2 (for (b)) can be read out from the heads of the rhs X  X , h swaps x 2 and x 3 , and g is the cyclic permutation x
So, using graph isomorphism (to be precise, edge-colored graph isomorphism, where we use different colors for the edges in P left , the edges in P , and the pairs in f or f 2 ), we can test for equivalence. Since our patterns are not very large, fast heuristics for graph isomorphism can be used [23]. This works well in practice, but theoretically this situation is not entirely satisfying, as graph isomorphism is not known to be ef fi ciently (polynomial-time) solvable in general. By a reduction from the isomorphism problem for bipartite graphs, we can actually show that isomorphism of our structures is really as hard as the general graph isomor-phism problem (proof deferred to the full paper). But as we show next, we can still capture an important special case in polynomial time, so that the general graph isomorphism heuristics only have to be applied on instances not captured by the special case.

The special ef fi cient case is to check whether ( P left ,P,f 1 ) and ( P left ,P,f 2 ) are already isomorphic with g the identity, i.e., whether the structures ( P, f 1 ) and ( P, f are already isomorphic. So, we look for an automorphism h of P such that f 2 = h  X  f 1 . This can be solved ef fi ciently by a reduction to node-labeled tree isomorphism. As ex-plained in Section 6, if we know the tree T underlying P , then P is characterized by the pair ( X  ,  X ) , and thus ( P, f ) is characterized by ( X  ,  X  ,f ) . We can view this triple as a labeling of T , as follows. We label every node y of P with a triple ( b  X  ,b  X  ,f  X  1 ( y )) , where b  X  is a bit that is 1 iff y b
 X  is a bit that is de fi ned likewise; and f  X  1 ( y ) is the set of nodes of P left that are mapped by f to y . Then ( P, f and ( P, f 2 ) are isomorphic if and only if the correspond-ing node-labeled trees are isomorphic, and the latter can be checked in linear time using canonical ordering [4, 6].
We are now in a position to describe how our general algorithm must be modi fi ed to avoid equivalent association rules. There is only extra checking to be done in loop 3. For each new containment mapping f from P left to P , we canon-ize the corresponding node-labeled tree and we check if the canonical form is identical to an earlier generated canonical form; if so, f is dismissed. We can keep track of the canon-ical forms seen so far ef fi ciently using a trie data structure. If the canonical form was not yet seen, we can either let f through to loop 4, if the presence of duplicates in the output is tolerable for the application at hand, or we can default to an edge-colored graph isomorphism check with the con-tainment mappings previously seen, to be absolutely sure we will not generate a duplicate.
As already explained in Section 6, in loop 2 we build up a structured database containing all frequency tables for all trees generated in loop 1. These two fi rst loops should be re-garding as a preprocessing step; once built up, the database is an ideal platform for an interactive tool by which the user can repeatedly specify lhs X  X , after which the tool only needs to run loops 3 and 4 to produce rhs X  X  that form an associa-tion with the given lhs.

In a typical usage scenario, the user draws a tree shape, marks some nodes as existential, marks some others as pa-rameters, instantiates some parameters by constants, but possibly also leaves some parameters open. The browser then returns, by consulting the appropriate frequency ta-ble in the database, all instantiations of the parameters that make the pattern frequent, together with the frequency. The user can then select one of these instantiations, set a min-conf value, and ask the browser to return all rhs X  X  that form a con fi dent association with the selected pure tree query as lhs. Also, instead of letting the browser return all associ-ation rules, the user can already suggest a rhs by drawing a tree shape, possibly with some nodes already marked as parameter or existential, and let the browser return all rhs X  X  of the prescribed form.

The preprocessing step, i.e., the building up of the database with frequent patterns, is of course a hugely inten-sive task, fi rst because the large data graph must be accessed intensively, and second because the number of frequent patterns is huge. Nevertheless, in our previous work [12] we already presented detailed experimental results showing that this can be implemented with satisfactory performance. Also, in scienti fi c discovery applications it is no problem, indeed typical, if a preprocessing step takes a few hours, as long as after that the interactive exploration of association rules can happen very fast.

And indeed, we found the actual generation of associa-tion rules (i.e., loops 3 and 4) to be very fast. For instance, Figure 10 shows the performance of generating association rules for two different (absolute) values of minconf, against a frequency table database built up for a random graph with 33 nodes and 113 edges, an absolute minsup of 25, and all trees up to size 7. We see that associations are gener-ated with constant overhead, i.e., in linear-output time. The coef fi cient is larger for the larger minconf, because in this experiment we have counted instantiated rhs X  X , and per rhs query less instantiations satisfy the con fi dence threshold for larger such thresholds. Had we simply counted rhs X  X  regard-less of the number of con fi dent instantiations, the two lines would have had the same slope.

The experiments were performed on a Pentium IV (3.6GHz) architecture with 2GB of internal memory, run-ning under Linux 2.6. The program was written in C++ with embedded SQL, with DB2 UDB 8.2 as the relational database system.
While the application of our algorithm to serious scien-ti fi c data mining is planned future work, in this section, we still report on some preliminary experiments performed us-
Figure 10. Performance in terms of number of discovered rules. ing our prototype implementation applied to a food web, a protein interactions graph, and a citation graph. These re-sults show that our approach is workable.

For each dataset we built up a frequency table database using the following parameters: food web 154 370 100 6 proteins 2114 4480 100 5 citations 2500 350000 100 4
The food web [24] comprises 154 organisms that live on the Scotch Broom (a common kind of shrub). Here are two associations we discovered: Since 45% + 55% = 100% , these rules together say that each path of length 5 either starts in 0 , or one beneath 0 . This tells us that the depth of the food web equals 6. Con-stant 0 turns out to denote the Scotch Broom itself, which is the root of the food web.

Another rule we mined, just to give a rather arbitrary example of the kind of rules we fi nd with our algorithm, is the following:
The protein interactions graph [18] comprises molecu-lar interactions (symmetric) among 1870 proteins occurring in the yeast Saccharomyces cervisae . We found the follow-ing rule: This rule expresses that almost all interactions that link to protein 746 also link to protein 376, which unveils a close relationship between these two proteins.

The citation graph comes from the KDD cup 2003, and contains around 2500 papers about high-energy physics taken from arXiv.org, with around 350 000 citations among these papers. One of the discovered rules is the following: This rule shows that paper 9503124 is an important paper. In 15% of all  X  X on-trivial X  citations (meaning that the citing paper cites at least one paper that also cites a paper), the cited paper cites 9503124.
 We thank Bart Goethals, Jan Hidders, and Dries Van Dyck for fruitful discussions.

