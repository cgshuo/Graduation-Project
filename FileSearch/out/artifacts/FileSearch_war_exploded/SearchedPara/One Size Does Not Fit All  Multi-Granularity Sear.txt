 Users rely increasingly on online forums, blogs, and mailing lists to exchange information, practical tips, and stories. Although this type of social interaction has become central to our daily lives and decision-making processes, forums are surprisingly technolog-ically poor: often there is no choice but to browse through massive numbers of posts while looking for speci fi c information. A crit-ical challenge then for forum search is to provide results that are as complete as possible and that do not miss some relevant infor-mation but that are not too broad. In this paper, we address the problem of presenting textual search results in a concise manner to answer user needs. Speci fi cally, we propose a new search approach over free-form text in forums that allows for the search results to be returned at varying granularity levels. We implement a novel hi-erarchical representation and scoring technique for objects at mul-tiple granularities, taking into account the inherent containment re-lationship provided by the hierarchy. We also present a score op-timization algorithm that ef fi ciently chooses the best k set while ensuring no overlap between the results. We evaluate the effectiveness of multi-granularity search by conducting extensive user studies and show that a mixed granularity set of results is more relevant to users than standard post-only approaches.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search process, Information fi ltering Multi-granular search, online forums, hierarchical scoring
Users have wholeheartedly integrated web forums as a mean of communication and information exchange. A common approach to gather feedback on a product, disease, or technical problem is to ask a question on an Internet forum and await answers from other participants. Alternatively, one can search through information in forums which often is already present as part of earlier discussions.
Unfortunately, web forums typically offer only very primitive search interfaces that return all posts that match the query key-word. Because of the nature of keyword-based search, short posts containing the query keywords may be ranked high even if they do not have much useful information, while longer posts with rel-evant information could be pushed down in the result list because their normalized scores are penalized by their size. When issuing queries to forums, users face the daunting task of sifting through a massive number of posts to separate the wheat from the chaff.
As a new search problem, search over forum text yields interest-ing challenges. Background information is often omitted in posts as it is assumed that readers share the same background knowledge [9]. A critical challenge then for web forums search is to provide results that are as complete as possible and that do not miss some relevant information but that are also focused on the part of indi-vidual threads or posts containing relevant text. Therefore, in this type of search the correct level of result granularity is important.
Consider the results in Table 1 retrieved in response to the user query hair loss in a breast cancer patient forum. Several succinct sentences (A) through (H), shown in boldface, are highly relevant to the query and provide very useful answers. Yet, when a post contains many relevant sentences as in Post1 and Post2, the post is a better result than the sentences alone. Dynamically selecting the best level of focus on the data helps users fi nd relevant answers without having to read large amounts of irrelevant text. Therefore, our goal is to improve the experience of users searching through web forums by providing results that focus on the parts of the data that best fi t their information needs. Our approach allows for search results to be returned at varying granularity levels: single pertinent sentences containing facts, larger passages of descriptive text, or entire discussions relevant to the search topics. In this paper, we focus our analysis on a patient forum, breastcancer.org ,al-though our techniques can be ported to any domain. Our example forum provides very basic search capabilities: keywords are used for fi ltering posts which are presented chronologically.
We propose a novel multi-granularity search for web forum data to offer the most relevant information snippets to a user query. In particular, we make the following contributions:  X  We propose a hierarchical model to represent forum data and present a recursive scoring function over the hierarchy (Section 2) which allows us to rank textual objects of varying sizes while taking into account their inherent containment relationships.  X  We present a novel score optimization algorithm that ef fi ciently chooses the best k -sized result set while ensuring no overlap be-tween the results (Section 3) and show that our optimization al-gorithm is highly ef fi cient in Section 5.  X  We study the usefulness of the multi granularity results by con-ducting user studies to evaluate their relevance (Section 5). We show that a mixed granularity set of results is more relevant than results containing only posts, as is the current standard.
The paper is structured as follows. We discuss our hierarchi-cal data model in Section 2, and describe our novel scoring over the multi-granularity hierarchy. We present an ef fi cient algorithm to compute the optimal scored non-overlapping result set over the multi-granular objects in Section 3. In Section 4, we describe our forum dataset. We assess the retrieval effectiveness and relevance of results generated by our multi-granularity search in Section 5, and demonstrate the ef fi ciency of our score optimization algorithm. We present related work in Section 6 and conclude in Section 7.
This work was performed as part of the PERSEUS (Patient Emo-tion and stRucture Search USer interface) project, which aims at helping both patients and health professionals access online patient-authored information by creating tools to process and enhance the textual data in patient forums.
Forum data has an intrinsic hierarchy; usually there are a few broad topics containing several threads on each topic, and each thread contains many posts written by different authors. Effec-tively searching through forums requires navigating through the hi-erarchical structure of the multi-level textual objects. We use the natural hierarchy to model forum data, with lower levels contain-ing smaller textual snippets (Section 2.1). We then design a uni fi ed scoring over objects at all granularity levels (Section 2.2).
A natural way to look at information in web forums is to break down the pieces of information into the structural components: each thread represents a discussion where users interact through individ-ual posts which each contain several sentences .Weusethesethree levels of information as the searchable objects in our system.
Figure 1 shows an example hierarchy over 12 searchable objects: 6 sentences and 4 posts contained in 2 threads. This representation models the containment relationship between the different object levels, while also representing the strength of the association be-tween parent-child nodes. The leaf nodes contain the keywords in user queries, and larger objects are at higher levels. The edges rep-resent containment indicating that the textual content of the child occurs completely in the text of the parent. The edge weight is equal to the number of times a child occurs in the entire text of the parent, i.e., the edge weight represents the association strength between the parent and the child. The default edge weight is 1 , a few instances of edge weight 2 are shown in Figure 1 where a word repeats in the sentence, or rarely a sentence like  X  X hanks. X  occurs two times in the same post. Note that other granularity of objects could also be considered: paragraphs within posts, groups of threads on the same topics, or groups of posts by an author.
The hierarchical model for forum data allows us to effectively store, access and score the objects at multiple levels by providing ef fi cient access to the parents and children of a node. We now use this data hierarchy to develop a uni fi ed scoring function.
Our search system enables users to retrieve results at different levels of granularity: sentences, posts and threads. A challenge of the search is to provide a scoring methodology that assigns com-parable scores across all levels of objects and that incorporates the containment between objects. In this section, we fi rst outline the shortcomings of traditional IR scoring for evaluating multi-granularity objects. We then design a novel scoring function that recursively computes scores for the nodes in our data hierarchy.
The popular tf*idf scoring increases proportional to the frequency of a term in the document, but is offset by the number of documents containing the term. In a multi-granularity system, the documents would include sentences, posts and threads. Suppose a search term occurs only in one sentence in a thread. A basic tf*idf scoring will assign the same score to the sentence as the post and thread con-taining the sentence. This is not ideal as users will have to read the entire thread to fi nd the single relevant sentence.

A common variation of the tf*idf scoring is to weight the score of an object with the character length [18], as shown below: where the search term is t , the document is d , N is the total num-ber of documents, tf t,d is the frequency of t in d and df number of documents containing t . Equation 1 correctly assigns higher scores to smaller objects, all other aspects kept equal. How-ever, consider a typical thread with two orders of magnitude bigger CLength than a sentence. For  X  =0 . 5 the thread is penalized by an order of magnitude more than the sentence. If the sentence has tf = m , for the thread to have a comparable score it needs to have score objects at multiple levels in a comparable manner.
Another popular IR scoring is Okapi BM25 [18] which has two parameters: b ( 0  X  b  X  1 ) controls the scaling by document length and k 1 controls the effect of the term frequency. With the ideal parameter selection (for instance, making the impact of size negli-gible), the tf*idf and BM25 scoring methods could be tweaked to assign comparable scores to sentences, posts and threads in our cor-pus. However, these existing methods score textual objects in iso-lation and ignore the containment relationship amongst the multi-granular objects. A post containing many relevant sentences should have a higher score than the individual sentences, presumably the overall post is more coherent and meaningful. Yet, if all the rele-vant information is in a single sentence then the parent post must have a lower overall score. Such containment dependencies are not captured by these existing scoring functions.

Consider the performance of the tf*idf and BM25 scoringonthe objects in Table 1. We also compare our novel HScore scoring, de-scribed in the following section. For the query hair loss , all three scoring functions score and rank the 3 posts and 8 sentences (A) through (H). Post1 and Post2 are highly relevant posts containing many relevant sentences (A) through (F). These posts are more use-ful for the search task than the sentences alone. Post3 contains a large amount of irrelevant text. Answering the query with the sen-tences (G) and (H) by themselves saves user time in reading the irrelevant text in the larger Post3. The top-4 ranked results gener-ated by the tf*idf and HScore functions (size parameter  X  =0 . 3 and BM25 (typical parameters b =0 . 75 , k 1=1 . 2 )areshownin Table 1. The ranking reveals that both the existing tf*idf and BM25 functions favor small sized objects and retrieve top-4 results only at the sentence granularity ( BM25 favors sentences with smallest length, while tf*idf picks sentences with highest tf ). These scor-ing functions rank sentences (A) through (E) higher than the more meaningful Post1 and Post2. Thus, Table 1 shows the failure of the existing scoring functions in generating a mixed granularity result set. In contrast, HScore correctly assigns a higher rank to Post1 and Post2, and correctly selects the sentences (G) and (H) in the top-4 results instead of Post3. Moreover, the only scoring that yields mixed granularity objects is HScore , described in the next section.
We use the ideas motivating IR scoring and our hierarchical data model to design a scoring function over the largely varying sized objects in our search system. Our scoring methodology operates in a bottom-up fashion: fi rst keywords at the leaf level are scored and the scores are built incrementally up the hierarchy. The hierarchy allows scoring every object using only its parent and children rela-tions, thereby treating different levels in a comparable manner. Our hierarchical scoring is built on the following intuitions:  X  Score of a node is proportional to the score of its children.  X  A node having several children or a large sized node, should have its score decreased proportionally to its size.  X  If the association between parent and child is strong, as learned from the edge weights, then this child contributes strongly to the overall score of the parent. This is what is commonly captured by the tf metric. In Figure 1, Word 5 is a stronger contributor to the score of Sent 5 than Word 3 or Word 4 .  X  If a child node occurs frequently in the corpus, it carries a lower weight in contributing to each parent X  X  score. Word 3 is a com-monly occurring node and is less in fl uential in affecting the score of its many parents. This is what is commonly captured by idf .
Therefore, the score for a node i in our hierarchy with respect to the search term t and having j children is given by the following: where HScore ( t, n ) represents the score derived using our hier-archical data model for node n w.r.t. term t , ew ij is the edge weight between parent i and child j and is equal to the number of times a child occurs in the entire text of the parent, P ( j ) is the number of parents of j , C ( i ) is the number of children of i and the parameter  X  controls the effect of the size of the node.
 To score the forum data at multiple levels, we assume that the HScore ( t, i ) of a leaf node i containing the query keywords is 1, all other leaf nodes have a score 0 . We then recursively compute scores for all parent and ancestor nodes containing the query key-words. For queries with multiple terms, the fi nal score of a node is the sum of its scores for individual terms [18]. Thus, our bottom-up hierarchical scoring leverages the containment amongst the multi-granular objects, which is ignored by existing scoring functions.
Note that the scores computed using the hierarchical scoring function of Equation 2 are not monotone to allow for comparable scores across all granularity levels. Having computed the scores of nodes in one level, we cannot guarantee any bounds on the scores of the parents or ancestors. As a result, our scoring cannot be used in conjunction with popular top-k algorithms [10]. Our current imple-mentation scores all objects and retrieves the best k objects using the techniques described in Section 3.
Our hierarchical scoring function has a size weighting factor in-versely proportional to the number of children of the node. The score of a node i having many children, or a large sized node, is penalized by a factor C ( i )  X  . Therefore, the parameter the composition of the mixed granularity results.

Figure 2 shows the average composition of the top-20 results across 18 queries listed in Table 2, for varying values of 0 , the scoring function ignores the size of the objects and larger ob-jects possibly containing many relevant children have higher scores. Hence, at  X  =0 , 0 . 1 we see a large number of threads in the top-20 results. As  X  increases we see a mix in result granularity. Even-tually at  X   X  0 . 4 the results comprise mainly of smaller objects or sentences, i.e., the size becomes the dominant factor in the scor-ing causing larger objects to be severely penalized. As discussed in Section 2.2.1, existing scoring mechanisms like tf*idf and BM25 are not suitable for generating mixed granularity results. Yet, as a baseline we show in the rightmost column of Figure 2, the composi-tion of the mixed granularity results of the BM25 scoring. Figure 2 shows that BM25 with typical parameters [18] of b =0 . 75 k 1=1 . 2 retrieves 98% sentences in the top-20 results. Reducing the effect of document length ( b =0 . 5 ) and increasing the effect of term frequency ( k 1=2 ) still resulted in 88% sentences.
Ideally, we would like to generate a result set with a mix of gran-ularity and hence we set  X  to 0 . 2 or 0 . 3 . Note that users can have the fl exibility of choosing their preferred result granularity level by varying  X  . In the following section, we discuss the challenges and strategies for generating a mixed result set for a user query. An issue that arises in a mixed granularity search is redundancy. Since the objects at different levels have a containment relationship Figure 2: Composition of top-20 result sets with varying  X  in the hi-the same information will be present in a sentence and its parent post and thread. Repetition should be avoided to ensure that users do not see the same information several times [3]. We now describe methods for fi nding non-overlapping results while ensuring the op-timal aggregate score. First, we describe result generation strate-gies in Section 3.1 and then describe our ef fi cient OAKS algorithm for fi nding the optimal non-overlapping results in Section 3.2.
When generating results with a non-overlapping constraint, it is not suf fi cient to simply rank objects using their score as computed in Section 2. Instead, we need to generate a result set that takes into account the containment relationship among objects. For instance, if we include a post in the fi nal result we should no longer include the sentences in the post or the thread containing the post.
Greedily selecting objects in our hierarchy with the highest scores may result in rejecting other good high scoring objects, causing a decrease in the overall quality of the result set produced. Suppose we want to maximize the sum of the scores of the objects in the re-sult set R . Let us call this optimization function SumScore a k -sized result set our optimization problem is as follows:
For example, suppose that the searchable objects containing the query keywords are the 12 objects (sentences, posts and threads) from Figure 1, and the scores are as shown in Figure 3. Thread 1 has a score of 0 . 1 , Post 1 has a score of 2 . 1 and so on. Note that the leaf nodes containing query keywords are used for scoring objects using Equation 2, but are not presented as search results by them-selves. We now describe three strategies for generating a result set:  X  Overlap : Highest scored k objects containing the query key-words are naively included in the result set allowing repetition of text across different granularity levels. From Figure 3, for the result set will contain { Post 3 ,Post 1 ,Post 2 ,Sent 1
SumScore =8 . 2 . While the overlap strategy will always re-turn the result set with the maximum SumScore , repetition of text should be avoided as is achieved by the next two strategies.  X  Greedy : Here, we include the highest scored object that is still available in the fi nal result, and repeat this k times. Each time after picking an object we make all its ancestors and descendants unavailable. From Figure 3, for k =4 ,we fi rst pick Post 3 the highest score and make Sent 5 and Thread 2 unavailable.
Repeating this we generate the top-4 greedy result of { Post 3
Post 1 , Post 2 , Sent 6 } with a SumScore =7 . 0 .  X  Optimal : In general, the greedy strategy may not yield the op-timal result. From Figure 3, the best non-overlapping result set maximizing the SumScore over the k =4 results is { Post 3
Post 2 , Sent 1 , Sent 2 } with a SumScore of 7 . 6 .Thisissig-ni fi cantly higher than the SumScore of the greedy method. Figure 3: Hierarchy of relevant nodes and scores w.r.t a query.
Our experiments show that 33% queries have 3 or more overlap-ping results in just the top-10 results returned by overlap, possibly causing user frustration. Neither optimal nor greedy strategies have any overlapping results. In the following section, we describe our novel algorithm for fi nding the optimal result set with no overlap.
For a result set of size k we wish to maximize a global function like the sum of the scores of the k objects. The problem of fi nding such a set can be cast as a knapsack problem [25]. Finding a result set involves solving a knapsack problem with a k knapsack weight limit, unit weight and score as value on all objects, and we have the additional independence constraint amongst the objects. The knapsack problem is NP-Hard and so it is a hard problem to fi nd a non-overlapping optimal set. Note that, as described in Sec-tion 2.2.2, the hierarchical scoring is not monotone to allow objects at multiple levels to have comparable scores. Hence, top-k opti-mization algorithms [10] are not useful for generating result sets.
In this section, we describe our approach for fi nding an ef fi cient solution to this problem. First, we describe our modi fi cation to the search graph in Section 3.2.1 and reduce our result generation prob-lem to the independent set problem. In Section 3.2.2, we describe the existing LAIS algorithm for listing all maximal independent sets and then describe our ef fi cient OAKS algorithm for fi nding the optimal result set in Section 3.2.3. For simplicity, throughout this paper we assume that the optimization task is as described in Equa-tion 3. It is trivial to adapt our algorithm to other linear optimization functions, and our experiments with alternate optimization func-tions did not indicate signi fi cant variation in result relevance.
We approach the optimization problem of Equation 3 as an inde-pendent sets problem. An independent set of a graph G =( V,E ) is a subset of nodes V  X  V such that each edge in the graph is incident on at most one node in V [6]. To model the adjacency constraint appropriately, we fi rst augment the search hierarchy with edges connecting all ancestor-descendant pairs shown by the dot-ted lines in Figure 3. To satisfy the non-overlap constraint we now need to fi nd an independent set over this augmented search graph.
In particular, we are interested in fi nding all maximal indepen-dent sets over the search graph. An independent set that is not a subset of any other independent set is called maximal [15]. Once we fi nd all the maximal independent sets M over the graph, we can generate our optimal result set by computing the sum of the scores of the k highest scored elements from each set m  X  M .However, there are exponentially many maximal independent sets too. We now present an algorithm that generates the maximal independent sets in a speci fi c order with only polynomial delay.
An algorithm for generating all maximal independent sets of a graph in lexicographic ordering is presented in [15]. Assume that we have a fi xed ordering over all nodes in the graph. For our problem, we fi x the ordering by decreasing object scores. A lex-icographic ordering of sets has the fi rst possible node in the fi rst possible set. For instance, for a graph with four nodes ordered as { a, b, c, d } having sets as { b, c } , { a, c, d } and { a, d graphic ordering is { a, c, d } , { a, d } , { b, c } .

The Lexicographic All Independent Sets (LAIS) algorithm [15] is shown in Algorithm 1. The algorithm begins by inserting the fi rst lexicographic maximal independent set in the priority queue Q ; this is the set chosen by the greedy strategy. In each iteration, LAIS picks from Q aset S , and then selectively branches from to fi nd new candidates. For a node j/  X  S such that in the sorted ordering j occurs after node i  X  S , a candidate set C j is consid-ered. C j contains nodes in S up to and including j , after removing  X ( j ) neighbors of j .If C j is maximally independent on the fi rst j nodes of the sorted order, the fi rst maximal independent set chosen greedily and containing nodes in C j is inserted into
Suppose that the LAIS algorithm is applied on the graph shown in Figure 3. The fi xed ordering of nodes based on the decreasing scores is Post 3 , Post 1 , Post 2 , Sent 1 , Sent 2 , Sent 3 Sent 6 , Sent 5 , Post 4 , Thread 1 , Thread 2 , breaking ties arbitrar-ily. The scores are only used to fi x the ordering, and LAIS gener-ates all maximal independent sets irrespective of the scores or sum of scores. The fi rst maximal independent set S  X  chosen greedily is {
Post 3 ,Post 1 ,Post 2 ,Sent 6 } .Inthe fi rst iteration S = S we consider all nodes j in the sorted ordering such that j cent to a node i  X  S ,and i precedes j in the sorted order The fi rst such node is Sent 1 and C j = { Post 3 ,Post 2 ,Sent 1 is a maximal independent set on the fi rst four nodes of the fi xed node ordering. Therefore, we insert the set T = { Post 3 , Sent 1 , Sent 2 , Sent 6 } into Q .Inthis fi rst iteration there exist other j nodes Sent 3 , Sent 5 , Post 4 , Thread 1 , Thread 2 ing in fi ve new candidate sets. Setting j to node Sent 2 yields non-maximal sets on the fi rst fi ve or seven nodes respec-tively, and hence these candidates are not added to Q . In the subse-quent iteration, each of the six new sets are popped from a time for fi nding new maximal independent sets.
 Algorithm 1 Lexicographic All Independent Sets Algorithm
The correctness proof and time bounds are in [15]. The delay be-tween outputting sets is bounded by O ( n 3 ) . At each iteration a set is extracted from Q , followed by n calculations of new candidates, each time requiring O ( n + m ) to fi nd a maximal set T .However, LAIS achieves the polynomial delay by using exponential space to store the exponential maximal independent sets in Q .

We now present a new algorithm that improves on these time and space bounds signi fi cantly, and fi nds the optimal k -sized result set. We wish to generate an optimal result set of size k such that the SumScore of the k nodes is maximized. Finding ordered indepen-dent sets is useful to solve this problem. The Optimal Algorithm for k Set (OAKS) of results is presented in Algorithm 2 and has some key modi fi cations over LAIS. First, for the k -result set we do not go through all n nodes of the graph to fi nd a maximal indepen-dent set. A user is often interested only in the top 10 or 20 results, i.e., k&lt;&lt;n (Table 2 shows that across 18 queries the average in our corpus is 23K). Secondly, for a set S ( k ) picked from the pri-ority queue, we branch only at nodes j | j  X  End ( S ( k ) nodes are ordered by decreasing scores, a node after the k of independent set generated by branching from this node will have a lower overall score. Third, each time we add a k -sized independent set to Q , we check if this set has a higher score than the previous k from the priority queue where the fi rst node of the set Start ( S occurs after the current best .
 Algorithm 2 Optimal Algorithm for k Set
To illustrate the functioning of OAKS let us return to our ex-ample graph from Figure 3. Using OAKS with k =4 , the initial greedy S  X  is the set { Post 3 ,Post 1 ,Post 2 ,Sent 6 } . Note that we only need to fi nd a k -sized independent set. We set sc best best to the k th node of Sent 6 .Inthe fi rst iteration, we evaluate branches of this set only from the nodes occurring before in the sorted order. Therefore, we do not evaluate branches from Sent 5 , Post 4 , Thread 1 or Thread 2 .Inthe fi rst iteration, new sets of { Post 3 , Post 2 , Sent 1 , Sent 2 } with SumScore =7 . 6 and { Post 3 ,Post 1 ,Sent 3 ,Sent 4 } with SumScore =7 . 3 added to the queue. Thus, after the fi rst iteration only two new sets are entered in Q compared to the six in LAIS. We then further re-duce the search space by setting sc best  X  7 . 6 and best In just the second iteration, no new candidates are generated and { Post 3 , Post 2 , Sent 1 , Sent 2 } is returned as the optimal answer. In comparison with LAIS, the OAKS algorithm evaluates signi fi -cantly fewer candidates and generates the optimal result ef fi ciently.
OAKS Proof of Correctness: We now prove that the k -sized subset returned by OAKS is optimal, i.e., no other k -sized indepen-dent set has a SumScore greater than the set returned by OAKS.
Assume a fi xed ordering ( v 1 ,v 2 ,...,v n ) over the n nodes by decreasing scores in response to a query. Let X be the k -sized in-dependent set output by OAKS with nodes { x 1 ,x 2 ,...,x proof consists of two parts. First, we prove that OAKS fi nds and evaluates at least the fi rst k -sized independent set starting from all nodes v i appearing before x k in the sorted ordering, v i such nodes are viable, i.e., qualify to be the starting nodes of max-imal independent sets. For instance, the nodes Sent 2 and in Figure 3 do not qualify to be starting nodes of maximal indepen-dent sets over the fi xed sorted ordering. Secondly, we show that OAKS fi nds the highest SumScore k -sized set starting with T HEOREM 3.1. Starting nodes of independent sets For every node v i | v i  X  x k in the sorted ordering, OAKS evaluates at least the fi rst independent set starting with v i , when viable.
P ROOF . OAKS starts with the greedily chosen k -sized indepen-dent set with v 1 as the fi rst node. Let us call this set as S with nodes s 1 ,s 2 , ...s k . OAKS then branches from all nodes when such branching yields new maximal independent sets. Some of these branches will result in including a neighbor of s we would reject s 1 in creating the candidate C ( k ) v v . This will yield a set with a starting node other than s include this set in the priority queue if it passes the maximality test. Repeating this across iterations, we fi nd new candidates with possi-bly new starting nodes, as long as the starting nodes appears before
At some iteration, OAKS fi nds the optimal set X , assigns to x k and inserts X into the priority queue. OAKS arrives at the set X after considering all viable starting nodes appearing before x . When OAKS picks X from the queue and starts branching, it evaluates candidates from all nodes before x k and inserts new can-didate sets with possibly new starting nodes into the priority queue. Hence, OAKS evaluates at least the fi rst k -sized independent set starting from all viable starting nodes v i  X  x k .
 T HEOREM 3.2. Optimal Score k -set with v i as starting node For an independent set with a starting node v i ,OAKS fi nds and evaluates the highest SumScore k -sized set starting with
P ROOF . From Theorem 3.1, OAKS inserts in its queue at least the fi rst k -sized independent set with v i at the starting position when possible. Consider the iteration of OAKS where this fi rst in-dependent set, say F v i , starting with the node v i is popped from the priority queue. OAKS fi nds all branches of F v i originating from nodes up to the k th node of F v i , i.e., OAKS branches from all nodes v j  X  F v i result in replacing some nodes appearing before F v i cency) with nodes appearing after F v i have a lower SumScore than F v i . Now, for all branches from nodes v j  X  F v i  X ( v j )  X  v j is maximal on the fi rst j nodes, and inserts these into the priority queue. Repeating this procedure for each of these new branching from nodes preceding End ( S ( k ) ) . Therefore, across all iterations of OAKS, for a starting node v i OAKS certainly evalu-ates the highest SumScore set.
 For a set Y to have a higher SumScore than X ,atleastthe fi rst node of Y has to appear before the k th node of X , y 1  X  Theorem 3.1, OAKS does not miss evaluating such independent sets with y 1  X  x k . Moreover, from Theorem 3.2 we see that OAKS fi nds the highest SumScore set amongst all k -sized independent sets starting from such a node y 1 . Therefore, it follows by contra-diction that a Y cannot exist such that it has a higher SumScore than X . OAKS fi nds the optimal k -sized independent set.
In the worst case, OAKS goes through all n nodes to fi nd a node. In such a rare scenario, OAKS achieves no performance gain over the LAIS algorithm. However, typically k&lt;&lt;n . Suppose that the k th node of a set S extracted from Q appears at position of the sorted order. We fi nd new candidates by at most p ings from S . Thus, the OAKS algorithm has a time complexity in the order of O ( p 3 ) which gives us a signi fi cant improvement when p&lt;&lt;n , as shown in Section 5.3. Moreover, OAKS requires po-tentially exponential space in p and not in n , and each set in only k nodes, resulting in signi fi cant space savings.

Thus, we design the novel OAKS algorithm for ef fi ciently fi nd-ing the optimal k -sized result set. The fi xed decreasing score order-ing of the sets evaluated by OAKS ensures that in case of a tie in SumScore , OAKS outputs the highest scored nodes at the earliest possible position in the ranked list and these results are accessed fi rst by the search user, which is desirable.
We implement a multi-granularity search system on a breast can-cer patient forum [14]. The data was collected from the publicly available posts on the online site breastcancer.org .Thefo-rum data contains threads on a variety of topics useful to breast cancer patients and their families, as well as for health profession-als. The search functionality offered by the web site over its forum data is very basic. Results are presented as a chronological list of posts fi ltered by keywords, irrespective of whether the post is the right level of result for the particular query.

The forum corpus is a large collection of 31,452 threads com-prising of 300,951 posts written during the period of May 2004 to September 2010. We used the OpenNLP [1] toolkit for sen-tence boundary detection and chunking on the text. This resulted in 1.8M unique sentences composed of several search keywords. We prune infrequent mis-spellings and word formulations and re-tain 46K keywords that occur at least fi ve times in the entire corpus.
We store our data in a MySQL version 5.5 database containing tables for each level in our data hierarchy: words, sentences, posts and threads. Every node in the database contains attributes to store parent and children information, allowing for ef fi cient score com-putation using Equation 2. For generating a non-overlapping re-sult set as described in Section 3, these parent-children relations are extended to fi nd and exclude ancestors and descendants when required. The score computation and result set generation is imple-mented using Python version 2.6. All experiments were run on a Linux machine (CentOS 5.2) with Intel Xeon (3GHz, 16GB RAM).
We now report on our experimental evaluation. In Section 5.1, we evaluate the retrieval performance of our hierarchical scoring function from Equation 2, by studying the ranks at which target objects are retrieved by our scoring function as compared to the traditional tf*idf scoring. We then conduct relevance assessment using crowd-sourcing and show that the relevance of search results improves when users are given a mix of objects at different gran-ularity levels (Section 5.2). In Section 5.3, we study the optimal answer and the ef fi ciency of our OAKS algorithm.
We compare our hierarchical scoring with state-of-the-art tf*idf scoring by the ranks at which relevant results are returned, when retrieving objects at a single granularity. We randomly selected 20 queries in the breast cancer domain and a target post that is an exactly relevant answer. There might be other posts which are also exact matches for the queries. The target posts however, are highly relevant and a good scoring should retrieve them at lower ranks.
Figure 4(a) shows the retrieval performance of HScore and tf*idf scoring averaged across the 20 test queries, at the granularity of
Figure 4: Normalized rank of targets at single granularity levels. posts. The rank of a target object is normalized by the total number of objects matching the query. A lower normalized rank implies that the target object was retrieved higher up in the list of returned results, which is the desired property. As shown in Figure 4(a), both the HScore and tf*idf scoring retrieve the target posts within the top 3% of results displayed to the users. For all values of HScore has better retrieval performance than the tf*idf scoring at the granularity of posts. As  X  increases to 0 . 3 and 0 . 4 the post dominates the tf*idf scoring yielding signi fi cantly poorer retrieval ranks as compared to HScore . Hence, at the single gran-ularity of posts HScore clearly outperforms the tf*idf scoring.
Furthermore, we study the effect of the hierarchical scoring at the granularity of threads and sentences. We de fi ne target threads as those containing the target posts, and de fi ne target sentences as the sentences in the target posts which contain the query keywords and have the best rank. Figure 4(b) shows that at  X   X  0 . 2 , at the gran-ularity of threads HScore outperforms the tf*idf scoring as seen by the lower normalized ranks. Figure 4(c) shows that both scoring functions perform poorly when retrieving the target sentences with ranks around top 9%. The target sentences are not the best sentence results in response to the queries even though the posts containing these sentences are highly relevant, thus demonstrating the need for dynamically choosing the result granularity level.

Therefore, HScore is better than or as good as the tf*idf scoring for ranked retrieval over forums, when a single granularity of re-sults is desired. In the following section, we demonstrate the added strength of our hierarchical model which allows retrieving a mix of objects of different granularities. In contrast, tf*idf and BM25 do not provide a uni fi ed scoring for objects at different levels.
We now evaluate the perceived quality of our results. First, we describe our evaluation setting with details on the relevance as-sessment scale and quality control mechanisms used for the crowd sourced workers. We then compare the relevance of our multi-granularity results with the traditional posts-only results.
We evaluate our hierarchical data model and scoring function using a set of 18 representative queries chosen randomly. These queries were chosen from different areas of interest for a breast cancer patient from side effects of medicines, alternate treatment options, and food and ingredients bene fi cial to patients. The queries contain 1 to 3 keywords with an average of 1 . 8 keywords per query. Table 2 lists the queries and the number of searchable nodes at each level of granularity that contain the query keywords. Thus, we need to score and rank a varying number of nodes ranging from a few hundred nodes to 200K nodes (for the query scarf or wig ).
We compare our mixed granularity search with strategies return-ing only posts, as current search systems over forums return iso-lated posts. Relevance judgments for four different experimental search systems were gathered: the Mixed-Hierarchy search strategy comprising results at multiple granularity levels scored using our hierarchical scoring function from Equation 2 and using our OAKS result generation algorithm, the Posts-Hierarchy search system that retrieves results comprising only of posts scored using the hierar-chical scoring function, the Posts-tf*idf search strategy which re-trieves posts scored using traditional tf*idf scoring, and the Mixed-BM25 search strategy that uses the BM25 scoring with the OAKS algorithm to generate results at multiple granularities. As discussed in Section 2.2.1, existing scoring methods like tf*idf and BM25 do not generate a true mixed granularity result as they favor smaller sentences. In addition, these scoring methods do not incorporate the containment relationships amongst objects. Yet, as a baseline we discuss the relevance of the Mixed-BM25 search which scores and ranks sentences, posts and threads. The Posts-tf*idf search mimics existing forum search approaches, which return only posts using IR scoring functions. We now compare these four search sys-tems by conducting relevance assessment experiments.
It is common practice in earlier works to use a graded relevance scale [17]. While it is dif fi cult to estimate relevance accurately, the complexity of the problem is multiplied when asking judges to es-timate relevance of objects at multiple levels of granularity. In [4], engineers were asked to assess relevance of large documents con-taining structured data at multiple levels. For evaluating our search systems, we adapt their relevance scale [17, 20] designed speci fi -cally for assessing relevance at multiple granularity. Therefore, we ask judges to annotate search results with one of the following:  X  Exactly relevant : Highly relevant information at the exact level.  X  Relevant but too broad : Document contains relevant informa-tion, but also includes other irrelevant information.  X  Relevant but too narrow : Relevant information lacking context.  X  Partial answer : Partially relevant information.  X  Not relevant : No relevant information.

This relevance scale captures user assessment towards varying granularity levels as well as the usefulness of the search result. We conducted relevance assessment on the Amazon Mechanical Turk crowd-sourcing website (https://www.mturk.com/). Workers were given 5 results to a query at a time and were asked to mark the relevance according to the proposed scale. Workers were only shown queries and textual results, without discussion on multi-granularity or containment of results. Workers were also provided with examples of search results belonging to each relevance grade.
Our tasks on Mechanical Turk were answered by high-quality workers with 95% or higher acceptance rate. We evaluated batches of tasks to fi nd spammers based on abnormal submissions, for in-stance when time taken was very low, and blocked these workers. As an additional quality check, each task answered by the workers had a unmarked honeypot question used to assess worker quality. The honey-pot questions were drawn from a pool of questions eval-uated by the authors and had the least ambiguity (we often picked irrelevant text to remove the granularity subjectivity). The honey-pot questions were answered correctly by workers who understood the instructions and who were not spammers. After these quality fi ltering steps, we retained 71% of the relevance annotations, result-ing in 7 . 6 individual assessments for each search result on average. The relevance assessments were completed by 175 workers, with 114 s required to complete each task on average. For computing the fi nal vote, we used the expectation maximization (EM) algorithm proposed by Dawid and Skene [8] that takes into account the qual-ity of a worker in weighting his vote. Gathering several votes for each task and utilizing these cleaning and pruning methods reduces the error in relevance judgements, and ensures that the relevance estimates obtained are highly re fl ective of a general user X  X  percep-tion. Moreover, we use identical relevance experiment settings to compare all the alternative search systems.

Figure 5 shows the majority relevance assessment of the top-20 results for the query shampoo recommendation generated by our Mixed-Hierarchy system. At  X  =0 . 1 , we see that many results have a grade of Relevant but too broad as at low values of number of results are threads (Figure 2). On the contrary, at high values of  X  the result set mainly contains short textual snippets, and many results have the Partial or Not relevant grades. We achieve the highest overall relevance for  X  =0 . 2 , 0 . 3 . Interestingly, these are the  X  values with the highest mix in result granularity as shown in Figure 2. Thus, we see that the result sets with a high granularity mix also have a high relevance as assessed by workers.
We now compare the relevance for the alternative search strate-gies described in Section 5.2.1.We evaluate the top-20 ranked lists using mean average precision (MAP) [18]. Computing MAP re-quires binary relevance assessment. For our experiments we as-sume that if the users annotate a search result as Exactly relevant, Relevant but too broad or too narrow, then the result is relevant. Table 3 shows the MAP at different top-k values for the alternative search systems. As described earlier, the composition of the ranked list of results and the overall perceived relevance varies with the size parameter  X  . Table 3 shows that the Mixed-Hierarchy search system has a clearly higher MAP than the two posts only systems, for  X  values of 0 . 1 , 0 . 2 and 0 . 3 . Mixed-Hierarchy performs signif-icantly better for  X  =0 . 2 when the top-20 OAKS non-overlapping result set has 2 sentences, 5 posts and 13 threads on average, as well as at  X  =0 . 3 with 6 sentence, 5 posts and 9 threads on aver-age; yielding the highest mix in result granularity. The percentage improvement of our Mixed-Hierarchy system over Posts-Hierarchy at top-20 is 35%, 34% and 16% for  X  =0 . 1 , 0 . 2 , 0 . 3 and the improvements over Posts-tf*idf are 31%, 32% and 18% respectively (statistically signi fi cant with p  X  0 . 01 ). Moreover, Mixed-Hierarchy hasveryhighMAPatthetop-1ortop-5results which are most likely to be accessed by users. The Posts-Hierarchy system utilizing our scoring from Equation 2 has MAP values simi-lar to the traditional Posts-tf*idf system; in terms of relevance at the granularity of posts our scoring function performs as well as tradi-tional scoring mechanisms. Lastly, Mixed-BM25 has a signi fi cantly worse MAP than the other search systems. Recall from Section 2.2, that the Mixed-BM25 results mainly contain sentences which often receive a Partial or Not Relevant grade.

As shown in Figure 2,  X  =0 . 4 skews the results towards sen-tences, which often are only partially relevant. This explains the degradation of MAP for the Mixed-Hierarchy approach at  X  =0 . 4 shown in Table 3. On the other end of the spectrum, results at 0 . 1 are mainly composed of threads which often have a Relevant but too broad assessment. The MAP measure unfortunately, favors relevant results even if they are too broad or too narrow. We further investigate the relevance of our results by taking the gradation of the annotations into account when comparing the search strategies. Discounted cumulative gain (DCG) [7] is a measure for assessing ranked lists with graded relevance. The DCG accumulated at rank k with rel i indicating the relevance of the result at position ranked list, is computed as DCG @ k = rel 1 + k
For our experiments, we translate the fi ve grades of relevance as follows: Exactly relevant has a score of 5 , Relevant but too broad and Relevant but too narrow have a score of 4 and 3 respectively (incomplete information is worse than having to read extra text), Partial answers have a score of 2 , and Not relevant has a score of 1 .
Normalized discounted cumulative gain (nDCG) is computed by normalizing the DCG@ k with the ideal DCG value or IDCG@ k IDCG is the highest achievable DCG of the ideal ranking. We as-sume that for each search systems, there exist at least 20 exactly rel-evant results with the highest relevance grade of 5 . Hence, we com-pute the IDCG at each level k as IDCG @ k =5+ k and compute the average nDCG across the 18 test queries. Table 4 shows the comparison of the nDCG values for the four search sys-tems. Comparing Posts-Hierarchy utilizing our hierarchical scor-ing with the traditional Posts-tf*idf system, we see that the overall relevance nDCG of the two systems is very similar. The results show that for  X   X  0 . 3 the Mixed-Hierarchy results have a higher nDCG than the two posts only systems, at all of the top-k settings (statistically signi fi cant with p  X  0 . 01 ). The performance improve-ment diminishes as  X  increases to 0 . 4 when the Mixed-Hierarchy results comprise of many partially relevant sentences. Similarly, Mixed-BM25 results contain many sentences and have a very low nDCG. At  X  =0 . 2 with a high mix of results, Mixed-Hierarchy clearly retrieves more relevant results at higher positions than the two post only methods. The improvement in nDCG at top-20 by the Mixed-Hierarchy system over Posts-Hierarchy , Posts-tf*idf and Mixed-BM25 is 22%, 18% and 49% respectively, for  X  =0 . 2 These values show that the perceived relevance of a mixed gran-ularity set of results is higher than post-only results, which is the current state of search over forums. Therefore, there is a clear ben-e fi t in generating a mixed granularity result for a user query.
In this section, we compare the result set output of the greedy strategy and the OAKS algorithm and evaluate the ef fi ciency of OAKS. As described earlier, experiments were run on a Linux Cen-tOS 5.2 machine with Intel Xeon (3GHz, 16GB RAM).
We generated a test bed of 200 single word queries randomly chosen from our corpus. For each of these queries, we evaluated the top-20 results generated using the greedy and optimal strategies. Our experiments showed that for 31% of the queries, OAKS re-turns an answer at top-20 with a higher SumScore than the greedy strategy. Moreover, for 22 of the queries, the improvement occurs within only the top-5 results. Thus, the OAKS algorithm has a no-ticeable effect on the quality of returned answers. Moreover, OAKS generates the optimal result with a low time overhead. Across the 200 queries, OAKS generates the top-20 optimal result in 0 on average (greedy required 0 . 004 s). In comparison, the time re-quired for scoring all objects containing the query keywords was 0 . 96 s on average. Thus, OAKS yields the optimal result set ef fi -ciently with a noticeable difference in the few high ranked results. LAIS generates all maximal independent sets, while our novel OAKS algorithm evaluates signi fi cantly fewer candidates by lever-aging the fact that generally users are interested in only the top-answers to a query, and typically k is much smaller than the size of the search hierarchy. We now compare our OAKS algorithm with the existing LAIS algorithm, both in terms of the run-time and the number of independent sets generated. We randomly generate 100 single word queries in each bucket of search term frequency with buckets of 20-30, 30-40, ... 70-80. In general, search terms in our corpus have much higher frequencies as seen in Table 2. We choose these bucket sizes conservatively because LAIS has to eval-uate all maximal independent sets which are exponential in the size of the hierarchy. The fi nal result set returned by LAIS and OAKS is the same, however OAKS is signi fi cantly more ef fi cient as shown in Table 5. We see that as the frequency of the search term in-creases, LAIS has to evaluate as many as 897 possible candidates for queries with frequency between 70-80. On the other hand the performance of OAKS depends only on k . As before, we set top-20 results. As shown in Table 5, OAKS evaluates less than 8 different candidate sets and fi nds the optimal answer in less than 0 . 12 s. Moreover, OAKS achieves this many orders of magnitude speed-up independent of the frequency of the nodes or the data size. We now generate synthetic datasets to study the ef fi ciency of OAKS on signi fi cantly larger search hierarchies than those in our corpus. LAIS cannot compute the optimal result on such large datasets due to the exponentially many maximal independent sets. For the synthetic datasets, we vary the number of nodes as well as the dependence between the nodes by varying the fanout  X  .We assume three levels in the hierarchy with 30 top-level nodes. Each non-leaf node has  X  children. As  X  increases the number of nodes in the hierarchy increases greatly, and the dependence between nodes also increases due to increasing number of ancestors and descen-dants of each node. We assign higher scores to higher level nodes with many descendants, forcing OAKS to evaluate multiple candi-dates to fi nd the optimal k -sized result set. The scores are assigned as follows: leaf nodes have a random real valued score in (0 second level nodes in (0 , 2) and top-level nodes in (0 , 3)
Table 6 shows the performance of OAKS averaged across 1000 runs for each  X  . We see that as fanout increases the number of nodes in the hierarchy increases drastically to as many as 303K nodes. Yet, when generating the optimal top-20 result set, OAKS evaluates less than 8 candidates and requires less than 6 performance of OAKS depends only on k , and hence we do not see an increase in the number of candidates as  X  increases (runtime increases due to the time spent in making increasing number of descendants unavailable). Therefore, OAKS ef fi ciently fi nds the optimal result even under varying data characteristics.
The standard web retrieval model returns ten links with sum-mary snippets. Recently, researchers have enhanced search results by presenting top ranking sentences and thumbnails along with the links [16], clustering search results [12] and presenting them in a hierarchy of topics [11]. As shown in [16], presenting top rank-ing sentences along with the web pages enhances user experience. Little work has been done in dynamically choosing the right focus level for the information. Our work focuses on retrieving text at the appropriate level of granularity to satisfy user needs without the burden of sifting through entire documents, when possible.
Online forums contain rich unstructured data with information on a variety of topics. In [24], the authors use trained classi fi ers to retrieve sentences about symptoms and medications from patient forums. Such topical analysis of the content posted by users along with the social network of interactions has been successfully used to predict the cancer stage of patients [14]. Textual content has been successfully used to introduce links between different threads in user forums [26]. Yet, very little research has focused on im-proving search over forums. Models have been developed to in-corporate information outside of a post [9], from the thread or the entire corpus, to enhance ranking of the retrieved posts. However, the retrieved results are still posts and will suffer from the lack of context. By varying the granularity of search results, our methods explicitly incorporate relevant neighborhood context.

Searching through XML documents at different levels of granu-larity has been well studied and [3] has an overview on XML search and the INEX workshops. We represent the containment relation-ships of objects at multiple granularities in a hierarchy for com-puting a bottom-up score. However, our objects are unstructured free-form text objects and relationships speci fi c to XML nodes and attributes do not apply. Avoiding overlapping results in XML has been addressed in previous work by greedily selecting high scored nodes in a path [23], adjusting parent and children node scores af-ter retrieving objects [5] or maximizing utility functions built on object scores and sizes [19]. In contrast, our OAKS algorithm generates a top-k result set by optimizing a global function, and does not rank objects in isolation. Generating a non-overlapping result set in our scenario implies avoiding repetition of the exact text within the multi-granular objects. Our work is orthogonal to result diversi fi cation [27], where the problem is to fi nd top-k search results that cover diverse topics or sub-topics from a concept hierar-chy. Our data hierarchy represents containment of objects and not a topic hierarchy. Previous work in [21, 22] shows that users prefer documents at a medium granularity to judge relevance, rather than short titles and metadata or the entire documents, suggesting that a balance must be struck between too coarse and too fi ne granu-larity. However, forum data has little explicit structure and multi-granularity retrieval over such text has not been studied before.
Estimating relevance of textual results is a notably hard task be-cause of the subjective assessments affected by the perception and biases of the judges. There has been a large body of literature with information on the factors affecting relevance estimation as well as a variety of scales and measures for assessing relevance. In [13], the authors suggest eighty factors that affect relevance, from personal biases, diversity of content, browsability and the type of relevance scale. Our approach to mitigating the effect of individ-ual subjectiveness in relevance estimation is to conduct large-scale user studies using crowd-sourcing, and effectively reducing spam annotations, as discussed in Section 5.2.3. As shown in [2], crowd-sourced relevance assessment of XML search obtained via Me-chanical Turk had comparable quality to INEX specialized judges.
Patient posts constitute an exciting area for new research: the language is both emotional and technical, the style is often narra-tive, and forums are highly interactive. In the future, we are inter-ested in studying social interactions in forums.
In this paper we have presented a novel search system over pa-tient forum data performed as part of the PERSEUS project. Our main contribution is the design of a hierarchical scoring methodol-ogy that allows several granularities of forum objects to be scored and compared in a uni fi ed fashion. Using our scores, we can gener-ate results that contain a mixed set of objects, dynamically selecting the best level of focus on the data. We designed the ef fi cient OAKS algorithm to generate the optimal non-overlapping result set that ensures no redundant information. We conducted user studies to assess the relevance of the retrieved search results and our exper-iments clearly show that a mixed collection of result granularities yields better relevance scores than post-only results.

We are investigating additional optimization functions for gener-ating multi-granularity results with different properties of the result set. We are also studying personalized search for web forum users leveraging their topics of interest to fi nd similar users or experts on particular subjects. We are currently developing a search interface for representing multi-granularity results in and out of context with visualization tools like highlighting relevant text.
This work was supported by NSF Grants IIS-0844935 and BCS-1027801, and a Google Research Award.
