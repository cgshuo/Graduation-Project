 This paper addresses the issue of query refinement, which in-volves reformulating ill-formed search queries in order to en-hance relevance of search results. Query refinement typically includes a number of tasks such as spelling error correction, word splitting, word merging, phrase segmentation, word stemming, and acronym expansion. In previous research, such tasks were addressed separately or through employing generative models. This paper proposes employing a unified and discriminative model for query refinement. Specifically, it proposes a Conditional Random Field (CRF) model suit-able for the problem, referred to as Conditional Random Field for Query Refinement (CRF-QR). Given a sequence of query words, CRF-QR predicts a sequence of refined query words as well as corresponding refinement operations. In that sense, CRF-QR differs greatly from conventional CRF models. Two types of CRF-QR models, namely a basic model and an extended model are introduced. One merit of employing CRF-QR is that different refinement tasks can be performed simultaneously and thus the accuracy of re-finement can be enhanced. Furthermore, the advantages of discriminative models over generative models can be fully leveraged. Experimental results demonstrate that CRF-QR can significantly outperform baseline methods. Further-more, when CRF-QR is used in web search, a significant improvement of relevance can be obtained.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query formulation Algorithms, Experimentation, Performance, Theory Query Refinement, Conditional Random Fields, Web Search  X  This work was conducted at Microsoft Research Asia.
In modern Information Retrieval (IR), search is formalized as a problem of document ranking based on degree of match-ing between query terms and document terms. Therefore, how to resolve a mismatch between query terms and docu-ment terms becomes one of the biggest challenges for IR. For example, if a document contains  X  X ew York Times X  while the user types  X  X y times X , typically the document would not be retrieved at a search system. Spink et al. [23] observe that users have to reformulate their search queries 40% to 52% of the time in order to find what they want. In fact, many ill-formed queries can be found from the query logs of web search engines. Queries may contain misspelled words, mistakenly split words, or mistakenly merged words. More-over, queries may include phrases that should be quoted (us-ing the quotation operator), words that should be properly stemmed, or acronyms that should be expanded.

The question then becomes whether we can offer a solution during search which automatically reformulates queries, in order to better represent users X  search needs and help users more easily find the relevant information. This is what we mean by query refinement as address in this paper. Note that for simplicity we only consider replacing the original query with the refined query in search (e.g., changing  X  X y times X  to  X  X ew york times X  and searching with it), but not combining the two.

There is previous work on query refinement. However, the issue was tackled in separate tasks or by employing gen-erative models. For example, Li et al. conducted spelling error correction for web search by using a Maximum En-tropy model as well as the Source Channel model [15]. Peng et al. performed automatic word stemming for web search by means of a Statistical Language model [17].

We propose exploiting a unified and discriminative model in query refinement, specifically (1) conducting various query refinement tasks in a unified framework, and (2) employing a special CRF model called CRF-QR to accomplish the tasks.
One advantage of employing CRF-QR is that the accu-racy of query refinement can be enhanced. This is because the tasks of query refinement are often mutually dependent, and need to be addressed at the same time, e.g., refining the query  X  X aper on machin learn X  to  X  X aper on  X  X achine learning X  X . Alternatively, we could employ a cascaded ap-proach in which we perform the refinement tasks one by one. However, the accuracy of this approach might not be high, because the dependencies between the tasks cannot be handled properly and errors can be accumulated through the refinement processes.
Query refinement is by nature a structured prediction problem which seeks to predict the latent structure of an observation sequence. Therefore, when we employ a dis-criminative model in query refinement, we enjoy all its ad-vantages as compared with employing a generative model. A straightforward application of existing models, for exam-ple conventional CRF, would not work, because the output space would necessarily become extremely large.

We instead propose a new CRF model for query refine-ment, referred to as CRF-QR. The CRF-QR model is largely different from conventional CRF. Given a sequence of query words, CRF-QR predicts a sequence of refined query words as well as corresponding refinement operations. The refine-ment operations are defined for the query refinement tasks. We consider two types of CRF-QR; one is called basic model and the other extended model. The former is used when only one refinement task can be applied to a word, while the latter is used when multiple refinement tasks can be applied to a word (e.g.,  X  X earm X  to  X  X earn X  and then  X  X earning X ). In learn-ing, we employ Maximum Likelihood Estimation to estimate the parameters of the model. In prediction, we employ the Viterbi Algorithm to find the best sequence of refined query words.

Without loss of generality, we consider spelling error cor-rection, word merging, word splitting, and phrase segmen-tation as example refinement tasks in our experiments. Ex-perimental results show that our approach (CRF-QR) sig-nificantly outperforms the cascaded approach and genera-tive approach to query refinement. Furthermore, when used in search, our approach can help significantly improve rele-vance.
Query refinement is a problem already identified and stud-ied in IR (cf., [27]). Much of the previous work, however, only focused on one task of refinement or resorted to gener-ative models. Li et al. [15] proposed a method for spelling error correction by using a Maximum Entropy (ME) model as well as the Source Channel model. They utilized distribu-tional similarities between the query word and its correction candidate as features in the ME model. Cucerzan and Brill [6] addressed a more generalized spelling correction task us-ing a Source Channel model and query log data. They made use of bigrams as the source model and Weighted Edit Dis-tance as the channel model. However, it is less possible to extend their approach to handle other alteration types, e.g. phrase segmentation. Peng et al. [17] proposed a method for conducting stemming on head words of queries. They em-ployed a Statistical Language model in stemming candidate selection. Risvik et al. [20] proposed a method for phrase segmentation using the so-called  X  X onnexity measures X . A  X  X egmentation score X  X s computed from connexity values and used as a criterion for segmentation. (See also [1][5][3]). Ta-ble 1 gives a summary on the previous work.

There are several other problems relevant to query refine-ment, although they are slightly different. In query expan-sion one adds new terms to the query to overcome the term mismatch problem [4][18]. There is no assumption that er-rors exist in the queries submitted by users. The so-called global analysis [8][10] and local analysis [21][22][28] are usu-ally used in query expansion. In query suggestion we present related queries to the user to enhance his/her search expe-rience [2][7][13]. The suggested queries can be semantically different from the input query. Search log data is usually used in query suggestion. Query substitution by Jones et al. [12] is similar to query refinement. The key idea of the work was to replace the current query with a new query that can improve search relevance, mined from search log data. Two models (linear classification and linear regression) were trained by using labeled data and employed in the substi-tution decision. The major difference between query sub-stitution and query refinement is that the former is used to consider inter query relations, while the latter considers intra query relations.(See also [11].)
Structured prediction is a problem in machine learning, in which given an observation sequence we are to predict the latent structure of the sequence. Many application tasks in information extraction, natural language processing, bioin-formatics, and speech recognition can be formalized as struc-tured prediction. One approach to the problem is to employ a discriminative model. For example, Lafferty et al. pro-posed using CRF [14] for structured prediction. CRF is a conditional probability distribution of structure given ob-servation sequence. The most widely used CRF model is the one that predicts a label sequence (structure) given an observation sequence. Maximum Likelihood Estimation can be used in learning and the Viterbi Algorithm in prediction. Taskar et al. [25] and Tsochantaridis et al. [26] addressed the structured prediction issue by means of Support Vector Machine (SVM). Another approach to structured prediction is to employ a generative model. A typical model in this approach is Hidden Markov Model (HMM)[19], which repre-sents a joint probability distribution of observation sequence and structure. Discriminative learning offers several advan-tages when compared with generative learning. Learning is equivalent to modeling the mapping relations from observa-tion sequence to structure but not to estimating the joint probability distribution between observation sequence and structure. Thus, it can be conducted more effectively toward the goal of enhancing prediction performance. Moreover, it is easier to incorporate various features into the model. As a result, a discriminative model can usually achieve better accuracies than a generative model. However, exploiting a generative model also has its merits. Usually there is no need to use labeled data in training; creating such data is costly anyway.

CRF-QR proposed in this paper is designed for query re-finement and differs greatly from existing CRF models. The conventional CRF model is defined on a label sequence (a chain) and is used for sequence data labeling [14]. Dynamic CRF proposed by Sutton et al. is somewhat similar to CRF-QR, in which multiple labels can be assigned to an obser-vation in the observation sequence [24]. However, Dynamic CRF does not have the operations that CRF-QR has.
Query refinement is a problem as follows. Given an ill-
Original Query Refined Query sytem requirement system requirement you tube youtube universityof california  X  X niversity of california X  data mine  X  X ata mining X  the office show  X  X he office X  show on line book store online bookstore papers on machin learn papers on  X  X achine learning X  system of a dowm  X  X ystem of a down X  las vegas cart race  X  X as vegas X  X  X art racing X  south sea port new york south seaport  X  X ew york X  chicargo news paper chicago newspaper formed query from the user, we refine the query and help the user to better retrieve documents. A number of refinement tasks are involved: spelling error correction, word splitting, word merging, phrase segmentation, word stemming, and acronym expansion. Table 2 shows some examples of query refinement. For instance, if the query typed by the user is  X  X apers on machin learn X , then it is very likely that no relevant documents will be retrieved. This is because the spelling error X  X achin X  X hould be corrected, the word X  X earn X  should be stemmed as  X  X earning X , and it is better to group the phrase  X  X achine learning X  together (use the quotation operator).

As can be seen from Table 2, refinement tasks are often mutually dependent. In the above example, stemming on  X  X earn X  X eeds help from spelling error correction on X  X achin X , and vice versa. Furthermore, phrase segmentation on  X  X a-chine learning X  depends on the stemming and the spelling error correction, and vice versa. Therefore, it is better to employ a unified framework with which we perform all the refinement tasks simultaneously. In this way, we are able to significantly boost the accuracy of query refinement.
Query refinement is by nature a structured prediction problem. Specifically, given a sequence of query words, we predict the most likely sequence of refined query words. Given enough labeled training data, we are able to train a reasonably effective model by using discriminative learning.
We propose employing a unified and discriminative model in query refinement, specifically the CRF-QR model. There are two types of models: a basic model and an extended model. For ease of explanation, we explain the former model first. In our experiments we used the latter model.
Let us first look at the basic CFR-QR model. In the basic model, we assume that given a query word only one refine-ment task (e.g., spelling error correction or word stemming) can be applied.

Let x denote a sequence of query words, and let y denote a corresponding sequence of refined query words. Without loss of generality, we assume that the sequences x and y have the same length. (When it is not the case, we can normalize them to the longest.) We use x = x 1 x 2 . . . x y = y 1 y 2 . . . y n to denote the words in the query and in the refined query, respectively. Here n denotes the length of the sequences.

A straightforward approach would be to employ a condi-Figure 1: Graphical representation of (a) conven-tional CRF, and (b) Basic CRF-QR tional probability model Pr( y | x ) for query refinement. The conditional probability model can be defined as a conven-tional CRF model on a chain, in which adjacent y  X  X  are dependent on each other and individual y  X  X  are dependent on all the x  X  X . It is depicted in the graphical model in Fig-ure 1(a) (for ease of presentation, we show the case in which individual y  X  X  only depend on the corresponding x  X  X ). As a result, the query refinement task becomes that of finding the sequence y  X  satisfying y  X  = arg max y Pr( y | x ) where the conditional probability is calculated with the CRF model. However, the learning of such a model would be intractable, because the space of y is as large as the space of x (this means that any word can be mapped to any other word) and a large amount of data is needed for training.
The key idea in CRF-QR is to introduce operations and incorporate the operations into the conditional probability model. In this way, we can make the construction and uti-lization of the model feasible, as explained below. For the task of spelling error correction, for example, we can consider the following refinement operations: deletion, insertion, sub-stitution, and transposition. For word stemming, we can introduce operations such as + s , + ed , and + ing . Similarly, we can define operations for other refinement tasks, as de-scribed in Table 3. (Note that the operations in a task are mutually exclusive.) In fact, more complicated refinement operations can be easily incorporated in our model.
We let o denote a sequence of refinement operations o = o o 2 . . . o n . We employ a conditional model Pr( y , o | x ) in query refinement. We call the model CRF-QR. We assume that adjacent y  X  X  are mutually dependent, o  X  X  are indepen-dent from one another, and individual y  X  X  are dependent on corresponding o  X  X  and all the x  X  X . Note that it is not necessary to assume that the dependency exists between o  X  X  because it is already somehow captured by the dependency between y  X  X ; this also makes the model simple. CRF-QR is actually a graphical model, in which vertexes represent refined query words, edges dependencies, and conditional vertexes input query words, as depicted in Figure 1(b) (for ease of presentation, we show the case in which individual y  X  X  only depend on the corresponding o  X  X  and x  X  X ). Therefore, query refinement becomes the task of finding the sequence y  X  satisfying y  X  o  X  = arg max yo Pr( y , o | x ) .
In general, a graphical model can be written as a product of potential functions over the maximal cliques of the graph. In our case, there are two types of maximal cliques in the graph. One is the edge between y i  X  1 and y i , i = 1 , 2 ...n . (Here we assume that there is a start node y 0 ). The other is the edge between y i and o i conditioned on x , i = 1 , 2 ...n . Table 3: Query Refinement Tasks and Correspond-ing Operations Therefore, we have where  X  ( y i  X  1 , y i ) is the potential function associated with ciated with edge y i and o i , and Z is the normalizing factor. The potential functions are strictly positive and real valued functions.

Here we assume that the potential functions are exponen-tial functions. Then we have denotes parameter. Substituting Equation (2) and (3) into (1), we obtain the basic CRF-QR model Z ( x ) =
The refinement (refined word) at each position y i has a dependency on the operation at position o i and the entire input query x . In CRF-QR, we use features h ( y i , o i , x ) to represent the dependency relationship.

It is supposed that there exists dependency between ad-jacent words in y . This is reasonable because dependency should only exist between refined  X  X rue X  words. Instead, we do not need to assume that dependency exists between op-erations in o , because that has already been reflected in y . The independency assumption in o will also make the con-struction and utilization of the model efficient. Moreover, we do not need to model the dependency between ill-formed words in x , because correct inputs are all alike but every incorrect input may be incorrect in its own way. In CRF-QR, we use features f ( y i  X  1 , y i ) to represent the dependency relationship.

The CRF-QR model is suitable for query refinement and is easy to learn. With the embedding of the refinement oper-ations in the model, the number of parameters in CRF-QR P ( y , o | x ) becomes significantly smaller than that in the con-ventional CRF P ( y | x ) . First, the mapping from x  X  X  to y  X  X  will not be completely free. Given x and o , the possible y  X  X  will become limited. For example, if x and o are  X  X achin X  and insertion operation in spelling error correction respec-tively, then y can only be X  X achina X , X  X achine X , etc. It turns out, therefore, that o works as a constraint in the model to drastically reduce the space of y for given x . Next, since the number of operations is small (each task only has several operations), we can index the feature h ( y, o, x ) by indexing o . The learning of CRF-QR, then, becomes very efficient.
In learning, we assume that labeled data ( x (1) , y (1) , o . . . , ( x ( N ) , y ( N ) , o ( N ) ) is given, where x y ( i ) a refined query, and o ( i ) a sequence of operations i = 1 , . . . , N . Given the training data, we maximize the regular-ized log-likelihood function of the training data with respect to the model, and then obtain the parameter  X   X  . where C denotes coefficient and k X k 2 denotes L 2 norm. In this paper, we employ Quasi-Newton Method to conduct the optimization, specifically we use the L-BFGS algorithm [16]. Because the log-likelihood function is convex, it is guaran-teed that the global optimal solution will be found.
In prediction, given a query x we employ the Viterbi al-gorithm to find the most likely refined query y  X  satisfying
The feature f ( y i  X  1 , y i ) represents the relation on adjacent words y i  X  1 and y i in the refined query. We can define it as where Pr( y i | y i  X  1 ) denotes the conditional probability of ob-serving y i given y i  X  1 in a corpus. We can use, for example, bigrams in web pages or query logs to estimate the proba-bilities. These data are much larger than labeled data for training CRF-QR, and thus more accurate estimation can be obtained.

The feature h ( y i , o i , x ) , indexed by o i , represents the re-finement operation of o i from x i to y i , conditioned on x . It is defined as a binary feature in this paper: h ( y i , o i , x ) =
Note that h ( y i , o i , x ) can be simplified as h ( y i or h ( , o i , x i ) . For example, whether the frequency of query word x i is higher than the frequency of refined word y i the corpus when o i is insertion, or whether the refined word y is in the lexicon when o i is deletion, or whether the query word x i is a stop word when o i is substitution. In this paper, we make use of the following features: Lexicon-based feature representing whether a query word Position-based feature representing whether a query word Word-based feature representing whether a query word Corpus-based feature representing whether the frequency Query-based feature representing whether the query is a
If we assume that only one refinement task can be applied to a query word, then we may directly employ the basic CRF-QR model. In practice, multiple refinement tasks may be needed for a query word (e.g., spelling error correction and word stemming). Thus the use of the basic model is not enough.

We consider the use of an extended CRF-QR model in this case. In the extended model, we use multiple sequences of operations as well as their corresponding sequences of intermediate results. In this way, we keep the number of parameters the same as that in the basic CRF-QR model.
Suppose that for the query word x i , we have multiple sequences of operations on it, resulting in different refined words y i  X  X . One sequence of operations is denoted as ~o o i, 1 o i, 2 ,  X  X  X  , o i,m i where m i stands for number of operations in the sequence. Among the operations, one operation is from one task and generates one intermediate result (note that each task can only be applied once in each sequence). For the sequence of operations ~o i = o i, 1 o i, 2 ,  X  X  X  , o have a sequence of intermediate results ~z i = z i, 1 z i, 2 Here for convenience, we let z i, 0 = x i and z i,m i = y that m i can be different for different positions.
We retain all the possible sequences of refinement oper-ations on a query word and make a prediction at the final stage. Even though the number of possible sequences of refinement operations is of exponential order, we can still handle them when the number of tasks is small, which is the case in this paper. When the number of tasks becomes large, we can use heuristics to reduce the number of possible sequences. We leave it as future work.

Again we assume that the operations are mutually inde-pendent, while the adjacent words in the final output query are mutually dependent. Figure 2 shows the relationships.
Similarly, we define the conditional probability distribu-tion Pr( y , ~ o , ~ z | x ) = 1 Figure 2: Graphical representation of Extended CRF-QR as the extended CRF-QR model and employ it in query re-finement. Here, Z is the normalizing factor, and we have We can define features in a similar way as we do in the basic model. We can also use the same learning and prediction methods in the basic model for the extended model. Note that in prediction a refined word can be obtained by mul-tiple ways of combining operations (e.g., first splitting then insertion, or first insertion then splitting). In such cases, we just adopt the one in the predicted result.
In our experiments we made use of a real data set consist-ing of 10,000 queries. The queries were randomly selected from the query log of a commercial web search engine. The average length of queries is 2.8 words. Table 4 shows 20 randomly selected queries.

We asked four human annotators to manually refine the ill-formed queries. We considered four types (tasks) of re-finement and the human annotators only made corrections belonging to these types. The four types are spelling error correction, word merging, word splitting, and phrase seg-mentation (adding quotation operators to phrases). This is because for those types, we were able to define a clear guide-line. We leave the annotation of other types of refinement such as word stemming as future work. Note that for word stemming it is not easy to make a refinement judgment, be-cause the effectiveness of a refinement also depends on the contents of document collection. Even with four types of refinement, we are still able to verify the effectiveness of the model we propose in this paper. In the annotation, if there was a disagreement among the annotators, we took a majority vote.

Table 5 gives some statistics of the annotated data. Among the 10,000 queries, 6,421 queries are refined. Note that the majority of the refinements are phrase segmentation. Fur-thermore, there are 649 queries with multiple refinements. The labeled data were further divided into a training set con-taining 7,000 queries and a test set containing 3,000 queries.
For language model estimation, we made use of a collec-tion of 50 million web pages. Texts were extracted from the web pages and bigrams were then created from the data.
We adopted the cascaded approach and the generative approach as baselines.

The cascaded approach builds one sub-model for each of the four refinement tasks. The sub-models have the same model structure and feature set as the model in our ap-proach; the only difference is that each of them only ad-dresses one type of refinement. In testing, we sequentially connect the sub-models in different orders. In our experi-ments, we put phrase segmentation at the end (it seems rea-sonable to do so) and all the other three tasks in different permutations at the beginning. This gives us six options for the cascaded approach, denoted as Cascaded1  X  Cascaded6.
The generative approach exploits a Source Channel model and Mutual Information in query refinement. For spelling error correction, word splitting, and word merging, we use the Source Channel model. We assume that the model has equal translation probabilities (channel model) and we only use language probabilities (source model) in refined query selection. For phrase segmentation, we use Mutual Informa-tion to identify phrases [12] [17]. Specifically, we compute a Mutual Information score for each pair of adjacent words us-ing the corpus data; if it exceeds a predefined threshold, we skip it, otherwise, we set a phrase boundary at the position. Here the threshold is tuned to be optimal on the training set.
In this experiment, we compared the performances of dif-ferent approaches to query refinement. We made the evalu-ations at query level (note that a query may have several re-finements) and used precision (Pre.), recall (Rec.), F1 score (F1), and Accuracy (Acc.) as evaluation measures.
Table 6 shows the results of query refinement by our ap-proach (extended CRF-QR model) and the baseline meth-Table 6: Comparisons between CRF-QR and Base-lines on Query Refinement at Query Level (%) ods. From the results in Table 6, we can see that CRF-QR outperforms the baseline methods in terms of all measures. When compared with the best of the baseline, the relative improvement by CRF-QR is 2.26% and 1.21% in terms of F1 and accuracy respectively. We conducted a sign test on the results, which shows that all the improvements are sta-tistical significant (p-value &lt; 0.01).
 Table 7 gives the results of different refinement tasks of CRF-QR and the baseline methods. From the results, we can observe the same tendencies, that is, CRF-QR performs the best.

CRF-QR works better than all the cascaded methods, no matter which order we use for cascading. The result sug-gests that it is better to conduct query refinement tasks in a unified framework. The performance of the generative ap-proach is the lowest, indicating that using only a Statistical Language model and Mutual Information in query refine-ment is not sufficient. With the use of additional features and a discriminative model, CRF-QR can achieve a much better performance than the generative approach.
We conducted analysis on the refinement results to see the differences between CRF-QR and the baseline methods. It seems that the cascaded approach suffers from the neglect of mutual dependencies between query refinement tasks. For example, it could not correctly refine the query  X  X ypark hi-tel X  to  X  X y  X  X ark hotel X  X . Specifically, it could not simultane-ously change  X  X itel X  to  X  X otel X  and change  X  X ypark X  to  X  X y park X , because one operation needed to leverage the result of the other. Furthermore, in the cascaded approach, an error made at an early stage can be propagated to the later stages. In one option, the cascaded approach conducted spelling er-ror correction first, and then word splitting, word merging, and phrase segmentation. It incorrectly altered the query  X  X ankin las vegas X  into  X  X anking  X  X as vegas X  X , while the ideal output would be  X  X ank in  X  X as vegas X  X . It failed in that case, because  X  X ankin X  was incorrectly changed to  X  X anking X  at the beginning and there was no chance to reverse the deci-sion later.

It seems that one can carry out the learning for query re-finement more effectively by training a unified model (CRF-QR) at one time than from training several sub-models sep-arately. We used the sub-models in the cascaded approach separately for the corresponding tasks in testing (note that in the cascaded approach the sub-models were trained inde-pendently in training and cascaded together in testing). We then forcibly replaced the parameters in the sub-models with the corresponding parameters in the unified model (CRF-QR), and used the new sub-models in the testing again. We Table 8: Comparisons between Unified and Inde-pendent Training on Refinement Tasks (%)
Segmentation Independent 67.47 50.71 57.90 made comparisons between the two cases. Table 8 shows the results. We can see that the use of parameters trained in a unified framework (Unified) outperforms the use of the pa-rameters trained independently (Independent). This seems to indicate that even for addressing individual refinement tasks, it is still better to consider the effects of all the tasks together in training.

The generative approach produced more incorrect results because it could only rely on the Statistical Language model and Mutual Information scores in its prediction. For exam-ple, it altered the query  X  X ick up stix X  to  X  X ick up six X , and altered the query  X  X oor to door X  to  X  X  X oor to X  door X . These types of errors occurred mainly because the information used was insufficient for making correct refinement decisions.
We further made error analysis on CRF-QR. There were three types of errors. (1) Errors were mainly made by one of the refinement tasks. This is also reflected in the experiment results in Table 7; for a few tasks, the recall of CRF-QR is lower than the generative approach. For example, CRF-QR could not recognize the spelling error in the query  X  X arnell roberts X , where  X  X arnell X  should be  X  X ernell X . We may re-duce such kinds of errors by either adding new features or increasing the data size for language model training. (2) Another error type, although rare, was caused by a com-petition between refinement tasks. For example, the query  X  X kate board dudes X  was changed to  X  X  X kate board X  dudes X  by CRF-QR, while the ideal output would be  X  X kateboard dudes X . CRF-QR could not make a correct refinement be-cause the refined query generated by applying phrase seg-mentation has a higher probability than the one generated by applying word merging. These sorts of errors are also related to features and training data size. (3) Some queries were difficult to refine even for humans, since they were short and included unknown words. This was particularly true for phrase segmentation. For example, the query  X  X hio buckeye Table 9: Results on Relevance Search with Entire Query Set (NDCG@3) Table 10: Results on Relevance Search with Refined Queries (NDCG@3) Human (Upper Bound) 2023 0.254 0.312 (+22.8%)
CRF-QR 1546 0.258 0.304 (+17.7%) card X  was changed to  X  X  X hio buckeye X  card X , while the ideal refinement would be  X  X hio  X  X uckeye card X  X . We evaluated CRF-QR in search relevance improvements. As a relevance measure, we utilized the Normalized Dis-counted Cumulative Gain (NDCG@3)[9].

We submitted the original queries and the refined queries in the test set to a commercial search engine. For each query the system returned 10 to 1,000 results. We asked human annotators to make judgments on the relevance of the top 3 documents with respect to the queries. There are five levels of relevance: perfect, excellent, good, fair, and bad.
Table 9 shows the results.  X  X efore X  stands for the results before query refinement and  X  X fter X  stands for the results after it. The numbers in the parentheses are the relative im-provement. The results indicate that when applied in web search, CRF-QR can help significantly improve search rele-vance. NDCG@3 can be enhanced by 8.7%. Table 10 shows the results on relevance search using only the refined queries. When we only look at the results of the refined queries, CRF-QR can help improve NDCG@3 by about 17.7%. We conducted a t-test on the results, which indicate that all the improvements are statistically significant (p-value &lt; 0.01). In the tables we include the search results using human refined queries that work as upper bounds of CRF-QR.
 We also investigate the influence of each refinement task. Table 11 shows the relevance search results by refinement tasks. We can see that all refinement tasks can help improve the relevance. Spelling error correction seems to be most effective, even though the number of affected queries is not very large. Phrase segmentation affects more queries, even though its improvement on relevance is the smallest. T-test results show that all the improvements are statistically significant (p-value &lt; 0.01). Table 11: Results on Relevance Search by Query Refinement Tasks (NDCG@3)
We have investigated the problem of query refinement, which is changing ill-formed queries for users before submit-ting them to the search engine. Query refinement includes a number of tasks such as spelling error correction, word split-ting, word merging, phrase segmentation, word stemming, and acronym expansion.

Previous work addressed the problem either separately or by using generative models. In this paper we show that employing a unified and discriminative model in query re-finement is effective. Since the query refinement tasks usu-ally are mutually dependent, it is better to employ a uni-fied framework to enhance the performance. Furthermore, employing a discriminative model can achieve better perfor-mance than employing a generative model if there is enough labeled training data.

We describe our new CRF model for performing query refinement, called CRF-QR. The model is unique in that it predicts a sequence of refined query words as well as corre-sponding operations given a sequence of query words. There are two variants of the model: a basic model and an extended model.

Experimental results on a large real data set show that our approach significantly outperforms the cascaded approach and generative approach. The results indicate that for query refinement it is better to adopt the CRF-QR model pro-posed in this paper. Experimental results also show that when using the refined queries with CRF-QR, a significant improvement can be obtained on search relevance.

There are other types of query refinement that have the potential to improve search relevance, but are not investi-gated in this paper, for example, word stemming and acronym expansion. We plan to investigate these problems in the fu-ture. The proposed unified and discriminative model would not be limited to query refinement. It is potentially useful for other query transformation problems, for example, trans-formation of natural language queries to phrasal queries. We plan to investigate these issues as well.
