 Basic content personalization consists in matching up the attributes of a user profile, in which preferences and interests are stored, with the attributes of a content object. The Web 2.0 (r)evolution and the advent of user generated content have changed the game for personalization, since the role of people has evolved from passive consumers of information to that of active contributors. One of the forms of user generated content that has drawn more attention from the research community is folksonomy , a taxonomy generated by users who collaboratively annotate and categorize resources of interests with freely chosen keywords called tags .
In this paper, we investigate whether folksonomies might be a valuable source of information about user interests. The main contribution is a strategy that enables a content-based recommender to infer user interests by applying machine learning techniques both on the  X  X fficial X  item descriptions provided by a publisher, and on tags which users adopt to freely annotate relevant items. Static content and tags are preventively analyzed by advanced linguistic techniques in order to capture the semantics of the user interests often hidden behind keywords. The proposed approach has been evaluated in the context of cultural heritage personalization. Preliminary experiments involving 30 real users show an im-provement in the predictive accuracy of the tag-augmented recommender compared to the pure content-based one. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing methods, Linguistic pro-cessing ; H.3.3 [ Information Storage and Retrieval ]: In-formation Search and Retrieval X  Information filtering Algorithms, Experimentation Recommender Systems, Machine Learning, Collaborative Tag-ging, Word Sense Disambiguation Web 2.0 is a term describing the trend in the use of World Wide Web technology that aims at promoting information sharing and collaboration among users. Web 2.0 allows users to do more than just retrieving information since it is based upon an  X  X rchitecture of participation X  that encourages the generation and distribution of content.

User generated content (UGC) refers to various kinds of media content, publicly available, that are produced by end-users. For example, on Amazon.com the majority of content is prepared by administrators, but numerous user reviews of the products being sold are submitted by regular visi-tors to the site. One of the forms of UGC that has drawn more attention from the research community is tagging ,the act of annotating resources of interests with free keywords, called tags , thus building a socially-constructed classification schema, called a folksonomy . Folksonomy is a portmanteau of the words folk and taxonomy, hence a folksonomy is a user generated taxonomy.

In this paper, we have begun to investigate whether folk-sonomies might be a valuable source of information about user interests and how to exploit them in existing content-based filtering algorithms. The goal of the paper can be formulated in form of the following research question: Does the integration of tags cause an increase of the prediction accuracy in the process of recommending items to users?
This paper presents an approach in which the process of learning user profiles is performed both on textual descrip-tions of items (hereafter, static content, in contrast with dynamic content provided by users) and tags. This research has been conducted within the CHAT project (Cultural Her-itage fruition &amp; e-learning applications of new Advanced multimodal Technologies), that aims at developing new sys-tems and services for multimodal fruition of cultural heritage content. Data has been gathered from the collections of the Vatican picture-gallery, for which both images and detailed textual information of paintings were available, and letting users involved in the study both rate and annotate them with tags.

The paper is structured as follows. Section 2 provides details about the strategies adopted by the content-based recommender for semantic document indexing and profile learning. Section 3 describes how users X  tagging activity is handled by the recommender when building user profiles. Section 4 presents the experimental session carried out to evaluate the proposed idea and discusses the main findings of the study. Related work are briefly analyzed in Section 5, while conclusions and directions for future work are drawn in Section 6.
ITem Recommender (ITR) [3] is a content-based recom-mender system, developed at the University of Bari. The system is capable of providing recommendations for items in several domains (e.g., movies, music, books), provided that descriptions of items are available as text documents (e.g. plot summaries, reviews, short abstracts). In the following, we will refer to documents as textual descriptions of items to be recommended. Figure 1 shows the general architecture of ITR. The recommendation process is performed in three steps, each of which is handled by a separate component: 1) Content Analyzer : It allows introducing semantics in the recommendation process by analyzing documents in or-der to identify relevant concepts representing the content. This process selects, among all the possible meanings (senses) of each polysemous word, the correct one according to the context in which the word occurs. In this way, documents are represented using concepts instead of keywords, in an attempt to overcome the problems due to natural language ambiguity. The final outcome of the preprocessing step is a repository of disambiguated documents. This semantic indexing is strongly based on natural language processing techniques, such as Word Sense Disambiguation (WSD), and heavily relies on linguistic knowledge stored in the Word-Net lexical ontology. Details are provided in Section 2.1. 2) Profile Learner : It implements a supervised learning technique for learning a probabilistic model of the interests of the active user from disambiguated documents rated ac-cording to her interests. This model represents the semantic profile, which includes those concepts that turn out to be most indicative of the user preferences. More details are provided in Section 2.2. 3) Recommender : It exploits the user profile to suggest relevant documents, by matching concepts contained in the semantic profile against those contained in documents to be recommended. More details are provided in Section 2.2.
In order to build semantic user profiles based on the mean-ings of words found in a training set of documents, a concept-based document representation is adopted. This requires a repository for word senses and an automated procedure for assigning the proper sense to each word occurring in a doc-ument.

As regards the first problem, WordNet version 2.0 has been embodied in the semantic indexing module. The ba-sic building block for WordNet is the synset ( SYN onym SET ), a structure containing sets of words with synonymous meanings, which represents a specific meaning of a word.
As regards the second problem, in Natural Language Pro-cessing the task of WSD consists exactly in determining which sense of an ambiguous word is suitable for a specific occurrence of that word in a document [11]. Our WSD al-gorithm, called JIGSAW, takes as input a document d = [ w 1 ,w 2 ,...,w h ] encoded as a list of words in order of their appearance, and returns a list of WordNet synsets X = [ s ,s 2 ,...,s k ]( k  X  h ), in which each element s j is obtained by disambiguating the target word w i basedonthe seman-tic similarity of w i with the words in its context, that is a set of words that precede and follow w i .Noticethat k  X  h because some words, such as most proper names, might not be found in WordNet , or because of bigram recognition. Semantic similarity computes the relatedness of two words. We adopted the Leacock-Chodorow measure [10], which is based on the length of the path between concepts in a IS-A hierarchy. The complete description of the WSD strategy adopted is not described here, because already published in [17]. What we would like to point out here is that the WSD procedure allows to obtain a synset-based vector space representation, called bag-of-synsets (BOS), that is an ex-tension of the classical bag-of-words (BOW) model. In the BOS model a synset vector, rather than a word vector, cor-responds to a document. ITR is able to suggest potentially relevant items to users, as long as item properties can be rep-resented in form of textual slots . The adoption of slots does not jeopardize the generality of the approach, since the case of documents not structured into slots corresponds to have just a single slot in our document representation strategy. The text in each slot is represented by the BOS model by counting separately the occurrences of a synset in the slots in which it appears. More formally, assume that we have a collection of N documents structured in M slots. Let s be the index of the slot, the n -th document is reduced to M bags of synsets, one for each slot: where t s nk is the k -thsynsetinslot s of document d n and D ns is the total number of synsets in slot s of document d For all n , k and s , t s nk  X  V s , which is the vocabulary for the slot s (the set of all different synsets found in slot s ). Document d n is finally represented in the vector space by M synset-frequency vectors: where w s nk is the weight of the synset t k in the slot s of doc-ument d n and can be computed in different ways: it can be the frequency of synset t k in s or a more complex feature weighting score. All the text operations performed on doc-uments are provided by a NLP tool developed at University of Bari, called META [1]. By invoking META on a text t ,wegetMETA( t )=( x, y ), where x is the BOS contain-ing the synsets obtained by applying JIGSAW on t ,and y is the corresponding synset-frequency vector. BOS-indexed documents are used in a content-based information filtering scenario for learning accurate sense-based user profiles, as discussed in the following section.
We consider the problem of learning user profiles as a binary Text Categorization task [16] since each document has to be classified as interesting or not with respect to the user preferences. Therefore, the set of categories is restricted to c + ,thepositiveclass( user-likes ), and c  X  thenegativeone ( user-dislikes ). The algorithm for inferring user profiles is na  X   X ve Bayes text learning, widely adopted in content-based recommenders[14]. Although na  X   X ve Bayes performances are not as good as some other statistical learning methods such as nearest-neighbor classifiers or support vector machines, it has been shown that it can perform surprisingly well in the classification tasks where the computed probability is not important [5]. Another advantage of the na  X   X ve Bayes approach is that it is very efficient and easy to implement compared to other learning methods.

There are two different probabilistic models in common use, both of which assume that all features are indepen-dent of each other, given the context of the class. In the multivariate Bernoulli model a document is a binary fea-ture vector over the space of words representing whether each word is present or absent. In contrast, the multinomial model captures word frequency information in documents: when calculating the probability of a document, the proba-bility of the words that occur are multiplied. Although the classifiers based on the multinomial model significantly out-perform those based on the multivariate model at large vo-cabulary sizes [12], their performance is unsatisfactory when: 1) documents in the training set have different lengths, thus resulting in a rough parameter estimation; 2) handling rare categories (few training documents available).

These conditions frequently occur in the user profiling task, where no assumptions can be made on the length of training documents, and where obtaining an appropriate set of negative examples (i.e., examples of the user-dislikes class) is problematic. Indeed, since users do not perceive having immediate benefits from giving negative feedback to the sys-tem [15], the training set for the class user-likes might be often larger than the one for the class user-dislikes.
In [8], the authors propose a multivariate Poisson model for na  X   X ve Bayes text classification that allows more reason-able parameter estimation under the above mentioned con-ditions. We adapt this approach to the case of user profiling task. The probability that a document d j belongs to a class c ( user-likes / user-dislikes ) is calculated by the Bayes X  theo-rem as follows:
If we set: then Eq. (1) can be rewritten as:
Using Eq. (3), we can get the posterior probability P ( c by calculating z jc . In the Poisson model proposed in [8] for learning the na  X   X ve Bayes text classifier: where | V | is the vocabulary size, w ij is the frequency of term t in d j ,  X  ic (  X  ic ) is the Poisson parameter that indicates the number of occurrences of t i in the positive (negative) training documents on average. The flexibility of this model relies on the fact that it can be expanded by adopting various methods to estimate w ij ,  X  ic and  X  ic .

In the following, the strategies we defined to adapt this model for the specific task of user profiling are described.
The first adaption is needed because, as described in Sec-tion 2.1, documents are subdivided into slots, therefore the model should take into account that d j is the concatena-tion of M documents d s j , M being the number of slots, s =1 ,...,M . Accordingtona  X   X ve assumption of features independence, slots are independent of each other, given the class (i.e. the token probabilities for one slot are indepen-dent of the tokens that occur in other slots), therefore: then Eq. (1) can be rewritten as: If we set: then Eq. (6) can be rewritten as: In the Poisson model with slots, Eq. (4) becomes: where w s ij is the frequency of term t i in the slot s of d
Using Eq. (6) and (9), the posterior probability P ( c | can be computed by estimating the Poisson parameters  X  s ic and  X  s ic . Since we want to normalize term frequencies ac-cording to document lengths, we compute  X  s ic (  X  s ic )asan average of normalized frequency of t i in the slot s over the number of documents in class c (  X  c ):  X  where D c ( D  X  c ) is the number of documents in class c (  X  c ), avgtf s j is the average frequency of a token in the slot s of d while avgtf s is the average frequency of a token in the slot s in the whole collection. This linear combination smoothes the term frequency using the characteristic of the entire doc-ument collection.

For the training step we assume that each user provided ratings on items using a discrete scale between MIN ( strongly dislikes )and MAX ( strongly likes ). Items whose ratings are greater than or equal to ( MIN + MAX ) / 2 are supposed to be liked by the user and included in the positive training set, while items with lower ratings are included in the negative training set. The user profile is learned from rated items by adopting the above described approach.

Therefore, given a new document d j , the recommenda-tion step consists of computing the a-posteriori classifica-tion scores P ( c + | d j )and P ( c  X  | d j ) (Eq. 6) by using Poisson parameters for synsets estimated in the training step as in Eq. (10). Classification scores for the class c + are used to produce a ranked list of potentially interesting items, from which items to be recommended might be selected.
The inceptive idea behind this paper is to include folk-sonomies in ITR by integrating static text describing items with dynamic UGC (tags).

Tags are collected during the training step, by letting users: 1) express their preferences for items by entering a numerical rating and 2) annotate rated items with free tags.
Givenanitem I , the set of tags provided by all the users who rated I is called SocialTags(I) , while the set of tags pro-vided by a specific user U on I is called PersonalTags(U,I) . PersonalTags(U) is the set of tags provided by U on all the items in the collection. Tags are stored in a further slot besides those containing static content.

For example, in the context of cultural heritage personal-ization, an artwork can be generally represented by at least three slots, namely artist , title ,and description .Provided that users have a digital support to annotate artifacts, tags can be easily stored in a fourth slot, say tags , which is not static as the other three slots because tags evolve over time.
The distinction between personal and social tags aims at evaluating whether including either just personal tags or so-cial tags in the user profile produces beneficial effects on the recommendations. The inclusion of social tags in the per-sonal profile of a user allows also to extend the pure content-based recommendation paradigm previously adopted by ITR, toward a hybrid content-c ollaborative paradigm.

The architecture described in Figure 1 has been modi-fied in order to include tags in the recommendation process. The main adaptation was due to the need of defining an ap-propriate indexing strategy for the slot containing tags, in addition to that already defined for static slots (Figure 2).
Since tags are freely chosen by users and their actual meaning is usually not very clear, the identification of user interests from tags is a challenging task. We faced such a problem by applying WSD to tags as well. This process allows us to enhance the document model from represent-ing tags as mere keywords or strings, to exploiting tags as pointers to WordNet synsets ( semantic tags ).

Semantic tags are obtained by disambiguating tags in a folksonomy, thus producing as a result a synset-based folk-sonomy . More specifically, we define SemanticSocialTags(I) the set of synsets obtained by disambiguating SocialTags(I) . In fact, META applied to SocialTags(I) produces the synset-based folksonomy corresponding to SocialTags(I) . Seman-ticPersonalTags(U,I) is the set of synsets obtained by dis-ambiguating the tags given by U on I ,thusitistheresult of invoking META on PersonalTags(U,I) .
 The algorithm used by META for tag disambiguation is JIGSAW, with a different setting for the context, compared to that adopted for disambiguating static content. While for static content the context for the target word is the text in the slot in which it occurs, this strategy is not suitable for tags, since the number of tags provided by users is generally small. This may result in a poor context and consequently in a high percentage of WSD errors on tags. The intent is to exploit a more reliable context, when available. Therefore, whether the target tag occurs in one of the static slots, the text in that slot is used as a context, otherwise we are forced to accept other tags as a context.

Semantic tags are exploited by the Profile Learner to in-clude information about tags in the user profiles. The pro-file learning process for user U starts by selecting all items (disambiguated documents) and corresponding ratings pro-vided by U . Items are subdivided into positive and negative training set depending on the ratings, in the same way as described in Section 2.2. Let TR + and TR  X  be the posi-tive and negative training set for user U . Different options for generating the user profile can be chosen at this point, depending on the type of content involved in the process.
If we would like to infer a user profile strictly related to personal preferences ( one-to-one user profile), all the seman-tic tags obtained from personal tags provided by U on all items she rated should be exploited in the learning step. This means that, for each d j  X  TR +  X  TR  X  , the additional slot for d j is SemanticPersonalTags(U, d j ) .

On the other hand, if we would like to build a content-collaborative profile for U , semantic tags obtained from so-cial tags provided by users on all items rated by U should be exploited in the learning step.

This means that, for each d j  X  TR +  X  TR  X  , the additional slot for d j is SemanticSocialTags( d j ) .

We performed several experiments, described in Section 4, in order to evaluate the accuracy of profiles generated by adopting different choices on the type of content included in the learning step.
 The generation of the user profile is performed by the Profile Learner , which infers the profile as a binary text classifier, as described in Section 2.2.

The profile contains the user identifier and the a-priori probabilities of liking or disliking an item. Moreover, the profile is structured in two main parts: profile like contains features describing the concepts able to deem items relevant, while features in profile dislike should help in filtering out not relevant items. Each part of the profile is structured in four slots, resembling the same representation strategy adopted for items, which in this case are artworks repre-sented by title , artist , description and tags .Eachslotre-ports the features ( WordNet identifiers) occurring in the training examples, with corresponding frequencies computed in the training step. Frequencies are used by the Bayesian learning algorithm to induce the classification model (i.e. the user profile) exploited to suggest relevant items in the recommendation phase.
The goal of the experimental evaluation was twofold: 1. to evaluate the predictive accuracy of ITR when dif-2. to investigate which type of content produces the most
The dataset considered for the experiments is represented by 45 paintings chosen from the collection of the Vatican picture-gallery. The dataset was collected using screenscrap-ing bots, which captured the required information from the official website 1 of the Vatican picture-gallery. In particular, http://mv.vatican.va/3_EN/pages/PIN/PIN_Main.html for each element in the dataset an image of the artifact was collected, along with three textual properties, namely its ti-tle, artist, and description (a short overview of the painting). A set of 30 volunteer users took part in the experiments. The average age of the users was 25. None of the users was an art critic or expert.

Users were requested to interact with a web application (Figure 3), to express their preferences for all the 45 paint-ings in the collection. The preference was expressed as a nu-merical vote on a 5-point scale (1=strongly dislike, 5=strongly like). Moreover, users were left free to annotate the paint-ings with as many tags as wished. For the 45 paintings in the dataset, 4300 tags were used. Some statistics about tag distribution in the dataset are reported in Table 1.
Each user provided about 3 tags for each rated item. The overall number of tags given by a user is about 143, thus the additional workload due to tagging activity is quite mod-erate. The average number of tags associated with each painting is about 95, thus experiments relied on a sufficient number of user annotations.

Since ITR is conceived as a text classifier, its effective-ness can be evaluated by classification accuracy measures, namely Precision and Recal l [16]. Precision ( Pr ) is defined as the number of relevant selected items divided by the num-ber of selected items. Recall ( Re ) is defined as the number of relevant selected items divided by the total number of relevant items available. F  X  measure, a combination of pre-cision and recall, is also used to have an overall measure of predictive accuracy (  X  sets the relative degree of importance attributed to Pr and Re ).

For the evaluation of recommender systems, these mea-Table 2: Results of the K-fold Cross Validation Type of content Pr Re F  X  =0 . 5 sures have been used in [7]. Since users should trust the recommender, it is important to reduce false positive errors. It is desirable to provide users with short lists of relevant items (even if not all the possible relevant items are sug-gested), rather than longer lists containing a greater number of relevant items, mixed-up with not relevant ones. There-fore, we set  X  =0 . 5for F  X  measure, in order to give more weight to precision.

These classification measures do not consider predictions and their deviations from actual ratings, they rather com-pute the frequency with which a recommender system makes correct or incorrect decisions about whether a painting is advisable for a user. We adopted these specific measures because we are interested in measuring how relevant asetof recommendations is for a user. In the experiment, a paint-ing is considered as relevant by a user if the rating is greater than or equal to 4, while ITR considers a painting as rel-evant if the a-posteriori probability of class likes is greater than 0 . 5. We designed 5 different experiments, depending on the type of content used for training the system: Exp #1: Static Content -only title, artist and descrip-tion of the painting, as collected from the official website of the Vatican picture-gallery Exp #2: SemanticPersonalTags(U,I) Exp #3: SemanticSocialTags(I) Exp #4: Static Content+Semant icPersonalTags(U,I) Exp #5: Static Content+Sem anticSocialTags(I) All experiments were carried out using the same methodol-ogy, consisting in performing one run for each user, sched-uled as follows: 1. select the appropriate content; 2. split the data into a training set Tr and a test set Ts ; 3. use Tr for learning the corresponding user profile; 4. evaluate the predictive accuracy of the profile on Ts .
The methodology adopted for obtaining Tr and Ts was the K-fold cross validation [9], with K = 5. Given the size of the dataset (45), applying a 5-fold cross validation technique means that the dataset is divided into 5 disjoint partitions, each containing 9 paintings. The learning of profiles and the test of predictions were performed in 5 steps. At each step, 4 (K-1) partitions were used as the training set Tr ,whereas the remaining partition was used as the test set Ts .The steps were repeated until each of the 5 disjoint partitions was used as the Ts . Results were averaged over the 5 runs.
Results of the 5 experiments are reported in Table 2, av-eraged over the 30 users. The first outcome is that the in-tegration of social or personal tags causes a significant in-crease of precision in the process of recommending artifacts to users. More specifically, precision of profiles learned from both static content and tags (hereafter, augmented profiles) outperformed the precision of profiles learned from either static content (hereafter, content-based profiles) or just tags (hereafter, tag-based profiles). The improvement ranges be-tween 2 . 05% and 2 . 45%. The significant increase in precision of augmented profiles, compared to pure content-based ones, corresponds to a slight and physiological loss of recall.
Another interesting finding is that precision of content-based profiles is comparable with that of tag-based profiles. Although this result may suggest that just tags are suffi-cient for providing accurate recommendations, a decrease of recall (-1.62% with personal tags, -3.77% with social tags) actually shows that static content cannot be ignored even when tags are available. The higher decrease of recall reg-istered with social tags leads to conclude that community tags introduce some noise in the recommendation process (relevant paintings are filtered out due to wrong advice by other users).

The general conclusion of the experiment is that the high-est overall accuracy is reached when augmented profiles are exploited in the recommendation process ( F  X  greater than 80%). In order to test whether these results are still valid when fewer training examples are available, the previous ex-periments were repeated by using a variant of the 5-fold cross validation, in which we can decide the number H of folds to use for training. The dataset is divided into 5 dis-joint partitions (folds). The learning of profiles and the test of predictions were performed in 5 H steps. At each step, H folds are used as the training set, whereas the remaining 5  X  H are used for testing. The steps were repeated until each group of H folds was used as the training set. Results were averaged over the 5 H steps.

The learning curve for F  X  is depicted in Figure 4. It is worth to notice that, in the worst learning condition ( H =1, i.e. only 9 examples are provided), profiles inferred using just social tags are the most accurate ( F  X  = 72.83). This result seems to be in conflict with the result of the previ-ous experiment, where augmented profiles outperformed all the other types of profiles. Indeed, this may be a clear in-dication that the profile learn ing process should rely more on annotations provided by the community than on content rated or annotated with personal tags by individual users.
By setting H =2or H = 3, i.e. 18 or 27 examples are provided, more evidence about preferences of individual users is available, therefore the profile learning process might depend more on content or personal tags. Indeed, content-based profiles and augmented profiles using only personal tags outperformed all the other types of profiles. The accu-racy of profiles inferred using just social tags is the lowest, thus revealing an opposite trend compared to the experiment with H =1.
To the best of our knowledge, few studies investigated on how to exploit tag annotations in order to build user profiles.
In [4], the user profile is represented in the form of a tag vector, with each element indicating the number of times a tag has been assigned to a document by that user. A more sophisticated approach is proposed in [13], which takes into account tag co-occurrence. The matching of profiles to infor-mation sources is achieved by using simple string matching. As the authors themselves foresee, the matching could be enhanced by adopting WordNet , as in the semantic docu-ment indexing strategy proposed in this paper.

In the work by Szomszor et al. [19], the authors describe a movie recommendation system built purely on the key-words assigned to movies via collaborative tagging. Recom-mendations for the active user are produced by algorithms based on the similarity between the keywords of a movie and those of the tag-clouds of movies she rated. As the authors themselves state, their recommendation algorithms can be improved by combining tag-based profiling techniques with more traditional content-based recommender strategies, as in the approach we have proposed. In [6], different strate-gies are proposed to build tag-based user profiles and to exploit them for producing music recommendations. Tag-based user profiles are defined as collections of tags, which have been chosen by a user to annotate tracks, together with corresponding scores representing the user interest in each of these tags, inferred from tag usage and frequencies of lis-tened tracks.

While in the above described approaches only a single set of popular tags represents user interests, in [22] it is observed that this may not be the most suitable representation of a user profile, since it is not able to reflect the multiple interests of users. Therefore, the authors propose a network analysis technique (based on clustering), performed on the personal tags of a user to identify her different interests. The main differences between the tag-based profiling process proposed in this paper and the previously discussed ones are: 1. we propose a hybrid strategy that learns the profile of 2. we elaborate on including in the profile of user U not 3. we propose a solution to the challenging task of identi-
When focusing on the application of personalization tech-niques in the context of cultural heritage, it is worth to no-tice that museums have recognized the importance of provid-ing visitors with personalized access to artifacts.The projects PEACH (Personal Experience with Active Cultural Her-itage) [18] and CHIP (Cultural Heritage Information Per-sonalization) [21] are only two examples of the research ef-fort devoted to support visitors in fulfilling a personalized experience and tour when visiting artworks collections. In particular, the recommender system developed within CHIP aims at providing personalized access to the collections of the Rijksmuseum in Amsterdam. It combines Semantic Web technologies and content-based algorithms for inferring vis-itors X  preference from a set of scored artifacts and then, recommending other artworks and related content topics. The Steve.museum consortium [20] has begun to explore the use of social tagging and folksonomy in cultural heritage personalization scenarios, to increase audience engagement with museums X  collect ions. Supporting so cial tagging of ar-tifacts and providing access based on the resulting folkson-omy, open museum collections to new interpretations, which reflect visitors X  perspectives rather than curators X  ones, and helps to bridge the gap between the professional language of the curator and the popular language of the museum vis-itor. Preliminary explorations conducted at the Metropoli-tan Museum of Art of New York have shown that profes-sional perspectives differ significantly from those of na  X   X ve visitors. Hence, if tags are associated to artworks, the result-ing folksonomy can be used as a different and valuable source of information to be carefully taken into account when pro-viding recommendations to museum visitors.
In this paper we have investigated how to effectively com-bine a content-based filtering algorithm with tags. The main contribution of the paper is a multivariate Poisson model for na  X   X ve Bayes text classification adapted to infer user profiles from both static content, as in classical content-based rec-ommender, and tags provided by users to freely annotate items. Being free annotations, tags also tend to suffer from syntactic problems, like polysemy and synonymy. We faced such a problem by applying WSD to content as well as tags.
Experiments were carried ou tinthecontextofcultural heritage personalization in order to evaluate the predictive accuracy of the proposed recommender system when differ-ent types of content are used in the training step (pure con-tent, personal tags, social tags, content combined with tags). The main outcome of the experiments is that the highest overall accuracy is reached when profiles learned from both content and tags are exploited in the recommendation pro-cess, while profiles learned from just social tags are the most accurate when a training set with very few examples is avail-able to the system. To gain more insights on the effects of community-generated content, we need to 1) perform an analysis of what tags are used to build the folksonomies and how they affect the user profile generation; 2) replicate the experiments with a more heterogeneous community, involv-ing experts in the art domain so as to identify differences with the tagging activity of na  X   X ve users.
 This research was partially funded by Regione Puglia un-der the contract  X  X istretto digitale a supporto della filiera produttiva del tessile e abbigliamento X  and by MIUR (Mi-nistero dell X  X niversit` a e della Ricerca) under the contract Legge 297/99, Prot.691 CHAT  X  X ultural Heritage fruition &amp; e-Learning applications of new Advanced (multimodal) Technologies X  (2006-08).

The authors are grateful to Cataldo Musto, Fedelucio Nar-ducci and Massimo Bux for their effort in performing the experimental evaluation. [1] P. Basile, M. de Gemmis, A. Gentile, L. Iaquinta, [2] F. Carmagnola, F. Cena, O. Cortassa, C. Gena, and [3] M. Degemmis, P. Lops, and G. Semeraro. A [4] J. Diederich and T. Iofciu. Finding communities of [5] P. Domingos and M. J. Pazzani. On the optimality of [6] C.S.Firan,W.Nejdl,andR.Paiu.Thebenefitof [7] J.L.Herlocker,J.A.Konstan,L.G.Terveen,and [8] S.-B. Kim, K.-S. Han, H.-C. Rim, and S.-H. Myaeng. [9] R. Kohavi. A study of cross-validation and bootstrap [10] C. Leacock, M. Chodorow, and G. Miller. Using [11] C. Manning and H. Sch  X  utze. Foundations of Statistical [12] A. McCallum and K. Nigam. A comparison of event [13] E. Michlmayr and S. Cayzer. Learning User Profiles [14] D. Mladenic. Text-learning and related intelligent [15] I. Schwab, A. Kobsa, and I. Koychev. Learning user [16] F. Sebastiani. Machine learning in automated text [17] G. Semeraro, M. Degemmis, P. Lops, and P. Basile. [18] O. Stock, M. Zancanaro, P. Busetta, C. Callaway, [19] M. Szomszor, C. Cattuto, H. Alani, K. O X  X ara, [20] J. Trant and B. Wyman. Investigating social tagging [21] Y.Wang,L.Aroyo,N.Stash,andL.Rutledge.
 [22] C. M. A. Yeung, N. Gibbins, and N. Shadbolt. A [23] S. Zhao, N. Du, A. Nauerz, X. Zhang, Q. Yuan, and
