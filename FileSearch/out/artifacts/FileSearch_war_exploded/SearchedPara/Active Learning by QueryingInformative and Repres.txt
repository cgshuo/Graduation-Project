 In this work, we focus on the pool-based active learning, whi ch selects an unlabeled instance from a given pool for manually labeling. There are two main criter ia, i.e., informativeness and represen-tativeness, that are widely used for active query selection . Informativeness measures the ability of an instance in reducing the uncertainty of a statistical mod el, while representativeness measures if an instance well represents the overall input patterns of un labeled data [16]. Most active learning algorithms only deploy one of the two criteria for query sele ction, which could significantly limit the performance of active learning: approaches favoring infor mative instances usually do not exploit the structure information of unlabeled data, leading to seriou s sample bias and consequently undesirable performance for active learning; approaches favoring repr esentative instances may require querying a relatively large number of instances before the optimal de cision boundary is found. Although sev-eral active learning algorithms [19, 8, 11] have been propos ed to find the unlabeled instances that are both informative and representative, they are usually a d hoc in measuring the informativeness and representativeness of an instance, leading to suboptim al performance.
 In this paper, we propose a new active learning approach by QU erying Informative and Represen-tative Examples (Q UIRE for short). The proposed approach is based on the min-max vie w of active learning [11], which provides a systematic way for measurin g and combining the informativeness and the representativeness. The interesting feature of the proposed approach is that it measures both the informativeness and representativeness of an instance by its prediction uncertainty: the informa-tiveness of an instance x is measured by its prediction uncertainty based on the label ed data, while the representativeness of x is measured by its prediction uncertainty based on the unlab eled data. The rest of this paper is organized as follows: Section 2 revi ews the related work on active learning; Section 3 presents the proposed approach in details; experi mental results are reported in Section 4; Section 5 concludes this work with issues to be addressed in t he future. Querying the most informative instances is probably the mos t popular approach for active learning. Exemplar approaches include query-by-committee [17, 6, 10 ], uncertainty sampling [13, 12, 18, 2] and optimal experimental design [9, 20]. The main weakness o f these approaches is that they are determined by a small number of labeled examples, making it p rone to sample bias. Another school of active learning is to select the instances that are most re presentative to the unlabeled data. These approaches aim to exploit the cluster structure of unlabele d data [14, 7], usually by a clustering method. The main weakness of these approaches is that their p erformance heavily depends on the quality of clustering results [7].
 Several active learning algorithms tried to combine the inf ormativeness measure with the represen-tativeness measure for finding the optimal query instances. In [19], the authors propose a sampling algorithm that exploits both the cluster information and th e classification margins of unlabeled in-stances. One limitation of this approach is that since clust ering is only performed on the instances within the classification margin, it is unable to exploit the unlabeled instances outside the margin. In [8], Donmez et al. extended the active learning approach i n [14] by dynamically balancing the uncertainty and the density of instances for query selectio n. This approach is ad hoc in combining the measure of informativeness and representativeness for query selection, leading to suboptimal performance.
 Our work is based on the min-max view of active learning, whic h was first proposed in the study of batch mode active learning [11]. Unlike [11] which measures the representativeness of an instance by its similarity to the remaining unlabeled instances, our proposed measure of representativeness takes into account the cluster structure of unlabeled insta nces as well as the class assignments of the labeled examples, leading to a better selection of unlabele d instances for active learning. We start with a synthesized example that illustrates the imp ortance of querying instances that are both informative and representative for active learning. F igure 1 (a) shows a binary classification problem with each class represented by a different legend. W e examine three different active learning algorithms by allowing them to sequentially select 15 data points. Figure 1 (b) and (c) show the data points selected by an approach favoring informative in stances (i.e., [18]) and by an approach favoring representative instances (i.e., [7]), respectiv ely. As indicated by Figure 1 (b), due to the sample bias, the approach preferring informative instance s tends to choose the data points close to the horizontal line, leading to incorrect decision boundar ies. On the other hand, as indicated by Figure 1 (c), the approach preferring representative insta nces is able to identify the approximately correct decision boundary but with a slow convergence. Figu re 1 (d) shows the data points selected by the proposed approach that favors data points that are bot h informative and representative. It is clear that the proposed algorithm is more efficient in finding the accurate decision boundary than the other two approaches.
 consists of n l labeled instances and n u = n  X  n l unlabeled instances, where each instance x Active learning selects one instance x s from the pool of unlabeled data to query its class label. For convenience, we divide the data set D into three parts: the labeled data D l , the currently selected instance x s , and the rest of the unlabeled data D u . We also use D a = D u  X  X  x s } to represent all by y a = [ y s , y u ] the class assignment for all the unlabeled instances. 3.1 The Framework To motivate the proposed approach, we first re-examine the ma rgin-based active learning from the viewpoint of min-max [11]. Let f  X  be a classification model trained by the labeled examples, i. e., where H is a reproducing kernel Hilbert space endowed with kernel fu nction  X  (  X  ,  X  ) : R d  X  R d  X  R .  X  ( z ) is the loss function. Given the classifier f  X  , the margin-based approach chooses the unlabeled instance closest to the decision boundary, i.e., It is shown in the supplementary document that this criterio n can be approximated by where We can also write Eq. 3 in a minimax form where A ( D In this min-max view of active learning, it guarantees that t he selected instance x s will lead to a are both informative and representative, we extend the eval uation function L ( D l , x s ) to include all the unlabeled data. Hypothetically, if we know the class ass ignment y u for the unselected unlabeled instances in D u , the evaluation function can be modified as The problem is that the class assignment y u is unknown. According to the manifold assumption [3], following evaluation function for query selection: 3.2 The Solution For computational simplicity, for the rest of this work, we c hoose a quadratic loss function, i.e.,  X  ( y, b y ) = ( y  X  b y ) 2 / 2 1 . It is straightforward to show where L = ( K +  X I )  X  1 and K = [  X  ( x i , x j )] n  X  n is the kernel matrix of size n  X  n . Thus, the evaluation function b L ( D l , D u , x s ) is simplified as Our goal is to efficiently compute the above quantity for each unlabeled instance. For the conve-nience of presentation, we refer to by subscript u the rows/columns in a matrix M for the unlabeled instances in D u , by subscript l the rows/columns in M for labeled instances in D l , and by subscript s the row/column in M for the selected instance. We also refer to by subscript a the rows/columns in M for all the unlabeled instances (i.e., D u  X  X  x s } ). Using these conventions, we rewrite the objective y  X  L y as y , we can switch the maximization of y u with the minimization of y s in (7). By relaxing y u to continuous variables, the solution to min y u y  X  L y is given by leading to the following expression for the evaluation func tion b L ( D l , D u , x s ) : where the last step follows the relation Note that although y u is relaxed to real numbers, according to our empirical studi es, we find that in most cases, y u falls between  X  1 and +1 .
 Remark . The evaluation function b L ( D l , D u , x s ) essentially consists of two components: L s,s  X  minimizing L s,s because L a,a is independent from the selected instance x s . Since L = ( K +  X I )  X  1 , we have Therefore, to choose an instance with small L s,s , we select the instance with large self-similarity K s,s . When self-similarity K s,s is a constant, this term will not affect query selection. To analyze the effect of the second component, we approximat e it as: The first term in the above approximation measures the confide nce in predicting x s using only labeled data, which corresponds to the informativeness of x s . The second term measures the pre-diction confidence using only the predicted labels of the unl abeled data, which can be viewed as the measure of representativeness . This is because when x s is a representative instance, it is expected to share a large similarity with many of the unlabeled instance s in the pool. As a result, the prediction for x s by the unlabeled data in D u is decided by the average of their assigned class labels b y u . If we assume that the classes are evenly distributed over the unla beled data, we should expect a low con-fidence in predicting the class label for x s by unlabeled data. It is important to note that unlike the Algorithm 1 The Q UIRE Algorithm Input: Initialize:
Calculate K repeat until the number of queries or the required accuracy is reached existing work that measures the representativeness only by the cluster structure of unlabeled data, our proposed measure of representativeness depends on b y u , which essentially combines the cluster structure of unlabeled data with the class assignments of la beled data. Given high-dimensional data, there could be many possible cluster structures that are con sistent with the unlabeled data and it is unclear which one is consistent with the target classificati on problem. It is therefore critical to take into account the label information when exploiting the clus ter structure of unlabeled data. 3.3 Efficient Algorithm labeled instance x s , leading to high computational cost when the number of unlab eled instances is very large. The theorem below allows us to improve the comput ational efficiency dramatically. Theorem 1. Let We have L  X  1 The proof can be found in the supplementary document. As indi cated by Theorem 1, we only need proposition allows us to simplify the computation for L  X  1 a,a .
 Proposition 2 follows directly from the inverse of a block ma trix. As indicated by Proposition 2, we only need to compute (  X I + K l,l )  X  1 . Given that the number of labeled examples is relatively small compared to the size of unlabeled data, the computatio n of L  X  1 a,a is in general efficient. The pseudo-code of Q UIRE is summarized in Algorithm 1. Excluding the time for computi ng the kernel matrix, the computational complexity of our algorithm is ju st O ( n u ) . We compare Q UIRE with the following five baseline approaches: (1) R ANDOM : randomly select query instances, (2) M ARGIN : margin-based active learning [18], a representative appr oach which selects informative instances, (3) C LUSTER : hierarchical-clustering-based active learning [7], a re p-resentative approach that chooses representative instanc es, (4) IDE: active learning that selects in-formative and diverse examples [11], and (5) DUAL: a dual str ategy for active learning that exploits both informativeness and representativeness for query sel ection. Note that the original algorithm in [11] is designed for batch mode active learning. We turn it into an active learning algorithm that selects a single instance in each iteration by setting the pa rameter k = 1 . Twelve data sets are used in our study and their statistics ar e shown in the supplementary document. Digit1 and g241n are benchmark data sets for semi-supervised learning [5]; austria , isolet , titato , vechicle , and wdbc are UCI data sets [1]; letter is a multi-class data set [1] from which we select U vs V , and construct a binary class data set for each pair. Each dat a set is randomly divided into two parts of equal size, with one part as the test data and the o ther part as the unlabeled data that is used for active learning. We assume that no labeled data is av ailable at the very beginning of active learning. For M ARGIN , IDE and DUAL, instances are randomly selected when no class ification model is available, which only takes place at the beginning. In each iteration, an unlabeled instance labeled instance. We evaluate the classification model by it s performance on the holdout test data. Both classification accuracy and Area Under ROC curve (AUC) a re used for evaluation metrics. For every data set, we run the experiment for ten times, each with a random partition of the data set. We also conduct experiments with a few initially labeled examp les and have similar observation. Due to the space limit, we put in the supplementary document the exp erimental results with a few initially labeled examples. In all the experiments, the parameter  X  is set to 1 and a RBF kernel with default Table 1: Comparison on AUC values (mean  X  std). The best performance and its comparable performances based on paired t -tests at 95% significance level are highlighted in boldface . LibSVM [4] is used to train a SVM classifier for all active lear ning approaches in comparison. Table 2: Win/tie/loss counts of Q UIRE versus the other methods with varied numbers of queries. 4.1 Results Figure 2 shows the classification accuracy of different acti ve learning approaches with varied num-bers of queries. Table 1 shows the AUC values, with 5% , 10% , 20% , 30% , 40% , 50% and 80% of unlabeled data used as queries. For each case, the best resul t and its comparable performances are highlighted in boldface based on paired t -tests at 95% significance level. Table 2 summarizes the win/tie/loss counts of Q UIRE versus the other methods based on the same test. We also perfo rm the Wilcoxon signed ranks test at 95% significance level, and obt ain almost the same results, which can be found in the supplementary document.
 First, we observe that the R ANDOM approach tends to yield decent performance when the number of queries is very small. However, as the number of queries in creases, this simple approach loses its edge and often is not as effective as the other active lear ning approaches. M ARGIN , the most commonly used approach for active learning, is not performi ng well at the beginning of the learn-ing stage. As the number of queries increases, we observe tha t M ARGIN catches up with the other approaches and yields decent performance. This phenomenon can be attributed to the fact that with only a few training examples, the learned decision boundary tends to be inaccurate, and as a result, the unlabeled instances closest to the decision boundary ma y not be the most informative ones. The performance of C LUSTER is mixed. It works well on some data sets, but performs poorly on the others. We attribute the inconsistency of C LUSTER to the fact that the identified cluster structure of unlabeled data may not always be consistent with the targe t classification model. The behavior of IDE is similar to that of C LUSTER in that it achieves good performance on certain data sets and fails on the others. DUAL does not yield good performance on m ost data sets although we have tried our best efforts to tune the related parameters. We att ribute the failure of DUAL to the setup of our experiment in which no initially labeled examples are provided. Further study shows that starting with a few initially labeled examples does improve the performance of DUAL though it is still significantly outperformed by Q UIRE .Detailed results can be found in the supplementary doc-ument. Finally, we observe that for most cases, Q UIRE is able to outperform the baseline methods significantly, as indicated by Figure 2, Tables 1 and 2. We att ribute the success of Q UIRE to the prin-ciple of choosing unlabeled instances that are both informa tive and representative, and the specially designed computational framework that appropriately meas ures and combines the informativeness and representativeness. The computational cost are report ed in the supplementary document. We propose a new approach for active learning, called Q UIRE , that is designed to find unlabeled in-stances that are both informative and representative. The p roposed approach is based on the min-max view of active learning, which provides a systematic way for measuring and combining the infor-mativeness and the representativeness. Our current work is restricted to binary classification. In the future, we plan to extend this work to multi-class learning. We also plan to develop the mechanism which allows the user to control the tradeoff between inform ativeness and representativeness based on their domain, leading to the incorporation of domain know ledge into active learning algorithms. Acknowledgements This work was supported in part by the NSFC (60635030), 973 Pr ogram (2010CB327903), Jiang-suSF (BK2008018) and NSF (IIS-0643494). [1] A. Asuncion and D.J. Newman. UCI machine learning reposi tory, 2007. [2] M. F. Balcan, A. Z. Broder, and T. Zhang. Margin based acti ve learning. In Proceedings of the [3] M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regular ization: A geometric framework [4] C. C. Chang and C. J. Lin. LIBSVM: A library for support vector machines , 2001. [5] O. Chapelle, B. Sch  X  olkopf, and A. Zien, editors. Semi-supervised learning . MIT Press, Cam-[6] I. Dagan and S. P. Engelson. Committee-based sampling fo r training probabilistic classifiers. [7] S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In Proceedings of the 25th [8] P. Donmez, J. G. Carbonell, and P. N. Bennett. Dual strate gy active learning. In Proceedings [9] P. Flaherty, M. I. Jordan, and A. P. Arkin. Robust design o f biological experiments. In Advances [10] Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. Selecti ve sampling using the query by [11] S. C. H. Hoi, R. Jin, J. Zhu, and M. R. Lyu. Semi-supervise d svm batch mode active learning [12] D. D. Lewis and J. Catlett. Heterogeneous uncertainty s ampling for supervised learning. In [13] D. D. Lewis and W. A. Gale. A sequential algorithm for tra ining text classifiers. In Proceedings [14] H. T. Nguyen and A. W. M. Smeulders. Active learning usin g pre-clustering. In Proceedings [16] B. Settles. Active learning literature survey. Comput er Sciences Technical Report 1648, Uni-[17] H. S. Seung, M. Opper, and H. Sompolinsky. Query by commi ttee. In Proceedings of the 5th [18] S. Tong and D. Koller. Support vector machine active lea rning with applications to text clas-[19] Z. Xu, K. Yu, V. Tresp, X. Xu, and J. Wang. Representative sampling for text classification us-[20] K. Yu, J. Bi, and V. Tresp. Active learning via transduct ive experimental design. In Proceedings
