 Multi-label learning studies the problem where each instance is associated with a set of labels. There are two challenges in multi-label learning: (1) the labels are interdependent and correlated, and (2) the data are of high dimensional-ity. In this paper, we aim to tackle these challenges in one shot. In particular, we propose to learn the label correlation and do feature selection simultaneously. We introduce a matrix-variate Normal prior distribution on the weight vec-tors of the classifier to model the label correlation. Our goal is to find a subset of features, based on which the label correlation regularized loss of label ranking is mini-mized. The resulting multi-label feature selection problem is a mixed integer programming, which is reformulated as quadratically constrained linear programming (QCLP). It can be solved by cutting plane algorithm, in each iteration of which a minimax optimization problem is solved by dual coordinate descent and projected sub-gradient descent al-ternatively. Experiments on benchmark data sets illustrate that the proposed methods outperform single-label feature selection method and many other state-of-the-art multi-label learning methods.
 I.2.6 [ Arti cial Intelligence ]: Learning; I.5.1 [ Pattern Recognition ]: Models Algorithms, Experimentation Feature Selection, Label Correlation, Multi-Label Learning, Dual Coordinate Descent, Cutting Plane
Multi-label learning [7, 30, 35, 39, 13, 27, 4, 11, 31, 36] is a very important topic in data mining and information retrieval. It studies the problem where each instance is as-sociated with a set of labels. This is not uncommon in many important applications, such as protein function classifica-tion [7], text categorization [19], and semantic scene classi-fication [1]. For example, one gene can be associated with several functions, one image may have several tags, and one document can cover several topics. Figu re 1: The label correlation computed from the labels of all the data points in the Yahoo/Arts data set There are mainly two challenges in multi-label learning. First, different from traditional single-label learning where the classes are mutually exclusive, the classes in multi-label learning are typically interdependent and correlated, which poses more difficulties to predict all the relevant labels for a given instance. For example, in image annotation,  X  X ea X  and  X  X hip X  tend to appear in the same image, while  X  X ar X  typically does not appear together with  X  X hip X . Figure 1 illustrates the label correlation which is computed from the labels of all the data points in the Yahoo/Arts data set. The higher the value between two labels is (lighter color), the more correlated these two labels are. It can be seen that the 5th label is highly correlated with the 14th and 18th labels, while it is not correlated with the 12th label. On the other hand, the label correlation offers a possibility to infer the unknown label of an instance from the known label. In order to utilize the relation between labels, [7, 6] proposed to learn the ranks of labels for each instance, which is basically first-order information. However, the correlation among labels is second-order information [36]. And we will show that it is essential for better performance in our experiments.
The seco nd challenge is that multi-labeled data usually have thousands or even tens of thousands of features. This is especially true for documents and news articles. For ex-ample, the news articles in the Yahoo data set used in our experiments are of about 20K features. As we know, high dimensional data may cause the curse of dimensionality , which increases the computational burden and deteriorate the generalization ability of the classifier. To overcome this problem, many dimensionality reduction based multi-label learning approaches [35, 39, 13, 31] have been proposed. Al-though these methods perform good for high dimensional data, they still fail to explicitly model the label correlation, which is crucial for better performance.

In this paper, based on the above motivation, we aim to solve the two challenges in one shot. We built up our model on the label rank support vector machine (LaRank SVM) [7] 1 , which is among state-of-the-art multi-label learn-ing methods [7, 13]. We introduce a matrix-variate Nor-mal prior distribution [10] on the weight vectors of LaRank SVM. Since the column covariance matrix of matrix-variate Normal distribution characterizes the correlation among the weight vectors, each of which associates with one label, the label correlation is modeled explicitly. To avoid the curse of dimensionality, we incorporate feature selection into LaRank SVM. Our goal is to find a subset of features, based on which the label correlation regularized loss of label ranking [7] is minimized. The resulting multi-label feature selection is a mixed integer programming problem, which is difficult to solve. Fortunately, it can be reformulated as Quadratically Constrained Linear Programming (QCLP) [2]. It is solved by cutting plane algorithm [17], in each iteration of which a minimax optimization problem is solved by dual coordinate descent [12] and projected sub-gradient descent [22] alterna-tively. As a by-product, we also propose a correlated label rank support vector machine (CLaRank SVM), which is an extension of LaRank SVM [7]. It is worth noting that, the proposed approach is able to not only learn the label cor-relation automatically, but also reduce the dimensionality of the original data. Experiments on benchmark data sets indicate that the proposed methods outperform single-label feature selection and many other state-of-the-art methods. The remainder of this paper is organized as follows. In Section 2, we discuss several related works on multi-label learning. In Section 3 we present correlated multi-label fea-ture selection. The experiments on real world data sets are demonstrated in Section 4. Finally, we draw a conclusion and point out the future work in Section 5.
In multi-label learning with c labels, each data point x i , i = 1 , . . . , n can be associated with a set of labels, i.e., y  X  { 1 , 2 , . . . , c } . We denote the complementary set of y there are totally 6 labels, and x i is labeled by the 2nd and 3rd labels, then y i = { 2 , 3 } ,  X  y i = { 1 , 4 , 5 , 6 denotes the j th row of X . e i is a unit vector of all zeros
Note that in the original paper, the authors called this model as Rank SVM. To distinguish this model from another well-known Rank SVM proposed in [14] for information re-trieval, we call this model as Label Rank SVM or simply LaRank SVM because it ranks the labels rather than data points. except the i th element equal to 1. 1 is a vector of all ones. 0 is a vector of all zeros. Given a matrix R , we denote its ( k, l )th entry by R kl , and its inverse matrix by R  X  1 the ( k, l )th entry of R  X  1 .
In this section, we give a brief review of multi-label classi-fication methods which are related to ours. Existing multi-label learning methods can be cast into different families.
The first family of multi-label learning method is to divide multi-label learning into a set of one-against-all binary clas-sification problems [23]. However, since each label is treated independently, it fails to consider the correlation among dif-ferent labels, which is essential in multi-label learning. It is desirable for a multi-label learning method to make use of label correlation for better performance. Moreover, this approach suffers from imbalanced data when constructing binary classifiers to distinguish each class from the remain-ing classes. This problem becomes more severe when the number of classes is large.

The second category of multi-label learning approaches are based on Label Ranking [7, 6, 4], where ranking-based strategy is taken to learn a ranking function of labels from the labeled instances and apply it to obtain a real-valued score for each instance-label pair, then classify each instance by choosing all the labels whose scores are above the given threshold. They achieve state-of-the-art results and are scal-able to large-scale data with the recent progress in support vector machine optimization [15, 25, 12, 16]. However, these methods do not explicitly exploit the label correlation, and are suffering from curse of dimensionality. This motivates us to propose a model built up on LaRank SVM [7], while it is able to overcome the limitations.

Another family of multi-label learning methods are based on dimensionality reduction, which assume that all the la-bels share a common subspace. For example, [35] extended unsupervised latent sematic indexing to make use of multi-label information. [39] proposed Multi-label Dimensionality reduction via Dependence Maximization (MDDM) method to identify a lower-dimensional subspace by maximizing the dependence between the original features and associated class labels. [31] proposed Multi-Label Linear Discriminant Anal-ysis (MLDA) which is an extension of linear discriminant analysis. [27] proposed to construct a hyper-graph on both the data points and labels, and find a subspace to preserve the information of the hyper-graph for classification. [13] proposed Multi-Label Least Square (MLLS) method to ex-tract a common subspace shared among multiple labels. These methods have been proved very effective for multi-label learning. They are also able to deal with the curse of dimensionality. Subspace based methods utilize the correla-tion between data and labels. However, they do not consider the correlation among labels, which is not uncommon in multi-label data as shown before. In this paper, rather than subspace learning, we propose to do feature selection for multi-label learning, which can be integrated into LaRank SVM [7] coherently. We assume that all the labels share a common subset of features. Due to the close relationship between subspace learning and feature selection, feature se-lection plays a similar role as subspace learning. Moreover, to capture the correlation among labels, we propose to learn the label correlation at the same time as feature selection.
Since the proposed method is built upon LaRank SVM [7], we first briefly review the formulation of LaRank SVM. It borrowed the large margin idea to multi-label learning and modified SVM to a ranking system of labels. The basic idea is, for each instance, the ranking scores of the labels assigned to the instance should be higher than the ranking scores of the labels not assigned to it. The resulting maximum margin multi-label ranking system is where C &gt; 0 is a regularization parameter. Note that a bias term can be incorporated into the form by expanding the weight vector and input feature vector as w k  X  [ w T k , b and x  X  [ x T , 1] T . It has been shown that LaRank SVM performs better than SVM [7, 27]. LaRank SVM consid-ers the ordinal relation among labels, which is first-order information. However, LaRank SVM does not consider the label correlation, which is a kind of second-order informa-tion among labels. Moreover, when the dimensionality of the data is very high, LaRank SVM does not perform as good as some dimensionality reduction based methods [27, 13]. This motivates us to consider the label correlation and do feature selection (dimensionality reduction) simultaneously in this paper.
To capture the correlation between labels, we place a matrix-variate Normal distribution prior [10] on the weight vectors of LaRank SVM, i.e., W = [ w 1 , . . . , w c ], where 0 d  X  c denotes a d  X  c zero matrix, I d is a d  X  d identity matrix, and MN ( X | M , A  X  B ) denotes a matrix-variate normal distribution with mean M  X  R a  X  b , row covariance matrix A  X  R a  X  a , and column covariance matrix B  X  R b  X  b The probability density function of the matrix-variate nor-mal distribution is defined as No te that similar prior has been used for multi-task learning [37] and transfer distance metric learning [38]. Plug Eq.(3) into Eq.(2), it can be simplified as S ince the column covariance matrix D models the correla-tion between any two w k , it is able to capture the correlation of different labels.
As to feature selection, we introduce a binary variable p { 0 , 1 } , j = 1 , . . . , d for each feature, such that if p the j th feature is selected. Otherwise, it is discarded. Our goal is to find a subset of features, such that the the label correlation regularized loss of the LaRank SVM in Eq.(1) is minimized, where p  X  x i is element-wise Hadamard product which per-forms feature selection. Note that the first two terms in the objective function can be seen as the negative log like-lihood of some kind of distribution on w k , and the third term is the negative logarithm of a prior on w k . Hence the whole objective function can be seen as a negative log-arithm of the posterior on w k . This is in spirit the same as maximum a posterior principle. Unfortunately, the term 2 log p ( W is not easy to optimize since it is non-convex. In this paper, we turn to solve the following similar problem, We call Eq.(6) as Correlated Multi-Label Feature Selection (CMLFS).

Both Eq. (5) and Eq.(6) are mixed integer programming [2]. Compared with Eq.(5), although Eq.(6) sacrifices the sound probabilistic interpretation to some extent, it has a more desirable optimization property, which is stated in the following theorems.
 Theorem 3.1 Given p , the optimization problem in Eq.(6) is jointly convex in w k and D .
 Proof. Please refer to [37].

It is worth noting that there are two special instances of the proposed model in Eq.(6). First, if we set  X  = 0, then the model in Eq.(6) reduces to multi-label feature selection without learning the label correlation. In the rest of this paper, we refer to this special model as Multi-Label Feature Selection (MLFS). Second, if we fix p = 1 , then the model in Eq.(6) can be seen as an extension of label rank SVM, which is not only learning to rank the labels, but also learning the correlation among labels. This special model is referred to as Correlated Label Rank SVM (CLaRank SVM). It is obvious that if we set  X  = 0 and fix p = 1 simultaneously, then Eq.(6) exactly reduces to original label rank SVM in Eq.(1). In the sequel, we will present the optimization algorithm to solve Eq. (6).
Instead of directly optimizing the problem in Eq. (6), we choose to optimize its dual problem [2]. Theo rem 3.2 The dual of the problem in Eq. (6) is min where R = I +  X  D  X  1 , R  X  1 is the inverse matrix of R , and R kl is the ( k, l ) th entry of R and  X  k ipq is de ned as, Moreover, we have
For the sake of notional simplicity, we denote the objective function of Eq.(7) by f ( , D , p ), and define Then the optimization problem in Eq.(7) can be rewritten as
By interchanging the order of min D  X  X  , p  X  X  and max k  X  X  in Eq. (12), we obtain According to the minimax theorem [18], the optimal objec-tive value of Eq.(7) is an upper bound of that of Eq.(13).
The problem in Eq. (13) is indeed a convex-concave op-timization problem, and therefore its optimal solution is a saddle point for the function f ( , D , p ) subject to the con-straints in Eq. (11). Let (  X  , D  X  , p  X  ) be optimal to Eq. (13). For any feasible and p , we have
Borrowing the idea used in [5] [20] [28], we add an addi-tional variable  X   X  R , then the problem in Eq. (13) can be reformulated equivalently as follows Note that each p t  X  X  corresponds to one constraint, so the above optimization problem has timization problem in Eq.(15) is called Quadratically Con-strained Linear Programming (QCLP) [2].

We introduce a set of Lagrange multipliers  X  t  X  0, each of which corresponds to an inequality constraint  X   X  X  X  f ( , D , p Then the Lagrange function of Eq.(6) is given by
Taking the partial derivative of L with respect  X  and set-ting it to zero, we obtain
Plugging Eq.(17) back into Eq.(15), we get the dual prob-lem of the inner maximization problem in Eq(15), we obtain the following problem, where  X  = {  X  t | due to the fact that the objective function is concave in and convex in D and .
Actually, Eq. (18) can be seen as a multiple kernel learn-ing problem [22], where the base kernels and kernel weights are the same for all the labels. It is worth noting that [29] proposed a multiple kernel learning with multiple labels. Their method is different from ours. In their method, the kernel weights are different for each label. Moreover, they did not consider the label correlation. As a result, their algorithm cannot be adapted to our problem.

Following the technique used in the state-of-the-art single-label multiple kernel learning [22], we optimize Eq. (18) in an alternative way. In particular, we alternatively solve one variable such as given the other variables such as D and fixed.
Fixing D and , the optimization problem in Eq.(18) re-duces to where g ( ) is defined as where p = [ p T 1 , . . . , p T |P| ] T and x i = [  X  1 x
The ab ove optimization problem can be efficiently solved by dual coordinate descent method [12]. It updates one vari-able at a time by minimizing a single variable subproblem. In particular, it picks one variable  X  ikl at a time and solves the following single variable subproblem while keeping all the other variables fixed, of Eq.(21) is a simple quadratic function of d , is independent on d , and  X  ikl g ( ) can be computed as where u k = has an optimum at d = 0 if and only if
If Eq.(25) holds, we do not need to update  X  ikl and di-rectly move to the next variable. Otherwise, the optimal solution of Eq.(21) is This means the subproblem can be solved analytically that ensures the efficiency of the coordinate descent method. Here, we need to calculate ( p  X  x i ) T ( p  X  x i ) and  X  P ikl ( p  X  x i ) T ( p  X  x i ) can be pre-computed and stored in the memory. Second, to evaluate  X  P ikl g ( ) using Eq.(23), we only need to maintain u k by
The dual coordinate descent method for optimizing is summarized in Algorithm 1.
 Theorem 3.3 The calculated by Algorithm 1 globally con-verges to an optimal solution  X  . The convergence rate is Alg orithm 1 Dual Coordinate Descent for Optimizing Input: C and m ; Output: ;
Initialize = 0 and w k = 0 , k = 1 , . . . , c ; repeat until converge at le ast linear. In other words, there is 0 &lt;  X  &lt; 1 and an iteration t 0 , such that Proof. Please refer to [12].
 The linear convergence result is remarkable, that means Algorithm can achieves an  X  -accurate solution in O (log( itera tions.
Given and , the optimization problem in Eq.(6) boils down to which is a semi-definite programming (SDP) [2]. Fortu-nately, it can be solved by spectral method as stated in the following theorem.
 Theorem 3.4 Let C = W T W , the optimal solution of Eq.(29) is and the optimal value equals to ( tr ( C 1 2 )) 2 Proo f. The proof is similar to Theorem 4.6 in [9]. Let D = A diag( ) A T where = [  X  1 , . . . ,  X  c ]  X  R d , then Next , we have sin ce tr( A )tr( B )  X  tr( AB ) if A and B are positive semi-definite. The equality holds if and only if C 1 2 a k a T of C 1 2 . The optimal  X  is tr( C 1 2 ). Henc e we obtain Con sequently, the optimal D = C proof.
Let h ( ) = of h ( ) with respect to  X  t by  X   X  t h ( ), which is calculated as Following [22], we use projected gradient descent to up-date the kernel weights  X  t . Note that other techniques such as semi-infinite linear programming [26] and extended level method [32] can also be adopted. Up to now, we have presented the algorithm for optimizing Eq.(18). However, given P , the problem has optimization variables ( , D , ) with tical to solve. Fortunately, cutting plane technique [17] en-ables us to deal with this problem, which keeps a polynomial sized subset  X  of working constraints and computes the op-timal solution to Eq. (18) subject to the constraints in  X . In detail, the algorithm adds the most violated constraint in Eq. (15) into  X  in each iteration. In this way, a succes-sively strengthening approximation of the original problem is solved. And the algorithm terminates when no constraints in Eq. (15) is violated.

The remaining thing is how to find the most violated con-straint in each iteration. Since the feasibility of a constraint is measured by the corresponding value of  X  , the most vio-lated constraint is the one which owns the largest  X  . Hence, it could be calculated as follows where s j = According to [28], its optimal solution can be obtained with-out any numeric optimization solver. Instead, it can be solved by first sorting s j and then setting the first m num-bers corresponding to d j to 1 and the rests to 0.
We summarize the algorithm to solve the problem in Eq. (18) in Algorithm 2. Note that the final selected features are the union set of the features corresponding to each constraint p Alg orithm 2 Correlated Multi-Label Feature Selection Input: C and m ; Output: and  X ; Initialize = 0 and t = 1;
Find the most violated constraint p 1 , and set  X  1 = { p repeat until converge We analyze the convergence property of Algorithm 2. Theorem 3.5 Let (  X   X  , D  X  ,  X   X  ) be the global optimal solu-tion of Eq. (15), l t = max 1  X  j  X  t min  X  X  , D  X  X  ,  X  f ( , D , p and u t = min 1  X  j  X  t max p  X  X   X  f ( j , D j , p ) , then With the number of iteration t increasing, the sequence { is monotonically increasing and the sequence { u t } is mono-tonically decreasing.
 Proof. Please refer to [28].
 Sin ce the number of constraints in P is finite, i.e., on Theorem 3.5, the algorithm will converge within finite number of iterations. Moreover, we can use the gap between l and u t to trace the convergence of Algorithm 2. When the gap is smaller than a predefined tolerance  X  , we stop the algorithm. Empirical study shows that the algorithm converges within 10 outer-iterations in our experiments.
In each outer iteration of Algorithm 2, it needs to find the most violated p . It can be obtained exactly by finding the m largest ones from d coefficients s j , which takes only O ( m log d ) time. In the inner iteration of Algorithm 2, it solves a minimax problem by alternating optimization. Its complexity is proportional to the sum of the complexity of dual coordinate descent and the complexity of calculating D . The complexity of dual coordinate descent is O ( c 2 ns ), where s is the average number of nonzero features among all the training samples. The complexity of calculating D is O ( dc ). Hence the total time complexity of the proposed method is O ( T ( c 2 ns + dc + m log d )), where T is the number of iterations needed to converge, Thus, the proposed method is computationally efficient for large-scale, high dimensional data.
So far we have only developed a ranking system. To ob-tain the final labels of each instance, we need to design a label set size predictor s ( x ). Following [7], we turn to learn a threshold function t ( x ), which differentiates labels in the target set from others. Given the threshold func-tion, the predictor of the set size is quite straightforward: to learn t ( x ). We formulate it as a regression problem. In detail, given a training instance x i , its label ranking scores are w T 1 x , . . . , w T c x , we define the corresponding threshold t = t ( x i ) by Once we generate the thresholds { t i = t ( x i ) } n i =1 training set, we can estimate the threshold function t ( x ) by any regression model. In this paper, we simply use linear regression to estimate t ( x ).
In this section, we empirically evaluate the effectiveness of the proposed methods. All experiments are performed on a PC with Intel Core i5 3.20G CPU and 4GB RAM and all algorithms in our experiments are implemented in Matlab and C++.
We carry our experiments on various sets of data, includ-ing data sets from LibSVM website 2 and Yahoo 3 . In Lib-SVM data sets, we choose scene data set [1] and yeast data set [7]. For Yahoo data set [30], we use four categories: Arts, Business, Education, and Health as four data sets. In each category, the sub-categories are the labels for each document. We pre-processed the data sets by removing sub-categories with less than 100 documents and documents with no sub-category. Table 1 summarizes the characteristics of these data sets.

To evaluate the performance of different algorithms for multi-label learning, we use three measures: the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC), Micro F1 and Macro F1. For AUC, we first compute the ht tp://www.csie.ntu.edu.tw/  X  cjlin/libsvmtools/datasets /multilabel.html http://www.kecl.ntt.co.jp/as/members/ueda/yahoo.tar.gz AUC for each class, and then compute the averaged AUC over all the classes. For more details about the measures, please refer to [33].
We compare the proposed methods with the related multi-label learning methods and a single-label feature selection method. We choose Fisher score [21] as the representative of single-label feature selection methods. The reason is that our empirical study [8] found that Fisher score is comparable to or even better than the other feature selection methods [34, 24] on the data sets used in our experiments. We will not report the results of MDDM [39] and MLDA [31] be-cause they are not better than MLLS [13]. All the methods and their parameter settings are summarized as follows. By default, the regularization parameter C of SVM type models in all the methods is tune by 5-fold cross validation on the training set via searching the grid { 10  X  3 , 10  X  2 , . . . , 10
SVM : linear SVM is used for one-against-all classification individually.

LaRank SVM [7]: The threshold function is learned by linear regression as stated in Section 3.8.

CCA+SVM : Canonical Correlation Analysis is used for dimensionality reduction before SVM. The dimensionality of the subspace is set to c  X  1 where c is the number of classes. The regularization parameter for CCA is tuned by 5-fold cross validation on the training set via searching the grid { 10  X  5 , 10  X  4 , . . . , 10  X  1 } .

MLLS 4 [13]: The dimensionality of the subspace is set to c  X  1. The two regularization parameters for MLLS is tuned by 5-fold cross validation on the training set by searching the grid { 10  X  5 , 10  X  4 , . . . , 10  X  1 } .

FS+SVM [21]: Fisher score (FS) is used for each one-against-all binary classification individually, followed with linear SVM. The number of selected features m is tuned by 5-fold cross validation via searching the grid { 10 , 20 , . . . , 10 } on Sc ene and Yeast data sets, and via the grid { 1000 , 2000 , . . . ,  X  n 1000  X  X  1000 } on the Yahoo data sets.
CLaRank SVM : The regularization parameter  X  is tuned by 5-fold cross validation on the training set by searching the grid { 10  X  2 , 10  X  1 , . . . , 10 2 } .

MLFS : The m which controls the number of features is also tuned by 5-fold cross validation on the training set over the grid { 10 , 11 , . . . , 20 } on scene and yeast data sets, and over the grid { 1000 , 2000 , . . . , 10000 } on Yahoo data sets.
CMLFS : The m is tuned the same as above. The regu-larization parameter  X  is tuned the same as CLaRank SVM.
Since learning with small number of labelled data is much more challenging than learning with large number of labelled data, we randomly sample 1000 data points from each data set for training, and the rest for testing. Note that each label is guaranteed to appear in at least one data point of the training set and in at least one data point of the testing set. The process was repeated 10 times and the mean along with standard deviation of measures are reported. The classification results of all the methods are shown in Table 2. CMLFS, MLFS and CLaRank SVM are the three methods proposed by us. As is pointed out before, MLFS and CLaRank SVM are two special instances of CMLFS. ht tp://www.public.asu.edu/  X sji03/multilabel/ Comp ared with other methods, these three methods show the best performance. Specifically, CLaRank SVM achieves better results because it considers label correlation. And the good performance of MLFS takes advantage of feature selection. Among these three, CMLFS performs the best. This demonstrates that it is very necessary to combine la-bel correlation and feature selection into classification model simultaneously.

Two state-of-the-art methods, LaRank SVM and MLLS, perform worse than our methods but still are better than the others. LaRank SVM classifies (ranks) all the labels simul-taneously. It considers the ordinal (first-order) information between labels, which is beneficial for multi-label learning. MLLS is based on subspace learning, it is able to learn a discriminative subspace for multi-label classification. That is why MLLS generally shows better results than LaRank SVM on Yahoo data sets, which are of high dimensionality.
Let us take a closer look at LaRank SVM in compari-son with the proposed methods. CLaRank SVM improves LaRank SVM consistently on all the data sets. The im-provement is a result of using the correlation (second-order) information among labels. As we mentioned above, LaRank SVM only considers the first-order information. On the other hand, MLFS performs better than LaRank SVM. The reason is that the feature selection in MLFS helps it avoid the curse of dimensionality.

Comparing MLLS with MLFS, the major problem of MLLS is that it fails to consider the label correlation. Though both MLLS and MLFS involve dimensionality reduction, MLFS is superior to MLLS at most cases because it considers the label rank (first-order information).

CCA+SVM and FS+SVM fail to perform well because both of them are in the fashion of two-stage approach. For CCA+SVM, it first carries out subspace learning and then learns a classification model. FS+SVM does feature selec-tion followed by learning the classifier. Both methods try to deal with high dimensional data but fail to integrate di-mensionality reduction and classifier learning into a unified framework. Besides, Fisher score is used in each one-against-all binary classification independently, so the selected fea-tures are generally different from each other for each binary classification problem.
In this subsection, we study the performance of multi-label learning with respect to the number of selected features. We compare CMLFS and MLFS with the single-label feature selection method, i.e., Fisher score. Since the number of selected features for the CMLFS and MLFS is determined implicitly by m , we increase m gradually and obtain a in-creasing number of features. Figure 2 depicts the AUC with respect to the increasing number of selected features. We can see that with a very small number of features, MLFS and CMLFS can achieve very good performance. In contrast, the performance of Fisher score is pretty bad. In fact, the satisfying classification results of Fisher score shown in Table 2 are achieved by selecting almost all the features. This again strengthens the superiorness of the proposed multi-label feature selection methods over single-label feature se-lection method.
In this paper, we present a multi-label feature selection method based on LaRank SVM. It is formulated as quadrat-ically constrained linear programming and solved by cutting plane algorithm, in each iteration of which a minimax opti-mization problem is solved by dual coordinate descent and stochastic sub-gradient descent alternatively. Its training time is linear in the number of training samples, which en-ables it applicable to large scale multi-label data.
In our future work, we will study how to solve the feature selection problem in the primal [15, 25]. Moreover, we also plan to study semi-supervised multi-label learning [3]. The work was supported in part by NSF IIS-09-05215, U.S. Air Force Office of Scientific Research MURI award FA9550-08-1-0265, and the U.S. Army Research Laboratory under Cooperative Agreement Number W911NF-09-2-0053 (NS-CTA). The views and conclusions contained in this docu-ment are those of the authors and should not be interpreted as representing the official policies, either expressed or im-plied, of the Army Research Laboratory or the U.S. Govern-ment. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstand-ing any copyright notation here on. We thank the anony-mous reviewers for their helpful comments. [1] M. R. Boutell, J. Luo, X. Shen, and C. M. Brown. [2] S. Boyd and L. Vandenberghe. Convex optimization . [3] G. Chen, Y. Song, F. Wang, and C. Zhang.
 [4] G. Chen, J. Zhang, F. Wang, C. Zhang, and Y. Gao. [5] J. Chen and J. Ye. Training svm with indefinite [6] O. Dekel, C. D. Manning, and Y. Singer. Log-linear [7] A. Elisseeff and J. Weston. A kernel method for [8] Q. Gu, Z. Li, and J. Han. Generalized fisher score for [9] Q. Gu and J. Zhou. Subspace maximum margin [10] A. K. Gupta and D. K. Nagar. Matrix Variate [11] B. Hariharan, L. Zelnik-Manor, S. V. N.
 [12] C.-J. Hsieh, K.-W. Chang, C.-J. Lin, S. S. Keerthi, measures are, the better the performance is.
 [13 ] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared [14] T. Joachims. Optimizing search engines using [15] T. Joachims. Training linear svms in linear time. In [16] T. Joachims, T. Finley, and C.-N. J. Yu.
 [17] J. E. Kelley. The cutting plane method for solving [18] S.-J. Kim and S. Boyd. A minimax theorem with [19] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A [20] Y. Li, I. Tsang, J. Kwok, and Z. Zhou. Tighter and [21] P. E. H. R. O. Duda and D. G. Stork. Pattern [22] A. Rakotomamonjy, F. Bach, S. Canu, and [23] R. M. Rifkin and A. Klautau. In defense of one-vs-all [24] M. Rogati and Y. Yang. High-performing feature [25] S. Shalev-Shwartz, Y. Singer, and N. Srebro. Pegasos: [26] S. Sonnenburg, G. R  X  atsch, C. Sch  X  afer, and [27] L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning [28] M. Tan, L. Wang, and I. W. Tsang. Learning sparse [29] L. Tang, J. Chen, and J. Ye. On multiple kernel [30] N. Ueda and K. Saito. Parametric mixture models for [31] H. Wang, C. H. Q. Ding, and H. Huang. Multi-label [32] Z. Xu, R. Jin, I. King, and M. R. Lyu. An extended [33] Y. Yang. An evaluation of statistical approaches to [34] Y. Yang and J. O. Pedersen. A comparative study on [35] K. Yu, S. Yu, and V. Tresp. Multi-label informed [36] M.-L. Zhang and K. Zhang. Multi-label learning by [37] Y. Zhang and D. yan Yeung. A convex formulation for [38] Y. Zhang and D.-Y. Yeung. Transfer metric learning [39] Y. Zhang and Z.-H. Zhou. Multi-label dimensionality
