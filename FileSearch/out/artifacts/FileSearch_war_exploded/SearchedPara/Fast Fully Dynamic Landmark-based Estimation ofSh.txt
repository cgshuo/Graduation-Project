 Computing the shortest path between a pair of vertices in to contemporary, rapidly evolving social networks with hun-dreds of millions of users and billions of connections. A num-ber of approximate methods have been proposed, includ-ing several landmark-based methods that have been shown to scale up to very large graphs with acceptable accuracy. This paper presents two improvements to existing landmark-based shortest path estimation methods. The first improve-ment relates to the use of shortest-path trees (SPTs). To-gether with appropriate short-cutting heuristics, the use of SPTs allows to achieve higher accuracy with acceptable time and memory overhead. Furthermore, SPTs can be main-tained incrementally under edge insertions and deletions, which allows for a fully-dynamic algorithm. The second im-provement is a new landmark selection strategy that seeks lected landmarks. The improved method is evaluated on the DBLP, Orkut, Twitter and Skype social networks. E.1 [ Data ]: Data Structures X  Graphs and networks, Trees ; H.2.4 [ Database Management ]: Systems X  Query process-ing Algorithms, Experimentation, Performance  X 
Corresponding author.  X  All authors are also affiliated with Software Technology and Applications Competence Center (STACC), Estonia Graph Databases, Shortest Paths, Social Networks, Land-marks, Trees, Dynamic Updates
Finding the shortest path between a given pair of ver-tices in a graph is a fundamental primitive in graph algorith-mics. For example, in the context of social network analysis, this primitive is useful for socially-sensitive search [18, 20], whereby a user of a social network searches for an individual by name and expects to see the results ranked in the order of their shortest path distance to him. Similarly, a user may another user in the network.

There exists a large body of methods to address this prob-lem [21]. Existing methods can be broadly classified into ex-act and approximate. Exact methods, such as those based on Dijkstra X  X  traversal, are prohibitively slow for perform-vertices, which is a typical size for a contemporary social net-work. Among the approximate methods, a family of scalable algorithms for this problem are the so-called landmark-based techniques, a fixed set of landmark nodes is selected and dis-tances or actual shortest paths are precomputed from each vertex to some or all of the landmarks. Knowledge of the dis-tances to the landmarks, together with the triangle inequal-ity, typically allows one to compute approximate distance between any two vertices in O ( k ) time, where k is the num-ber of landmarks, and O ( kn ) space, where n is the number of vertices in the network. Those estimates can then be used as-is, or exploited further as a component of a graph traver-sal or routing strategy in order to obtain an exact shortest path [7, 10].

Although landmark-based algorithms do not provide strong theoretical guarantees on approximation quality [11], they have been shown to perform well in practice, scaling up to graphs with millions or even billions of edges with accept-able accuracy and response times of under one second per query [5, 9, 16].

In this paper we describe two improvements to existing landmark-based estimation methods for undirected graphs. These improvements allow us to achieve higher accuracy than existing methods with millisecond-execution times on a graph with over three billion edges.

The first improvement derives from the use of shortest path trees (SPTs) to maintain the paths between each landmark and every vertex in the graph. Based on this data structure, we present three novel strategies for computing an approxi-mate shortest path between any pair of nodes. Moreover, the use of SPTs makes the proposed method suitable for contin-uously evolving graphs, since practically efficient algorithms exist for incremental SPT update [3, 6]. For completeness X  sake we explicitly present a version of the incremental up-date algorithm from [6], simplified to unweighted graphs.
The second improvement relates to the selection of land-marks. Specifically, we propose a greedy approach to select those landmarks that provide the best coverage of all short-est paths in a random sample of vertex pairs.

We evaluate the proposed method on four large social net-work, the largest of them (Skype) consisting of circa 500 mil-lion users and 3 billion connections. The evaluation demon-strates improved precision of distance estimates gained by both the landmark selection technique and the use of SPTs.
The rest of the paper is structured as follows. Section 2 in-troduces the notation used to present the algorithms, which are themselves given in Section 3. Section 4 summarizes the experimental evaluation results. Finally, Section 5 discusses related work, while Section 6 provides concluding remarks.
Let G = ( V,E ) denote a graph with n = | V | vertices and m = | E | edges. For simplicity of exposition, we shall consider an undirected, unweighted graph, although our ap-proach can be easily generalized to accommodate weighted directed graphs as well.

A path  X  s,t of length ` between two vertices s,t  X  V is defined as a sequence  X  s,t = ( s,u 1 ,u 2 ,...,u `  X  1 { u is the combined path  X  s,v =  X  s,t +  X  t,v = ( s,...,t,...,v ).
The distance d ( s,t ) between vertices s and t is defined the triangle inequality : for any s,t,u  X  V The upper bound becomes an equality iff there exists a short-est path  X  s,t which passes through u .

The diameter of a graph is the maximal length of a short-est path in the graph. In this work we rely on an important property of social networks  X  their diameter is small [19].
Centrality of a vertex is a general term used to refer to a number of metrics of importance of a vertex within a graph. Betweenness centrality corresponds to the mean proportion of shortest paths passing through a given vertex. Closeness centrality measures the average distance of a vertex to all other vertices in the graph. Computing centrality measures for all vertices exactly is typically hard (e.g., the best be-tweenness centrality algorithm so far requires O ( mn ) time on unweighted graphs [2]), but can be approximated using random sampling [1].
 Algorithm 1 Landmarks-Basic Require: Graph G = ( V,E ), number of landmarks k . 1: procedure Precompute 2: U  X  Select-Landmarks( G , k ) . Algorithm 4 3: for u  X  U do 4: Do a BFS traversal starting from u . 5: For each v  X  V store its distance from u as d u [ v ]. 6: end for 7: end procedure 8: function Landmarks-Basic ( s,t ) 11: end function
As noted in Equation 1, if we fix a single landmark node u and precompute the distance d ( u,v ) from this node to each other vertex v in the graph, we can get an upper bound approximation for the distance d ( s,t ) between any two ver-tices s and t : If we now select a set U = { u 1 ,u 2 ,...,u k } of k landmarks, a potentially better approximation can be computed:
In principle, the triangle inequality also allows to compute a lower bound on the distance, but previous work [16] indi-cates that lower-bound estimates are not as accurate as the upper-bound ones.
 In the following we refer to this algorithm as Landmarks-Basic (Algorithm 1). For unweighted graph, the algorithm requires O ( km ) time to precompute distances using k BFS only allows us to compute an approximate distance, but does not provide a way to retrieve the path itself.
The central contribution of this paper is the idea of main-taining an explicit shortest path tree (SPT) for each land-mark, instead of simply storing the distances to landmarks on an arbitrarily chosen shortest path from a vertex v to a in the SPT of u (Figure 1). Similarly to distances, parent links can be computed in a straightforward manner during a BFS traversal of the graph in O ( m ) time per landmark.
The availability of parent links enables us to recover an exact shortest path from each vertex v to each landmark u by simply following the corresponding links. Consequently, it also allows to compute the shortest path distance d ( u,v ) and thus directly apply the ideas of the Landmarks-Basic algorithm, with the only difference that each distance com-putation now requires O ( D ) steps, where D is the diameter of the graph. As the diameters of social network graphs tend Figure 1: Shortest path tree for landmark u . Black arrows denote parent links. Dashed lines are graph edges that are not part of the tree. to be small, the expected overhead of such a computation is minor.

Note that this approach allows to retrieve an actual path between any two vertices in addition to the distance approx-imation.
Besides performing basic landmark-based approximation, the availability of the SPT allows us to significantly improve the upper bound estimates on distances for many vertex pairs. Consider the situation depicted in Figure 2 and sup-pose we wish to approximate the distance between v 5 and v By applying the basic technique we obtain an upper bound paths: we can note that both of them pass through v 3 and thus the estimate will result in a better upper bound. In general, whenever two shortest paths  X  s,u and  X  t,u have a common vertex v 6 = u , we have and thus if we use v instead of u to approximate d ( s,t ) we obtain a tighter bound. Naturally, it makes sense to select the vertex v providing the best such approximation. It can be easily seen that this vertex is the lowest common ancestor (LCA) of s and t in the SPT of u .

This observation provides the basis of our LCA approxi-mation method ( Distance-LCA , Algorithm 2). By substi-tuting this distance estimate into Equation (3), we obtain a new algorithm Landmarks-LCA with increased accuracy. return the actual path.

One way to understand the extent of improvement is to note that the basic algorithm will provide exact estimates only for shortest paths that pass through the landmark ver-tex. In Figure 2 those are only the paths connecting v 2 v and v 3 . The LCA algorithm, however, will provide exact answers for all shortest paths that lie along the SPT, and there will be typically considerably more of those. Denote the lowest common ancestor of s and t by v . The LCA algorithm approximates  X  s,t by a concatenation of  X  s,v with  X  v,t . However, it may happen that a vertex w  X   X  s,v is connected directly by an edge with a vertex w 0 In this case, an even shorter approximation to  X  s,t can be Figure 2: Lowest common ancestor technique. When approximating distance between v 5 and v 8 we use their lowest common ancestor v 3 instead of the landmark u as a reference.
 Figure 3: Landmark-BFS technique. Here, solid ar-rows belong to the SPT of u 1 , and dotted arrows belong to the SPT of u 2 . obtained by concatenating the paths  X  s,w ,  X  w,w 0 and  X  For example, in Figure 2, the edge ( v 5 ,v 6 ) acts as a short-may further improve the LCA distance estimate to the true shortest path d ( v 5 ,v 8 ) = 2.

In order to locate shortcuts we can simply examine all pairs of vertices in  X  s,v  X   X  t,v and if some of them are con-nected by an edge, find the edge providing the best distance mation method as Distance-SC (Algorithm 2). By using this upper bound estimate in Equation (3) we obtain the landmark-based algorithm Landmarks-SC .
The algorithms Landmarks-Basic , Landmarks-LCA , and Landmarks-SC use each landmark for distance approx-imation independently of the other landmarks. This is not the best possible use of all available landmark data. Con-sider Figure 3, for example. When approximating distance between vertices v 1 and v 5 , we would obtain a path of length 5 if we used the two landmarks independently. By combin-into account, we further improve the distance approxima-tion to 3.

This suggests a very simple, yet powerful improvement over the previous approaches. In order to approximate dis-tance between two vertices, collect all paths from those ver-tices to all landmarks, and perform a usual BFS (or, in the case of weighted graphs, Dijkstra) traversal on the subgraph, induced by the union of those paths. We refer to this algo-rithm as Landmarks-BFS (Algorithm 3).

For k landmarks, the size of the subgraph will be less than 2 kD . Consequently, the memory complexity of Landmarks-BFS is O ( kD ) and the time complexity is at most O ( k 2
Although landmarks can be selected uniformly at random, experiments of Potamias et al. [16] show that selecting land-Algorithm 2 LCA-based upper bounding algorithms Require: Graph G = ( V,E ), a landmark u  X  V , a parent 1: function Path-To u (s,  X  ) 2: Result  X  ( s ) . Sequence of 1 element. 3: while s /  X   X  do 4: s  X  p u [ s ] 5: Append s to Result 6: end while 8: end function 9: function Distance-LCA u (s,t) 10:  X  (1)  X  Path-To u ( s, ( u ) ) 11:  X  (2)  X  Path-To u ( t, X  (1) ) 12: LCA  X  Last element of  X  (2) 13:  X  (3)  X  Path-To u ( s, (LCA) ) 14: return |  X  (2) | + |  X  (3) | 15: end function 16: function Distance-SC u (s,t) 17:  X  (1)  X  Path-To u ( s, ( u ) ) 18:  X  (2)  X  Path-To u ( t, X  (1) ) 19: LCA  X  Last element of  X  (2) 20:  X  (3)  X  Path-To u ( s, (LCA) ) 21: Best  X  |  X  (2) | + |  X  (3) | 22: for ( w,w 0 )  X  (  X  (2)  X   X  (3) )  X  E do 23: Current  X  |  X  s,w | + |  X  w,w 0 | + |  X  w 0 ,t | 24: Best  X  min(Current,Best) 25: end for 26: return Best 27: end function marks with the highest degree or lowest closeness central-ity typically ensures better distance estimates, whereas it is shown that the two methods provide similar accuracy. In our experiments we use the highest degree landmark selec-tion method and compare it with the following one. Best coverage. When a landmark u lies on the shortest path between s and t , its upper bound distance estimate is exact. We say that such a landmark covers the pair ( s,t ). Consequently, the most desirable set of landmarks would be the one that covers as many vertex pairs as possible. It can be shown that the task of finding the optimal landmark set (i.e., the one with the maximal coverage) is NP-hard [16]. Instead, we propose a simple greedy strategy based on sam-pling (Algorithm 4). We sample a set of M vertex pairs, and compute exact shortest path for each pair. As the first landmark we select the vertex that is present in most paths of the sample. We remove the paths covered by that first landmark from the sample and proceed to select the second landmark as the vertex, which covers most of the remaining paths, etc.
If the graph is subject to intensive edge insertion and dele-tion, landmarks that have been computed originally become Algorithm 3 Landmarks-BFS Require: Graph G = ( V,E ), a set of landmarks U  X  V , an 1: function Landmarks-BFS (s,t) 2: S  X   X  3: for u  X  U do 4: S  X  S  X  Path-To u ( s, ( u )) . (see Algorithm 2) 5: S  X  S  X  Path-To u ( t, ( u )) 6: end for 7: Let G [ S ] be the subgraph of G induced by S . 8: Apply BFS on G [ S ] to find a path  X  from s to t . 9: return |  X  | 10: end function Algorithm 4 Select-Landmarks Require: Graph G = ( V,E ), number of landmarks k , sam-1: function Highest-Degree 2: For each v  X  V let d [ v ]  X  Degree ( v ). 3: Sort V by d [ v ]. 4: Let v ( i ) denote the vertex with i -th largest d [ v ]. 6: end function 7: function Best-Coverage 8: P  X   X  9: for i  X  X  1 ,...,M } do 10: ( s i ,t i )  X  Random pair of vertices 11: p i  X  ShortestPath ( s i ,t i ) 12: P  X  P  X  X  p i } 13: end for 15: for i  X  X  1 ,...,k } do 16: For each v  X  V P let c [ v ]  X  X { p  X  P : v  X  p }| 17: u i  X  argmax v  X  V 18: P  X  P \{ u i } 19: end for 20: return { u 1 ,...,u k } 21: end function outdated and the approximation performance deteriorates. Therefore, landmarks have to be maintained up to date. Al-though this can be achieved by means of daily or hourly full recomputation, such a solution is computationally expen-sive. Moreover, for certain applications, such as the above-mentioned social search, it can be particularly important to maintain landmarks up to date at all times. Indeed, if the social search feature is relied upon by new users to establish their first list of contacts, it is important that adding a new contact would be immediately reflected in the consequent search orderings.

Fortunately, when landmarks are maintained in the form to accommodate edge insertions or deletions. The proce-dures for maintaining SPTs under insertions and deletions are well-known [3, 6]. In the particular case of unweighted ward.
 As an informal example, consider the SPT presented on Figure 1. Suppose that an edge { u,v 8 } has just been inserted Algorithm 5 Insert-Edge Require: Graph G = ( V,E ), a landmark u  X  V , a parent 1: function Insert-Edge u (s,t) 2: if DistTo u ( s ) &gt; DistTo u ( t ) then 3: (s,t) = (t,s) 4: end if 5: DistChanged  X  FIFOQueue() 6: UpdateIfBetterParent u ( s,t, DistChanged) 7: while not DistChanged.empty() do 8: s  X  DistChanged.pop() 9: for t  X  Neighbors( s ) do 10: UpdateIfBetterParent u ( s,t, DistChanged) 11: end for 12: end while 13: end function 14: function DistTo u (s) 15: d  X  0 16: while p u [ s ] 6 = u do 17: s  X  p u [ s ] 18: d  X  d + 1 19: if s == null then 20: return  X  . used in Delete-Edge 21: end if 22: end while 23: return d 24: end function 25: function UpdateIfBetterParent u (s,t,queue) 26: if ( p u [ t ] 6 = s ) 27: and ( DistTo u ( t ) &gt; DistTo u ( s ) + 1) then 28: p u [ t ]  X  s 29: queue.push( t ) 30: end if 31: end function into the graph. The SPT update algorithm would proceed as follows. Firstly, note that the newly added edge provides a shorter path from v 8 to the landmark than what was pre-viously available. Therefore, the parent pointer of v 8 has to be changed to make use of the new edge: p u [ v 8 ] := u . Now that the path to the landmark from v 8 has improved, we have to recursively examine all neighbors of v 8 (i.e., v v ) and check, whether switching their parent pointer to v 8 would improve their previously known path to the landmark. This is true both for v 6 and v 7 , hence we set p u [ v 6 p [ v 7 ] := v 8 . We repeat this again for all neighbors of v v . Having found no new path improvements, we complete the update.

The deletion of an edge involves two passes. Consider mark (and a new parent pointer) for v 3 , we first examine its neighbors ( v 5 and v 6 ). Unfortunately, both of them relied on Algorithm 6 Delete-Edge Require: Graph G = ( V,E ), a landmark u  X  V , a parent 1: function Delete-Edge u (s,t) 2: if p u [ s ] == t then 3: (s,t) = (t,s) 4: else if p u [ t ] 6 = s then 5: return . SPT not affected 6: end if 7: prevDist  X  DistTo ( t ) 8: p u [ t ]  X  null 9: DistChanged  X  PriorityQueue() 10: PushIfDistChanged u ( t, prevDist, DistChanged) 11: while not DistChanged.empty() do 12: t  X  DistChanged.pop() 13: Find the neighbor s of t 14: with minimal DistTo u ( s ) 15: p u [ t ]  X  s 16: end while 17: end function 18: function PushIfDistChanged u (t, prevDist, pqueue) 19: Find the neighbor s of t 20: with minimal DistTo u ( s ) 21: For all neighbors of t that are in the pqueue, 22: and have their key &gt; DistTo u ( s )+2, 23: update their key to DistTo u ( s )+2. 24: if DistTo u ( s ) == prevDist-1 then 25: p u [ t ]  X  s 26: else 27: pqueue.push( t , key= DistTo u ( s )+1) 28: for v  X  children of t in the SPT do 29: p u [ v ]  X  null 30: PushIfDistChanged u ( v, prevDist+1,pqueue) 31: end for 32: end if 33: end function v for reaching the landmark, hence they provide no immedi-ate fix. We record v 3 temporarily in a priority queue, using the best available new path length (  X  so far) as the key. We then recursively descend to process the children of v 3 in the SPT. Vertex v 5 has no immediate fix and gets recorded in the priority queue with key  X  . Vertex v 6 , however, can be connected to v 4 , retaining a path to the landmark of length 3. Consequently, there is no need to process children of v After reconnecting v 6 we must update the keys of its neigh-bors ( v 3 and v 5 ) in the priority queue  X  the new potential path of length 4 is better than the previously recorded  X  . This completes the first pass. In the second pass we empty the priority queue, rebuilding the rest of the SPT.
We provide a more formal description of the update pro-cedures in Algorithms 5 and 6, and refer the reader to [6] for detailed explanations.

In theory, a single update may trigger the SPT recompu-tation for the whole graph (e.g. deleting an edge that was a bridge between the landmark and all the other nodes). In to our experiments, the amortized time necessary to process a single update in a real Skype network is in the order of milliseconds (see Section 4.3).
We tested our approach on four real-world social network terms of network size.
The properties of these datasets are summarized in Ta-ble 1. The table shows the number of vertices | V | , number of edges | E | , average distance between vertices d (computed on a sample vertex pairs), approximate diameter  X , frac-and average time to perform a BFS traversal over the graph t Dataset | V | | E | d  X  | S | / | V | t BF S DBLP 770K 2.6M 6.3 25 85% 345 ms Orkut 3.1M 117M 5.7 10 100% 8 sec Twitter 41.7M 1.2B 4.2 25 100% 9 min Skype 454M 3.1B 6.7 60 85% 20 min
To evaluate the performance of our methods we first select a random sample of 500 vertex pairs from each graph and precompute the actual shortest path distance for every pair. We then apply the distance approximation techniques to those vertex pairs and measure their Approximation error , Time , and Disk space .

Approximation error is computed as ( ` 0  X  ` ) /` , where ` is the approximation and ` is the actual distance. Time approximation for a pair of vertices. Finally, the Disk space corresponds to the amount of data stored for each landmark.
We run our measurements on a server with 32  X  Quad-core AMD Opteron 64bit 2.2GHz processors, 256G of RAM, accessing IBM DS 3400 FC SAN disk array, running Red Hat Enterprise Linux 5 operating system. We used C++ for algorithm implementation.
The approximation quality measurements are summarized in Figure 4 and Table 3. Observe that landmark selection for the Landmarks-Basic and the Landmarks-LCA algo-rithms. The use of shortcutting in the Landmarks-SC and Landmarks-BFS seems to reduce the importance of land-mark selection. Indeed, in case of Landmarks-BFS ran-domly selected landmarks often outperform the more sophis-ticated techniques. Overall, the best coverage and highest degree techniques perform nearly equally well, and depend-ing on the particular graph either one or the other should be preferred to achieve the best possible results.
Note that the use of the LCA approach reduces the er-ror of the basic technique consistently by 10 X 50%, with fur-ther slight improvements obtained by shortcutting and BFS methods.
The disk usage in all the discussed methods is linear with respect to number of vertices, because we have to store a sin-gle value for each vertex-landmark pair. In the basic method this value is a distance and can be stored in a single byte, as distances in the studied social network graphs are small. When using SPTs, a vertex pointer needs to be stored for each vertex-landmark pair. For a graph as large as Skype, a 4-byte pointer is necessary. Consequently, the per-landmark disk space is 4 times greater when using SPTs than when storing distances only (see Table 2).

Table 4 reports the average execution time per query. This is computed as the total time required process 500 random queries sequentially divided by 500. This also includes the time spent to load precomputed data from disk on-the-fly using Linux mmap facilities. We observe that the LCA and SC methods are 3-6 times slower than the basic algorithm, milliseconds even for the Skype graph. The Landmarks-BFS method can be considerably slower, especially so for the Twitter graph, due to the presence of nodes with very high degree in this network. Basic LCA SC LBFS Table 4: Query execution time averaged across 500 queries (in ms).
Precomputation time is comprised of two parts  X  land-mark selection and the computation of SPTs (or distances, in the case of the basic method) for each landmark.
We tested the performance of the incremental update pro-cedures on our graphs by simulating a random sequence of 1000 edge modifications and using the landmark update pro-cedures to maintain 100 landmarks up to date. Each edge modification was randomly chosen to be a deletion or an insertion of an edge between two random vertices. Table 6 presents the average time necessary to update one landmark. Table 6: Average time to perform one update for one landmark.
The task of finding a shortest path between an arbitrary stra X  X  traversal from the source to the destination vertex on every query. An improvement to this can be obtained by running a bi-directional search [15]. A further improvement is obtained by exploiting the A* search with landmark-based heuristics [7, 8, 10].

Sometimes it makes sense to precompute all pairwise dis-tances. The corresponding algorithms are typically referred to as all pairs shortest paths (APSP) . Although a variety of as dynamic programming, path-forming and Boolean ma-trix multiplications, most known exact APSP algorithms are about O ( n 3 ) in time, with a few subcubic solutions for cer-distance estimation method. tain types of graphs [21]. This is not significantly better than simply performing a separate SSSP run for each vertex.
For many practical applications, finding out approximate distances between vertices can be sufficient. Careful index-ing of the graph can provide a way to later provide approx-imate answers to arbitrary distance queries in constant or logarithmic time. Thorup and Zwick [17] coin the term ap-proximate distance oracles for such algorithms. They present a method which requires O ( kn 1+1 /k ) space and O ( kmn query time. The idea of their method is to compute a se-quence of nested sets of randomly picked landmarks. The closest landmark from each set is located and stored for each d ( s,t ) can then be answered by finding a landmark u which is one of the closest to both s and t and using the approxi-mation given by Equation (2). The authors prove that their algorithm provides distance estimates which can be wrong up to a factor of 2 k  X  1.

An interesting analogy of our method to this algorithm can be observed. Indeed, let u be a single landmark. Con-sider the collection of nested sets A 0  X  A 1  X  X  X  X  A D , where A i = { v  X  V , d ( u,v )  X  i } , and D is the diameter of the graph. Then the complete shortest path  X  s,u corresponds to the bunch concept from Thorup X  X  algorithm, and the process of finding the LCA is similar to the distance estimation tech-nique used in that paper. However, the strategy of selecting the nested sets A i is completely different. Besides, the anal-used in our algorithm.

In general, the idea of landmark-based estimation has 9, 16, 18]). A closely related work is that of Potamias et al. [16], where the Landmarks-Basic algorithm is evaluated under different landmark selection strategies. The major in-novation of our work is the use of SPTs instead just keeping the distance from each landmark to every vertex.
 The algorithms Landmarks-LCA , Landmarks-SC and Landmarks-BFS are also similar to those suggested by Gu-bichev et al. [9]. However, the algorithms in [9] use different sets of landmarks for each vertex and thus store complete shortest paths to each landmark at each vertex. This results in higher memory requirements ( O ( Dkn ) instead of O ( kn ) in our approach) and prevents the possibility of performing incremental updates. The execution times reported in [9] are considerably slower when compared to ours  X  more than 4 seconds on a graph with 10 times less edges and 100 times less vertices than the Skype graph.

An important aspect of landmark-based methods is the can have a significant positive effect. Strategies, which rely on selecting landmarks with high degree , betweenness-and closeness centrality as well as ensuring proper dispersion of landmarks over the graph and its parts, have been suggested, with highest degree and closeness centrality being shown to typically yield highest accuracy in [16]. In our work, we pro-posed and evaluated an additional method that can compete with the highest degree approach, outperforming it slightly on some datasets. The combined effect of our improvements ( best coverage landmark selection with Landmarks-BFS al-gorithm) for the large Skype network is a 40% smaller error.
This paper described and evaluated two improvements to existing approaches for landmark-based estimation of short-est paths. These improvements strike a tradeoff between accuracy, query execution time and disk usage for precom-puted data. With respect to previous related work, we achieve notable accuracy improvements while maintaining the response time per query within a few milliseconds  X  even for a graph with billions of edges  X  and a space consump-tion comparable to previous state of the art methods. An exclusive property of the proposed methods is the support for dynamic updates.
 Several extensions to the proposed method are possible. presented the algorithms for the case of an undirected un-weighted graph. The generalization to weighted graphs is obtained by replacing the BFS in the SPT precomputation phase and in the Landmark-BFS algorithm with a Dijk-stra traversal. The generalization to directed graphs requires computing two shortest path trees for each landmark  X  the first one holding distances to the landmark, and the second one with distances from the landmark. The algorithms then need to be updated slightly to use both trees appropriately (e.g. lines 4 and 5 of Algorithm 3 will refer to two different trees rather than one).
 tion scheme, a landmark-based algorithm can be used as a heuristic in the (unidirectional or bidirectional) A* search, estimate exact shortest paths allows us to take larger sam-ples for best coverage landmark selection. Note that due to the incremental update capabilities of our approach, the result is a fast fully-dynamic exact shortest path algorithm. proach, all landmarks are selected ex ante and the selection of landmarks is never revised. A further improvement might be obtained by using information collected during the pro-cessing of queries in order to add or remove landmarks. Each time a query is answered, we can identify which vertices are could promote certain vertices, which lie on shortest paths frequently, to become landmarks, or we could drop land-marks that are infrequently used. The authors gratefully acknowledge the contributions of Andres K  X  utt and Andr  X e Karpi X st X senko from Skype Technolo-gies. This research is funded by the ERDF via the Estonian Software Technology and Applications Competence Center. [1] D. A. Bader, S. Kintali, K. Madduri, and M. Mihail. [2] U. Brandes. A faster algorithm for betweenness [3] E. P. F. Chan and Y. Yang. Shortest path tree [4] L. J. Cowen and C. G. Wagner. Compact roundtrip [5] A. Das Sarma, S. Gollapudi, M. Najork, and [6] D. Frigioni. Fully dynamic algorithms for maintaining [7] A. V. Goldberg and C. Harrelson. Computing the [8] A. V. Goldberg, H. Kaplan, and R. F. Werneck. [9] A. Gubichev, S. J. Bedathur, S. Seufert, and [10] T. Ikeda, M.-Y. Hsu, H. Imai, S. Nishimura, [11] J. Kleinberg, A. Slivkins, and T. Wexler. Triangulation [12] H. Kwak, C. Lee, H. Park, and S. Moon. What is [13] M. Ley and P. Reuther. Maintaining an online [14] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel, [15] I. Pohl. Bi-directional search. In D. Meltzer, [16] M. Potamias, F. Bonchi, C. Castillo, and A. Gionis. [17] M. Thorup and U. Zwick. Approximate distance [18] M. V. Vieira, B. M. Fonseca, R. Damazio, P. B. [19] D. J. Watts and S. H. Strogatz. Collective dynamics of [20] X. Zhao, A. Sala, C. Wilson, H. Zheng, and B. Y. [21] U. Zwick. Exact and approximate distances in graphs
