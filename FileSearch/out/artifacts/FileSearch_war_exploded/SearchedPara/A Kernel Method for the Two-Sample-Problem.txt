 MPI for Biological Cybernetics We address the problem of comparing samples from two probabi lity distributions, by proposing a subtypes of cancer may be treated as statistically indistin guishable from a diagnosis perspective, able to merge databases containing multiple fields, where it is not known in advance which fields drawn from each of them, by finding a smooth function which is l arge on the points drawn from p , between the mean function values on the two samples; when thi s is large, the samples are likely from different distributions. We call this statistic the Ma ximum Mean Discrepancy (MMD). Clearly the quality of MMD as a statistic depends heavily on t he class F of smooth functions that define it. On one hand, F must be  X  X ich enough X  so that the population MMD vanishes if a nd only if empirical estimate of MMD to converge quickly to its expecta tion as the sample size increases. We these will be shown to satisfy both of the foregoing properti es. On a more practical note, MMD is cheap to compute: given m points sampled from p and n from q , the cost is O ( m + n ) 2 time. We define two non-parametric statistical tests based on MMD. The first, which uses distribution-independent uniform convergence bounds, provides finite sa mple guarantees of test performance, based on the asymptotic distribution of MMD, and is in practi ce more sensitive to differences in distribution at small sample sizes. These results build on o ur earlier work in [6] on MMD for the employs a more accurate approximation to the asymptotic dis tribution of the test statistic. We begin our presentation in Section 2 with a formal definitio n of the MMD, and a proof that the population MMD is zero if and only if p = q when F is the unit ball of a universal RKHS. We also approaches. In Section 3, we provide a bound on the deviation between the population and empirical demonstrate the performance of our method on problems from n euroscience, bioinformatics, and attribute matching using the Hungarian marriage approach. Our approach performs well on high dimensional data with low sample size; in addition, we are ab le to successfully apply our test to software may be downloaded from http : // www . kyb . mpg . de / bs / people / arthur / mmd . htm Our goal is to formulate a statistical test that answers the f ollowing question: Problem 1 Let p and q be distributions defined on a domain X . Given observations X := { x 1 ,...,x m } p and q respectively, is p 6 = q ? distinctive value only when p = q . It will be defined based on [10, Lemma 9.3.2].
 Lemma 1 Let ( X ,d ) be a separable metric space, and let p,q be two Borel probability measures defined on X . Then p = q if and only if E space of continuous bounded functions on X .
 unspecified function classes F , to measure the discrepancy between p and q , as proposed in [11]. Definition 2 Let F be a class of functions f : X  X  R and let p,q,X,Y be defined as above. Then we define the maximum mean discrepancy (MMD) and its empirica l estimate as in subsequent sections). To this end, we select F to be the unit ball in a universal RKHS H [22]; compact, a universal RKHS is dense in C ( X ) with respect to the L Gaussian and Laplace kernels are universal.
 Theorem 3 Let F be a unit ball in a universal RKHS H , defined on the compact metric space X , with associated kernel k ( , ) . Then MMD [ F ,p,q ] = 0 if and only if p = q .
 This theorem is proved in [13]. We next express the MMD in a mor e easily computable form. This is  X  a sufficient condition for this is k [ p ] k 2 x may rewrite Using [ X ] := 1 associated test, in Section 4). Intuitively we expect MMD[ F ,X,Y ] to be small if p = q , and the Overview of Statistical Hypothesis Testing, and of Previou s Approaches Having defined our present context, following [9, Chapter 8]. Given i.i.d. sam ples X  X  p of size m and Y  X  q of hypothesis H test rejects the null hypothesis (bearing in mind that a zero population MMD indicates p = q ). The proposed in this paper are consistent.
 We next give a brief overview of previous approaches to the tw o sample problem for multivariate counting the number of edges in the minimum spanning tree ove r the aggregated data that connect points in X to points in Y . The computational cost of this method using Kruskal X  X  algo rithm is O (( m + n ) 2 log( m + n )) , although more modern methods improve on the log( m + n ) term. Two possible generalisations of the Kolmogorov-Smirnov test t o the multivariate case were studied in proposed in [20], which is based on the minimum distance non-bipartite matching over the aggregate p , it requires computing the closest points in the aggregated data, and counting how many of these statistic is costly to compute; [15] consider only tens of po ints in their experiments. Yet another approach is to use some distance (e.g. L where the RKHS kernel is an inner product between Parzen wind ows. Since we are not doing density the kernel width reduces the convergence rate of the associated two-sample test, com pared with Hence we use this test only for low-dimensional problems in o ur experiments. not p = q , the empirical MMD converges in probability at rate 1 /  X  m + n to its population value. This establishes the consistency of statistical tests base d on MMD. Second, we give probabilistic bounds for large deviations of the empirical MMD in the case p = q . These bounds lead directly to a threshold for our first hypothesis test.
 We begin our discussion of the convergence of MMD[ F ,X,Y ] to MMD[ F ,p,q ] .
 Theorem 4 Let p,q,X,Y be defined as in Problem 1, and assume | k ( x,y ) | X  K . Then
Pr hypothesis p = q . Under this circumstance, the constants in the exponent are slightly improved. Theorem 5 Under the conditions of Theorem 4 where additionally p = q and m = n , both with probability less than exp  X   X  2 m In this theorem, we illustrate two possible bounds B B 1 ( F ,p ) need to provide an additional bound to show convergence of an empirical estimate of B population equivalent. Thus, in the following test for p = q based on Theorem 5, we use B to bound the bias.
 Lemma 6 A hypothesis test of level  X  for the null hypothesis p = q (equivalently MMD[ F ,p,q ] = 0 ) has the acceptance region MMD[ F ,X,Y ] &lt; 2 p K/m 1 + p log  X   X  1 .
 probability decreases to zero at rate 1 /  X  m (assuming m = n ). To put this convergence rate in perspective, consider a test of whether two normal distribu tions have equal means, given they have bution with n + m  X  2 degrees of freedom, and its error probability converges at t he same rate as our test. We now propose a second test, which is based on the asymptotic distribution of an unbiased estimate of dent random variables with distribution q , the population MMD 2 is (see [13] for details). Let Z := ( z we assume m = n ). An unbiased empirical estimate of MMD 2 is which is a one-sample U-statistic with h ( z The empirical statistic is an unbiased estimate of MMD 2 , although it does not have minimum vari-ance (the minimum variance estimate is almost identical: se e [21, Section 5.1.4]). We remark that these quantities can easily be linked with a simple kernel be tween probability measures: (5) is a special case of the Hilbertian metric [16, Eq. (4)] with the a ssociated kernel K ( p,q ) = E [16, Theorem 4]. The asymptotic distribution of this test st atistic under H 5.5.1], and the distribution under H see [13] for details.
 Theorem 8 We assume E h 2 &lt;  X  . Under H [14, Section 7.2]) to a Gaussian according to where  X  2 B, p. 193]. Under H converges in distribution according to where z and  X  k ( x Our goal is to determine whether the empirical test statisti c MMD 2 form of the distribution under H we obtain (see [13]) and The fourth moment E MMD 2 kurt MMD 2 u  X  skew MMD 2 u 2 + 1 . We conducted distribution comparisons using our MMD-based tests on datasets from three real-uniform convergence approach ( MMD ), the asymptotic approach with bootstrap ( MMD 2 and the asymptotic approach with moment matching to Pearson curves ( MMD 2 test, the Friedman-Rafsky Kolmogorov-Smirnov generalisa tion ( Smir ), the Friedman-Rafsky Wald-that MMD is the only method applicable to structured data suc h as graphs.
 parameters. We illustrate this with a Gaussian RBF kernel, w here we must choose the kernel width  X  also approaches zero as  X   X   X  (where the aggregate Gram matrix becomes uniformly constan t). We set  X  to be the median distance between points in the aggregate sam ple, as a compromise between these two extremes: this remains a heuristic, however, and t he optimum choice of kernel size is an ongoing area of research.
 Data integration As a first application of MMD, we performed distribution test ing for data inte-both original samples are generated from the same distribut ion. Clearly, it is important to check caused by combining the two different source distributions , and not by real-world phenomena. We chose several real-world settings to perform this task: we c ompared microarray data from normal local field potential (LFP) electrode recordings from the Ma caque primary visual cortex (V1) with (which has very high dimension and low sample size), and iden tical (error-free) performance on the data with largest sample size.
 size (dimension; repetitions of experiment): Neural I 4000 (63; 100) ; Neural II 1000 (100; 1200); Health Status 25 (12,600; 1000); Subtype 25 (2,118; 1000).
 Attribute matching Our second series of experiments addresses automatic attri bute matching. Given two databases, we want to detect corresponding attrib utes in the schemas of these databases, based on their data-content (as a simple example, two databa ses might have respective fields Wage and Salary, which are assumed to be observed via a subsamplin g of a particular population, and we of attributes from A and from B against each other, to find the o ptimal assignment of attributes A 1 ,...,A n number of attributes.
 As a naive approach, one could assume that any possible pair o f attributes might correspond, and matches, in Table 2. We used three datasets: the census incom e dataset from the UCI KDD archive (CNUM), the protein homology dataset from the 2004 KDD Cup (B IO) [8], and the forest dataset from the UCI ML archive [5]. For the final dataset, we performe d univariate matching of attributes (FOREST) and multivariate matching of tables (FOREST10D) f rom two different databases, where each table represents one type of forest. Both our asymptoti c MMD 2 or better than the alternatives, notably for CNUM, where the advantage of MMD 2 are Wolf or Hall , whereas in FOREST they are Smir , Biau , or the t-test. Thus, MMD 2 perform more consistently across the multiple datasets. Th e Friedman-Rafsky tests do not always the BIO dataset (on these data, MMD 2 designed Type I performance). Finally, our uniform converg ence approach performs much better than in Table 1, although surprisingly it fails to detect dif ferences in FOREST10D. (  X  1 ( A 1 ) , X  2 ( A 2 ) ,..., X  n ( A n )) attributes of A (and also decomposes this way on the attribut es of B). In this case, MMD 2 can be Our goal of optimally assigning attributes from B to attributes of A via MMD is equivalent to find-ing the optimal permutation  X  of attributes of B that minimizes P n define C the linear assignment problem, which costs O ( n 3 ) time using the Hungarian method [19]. (FOREST10D). Numbers indicate the percentage of accepted n ull hypothesis (p=q) pooled over 100); FOREST 538 (1; 10; 100); CNUM 386 (1; 13; 100); FOREST10 D 1000 (10; 2; 100). We tested this  X  X ungarian approach X  to attribute matching v ia MMD 2 (BIO, CNUM, FOREST) and for table matching on a fourth (FORES T10D). To study MMD 2 on structured data, we obtained two datasets of protein grap hs (PROTEINS and ENZYMES) and used the graph kernel for proteins from [7] for table matchin g via the Hungarian method (the other tests were not applicable to this graph data). The challenge here is to match tables representing classes) in B. Results are shown in Table 3. Besides on the BIO dataset, MMD 2 statistics are based on the maximum deviation of the expecta tion of a function evaluated on each Dataset Data type No. attributes Sample size Repetitions % correct matches BIO univariate 6 377 100 90.0 CNUM univariate 13 386 100 99.8 FOREST univariate 10 538 100 100.0 FOREST10D multivariate 2 1000 100 100.0 ENZYME structured 6 50 50 100.0 PROTEINS structured 2 200 50 100.0 Table 3: Hungarian Method for attribute matching via MMD 2 EST), multivariate (FOREST10D), and structured data (ENZY MES, PROTEINS) (  X  = 0 . 05 ;  X % correct matches X  is the percentage of the correct attribute matches detected over all repetitions). estimates as an intermediate step. Our method either outper forms competing methods, or is close to graphs, for which it is currently the only option.
 Acknowledgements: The authors thank Matthias Hein for helpful discussions, Pa trick Warnat (DKFZ, Heidelberg) for providing the microarray datasets, and Nikos Logothetis for providing the neural datasets. NICTA is funded through the Australian Gov ernment X  X  Backing Australia X  X  Ability initiative, in part through the ARC. This work was supported in part by the IST Programme of the European Community, under the PASCAL Network of Excellence , IST-2002-506778.

