 This paper describes our deep learning system for sentiment anal-ysis of tweets. The main contribution of this work is a new model for initializing the parameter weights of the convolutional neural network, which is crucial to train an accurate model while avoid-ing the need to inject any additional features. Briefly, we use an unsupervised neural language model to train initial word embed-dings that are further tuned by our deep learning model on a distant supervised corpus. At a final stage, the pre-trained parameters of the network are used to initialize the model. We train the latter on the supervised training data recently made available by the official system evaluation campaign on Twitter Sentiment Analysis orga-nized by Semeval-2015. A comparison between the results of our approach and the systems participating in the challenge on the of-ficial test sets, suggests that our model could be ranked in the first two positions in both the phrase-level subtask A (among 11 teams) and on the message-level subtask B (among 40 teams). This is an important evidence on the practical value of our solution. I.5.1 [ Pattern Recognition ]: Models X  Neural nets Convolutional neural networks; twitter sentiment analysis
In this work we describe our deep convolutional neural network for sentiment analysis of tweets. Its architecture is most similar to the deep learning systems presented in [2, 3] that have recently es-tablished new state-of-the-art results on various NLP sentence clas-sification tasks also including sentiment analysis. Convolutional neural networks have been also successfully applied in various IR applications, e.g., [8, 9]. While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and
This work was carried out at University of Trento. Professor at University of Trento, DISI.
 c  X  2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
 automatically constructed lexicons, e.g. [5, 11], requires careful at-tention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples.

It turns out that providing the network with good initialisation parameters can have a significant impact on the accuracy of the trained model. To address this issue, we propose a three-step pro-cess to train our deep learning model for sentiment classification. Our approach can be summarized as follows: (i) word embeddings are initialized using a neural language model [4, 7], which is trained on a large unsupervised collection of tweets; (ii) we use a convo-lutional neural network to further refine the embeddings on a large distant supervised corpus [1]; (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network with the same architecture, which is then trained on a supervised corpus from Semeval-2015.

We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge: phrase-level (subtask A) and message-level (subtask B). Our system achieves high results on the official tests sets of the phrase-level and on the message-level subtasks. In addition to the above test sets, we also used the so-called progress test set, which consists of five test sets, where our system again outperforms most of the systems partici-pated in the challenge. In particular, if we ranked all systems (in-cluding ours) according to their accuracy on each of the six test sets and compute their average ranks, our model would be ranked first in both subtasks, A and B.
The architecture of our convolutional neural network for senti-ment classification is shown on Fig. 1. It is mainly inspired by the architectures used in [2, 3] for performing various sentence classifi-cation tasks. Given that our training process (described in Sec. 3.3) requires to run the network on a rather large corpus, our design choices are mainly driven by the computational efficiency of our network. Hence, different from [2], which presents an architecture with several layers of convolutional feature maps, we adopt a sin-gle level architecture. Nevertheless, single-layer architectures have been shown in [3] to perform equally well.

Our network is composed of a single convolutional layer fol-lowed by a non-linearity, max pooling and a soft-max classification layer.

In the following, we give a brief explanation of the main compo-nents of our network: sentence matrix, activations, convolutional, pooling and softmax layers. We also describe how to adapt the network for predicting sentiment of phrases inside the tweets. Figure 1: The architecture of our deep learning model for sen-timent classification.
The input to our model are tweets each treated as a sequence of words: [ w i ,..,w | s | ] , where each word is drawn from a vocabulary V . Words are represented by distributional vectors w  X  looked up in a word embeddings matrix W  X  R d  X | V | . This matrix is formed by simply concatenating embeddings of all words in V . For convenience and ease of lookup operations in W , words are mapped into indices 1 ,..., | V | .

For each input tweet s , we build a sentence matrix S  X  R where each column i represents a word embedding w i at the cor-responding position i in a sentence (see Fig. 1). To learn to capture and compose features of individual words in a given sentence from low-level word embeddings into higher level semantic concepts, the neural network applies a series of transformations to the input sentence matrix S using convolution, non-linearity and pooling op-erations, which we describe next.
The aim of the convolutional layer is to extract patterns, i.e., dis-criminative word sequences found within the input tweets that are common throughout the training instances.

More formally, the convolution operation,  X  , between an input matrix s  X  R d  X | s | and a filter F  X  R d  X  m of width m results in a vector c  X  R | s | + m  X  1 , where each component is computed as follows: where  X  is the element-wise multiplication and S [: ,i  X  m +1: i ] matrix slice of size m along the columns. Note that the convo-lution filter is of the same dimensionality d as the input sentence matrix. As shown in Fig. 1, it slides along the column dimension of S producing a vector c  X  R 1  X  ( | s | X  m +1) in output. Each compo-nent c i is the result of computing an element-wise product between a column slice of S and a filter matrix F , which is then summed to a single value.

So far we have described a way to compute a convolution be-tween the input sentence matrix and a single filter. To form a richer representation of the data, deep learning models apply a set of fil-ters that work in parallel generating multiple feature maps (also shown on Fig. 1). A set of filters form a filter bank, F  X  sequentially convolved with the sentence matrix S and producing a
In practice, we also need to add a bias vector b  X  R n to the result of a convolution  X  a single b i value for each feature map c This allows the network to learn an appropriate threshold.
To enable the learning of non-linear decision boundaries, each convolutional layer is typically followed by a non-linear activation function,  X  () , applied element-wise. Among the most common choices of activation functions are: sigmoid (or logistic), hyper-bolic tangent tanh , and a rectified linear (ReLU) function defined as simply max (0 , x ) to ensure that feature maps are always posi-tive.

We use ReLU in our model since, as shown in [6], it speeds up the training and sometimes produces more accurate results.
The output from the convolutional layer (passed through the ac-tivation function) is then passed to the pooling layer, whose goal is to aggregate the information and reduce the representation. The result of the pooling operation is: where c i is the i th convolutional feature map with added bias (the bias is added to each element of c i and e is a unit vector of the same size as c i ) and passed through the activation function  X  () .
The most popular choices for pooling operation are: max and average pooling. Recently, max pooling has been generalized to k-max pooling [2], where instead of a single max value, k values are extracted in their original order. We use max pooling in our model, which simply returns the maximum value. It operates on columns of the feature map matrix C returning the largest value: pool ( c R
The convolutional layer utilizing the activation function and the pooling layer acts as a non-linear feature extractor. Given that mul-tiple feature maps are used in parallel to process the input, deep learning networks are able to build rich feature representations of the input.
The output of the penultimate convolutional and pooling layers x is passed to a fully connected softmax layer. It computes the probability distribution over the labels: where w k and b k are the weight vector and bias of the k -th class.
To perform phrase-level sentiment analysis, we feed the network with an additional input sequence indicating the location of the tar-get phrase in a tweet. The elements are encoded using only two word types: the tokens spanning the phrase to be predicted are en-coded with 1 s and all the others with 0 s. Each word type is asso-ciated with its own embedding. So, when tackling the phrase-level sentiment classification, we form a sentence matrix S as follows: for each token in a tweet, we have to look up its corresponding word embedding in the word matrix W , and the embedding for one of the two word types. Hence, the input sentence matrix is augmented with an additional set of rows from the word type em-beddings. Other than that, the architecture of our network remains unchanged.
Convolutional neural networks can be tricky to train as are often severely subject to overfitting when trained on small datasets. In the following, we describe our approach to train our deep learning model.
We use stochastic gradient descent (SGD) to train the network and use backpropogation algorithm to compute the gradients. We opt for the Adadelta [12] update rule to automatically tune the learning rate.
While neural networks have a large capacity to learn complex decision functions they tend to easily overfit especially on small and medium sized datasets. To mitigate the overfitting issue, we augment the cost function with l 2 -norm regularization terms for the parameters of the network.

We also use another popular and effective technique to improve regularization of the neural networks  X  dropout [10]. Dropout prevents feature co-adaptation by setting to zero (dropping out) a portion of hidden units during the forward phase when computing the activations at the softmax output layer.
Convolutional neural networks are trained with non-convex func-tion optimization algorithms, which typically lead to locally op-tima. Hence, starting the optimization from a good point can be crucial to train an accurate model. We propose the following 3-step process to initialize the parameter weights of the network: 1. Given that the largest parameter of the network is the word 2. When dealing with small amounts of labelled data, starting 3. Finally, we take the the parameters  X  of the network obtained
We test our model on two subtasks from Semeval-2015 Task 10: phrase-level (subtask A) and message-level (subtask B) datasets used in Semeval-2015 are summarized in Table 1. We use train and dev from Twitter X 13 for training and Twitter X 13-test as a validation set. The other datasets are used for testing, whereas Twitter X 15 is used to establish the official ranking of the systems. For evaluation we use the official scorers from Semeval 2015, which compute the average between F-measures for the positive and neg-ative classes.

To pre-train the weights of our network, we use a large unsu-pervised corpus containing 50M tweets for training the word em-beddings and a 10M tweet corpus for distant supervision. The lat-ter corpus was built similarly to [1], where tweets with positive emoticons, like  X  :)  X , are assumed to be positive, and tweets with negative emoticons, like  X  :(  X , are labeled as negative. The dataset contains equal number of positive and negative tweets.

The parameters of our model were (chosen on the validation set) as follows: the width m of the convolution filters is set to 5 and the number of convolutional feature maps is 300. We use ReLU activation function and a simple max-pooling. The dimensionality of the word embeddings d is set to 100. For the phrase-level subtask the size of the word type embeddings, which encode tokens that span the target phrase or not, is set to 10.
To train our deep learning model, we follow our 3-step process as described in Sec. 3.3. We report the results for training the network on the official supervised dataset from Semeval X 15 using parame-ters that were initialized: (i) completely at random ( Random ); (ii) using word embeddings from the neural language model trained on a large unsupervised dataset ( Unsup ) with the word2vec tool and (iii) initializing all the parameters of our model with the pa-rameters of the network that uses the word embeddings from the previous step and are further tuned on a distant supervised dataset ( Distant ).

Table 2 summarizes the performance of our model on five test sets using three parameter initialization schemas.

We note that: first, training the network with all parameters ini-tialized completely at random results in a rather mediocre accuracy. This is due to a small size of the training set. the test datasets of SemEval X 15 subsume the test sets from previ-ous editions of Semeval, i.e., Semeval X 13 and Semeval X 14, so our results directly apply to those of the previous years. Table 2: Testing the model on the progress test sets from Semeval-2015 with different parameter initializion schemes: Random (random word embeddings); Unsup (word2vec em-beddings); Distant (all parameters from a network trained on a distant supervised dataset).

Secondly, using embeddings pre-trained by a neural language model considerably boosts the performance.

Finally, using a large distant supervised corpus to further tune the word embeddings to also capturing the sentiment aspect of the words results in a further improvement across all test sets (except for a small drop on LiveJournal X 14).
The comparison of our system performance with the official sys-tem rankings from Semeval X 15 for both subtasks A and B are sum-marized in Table 3. As we can see our system performs particularly well on subtask A, it would be ranked 1st on the official Twitter X 15 test set, while also showing excellent accuracy on all other test sets.
On subtask B our system would rank 2nd also showing high re-sults on the other test sets (except for the LiveJournal X 14). In fact, no single system at Semeval-2015 performed equally well across all test sets. For example, a system that ranked 1st on the official Twit-ter X 15 dataset performed much worse on the progress test sets rank-ing, i.e., { 14 , 14 , 11 , 7 , 12 } on { LiveJournal X 14 , SMS X 13 , Twitter X 13 , Twitter X 14 , and Sarcasm X 14 }, respectively. This results on an AveRank of 9.8, which is only at the 6th posi-tion if systems were ranked according to this average rank metric. In contrast, our system shows high robustness as its results, across all tests, would provide the AveRank of 4.3, which is the top-score according to this metric among all 40 submissions.
We described our deep learning approach to sentiment analysis of tweets for predicting polarities at both message and phrase lev-els. We give a detailed description of our 3-step process to train the parameters of the network that is the key to our success. The resulting model sets a new state-of-the-art on the phrase-level and is 2nd on the message-level subtask. Considering the average rank across all test sets our system is 1st on both subtasks.
Our network initialization process includes the use of distant su-pervised data (noisy labels are inferred using emoticons found in the tweets) to further refine the weights of the network passed from the completely unsupervised neural language model. Thus, our so-lution successfully combines together two traditionally important aspects of IR: unsupervised learning of text representations (word embeddings from neural language model) and learning on weakly supervised data. In the future we plan to apply deep learning ap-proach to other IR applications, e.g., learning to rank for Microblog retrieval and answer reranking for Question Answering.
 Acknowledgments. This work has been supported by the EC project CogNet, 671625 (H2020-ICT-2014-2). The first author was sup-ported by the Google Europe Doctoral Fellowship Award 2013. Table 3: Results on Semeval-2015 for phrase and tweet-level subtasks. Rank shows the absolute position of our system on each test set. AveRank is the averaged rank across all test sets. [1] A. Go, R. Bhayani, and L. Huang. Twitter sentiment [2] N. Kalchbrenner, E. Grefenstette, and P. Blunsom. A [3] Y. Kim. Convolutional neural networks for sentence [4] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and [5] S. M. Mohammad, S. Kiritchenko, and X. Zhu. Nrc-canada: [6] V. Nair and G. E. Hinton. Rectified linear units improve [7] J. W. Ronan Collobert. A unified architecture for natural [8] Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil. A latent [9] Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil. Learning [10] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and [11] S. M. M. Xiaodan Zhu, Svetlana Kiritchenko.
 [12] M. D. Zeiler. Adadelta: An adaptive learning rate method.
