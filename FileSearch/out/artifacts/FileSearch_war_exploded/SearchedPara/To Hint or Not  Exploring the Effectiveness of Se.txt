 Extensive previous research has shown that searchers often require assistance with query formulation and re nement. Yet, it is not clear what kind of assistance is most useful, and how e ective it is both objectively (e.g., in terms of task success) and subjectively (e.g., in terms of searcher percep-tion of the search diculty). This work describes the results of a controlled user study comparing the e ects of provid-ing speci c vs. generic search hints on search success and satisfaction. Our results indicate that speci c search hints tend to e ectively improve searcher success rates and reduce perceived e ort, while generic ones can be detrimental in both search e ectiveness and user satisfaction. The results of this study are an important step towards the design of future search systems that could e ectively assist and guide the user in accomplishing complex search tasks.
 H.3.3 [ Information storage and retrieval ]: Information Search and Retrieval| query formulation, search process User studies, query reformulation, search suggestions and assistance.
Search engines are ubiquitous, and millions of people of varying experience use them on daily basis. Unfortunately, not all searches are successful. Bilal and Kirby [3] reported that about half of the participants of their user study felt frustration when searching. Xie and Cool [10] demonstrated that most of the time users have problems with formulating and re ning search queries. Besides good retrieval perfor-mance, a successful search requires users to possess certain skills. Search skills can be trained, e.g. Google o ers a course 1 on improving search eciency. Although very use-ful, such courses are time consuming and detached from real h ttp://www.powersearchingwithgoogle.com th at in 59.5% of the cases users need help to re ne their searches or to construct search statements. Individual term ([9]) or query suggestion ([2, 4, 5]) are among the most pop-ular techniques for helping users to augment their queries. The study in [6] demonstrated that users prefer query sug-gestions over term relevance feedback, and that good man-ually designed suggestions improve retrieval performance. Query suggestion methods usually use search logs to extract queries that are similar to the query of interest and work better for popular information needs [2].

When query or term suggestions are not ecient, it is still possible to help users by providing potentially useful search hints. An adaptive tool providing tactical suggestions was presented in [7] and users reported overall satisfaction with its automatic non-intrusive advices. Modern search engines have many features that are not typically used by an aver-age user, but can be very useful in particular situations as shown in [8]. The study demonstrated the potential e ec-tiveness and teaching e ect of hints. The major di erence of our work from [8] is the type of search hints used. Rather than suggesting to users the available search functionality, this work focuses on strategic search hints, designed to solve dicult informational questions.
To estimate the e ect of strategic search hints on user be-havior we conducted a study in a form of a web search game similar to \a Google a Day" 2 and uFindIt [1]. Participants were hired using Amazon Mechanical Turk 3 .

The goal of the web search game used in the user study is to nd answers to several questions with the provided web search interface (Figure 1). Players are instructed not to use any external tools. The questions are given one by one and since tasks might be too dicult, a chance to skip a question was provided, although users were instructed that e ort put into solving a question will be evaluated. To an-h ttp://www.agoogleaday.com/ http://www.mturk.com/ 1 . Split the question into 2 or more logical parts 2. Find answers to the parts of the question 3. Use answers to the parts of the question to nd answer For example, the question: \The second wife of King Henry VIII is said to haunt the grounds where she was executed. What does she supposedly have tucked under her arm?" 1. Search [second wife King Henry VIII] to nd Anne 2. Search [Anne Boleyn under arm] to nd that her ghost T o control for the learning e ect demonstrated in [8], each user was assigned to one of the three groups: 1. users who didn't get any hints 2. users who got task-speci c hints 3. users who got the generic hints From 199 unique participants, who clicked the HIT on Amazon Mechanical Turk only 90 players nished the game. We further examined all games manually and ltered out 9 submissions for one of the following reasons: lack of e ort (e.g. skipped several tasks after none or a single query) or usage of external resources (e.g. the answer was obtained without submitting any queries or results explored didn't contain the answer). Furthermore, 10 players from the group which received hints indicated in the survey that they didn't see them, so we ltered out those submissions and nally we had 71 completed games (29 for no hints, 20 for task-speci c hints and 22 for generic hints groups).
In order to measure search success rate we looked at the number of questions answered correctly by di erent groups of users 5 . Figure 2 shows that success rate is higher for users who saw task-speci c hints compared to users who didn't get such assistance. Surprisingly, having the generic hint decreased the success rate, although users could easily ignore a hint they didn't like. A possible explanation is: generic hints were harder to follow and users who tried and failed became frustrated and didn't restart their searches.
The plot of average time to answer a question on Figure 3 doesn't show an improvement for the task-speci c hints group, except for the question 1. Our task-speci c hints represent a possible way to solve a problem and there is no guarantee, that it is the fastest one. It is worth noting, that users from the generic search hint group had slightly higher variance in success time, which can probably be explained by the fact that some users were successful in nding the right way to follow the hint and some other users struggled with it much longer. Another insight comes from the number of incorrect attempts users made. Figure 4 demonstrates the average number of incorrect answer attempts for all groups of users. Although the variance is high, there is a tendency for users who saw task-speci c hints to make less attempts than both other groups. This is not in direct correspondence
Si nce users were allowed to skip a question we are counting the number of questions that were eventually solved cor-rectly even if a player made some incorrect attempts
Finally, we looked at the surveys lled out by each group of users. Figure 5 presents proportions of di erent answers to three of the questions: \How did you like the game?", \How dicult was the game?" and \Were search hints use-ful to you?". Surprisingly, user satisfaction with the game was lower for users who saw hints during the game and users who didn't get any assistance enjoyed it more. The replies to the question about game diculty are in agreement with the success rate: users who saw task-speci c hints rated diculty lower than participants who struggled to nd the correct answers. The game was very dicult on average, however, some participants from the group who received task-speci c hints surprisingly rated it as very easy, which suggests that our hints do help users. This is supported by the answers to the last question on whether hints were helpful (Figure 5c).

To summarize, the results of the conducted user study suggest that speci c search hints can be helpful, which is indicated by higher success rate, lower number of incorrect attempts and positive feedback in the end of study survey. In contrast, generic hints can have negative e ect on user ex-perience, which is indicated by lower success rate, increased number of incorrect attempts and higher perceived tasks complexity according to the survey.
In this paper we studied the e ect of strategic search hints on user behavior. The conducted user study in a form of a web search game demonstrated the potential of good hints in improving search success rate. However, to be useful, they should be designed carefully. Search hints that are too general can be detrimental to search success. We also nd that even searchers who are more e ective using speci c search hints, feel subjectively less satis ed and engaged than the control group, indicating that search assistance has to be speci c and timely if it is to improve the searcher experience.
We should note, that speci c search hints used in this work were manually generated and an interesting question of future work is how to generate such useful hints automat-ically. It should be possible to learn strategies applied by the experienced search users and suggest them to the rest.
The authors would like to thank Daniel Russel for pro-viding an archive of questions from \a Google a Day" search game. This work was supported by the DARPA CSSG pror-gram through grants N11AP20012 and D11AP00269.
