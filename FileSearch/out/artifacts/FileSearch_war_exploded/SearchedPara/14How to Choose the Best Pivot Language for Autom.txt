 MICHAEL PAUL, ANDREW FINCH, and EIICHRIO SUMITA , National Institute of Information The quality of statistical machine translation ( SMT ) approaches heavily depends on the amount and coverage of bilingual language resources available for training the statis-tical models. There exist several data collection initiatives large amounts of textual data. For frequently used language pairs like French-English, large text datasets are readily available. However, for most of the other language pairs, only a limited amount of bilingual resources are available, if any at all.
In order to overcome language resource limitations, recent research on SMT has fo-cused on the usage of pivot languages [Bertoldi et al. 2008; de Gispert and Marino 2006; Utiyama and Isahara 2007; Wu and Wang 2007]. Instead of a direct translation between two languages, where only a limited amount of bilingual resources is avail-able, the pivot translation approach makes use of a third language that facilitates the use of larger amounts of bilingual data for training. In a first step, the source lan-guage input is translated into the pivot language using statistical translation models trainedonthe source-pivot language resources. In the second step, the translation in the pivot language is translated into the target language using a second translation engine trained on the pivot-target language resources. Although the pivot translation approach does enable translation between languages where no bilingual resources ex-ist at all, the drawback of this translation method is that the translation quality may deteriorate in the two-step process, that is, small translation errors during the first step may lead to severe errors in the target language output.

In previous research on pivot translation, the pivot language was typically selected based on two criteria: (1) the availability of bilingual language resources and (2) the language relatedness between source and pivot languages.

In most recent research, English has been the pivot language of choice due to the richness of available language resources. For example, Utiyama and Isahara [2007] exploited the Europarl 2 corpus for comparing pivot translation approaches between French, German, and Spanish via English, and the IWSLT evaluation campaign [Paul 2008] featured a pivot translation task for Chinese-Spanish translation via English. In addition, several research efforts tried to exploit the closeness between specific lan-guage pairs to achieve high-quality translation hypotheses in the first step to minimize the deterioration effect in the pivot approach. For example, de Gispert and Marino [2006] proposed a method for translating Catalan-English via Spanish, and Babych et al. [2005] translated Ukrainian-English via Russian. Moreover, Cohn and Lapata [2007] exploited multiple translations of the same source phrase to obtain more reli-able translation frequency estimates from small datasets and showed that using more than one pivot improve the overall system performance. Leusch et al. [2010] generate intermediate translations in several pivot languages and using system combination techniques to output a consensus translation.

However, the preceding criteria might not be sufficient for choosing the best pivot language, especially for Asian languages. With the exception of Chinese, only a few parallel text corpora for Asian languages and English are publicly available. Moreover, language families in Asia cover a large number of different languages and are more linguistically diverse than Indo-European language families. Recent research on pivot translation from or into Asian languages has shown that the usage of non-English pivot languages can improve translation quality for certain language pairs [Paul et al. 2009].

Concerning the contribution of aspects of different language pairs on the quality of machine translation, Birch et al. [2008] identified three features (morphological com-plexity, amount of reordering, historical relatedness) for predicting the success of MT in translations between the official languages of the European Union. Moreover, Koehn et al. [2009] investigated an additional feature (translation model complexity) using the JRC-Aquis corpus covering not only Indo-European languages but also one Semitic and three Finno-Ugric languages. Specia et al. [2011] investigated the applicability of quality estimation indicators (complexity, fluency, named entities) in predicting the adequacy of translations on the sentence level for Arabic-English.
This article differs from previous research in the following aspects: (1) it focuses on the framework of pivot translation, where a target language translation of a source language input is obtained through an intermediate pivot language; (2) it investigates what factors make a pivot language effective; and (3) it analyzes what impact these factors have on the overall translation quality of language pairs, not only including Indo-European languages, but also a large variety of Asian languages. Pivot-based SMT experiments translating between 22 Indo-European and Asian languages are carried out and analyzed in Section 2 to provide new insights into how much language differences affect the translation performance of pivot translation approaches. In Section 3, eight factors (language family, vocabulary, sentence length, language perplexity, translation model entropy, reordering, monotonicity, engine performance) are investigated to determine the significance of each factor in predicting translation quality using linear regression analysis. Pivot translation is a translation from a source language ( SRC ) to a target language ( TRG ) through an intermediate pivot (or bridging ) language ( PVT ). Within the SMT framework, the following coupling strategies have already been investigated. (1) Cascading of Two Translation Systems . The first MT engine translates the source (2) Pseudo Corpus Approach . (a) Creates a  X  X oisy X  SRC-TRG parallel corpus by trans-(3) Phrase-Table Composition . The translation models of the SRC-PVT and PVT-TRG (4) Bridging at Translation Time . The coupling is integrated into the SMT decoding (5) Multi-Pivot Translation . Intermediate translations into several pivot languages
However, as the scope of this article is not to improve pivot translation methods but to investigate the effects of the pivot language selection for statistical machine translation involving low-resource languages, the method of cascading two translation systems is adopted in the pivot translation experiments reported in this article.
Pivot translation using the cascading approach requires two MT engines, where the first engine translates the source language input into the pivot language and the sec-ond engine takes the obtained pivot language output as its input and translates it into the target language. Given N languages, a total of 2*N*(N-1) SMT engines have to be built in order to cover all N*(N-1)*(N-2) SRC-PVT-TRG language pair combinations. The effects of pivot language selection on MT quality are investigated using the multi-lingual Basic Travel Expressions Corpus ( BTEC ), which is a collection of sentences that bilingual travel experts consider useful for people going to or coming from another country [Kikui et al. 2006]. The sentence-aligned corpus consists of 160K sentences pairs 3 covering 22 Indo-European and Asian languages which belong to a variety of language families, including Germanic (DA, DE, EN, NL), Romance (ES, FR, IT, PT, PTB), Slavic (PL, RU), Indo-Iranian (HI), Afro-Asiatic (AR), Austronesian (ID, MS, TL), Taid-Kadai (TH), Austro-Asiatic (VI), Sino-Tibetan (ZH, ZHT), Japanese (JA), and Korean (KO) languages.

The corpus statistics are summarized in Table I, where Voc specifies the vocabulary size, Len the average sentence length, and OOV the percentage of unknown words in the respective datasets. These languages differ largely in word order (i.e., order : subject-object-verb ( SOV ), subject-verb-object ( SVO ), verb-subject-object ( VSO ), no dom-inant word-order 5 ( mixed )), segmentation unit (i.e., unit : phrase, word, none), and de-gree of inflection (i.e., inflection : high, moderate, light). Very similar characteristics can be seen for Indo-European languages and for certain subsets of Asian languages (JA, KO; ID, MS).

In addition, Indo-European languages have, in general, a higher degree of inflection compared to Asian languages. Concerning word segmentation for languages that do not use a white space to separate word/phrase tokens, the corpora were preprocessed using language-specific word segmentation tools, that is, CHASEN CLAS 7 for Chinese, WORDCUT 8 for Thai, and an inhouse segmenter for Korean. For all other languages, simple tokenization tools were applied. All datasets were processed in a case-sensitive manner with punctuation marks preserved.

The language resources were randomly split into three subsets for the evaluation of translation quality ( eval , 1,000 sentences); the tuning of the SMT model weights ( dev , 1,000 sentences), and the training of the statistical models ( train ). However, in a real-world application, identical language resources covering three or more languages are not necessarily to be expected. In order to avoid a trilingual scenario for the pivot translation experiments, the train corpus was randomly split into two subsets of 80K sentences each, whereby the first set of sentence pairs was used to train the SRC-PVT translation models and the second subset of sentence pairs was used to train the PVT-TRG translation models. In total, 924 SMT translation engines were built to cover all 9,240 language-pair combinations.

The SMT model training as well as the evaluation of the MT results were carried out in a case-sensitive fashion with punctuation marks reserved. For the training of the SMT models, standard word alignment [Och and Ney 2003] and language modeling [Stolcke 2002] tools were used. For the translation, a multistack phrase-based decoder [Finch et al. 2007] built within the framework of a feature-based exponential model containing a standard set of features 9 was used. Minimum error rate training ( MERT ) was used to tune the decoder X  X  parameters, and was performed on the dev set using the technique proposed by Och and Ney [2003].
 For the translation quality evaluation, we applied the standard automatic metric BLEU [Papineni et al. 2002], which calculates the geometric mean of n-gram precision of the system output with respect to reference translations multiplied by a brevity penalty to prevent very short candidates from receiving too high a score. Scores range between 0% (worst) and 100% (best). For the experiments reported in this article, sin-gle translation references were used. In order to get an idea of how diverse the investigated languages are, we calculated the language perplexity of the target language evaluation datasets according to a standard 5-gram language model trained on the respective training datasets. Table II lists the language perplexity and the total entropy , that is, the entropy multiplied by the number of words of the evaluation dataset. The total entropy figures represent the entropy of the whole corpus, and the numbers indicate that Hindi and Vietnamese are supposed to be the most difficult languages, followed by Tagalog, Thai, and Japanese. In general, the total entropy figures of Indo-European languages are much lower than those of Asian languages.

In order to get an idea of how difficult the translation task for the different lan-guages is supposed to be, we calculated the BLEU scores for all the language-pair com-binations of the direct translation approach using the SRC-TRG engines trained on the full corpus. The obtained results are summarized in Table III.

For each source (target) language, the language pair achieving the highest evalua-tion scores are highlighted using black (white) scores in boldface (italic), respectively. The highest evaluation scores were achieved for closely related language pairs, such as Portuguese  X  Brazilian Portuguese, Indonesian  X  Malay, English Japanese  X  Korean. The lowest translation quality were obtained when translating from Chinese, Japanese, or Korean into any of the not closely related languages and vice versa.

The results show the large diversity between the investigated language pairs. In general, the evaluation scores for Indo-European-only language pairs are much higher than those for language pairs involving Asian languages. Interestingly, not all lan-guage pairs having English as the source language always achieved the highest scores, especially when translating into Asian languages. Similarly, the quality of English translations depends largely on the respective source language.
 This indicates that a deterioration in translation quality is to be expected when English is used as the pivot language compared to other pivot languages, where higher evaluation scores for the direct translation from/into the pivot language were obtained. Figure 1 summarizes the BLEU score ranges ([MIN:MAX]) for all the pivot translation experiments obtained for the given pivot language in terms of a box-and-whisker dia-gram. Each box part goes from the first to the third quartiles, and the dot in the box represents the mean score of the respective BLEU score distribution. The results show a large variation in BLEU scores for all pivot languages, indicating that there is not a single  X  X est X  pivot language, but the quality of a given pivot translation task largely depends on the respective source and target languages. For Indo-European pivot lan-guages, the best language combination scores are, in general, much higher than the ones obtained for Asian pivot languages.

Table IV lists the highest BLEU scores for the pivot translation experiments obtained for all language-pair combinations. The pivot languages achieving the highest scores ( oracle pivot ) for translating the source language into the target language are given in parentheses. Non-English oracle pivot languages are highlighted in boldface. The figures show that the English pivot approach still achieves the highest scores for the majority of the examined language pairs. However, in 54.8% (230 out of 420) of the cases, a non-English pivot language (mainly PT, PTB, MS, ID, JA, KO) is preferable.
In addition, the experimental results show that the selection of the best pivot lan-guage is not symmetric for 21.4% (90 out of 420) of the investigated language pairs. For languages that are closely related, such as Portuguese versus Brazilian Portuguese and Malay versus Indonesian, the related language should be chosen as the pivot lan-guage when either translating from or into the respective language for 88.7% (71 out of 80) and 85.0% (68 out of 80) of the pivot translation experiments. Moreover, Japanese is the dominant pivot language when translating from Korean into another language (95.0%, 19 out of 20) , but not for the translation into Korean (30.0%, 6 out of 20). These results suggest that in general pivot languages closely related to the source language have a larger impact on the overall pivot translation quality than pivot languages re-lated to the target language.

Interestingly, for Indo-European-only language pairs, only Indo-European languages are the oracle pivot language, the majority of which is English. In addition, Span-ish is the pivot language of choice when translating from English into another Indo-European language, and the Dutch pivot achieved the highest BLEU scores for Germanic-only language pairs. On the other hand, when translating between Asian languages, only 65.6% (59 out of 90) of the oracle pivot languages are Asian languages.
In order to investigate the dependency of pivot language selection and language families further, Table V summarizes the BLEU scores of pivot translations between only (a) non-English Indo-European and (b) Asian language pairs. The results of the Indo-European-only language pairs in the table on the left confirm the findings of Table IV. Portuguese and Brazilian Portuguese are still the dominant pivot languages for non-English Indo-European language pairs. An increase of Spanish (Dutch) oracle pivot language pairs can be seen for the translation between only Romance (Germanic) languages, respectively. Similarly, Malay and Indonesian are the dominant pivot lan-guages, followed by Japanese and Korean, for Asian-only language pairs, most of which achieve BLEU scores that are only slightly lower than the ones for the English oracle pivot language experiments reported in Table IV.

Table VI summarizes the proportion of the experiments in which the respective pivot language achieved the highest evaluation score for the pivot translation experiments summarized in Table IV (all language pairs) and Table V (non-English Indo-European language pairs, Asian language pairs). The results show that English is indeed the pivot language of choice for the majority of the investigated translation directions, but for almost half of the language pairs, a non-English pivot language is preferable.
In order to investigate how much of an improvement in pivot translation perfor-mance can be achieved by using non-English pivot languages instead of an English pivot, we calculated the difference in BLEU scores for all 188 non-English language pairs, where the non-English pivot language improved translation quality. Table VII summarizes the average, minimal, and maximal gains in BLEU scores for the respec-tive pivot language translation experiments. The pivot languages are sorted according to the highest average increase in translation performance, and the amount of im-proved language pairs are given in parentheses. In total, an average gain of 2.2 BLEU points was obtained for the investigated language pairs. The highest gains (13.3/11.4 BLEU points) were achieved for the Japanese/Korean pivots when translating Korean/Japanese into Chinese, respectively.
 If we had to select a single pivot languages for all translation directions, however, English seems to be the best choice. Figure 2 lists the average BLEU score differences of the respective non-English pivot towards the English pivot translation tasks. In order to investigate the dependency between the best pivot language selection and the amount of available training resources, we repeated the pivot translation exper-iments described in the previous sections for SMT models trained on 10K sentence subsets ( BTEC 10 k ) randomly extracted from the BTEC 80 k
The results showed that 86.4% of the pivot language selections are identical for the small (10K) and large (80K) training data conditions. For the remaining 63 out of 462 translation tasks, Table VIII lists how the oracle pivot language selection changed. In the case of the small training datasets, the pivot language is closely related (in terms of direct translation quality) to the source language. However, for larger training datasets, the focus shifts towards closely related target languages (marked in boldface) for the majority (37 out of 63) of the investigated language pairs that are listed in the left part of Table VIII. Therefore, in general, the higher the translation quality of the pivot translation task, the more dependent the selection of the best pivot language is on the system performance of the PVT-TRG task. Moreover, for 18 out of 63 translation tasks, the pivot language changed to English even for tasks where the 10K oracle pivot is closely related to either the source or the target language. The remaining eight translation tasks where the oracle pivot selection depends on the training data size translated mainly from or into Chinese and consist of the more difficult translation tasks investigated in this article. This indicates that languages closely related to either the source or the target language are to be preferred as pivot languages for language pairs of low translation quality which augurs well for data availability. The diversity of the best pivot languages reported in the last section give rise to the question of what makes a language an effective pivot language for a given language pair.

We investigated the following eight factors (comprised of a total of 45 distinct fea-tures) based on the language resources and SMT engines ( SRC-PVT , PVT-TRG )usedfor the pivot translation experiments described in Section 2. The number given in paren-theses after each factor indicates the total number of features of the respective factor. For SMT engine-related features, both translation directions ( SRC-PVT , PVT-TRG ) are taken into account.  X  Language Family (2) . A binary feature verifying whether or not the source and  X  Vocabulary (15) . The training data vocabulary size of source and target languages,  X  Sentence Length (12) . The average sentence length (computed in terms of words) of  X  Reordering (6) . The amount and span of word order differences (reordering) in the  X  Language Perplexity (4) . The perplexity of the utilized language models measured  X  Translation Model Entropy (2) . The amount of uncertainty involved in choosing  X  Engine Performance (2) . The BLEU scores of the respective SMT engines used for  X  Monotonicity (2) . The BLEU score difference of a given SMT engine for decoding
The impact of these factors in isolation on the translation performance is measured using linear regression, which models the relationship between a response variable and one or more explanatory variables. Datasets are modeled using linear functions, and unknown model parameters are estimated from the data. In this article, the response variable is defined by the BLEU metric (measuring the pivot translation per-formance), and the explanatory variables are given by the feature values obtained for each of the respective language pair combinations.

Figure 3 gives an example for a simple linear regression using the reordering quan-tity feature as the explanatory variable for (a) all language pairs, (b) Indo-European languages only, and (c) Asian languages only. The closely grouped plot of the Indo-European languages indicates that word-order differences are quite limited. In con-trast, the Asian language plot is quite scattered, and therefore more errors are to be expected for the translation between these languages. Taking into account translations between Indo-European and Asian languages, translation errors due to word-order dif-ferences are even more severe, as illustrated in the all-language plot.

The  X  X oodness of fit X  of the explanatory variable(s) is calculated using the R efficient of determination, which is a statistical measure of how well the regression line approximates the real data points. An R 2 of 1.0 indicates that the regression line perfectly fits the data. For the reordering quantity factor, for example, we obtain an R 2 of 0.2385 for all language pairs, which indicates that 23.85% of the differences in translation performance can be explained by this factor. Table IX summarizes the R 2 scores of the multiple linear regression analysis of the respective investigated factors, that is, all features of a given factor are combined and treated as multiple explanatory variables. In total, 81% of the system performance variations can be explained when all investigated factors are taken into account. For Indo-European language pairs, the impact is even larger (91%). However, for Asian language pairs, the investigated factors have much less correlation (an R with the overall pivot translation translation quality, indicating the difficulty of select-ing an appropriate pivot language for translation tasks, including Asian languages. The impact of each factor on the translation performance is also given in Table IX. The results show that engine performance is the most correlated factor, followed by translation model entropy and reordering when all language combinations are taken into account. Language family and language perplexity seem to have the least impact on translation performance. However, when applying linear regression on lan-guage subsets (only Indo-European vs. only Asian languages), the impact of the factors largely differs. Similar for all language pairs, the engine performance factor is most rel-evant for both Indo-European and Asian language subsets.

For pivot translations between Indo-European languages, sentence length , reorder-ing ,and vocabulary are more predictive than the translation model entropy factor. Moreover, the monotonicity factor obtains the lowest R 2 score, indicating that word-order differences between Indo-European languages occur mainly on a phrase level ( local reordering ) and that only minor gains can be achieved when reordering suc-cessive phrases. The high R 2 score for sentence length also suggests that the ratio of sentence length is an important feature when selecting an appropriate pivot language for closely related languages.
 On the other hand, looking at the Asian language pair regression results, the lower R 2 scores underline the large diversity between the Asian languages. Relatively high R 2 scores for reordering and monotonicity are obtained for Asian languages, indicating that structural differences between the pivot language and the source/target language largely affect the overall pivot translation quality. Besides the predictive power of each factor, we calculated the R besides one ( leave-one-out ) in order to investigate the contribution of each factor to the multiple linear regression analysis. In general, the smaller the R a given factor, the larger the contribution of this factor to the explanation of the overall translation performance is supposed to be.

The results summarized in Table X show that the largest contribution for all lan-guage pairs is obtained for the engine performance factor, followed by language perplex-ity and sentence length . Interestingly, the vocabulary factor contributes as much as the engine performance factor for Indo-European languages, but not for Asian languages. This confirms that morphological similarities between highly inflected languages are important for identifying an appropriate pivot language. Moreover, for Indo-European-only and Asian-only language pairs, the omission of any of these factors led to lower R 2 scores, but the difference to the complete factor set is much smaller. This shows the importance of all the investigated features for the task of pivot language selection, especially if largely diverse languages are to be taken into account. In order to investigate whether the selection of a pivot language depends more on its relationship to the source language or the target language, we carried out a linear re-gression analysis based on all factors using (a) only source language-related features ( SRC-PVT only ) and (b) only target language-related features ( PVT-TRG only ). The re-sults are summarized in Table XI.

The source language features seem to be more predictive than the target language features. However, for more coherent language pairs, like in the case of Indo-European languages, the impact on how much language diversity affects pivot translation per-formance shifts towards the target language-related features. Moreover, limiting the features to either only the source or only the target features leads to a large decrease in the R 2 scores for all language datasets, underlining the importance of both source language-related and target language-related feature sets for identifying an appropri-ate pivot language for a given language pair. In this article, the effects of using non-English pivot languages for translations be-tween 22 Indo-European and Asian languages were compared to the standard English pivot translation approach. The experimental results revealed that English is the best pivot for the majority of the investigated languages, but for 54.8% of language pairs, a non-English pivot language is preferable. On average, a gain of 2.2 BLEU points can be obtained by using non-English pivot languages instead of an English pivot. In addition, the choice of the best pivot is not symmetric for 21.4% language pairs. Interestingly, for Indo-European-only language pairs, only Indo-European languages are the oracle pivot language, whereas only 65.6% of the oracle pivot languages are Asian languages when translating between Asian languages.

In order to get an idea of what makes a language an effective pivot language for a given language pair, we investigated the impact of eight translation quality indi-cators. A linear regression analysis showed that 81% of the variation in translation performance differences can be explained by a combination of these factors. The most informative factor in identifying the best pivot language is engine performance ,thatis, the translation quality of the SMT engines used to translate (a) the source input into the pivot language and (b) the pivot language MT output into the target language. In addition, the highest correlation of the investigated factors to pivot translation perfor-mance was obtained when both source language-related and target language-related features were combined. The importance of source versus target language features largely depends on the diversity of the investigated language pairs, that is, source language features are preferable for heterogeneous language pairs, whereas the fo-cus shifts towards target language-related features for more coherent language pairs. In addition, the differentiation between Indo-European and Asian languages revealed that the task of identifying a pivot language for new language pairs largely depends on the availability of structurally similar languages.

As future work, we are planning to investigate the importance of the factors ana-lyzed in Section 3 in the selection of pivot languages for new language pairs by ap-plying a machine learning approach, such as support vector machines (SVM) to train discriminative models for the task of predicting a pivot language that achieves the highest translation performance for a given translation task.

In addition, we would like to study the effects of pivot language selection on pivot translation methods other than the cascading method utilized here. Although such methods are computationally more expensive, we expect these to improve the overall pivot translation quality further.

