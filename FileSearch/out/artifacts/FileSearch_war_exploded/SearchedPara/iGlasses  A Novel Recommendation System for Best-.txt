 We demonstrate iGlasses , a novel recommendation system that accepts a frontal face photo as the input and returns the best-fit eyeglasses as the output. As conventional recom-mendation techniques such as collaborative filtering become inapplicable in the problem, we propose a new recommen-dation method which exploits the implicit matching rules between human faces and eyeglasses. We first define fine-grained attributes for human faces and frames of glasses re-spectively. Then, we develop a recommendation framework based on a probabilistic graphical model, which effectively captures the correlation among these fine-grained attributes. Ranking of the frames (glasses) is done by their similarity to the query facial attributes. Finally, we produce a syn-thesized image for the input face to demonstrate the visual effect when wearing the recommended glasses.
 Eyeglasses Recommendation; Probabilistic Graphical Model
People will not stop pursuing beauty and fashion. Every-one wants to be attractive and gains self-confidence in the presence of other people. Among all fashionable accessories, eyeglasses are probably one of the most important tools to show one X  X  temperament. However, people often face the problem of selecting a right pair of eyeglasses that fit his/her face shape and hairstyle the most. The main difficulty is that everyone is unique and has distinctive appearance which makes it hard to refer to others X  recommendations. More-over, making the right choice requires prior knowledge of understanding style and color matching between glasses and one X  X  face. For instance, rectangular shape of eyeglasses can make a round face appear thinner and longer. To address the above problem, we develop a novel mobile APP named iGlasses , which recommends the best-fit eyeglasses based on one X  X  facial traits like a domain expert.

We utilize 17 fine-grained facial attributes to construct user profiles, including gender , race , eyebrow thickness , eye-brow length , eyes shape , eyes color , nose bridge , mouth width , smiling , lip thickness , lip color , skin color , jaw shape , face shape , fatness , hair color and hair length . We focus on the facial attributes as they include rich information of people and act as the main influence factors in the context of eye-glasses recommendation.

For facial attribute extraction and learning, we make use of the adaptive framework proposed by Kumar et al. [3], where SVM and Adaboost are combined to automatically se-lect on screen space the face region and feature type for each facial attribute. Firstly, all face images are preprocessed be-fore feature extraction. We align faces to a canonical pose by choosing the corners of both eyes as two fiducial points. Then, all face images are cropped and resized to a fixed width by running Viola Jones face detector [6]. To extract hair features, hair segmentation is done by using the Grab-Cut algorithm [5]. Once the feature extraction is completed, a set of SVM classifiers with an RBF kernel are trained for each attribute by extracting visual features (e.g., Gabor Fil-ter, HOG, Color Moments, Color Histogram, LBP, Shape Context) from different face components (e.g., whole face, eyes, nose, mouth). Experiments on our face photo dataset achieve an average accuracy higher than 80% in detecting the facial attributes.
Our recommendation model is based on a probabilistic graphical model where complex relationships among facial attributes and frame attributes are explored. Similar to the facial attributes, we define 7 discriminative frame attributes, namely type , shape , color , fit , material , thickness and size . Specifically, we construct a tree-structured conditional ran-dom fields model[4] where each node represents an attribute, and each edge represents the mutual dependencies between two nodes. The reason for using tree model is that inference is easily tractable and can be learned efficiently.
A training image is denoted by a vector of attributes  X  = {  X  f ,  X  g } , where  X  f = { a f N f is the number of facial attributes (in our case is 17) locate 77 feature points on the input face image to gain the size of eyes, the width of face and etc. Secondly, the frame image is scaled according to the human face width. Finally, the face photo is overlaid with the frame image by aligning the center of the face against the center of the frame.
We construct two datasets, including a face photo (FP) dataset and an eyeglasses product (GP) dataset, for evalu-ating the iGlasses system.
 FP Dataset: We collect face photos, in which people wear-ing eyeglasses, from search engines and photo sharing web sites (e.g. Flicker, Pinterst) by using queries such as celebri-ties with eyeglasses and stars with eyeglasses . We use the images of movie stars and celebrities who wear eyeglasses as our training images, since those people always have a great sense of style. Viola Jones face detector [6] is utilized to re-move those crawled images with no face detected. Then we retain 3039 face images where the eyeglasses is considered to match with the face. Each retained face image is anno-tated with both facial attributes and frame attributes. We leverage FP dataset to learn facial attributes and build our recommendation model.
 GP Dataset: We collect eyeglasses product images from a variety of popular online eyewear stores (e.g. Warby Parker, Coastal, LensCrafters) for the recommendation results. In total, 2035 eyeglasses images are collected and each product image is labeled with frame attributes.
Our recommendation approach bridges the gap between low-level facial features and frame attributes by introduc-ing facial attributes. To evaluate the effectiveness of in-termediate facial attributes, we implement two alternative recommendation methods which directly predict the frame attributes with low-level features extracted from face im-ages. More specifically, a set of classifiers are trained for each frame attribute with FP Dataset by using multi-class SVM and neutral network methods. Here different types of fea-tures (Gabor Filter, HOG, LBP, Color Moments, Color His-togram, Shape Context, etc.) are extracted from the whole face and concatenated to form a feature vector. Then the concatenated feature vectors are utilized to train a classifier
The iGlasses prototype includes an Android APP and a server backend. The mobile client is implemented on an Android smartphone and the web server is deployed with Apache Tomcat. The client is mainly in charge of display-ing images, such as face images, eyeglasses images and syn-thesized images. While the server side is responsible for computing and communication with the client side. In the offline phase, the server builds facial attribute classifiers, constructs three recommendation models, and learns image ranking model. In the online phase, the server recognizes facial attributes and returns the synthesized images to the client.
The iGlasses demo consists of the following steps, as il-lustrated in Figure 4: Step 1: The user can either use iGlasses APP to take a photo or select an existing photo from his/her album as the input. Once the user chooses a photo, the query photo will be displayed at the client.
 Step 2: As soon as the user submits the facial attribute query on the client, the above input photo is forwarded to the server. The server utilizes active shape model [2] to lo-cate 77 feature points on the received face image and returns 17 fine-grained facial attributes by using the pre-trained SVM classifiers. Once the client obtains the facial attribute values, these facial attributes will be displayed along with face photo at the client.
 Step 3: With the recognized/predicted facial attributes, iGlasses can recommend proper eyeglasses based on one X  X  fa-cial traits once the user submits a recommendation request. The server uses our probabilistic graphical model and image ranking model to recommend the best-fit eyeglasses. For comparison purpose, we also implement two alternative rec-ommendation models on server using multi-class SVM and neural network methods, which can be configured in the APP.
 Step 4: Once the ranked list of recommended eyeglasses are returned to the user, the iGlasses system can generate the synthesis result efficiently. Users can have a preview of how the recommended eyeglasses look on their faces. In most cases, our approach outperforms the baseline methods and produces high quality recommendation results.
In this demonstration, we presented iGlasses , a novel rec-ommendation system for recommending the best-looking eye-glasses. iGlasses used a new recommendation approach based on a probabilistic graphical model, which exploited implicit matching rules between faces and eyeglasses. To qualita-tively evaluate our recommendation method, we also imple-mented two baseline methods for comparison and conducted a user study. Experiments showed promising results from our approach.
This research is supported by the National Key Basic Re-search Program of China (GrantNo. 2015CB352400). This research is also partially supported by the National Research
