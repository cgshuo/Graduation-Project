 Concise representations of frequent itemsets sacrifice read-ability and direct interpretability by a data analyst of the concise patterns extracted. In this paper, we introduce an extension of itemsets, called regular, with an immediate se-mantics and interpretability, and a conciseness comparable to closed itemsets. Regular itemsets allow for specifying that an item may or may not be present; that any subset of an itemset may be present; and that any non-empty subset of an itemset may be present. We devise a procedure, called RegularMine , for mining a set of regular itemsets that is a concise representation of frequent itemsets. The procedure computes a covering, in terms of regular itemsets, of the fre-quent itemsets in the class of equivalence of a closed one. We report experimental results on several standard dense and sparse datasets that validate the proposed approach. H.2.8 [ Database Management ]: Database Applications-Data Mining Algorithms Concise Representations, Closed and Free Itemsets
The intended objective of concise representations is to al-leviate the problems due to extracting, storing and post-processing a huge amount of frequent patterns. They sacri-fice readability and direct interpretability by a data analyst in favor of a compact, lossless representation, where item-sets whose support is derivable from others are pruned away. Closed itemsets [2] are a concise representation of frequent itemsets, yet not the only one [4, 5, 6, 7, 12, 13, 16], surely 1 abcde 2 abcd 3 b 4 ac Figure 1: A sample transaction database, the  X  -equivalence class of abcd and its covering. the most well-known. Let us explain by an example what we intend for  X  X acrificing readability X  in the case of closed itemsets. Consider the transaction database in Figure 1.
For a minimum support of 2, there is a total of 15 frequent itemsets, but only 3 frequent closed itemsets: C 1 = abcd with support 2; C 2 = b with support 3; and C 3 = ac with support 3. Closed itemsets (and concise representations, in general) are able to answer frequency queries such as  X  X s the itemset X frequent? X  and, if it is,  X  X hat is the support of X ? X . For instance, for X = abc , we look at closed itemsets that include X . If there is one ( C 1 includes it), then X is frequent. In such a case, the support of X is the maximal support of the closed itemsets that include it (only C 1 , hence the support of X is 2).

Assume now that a data analyst has focussed her atten-tion on itemsets with support of 2. Would it be reasonable to prompt her with C 1 ? On the one side, it is the only closed itemset with support 2, hence it concisely represents all item-sets the analyst is interested in. On the other side, however, the conciseness itself is the source of interpretability prob-lems. Once prompted with C 1 the data analyst has to fig-ure out which itemsets are represented by C 1 , or in other words, what its semantics is. The answer is hardly useful: all subsets of C 1 except the subsets of closed itemsets whose support is greater than the support of C 1 (technically, the  X  -equivalence class of C 1 ). Such an answer highlights that a closed itemset in isolation makes no sense for the analyst, because the itemsets it denotes, its semantics, is undeter-minable. The only practical way of presenting the semantics of C 1 to the analyst seems then by enumerating the 11 item-sets in its  X  -equivalence class, as shown in Figure 1. But this means loosing the so-much-acclaimed compactness property of concise representations.

In this paper, we introduce an extension of itemsets, called regular, with an immediate semantics and interpretability, and a conciseness comparable to closed itemsets. Regular itemsets allow for specifying that an item a may or may not be present, using the notation a ?; that any subset of an item-set may be present, using the notation { a 1 , . . . , a h that any non-empty subset of an itemset may be present, using the notation { a 1 , . . . , a k } + . We devise a procedure, called RegularMine , for mining a set of regular itemsets that is a concise representation of frequent itemsets. The procedure computes a covering, in terms of disjoint regu-lar itemsets, of the  X  -equivalence class of a frequent closed itemset. For the example C 1 above, we obtain two regu-lar itemsets, namely b { ac } + and d { abc } ? . They are a cover because every frequent itemset equivalent to C 1 belongs to the semantics of one of them. They are disjoint because no frequent itemset belongs to the semantics of both. For the example C 2 above, we obtain b ; and for C 3 we obtain { ac } We report experimental results on several standard dense and sparse datasets that show how the size of the concise representation using regular itemsets is in most cases very close to the size of closed itemsets.

The paper is organized as follows. In Section 2, we set up the notation and recall basic definitions about frequent itemsets,  X  -equivalence, closed itemsets, free sets and concise representations. The syntax and semantics of regular item-sets is introduced in Section 3. In Section 4 we propose the mining procedure RegularMine , which is experimented in Section 5. Finally, we discuss related work in Section 6 and then summarize the contribution of the paper.
Let I be a finite set of literals called items . We use meta-variables a, b, c, . . . to denote items. A set X = { a 1  X  X  is called an itemset , or a k -itemset if it contains k items. X  X  Y is abbreviated to X, Y .

A transaction over I is a pair T = ( tid, X ) where tid is a transaction identifier and X is an intemset. A transaction database D over I is a set of transactions over I . From now on, we omit I and D when clear from the context.
 A transaction T = ( tid, X ) supports an itemset I if X  X  I . The cover of I is the set of transactions that support I : The support of I is the number of transactions in its cover: support ( I ) = | cover ( I ) | . An itemset is called frequent if its support is no less than a given minimum threshold minsupp . The set of frequent itemsets is defined as:
Bastide et al. [2] introduced the relation  X  between fre-quent itemsets supported by the same set of transactions, hence equivalent (and indistinguishable) with respect to the transaction database. Given two itemsets X and Y , we write X X Y , and say that X is  X  -equivalent to Y , when cover ( X ) = cover ( Y ).  X  is an equivalence relation, namely it is reflexive, symmetric and transitive. The class of  X  -equivalence of an itemset X consists of all itemsets  X  -equivalent to X : Minimal elements (with respect to set inclusion) of a  X  -equivalence class are called free itemsets [4] or generators [2]. Formally, X is free if X  X  Min [ X ], where the mimimal function is defined as: Min S = { X  X  S | @ Y  X  S.Y  X  X } . It turns out that X is free iff there is no Y  X  X such that support ( Y ) = support ( X ). Another useful property of free itemsets is anti-monotonicity [2, 4], namely all subsets of a free itemset are free.

Maximal elements (with respect to set inclusion) of a  X  -equivalence class are called closed itemsets . Formally, X is closed if X  X  Max [ X ], where the maximal function is defined as: Max S = { X  X  S | @ Y  X  S.Y  X  X } . It turns out that X is closed iff there is no Y  X  X such that support ( Y ) = support ( X ). Given Y  X  [ X ], it is immediate to observe that the itemset X, Y belongs to [ X ]. This im-plies that Max [ X ] is a singleton, namely there is a bijection between classes of  X  -equivalence and closed itemsets.
The number of frequent itemsets can be so large that no efficient algorithm exists to enumerate all of them. This case occurs, for instance, for very low minimum support thresh-olds and for highly correlated data. A concise representation [7, 15] of frequent itemsets is a lossless representation, typi-cally consisting in a subset of F , that addresses the problem. By lossless representation, one means that starting from it: (1) frequent itemsets can be enumerated; and (2) given an itemset it can be decided whether it is frequent or not, and, if it is frequent, its support can be derived.

The set CS of frequent closed itemsets is a concise rep-resentation [17]. An itemset X is frequent iff there exists Y  X  X S such that X  X  Y . In such a case, the support of X can be calculated as: max { support ( Y ) | X  X  Y  X  Y  X  X S} .
The set FS of frequent free itemsets is not a concise rep-resentation. The pair of FS and of the free itemsets in the negative border of FS is a concise representation [4, 14]. The latter element in the pair is essential to determine whether an itemset X is frequent or not. If frequent, the support of X can be calculated as: min { support ( Y ) | X  X  Y  X  Y  X  X S} .
In this section, we introduce an extended formulation of itemsets, whose main purpose is to trade-off conciseness and interpretability. The basic idea consists of introducing spe-cial items that model cases when: an item a may or may not appear, and this will be denoted by a ?; any subset of items a 1 , . . . , a h may appear, and this will be denoted by { a 1 , . . . , a h } ? ; any non-empty subset of items a 1 , . . . , a appear, and this will be denoted by { a 1 , . . . , a k }
We start by extending the syntax of items and itemsets along this line. ? Z  X  X 6 =  X  R, { a, Y }  X  a 6 X  R Y 6 =  X   X  X ? ] , Y ? R \{ a ? } [ { a, X }  X   X  X  X  ] , a, Y  X  R, { a, b } + R, Y + R, Z + , Y ? An extended item is defined by the following grammar: where a , a i  X  X  are items, h  X  0 and k &gt; 0. We use e, f, g as meta-variables for extended items. Let J be the (finite) set of extended items. A extended itemset is a subset R  X  X  .
Example 3.1. The extended itemset ab { cd } ? represents the itemsets where a and b must necessarily appear, while c and d may or may not appear. The intended meaning of ab { cd } ? is then the set of itemsets { ab, abc, abd, abcd } .
The extended itemset ab ? { cd } + represents the itemsets where a must necessarily appear, b may or may not, and at least one between c and d appears. Its intended meaning is then { ac, ad, acd, abc, abd, abcd } .

We now formalize the intuitions underlying the example by providing a semantics mapping an extended item/itemset to the set of itemsets it denotes. The semantics s e () for extended items is defined as follows: s e ( { a 1 , . . . , a h } ? ) = { X | X  X  X  a 1 , . . . , a s e ( { a 1 , . . . , a k } + ) = { X | X  X  X  a 1 , . . . , a The semantics s () for extended itemsets is defined as follows: Notice that the semantics s () is and-compositional, namely for f ( S 1 , S 2 ) = { X  X  Y | X  X  S 1 , Y  X  S 2 ) } ). This means that the meaning of an extended itemset can be obtained by looking (only) at the meaning of its parts. As discussed in the introduction, closed itemsets and other concise repre-sentations do not have such a property. Let us consider now some syntactic issues. Since the following holds: the ? operator can be seen as syntactic sugar. In this sense, we will not make any further distinction between the ? and the ? operators, e.g., when stating that a ? belongs to b { ac } Analogously, since s ( { a } + ) = s ( a ), we can rewrite singleton itemsets over the + operator into an item.

Example 3.2. According to the definition of extended item-sets, an item can appear more than once, e.g., as in ab { ac } However, the following identities: allow for removing duplicates. The extended item above is equivalent to abc ? .

The rewriting rules describes so far are reported in Fig-ure 2 (a) as rules N 1  X  N 5. We say that an extended itemset is in normal form if no rule can further apply. Irrespectively of the order the rules are applied, an extended itemset R can be rewritten in one and only one extended itemset in normal form, which we call the normal form of R .
The notion of extended itemset does not take into account the cover nor the support of the itemsets in its semantics.
Example 3.3. Consider the transaction database D = { (1 , ab ) , (2 , a ) } , and the extended itemset R = ab ? .
Two itemsets belong to s ( R ) , namely a and ab . However, cover ( a ) = { 1 , 2 }6 = { 1 } = cover ( ab ) .
Extended itemsets are then relevant to the frequent item-set mining problem only when they denote itemsets with a common cover.

Definition 3.4. An extended itemset R is said regular if for every X, Y  X  s ( R ) we have that cover ( X ) = cover ( Y ) .
Using the notation of  X  -equivalence classes, R is regular if s ( R )  X  [ X ] for some itemset X . An equivalent formulation consists of requiring that all itemsets in the semantics of R have the same support.
 Lemma 3.5. An extended itemset R is regular iff for every X, Y  X  s ( R ) we have that support ( X ) = support ( Y ) .
Proof. The only-if part is immediate, since cover ( X ) = cover ( Y ) implies support ( X ) = support ( Y ). Consider the if-part. Let C be the itemset obtained from R by replac-ing a ? with a , and { a 1 , . . . , a k } + with a 1 , . . . , a maximal itemset in s ( R ), hence X  X  C and Y  X  C , and then cover ( X )  X  cover ( C ) and cover ( Y )  X  cover ( C ). Since by hypothesis support ( X ) = support ( C ) = support ( Y ), we conclude that cover ( X ) = cover ( C ) = cover ( Y ).
For a regular itemset R , we define cover ( R ) = cover ( X ), where X is any itemset in s ( R ). Also, we extend the notion of support as follows: support ( R ) = | cover ( R ) | . Finally, we say that a regular itemset R is frequent if support ( R )  X  minsupp .

Example 3.6. Consider the transaction database of Fig-ure 1. The extended itemset ab { cd } ? from Example 3.1 is regular, and its cover is { 1 , 2 } . The extended itemset { 1 , 2 } = cover ( abc ) .
Frequent regular itemsets are natural candidates to be adopted for a concise representation of frequent itemsets. First, a single regular itemset R represents a possibly large set s ( R ) of itemsets. Second, the interpretation of an ex-tended item in R is straightforward, even for non-technical data analysts: a ? means a may appear; { a 1 , . . . , a k that at least one among a 1 , . . . , a k must be present. Third, the and-compositionality property makes it possible to fig-ure out the semantics s ( R ) by looking at extended items in R only. We therefore formalize the notion of concise repre-sentation to the case of regular itemsets.

Definition 3.7. A finite set of regular itemsets R is a concise representation of the set F of frequent itemsets if: (a)  X  R  X  X  s ( R ) = F , and (b) for every pair R 1 6 = R 2  X  X  , s ( R 1 )  X  s ( R 2 ) =  X  .
Intuitively, given an itemset X : (a) means that X is fre-quent iff X belongs to the semantics of some R  X  X  ; and (b) means that if X is frequent, there exists one and only one such an R , hence support ( X ) can be obtained as support ( R ).
A natural question arise at this stage. How large is a concise representation R ? Since the semantics of a regular itemset is included in the class of  X  -equivalence of a closed itemset, we conclude that |CS|  X  |R| is a lower bound. As for upper bounds, at this stage we cannot draw any con-clusion (apart from the trivial one |R|  X  |F| ), but later on we will show that, in practice, there exist concise represen-tations whose size is close to |CS| and abundantly smaller than the number of frequent free sets |FS| .
We tackle the problem of mining a concise representation by looking for a set of (pairwise disjoint) regular itemsets that cover all the itemsets in a  X  -equivalence class. We start with a simple observation.

Lemma 4.1. Let C be a closed itemset, and let Min [ C ] = { X 1 , . . . , X n } be its free sets. An itemset Y belongs to [ C ] iff there exists i such that X i  X  Y  X  C .

Proof. The if-part follows since X i  X  Y  X  C implies cover ( X i )  X  cover ( Y )  X  cover ( C ) = cover ( X i ). The only-if part is immediate.

This result characterizes the  X  -equivalence class [ C ] given its maximal (closed) itemset and its minimal (free) itemsets. As a consequence, [ C ] is equivalent to: However, while the itemsets X 1 ( C \ X 1 ) ? , . . . , X satisfy condition (a) of Definition 3.7, they do not satisfy condition (b) , namely they are not pairwise disjoint.
Example 4.2. Consider the sample database and the class of equivalence [ abcd ] reported in Figure 1. Starting from the three free itemsets X 1 = d , X 2 = ba and X 3 = bc , the three regular itemsets R 1 = d { abc } ? , R 2 = ba { cd } R 3 = bc { ad } ? cover all itemsets in the class of equivalence.
However, they overlap since s ( R 1 )  X  s ( R 2 ) = { abd, abcd } , s ( R 1 )  X  s ( R 3 ) = { bcd, abcd } , s ( R 2 )  X  s ( R We point out that the overlapping between R i and R j starts at the itemset X i , X j , namely the minimal common superset of X i and X j .

In the next subsections, we devise a procedure to compute a pairwise disjoint set of regular itemsets. First, we intro-duce a further extension of items, called non-compositional, which serves to divide [ C ] into disjoint sets. Then we trans-form non-compositional itemsets into regular itemsets with-out the + operator. Finally, we merge pairs of regular item-sets by means of the + operator.
A non-compositional item is defined by the grammar of extended items augmented with the following: where h  X  0. Intuitively, { a 1 , . . . , a h }  X  represents any sub-set of { a 1 , . . . , a h } except for the the maximal one a Formally: Notice that s e ( { a }  X  ) = { X  X  , i.e., only the empty itemset is in the semantics, while s e ( {}  X  ) =  X  , i.e., no itemset is in it.
Consider now itemsets. A non-compositional itemset is a finite set of non-compositional items. The semantics s () de-fined as in (1) does not reflect the intuitive meaning of non-compositional itemsets. Consider, as an example, { ab }  X  Intuitively, we expect that b  X  s ( { ab }  X  ) and that a  X  s ( { ac } However, their conjunction ab should not be in s ( { ab } since it violates the constraint that a and b should not oc-cur together. In this sense, an and-compositional semantics does not exists. Here it is a non-compositional one: A non-compositional itemset R is said regular if cover ( X ) = cover ( Y ) for every X, Y  X  s 0 ( R ). Similarly, we can extend the notion of concise representation. However, due to the lack of and-compositionality, the class of non-compositional itemsets is not suitable, in our opinion, to be proposed to a data analyst for direct interpretation. Nevertheless, its is an intermediate representation that is useful for our purposes. The next example clarifies how the  X  -equivalence class [ C ] can be easily covered by regular non-compositional itemsets.
Example 4.3. Consider again the class of  X  -equivalence [ C ] in Figure 1, where C = abcd is a closed itemset, and X 1 = d , X 2 = ba and X 3 = bc are the free itemsets in the class. As for X 1 , we can define R 1 = X 1 , C ? = d { abcd } to cover all itemsets X such that d  X  X  X  abcd . As for X , we define R 2 = X 2 , X  X  1 , C ? = ba { d }  X  { abcd } all itemsets X such that ba  X  X  X  abcd , but such that d 6 X  X . It turns out that s 0 ( R 2 ) = { ba, bac } . Finally, for X we define R 3 = X 3 , X  X  1 , X  X  2 , C ? = bc { d }  X  { ba } cover all itemsets X such that bc  X  X  X  abcd , but such that d 6 X  X and ba 6 X  X . It turns out that s 0 ( R 3 ) = { bc } . Next we formalize the intuitions of the example.

Lemma 4.4. There exists a set R of regular non-compo-sitional itemsets with |R| = |FS| that is a concise represen-tation of frequent itemsets.

Proof. Let C be a frequent closed itemset, and let Min [ C ] = { X 1 , . . . , X n } be its free sets. For the regular non-compo-sitional itemsets N i = X i , X  X  1 , . . . , X  X  i  X  1 , C we have: (a)  X  i =1 ...n s 0 ( N i ) = [ C ]. By Lemma 4.1, X  X  [ C ] iff for some i  X  [1 , n ], X i  X  X  X  C . Let k be the minimum of such i  X  X . By construction, we have X  X  s 0 ( N k ). (b) For every pair N i , N j with i 6 = j , s 0 ( N i )  X  s  X  . In fact, assume, without loss of generality, that i &lt; j . We have N j = X j , X  X  1 , . . . , X  X  i , . . . , X s ( N i ) then X  X  X i , but since X  X  i is in N j , we have X 6 X  s ( N j ).
In this subsection, we devise a covering procedure that, given a non-compositional itemset R in , computes a set R of extended itemsets equivalent to R in and pairwise disjoint, or, formally, such that s 0 ( R in ) =  X  R  X  X  out s ( R ) and such that R 1 6 = R 2  X  R out implies s ( R 1 )  X  s ( R 2 ) =  X  . When applied to the non-compositional itemsets whose semantics is the class of  X  -equivalence [ C ], it then provides a covering of [ C ] through regular itemsets. The approach follows the rewriting rules S 1  X  S 5 reported in Figure 2 (b). Let us introduce the intuitions behind them with a few examples. Example 4.5. Consider Example 4.3.

It is immediate to notice that R 1 = d { abcd } ? can be sim-plified to d { abc } ? , i.e., by removing the item d from { abcd } due to the fact that d must necessarily occur. This is the analogous of the simplification rule N 3 from Figure 2 (a) for extended itemsets. Similarly, R 2 = ba { d }  X  { cd } R 3 = bc { d }  X  { ba }  X  { ad } ? . The general case is stated as rule S 2 in Figure 2 (b).

A similar reasoning applies to the extended item { ba }  X  R . Since b necessarily appear in R 3 , it can be removed from { ba }  X  . Thus, R 3 = bc { d }  X  { a }  X  { ad } ? . In general, we have rule S 1 .
 Algorithm 1 Covering Input: a non-compositional itemset R in of the form X, Y  X  1 , . . . , Y  X  n , Z ? Output: a set R out of pairwise disjoint extended itemsets equivalent to R in , obtained by the splitting rules S 1-S 5
R  X  X, ( Y 1 \ X )  X  , . . . , ( Y n \ X )  X  , ( Z \ X ) ? if  X  i.Y i \ X 6 =  X  then //rule S3 end if
Example 4.6. Consider R = a { a }  X  b ? . By rule S 1 , R is equivalent to a  X   X  b ? . As already noted, s (  X   X  ) is empty, and this is inherited by any itemset containing  X   X  . Thus, s ( R ) =  X  . Since any extended itemset has a non-empty semantics, this means that no extended itemset is equivalent to R . This motivates rule S 3 in Figure 2 (b).

It is worth noting, however, that a non-compositional item-set N i = X i , X  X  1 , . . . , X  X  i  X  1 , C ? defined in Lemma 4.4 for covering a  X  -equivalence class has a non-empty semantics. In fact, since X 1 , . . . , X i are minimal sets, X i 6 X  X j = 1 . . . n , and then X i  X  s 0 ( N i ) .

Example 4.7. Consider R 2 = ba { d }  X  { cd } ? from Exam-ple 4.5. The conjunct { d }  X  implies that the item d must not appear. So, { d }  X  can be removed together with all d ? in R thus yielding R 2 = ba { c } ? = bac ? . Analogously, one con-cludes R 3 = bc . In general, we have rule S 4 in Figure 2 (b). Let us briefly explain what happens if the hypothesis a 6 X  R of such a rule is not satisfied, e.g., for the non-compositional itemset a { a }  X  . Here, rule S 1 applies, so it can be rewritten as a  X   X  which, by rule S 3 , has an empty semantics. The next example explains rule S 5.

Example 4.8. Consider R = cd { ab }  X  { ab } ? . The con-junct { ab }  X  imposes that a and b cannot be both present. Thus, we partition the semantics s 0 ( R ) in two sets.
First set: s 0 ( R )  X  X  X  X  X  | a 6 X  X } . We characterize it by removing any a ? from R , and by replacing every occurrence of the form { Y, a }  X  by Y ? . In fact, since a cannot be present, any other subset of Y can appear without violating { Y, a } Summarizing, R 1 = cdb ? covers the first set.

Second set: s 0 ( R )  X  X  X  X  I | a  X  X } . We characterize such a set by adding a to R , by removing any a ? from R , and by replacing { Y, a }  X  by Y  X  . In fact, since a is now present, the constraint imposed by any { Y, a }  X  becomes equivalent to the one imposed by Y  X  . Summarizing, R 2 = cda { b }  X  covers the second set. By applying rule S 4 , we get R 2 = cda .
Figure 2 (b) summarizes the rewriting rules mentioned in the examples above. They allow for deriving zero, one or two non-compositional itemsets that are equivalent to a given one but smaller in the precise sense that at least one item a is removed from extended items of the form Y  X  . As a result, the rewriting process starting from a (set of) non-compositional itemset(s) terminates with an equivalent set of extended itemsets, i.e., with no item of the form Y  X  . The only rewriting rule that yields two itemsets is rule S 4. Here, we have to ensure that the two itemsets in the rule conse-quence are disjoint. This is immediate because one itemset does not contain a (neither a ? nor { X, a }  X  ) whilst the other does contain a . The Covering Algorithm 1 implements the rewriting rules with two optimizations. First, if applied at once, rules S 1 and S 2 do not need to be re-checked, since all other rules remove items a appearing in { Y, a }  X  or in { a } (preventing rule S 1 to fire) and explicitly remove items a ? (preventing rule S 2 to fire). Also, the initial application of S 1 and S 2 makes it superfluous to check the hypothesis a 6 X  R in rules S 4 and S 5. As a second optimization, if ap-plied at once, rule S 3 can only be re-checked after rule S 5, where an item  X   X  can potentially be introduced. Thus, rule S 3 can be folded within rule S 5.

Example 4.9. The (size of the) covering produced may vary with the order in which free sets are considered in the construction of the non-compositional itemset. For instance, consider again Example 4.3. If we reverse the order of free sets, we obtain R 0 1 = bc { abcd } ? which can be rewritten to bc { ad } ? , R 0 2 = ba { bc }  X  { abcd } ? which can be rewritten to bad ? , and R 0 3 = d { bc }  X  { ba }  X  { abcd } ? = d { bc } The only rule applicable to R 0 3 is S 5 , which yields two item-equivalent to db . Summarizing, the cover obtained includes 4 regular itemsets vs. the 3 regular itemsets obtained in Ex-amples 4.5, 4.7.
The Covering procedure yields a set of extended itemsets of the form X, Y ? , that is, the + operator is not exploited at all. In this subsection, we devise an algorithm to merge two or more extended itemsets by exploiting the rewriting rules M 1  X  M 6 reported in Figure 2 (c).

Example 4.10. With reference to our running example, in Examples 4.5 and 4.7 we derived the regular itemsets R 1 = d { abc } ? , R 2 = bac ? and R 3 = bc . Consider R 2 R . Their common part is b . The semantics of R 2 is that, in addition to b , the item a is present and c may or may not be present. The semantics of R 3 is that, in addition to b , the item c is present. The semantics of both R 2 and R can be rephrased as follows: in addition to b , at least one of a and c must be present. This is precisely the semantics of b { ac } + which, together with R 1 , covers [ abcd ] in Figure 1. This example is an application of rule M 3 in Figure 2 (c). Rule M 4 is the generalization of M 3 to the case of extended items of the form Y + (vs. items b ). Rule M 1 is self-explicative, and rule M 2 is its generalization to extended items of the form Y + .
 Algorithm 2 Merging Input: a set of R in of pairwise disjoint extended itemsets Output: a set R out of pairwise disjoint extended itemsets equivalent to R in , obtained by the merging rules M 1-M 6 while R6 =  X  do end while Let us show next an example using rule M 5.

Example 4.11. Consider the alternative cover of [ abcd ] reported in Example 4.9. It consists of R 0 1 = bc { ad } bad ? , R 0 3 = d { ac } ? and R 0 4 = db . We can apply rule M 3 to R 0 2 and R 0 4 to obtain b { ad } + . This and R 0 1 together have the following semantics: in addition to b , if c is present then any of a and d may be present or not; and if c is not present then at least one of a and d must be present. This is precisely the semantics of b { acd } + which, together with R 0 3 represent another cover of size 2 for [ abcd ] . Rule M 5 generalizes the reasoning of this example.

Finally, rule M 6 is the generalization of M 5 to the case of extended items of the form Z + (vs. items a ).

The rewriting rules M 1  X  M 6 allow for merging two ex-tended itemsets into a single one. The rewriting process ter-minates as soon as no rule can be further applied. However, such a process is inherently non-deterministic, in the sense that the order with which rules are applied is left unspecified. The Merging Algorithm 2 implements a top-down rewriting strategy, which is motivated by the following observation. For an extended itemset R , let us denote by k R the number of pure (not extended) items in R , namely k R = | R  X  X | . k 1 , k R 3  X  [ k R 2  X  1 , k R 2 ]. For instance, for rule M 1, it turns Let now k be the maximal k R for R belonging to the set of extended itemsets R under rewriting. The Merging algo-rithm proceeds top-down by considering first rules involving R 2 with k R 2 = k . By the previous observation, the rationale is to progressively reduce the number of pure items from extended itemsets with large values of k R 2 . Once no rule M 1  X  M 6 can be further applied to any R 2 with k R 2 = k , the set K of residual extended itemsets with k R 2 = k is re-moved from R and added to the output. The loop continues while R is not empty.

Example 4.12. Let C = abcd and a , b , c , and d be the free sets in [ C ] . The Covering procedure returns the follow-ing extended itemsets to be merged: a { bcd } ? , b { cd } First, a { bcd } ? and b { cd } ? are merged (rule M 3 ) to R { ab } + { cd } ? ; and cd ? and d are merged (rule M 3 ) to R { cd } + . Then, R 1 and R 2 are merged (rule M 6 ) to the final answer { abcd } + . As the last example, assume now that ac , ad , bc , and bd are the free sets in [ C ] . The Covering pro-cedure returns: ac { bd } ? , adb ? , bcd ? , bd . First, ac { bd } adb ? are merged (rule M 3 ) to R 1 = a { cd } + b ? ; and bcd ? and bd are merged (rule M 3 ) to R 2 = b { cd } + . Then, R 1 are merged (rule M 3 ) to the final answer { ab } + { cd }
We are now in the position to devise a procedure for min-ing a concise representation of frequent itemsets. Starting from a frequent closed itemset and the free sets in its class of  X  -equivalence, by Lemma 4.4 we first derive a concise rep-resentation of the frequent itemsets in the class in terms of pairwise disjoint non-compositional itemsets. Next, by the Covering and the Merging procedures we rewrite the non-compositional itemsets into equivalent pairwise disjoint reg-ular itemsets. The overall procedure, called RegularMine , is reported as Algorithm 3.

There are three sources of non-determinism in the var-ious components of the procedure. The first one is con-cerned with the order by which the free itemsets X 1 , . . . , X are considered in building the non-compositional itemsets N amples 4.9 and 4.11, the (size of the) covering found may depend on such an order. Intuitively, smaller free itemsets should be arranged first, so that the initial N i  X  X  cover as much as possible of the elements in [ C ]. For free sets of the same size, a lexicographic ordering leads to simpler non-compositional itemsets. This is due to the fact that N i is at once rewritten as X i , ( X 1 \ X i )  X  , . . . , ( X i  X  1 A total order considering first itemset size and then lexico-graphic ordering was introduced in [8, 11]. It formalizes our intuitions, and it is adopted in the RegularMine algorithm.
Definition 4.13. Let  X  be a total order over items, and let  X  l be the lexicographic ordering induced by  X  over item-sets.  X  is extended to itemsets as follows: X  X  Y iff | X | &lt; | Y | or, | X | = | Y | and X  X  l Y .

The second source of non-determinism is in the Covering procedure, which contains two choices (see Algorithm 1): (1) which R  X  R to select; and (2) which Y  X   X  R to select. It is readily checked that (1) does not affect the output, since the splitting rules S 1-S 5 deal with each non-compositional itemset in isolation. On the contrary, the choice (2) can affect the (size of the) output.
 Algorithm 3 RegularMine Input: a transactional database D Output: a set R out of frequent regular itemsets that is a concise representation of frequent itemsets extract frequent closed itemsets CS from D for every C  X  X S do end for
Example 4.14. Let C = abcd be a closed itemset and ab , bc and cd be the (ordered) free sets in [ C ] .

The non-compositional itemset for the third free set is R = cd { ab }  X  { b }  X  { ab } ? . By choosing Y  X  = { ab }  X  first rule S 5 to obtain cd { b }  X  b ? and cda { b }  X  b ? , which are further rewritten by rule S 4 , to cd and cda . By choosing Y  X  = { b }  X  , we apply rule S 4 to obtain cda ? . The latter choice leads to a smaller cover of R .

Intuitively, rule S 4 should be preferred, if possible, over rule S 5  X  which rewrites a non-compositional itemset into two ones. In the actual implementation of the Covering procedure, we achieve that by choosing Y  X   X  R as one of those with the smallest size.

The third source of non-determinism is in the Merging algorithm, where a pair R 1 , R 2  X  X  of extended itemsets has to be selected. Notice that, since the hypotheses of the rules M 1-M 6 are mutually-exclusive, at most one of them applies for a given pair; thus, the choice of the rule is deterministic once the pair has been selected. The next example shows that the choice of R 1 , R 2 can affect the output.
Example 4.15. Let C = abcdefg be a closed itemset and adf , aef , bdf , bef , cdf , cef , def and dfg be the free sets in [ C ] . The Covering procedure returns the following ex-tended itemsets: R 1 = adf { bceg } ? , R 2 = aef { bcg } bdf { ceg } ? , R 4 = bef { cg } ? , R 5 = cdf { eg } ? , R R 7 = defg ? , and R 8 = dfg .

Assume that the Merging procedure applies rule M 3 first to R 1 and R 2 , yielding R 0 1 = af { de } + { bcg } ? ; and next to R 7 and R 8 , yielding R 0 2 = df { eg } + . Let us follow from here two possible computations of the Merging procedure that yield different outputs. In the first computation, rule M 3 is applied to rewrite R 5 and R 6 to R 0 3 = cf { de } + g ? ; then, to rewrite R 3 and R 4 to R 0 4 = bf { de } + { cg } ? ; then, to rewrite R 1 and R 0 4 to R 0 5 = f { ab } + { de } + { cg } ? . Finally, rule M 4 is able to rewrite R 0 5 and R 0 3 to R 0 6 = f { abc } + final result is then { R 0 6 , R 0 2 } .
 In the second computation, rule M 5 is applied to rewrite R 2 and R 5 to R 0 7 = df { ceg } + ; then, to rewrite R 0 7 to R 0 8 = df { bceg } + . Finally, rule M 3 is used to rewrite R 4 and R 6 to R 0 9 = ef { bc } + g ? . The final result is then { R
In the actual implementation of the Merging procedure, the selection of a pair R 1 , R 2 for which one of the rules M 1, M 4, and M 5 can be applied is preferred. The rationale is that these rules tend to smoothly add one item at a time to extended items of the form Y + or Y ? . Rules M 2, M 3 and Figure 4: Number of regular itemsets extracted by RegularMine for different orderings of free itemsets. M 6 instead, introduce new or merge existing extended items of the form above, which could compromise further rewrit-ings. Of course, this choice is an heuristics. Experimentally it performs well, but there are cases, as in the previous ex-ample, where it does not yield the smallest output.
Finally, notice that Algorithm 3 does not further specify how to extract closed and free sets. To this purpose, we can resort to a large body of algorithms for frequent closed itemset mining. Most of them actually screen (and some explicitly store, e.g., [22]) the frequent free sets associated to a closed one as a sufficient condition for pruning the search space. We refer the reader to [20] for a survey.
We have experimented the RegularMine procedure on standard dense (pumsb, census, mushroom, chess) and sparse (BMS-Webview 1, BMS-Webview 2, T10I4D100K, T10I8-D100K) datasets obtained from the FIMI public repository [10], or generated by the Quest synthetic data generator [1]. Figure 3 reports the number of frequent, free, closed and regular itemsets at the variation of the minimum support threshold (for mushroom and T10I8D100K, the plot of fre-quent itemsets is well beyond the y-range, thus it is not visible). Apart from the BMS-Webview 1 dataset, the size of regular itemsets is very close to the size of closed itemsets. For sparse datasets, this result is expected, since the number of frequent, free and closed itemsets (and even of advanced concise representations [12]) tend to coincide  X  apart from very low minimum support, e.g., the plot of T10I4D100K shows a relative support in the range of 0.004% -0.02%. For dense datases, this result supports our claim that regu-lar itemsets, when compared to closed itemsets, are a good trade-off between conciseness and interpretability.
Figure 4 shows, for the sample mushroom dataset, how the ordering of free sets in the RegularMine procedure affects the number of regular itemsets extracted. regular is the or-dering of Definition 4.13; regular-inverse sorts free sets by descending size, rather than ascending; and regular-random is a random shuffle of the free sets. The rationale behind the choice of the  X  ordering is supported by its performances.
Let us consider now efficiency of RegularMine . When compared to frequent closed itemset mining, the additional tasks in the procedure consist of: (1) first collecting the free Figure 5: Execution times for mining closed, closed &amp; free, and regular itemsets. sets associated to a closed one; and (2) then computing a covering through the Covering and Merging procedures. To understand the relative weight of these two tasks, we re-port in Figure 5, for the sample pumsb dataset, the running times for extracting closed itemsets, for extracting closed and their associated free itemsets, and for the overall Reg-ularMine procedure. Experiments were execute on a PC with Intel Xeon 2.8Ghz and 3Gb RAM running Linux core 2.6.17. Our implementation of RegularMine is written in standard C++, and it builts on the open source code of the FP-growth algorithm by Borgelt [3]. Figure 5 highlights that the overhead required by RegularMine over the extraction of frequent closed itemsets is mainly due to the extraction and storage of free itemsets.
In addition to the cornerstone concepts of closed and free itemsets, other concise representations in the literature ex-ploit identities (e.g., inclusion-exclusion [9]) and regularities (e.g., disjunction rules X  X  a  X  b ) in order to prune from a representation those itemsets whose support can be de-rived from other ones in the representation. We mention disjunction-free sets [5], non-derivable itemsets [6], closed non-derivable itemsets [16], and, more recently, approaches that maintain the disjunctive or the negative support of itemsets [12, 13], or that refer to measures other than sup-port [19]. While these proposals achieve a higher compact-ness when compared to closed itemsets (actually, mainly for dense datasets), they all share, and perhaps exacerbate, the interpretability problem highlighted in the introduction for closed itemsets. Among the large body of literature about this subject, the investigation of a concise form for free item-sets seems the closest work to ours. [8] introduced and [11] systematized succint minimal generators . They observed that free sets in a class of  X  -equivalence can be partitioned with respect to another equivalence relation, called the  X  -relation. Hence, only a representative of each  X  -equivalence class needs to be maintained. On a general level, we also try and reduce the covering produced by Covering (start-ing from a non-compositional itemset for each free set) by merging extended itemsets through the + operator. On a more concrete level, we rely on the total order  X  of simpler-to-complex itemsets that is introduced by [8] for defining the  X  -relation. However, there is no direct relation between suc-cint minimal generators and regular itemsets. First, succint minimal generators are not a concise representation, since free sets alone are not. Second, to reconstruct the free sets of a  X  -equivalence class, one has to look at succint minimal generators of that class and of other classes, so the meaning of a succint minimal generator is not and-compositional.
The study of patterns that are easy to understand, to manipulate and to reason about by data analysts, not nec-essarily data mining experts, is of primary importance for a general acceptance of the knowledge discovery methodology in everyday working life. In this paper, we have introduced an extension of itemsets, called regular itemsets, its clean semantics and a procedure, called RegularMine , for min-ing a concise representation of frequent itemsets. The main idea consists of finding a covering of a  X  -equivalence class in terms of regular itemsets. Experiments support our claim that regular itemsets are a good trade-off between concise-ness and direct interpretability by a data analyst.
A few open directions include the application of regular itemsets in non-redundant association rule mining [18, 21] and in case studies to validate their actionability on the field. From a computational side, our approach acts as a post-processing phase starting from the closed itemset and the free sets in a  X  -equivalence class. As a future work, we intend to study how the approach can be integrated directly within the closed frequent itemset mining phase. [1] R. Agrawal and R. Srikant. Quest synthetic data [2] Y. Bastide, R. Taouil, N. Pasquier, G. Stumme, and [3] C. Borgelt. An implementation of the FP-growth [4] J.-F. Boulicaut, A. Bykowski, and C. Rigotti. [5] A. Bykowski and C. Rigotti. DBC: A condensed [6] T. Calders and B. Goethals. Non-derivable itemset [7] T. Calders, C. Rigotti, and J.-F. Boulicaut. A survey [8] G. Dong, C. Jiang, J. Pei, J. Li, and L. Wong. Mining [9] J. Galambos and I. Simonelli. Bonferroni-type [10] B. Goethals. Frequent Itemset Mining Implementations [11] T. Hamrouni, S. B. Yahia, and E. M. Nguifo. Succinct [12] T. Hamrouni, S. B. Yahia, and E. M. Nguifo. Sweeping [13] M. Kryszkiewicz, H. Rybinski, and K. Cichon. On [14] G. Liu, J. Li, L. Wong, and W. Hsu. Positive borders [15] H. Mannila and H. Toivonen. Multiple uses of frequent [16] J. Muhonen and H. Toivonen. Closed non-derivable [17] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. [18] N. Pasquier, R. Taouil, Y. Bastide, G. Stumme, and [19] A. Soulet and B. Cr  X emilleux. Adequate condensed [20] S. B. Yahia, T. Hamrouni, and E. M. Nguifo. Frequent [21] M. J. Zaki. Mining non-redundant association rules. [22] M. J. Zaki and C.-J. Hsiao. Efficient algorithms for
