 In speech recognition, language model plays an important ro le. It models the prior probabilities of all possible word sequence that a spe ech recogniser can deal with. It is independent of acoustic observations and defines the search space of a speech recogniser. In speech recognition, word error rate ( WER) is usually used as the ultimate evaluation metric for the whole system. Alth ough WER can also be used to evaluate language model given a fixed acoustic mode l, it is not conve-nient to do so because acoustic data is required and decoding is timeconsuming. To conveniently evaluate the quality of an estimated langua ge model, perplex-ity was proposed and has been the most widely used metric [5]. Perplexity is essentially the exponent of the cross entropy between the re al word sequence distribution and the estimated word sequence distribution . Its calculation is in-dependent of acoustic data and can be done quickly. More impo rtantly, it was shown that perplexity has good correlation with WER [1, 6]. H ence, it has been used for decades to evaluate language model in speech recogn ition. However, there has also been a long argument about the correlation bet ween perplexity and WER. Previous works showed that the good correlation bet ween perplexity and WER only exists in certain cases [3] and modifications of p erplexity has been proposed to improve the correlations in more general ca ses [3, 4, 2]. models, such as corpus size, smoothing algorithm, interpol ation weight and so on. Then the correlation between perplexity and WER of all di fferent language models is investigated. However, all the previous works, to our best knowledge, have not explicitly considered the influence of voabulary on language model training. It may be because that vocabulary is normally fixed before language model training given certain training corpus and consequen tly does not have remarkable influence. Although this is a common case in word b ased languages, in character based languages such as Chinese, the influence o f vocabulary can not be neglected. Since character based languages are not na turally defined with spaces appearing between words, corpus needs to be segmente d to form words before language model training. Different segmentation str ategies will generate different word vocabularies with totally different size and c omponents which lead to different probability distribution and final recognition result. We will show in the following chapter that in this situation, perplexity is incompetent to predict the recognition performance.
 used to evaluate the final performance instead of word error r ate because char-acter becomes the basic unit while language model is still tr ained based on word, since word based language model always tends to get a better p erformance in application. This mismatch makes it harder for perplexity t o do an accurate eval-uation that perplexity only considers the probability dist ribution of each word but ignores the information of word itself. For example, it i s intuitive that the length of word have relation with the CER because word with mo re characters will cause more incorrectly recognised characters in CER ca lculation and this effect will not be recognised by perplexity.
 of vocabulary construction into consideration. Two new eva luation functions are proposed, one is taking the vocabulary size into considerat ion and the other one is considering the vocabulary size as well as the length of wo rd. Experiments are performed to investigate the correlation between different versions of perplexity and CER, where the segmentaion strategy and word vocabulary are the vari-able quantities. The result shows that these new measures ar e more robust and present much more consistent with CER while the influence of w ord length is not as strong as we thought.
 word based perplexity and proposes two modified versions for character based languages. Experiments are described in section 3, followe d by conclusion. 2.1 Word based perplexity and its limitation In natural language processing, it is assumed that the appea rance of word in sen-tences satisfying some specific kind of probability distrib ution referred to as lan-guage model. The model that can best reflect such distributio n is called the real model but limited to the calculation ability, it is impossib le to achieve this real model in practice. Therefore, the quality of language model is always assessed by quantitatively measuring the difference between the estima ted language model and the real model. This can be done by asking how well the esti mated model can predict the words generated from the real word distribut ion. For a given test word sequence w = { w 1 ,  X   X   X  , w N } , where N is the number of words, the perplexity ( ppl ) of the estimated language model q ( w ) is defined as the word history of w i . Assuming the real word sequence distribution is p( w ), better estimated model q( w) of the unknown distribution p( w ) will tend to assign higher probabilities to the test word sequences. Thu s, they have lower perplexity, meaning that they are less surprised by the test sample.
 of word w i given history h i , the exponent in equation (1) can be regarded as the number of bits needed per word to represent the test set if the coding scheme used is based on q (  X  ). Low ppl means the estimated model requires few bits per word to compress the test set which means the model is more clo se to the real model.
 vocabulary changes, it always tends to behave poorly. Since language model is word based, even for character based language, a word vocabu lary is required to determine the set of valid words. Words not appeared in the vocabulary will not be taken into consideration when calculating the ppl . The size and compo-sition of the word vocabulary will severely affect ppl s evaluation. For example, considering two language model LM A and LM B , LM A has only 50 words, and the probability of each word is equal which is 1/50, and LM B has 100 words and the probability of each word is also equal for convenienc e. According to the equation (1), the ppl of LM A is 50 while the ppl of LM B is 100. Although the ppl of LM A is much lower than LM B , it is likely that, LM A which contains more words will get a better performance in application due t o better coverage of words. 2.2 Character based perplexity Considering the definition of perplexity( ppl ), it uses the average bits needed to compress the test set as the criterion to evaluate language m odel but ignores the vocabulary size. As the example given in last paragraph, it i s obviously unfair to compare the number of bits if the two language model have diffe rent vocabulary size. Therefore, equation (2) is extended to take the size of vocabulary into consideration. Since this function is designed for conquer ing problem appearing in character based languages, it is denoted as character-ba sed perplexity ( cppl ) for convenience. The extended function is defined as: where | V | is the number of words of vocabulary V . This is an empirical function that introduces the size of vocabulary as a balancing factor . The language model which has a smaller vocabulary size tends to have larger q () and therefore will get a smaller exponent and smaller ppl . In contrast, in equation (2), the exponent will become larger with smaller vocabulary size which will n eutralize the effect of q (  X  ).
 tion of word itself is also an influence factors. Since charac ter based languages are not naturally defined with spaces appearing between words, t hese words which are decided by segmentation and corpus contains far more pos sibilities than those in word based languages. For example, on a 310M Chinese text c orpus, the size of vocabulary after word segmentation can be more than 1000k ! Not only the vocabulary size, the words in vocabulary constructed from d ifferent segmenta-tion strategies may also have notable difference. To make it e asy to consider this difference, the effect of word length is considered, sinc e it seems intuitive that longer word will cause more error characters if it is inc orrectly recognized in speech recognition. The bits needed to transfer the word i nto equation (2) is further introduced and a refined character-based perplexit y, referred to as cppl 2 is defined as below: where | w | denotes the number of characters of word w , i.e. word length. This is also an empirical function that considering both of the effec t of the vocabulary composition as well as the vocabulary size. To investigate the correlation between the new language mod el evaluation mea-sures and CER, experiments were performed on a large vocabul ary Chinese speech recognition task. The acoustic model is a cross-word triphone model trained on about 200 hours of read speech using the minimum ph one error (MPE) criterion. It has about 3000 clustered states and an average of 12 Gaussian com-ponents per state. The acoustic model was fixed for all experi ments. The text corpus used to train language models were extracted from Wei bo 2 consisting of 42M sentences and 101M characters. A series of trigram langu age models were then trained during the experiments. The test data for calcu lating perplexity and CER consists of 2040 sentences, about 20K characters. All th ese sentences were preprocessed to ensure that they were composed with 6763 sim plified Chinese characters and other symbols were filtered. The toolkit to tr ain language model was SRILM[7] and HTK toolkit[8] was used to decode the lattic e transcript. previous works which mostly focused on adjusting the smooth ing algorithm or interpolation weight, different language models were gener ated by utilizing dif-ferent segmentation strategies in this experiment. To achi eve many different seg-mentation strategies, backward maximal matching(BMM) wor d segmentation algorithm was used with different vocabularies. These vocab ularies was con-sciously constructed to let the segment result varied obvio usly, having apparent divergence in word length and vocabulary size to better chec k the performance of cppl and cppl 2 . The pseudocode generating these vocabularies is shown in Algorithm 1.
 trigram count with high frequency. In our algorithm, if the n -gram(n &gt; 1) words having high frequency which is represented by the appearanc e times counted in held out corpus, it is supposed to be a new word and is added t o the new vocabulary generated for the next segmentation strategy. T he criterion judging high frequency is determined by the input parameter mc which represents the number of new word will be added. When the new vocabulary is us ed for seg-mentation, many bigrams and trigrams will be recognized as a integrated word which will increase the average word length of the segmented corpus.
 is summarized in Table 1.
 Algorithm 1 Generating segmentation dictionary 3.1 Correlation between CER and ppl With the trigram language models trained on the 10 different t ext corpra, nor-mal word-based perplexities were calculated and CERs were g enerated after full decoding on the acoustic data. The correlation between CER a nd word-based perplexity ppl is shown in figure 1 To quantify the correlation between different metrics with c haracter error rate, linear correlation coefficient(or Pearson coefficient) was ca lculated to measure the degree of linear correlation. The Linear correlation co efficient of CER and ppl is -0.70. The coefficient of CER and log( ppl ) is -0.79. All of the correlation coefficients are negative in this experiment. It is inconsist ent with the expectation that CER is positively correlated with ppl .
 Here, the segmentation strategy is fixed and the size of corpu s to train language model varied from 10M to 100M. The result is shown in figure 2 observation as the previous work on perplexity. From the abo ve two experiments, the correlation between CER and ppl varies from positive to negative which is quite inconsistent, and therefore, we conclude ppl is incompetent for evaluating CER. 3.2 Correlation between CER and cppl The setup of this experiment was same as the previous experi-ment except equa-tion (2) was used to calculate the cppl instead of ppl . The correlation between cppl and CER when segmentation strategies varies is shown in figur e 3 and when the corpus size changes, the correlation is shown in figure 4 the absolute value of ppl but a little lower than absolute value of log( ppl ) and in figure 4 is 0.97 which is equal to ppl . In both figures, cppl shows a positive correlation with CER.
 word length was also performed. Equation (3) was used to calc ulate the cppl 2 . The correlation result was similar to cppl but with a litter increase in correlation coefficient. The improvement is shown in table 2 correlation coefficients, but this influence was very tiny com pared to the effect caused vocabulary size change.
 predicting language models quality for character based lan guages. One main reason is that perplexity is not only affected by the probabil ity distribution of language model but also by the scale of vocabulary size. Sinc e it is only the probability distribution deciding the language models per formance in speech recognition, the influence of vocabulary size will observab ly interfere the corre-lation. Therefore, the proposed metric cppl empirically neutralizing this effect retained inconsistence with character error rate in the two experiments. ation does not have apparent improvement to the evaluation. It infers that word length may not be as important to the correlation as we though t. This is because by our analysis, the influence of vocabulary composition var ies is very complex and length only describing a simple physical attribute of a w ord without reaching its probability attributes or its character element is inad equate to neutralizing the effect caused by vocabulary change. Therefore, our futur e work will focuses on the further investigation of the influence caused by vocab ulary composition, more information and more complex model about the word in voc abulary will be considered. In this paper, perplexity is shown incompetent to predict CE R for character based language, since the segmentation strategies which ch ange the vocabulary composition will distinctly affect the evaluation of perple xity. To address this problem, word-based perplexity has been extended. A new met ric taking vocab-ulary size into consideration is proposed. It is shown to suc cessfully neutralize the influence of vocabulary change and is more robust. Length of word in vo-cabulary is also considered while it is proved having little effect about the final correlation. The main factor about the influence of the vocab ulary composition should be further investigated.

