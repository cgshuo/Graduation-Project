 JINHUI TANG, RICHANG HONG, SHUICHENG YAN, Recent years have witnessed the proliferation of social media and the success of many photo-sharing websites, such as Flickr 1 and Picasa. 2 These websites allow users to upload personal images and assign tags to describe the image contents. With the rich tags as metadata, users can more conveniently organize and access these shared images. Out of these, a question naturally arises for research on image annotation (i.e., inferring images X  labels on different semantic concepts) X  X an we infer the images X  semantic labels effectively from these user-shared images and their associated tags?
Utilizing machine learning techniques to improve image annotation performance has attracted much attention in the multimedia research community. However, the effectiveness of these machine learning techniques heavily relies on the availability of a sufficiently large set of balanced labeled samples, which typically come from users in an interactively manual process. This manual labeling process is very time-consuming and labor-intensive. In order to reduce this manual effort, many semi-supervised learning or active learning approaches have been proposed [He et al. 2004; Goh et al. 2004]. Nevertheless, there is still a need to manually annotate a large set of images to train the learning models. On the other hand, the image sharing sites offer us a great opportunity to  X  X reely X  acquire a large number of images with annotated tags. The tags of the images are collectively annotated by a large group of heterogeneous users. It is generally believed that most of the tags are correct, although there are many incorrect and missing tags. Thus, if we can infer the images X  semantic labels effectively from these user-shared images by using their associated noisy considerable manual efforts can be eliminated for labeling the training data. Figure 1 presents an overview of the process of inferring images X  labels from the community-contributed images and associated noisy tags.
Many traditional methods, such as the support vector machine and k nearest neigh-bors ( k NN) method, can be applied to infer the images X  labels from the user-shared im-ages and associated tags. To annotate the images more accurately, we propose a novel k NN-sparse graph-based semi-supervised learning method in this paper. By utilizing the labeled and unlabeled data simultaneously, semi-supervised learning has been demonstrated to be more effective than purely supervised learning when the train-ing data is limited [Chapelle et al. 2006; Zhu 2005]; and graph-based semi-supervised learning methods have been widely used in image annotation and retrieval [He et al. 2004; Wang et al. 2006a]. However, the traditional graph-based methods share a com-mon disadvantage, namely, they all have certain parameters which require manual tuning. The parameters may have great impact on the structure of the constructed graph. Thus, the performances of these methods are sensitive to these parameters and the algorithmic robustness is challenged. Meanwhile, the traditional graphs are con-structed only based on visual distance, and there may exist many links between the samples with unrelated concepts. This may cause the label information to be propa-gated incorrectly.

Actually, a graph is a gathering of pairwise relations, while the relation among visual images is essentially an estimation based on human cognition system. It has been found in neural science that the human vision system seeks a sparse representation for the incoming image using a few words in a feature vocabulary [Rao et al. 2002]. This moti-vates us to construct the so-called sparse graph through the sparse reconstructions of the samples. However, the one-vs-all reconstruction is very time-consuming and needs too much memory for large-scale dataset. Thus compared to our previous work [Tang et al. 2009], we sparsely reconstruct each sample from its k nearest neighbors in feature space instead of using all the other samples to improve the efficiency while maintain-ing its effectiveness. We call it one-vs-k NN sparse reconstruction. The approximate k NN search [Mount and Arya 1997] is also applied to accelerate the process. The semi-supervised label inference for semantic concepts is then conducted on this sparse graph.
The k NN-sparse graph-based semi-supervised learning method has the following advantages: (1) it can remove most of the semantically-unrelated links to avoid the propagation of incorrect information, since each sample only has links to a small number of most probably semantically-related samples; (2) it is robust to noisy elements in the visual features; (3) it is naturally effective for discrimination since the sparse graph characterizing the local structure can convey important information for classification [Belkin and Niyogi 2003]; and (4) it is practical for large-scale applications since the sparse representation can reduce the storage requirement while the approximate k NN-sparse graph construction is much more efficient than normal sparse graph construction.

More importantly, in this graph-based learning framework, we propose an effective training label refinement strategy to handle the noise in the training labels, by bringing in a dual regularization for both the quantity and sparsity of the noise. This is a key-point for our scenario, since our training labels are extracted from the community-contributed noisy tags.

We conduct extensive experiments on a real-world dataset [Chua et al. 2009] consist-ing of 55,615 community-contributed images and their associated tags crawled from Flickr to demonstrate the advantages of the proposed k NN-sparse graph-based semi-supervised learning approach and the training label refinement strategy for noisy tag handling.

The main contributions of this work are as follows: (1) We propose a novel k NN-sparse graph-based semi-supervised learning approach, (2) An effective training label refinement strategy is proposed within this graph-based Several approaches have been proposed for annotating images by mining the web images with surrounding descriptions. A series of research were also done to leverage information in world-wide web to annotate general images [Wang et al. 2008, 2006b; Li et al. 2006]. Given a query image, they first searched for similar images from the web, and then mined representative and common descriptions from the surrounding descriptions of these similar images as the annotation for the query image. By fully leveraging on the redundancy of information on the Web, Torralba et al. [2008] collected about 80 million tiny images, each of which is labeled with one of the 75,062 abstract nouns from WordNet. They claimed that with sufficient number of samples, the simple nearest neighbor classifier can achieve reasonable performance for several object/scene detection tasks such as the human and face detection, when compared with the more sophisticated state-of-the-art techniques. However, the assignment of only one noun to each image and the use of small sized image of 32-by-32 pixels are inadequate to reflect the complex content of real-world images. These efforts annotated the query image by collecting the descriptions of its similar images in the web. Their robustness to the noisy descriptions and the semantically unrelated neighbors are challenged.
Several approaches tried to model the visual patterns of certain concepts by mining the images gathered from the web. After web images are gathered using an object name, Fergus et al. [2005] modeled the visual object as a constellation of parts us-ing a probabilistic representation called TSI-pLSA. In Sun et al. [2008], web images were mined to obtain multiple visual patterns automatically that are then used to model a semantic concept. Both these approaches gathered a separate training set for each concept, and need to train models for different concepts separately. Thus, their applications are limited to a small number of concepts.

Recently, graph-based semi-supervised learning has attracted much attention in both machine learning and multimedia retrieval communities. Actually graph-based semi-supervised learning is a label propagation process [Tang et al. 2007]. The most typical ones include the Gaussian random fields and harmonic functions method [Zhu et al. 2003], as well as the local and global consistency method [Zhou et al. 2003]. However, they both have the disadvantage of the requirement to tune certain parameters. An-other popular method is the linear neighborhood propagation [Wang and Zhang 2008], in which the sample reconstruction method is used to construct a graph. It has been shown that in most cases, linear neighborhood propagation is more effective and robust than the traditional semi-supervised methods on similarity graphs [Wang and Zhang 2008; Tang et al. 2008]. However, it still cannot handle the links among semantically-unrelated samples. A more detailed survey on semi-supervised learning can be found in Zhu [2005].

In this article, a novel k NN-sparse graph-based semi-supervised learning method with regularization on training labels is proposed to annotate images by label propagation over the noisily-tagged web images. Here the graph is constructed sparsely to handle the semantically unrelated links. It is constructed by reconstructing each sample from its k nearest neighbors to improve the efficiency, while the approximate method is applied to accelerate the k NN search. And the regularization is proposed to handle the noise in the training labels. Most traditional graph-based semi-supervised learning algorithms construct the graphs only according to the visual distance, thus are very sensitive to the noise in visual features. One dimension of noisy feature may affect the graph structure signif-icantly. Moreover, constructing the graph only based on the visual distance will bring in semantically unrelated links between samples due to the semantic gap . An alterna-tive way to construct a graph is to reconstruct each image by the other images as in locally linear embedding [Roweis and Saul 2000] and linear neighborhood propagation [Wang and Zhang 2008]. However, they still cannot handle the semantically unrelated links.

It has been found in neural science that the human vision system seeks a sparse representation for the incoming image using a few words in a feature vocabulary [Rao et al. 2002]. Wright et al. [2009] demonstrated that the reconstruction error minimization can naturally lead to a sparse representation for the images. The sparse reconstruction is robust to the noise in features, and shows to enforce the images selected to reconstruct the test image are semantically-related to the test image. This motivates us to construct the graph by datum-wise sparse reconstructions of samples via 1 -norm minimization. The graph constructed by datum-wise sparse reconstruction of samples can remove considerable semantically-unrelated links between those semantically unrelated samples to avoid incorrect information propagation. However, the one-vs-all sparse reconstruction is computationally very complex. Thus, compared to our previous work [Tang et al. 2009], we propose the so-called one-vs-k NN sparse graph construction by reconstructing each sample from its k nearest neighbors instead of reconstruction from all the other samples. Meanwhile, the one-vs-all sparse reconstruction needs too much memory to store the feature vectors of all samples for the optimization. Thus, it is not feasible for the large-scale applications. While the one-vs-k NN sparse reconstruction can tackle this problem effectively as it only needs to store k + 1 feature vectors for each reconstruction.

In addition, considering the fact that the training labels are noisy as they are ex-tracted from the user-contributed tags, we propose a training label refinement strategy to restrain the effects of the noise in the training labels, by introducing a dual regu-larization for both the quantity and sparsity of the noise into the optimization of label inference.

Figure 2 shows an exemplary comparison of sparse graph and conventional similarity-based graph. In the similarity-based graph, there exists link for each sample pair, and the weight is in inverse proportional to the distance measured in visual space. Thus, the information may be propagated between semantically unrelated samples. In the constructed sparse graph, only a small number of most probably semantically-related samples are selected to have links to the reference sample. Thus, the sparse graph can remove most of those semantically unrelated links between images to avoid propagation of incorrect information. The pursue of the sparsest solution for sample reconstruction over an overcomplete dictionary is an NP-hard problem in general. However, recent results [Donoho 2006] show that if the solution is sparse enough, the sparse representation can be recovered by convex 1 -norm minimization. Suppose we have an under-determined system of linear equations: x = Dw , where x  X  R d is the feature vector of the image to be reconstructed, w  X  R n is the vector of the unknown reconstruction coefficients, and D  X  R d  X  n ( d &lt; n ) is a matrix formed by the feature vectors of the other images in the dataset. The sparse solution for w can be obtained by solving the following convex optimization problem [Donoho 2006]:
In practice, there may exist noise on certain elements of x , and a natural way to recover these elements and provide a robust estimation of w is to formulate x where  X   X  R d is the noise term. We can then solve the following problem with respect to both reconstruction coefficients and feature noise: where B = [ D ; I ]  X  R d  X  ( n + d ) and  X  w = [ w T ;  X  and can be transformed into a general linear programming problem. There exists a globally optimal solution, and the optimization can be solved efficiently using many available 1 -norm optimization toolboxes like [ 1 MAGIC]. Note that the mization toolbox may convert the original constrained optimization problem into an unconstrained one, with an extra regularization coefficient which can be tuned for optimality in practice but essentially does not exist in original problem formulation.
Let X ={ x 1 ,..., x l , x l + 1 ,..., x N } be the set of feature vectors for the N images in the dataset, where x i  X  R d represents the i th sample in the dataset, and { w edge weight matrix. The construction of the k NN-sparse graph can be summarized as follows. (1) For each sample x i , search its k nearest neighbors N (2) Form the matrix B i with all samples x i (3) Set the edge weight w ij from the sample x j to the sample x Here we re-order the samples in set X and have X = L  X  U , where tains the first l samples labeled as y i  X  X  1 , 0 } for every concept, and contains the unlabeled ones. The label  X 1 X  indicates that the sample is relevant to a certain concept and  X 0 X  otherwise. It is well known that directly optimizing the binary label 1/0 is an NP-hard problem. Thus, these labels are usually relaxed to be of real values. Each real-value label can be seen as the relevance score of the sample to a cer-tain concept. As the objective of the semantic label inference is to rank the unlabeled samples according to their relevance values to each concept, so the real-value scores are naturally suitable. Denote the vector of the predicted labels of all samples as f , which can be split into two blocks as: Similar to the assumption in linear neighborhood propagation algorithm [Wang and Zhang 2008], we assume that the label of each sample can be reconstructed from the other samples, while the reconstruction coefficients are the same as those for the sparse reconstruction of sample vectors. Thus, the linear reconstruction coefficients in the constructed sparse matrix can be used to predict the labels of the unlabeled samples. This prediction is based on the intuition that the weight sample x i to have the same label as sample x j .

Based on the label reconstruction assumption, we can infer the labels of the unlabeled samples by minimizing the label reconstruction error as follows: This formulation can be represented in matrix form as: where y is the label vector for the first l samples. Let C entiate the right side of Eq. (7) with respect to f , we obtain: where M = C + C T is a symmetric matrix.
 By splitting the matrix M after the l th row and l th column, we have: and Eq. (8) can then be rewritten as: By solving the second equation, we can obtain the label vector for the unlabeled samples:
Typically, the matrix M UU is very large for image annotation and retrieval tasks. It is often computationally prohibitive to calculate its inverse directly. Some conventional methods enforce the non-negative constraints for the reconstruction coefficients and use the iterative label propagation method to solve this problem. However, generally enforcing a non-negative constraint is not reasonable since some samples may have negative contributions to some other samples. Fortunately, the second equation of (10) can be reformulated as: The generalized minimum residual method (usually abbreviated as GMRES) [Saad and Schultz 1986] can be used to iteratively solve this large-scale sparse system of linear equations effectively and efficiently. The GMRES method approximates the solution by a vector in a Krylov subspace [Saad 2003] with minimal residue. As previously mentioned, the associated tags are often noisy for those community-contributed images. A quantitative analysis of noise in the associated tags for Flickr images can be found in Chua et al. [2009]. Thus, it is necessary to recover these noisy tags for achieving satisfactory image annotation performance if we use them as training labels.

To handle the noise in the training labels, we cannot assume that the training labels are fixed during the inference process as in Eq. (6). The noisy training labels should be refined during the label inference step. However, they should be still consistent with the original labels to some extent. To handle these noisy labels, we propose to infer the labels of those unlabeled samples by adding two regularization terms: where f L encodes the training samples X  labels that are propagatable on the sparse graph, and  X  f L denotes the ideal label vector of the training samples. The first term of this formula is the same as in Eq. (6). The second term enforces the ideal labels of the training samples to be consistent with the labels propagatable on the derived sparse graph. This term essentially measures the quantity of the content-to-label noise. The third term is an 1 -norm, which measures the sparsity of the tag noise, and the minimization of which constrains that only a few elements are different between the ideal labels and the original labels, since generally only a limited number of labels are noisy. The intuitive explanation for the regularization is that the training labels should be consistent to both the original tags and the inferred labels of the training samples.

This problem can be solved in the following three steps. (1) Set the original label vector as the initial estimation of ideal label vector, that is, (2) Fix f L and solve (3) Use the obtained  X  f L to replace the y in Eq. (12), and we can solve the sparse system
Note that the first and second steps can be iterated several times for more robust removal of tag noise. Our experiments show that generally one iteration is enough to achieve a sufficiently stable solution. To evaluate the performance of the proposed k NN-sparse graph-based semi-supervised learning method, we conducted extensive experiments on a real-world community-contributed image dataset along with their associated tags. In Table I, we abbreviate the names of all the compared methods in the experiments. The dataset we used in all the experiments is a lite version of the NUS-WIDE database [Chua et al. 2009]. This dataset includes 55,615 images and their associated tags, which are crawled from Flickr. We use half of these images (i.e., 27,807 images) for training by using their associated noisy tags as training labels , and the rest (i.e., 27,808 images) for testing by ignoring the crawled tags associated to the test images. The data separation is the same as in Chua et al. [2009]. Annotation performances are evaluated based on the 81 concepts defined in NUS-WIDE, where the ground-truth of these concepts for all images are provided for evaluation.

The low-level features we used here include the 64-D color histogram and 73-D edge direction histogram. We combine these two kinds of features directly by merging the two feature vectors of each sample. We subtract every element of each dimen-sion of features by the mean of all elements in this dimension, and then divide by three times the standard variation of all elements in this dimension to normalize the features.

For each concept, the test images are ranked according to the probability that the images are relevant. The performance is measured via non-interpolated Average Pre-cision (AP), a standard metric used for image retrieval [TREC]. We average the APs over all the evaluated 81 concepts to create the Mean Average Precision (MAP), which is an overall performance measure. All approaches in the experiments are executed on a PC with Intel 3.0-GHz CPU and 16-G memory. To demonstrate the effectiveness of the sparse graph-based semi-supervised learning approach (SGSSL), we compare its performance with the following four methods for image annotation: SVM, k NN, LNP, and S-Recon. LNP is one of the state-of-art graph-based semi-supervised learning methods. Different from constructing the graph by sparse reconstruction that is achieved by 1 minimization, it constructs the graph by minimizing the 2 -norm of reconstruction error  X  i = x can be regarded as a supervised version of the approaches in this article. It reconstructs the labels of the given samples directly using the same sparse coefficients that recon-struct the samples: if the sparse coefficient vector of reconstructing the given sample x is w i (refer to formula (3)), the label of x i can be predicted as: f
We conducted six groups of experiments to compare the performances of these five methods by using different proportions of training set: 10 percent, 20 percent, 30 percent, 50 percent, 75 percent, and 100 percent (i.e., the entire training set). When we use partial training data for inference, the samples are randomly sampled from the entire training set according to the given proportions. All evaluations were conducted on the same test dataset. The MAPs of these five methods using different propor-tions of training data are illustrated in Figure 3. From these results, we can observe that: (1) for all cases SGSSL outperforms the first three methods significantly, (2) SGSSL always outperforms S-Recon when using different proportions of training (3) the performances of both SGSSL and S-Recon increase accompanied with the in-
Due to the limitation of space, we only provide the comparison of APs for different concepts using 10 percent of training data as shown in Figure 4. From these results, we can observe that SGSSL outperforms the other four methods for almost all the 81 concepts.

The approximate execution times of these five methods for annotating the 81 concepts with 10 percent of training data are given in Table II. Here k Although SGSSL is much slower than k NN, it is significantly more effective. Also it is slower than S-Recon when using 10 percent of training data but with significant improvement in annotation accuracy. However, when the size of training data increases, the annotation accuracy of S-Recon will increase to be comparable with SGSSL, but its execution time will also increase to be similar to that of SGSSL. As the one-vs-all sparse reconstruction is very time-consuming, we reconstruct each sample from its k nearest neighbors to form the k NN-sparse graph to reduce the compu-tational complexity. Meanwhile, an approximate method [Mount and Arya 1997] is also adopted to accelerate the k NN search. In this section, we evaluate the performances of label propagation on the k NN-sparse graph and approximate k NN-sparse graph. All experiments use the entire training set for label propagation.

Figure 5 compares the MAPs of k NN-SGSSL with different k . We can see that the performance does not change too much when k exceeds 300, hence we set the value of k to 300 for the rest of experiments. In Figure 6, we compare the APs obtained by SGSSL, k NN-SGSSL, and A k NN-SGSSL, with k = 300. From these results, we can see that the effectiveness of these three methods are similar for image annotation. The MAP obtained by k NN-SGSSL is 0.1133, which is even a bit better than the 0.1123 obtained by SGSSL. This is because that the constructed k NN-sparse graph utilizes both the visual distance and sparse reconstruction, thus it is better than using only the sparse reconstruction. The A k NN-SGSSL obtains a MAP of 0.1124, which is similar to that of k NN-SGSSL. That is to say, the approximate k NN nearly does not affect the effectiveness compared to the accurate k NN.
 Table III illustrates the executing time of each step in the SGSSL, k NN-SGSSL, A k NN-SGSSL and A k NN-SGSSL dn. We can see that k NN-SGSSL is much more ef-ficient than SGSSL, and A k NN-SGSSL further reduces the computational complexity significantly.
 To evaluate the effectiveness of the training label refinement strategy, we compare the performances of approximate k NN-SGSSL with and without training label refinement. We empirically set the parameters for the handling of label noise: the labeled samples should change but should not change too much compared to the initial labels. Thus, it should be much larger than 1. In Eq. (15), the to control the balance between the two regularization terms.

Figure 7 compares the APs obtained by A k NN-SGSSL and A k NN-SGSSL dn. We can see that after handling the noise in the training labels, A k NN-SGSSL dn outperforms A k NN-SGSSL significantly for almost all the 81 concepts. A k NN-SGSSL dn achieves an MAP of 0.1428, which has an improvement of 27.1% over A k NN-SGSSL. It indicates that the training label refinement step is critical and valuable for image annotation with noisy training labels.
 The executing time of A k NN-SGSSL dn is comparable to that of A k NN-SGSSL (see Table III). Thus, we can see that performing noisy training label refinement will not bring too much additional computational cost but will bring much extra benefits in effectiveness. In this work, we exploited the problem of annotating images by label propagation over community-contributed images and their associated noisy tags. A novel k NN-sparse graph-based semi-supervised learning approach was proposed to improve the anno-tation performance by handling the links among the semantically-unrelated samples. Meanwhile, the approximate k NN search is applied to ensure the efficiency. In addi-tion, an effective training label refinement strategy is proposed into the graph-based learning framework to reduce the effects of noise in the tags. Extensive experiments conducted on the NUS-WIDE-Lite dataset have demonstrated the effectiveness and efficiency of the proposed approach. From the experimental results, we can see that a key factor, which affects the performance of image annotation with the tags as train-ing labels, is the noise in tags. Actually, for image annotation, we may not need to correct all the noisy tags. Instead, we can collect the correct image-label pairs as much as possible for training. Thus, our future work will focus on how to construct an effective training set from the community-contributed images and tags.

