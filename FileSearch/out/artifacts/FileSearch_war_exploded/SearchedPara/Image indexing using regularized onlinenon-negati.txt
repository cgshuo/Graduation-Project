 MindLab Research Group, Universidad Nacional de Colombia, Bogot X , Colombia 1. Introduction
Due to the fast advance in digital image acquisition, data storage and communication technology, huge amounts of multimedia data have become widely availa ble. There are very intere sting potential appli-cations for these large multimedia data collections in areas as diverse as medicine, crime prevention, e-education and publishing, among others [11,24,27]. But in order to exploit this potential, an effec-providing keywords as queries, however, this has the disadvantage of requiring that all images in the using only keywords and it is desirable to search by providing an example image. This approach, called Content-based Image Retrieval (CBIR), has been studied during the last two decades resulting in impor-tic validity. In order to overcome this problem, this paper presents an indexing method which enriches the relationships between visual features and text keywords co-occurring in images.
Semantic Embedding is a successful strategy which finds these relationships by building a common semantic representation space where both image and text content are embedded. This strategy has been previously approached using different methods: Latent Semantic Analysis (LSA) [21], Latent Dirich-let Allocation (LDA) [21], Non-negative Matrix Factorization (NMF) [6] and Non-negative Semantic Embedding (NSE) [29], among others. Unfortunately most semantic learning algorithms demand huge computational resources in terms of memory and time processing [9], making them infeasible for large data collections.

To solve this drawback, this paper proposes an online version of the NSE algorithm [29], online non-negative semantic embedding (ONSE), which is able to deal with large image collections by keeping ONSE was introduced for the first time. The algorithm presented in this paper adds two main enhance-The algorithm was evaluated on two different CBIR tasks exhibiting an enhanced performance when compared against state-of-the-art image indexing strategies based on semantic embedding.
The rest of this paper is organized as follows: Section 2 discusses the related work; Section 3 intro-Section 5 presents some concluding remarks. 2. Related work
Connecting visual and textual content through machine learning supervised and non-supervised mod-approach this problem [10,34,35], including Multiple-Bernoulli Relevance Model (MBRM) [16], which models a joint probability of observing visual feature vectors with possible annotation words, multi-modal multilayer Probabilistic Latent Semantic Analysis (mmPLSA) [22], which learns a joint distri-bution for texts and image features, and Topic Regression Multimodal Latent Dirichlet Allocation [21], between variables.

Also, several matrix factorization algorithms have been proposed for modeling latent structures based on multimodal interactions. Chandrika et al. [9] evaluated a multimodal Latent Semantic Indexing (mmLSI) algorithm, based on Singular Value Decomposition (SVD), and Caicedo et al. [6] and Akata et al. [1] proposed finding multimodal relationships using Nonnegative Matrix Factorization (NMF). Vanegas et al. [29] proposed the Non-negative Semantic Embedding (NSE) as a variant on the NMF algorithm, where the semantic encoding is already known and is defined by the text modality, and the sual and text content. The experimental evaluation in [29] showed that NSE performs better than other semantic embedding models when the text modality corresponds to clean and semantic rich annotations.
Unfortunately, most of the proposed algorithms have been designed without taking into account scala-collections, due to the required high computational cost, in terms of time, memory and storage. These computational resources. However, this can be expensive, hard to accomplish and this can require a lot of care and technical skills.
 There are some works that consider a large-scale setup in the formulation of the models. For instance, Hsan et al. [28] propose to incorporate visual and textual information as embedded objects, by using a linear projection to approximate the embedding functions. The linear projection is found by solving a non-smooth convex optimization problem. In this work, the authors propose a reformulation of the basic algorithm called MCR (Multi-stage Convex Relaxation) to make it suitable for large scale image in the amount of required storage by reducing the dimensionality of the representation matrix.
In others related works, stochastic gradient descent (SGD) is used, allowing to reduce the memory resent images and annotations jointly in a low-dimensional embedding space. In the same way, Caicedo training data set, in order to find a common semantic representation by modeling the correspondences between visual patterns and text terms.

The algorithm presented in this paper, called ONSE is a reformulation of the classic NSE [29] as an online-learning algorithm using a stochastic gradient descent approach, which only needs to keep small risk. ONSE retains the advantages of NSE which make it perform better than other matrix factorization approaches when applied to images with clean and semantic-rich annotations. Moreover, with respect to the first version of ONSE presented in our previous published work [30], this paper introduces two increases the retrieval performance, and second, an adaptive learning rate is added instead of using a is very sensitive in practice. 3. Online non-negative semantic embedding model
The Non-negative Semantic Embedding (NSE) algorithm [29] reduces the problems of finding a com-mon semantic representation for both visual and text content to the problem of embedding the visual 3.1. Non-negative semantic embedding
Assume a collection of images with annotations. Assume that the image visual content is represented the number of terms in the codebook.

If we assume that the image semantics is represented by the text that accompanies it, we can use NSE visual content, imposing a non negativity constraint on the solution: where, S  X  R n  X  m is the transformation matrix which models the linear mapping between the visual to the presence of some associated labels.

Vanegas et al. [29] presented this problem as a special case of non-negative matrix factorization (NMF [19]), where the semantic encoding corresponds to text data and is fixed; and the factorization problem is solved using the Kullback-Leibler divergence criterion, following the Lee and Seung X  X  ap-descent. This strategy is a gradient descent optimization method which seeks to minimize an objective problem of semantic embedding as the following optimization problem: structed one ( ST ), and the purpose is to find S that minimize this difference. 3.2. Optimization problem based on Kullback-Leibler divergence
There are many alternatives to measure the difference between the original matrix and the approxima-tion produced by the factorization [15]. A popular measure used as cost function in NMF algorithms is the generalized Kullback-Leibler (KL) divergence [20]. The KL-divergence is not symmetric, and there-and this may have advantages for some particular problems, as the one we are trying to solve. Zhirong approximation than others widely used NMF algorithms. The corresponding optimization problem using KL-divergence is: where, D KL is the KL-divergence function. And the gradient of a cost function based on KL-divergence is: rate is as follows: 3.3. Non-negative restriction
The use of Kullback-Leibler as cost function implies a distributional interpretation of the data and requires a non-negativity restriction that can be satisfied by using a projected gradient method [18]. iteration, updating the current solution S  X  to S  X  +1 by using the following rule: 3.4. Regularized ONSE
The optimization problem in Eq. (2) may be extended as follows: the optimization problem using the KL-divergence becomes:
And the gradient of the optimization function based on KL-divergence with a regularizer function based on the Frobenius norm is as follows: 3.5. Online formulation set under modest memory requirements, making this method suitable for large scale image collections. is reformulated as follows: Algorithm 1 Online Non-negative Semantic Embedding input S 0 : Initial transformation matrix,  X  0 : initial step size, N : number of iterations 1. for  X  =1 to N do 2. Compute gradient: g  X  = [1] n  X  1  X  v  X  S 3. Learning rate calculation:  X   X  =  X  0 / (1 +  X  0  X  X  ) 4. Compute update:  X  S  X  =  X   X  g  X  5. Update transformation matrix: S  X  +1 = P ( S  X   X   X  S  X  ) 6. end for 7. return S  X  +1
With this reformulation in the updating rule, the general algorithm (Algorithm 1), can be described updating the transformation matrix from an observed pair of visual and text features randomly sampled. function [4] that depends on the number of iterations and an initial step size  X  0 .
This algorithm can be generalized by using several samples (grouped in a mini-batch) at each iteration instead of using only one. Previous works have shown faster execution when using mini-batches instead of single samples, and also a better numerical stability [12]. 3.6. Adaptive learning rate
The algorithm described in the previous section has a set of hyperparameters that can impact the setting of these hyperparameters may cause the algorithm to slowly converge or diverge. Determining a good learning rate require s a costly initial hyperparameter exploration.

There are methods that require second order derivatives of the cost function to determine the optimal step size, which are usually based on Newton X  X  method and inversion of the Hessian [2,3,23]. Unfortu-for each iteration, an expensive computation that involves a large dense matrix. 3.6.1. ADADELTA method
ADADELTA is an adaptive learning rate method which dynamically adapts over time using only first order information [33]. Conventional gradient descent use a step which is a multiple of the gradient, i.e., the same learning rate is applied to all the components of the gradient. In contrast, ADADELTA a good learning rate based on an approximation of the diagonal Hessian using only root mean square (RMS) measures of the gradient ( g ) and last updates (  X  S ).

For the calculation of the RMS, this method implements an accumulation of the squared gradients as as follows: where  X  is a decay constant. The RMS of the gradient at time  X  , RMS [ g ]  X  , is then defined as: Algorithm 2 Online Non-negative Semantic Embedding with ADADELTA input S 0 : Initial transformation matrix,  X  0 : initial step size, N : number of iterations 1. Initialize accumu lation variables E g 2 0 =0 , E  X  S 2 0 =0 2. for k =1 to N do 3. Compute gradient: g  X  = [1] n  X  m  X  v  X  S 4. Accumulative gradient: E g 2  X  =  X E g 2  X   X  1 +(1  X   X  ) g 2  X  5. Compute update: ( X  S  X  ) i = 6. Accumulate updates: E S 2  X  =  X E S 2  X   X  1 +(1  X   X  ) S 2  X  7. Update transformation matrix: S  X  +1 = P [ S  X  + S  X  ] 8. end for 9. return S  X  +1 where (  X  ) i denotes the i -th component of a vector and is a constant added to better condition the denominator. The step at time  X  ,  X  S  X  , is then calculated as: where RMS [ X  S ]  X   X  1 is calculated by replacing g by  X  S in Eqs (13) and (14).

An important property of ADADELTA is the insensitivity of the hyperparameters (  X  and )tothe characteristics of the dataset. Due to this, the hyperparameters did not need to be tuned. 3.7. Image indexing and search may be interested in searching into the database using example images as queries (query-by-example strategy). A new image without associated text can be projected to the semantic space by using the pseudo-inverse of the transformation matrix ( S + ): where, v is a column vector with the visual representation of the new image, t is the corresponding semantic representation, and  X I is a the identity matrix scaled by  X  which is used as regularization parameter to deal with a near-singular S T S matrix, which could make the problem ill-posed.
The inverse transformation matrix, S + , has to be calculated only once and stored in memory, which makes the process of indexing new unannotated images very efficient. Image search is done by compar-ing the query and the collection images using their semantic representations. Results are ranked using some similarity function (in this work the histogram intersection similarity [26] is used). 4. Experiments and results The objective of this section is to evaluate the performance of the proposed algorithm in a CBIR task. The evaluation includes a convergence analysis in order to determine how fast the algorithm achieves a solution. Also, the performance of the proposed algorithm is compared with several baselines using reported in order to evaluate its ability to deal with potentially large image collections. 4.1. Datasets 4.1.1. Carcinoma dataset
This dataset is based in a histopathology image collection that presents tissue samples from a col-lection of more than 300 cases, which has been used for the diagnosis of a kind of skin cancer called logical cases and the remanning images come from normal tissues samples. Each of these images was 10X and 20X), and stored at 1280  X  1024 pixels. Figure 1 presents some examples of the histopathology artifacts among others. 4.1.2. MIRFlickr 25,000 dataset
This collection consists of 25,000 natural scene images that were downloaded from the popular social photography site Flickr to provide a benchmark dataset for CBIR [17]. These images were collected in 38 categories, which we used in this work as semantic terms. Figure 2 presents some examples of the images, together with its related terms, that we can find in this collection. 4.1.3. Image representation
A bag-of-features representation [14] is used in both datasets, using the following procedure: for the construction of the codebook from each image in a selected training set, patches of 8  X  8pixels For each patch, the DCT (Discrete Cosine Transform) is computed in the 3 RGB channels, and the largest 21 coefficients per channel are used as features, generating a patch descriptor of 63 features with color and texture information (previous works have shown that DCT-based visual codewords are an used, 500 visual terms for carcinoma and 2000 visual terms for MIRFlickr. Experimental evaluation showed that a higher number of visual terms did not provide significant improvements, but carried more computational overload. Once the codebook was built, all images in the collection went through the and n = 2000 for MIRFlickr), which represents the histogram of visual term frequencies. 4.1.4. Text representation
In both datasets the text features are given by the clean and clearly predefined term annotations and the collection ( m =18 for carcinoma and m =39 for MIRFlickr), with 1 in a particular vector position indicating the presence of the corresponding term, and 0itsabsence. 4.2. Experimental setup
We conducted retrieval experiments using the query-by-example strategy and the evaluation was done using conventional image retrieval performance measures, including precision at 10 (p@10) and mean average precision (MAP). In both datasets 20% of the images were randomly selected as queries and the remaining 80% of the images were used as the target collection to find relevant images. Automatic experiments were performed by sending a random selected query to the system and evaluating the rel-considered relevant if it shares at least one text term with the query. 4.3. Convergence
The first evaluation conducted in this work is the convergence analysis of the proposed stochastic algorithm, comparing the classical NSE and the online learning method (ONSE). The algorithms were iterated by a number of epochs and the loss function (Kullback-Leibler divergence) was evaluated for each epoch. An epoch corresponds to a full pass over the whole training data set.

Figure 3 shows the Kullback-Leibler divergence between the original visual matrix and the recon-structed visual matrix calculated by multiplicating the textual matrix and the learned transformation matrix. The stochastic approach can achieve a faster convergence rate in comparison with the classical algorithm. For the carcinoma dataset, ONSE only required about 5 epochs to achieve convergence, in-MIRFlickr the convergence of ONSE is very fast, requiring only about two iterations over the whole training dataset.
 of unannotated images and queries, improving the retrieval performance of the system. This aspect is evaluated in the next subsection. 4.4. Retrieval performance
In order to evaluate the model performance in an image retrieval task, we compared it against two state-of-the-art semantic embedding methods: the classical NSE (based in KL-divergence and using multiplicative updating rules) and MMCR (Modified M ulti-stage Convex Relaxation) proposed by Hsan keyword with the query. The text tags of query images are not shown to the system, they are only used to judge the relevance of the results.
 For instance, the hyperparameters  X  0 and  X  control how quickly the algorithm converges and improper values for these parameters may cause the algorithm to converge slowly or to diverge. So, initially we seek the best configuration for each strategy by exploring the set of hyperparameters using cross-that performs best in average for all the folds, were selected for the following experiments.
Once, we had found then best configuration, we evaluate the algorithms with the remaining 20% of the remaining 80% as the target image database. Table 1 summarizes the findings of our experimental of the images. All the semantic embedding algorithms improve the results, in terms of MAP, of the visual baseline strategy. However, in terms of precision (P@10), the visual baseline has a competitive performance that is only outperformed by ONSE in the carcinoma dataset.
 In all the cases, the algorithm presented in this paper, regularized ONSE with and without ADADELTA, obtained the best performance, both in terms of MAP and precision. This suggests that overfitting. The ADADELTA variant does not present any degradation in retrieval performance, in fact, we can see an improvement in early precision (P@10) in the carcinoma dataset. The main advantage exploration to tune the learning rate, which can be an expensive task.

In Fig. 4 the interpolated recall-precision curves for carcinoma (a) and MIRFlickr (b) datasets are shown. For the carcinoma dataset we can see that direct visual matching presents very good results in in images without direct visual connection. A similar phenomena happens for the MIRFlickr dataset where the semantic embedding approaches also outperform the visual matching strategy. Also we can see In general, the main conclusion of the retrieval performance evaluation is that the proposed algorithm has a competitive performance in terms of the relevance of the results. However its main advantage is the efficiency of the learning process, which will be evaluated in the next section. 4.5. Computational load Table 2 shows the required time in training phase to achieve convergence for the different algorithms. Reported times are the average results after running all algorithms 5 times in a computer with 4 GB of ram memory and a CPU at 2.4 Ghz using only one core. The size of each dataset is also reported, in order to compare how the algorithms complexit y grows with an increasing number of samples. The NSE algorithm takes about 5 seconds to process the carcinoma dataset and increases to 494 seconds for MIRFlickr. MMCR requires the largest amount of time, taking about 2 seconds for the carcinoma dataset and 2834 for MIRFlickr. In contrast, the ONSE algorithm requires only 0.3 seconds for carcinoma and 27 for MIRFlickr. ONSE algorithm with ADADELTA requires more time due to the additional computation with ADADELTA to be 13 times faster than NSE and 78 times faster than MMCR in the MIRFlickr dataset.

The main reason for the reduction in training time in ONSE is that the number of required epochs until required number of epochs to achieve the maximum retrieval performance (retrieval results reported in Table 1), when an increase in the number of epochs does not carry an improvement in the performance. and the online version only needed 4. This is an expected behavior for algorithms based on stochastic and for large collections, one full scan is usually enough. 4.5.1. Memory usage Table 3 shows the maximum memory usage for each algorithm. The results clearly show that not only ONSE algorithm and its variants consume less memory, but also the amount of memory required to reason is that ONSE only needs to keep the transformation matrix in the main memory, since visual and textual samples used in each update can be discarded afterwards. Also, we can see that the addition of ADADELTA and the regularization function dos not significantly increase the memory requirements. 5. Conclusions
This paper presents a new method for semantic image indexing, ONSE, which efficiently builds a semantic representation space based on associated text annotations. The method finds a semantic rep-resentation for images, by modeling a mapping between the visual information and the semantic space spanned by the text representation. According to the results of the experimental evaluation, this new semantic representation improves the performance in content-based image retrieval.
 a significant reduction in memory requirements and computation time in comparison with the classical NSE. This characteristic allows ONSE to deal with large repositories of images.

ONSE formulation includes a regularization term in its loss function to control the model complexity, this characteristic showed an improvement in retrieval performance when compared to a previous version costly initial hyperparameter exploration.
 Acknowledgements This work was partially funded by project Multimodal Image Retrieval to Support Medical Case-Based Scientific Literature Search, ID R1212LAC006 by Microsoft Research LACCIR and Jorge Vane-gas also thanks for doctoral grant supports Colciencias 617/2013.
 References
