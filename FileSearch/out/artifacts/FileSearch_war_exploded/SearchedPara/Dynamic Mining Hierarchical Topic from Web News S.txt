 On most Web pages, vast amounts of useful knowledge are embedded into text. Given structured knowledge, would enhance efficient document access. Given that the Web has become a vehicle for the distribution of information, many news organizations are news services, we have focused our attention on mining topic from news streams. meaningful topics from news stream data. We introduce the algorithm that works in a The algorithm explore dynamically divisive and agglomerative characteristic in whole document clustering process. 
Conventional divisive clustering algorithm such as K-means and K-medoid algo-ventional agglomerative clustering algorithm is completely accurate but is very CPU clustering as the new incoming documents arrive, and both clustering phases equip a deserves division, then the system searches for possible aggregation of clusters. 
The main problem, then, with both of these methods is that their inability of identi-clustering algorithm is further able to work by leveraging off the nearest neighbors of shapes and different densities of clusters. 
Main features of our algorithm include the use of similarity as distance measure, a needed clusters. 
The rest of this paper is organized as follows. In Section 2, we introduce our prob-lem definition. In Section 3 we represent our proposed method, In Section 4 we pro-vide experimental results. In Section 5 we summarize our works. The following section is terminology and definitions. These are necessary to con-cretely define the problem at hand, and to explain our proposed solution. ness between two documents, we use the Cosine metric, which measures the similar-ity of two vectors according to the angle between them. The cosine of the angles be-tween two n-dimensional document vectors ( i d and j d ) is defined by the dissimilarity between two documents is represented as as similar to a document j d . 3.1 Streaming News Model sequences. In this paper, we use logical-based landmark windows [2], also known as count-based or sequence-based landmark windows. The length of window is defined in terms of the number of news sequences. 3.2 Dynamic Divisive-Agglomerative Document Clustering technique that constructs the hierarchy from the top (large cluster) to bottom (several clusters). Agglomerative Nesting (Agnes). Agnes proceeds by a series of fusions. Initially, all rithm finds a pair of objects with minimal dissimilarity. If there are several pairs with minimal dissimilarity, the algorithm picks a pair of objects at random. main difference with the agglomerative method (Agnes) is that it constructs the hierar-all clusters, comprise of single objects. Thus, the hierarchy is built in n-1 steps. minimum number of observations that are necessary to assure convergence. Tech-have in fact be successfully used in online decision trees [8] [9]. Hoeffding bounds or additive Chernoff bounds. After n independent observations of a real-valued random variable r with range R, the Hoeffding bound ensures that, with mean of the samples and Figure 1 shows our proposed dynamic divisive-agglomerative clustering algorithm. that only news documents 12 {,,, } documents itself forms a singleton cluster. Adding a new document to existing cluster structure proceeds in three phases: neighborhood search, dynamic divisive phase and dynamic agglomerative phase. clustering algorithm. suffix-stripping algorithm [4] as implemented by [5]. Input: A set of streaming news document, is the length of the landmark window. 2. Neighborhood search: Given a new incoming document { } , obtain 
Nd Nd Nd  X  X   X  by performing a neighborhood search, and f ind 
The quality of a generated cluster hierarchy was determined by two metrics, preci-sion and recall. measure neighborhood for a document i d , varies between 0.2 and 0.25, i.e., the algo-rithm guessed the exact number of clusters. If the value of  X  was too small, then the identified if the value  X  is too large. 
For the purpose of comparison, we decided to use spherical K-means clustering al-gorithm [6] and DC-tree clustering algorithm [7]. We compare the results of the vari-ous experiments across algorithms and represent in bellow Table1. congestion intrusion detection 
Job oppor-
Since the sizes of clusters can be of arbitrary numbers, clustering algorithms must fying clusters with different densities, we organized datasets where each dataset con-rithm on this datasets. Table 2 shows the average values of precision and recall for all topics. As shown in Table 2, when the density of each cluster is not uniform, the accu-racy of the modified K-means clustering al gorithm degraded. In contrast, the accuracy of our algorithm remains similar. Then we can conclude that the proposed algorithm outperforms the modified K-means algorithm in terms of precision and recall. This is neighborhood of a document while spherical K-means [6] and DC-tree [7] clustering measures similarity between a cluster and a document. stream data. It also has ability of identifying the different shapes and different densi-ties of clusters. 
