 Traditional batch model-based Collaborative Filtering (CF) approaches typically assume a collection of users X  rating data is given a priori for training the model. They suffer from a common yet critical drawback, i.e., the model has to be re-trained completely from scratch whenever new training data arrives, which is clearly non-scalable for large real rec-ommender systems where users X  rating data often arrives sequentially and frequently. In this paper, we investigate a novel efficient and scalable online collaborative filtering tech-nique for on-the-fly recommender systems, which is able to effectively online update the recommendation model from a sequence of rating observations. Specifically, we propose a family of online multi-task collaborative filtering (OMTCF) algorithms, which tackle the online collaborative filtering task by exploiting the similar principle as online multitask learning. Encouraging empirical results on large-scale datasets showed that the proposed technique is significantly more ef-fective than the state-of-the-art algorithms.
 H.3.3 [ Information Storage and Retrieval ]: Information Filtering; I.2.6 [ Artificial Intelligence ]: Learning Recommender systems, Collaborative Filtering, Online learn-ing, Multi-task Learning
Collaborative filtering (CF) aims to make accurate predic-tions ( X  X iltering X ) about the preferences of a user by learn-ing/leveraging from a collection of preferences from many other users ( X  X ollaborative X ). It is a core learning technique widely used in real-world recommender systems [30]. In literature, a variety of CF algorithms have been proposed, which can be generally grouped into two schools: (i) mem-ory based methods [26, 20, 16, 11, 32, 13], and (ii) model based methods [27, 15, 31, 29, 23]. The model-based meth-ods, typically powered by machine learning techniques, are more desired than the memory -based methods, especially when the amount of rating observations is relatively limited or sparse, which is common for real recommender systems.
Most existing model-based CF approaches assume a col-lection of users X  rating data is given a priori to train the model in a batch learning fashion. Typically, the model has to be re-trained whenever there is new training data. Such approaches are impractical for real-world recommender sys-tems where training data often arrive sequentially as new users are being added daily or even hourly, and new prod-ucts/items are being offered dynamically. As a result, tradi-tional batch learning methods are non-scalable due to their highly expensive re-training cost. This calls for an urgent need of efficient and scalable CF techniques for learning the model on-the-fly for real-world recommender systems.
To this end, we investigate Online Collaborative Filter-ing (OCF) techniques for on-the-fly recommender systems in this paper. The state-of-the-art OCF approach is based on the online low-rank matrix approximation algorithm [1, 17] by applying the simple online gradient descent (OGD) al-gorithms to solve the matrix factorization task, which thus avoids the highly expensive re-training cost of traditional batch matrix factorization algorithms. Despite their merit of high efficiency, their naive gradient descent approaches may not be very effective since they completely neglect the underlying structure of the collaborative filtering task.
To overcome the limitation of the existing OCF approaches, we propose a novel framework of Online Multi-Task Col-laborative Filtering (OMTCF) by exploiting the close rela-tionship between collaborative filtering and multi-task learn-ing [22]. The key idea of OMTCF is to not only update the weight vectors of the user (task) related to the current ob-served data, but also the weight vectors of some other users (tasks) according to a user interaction matrix. As a result, OMTCF is able to learn the model more accurately than the existing OCF algorithms, with the only disadvantage of being slightly less efficient due to the cost of multi-task learning. In this paper, we propose a family of OMTCF algorithms to trade off between efficacy and efficiency, and extensively examine their performance for on-the-fly recom-mender systems on various large benchmark data sets.
The rest of the paper is organized as follows. Section 2 introduce the background and related work, Section 3 pro-poses the framework of Online Multi-Task Collaborative Fil-tering. Section 4 discusses our experimental results, and Section 5 sets out the conclusion of our work.
This section briefly reviews the background of some major groups of related work, including batch collaborative filter-ing, online collaborative filtering, and multi-task learning.
One of the state-of-the-art methods for regular CF tasks is the latent factor or matrix factorization method [31, 23], which is one of the major techniques used by the Netflix prize winner X  X  algorithms [14]. The key idea of latent factor model assumes that the similarity between users and items is simultaneously induced by some hidden lower-dimension structure in the data. For example, the rating that a user gives to a movie might depend on a few implicit factors such as the user X  X  taste across various movie genres. Beyond this direction, some probabilistic and Bayesian matrix factoriza-tion for collaborative filtering methods have also been pro-posed [25, 19]. For a more comprehensive survey on regular CF techniques, please refer to the survey paper [30]. Al-though the batch algorithms for matrix factorization have shown great successes, they generally suffer from high time complexity and memory cost, which thus are non-scalable for building on-the-fly recommender systems.

Online collaborative filtering has received emerging atten-tion recently. The work in [10] is perhaps one of early work, in which OCF is cast as an online ranking problem [8]. This algorithm is however not very practical because it assumes all the users X  preferences can be known for each training in-stance, which is not always true. The related work most relevant to our study is the online collaborative filtering by stochastic gradient descent [1, 2] and another improved work in [17], which attempted to optimize the objective function of matrix factorization based formulation for collaborative filtering in online learning fashion. Their naive gradient de-scent strategy simply neglects the underlying structure of CF tasks which thus limits their learning efficacy. Our work is partially motivated to overcome their limitation. Besides, our work is also somewhat related to the online evolution-ary collaborative filtering work in [18] which assigns larger weights to the new rating and incrementally updates the users X  and items X  similarities, but differs in two major as-pects: (i) to be more precise from an online learning per-spective, [18] is essentially a mini-batch or incremental algo-rithm that does not update the model upon a single obser-vation; and (ii) [18] generally belongs to a simple memory-based approach, which is usually less effective as compared to the state-of-the-art matrix factorization approaches. Fi-nally, our work is very different from the work [9] which tried to improve scalability of batch CF methods by explor-ing practical tricks, such as the MapReduce framework.
Our work is also inspired in part by some related work in Multi-task learning (MTL) [3], which is a machine learn-ing method where multiple tasks are jointly learnt such that each of them benefits from each other. A popular frame-work for MTL is multi-task feature learning [4], which as-sumes that all tasks share a common yet latent feature rep-resentation. Similarly, although MTL has many advantages, it also suffers some disadvantages, e.g., low efficiency. Re-cently, online multi-task learning [7, 24] has been proposed to extend traditional MTL in online learning setting. The online multi-task learner proceeds in rounds by observing a sequence of examples, each belonging to some task from a pre-defined set tasks. The basic idea of the online multi-task learning in [7] is that instead of only updating the weight vector of the task related to the current instance, it online updates weight vectors of multiple tasks based on a task interaction matrix. Furtherm ore, instead of using a fixed task interaction matrix, [24] proposed to update the task relationship matrix during the online learning process.
Although both online collaborative filtering and online multi-task learning have been actively studied in different research communities separately, to the best of our knowl-edge, no existing work has attempted to tackle online collab-orative filtering by exploiting the idea of online multi-task learning for building on-the-fly recommender systems.
In this section, we present the proposed framework for On-line Multi-Task Collaborative Filtering (OMTCF) for build-ing on-the-fly recommender systems. We emphasize that an essential difference between online CF and traditional batch CF tasks is that batch CF assumes the entire collection of training data is given a prior before the learning task, while online CF learns the model on-the-fly from a sequence of training data. In the following, we will firstly introduce the problem setting and then present a family of OMTCF algo-rithms for addressing a variety of practical issues.
First of all, we introduce the problem of a regular collab-orative filtering task. In a collaborative filtering task, some users from a total of n users rated some products (items) from a total of m products, and these ratings form an in-complete matrix R  X  R n  X  m ,where r ij is the rating on the j -th item given by the i -th user. The goal of collaborative fil-tering is to predict the unknown ratings based on the known ones. For collaborative filtering, one of the well-known ap-proach is the matrix factorization algorithm, which learns the latent structure by factorizing the rating matrix to a user matrix U  X  R n  X  k and an item matrix V  X  R m  X  k through the following optimization problem: where R F is the Frobenius norm of the matrix R. If the rating matrix R is fully observable, then this problem can be reduced to a Singular Value Decomposition (SVD) problem. However, the matrix for collaborative filtering is only partially observed, which results in an ill-posed prob-lem for the above formulation. To tackle the challenge, we can apply the low-rank matrix approximation technique to re-formulate this problem. Specifically, let U a be the a row of U ,and V b be the b -th row of V , then given a partial collection of observed pairs C = { ( a, b ) } ,let |C| denote the number of observed ratings, the collaborative filtering prob-lem can be re-formulated as the regularized optimization task for low-rank matrix factorization: where  X &gt; 0 is a regularization parameter, and ( U a ,V is a loss function that defines the loss between the true and the prediction U a V b .

However, this new problem is a non-convex optimization which cannot be solved directly using a standard SVD al-gorithm. Since the optimization problem (2) is non-convex, [28] proposed to replace the Frobenius norm regularization by a trace norm regularization in order to relax it to a convex optimization problem, which can be solved by Semi-definite Programming (SDP) using the following property of trace norm regularization: However, the heavy cost of solving a sparse SDP task makes it infeasible for real datasets with millions of observations.
To overcome this limitation of regular collaborative filter-ing, [1] proposed the online collaborative filtering based on a simple gradient descent approach. In particular, given a sin-gle prediction problem of user a on item b , the algorithm first makes a prediction of rating  X  r a,b = U a V b ;afterthetruerat-ing r a,b is revealed, the algorithm suffers a loss ( U a finally, the OCF algorithm makes updates on their model U and V based on the gradient descent approach: where  X  is the learning rate parameter. In general, one can define different type of loss function for different pur-poses. For example, to optimize the Root Mean Square Er-can define the loss by the square error function as: Similarly, if one aims to optimize the Mean Absolute Error the absolute loss function as:
The proposed OMTCF method is generally inspired by noticing the equivalence between multi-task learning and collaborative filtering formulations. To illustrate this clearly, we rewrite the formulation of the optimization task of col-laborative filtering as follows: arg min
By treating each user i as an individual task, each U i as the task model, V as the features of items and r i,b as the prediction output of model i for item b , it is not difficult to see that the above formulation is essentially equivalent to the formulation of a multi-task learning that optimizes the models of multiple tasks simultaneously. The equivalence between collaborative filtering and multi-task learning has also been shown by some previous studies in literature [22, 21], which partially inspire our study in this paper.
Motivated by the above equivalence fact, our approach is to exploit the idea of online multi-task learning [7] to tackle the online collaborative filtering task. For online multi-task learning, one important step is to define a task interaction matrix A  X  R n  X  n , which essentially indicates the similarity or interaction degree between tasks. Following the similar idea, we can define a user interaction matrix A  X  R n  X  n as a large value A i,j indicates a close interaction should be imposed between user i and user j . In general, matrix A can be computed if prior knowledge about the users is available. If however such prior knowledge is not available, one can define some constant matrix. For example, one simple ap-proach used by the previous study is to define A as follows: where the above matrix indicates that we should make a full update ( A ii = 1) of the user X  X  model when the instance belongs to, and make a half update ( A ij = 1 2  X  i = j )ofother users X  models otherwise.

Unlike the existing OCF approach where only one user is updated for every observed rating, the proposed online multi-task collaborative filtering (OMTCF) approach will update multiple users for each observed rating. More for-mally, given an incoming rating r a,b with respect to user and item b , the algorithm will update the models of multiple users (i.e., multiple rows of U) according to the user interac-tion matrix A. Specifically, we have the following functions for updating the models of multiple users: where i =1 ,...,n ,  X  is the learning rate and ( U a ,V b is a loss function which is defined based on either Eq. (6) for RMSE or Eq. (7) for MAE. In the above, a larger value of A ( a, i ) will result in a stronger update on U i eventually. With respect to the two kinds of loss functions, we derive the detailed online updating rules by gradient descent associated with the interaction matrix in the following propositions.
Proposition 1. In an OMTCF task, given an observed rating pair ( a, b ) , the updating rule with respect to the loss function 1 defined in Eq. (6) can be expressed as follows: where i =1 ,...,n .

Proposition 2. In an OMTCF task, given an observed rating pair ( a, b ) , the updating rule with respect to the loss function 2 defined in Eq. (7) can be expressed as follows: where i =1 ,...,n .
 In the proposed OMTCF algorithms, one key issue is how to determine an appropriate user interaction matrix A. The following will discuss this issue in detail.
Instead of choosing a constant user interaction matrix A as shown in Eqn (9), another possible approach is to calculate a (sparse) matrix A from prior knowledge of user information when available: where similarity( i, j ) is a function of defining the similarity betweentwousersaccordingtothepriorknowledge. For example, if we only have the age information about users, we can probably set the similarity value for the users who belongs to the same age group as 1, and 0 otherwise.
The above approaches are generally limited in that they either require the prior knowledge which is not always avail-able or often fix the user interaction matrix as a constant matrix, which may somewhat restrict the power of the pro-posed algorithm for achieving faster convergence. To over-come these limitations, we also propose to learn the user interaction matrix A automatically during the online learn-ing process. In particular, we can choose the user interaction matrix by using the covariance matrix of user matrix U that is updated sequentially as follows: which is somewhat inspired by the Gaussian Process based multi-task learning [5], where the task relatedness is mea-sured by the Gaussian Process covariance function.
Although the above suggested matrices are fairly reason-able, in a real-world scenario, they are only an approxima-tion of the user similarity, which may not exactly reflect the true user interaction. In addition, online multi-task learning often converges much faster than online single task learning at the beginning of the online learning process, but the ad-vantage of performing multi-task updates will become less significant as time goes by as the models become more and more accurate. To address these issues, we propose to define the following attenuation coefficient function over the user relationship matrix: where I x is an indicator function that outputs 1 when x is true and 0 otherwise. This attenuation function weakens the effect of updating the multiple users as time goes. Thus, the final true user interaction matrix used in OMTCF will be the user interaction matrix multiplied by the attenuation coefficient as: where is the element-wise produce, i.e., A t ( i, j )=  X  t A ( i, j ). Finally, Algorithm 1 summarizes the framework of the proposed OMTCF algorithms. It is not difficult to see that the proposed algorithms are efficient and scalable with linear time and space complexity.
 Algorithm 1 OMTCF  X  Framework of Online Multi-Task Collaborative Filtering algorithms
Although the proposed OMTCF algorithms achieve sig-nificantly faster convergence rate than the traditional OCF approach, this advantage is paid by higher computation cost of performing the multi-task updates. Specifically, because OMTCF needs to update the models of multiple users dur-ing the online learning step, the running time cost would be much higher than OCF. In this part, we would propose a hybrid algorithm to trade off between efficiency and efficacy.
The proposed algorithm follows the similar framework as the OMTCF-I algorithm. In the online learning process, we monitor the amount of prediction change (in either RMSE or MAE) over a past certain period (defined by a window size T ) X ( t, T ) defined as follows: We then introduce a threshold  X  to indicate whether the learning process has converged sufficiently. If the change  X ( t, T ) is smaller than  X  , the algorithm will then switch to a single-task update, i.e., We denote this hybrid algorithm as  X  X MTCF-IV X  for short.
The above OMTCF algorithms follow a formal online learn-ing setting, but they make an implicit assumption, i.e., both the number of users and the number of items are fixed and they are both known beforehand. In a real-world online ap-plication, this is not realistic. In this part, we aim to extend OMTCF algorithms to handle the situation where an incom-ing rating observation is related to a novel user or a novel item. The key idea of the proposed algorithm here is that we will try to expand the user/item matrix by adding one user/item vector whenever a new user/item appears. We assume the user interaction matrix is fixed as Eq.(9), which is the same as  X  X MTCF-I X  (we could also consider other type of interaction matrix). We keep a multi-task cumu-lative updated user vector and update it at each iteration. This multi-task cumulative updated user vector will be ap-plied to initialize the new user vector whenever a new user is added. This strategy is able to guarantee the algorithm achieves the same performance as the  X  X MTCF-I X  without considering the difference caused by different random ini-tializations. We denote this algorithm for handling novel sample extension as  X  X MTCF-V X  for short. The details are summarized in Algorithm 2.
As we can see, algorithm  X  X MTCF-V X  can build the user and item matrix from scratch and online extended the user and item matrix based on the data observed, which could save the memory and make the algorithm more efficient. The algorithm  X  X MTCF-IV X  can avoid unnecessary multiple up-dates when the online learning process has converged well. In fact, we can adopt the two improvements over original online multi-task collaborative filtering algorithm simulta-neously into a single new algorithm, which is able to make online multi-task learning strategy for collaborative filter-ing more practical and efficient for large-scale datasets. We Algorithm 2 OMTCF-V : The proposed OMTCF algo-rithm for handling novel sample extension name the new algorithm as  X  X MTCF-VI X , which is a combi-nation of OMTCF-IV and OMTCF-V. We omit the detailed algorithm due to space limitation.

Remarks on Parallelization. One important advan-tage of online CF over batch CF is that online algorithms only need to process one rating at a time, making the up-dating efficient and scalable. Although our OMTCF algo-rithms are generally more computationally expensive than the simple OCF algorithm in [1], this disadvantage can be somewhat compensated by exploring the advantages of par-allel computing techniques, which can be easily deployed by the proposed OMTCF algorithms. In particular, in contrast to the OCF algorithm, our OMTCF algorithms update mul-tiple users simultaneously and the updates of these users do not affect each other at each learning round, making them to be easily parallelized by a trivial implementation.
In this section, we evaluate the empirical performance of the proposed OMTCF algorithms for online collaborative fil-tering tasks. It is important to note that we do not compare the proposed algorithms with other existing batch collabo-rative filtering algorithms since the performance evaluation protocol and settings between online and batch learning al-gorithms are very different, making them unfair and mean-ingless to be compared directly.
We compare the proposed OMTCF algorithms with the emerging online collaborative filtering algorithm. Specifi-cally, the compared algorithms in our experiments include:
To extensively examine the empirical performance, we conduct the experiments on a variety of publicly available datasets widely used for benchmark evaluation of CF in lit-erature. The first two relatively smaller datasets include: (i) the  X  X ovieLens 100k X  dataset collected by the Grouplens Research Project from the MovieLens web site 1 , where users can freely give their ratings on various movies and receive movie recommendations; it consists of 100,000 ratings from 943 users on 1682 movies, and also provides additional user info, such as their genders, and ages, etc; (ii) the  X  X etRec 2011 MovieLens X  dataset, which links the movies of Movie-Lens with their corresponding web pages at IMDb and Rot-ten Tomatoes movie review systems; this dataset consists of 855,598 ratings from 2113 users on 10197 movies; it however does not contain any user info. We also test on other four large-scale data sets which will be introduced later.
To make fair comparisons, all the algorithms adopt the same experimental setup. Firstly, for the proposed X  X MTCF-II X  algorithm, we set the similarity between a pair of users as 1 when they are from the same gender and in the same age period, while the similarities of others pairs as 0. Note that two users are considered as in the same age period if the difference of their ages is less than 5 years. Considering the fact that only the  X  X ovieLens 100k X  dataset consists of the user information, the algorithm  X  X MTCF-II X  is only tested on this dataset. Secondly, for the proposed  X  X MTCF-III X  algorithm, we use the gaussian kernel for the users vectors to compute the user similarity, where the kernel width  X  is set as 1. To make a fair comparison, the learning rate  X  of all algorithms is set to 0 . 005, and the regularization parameter is set to 3  X  6 ,the  X  parameter in DA-OCF algo-rithm was set to 0 . 006, which was suggested to achieve the best performance according to [17]. The rank parameter k of matrix U and V is set to two cases: 5 and 10, respec-tively. After the parameters are chosen, all the experiments were conducted over 20 runs of different random permuta-tions for each dataset. All the experimental results were reported by averaging over these 20 runs. For performance metric, we evaluate the performance of online collaborative filtering algorithms by measuring their scores of online Root Mean Square Error (RMSE) and online Mean Absolute Er-ror (MAE) on the test set.
Table 1 summarizes the average performance of the com-pared algorithms over the two datasets. From the experi-mental results, several observations can be drawn as follows. http://movielens.umn.edu Table 2: Evaluation of Efficacy and Time Cost
MovieLens RMSE MAE 100k RMSE TIME(s) MAE TIME(s) OCF 1.2779 0.76 1.1890 0.68 DA-OCF 1.2722 2.01 1.1438 2.06 OMTCF-I 1.0534 102.41 0.8644 104.08 OMTCF-II 1.1103 23.81 0.9514 24.03 OMTCF-III 1.0443 5883.83 0.8514 5732.84 OMTCF-IV 1.0607 2.19 0.8967 2.99 OMTCF-V 1.0532 88.61 0.8648 91.66 OMTCF-VI 1.0521 1.34 0.8625 1.96 HetRec 2011 RMSE MAE MovieLens RMSE TIME(s) MAE TIME(s) OCF 0.9408 7.79 0.7560 5.99 DA-OCF 0.9114 17.08 0.7273 16.93 OMTCF-I 0.8757 1964.89 0.6786 1992.89 OMTCF-III 0.8719 2 . 3  X  10 6 0.6785 2 . 3  X  10 6 OMTCF-IV 0.8794 22.27 0.6818 33.85 OMTCF-V 0.8767 1126.62 0.6779 1159.84 OMTCF-VI 0.8757 12.78 0.6713 16.57 The parameters for OMTCF-V is the same as OMTCF-IV. After choosing the parameters, all the experiments were con-ducted over 20 runs of different random permutations for each dataset. All the experimental results were reported by averaging over these 20 runs. The performance evaluations are summarized in Table 2.

Several observations can be drawn from the results. First, we found that OMTCF-III, though achieving the best RMSE and MAE performance, runs significantly slower than the other algorithms, indicating the importance of improving ef-ficiency of the proposed algorithms. Further, we can see that OMTCF-IV achieves significantly smaller values of both RMSE and MAE than OCF, which demonstrates the strategy of the proposed OMTCF-IV algorithm is significantly more ef-fective than the state-of-the-art OCF algorithm. In addi-tion, the OMTCF-IV algorithm is slightly worse than the OMTCF-I algorithm in terms of RMSE and MAE values, but the difference is very small. In addition, according to the time evaluation results, OMTCF-IV runs slightly slower than the OCF algorithm, but significantly faster than OMTCF-I. From these promising results, we can conclude that the proposed OMTCF-IV algorithm empirically achieves fairly comparable RMSE/MAE performance as OMTCF-I, and shares quite similar empirical time complexity as OCF, which indicates the OMTCF-IV algorithm in general achieves a good trade-off between efficacy and efficiency. Finally, we examine the efficacy of the proposed OMTCF-V algorithm for handling new sample extension issue. In particular, by inspecting the performance of the OMTCF-V algorithm, we observe that OMTCF-V achieves almost identical values of RMSE and MAE as compared with the OMTCF-I algorithm (the marginal differences should be caused by different randomization for the user and item vectors), but save much time cost than the OMTCF-I al-gorithm, which demonstrates that the proposed OMTCF-V algorithm is not only capable of handling the new sample extension issue perfectly, but also runs more efficiently than the previous OMTCF algorithms. Among all the OMTCF algorithms, OMTCF-VI is the most efficient one and has comparable RMSE/MAE performance with other algorithms, making it more applicable for large-scale applications.
We now evaluate the practical OMTCF-VI algorithm on four large-scale datasets: (i) Dating Agency [6]: The Dat-ing Agency dataset 2 , which contains 17,359,346 anonymous ratings of 168,791 profiles made by 135,359 LibimSeTi users; (ii) Jester Joke: this dataset from online Joke recom-mendation system 3 contains 1,761,439 ratings of 150 jokes from 63,974 users; (iii) Movielens 1M: this Movie rating dataset 4 contains 1,000,209 ratings of 3,900 movies by 6,040 users; and (iv) Movielens 10M: this Movie rating dataset 5 contains 10,000,054 ratings of 10,681 movies by 71,567 users.
Table 3 and Figure 2 summarize the empirical results of our evaluation. We can observe that OMTCF-VI performs significantly better than the OCF algorithm in terms of both RMSE and MAE metrics. In terms of the time efficiency, the online algorithms (OCF and OMTCF-VI) are generally fairly efficient, which typically took several hundreds sec-http://www.occamslab.com/petricek/data/ http://goldberg.berkeley.edu/jester-data/ http://movielens.umn.edu http://movielens.umn.edu onds to run on a dataset with 10,000,000 ratings. Finally, among all the online algorithms, the proposed OMTCF-VI algorithm is on average just 2-3 times slower than the OCF algorithm, and slightly slower than or sometimes compara-ble to the DA-OCF algorithm.
 This paper proposed a novel framework of Online Multi-Task Collaborative Filtering (OMTCF) for on-the-fly rec-ommender systems, in which a family of novel OMTCF al-gorithms were proposed. We conducted an extensive set of experiments by comparing several variants of the proposed algorithms with the existing online algorithms. Our promis-ing empirical results showed that (i) online algorithms are very efficient and highly scalable which can run on large datasets with 10-million ratings in several minutes using a regular machine; and (ii) the proposed online technique is considerably more effective than the existing online algo-rithms. Future work will address the theoretical analysis of the proposed algorithms and explore new algorithms. For example, our current algorithms treat users as tasks and up-date the models of multiple users simultaneously. One can also treat items as tasks and update the models of multiple items simultaneously. Our technique may also be extended to tackle some open challenges in CF, e.g., tracking tem-poral dynamics [12], for which online algorithms potentially could be a natural and perhaps better solution.
 This work was supported by MOE tier-1 grant (RG33/11).
