 Biomedical images and captions are one of the major sources of information in online biomedical publications. They often contain the most important results to be reported, and provide rich information about the main themes in published papers. In the data mining and information retrieval community, there has been much effort on using text mining and language modeling algorithms to extract knowledge from the text content of online biomedical publications; howev er, the problem of knowledge extraction from biomedical images and captions has not been model with background distribution (HPB) is introduced to uncover the latent semantic topics from the co-occurrence patterns of caption words, visual words and biomedical concepts. With downloaded biomedical fi gures, restricted captions are extracted with regard to each individual image panel. During the indexing stage, the  X  X ag-of-words  X  representation of captions is supplemented by an ontology-based concept indexing to alleviate the synonym and polysemy problems. As the visual counterpart of text words, the visual words are extracted and indexed from corresponding image panels. The mode l is estimated via collapsed Gibbs sampling algorithm. We compare the performance of our model with the extension of the Correspondence LDA (Corr-LDA) model under the same biomedical image annotation scenario using cross-validation. Experiment al results demonstrate that our model is able to accurately extract latent patterns from complicated biomedical image-caption pairs and facilitate knowledge organization and unders tanding in online biomedical literatures. H.2.8 [ DATABASE MANAGEMENT] : Database applications  X  Data mining; Image databases; I.2.6 [ARTIFICIAL INTELLI-GENCE] : Learning Algorithms, Experimentation, Theory. sampling, visual words, au tomatic image annotation. produce hundreds of thousands of digital publications each year. Although there are several public available digital databases such as PubMed Central, which provide immediate access to full-text biomedical and life science journal articles, users are still facing a difficult task of organizing the massive information from the digital repositories. In particular, it is extremely difficult for users to handle the highly complicated process of mapping the visual content in biomedical images to various domain-specific terms and concepts in corresponding captions. Biomedical images and captions are one of the major information sources in online biomedical literatures; they contain the most important results to be reporte d and provide rich information about the main themes in the published papers. Compared to free-form image captions (such as that from social network data source, like Flickr.com and Facebook.com ), which are characterized by user-sensitive descriptions, the image captions in biomedical literatures have relatively standard representation with restricted terms and always highly conform to the image content. In extracting biomedical concepts from captions, polysemies and synonyms are the major barrier. Biomedical ontologies (such as UMLS) provide the ability to overcome the polysemy and synonym problems. Therefore, if we can uncover the latent themes from the co-occurrence patterns of image content, caption words and biomedical concepts, we will be able to help biologists to find, understand and orga nize complicate knowledge from biomedical figures and satisfy their information needs.  X  X emantic gap X  between image features and the user Specifically, the problem is to identify a set of image features that well preserve the semantic consistency of image content. Recently, the  X  X ag-of-visual-words X  [6] approach exhibits very good performance in image categor ization and semantic image retrieval across several well-known databases such as the LabelMe , the TRECVID and the Visual Object Classes (VOC) that the patterns of different image categories can be represented by different distributions of micr ostructures (key-points). As an image document can be constantly represented as an unordered collection of key-points which carry rich local information, it can to some extent be regarded as a  X  X ag of visual words X . In practice, image patches containing key-points are quantified based on proposed the idea of assigning all the patch descriptors into clusters to build a  X  X ocabulary X  of  X  X isual words X  for a specific image set [6] . As a visual counterpart of the  X  X ag-of-word X  model, the  X  X ag-of-visual-words X  approach usually represents each image as a vector of visual words ba sed on the visual term frequency . After representing image content as  X  X ag-of-visual words X , the second issue is to uncover latent semantic themes from the co-occurrence patterns of image cont ent (i.e. the extracted  X  X ag-of-visual words X ), text captions a nd ontology-based concepts. In the data mining and information retrieval community, there has been much effort on using probabilistic models to learn latent topics from text content (such as the abstract) in online publications. Several effective probabilistic mode ls such as the Na X ve Bayesian model, the Probabilistic Latent Semantic Indexing (pLSI) model and the Latent Dirichlet Allocation (LDA) model proposed. Particularly, the LDA model has been very popular with the text mining community due to its solid theoretical foundation and promising performance. Despite the success of these models in text mining, th e problem of topic learning from both images and captions has not been fully studied yet. There are some approaches toward modeli ng latent topics from visual words, such as directly using LDA [17] and using Spatial Latent captions and ontology-based concep ts in one single probabilistic model. The Correspondence LDA (CorrLDA) model [7] proposed by Blei et al. for automatic image annotation, provides a natural way to learn the correlati on between text words and other to generate other entities (such as image features). By extending the entities in the CorrLDA model to visual words and ontology-probabilistic model that uncovers latent themes from the co-biomedical concepts. Although the CorrLDA model is able to learn latent topics from the image-caption pairs, however, as indicated in our study, the discovered topics can be overw helmed by several background words that frequently appear in the database. With this consideration, a hierarchical probabilistic topic model with background distribution is presented in this paper. With downloaded biomedical figures, restricted captions are extracted with regard to each individual image panel. During the indexing stage, the  X  X ag-of-words X  representation of captions is supplemented by an ontology-based concept indexing to alleviate the synonym and polysemy problems. As the visual counterpart of text words, the visual words are extracted and indexed from corresponding image panels. The mode l is estimated via collapsed Gibbs sampling algorithm, while the parameter selection is achieved by studying the likelihood and perplexity. We compare the performance of our model with the extension of the Correspondence LDA (Corr-LDA) model under the same biomedical image annotation scen ario using cross-validation. accurately extract latent patterns from highly complicated biomedical image-caption pairs, facilitate knowledge organization and understanding in online biomedical literatures. The remainder of this paper is or ganized as follows. In Section 2, we describe the procedure of preprocessing and indexing of biomedical figures. In Section 3, we present the extension of CorrLDA model and our hierarchical probabilistic topic model with background distribution. Section 4 provides the collapsed Gibbs sampling algorithms for inference and learning the proposed probabilistic models. Sec tion 5 reports the experimental results of the proposed method and compares our approach to the extension of CorrLDA model. We c onclude the paper in Section 6. In our research, we deal with biomedical figures downloaded from the PubMed Central web pa ges. Generally, a biomedical figure involves two parts, a singl e image composed with one or multiple image panels (sub-images) and the corresponding captions. Therefore, the preprocessing section of biomedical figures has two parts, the image processing part and the caption processing part. Within the downloaded biomedical figures, images are segmented into several individual image panels . It should be pointed out that there are image panels which contain flow charts or diagrams. Therefore, they are filtered out using basic region segmentation method. In caption texts, there are some pa renthesized expressions refer to specific image panels. Most of them are simply composed of such as (a and b), (b,c) and (a-c). We refer to these parenthesized expressions as image pointers (as ma rked by red color in Fig. 1b). in captions, which is similar to the HANDCODE2 method in [5]. Image pointers are commonly placed in some important positions (such as upper left and lower left corner) of image panels. Therefore, we apply the Asprise OCR Java SDK toolkit optical character recognition (OCR) in sub-images of image corners (Fig. 1a). The OCR toolkit achieved a moderate precision research. We check the image pointer extraction results and make necessary manual corrections. entire caption to each image panel, we develop a restricted caption scanner to identify restricted captions (Fig. 1b) with regard to the image pointer of each image panel. The association of texts and image pointers are determined according to different cases, such as image pointers locate at the beginning of a sentence, preceded by preposition and noun phrases, followed by a clauses, etc. Generally, the undergoing image pointer(s) for captions are disabled when the scanner meets another image pointer or reaches the end of a clause or a sentence. All the texts that don X  X  have any assigned image pointers are regarded as global captions (Fig. 1b). The image panel and captions associated with the same image pointer are named as an image-caption pair . In an image-caption pair, the final caption words are generated via a linear combination of restricted captions and global captions. The combination avoids the over-representation problem and preserves the uniqueness of each individual image panel. Each image-caption pair is assigned a unique ID like  X  X cr1011-1_a X , in which  X  X cr1011 X  is the PubMed Ce ntral article ID,  X 1 X  is the number of figure in the article, while  X  X  X  is the name of image pointer of a given image panel. During the indexing stage, we choose to represent the image content in each image-caption pair as a  X  X ag-of-visual-word X . First, we adopt the Difference-of-Gaussi an (DoG) salient point detector to detect salient points from im ages. The detection is achieved by locating scale-space extreme points in the difference-of-Gaussian images. The main orie ntations of salient points are determined by image gradient . Image patches containing the salient points are then rotated to a canonical orientation and different orientations are calculated. Consequently, each salient point is described by a 128-di mensional SIFT descriptor. Compared to other local descriptor s, the SIFT descriptor is more robust and invariable to rotati on and scale/luminance changes The SIFT descriptors extracted from training images are clustered into 1000 clusters using k-mean clustering to establish a codebook shown in Fig. 2, the image inde xing is achieved by computing the The toolkit is downloaded from the home page of LAB Asprise! ( http://asprise.com/product/ocr/selector.php ) on Dec. 2008 term frequency and building index of visual words for each image panel. the concept index (Fig. 2). The term index is simply obtained by calculating the term frequency of caption words after lemmatizing and stop-word removal. In our approach, the Van Rijsbergen's stop-word lists [14] and the UMLS biomedical stop-word list used to remove non-content-bearing terms. The concept index is achieved by calculating the term frequency of concepts according to the results of concept extraction. In biomedical ontology, a concept carries a unique meaning and represents a set of synonym ous terms. For example, C0006149 is a concept about the benign or malignant neoplasm of the breast parenchyma in Unified Medi cal Language System (UMLS) [15] represents a set of synonyms including Breast Neoplasm, Breast Tumor, tumor of the Breast and Neoplasm of the Breast. Compared to individual words and multiple word phrases, a concept is more meaningful, theref ore, used as indexing terms in large-scale biomedical literatures. In our approach, we adopt MaxMatcher [12] , a dictionary-based biological concept extraction tool, to extract UMLS concept from captions. from biomedical image and cap tions. The underlying philosophy the co-occurrence patterns of caption words, visual words and biomedical concepts in this imag e-caption pair are related to some presence/absence of specific topics. the extended Correspondence LDA (CorrLDA) model and the other is our proposed hierarchical probabilistic topic model with background distribution (HPB). For clarity of the notations, we name each image-caption pair as a document . Some notations to be used in the two probabilistic models are list as follows: D is the number of documents, T is the anticipated number of latent topics, N is the total number of text words in document d , N the total number of extracted biomedical concepts in document d , while M d represents the total number of extracted visual words in document d . CorrLDA model [7] provides a natural way to learn latent topics from text words and other entities. Therefore, our topic learning CorrLDA model to visual words and ontology-based biomedical concepts. The differences between our extension and the original CorrLDA model are twofold. First, we combine visual words, text captions and ontology-based concepts in one single model. features such as color and texture, while our extension deals with visual words which are more robust than global image features assumed to fit multinomial distributions). The generative process for the extend CorrLDA model is: In the first step, a T -dimensional topic-prior vector  X  document d , the generative process of the N d words is achieved by sampling topics from the documen t-topic multinomial distribution (with Dirichlet prior  X  d ) and sampling words from the topic-word that associated with the N d words in document d are used to ,, and  X  X  X  '  X  '' are hyperparameters for the Dirichlet priors. In our approach, we assume symmetric Dirichlet priors, with , , ' and ''  X   X  X   X  being scalar parameters. Although the CorrLDA model is able to learn latent topics from the image-caption pairs and esta blish direct correlation among words, visual words and concepts, however, after looking into the discovered topics from the data collection, we found several background words appear at the top ranked terms of most discovered topics due to their hi gh frequency. For example, when we use image-caption pairs from online journal:  X  X reast Cancer Research X  as training data and learn topics using the CorrLDA model, we found  X  X reast X ,  X  X an cer X ,  X  X ammary X  are among the top-tanked words of many topics . These words, which we named as  X  X ackground words X , appear frequently in many topics and take the places of the topic-specific key words. It X  X  necessary to discover these  X  X ackground words X  from the dataset, otherwise, the topic learning would be less effective. It should be note that during the caption indexing stage, we have removed the non-content-bearing stopwords according to the Van Rijsbergen's stopword lists [14] and the UMLS stopword list Obviously, the  X  X ackground words X  do not belong to regular stopwords. As we have seen, these words carry some contextual information which is shared by most image captions in a biomedical journal. As such  X  X ackground words X  turn to be different from one journal to anot her, it X  X  better to discover them automatically rather than manually specifying them for each journal. In [20], Newman et al. proposed the  X  X witchLDA X  model, in which a switch variable is introduced to control the fraction of hierarchical probabilistic model with background distribution (HPB model) to capture the background topic z 0 . In this model, an additional Binomial distribution  X  (with a Beta prior of  X  1. For the d th ( d =1... D ) documents, sample () 2. For the t th ( t =1... T ) topic, sample () 3. For each of the N d words w i in document d : 4. For each of the N c d concepts c i in document d : 5. For each of the M d visual words v i in document d : was incorporated to control the switch variable x (Fig. 3b), which decides whether a term should be drawn from a background topic z or a regular latent topic z i . It X  X  not clear whether the background words and concepts (Fig. 4) are related to certain image content, as image content may always be dramatically different from one to another. Therefore, in our model. The generative process is as following: In the proposed model,  X  is the Bernoulli parameter for switch variable x . In our experiment, we assu me symmetric priors and set  X   X  X   X   X   X  == = == . For clarity, we call the variation of HPB model (in gray color) as HPB2 model. In the HPB model, visual words has nothing to do with the background topic, while in HPB2 model, the presence of background topic z in the caption words of document d is used to generate visual words, which results in direct correlation between visual words and the background topic. The model estimation is achie ved via the Collapse Gibbs Sampling procedure [3] , which iteratively estimates the posterior probability conditioned on current entity-topic assignment and adopts a Monte Carlo process to determine the assignment of entity-topic in the next iteration. Some notations to be used in Collapse Gibbs Sampling are list as following: W accounts for the vocabulary size of indexed words in the testing dataset; N W denotes the total number of indexed and the total number of concepts and visual words, respectively. 
Background Topic Background Topic background topic of online jour nal  X  X reast Cancer Research X  Given the generative process in Section 3.1, our objective is to compute the word-topic posterior probability, which is: approximated by integrating out (collapsing) all the latent variables (| ,, ) (| ,,, )(|, ) pw z j pw z j p d (|,)(|)(|,) pz j pz j p d Therefore, posterior probability for current word 1. For the d th ( d =1... D ) documents, sample () 2. For the t th ( t =1... T ) topic, sample () Variation (for HPB2 model) : For background topic, sample 3. For each of the N d words w i in document d : 4. For each of the N c d concepts c i in document d : 5. For each of the M d visual words v i in document d : 
Variation (for HPB2 model) : In which total number of times word current one, number of words in document d assigned to topic j except for current word. Having obtained the word-topic posterior probability, the Monte Carlo process is then straightforward -it is similar to throwing dice (based on the posterior probability) to determine the topic assignment for current word Based on sampled topic variables for each word w probabilities for visual word-topic and concept-topic can be approximated in similar formations. For simplicity, we give their posterior probabilities in a uniform expression, which is: In which to topic j ; N d is the total number of words in document d ; the total number of entities (concepts /visual words) assigned to topic j except for current entity: Similar to the Gibbs sampling proce dure in Section 4.1, we derive the sampling equation for proposed HPB model as follows, which allow for joint sampling of the topic variables and the switch variable x for each word px z w (1, |,,,) px z j w current word topics in document d . In equation (3), times word current one, while the total number of times word for current one, total number of words in document d assigned to topic j except for current word. The sampling equations or concep t and visual words have two different cases. For the HPB model , we have: px y j c background topic and regular latent topics in document d . the total number of times concept except for current one, while visual word For the variation of HPB model (i.e. the HPB2 model ), we have a uniform expression of posterior probabilities for both concept and visual words: px z w (1, |,,,,,) i px z j w In this section, we apply the proposed HPB model to topic learning and compare the performance of HPB model with that of the extended Correspondence LDA (Corr-LDA) model under the same biomedical image annotation scenario using cross-validation. For topic learning, we look into the average log-likelihood of two performance of automatic image annotation is evaluated by perplexity and annotation accuracy. The data used in our experiment is from the online journal  X  X reast Cancer Research X  in the publicly available PubMed Central database (http://www.pubmedcentral.nih.gov/). In this journal, all the research articles (in digital version) between year 2002 and 2008 are downloaded and parsed. After that, a total of 2320 image-caption pairs are extracted from the original biomedical literatures and make up the dataset for experiment. As introduced in Section 2, words, visual wo rds and ontology-based biomedical concepts are indexed from image-caption pairs. In total, we indexed 132,978 text tokens wh ich belong to 4113 unique words, 379,526 visual words from a voca bulary size of 1000, and 53,825 concepts, with 1938 unique concepts appear. for testing the model, and the remaining 4 subsets (80%) are used as training data. For image annotation evaluation, the cross-validation process repeats 5 times, with each of the 5 subsets used once as the validation data. After that, we take the average results for evaluation. The topic learning process of the proposed probabilistic model is achieved by running the collapse Gibbs sampling process over training dataset until converge (basically, it takes less than 100 iterations to converge in model estimation). When the topic model is estimated from the training dataset, we will be able to visualize the uncovered latent themes and tell the correlation among words, visual words and biomedical concepts. Log-likelihood is a standard criterion for generative models. It convergence of Gibbs sampling. Generally, the higher log-likelihood the model assigned to the data, the better predictive power and generalization ability the model has. The average word likelihood of the extended Corr-LDA model and the HPB model is compared. The marginal likelihood p( w | z ) of the extended Corr-LDA model can be calculated by integrating out latent variables  X  : The average word likelihood can be obtained by taking the logarithm of p( w | z ) and averaging the resulting summation by W . For the HPB model, the marginal likelihood p( w | z ) is: (|) . . p wz The average word likelihood of th e HPB2 model is the same as the HPB model. as the number of topic increase, which means that a relatively larger topic numbers may potentially result in better modeling of between topic numbers and converg ence time of models. And, as we would see in Section 5.3, the increase of topic number does not always lead to the improvement of predictive results. In general, the log-likelihood of the extended Corr-LDA model and the HPB model are close, the difference between two models can be explained by the introduction of background topic in the HPB model. One major objective of the proposed models is to uncover the latent topics from image-caption pairs and facilitate knowledge organization and understanding in online biomedical literatures. With this consideration, we visu alize the discovered latent topics by providing the top-ranked words, top-ranked concepts (Fig. 4 and 6) and most related images (Fig. 6, with probability under HPB model, in which the topic number is 125. Fig. 6 Illustration of discovered latent themes by HPB model contextual information of the biomedical journal, such as breast cancer, human body and tumor. The regular latent topics, on the other hand, reveal some domain specific knowledge. As illustrated in Fig. 6, the top-ranke d words, concepts and images of the uncovered latent topics have high semantic consistency. The top ranked words and concepts not only contain domain specific terms such as receptor, carcinomas, breast adenocarcinoma and Immunohistochemical, which help users to interpret the topics, but also provide many protein names and gene names that are related to the uncovered latent topic. The proposed probabilistic models are able to establish direct correlation among caption words, vi sual words and biomedical concept in biomedical image-caption pairs. Therefore, given the image content, a good model should be able to predict the missing captions. Next we automatically annotate caption words and concepts for images in the testing dataset based on the uncovered concepts in testing dataset regarded as unknown (missing). The performance of automatic annotation is evaluated by perplexity and annotation accuracy using cross-validation. In our experiment, we resort to the word caption perplexity as standard criteria of the annotation performance. The perplexity of a set of testing image-caption pairs (for all dD  X  ) is defined as the exponential of the negative normalized predictive log-likelihood using the training model, in which the topic-word conditional probability: (| ) from the Gibbs sampling process of training dataset in Section 4. ppx Epww zt Epztd j With uncovered latent topics fro m training image-caption pairs, the estimation of prior probability of topic in a testing image can be approximated by running collapse Gibbs sampling over all the extracted visual words (no words or concepts used) in testing dataset (eq. 10) using fixed visual word-topic conditional probability (|'' ) sampling process of training dataset in Section 4). After the convergence of the Gibbs sampling process, the probability for the  X  X issing X  caption words and concepts of an image can be calculated via the production of topic-word/concept conditional probability and the prior probability for each topic. Recall that for HPB model, we assume no background topic for visual words, the prior for background topic in a document is approximated by averaging probability over the training dataset. Fig. 5b represents the perplexity of CorrLDA and HPB model over different topic numbers. The perplexity of HPB model is lower than that of the CorrLDA model, which indicates that HPB testing data, thus, it demonstrates better ability in annotation. What is more, as the topic numbe r increases, the perplexities of both models decrease first, and then increase, with 100 topics number does not always lead to persistent improvement of predictive ability. Fig. 5c illustrates the perplexities over the iterations when the topic number is 100. Although the HPB model appears to be more sophisticated than the Corr-LDA model, they converged in similar number of iterations. Recall that we have a variation of HPB model (named as the HPB2 model), which assumes that background words and concepts are related to certain image content (visual words). As shown in Fig. 5c, the perplexity of HPB2 increases sharply and quickly exceeds 10000, which indicates that the Gibbs sampling process for this model fails to converge. Finally, over 90% of the entities in documents are assigned to the background topic (as a comparison, only about 1/10 of the words will be assigned to background topic when the Gibbs sampling process of HPB m odel converges). According to the perplexity results, there is no evidence that there exist a direct correlation between image content and background information in the caption. estimated (eq. 10), the word and caption annotation for each document can be achieved by ranking words and concepts with regard to the following probability. The words and concepts that achieve highest probability value in annotations are compared to the original words and concepts in testing image-caption pairs for validation. During annotation evaluation, the cross-validation process repeats 5 times, and the results are averaged to produ ce the final annotation accuracy. The accuracy of word and concepts annotation over different represents the annotation accuracy from top 5 annotation words to top 30, while Fig. 7b provides th e annotation accuracy from top 5 concepts to top 20. According to the experiment results, the HPB achieves best annotation perform ance when topic number is 150, while the Corr-LDA model achieves best performance with 100 topics. As the topic number incr eases, the annotation accuracy of both models increase first, and then decrease, which is consistent with the results in perplexity comparison. The annotation accuracy of extended Corr-LDA model and the proposed HPB model is compared using their best annotation performance (i.e. 100 topics for Corr-LDA model, and 125 topics for HPB model). As illustrated in Fig. 8, the HPB model is consistently better than the extended Corr-LDA model in both word annotation and concept annota tion tasks, which is consistent Furthermore, according to Fig. 7 and Fig. 8, the performance of HPB model drop slower than the Corr-LDA model when annotation terms. The result indi cates that HPB model is more robust and is able to achieve better performance in annotating less frequent terms. The contribution of this paper is twofold. First, we proposed a novel HPB model to integrate background information in topic learning, incorporating contextual information to interpret the uncovered latent topic and improve the image annotation accuracy. Second, in our experiment s, we discovered that there is no direct correlation between image content and the background information in the captions. In other word, the extracted visual words from images have nothing to do with the background topic. It is unnecessary to incorporate contextual information when modeling the image contents. For future work, we plan to incorporate other kinds of knowledge (such as protein entities, gene na mes and concept relations) in our model to enrich the discovered latent semantic topics and to facilitate knowledge organization and understanding in online biomedical literatures. [1] T. Hofmann. Probabilistic Latent Semantic Indexing. [2] A. W. M. Smeulders, M. Worring, S. Santini, A. Gupta, and [3] T. L. Griffiths, M. Steyvers. Finding scientific topics. [4] J. Yang, Y. G. Jiang, A. G. Hauptmann, C. W. Ngo, [5] W. W. Cohen, R. Wang, a nd R. F. Murphy. Understanding [6] Sivic, J., Zisserman, A.: Vi deo Google: A Text Retrieval [7] D. Blei and M. Jordan, Modeling Annotated Data , Proc. ACM [8] J. Zhang, M. Marszalek, S. Lazebnik, and C. Schmid, Local Features and Kernels for Classi fication of Texture and Object Categories: A Comprehensive St udy. International Journal of 
Computer Vision, vol. 73, no. 2, June 2007, pp. 213-238 [9] T. Kadir and M. Brady. Scale, Saliency and Image Description. [10] O. Yakhnenko, V. Honavar, Annotating images and image objects using a hierarchical Dirichlet process model, proceedings of the 9th International Workshop on Multimedia 
Data Mining, pp. 1-7, 2008. [11] K. Mikolajczyk and C. Schm id. A Performance Evaluation of [12] Zhou, X., Zhang, X., and Hu, X., "MaxMatcher: Biological 
Concept Extraction Using Approximate Dictionary Lookup," the 9th biennial The Pacific Rim International Conference on Artificial Intelligence (PRICA I 2006), Aug 9-11, 2006, Guilin, 
Guangxi, China, Page 1145-1149 [13] Lowe, D. Distinctive Image Features from Scale-Invariant [14] Van Rijsbergen, C.J., Information Retrieval, Butterworths, 1975. [15] Humphreys B. and Lindberg D.  X  The UMLS project: making the conceptual connection between users and the information they need  X  Bulletin of the Medical Library 
Association 81(2): 170, 1993. [16] Yu-Gang Jiang, Chong-Wa h Ngo, Jun Yang: Towards [17] L. Fei-Fei and P. Perona, A Bayesian hierarchical model for learning natural scene categories. In CVPR, volume 2, pages. 524 X 531, 2005 [18] X. Wang and E. Grimson, Spatial Latent Dirichlet Allocation, in Proceedings of Neural Information Processing 
Systems Conference (NIPS) 2007 [19] D. Blei, A. Ng. and M. Jord an. Latent dirichlet allocation. 
Journal of Machine Learning Research , 3:993-1022,2003. [20] Newman, D., Chemudugunta, C., Smyth, P., Steyvers, M.: Statistical entity-topic models. In: Proceedings of the 12th ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining, Phila delphia, Pennsylvania, USA, pp. 680 X 686 (2006) 
