 Functional Magnetic Resonance Imaging (fMRI) poses a large-scale, noisy and altogether difficult problem for machine learning algorithms. The Blood Oxygen Level Dependent (BOLD) signal, from which fMR images are produced, is a measure of hemodynamic activity in the brain  X  only an indirect indicator of the neural processes which are of primary interest in most cases. of the data, and the hemodynamic response itself is a form of temporal blurring. We are interested in the application of machine learning techniques to reveal meaningful patterns of neural activity from fMRI. In this paper we construct a model of the processes underlying the of Dynamic Causal Modelling (DCM) [ 3 ]. The main innovation over these deterministic models is DCM reduces to a generative model with steady state equilibrium BOLD activity and independent here is applied to multiple regions and their interactions, not single regions in isolation. Other approaches to this type of problem are worth noting. Perhaps the most commonly used tech-regression technique where each dependent variable may be a linear combination of both indepen-single observation. Furthermore, it does not distinguish between neural and hemodynamic activity, and in essence identifies interactions only at the hemodynamic level.
 dynamic activity, formulating a filtering and smoothing approach for inference in this model, and to the domain problem and is temporally consistent with the stimulus. The approach is also able to establish connectivity relationships.
 poral causal order, temporal models of this form have no such equivalence problems. Any small can disambiguate between statically equivalent models.
 Section 2 outlines the basis of the hemodynamic model that is used. This is combined with neural, input and measurement models in Section 3 to give the full framework. Inference and parameter estimation are discussed in Section 4 , before experiments and analysis in Sections 5 and 6 . Temporal analysis of fMRI is significantly confounded by the fact that it does not measure brain model used to relate neural and hemodynamic activity.
 a venous compartment as a balloon using Windkessel dynamics. The state of the compartment is represented by its blood volume normalised to the volume at rest, v = V/V 0 (blood volume V , rest volume V 0 ), and deoxyhemoglobin (dHb) content normalised to the content at rest, q = Q/Q 0 (dHb f dynamics may be represented by the differential system: where  X  0 and  X  are constants, and E 0 is the oxygen extraction fraction at rest. neural activity z ( t ) via an abstract vasodilatory signal s [ 13 ]: time may be predicted using [ 12 ]: Figure 1 illustrates the system dynamics. Nominal values for constants are given in Table 1 . Figure 1: Response of the balloon model to a 1s burst of neural activity at magnitude 1 (time on x axis, response on y axis). We define a model of the neural and hemodynamic interactions between M regions of interest. A given by: The complete state at time t is given by x ( t ) = ( x 1 ( t ) T , . . . , x M ( t ) T ) T . model, the hemodynamic model and the measurement model. 3.1 Input model The input model represents the stimulus associated with the experimental task during an fMRI ses-one-dimensional box-car function is sufficient. 3.2 Neural model Neural interactions between the regions are given by: where d W is the M -dimensional standard (zero mean, unit variance) Wiener process, A an M  X  M matrix of efficacies between regions, C an M  X  U matrix of efficacies between inputs and regions, c an M -dimensional vector of constant terms and  X  z an M  X  M diagonal diffusion matrix with  X  tion, but excludes the bilinear components allowing modulation of connections between seeds. In theory these can be added, we simply limit ourselves to a simpler model for this early work. In addition, and unlike DCM, nonlinear interactions between regions could also be included to account approach. 3.3 Hemodynamic model Constant  X  0  X  f  X  s  X   X  V 0 E 0 k 1 k 2 k 3 hemodynamic activity is independent given neural activity[ 14 ]. Noise in the form of the Wiener positivity: 3.4 Measurement model This may be converted to an absolute measurement y  X  i for comparison with actual observations by using the baseline signal b i for each seed and an independent noise source  X   X  X  (0 , 1) : whereby the input, neural and hemodynamic models define state transitions, and the measurement model predicted observations. For i = 1 , . . . , M ,  X  z and  X  y given all the data.
 Because of non-Gaussianity and nonlinearity of the transitions and measurements, a two-pass parti-method, the adaptive step size maintaining fixed error bounds.
 model is divergent in q and v , so that the accumulated numerical errors of the Runge-Kutta can easily cause an explosion to implausible values and a tip-toe adaptive step size to maintain error bounds. This can be mitigated by tightening the error bounds, but the task becomes computationally prohibitive well before the system is tamed.
 them on the backwards pass so that no explicit backwards dynamics are required. This sidesteps the divergence issue completely, but is computationally and spatially expensive and requires computa-tion of p ( x ( t n ) = s ( i ) t limitations, but is nevertheless the method used here.
 for i = 1 , . . . , P . Initialising with  X  t as follows [ 17 ] 2 : These are then normalised so that is stored.
 There are numerous means of propagating particles through the forwards pass that accommodate the resampling step and propagation of the Wiener noise through the nonlinearity. These include var-ious stochastic Runge-Kutta methods, the Unscented Transformation [ 4 ] or a simple Euler scheme efficiently make P 2 density calculations of p ( x ( t n +1 ) = s ( i ) t pass is challenging with such approaches, however. To keep things simple, we instead simply prop-agate particles noiselessly through the transition function, and add noise from the Wiener process the system while keeping the density calculations very simple  X  transition s ( j ) t the mean value of a Gaussian with covariance equal to that of the system noise, then calculate the density of this Gaussian at s ( i ) t Observe that if system noise is sufficiently tight,  X  t round to zero. Implementing  X  t Propagation of particles through the transition function and density calculations can be performed calculated, filling in one column of  X  t constant. The same applies to parameters of the balloon model, which may be included to allow variation in the hemodynamic response across the brain. We apply the model to data collected during a simple finger tapping exercise. Using a Siemens Vision at 2T with a TR of 4.1s, a healthy 23-year-old right-handed male was scanned on 33 separate days over a period of two months. In each session, 80 whole volumes were taken, with the first ing 6TR blocks of rest and tapping of the right index finger at 1.5Hz, where tapping frequency is provided by a constant audio cue, present during both rest and tapping phases. performed, from which 13 voxels were selected to represent regions of interest. No smoothing or region.
 for the more expensive backwards pass. Figure 2: Experimental input u ( t ) , x axis is time t expressed in TRs. A i,i i = 1 , . . . , N  X  1 1 / 2 10  X  2 A i,j i, j = 1 , . . . , N , i 6 = j 0 1 / 2 10  X  2 z i i = 1 , . . . , N 0 1 / 2 10  X  1 f i , s i , q i , v i , c i i = 1 , . . . , N 0 1 / 2 10  X  2 b i i = 1 , . . . , N  X  y i 10 10  X  2 The experiment is run on the Eddie cluster of the Edinburgh Compute and Data Facility (ECDF) 3 over 200 nodes, taking approximately 10 minutes real time. The particle filter and smoother are distributed across nodes and run in parallel using the dysii Dynamic Systems Library 4 . compared to actual measurements acquired during the experiment to assess model fit. correlated with the experimental stimulus. Parameter estimates are generally constant throughout the length of the experiment and some efficacies are significant enough in magnitude to provide tapping task. However, as the focus of this paper is the development of the filtering approach we filter and its capabilities and deficiencies. A number of points are worth making in this regard. the backwards pass. This is particularly obvious towards the extreme left of Figure 4 , where the smoothed results appear to become erratic, essentially due to degeneracy in the backwards pass. Furthermore, while the smooth weighting of particles in the forwards pass is informative, that of the backwards pass is often not, potentially relying on heavy weighting of outlying particles and shedding little light on the actual nature of the distributions involved.
 Figure 3 provides empirical results as to the sparseness of  X  t are zero, demonstrating the advantages of a sparse matrix implementation in this case. These estimates also come with distributions in the form of weighted sample sets which enable the filter to be a promising approach for systematic connectivity analysis. Figure 7: Parameter estimates of C ( y axis) over time ( x axis). Forwards pass results as shaded histogram, smoothed results as solid line with 2  X  error.

