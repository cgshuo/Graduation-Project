 Bei Pan  X  Ugur Demiryurek  X  Chetan Gupta  X  Cyrus Shahabi Abstract The advances in sensor technologies enable real-time collection of high-fidelity spatiotemporal data on transportation networks of major cities. In this paper, using two real-world transportation datasets: (1) incident and (2) traffic data, we address the problem of predicting and quantifying the impact of traffic incidents. Traffic incidents include any nonrecurring events on road networks, such as accidents, weather hazard or road construction. By analyzing archived incident data, we classify incidents based on their features (e.g., time, location, type of incident). Subsequently, we model the impact of each incident class on its surrounding traffic by analyzing the archived traffic data at the time and location of the incidents. Consequently, in real-time, if we observe a similar incident (from real-time incident feeds), we predict and quantify its impact on the surrounding traffic using our models. This information, in turn, can help drivers to effectively avoid impacted areas in real-time. To be useful for such real-time navigation application, and unlike current approaches, we study the dynamic behavior of incidents and model the impact as a quantitative time varying spatial span. In addition, we study a novel approach that improves our classification method by analyzing traffic density around the incident area and the initial behavior of the incident. We evaluated our approach with very large traffic and incident datasets collected from Los Angeles County and the results show by utilizing our impact prediction approach in the navigation system, precision of the travel time calculation can be improved by up to 67 %. Keywords Intelligent transportation  X  Traffic forecast  X  Traffic incidents  X  Impact analysis  X  Spatiotemporal data  X  Next-generation navigation 1 Introduction The Texas annual Transportation report (TTI) estimates that 5.5 billion hours and 2.9 billion gallons of fuel are wasted due to the problem of traffic congestion in the USA [ 23 ]. According to Report [ 18 ], approximately 50 % of the freeway congestions are caused by non-recurring incidents, such as traffic accidents, weather hazard, special events, and construction zone closures. Hence, our goal is to predict and quantify the impact of traffic incidents on the surrounding traffic. This quantification can alleviate the significant financial and time lost by traffic incidents, for example, it can be used by city transportation agencies for provid-ing evacuation plan to eliminate potential congested grid locks, for effective dispatching of emergency vehicles, or even for long-term policy making.

The McKinsey report Institute [ 7 ] predicts a worldwide consumer saving of more than $600 billion annually by 2020 for location-based services, where the biggest single consumer benefit will be from time and fuel savings from navigation services tapping into real-time traffic data. Therefore, for the remainder of this paper, we focus on a next-generation consumer navigation system (in-car or on smart phone), called ClearPath , as a motivating application, which can help drivers to effectively plan their routes in real-time by avoiding the incidents X  impact areas. That is, suppose an accident is reported in real-time (by crowdsourcing Waze [ 26 ] or through agency reports or SIGALERTS [ 21 ]) in front of a driver, but the accident is 20 min away. If we can effectively quantify the impact of the accident, ClearPath would know that this accident would be cleared in the next 10 min. Thereby, ClearPath would guide the driver directly toward the accident because it knows that by the time the driver arrives the area, there would be no accident.
 caution mark, the directed solid red lines, and the dashed blue lines represent the incident location, the congested region caused by the incident, and the route a driver plans to follow, respectively. Without prediction, but with the knowledge of the incident, a typical navigation application, such as Waze [ 26 ], may suggest the route shown in Fig. 1 a to the drivers. If the driver follows this route, he would be stuck in the traffic congestion caused by the incident, as illustrated in Fig. 1 b, due to the fact that the congested region has grown. On the other hand, if we can predict how the impacted spatial span (i.e., congested region) evolves over time, ClearPath could calculate the route that can effectively avoid the congestion from the beginning, as shown in Fig. 1 c.

The problem of predicting traffic incident X  X  impact has been widely studied by researchers in multiple disciplines, including in transportation science, civil engineering, policy plan-ning, and operational research (e.g., [ 27 ]). In the past, without real-world traffic data, most researchers resorted to mathematical models, simulation studies, and field surveys (e.g., [ 10 ]). However, these theoretical methodologies cannot accurately infer the impact of incidents in real-world scenarios and the spatial transferability of their models is limited. In recent years, due to the sensor instrumentation of road networks in major cities as well as the vast avail-ability of auxiliary commodity sensors (e.g., CCTV cameras, GPS devices), for the first time, a large volume of real-time traffic and incident data at very high spatial and temporal resolu-tions has become available. In this paper, we use such datasets that we have been collecting and archiving in the last three years in the LA County and Orange County, toward predicting the impact of traffic incidents to the surrounding traffic.
For our motivating navigation application, ClearPath, to be effective, we need to predict specific values of speed changes and backlog lengths over the lifetime (i.e., temporal) and impact area (i.e., spatial) of an incident. This is in contrast to previous application scenarios where forecasting abstract or aggregate values was sufficient. In particular, consider the following three aspects that we need to forecast.

First, we need to predict the exact values of speed changes and backlog lengths. There are two major approaches to measure the impact of incidents: (1) qualitative approaches (i.e., classify incident X  X  impact into conceptual categories such as  X  X evere X  or  X  X on-severe, X  and  X  X ignificant delay X  or  X  X light delay X ); (2) quantitative approaches (i.e., providing numeric measurement such as 45 % speed decrease, and 3.2 miles of congested backlog). In the past, most studies focused on qualitative approaches for measuring impact, which makes the impact easier to predict (e.g., [ 14 ]). The qualitative measurement may be sufficient for general decision-making or response analysis, however, not precise enough for ClearPath. In this paper, we describe the impact from a quantitative perspective and provide numeric measurements of the impact to the surrounding areas.
 Second, since the impact region of an incident evolves over time and space (as shown in Fig. 1 ), we need to predict the spatiotemporal behavior of the impact. In previous studies, it was sufficient to predict an incident X  X  impact as a single or a set of aggregate values. For example, in Pan et al. [ 16 ], the impact is predicted as average speed decrease or average of the backlog length. In this paper, the outcome of our prediction approach is the exact length of time varying backlogs (i.e., evolution of congested spatial span) with different scales of speed changes.

Third, we need to predict the sudden speed changes caused by incidents in a faraway future (e.g., the next 30 min). The occurrence of incidents always involves two phenomenon: (1) abrupt speed changes; for example, it is very common for the traffic speed to drop 60 % when an incident occurs on freeways in LA; and (2) long -lasting propagation of the speed changes; for example, a closer sensor to the incident may report speed decrease in 3rd minute after its occurrence, however, a farther sensor may report similar decrease in 30th minute. Since traditional prediction approaches rely on the immediate past data to predict the future, they cannot effectively predict the abrupt speed changes and how they propagate over a long term, which is important for ClearPath to successfully navigate drivers around the incident impact area. Toward this end, we analyze the correlations between archived incident data and traffic data. Specifically, we first classify incidents based on their features (e.g., time, location, type of incident), which are correlated with their impact to the surrounding traffic. Next, we improve the classification by incorporating traffic density and the initial behavior of incident. By utilizing such models, we can effectively predict the abrupt speed change and the propagation over a long term by identifying similar classes of incidents mined from archived dataset.

This paper substantially extends our previous work Pan et al. [ 17 ] in several aspects. First, we discuss the strategy on how to choose the parameter of impact threshold in the real-world applications. Second, we consider an additional baseline method based on theoretical model which is widely used in the fields of transportation research. Third, we briefly reveal the new challenges and our solutions in the prediction of clearance behavior. Fourth, we conduct extensive additional experiments to evaluate the previous models and new proposals on clearance behavior. Finally, we utilize two real-world case studies to evaluate the proficiency of our impact prediction approaches in helping the travel time calculation for navigation applications.

In sum, the contributions of our paper are as follows:  X  We present a novel method to quantify the impact of incidents as a time varying spatial  X  For impact prediction, we leverage incident features, traffic density, and the initial incident  X  We validate our approaches using a large-scale, real-world traffic and incident datasets,
The remainder is organized as follows: We review the related work and introduce pre-liminaries in Sects. 2 and 3 , respectively. In Sect. 4 , we explain our approach of quantifying incident X  X  impact. We detail our prediction approaches in Sect. 5 and 6 for impact propagation behavior and clearance behavior respectively. In Sect. 7 , we present our evaluation strategies and results. In Sect. 8 , we conclude our paper. 2 Related work In the last decade, the impact of traffic incidents has been widely studied in multiple disci-plines. Most of these studies are based on theoretical modeling and simulations, which can be classified into three groups: (1) deterministic queuing theory or shockwave theory (e.g., [ 10 , 27 ]); (2) heuristic methods and simulations (e.g., [ 15 ]); (3) microscopic modeling of driver X  X  behavior (e.g., [ 5 , 24 ]). However, the outcome of these studies relies on theoretical simulations of road network traffic instead of the real-world collected traffic data. Also, none of these studies use a source of incident data with description variables and reporting tech-niques, and their spatial transferability is limited. In this work, we use a very detailed high resolution traffic dataset and incident dataset.

Recently, with the availability of real-world data, a variety of data mining approaches have been applied for the prediction of incident X  X  impact, such as decision trees Ozbay and Kachroo [ 14 ], classification trees Kim et al. [ 8 ], Smith and Smith [ 22 ], as well as Bayesian classifier Boyles et al. [ 2 ] and nearest neighbor classifier Kwon et al. [ 9 ]. In most of these studies, the focus is to predict the general behavior of incident X  X  impact (e.g., severe or not severe [ 6 ]). Thereby, they always categorize the incident X  X  impact into different classes and utilize classification models for the prediction. However, our problem is to provide numerical results in both spatial (i.e., affected region) and temporal (i.e., traffic speed decrease) aspects as the predicted impact. For example, the region of 60 % travel time delay is 3.2 miles in 20th minute. Therefore, their classification models are not suitable for our problem.
 The set of most relevant studies to our study are the models proposed in Pan et al. [ 16 ], Miller and Gupta [ 13 ], Chung and Recker [ 4 ]. In these studies, they considered both spa-tial and temporal aspects to quantify the impact. However, their quantification strategy are designed to capture the one-time impact of the incident, instead of the time varying nature of impact at different locations. As illustrated in the example of Fig. 1 , the impact of traffic is not always an one-time phenomenon, in fact, it follows a growing/shrinking pattern after the occurrence of incident. Toward this end, in this paper, we quantify the impact of an incident as a time varying spatial span. Hence, instead of predicting static parameters for the one-time impact, our approach predict the behavior of the time varying spatial span of an incident. 3 Preliminaries To explain the preliminaries, consider a sample incident that occurred on the freeway I-5 South as illustrated in Fig. 2 a. Sensor S1  X  S4 represents the four affected sensors located on I-5 South upstream of the incident location. 1 In the rest of this paper, we use this scenario as a running example to explain our approach.
 Definition 1 (Speed Change Ratio) The speed change ratio ( v ) at a specific location ( l ) and time ( t ) is defined as decreased ratio of current traffic speed ( v c ) compared with normal traffic speed at l and t , as shown in Eq. ( 1 ). Here, the normal speed ( v r ) is calculated as the historical average value at location l of same time t in the past. Figure 2 b shows the corresponding time varying speed change ratios for four sensors depicted in Fig. 2 a. Here, the axis labeled as Time refers to the elapsed time after the occurrence of the incident, where the negative values refers to the time stamp before the incident occurs. The axis labeled as Distance refers to the road network distance between sensor location and incident location.

In our problem, the key to predicting the time varying spatial span is to predict the speed changes of all sensors over time. One intuitive solution is to apply traditional time series prediction approach on the speed time series. Toward this end, we need to predict the speed changes for each sensor. However, this solution has a few limitations and drawbacks. In the following, we provide a brief explanation of its limitations through two critical observations made from Fig. 2 b.
 Observation 1 For all sensors, the speed decreases abruptly after the occurrence of a traffic incident, suggested by the sudden increase of speed change ratio.

For example, for sensor S 1, the speed dropped from 67 MPH to 18 MPH within 2 min after the occurrence of incident. The time series prediction approaches Pan et al. [ 16 ] (e.g., auto-regressive models) cannot effectively predict abrupt variation in time series because most of them relies on the data in the immediate past. Thereby, according to observation 1, traditional time series prediction techniques cannot effectively predict the traffic time series at the beginning of a traffic incident.
 Observation 2 The abrupt speed change for each sensor starts at different time stamps after the incident X  X  occurrence.

In our running example, sensor S3 reports the abrupt speed decrease at 12th minutes, while sensor S4 reports at 19th minutes after the incident X  X  occurrence. Hence, in this scenario, given the incident just occurred, we need to predict the speed changes in 12 or 19 min ahead. This task requires a multi-step prediction strategy for time series prediction approaches. However, according to the study in Cheng et al. [ 3 ], multi-step time series prediction suffers from error accumulation problem when the prediction period is long. Thus, the time series approach cannot accurately predict the speed changes in a long term, for example, 30 min in advance for general cases.

To conclude, we argue that traditional time series prediction technique cannot effectively predict the speed decrease for all sensors impacted by an incident. To address this issue, in the following, we propose a modeling strategy toward incidents X  impact and corresponding prediction techniques. 4 Impact modeling First, we define whether a location is impacted according to the magnitude of speed changes as follows: Definition 2 (Impacted Threshold  X )  X  is defined as a parameter that indicates the magnitude of the speed changes. Given a time stamp t and a location l , if the speed change v( l , t ) satisfy the following inequality, we denote the location l as impacted at time t . In the experiments, we will study the effects of  X  values in the prediction accuracy of prop-agation behavior.
 Consider  X  as 60 % and cut the 3D Fig. 2 b horizontally with v = 60 %. We will obtain a series of scatter points in a 2D space of distance and time, as depicted in Fig. 3 . Each point ( x , y ) in Fig. 3 represents a specific sensor located at y miles from the incident location with 60 % speed decrease at x -minute after the incident occurrence time. For the four points on the left side (with x &lt; 20), their x -axis value indicates the time stamp when a sensor starts to get impacted, which is referred as propagation phase . For the other four points, their x -axis value indicates when a sensor ends from getting impacted, which is referred as clearance phase . As a byproduct, the impact duration of a sensor can be derived as the time difference between the points in the propagation phase and clearance phase. In this study, we focus on predicting the impact in propagation phase.

AsshowninFig. 3 , we observe that the closer a sensor is to the incident location, the earlier it starts to get impacted. Intuitively, if a sensor s get impacted at a time t , all the sensors closer than s should be impacted before t . Therefore, the impact backlog (i.e., spatial span) of traffic incident is defined as follows: Definition 3 (Impact Backlog) Given an incident location on freeway l and occurrence time t , and impact threshold  X  ,the impact backlog b at time t ( b t ) is the road network distance between the occurrence location and the furthest impact location (with v( l , t )  X   X  ), along the upstream direction (i.e., the opposite direction of the vehicle flow).

In the following, we will use the example in Fig. 3 to explain how to calculate b t , with  X  = 60 %. In this example, sensor S2 (0.9 miles from the incident) starts to get impacted at 8th minute after the incidents. Therefore, the impact backlog at the 8th minute is 0.9 miles. If we consider the granularity of time stamp ( t ) in the definition as 1 min, we could derive b = 0 . 9. Similarly, we could derive b 1 , b 12 and b 19 from the sensor S1 , S3 ,and S4 , according to the time they get impacted and their distances to the incident location. 4.1 Modeling propagation behavior With the notation of impact backlog, the time varying spatial span of incident impact in terms of propagation behavior is defined as follows: Definition 4 (Propagation Behavior) Given an incident ( e ) at location l occurred at time t 0 , and  X , e  X  X  propagation behavior is defined as a time series of impact backlog after t 0 and before it reaches the maximum impact backlog. Assuming e reaches the maximum impact backlog after t minutes, its propagation behavior is represented as b or { b 0 , b 1 ,..., b t } , where the subscript i for b i represents the time units after t 0 . Here, b i is the distance from the incident location that is  X  X tart to get impacted X  at time t i .

To calculate the propagation behavior for an incident, one naive way is to record the speed changes on all the possible upstream locations. However, this method requires a fairly dense placement of sensors. In most sensor networks, the sensors reporting traffic speed are always placed with a certain distance interval (e.g., 0.5 mile). Therefore, due to the limited availability of sensor data, we can only derive impact backlog from the locations equipped with sensors. To create a continuous propagation behavior, we utilize a fitting strategy. The overall modeling strategy is summarized as follows: 1. We utilize the distance of a sensor from the incident location to represent the impact 2. Consequently, we plot the derived impact backlogs into 2D space (e.g., the scatter points 3. Finally, we utilize the learned fitting function and interpolate the backlogs at missing time
There are alternative modeling approaches, such as the use of coefficients in polynomial fitting function. The superiority of our modeling strategy over this approach is as follows: When we construct the propagation behavior, we only use the fitting function to interpolate the missing impact backlogs, for existing impact backlogs we still use the original data. However, if we rely on the coefficient vectors of the fitting function, we may introduce fitting error into the original data, which may result in inaccurate representation of the propagation behavior. Applications of Propagation Behavior: The prediction of propagation behavior can enable intelligent route planning, effective transportation policy making, and faster traffic emergency responses. In the following, we will briefly detail how to use the propagation behavior within route planning applications. For each traffic incident, we can predict multiple propagation behaviors based on different  X  values. For example, Fig. 5 illustrates the propagation behavior for the running example under different  X  s. The value of  X  can be tuned according to the preference of the end users of a route planning application.

For a specific time, by utilizing the combination of propagation behaviors, we could derive the set of affected road segments under different magnitude of speed changes. For example, in Fig. 5 , at 15th minute after the occurrence of incident (i.e., x = 15), the location at 1.3 mile toward the incident is at least 60 % speed decrease, the location at 1.7 mile is at least 40 % speed decrease and the location at 2.0 mile is at least 20 % speed decrease. Similarly, for a specific location, by fixing the y values, we could derive the time when starts to get 20, 40 or 60 % speed decrease. Such predictive information are crucial to generate travel time weight for road segments near incident locations, further to be utilized in the fastest path calculation in route planning. 4.2 Determining minimum impact threshold (  X  ) As we discussed, impact threshold (  X  ) is a parameter that represents the magnitude of the speed changes caused by traffic incidents. In real-world applications, users can tune the value of  X  in order to obtain different set of propagation behaviors. This is particularly important when the small scale of speed difference between recent traffic speed and historical average traffic speed does not reflect the impact from traffic incidents. Such small fluctuation may be due to regular fluctuation of traffic speed or noisy data from sensors. Thereby, if  X  is too small, when we observe the speed change at a particular location with v  X   X  , we cannot distinguish whether this location is actually get impacted by a traffic incident or not. As a consequence, we cannot compute the propagation behavior accurately. In this section, we will briefly discuss how to determine the minimum impact threshold to accurately capture speed changes due to incidents.

To calculate the minimum impact threshold (  X  min ), we first derive historical average traffic speed and its 95 % confidence interval for each time stamp reported by each sensor. Figure 6 illustrates the result for a sample sensor. In this study, we assume any traffic speed reading within the 95 % confidence intervals as regular fluctuation toward the historical average. And the speed readings outside this interval are considered as anomalous readings impacted by traffic incidents. In the example shown in Fig. 6 , during 6 a.m. to 10 a.m., the confidence interval is also small, indicating the scale of regular speed fluctuation for this sensor in this time interval is fairly small. This phenomenon normally occurs in non-rush hours when the historical average traffic speed is generally high. In this case, even if a smaller scale of speed changes (e.g., 20 %) occurs to this sensor during this interval, the sensor can still be consid-ered as impacted by traffic incidents. On the other hand, during the time period 2 p.m to 8 p.m, when congestion starts to happen, the confidence interval is quite large, indicating the traffic speed fluctuate largely around the historical average around these hours. In other words, if we set  X  as a fairly small value (e.g., 20 %), we may inaccurately identify the regular speed fluctuation during this interval as impacted by traffic incidents.

Thereby, we define the minimum impact threshold (  X  min ) at location l , and time t as follows: where v r and  X  refers to the historical average value at location l of same time t in the past and the standard deviation, respectively. Here, to ensure 95 % confidence interval, the constant C is set to 1.96 according to the theorems published by Stuart et al. [ 25 ]. In real-world applications, users should set the impact threshold to at least  X  min to ensure accurate modeling of the propagation behavior of traffic incidents. For example, when a traffic incident occurs around the sample sensor illustrated in Fig. 6 , the impact threshold should be set as follows: For the incidents occurred during [6, 10 a.m.], the speed changes should be at least 15 % (i.e.,  X  min  X  15 %) to indicating the sensor is impacted by this incident; during [10 a.m., 2 p.m.] and [2, 8 p.m.],  X  min should be increased to around 25 and 65 % respectively, to justify whether this sensor is impacted. The effects of choosing different  X  values will be further evaluated in the experiment (Sect. 7.2.3 .). 5 Prediction of propagation behavior In this section, we will explain our proposed techniques for predicting the impact of inci-dents on road networks in terms of propagation behavior (as defined in Sect. 4.1 ). First, we will discuss a baseline approach for grouping similar incidents based on their attributes to estimate the impact. However, in some particular cases, although two incidents have similar attributes, their impacts are still highly different from each other. Therefore, we introduce a new prediction model that addresses the shortcomings of the baseline approach by incor-porating traffic density measures such as volume and occupancy. Then, we will explain a multi-step prediction approach that takes into account initial behavior (i.e., sub-pattern of propagation behavior) of an incident that further improves the prediction accuracy.
Our dataset includes three years of historical sensor readings (i.e., speed, volume and occupancy) referred to as traffic data (D) . Specifically, volume represents the number of cars passed by a sensor within a sampling interval (e.g., 30 s), and occupancy represents the percentage of time a sensor is occupied. For example, if the occupancy of a sensor equals to 10 % of a sensor with sampling interval 30 s, it means that there are totally 3 s in the last 30 s with vehicles presence on top of this sensor. In addition to traffic sensor data, we also include the dataset of incident reports that includes set of 43 attributes, such as fatality and number of lanes affected, referred as incident data (R) . Our impact prediction problem is defined as follows: Problem Definition: Givenanincident e ( e  X  R ) occurred at time t 0 , and the dataset D collected before t 0 (i.e., [ t 0  X  T , t 0 ], where T is the duration of the datasets), to predict propagation behavior of e in the next t time stamps, i.e., { b 1 , b 2 ,..., b t } . 5.1 Baseline approaches In this section, we introduce two baseline approaches for impact prediction: (a) based on theoretical traffic flow simulations by Wirasinghe [ 27 ] and (b) based on a clustering idea using the real-world traffic and incidents data proposed in Pan et al. [ 16 ]. 5.1.1 Theoretical baseline (TB) With this baseline approach, we adopt the shockwave model which is widely used for esti-mating queuing delay caused by traffic incident Wirasinghe [ 27 ], Al-Deek et al. [ 1 ]. The shockwave model is developed based on the theory of kinematic waves, which takes traffic flow as a continuous fluid with a flow-density relationship proposed by Lighthill and Whitham [ 11 ]. This approach assumes when a lane is blocked by a traffic incident, the congestions propagates linearly along the shockwave speed. Specifically, a traffic stream can be described by its average flow ( q ) and average density ( k ). A shockwave is created when the state of a ( q j , k j ). According to the literature published in Lighthill and Whitham [ 11 ], the shockwave speed ( c ij ) is calculated as follows: Using this model, we calculate the propagation behavior as a linear function between backlog and time, with the gradient equals the shockwave speed ( c ). To calculate the shockwave speed, we utilize the speed and volume readings collected from the closest upstream sensors near the incident locations. Specifically, we can directly derive the traffic flow ( q ) from traffic volume and estimate traffic density (vehicle/distance) through the division between volume (vehicle/time) and speed (distance/time). Below are the steps we take to predict the impact of a given incidents: 1. When a new incident occurs at t 0 , we derive the regular state ( q 1 , k 1 ) of traffic stream 2. We derive the shockwave speed ( c ) based on the equation defined in Eq. ( 4 ). 3. We calculate the predicted propagation behavior at i th time stamps after the occurrence 5.1.2 Data-driven baseline (DB) The Data-driven Baseline approach (DB) utilizes the propagation modeling approach dis-cussed in Sect. 4 . In addition, DB utilizes incident report data to classify incidents solely based on their attributes for prediction Pan et al. [ 16 ]. In particular, we use historical incident information to create classes that we use to model the impact based on the attributes of inci-dents. The main intuition here is that the incidents within the same class should be strongly correlated, and hence given an incident e with certain attributes will follow the similar impact. The detail steps of DB is as follows: (1) given historical incidents and all their attributes, apply a feature subset selection algorithm to identify the set of related features that are max-imally correlated with their propagation behavior; (2) classify all historical incidents into different groups according to their values of selected features. For example, if the incident location (e.g., I-5 South) is one of the selected features, all incidents occurred on freeway I-5 South should be put into one group, and within each group, we use the average propagation behavior as the representative for prediction. In this way, when a new incident occurs, we extract its correlated feature values, use them to identify the group it belongs to, and use the representative in that group as predicted propagation behavior.

With our dataset, we observe that the feature subset selection algorithm determines the following attributes: street name (e.g., I-5 South), start time (i.e., occurrence time), affected number of lanes (i.e., number of lanes blocked by the incidents), and incident type (such as traffic collision, road construction, etc). Therefore, in the rest of the paper, we will use these attributes to classify the incidents.

Note that the length of propagation behavior might be different from each other, thereby, during the calculation of average propagation behavior (i.e., Step 2 in prediction phase), its length equals the longest propagation behavior in one cluster. Assuming the length of propagation behavior is denoted as t , each time stamp in the average propagation behavior ( b ) is calculated as follows: 5.2 Prediction with traffic density (PAD) In the baseline approach, we assumed that incidents with similar attributes may follow similar impact, and hence classified the incidents based on the values of selected attributes. However, our observations from the real-world datasets show that in some cases, even two incidents have similar attributes, their impact propagation behavior can be significantly different from each other. This is particularly notable when two incidents occurred on the same street but different road segments. For example, consider two incidents (with same attributes) that occur at a rush hour on two different segments passing through downtown area and rural area (significantly less crowded). Obviously, the impact of these accidents will be different. Therefore, we argue that traffic  X  X ensity X  around the incident is correlated with its propagation behavior and hence can improve the prediction accuracy. In the rest of this section, we will present two selected case studies to verify our hypothesis and propose an approach that utilizes traffic density.

We quantify the traffic density using two traffic measures: volume (the number of cars passing from a sensor location) and occupancy (the percentage of time the sensor is being occupied) from the sensors that on the same streets close to the incident location. Note that we cannot just use single parameter (i.e., either volume or occupancy) to describe traffic density. According to the LWR model published in Lighthill and Whitham [ 11 ], the traffic volume/occupancy itself cannot precisely describe the congestion information of traffic. For example, same volume number (e.g., 5 vehicles/30 s) may exist in either free flow situation or congestion situation. Only if we use both parameters together, we can clearly measure the congestion situations of traffic flow. As we discussed, these measures are available in our sensor dataset. Below we explain the effect of each measure in turn.
 Effect of volume To illustrate the correlation between volume and propagation behavior, we present two real-world incidents ( e A and e B ) that occurred on I-405 S with similar incident attributes, but different volume values (i.e., low volume for e A , high volume for e B ). Their propagation behavior are depicted in Fig. 7 a. As shown, for e B , as the vehicles accumulated quickly (due to large traffic volume), the impact propagates very fast after a few minutes. On the other hand, the propagation speed of e A (with lower volume) is not as fast as e B . Hence, it is likely that different volume values can result in different propagation behavior. Effect of occupancy Similar to volume case study, we will show the impact of occupancy using an example. In this case, we choose two incidents that occurred on I-5 S with dif-ferent occupancy values. Figure 7 b shows the propagation behavior for e A (with higher occupancy value) and e B (with lower occupancy value). Obviously, the average propagation speed (average curve gradient) for e A is higher than that of e B . This means that the incident impact propagates faster on more occupied locations, and hence, occupancy is also correlated with propagation behavior.

As illustrated in the above two case studies, the traffic density (measured by volume and occupancy) is very important parameters to predict the propagation behavior of an incident. Therefore, we incorporate traffic density into our prediction model. In particular, for each incident, we create a two-dimensional feature vector composed of volume and occupancy values and cluster incidents based on this vector. Our prediction approach that combines incident attributes and traffic density (PAD) is summarized as follows:  X  Training phase (1) Classify the historical incidents into groups according to their cor- X  Prediction phase For a newly occurred incident e , (1) we identify its group based on its
To ensure the cluster quality, we maximize the number of clusters ( k ) while guaranteeing the quality of each cluster, which is measured by average silhouette coefficient ( s )definedin [ 20 ]. 2 5.3 Prediction with initial behavior (PADI) In the previous section, we discussed PAD model that improves the accuracy of the baseline approach by using traffic density information. However, there are still other impact correlated features that PAD does not take into consideration, such as weather conditions or other information that are not available in our dataset. Therefore, in some cases, the accuracy of PAD still can be improved. Figure 8 a shows one such case for a sample cluster learned by PAD. In this figure, prediction candidate refers to the average propagation behavior with similar attributes and traffic density, and pre-diction range (i.e., the gray area) is calculated based on the maximum deviation of each instance toward the candidate. If we use this candidate for predicting propaga-tion behavior for incidents with same attribute and density, the prediction error would be non-trivial. To shrink the range for the prediction candidate, we cluster all the propagation behavior within a group of incidents (under same attributes and traffic density) and generate multiple prediction candidates. This eliminates the need to rely on the candidate in terms of average propagation behavior for the prediction. Fig-ure 8 b shows a sample candidate and its range after the clustering on propagation behavior.
 We elaborate the training procedure for this method as a hierarchy structure illustrated in Fig. 9 . Levels I, II, and III indicates the successive grouping of incidents based on attributes, density, and propagation behavior. One may think of merging all three levels into one level containing all three types of information (i.e., attributes, environment, propagation), and conduct clustering algorithm only once. However, it is difficult to balance the weight for the features of the three types of information during clustering. Therefore, the hierarchical structure helps us to avoid potential problems in weight tuning step.

During the prediction step, for a given incident, we use its attributes and traffic density to search in the first two levels. To identify a suitable cluster in Level III, we relax the prediction problem, and use initial behavior of the accident to match the cluster centroid, which is defined as follows: Definition 5 (Initial Behavior) Given an incident ( e ) and its propagation behavior b , i.e., { b where h is defined as forward lag ,and h &lt; t .

In particular, with the help of initial behavior, when a new incident e occurs, we match its initial behavior with the first h times stamp (i.e., b 1 ... h ) among the corresponding propagation predicting b h + 1 ... t . Note that initial behavior can be learned from traffic data. Therefore, by considering the initial behavior as input, we relax our prediction problem by knowing the traffic in the first a few minutes after the occurrence of incidents.

To illustrate the use of initial behavior, consider the example in Fig. 10 . The prediction candidates (i.e., cluster centroids on propagation behavior) for incidents that occurred on freeway I-405 South with similar attributes and traffic density is illustrated as solid lines in Fig. 10 a. The black dash line in Fig. 10 b represents the initial behavior in the first 5 min for a newly occurred incident. By matching { b 0 ,..., b 5 } between its initial behavior and the five prediction candidates, we select the closest cluster centroid to predict the propagation behavior after b 5 , as depicted in Fig. 10 b.

It is important to note that there exists various metrics to evaluate the  X  X loseness X  between initial behavior and first h stamps in cluster centroids. In our approach, we use both Euclidean distance and Mahalanobis distance [ 12 ] to measure the closeness. The Mahalanobis distance differs from Euclidean distance in that it takes into account the correlations in the dataset and is scale-invariant. To measure the differences between propagation behavior b 1 and b 2 , the Mahalanobis distance is calculated as follows: where S is the covariance matrix between b 1 and b 2 . We evaluate the prediction accuracy for both Euclidean distance and Mahalanobis distance in Sect. 6 . 5.4 Discussion So far, we have discussed the strategy of using traffic density and initial behavior to predict the propagation. Last but not the least, we want to complete the discussion by providing a solution to navigation system where the measurement of traffic density is either not available or inaccurate. In particular, for navigation systems based on crowd sourcing, although they can still have access to incident reports and speed changes, but it is generally challenging for them to have accurate traffic density measurement such as volume and occupancy around the incidents. Therefore, for these systems, we provide a similar Prediction strategy by only using incident Attributes and Initial behavior (PAI). To implement this strategy, instead of completing the three levels as shown in Fig. 9 , we only utilize the first and third level. That is, during the training phase, we first group the historical incidents by their attributes and then conduct clustering algorithm on their propagation behavior; during the prediction phase, we utilize the attributes and initial propagation behavior of the incoming incident for predicting its propagation behavior. 6 Prediction of clearance behavior modeled in the similar way as propagation behavior. According to the explanation regarding Fig. 3 , behavior in the propagation phase can be modeled by the time stamps when a sensor starts to get impacted. Similarly, the behavior in clearance phase can be derived by the time stamps when a sensor ends from getting impacted (i.e., the first time stamp with v &lt;  X  ). The prediction of clearance behavior is more challenging than the prediction of propagation behavior. In this section, we will explain these challenges based on the following two examples and briefly discuss our strategy to solve these challenges.

Consider the impact behavior of two incidents as illustrated in Fig. 11 . In this figure, each pair of the rectangle and triangle markers (with the same impact backlog) indicates the start and end time stamp of a particular sensor getting impacted, respectively. As shown in Sect. 4 , the propagation and clearance behavior for each incident can be learned by fitting the markers with polynomial functions, which is illustrated as solid curve in Fig. 11 .

The first new challenge in predicting the clearance behavior lies in the location where the clearance behavior starts. In the prediction of propagation behavior, we assume the propa-gation always starts at the location of traffic incident. However, this is not the case for the clearance behavior. Consider the case illustrated in Fig. 11 a, the sensor closest to the inci-dent location is cleared first, followed by the second closest sensor and so on, indicating the clearance behavior starts at the incident location. On the other hand, according to the case in illustrated Fig. 11 b, the sensor furthest to the incident location is cleared first, followed by the second furthest sensor, which suggests that the clearance behavior starts at the location with maximum backlog. Based on these two cases, in the prediction of clearance behavior, it is important to identify the locations where the clearance begins. If we cannot identify the correct starting locations, the pattern of the clearance behavior will be predicted in a completely wrong way. Moreover, predicting the starting location of clearance behavior is important for navigation systems to identify the size and the location of the impact area. As shown in Fig. 11 a, the location and the size of impact area for incident A is dynamically changing over time. For example, at 20th min, its impact area starts at 0 miles toward the incident and reaches 2.5 miles backlog. But at 30th min, the impact area starts at 3rd mile toward the incident, reaches the 4th mile, indicating its size is only around 1 mile. On the other hand, for incident B illustrated in Fig. 11 b, only the size of the impact area is changing, and starting location of the impact area is always at incident location. In sum, if we cannot accurately predict the starting location of the clearance behavior, the navigation systems can-not accurately capture changing of impact area, further cannot provide the efficient routing plan.
 The second new challenge comes from the beginning time stamp of the clearance behavior. During the prediction of propagation behavior, we assume the propagation starts right after the occurrence of the incident. Thereby, the beginning time stamp of the propagation behavior is the incident X  X  occurrence time, which can be acquired from the incident X  X  report. Similarly, we could assume the beginning time stamp for clearance behavior is the incident clearance time (e.g., when the involved vehicle leaves the scene or when the blocked lane is cleared). However, for the recently occurred incidents, their clearance time stamps are always unknown at the time when they are reported. On the other hand, even if the clearance time is already known, we cannot directly use it as the beginning point of the clearance behavior. In fact, for some traffic incidents, even if the incident is cleared, drivers may still slow down their vehicles to see the scene of the incident due to their curiosity, in particular for some severe incidents, such as car-on-fire. In this way, the traffic congestion caused by the traffic incident is still not resolved, and thereby, the clearance time of the scene cannot be considered as starting point of clearance behavior. Thereby, for predicting the clearance behavior, we also need to predict the time stamp when the clearance behavior begins.

One way to address the two mentioned challenges is to directly calculate the starting location and time of clearance behavior based on the sensor data. The location can be derived by keeping track of the speed readings from the closest sensor and the furthest sensor in the impact region, and see whose speed reading recovers to regular speed reading first. And the starting time is the first speed recovery time among the two sensors. If the closest sensor is recovered first, the clearance behavior should be similar with incident A shown in Fig. 11 a, otherwise, it should be similar with incident B shown in Fig. 11 b. However, this solution only works at the time stamp when the incident starts to clear. In other words, it cannot predict the clearance behavior immediately after the incident is occurred, instead, it needs to wait until the time when any impacted sensor reports speed recovery. As a result, the application of this solution is very limited due to its short prediction interval. Thereby, as an alternative, we try to predict the starting time and location of the clearance behavior at the occurrence time of the incident by identifying correlations of between clearance behaviors and incident attributes. For example, we observe that for small scale of traffic collision, incidents occurred during non-rush hour which are always cleared very fast, with clearance behavior always starting at the incident location, as depicted in Fig. 11 a. On the other hand, severe incidents such clearance behaviors always start at the furthest location, as depicted in Fig. 11 (b). Driven by such observations, to predict the clearance behavior, we first identify the set of correlated attributes of incidents in predicting the start time and location of the clearance behavior, similar with the DB approach). After the starting time and location is predicted, we then follow the same strategy proposed in Sect. 5 to predict the entire time series for the clearance behavior. 7 Experiments 7.1 Experimental setup In the experiments, we evaluated our approaches with real-world traffic and incident datasets. First, we evaluate our proposed impact prediction techniques on propagation behavior under various parameters. Second, we briefly shown our result in predicting the clearance behavior. Finally, we conduct two case studies on real-world traffic incidents to reveal the superiority of utilizing our approach in estimating the travel time in navigation systems. 7.1.1 Data set At our research center, we maintain a very large-scale and high resolution (both spatial and temporal) dataset collected from entire LA County highways and arterial streets RIITS [ 19 ]. We have been continuously collecting and archiving the data for the past three years. We use this real-world dataset to create and evaluate our techniques. This dataset includes: 1. Traffic data : collected from traffic sensors covering approximately 5,000 miles. The 2. Incident data : collected from various agencies including California Highway Patrol
The statistics about this dataset is given in Table 1 . 7.2 Evaluation of propagation prediction 7.2.1 Evaluation method For evaluating propagation behavior, we first use two case studies to reveal the effectiveness of traffic density and initial behavior in the prediction of impact. Then, we evaluate the overall prediction accuracy under various system parameters, which is listed in Table 2 . For each set of experiments, we only vary one parameter and fix the remaining to the default values. Specifically, the occurrence time refers to the first report time of the incidents. The peak hours and nonpeak hours refers to the time intervals [6, 10 a.m.], [3, 7 p.m.] and [10 a.m., 3 p.m.], [7, 9 p.m.], respectively. In addition, the prediction interval t is to 30 (indicating 30 min) as the default value to evaluate the results. This means we evaluate our approach by forecasting the time series { b 1 , b 2 , ..., b 30 } ,where b i refers to the backlog at i th minute after t 0 .
The prediction accuracy is measured by root mean square error between the predicted propagation behavior (i.e., { b i } ) and actual propagation behavior b (i.e., { b i } ).
In the experiments, we will compare following techniques: theoretic baseline (TB), data-driven baseline solely on attributes of incidents (DB), prediction with attributes and traffic density (PAD) and prediction with attributes, density, and initial behavior (PADI), and pre-diction based on attributes and initial behavior only (PAI) for transportation system without density information. 7.2.2 Case studies In this section, we select two traffic incidents (i.e., collision accident) and compare the pre-diction accuracy of two baseline approaches with PAD, and PAI, to illustrate the effectiveness of traffic density and initial behavior independently. The results are shown in Fig. 12 where the solid black line indicates the actual propagation behavior interpolated from the actual sensor readings. Figure 12 a, b depict the traffic collision incidents that occurred on I-405 North freeway and on I-5 South freeway, respectively.
In the first case study, the propagation behavior predicted by theoretical baseline (TB) is close to the ground truth in the initial 15 min, but highly deviated from ground truth from 15 to 30 min. And the data-driven baseline (i.e., the baseline approach solely on incident X  X  attributes) yields the worst accuracy (i.e., with predicted pattern furthest to the actual one). In this case, the theoretical model outperforms the baseline solely on incident attributes, but still not as good as the other two approaches using real-world traffic data (i.e., PAI and PAD). In the second case, although the DB outperforms TB since 18th mins after the incident X  X  occurrence, the prediction accuracy from both of them are lower than PAI and PAD. Such observations indicates that for theoretical models, it may provide accurate prediction in the beginning during the presence of the incidents. But as time elapsed, it is likely that more complex situations in the traffic stream (e.g., lane switching) cannot be accurately modeled by the shockwave theories. And such problems do not exist in the approaches utilizing the real-world data such as PAI and PAD.

From this set of case studies, we can also observe that sometimes PAI yields the best accuracy (i.e., case (a)) and some times PAD yields the best accuracy (i.e., case (b)), and both of them outperforms the two baseline approaches in both cases. The observation implies that (1) the use of traffic density and initial behavior can improve the prediction accuracy compared with the baseline approach; (2) both of them are necessary for the improvement of prediction accuracy, since the results reflect that they are functioning in different ways toward the improvement of prediction accuracy in different cases. Due to the necessity of both traffic density and initial behavior in the prediction, there is no clear ranking between PAI and PAD on which one is better than the other. 7.2.3 Effects of impact threshold (  X  ) In this set of experiments, we compare the prediction accuracy under different  X  s. Figure 13 a depicts the average of prediction error for 905 incidents in the test data for the three approaches with available traffic sensor dataset. Note that since theoretical baseline approach does not utilize the proposed modeling strategy of propagation behavior, in this experiment, we only compare proposed approaches with the data-driven baseline approach (DB). As shown, both PAD and PADI outperforms the data-driven baseline approach and the percentage of their improvement over baseline is listed in the Fig. 13 b. In addition, as illustrated in Fig. 13 a, as  X  increases, the prediction error decreases regardless of which approach is used. To investigate the reason of this phenomenon, we conduct an case study based on an incident occurred on I-405 South during off-peak hours (see Fig. 14 ).

In fact, when we increase  X  , the number of impacted sensor decreases as well. Figure 14 a shows the interpolation result when we create propagation behavior with respect to different  X  values. Each scatter point ( x , y ) represents a sensor located at y starts to get impacted at time x . The dashed lines represent the fitted curves for the corresponding set of scatter points. Figure 14 b shows the average fitting error for each fitted curve. As illustrated, the larger the  X  is, the less error in the fitting result. This is because large  X  is more probable to be greater than the minimum impact threshold (  X  min ), thereby we accurately identify the speed change is caused by traffic incident instead of regular speed fluctuation. For smaller  X  value, since we cannot distinguish whether the speed change is from regular fluctuation from impact of traffic incident, we may introduce more fitting errors in the propagation behavior. The result also indicates that if the propagation behavior is quantified in a more accurate way, the prediction accuracy is also higher. When  X  is small, we may not accurately identify the speed changes especially when it is less than the minimum impact threshold (  X  min ), which yields lower prediction accuracy as a consequence. According to our studies within the dataset, we found that the scale of speed changes can reach up to 85 or 90 % due to a freeway traffic incident. Thereby,  X  can be set as large as 85 or 90 %. When transportation agencies would like to know the locations with most severe impact by a traffic incident, they need to increase the impact threshold (lambda) to a larger value, to eliminate the locations with less severe impacts.

Furthermore, we also observe that larger  X  values cause shorter propagation behavior. This is because, given an incident, the significant speed decrease normally propagates a shorter distance than that of trivial speed changes. Thereby, it is easier to predict the propagation behavior with less time duration under large  X  value. In sum, with larger  X  , the propagation behavior is modeled more accurately (i.e., less fitting error), and hence easier to predict. 7.2.4 Effects of forward lag (h) In our impact prediction framework, system users can also tune the forward lag in the impact prediction. It depends on how far in advance the users try to predict the impact caused by the incidents. For example, for navigation applications, sometimes it is important to predict 30 min of traffic conditions in advance to calculate the fastest path. Thereby, in this set of experiments, we study the effect of forward lag ( h ) length over the prediction accuracy (see Fig. 15 ). We only evaluate the prediction accuracy based on PAI and PADI as there is no initial behavior pattern matching step in the two baseline approaches and PAD. It is important to note that when h = 0, PAI, PADI are reduced to DB and PAD, respectively. Figure 15 a depicts the average prediction accuracy of PAI and PADI by varying the forward lag from 0 to 10. Here, the unit of h is minute. Figure 15 b shows the improvement of PADI over PAI regarding different values of h . In general, as h increases, the prediction accuracy of both PAI and PADI increases. This is because the longer time using initial behavior as indicator yields better estimation. However, for some cases, there is an slight increase in prediction error (e.g., when h increases from 0 to 2 min). One explanation for this case is that the propagation behavior for the first 2 min is noisy, which may due to the difference in immediate reactions of the drivers to the incidents. For example, at the very beginning of the incidents, whether to stay of the road or move to the shoulder to take an exit may greatly affects the incident propagation behavior. 7.2.5 Effects of occurrence time To evaluate the prediction accuracy among all approaches based on real-world traffic data, we compare the prediction accuracy under different occurrence time of traffic incidents, as illustrated in Fig. 16 .The x -axis of this figure is a combination of the incident location and the category of occurrence time, where  X  X eak X  means the  X  X eak hour X  which refers to the rush hours in the morning and in the afternoon, and  X  X ff X  means the  X  X ff-peak hours X  which refers to the time intervals when the road network is less crowded, as explained in Sect. 7.2.1 . As shown in Fig. 16 , DB approach yields the worse prediction accuracy, followed by the PAD and PAI approach, and the PADI approaches is the best of all. The figure also shows that the PAD yields better accuracy than PAI (e.g., I-5 S Peak), sometimes PAI yields better accuracy (e.g., I-405 S Peak), which suggests both the initial propagation behavior and environment information in terms of volume/occupancy are essential for enhancing the prediction accuracy. Moreover, we also observe that for all approaches, the prediction accuracy in the off-peak hours is higher than that in the peak hours, which implies the fact that the propagation behavior for incidents during off-peak hours is easier to predict. 7.2.6 Effect of distance metric In this set of experiments, we compare the prediction accuracy by choosing the distance metric by matching the initial behavior in PADI. Figure 17 a illustrates the prediction accu-racy for top six freeways with most incident occurrences using Euclidean distance metric and Mahalanobis distance metric. As shown, the performance of Euclidean and Mahalanobis dis-tance metrics are variant, i.e., changes based on highways. For example, while Mahalanobis distance yields better results on I-405 South and I-405 North, Euclidean distance is better for I-10 East and I-5 North.

To investigate the reason, we plot the first 5 min of training results under two selected freeways (see Fig. 17 b). Specifically, we choose the two clusters for I-405 S and I-10 E to represent the cases with better prediction in Mahalanobis and Euclidean distance metric, respectively. As shown in Fig. 17 a, the 5 min of cluster centroids in I-405 S present distinct patterns from each other. Thereby the Mahalanobis distance metric is more helpful in selecting the centroids for prediction, due to it measures the correlative distance between two variables. However, first 5 min of cluster centroids in I-10 E follow the similar pattern (i.e., curves with similar gradient), which means they are already highly correlated with each other. In this case, the correlation is no longer a good metric, we need to utilize scale information to distinguish them from each other. Therefore, the Euclidean distance metric introduces lower prediction error in this case. To effectively select the distance metric in our techniques, we evaluate the degree of pattern correlation in the first h minutes of the cluster centroids trained by PADI approach, and set specific thresholds to decide the better metric accordingly. 7.2.7 Effects of prediction interval We conclude the evaluation of predicting propagation behavior using Fig. 18 , which illustrates the overall performance of the three prediction approaches (i.e., data-driven baseline (DB), PAD and PADI) over prediction time interval ( t ). In this experiments,  X  and h is set to 60 % and 5 min, respectively. To compute the prediction result, we directly calculate the differences of actual propagation behavior and predicted ones at each time stamp. That is, for each incident at time t ,the  X  t is defined as | b t  X  b t | ,where b t refers to the impact backlog for its actual propagation behavior at time t ,and b t refers to the impact backlog for the predicted behavior at t .

As shown in Fig. 18 a, the prediction error increases as t increases. For example, for the prediction of impact backlog in 10th minute, the accuracy is higher than the same prediction in 30th minute. In addition, at any time stamp, PADI outperforms both PAD and Baseline. To calculate the percentage of incidents that are accurately predicted before time T ,for each incident occurred at t 0 , we consider its impact as accurately predicted if the following inequality is satisfied: where  X  is set to 0.5 mile according to the sensor placement configuration on Los Angeles freeways (i.e., the average sensor placement interval is 0.5 mile). Since our approach is based on the interpolation of traffic between sensors, the average estimation error brought by the availability of sensor data is also 0.5 mile. Under this circumstances, if the average error for an incident i before T is no more than the internal estimation error, we define the impact of the incident i is accurately predicted. Figure 18 b summarizes the percentage of incidents that is accurately predicted under different time interval T , from our best approach PADI. As shown, for predicting the spatial span with 60 % travel time delay in 15th, 20th and 30th minutes after the occurrence of incidents, our best solution reaches the prediction accuracy of 91.7, 84.2 and 72.4 %, respectively. 7.3 Evaluation of clearance prediction Based on our discussion in Sect. 6 , given the start time and location of the clearance behav-ior, we could easily predict the clearance behavior through the same prediction strategy as the propagation behavior. Thereby, in this subsection, we mainly evaluate the accuracy in predicting the start time and location of clearance behavior.

Figure 19 a shows the distribution and prediction accuracy of the start locations. Here, the  X  X losest X  and  X  X urthest X  refers to starting locations of the clearance behavior toward the incident location, indicating the corresponding clearance behavior is similar with the one illustrated in Fig. 11 a, b, respectively. As shown, around three-fourths traffic incidents are follow the clearance behavior illustrated in Fig. 11 a, and the other one-fourth follows the behavior in Fig. 11 b, which implies that most incidents occurred in Los Angeles are small-scale incidents and cleared fast. The prediction accuracy of the starting locations based on incident attributes is 82.3 %, indicating there do exists correlations between clearance behaviors and the incident attributes.

Figure 19 b shows the prediction accuracy of start time in clearance behavior, where the category  X  5 ,  X  10 and  X  15 refers to the percentage of incidents whose absolute error in predicting start time is within 5, 10, and 15 min range, respectively. As shown, for the incidents with clearance locations starts at closest location (i.e., occurrence location), their clearance starting time always involve with the human factors, which makes the start time of clearance is harder to predict. For example, the start time relates with the time when drivers move the incident scene to the road shoulder, or even the time stamp when the police arrive the scene. For incidents started to be cleared at the furthest locations, their clear time is not necessarily correlated with the time when the scene is cleared, and it is easier to predict according to the result depicted in Fig. 19 b. 7.4 Case studies on travel time calculation We further evaluated our impact prediction approaches using two scenarios based on real-world incidents. For each scenario, we consider a routing plan which starts after the incident is reported and passes through the incident location. In order to estimate the travel time on the routing plan, we utilize two strategies: one is based on the existing impacted area of the incident, another one is based on our predicted impact behavior of the incidents. The actual travel time calculated based on sensor speed for this routing plan is considered as the ground truth. We evaluate the accuracy of two strategies in estimating travel times.

Figure 20 shows the first scenario for a real-world traffic collision incident reported on 11:58 a.m., September 6, 2013. The incident is occurred on I-5 North and our selected route is from A to B as illustrated in Fig. 20 a. In this scenario, we set the start routing time is 12:05 p.m., which is 7 min after the occurrence of the incident. Fig. 20 b shows the actual propagation behavior and the predicted propagation behavior after 12:05 p.m., based on our prediction strategy with  X  = 40%. 3 As shown by the actual propagation behavior, the existing impact area is only 1.5 miles toward the incident location, and the impact area grows rapidly as time elapsed. For traditional navigation systems based on existing traffic situations, the travel time estimation only considers the 1.5 mile congestion toward the incident location. In reality, as drivers approaching the impact area along the route from A to B, the conges-tion area is already expanded, which results in the actual travel time is much larger than the one estimated by traditional navigation systems. Figure 20 c shows the result of travel time estimation based on existing impact and predicted impact of traffic incidents. As shown, the traditional navigation system based on existing impact largely underestimate the travel time. The next-generation navigation system based on our predicted impact improve the estimation accuracy toward the traditional one by 67 %. Moreover, in this scenario, if there exists another route from A to B which takes 12 min to go through, the traditional navigation system will not select this route since it assumes the current route from A to B only take 10 min based on the existing incident X  X  impact, which is less than 12 min. However, for next-generation navigation system utilized our impact prediction, it will select the route takes 12 min instead of the existing route since 14 min is more than 12 min . As a result, the routing choice made by the next-generation navigation system saves 1 min travel time compared with the ground truth.

The second scenario is illustrated in Fig. 21 based on another traffic collision incident reported on 7:44 p.m., September 16, 2013. This incident is occurred on I-405 South and our selected route is from A to B as illustrated in Fig. 21 a. Figure 21 b shows the actual propagation behavior and predicted clearance behavior based on our prediction strategy with  X  = 40 %. In this scenario, we set the start routing time is 8:55 p.m., which is after the beginning of the clearance behavior of the incident (the clearance behavior begins at 8:53 p.m., as shown in Fig. 21 b). As shown, at 8:55 p.m., the existing impact area is still around 2 miles toward the incident location, and the impact area will be completely cleared in 5 min. In this scenario, for traditional navigation systems based on existing impact, the travel time from A to B will be largely over-estimated, since at 8:55 p.m., the navigation system will still consider the congestion area caused by the incident is up to 2 miles, but it will be cleared soon as drivers approaching the area. Figure 20 c reveals the result of travel time estimation. As shown, the actual travel time is only 9 min, which is 2 min less than the estimation based on the existing impact. Also, according to our prediction of clearance behavior, the travel time estimation is 50 % more accurate compared with the traditional travel time estimation. Similarly, in this scenario, if there exists another route from A to B which takes 10 min to go through, the traditional navigation system will select this route instead of the current route since it assumes the current route from A to B take 1 additional minute from A to B. The next-generation navigation system will select current route since the other route takes 10 min which is more than the estimated 8 min on the current route, and in the end, it saves 1 min travel time than compared with the ground truth.

To conclude, the travel time estimation based on existing impact of an incident can both underestimate and overestimate the actual travel time due to neglecting the dynamic develop-ment of the impact over time. By utilizing the predicted impact behavior, the next-generation navigation system can estimate the travel time in a more accurate way, enabling more efficient routing strategies. 8 Conclusions and future plans In this paper, we proposed an approach that quantifies the spatiotemporal impact of traffic incidents. Our approach can predict when and how the travel time delays will occur in road networks due to traffic incidents. Based on evaluation with real-world traffic and incident datasets, we showed that our proposed prediction algorithm utilizing the traffic density and the initial behavior significantly improves the prediction accuracy of baseline approaches by up to 45 %. Moreover, by utilizing our impact prediction approach in the navigation system, the accuracy of the travel time estimation can be largely improved.

In the future, we plan to extend this study by investigating the effects of different incident types on our impact prediction model, as well as examining the effectiveness of our models in different datasets depending on the season. In addition, we plan to investigate effective methods to update our models online with streaming real-time data. Finally, we will focus on predicting the impact of traffic incidents in more complex regions, including arterial streets and intersecting freeways.
 References
