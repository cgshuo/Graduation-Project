 This paper improves spatial pyramid kernel (SPK) and pro-poses a relevance learning approach to compare performer X  X  poses in a large dance archive, the NRCD collection 1 . Do-main knowledge of Choreutics is exploited to define pose topics and a selection operator is developed for pose topic matching. The visual structure descriptor of self similarity (SSF) is extended to hierarchical self similarity (HSSF) to keep shape context. The framework of Bag-of-Visual Words (BOVW) is applied to encode as well as to speed up the matching on pose topics/topic combinations. This allevi-ates the complexity in limb allocation which is infeasible in our data. Extensive experiments show that the new ap-proach outperforms the original SPK in both precision and robustness.
 H.4 [ Information Systems Applications ]: Content-based video retrieval pose relevance learning, action recognition, dance retrieval
Pose remains a fundamental communication approach and a well-designed pose sequence creates the art of dance. The faulty of dance study is curious in pose similarity measure-ment. Numerous visual documents, including portrait photo, performance recording and theatre post, have been collected since the early nineteenth century and thus generate large dance archives, e.g. Siobhan Davies Replay and the UK Na-tional Resource Centre for Dance (NRCD). The online ver-sion [4] is recently published as the Digital Dance Archive Na tional Resource Centre for Dance, University of Surrey, UK DDA, www.dance-archives.ac.uk This paper presents one forthcoming aspect of the DDA vi-sual retrieval functionality, i.e. visual searching based on the posture of dance performances, which accepts a pose photo and returns video clips with similar poses. Moreover, this original work is also useful in the investigation of the rele-vance between general poses, e.g. action recognition, as (1) this approach is based on visual appearance, which alleviates the constrains on action registration [7]; and (2) a huge pose collection are studied from numerous performers at different time as well as from various dance topics.

The challenge is mostly from embedded dance semantics and low visual quality. The meaning of a pose is defined by limb distribution in 3D space rather than body shape [6]. However, the DDA collection, as a historical record, lacks the information of camera configuration, e.g. view-point, depth or 3D view. Consider frequent limb occlusions, it is of a high complexity to allocate limbs directly from monocular images [3]. As a consequence, we exploit visual structure context to discriminate poses. A visual structure feature called self similarity [8] is extracted from multiple resolutions to describe local visual structure. The frame-work of Bag-of-Visual Words encodes SSFs and a selection operator is implemented to improve the spatial pyramid ker-nel (SPK). The SPK based support vector machine (SVM) finally weights matched pose topics and decides on the over-all relevance.

The remainder is organised as follows. Section 2 briefly reviews the literature in content-based dance retrieval and pose/action recognition. System framework and feature com-putation are found in Section 3. Section 4 describes the selection operator and the SPK based relevance estimation function. Experiments and case studies are reported in Sec-tion 5. Conclusions are found in Section 6.
We regard this paper as a beginning step towards content-based dance retrieval, in which guidelines of dance composi-tion is cooperated with arts from information retrieval and computer vision to provide an effective approach for dance archive management. However, this research domain re-mains unexplored, although Smoliar et al. [9] recommend dance archives as an important data resource at the dawn of video retrieval. This is partially due to the scarcity of public dance archives and partially due to the complexity in pose recovery from dance videos [3, 4]. Hachimura et al. [4] develop a prototype system for Japanese dance search-ing. A two-tier framework is proposed: (1) project dance poses to Laban scores and (2) match the string of Laban sc ores. However, Laban score is a 3D trajectory descriptor (Figure 1). It is of a high complexity to learn these scores from a monocular image/video [3]. Kannan et al. [5] turn to external knowledge and suggest the usage of dance ontol-ogy to remove mismatches in high-level annotations. This improves the robustness but too many mismatches are un-avoidable due to the poor projection quality.
Choreutics is the art of dance marking [6], which develops the set of Laban scores to annotate body motions. These symbols are widely accepted as an effective representation of dance contents. Rudolf Laban asserted that  X  X ance move-ment arises from an inner volition which results in a trans-ference of the body or one of limbs from one spatial position to another X . In general, a Laban score stands for the posi-tion of a body principle zone at three spatial levels, i.e. the floor, the mid-height of the body and the height above the head (Figure 1). Five principle body zones are marked: the zone of the head, the two zones of the arms, and the two zones of the legs. A dance pose is therefore symbolised as a five-element vector, in which each element is a Laban score.
To summarise, three domain related conclusions are reached: a dance pose contains at the most five topics; the matching between body principle zones decides on the relevance; and torso is a noise for pose relevance estimation under the con-text of dance. In addition, pose or action recognition is a fundamental problem in computer vision [3], but a complete overview is beyond the scope of this paper.
Figure 2 displays system framework. We allocate perform-ers by pedestrian detection [2]. SSFs are intensively sampled inside performer bounding box from multiple resolutions and grouped into HSSF according to spatial adjacency. Visual vocabulary is generated by hierarchical K-mean. A HSSF thus becomes a set of visual words (or a visual sentence), which is equivalent to a SSF histogram around the neigh-bourhood. We index HSSFs for pose retrieval. The following sections present the computation of HSSF.
SSF is a local structure descriptor [8]. For a pixel q , we extract a 5 5 surrounding patch and compare it with a larger surround image region (20 20 in experiments) which shares the same centre of q . Sum of square difference is calculated between patch colours. The resulting distance surface SSD q is normalised into a correlation surface S q (Equation 1).
 where var noise is a constant standing for acceptable visual variations in both colour and illumination, and var auto ( q ) denotes the maximum of differential variances in the neigh-bourhood region of 2 2. S q is then transformed into log-polar coordinates centred at q . 48-bins are extracted, includ-ing 4 radial and 12 angle intervals. We compute maximal correlation values from each bin to form a 48 entries vec-tor S dq . Late, S dq is linearly normalised into [0 :: 1]. SSF is therefore invariant to the difference in texture and colour distribution of surrounding image regions.

Consider intensive sampling, a threshold is set for SSFs to remove non-informative ones and to improve discriminative power. We compute SSF covariance distribution and max-imise entropy gain to decide on such a threshold. This is because the criterion of maximised entropy can find a bal-ance between informative effectiveness and feature collection size. On one hand, the usage of entropy gain avoids a rude judgement on SSF effectiveness. On the other hand, we avoid either an extremely small or a huge feature collection for pose representation, which is unavoidable with a constant threshold [8]. Such a character is valuable for later relevance estimation, especially in the statistics of visual words.
HSSF aligns SSFs from multiple resolutions to keep struc-ture context. This provides a solution to maintain geomet-rical relationships in BOVW. The computation process is as follows. We normalise dancer bounding boxes into a given size [2]. A three layer pyramid is created above the bound-ing box, in which each layer is twice larger than the upper. SSFs are extracted on every pyramid layer. HSSF grouped these SSFs with a floating window which scans the bounding box. Therefore, HSSF becomes a hierarchy representation, in which the root is the SSF at the lowest resolution and leaves are those at the finest resolution. After visual vo-cabulary translation, a HSSF turns into a sentence of visual words. There are many advantages. First, a HSSF keeps both a visual word and the word X  X  ancestors at coarse reso-lutions. This improves the statistical effectiveness of visual word frequency, as such a frequency now reflects the signifi-cance of this visual word in perception as well as in content richness. On one hand, a visual word at a low resolution is easy to be noticed and covers a relatively large image area. On the other hand, a visual word containing rich internal sub-structures is usually more informative than other plain one. Second, structure adjacency can be learnt from the length of common sub-string. HSSFs which share a long co mmon sub-string, are of a high probability to be similar. This character facilitates spatially grouping of visual struc-tures and therefore helps the identification of matched prin-cipal zones. Third, HSSF provides a natural break between visual structures. This allows the estimation of relevance on large visual structures rather than the count on small image regions. Such a character improves the robustness and the effectiveness of relevance estimation.
In this section, a selection operator  X  is proposed to im-prove SPK [1] for pose relevance learning. We match HSSFs by using SSFs at the lowest resolution, but entirely over-lapped pairs will be rejected, because (1) overlapped limb should be treated as one pose topic and (2) poses topics should be apart from each other. If the number of matched HSSF pairs less than eight, we carry on such a selection on the second lowest resolution. In summary, we seek for no more than eight non-overlapped HSSF pairs at a resolu-tion as coarse as possible. The histogram of visual words at the finest resolution of selected HSSF pairs is then cal-culated and the intersection distance is applied to measure histogram similarity [1]. The SPK function is rewritten as Equation 2 for two HSSF collections HSSF I and HSSF J from image I and J, respectively.

K ( HSSF I ; HSSF J ) = where l is a matched HSSF pair selected by operator  X , dist () is the intersection distance, is a combination parameter.
The evaluation collection includes 45 videos at the reso-lution of 704 576 (MPEG-2 PAL) from the Natural Move-ment collection in the NRCD, among which five videos are manually labelled for training. 1827 single person poses are marked and projected into 65 query classes for (1) generat-ing the baseline of SPK; and (2) training the SVM to learn combination parameters. The overall length of the evalua-tion collection is about 30 hours. The query collection Q consists of 65 queries (Figure 3), generated by a group of dance professionals. Most query images are portrait pho-tos from the Visual Item collection in the NRCD to ensure query quality.

The original SPK [1] is used as the baseline. This state-of-art improves the pyramid matching kernel (PMK) based SVM and accumulates SIFTs/HOG from multiple resolu-tions for general shape discrimination. In this paper, we propose a selection operator to choose a limited number of matched feature pairs rather than seeking for a global min-imisation. This avoids over-fitting on tiny regions. More-over, SPK relies on a constant grid, which is not so effective in pose data, as body principle zones can partially overlap. We randomly select 30 query classes to train the SVM in both SPK and our approach, whilst keeping the remain-der for evaluation. The average of precision at 30 returns AP 30 is used to evaluate the effectiveness. Table 1 com-pares retrieval performance with various visual vocabularies, in which BM 25 refers to the usage of Okapi BM25 model directly on SSF based visual words; HSSF denotes the HSSF based relevance learning and SPK is the baseline. Table 1: Vocabulary sensitivity on the rst subset by using AP30
HS SF based pose relevance learning significantly decreases the sensitivity on visual vocabulary, comparing with the BM25 model. This shows the effectiveness of the rank-by-learning. SPK reaches the best performance earlier than HSSF but the effectiveness decreases with the enlargement of vocabulary. We think this is because SPK tries to min-imise the distance across all image grids and falls into mis-matching, since the background is a dark platform in many instances. Moreover, this indicates the effectiveness of the selection operator.
Dance pose experiences a strong variation in appearance, e.g. that from the configuration of video recording, such as camera viewpoint and the composition of dance contents, such as costume patterns. Figure 4 displays a query and the top 15 returns, in which a dancer expands her arms hori-zontally with the shoulder and steps out. A wide spread of visual distortions are observed due to the change of camera viewpoints. The precision-recall (PR) curves are shown in Figure 5. SP K is of a high precision but a low recall. This is because the change of viewpoint significantly modifies the spatial distribution of key points. The HSSF based relevance learning is robust against viewpoint changes.

The major part of human body, i.e. torso, contributes few dance semantics. SSFs from torso are therefore domain related noise. In addition, human body is of bilateral sym-metry. It is of a high complexity to discriminate left or right limb in a low visual resolution without prior knowledge on camera viewpoint, although these principle zones denote dif-ferent dance semantics. Figure 6 displays such a query in which a dancer extends his limbs and shows an almost sym-metrical pose. As a consequence, torso contributes most of visual words and ill-positions the query.

PR curves in Figure 7 show a similar performance of SPK and HSSF based learning. We remove the most frequent visual words to reduce torso noise. This leads to a relatively small number of HSSFs as well as a very small number of matched topics in relevant visual documents. The learning based approach is hence not so effective. We see many single hand cases in retrieval results (Figure 6b). This indicates a matching on a part of pose topics. However, some dance professionals accept such a partial match as relevant.
This paper aims to learn relevance in dance poses. The vi-sual structure feature of SSF is extended to hierarchical SSF in order to catch structure contexts from multiple resolu-tions. This cooperates with domain knowledge of Choreutics to alleviate the complexity in limb allocation from monocu-lar images. We compare visual words at the lowest resolution and filter out overlapped regions to gather possible matches. Then, the visual word histogram at the finest resolution are submitted to SPK based SVM to decide on the relevance. The contributions are: (1) a geometric related selection op-erator to improve the SPK kernel; (2) an efficient feature representation (HSSF) to keep structure context, which can be further improved to keep geometrical relationship be-tween key points; and (3) a relevance learning framework for content based dance pose retrieval. In addition, this is an original work in content based dance retrieval.
This research is partially supported by the EU funded project LiMoSINe (288024) and by the AHRC project Dig-ital Dance Archive (DDA). [1] A. Bosch, A. Zisserman, and X. Mu  X noz. Representing [2] N. Dalal, B. Triggs, and C. Schmid. Human detection [3] M. Germann, T. Popa, R. Ziegler, R. Keiser, and [4] K. Hachimura. Digital archiving of dancing. Review of [5] R. Kannan, F. Andres, and C. Guetl. Danvideo: an [6] R. Laban. Choreutics . Maconald and Evans, 9 John [7] F. Lv and R. nevatia. Single view human action [8] E. Shechtman and M. Irani. Matching local [9] S. Smoliar and H. Zhang. Content based video indexing
