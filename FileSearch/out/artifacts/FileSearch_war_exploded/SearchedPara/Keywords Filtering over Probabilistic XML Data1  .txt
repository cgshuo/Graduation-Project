 Many important XML applications such as automatic information integration and fault diagnose produce uncertainty. Probabilistic XML data management is becoming a critical issue. In the current probabilistic XML model [1,2,3,4,5,6], a probabilistic XML document( p -document ) is considered as a labelled tree, con-sisting of two types of nodes, ordinary (ORD) nodes representing actual data and distributional nodes representing the probability distribution of the child nodes. Distributional nodes have five types, { IND,MUX,DET,EXP,CIE } .[5]de-fines p -document family as PrXML C , C  X  X  IND,MUX,DET,EXP,CIE } . [7,8] have discussed structured query over probabilistic XML data. Only [9] concerns with keyword query, in which two types of distributional nodes, IND and MUX(the children of them are independent and mutually exclusive respec-tively), are considered.

From the XML keyword search aspect, SLCA [10,11] is a widely accepted keyword semantics. SLCA-based keywords filtering over probabilistic XML data meets new challenges, such as how to compute the probability for a certain node to be a SLCA node and whether a SLCA node is still SLCA node and so on.
To solve these problems, we propose a SLCA-based keywords filtering solution over probabilistic XML data model PrXML { exp,ind,mux } .

We summarize the contributions of this paper as follows:  X  We present a more general model PrXML { exp,ind,mux } for keywords filtering  X  Algorithms are given to find SLCA nodes and compute the probability for  X  Experimental evaluation has demonst rated the efficiency of the proposed The rest of the paper is organized as follows. Motivations and preliminary knowl-edge will be given in Section 2. Sectio n 3 gives the overview of the keyword filtering over probabilistic XML. The system architecture and algorithms are proposed in Section 4. Section 5 evaluates the features and efficiency of our algorithms through experiments. Conclusions and future work are in the end. 2.1 Motivations Some common and useful data dependencies deserve investigation. For instance, both authors, Tommy and Hung ,inanXMLdocumentshowninFig.1are uncertain. If Tommy appears, Hung appears with some probability(for example cooperation relationship). This kind of data dependency is common among XML data and has great merits in maintaini ng data accuracy and query correctness. The sibling dependency can be described by EXP node, which can represent arbitrary sibling nodes dependency relationship using node sets.

However, [9] didn X  X  discuss the probability model including EXP nodes. This paper focuses on keyword filtering over model PrXML { exp,ind,mux } , which rep-resents more general relationship among sibling nodes. Following are some defi-nitions related to our filtering algorithms. 2.2 Preliminaries Example 1. keyword query: Tommy, 2008 .
 Example 1 gives a keyword query. Fig. 1 shows a probabilistic XML tree. The tree contains ordinary nodes, EXP nodes and MUX nodes. The number at-tached on each edge in the tree indicates child node X  X  conditional probability given the existence of the parent node.  X 1 X  is the default conditional probabil-ity. The node EXP in Fig. 1 has three children sets, { Tommy } , { Hung } and {
Tommy, Hung } , whose set probabilities are 0.3, 0.2 and 0.5 respectively. IND nodes are omitted in Fig. 1 because computing the probability of IND nodes and of ordinary nodes are the same [9].
 Definition 1. The kdptab of subtree SubT ( n ) ,namely kdptab n , is defined in equation 1. bitvector is a binary string which record which keywords appear. kdptab n is used to maintain the keyword distributions of the subtree SubT ( n )rootedat node n .Takenode Tommy as an example. kdptab Tommy is shown in Fig. 1. One term &lt;  X 01 X  , 1 &gt; in kdptab Tommy means that only the first keyword in Example 1 appears in SubT ( Tommy ) and its probability is 1. kdptab n is defined in Definition 1.
 Definition 2. Dot product(  X  )of kdptab : Dot product of kdptab is defined in Definition 2. Take kdptab 2008 in Fig. 1 as an Definition 3. Addition operation( + )of kdptab : kdptab 1 + kdptab 2 = S 1  X  S 2  X  S 3 , Definition 3 gives the addition operation of kdptab . For example, given  X 00 X  , 0 . 6 &gt;, &lt;  X 01 X  , 0 &gt;, &lt;  X 10 X  , 0 . 2 &gt;, &lt;  X 11 X  , 0 &gt; } . Cartesian product of kdptab is described in Definition 4.
 Definition 4. Cartesian product(  X  )of kdptab In Fig. 1, kdptab Author equals kdptab EXP and kdptab Year equals kdptab MUX . Given kdptab 1 = kdptab Author  X  0 . 7and kdptab 2 = kdptab Year  X  0 . 6, the result of kdptab 1  X  kdptab 2 equals kdptab Paper ,whichisshowninTable4.
 Definition 5 gives the priority of kdptab  X  X  operations.
 Definition 5. The operation priority of + ,  X  and  X  increases successively. Lemma 1. For any kdptab 1 , kdptab 2 and kdptab 3 , kdptab 1  X  kdptab 3 + kdptab 2  X  kdptab 3 =( kdptab 1 + kdptab 2 )  X  kdptab 3 .
 The detail proof for this lemma is omitted due to limited space. In a deterministic XML document, a node v isaSLCAnodeif(1)thesubtree SubT ( v ) rooted at the node v contains all the keywords, and (2) there doesn X  X  exist any v  X  X  descendant satisfies condition(1). [9] mentioned that a SLCA node is represented by a 2-tuple &lt;v,p&gt; in probabilistic XML. v is a document node and p is the probability for v to be a SLCA node. p can be computed by equation 6.
 Pr ( path r  X  v ) indicates the existence probability of v in all possible worlds. Pr local ( v ) is the containing probability that SubT ( v ) contains all keywords. 3.1 Existence Probability Pr ( path r  X  v ) Bayes equation can be used to compute nodes X  existence probability in prob-abilistic XML [2]. One node X  X  existence probability is only related to the con-ditional probabilities of all the nodes on the path from the root node to the current node. However, EXP nodes gives conditional probabilities of child node sets instead of conditional probabilities of each individual child node. Then we X  X l discuss how to compute node v  X  X  existence probability when EXP nodes exist.
If all EXP nodes appear in the descendants of the current node v ,thenevery conditional probability of the nodes on the path( r  X  v ) is known. The existence probability of v can be computed by multiplying every conditional probability of the nodes on the path. Otherwise, If there is any EXP node on the path from the root node r to the current node v , one of the EXP node X  X  child node c is also on the path. c  X  X  conditional probability should be computed from sets X  conditional probabilities firstly. Then v  X  X  existence probability can be computed. For exam-ple, there X  X  an EXP node on the path from root Paper to node Tommy in Fig. 1. We compute node Tommy  X  X  conditional probability using the set probabilities. We can get the existence probability of node Tommy . 3.2 Containing Probability Pr local ( v ) Given the condition that no descendants of node v are SLCA nodes, the prob-ability for node v to be a SLCA node equals the total probability of SubT ( v ) X  X  possible worlds including all keywords. kdptab v is used to record the probabil-ity for SubT ( v ) to contain query keywords. Following we X  X l describe how to use tuples from children to get kdptab v .
 Tuples from Children to Parents: Each child node transmit to parent node a 2-tuple &lt;prob,kdptab&gt; . Prob is the conditional probability of the child node and kdptab is the keyword distribution probability table.

Example 1 is an keyword query. In Fig. 1, the 2-tuple transmitted by Tommy and 0.2 are node Tommy and node 2008 X  X  conditional probability respectively. Terms whose prob is non-zero are recorded to save storage space.
 Tuples Processing: Normally, any none-leaf node v processes tuples from chil-dren following three steps: (1)Compute probabilities of possible worlds which are composed of v  X  X  child nodes based on the relationships among child nodes. (2)Compute the keyword distribution probability for each possible world us-ing kdptab from children. (3)Sum correlative probabilities of all possible worlds. Then we can obtain kdptab of SubT ( v ). However, the above steps scan nodes multiple times. Following we X  X l try to merge above steps for IND(and ORD), MUX, EXP nodes to reduce time complexity.
 Case 1-MUX: M is a distributional node which has n mutually-exclusive the keyword distribution probability table for SubT ( X i )whennode X i exists. We define P n +1 as the probability for M to have no children. Then P n +1 = 1  X  of this possible world. The keyword distribution table kdptab M can be computed by Equation 7. Using Equation 7, MUX node X  X  keyword distribution table can be obtained after scanning child nodes once. kdptab MUX (shown in Fig. 1) of node MUX can be obtained using kdptab 2008 and kdptab 2009 according to Equation 7.
 Case 2-EXP: Suppose EXP node E has m child node subsets, which cor-responds to SubT ( E ) X  X  m possible worlds. The existence probability for i th subset is P i and the subset contains n child nodes whose kdptab information kdptab i (1  X  i  X  n ) are already obtained. Then the keywords distribution table for i th possible world kdptab pw i can be computed by Equation 8. can be computed by Equation 9.
In Fig. 1, node EXP has 3 child subsets: { Tommy } , { Hung } , { Tommy, Hung } . kdptabs of SubT ( EXP ) X  X  corresponding possible worlds are shown in Table 1, Table 2 and Table 3. Then kdptab EXP can be obtained using Equation 9. 00 01 10 11 0100 Case 3-IND and ORD: Suppose there is an IND or ORD node. It has n independent children X 1 ,X 2 ,...,X n , whose joint distribution is: There are 2 n possible worlds, whose keyword distribution probability table can be obtained by Equation 11.
 X  X  X  existence probability P ( X i = 1) is given. P ( X i =0)=1  X  P ( X i =1). If X i exists, SubT ( X i ) X  X  kdptab information kdptab X i =1 is already computed using children X  X  kdptabs .If X i doesn X  X  exist, no nodes are in SubT ( X i ). So its kdptab information kdptab X i =0 = { &lt;  X 00 X  , 1 &gt; } .Using kdptab X P ( X i )  X  kdptab X i (1  X  i  X  n ), Equation 11 equals Equation 12. Then we get kdptab IND by adding kdptabs of each possible world. It is easy to prove that Equation 13 equals Equation 14 using Lemma 1: An ORD node may contain keywords itsel f. So Equation 14 needs to be altered to Equation 15 ( kdptab ORD local records the keyword distribution probabilities of the ORD node) to compute kdptab ORD . We can get the kdptab information of IND and ORD nodes using Equation 14 and Equation 15 by scanning their child nodes once. In Fig. 1, node Paper is an ORD node. kdptab Author = kdptab EXP , kdptab Year = kdptab MUX . kdptab EXP and kdptab MUX are shown in Fig. 1. kdptab Paper = kdptab Paper is shown in table 4. The 2-tuple &lt;  X 11 X  , 0 . 0672 &gt; in Table 4 means that the probability for SubT ( Paper ) to contain both keywords is 0.0662. So the probability for the node Paper to be a SLCA node is 0.0672. Fig. 2 shows the system architecture of SLCA-based keywords filtering over prob-abilistic XML. Users submit keyword queries. The system receives probabilistic XML data continually, parses these data and returns results based on users X  queries. The results are in the form of SLCA nodes.

We use SAX parser to read XML document. The parser will produce a stream of events. The main events include StartDocument , EndDocument , StartElement , EndElement and Characters . We keep a record ( level,id,bitvector, nodeProb, type, expInfo, kdptab ) for every XML node (whether it is ordinary node or distributional node). Level, id represent the depth and ID of the current node. Bitvector are the keywords inclusion information. NodeProb records the conditional probability of the current node. Type represents the type of the cur-rent node and its value can be ORD, IND, MUX, EXP or SLCA. Type = X  SLCA  X  means that either the current node or at least one descendent of it is a SLCA node and it will be transmitted upwards to prevent ancestors from being a SLCA node. ExpInfo records the subsets information of child nodes. kdptab is the keyword distribution probability table. In fact, we can consider SAX parsing as preorder traversal of XML tree. The records are transmitted bottom-up. After all descen-dants are processed, all information of children will be combined with informa-tion of their parent. Once SLCA node is identified, put ID of it into result-set. When the parsing is finished, all computation will end. Algorithm 1. EndElement 4.1 Implementation StartDocument event initializes some global variables. If the parser meets the beginning of an element, it triggers StartElement event. StartElement event constructs current element X  X  record, which is  X  level,id,bitvector,nodeProb,type, expInfo, kdptab  X , and push it into Stack . Variable pathProb is used to record current node X  X  existence probability. Bitvector and kdptab of current node may be updated when Characters event comes.
 End mark of an element triggers event EndElement (Algorithm 1). When EndElement event comes, we will combine the tuples from child nodes with it of the current node and compute the probability for the current node to be a SLCA node. If the current node is a leaf node (Line2-12), function isSLCA() is called to get the probability of current node to be SLCA node. If the probability is high enough(judged by function isTopK() ), then the current node is a SLCA node and this information will be recorded in type . If the current node is not a leaf node (Line13-34), information of all the child nodes are popped from Stack . We X  X l obtain the record of current node by equations in subsect ion 3.2 according to the relationship among child nodes. If the subtree rooted at the current node contains all the keywords and the SLCA probability is enough high, then the current node is a SLCA node and this information will be recorded in type .
Only ordinary nodes can be SLCA nodes. Function isSLCA() makes sure that no descendants of the current node is a SLCA node and then confirms that the current node is an ordinary node. Afterwards function isSLCA() will read the probability of the node containing all the keywords from kdptab . The probability multiply pathProb and be returned as the probability for the current node to be a SLCA node. 4.2 Optimization Line 10 and line 31 give optimizations just for the case that p -document has no EXP nodes. The condition shows that if the current node doesn X  X  contain any keyword and its subtree doesn X  X  have SLCA nodes, its record needn X  X  to be stored in Stack . Temporarily, there is no optimization towards the p -document which contains EXP node.

Time complexity of the whole method is related to the number and the types of document nodes. ORD, IND and MUX nodes need to be scanned only once during the process. Child nodes of the EXP node, however, need to be scanned multiple times because they may appear in different subsets. Given a document which has n nodes, m 1 nodes are child nodes of EXP nodes. There are s sets composed of child nodes of EXP nodes, and on average there will be m 2 nodes in each set. In terms of the data size, the time complexity of the whole method is O ( n + s  X  m 2  X  m 1 ). So, given a fixed size document, the number of subsets, the number of nodes in the subsets, and the number of EXP nodes will affect the algorithm efficiency. In this section, experiments are given to evaluate SLCA keywords filtering al-gorithms over probabilistic XML. The experiments analyze the features and efficiency of the algorithms from differ ent aspects such as data set and query features. The program is coded in Java. The experiments are performed using dual-core desktops with 2GB memory. We use real dataset DBLP.We generate probabilistic XML tree using the same method as used in [9,7]. We visit the nodes in the original XML tree in pre-order way. For each node v visited, we randomly generate some distributional nodes of  X  X ND X  or  X  X UX X  or  X  X XP X  types as children of v with the percentage of 5% -20%. For the original children of v , we choose some of them as the children of the new generated distributional nodes. Then random probability distributions are assigned to these children with the restriction that the sum of them for a MUX node is no greater than  X 1 X  and the sum of them for a EXP node is  X 1 X . The existence probabilities of each in-dividual child node of the EXP nodes should be pre-calculated and stored. The features of datasets used in this experiment are shown in Table 5.

Queries in [9] are parted of queries used in our experiment. We also adopted the query generating pattern kN -L -H in [11]. kN is the number of keywords in the queries. L and H are frequencies of the low est frequency and highest frequency of keywords. We randomly gen erate a group of queries and execute them 5 times. The average time of each qu ery is recorded in following figures. Ratio of distributional Nodes: There are four options, 5%, 10%, 14.5% and 20%,oftheratioofthe distributional nodes. The corresponding document are Doc 9, Doc 11, Doc 13 and Doc 15. The queries used are the same with queries in [9]. Fig. 3 shows the average execution time of different queries over different datasets using optimized(just for no-EXP docs) or non-optimized algorithms. Experimental results indicate that the ex ecution time increases linearly with the increasing of distributional nodes. Scanning and parsing the added data are the main reason for the time growth. The optimized algorithm not only saves storage space, but also avoids processing irrelevant nodes and boosts efficiency. Comparison with Previous Work: The experiment adopt similar datasets (considering the number of nodes, ratio of distributional nodes, size of the doc-ument) and same queries with them of [9]. And it makes comparison on query efficiency with [9]. Fig. 4 shows either fo r optimized or non-optimized algorithm, the execution time of the five queries r anges from 1.6 to 3.1 seconds. However, the execution time of the same query consumes about 7-13 seconds in [9]. Our algorithm compute the SLCA probability as soon as a SLCA node is identified and no redundant computations. [9] need compute all potential SLCAs and then compute the probabilities for them to be SLCAs. And the real SLCAs will be picked out finally. But there are so many SLCA candidate nodes that extra work is needed to find the real SLCA nodes in [9].
 Number of Query: Our algorithm only needs to scan and parse the XML document once regardless of dataset size. So a batch of queries can make full use of the algorithm ability. We randomly generate queries (query type is 2-100-100) and run them on datasets Doc 11 and Doc 12. Fig. 5 shows that the average query time slowly decreases and finally stabili zes as the number of query increases. Frequency of Keywords: Fig. 6 records the average execution time of different patterns queries on Doc 11 and Doc 12. Fig. 6 shows the average execution time doesn X  X  change significantly when the keyword frequency increases from 100 to 10,000. Therefore, algorithms aren X  X  sensitive to the keyword frequency. Number of Keywords: Fig. 7 shows the influence of the keyword number on the execution time. The number of keywords increases from 2 to 4. The queries run on Doc 11 and Doc 12. Experimental results indicate that the execution time increases linearly when the number of keywords increases from 2 to 4. Dataset size: Fig. 8 demonstrates the influence of dataset size on the average execution time. We randomly generate queries (type is 2-100-100) and run them on Doc 11 and Doc 12. Experimental result indicates the average execution time increases linearly when the dataset size increases. This paper works on keyword filtering over probabilistic XML data model PrXML { exp,ind,mux } . We analyze probability computation, define several oper-ators concerning the computation and then give the whole algorithms which computes the SLCA probability by scanning the document only once bottom-up. Experimental results demonstrate the expansibility of our algorithms on data type, dataset size and query times. Our algorithm is insensitive to query keywords frequency and suitable for high-frequency keyword filtering. Acknowledgments. This work was supported by the National Major Projects on Science and Technology under grant number 2010ZX01042-002-003-004,NSFC grant (No. 61033007, 60903014 and 61170085), 973 project(No. 2010CB328106), Program for New Century Excellent Talents in China (No.NCET-10-0388).
