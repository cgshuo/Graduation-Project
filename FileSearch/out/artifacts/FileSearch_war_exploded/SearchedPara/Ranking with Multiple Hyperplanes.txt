 The central problem for many applications in Information Retrieval is ranking and learni ng to rank is considered as a promising approach for addressi ng the issue. Ranking SVM, for example, is a state-of-the-art me thod for learning to rank and has been empirically demonstrated to be effective. In this paper, we study the issue of learning to rank, particularly the approach of using SVM techniques to perform the task. We point out that although Ranking SVM is advantageous, it still has shortcomings. Ranking SVM employ s a single hyperplane in the feature space as the model for ranking, which is too simple to tackle complex ranking problems. Furthermore, the training of Ranking SVM is also computationall y costly. In this paper, we look at an alternative approach to Ranking SVM, which we call  X  X ultiple Hyperplane Ranker X  (MHR), and make comparisons between the two approaches. MHR takes the divide-and-conquer strategy. It employs multiple hyperplanes to rank instances and finally aggregates the ranking re sults given by the hyperplanes. MHR contains Ranking SVM as a special case, and MHR can overcome the shortcomings whic h Ranking SVM suffers from. Experimental results on two information retrieval datasets show that MHR can outperform Ranking SVM in ranking. H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms, Performance, Theory Ranking with Multiple Hyperplanes, Ranking SVM Ranking is the central problem fo r many IR applications. These include document retrieval [4], co llaborative filt ering [15], key term extraction [8], expert finding [31], important email routing [5], sentiment analysis [27], product rating [9], and anti web spam [14]. In the task, given a set of instances, we make use of a ranking model (function) to calcul ate the score of each object and sort the objects with the sc ores. The scores may represent the degrees of relevance, prefer ence, or importance, depending on applications. ranking model using some traini ng data and machine learning techniques. A typical setting in learning to rank, which is also categories) are given as training data. gaining increasing attention in IR and related fields. Many methods of learning to rank have been proposed (e.g., [3][13][18][23][25] [26]) and applied to IR applications (e.g., [4][31]). Among them, Ranking SVM (RSVM) [18] is a typical method, which performs the learni ng task by utilizing the SVM techniques, one of the most powerful tools in machine learning. In this paper, we also focus on learning to rank and adopt the SVM approach. (The idea, insigh ts, and discussions we present in this paper should be extensible to other approaches.) on instance pairs. More precisely, in training a set of instance pairs is created; each pair consists of two instances from two different ranks. Therefore, for each instance pair, there is an order between the two instance s. A classification model is constructed for identifying the order relationship between the two instances in any instance pair. Ranking can be then conducted on the basis of the classification model. (More detailed descriptions on RSVM will be given in Section 2.) because the SVM approach to learning to rank is important and needs more investigations, and because RSVM has both pros and cons and needs fu rther improvements. classifier on instance pairs and makes use of it for ranking. One advantage of it is the simplicity of the model. However, this also ranking instances from all ranks. In reality, the ranking of order relationships between instances fr om different ranks are hard to be handled with a single model. Another problem with RSVM is that the training of it is in general costly. This is because it uses the training data size. spectrum. Specifically we take the divide-and-conquer strategy and work out a new method for learning to rank using SVM techniques. We try to make thorough comparisons between the two methods. The relation betw een RSVM and our method is similar to that between Multi-class SVM [19][30] and ECOC [10][24] for multi-class classification. (MHR), employs several hyperplane classifiers and aggregates the results of them for final ra nking. MHR contains two major components: base ranker and rank aggregation. Each base ranker is a hyperplane for identifying ordering relationships between instances from two ranks. In lear ning, a base ranker is created for any two ranks to ensure high accuracies on the local ranking. Rank aggregation is conducted by using an ensemble model of the base rankers. In learning, the ensemble model is created, to ensure high accuracy in the global ranking. case, and is complementary to RSVM. The advantages of MHR include higher accuracy in ranking, efficiency in training, and ease of incorporating prior knowledge. The disadvantages of it are the requirement of the use of training data based on ranks and the increase of model complexity. Experimental results on two information retrieval data sets show that MHR works better than RSVM. of a new learning to rank method MHR, (2) an introduction of a general framework on the SVM approach to learning to rank, and (3) thorough comparisons between RSVM and MHR, and empirical verification of the effectiveness of MHR. introduces Ranking SVM. S ection 3 describes MHR. Experimental results are reported in Section 4. Section 5 introduces related work. Conclusion and future work are given in Section 6. Suppose that X  X  R d is the feature space, where d is the number of ranks. Further assume that there exists a total order between ( x i , and y i  X  Y is the label of instance i . If y ranked ahead of x j , denoted as ij x x f . Assume that F is the set of ranking functions, such that each member of it f  X  F can rank instances: In Ranking SVM (RSVM), f is assumed to be a linear function [18], where  X  is weight vector and ,  X  X  X   X  X  X  denotes inner product. f ( x )=0 corresponds to a hyperplane in the feature space. Thus we have Given an instance pair x i and x j , we create a new instance x If x i is ranked ahead of x j , we assign a label +1, otherwise -1 to the new instance. In this way, we produce a new data set and we can build a binary classification model, for example, a linear SVM (hyperplane) using the data set. This is exactly the RSVM model. Since (1) and (3) hold, the RSVM model (2) can be directly used for ranking instances. Programming problem as shown below: hyperplane and  X  ij denotes a slack vari able. Suppose that the solution to (4) is  X  * , then we can make the ranking function as The advantages of RSVM include the simplicity of its model and the effectiveness of its uses. Theoretically, the ranking accuracy of RSVM in terms of Average Precision is known to be approximately bounded from below by the inverse of classification errors on instance pairs [23]. Empirically, the effectiveness of it has been demonstrated. model might be too simple for tackling complex ranking problems in practice, as will be seen below. Second, the training process of RSVM is time consuming. The problem becomes severe, when the size of training data gets large and when the number of ranks increases. This is because RSVM makes use of instance pairs as training data (which is of quadratic order of training data size). Third, it is not easy to incorporate prior knowledge into the model. In many IR applications, it is important to focus on the training on the tops of rankings, as indicated in [25]. One solution to the problem is to add different weights on the ordering (cla ssification) decisions between instances from different ranks. The original RSVM cannot cope with the problem, however. single hyperplane for ranking can be problematic. We have made analyses on the OHSUMED document retrieval data, by means of Principal Component Analysis (PCA). There are three ranks in the data  X  X efinitely relevant X ,  X  X artially relevant X , and  X  X rrelevant X . For each query, there are a certain number of associated documents. An instance (feature vector) can be created by using one query and one associated document. We have plotted the instances from different queries in the space described by the two principal coordinates. It seems to be always true that single hyperpla nes cannot separate very well the instance pairs in different ranks. for query 5 in the OHSUMED data set, in the space described by the two principal coordinates. Red crosses denote  X  X efinitely relevant X  documents, green rectangles  X  X artially relevant X  documents, and blue triangles  X  X rrelevant X  documents. We can see that exploiting a single hyperplane cannot rank the documents properly. When we create hyperplanes for identifying order relationships between instances from any two of the ranks, we see that the normal directions of the hyperplanes are very different: direction 1 is that between  X  X efinitely relevant X  and  X  X rrelevant X ; direction 2 that between  X  X artially relevant X  and  X  X rrele vant X ; and direction 3 that between  X  X efinitely relevant X  and  X  X artially relevant X . processing of PCA. In the original space, the data might be more separable. It seems that this is no t the case, as will be seen in our experimental results in Section 4. depend on the features used and when more features become available the problem may disappear. It is difficult to anticipate what will happen when more features are available. In our document retrieval. Therefore, at least with the standard feature set, we observe the phenomena explained here. exists when kernels are used. We think, however, that the overall trend should not be drastic ally changed in the case. This is because as a general principl e, dividing the whole problem into sub-problems will lead to better solutions to the sub-problems, and further effectivel y combining the base solutions will lead to a better total solution. We propose an alternative to Ranking SVM for learning to rank, referred to as Multiple Hyperplane Ranker (MHR). MHR exploits multiple hyperplanes as base rankers and aggregates the rankings of the base rankers. Base rankers are prepared for all the rank pairs. Each base ranker is simply a hyperplane trained with ranking SVM for ranking instances from one rank pair. Rank aggregation is performed by using an ensemble of the base rankers. It is easy to verify th at MHR will be equivalent to RSVM, if we set the normal directions of all the hyperplanes to be the same. That is, MHR contains RSVM as a special case. data. We first partition the training set into several subsets by putting all the instance pairs from the same rank pairs into the subset of instance pairs cons isting of a document with rank s and a document with rank t . Using the instance pairs in each subset, we can construct one base ranker for the corresponding rank pair. Obviously, the number of instance pairs for each base ranker is smaller than that of the entire problem. Therefore, the space complexity and time complexity of the training in base ranker construction are lower than those of RSVM training on the entire set of rank pairs. Furthe rmore, each base ranker focuses on the rankings regarding to one rank pair, and thus the accuracy should be higher than that of RSVM. employ an existing method to create the ensemble, in either a supervised or an unsupervised fashion. If each of the base rankers can conduct accurate ranki ng on a subset of the data and appropriate aggregation method can create an ensemble model with high ranking accuracy. We can also incorporate prior knowledge into the rank aggrega tion process. For example, we can give higher weights to the base rankers which we think are important. Let  X  s,t denote that the parameter vector of the base ranker (RSVM) for the rank pair s and t . Then, we can build up a base ranker: where () s i x indicate an instance x i with rank s . for the K ( K -1)/2 rank pairs. For example if K is 4, then the base rankers are hyperplanes represented by{  X  1,2 ,  X  1,3 ,  X   X  3,4 ,} corresponding to rank pairs {(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)}. For example, instead of creating base rankers for all the rank pairs, we can create base rankers only for the adjacent rank pairs. We can also conduct sampling on the data and use the sampled data in base ranker creation. We employ two rank aggregation methods for creating an ensemble of base rankers: BordaCount [2][12] and Weighted BordaCount. D , generated by the base rankers in MHR, where l is the number of base rankers. positions in the ranking lists. For example, the score of an entity can be defined as the number of entities that are ranked lower than the entity in all the rankin g lists. Formally, the score of an entity x is defined as where ( ) #{ | , } entity x is ranked higher than entity y in ranking list  X  BordaCount sorts all the entities according to their scores. One advantage of BordaCount is that it can be run in linear time. where  X  k denotes weight. There are several ways to determine the weights. For example, one ca n use a separate validation set to tune the weights. It is al so possible to manually set the weights reflecting human X  X  prior knowledge. example, Median Rank Aggregation [12] and Markov Chain based Rank Aggregation [11]. Median Rank Aggregation sorts all the entities by the medians of their positions in different ranking lists. Markov Chain base d Rank Aggregation defines a Markov Chain model in which entities correspond to states and order relationships between entities correspond to transitions between states. It utilizes the stationary distribution of the Markov Chain to rank the entities. We applied our method MHR to information retrieval. Particularly we compared the performances of MHR with those of RSVM. When conducting the experiments, we performed 4-fold cross-validation. Thus, all the results reported in this section are those averaged over four trials. We used two information retrieval datasets: one is a public dataset named OHSUMED [17][18], and the other is a dataset for definition search, obtained from the authors of [31]. OHSUMED is a collection of documents and queries on medicine, consisting of 348,566 references and 106 queries. There are in total 16,140 query-document pairs upon which relevance judgments are made. In this dataset the relevance judgments have three levels:  X  X  efinitely releva nt X ,  X  X artially relevant X , and  X  X rrelevant X . For simplicity, we will use rank 1 to denote  X  X efinitely relevant X , rank 2 to denote  X  X artially relevant X , and rank 3 to denote  X  X rrelevant X . We extracted 30 features similar to those used in [4][26] from the query-document pairs. Examples of the features are shown in Table 1, including term frequency ( tf) , inverse document frequency ( idf ), document length ( dl ), their combinations, and BM25 score [28]. Table 1. Features extracted from the OHSUMED dataset c ( w , d ) represents frequency of query word w in document d ; C represents the entire collection; n denotes number of words in query; |.| denotes size of set; and idf (.) denotes inverse document frequency. This dataset comes from definition search [31], in which given a query (usually a noun phrase representing a terminology), the system returns a ranked list of paragraphs which are considered goodness as definition. This dataset provides three levels of judgment:  X  X ood definition X  (rank 1),  X  X ndifferent definition X  (rank 2) and  X  X ad definition X  (rank 3). There are about 170 queries and more than 2,000 definition candidates for each query. Features are the same as those in [31]. Table 2 gives example features. 1. &lt;query&gt; occurs at beginning of paragraph. 2. &lt;query&gt; begins with  X  X he X ,  X  X  X , or  X  X n X . 3. All the words in &lt;query&gt; begin with uppercase letters. 4. Paragraph contains predefined negative words, e.g.  X  X e X ,  X  X aid X ,  X  X he X  5. &lt;query&gt; contains pronouns. 6. &lt;query&gt; contains  X  X nd X ,  X  X r X ,  X  X f X ,  X  X or X , or  X , X . 7. &lt;query&gt; re-occurs in the paragraph. 8. &lt;query&gt; is followed by  X  X s an X ,  X  X s a X  or  X  X s the  X . 9. Number of sentences in paragraph. 10. Number of words in paragraph. 11. Number of the adjectives in paragraph. 12. Bag of words: words frequently occurring within a window after &lt;query&gt; We used two evaluation criteria in our experiments for ranking accuracy evaluations: Mean Average Precision (MAP) [1] and Normalized Discount Cumulative Gain (NDCG) [20][21]. They are measures widely used in IR. MAP is a measure on precision of ranking results. It is assumed that there are two ranks: positive (relevant) and negative (irrelevant). Precision at n measures accuracy of top n results for a query. Average precision of a query is calculated based on precision at n : where n is position, N is number of instances retrieved, pos(n) is a binary function indicating whether the instance at position n is positive (e.g., relevant). MAP is defined as AP averaged over all queries. In our experiments, the data sets have three ranks. We when calculating MAP. NDCG is designed for measuring ranking accuracies when there are more than two ranks. Given a query, NDCG at position n is defined as where n is position, R ( j ) is score for rank j , and Z normalization factor to guarantee that a perfect ranking X  X  NDCG at position m is 1. For queries for which the number of retrieved instances is less than n , NDCG is only calculated for the retrieved instances. We conducted experiments on document retrieval and definition search using MHR and RSVM with the two data sets. We denote the options of using BordaCount and Weighted BordaCount as MHR-BC and MHR-WBC respectively. The default parameter setting in the tool was used. In MHR-WBC, we tuned the weights in an ensemble by using the entre training dataset (note that base rankers should be trained with the subsets of data, while an ense mble should be trained with the entire data set). on the OHSUMED data set in terms of both NDCG and MAP. with more than 2% relative improvement. For NDCG@1, the relative improvement is as larg e as 7%. MHR-WBC shows even better performance, for whic h NDCG@1 is relatively 12% higher than that of RSVM. For MAP, we obtain similar improvements. These results indi cate that MHR can outperform RSVM. Moreover, using Weighted BordaCount is better than using BordaCount. Table 3 shows the relative improvements of MHR over RSVM (note that the results are averaged over four trials in cross validation). BM25 [28] over the 4 trials of OHSUMED data are 0.538, 0.518, and 0.243 separately. It is eas y to find that both RSVM and MHR are much better than BM25. search dataset. Again, MHR improves upon RSVM in ranking accuracy in terms of all measures. Particularly, MHR-WBC achieves about 15% relative impr ovement over RSVM in terms of MAP. Table 4 shows the re lative improvements of MHR over RSVM. In Section 2, we have shown, wi th an example, that the normal directions of hyperplanes (base rankers) for different rank pairs can point to completely different directions. This can be verified by looking at the cosine similarities between the hyperplanes. We use  X  to denote the hyperplane of RSVM, and  X   X  2,3 the hyperplanes of MHR for th ree rank pairs. We define the cosine similarity be tween two hyperplanes  X  i ,  X  j as Table 5 shows cosine similariti es between any two hyperplanes in RSVM and MHR. cosine similarities for the same hyperplane pairs do not change largely across trials, indicating that the normal directions of hyperplanes are stable. 2) The normal directions of the four hyperplanes point away from each other. An extreme case is that hyperplanes  X  1,2 and  X  2,3 are almost perpendicular on the definition search data (i.e. their co sine similarity is almost zero). This implies that using a single hyperplane to rank instances from different ranks may be inappropriate. To further examine the reason that MHR can achieve higher ranking accuracies than RSVM, we studied the Order Error Rates of RSVM and MHR on trai ning set. Order Error Rate (OER) is defined as follows. the OER of MHR, we used hyperplane  X  s,t to rank all the instance pairs in rank pair ( s , t ). That is, OER of RSVM is OER of a single hyperplane on three subsets of instance pairs, and OER of MHR is OER of three hy perplanes on three subsets of instance pairs separately. The last two rows are the average over four trials. ranking instance pairs than MHR. Especially for rank pair (1,2) of definition search data, OER of RSVM is as high as 15% to 20%. In contrast, OER of MHR is only about one third of that of RSVM. This is consistent with the results shown in Table 5(a): the normal directions of hyperplanes  X  and  X  1,2 differ largely. These results indicate that to address complex ranking problems like those in our experiments, the divide-and-conquer strategy is really needed. As aforementioned, in training MH R partitions data into subsets (hyperplane). In this way, it can reduce the computation time in training. We made a comparison on training time between MHR and RSVM. The experiments were conducted using SVM Light and on a PC with 2.2GHz CPU and 2G memory. Table 7 shows the results. in training when compared with RSVM. This is particularly true when the data size becomes larger. In the definition search dataset, there are about 10,000 instance pairs in each trial, and the total training time of MHR is about two-thirds of that of RSVM. In the OHSUMED datase t, there are about 500,000 instance pairs in each trial, and the total training time of MHR is only one-third of that of RSVM. validate the correctness of our claim: MHR can not only improve the rank accuracy but also training efficiency with its divide-and-conquer strategy. Th erefore MHR is a reasonably good choice for practical ranking problems. MHR also has certain shortcomi ngs. First, MHR requires that the training data is based on multi-level rank judgments, while Ranking SVM only requires that the training data contains pairwise ranking information, which can be automatically derived from certain data sources [23]. Second, the model of MHR is more complex than that of Ranking SVM, and thus there may be a higher probability of over-fitting for MHR than Ranking SVM. As a result, in th eory MHR needs more training data in learning than Ranking SVM. Learning to rank is to automatically create a ranking function which assigns scores to instances and then rank the instances by using the scores. Many methods have been proposed to address the issue. One major approach to learning to rank is that of Methods of the approach include Ranking SVM [4][18][23] [31], RankBoost [13], and RankNet [3][25 ]. (For other approaches, see [6][7][16][29].) Our method of MHR also falls into this category. There are several existing works [13][25] which are closely related to our current work. multiple  X  X eak X  rankers and linearly combine them to obtain a RankBoost, all the instance pairs are used in training. In MHR, instance pairs are separated into groups and used. In that regard, MHR is more efficient than RankBoost. There are also similarities between RankBoost and MHR. In RankBoost, each weak ranker is created so that it is complementary to the previous weak rankers. In MHR, each base ranker is a hyperplane constructed with a subs et of training data and thus is also complimentary to the other base rankers. which manages to improve the accuracies at the tops of rank lists by iteratively re-ranking the top ranked results. The major differences between MNR and MHR are as follows. (1) In MNR, the nested rankers are trained sequentially; there is a dependency of the current ranker on its prev ious rankers. As a result, the training of MNR cannot be conducte d in parallel, while this is not the case for MHR. (2) In MNR the size of training dataset for rankers shrinks step by step. In contrast, in MHR the training result, an instance pair is only used once in training of MHR, while it might be used multiple times in training of MNR. [4]. It creates a Ranking SVM m odel for document retrieval by modifying the loss function such th at the model is trained with more considerations on the tops of ranking lists and queries with a small number of associated documents. RSVM-IR treats different rank pairs differently by changing the loss function. The model for final ranking is a unified model. In contrast, MNR treats different rank pairs differently by introducing base rankers. The model for final ranking is an ensemble of base rankers. In this paper, we have proposed a new method called  X  X ultiple Hyperplane Ranker X  (MHR) for learning to rank. MHR takes the divide-and-conquer strategy to train multiple hyperplanes to rank instances and finally aggreg ates the ranking results given by the hyperplanes. MHR cont ains Ranking SVM as a special case, and is more flexible, effective, and efficient than Ranking SVM. Experimental results show that MHR can outperform Ranking SVM in ranking on two in formation retrieval datasets. 1) Base ranker construction is an important component of 2) Ranking aggregation is another important component of 3) We want to conduct more ex periments with large scale 4) We also plan to investigate the generalization ability of [1] Baeza-Yates, R., Ribeiro-Neto, B. Modern Information [2] Borda, J. C. M X moire sur les  X lections au scrutin. Histoire [3] Burges, C.J.C., Shaked, T., Renshaw, E., Lazier, A., [4] Cao, Y., Xu, J., Liu, T.Y., Li, H., Huang, Y., Hon, H.W. [5] Chirita, P.A., Diederich, J., and Nejdl, W. MailRank: using [6] Chu , W., and S. Sathiya Keerthi, New approaches to [7] Cohen, W.W., Scha pire, R.E., and Singe r, Y. Learning to [8] Collins, M. Ranking algorithms for named-entity [9] Dave, K., Lawrence, S., Pennock, D.M. Mi ning the peanut [10] Dietterich, T.G. and Bakiri, G. Solving multiclass learning [11] Dwork, C., Kumar, R., Naor, M., and Sivakumar, D. Rank [12] Fagin, R., Kumar, R., and Sivakumar, D. Efficient [13] Freund, Y., Iyer, R., Schapire, R., &amp; Singer, Y., An [14] Gyongyi, Z., Garcia-Molina, H., and Pedersen, J. [15] Harrington, E. F. Online Ranki ng/Collaborative filtering [16] Har-Peled, S. , Roth, D., and Zimak, D. Constraint [17] Hersh, W. R., Buckley, C., Leone, T. J., and Hickam, D. [18] Herbrich, R., Graepel, T., &amp; Obermayer, K. (2000). Large [19] Hsu, C.W., and Lin, C.J. A comparison of methods for [20] Jarvelin, K., &amp; Kekalainen , J. (2000). IR evaluation [21] Jarvelin, K., &amp; Kekalainen, J. Cumulated Gain-Based [22] Joachims, T. Making large-Scale SVM Learning Practical. [23] Joachims, T. Optimizing Search Engines Using [24] Kong, E.B., and Dietterich, T.G. Error-correcting output [25] Matveeva, I., Burges, C., Burkard, T., Laucius, A., and [26] Nallapati, R. Discriminative models for information [27] Pang, B., and Lee, L. Seei ng Stars: Exploiting Class [28] Robertson, S. E. Overview of the okapi projects, Journal of [29] Shashua, A., and Levin, A. Taxonomy of Large Margin [30] Weston, J. and Watkins, C. Multi-class support vector [31] Xu, J., Cao, Y.B., Li, H., Zhao, M. Ranking definitions 
