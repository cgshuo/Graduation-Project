 Latent Dirichlet Allocation (LDA) is a pop u lar model u sed to s u mmarise text u al doc-serve as the constit u ent topics covered by these doc u ments [1]. However, one weak-ness of LDA is that the s u mmary g enerated from the inp u t doc u ments contains g ener-al and what appears to be u nrelated to the topic [2]. The g ravity of this matter is more apparent in short s u mmaries constit u ted from wei g hty words in LDA s u mmaries. For example, Table 1 shows the first fo u r topics and their correspondin g sets of words for a collection of doc u ments on Du ri an . Each topic is assi g ned a topic wei g ht by LDA word wei g ht by LDA (shown in the brackets next to the words). The words are sorted red u ndant words s u ch as fr u it and tree in the s u mmary. 
First, LDA extracts co-occ u rrin g words in doc u ments to form topics. As s u ch, the doc u ments. Second, even tho ug h, the topics in LDA are not eq u i-probable (i.e., some topics are ass u med to have hi g her absol u te probability val u e than others) [4], the topic wei g hty LDA words distin gu ish the hi g h-content words in the doc u ments, there is still the need to restrict the n u mber of words in order to filter o u t the less important words in order to form a  X  g ood  X  short s u mmary. 
Cl u sterin g is a collection of data that is g ro u ped to g ether beca u se of their similari-ties. In a sense, it is a type of classification [5]. Since doc u ments abo u t similar topics and so doc u ment cl u sterin g is u sed to improve information retrieval [6]. inp u t doc u ments can be cl u stered accordin g to their similarity content before applyin g to LDA, the res u ltin g short s u mmary constit u ted from wei g hty words that are propor-tionately drawn from each cl u ster will si g nify a hi g her q u ality of the s u mmary. 2.1 Latent Dirichlet Allocation collection of doc u ments, where each doc u ment is considered as a collection of words. LDA attempts to provide a brief description of the words in the doc u ments by pre-s u mes that each doc u ment is represented as a mixt u re of latent topics, and each topic data itself. The g enerative process is o u tlined as follows: 1. For each topic, sample a distrib u tion over words from a Dirichlet prior 2. For each doc u ment, sample a distrib u tion over topics from a Dirichlet prior 3. For each word in the doc u ment  X  Sample a topic from the doc u ment's topic distrib u tion  X  Sample a word from the topic's word distrib u tion  X  Observe the word 2.2 Document Clustering Basically, there are two common types of doc u ment cl u sterin g techniq u es, i.e., hierar-chical and partitional cl u sterin g [5],[7]. Hierarchical clustering prod u ces a nested seq u ence of partitions, with one incl u sive cl u ster at the top and sin g leton cl u sters of doc u ments at the bottom. Each in-between viewed as a tree, also known as a dendo g ram. While the method scales linearly, it is sensitive to the order of the doc u ments in the collection. For example, Qlan g o [8] is a to cl u ster doc u ments. way partitionin g via repeated bisections rec u rsively applies 2-way partitional cl u ster-in g . While the method is relatively efficient, we need to specify the n u mber of cl u s-ment cl u sterin g tool. 2.3 Summary Evaluation When eval u atin g s u mmaries, there are two meas u res that are often considered: Reten-tion ratio and Compression ratio [10]. Retention Ratio shows how m u ch of the central information is retained, i.e., how m u ch of the information from the f u ll text (doc u ments) is retained in the s u mmary as described by Eq u ation (1). s u mmary information, and vice versa. The retention can be eval u ated by considerin g sen-Shannon Diver g ence P robability (JSD) [11], K u llback Leibler Diver g ence (KLD) [12] and similarity meas u res (s u ch as Cosine Similarity [13]) are few methods that are u tilised to eval u ate the effect of s u mmarisation. However, KLD is a non-symmetric meas u re. JSD is a symmetrical meas u re defined in terms KLD. JSD incorporates the idea that the distance between two distrib u tions cannot be very different from the avera g e of distances from their mean distrib u tion. A lesser diver g ence indicates that the devia-tion of the probability val u e is small. As a res u lt, a lower diver g ence probability val-ment collection. 
Eq u ation (2) defines the JSD meas u re J, where P and Q are two probability distri-b u tion; D refers to KLD meas u re between probability distrib u tions R and S (see Eq-u ation (3)); and A is the mean distrib u tion of P and Q (i.e., A = [ P + Q] / 2). 
Cosine Similarity calc u lates the similarity between two doc u ments: A and B. The meas u re calc u lates the cosine of the an g le  X  between them, which is done by calc u lat-in g the dot prod u ct for the cosine  X  , which is shown by Eq u ation (4). 
However, when compared to KLD and Cosine Similarity, JSD o u tperforms the u se of model s u mmaries for comparison p u rposes [15]. Conseq u ently, we u sed JSD the s u mmary by meas u rin g the  X  X loseness  X  between probability models of the collec-Inp u t similarity Metrics (SIMetrix) tool [14] is u sed to calc u late the JSD val u es of the s u mmaries. Compression Ratio is the ratio of the len g th of the compressed text (s u mmary) to the len g th of the f u ll text [16]. It is represented by Eq u ation (5) as shown below. 
The shorter a s u mmary, the hi g her is its CR. However, a hi g h CR means less in-formation is retained, which s ugg ests that relevant text information may have been discarded. 
Therefore, it is obvio u s that retention and compression are inversely proportional to each other. The strate g y is to find a balance when considerin g both these proper-way, we can objectively meas u re the content q u ality of the short s u mmaries based on JS P meas u res alone. We propose a Cl u stered-LDA ( Cl u sL D A ) that adopts the LDA approach to s u mmarise framework of the proposed method is shown in Fi g . 1. The idea is that a collection of words with hi g her probabilities (wei g hts) in each s u mmary will be extracted to form the representative s u mmary of the whole collection, s w . proach. 4.1 Sample Documents The sample doc u ments are extracted from forty-two (42) websites on crops describin g of web bookmarks that link to the doc u ment so u rces u sed in this research. 
Since we are only interested in text s u mmarisation, the website contents are con-verted into text format in the experiment. The content from each website is treated as a sin g le doc u ment. 4.2 Text Processing Tools The LDA analysis is performed u sin g the MALLET toolkit [17]. For sake of valida-Qlan g o [8] and DataNinja [9] are u sed to cl u ster the doc u ments. 4.3 Experiment Design which determines the k val u e based on the inp u t text size. DataNinja (DN+LDA), and cl u sterin g u sin g Qlan g o (QL+LDA). 
The three experiments involvin g Cl u sL D A (DN+LDA and QL+LDA) and U n -cl u sL D A are cond u cted on three datasets of varyin g text sizes: Small (14 doc u ments;  X  15,000 words), Medi u m (20 doc u ments;  X  30,000 words) and Lar g e (42 doc u ments;  X  60,000 words). Therefore, in total nine cases are analysed. The n u mbers of cl u s-ters, k for the three datasets are he u ristically determined by DataNinja as 3, 4 and 5, respectively. 
In order to prod u ce the representative s u mmary for a collection, we first set combine the red u ndant words and their correspondin g word wei g hts ( ww ) 2 ; th u s, leav-based on their word wei g hts in each topic, which are re g arded as g ood representative date words, the n u mber of words in the representative s u mmary of U n cl u sL D A for the Small dataset, m is 100. Note that m is approximately 0.67% of the inp u t text size, i.e., the predetermined compression ratio, CR . means there are three or more s u mmaries to consider in the case of latter. For exam-of the three cl u sters in the Cl u sL D A is 5, which means there are 15 * 20 = 300 candi-date words to consider. So, we sort the candidate words of all n topics of each cl u ster based on their topic and word wei g hts ( t w * ww ) and extract the candidate words from each cl u ster that is proportionate to the size of the cl u ster in order to form a represent-ative s u mmary of the collection of size m words. 
Table 2 describes the information abo u t the three experiment datasets. Note that the inp u t text size. (DN+LDA and QL+LDA) u sin g JSD and CR. The res u lts of the Small, Medi u m and Lar g e datasets are shown in Tables 3, 4 and 5, respectively. A lower JSD val u e si g ni-fies a hi g her q u ality of the s u mmary. Beca u se the CR val u e is fixed, we can objective-ly meas u re and compare the content q u alities of the s u mmaries of different text sizes. For the Small dataset, the JSD val u e for the Cl u sL D A u sin g QLan g o, i.e., QL+LDA is the smallest at 0.3888. In fact, both DataNinja and QLan g o cl u stered-LDA (i.e., DN+LDA and QL+LDA) have a smaller JSD val u e than U n cl u sL D A for DN+LDA, the JSD meas u re has improved by only 0.1%, while for QL+LDA, the improvement is 0.5%. 
For the Medi u m and the Lar g e datasets, the JSD val u e of U n cl u sL D A is the smal-dataset, and a decline of 5.5% and 4.8% for the Lar g e dataset, when u sin g the Data-Ninja and Qlan g o, respectively. The st u dy tests the hypothesis that if the inp u t doc u ments can be cl u stered accordin g to their similarity content before applyin g to LDA, the res u ltin g s u mmary constit u ted Medi u m and Lar g e. The content q u ality of the s u mmaries of U n cl u sL D A and Cl u sL-D A (DN+LDA and QL+LDA) are eval u ated u sin g JSD (c.f. RR) and CR. not necessarily help to improve the content q u ality of short s u mmaries. comparison of the res u lts. Second, the size of the Lar g e dataset can be increased. If present 0.67% of the inp u t text size. Acknowledgement. This project is s u pported by the Universiti Teknolo g i MARA  X  s Cl u ster Grant No. 600-RMI/DANA 5/3/CG (12/2012). 
