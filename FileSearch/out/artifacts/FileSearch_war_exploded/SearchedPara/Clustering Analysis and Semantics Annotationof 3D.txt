 With the proliferation of 3D models, 3D mo del retrieval emerges as an important research field in the last decade. The performance of 3D model retrieval can be greatly improved by utilizing semantics[11]. It is well accepted that the semantics of an object is related to human X  X  understanding. And the semantics is generally represented by the keywords at present.

Compared to the document retrieval, 3 D model retrieval lacks valuable text information. While it is too expensive for experts to annotate semantics of a large amount of 3D models, it encounters quality problem to extract semantics from supplemental texts like saving path or file name of a 3D model. Therefore, it be-comes an important topic to acquire sema ntics of 3D models semi-automatically or automatically.

Since feedbacks reflect users X  understanding of the retrieved objects, they contain semantics. User feedback can be c lassified into two categories: (1) implicit feedback or operational information, such as mouse click; (2) relevance feedback, which can be further divided into the positive and the negative feedback.
Previous researches usually utilize relevance feedback in similarity computing [1], especially in image retrieval. And a few works also adopt relevance feed-back in semantics annotation [3]. Since users is unwilling to provide relevance feedback, ref. [5] classifies the queries based on user X  X  clicks.

However, only a few researches focus on 3D model retrieval. And the rela-tionship between implicit feedback and semantics of 3D model still needs to be explored. It is not an easy task, because u sers X  operations vary differently and contain lots of noises.

This paper proposes a strategy novel based on complex network to analyze semantics clusters and to annotate semantics of 3D models according to noisy implicit feedbacks.

This paper first constructs a weighted se mantics network of 3D models accord-ing to implicit feedbacks based on our previous work[4]. Thus, the semantics of 3D models is reflected by their topology and clustering property in the complex network and will be represented by sever al keywords after semantics annota-tion. Then, the paper proposes a robust agglomerative hierarchical clustering algorithm of complex network to discover semantics communities with different granularity. The algorithm is named CACNSC. Finally, based on the hierar-chical structure of semantics relationship, the semantics of all 3D models can be automatically annotated according to that of a few models whose semantics can be already existed or decided manua lly. The proposed strategy requests no additional work from users.

In addition to the simulated dataset with lots of noise, the proposed method is verified by the real feedbacks of Princeton Shape Benchmark[8] (termed PSB in the following parts). PSB is a benchma rk of 3D model retrieval. Serial exper-iments show that the proposed method performs quite well not only in semantic clustering but also in annotation. As stated in our previous work[4], there are two phenomena coexisting in im-plicit feedbacks: the random of single feedback and the commonness of lots of feedbacks. Therefore, high quality semantics can be revealed by utilizing lots of feedbacks. Our preliminary research has verified this assumption.

This section introduces the weighted c omplex network to express semantics relationships among 3D models, which are constructed based on implicit feed-backs. A feedback can be a user oper ation or a positive feedback.

Suppose there is a multimedia database O = { o 1 ,o 2 ,...,o N  X  1 } with N 3D models. The database is categorized into l semantics classes { A 1 ,A 2 ,...,A l } . These classes contain n 1 ,n 2 ,...,n l 3D models respectively. Let q r be the r -th query, where q r can be a set of keywords, a sample 3D model etc.. Terming the feedback of q r as ( q r ,V r ), where V r is a N dimensional vector; V i r =1,iff o i appears in the feedback of q r ,otherwise V i r =0.Andall N fb feedbacks are recorded as a N  X  N fb matrix M fb . Fig. 1.(b) shows an example of M fb , which is extracted from 5 feedbacks of Fig. 1.(a) with O = { o 0 ,o 1 ,o 2 ,o 3 } .And ( q We define the semantics relationship reflected by implicit feedbacks as follows:
Therefore, we define the seman tics relationship matrix M sem among 3D mod-elsasfollows: Definition 2. Define the semantics relationship matrix as M sem =[ a ij ] N  X  N , where a ij = sem ( o i ,o j ) if i = j ,otherwise a ij =0 .
 Fig. 1.( c )showsthe M sem obtained from the feedbacks of Fig. 1.( b ). since o 0 and o 1 appear in q 1 and q 4 , sem ( o 0 ,o 1 )=2.
 The matrix M sem can be easily converted to a weighted complex network G sem . Its node v i corresponding to a 3D model o i ,theedge e ( i,j ) is the edge Other notations of a complex network[9] will also be used in the following parts: the degree of node v i d ( v the edges connecting to v i and the average weight w ( v to v i .

Therefore, the analysis of implicit fee dbacksisconvertedtotheanalysisof semantics complex network G sem . The construction of G sem needs no text in-formation. And G sem evolves with the accumulation of feedbacks. It is an unsupervised learning problem to discover semantics clusters in G sem without any prior knowledge of { A 1 ,A 2 ,...,A l } . A cluster in a complex net-work is also termed as a community or a group .Ref.[7]showsthatthereis a hierarchical structure in many complex networks. Although many clustering algorithms have been proposed, their performances are still unstable for different problems.

This section introduces a robust hierarchical agglomerative clustering algo-rithm based on semantics core for analyzing 3D models semantics. The algo-rithm is designed to handle weighted net works with different local topologies. Based on the hierarchical clustering pro cedure, a binary tree reflecting semantics accumulation under different granularity can be obtained in section 4. 3.1 Characteristics of Weighted Semantic Complex Network Previous researches on complex network clustering concentrate on analyzing non-weighted network. However, there are apparent differences between a non-weighted community and a weighted comm unity. For instance, it is assumed that the connectivity of a intra-community is higher than that of inter-communities is an example, where the round nodes and the rectangle nodes form two com-munities. But the inter-connectivity b etween them is not lower than the intra-connectivity in any community, if the edge weight is not taken into consideration.
Meanwhile, a weighted semantics network has the following features: (1) Local topologies such as the size of communities are affected by the size (2) Nodes/models in the weighted network have quite different topology prop-According to these features, the clustering method should take the local topol-ogy into consideration. Otherwise, small communities existing besides big ones, or a loose but big community neighboring to the compacted ones, won X  X  be recognized. And the special nodes should have the priority to be detected. 3.2 The Definition and Detection of Semantic Core Since the node with high w ( v set of these nodes as a semantics core.
 v  X  N And v i is called the centroid of Core ( v i ).

It is easy to prove that  X  i, j, Core ( v i )  X  Core ( v j )=  X  . According to the definition, the connectivity degree of a semantics core evaluated by w is higher than that of its neighbors. This is a local constraint to adapt different local topologies in semantics network. Fig.2.( b ) shows the semantics cores detected from Fig.2.( a ). It shows that although the connectivity in a core is higher than that of its neighbors, it isn X  X  the globally highest, such as Core ( v 2 ). The algorithm Core Detection detecting semanti cs core is listed as follows. After core detection, severa l small clusters are obtained before further hierarchi-cal clustering. To further reduce the hier archical clustering times, the detected semantics cores are expanded. first, G sem is replaced by G sem  X  core by treating each semantics core as a single node. Then, the weights of edges between seman-tics cores Core ( v i )and Core ( v j ) are updated according to formula (1). Finally, we perform Core Detection( G sem  X  core ) to expand cores. Algorithm 1. Core Detection( G sem ) 3.3 Similarity Computation between Communities Similarity computation is the key of clustering. To evaluate the local feature of a community C i , define the density den ( C i ) as the average weight of all edges of C . Where | C i | equals the number of 3D models belong to C i and den ( C i )showsthe relationship between the edges and their weights in C i .

In the process of hierarchical clust ering, the connectivity between C i and C j should be one of the highest if they are the candidates to be merged, while the local topology of C i and C j and that of the inter-part between C i and C j should be similar. In this case, the new community created by merging C i and C j can have similar intra-topology.

Define the factor that reflects the difference between local topology of C i and that of the inter-part between C i and C j as follows: Where w ( C formula (3),  X  den ( C i )  X  1. The smaller the value of  X  den ( C i )  X  1is,themore different the topologies of C i and the inter-part between C i and C j is. So does  X 
Therefore, the similarity between two c ommunities is computed as formula (4), which not only contains the connect ivity degree between two communities but also considers the difference of local topology dynamically in clustering. 3.4 CACNSC Algorithm Finally, the paper proposes a robust agglomerative hierarchical algorithm, the C lustering A lgorithm for C omplex N etwork based on S emantics C ore, named CACNSC. The algorithm first detects and expands semantics core. A semantics core is treated as a whole in the following clustering process, which reduces the complexity of hierarchical clustering. In the clustering, the most similar clus-ters based on connectivity and local topology are merged, until only K clusters remain. The overview of CACNSC is as follows: Algorithm 2. CACNSC( G sem , K )
Fig.2( d ) shows the hierarchical clustering process of Fig.2.( a ) with K =2. The computation complexity of CACNSC is analyzed as follows: the sorting complex-of hierarchical clustering is O ( N 2 ) and the complexity of similarity computation of each merged community with others is O (( N  X  k )  X  N ). Thus the overall complexity is O ( N 2 ).

Compared with traditional clustering methods and clustering algorithms of complex network, CACNSC only need one parameter K and has relative low complexity. For instance, the complexity of traditional hierarchical clustering is O ( N 2 ). The complexity for FN[2] is O (( M + N ) N ), where M is the number of edges in the network and is usually much larger than N .Thecomplexityof spectral clustering[13] is O ( KN 3 ). Semantics-based 3D model retrieval requires accurate semantics, which is usu-ally represented by several keywords. B ased on the semantics clustering tree of Section 3, this section aims at annotating automatically according to the se-mantics of limited 3D models. This section also states a method to recommend a few important 3D models for expert labeling, which forms a good foundation for automatic annotation.
The hierarchical clustering proces s of CACNSC forms a semantics tree T , which shows the semantics accumulation under different granularity. Fig.2.( d )is an example. Leaves of T correspond to the nodes that can be classified into 3 classes: (1) core node corresponding to semantics core, such as node Core ( v 1 ) and Core ( v 2 ) in Fig.2.( d ). The weight of path that connects a core node with its child is equal to the weight of the corresponding edge in a complex network. For instance, the weight between tree node Core ( v 1 )and v 3 is 3. (2) Expanded that connects a v core + with its child equals the weight of corresponding edge in complex network in G sem  X  core . For example, the weight between v core ( v v is 1.33. (3) Non-leaf node is created by me rging two communities in clustering. And the weight of the path that connects a non-leaf node with its child is equal to the similarity between its two children according to formula (4).
Therefore, semantics annotation of 3D models is equivalent to decide se-mantics of all leaf nodes in T . And the semantics of a model o i is termed as SM ( o i )= { keyword i 1 ,...,keyword i r } with r =1 in the paper, which means us-ing just one keyword as semantics. Since a community is a collection of models having similar semantics, we treat a community as the basic unit for annota-tion. After extracting a community C i as a sub-tree T i from T , the semantics annotation algorithm is stated as follows:
If a community has no semantics-known node, the semantics of its nodes is decided by its most similar community. Fig.3.( a ) is an example of pruned tree of where only two nodes v 8 and v 9 have initial semantics  X  X  X  and  X  X  X  respectively. At the first step, v 9  X  X  brother and its father are annotated with  X  X  X . Then, v 6 is annotated with  X  X  X , since the path weight between v 6 and v 9  X  X  father is the highest. All nodes in Core ( v 1 ) are annotated with  X  X  X  according to the semantics of v 8 , although no node of Core ( v 1 ) is semantics known.
The complexity of semantics annotation is analyzed as follows: semantics clus-tering tree can be constructed during clu stering and in the worst case a tree with 2 N  X  1 nodes are obtained; it costs O (2 N  X  1) to traverse T , therefore it costs O ((2 N  X  1)( N  X  N known )) at most, where N known is the count of semantics-known nodes. Thus, its complexity is O ( N 2 ). It is much lower than an annotation method based on the shortest route of a graph, whose complexity is O ( N 3 ). Algorithm 3. Semantic Annotation( T i )
Automatic semantics annotation ca nnot be performed when no model has semantics. Therefore, this paper r ecommends a few important 3D models for expert labeling. The importance of a node can be decided by the ranking tech-nology, such as PageRank [14]. Instead of applying PageRank to analyze the whole network, PageRank is used to recommend the most important node of each community as a representative. And K representatives are recommended. Since K N , the labeling cost can be greatly reduced. The experiment adopts a simulated dataset and the real feedback dataset of Princeton Shape Benchmark [4].

The simulated dataset forms a weighted complex network with quite different local topologies and lots of noises. The dataset contains 1000 feedbacks of 1000 objects, which belong to 6 classes with n 1 = 400 ,n 2 = 250 ,n 3 = 150 ,n 4 = 100 ,n 5 =50and n 6 = 50. Fig.4.( a ) visualizes the relationship matrix M sem .
Three users (two men and one woman) provide 2721 feedbacks for 907 3D models ranging from m0 to m906 of PSB. The manual classification  X  X oarse-1 X  is treated as ground truth, which classifies these models into 60 semantics classes. 5.1 Clustering Performance We use the criterions Entropy and Purity[15] to evaluate the clustering perfor-mance. The definition of entropy and purity is as follows: Where l is the count of the artificial classes and K is the number of result clusters, n j i is the count of the data which belongs to the j -thclassandappears in the i -th cluster. The smaller the Entropy is and the bigger the Purity is, the better the clustering performance is.

Table 1 shows the comparative result between CACNSC and other clustering algorithms. The spectral clustering method satisfying normalized cut [13], the FN method which is an expanding of modularity evaluation function in weighted network based on the idea of ref.[12] and X-means [17] are used to compare. Clus-tering result based on combined shape feature [16] that performs much better ing results of CACNSC algorithm and spectral clustering algorithm. Obviously, CACNSC algorithm performs better for both real data and simulated data. 5.2 Semantics Annotation Performance The automatic annotation performance is evaluated based on the clustering re-sult of CACNSC.

First, we test the annotation performance using different number of semantic-known objects. We randomly appoint 5%, 10%, 20% and 50% objects of simu-lated data and PSB as semantics-known models. For each ratio, the sampling process repeats 20 times to avoid performance fluctuation. Fig.5.( a )showsthat the average precision is over 85% when only 5% objects have semantics for the simulated dataset.

Second, we test the annotation performance based on different clustering re-sults. Fig. 5. ( b ) is the annotation evaluation of PSB, and the clustering results of CACNSC are obtained with K =50 based on the feedbacks sampled by ra-performed according to the sampled semantics-known objects by ratio 5%, 10%, 20% and 50%. Even with only 1 3 feedbacks, the precision achieves 65% with only 5% semantics-known models.

Third, the annotation performance based on the semantic of recommended ob-jects is evaluated. The annotation precision reaches 80.2% for simulated dataset, when only 6 nodes are labeled. And Fig.5.( c ) shows that the annotation preci-sion of PSB achieves 75% based on the semantics of 50 recommended models while the feedbacks are sampled. We can see that the precision of automatic annotation is quite good, while the expert labeling is better. The paper explores a complex-network-bas ed strategy to extract semantics rela-tionships, to analyze semantic clusters and to annotate precise semantics for 3D models. The semantics network comes from the implicit feedbacks. The proposed strategy performs quite well in semantics analysis and automatic semantics an-notation. Our future work will concentrate on the evolution model of semantic complex network, which evolves with the increment of feedbacks. Acknowledgments. This work is sponsored by the National Key Technology Research and Development Program of the Ministry of Science and Technology of China under grant number 2009BAH42B02, 2012BAH08B02, by the Natural Science Foundation of China unde r grant number 71272216, 60903080 and by the Fundamental Research Funds for the Central Universities under grant number HEUCF1212, HEUCF1208.

