 1. Introduction
In the past decade, the quantity of user-generated contents on the Internet has been growing exponentially. Social Media platforms, such as Facebook, Twitter, Flickr and LinkedIn, as well as commercial sites, like Amazon and Booking.com offer their users the possibility to share their experiences and opinions on topics ranging from economics, to politics, products,
VIPs and globally-critical events. The value of such unbiased, real-time user-generated content has been shown to be tremendous, with applications in Marketing, Decision Support Systems, Politics and Public Policy support, disaster and crisis management, etc. Since the high volume of opinionated information makes its manual processing virtually impossible, systems have been developed to treat texts and process the opinions they contain automatically, in the context of the Subjectivity and Sentiment Analysis tasks, within the field of Natural Language Processing (NLP).

Subjectivity and Sentiment Analysis typically aim at detecting subjective,  X  X  X rivate X  X  states (i.e. opinions, emotions, 2000 ) and subsequently classifying them according to their polarity.

A lot of research has concentrated on developing methods for subjectivity and sentiment analysis in different types of texts and with different applications in mind. Nonetheless, the majority of the research has concentrated on texts written  X  in English, since it is the language with most processing tools and annotated resources. While for some applications analyz-ing only opinions written in English is enough, for others, such as news monitoring, being able to detect and comparatively analyze opinions expressed in different sources is an important requirement.

This paper presents the experiments carried out for the Sentiment Analysis in Tweets task of SemEval 2013 and the modifications performed to the English system for the participation in the TASS 2013 ). SemEval 2013 Task 2 was entitled  X  X  X entiment Analysis in Tweets X  X  and is focused on English. TASS is an experimental evaluation workshop for sentiment analysis and online reputation management systems developed with a focus on Spanish.
We present the approaches followed in these competitions and their adaptation to new languages, as well as additional experiments carried out to improve the results obtained.

In the SemEval 2013 task 2, participating systems had to classify snippets from or entire tweets according to their polarity criminate them from the objective ones. To tackle this task, we applied an approach based on machine learning by trying different feature combinations, using dictionary-based features and adding external data for training obtained through machine translation. The main motivation for the experiments in the TASS competition was to evaluate the manner in which our approach (applied for English and combinations of data from different languages) could perform for Spanish. It followed titions and in the subsequent experiments show that the use of supervised learning with additional dictionary features and external training data obtained from machine translated texts might be considered good strategies to generate learning data for polarity classification systems.
 The rest of the paper is organized as follows: the following section deals with the state of the art in sentiment analysis. in Section 7 and Section 8 , respectively. 2. State of the art
The work presented herein is related to research in NLP on short informal text classification and multilingual text classification.

As regards short informal text classification, Go, Bhayani, and Huang (2009) performed one of the first studies involving ative tweets. Following their initial findings, Read (2005) employed the method to generate a corpus of sentiment-annotated approaches (SVM, Na X ve Bayes and Maximum Entropy) and various sets of features and conclude that the simple use of unigrams leads to good results, but it can be slightly improved by the combination of unigrams and bigrams.
In the same line of thinking, Pak and Paroubek (2010) also generated a corpus of tweets for sentiment analysis, by selecting positive and negative tweets based on the presence of specific emoticons. Subsequently, they perform different experiments to classify sentiment in the obtained corpus and conclude that the best settings include the use of a Na X ve Bayes classifier with unigrams and part-of-speech tags.

Another approach on sentiment analysis in tweets is that of Zhang, Ghosh, Dekhil, Hsu, and Liu (2011) . Here, the authors adopt a hybrid approach, combining supervised learning with the knowledge on sentiment-bearing words, which they extract from the DAL sentiment dictionary ( Whissell, 1989 ). Their pre-processing stage includes the removal of retweets, translation of abbreviations into original terms and deleting of links, a tokenization process, and part-of-speech tagging. They employ various supervised learning algorithms to classify tweets into positive and negative, using n -gram features with
SVM and syntactic features with Partial Tree Kernels, combined with the knowledge on the polarity of the words appearing in the tweets. The authors conclude that the most important features are those corresponding to sentiment-bearing words. information on the context of the tweet to its text (e.g. the event that it is related to). Subsequently, they use SVM and General Inquirer and perform a three-way classification (positive, negative, neutral).

In SemEval 2013, a task was organized on sentiment analysis in tweets ( Wilson et al., 2013 ). Here, the best-performing systems used additional dictionaries that were built from large data sets and word-emotion association dictionaries built from millions of tweets. From here, we can see that the use of dictionaries to improve the features used in supervised learning is a good strategy.
The TASS evaluation campaign has also been organized in 2012. The best participating system employed 5 classifiers to distinguish among the 5 classes of polarity (among themselves) and the objective class (separately). The training and test data were both in Spanish.

With regard to sentiment analysis in different languages, several authors have proposed approaches to deal with resource
Banea, Mihalcea, and Wiebe (2008) apply bootstrapping to build a subjectivity lexicon for Romanian, starting with a set of 60 words which they translate and subsequently filter using a measure of similarity to the original words, based on Latent
Semantic Analysis (LSA) Deerwester, Dumais, Furnas, Landauer, and Harshman (1990) scores. Another approach to mapping subjectivity lexica to other languages is proposed by Xiaojun (2009) , who uses co-training to classify un-annotated Chinese reviews using a corpus of annotated English reviews. He first translates the English reviews into Chinese and subsequently back to English, then performs co-training using all generated corpora. Kim, Li, and Lee (2010) create a number of systems annotated for subjectivity analysis (MPQA), the subjectivity clues (Opinion Finder) lexicon and re-train a Naive Bayes classifier that is implemented in the Opinion Finder system using the newly generated resources for all the languages considered. Banea, Mihalcea, and Wiebe (2010) translate the MPQA corpus into five other languages (some with a similar etymology, others with a very different structure). Subsequently, they expand the feature space used in a Na X ve Bayes classifier using the same data translated to 2 or 3 other languages. Finally, Steinberger et al. (2011) and Steinberger,
Lenkova, Kabadjov, Steinberger, and van der Goot (2011) create sentiment dictionaries in other languages using a method called  X  X  X riangulation X  X . They translate the data, in parallel, from English and Spanish to other languages and obtain dictionaries from the intersection of these two translations. 3. Proposed approaches 3.1. Sentiment classification in English tweets For the classification of English tweets, we employ two different approaches: (a) one based on supervised learning using
Support Vector Machines Sequential Minimal Optimization (SVM SMO) using unigram and bigram features; and (b) a hybrid approach, based on supervised learning with a SVM SMO linear kernel, on unigram and bigram features, but exploiting as features sentiment dictionaries, emoticon lists, slang lists and other social media-specific features. SVM SMO was preferred due to the computation speed. We do not employ any specific language analysis software. The aim is to be able to apply, in a straightforward manner, the same approach to as many languages as possible. The approach can be extended to other languages by using similar dictionaries that have been created in our team ( Steinberger et al., 2011; Steinberger, Lenkova,
Kabadjov et al., 2011 ). 3.2. Sentiment classification in Spanish tweets
Two main approaches were proposed for the experiments carried out in TASS. For the dictionary-based approach, we took into account the linguistic peculiarities of tweets, regarding spelling, use of slang, punctuation, etc., and also the sentiment-bearing words from the training data were replaced with a unique label. In this way, the sentence  X  X  X  love roses. X  X 
In the same line of thought, we also replaced modifiers with unique corresponding labels. The sentiment dictionary generated by Steinberger, Lenkova, Kabadjov et al. (2011) was used to replace the sentiment-bearing words contained in the tweets with unique labels describing their polarity. As such, words that were found in the  X  X  X igh positive X  X  category in the dictionary were replaced with the label  X  X  X POSITIVE X  X , those that were in the  X  X  X ositive X  X  category were replaced with and  X  X  X EGATIVE X  X  respectively. In the same manner, negators, intensifiers and diminishers, as identified by the sentiment dictionary, were replaced with the labels  X  X  X EGATOR X  X ,  X  X  X NTENSIFIER X  X  and  X  X  X IMINISHER X  X . Finally, we replaced the emoticons with the sentiment value they had, giving them positive, high positive, negative or high negative labels and replaced the repeated punctuation signs  X  X ! X  X ,  X  X ? X  X ,  X  X . X  X  (more than 2 appearances) with the unique labels  X  X  X ULTIEXCLAMATION X  X ,  X  X  X ULTIINTERROGATION X  X  and  X  X  X ULTISTOP X  X . As can be seen from the results obtained, although the dictionaries used (for approach was the best-performing one.

For the second approach we also tested the performance of the sentiment classification by applying 4 separate pairs of versus very negative). Our aim was to see if the use of separate classifiers (in a cascade) could improve the performance, by fitting the data more appropriately.
Finally it is noteworthy that for both approaches we used simple heuristics to select the features. Although feature selec-tion algorithms are easy to apply when a data mining environment is used, the final choice is influenced by the data at hand in the classification model based on the condition that they should occur at least twice in the training set. 4. Data
Several data sets have been used to carry out the experiments. They are briefly presented in the next subsection. Further on, different pre-processing steps applied to these data sets are also explained. 4.1. Data sets 4.1.1. Data set for English
The data set of tweets put forward for the SemEval 2013 Task 2 covered a wide range of topics ( Wilson et al., 2013 ). Topics included a mixture of entities (e.g., Gadafi, Steve Jobs), products (e.g., Kindle, Android phone), and events (e.g., Japan earthquake, NHL playoffs). It had the following structure (see Table 1 ): 4.1.2. Data sets for Spanish
Two main data sets for learning purposes have been used in our experiments: the general corpus training set of TASS 2013 and the data set of tweets used in Task 2 (B) of the SemEval 2013 evaluation campaign. The first one was provided by the
TASS 2013 organizers for the sentiment analysis at global level task.
Spanish about well-known personalities in politics, economics, communication or culture, between November 2011 and March disagreement of the expressed sentiment within the content, with two possible values: AGREEMENT and DISAGREEMENT. This negative sentiments at the same time. On the other hand, a set of topics has been defined based on the thematic areas covered these topics. Table 2 shows the statistics of the general corpus provided by TASS 2013.

The sentiment-annotated tweets in the SemEval 2013 Task 2(B) were provided by the task X  X  organizers. obtained the Spanish translation by applying Machine Translation (MT) using the Google MT engine. version was also included in the training data set for our TASS experiments. 4.2. Data pre-processing for English
The sentiment analysis process for English contains two stages: preprocessing and sentiment classification. The preprocessing stage contains the following steps:
Repeated punctuation sign normalization (RPSN). In the first step of the preprocessing, we detect repetitions of for the fullstops,  X  X  X ultiexclamation X  X  in the case of exclamation sign and  X  X  X ultiquestion X  X  for the question mark and spaces before and after.
 Emoticon replacement (ER). In the second step of the preprocessing, we employ the annotated list of emoticons from
SentiStrength 7 and match the content of the tweets against this list. The emoticons found are replaced with their polarity ( X  X  X ositive X  X  or  X  X  X egative X  X ) and the  X  X  X eutral X  X  ones are deleted.

Lower casing and tokenization (LC&amp;N). Subsequently, the tweets are lower cased and split into tokens, based on spaces and punctuation signs.

Slang replacement (SR). The next step involves the normalization of the language employed. In order to be able to include the semantics of the expressions frequently used in Social Media, we employed the list of slang expressions from dedicated sites. 8 This step is especially relevant to SMS texts, whose language in their original form has little to do with language employed in ordinary texts.

Word normalization (WN). At this stage, the tokens are compared to entries in Roget X  X  Thesaurus. If no match is found, repeated letters are sequentially reduced to two or one until a match is found in the dictionary (e.g. this form are maked as  X  X  X tressed X  X .
 Affect word matching (AWM). Further on, the tokens in the tweet are matched against three different sentiment lexicons:
General Inquirer, LIWC and MicroWNOp, which were previously split into four different categories ( X  X  X ositive X  X ,  X  X  X igh posi- X  X  X positive X  X  and  X  X  X negative X  X .

Modifier word matching (MWM). Similar to the previous step, we employ a list of expressions that negate, intensify or diminish the intensity of the sentiment expressed to detect such words in the tweets. If such a word is matched, it is replaced with  X  X  X egator X  X ,  X  X  X ntensifier X  X  or  X  X  X iminisher X  X , respectively.

User and topic labeling (U&amp;TL). Finally, the users mentioned in the tweet, which are marked with  X  X  X  X  X , are replaced with  X  X  X ERSON X  X  and the topics which the tweet refers to (marked with  X  X # X  X ) are replaced with  X  X  X OPIC X  X .

Once the texts are preprocessed, they are passed on to the sentiment classification module. We employed supervised learning using Support Vector Machines Sequential Minimal Optimization (SVM SMO) ( Platt, 1998 ) with a linear kernel, employing boolean features  X  the presence or absence of unigrams and bigrams determined from the training data (tweets that were previously preprocessed as described above) that appeared at least twice. Bigrams are used especially to spot the influence of modifiers (negations, intensifiers, diminishers) on the polarity of the sentiment-bearing words. We tested different parameters for the kernel and modified only the C constant to the best value determined on the training data (5.0). 4.3. Data pre-processing for Spanish
The training data have been preprocessed by discarding the stop words and applying a stemming process. For removing the stop words, the list for the Spanish language provided by Snowball words included in the original Snowball list, 228 were removed, resulting in a final list of 97 stop words.
Regarding the stemming process, the 3.2 version of TreeTagger different variants of the same type of word by using one unique lemma even for different gender. Some examples of these el intento , buen d X a ) bueno d X a , etc.

Taking into account these pre-processing steps, several training data sets were generated: tassTrain-base: original training TASS data without applying any pre-processing step. tassTrain-lemma: original training TASS data without removing stop words but applying the stemming process. tassTrain-lemmaStop: original training TASS data + stopper + stemmer. semevaltassTrain-base: tassTrain-base + tweets of SemEval 2013 Task 2 (B), without applying any pre-processing step. 5. Experiments classifying sentiments in English tweets We participated in Task 2 of SemEval 2013 with two versions of the system. This task called  X  X  X entiment Analysis in sub-tasks provided the same data set for training and development but with different annotations. For subtask A the orga-nizers provided annotations at expression-level, while for subtask B, the typical annotations at global message level were generated. In addition, for  X  X  X nconstrained X  X  submissions, we added to the joint training and development data provided by SemEval the set of MySpace comments provided by Thelwall, Buckley, Paltoglou, Cai, and Kappas (2010) .
The main difference among the two experiments submitted to SemEval 2013 was the use of dictionaries for affect (AWM) and modifier word matching (MWM) and replacement. As such, in the first method (denoted as  X  X  X ict X  X ), we perform all the preprocessing steps mentioned above, while the second method (denoted as  X  X  X oDict X  X ) is applied on the data on which the AWM and MWM are not performed (i.e. words that are associated with a sentiment in a lexicon are not replaced with labels).
Table 3 summarizes the experiments submitted to SemEval 2013 only for the test sets related to Twitter messages. 6. Experiments classifying sentiments in Spanish tweets
Different experiments have been carried out in our first participation in the TASS workshop. They are mainly based on the machine learning approach, combining different results or even by using external semantic resources like dictionaries. WEKA 11 has been used as a tool for generating the different learning models, by applying Support Vector Machines Sequential text categorization and has been applied successfully in many opinion mining tasks, performing better than other machine learning techniques ( Esuli &amp; Sebastiani, 2005; O X  X eefe &amp; Koprinska, 2009 ).
 Taking into account the learning data sets explained in the previous section, three main experiments were proposed:
SVM . For the first experiment, SVM SMO was used as learning algorithm. Thus, these experiments are represented by con-taining the word SVM in their title or id.

DICT . For the second experiment, we applied the dictionary-based approach (see Section 3 ). Specifically, we have used external semantic resources such as the dictionaries provided by Steinberger, Lenkova, Kabadjov et al. (2011) and General
Inquirer. 4CLS . For the third experiment we applied the second approach in which we combined the results of 4 separate pairs of ative versus neutral, positive versus very positive and negative versus very negative labeled tweets from the training data sets.

According to these approaches and the different learning data sets generated, a total of 18 experiments were submitted to the TASS 2013 workshop. Table 4 summarizes what each experiment represents. For each experiment and tweet, the global polarity using 5-levels (P+, P, NEU, N, N+) was obtained. Then, the 3-level version of each experiment was obtained by con-sidering as P and N those tweets classified as P+ and N+, respectively. The rest remained with identical labels than those obtained for the 5-level experiments. 7. Results and discussion 7.1. Results obtained in the SemEval 2013 Task 2 Table 5 shows the results obtained in SemEval 2013 Task 2 in terms of F1-measure, applying the approach explained in
Section 5 . Please note that word normalization, which affected 2% of the words in the SemEval 2013 tweets, was applied to all the entire dataset.
 to these results, we can say that the joint use of slang replacement, dictionaries and punctuation sign mark-up for tweets the words in tweets, 1053 question marks, 3037 exclamation marks, 360 positive words and 88 negative words.
In addition, Table 6 shows the comparison of our best results obtained in SemEval with the best ones obtained by other 23 teams participated in the sub-task  X  X  X  X  X  and 38 teams in the sub-task  X  X  X  X  X . 7.2. Results obtained in TASS 2013 Task 1
The official results for the 18 experiments submitted to TASS 2013 are shown in Tables 7 and 8 . Table 7 shows the results and failures globally, i.e., without taking into account each class, and therefore averaging P, R and F1 in total.
As can be seen from the results, our approach (that was initially tailored for English data) performed well. Although the calculation of the systems X  performance as accuracy is debatable, given that the classes evaluated were highly unbalanced, we can conclude that our system is robust and the performance is relatively stable. Further analysis on the per-class perfor-mance is required in order to establish which of the classes were less well distinguishable, leading to improved features in our system. Surprisingly, the 4-classifiers approach performed the lowest. In this sense, further analysis must be done to determine at what step of the cascade the mis-classification of the examples has led to a loss in accuracy. Finally, Table 9 shows the comparison of our best results obtained in TASS 2013 with the best ones obtained by other participants in the participants is also shown. A total of 12 teams participated in Task 1 called  X  X  Sentiment Analysis at Global Level  X  X . 7.3. Additional experiments
Subsequent to the SemEval 2013 and TASS 2013 competitions, we extended our experiments with the aim of improving the sentiment classification performance in the two languages.

As such, subsequent to the tweet normalization phase, we translated the Twitter data (the training and development data in the SemEval Task 2 campaign) using the Google machine translation system to four languages  X  Italian, Spanish, French and allows us to manually check and correct it, to obtain a Gold Standard (and ensure that performance results are not biased by the incorrect translation in both the training, as well as the development data).

Further on, we extract the same features as in the case of the system working for English  X  unigrams and bigrams  X  from these obtained datasets. We employ the features to train an SVM SMO classifier, in the same manner as we did for English.
The results of the classification experiments are presented in Table 10 . We consider the measure of accuracy and do not
The results show that the use of joint classifiers for the different languages improves the overall sentiment classification performance. The explanation for this is that by adding multilingual features (thus increasing the feature space), for languages that are closer to one another, the features that are important will have an even higher weight. At the same time, more accurately since it reduces the expected probability of error, thus generalizing better over new examples. 8. Conclusions and further work
In this article, we presented our participation to the SemEval 2013 and TASS 2013 evaluation campaigns. We participated with a system that was designed for English for the SemEval campaign and we showed how we adapted it to Spanish, by employing in-house built dictionaries and machine-translated data for training. Additionally, we tested the manner in which to the finer-grained classes of polarity. Subsequently, we combined the multilingual data and obtained a multilingual clas-sifier, that performed overall better than the monolingual classifiers taken separately.

Several conclusions can be inferred from the experiments carried out. One of them concerns with the use of minimal lin-guistic processing, which makes the approach easily portable to other languages. On the other hand, from the results obtained, it has shown that the use of linguistic processing (e.g. lemmatization, stopword removal) actually worsen the per-formance. Finally, the use of unigrams and bigrams to spot modifications in the polarity of the sentiment expressed, allowed successfully applied for English and, as we could see from the results obtained, also for Spanish. From the experiments com-bining the two languages, we can see that the use of joint classifiers can help to improve the performance of monolingual classifiers, by eliminating noisy features and reinforcing valuable ones.

In further work, we would like to tune our classifiers for the Spanish data employed and use additional language-specific features. We also plan to enrich the sentiment dictionaries used for the TASS experiments, so that more informal sentiment expressions can be captured and adopted as features for the polarity classification. Finally, we plan to include text normal-built specifically for Spanish, in order to be able to spot the same phenomena as in English.
 References
