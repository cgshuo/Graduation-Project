 Many existing ranking-related information processing applications can be summarized into one theoretical problem called group rank-ing (GR). A simple average-ranking approach is usually applied to GR. Although the approach seems reasonable, no theoretical analy-sis about its intrinsic mechanism ha s been presented, increasing the difficulty of evaluating the ranking results. This study provides a formal analysis for GR. We first construct an objective function for the GR problem, and discover that each GR problem can be trans-formed into a rank aggregation problem whose objective function is proved to be equal to the objective function of GR. As a conse-quence, the average-ranking appr oach can be explained by two well-known rank aggregation techni ques. We incorporate two other effective rank aggregation methods into the GR problem and obtain two new GR algorithms. We apply the GR algorithms into image retrieval to diversify the image search results returned by search engines. Experimental results show the effectiveness of the proposed GR algorithms. Search and Retrieval  X  Retrieval models . Algorithms, Experimentation, Theory. Group Ranking, Rank Aggregation, Cluster Raking, Visual Diver-sity. In many real information processing applications, placing in order a set of instance groups such as people, document, product, and image groups is necessary. For example, school administrators usually require ranking classes, each of which contains dozens of students. Search engines rank web pages, each of which consists of several page blocks. We summarized such problems into one theoretical problem called group ranking (GR), which aims to rank a set of instance groups instead of a set of instances. A simple yet popular approach in addressing GR is to utilize the average-ranking algo-rithm, which calculates the average score/rank of each group and then order the average scores to achieve group order. For example, school administrators calculate the average scores of each class (i.e., student group) average scores and then arrange classes by their cor-responding average scores. Although this heuristic strategy seems quite reasonable, it lacks a theoretical analysis: How can we explain the average-ranking approach in th eory? Are the results of this ap-proach reasonable? Are there any other alternative solutions? To answer the questions listed above, we make a formal study on the GR problem. We first formalize th e GR problem into an optimiza-tion problem geared toward a defined objective function. We are able to prove that the objective function is equal to a Kemeny opti-mal rank aggregation function. Ra nk aggregation techniques can be adapted to solve the GR objective function. Average-ranking strat-egy can be explained by two classical rank aggregation techniques, namely, linear combination meth od (LCM) [3] and Borda X  X  count (BC)[7]. This conclu sion conversely shows th e rationality of the proposed objective function as well as the problem transformation. We further propose several new methods in the light of rank aggre-gation studies. We explore the utilization of GR studies into the visual diversifica-tion of image search results. In visual diversification [1], the search images returned by search engines are clustered into a set of image groups to make the returned image as diverse as possible. This ap-proach is shown in Fig. 1(a). Upon obtaining the image clusters (groups), these clusters are arrang ed from large to small according to the contained image counts in each cluster. Note that the relevance of clusters is also important to users. Existing studies ignore the ranking of image clusters and lack deep investigation on the ranking of the returned image clusters. In essence, the problem in ranking of image clusters is actually the probl em of ranking a set of groups. We apply our proposed GR algorithms to rank the returned image clus-ters. Our approach is shown in Fig. 1(b). The remainder of this paper is organized as follows: Section 2 briefly reviews related issues. Sec tion 3 gives a formal description of the GR problem. Section 4 transforms GR into a classical rank aggregation problem. Section 5 in troduces the solutions for GR. Section 6 reports experimental re sults on image retrieval. Conclu-sions are given in Section 7. 
Figure 1. The visual diversifying approaches for image retrieval: In this section, we will introduce a related work, namely, rank ag-gregation. This study explores the connections between rank aggre-gation and our proposed GR problem. Rank aggregation is a funda-mental and classical optimizatio n problem addressed in various areas including theoretical computer science, economics, statistics, and information retrieval [2]. It combines different rank orderings on ment in a rank list. Formally, rank aggregation aims to find an opti-mal rank list  X  * with the following objective function: where d (  X  ,  X  ) is the distance function between the lists  X  and  X  widely accepted distance function for two fully ordered lists is the Kendall tau distance [2]: There are numerous rank aggrega tion techniques. One simple and well-known method is Borda X  X  count (BC)[7]. This method assigns a weight to each element. Elements can be ranked according to their weights in increasing order. Some other methods calculate the weights by combining the scores of elements in a linear way. One linear combination method (LCM) proposed in [3] calculates the weights according to the elements X  scores. Both the BC and LCM methods can be seen as direct aggregation approaches. There are some other methods utilizing op timization approach. Dwork [2] proposed the Markov chains method to find the Kemeny optimal aggregation. Markov chains method is a series of algorithms dif-fered in the strategy of constructing the state transmission matrix. We will bring two Markov chains algorithms namely MC1 and MC4 proposed in [2] into our study. In this section, we attempt to give a formal description for GR. We first define some symbols used in the paper. Let T = { B be a set of groups, where each element denotes a group of instances. rank list, we use  X  ; if referring to a rank list of groups over T , we use  X  T ; and when referring to a rank list of instances over X , we use  X  X. The smaller of the value of  X  (  X  ), the higher order the element ranks. are able to derive an ordering list over X according to the scores. We denote this derived rank list as  X  (in some cases, lower score means better rank; thus, the above rule should be modified accordingly). With the above symbols, the GR problem can be formally described as follows: Group Ranking (GR) Problem : Given a set of groups T and the score list (Scs) as well as the instance rank list  X  , how can we derive a reasonable ordering of all the groups? As mentioned in the beginning of the paper, the widely used ap-proach for GR is based on the ranking of average scores/ranks of the groups. The average scores ( a_s i ) and ranks ( a_r i ) are: These two formulas seem quite simple and reasonable. Nevertheless, they lack theoretical basis. In other ranking studies such as rank learning and rank aggregation, pairwise comparison is the base stone of the whole task [2, 4]. Mo-pare any two groups by cons idering the following case: each instance in B j . If the instance from B i ranks better, the score of B increases by 1; vise versa, the score of B j increases by 1. There are | B |  X  |B j | times of comparison. The comparing results (scores) are represented as follows:  X = X  = &lt;  X = X  = &lt; In the round-robin comparison, if  X  ij &gt;  X  ji , B i B wins ; otherwise, they are equal. Note that numbers of instances in different groups may differ a lot. The comparing results are normal-ized as below:  X  X  = X   X  = X   X  (2) If each instance of B i ranks higher than all the instances in B equals 1; if each instance of B i ranks lower than all the instances in B ,  X  ij equals 0. These two cases are consistent with the real applica-tions and our intuition. Based on the pairwise comparison, we are below: Definition 1 ( Inconsistency index ) where between a candidate rank list  X  T and the pairwise round-robin com-paring results derived from a given GR problem. The lower the Q (  X  T ), the better the list  X  T . As a result, the goal of GR is formalized mized. The GR problem aims to so lve the following objective func-tion: The inconsistency index virtually reflects the intensity of the  X  X p-posed sound X  towards a candidate rank list. To solve the function, we transform GR into the rank aggregation problem and explore the connections between them in the follo wing section. We find that the GR problem can be addressed by using rank aggregation techniques introduced in Section 2. In this section, we transform the GR problem into a typical rank aggregation problem. We prove that the objective function of GR is equivalent to its transformed rank aggregation. We are able to generate a numbe r of instance combinations from T . Each combination consists of | T | instances coming from the groups in T separately (different instances come from different groups). The is
BB B  X  X  X  L . Given that the order of each instance in each combination is already known, each combination can be ar-ranged into a rank list of the instances it contained. We name the set of combination rank lists as  X  . If each instance is replaced with the group it locates, each combina-tion rank list becomes a rank list of all the groups in T . This means each combination (instance) rank lis t can produce a group rank list. We denote the set of the produced group rank lists as  X  . Given that we have produced a number of full rank lists for all the groups in T , we obtain an optimal rank list by solving the following rank aggre-gation objective function: where  X  * denotes the optimal rank list and d () is a distance function. Note that each GR problem corresponds to a rank aggregation prob-lem. Consequently, we are interested to know whether or not there is connection between the two optimal objective functions, i.e., Eq. (4) and Eq. (5). We have the following Theorem. Theorem 1 : Eq.(4) and Eq.(5) are equivalent when Kendall tau distance is used. Proof. Ommited due to lack of space (The interested readers can refer to the full version of this paper). Theorem 1 reveals the GR problem is equivalent to the Kemeny optimal rank aggregation problem transformed from GR. As a result, many useful properties can be di rectly inherited from rank aggrega-tion studies and applied to GR. In the following section, we attempt to solve Eq. (4) by solving Eq. (5). It is should be noted that, during the calculation steps it is unnecessary to produce the combination rank lists so we can obtain all the middle parameters without ac-cessing the rank list sets  X  and  X  . This section will show that the heuristic average-score/rank ap-proach is essentially identical to two rank aggregation techniques. To differ from the rank aggregation techniques, the methods pro-posed for GR are added by the prefix  X  X R- X . There are two main classes of the rank aggregation techniques for Kemeny optimal ag-gregation (also for GR): direct approaches and optimization ap-proaches. A simple way of approximately solving the objective function given in Eq. (5) is using the linear combination aggregation method (LCM). The weight for a group is calculated as: This formula shows that the weight of a group is the average score of its contained instances. By ordering the weights of all the groups, we can obtain their order. We call this method GR-LCM. Similarly, we can obtain a new method which is called GR-BC based on Borda X  X  count (BC) method. Obviously, the above two methods are identical to the average-ranking (a verage score/rank) approach in-score/rank approach can be viewed as the direct approached in ag-gregation approach and thus its properties can be inherited from studies for LCM and BC. Next, we modify the Markov chains method proposed in [2] to ad-dress the GR problem. The key step of this method is the transition probability calculation between any two states (here, we used groups). For an arbitrary group B i , its multiset is named as S ( B # B ij be the number of B j in S ( B i ). Assume the current state is B the next state is B j . Based on Lemma 1, we can obtain: When j equals i , we prescribe that # | | matrix, if i does not equal to j , Otherwise, Based on the above formulas, we can easily modify MC1 to GR-MC1 as shown in Table 1. The modification of MC4 to GR-MC4 can also be obtained accor ding to the similar manner. Input: T ,  X  X * ,  X  Output:  X  Steps: a) Calculate  X  ij using Eq.(2) ( i , j = 1,..., | T| ); b) Calculate M ij using Eq.(6) and Eq.(7) ( i , j = 1,..., | T| ); c) Perturb M into a new matrix M  X  (= M - X  I+(  X  /rank(M))1*1 d) Calculate the left prin cipal eigenvector of M  X  . e) Order the groups according to their corresponding values in the f) Output will be the rank of the groups (  X  ). GR-LCM and GR-BC theoretically e xplain the average-score/rank approach which conversely shows the rationality of the proposed inconsistency index and the objective function. There are other nu-merous rank aggregation methods such as median rank [5], which can also be used to address GR. Considering that this study is mainly concerned the formal description of GR, we do not attempt to list all the available methods but leave them for future research instead. The computational complex ities of the direct methods are O ( |X| ) in calculating the weights and O ( TlogT ) in ordering the weights. For optimization methods, the complexity of calculating scores and creating the state transition matrix is O ( |X| complexity of calculating the left pr incipal eigenvector is, for exam-ple, O ( |T| 3 ) when QR decomposition is used. The whole complexity for MC-GR1 and MC-GR4 is O ( |X| 2 ) + O ( |T| 3 ). This section reports our experimental results in the visual diversifi-cation for image retrieval results. Four algorithms were compared: GR-MC1, GR-MC4, GR-BC, and the conventional algorithm that is based on the Instance Counts in each Cluster (referred to as the ICC algorithm). In GR-MC2 and GR-MC4, both their permutation pa-rameters (  X  ) were set to 0.01. We posted twenty image queries to the Yahoo! image search engine and downloaded top-50 and top-100 images of the returned results from the search engine for each query. We only report the results on top-50 image collections due to lack of space. To establish the ground truth, three users were invited to manually cluster the downloaded images and then order the image clusters. In our ex-periments, the image features (including color, texture, edges) were extracted according to the methods described in [1]. Three image clustering algorithms pr oposed in [1] were then applied: Folding, Maxmin, and Reciprocal election. Finally, the clustered results were ordered using our proposed GR algorithms as well as the instance counts based cluster ranking method (ICC). The Kendall X  X  Tau-b [6] value was used to evaluate an or dered clustering with respect to three ordered clustering given by users. We apply the three clustering algorithms (i.e., Folding, Maxmin, and Reciprocal election) to cluster the top-50 images for each query. The average numbers of clu sters for each query obtained from the three clustering algorithms were 11, 13 , and 19, respectively. We then calculated the average mu tual information of the clusters achieved by the three algorithms. The averag e values were 0.9084, 1.3693, and 0.9118, respectively. These results show that the clusterings obtained using the Maxmin algorith m are better than those of the two other algorithms. The four GR algorithms (GR-MC1, GR-MC2, GR-BC, and ICC) were then used to rank the image clusters obtained by the three clustering algorithms. The Kendall  X  X  Tau-b values for each combina-tion of the three clustering algorithms and four GR algorithms (to-tally 12 combinations) are listed in Table 2. When the GR algo-rithms were compared, results showed that GR-MC1 achieved the best overall performances among the four GR algorithms. The com-bination of GR-MC4 and Maxmin obtained the highest Kendall  X  X  Tau-b value (0.3632). GR-BC achieved the worst results partially because many lower ranked images affected the order of the image group. ICC also achieved good results. The underlying reason is that in most queries, the top-1 image clusters returned by users had the largest numbers of images. Given that current image search engines index images are based on surrounding texts, some irrelevant im ages are also returned and may have higher ranks. We observed that many irrelevant images usually two images. Hence, if at least two clustering algorithms take one or tered out before performing the four ranking algorithms. The ex-perimental results are shown in Table 3. Results show that most combinations behave better after di scarding irrelevant images. The best result was 0.3707, which was achieved by the combination of GR-MC4 and Maxmin. Table 2. The Kendall  X  X  Tau-b values of different combinations GR-MC1 0.2165 0.3491 0.2918 GR-MC4 0.2068 0.3632 0.2764 GR-BC -0.1384 -0.2162 -0.0155 
Table 3. The Kendall  X  X  Tau-b values of different combinations GR-MC1 0.2434 0.3337 0.3044 GR-MC4 0.1586 0.3707 0.2918 GR-BC 0.0152 0.0987 0.1127 This paper proposed a new ranking problem, i.e., ranking groups of instances. We have set up a formal description; in addition, a crite-rion named round robin comparison and an index named inconsis-tency index are defined respectively. Using the criterion and the index, we evaluate any candidate rank list on a given set of groups. We have proved that the optimal function of the proposed problem equals to a rank aggregation prob lem. As a consequence, we ex-tended several well known rank aggregation algorithms into four new solutions to our ranking problem. The conducted experiments on visual diversification in image retrieval suggest that the proposed solutions are useful in the real applications. Our future work will focus on: 1) collecting large image data sets to study the perform-ance of the proposed approach and 2) employing supervised infor-mation such as [7] to achieve better results. We would like to thank the anonymous reviewers for their useful comments and suggestions. This work is partly supported by NSFC (Grant No. 60825204, 60672040) and the Excellent SKL Project of NSFC (No. 60723005). [1] Leuken, R., Garcia, L. and Olivares, X., Visual diversification of [2] Dwork, C., Kumar, R., Naor, M. and Sivakumar, D., Rank ag-[3] Lee, J. H., Analyses of multiple evidence combination. In Proc. [4] Dekel, O., Manning, C. and Singer, Y., Log-Linear models for [5] Fagin, R., Kumar, R. and Sivakumar, D., Efficient similarity [6] Pedro, J. S. and Siersdorfe r, S., Ranking and classifying attrac-[7] Chen, S., Wang, F., Song, Y., and Zhang, C., Semi-supervised [8] http://en.wikipedia. org/wiki/Borda_count 
