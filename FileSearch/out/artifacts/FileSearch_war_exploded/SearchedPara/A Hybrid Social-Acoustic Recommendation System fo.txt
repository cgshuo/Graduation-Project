 Recommendation systems leverage several types of informa-tion relating to a recommendable item. The recommenda-tion methods are often based on the analysis of how a set of users associate or rate a given set of items, but they can also focus on the analysis of how the content of the items is related. This paper discusses a hybrid recommendation sys-tem for music -a system that leverages both spectral graph properties of an item-based collaborative filtering associa-tion network as well as acoustic features of the underlying music signal. Both features are balanced appropriately and used to disambiguate the music-seeking intentions of a user. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing Methods, Abstracting Meth-ods ; H.3.3 [ Information Storage and Retrieval ]: In-formation Search and Retrieval X  Information Filtering, Re-trieval Models Algorithms, Theory hybrid, recommendation, acoustic, music, social
Music was one of the first forms of content to be addressed by social filtering recommender systems such as Ringo, Firey, and HOMR [21, 20]. Music is a particularly difficult form of content to classify, partly because it cannot always be reliably organized by a consistent genre taxonomy (for an in depth discussion, see [18]). Instead of focusing on in-trinsic categorical aspects of music itself, attention has of-ten been given to how people organize, rate, and associate songs according to their own personal preferences. In par-ticular, conventional collaborative filtering (CF) techniques have taken advantage of this innate human behavior in order to match people to candidate items that they aren X  X  aware of or don X  X  own yet [10, 19]. This can also be done as an item-to-item based collaborative filtering approach, as pop-ularized by Amazon [15].

Content based recommendation attempts have also been the subject of much interest. Content analysis (CA) based systems characterize the content of a given artist or song ex-plicitly, often through an acoustic feature detection routine, or through an analysis of a score based symbolic representa-tion of the music. Also, various meta-content analysis meth-ods exist, including correlating songs on the basis of their lyrics, or on the basis of the semantic similarity between on-line textual content pertaining to artists [6, 13]. Acoustic feature detection in particular can show pronounced musi-cal genre clustering that is driven by similarities in Mel-frequency cepstral coefficients [16], beat detection [12], sym-bolic score analysis [5, 23], or various combinations of sev-eral of these features at once [14, 25, 22]. Taking several of these components together, a feature extraction method can produce over an 80% accuracy rate for classifying unknown songs into genres [3].

Both CA and CF approaches have considerable merit. CF approaches can reflect the aggregate individual preferences in arrangements of songs, reflecting a cultural knowledge about the songs that a given population holds [4]. Fur-thermore, these methods can also capture the dynamic rela-tionships between songs as the population changes its sen-sibilities. However, recommendation systems that use this method cannot directly address new songs since individuals have not yet associated them with anything. By contrast, CA does not need user feedback in order to characterize a given song. By analyzing acoustic features of a song, CA can immediately associate new content with other similar sound-ing songs. However, CA alone cannot discriminate popular music from unpopular music, nor can it always detect ar-bitrary cultural contexts such as holiday music (Christmas, etc).

Compounding this issue is a variety of search intention on behalf of the user [7, 11]. Users often use a variety of non-musical attributes and concepts to guide their arrangement of and search for music in real-world environments (such as in music stores, and in their own personal space). The latent organizational schemes that users employ are often exhibited in the creation of digital music playlists; where the user arranges music into sets according to an idiosyn-cratic organizational scheme. Item-to-item collaborative fil-tering utilize frequent associations between songs in order to guide the recommendation process (i.e. a song A is strongly associated with song B on several playlists, therefore, rec-ommend B if the user possesses A but not B). In this way, item-to-item collaborative filtering can suggest songs with little to no input (only one starting song is needed as a ba-sis), and without any explicit understanding of the reason why the songs are associated. However, the same song can mean different things to different people, and take part in many meaningful associations. For instance,  X  X lue Christ-mas X  by Elvis Presley is just as likely to be associated with other Christmas songs as it is to be associated with other Elvis Presley songs. Including other songs as an  X  X nput X  into a recommender system can help clarify which association the user intends. For instance, providing  X  X lue Christmas X  with  X  X hite Christmas X  by Bing Crosby will enable the rec-ommender to select recommendation candidates that share more associations with both songs, and therefore select more Christmas songs. Providing  X  X lue Christmas X  with  X  X ound Dog X , also by Presley, will enable the recommender to select more songs by Presley. In this fashion, multiple songs serve as a query that disambiguates the elements in the query set in much the same way that latent semantic indexing is used with textual queries [8].

Several researchers have noted similar results when com-paring acoustic and subjective song similarity measurements [2], indicating that the  X  X round truth X  of music relation-ships is present in both a cultural sensibility of music as well as in an objective analysis of its content. Such a simi-larity suggests that it may be possible to utilize one method to overcome some of the weaknesses or ambiguities of the other, and vice versa. Many researchers have mixed subjec-tive and objective measurements in this fashion. However, many of these systems are either designed for conventional text content (as is the case with Fab [1]), or use abstract meta-content measurements of the underlying media (as is the case with  X  X ontent-based X  analysis of movies in [17]).
The hybrid recommendation system defined here com-bines the graph-like nature of item-to-item collaborative fil-tering techniques with several acoustic feature detection ap-proaches. The dataset, taken from a subset of the MyS-trands recommendation data service, comprises an item set of approximately one hundred thousand songs, along with audio previews that give a constant-time snapshot of the respective music content.
We prepare the adjacency matrix A  X  R m  X  n which repre-sents the playlist co-occurrence graph. Every column or row represents a song that exists on a playlist in the database. Each cell contains the number of times song (given as a row index) co-occurs with another song (given as a column in-dex). Since this graph is sparse (most entries between songs are zero), each cell entry from A is encoded as a triplet a containing the row, column, and value of the entry. These values can then be indexed to speed retrieval. The matrix A is then decomposed using eigenvalue estimation [9]. The eigenvalues and corresponding eigenvectors of A comprise a set of spectral item-to-item graph features that describe a given song. For instance, songs with higher scores along the first eigenvector will have a higher centrality , indicating that they serve as  X  X ubs X  with which many other songs co-occur with. Songs on opposite ends of the second eigenvector are most likely on the diameter of the graph. They are the songs that not only share few to no connections, but share no con-nections between their respective neighbors either. They are essentially on opposite sides of the network from each other and constitute a dissimilar cultural music sensibility. Early k-core network estimates of this eigenvector indicate a eas-ily interpreted 1 polarization of taste between  X  X dult Easy Listening X  and  X  X unk/ Nu-Metal X . Essentially this means that songs from artists like David Gray are not often on playlists with songs from Green Day at the time that this study was performed, even though both artists X  songs ex-ist on many different playlists. The low rank estimate of A provides a set of orthogonal k eigenvectors V k and corre-sponding k eigenvalues  X  k 2 .
Three acoustic feature detection methods are performed on each thirty second sample audio clip in order to gener-ate, similar to the method described by Lamere and West in [24] 3 . These methods include calculating Mel-frequency cep-stral coefficients as a method of capturing timbral variation; calculating auto-correlation metrics which capture aspects of rhythm and time signature; and finding spectral frequency attributes, which indicate strong pitched or  X  X eyed X  compo-nents in the underlying signal. In total, 30 or so feature vectors are extracted for each song (using the method from Lamere and West), with 19 timbral, 6 rhythmic, and 5 pitch content dimensions. These dimensions make up a set of 30 acoustic feature vectors.
The spectral graph and acoustic feature vectors describe a single feature space that characterize a given song. Analyz-ing the merged feature vectors of one or more songs can give an indication of similarity between the given songs, as well as describe where these similarities come from. The simple vec-tor space also provides the basis for linear-time recommen-dation. However, merging the different feature vectors is not as simple as concatenating them together into a single ma-trix. Each feature space has different distribution character-istics and scaling. The distributions of spectral graph eigen-vectors must be balanced with the distribution of acoustic feature vectors so as to not inappropriately influence one method over the other (initially). Furthermore, the charac-teristics of the spectral graph features are ranked in order of the eigenvalue magnitude. In essence, large differences in a position on a low-magnitude eigenvector are less impor-tant than large differences in a position on a high magnitude eigenvector. By contrast, with the acoustic feature vectors, each vector is more or less equally important, although per-haps with a different scaling to its distribution. To give each
The division between the artists is a classic example of differences in taste between age demographics.
Currently, five positive eigenvalues and associated eigen-vectors are expected to be extracted from the song graph.
Pending completion of model specification. metric equal influence, and to weight the spectral graph vec-tors appropriately, a z-score normalization method is used. Each of the 35 different acoustic and spectral (eigenvector) feature vectors are z-score normalized: with x corresponding to each element of the acoustic feature vector distribution,  X  corresponding to the vector standard deviation, and  X  corresponding to the vector mean. This gives unit variance and an equal mean. At this point, each vector is directly statistically comparable to another, and differences between any two songs feature values are directly interpretable. For instance, compare the (abbreviated) fea-ture vectors of the two songs in the given table
Song A and Song B are similar along a number of dif-ferent vectors. However, feature number 1 is particularly important because the songs have similar values and are at least three standard deviations away from their respective means. This basic form of comparison allows for statistically meaningful similarities to be calculated across vectors and across spectral graph and acoustic feature spaces. A weight-ing scheme comparing two or more songs can simply add the feature vectors together and identify significant correlations along any of the acoustic or spectral features by a large de-viation from zero. Any of the features that have significant cumulative deviation in a certain direction will then have a larger influence over the recommendation selection process.
With the ability to identify and compare spectral and acoustic features on a unified scale, it is possible to disam-biguate the music seeking behavior of a given user if they supply a given playlist as a  X  X uery X . By analyzing the cor-relations of the feature vectors that are present in the song, one can determine if there are pronounced similarities in the social sensibilities or acoustic properties of the music, and recommend songs accordingly using k-nearest neighbor approaches. If a user submits a list of popular music, the first spectral graph eigenvector will show pronounced shared positive deviation among all the songs, and will influence the recommender system to select more songs that have similar popular characteristics. Perhaps the user wishes to avoid  X  X verly X  popular music, and wants to hear heavy metal songs (an easily detected acoustic signature) that are  X  X n-derground X  or not mainstream. Many of these songs would show pronounced shared negative deviation on the first spec-tral eigenvector, along with several shared deviations along the various relevant feature vectors. This would in turn lead to a selection of new or non-mainstream songs that matched the shared characteristics of the given playlist.

A simple recommendation process would take two or more query playlist song feature distributions and create a weight-ing vector: where  X  once again is the standard deviation of the distri-bution of scores between features, and  X  is the mean of the scores. In the previous example, high and similar shared deviation for the popular playlist songs would create a high weight for this particular feature. Conversely, songs with divergent features would have low weights.

The mean spectral  X  s and acoustic  X  a feature scores of the weighting vector are calculated and proportionate weights are given by  X  0 s =  X  s / (  X  a +  X  s ) and  X  0 a =  X  Next, the entire feature distribution of the query playlist songs are averaged together into a mean vector V .

Euclidean or Mahalanobis distances between both spectral and acoustic feature spaces will be calculated between the mean vector V and the candidate songs from the recommen-dation database. The distances will be multiplied by their corresponding proportionate weights (  X  0 s or  X  0 a ), then added together. Candidate songs with the shortest distances will be the best candidates according to this approach. The best candidates will likely be strongly influenced by any shared divergent variation in any one of the feature vector spaces, but this influential factor is only introduced as a propor-tionate mixing method balancing out the spectral graph and acoustic correlations between on or more songs, and will not cause skewing or over emphasis of one feature over another.
This paper proposes a hybrid popular music framework that leverages both social/cultural aspects of music in the form of item-to-item associative networks created from human organizational behavior, as well as from acoustical content-analysis methods. It also proposes a low-dimensional linear-time method for recommendation that uses easily provided playlist-based query methods to disambiguate user intention and appropriately influence the correlations produced by either spectral or acoustic similarity metrics.
The author wishes to thank MyStrands for their generous support and data, as well as Chris Raphael, Don Byrd, and Ian Knopke for their discussions and guidance. [1] M. Balabanovi  X c and Y. Shoham. Fab: content-based, [2] A. Berenzweig, B. Logan, D. P. W. Ellis, and B. P. W. [3] J. Bergstra, N. Casagrande, D. Erhan, D. Eck, and [4] E. Blanzieri and P. Giorgini. From collaborative [5] H. C. Chen and A. L. P. Chen. A music [6] W. W. Cohen and W. Fan. Web-collaborative [7] S. J. Cunningham, N. Reeves, and M. Britland. An [8] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. [9] J. Falkner, F. Rendl, and H. Wolkowicz. A [10] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. [11] J. Y. Kim and N. J. Belkin. Categories of music [12] D. Kirovski and H. Attias. Beat-id: identifying music [13] P. Knees, E. Pampalk, and G. Widmer. Artist [14] Q. Li, B. M. Kim, D. H. Guan, and D. Oh. A music [15] G. Linden, B. Smith, and J. York. Amazon. com [16] B. Logan. Music recommendation from song sets. [17] P. Melville, R. J. Mooney, and R. Nagarajan.
 [18] F. Pachet and D. Cazaly. A taxonomy of musical [19] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [20] U. Shardanand. Social information filtering for music [21] U. Shardanand and P. Maes. Social information [22] G. Tzanetakis and P. Cook. Musical genre [23] S. Vembu and S. Baumann. A self-organizing map [24] K. West and P. Lamere. A model-based approach to [25] E. Wold, T. Blum, D. Keislar, and J. Wheaten.
