 In this paper, we propose a novel spatio-temporal model for collaborative filtering applications. Our model is based on low-rank matrix factorization that uses a spatio-temporal filtering approach to estimate user and item factors. The spatial component regularizes the factors by exploiting co r-relation across users and/or items, modeled as a function of some implicit feedback (e.g., who rated what) and/or some side information (e.g., user demographics, browsing history). In particular, we incorporate correlation in fac -tors through a Markov random field prior in a probabilistic framework, whereby the neighborhood weights are functions of user and item covariates. The temporal component en-sures that the user/item factors adapt to process changes that occur through time and is implemented in a state space framework with fast estimation through Kalman filtering. Our spatio-temporal filtering ( ST-KF hereafter) approach provides a single joint model to simultaneously incorporat e both spatial and temporal structure in ratings and therefor e provides an accurate method to predict future ratings. To ensure scalability of ST-KF , we employ a mean-field approx-imation for inference. Incorporating user/item covariate s in estimating neighborhood weights also helps in dealing with both cold-start and warm-start problems seamlessly in a sin-gle unified modeling framework; covariates predict factors for new users and items through the neighborhood. We il-lustrate our method on simulated data, benchmark data and data obtained from a relatively new recommender system application arising in the context of Yahoo! Front Page.
Matrix factorization (MF) is an effective prediction tech-nique that has been successfully applied to several collabo -rative filtering applications [17, 13, 18, 19]. However, mos t existing MF-based collaborative filtering algorithms do no t consider the following facts:
In this paper, we provide a new method to address the above-mentioned problems through a model that simulta-neously incorporates the spatial and temporal structure in rating history. We show that this joint model, referred to as spatio-temporal Kalman filtering ( ST-KF ), improves pre-diction accuracy over standard matrix factorization on syn -thetic data, Movielens data and the Yahoo! Front Page data.
Our work enhances the basic factor model for collabora-tive filtering that models the rating of item i by user u as where p ( u ) and q ( i ) are k -dimensional latent user and item factors respectively, and  X  ( ui ) denotes observation error. Es-timation of these factors is obtained through some regular-ization on factors to prevent over-fitting; it is customary to constrain the factors by regulating the L 2 norm of fac-tors. The main contribution of our work is to enhance the regularization through a spatio-temporal filtering approa ch to obtain better estimates of user and item factors. The spatial component, discussed in Section 2, regularizes the factors by exploiting correlations across users and/or ite ms. The temporal component, introduced in Section 3, ensures that user/item factors adapt to process changes that occur through time. In particular, temporal change in factors is modeled in a state space framework with fast estimation through Kalman filtering. Our spatio-temporal filtering ap-proach (named ST-KF , see Sections 4-5) provides a single joint model to simultaneously incorporate both spatial and temporal structure in ratings using a  X  X roduct of experts X  approach that results in an accurate method to predict fu-ture ratings. Although classical Kalman filtering is a fast estimation method for linear state-space models, simulta-neous estimation of both spatial and temporal components induces a model that is computationally intensive; we ensur e scalable inference for ST-KF through mean-field approxima-tion. Our model also handles both cold-start and warm-start problems seamlessly in a single unified modeling framework by incorporating user/item covariates in estimating neigh -borhood weights; covariates predict factors for new users and new items through the neighborhood.
 Notation We use superscripts to index users, e.g., p ( u ) , and items, e.g., q ( i ) , and use subscripts for types (e.g. users vs. items) or time index in temporal modeling. We use bold upper-case letters, e.g., R , for matrices, bold low-case letters, e.g., r , for vectors, and italics for scalars, e.g., r , and the entries in a matrix or vector, e.g., W ( uv ) .
We first consider incorporating spatial correlation across users and/or items into the collaborative filtering model. Here we focus on the matrix factorization (MF) model, and express our prior belief on the user and item similarity as a Markov random field prior for user and item factors.
Consider a user-item rating matrix R  X  R N  X  M ( N users and M items) that is partially observed. Matrix factoriza-tion models attempt to find a rank-k approximation of R of the form where the rows in P are the user factors and rows in Q the item factors . The most commonly used approach for estimating P and Q is to minimize the cost function where B indicates the location of observed ratings with and  X  stands for the Hadamard product. Equation (2) can be equivalently interpreted as finding the maximum a poste-riori (MAP) solution of { P , Q } while assuming that both the user and item factors are drawn from a spherical Gaussian and R is contaminated with Gaussian noise.

Now suppose we have some additional similarity informa-tion for users either given a priori , or extracted from side information, which leads to a more informative prior for use r factors { p (1) , , p ( N ) } , denoted f p ( P ), where W ( uv ) p  X  0 represents the similarity between users u and v , and the parameter  X  controls the strength of this prior. Equation (3) defines a Gaussian Markov random field (MRF) [12] over { p (1) , , p ( N ) } . In fact, the conditional factors except that of user u ) only depends on the factors in the neighborhood of u and is a k -dimensional Gaussian given by p where U ( u ) denotes the neighbors of u and I denotes the identity matrix. It follows from the celebrated Hammersely -Clifford theorem that for symmetric W p , the conditional distribution in (4) induce a unique joint distribution that is given by (3). Thus, we are modeling the joint distribution of factors by modeling the precision matrix (the inverse of covariance matrix) through similarity functions W p instead of modeling the covariance matrix. All existing work on matrix factorization assumes independent priors on factor s. In contrast, we impose dependencies at the outset through a joint distribution resulting in ellipsoidal constraints t hat are functions of the covariates. A similar prior can be imposed on item factors, for ease of exposition we assume the same  X  as in (3), This MRF prior, after combined with the spherical Gaussian prior in a  X  X roduct of experts X  fashion, gives a joint prior f or user and item factors, With this prior, finding the MAP estimate of P and Q amounts to minimizing k B  X  ( R  X  PQ T ) k 2 F +  X  ( k P k 2 F + k Q k 2 F )+ where tr( ) denotes the trace of a matrix,  X  p is the graph Laplacian composed from the similarity matrix W p (assum-ing W ( uu ) p = 0 , u = 1 , 2 . , N ), and D p is the diagonal degree matrix with D ( uu ) p = It can be easily verified that tr( P T  X  p P ) = p ( v ) k 2 penalizes differences between similar users u and v . The regularization for items is defined in the same way. This spatially regularized matrix factorization scheme will be re-ferred to as SptMF .

The graph Laplacian regularized matrix factorization mode l in (6) can be used standalone as a way to incorporate side information about users and items or as an additional com-ponent in a more complex model. Moreover, as will be shown in Sections 4, it can also serve as an initialization step for modeling the temporal structure.
We construct the similarity matrix W p and/or W q by exploiting side information and ratings history. For simpl ic-ity, we will only discuss similarity construction among use rs, and similar discussion holds for items. We provide a few ex-amples below of constructing such similarity measures: From covariates. When the covariate is categorical (e.g., gender, occupation, etc), we use the following measure where x u indicates the category of user u . When the covari-ate is numerical (e.g., age), we use the following Gaussian RBF kernel From rating history. The simplest similarity measure is the co-occurrence based on the  X  X ho-rated-what X  matrix,
We can also combine the similarities constructed from dif-ferent sources { W (1) , , W ( m ) } . One way is to find a convex combination W = alignment between W and some target correlation, for ex-ample, the Pearson correlation among users extracted from observed ratings. This alignment strategy has been proven effective for kernel learning [9] and can be readily used for our problem. Furthermore, we make our similarity matrix W sparse by removing weak similarities to reduce noise in estimates of neighborhoods. Such a sparse W reduces com-putational cost and enables a scalable procedure. Indeed, f or both alternating least squares and stochastic gradient 1 (two commonly used methods for estimating factors with matrix factorization), estimating the factors for a particular us er u involves calculating the average of its nearest neighbors which needs O ( k ) time if W is a k -NN graph, but O ( N ) time if W is dense. The advantage of having a sparse k -NN graph will become more obvious for the joint spatio-temporal fil-tering, for which we have to dynamically incorporate the user similarity prior in filtering steps.
The spatial model in Section 2 exploits correlation in co-variate space to enforce smoothness across users and/or ite m factors. Another source of correlation is through time, whi ch is important for dynamical modeling of the user and item factors. For simplicity, we will first assume the item char-acteristic to be time-invariant. Later in Section 4 we will relax this assumption and allow for on-line re-estimation o f the item factors. As mentioned before, the temporal struc-ture can be modeled in a state space framework with fast estimation through Kalman filtering [8].
For example, see Simon Funk X  X  algorithm http://sifter.org/ simon/journal/20061211.html
We assume the item factors are known a priori , e.g., as item features given by other sources or pre-estimated by some preprocessing step such as a static MF. We assume the user factors for each user u follow a random walk driven by Gaussian noise: where r ( u ) t is the vector of ratings from user u in time in-terval t , and H ( u ) t is the observation operator composed of corresponding rows of Q (item factors) based on the model and the observation noise, both Gaussian: w ( u ) t  X  X  (0 ,  X  v t  X  X  (0 ,  X  2 o I ), and uncorrelated across individual users.
Both variances ( X  p ,  X  o ) are either known or can be esti-mated from data. For example, we may assume that  X  p =  X  I and tune  X  through cross-validation.
With the dynamic model described above, the user factor can be dynamically and efficiently estimated with Kalman filtering (KF). Basically, KF sequentially takes the rating s mal state estimate at time t , denoted by  X  p ( u ) t | t dated by incorporating the new observation r ( u ) t as follows step 1: T ime Update step 2: M easurement Update
 X   X  p Although it is conceptually appealing to have a joint filteri ng model for both users and items, it renders the observation step (Equation (8)) nonlinear since it involves the dot prod -uct of the user factors and item factors. Nonlinear KF ex-tensions such as Sigma-point Kalman filter [20] would have to be employed for this purpose. In this paper, we will focus on the linear KF, and assume the item factors are either known, or can be (dynamically) estimated by an external model (see however, Section 5).
In this section, we combine the modeling ideas in Sections 2 and 3 to obtain our ST-KF model that exploits both spatial and temporal correlations in the ratings.
We first consider the spatio-temporal prior for the user factors p t  X { p (1) t , , p ( N ) t } . Let  X  = {  X ,  X ,  X  all the parameters. At each time step t , the prior for p comes from two independent sources: Temporal Continuity: This is expressed through the prob-ability p ( p t | p t  X  1 ;  X  ), which penalizes a large deviation be-tween p t and its prediction at t  X  1. If we assume random walk dynamics as in (7), we have p ( p t | p t  X  1 ;  X  ) = Spatial Similarity: This is expressed through the time-varying Gaussian MRF prior p ( p t ; W p,t ,  X  ), where W ifies the user similarity at time t : where W ( uv ) p,t is the ( u, v ) entry of matrix W p,t .
The spatio-temporal prior is then given by the product This type of spatio-temporal prior has been used in filtering tasks in other domains [15].

From the independence assumption, the likelihood of rat-ings given the user factors is p ( r t | p t ;  X  ) = Using r t  X { r (1) t , , r ( N ) t } to denote the observed rating at time t , the complete likelihood of { p  X  } t  X  =1 and { r given by This model will be referred to as Spatio-Temporal filtering ( ST-KF ) in this paper. A pictorial illustration of ST-KF is given in Figure 1.
Due to the correlation introduced by W p,t , the estimate of each p ( u ) t cannot be done separately as in Section 3. The brute force implementation of KF update requires consider-ing a concatenated state vector and the corresponding covariance matrix  X   X  t (  X  R Nk  X  Nk the concatenated state vector. As for regular KF, we can estimate the probability p (  X  p t |{ r  X  } t  X  =1 ; { W sively.

M-update: p (  X  p t |{ r  X  } t  X  =1 ; { W p, X  } t  X  =1 ,  X  ) covariance of  X  p t at time t  X  1.

To avoid the computation of inverse of a huge covariance matrix in the measurement update (see the function KFup-date in Section 3.2), we can use mean field approximation (MFA) [11] for inference at each time step, which turns out to be fairly cheap if W p,t is sparse (e.g., a k NN graph). The na  X   X ve MFA uses the following fully factorized probability q to approximate p (  X  p t |{ r  X  } t  X  =1 ; { W p, X  } t  X  =1 dependence assumption, the posterior covariance can be re-duced to individual ones We find q t ( p t ) with the minimum KL-divergence to the true posterior, q  X  t ( p t ) = arg min which can be recast as where E q t [ ] stands for the expectation with respect to q Generally (11) does not have a closed-form solution and is not even a convex problem. Instead a local optimum can be found iteratively with the following update equations: (fo r u = 1 , 2 , , N ) where E q t [log p ( p t |{ r  X  } t 1 ; { W  X  } t 1 ,  X  ) | p timate of) q t conditioned on p ( u ) t , and is q t ( p t ). For more details of the mean field approximation, see the Appendix.
In this section we give some implementation details, and then pseudo-code for our ST-KF approach.
 Initialization We often need to perform a static matrix factorization (e.g. , MF or SptMF ) before the filtering, in order to obtain item factors as well as initial user factors. In practice it is oft en the case that we encounter new users and new items during the filtering process. For new users, we need to have an ini-tial guess of user factors before seeing any ratings, and the re-fore the initial factors for new users will be obtained purel y based on the covariates. One such solution can be naturally derived from the conditional distribution of the Markov ran -dom field prior, or equivalently the objective function in (6 ). Without loss of generality, we can assume that the N th user is new and has no ratings. It is easy to verify that given { p (1) , , p ( N  X  1) } , the solution of p ( N ) to (6) is simply a regularized version of nearest neighbors interpolation New Items
Handling new items is more involved since we assume item factors are known. The same difficulty arises when there are too few ratings for an item for reliable factors fitting, or th e item factors also change with time. Here, we resort to the following approximation. At each time step t , we update the item factors q ( i  X  ) t by finding an approximate solution to the following optimization where the first term on the right hand side is the rating square error, and the second term is the regularization from the item similarity. F  X  ( i ) stands for the indices of users who have rated item i at time  X  , and U ( i ) contains the indices of the items that are nearest neighbors of item i (according to W q ) and also has been reliably estimated (with enough number of ratings of it). In practice, all the reliably esti-mated items are stored in a stack, which is also dynamically updated. It is easy to see that when there are no ratings for item i , the solution for q ( i ) t becomes a neighborhood inter-pretation that has the same form as (12) Algorithm 1: Spatio-Temporal Filtering (ST-KF) Input: R 0 , the ratings before time 0, and the sequence of Output: User factors { p (1) t , , p ( N ) t } for t = 1 , , T . step 0: I nitialization. step 1: I ndividual Kalman filtering step 2: M ean Field Approximation step 3: U pdate the item factors and stack. step 4: t = t + 1, go to step 1 . step 0: I nitialization. step 2: If converged, then return the mean and covariance We tested the proposed algorithms on synthetic data, the MovieLens data, and Yahoo! Front Page data. On synthetic data and MovieLens, the task is to predict the missing en-tries based on the (sparsely) observed ones. The prediction performance is measured as the root of mean square error on test set, where test stands for the set for all the entries in test set. For Yahoo! Front Page data, the error is measured by the more relevant ROC curve for  X  X lick-or-not X  prediction.
The experiments on synthetic data are designed to show that both spatial correlation and temporal structure indiv id-ually help in finding more accurate user factors, and their strengths can be combined by using spatio-temporal filter-ing. For data, we generate a rank-5 100  X  50 rating matrix R = PQ T , where entries of P and Q are independently drawn from a uniform distribution on interval [0 , 1]. In the MF model, we also set the number of factors to be 5. Spatial Model We considered two types of artificially generated similarit ies between users (Similar for item similarity generation): We randomly selected 10% of the entries in the rating matrix for training and used the remaining entries for testing. We follow the spatial objective function given in (6) and use stochastic gradient for optimization. Figure 2 shows the RMSE on test set achieved by different settings of  X  and  X  in training. We note that when using the weak similarity, the best performance is achieved with a balanced  X  and  X  , while with strong similarity, the performance is the best when the Laplacian regularization term dominates. Figure 2: The RMSE of SptMF with strong and weak similarity and different (  X ,  X  ) . The white cross in-dicates the location of optimal (  X ,  X  ) . With only Frobenius norm regularization (  X  = 0 ), the minimum RMSE = 1.5862.
 Temporal Model We assume that the user factors change linearly with time, while the item factors keep unchanged. In this experiment we generated 10% of entries with the initial user factor p and then let the user factors evolve with time as in (14), while generating 2% of entries observable at each time step. The remaining 70% of the entries are generated with p 10 , but will be held out for testing.
 To get Q and initial P with the static MF (step 0 in Algorithm 1), two strategies can be taken: Strategy II , if applicable, often works better since it usu-ally gives a more accurate fitting of the item factors. One question associated with Strategy II, however, is  X  X t which time step should we start evolving user factors? X . Intuitiv ely, we should go back to time 0 as we do with strategy I, but we observed that the results are often better when starting in the middle of the training duration (e.g. step 6 in this case). Figure 3 (left panel) compares the two initializatio n strategies as well as the two choices of starting points on th e synthetic data. See Section 6.2 for similar results on Movie -Lens data.
 Spatio-Temporal Model We take the same data from last experiment, but for each step, we also assume there is a noisy and sparse similarity with a proper  X  , where we also assume only 50% of the sim-ilarities (randomly chosen at each time step) are observed. We pruned the graph to be 5-NN, which further sparsifies the similarity W p,t .

In Figure 3 (right panel) we compared ST-KF and KF with two different initialization strategies. Clearly, und er Figure 3: Kalman filtering on synthetic data. Leg-end: (ini): initialize with the first 10% of the ratings; (trn): initialize with all the 30% of ratings collected in 10 time steps; (mid): initialization with all the 30% of ratings, but start filtering after step 6 . all configurations the filtering reduces the test RMSE from initial MF. With each of the initialization strategies, ST-KF outperforms KF by large margin.
We used the MovieLens data 2 with 6040 users, 3952 movies and around one million ratings. It is a commonly used data set for missing entry prediction, where typically some randomly selected entries are assumed to be observed and the rest are for testing. We argue that a more proper setting of the problem is to predict the ratings at time t + 1 and after based on ratings obtained until time t . For the MovieLens data, we have ratings (from different users) for 1083 days, and we use the ratings in the first 420 days (95% of all the ratings) for training and the ratings in the remain -ing 663 days (5% of the ratings) for testing. This particular split of the data makes it much harder than what we know from [16, 1], in that (1) the user characteristic might have drifted away from it was in training phase after up to 20 months, and (2) only 813 users have ratings in the test set, and the particular training/testing split for those users i s around 80 / 20.

For MovieLens data, in addition to the ratings, we also have the movie genres and the user demographic informa-tion: age, gender, occupation, and geo-location. We find a convex combination of user similarities composed from the four sources via a similarity-target alignment, as describ ed in Section 2.2. We compared four different settings for this rating prediction task: (1) standard MF (for initialization) + standard KF (for filtering), (2) standard MF + ST-KF , (3) SptMF + standard KF , and finally (4) SptMF + ST-KF . We use all the data before day 420 for training and start the filtering at day 250 3 , as suggested in Section 6.1. The result is shown in Figure 4. We have the following three observations http://www.grouplens.org/taxonomy/term/14
The filtering starting at day 0 returns significantly worse result, see Figure 4 for details. Figure 4: The result on MovieLens. Legend: (MF-trn): initialize with a standard MF. (SMF-trn): ini-tialize with SptMF . The numbers on the right y-axis indicate the test RMSE achieved at day 420, while the numbers in parentheses are the those obtained with starting point time 0. Most saliently, the most sophisticated method ( SptMF + ST-KF ) reduces RMSE from the that of baseline matrix fac-torization method by 1 . 4% (0 . 9163  X  0 . 9022).
We now describe a relatively new recommender system application that arise in the context of Yahoo! Front Page. This application has been studied recently (see [4, 7] for a detailed description). The application involves recommen d-ing content items on a module (Today Module) that is pub-lished on Yahoo! Front Page to maximize overall click-rates . The module consists of four tabs (Featured, Entertainment, Sports and Video), our goal is to recommend the best stories from the available content pool to fill up the four slots on the featured tab. The available content in this application is programmed by human editors and typically consists of a few items (few tens) at any given point in time. However, the pool is dynamic and changes over time, editors push new stories and take out old ones. Hence, each content item has a short lifetime.
 Data Characteristics There are several characteristics that makes this applicat ion different from movie recommender problem. First, short ar-ticle lifetime means item factors have to be learnt online, the items in the test period have no overlaps with those in the training period. Second, we have rich meta-data on users which includes age, gender, geo-location, and brows-ing history. For items, we have content features in the form of content categories that are assigned by editors manually . We note that such problems are commonplace in web appli-cations; sites like Digg, Top Picks on MSN, Yahoo! Buzz, Yahoo! Finance, HotFeeder etc face similar content recom-mendation problems.

We created a data set that consists of about 2M binary ratings (click or no click) for about 30K users over a six month period that covered about 4.3K items. Other than age, gender and geo-location, our user features include bro ws-ing behavior that are inferred based on a user X  X  network wide activity (search, ad-clicks, page views, subscriptions, e tc.) on the Yahoo! portal. In fact, a user is assigned an intensity score in a few thousand content categories based on his/her activity pattern in the recent past; we reduced these to a few hundred features by conducting a principal components analysis on the training data.
 Algorithm Details For Yahoo! Front Page data, besides the user factor and item factor, we also considered a time-varying overall bias , the user bias b , and the news popularity bias c . So at time t , the rating (click it or not) is modeled as bias of user u and the bias of item i at time t . The user bias and the popularity bias can be expressed with same rating model in (1 ) with the following extension. Let then it is easy to see (  X  p ( u ) t ) T  X  q ( i ) = b ( u ) Results on Y! Front Page Data To illustrate the performance of ST-KF , we compare against three baseline models that are (a) Cov-Only : This is a linear regression based only on user and item covariates. (b) Fact-Only : This is the usual matrix factorization model without any spatial or temporal smoothing. Since most of the items in the test set are new, the item popularity and item factors are estimated as zeros and hence this reduces to a model that is based only on global and user popularity terms, i.e., + b ( u ) t . (c) Item-Cov : In this model, we estimate the user and item factors on the training data using the usual matrix factorization model. To avoid cold-start in the test data, w e further estimate a linear regression model based on user and item covariates to estimate the respective factors obtaine d from matrix factorization. On the test set, we use the regres -sion to predict factors for new user/item. Figure 5 shows the ROC curves comparing the methods. First, all our methods are better than the straw man baseline that predicts a con-stant score for all test cases, the curve for this model is giv en by the 45 degree straight line. Using covariates alone does not provide good performance, showing the need to learn user and item specific models for this application; in fact, the Fact-Only model is better than Cov-Only . As expected, the Item-Cov model is better than Fact-Only ; however, in-corporating both spatial and temporal smoothing through ST-KF provides the best performance.
There has been some work on incorporating user and item covariates or side-information into collaborative filteri ng. The most well-studied direction is to use kernel-based classifi ca-tion or regression models, where the covariates-based kern el serves either as a  X  X asic X  kernel in a kernel combination [6, 1] or as an initial kernel for later kernel fitting [21]. Anoth er direction is to treat collaborative filtering as a parameter -ized regression problem, where the covariates (or features induced from other side-information) become part of the re-gression parameters [5]. The work that most resembles our spatial model is proposed independently in [14] for relatio nal data analysis, where the links between entities are treated Figure 5: ROC curves comparing different methods on Y! FP data as the auxiliary similarity used to regularize a matrix fac-torization model.

Incorporating temporal component and covariate into rec-ommender system problems have been studied very recently in several papers [4, 3, 2]. Of these, [10] is most related to our work where the authors regularize the factors through a regression and capture temporal variation through ran-dom walk priors on each parameter. We note that it is easy to incorporate their model in our framework by replacing  X  ( || P || 2 F + || Q || 2 F ) in Equation 6 with  X  ( || P  X  GX || Q  X  FX q || 2 F ) where G and F are unknown regression co-efficient matrices, and X p , X q are user and item covariate vectors respectively. Our spatio-temporal prior provides ad-ditional regularization by inducing dependencies in the fa c-tors a-prior through a Markov random field.
We presented an efficient spatio-temporal approach to col-laborative filtering, and showed its efficacy on both syntheti c and real-world data sets. Our future work will focus on bet-ter models for joint and dynamical estimation of user factor s and item factors, including bilinear filtering model based on Sigma-point Kalman filter, and parameterized regression models as in [10].
This research is partially supported by NSF grant CCF-0431257 and a gift from Yahoo! research. ZL is supported by an ICES postdoctoral fellowship at UT Austin. From Bayes rule we have the Markovian property
Also we assume the temporal prior factorizes, which is a result of the MFA at t  X  1. Easy to verify where c is a constant. Easy to see that for each u
When W p,t is given by a k NN graph, E q t [log p ( p t ; W | p t ] can be evaluated efficiently as where U ( u ) is the set of nearest neighbors of u .
