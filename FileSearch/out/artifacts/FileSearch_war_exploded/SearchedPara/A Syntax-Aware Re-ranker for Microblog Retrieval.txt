 We tackle the problem of improving microblog retrieval algorithms by proposing a robust structural representation of (query, tweet) pairs. We employ these structures in a principled kernel learning framework that automatically extracts and learns highly discrimi-native features. We test the generalization power of our approach on the TREC Microblog 2011 and 2012 tasks. We find that rela-tional syntactic features generated by structural kernels are effec-tive for learning to rank (L2R) and can easily be combined with those of other existing systems to boost their accuracy. In particu-lar, the results show that our L2R approach improves on almost all the participating systems at TREC, only using their raw scores as a single feature. Our method yields an average increase of 5% in retrieval effectiveness and 7 positions in system ranks. H.3 [ Information Storage and Retrieval ]: H.3.3 Information Search and Retrieval Microblog search; semantic modeling; re-ranking
Social media has become part of our daily lives, and is increas-ingly growing into the main outlet for answering various informa-tion needs, e.g., the query, Facebook privacy , may be answered by the following tweet: Facebook Must Explain Privacy Practices to Congress http://sns.ly/2Qbry7 . Such queries have proven diffi-cult to answer with a single retrieval model, and lead to models that learn to combine a large number of rankers. Learning to rank (L2R) methods have been shown to improve retrieval effectiveness and they have recently been used for ranking short documents from social media. However, L2R suffers from an important drawback: different training data is needed for different applications. The re-quired amount of training data critically depends on the task being tackled and the quality of the used text representations, e.g., lexical features are less powerful than search engine scores or other meta-features. Optimal representations require considerable effort to be designed and implemented. Hence, flexible and adaptable features can be valuable for rapid and effective designs of L2R systems.
Previous work has shown that one source of more adaptable features comes from structural relations between object pairs [6], which in the case of text mainly refers to its syntactic structure. Unfortunately, the latter is subject to errors when it is automatically generated. This problem is exacerbated when we deal with infor-mal and unedited text typically prominent in social media. Most importantly, it is not clear which part of the structure should be considered to design effective features.
 We tackle the problems noted above in the context of recent TREC Microblog retrieval tasks by proposing relational shallow syntactic structures to represent (query, tweet) pairs. Instead of try-ing to explicitly encode salient features from syntactic structures, we opt for a structural kernel learning framework, where the learn-ing algorithm operates in rich feature spaces of tree fragments au-tomatically generated by expressive tree kernel functions.
The following characterizes our approach: (i) it uses shallow syntactic parsers developed for social media, which are robust and shown to be accurate in such domains; (ii) tree kernels implicitly generate all possible tree fragments, thus all of them are used as fea-tures by the learning algorithm, solving the problem of engineering task-specific features. We design experiments using the 2011 and 2012 editions of the TREC Microblog track to verify the follow-ing: (i) relational syntactic features produced by a shallow syntactic parser are effective for L2R; (ii) our automatic feature engineering approach based on structural kernels is accurate and produces gen-eral features, which are complementary to those typically used in L2R models; and (iii) our structural representations can easily be combined with existing systems to boost their accuracy.

Our results show that employing relational syntactic structures improves on almost all the participating systems by only using their raw scores along with our L2R model based on relational syntactic structures. Our method boosts retrieval effectiveness by more than 5% on average and improves the rankings of participating systems by at least 7 positions on average.
Our syntax-aware re-ranker consists of two components: (i) a syntactic model that encodes tweets into shallow linguistic trees to ease feature extraction, and (ii) a tree kernel learning framework that computes similarities between (query, tweet) pairs. We also define a shallow tree kernel to enable efficient kernel computations.
Our approach to extract features from (query, tweet) pairs goes beyond traditional feature vectors. We employ structural syntactic models ( STRUCT ) that encode each tweet into shallow syntactic Figure 1: Shallow tree representation for an example (query, tweet) pair: (  X  X acebook privacy X ,  X  X acebook Must Explain Pri-vacy Practices to Congress http://sns.ly/2Qbry7 X  ) (in the original tree we use word stems). Part-of-speech tag  X  refers to a com-mon noun. Note that an additional REL tag links the words (stems) common between the query and the candidate tweet, Facebook and privacy ). trees. The latter are input to tree kernel functions for generating structural features. Our structures are specifically adapted to the noisy tweets and encode important query/tweet relations.
In particular, our shallow tree structure (inspired by [6 X 8]) is a two-level syntactic hierarchy built from word lemmas (leaves) and part-of-speech tags that are grouped into chunks (Fig. 1). While full syntactic parsers would significantly degrade in performance on noisy texts such as tweets, our choice for shallow structure relies on simpler and more robust components: a part-of-speech (POS) tagger and a chunker. For POS tagging we use the CMU tagger [3] trained on Twitter data and an off-the-shelf OpenNLP chunker.
Fig. 1 provides an example of a candidate (query, tweet) pair each of which is encoded into a shallow linguistic structure. To up-weight the tree fragments spanning words that are found in both the query and the tweet we introduce a special REL tag at the level of part-of-speech and chunk nodes. This step is important to generate syntactic patterns that carry additional semantics of sharing com-mon terms between a query and a tweet. To find matching word pairs we lowercase and stem words and use plain string matching.
We employ a pointwise approach to re-ranking where a binary classifier is used to learn a model to discriminate between rele-vant and non-relevant (query, tweet) pairs. The prediction scores from a classifier are then used to re-rank candidates. We define a novel and efficient tree kernel function, namely, Sh allow syntactic T ree K ernel (SHTK), which is as expressive as Partial Tree Kernel (PTK) [4] to handle feature engineering over the structural repre-sentations of the STRUCT model. For feature vectors we use a linear kernel.
 Computing similarity between (query, tweet) pairs. A typical kernel machine classifies a test input example x using the following prediction function: h ( x ) = P i  X  i y i K ( x , x i ) , where  X  model parameters estimated from the training data, y variables, x i are support vectors, and K (  X  ,  X  ) is a kernel function that computes the similarity between two input objects.

We represent each (query, tweet) pair x as a triple composed of a query tree T q and a tweet tree T tw together with a traditional feature vector v , i.e., x =  X  T q , T tw , v  X  . Given two (query, tweet) pairs x i and x j , we define the following similarity kernel:
K ( x i , x j ) = K TK ( T i q , T j q ) + K TK ( T i q where K TK computes a tree kernel similarity between linguistic trees and K v is a kernel over feature vectors. It computes an all-vs-all tree kernel similarity between two (query, tweet) pairs. Shallow syntactic tree kernel. Following the convolution ker-nel framework, we define the new SHTK function from Eq. 1 to compute the similarity between tree structures. It counts the num-ber of common substructures between two trees T 1 and T 2 out explicitly considering the whole fragment space. The gen-eral equation for Convolution Tree Kernels is: K TK P of the nodes in T 1 and T 2 , respectively, and  X ( n 1 ,n the number of common fragments rooted in the n 1 and n 2 nodes, according to several possible definitions of the atomic fragments.
To speed up the computation of K TK , we consider pairs of nodes ( n 1 ,n 2 ) belonging to the same tree level. Thus, given H , the height of the STRUCT trees, where each level h contains nodes of the same type, i.e., chunk, POS, and lexical nodes, we define SHTK as the following: where N h T 1 and N h T 2 are sets of nodes at height h .
The above equation can be applied with any  X  function. To have a more general and expressive kernel, we use  X  from PTK, which employs subsequence kernels, thus making it possible to generate child subsets of the two nodes, i.e., it also allows for gaps, which makes matching of syntactic patterns less rigid.

The resulting SHTK is a special case of PTK [4], adapted to the shallow structural representation STRUCT . When applied to STRUCT trees, SHTK computes the same feature space as PTK, but faster (on average). Unlike PTK, where all combinations of node pairs are considered, the kernel definition in (2) constrains the node pairs being considered to be from the same level, i.e., the matched nodes have to be of the same type X  X hunk, POS or lexi-cals. Hence, the number of node pairs considered for matching by SHTK is smaller, which results in faster kernel evaluation.
Finally, given its recursive definition in Eq. 2 and the use of subsequences (with gaps), SHTK can derive useful dependencies between its elements. E.g., it will generate the following subtree fragments (in nested parenthesis format): 1. [ROOT [REL-NP[REL-^ facebook]][VP V][REL-NP 2. [ROOT [REL-NP[REL-^]][VP V][REL-NP [REL-N]]] 3. [ROOT [REL-NP][VP][REL-NP]] 4. [ROOT [VP[V explain]][NP[N privacy]]] .
 Subtree 3 generalizes Subtree 2, which, in turn, generalizes Sub-tree 1. These structures are interesting when paired with the query structure. E.g., given the query pattern, [REL-NP [REL-^][REL-N]] , which means a famous proper noun (^) followed by a noun, if the tweet contains Subtree 2, i.e., a famous proper noun (matched in the query) followed by a verbal phrase (VP) and a common noun (also matched in the query), the candidate tweet may be relevant.
To evaluate the utility of our structural syntactic re-ranker for microblog search we focus on the 2011 and 2012 editions of the ad-hoc retrieval task at TREC microblog tracks [5, 9]. Our main research question is: Does the use of relational syntactic features produced by our shallow syntactic parser, and the automatic feature engineering approach based on structural kernels lead to improve-ments in state-of-the-art L2R and retrieval algorithms?
To answer this question, we test our model in two settings. In the first, we re-implement an accurate recent L2R-based approach and add our features alongside its features. This will allow us to see directly if our features are complementary to the other features. We opted for the L2R approach in [2] ( X  X he UvA model X ), because of its comprehensiveness. It uses pseudo-test collections [1] to learn to fuse ten well-established retrieval algorithms and implements a number of query, tweet, and query-tweet features. It is a strong baseline, its performance ranks sixth and 26th in the 2011 and 2012 editions of the microblog track, respectively. In the second setting, we use the participant systems in the TREC microblog task as a black-box, and implement our model on top of them using only us-ing their raw scores (ranks) as a single feature in our model. This allows us to see whether our features add information to the ap-proaches these retrieval algorithms use. Dataset. Our dataset is the tweet corpus used in the TREC Mi-croblog track in both 2011 (TMB2011) and 2012 (TMB2012). It consists of 16M tweets spread over two weeks, and a set of 49 (TMB2011) and 60 (TMB2012) timestamped topics. We mini-mally preprocess the tweets X  X e normalize elongations (e.g., sooo  X  so) and normalize URLs and author ids. For the second set of experiments, we also use the system runs submitted at TMB2011 and TMB2012, which contain 184 and 120 models, respectively. Training and testing an L2R algorithm. For learning to rank we use SVM-light-TK 1 with no parameter tuning. In our first set of experiments, we train on TMB2011 topics, test on TMB2012 topics, and vice versa. In the second set, where we build upon the TREC participant runs, we train our system only on the runs submitted at TMB2011, and test on the TMB2012 runs. We focus on one direction only to avoid training bias, since TMB2011 topics were already used for learning systems in TMB2012.
 Feature normalization . When combining our features with those of the UvA model, while training and testing we use the features of the latter model as v in Eq. 1; these features are already normalized. In contrast, we use the output of participant systems as follows. We use rank positions of each tweet rather than raw scores, since scores for each system are scaled differently, while ranks are uni-form across systems. We apply the following transformation of the rank r : 1 / log ( r + 1) . In the training phase, we take the top {10, 20, or 30} systems from the TMB2011 track (in terms of P@30). For each (query, tweet) pair we average the transformed rank over the top systems to yield a single score. This score is then used as a single feature in v from Eq. 1. In the testing phase, for each partic-ipant system we want to improve, we use the transformed rank of the (query, tweet) pairs as the single feature in v .
 Evaluation. We report on the official evaluation metric for the TREC 2012 Microblog track, i.e., precision at 30 (P@30), and also on mean average precision (MAP). Following [2, 5], we re-gard minimally and highly relevant documents as relevant and use the TMB2012 evaluation script. For significance testing, we use a pairwise t-test, where M and N denote significance at  X  = 0 . 05 and  X  = 0 . 01 , respectively. Triangles point up for improvement over the baseline, and down otherwise. We also report the improvement in the absolute rank (R) in the official TMB2012 ranking.
Table 1 lists the outcome of our first set of experiments, where we use our syntactic features alongside the features of the UvA model. It shows the obtained MAP and P@30 scores when we train on TMB2011 and test on TMB2012 topics, and vice versa. The STRUCT model yields a significant improvement in P@30 and MAP scores on TMB2012 pushing up the system by 15 positions in the official ranking, and making it second best in TMB2011. The Table 1: System performance (P@30, MAP; higher is better) and system rank (R; lower is better) for UvA X  X  L2R system [2] (UvA), our re-implementation (UvA*), and a UVA* system us-ing our STRUCT model (+STRUCT). We report on relative im-provement (Impr) and statisical significance against UvA*. Model TMB2011 TMB2012 UVA .3880 .4460 6 .2450 .3920 26
UVA  X  .3845 .4456 6 .2467 .3870 28 + STRUCT .3991 .4571 2 .2683 .4277 13
Change +3.8% M +2.6% +4 +8.8% N +10.5% N +15 result support our claim that learning useful syntactic patterns from noisy tweets is possible and that relational syntactic features gen-erated by our shallow syntactic tree kernel improve over a strong feature-based L2R baseline.

Table 2 reports on the application of our syntax-aware re-ranker on participant systems. It has results for re-ranking runs of the best 30 systems from TMB2012 (based on their P@30 score) when we train our system using the top {10, 20, or 30} runs from TMB2011. Our re-ranker improves P@30 for all systems with a relative im-provement ranging from several points up to 10% X  X bout 5% on average. This is remarkable, given that the pool of participants in TMB2012 was large, and the top systems are therefore likely to be very strong baselines. We observe that our syntactic model has a precision-enhancing effect. In cases where MAP drops a bit it can be seen that our model sometimes lowers relevant documents in the runs. It is possible that our model favors tweets with a higher syn-tactic quality, and that it down-ranks tweets that contain less syn-tactic structure but are nonetheless relevant. This is an interesting direction for analysis in future work.

Looking at the improvement in absolute position in the official ranking (R), we see that, on average, using our re-ranker boosts the absolute position in the official ranking for top 30 systems by 7 positions. All in all, the results suggest that using syntactic features adds useful information to many state-of-the-art microblog search algorithms.

Finally, using aggregate scores from the best 10, 20 or 30 sys-tems from TMB2011 does not reveal large differences, which sug-gests that our syntax-aware re-ranker is robust w.r.t. the exact re-trieval models used in the training stage.

While improving the top systems from 2012 represents a chal-lenging task, it is also interesting to assess the potential improve-ment for systems that ranked lower. For this purpose, we select 30 systems from the middle and the bottom of the official ranking. Table 3 summarizes the average improvement in P@30 for three groups of 30 systems each: top-30, middle-30, and bottom-30. We find that the improvement over underperforming systems is much larger than for stronger systems. In particular, for the bottom 30 systems, our approach achieves an average relative improvement of 20% in both MAP and P@30. These results further support our hy-pothesis that syntactic patterns automatically extracted and learned by our re-ranker can provide an additional benefit for learning to rank methods on microblog data.
To the best of our knowledge, this work is the first to study the utility of syntactic patterns for microblog retrieval. We propose an efficient way to encode tweets into linguistic structures and use kernels for automatic feature engineering and learning. Our experi-Table 3: System performance for top, middle (mid), and bot-tom (btm) 30 systems from TMB2012 system ranking and rela-tive improvements using our method trained on top 20 (TOP20) performing systems in TMB2011.
 mental findings show that our model: (i) improves in both MAP and P@30 when coupled with the features from a strong L2R baseline; (ii) provides a complementary source of features general enough to improve the best 30 systems from TMB2012; (iii) the performance gains are stable when we use run scores from the top 10, 20 or 30 best systems for learning; and (iv) the improvement becomes larger for underperforming systems achieving an average 20% of relative improvement in MAP and P@30 for bottom 30 systems.
 Acknowledgments. This research was partially supported by the Google Europe Doctoral Fellowship Award 2013, the European Community X  X  Seventh Framework Programme (FP7/2007-2013) un-der grant agreements nr 288024 (LiMoSINe) and nr 312827 (VOX-Pol), the Netherlands Organisation for Scientific Research under nrs 727.011.005, 612.001.116, HOR-11-10, 640.006.013, the Cen-ter for Creation, Content and Technology (CCCT), the QuaMerdes project funded by the CLARIN-nl program, the TROVe project funded by the CLARIAH program, the Dutch national program COMMIT, the ESF Research Network Program ELIAS, the Elite Network Shifts project funded by the Royal Dutch Academy of Sciences (KNAW), the Netherlands eScience Center under number 027.012.105 the Yahoo! Faculty Research and Engagement Pro-gram, the Microsoft Research PhD program, and the HPC Fund. [1] L. Azzopardi, M. de Rijke, and K. Balog. Building simulated [2] R. Berendsen, M. Tsagkias, W. Weerkamp, and M. de Rijke. [3] K. Gimpel, N. Schneider, B. O X  X onnor, D. Das, D. Mills, [4] A. Moschitti. Efficient convolution kernels for dependency [5] I. Ounis, C. Macdonald, J. Lin, and I. Soboroff. Overview of [6] A. Severyn and A. Moschitti. Structural relationships for [7] A. Severyn, M. Nicosia, and A. Moschitti. Learning semantic [8] A. Severyn, M. Nicosia, and A. Moschitti. Building structures [9] I. Soboroff, I. Ounis, J. Lin, and I. Soboroff. Overview of the
