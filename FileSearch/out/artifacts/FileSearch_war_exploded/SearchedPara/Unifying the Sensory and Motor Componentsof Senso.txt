 When exposed to a novel visuomotor environment, for instanc e while wearing prism goggles, subjects initially exhibit large directional errors durin g reaching movements but are able to rapidly adapt their movement patterns and approach baselin e performance levels within around 30-50 reach trials. Such visuomotor adaptation is multifaceted, comprising both sensory and motor components [5]. The sensory components of adaptation can be measured through alignment tests in which subjects are asked to local ize either a visual target or their unseen fingertip, with their other (also unseen) fingertip (w ithout being able to make contact between hands). These tests reveal substantial shifts in th e perceived spatial location of both visual and proprioceptive cues, following adaptation to sh ifted visual feedback [7]. While a shift in visual spatial perception will be partially reflected in reaches towards visual targets, sensory adaptation alone cannot fully account for the completenes of visuomo-tor adaptation, since the shifts in visual perception are al ways substantially less than the experimentally-imposed shift. There must therefore be som e additional motor component of adaptation, i.e. some change in the relationship between the planned movement and the issued motor command. This argument is reinforced by the find ing that patterns of reach aftereffects following visuomotor adaptation depend stron gly on the motor task performed during adaptation [5].
 From a modelling point of view, the sensory and motor compone nts of adaptation have previously only been addressed in isolation of one another. Previously proposed models of sensory adaptation have assumed that it is driven purely by d iscrepancies between hand position estimates from different sensory modalities. Ghah ramani et al. [2] proposed a computational model based on a maximum likelihood principl e, details of which we give in Section 3. On its own, this sensory adaptation model cannot p rovide a complete description of visuomotor adaptation since it does not fully account for improvements in performance from trial to trial. It can, however, be plausibly combined w ith a conventional error-driven motor adaptation model in which the performance error is cal culated using the maximum likelihood estimate of hand position. The resulting compos ite model could plausibly account for both performance improvements and perceptual shifts du ring visuomotor adaptation. According to this view, sensory and motor adaptation are ver y much independent processes, one driven by sensory discrepancy and the other driven by (es timated) task performance error.
 In Section 4, we argue for a more unified view of sensory and mot or adaptation in which all three components of adaptation are jointly guided by opt imal Bayesian inference of the corresponding potential sources of error experienced on ea ch trial, given noisy visual and proprioceptive observations of performance and noisy moto r execution. This unified sensory and motor adaptation model is also able to account for both pe rformance improvements and perceptual shifts during visuomotor adaptation. However, our unified model also makes the surprising prediction that a motor disturbance, e.g. an ext ernal force applied to hand via a manipulandum, will also elicit sensory adaptation. The ML E-based model predicts no such sensory adaptation, since there is never any discrepan cy between sensory modalities. We test this prediction directly with an experiment (Sectio n 5) and find that force field adaptation does indeed lead to sensory as well as motor adapt ation. Before describing the details of the models, we first outline a basic mathematical frame-work for describing reaching movements in the context of a mo tor adaptation experiment, representing the assumptions common to both the MLE-based a nd the Bayesian adapta-tion models. Figure 1 illustrates a graphical model of a sing le reaching movement during an adaptation experiment, from the subject X  X  point of view. The multiple components of visuomotor adaptation described above correspond to three distinct potential sources of observed outcome error (across both observation) modaliti es in a single reaching trial. On trial t , the subject generates a (known) motor command u t . This motor command u t leads to a final hand position y t , which also depends on some (unknown) motor disturbance r t (e.g. an external force applied to the hand) and motor noise  X  u t . We assume the final hand position y t is given by ics of the reaching movement, it can be regarded as a first-ord er approximation to the true dynamics. Similar assumptions have proved very successful elsewhere in models of force field adaptation, e.g. [1] The experimenter ultimately measures the hand position y t , however this is not directly observed by the subject. Instead, noisy and potentially shi fted observations are available through visual and proprioceptive modalities, , respectively.
 We denote the full set of potential disturbances on trial t by disturbance r t and selects his motor commands on each trial accordingly. Fo r reaches to a visual target located at v  X  t , the appropriate motor command is given by Adaptation can be viewed as a process of iteratively updatin g the disturbance estimate,  X  r t , following each trial given the new (noisy) observations v t and p t and the motor command u . Exactly how the subject uses the information available to i nfer the current disturbances is the subject of subsequent sections of this paper. The prevailing view of sensory adaptation centres around th e principle of maximum likeli-hood estimation and was first proposed by Ghahramani et al. [2 ] in the context of combining discrepant visual and auditory cues in a target location tas k. It has nevertheless been wide-ley accepted as a model of how the nervous system deals with vi sual and proprioceptive cues. Van Beers et al. [7], for instance, based an analysis of the relative uncertainty of visual and proprioceptive estimates of hand location on thi s principle.
 We suppose that, given the subject X  X  current estimate of the visual and proprioceptive by respectively. These distinct estimates of hand position ar e combined via maximum likelihood estimation [7] into a single fused estimate of hand position .The maximum likelihood estimate (MLE) of the true hand position y t is given by The MLE-based sensory adaptation model states that subject s adapt their future visual and proprioceptive estimates of hand location towards the MLE i n such a way that the MLE itself remains unchanged. The corresponding updates are gi ven by where  X  is some fixed adaptation rate. This adaptation principle can be interpreted as an online expectation-maximization (EM) procedure in the gra phical model shown in Figure 2. In this model, r v and r p are treated as parameters of the model. The E-step of the EM procedure corresponds to finding the MLE of y t and the M-step corresponds to gradient ascent on the likelihood of  X  r v and  X  r p . 3.1 Extending the MLE model to account for motor component of adaptation As it stands, the MLE-based model described above only accou nts for sensory adaptation and does not provide a complete description of sensorimotor adaptation. Visual adaptation will affect the estimated location of a visual target, and the refore also the planned movement, but the effect on performance will not be enough to account for complete (or nearly complete) adaptation. The performance gain from this component of ada ptation will be equal to the discrepancy between the initial visual setimate of hand pos ion and the MLE -which will be substantially less than the experimentally imposed shift.
 This sensory adaptation model can, however, be plausibly co mbined with a conventional error-driven state space model [6, 1] of motor adaptation to yield an additional motor component of adaptation  X  r y t . The hand position MLE  X  y t can be used in place of the usual uni-modal observation assumed in these models when calcula ting the endpoint error. The resulting update for the estimated motor disturbance  X  r y t on trial t is given by rate.
 This combined model reflects the view that sensory and motor a daptation are distinct processes. The sensory adaptation component is driven pure ly by discrepancy between the senses, while the motor adaptation component only has acces s to a single, fused estimate of hand position and is driven purely by estimated performance error. We propose an alternative approach to solving the sensorimo tor adaptation problem. Rather than treat the visual shifts r v and r p as parameters, we consider all the disturbances (in-cluding r y t ) as dynamic random variables. We assume that the subject X  X  b eliefs about how these disturbances evolve over time are characterised by a t rial-to-trial disturbance dynamics model given by where A is some diagonal matrix and  X  t is a random drift term with zero mean and diagonal covariance matrix Q , i.e. A and Q are both diagonal to reflect the fact that each disturbance ev olves independently. We denote the diagonal elements of A by a = ( a v , a p , a u ) and the diagonal of Q by q = ( q v , q p , q u ). The vector a describes the timescales over which each disturbance persi sts, while q describes the amount of random variation from trial to trial , or volatility of each disturbance. These parameters reflect the statistics of the usual fluctuations in sensory calibration errors and motor plant dynamics, which the sens orimotor system must adapt to on an ongoing basis. (Similar assumptions have previously b een made elsewhere [3, 4]). Combining these assumptions with the statistical model of e ach individual trial described in Section 2 (and Figure 1), gives rise to a dynamical model of the disturbances and their impact on reaching movements, across all trials. This model , representing the subjects beliefs about how his sensorimotor performance is liable to vary over time, is illustrated in Figure 4. We propose that the patterns of adaptation and the s ensory aftereffects exhibited by subjects correspond to optimal inference of the disturba nces r t within this model, given the observations on each trial.
 The linear dynamics and Gaussian noise of the observer X  X  mod el mean that exact inference is straightforward and equivalent to a Kalman filter. The laten t state tracked by the Kalman observations v t and p t are related to the disturbances via where z t = ( v t  X  u t , p t  X  u t ) T and H is the matrix of 1 X  X  and 0 X  X  in equation (14). The observation noise covariance is given by The standard Kalman filter update equations can be used to pre dict how a subject will update estimates of the disturbances following each trial a nd therefore how he will select his actions on the next trial, leading to a full prediction of performance from the first trial onwards. We have described two alternative models of visuomotor adap tation which we have claimed can account for both the motor and sensory components of adap tation. We fitted both Figure 5: (a) Experimental Setup, (b) Sample trajectories a nd performance error measure models to performance data from a visuomotor adaptation exp eriment [4] to validate this claim. In this study in which this data was taken from, subjec ts performed visually guided reaching movements to a number of targets. Visual feedback o f hand position (given via a The mean directional error (averaged over targets and over s ubjects) over trials is plotted in Figure 4. The Matlab function lsqnonlin was used to find the parameters for each model which minimized the sum of the error between the data and the p redictions of each model. model we assumed that all disturbances had the same timescal e, i.e. all elements of a were in Figure 4. The spread of adaptation across components of th e model was qualitatively similar between the two models, although no data on perceptu al aftereffects was available from this study for quantitative comparison. The Bayesian m odel clearly displays a closer fit to the data and the Akaike information criterion (AIC) confir med that this was not simply due to extra parameters ( AIC = 126 . 7 for the Bayesian model vs AIC = 159 . 6 for the MLE-based model).
 Although the Bayesian model appears to describe the data bet ter, this analysis is by no means conclusive. Furthermore, the similar scope of predic tions between the two models means that gathering additional data from alignment tests m ay not provide any further leverage to distinguish between the two models. There is, ho wever, a more striking difference in predictions between the two models. While the MLE-based m odel predicts there will be sensory adaptation only when there is a discrepancy between the senses, the Bayesian model predicts that there will also be sensory adaptation in respo nse to a motor disturbance such as an external force applied to the hand). Just as a purely vis ual disturbance can lead to a multifaceted adaptive response, so can a purely motor di sturbance, with both motor and sensory components predicted, even though there is neve r any discrepancy between the senses. This prediction enables us to distinguish decisive ly between the two models. 5.1 Experimental Methods We experimentally tested the hypothesis that force field ada ptation would lead to sensory adaptation. We tested 11 subjects who performed a series of t rials consisting of reaching movements interleaved with perceptual alignment tests.
 Subjects grasped the handle of a robotic manipulandum with t heir right hand. The hand was not visible directly, but a cursor displayed via a mirror /flat screen monitor setup (Fig-ure 5.1(a)) was exactly co-planar and aligned with the handl e of the manipulandum. In the movement phase, subjects made an out-and-back reaching movement towards a visual target with their right hand. In the visual localization pha se, a visual target was displayed pseudorandomly in one of 5 positions and the subjects moved t heir left fingertip to the perceived location of the target. In the proprioceptive loc alization phase, the right hand was passively moved to a random target location, with no visu al cue of its position, and subjects moved their left fingertip to the perceived locatio n of the right hand. Left fingertip Figure 6: (a) Average lateral (in direction of the perturbat ion) localization error across subjects before vs after adaptation, for vision and proprio ception. Error bars indicate standard errors. (b) Same plots for y -direction positions were recorded using a Polhemus motion tracker. Ne ither hand was directly visible at any time during the experiment.
 Subjects were given 25 baseline trials with zero external fo rce, after which a force field was gradually introduced. A leftward lateral force F x was applied to the right hand during the reaching phase. The magnitude of the force was proportional to the forward velocity  X  y of the hand, i.e.
 The force was applied only on the outward part of the movement (i.e. only when  X  y &gt; 0). After steadily incrementing a during 50 adaptation trials, the force field was then kept constant at a = 0 . 3 N/ ( cms  X  1 ) for a further 25 post-adaptation test trials. All subjects received a catch trial at the very end in which the force field w as turned off. The particular force field used was chosen so that the cursor t rajectories (and motor com-mands required to counter the perturbation) would be as clos e as possible to those used to generate the linear trajectories required when exposed t o a visuomotor shift (such as that described in [7]). Figure 5.1(b) shows two trajectorie s from a typical subject, one from the post-adaptation test phase and one from the catch trial a fter adaptation. The initial outward part of the catch trial trajectory, the initial move ment is very straight, implying that similar motor commands were used to those required by a v isuomotor shift. 5.2 Results We compared the average performance in the visual and propri oceptive alignment tests before and after adaptation in the velocity-dependent forc e field. The results are summarized in Figure 6(a). Most subjects exhibited small but significan t shifts in performance in both the visual and proprioceptive alignment tests. Two subject s exhibited shifts which were more than two standard deviations away from the average shif t and were excluded from the analysis. We found significant lateral shifts in both visual and proprioceptive localization error in the direction of the perturbation (both p &lt; .05, one-tailed paired t-test). Figure 6(b) shows the same data for the direction perpendicular to t he perturbation. Although the initial localization bias was high, there was no significant shift in this direction following adaptation.
 We quantified each subject X  X  performance on each trial as the perpendicular distance of the furthest point in the trajectory from the straight line betw een the starting point and the target (Fig. 5.1(b)). We fitted the Bayesian and MLE-based mo dels to the data following the same procedure as before, only this time penalizing the disa greement between the model and the data for the alignment tests, in addition to the reach ing performance. Figure 7 illustrates the averaged data along with the model fits. Both models were able to account reasonably well for the trends in reaching performance acro ss trials (7(a)). Figures 7(b) and 7(c) show the model fits for the perceptual localization task . The Bayesian model is able to account for both the extent of the shift and the timecourse of this shift during adaptation. Figure 7: Trial-by-trial data and model fits. (a) Reaching er ror, (b) Visual alignment test error, (c) Proprioceptive alignment test error. The Bayesi an (solid blue lines) and MLE-based (dashed red lines) were fitted to averaged data across s ubjects (circles). Since there was never any sensory discrepancy, the MLE-base d model predicted no change in the localization task. Our experimental results demonstrate that adaptation of re aching movements in a force field results in shifts in visual and proprioceptive spatial perception. This novel finding strongly supports the Bayesian model, which predicted such adaptation, and refutes the MLE-based model, which did not. The Bayesian model was able t o account for the trends in both reaching performance and alignment test errors on a t rial-to-trial basis. Several recent models have similarly described motor adapt ation as a process of Bayesian inference of the potential causes of observed error. K  X ordi ng et al. [3] proposed a model of saccade adaptation and Krakauer et al. [4] modelled visuomo tor adaptation based on this principle. Our work extends the framework of these models to include multiple observation modalities instead of just one, and multiple classes of dist urbances which affect the different observation modalities in different, experimentally measu rable ways.
 Overall, our results suggest that the nervous system solves the problems of sensory and motor adaptation in a principled and unified manner, support ing the view that sensorimotor adaptation proceeds according to optimal estimation of enc ountered disturbances. [1] Opher Donchin, Joseph T Francis, and Reza Shadmehr. Quan tifying generalization from [2] Z. Ghahramani, D.M. Wolpert, and M.I. Jordan. Computati onal models for sensorimotor [3] Konrad P. K  X ording, Joshua B. Tenenbaum, and Reza Shadme hr. The dynamics of [4] John W Krakauer, Pietro Mazzoni, Ali Ghazizadeh, Roshni Ravindran, and Reza Shad-[5] M.C. Simani, L.M. McGuire, and P.N. Sabes. Visual-shift adaptation is composed of [6] K A Thoroughman and R Shadmehr. Learning of action throug h adaptive combination [7] Robert J van Beers, Daniel M Wolpert, and Patrick Haggard . When feeling is more
