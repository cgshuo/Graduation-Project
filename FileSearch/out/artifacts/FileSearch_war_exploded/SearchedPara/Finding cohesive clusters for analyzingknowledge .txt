 A knowledge community [2] is an informal community of researchers who build on each other X  X  ideas and share similar interests. Such comm unities usually con-sist of people doing research on the same or closely related fi eld. They are also known as intellectual communities , or schools of thought [19]. Belonging to such a community has the advantage for a researcher of making it eas ier to disseminate and gather new knowledge. Papers of interest are easier to fin d, new papers have an already existing audience and the content is familiar and thus accessible. upon previous discoveries, thus papers often cite other pap ers in the same com-munity. Certain high impact or historical papers will be fre quently cited within the community. Papers from related communities will also be cited occasion-ally. Since patterns of citation are shared among papers in t he same community, knowledge communities can be identified by clustering docum ents based on their citations.
 what features of a community predict whether it will grow or s hrink. To do this, we cluster papers based on the papers they cite. As explained in detail later, not every document is assigned to a community; many documents ar e assigned to a background cluster. Once the knowledge communities are di scovered, we fit a supervised model and find which features of the clusters are s tatistically signif-icant in predicting cluster growth. Features used include t he citation patterns, (e.g., how many of the citations are to papers within or exter nal to the com-munity), vocabulary usage (e.g., how unique are the words us ed to the cluster), and exogenous measures such as the fraction of authors who ha ve an industrial rather than academic affiliation.
 their knowledge use, as measured by what papers or communities they cite, and rhetoric , as measured by what vocabulary they use and how vocabulary changes over time or across communities. We find that success ful communities use knowledge and rhetoric in opposite ways. Successful com munities flexibly use broad knowledge . They have a unique area of focus, but cover new areas and incorporate knowledge from multiple domains. Also, succes sful communities use narrow, unchanging vocabulary, which is common across know ledge communities. Apparently, novel work that is described with new terminolo gy is harder to understand; standardized terms can reduce this difficulty. To reach these conclusions, we cluster papers into foregrou nd clusters (knowledge communities), which cite many of the same papers, or into a mo re diffuse back-ground. We take the notion of foreground and background from vision, where there are often cohesive foreground objects in front of a mor e diffuse background. In text mining, foreground clusters are cohesive communiti es or topics. The back-ground consists of lower density regions, where there are fe wer similar items. For example, when clustering documents, the foreground will co nsist of documents in some specific area (e.g., that cite the same papers), while the background will contain documents that cover several different areas on topics that are not widely cited.
 where one wants to find the tight groups of papers or people. Cl ustering pub-lished documents according to what they cite, as we do in this paper, reveals knowledge communities, their sizes and how they evolve in ti me by drifting in nearby areas of scientific research, expanding or dying out. Co-citation analysis has long been used to systematically map and examine the netw ork structures of research papers or patents and to isolate and identify the st ructure of scientific disciplines [9, 20]. A wide variety of methods have been used since then to clus-ter documents based on citations, including k -means, co-clustering [3] and EM methods. However, none of these co-citation-based cluster ing algorithms used for text mining find foreground clusters against a backgroun d. Below, we pro-pose and test two new algorithms aimed at foreground/backgr ound clustering: background k -means , a simple modification to k -means; and Streemer , a more elaborate algorithm.
 clusters can be used as an aid for information retrieval, or f or looking at the growth of communities over time [17]. We use the clusters tha t we find to build predictive models of community growth. The properties of th e clusters (e.g. size, growth rate, cohesiveness, etc.) are used both as features a nd as values to be predicted. The paper consists of two main parts. In the first half of the pa per, in sections 2 and 3, we present the two clustering methods, background k -means and Streemer, and find foreground clusters against a background, constitu ting our knowledge communities. We evaluate the clusters in terms of their cohe rence, using external labellings of the clustered documents. In the second half, i n sections 4 and 5, we describe the features and the model used to predict the futur e growth of the clusters from their past properties.
 the clusters found and to do so efficiently for large and high-d imensional data sets. Coherence is defined in terms of the cluster size, separ ation (distance) from neighboring clusters and cluster density. After clusterin g the papers, we use the results to generate features and use a generalized least squ ares model to predict the evolution of clusters over time. Data from different time periods are clustered separately. Finally, we examine which features are signific ant in this prediction and therefore are indicative of successful knowledge commu nities.
 and background k -means clustering algorithms. Section 3 describes the data and evaluates the results of the clustering. Section 4 expla ins the generalized least squares model used for modelling the growth of communi ties. Section 5 presents the results for community prediction and analyzes the features that were most important. We conclude with a review of related wor k in section 6 and a discussion in section 7. We want to cluster the data so that observations that are not a ssigned to a standard cluster are assigned to a diffuse cluster that repre sents the background. This background will surround all (or almost all) of the fore ground clusters, which are embedded like islands in the background. Thus, the background clus-ter is not only non-convex, but also non-compact, i.e. it con tains holes. Such clusters cannot be found by many widely used methods such as k -means, which finds a tessellation of the space where every piece is defined b y piecewise lin-ear boundaries. The resulting clusters are always convex, a nd cannot represent foreground clusters embedded in a background.
 two mixture components with similar means, but different var iances. Assuming, as shown in figure 1 for the 1-D case, that the separation betwe en the cluster centers is small compared to the difference between the clust er variances, we would prefer the cluster with center  X  1 = 0 to be surrounded by the other cluster, in accordance with the posterior probabilities. The best th at we can expect from k -means, however, is to pick a decision boundary between the m eans of the two distributions. This effectively assigns all negative point s to the left cluster, even though the probability of them belonging to the right cluste r is higher. which discourages finding clusters that are very small or ver y big. This follows from the view of k -means as a limiting case of a Gaussian mixture model with equal priors and equal cluster variances, where k -means emerges in the limit of the variances going to zero [13]. However, when clusterin g documents into knowledge communities, we do not expect all of the communiti es to be of similar sizes. This is another argument for using some alternative c lustering method, instead of k -means or a k -means variant. The input to Streemer consists of the data to be clustered, the fraction b of points in the background, and the number of clusters k . There are also some hidden parameters, which will be described later, but the result is not sensitive in their values. Additionally, Streemer requires a similarity func tion sim () between a data point and a cluster centroid, or between two centroids.
 ing clustering at minimal extra computational cost. Streem er initially finds a large number of candidate clusters using streaming cluster ing. Then it selects k of them that are good in terms of size, density and position wi th respect to the other clusters. In the last step, the points are assigned to t he k clusters, or to the background, if they are far enough from every cluster.
 step 2 to generate a set of candidate clusters. Examining eac h point in sequence, it either adds it to an existing candidate cluster, or it crea tes a new cluster and assigns the point to it. This typically gives a large number o f candidate clusters (a few thousand in our experiments). In steps 4-5, it selects k  X  X ood X  clusters from the candidates, where  X  X ood X  clusters are large and als o either cohesive or isolated. Finally, in steps 6-7 it assigns each point to a clu ster if it is sufficiently close to the cluster centroid, or otherwise to the backgroun d. The appropriate threshold is chosen to give the desired fraction of points in the background. CBC has many parameters and there is no principled way to deci de how to set them. The user of CBC ends up doing a blind search in the parame ter space, which is time-consuming and not guaranteed to produce good r esults. Streemer, by way of contrast, has only the minimum number of parameters that are re-quired and all the parameters have an intuitive interpretat ion that makes setting them easy.
 ing clustering, requiring time on the order of | S | N operations ( | S | is the number of candidate clusters found and N the number of data points). The part of the algorithm filtering the candidate clusters involves compar isons between them-selves and is repeated approximately log( | S | ) times. Finally, the last step makes one more pass over the data making kN comparisons. Overall, the complexity of Streemer is dominated by the first pass, which is that of str eaming clustering [10].
 a strong bias towards equal sizes and variances. Also it can fi nd a background cluster that can surround the foreground clusters. This bac kground cluster is optional, in that it is possible to configure Streemer so that all the observations will be assigned to the foreground clusters. Streemer compa res favorably to stan-dard clustering methods. It is significantly faster and more efficient than EM. It is almost as fast as k -means, but it returns higher quality clusters with fewer structural restrictions. It also requires fewer (and more m eaningful) parameters than CBC. A general question with any streaming clustering algorithm is how to specify a threshold for similarity (or distance). As each observatio n is examined, a decision is made whether to add it to an existing cluster if it similar e nough, or to start a new cluster and put it there. Being a streaming algorithm it self, Streemer also requires a threshold on the similarity of items to clust er centroids. We have empirically found that the final clustering result of Streem er is not sensitive to the value of the threshold,  X  . Varying  X  from 0.0001 to 0.01 has almost no effect on the number of candidate clusters for a given dataset. (Thi s, even though the computer science dataset yields about 4,500 candidate c lusters while the management dataset yields 35,000). Small differences in the number of candidate clusters have no effect on the final result, as steps 4-5 filter t hem out. In all of our experiments we used  X  = 0 . 001.
 date clusters. Instead of setting it explicitly however, we perform binary search until the final number of clusters is k . Finally, in the last step Streemer assigns all points to the nearest cluster or, if no cluster is close en ough, to the back-ground. The algorithm selects the N (1  X  b )-th greatest distance and uses that as a threshold to assign points to their nearest foreground c luster or the back-ground. Equivalently, the user could specify this threshol d instead of b . In this case, our choice to specify b was motivated by some intuition on the structure of communities and a goal to understand the effect of belonging m ore closely to a community vs. being more dispersed.
 with a final step for generating a background cluster by trimm ing far points from the clusters. The difference is that Streemer finds a numb er of candidate clusters much larger than k , and uses a second step to select k of those candidates as clusters. This makes Streemer less greedy, which improve s cluster quality. Additionally, in standard streaming clustering, users spe cify a threshold, and thus cannot specify the desired number of clusters. We find it more intuitive and useful to specify the desired number of clusters and let Stre emer, by searching over the threshold values, find that number of clusters.
 We also evaluated a simple modification of the k -means algorithm to include a background cluster (figure 3). We call this method background k -means . Like k -means, the first step in every iteration is to assign each poi nt to its nearest cluster. The second step, which is new, moves to the backgrou nd a pre-defined fraction of the points that have the greatest distance from t he centroid of their cluster. The third step then re-estimates the cluster centr oids using only the assigned points and the procedure repeats until convergenc e. As in k -means, all the foreground clusters are convex and have piecewise linea r boundaries. To test and validate the clustering methods, we used two data sets, one consisting of papers from computer science fields and the other from mana gement. The computer science data were drawn from CiteSeer, a digital li brary of papers from conferences and journals in computer science. CiteSee r collects computer science papers posted on the Internet as well as by linking di rectly to publishers, conference sites, and journals, and then parses these artic les to find the citations and descriptive information in each paper. We cross-refere nced these papers with the DBLP Computer Science Bibliography, a database that ind exes a similar group of computer science papers, in order to verify existin g information and gather supplemental information on journals and conferenc es. The majority of papers in the version of these databases that we used were fro m between 1992 and 2003.
 lected 41 core journals and conference proceedings in manag ement and collected complete sets of all articles and their citations for these 4 1 journals/proceedings since 1956. The list includes within the field of management b oth the macro (which is heavily influenced by economics and sociology) and the micro (which is heavily influenced by psychology) specialties.
 vectors with elements 0 or 1. The j -th element of vector i is 1 if document i was cited by document j , and 0 otherwise. The vectors were L 2 -normalized before clustering, to give documents with different number o f citations equal weight. The computer science dataset consists of 341,458 do cuments, represented as boolean vectors of 197,163 dimensions. The vectors are sp arse: the average number of nonzero elements (i.e. number of times a document w as cited) is 5.19. The management dataset consists of 114,450 documents in 1,0 82,729 dimensions with 21.12 citations per document on average. We also extrac ted the text of the paper titles and keywords. We clustered our two data sets using k -means, background k -means, and Streemer and evaluated the clusters by computing two measures of how h omogeneous are the class labels of the points in the clusters. As labels we us ed the journals and conference proceedings where the documents were published . Even though the mapping between journals/conferences and knowledge commu nities is not one-to-one, there is some correlation between them (for example most researchers in computer architecture, graphics, and machine learning p ublish in different venues). Citeseer provides publication information, but b ecause the annotation is automated, it contains many errors. To get more reliable p ublication data we mapped a sample of the papers to DBLP, which is of higher data q uality. We found that the annotated documents belonged to 1,495 journa ls/proceedings. For the management dataset we used the titles of the 41 journa ls/proceedings where the documents were published.
 entropy (WAE) [6]: where n i is the number of points in cluster i , N is the total number of points and E i is the entropy of the distribution of labels (i.e., journals or proceedings) for points in cluster i . The lower the WAE, the better the clustering matches the given data labels.
 where Y and  X  Y are random variables taking the values of the external and th e cluster labels respectively. I ( Y,  X  Y ) is the mutual information between these two variables and H ( X ) is the entropy of a random variable X . NMI is 1 when the clusters match the external labels exactly and 0 for a random clustering. In the experiments we compared k -means, background k -means and Streemer using the cosine as the similarity function. We used b = 0 . 67 for the computer science dataset and b = 0 . 45 for the management dataset.  X  was set to 0.001 and k to 22 for both datasets. These values were deemed reasonable , based on our experience with the fields. In spite of doing an extensive search over the user-specified values, we were unable to get CBC to give anyth ing close to the desired foreground/background split and number of cluster s, so no CBC results are given. For k -means, which does not explicitly find a background cluster, we used the biggest of the clusters as background. Fortunately , for both datasets one cluster was much larger and heterogeneous than the rest. The largest k -means cluster for the computer science dataset contained 21% of th e documents and for management 39%; all of the other clusters were approxima tely of equal sizes in both cases.
 entropy for all the clusters (including background), k -means is either better or comparable to the background k -means and Streemer. This is not surprising, as the background cluster found by background k -means and Streemer is both big and of low cohesiveness by construction. Therefore its entr opy is quite high and, coupled with the big size, it contributes significantly in th e overall weighted en-tropy. The reason that background k -means and Streemer are worse for the com-puter science case but about the same for management is that t he background cluster was bigger in computer science (67%) than in managem ent (45%) and thus had a larger effect on the overall entropy. In terms of NMI , k -means was about the same as background k -means and Streemer for the CiteSeer data and worse for management.
 poses is the average entropy and NMI of the foreground cluste rs only, denoted with  X (fg) X  in the table. Streemer is always best for NMI (fg) , but background k -means is sometimes competitive for WAE (fg). Excluding the large, diffuse background cluster from the calculation can only improve th e entropy; thus both background k -means and Streemer perform better than k -means for both WAE and NMI. As hoped, including a background cluster always lea ds to better fore-ground clusters. Most current popular clustering algorithms assume that clu sters over time are static -that is, that all clusters exist at the beginning and end of the time period under consideration and that no new ones are formed in the int erim [1, 25]. This is a tolerable simplifying assumption for short periods in s table environments but more troubling for data over time in a dynamic environmen t where we must consider emerging clusters, merging clusters, and dying cl usters. The cluster structure of Computer Science documents in 1975 is very diffe rent from that of 1995.
 tering X ) that successfully resolves this temporal confoun ding. We built an iter-ated  X  X verlapping X  clustering methodology into our algori thm that re-clusters in overlapping 5-year blocks, stepping forward by one year at a time. Therefore the elements in year 1990 would be clustered based only on the ele ments in 1985 to 1990, papers in year 1991 would be clustered based only on 198 6 to 1991, and so on. We then match up clusters over time using the overlapping years of the two clustering runs (in the case above, 1986-1990). Our cluster ing algorithm looks only backward in time to determine clusters in a given year;  X  linking X  is only a done after the fact. The temporal overlap ensures some cons istency in cluster composition, while allowing new clusters to be created and e xisting clusters to merge or wither away.
 A and C appear throughout the 3 time windows. Cluster B disapp ears in the third time window. Cluster D appears in the second time window. Thr oughout the time windows the slow dynamic movement of the clusters as they cha nge over time is visible. Essentially, we have chained together a series of o verlapping clusterings so that we can create continuity while allowing for an evolving knowledge landscape. looking only, based on the previous 5-year frame -an appropr iate  X  X ontext X  for knowledge development. At the same time we find very high cont inuity between clusters, since the knowledge landscape we created changes gradually. Another benefit of this method is that our measures of  X  X entrality X  at the paper and cluster levels refer to the appropriate frame rather than an aggregate over the entire time range, as with all other standard methods.
 we need to use only clusters (and cluster features) based on e arlier data. Our process assures that clusters at a given time only depend on p rior history. The clusters capture what agents looking at that intellectual l andscape would see at that time (i.e., in real time without the benefits of hindsigh t). The evolution of clusters over time can be seen as a result of t he choices agents make as they, in aggregate, position themselves on this land scape. 1992 to 2003 marked a dramatic growth of computer science and radical evo lution of its scope of use. To further test the validity of our method we look at th e knowledge communities we found and see if they accurately reflect the ch anges in com-puter science during this period. Figure 5 and table 2 give de tails on the 21 knowledge communities we identified. Figure 5 provides grap hs of the growth of each knowledge community over time, as well as a sense of each community X  X  appearances and disappearances. Table 2 details our propos ed names for each knowledge community and also provides some details about th em.
 new knowledge communities formed and none disappeared. Fro m 1999 to 2001 five knowledge communities disappeared and none were create d. This finding is in keeping with the dramatic growth of computer science in th e Internet boom and the subsequent collapse of the Internet bubble. The move ment and rates of change of clusters also reflect these changes, with more acti vity during times of shake-up in 2000-2001 as knowledge communities collective ly struggle to readjust to and survive in a period of dramatic correction in the secto r.
 can be seen in microcosm here. For example, clusters 5 and 21 a re both on very similar topics - X  X achine vision/graphics X  and  X  X mage analysis/tracking X , respectively -but are very distinct communities. In the mid 1990s the first expe-rienced a steep decline as a research community while the lat ter emerged from nowhere and became quite significant. Clusters 4 and 20 on  X  X e sign of crypto-graphic systems X  and  X  X ryptography X , respectively, exper ience the same pattern, with cluster 20 seeming to emerge and grab cluster 4 X  X  intell ectual space. These seem to be examples of established communities of researche rs being unable to absorb or compete with emerging research communities. Duri ng the mid 1990s as the Internet grew exponentially and broadband allowed vide o to be more easily transferred and stored, we also saw the emergence of two clus ters on  X  X ongestion control X  and  X  X mage analysis/tracking X . At the same time we saw the decline of  X  X istributed computing X  and  X  X hared memory/parallel proc essing X . These trends seem to fit the intuitive understanding of trends in computer science. edge community or the absorption of one knowledge community by another. Our dynamic clustering methodology allows some insight int o how knowledge evolves and changes. For example, in 1996 the cluster repres enting the knowl-edge community researching  X  X nternet traffic management, X  s hattered to form several smaller clusters. Most fragments were below the thr eshold of size and cohesiveness to be knowledge communities, but there did rem ain remnants of the original cluster and a new cluster which represents  X  X is tributed comput-ing X . Both are significantly smaller -38% and 16%, respectiv ely, of the size of the original cluster. In 2000 there was also a merger between the clusters rep-resenting the knowledge communities researching  X  X onstra int satisfaction X  and  X  X ptimization X , respectively. These fields are clearly rel ated, and both clusters were approximately the same size.
 the start of our study. In 1996 a new cluster emerged on  X  X atam ining/Web X . One of its top three most cited papers is by Larry Page and Serg ey Brin, the founders of Google. In 1996 the knowledge community represe nting  X  X atamin-ing/Web X  comprised only 0.23% of our computer science paper s -in 2003 it represents 7.20%. Our main goal, however, is not to give us in sight into what happened historically, but to predict what will happen goin g forward in an area of research and to define the attributes of knowledge communi ties that lead to their differential success. For the rest of the paper we analy ze the computer sci-ence dataset. The same analyses on the management dataset ga ve qualitatively similar results [24]. In this section, we use the foreground and background cluste rs found previously as the basis for analyzing the growth of knowledge communiti es. We ask how the knowledge content, as measured by their citations, and the r hetorical content, as measured by the vocabulary they used, affect the success of th ese communities. We also examine the effect of community characteristics of co hesion, uniqueness, and adaptability, as described below. Our goal is to investigate the significance of a number of fact ors in explaining the success of a knowledge community. We look at attributes s uch as the cohe-siveness and uniqueness of their vocabulary and the knowled ge they draw on. Our dependent (predicted) variable is a measure of the vigor or performance of a community/cluster at a given time, as measured by the num ber of papers presented at conferences or published in journals in a clust er each year. dard errors for determining statistical significance, whic h allowed us to investi-gate the time trends within our data while also adjusting the standard errors for intra-group correlations. This is necessary because we bel ieve the performance measures of any cluster will be correlated over time. Since t he knowledge com-munities were clustered based on their similarity of citati ons, larger communities will tend to contain more diverse citations. We included a 1-year lag in the re-gression as well, thus controlling for the size of the cluste r the previous year; this means that the results presented below are not due to community size. where i indexes the clusters, t indexes years (time), y it denotes the number of papers in a cluster presented or published each year, x it is the vector of features with corresponding coefficients  X  capturing effects that are the same across all clusters (the fixed effects), z it the features with coefficients b i which capture the variation across clusters (the random effects), and e it represents the error term. bility, leadership/coordination controls, prestige cont rols and industry/academia controls.
 of both the shared knowledge (papers cited) and shared rheto ric (words) of the knowledge community are significant for predicting its perf ormance. Knowledge cohesiveness represents how widely (or narrowly) authors i n the cluster searched tween the citations of each paper and the overall citations o f the cluster: where  X  c represents the centroid of cluster c for a given year; n c is the number of papers in cluster c , x i is the i-th paper in c and sim () is the measure of simi-larity, which in our experiments was the cosine function. Rh etorical cohesiveness measures how similarly authors in a cluster use vocabulary. It was computed as the similarity of the stemmed words in the title and keywords of each paper to the average for its cluster. As is common, stop words were rem oved.
 nity is, either in the knowledge it generates or in the rhetor ic (vocabulary) it uses, from other intellectual communities. Uniqueness of r hetoric represents how different the vocabulary of a knowledge community is at a give n point in time compared to other clusters. Similarly, uniqueness of knowl edge measures how dif-ferent the sources of knowledge of a knowledge community are at a given point in time. For this feature we compare the average citations or vocabulary for a cluster to all other clusters X  average citations or vocabul ary. For example, if a cluster generally uses the same keywords or cites the same pa pers, it will have a low  X  X niqueness. X  more over time relative to other clusters. Change in vocabul ary is measured by how much the word usage in a cluster changes from one year to the next; change in knowledge is measured by how much a cluster X  X  avera ge use of citations changes. In both cases, we compute the cosine similarity bet ween the 3-year running averages of the citation structure and language cen troids for each cluster and itself in the previous year.
 coordination) on three levels -from members of the communit y, for concentration of the institutions the members identify with, and for conce ntration in the venues the community publishes in. Space precludes a full descript ion of these features; for details, see [24].
 explaining differential performance in knowledge communit ies. We control for prestige on the member, journal/conference, and employer/ university levels. For members we wish to control for the prestige that would result from the  X  X op X  members of a field preferring to publish in some knowledge com munities, leading to superior performance. We constructed a variable by count ing the number of authors who were fellows of IEEE, ACM or the National Academy of Engineering and published in any of our communities. Next we constructed a variable that counted the number of papers coming from the twenty most pres tigious univer-sities in computer science as ranked by the US News and World R eport graduate school rankings. By doing this we control for the tendency of some communities to be associated with prestigious institutions. Lastly, we constructed a variable that counted the number of papers published in the top ten mos t prestigious journals as ranked by impact factor in Thomson ISI X  X  Impact F actors and the top ten most prestigious conferences, as ranked by citation impact by DBLP. We ranked these counts within year by cluster. The ranked list o f clusters by year indicated the relative prestige of knowledge communities o n multiple levels. filiated with a firm or academic/research institution. We the n code each paper as  X  X cademic X  if all of its authors are affiliated with academic/ research institutions,  X  X ndustry X  if all of its authors have firm affiliations, and  X  X i xed X  if some of its authors are affiliated with firms and some with academic/resea rch institutions. We entered this information into the regression by includin g the two categorical variables  X  X ixed X  and  X  X ndustry X .
 their marginal effects as well as the end joint effects. Our model examines the effects of all of the features discusse d above on knowl-edge community performance (table 3). We find that cohesive r hetoric (low vari-ance of vocabulary within a cluster) is associated with impr oved performance, while a broad use of knowledge (high variance of citations wi thin a cluster) max-imizes performance. Also, a knowledge community maximizes performance when it uses vocabulary that is similar to that of other clusters, while knowledge, as represented by citations, that is gathered from diverse sou rces predicts supe-rior community performance. Community flexibility in citat ions predicts com-munity growth, while changing vocabulary has the opposite e ffect (significant at p &lt; 0 . 05).
 performance is enhanced by a high percentage of purely indus try-affiliated pa-pers. On the other hand, a higher percentage of mixed industr y-affiliated papers indicated a negative impact on community performance ( p &lt; 0 . 05). Clusters with higher proportions of purely industry-affiliated paper s were associated with higher performance than clusters with elevated proportion s of either purely aca-demic or mixed-affiliation clusters, but the direction of cau sality is unclear. three measures, we also examined the correlation between rh etoric and citation structures for each pair of similar variables. There was a si gnificant, positive re-lationship between citation and rhetoric measures for all t hree knowledge com-munity measures. It is not surprising that use of language an d citations are related to each other, since authors are citing papers they l earned from. On the other hand, they are not identical -a paper, while it relies o n citations, is not only a function of them. Analysis shows that all the effects de scribed above are unchanged, and remain statistically significant when corre lation is taken into account.
 tics. They use knowledge and rhetoric in diametrically oppo site ways:  X  Successful use of knowledge means using broad, rapidly repositioned and com-munity-specific knowledge.  X  Successful use of rhetoric means using narrow, unchanging language, which is common to many communities.
 sistent results [24]. We focus on the way knowledge communities use knowledge and r hetoric to help explain why some of these knowledge communities flourish and grow. We find that the patterns for knowledge and rhetoric use are very diff erent. A broad-searching, far-ranging, and flexible use of knowledge maxim izes community per-formance, while a shared, common, and stable rhetoric is mos t beneficial to com-munity performance. We did not find support for the propositi on that the use of unique knowledge benefits knowledge communities. Increase d work by authors associated with firms had an overall positive effect on knowle dge community performance, but an increase in work done jointly by researc hers from firms and academic institutions led to an overall negative effect on kn owledge community performance.
 nities? We speculate that in situations of large-scale coll aboration and low co-ordination, a shared technical language helps minimize the cost and complexity of communication. Using a unified and consistent vocabulary , we believe, allows researchers to more efficiently exchange ideas and collabora te. Using terms that other communities know, makes it easier to be understood by t hese communities, too.
 gests that there is a tradeoff between exploration (searchin g for new ideas as measured by citing papers in diverse communities) and explo itation (making contributions based on papers central to one X  X  own communit y). The data here indicate that knowledge communities which search broadly a nd remain intellectu-ally nimble perform best. Particularly in the face of very di verse ideas, expressing these innovations in a unified rhetorical and intellectual f ramework allows many ideas to be absorbed by a successful community and translate d into a unified, efficient and shared rhetorical framework. Clustering has been used extensively for text mining [21]. I n many cases it is based on the actual words of the text, but it has also been used to cluster doc-uments based on their citation structure. Citation (and co-citation) analysis is quite old [23]. More recent research uses newer clustering a lgorithms, including spectral [4], information theoretic [3] or Bayesian models . Latent Dirichlet Al-location (LDA) is also increasingly used to cluster documen ts, including their evolution over time [1]. Other papers deal with the similar p roblem of clustering web pages, where the links take the role of citations [7, 8].
 falls into the category of distance-based methods, as define d in [26]. By going over the points twice and finding a background cluster, Stree mer avoids the prob-lems mentioned there of frequently scanning the points and o f treating them all equally. Much like BIRCH, Streemer first finds a large number o f clusters which it later reduces. The difference is that Streemer does not emp loy an external clustering algorithm to do that. In [26] the authors use aggl omerative hierarchi-cal clustering. Additionally, Streemer can use any provide d distance function, as opposed to BIRCH, which is limited to distances that can be co mputed by its  X  X lustering feature X  (CF) vectors.
 finds clusters by repeatedly adding points that are close tog ether and have a large number of neighbors. DBSCAN can find clusters of arbitr ary shapes, but it requires the specification by the user of the parameters Eps and MinPts and is very sensitive to their values. Streemer also requires si milar parameters, but we found that it is not sensitive to them. Furthermore, DBSCA N can suffer from robustness problems, because it operates on the whole set of points and does not do some form of preliminary clustering. If there is a string o f points connecting two clusters, DBSCAN will merge the clusters. Streemer on th e other hand first finds candidate clusters and then only merges them if the resu lting cluster is highly cohesive.
 paper examines several variations, such as sampling and find ing first a large number of clusters which are then clustered down to the reque sted number k , which is reminiscent of Streemer X  X  second step. The idea of c luster cohesiveness in Streemer was inspired by the Clustering By Committee (CBC ) algorithm [16]. CBC finds a set of cohesive clusters, called committees, that are well separated and which initially include only a subset of the points. The a lgorithm proceeds by assigning points to their most similar committee.
 has, of course, been studied in the past. This paper is unique in using clusters to build predictive models of how communities evolve, and ho w location in a cluster or in the background predicts how widely cited a pape r will become. Agglomerative clustering is used in [11] to find co-citation communities that are strong and others that are essentially random, but they do no t specifically use the notion of background in their clustering, and do not use t heir clusters in predictive models. Similarly, in [17] the authors search fo r temporal trends in hyper-linked document databases using clustering, but do n ot build predictive models of community growth. The authors in [15] identify res earch communities (and make paper acceptance predictions) from the citation p atterns and text of papers, using relational learning techniques, but do not st udy the communities themselves.
 ground and background clusters, an idea that has been used in vision [12, 18], but is rare when looking at documents. A common alternative a lgorithm with a similar property is a Gaussian mixture model with non-unifo rm variances. Esti-mating such a mixture model provides soft assignments of ite ms to clusters, but is significantly more computationally demanding than Stree mer or background k -means. We have presented a new clustering algorithm, Streemer, wit h several useful characteristics. Streemer finds dense foreground clusters embedded in a more diffuse background cluster. It requires only two passes thro ugh the data, and unlike k -means or its variant, background k -means, Streemer is particularly good at avoiding local minima, and is able to find clusters of widel y divergent sizes. This is useful, among other applications, for clustering do cuments into scientific communities.
 in a background cluster) gives cleaner foreground clusters and allows important insights to be made. Knowledge communities, as defined by our clusters, produce a disproportionate amount of the knowledge in computer scie nce. In our dataset of computer science publications in technical journals and conferences, 57% of citations are received by papers in clusters even though onl y 44% of papers are in clusters. Even more dramatically, 76% of citations of pap ers in a cluster refer to another paper in a cluster. On the other hand, papers not in a cluster cite almost proportionately to the ratio of papers in and out of cl usters, with 41% of citations going to the 44% papers in a cluster and 59% of citat ions going to the 56% papers in the background.
 that were found from clustering. The coefficients of the featu res for the fitted model describe the properties of successful knowledge comm unities. We found that in order for a community to grow, its members should use b road, flexible and unique information in their publications. At the same time t he vocabulary they use should be narrow, unchanging and common. This perhaps is not surprising; introducing new terms and definitions at the same time as nove l ideas can make it hard for the readers to absorb such a large amount of inform ation at once. New jargon obfuscates the content and limits its spreading. Fur ther research into the differential success of knowledge communities can provide a better understanding of what guides the development and direction of innovation.

