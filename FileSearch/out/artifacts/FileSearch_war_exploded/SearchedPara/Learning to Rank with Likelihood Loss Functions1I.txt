 Ranking documents with respect to given que ries is the central issue for designing effective web search engines, as the ra nking model decide relevance of search results. Many approaches are proposed for ranking. The purpose of ranking is to permute the relevance documents on the top positions of the result list. Learning to rank [ 1 ] is an effective machine learning ap proach to improve the performance of information retrieval. However, the previous approaches always take the every docu X  ment as a single object respectively, although the documents may be labeled by same relevance judgment. It may increase the tr aining time and computational complexity. In addition, if we take the documents with the same relevance judgment as a group, the ranking task is reduced from ranking the multiple documents to ranking several groups. Moreover, the permutation in a single group is also effective to the final performance. And the different combinations of group sample can also affect the results of ranking. In this paper we try to improve classic approaches of learning to rank by presenting a new framework, named group wise framework. The loss func X  tion of our framework is based on novel samples one-group sample and group-group sample. In order to acquire higher ra nking accuracies, we also explore optimal selection of the initial ranking list for group samples. For the data set with more than two relevance judgments, we develop a new loss function by weighting their group samples.
 The contributions of this paper are as foll ows: (1) we investigate the problems of the existing likelihood loss based approaches; (2) we propose a relevance preference based approach to optimize the group ranking loss function with more than two relevance judgments; (3) we investigate the influence of initial ranking permutation of documents and develop a permutation selection to improve its likelihood loss construction. Recently, there has been a great deal of res earch on learning to rank. They are usually catego-rized into three appro aches: the pointwise, pairwise and listwise approaches, which are based on different input samples for learning. Most approaches of learning to rank are based on the three frameworks. Ho wever, there are a few studies that have improved the learning to rank methods using other input samples. The roles of ties, which are document pairs with same relevance are, investigated in the learning process [ 2 ], which shows that it is feasible to improve the performance of learning ranking functions by introducing the new samples.
 ListMLE [ 3 ] is an effective ranking approach of listwise that formalizes learning to rank as a problem of minimizing the likelihood function of a probability model. Xia et al. [ 4 ] presented a new framework, which is used to optimize the top-k ranking. They demonstrate it is effective to improve the ranking performance of top-k and also derive sufficient conditions for a listwise ranking method to be consistent with the top-k true loss. In our previous work [ 5 ], we conducted some preliminary experiments to expand their work. In this paper, we divide the list of documents with respect to a query into several groups based on their relevance judgments. There are two patterns in the frame X  work to construct samples: One-group and Group-group. We also define the new loss function of group sample based on likelihood loss to examine whether it is effective to improve the ranking performance. In this section, we briefly introduce the framework of group ranking [ 5 ], which is used to improve the ranking accuracies. It is de veloped from the framework of listwise and the framework of top-k ranking. We analy ze likelihood based approaches and point out the existing problems. In order to improve the two frameworks, we proposed the frame X  work of group ranking framework.
 Group ranking framework is similar to the top-k ranking framework. However, the samples of the two methods are different, and the meaning of k is different. We denote the ranking function based on the neural network model w as f . Given a group feature gradient decent to perform the optimization. When we use likelihood loss function as metric, the group loss function becomes: ranking samples: for one-group sample r is set to 1, but for the group-group sample r is set to the length of the group with the higher label. X optimum permutation for x g .
 Relevance Preference Based Loss Function. Although the group-wise approaches can get an appropriate level of ranking performance, there are still several problems with the construction of loss function.
 samples with different preferences are consider ed as the equivalent ones in the training process, which may neglect the difference of original relevant labels for the group of documents. In this paper, we propose a relevance preference based approach to solve the problem. Based on this approach, our method can lead to more significant improve X  ments than original group ranking approaches in retrieval effectiveness.
 cially for the data set with binary relevance labels, it can get a more significant perform X  ance than the multiple relevance labeled data set. The reason for that may cause the different relevant judgment labels for the two types of data set. For the group sample construction of binary label data set, the importance of each sample is no differences. However, there are often multiple relevance judgments, such as 2 (definitely relevant), 1 (possibly relevant), 0 (irrelevant). Thus the group sample constructed by the documents with labels 2 and 1 is indeed different from that constructed by the documents with labels 2 and 0. So it is imperfect that the group ranking framework takes all the samples as equivalent. In this paper we propose the preference weighted loss function to deal with this problem. In the case of learning to rank web documents, preference data are given in the form that one document is more rele vant than another with respect to a given query. For each group sample, there is a preference for two group of documents, which reflects the relevance difference between the two labels. We introduce the preference to improve the group ranking loss function, which is based on Likelihood. We define the loss function for each sample as follows: that depends on the group and preference, which can introduce the relevance of the documents into the learning process. We defined the weight function for the sample as follows: g i s the i -th of group samples, label h ( g i ) and label in the group sample. In this way, we can de fine the weight by the preference, the larger the difference between the two labels, the bigg er the weight. We can introduce the rele X  vant labels and preference into the loss function to improve the original group ranking loss functions. We name this approach W-GroupMLE for short.
 Initial Ranking Permutation Optimization. In the training set, as matter of fact that the relevance labels of document 1 and 2 ar e equal, the descent loss seems to be not necessary. However, it is still a key clue to improve our approaches. For the likelihood loss of ListMLE, y is a randomly selected optimum permutation which satisfies the condition for any two documents x i , x j , if label( x in y . However, the optimal ranking list for y is not unique, different orders of documents for the selected y may result in different loss functions. For the group-group ranking, there are still a group documents with higher label in the list, so it is similar to ListMLE, where different permutations may generate different loss function. It is an important issue to distinguish which function could get the best performance. Furthermore, for the documents 1 and 2, if the basis of the initial ranking decides that document 1 should be permuted before document 2, it may be more effective to select the ranking model f this paper for the initial ranking list y , instead of selecting optimum permutation randomly, we choose the ranking features with the best ranking performance as the basis of optimum permutation in training set. We evaluate our methods on the Letor3.0 data set released by Microsoft Research Asia. This data set contains two collections: the OHSUMED collection and the.Gov collec X  tion. The collections we use to evalua te our experiments are the OHSUMED and TD2003, TD2004. As evaluation measure, we adopt NDCG@N an d MAP to evaluate the performance of the learned ranking function.
 Effectiveness of Preference We ighted Likelihood Loss. Varying from TD2003 and Td2004 data set, there are three level labels: 2 (definitely relevance), 1 (possibly rele X  vant) and 0 (irrelevant) in the OHSUMED data set. It is not correct to take all the group ranking samples as equal, because there are samples with different preferences. According to the Sect. 4 , we use the weighted likelihood loss to optimize the training process of OHSUMED data set. In this section, we examine the effectiveness of group ranking methods. The results of group ranking methods on OHSUMED collection are shown in Table 1 . From the Table 1 , we can see that the W-GroupMLE can significantly boost the ranking accuracies based on one-group sample (W-GroupMLE1) and group-group sample (W-Group MLE2). In addition, preference weighted method gets best performance, which clearly validates our argument that it can improve the ranking performance by introducing the preference to loss function based on relevant label. The group sample whose preference is big should be set a large weight for training. It is effective to optimize the loss function. Effectiveness of Optimum Permutation Selection. First, we list the feature number with the best and the worst performance (short for max and min) evaluated by MAP on the Table 2 . We can see different f eatures can gets different performances. However, on the Letor3.0 data set, although the features with the best performance are different, the worst is the same one in the same data set for 5 folds. The Letor3.0 ranks the documents with respect to one query by the feature whic h is from the scores of BM25 for the whole document. The above experiments are based on these ranks for the likelihood loss func X  tions. However, we find that the BM25 feature do not get the best performance on the data set.
 with the BM25 scores. The results evaluated by MAP are listed on Table 3 . For the evaluations, the features with the best pe rformance all achieve better ranking accuracies than the other features used as initial ranking list. Overall, as a good information retrieval method, BM25 also gets a better performan ce than the worst performance features, but it cannot outperform the best performance features which are learned from training data of single fold. Moreover, the group-group ranking methods almost all outperform the one-group ranking method by introducing the information of initial ranking list to the loss function on the training process.
 with the existing methods. We select several representative ranking algorithms compared with our group ranking. We choose OHSUMED and .Gov collections as the test collections, because they have different type relevant judgments. The performance of the ranking methods is shown in Fig. 1 . The results on the test collections show that the group-group ranking method, based on preference weighted likelihood loss and optimum permutation selection, attains a notable improvement over existing ranking method by learning a suitable model based on group loss function and group samples. These findings indicate that our method in comparison to the collection with multiple relevant labels is more effective. In this paper, we develop a preference weighted likelihood loss function to boost ranking accuracies. In addition, the experimental re sults show that the optimization of initial ranking list for likelihood loss function is also effective to improve the ranking perform X  ance of group ranking approaches. As future work, we will continue to study the theory basis of the group ranking framework and examine whether the ranking performance can be improved further; and we will also exploit the odds to using other existing methods to implement the group ranking methods.

