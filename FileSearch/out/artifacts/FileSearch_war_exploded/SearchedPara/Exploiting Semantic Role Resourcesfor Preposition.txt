 University of Maryland, Baltimore County University of Pittsburgh tion. The main resources include the semantic role annotations provided by the Penn Treebank and FrameNet tagged corpora. The resources also include the assertions contained in the Fac-totum knowledge base, as well as information from Cyc and Conceptual Graphs. A common work.
 word-sensedisambiguationisintroduced,usingWordNethypernymsascollocationsratherthan just words. Various experiments over the Penn Treebank and FrameNet data are presented, in-
FrameNet). Other experiments are included with the FrameNet data mapped into the common might be applied in lexical acquisition. 1. Introduction
English prepositions convey important relations in text. When used as verbal adjuncts, they are the principal means of conveying semantic roles for the supporting entities described by the predicate. Preposition disambiguation is a challenging problem. First, prepositions are highly polysemous. A typical collegiate dictionary has dozens of senses for each of the common prepositions. Second, the senses of prepositions tend to be closely related to one another. For instance, there are three duplicate role assign-ments among the twenty senses for of in The Preposition Project (Litkowski and
Hargraves 2006), a resource containing semantic annotations for common prepositions.
The choice between the purpose and manner meanings for on in these sentences is difficult. The purpose meaning seems preferred for sentence 1, as grounds is a type of justification. For sentence 2, the choice is even less clear, though the manner meaning seems preferred.
 mation learned from annotated corpora as well as knowledge stored in declarative lexical resources. The approach allows for better coverage and finer distinctions than in previous work in preposition disambiguation. For instance, a traditional approach would involve manually developing rules for on that specify the semantic type of objects associated with the different senses (e.g., time for temporal ). Instead, we infer this based on lexical associations learned from annotated corpora.
 acquisition (O X  X ara 2005). The focus of the system is to acquire distinguishing infor-mation for the concepts serving to define words. Large-scale semantic lexicons mainly emphasize the taxonomic relations among the underlying concepts (e.g., is-a and part-of ), and often lack sufficient differentiation among similar concepts (e.g., via attributes or functional relations such as is-used-for ). For example, in WordNet (Miller et al. 1990), the standard lexical resource for natural language processing, the only relations for beagle and Afghan are that they are both a type of hound . Although the size difference can be inferred from the definitions, it is not represented in the WordNet semantic network. the underlying concepts and serve as nodes in a semantic network. Synsets are ordered into a hierarchy using the hypernym relation (i.e., is-a ). There are several other semantic relations, such as part-whole , is-similar-to ,and domain-of . Nonetheless, in version 2.1 of
WordNet, about 30% of the synsets for noun entries are not explicitly distinguished from sibling synsets via semantic relations.
 approach to lexical acquisition, building upon earlier knowledge-based approaches in dictionary definition analysis (Wilks, Slator, and Guthrie 1996). This involves a two-step process: Definitions are first analyzed with a broad-coverage parser, and then the result-ing syntactic relationships are disambiguated using statistical classification. A crucial part of this process is the disambiguation of prepositions, exploiting online resources with semantic role usage information. The main resources are the Penn Treebank (PTB; Marcus et al. 1994) and FrameNet (Fillmore, Wooters, and Baker 2001), two popular corpora providing rich annotations on English text, such as the semantic roles associated with prepositional phrases in context. In addition to the semantic role annota-tions from PTB and FrameNet, traditional knowledge bases (KBs) are utilized to provide training data for the relation classification. In particular, the Factotum KB (Cassidy 2000) is used to provide additional training data for prepositions that are used to convey particular relationships. Information on preposition usage is not explicitly encoded in Factotum, so a new corpus analysis technique is employed to infer the associations. be found in O X  X ara (2005). This article focuses on the aspects of this method relevant to the processing of prepositions. In particular, here we specifically address preposition 152 disambiguation using semantic role annotations from PTB, FrameNet, and Factotum.
In each case, classification experiments are presented using the respective resources as training data with evaluation via 10-fold cross validation.
 the relation inventories used during classification, including one developed specifically for definition analysis. Section 3 discusses the relation classifiers in depth with results given for four different inventories. Section 4 discusses related work in relation disam-biguation, and Section 5 presents our conclusions. 2. Semantic Relation Inventories
The representation of natural language utterances often incorporates the notion of semantic roles , which are analogous to the slots in a frame-based representation. In particular, there is an emphasis on the analysis of thematic roles , which serve to tie the grammatical constituents of a sentence to the underlying semantic representation.
Thematic roles are also called case roles, because in some languages the grammatical constituents are indicated by case inflections (e.g., ablative in Latin). As used here, the term  X  X emantic role X  refers to an arbitrary semantic relation, and the term  X  X hematic role X  refers to a relation intended to capture the semantics of sentences (e.g., event participation).
 (NLP). Some systems use just a small number of very general roles, such as beneficiary .
At the other extreme, some systems use quite specific roles tailored to a particular domain, such as catalyst in the chemical sense. 2.1 Background on Semantic Roles
Bruce (1975) presents an account of early case systems in NLP. For the most part, those systems had limited case role inventories, along the lines of the cases defined by
Fillmore (1968). Palmer (1990) discusses some of the more contentious issues regarding case systems, including adequacy for representation, such as reliance solely upon case information to determine semantics versus the use of additional inference mechanisms.
Barker (1998) provides a comprehensive summary of case inventories in NLP, along with criteria for the qualitative evaluation of case systems (generality, completeness, and uniqueness). Linguistic work on thematic roles tends to use a limited number of roles.
Frawley (1992) presents a detailed discussion of twelve thematic roles and discusses how they are realized in different languages.
 domains to those that can handle open-ended domains, there has been a trend towards the use of larger sets of semantic primitives (Wilks, Slator, and Guthrie 1996). The
WordNet lexicon (Miller et al. 1990) serves as one example of this. A synset is defined in terms of its relations with any of the other 100,000+ synsets, rather than in terms of a set of features like [  X  ANIMATE ]. There has also been a shift in focus from deep under-standing (e.g., story comprehension) facilitated by specially constructed KBs to shallow surface-level analysis (e.g., text extraction) facilitated by corpus analysis. Both trends seem to be behind the increase in case inventories in two relatively recent resources, namely FrameNet (Fillmore, Wooters, and Baker 2001) and OpenCyc (OpenCyc 2002), both of which define well over a hundred case roles. However, provided that the case roles are well structured in an inheritance hierarchy, both paraphrasability and coverage can be addressed by the same inventory. 2.2 Inventories Developed for Corpus Annotation
With the emphasis on corpus analysis in computational linguistics, there has been a shift away from relying on explicitly-coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. For example, rather than manually devel-oping rules for preferring one sense of a word over another based on context, the most successful approaches have automatically learned the rules based on word-sense annotations, as evidenced by the Senseval competitions (Kilgarriff 1998; Edmonds and Cotton 2001).
 of case annotations for general-purpose text. These are very general roles, following
Fillmore (1968). The Berkeley FrameNet (Fillmore, Wooters, and Baker 2001) project currently provides the most comprehensive set of semantic roles annotations. These are at a much finer granularity than those in PTB, making them quite useful for applications learning semantics from corpora. Relation disambiguation experiments for both of these role inventories are presented subsequently. 2.2.1 Penn Treebank. The original PTB (Marcus, Santorini, and Marcinkiewicz 1993) pro-vided syntactic annotations in the form of parse trees for text from the WallStreetJournal .
This resource is very popular in computational linguistics, particularly for inducing part-of-speech taggers and parsers. PTB version II (Marcus et al. 1994) added 20 func-tional tags, including a few thematic roles such as temporal , direction ,and purpose . These can be attached to any verb complement but normally occur with clauses, adverbs, and prepositions.

In addition to the usual syntactic constituents such as NP and VP , function tags are included. For example, the second NP gives the subject. This also shows that the first prepositional phrase (PP) indicates the time frame, whereas the last PP indicates the Sentence:
In 1982, Sports &amp; Recreation X  X  managers and certain passive investors purchased the company from Brunswick Corp. of Skokie, Ill.

Parse: (S (PP-TMP In (NP 1982)), temporal extent (NP-SBJ grammatical subject (VP purchased 154 location. The second PP is tagged as closely-related , which is one of the miscellaneous
PTB function tags that are more syntactic in nature:  X  X CLR] occupy some middle ground between arguments and adjunct X  (Bies et al. 1995). Frequency information for the semantic role annotations is shown in Table 1. 2.2.2 FrameNet. FrameNet (Fillmore, Wooters, and Baker 2001) is striving to develop an
English lexicon with rich case structure information for the various contexts that words can occur in. Each of these contexts is called a frame , and the semantic relations that occur in each frame are called frame elements (FE). For example, in the communica-tion frame, there are frame elements for communicator , message , medium , and so forth.
FrameNet annotations occur at the phrase level instead of the grammatical constituent level as in PTB. Figure 2 shows an example.
 that the semantic roles in FrameNet can be quite specific, as with the roles cognizer , evaluee ,and addressee . In all, there are over 780 roles annotated with over 288,000 tagged instances.
 Sentence:
Hewlett-Packard Co has rolled out a new range of ISDN connectivity enabling stand-alone workstations to communicate over public or private ISDN networks.
 Annotation: Hewlett-Packard Co has rolled out a new range of ISDN connectivity enabling
C FE= X  X ommunicator X  PT= X  X P X  standalone workstations / C to C TARGET= X  X  X  communicate / C C FE= X  X edium X  PT= X  X P X  over public or private ISDN networks / C .
 2.3 Other
A recent semantic role resource that is starting to attract interest is the Proposition Bank (PropBank), developed at the University of Pennsylvania (Palmer, Gildea, and Kings-bury 2005). It extends the Penn Treebank with information on verb subcategorization.
The focus is on annotating all verb occurrences and all their argument realizations that occur in the Wall Street Journal , rather than select corpus examples as in FrameNet.
Therefore, the role inventory is heavily verb-centric, for example, with the generic labels arg0 through arg4 denoting the main verbal arguments to avoid misinterpretations. Verbal adjuncts are assigned roles based on PTB version II (e.g., argM-LOC and argM-
TMP). PropBank has been used as the training data in recent semantic role labeling competitions as part of the Conferences on Computational Natural Language Learn-ing (Carreras and M ` arquez 2004, 2005). Thus, it is likely to become as influential as FrameNet in computational semantics.
 resource, namely FrameNet. It is being developed by CL Research (Litkowski and
Hargraves 2006) and endeavors to provide comprehensive syntactic and semantic in-formation on various usages of prepositions, which often are not represented well in semantic lexicons (e.g., they are not included at all in WordNet). The Preposition
Project uses the sense distinctions from the Oxford Dictionary of English and integrates syntactic information about prepositions from comprehensive grammar references. 156 2.4 Inventories for Knowledge Representation
This section describes three case inventories: one developed for the Cyc KB (Lenat 1995), one used to define Conceptual Graphs (Sowa 1984), and one for the Factotum
KB (Cassidy 2000). The first two are based on a traditional knowledge representation paradigm. With respect to natural language processing, these approaches are more representative of the earlier approaches in which deep understanding is the chief goal.
Factotum is also based on a knowledge representation paradigm, but in a sense also reflects the empirical aspect of the corpus annotation approach, because the annotations were developed to address the relations implicit in Roget X  X  Thesaurus.
 tum, given that the others do not readily provide sufficient training data. However, the other inventories are discussed because each provides relation types incorporated into the inventory used below for the definition analysis (see Section 3.5). 2.4.1 Cyc. The Cyc system (Lenat 1995) is the most ambitious knowledge representation project undertaken to date, in development since 1984. The full Cyc KB is propri-etary, which has hindered its adoption in natural language processing. However, to encourage broader usage, portions of the KB have been made freely available to the public. For instance, there is an open-source version of the system called OpenCyc ( www.opencyc.org ), which covers the upper part of the KB and also includes the Cyc inference engine, KB browser, and other tools. In addition, researchers can obtain access to ResearchCyc, which contains most of the KB except for proprietary information (e.g., internal bookkeeping assertions).
 the 8,756 concepts in OpenCyc, 130 are for event-based roles (i.e., instances of actor-slot ) with 51 other semantic roles (i.e., other instances of role ). Table 3 shows the most commonly used event-based roles in the KB. 2.4.2 Conceptual Graphs. The Conceptual Graphs (CG) mechanism was introduced by Sowa (1984) for knowledge representation as part of his Conceptual Structures theory.
The original text listed two dozen or so thematic relations, such as destination and initiator . In all, 37 conceptual relations were defined. This inventory formed the basis for most work in Conceptual Graphs. Recently, Sowa (1999) updated the inventory to allow for better hierarchical structuring and to incorporate the important thematic roles identified by Somers (1987). Table 4 shows a sample of these roles, along with usage estimates based on corpus analysis (O X  X ara 2005). 2.4.3 Factotum. The Factotum semantic network (Cassidy 2000) developed by Micra,
Inc., makes explicit many of the relations in Roget X  X  Thesaurus. resources such as Cyc, Factotum is the most comprehensive KB with respect to functional relations , which are taken here to be non-hierarchical relations, excluding attributes.
OpenCyc does include definitions of many non-hierarchical relations. However, there are not many instantiations (i.e., relationship assertions), because it concentrates on the higher level of the ontology. and specifies the relations that hold between the Roget categories and the words listed in each entry. Factotum incorporates information from other resources as well. For instance, the Unified Medical Language System (UMLS) formed the basis for the initial inventory of semantic relations, which was later revised during tagging.
 ganization is still used, although additional hierarchical levels have been added. The relations are contained within double braces (e.g.,  X  {{ has subtype apply from the category to each word in the synonym list on the same line. For example, the line with  X  {{ result of }}  X  indicates that conversion is the result of transforming, as shown in the semantic relation listing that would be extracted. There are over 400 different relations instantiated in the knowledge base, which has over 93,000 assertions.
Some of these are quite specialized (e.g., has-brandname ).Inaddition,therearequitea few inverse relations, because most of the relations are not symmetrical. Certain features of the knowledge representation are ignored during the relation extraction used later.
For example, relation specifications can have qualifier prefixes, such as an ampersand to indicate that the relationship only sometimes holds. 158 and includes others that are used in the experiments discussed later. frequencies just reflect relationships explicitly labeled in the KB data file. For instance, this does not account for implicit has-subtype relationships based on the hierarchical organization of the thesaural groups (e.g., simple-change, has-subtype , conversion ).
The functional relations are shown in boldface. This excludes the meronym or part-whole relations (e.g., is-conceptual-part-of ), in line with their classification by Cruse (1986) as hierarchical relations. The reason for concentrating on the functional relations is that these are more akin to the roles tagged in PTB and FrameNet.
 functional relations (e.g., non-hierarchical relations such as uses and is-function-of ). For comparison purposes, Table 6 shows the semantic relation usage in WordNet version Original data:
A. ABSTRACT RELATION ...

A6 CHANG E(R140 TO R152) ...

A6.1 SIMPL ECHANG E(R140) ...

A6.1.4 CONVERSION (R144) #144. Conversion.

N. {{ has subtype(change, R140) }} conversion, transformation. {{ has case: @R7, initial state, final state }} . {{ has patient: @R3a, object, entity }} . {{ result of }}{{ has subtype(process, A7.7) }} converting, transforming. {{ has subtype }} processing. transition.

Extracted relationships: change, has-subtype , conversion change, has-subtype , transformation conversion, has-case , initial state conversion, has-case , final state conversion, has-patient ,object conversion, has-patient , entity conversion, is-result-of , converting conversion, is-result-of , transforming process, has-subtype , converting process, has-subtype , transforming conversion, has-subtype , processing 2.1. As can be seen from the table, the majority of the relations are hierarchical.
WordNet 2.1 averages just about 1.1 non-taxonomic properties per concept (includ-ing inverses but excluding hierarchical relations such as has-hypernym and is-member-meronym-of ). OpenCyc provides a much higher average at 3.7 properties per concept, although with an emphasis on argument constraints and other usage restrictions. Fac-totum averages 1.8 properties per concept, thus complementing WordNet in terms of information content. 4 2.5 Combining the Different Semantic Role Inventories due both to the different nature of the inventories (e.g., developed for knowledge bases as opposed to being derived from natural language annotations) and due to the way the 160 relation listings were extracted (e.g., just including event-based roles from OpenCyc).
As can be seen from Tables 2 and 3, FrameNet tends to refine the roles for agents (e.g., communicator ) compared to OpenCyc, which in contrast has more refinements of the object role (e.g., object-removed ). The Concept Graphs inventory includes more emphasis on specialization relations than the others, as can be seen from the top entries in Table 4 (e.g., attribute ).
 the semantic role inventories just discussed. For the application to dictionary defin-ition analysis, we need to combine the classifiers learned over PTB, FrameNet, and
Factotum. This can be done readily in a cascaded fashion with the classifier for the most specific relation inventory (i.e., FrameNet) being used first and then the other classifiers being applied in turn whenever the classification is inconclusive. This would have the advantage that new resources could be integrated into the combined relation classifier with minimal effort. However, the resulting role inventory would likely be heterogeneous and might be prone to inconsistent classifications. In addition, the role inventory could change whenever new annotation resources are incorporated, making the overall definition analysis system somewhat unpredictable.
 separate relation classifier induced over the resulting data. This has the advantage that the target relation-type inventory remains stable whenever new sources of relation annotations are introduced. In addition, the classifier will likely be more accurate as there are more examples per relation type on average. The drawback, however, is that annotations from new resources must first be mapped into the common inventory before incorporation.
 the general relation types defined by Gildea and Jurafsky (2002) for their experiments in classifying semantic relations in FrameNet using a reduced relation inventory. They defined 18 relations (including a special-case null role for expletives), as shown in
Table 7. These roles served as the starting point for the common relation inventory we developed to support definition analysis (O X  X ara 2005), with half of the roles used as is and a few others mapped into similar roles. In total, twenty-six relations are defined, including a few roles based on the PTB, Cyc, and Conceptual Graphs inven-162 tories. Table 8 shows this role inventory along with a description of each case. In addition to traditional thematic relations, this includes a few specialization relations, which are relevant to definition analysis. For example, characteristic corresponds to the general relation from Conceptual Graphs for properties of entities; and category gen-eralizes the corresponding FrameNet role, which indicates category type, to subsume other FrameNet roles related to categorization (e.g., topic ). Note that this inventory is not meant to be definitive and has been developed primarily to address mappings from
FrameNet for the experiments discussed in Section 3.5. Thus, it is likely that additional roles will be required when additional sources of semantic relations are incorporated (e.g., Cyc). The mappings were produced manually by reviewing the role descriptions in the FrameNet documentation and checking prepositional usages for each to determine which of the common inventory roles might be most relevant. As some of the roles with the same name have frame-specific meanings, in a few cases this involved conflicting usages (e.g., body-part associated with both area and instrument ), which were resolved in favor of the more common usage. 5 3. Preposition Disambiguation
This section presents the results of our experiments on the disambiguation of relations indicated by prepositional phrases. Results are given for PTB, FrameNet, and Factotum.
The PTB roles are general: For example, for the preposition for, there are six distinctions (four, with low-frequency pruning). The PTB role disambiguation experiments thus address a coarse form of sense distinction. In contrast, the FrameNet distinctions are quite specific: there are 192 distinctions associated with for (21 with low-frequency prun-ing); and, there are 17 distinctions in Factotum (15 with low-frequency pruning). Our
FrameNet and Factotum role disambiguation experiments thus address fine-grained sense distinctions. 3.1 Overview
A straightforward approach for preposition disambiguation would be to use typical word-sense disambiguation features, such as the parts-of-speech of surrounding words and, more importantly, collocations (e.g., lexical associations). Although this can be highly accurate, it tends to overfit the data and to generalize poorly. The latter is of particular concern here as the training data is taken from a different genre than the application data. For example, the PTB data is from newspaper text (specifically, Wall
Street Journal ), but the lexical acquisition is based on dictionary definitions. We first discuss how class-based collocations address this problem and then present the features used in the experiments.
 the use of hypernym collocations. Consider the following purpose role examples, which are similar to the first example from the introduction. when the sense for on is purpose (or reason). Thus, these words would likely be chosen as collocations for this sense. However, for the sake of generalization, it would be better to choose the WordNet hypernym subject matter , as that subsumes both words. This would then allow the following sentence to be recognized as indicating purpose even though censure was not contained in the training data. 3.1.1 Class-Based Collocations via Hypernyms. To overcome data sparseness problems, a class-based approach is used for the collocations, with WordNet synsets as the source of the word classes. (Part-of-speech tags are a popular type of class-based feature used in word sense disambiguation (WSD) to capture syntactic generalizations.) Recall that the WordNet synset hierarchy can be viewed as a taxonomy of concepts. Therefore, in addition to using collocations in the form of other words, we use collocations in the form of semantic concepts.
 data (e.g.,  X  X n X  sentences with correct role indicated). The first pass tabulates the 164 co-occurrence counts for each of the context words (i.e., those in a window around the target word) paired with the classification value for the given training instance (e.g., the preposition sense from the annotation). These counts are used to derive conditional probability estimates of each class value given co-occurrence of the various potential collocates. The words exceeding a certain threshold are collected into a list associated with the class value, making this a  X  X ag of words X  approach. In the experiments dis-cussed below, a potential collocate ( coll ) is selected whenever the conditional probability for the class ( C ) value exceeds the prior probability by a factor greater than 20%:
That is, for a given potential collocation word ( coll ) to be treated as one of the ac-tual collocation words, the relative percent change of the class conditional probability
The second pass over the training data determines the value for the collocational feature of each classification category by checking whether the current context window has any of the associated collocation words. Note that for the test data, only the second pass is made, using the collocation lists derived from the training data.
 replaced with each of their hypernym ancestors from WordNet. The adjective hierarchy is relatively shallow, so it is augmented by treating is-similar-to as has-hypernym . For example, the synset for  X  X rid X  and  X  X aterless X  is linked to the synset for  X  X ry (vs. wet). X  Adverbs would be included, but there is no hierarchy for them. Because the co-occurring words are not sense-tagged, this is done for each synset serving as a different sense of the word. Likewise, in the case of multiple inheritance, each parent synset is used. For example, given the co-occurring word money, the counts would be updated as if each of the following tokens were seen (grouped by sense).
Thus, the word token money is replaced by 41 synset tokens. Then, the same two-pass process just described is performed over the text consisting of the replacement tokens.
Although this introduces noise due to ambiguity, the conditional-probability selection scheme (Wiebe, McKeever, and Bruce 1998) compensates by selecting hypernym synsets that tend to co-occur with specific roles. hypernyms. Instead, they are inferred automatically based on the word to be disam-biguated (i.e., preposition for these experiments). Hypernyms at the top levels of the hierarchy are less likely to be chosen, as they most likely occur with different senses for the same word (as with relation#1 previously). However, hypernyms at lower levels tend not to be chosen, as there might not be enough occurrences due to other co-occurring words. For example, wealth#4 is unlikely to be chosen as a collocation for the second sense of money, as only a few words map into it, unlike property#2 .The conditional-probability selection scheme (i.e., Equation (1)) handles this automatically without having to encode heuristics about hypernym rank, and so on. 3.1.2 Classification Experiments. A supervised approach for word-sense disambiguation is used following Bruce and Wiebe (1999).
 repeatedly trained on 90% of the data and tested on the remainder, with the test sets randomly selected to form a partition. The results described here were obtained using the settings in Figure 4, which are similar to the settings used by O X  X ara et al. (2004) in the third Senseval competition. The top systems from recent Senseval competitions (Mihalcea 2002; Grozea 2004) use a variety of lexical features for WSD. Words in the im-mediate context ( Word  X  i ) and their parts of speech ( POS collocations are also common, but there are various ways of organizing collocations into features (Wiebe, McKeever, and Bruce 1998). We use the simple approach of having a single binary feature per sense (e.g., role) that is set true whenever any of the associated collocation words for that sense are encountered (i.e., per-class-binary).
Chklovski, and Kilgarriff 2004) concerns the hypernym collocations. The collocation context section of Figure 4 shows that word collocations can occur anywhere in the sentence, whereas hypernym collocations must occur within five words of the target Features: Prep: preposition being classified POS  X  i: part-of-speech of word at offset i Word  X  i: stem of word at offset i WordColl r : context has word collocation for role r HypernymColl r : context has hypernym collocation for role r Collocation context: Word: anywhere in the sentence Hypernym: within 5 words of target preposition Collocation selection: Frequency: f ( word ) &gt; 1 Conditional probability: P ( C | coll )  X  . 50
Relative percent change: ( P ( C | coll )  X  P ( C )) / P ( C ) Organization: per-class-binary Model selection: C4.5 Decision tree via Weka X  X  J4.8 classifier (Quinlan 1993; Witten and Frank 1999) 166 prepositions (i.e., a five-word context window). 7 This reduced window size is used to make the hypernym collocations more related to the prepositional object and the modified term.
 based collocations alone, hypernym collocations alone, and both collocations together.
Combining the two types generally produces the best results, because this balances the specific clues provided by the word collocations with the generalized clues provided by the hypernym collocations.
 being disambiguated; therefore, a single classifier can be produced rather than indi-vidual classifiers. This has the advantage of allowing more training data to be used in the derivation of the clues indicative of each semantic role. However, if there were sufficient annotations for particular preposition, then it would be advantageous to have a dedicated classifier. For example, the prior probabilities for the roles would be based on the usages for the given preposition. Therefore, we perform experiments illustrating the difference when disambiguating prepositions with a single classifier versus the use of separate classifiers. 3.2 Penn Treeban kClassification Experiments
The first set of experiments deals with preposition disambiguation using PTB. When deriving training data from PTB via the parse tree annotations, the functional tags as-sociated with prepositional phrases are converted into preposition sense tags. Consider the following excerpt from the sample annotation for PTB shown earlier:
Treating temporal as the preposition sense yields the following annotation:
The relative frequencies of the roles in the PTB annotations for PPs are shown in Ta-ble 9. As can be seen, several of the roles do not occur often with PPs (e.g., extent ). This somewhat skewed distribution makes for an easier classification task than the one for
FrameNet. 3.2.1 Illustration with  X  X t.  X  As an illustration of the probabilities associated with class-based collocations, consider the differences in the prior versus class-based conditional probabilities for the semantic roles of the preposition at in the Penn Treebank (ver-sion II). Table 10 shows the global probabilities for the roles assigned to at, along with conditional probabilities for these roles given that certain high-level WordNet synsets occur in the context. In a context referring to a concrete concept (i.e., entity#1), the difference in the probability distributions for the locative and temporal roles shows that the locative interpretation becomes even more likely. In contrast, in a context referring to an abstract concept (i.e., abstraction#6), the difference in the probability distributions for the same roles shows that the temporal interpretation becomes more likely. Therefore, these class-based lexical associations capture commonsense usages of the preposition at. 3.2.2 Results. The classification results for these prepositions in the Penn Treebank show that this approach is very effective. Table 11 shows the accuracy when disambiguating the 14 prepositions using a single classifier with 6 roles. Table 11 also shows the per-class statistics, showing that there are difficulties tagging the manner role (e.g., lowest
F-score). For the single-classifier case, the overall accuracy is 89.3%, using Weka X  X  J4.8 classifier (Witten and Frank 1999), which is an implementation of Quinlan X  X  (1993) C4.5 decision tree learner.
 prepositions annotated in PTB. A few prepositions only have small data sets, such as of which is used more for specialization relations (e.g., category ) than thematic ones.
This table is ordered by entropy, which measures the inherent ambiguity in the classes as given by the annotations. Note that the Baseline column is the probability of the most frequent sense, which is a common estimate of the lower bound for classification 168 experiments. When using preposition-specific classifiers, the hypernym collocations surprisingly outperform the other configurations, most likely due to overfitting with word-based clues: 82.1% versus 80.0% for the word-only case. 3.3 FrameNet Classification Experiments The second set of experiments perform preposition disambiguation using FrameNet. A similar preposition word-sense disambiguation experiment is carried out over the
FrameNet semantic role annotations involving prepositional phrases. Consider the sam-ple annotation shown earlier:
The prepositional phrase annotation is isolated and treated as the sense of the preposi-tion. This yields the following sense annotation:
Table 13 shows the distribution of common roles assigned to prepositional phrases. The topic role is the most frequent case not directly covered in PTB. 3.3.1 Illustration with  X  X t.  X  See Table 14 for the most frequent roles out of the 124 cases that were assigned to at , along with the conditional probabilities for these roles given that certain high-level WordNet synsets occur in the context. In a context referring to concrete entities, the role place becomes more prominent. However, in an abstract context, the role time becomes more prominent. Thus, similar behavior to that noted for
PTB in Section 3.2.1 occurs with FrameNet. 3.3.2 Results. Table 15 shows the results of classification when all of the prepositions are classified together. Due to the exorbitant number of roles (641), the overall results are low. However, the combined collocation approach still shows slight improvement (23.3% versus 23.1%). The FrameNet inventory contains many low-frequency relations 170 1% of the role occurrences for prepositional phrases, substantial improvement results, with entropy 3.82). Table 16 also shows the per-class statistics, indicating that the means and place roles are posing difficulties for classification.

This illustrates that the role distributions are more complicated than those for PTB, yielding higher entropy values on average. In all, there are over 360 prepositions with annotations, 92 with ten or more instances each. (Several of the low-frequency cases are actually adverbs, such as anywhere , but are treated as prepositions during the annotation extraction.) The results show that the word collocations produce slightly better results: 67.8 versus 66.0 for combined collocations. Unlike the case with PTB, the single-classifier performance is below that of the individual classifiers. This is due to the fine-grained nature of the role inventory. When all the roles are considered together, prepositions are sometimes being incorrectly classified using roles that have not been assigned to them in the training data. This occurs when contextual clues are stronger for a commonly used role than for the appropriate one. Given PTB X  X  small role inventory, this problem does not occur in the corresponding experiments. 3.4 Factotum Classification Experiments The third set of experiments deals with preposition disambiguation using Factotum.
Note that Factotum does not indicate the way the relationships are expressed in English.
Similarly, WordNet does not indicate this, but it does include definition glosses. For example, (10)
These definition glosses might be useful in certain cases for inferring the relation markers (i.e., generalized case markers). As is, Factotum cannot be used to provide training data for learning how the relations are expressed in English. This contrasts with corpus-based annotations, such as PTB (Marcus et al. 1994) and FrameNet (Fillmore, Wooters, and Baker 2001), where the relationships are marked in context. 3.4.1 Inferring Semantic Role Markers. To overcome the lack of context in Factotum, the relation markers are inferred through corpus checks, in particular through proximity searches involving the source and target terms from the relationship (i.e., source, 172 relation , target ). For example, using AltaVista X  X  Boolean search,  X  X ource NEAR target. X  search results, possibly including parsing, in order to extract the patterns. As an ex-pedient, common prepositions 9 are included in a series of proximity searches to find the preposition occurring most frequently with the given terms. For instance, given the relationship drying, is-function-of , drier , the following searches would be performed. (11) drying NEAR drier NEAR in mation (MI) statistics (Manning and Sch  X  utze 1999, pages 66 X 68) are used in place of the raw frequency when rating the potential markers. These are calculated as follows:
Such checks are done for the 25 most common prepositions to find the preposition yielding the highest mutual information score. For example, the top three markers for the drying, is-function-of , drier relationship based on this metric are during, after, and with. 3.4.2 Method for Classifying Functional Relations. Given the functional relationships in
Factotum along with the inferred relation markers, machine-learning algorithms can be used to infer what relation most likely applies to terms occurring together with a particular marker. Note that the main purpose of including the relation markers is to provide clues for the particular type of relation. Because the source term and target terms might occur in other relationships, associations based on them alone might not be as accurate. In addition, the inclusion of these clue words (e.g., the prepositions) makes the task closer to what would be done in inferring the relations from free text.
The task thus approximates preposition disambiguation, using the Factotum relations as senses.
 the feature set used in the PTB and FrameNet experiments (see Figure 4), simplified to account for the lack of sentential context. Figure 6 contains sample feature specifications from the experiments discussed in the next section. The top part shows the original relationships from Factotum; the first example indicates that connaturalize causes simi-larity . Also included is the most likely relation marker inferred for each instance. This shows that  X  X /a X  is used whenever a preposition for a particular relationship cannot be inferred. This happens in the first example because connaturalize is a rare term. for the three different experiment configurations, based on the inclusion of word and/or hypernym collocations. In each case, the classification variable is given by relation .
For brevity, the feature specification only includes collocation features for the most frequent relations. Sample collocations are also shown for the relations (e.g., vulgar-ity for is-caused-by ). In the word collocation case, the occurrence of similarity is used to determine that the is-caused-by feature (WC 1 ) should be positive (i.e.,  X 1 X ) for the first two instances. Note that there is no corresponding hypernym collocation due to conditional probability filtering. In addition, although new is not included as a word collocation, one of its hypernyms, namely Adj:early#2 , is used to determine that the has-consequence feature (HC 3 ) should be positive in the last instance. 174 Context: Source and target terms from relationship ( source, relation , target ) Features: POS source : part-of-speech of the source term POS target : part-of-speech of the target term Prep: preposition serving as relation marker ( X  X /a X  if not inferable) WordColl r : 1 iff context contains any word collocation for relation r HypernymColl r : 1 iff context contains any hypernym collocation for relation r Collocation selection: Frequency: f ( word ) &gt; 1
Relative percent change: ( P ( C | coll )  X  P ( C )) / P ( C ) Organization: per-class-binary grouping Model selection: Decision tree using Weka X  X  J4.8 classifier (Witten and Frank 1999) 3.4.3 Results. To make the task more similar to the PTB and FrameNet cases covered previously, only the functional relations in Factotum are used. These are determined by removing the hierarchical relations (e.g., has-subtype and has-part ) along with the attribute relations (e.g., is-property-of ). In addition, in cases where there are inverse functions (e.g., causes and is-caused-by ), the most frequently occurring relation of each inverse pair is used. This is done because the relation marker inference approach does not account for argument order. The boldface relations in the listing shown earlier in
Table 5 are those used in the experiment. Only single-word source and target terms are considered to simplify the WordNet hypernym lookup (i.e., no phrasals). The resulting data set has 5,959 training instances. The data set also includes the inferred relation markers (e.g., one preposition per training instance), thus introducing some noise. relationship similarity, is-caused-by ,rhyme from Factotum is augmented with the by marker prior to classification. Again, these markers are inferred via Web searches involving the terms from the original relationship.
 types achieves the best overall accuracy at 71.2%, which is good considering that the baseline of always choosing the most common relation ( is-caused-by ) is 24.2%. This com-bination generalizes well by using hypernym collocations, while retaining specificity via word collocations. The classification task is difficult, as suggested by the number of classes, entropy, and baseline values all being comparable to the filtered FrameNet experiment (see Table 16). 3.5 Common Relation Inventory Classification Experiments
The last set of experiments investigate preposition disambiguation using FrameNet mapped into a reduced semantic role inventory. For the application to lexical acqui-sition, the semantic role annotations are converted into the common relation inventory discussed in Section 2.5. To apply the common inventory to the FrameNet data, anno-tations using the 641 FrameNet relations (see Table 2) need to be mapped into those Relationships from Factotum with inferred markers:
Relationship Marker similarity, is-caused-by , connaturalize n/a similarity, is-caused-by ,rhyme by approximate, has-consequence ,imprecise because new, has-consequence , patented with Word collocations only: is-caused-by NNVBn/a 1000000 is-caused-by NN NN by 1 0 0 0 0 0 0 has-consequence NN JJ because 0 0 0 0 0 0 0 has-consequence JJ VBN with 0 0 0 0 0 0 0
Sample collocations: is-caused-by { bitterness, evildoing, monochrome, similarity , vulgarity has-consequence { abrogate, frequently, insufficiency, nonplus, ornament Hypernym collocations only: is-caused-by NNVBn/a 0000000 is-caused-by NNNN by 0000000 has-consequenceNNJJbecause0000000 has-consequenceJJVBNwith0010000
Sample collocations: is-caused-by { N:hostility#3, N:inelegance#1, N:humorist#1 has-consequence { V:abolish#1, Adj:early#2 , N:inability#1, V:write#2 Both collocations: is-caused-by NN VB n/a 1 ... 0 0 0 0 ... is-caused-by NN NN by 1 ... 0 0 0 0 ... has-consequence NN JJ because 0 ... 0 0 0 0 ... has-consequence JJ VBN with 0 ... 0 0 0 1 ...
 Legend: POS s &amp; POS t are the parts of speech for the source and target terms; and r &amp; HC r are the word and hypernym collocations as follows: 1. is-caused-by 2. is-function-of 3. has-consequence 4. has-result 5. is-caused-by mental 6. is-performed-by 7. uses 176 using the 26 common relations shown in Table 8. Results for the classification of the
FrameNet data mapped into the common inventory are shown in Table 19. As can be seen, the performance is well above that of the full classification over FrameNet without filtering (see Table 15). Although the low-frequency role filtering yields the highest performance (see Table 16), this comes at the expense of having half of the training instances discarded. Corpus annotations are a costly resource, so such waste is undesirable. Table 19 also shows the per-class statistics, indicating that the means , direction ,and part roles are handled poorly by the classifier. The latter two are due to the relatively small training examples for the roles in question, which can be addressed partly by refining the mapping from FrameNet. However, problems classifying the means role occur with all classifiers discussed in this article, suggesting that that role is too subtle to be classified with the feature set currently used.
 an additional advantage of improving performance in the classification, compared to a cascaded approach. This occurs because several of the miscellaneous roles in FrameNet cover subtle distinctions that are not relevant for definition analysis (e.g., cognizer and addressee ). The common inventory therefore strikes a balance between the overly general roles in PTB, which are easy to classify, and the overly specialized roles in FrameNet, which are quite difficult to classify. Nonetheless, a certain degree of classification diffi-culty is inevitable in order for the inventory to provide adequate coverage of the dif-ferent distinctions present in dictionary definitions. Note that, by using the annotations from PTB and FrameNet, the end result is a general-purpose classifier, not one tied into dictionary text. Thus, it is useful for other tasks besides definition analysis. system we developed at NMSU (O X  X ara 2005). Evaluation of the resulting distinctions was performed by having the output of the system rated by human judges. Manu-ally corrected results were also evaluated by the same judges. The overall ratings are not high in both cases, suggesting that some of the distinctions being made are subtle.
For instance, for  X  X ounterintelligence achieved by deleting any information of value X  from the definition of censoring, means is the preferred role for by, but manner is ac-
Thus, the judges differed considerably on these cases. However, as the ratings for the uncorrected output were close to those for the corrected output, the approach is promising to use for lexical acquisition. If desired, the per-role accuracy results shown in Table 19 could be incorporated as confidence values assigned to particular relation-ships extracted from definitions (e.g., 81% for those with source but only 21% when means used). 4. Related Work
The main contribution of this article concerns the classification methodology (rather than the inventories for semantic roles), so we will only review other work related to this aspect. First, we discuss similar work involving hypernyms. Then, we address preposition classification proper.
 include a numeric density feature for any synset that subsumes words appearing in the document, potentially yielding hundreds of features. In contrast, the hypernym collocations discussed in Section 3.1.1 involve a binary feature for each of the relations being classified, using indicative synsets based on the conditional probability test. This test alleviates the need for their maximum height parameter to avoid overly general hypernyms. Their approach, as well as ours, considers all senses of a word, distrib-uting the alternative readings throughout the set of features. In comparison, Gildea 178 and Jurafsky (2002) instead just select the first sense for their hypernym features for relation classification. They report marginal improvements using the features, whereas configurations with hypernym collocations usually perform best in our preposition disambiguation experiments.
 information extraction inferred from FrameNet annotations by distributing support from terms co-occurring in annotations for frame elements to the terms for hypernyms.
However, they do not incorporate a filtering stage, as with our conditional probability test. Mihalcea (2002) shows how hypernym information can be useful in deriving clues for unsupervised WSD. Patterns for co-occurring words of a given sense are induced from sense-tagged corpora. Each pattern specifies templates for the co-occurring words in the immediate context window of the target word, as well as their corresponding synsets if known (e.g., sense tagged or unambiguous), and similarly the hypernym synsets if known. To disambiguate a word, the patterns for each of its senses are evaluated in the context, and the sense with the most support is chosen.
 indicated by prepositional phrases (i.e., preposition word-sense disambiguation). Until recently, there has been little work on general-purpose preposition disambiguation.
Litkowski (2002) and Srihari, Niu, and Li (2001) present approaches using manually derived rules. Both approaches account for only a handful of prepositions; in contrast, for FrameNet we disambiguate 32 prepositions via individual classifiers and over 100 prepositions via the combined classifier. Liu and Soo (1993) present a heuristic approach for relation disambiguation relying upon syntactic clues as well as occurrence of specific prepositions. They assign roles to constituents of a sentence from corpus data provided that sufficient instances are available. Otherwise, a human trainer is used to answer questions needed by the system for the assignment. They report an 86% accuracy rate for the assignment of roles to verbal arguments in about 5,000 processed sentences.
Alam (2004) sketches out how the preposition over might be disambiguated into one of a dozen roles using features based on the head and complement, such as whether the head is a movement verb or whether the complement refers to a duration. These features form the basis for a manually-constructed decision tree, which is interpreted by hand in an evaluation over sentences from the British National Corpus (BNC), giving a precision of 93.5%. Boonthum, Toida, and Levinstein (2006), building upon the work of Alam, show how WordNet can be used to automate the determination of similar head and complement properties. For example, if both the head and complement refer to people, with should be interpreted as accompaniment. These features form the basis for a disambiguation system using manually constructed rules accounting for ten commonly occurring prepositions. They report a precision of 79% with a recall of 76% over an inventory of seven roles in a post hoc evaluation that allows for partial correctness. proach used here. Gildea and Jurafsky (2002) perform relation disambiguation using the
FrameNet annotations as training data. They include lexical features for the headword of the phrase and the predicating word for the entire annotated frame (e.g., the verb corresponding to the frame under which the annotations are grouped). They also use several features derived from the output of a parser, such as the constituent type of the phrase (e.g., NP), the grammatical function (e.g., subject), and a path feature listing part-of-speech tags from the target word to the phrase being tagged. They report an accuracy of 78.5% with a baseline of 40.6% over the FrameNet semantic roles. However, by conditioning the classification on the predicating word, the range of roles for a particular classification instance is more limited than in the experiments presented in this article.
Blaheta and Charniak (2000) use the PTB annotations for relation disambiguation. They use a few parser-derived features, such as the constituent labels for nearby nodes and part-of-speech for parent and grandparent nodes. They also include lexical features for the head and alternative head (because prepositions are considered as the head by their parser). As their classifier tags all adjuncts, they include the nominal and adverbial roles, which are syntactic and more predictable than the roles occurring with prepositional phrases.
 (Carreras and M ` arquez 2004, 2005; Litkowski 2004). A common approach is to tag all the semantic roles in a sentence at the same time to account for dependencies, such as via Hidden Markov Models. To take advantage of accurate Support Vector Machine classification, Pradhan et al. (2005) instead use a postprocessing phrase based on trigram models of roles. Their system incorporates a large variety of features, building upon sev-eral different preceding approaches, such as including extensions to the path features from Gildea and Jurafsky (2002). Their lexical features include the predicate root word, headwords for the sentence constituents and PPs, as well as their first and last words.
Koomen et al. (2005) likewise use a large feature set. They use an optimization phase to maximize satisfaction of the constraints imposed by the PropBank data set, such as the number of arguments for particular predicates (e.g., just two for stalk, arg0 and arg1 ). hypernyms selected to serve as collocations, building upon our earlier work (O X  X ara and Wiebe 2003). They report 87.7% accuracy in a setup similar to ours over PTB (i.e., a gain of 2 percentage points). They use a different type of collocation feature than ours: having a binary feature for each potential collocation rather than a single feature per class. That is, they use Over-RangeBinary rather than Per-ClassBinary (Wiebe,
McKeever, and Bruce 1998). Moreover, they include several hundred of these features, rather than our seven ( benefactive previously included), which is likely the main source of improvement. Again, the per-class binary organization is a bag of words approach, so it works well only with a limited number of potential collocations. Follow-up work of theirs (Ye and Baldwin 2007) fared well in the recent preposition disambiguation competition, held as part of SemEval-2007 (Litkowski and Hargraves 2007). Thus, an immediate area for future work will be to incorporate such improved feature sets. We will also investigate addressing sentential role constraints as in general semantic role tagging. 5. Conclusion
This article shows how to exploit semantic role resources for preposition disambigua-tion. Information about two different types of semantic role resources is provided. The emphasis is on corpus-based resources providing annotations of naturally occurring text. The Penn Treebank (Marcus et al. 1994) covers general roles for verbal adjuncts and
FrameNet (Fillmore, Wooters, and Baker 2001) includes a wide range of domain-specific roles for all verbal arguments. In addition, semantic role inventories from knowledge bases are investigated. Cyc (Lehmann 1996) provides fine-grained role distinctions,
Factotum (Cassidy 2000) includes a variety of functional relations, and work in Concep-tual Graphs (Sowa 1999) emphasizes roles for attributes. Relations from both types of resources are considered when developing the inventory of relations used for definition analysis, as shown in Table 8.
 and is framed as word-sense disambiguation for the preposition in question. A new 180 type of feature for word-sense disambiguation is introduced, using WordNet hyper-nyms as collocations rather than just words, as is typically done. The full feature set is shown in Figure 4. Various experiments over the PTB and FrameNet data are presented, including prepositions classified separately versus together, and illustrating the effects of filtering. The main results in Tables 11 and 16 show that the combined use of word and hypernym collocations generally achieves the best performance. For relationships derived from knowledge bases, the prepositions and other relational markers need to be inferred from corpora. A method for doing this is demonstrated using Factotum, with results shown in Table 18. In addition, to account for granularity differences in the semantic role inventories, the relations are mapped into a common inventory that was developed based on the inventories discussed in the article. This allows for improved classification in cases where inventories provide overly specialized relations, such as those in FrameNet. Classification results are shown in Table 19.
 ness of incorporating a variety of clues for general-purpose relation disambiguation (Carreras and M ` arquez 2005). Some of the techniques developed here for preposition disambiguation can likely help with relation disambiguation in general. For instance, there are quite a few lexical features, such as in Pradhan et al. (2005), which could be extended to use semantic classes as with our hypernym collocations. In general it seems that, when lexical features are used in supervised machine learning, it is likely that corresponding class-based features based on hypernyms can be beneficial for improved coverage.
 lexical acquisition from dictionaries, which was the motivation for the emphasis on preposition disambiguation. Isolating the preposition annotations allows the classifiers to be more readily tailored to definition analysis, especially because predicate frames are not assumed as with other FrameNet relation disambiguation. Future work will investigate combining the general relation classifiers with preposition disambiguation classifiers, such as is done in Ye and Baldwin (2006). Future work will also investigate improvements to the application to definition analysis. Currently, FrameNet roles are always mapped to the same common inventory role (e.g., place to location ). However, this should account for the frame of the annotation and perhaps other context information.
Lastly, we will also look for more resources to exploit for preposition disambiguation (e.g., ResearchCyc).
 Acknowledgments References 182 184
This article has been cited by:
