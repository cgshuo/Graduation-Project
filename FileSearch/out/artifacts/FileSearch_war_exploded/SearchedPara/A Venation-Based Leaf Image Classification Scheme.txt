 Recently, due to the development of computer and network technologies, generating, processing and sharing digital contents have become popular. And this leads to a huge amount of images being available. As the number of digital images has increased, the need for sophisticated image retrieval has been emphasized. Traditional image retrievals relied on th e textual information such as file names or keywords describing memorizing such text information is not manageable any more by human beings. To automatically some useful information describing those objects including shapes, textures and colors. 
CBIR techniques have huge diverse applications. Especially, due to the popularity garden, people may encounter some unfamiliar plant. In this case, instead of looking drawing or taking a picture of it and query to the database via wireless connection [1]. As another example, if someone is on a fishing trip and he wants to know about some information about the fish [2]. 
For the effective content based image retrieval, the system needs to figure out and uses images features such as textures, colors, or shapes. provide some clue to finding similar ones. In addition, if we examine the leaf similar ones from its corresponding categorized group in the database. Leaf venations the density of feature points using non-parametric estimation density. Section 3 describes a vena tion-based leaf image categorization scheme which collects leaf venation X  X  feature points and calculates their distribution using the Parzen Window [3]. Based on this distribution, the type of leaf venation is identified. Section 4 describes several experiments and the last section concludes the paper and discusses future work. Well-designed image retrieval tools enable people to make an efficient use of digital maintaining annotation consistency among images in large databases. In order to researched in the last decade. Examples of some of the prominent systems using this approach are VIRAGE, QBIC, Photobook, and VisualSEEk. 
In many CBIR systems, an image is represented by low level features such as color, texture, shape, and structure. Relevant images are retrieved based on the similarity of their image features. In particular, shape-based image retrieval is regarded as an efficient and interesting approach. For example, shape recognition methods have been proposed and implemented into face recognition, iris recognition, and fingerprint recognition. In case images show similar color or texture, shape-based instance, leaves of most plants are green or brown; but the leaf shapes are distinctive and can thus be used for identification. One of the main issues in these studies is how to represent the shape of a leaf image. One approach is to get an approximat ed polygon of leaf shape via Minimum Perimeter Polygon (MPP) algorithm [4]. A leaf shape can be represented by positions of vertexes [5] or a set of line segments connecting two adjacent vertexes and angles effective. On the other hand, there is a representation scheme called Center-Contour Distance Curve (CCD) which calculates distances between the center and external points of suitable for the general leaf image retrieval. In this section, we describe how to identify leaf venations. Leaf venation corresponds to the blood vessel of organisms. Before we describe details, we first explain the types will show how to select feature points for the representation of venation. Finally, we distribution of those selected feature points. 3.1 Venation Types of Leaves categorization. observe a lot of primary veins, which are parallel up to the end of the leaf, split from last, type (d) is palmate venation, in which three or more primary veins are split from the petiole and form palm-like shape. 
The key characteristic of pinnate venation is that there exists one primary vein and categorization, we need to find out the points where the secondary veins get split, and check the distribution of those points. If the observed distribution is in the line-type, then this line is considered as a primary vein and the points along this line are where the secondary veins get split. 
The key characteristic of parallel venation is the fact that all the veins merge at the end of the leaf. In this case, we check the distribution of the points where the vein gets ended. If there are heavy densities at the top of the leaf, then the leaf is considered to check locations with heavy density, where vein gets split. Another method to separate them would be to check whether it has line-type distribution or not. 
In the case of palmate venation, we can observe the vein gets split at the bottom of points where the vein gets split. 3.2 Leaf Feature Extraction were also categorized by the venation type, then we can reduce the number of images Corner Detection algorithm [9] in order to extract those feature points. This algorithm are the maximum curvature points. 3.2.1 Edge Detection Before we apply the CSS algorithm to image, we first perform the Canny Edge applying the Canny Edge Detection algorithm to it. 
During this step, if the leaf venation is somehow broken or the vein is too thin, the detected as a single closed loop. If we have several curves due to the reasons already mentioned, the order of feature points extracted will be mixed up and cause a problem, which we will explain later. This problem can be solved by adding image pre-processing step. That is, before the Edge Detection process, making the venation thicker and increasing the contrast of the image would solve the broken vein problem. 3.2.2 Feature Points Detection Feature points can be obtained from the curves in the previous step. The CSS algorithm will be used at this point. Applying the algorithm to the image on the right side of Fig. 2 will give the venation feature points where the curvature gets maximum values. At these points, the venation gets branched and ended. gets branched, because they both have the maximum curvature value. In order to solve this problem, we need to do the following process. 
Two feature points are not necessarily representing one position. Therefore, we points, and then detect a point which have less than 90 degree angle value. In the case of Fig. 3, the black point, which is located below, will be ignored, and the white point will be selected as a feature point. The feature points after applying the CSS algorithm to the image of Fig. 2 are showed in Fig. 4. 3.2.3 Branching Points / Ending Points Distinction Branching Points (BP) or as Ending Points (EP). For example, for the ending point in Fig. 5(b), the direction changes from the ending point to the left side, and changes connected points ( BP/EP for the middle point which means checking the location of later point position or bottom position) will be the decision maker. If position, then the proceeding direction will be changed to the left and EP based on previous proceeding direction. If it is the other way, then If the angle between the line reference point and checking the y-coordinate of coordinate of negative value, then it is Branching Point. Detailed algorithm is showed in Table 1. 
To judge the proceeding direction, we set the bottom venation starting point as base point and check whether the direction is clockwise or counter-clockwise compared to the x-coordinates of previous point and later point. Fig 6, grey points are where venation gets branched (Branching Point) and black points are where the venation gets ended (Ending Point). 3.3 Density Distribution of Feature Points along a line or around one point. The density of Branching Points and Ending Points can be calculated by the Parzen Window method [5] which is non-parametric density. This method estimates the density function from a limited data. We first explain how to get the standard line that is necessary to calculate the density of feature points, and this standard line. 3.3.1 Pseudo Primary Vein distribution, we need to obtain the dens ity of feature points by calculating the distance that connects from the top point of the venation to the bottom point. And the calculated perpendicular line is used as the pseudo normal line. We can check the row find where density gets maximum value. Similarly to this, by calculating the density between BP or other feature points and the pseudo normal line, we can possibly check the column distribution. 3.3.2 Parallel Venation Verification densely dispersed at end of the leaf. To check this type of distribution, we have to see the column distribution of feature points. Table 2 shows the algorithm for calculating the density of distance between a line and feature points. 
In order to get the distance where the density gets maximum value, we need to check the number of maximum values. If the number of maximum values is one and maximum values is two and the average distances of feature points on each maximum value are distributed above and below the venation, then we may consider it parallel venation too. Fig. 8 shows a sample graph from calculating density of feature points in the parallel venation. 3.3.3 Relationships of Branching Points In this step, we calculate the density of BPs to check whether the primary vein does exist or not and to decide whether it is palmate venation or not. 
To check whether the distribution of BPs is line-shaped or densely dispersed around one point, we need to calculate both the row density and the column density. We find out points where the density gets maximum value by calculating the row and column density. And then we need to check BPs whose distance is around this horizontally related BPs from the pseudo normal line. parallel to the pseudo primary vein. Like a palmate venation, if some BPs are with no relationships. They are considered as secondary branching point or noise and will be ignored in the vein classification process. In the figure, a black box indicates a horizontally related BP and a cross indicates a vertically related BP. Finally, a small black point is an EP. 3.3.4 Venation Classification related BP is dominant, a real primary vein is found and the BPs are on it. In this case, the leaf image can be classified as pi nnate venation or parallel venation. If maximum density value is found at the top of the venation, this leaf will be classified as parallel relations in both directions. In order to measure the effects of the venation-based categorization in the leaf image retrieval, we have used the CLOVER system as our test-bed. CLOVER is a shape-based image retrieval system that we have built for retrieving domestic aqua-plants in Korea. The algorithms were tested on the PC with Pentium 4 3.0GHz CPU, 1GB RAM. In the test, we extracted leaf images fr om Illustrated flora of Korea [8], which points. Fig. 10 and Table 3 show the result. Method r = 1% r = 2% r = 3% r = 4% r = 5% Without Categorization With Categorization 
In Fig. 10, a query image is drawn by a user. For the comparison, we have retrieval with venation categorization which was described in this paper. Each retrieval scheme calculates image similarities between the query image and images in the database. In the shape-based retrieval with venation categorization, we categorize the query image first, and calculate the similarity against database images that belong to the same category as the query image. Based on it, Fig. 10 shows ten most similar images in the database. 
Table 3 shows average rates of success retrievals which the querying images are observe that our categorization scheme enhances the retrieval effectiveness a lot. 
Average time taken to extract the feature points by MATLAB was 0.55 second, and average time to categorize the leaf venation using this result was 0.08 second. 
By incorporating this scheme, we can reduce the time for retrieving similar images proposed categorization scheme. In this paper, we have presented a novel leaf image categorization scheme by using its performance by reducing the number of images to be searched for. Through the very little time (less than 1 sec) whereas it enhanced the retrieval time and accuracy a lot. The proposed categorization scheme needs furt her studies. A classification of the As a result, some BPs and EPs are not classified properly. This may be corrected by thickening the vein and increasing its contrast. But, if the position of a fault point was around the petiole, the extraction direction of feature points might be inversed. So, the whole BP/EP classification would be mixed up. We need more studies to solve these problems. Acknowledgments. This research was supported by the MIC(Ministry of Information and Communication), Korea, under the ITRC support program supervised by the IITA and a grant(no.BDM0100211) to JRL from the Strategic National R&amp;D Program through the Generic Resources and Information Network Center funded by the Korean Ministry of Science and Technology. 
