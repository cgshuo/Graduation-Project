 DAGger is a clustering algorithm for uncertain data. In con-trast to prior work, DAGger can work on arbitrarily corre-lated data and can compute both exact and approximate clusterings with error guarantees.

We demonstrate DAGger using a real-world scenario in which partial discharge data from UK Power Networks is clustered to predict asset failure in the energy network. H.2.8 [ Database Management ]: Database Applications X  Data mining Clustering, classification, uncertain data, probabilistic data, correlations, partial discharge, dagger.
Recent years have witnessed a surge in the amount of digitally-born data. In many scenarios, this data is inher-ently uncertain or probabilistic, such as in automatic data extraction, image and voice detection ( e.g. , processing hand-writing, controlling mobile phones by voice), location detec-tion, sensor networks, and measurement data [13]. Uncer-tain data calls for new processing approaches where uncer-tainty is explicitly accounted for, and it has led to a solid body of work on building probabilistic databases, such as MystiQ, Trio, and MayBMS. Albeit at a smaller scale, there is effort to adapt well-known data mining tasks to uncertain data, e.g., in discovery of frequent patterns and association rules [14], clustering [5], and classification [10]. However, to the best of our knowledge, prior work only considers limited probabilistic data models based on a simplifying indepen-dence assumption and circumvents the hardness of probabil-ity computation by the use of expected values and Monte-Carlo sampling. Expected values can lead to unintuitive re-sults, for instance when data values and their probabilities Table 1: Simplified data set. The labelled sensor readings are prior to a fault on January 11, 2011. The last two read-ings can be classified by clustering them with labelled data. of the clustering for the set of new sensor readings and are able to distinguish spurious readings from readings that in-dicate an imminent failure of an asset ( e.g. , a cable). The audience of this demonstration can explore the clustering outcome visually, as well as a ranked list of critical assets.
In the rest of this paper, we explain our demonstration scenario, show how DAGger clusters uncertain sensor read-ings, and detail on how the audience of our demonstration can interact with the system.
We demonstrate the clustering capability of DAGger in an application that predicts asset failure in energy networks.
Partial discharge (PD) is an electrical discharge that does not fully bridge the insulation between two conducting elec-trodes. It has been identified as one of the major causes of long-term degradation and eventual failure of cables.
In order to minimise the customer minutes lost, energy distribution network operators (DNOs) are currently deploy-ing sensors to monitor partial discharge activity in the dis-tribution network, to be able to act preemptively [8, 9]. Un-fortunately, monitoring partial discharge is not a straightfor-ward task: the phenomenon is hard to detect, sensors often report spurious measurements and are prone to failure (as are the transmission channels).

The HiPerDNO project [15] aims to show the benefits of the introduction of cutting edge computational tools and techniques to improve electricity distribution network oper-ations in partnership with UK Power Networks and other European DNOs.
The data used to demonstrate our system is historical data on partial discharge activities in distribution networks, as well as records of network load and asset failure. It is gath-ered from two different types of sensors: (1) partial discharge sensors installed on switchgear and cables in substations of the distribution network, and (2) network load sensors in substations. By aggregating the number of partial discharge occurrences over the duration of an hour and subsequently pairing this value with the average network load during that Figure 1: Partial DAG with five layers encoding clustering events for clusters C 0 (OK) and C 1 (warn) in our example.
In this expression,  X  [ o i  X  C j ] denotes the event that read-ing o i belongs to cluster C j . DAGger can cluster the data set from Table 1 and perform exact classification of o 25 within seconds. The system can thus inform the user whether new readings indicate that a fault is imminent.
At the core of DAGger lies the well-known k-medoids clus-tering algorithm [2, 7], an unsupervised data mining tech-nique that partitions a set of data points into k groups of similar points. It repeatedly assigns data points to clusters and re-elects cluster medoids, until convergence is reached.
In DAGger , the assignment of data points to clusters and selection of cluster medoids are probabilistic events. There-fore, a data point belongs to a cluster or is a cluster medoid with a certain probability. Conceptually, DAGger  X  X  outcome is equivalent to applying the standard k-medoids algorithm in each possible world. However, DAGger cannot afford to enumerate the exponentially many possible worlds and per-form a clustering in each of them. Instead, its computation is more symbolic as it traces the clustering events and uses them to compute probabilities of possible clusterings to any approximation degree. This symbolic computation can be orders of magnitude faster than the more extensional ap-proach based on explicit enumeration of the possible worlds. In this section, we give some details on how DAGger works. Constructing events. The events  X  [ o i ] associated with input readings are the building blocks for events that are subsequently created by DAGger to express medoid selection and cluster assignment. At each clustering step, such events depend solely on events from the previous step. All events can be represented in a layered structure, where each layer corresponds to a clustering step and where we factor out common expressions. This layered factorisation, which is a directed acyclic graph (DAG), is key to the compact rep-resentation of the events, as it exploits the combinatorial nature of clustering computation. For instance, the event  X  [ o i  X  C j ] that reading o i belongs to cluster C j is expressed as a conjunction of the event  X  [ o i ] and of events for all cases in which a reading o l is the medoid of cluster C j and the dis-tance from o i to o l is the smallest among all distances from o to the other readings. Figure 1 partially depicts such a DAG. Clustering events are expressed using conditional ex-pressions that involve propositional formulas and distances, since the selection of new cluster medoids depends on in-put events and distances between data points. They are expressed in the algebraic structure of the semimodule de-
DAGger has a graphical user interface to present the clus-tering outcome, as well as the incremental probability com-putation of the clustering events. Screenshots of this inter-face are given in Figures 2 and 3.

On the first tab, the user can make a selection of the input data (both labelled and unlabelled data) which is to be analysed by DAGger . After the data analysis has started, the user can monitor the progress and examine the results.
On the tab  X  X lassification: asset risks X  (Figure 2), the sys-tem displays the results of the classification of the unlabelled data points. It lists the assets that were classified into the warn category in decreasing order of probability.

The tab  X  X lustering: assignments X  (Figure 3a) shows the probabilistic assignment of data points to clusters.
The tab  X  X lustering: visualisation X  (Figure 3b) presents the user with a visual representation of the uncertain clus-tering. By selecting a sensor reading (in this case: o 6 ), the interface will show the user the probability that the data point will be clustered into the same cluster as the closest neighbouring data points: the darker the line that connects o to another data point, the higher the probability that the two data points end up in the same cluster.

Throughout the interface of the system, the user will see the exact lower and upper bounds of the probabilities, whilst the probabilities are being established. Unless DAGger is configured to compute approximate probabilities, the system will present the user with the exact probabilities once the lower and upper bounds have converged.
 The authors would like to thank Peter Lang, Matthieu Michel, and Koen Tavernier (UK Power Networks, IPEC) for providing us with the data. This work is sup-ported by EC FP7 HiPerDNO project under grant 248235 and EPSRC ADEPT project under grant EP/I000194/1.
