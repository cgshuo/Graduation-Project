 Hua Wang huawangcs@gmail.com Feiping Nie feipingnie@gmail.com Heng Huang heng@uta.edu Traditional machine learning methods usually work well when sufficient training data are available. How-ever, because manually labeling data is both expensive and time-consuming, it is desirable to have new tech-niques to learn a classifier with high accuracy but from only a limited number of labeled training data. Semi-supervised learning methods (Zhu, 2006) exploit unla-beled data to remedy the lack of labeled data, which, however, requires that the unlabeled data are under the same distribution as the labeled. Typical trans-fer learning methods (Pan &amp; Yang, 2009) relax this restriction to learn useful representations from data under different distributions, which, though, still re-quire the further labeled data from related homoge-nous tasks. For example, the images from horse, dol-phin, bear classes can help categorizing other animal images, such as armadillos, tigers, zebras images. In this paper, we ask how unlabeled data from heteroge-neous classes, which are much easier to be obtained, to be used for helping classification tasks. For exam-ple, given unlimited access to unlabeled and randomly chosen images, e.g ., those downloaded from Internet (probably none of which contains the object of inter-est), can we do better in an existing image categoriza-tion task? Motivated by the observation (Raina et al., 2007; Raina, 2009; Lee et al., 2009) that many randomly downloaded images can still contain the basic visual patterns (such as edges) that are similar to those in existing training images, as shown in Figure 1, one can learn a succinct and higher-level feature representation of the unlabeled data, which could potentially improve the existing image categorizations. Our new approach belongs to an emerging machine learning topic of self-taught learning (STL) (Raina et al., 2007; Dai et al., 2008; Raina, 2009; Lee et al., 2009), a special type of transfer learning. Because self-taught learning places fewer restrictions on unlabeled data, it has much more applications than traditional transfer learning or semi-supervised learning methods. For example, it is far easier to obtain 10,000 Internet images than obtain 10,000 images of tigers or armadillos.
 The flexibility of self-taught learning makes it of par-ticular use in practice, which, though, also brings new challenges. First, because the unlabeled data are ran-domly obtained from Internet or other inexpensive sources, these data could be very different the tar-get objects. Consequently, noises and outlier samples abound in the unlabeled data by nature, which, com-pared to standard supervised classification tasks, re-quires more robustness on the learning model. Second, existing self-taught learning methods (Raina et al., 2007; Lee et al., 2009) unsupervisedly learn the feature dictionary and ignore the supervision information con-tained in labeled images. Thus, effectively utilizing the labeling information is another challenging yet impor-tant issue. To tackle these difficulties, in this paper we propose a novel robust and discriminative self-taught learning approach with the following contributions: 1. Instead of using traditional squared  X  2 -norm loss function when learning the feature dictionary, we use the  X  2 , 1 -norm loss function, which is robust to out-lier samples (Ding et al., 2006; Nie et al., 2010). To our best knowledge, we are the first to learn a robust dictionary in both self-taught learning and dictionary learning areas. 2. Different to existing methods that incorporate prior knowledge by introducing additional terms into the ob-jectives, we propose a new dictionary learning objec-tive to leverage the labeling information by imposing structured sparsity on the representation coefficients via the  X  2 , 1 -norm regularizations (Bradley &amp; Bagnell, 2009; Jia et al., 2010), such that no extra parameter is involved and our model is easier to fine tune. More-over, through the selected prominent basis vectors due to the  X  2 , 1 -norm regularization, the optimal dictionary size is automatically determined. 3. We derive a new efficient iterative solution algo-rithm, whose convergence is rigorously proved. In this section, we will first briefly review the tradi-tional self-taught learning method, from which we will systematically develop our new robust and discrimina-tive self-taught learning model.
 Notations and problem formalization. Through-out this paper, we will write matrices as bold upper-case characters and vectors as bold lowercase charac-ters. Given a matrix M = [ m ij ], we denote its i -th row and its j -th column as m i and m j , respectively. In self-taught learning, we are given a labeled training Figure 1) drawn independently and identically from a certain distribution D . x l i  X  R p is a feature vector as-sociated to its binary label indicator y l i  X  { 0 , 1 } K for K classes of interest, such that y l i ( k ) = 1 if x l i to the k -th class, and 0 otherwise. In addition, we also have a set of m unlabeled data { x u i  X  R p } m i =1 in the auxiliary domain. Crucially, we do not assume that the data from the auxiliary and target domains share the same distribution or class labels. Our goal is to beled data { x u i } m i =1 a function that is able to predict labels for an unseen data point x drawn from the dis-tribution D in the target domain as shown in Figure 1. For convenience, we write X k  X  R p  X  n k (1  X  k  X  K ) as the data matrix of the k -th class, whose columns are the n k labeled images belonging to the k -th class. 2.1. A Brief Review of Traditional STL In self-taught learning (Raina et al., 2007), we first learn a set of r basis vectors, { d j  X  R p } r j =1 , forming to make the dictionary over-complete), from unlabeled data by minimizing the following objective: where  X  &gt; 0 is a parameter and a u i  X  R r is the representation coefficient vector of x u i with respect to the dictionary D . Here we constrain d j to avoid de-generate solution, because the reconstruction errors in the first term of J u are invariant to simultane-ously scaling D by a scalar and a u i by its inverse (Lee et al., 2007). Due to the  X  1 -norm regularization on a , it is sparse with very few non-zero entries (Tib-shirani, 1996; Cand`es &amp; Wakin, 2008). Therefore, d j (1  X  j  X  r ) are considered as high-level feature pro-totypes learned from the unlabeled data, which could be more discriminative and convey more semantic in-formation (Raina et al., 2007; Mairal et al., 2009). Then the labeled data can be represented with respect to the learned dictionary D by minimizing: respect to D . Again, a l i is sparse due to the  X  1 -norm regularization.
 e.g ., support vector machine (SVM) as in (Raina et al., 2007), to classify unseen images under the distribution D . Despite a number of imperfections in the current implementations, compared to directly classifying the have demonstrated better performance in a number of learning tasks (Raina et al., 2007; Raina, 2009; Lee et al., 2009; Bengio et al., 2009). In the rest of this sec-tion, we will discuss the weaknesses of the current self-taught learning methods and develop our new method to address them. 2.2. Learning Robust and Adaptively Learning robust dictionary with both labeled and unlabeled data. In existing self-taught learning methods (Raina et al., 2007; Raina, 2009; Lee et al., 2009), the dictionary to transfer knowledge is learned from some unlabeled data as in Eq. (1) and used for the labeled data as in Eq. (2), separately. Because the final classification is performed on unseen data un-der the same distribution as the labeled data, it could be beneficial to learn the dictionary and sparse data representations from both unlabeled and labeled data together by minimizing the following objective: where, for notation brevity, we denote C =
D | k d j k 2  X  1 ,  X  1  X  j  X  r as the feasible domain of the problem.
 Because J 1 in Eq. (3) uses the squared  X  2 -norm loss function to measure reconstruction errors, which is no-toriously known in statistical learning to be sensitive to outlier training samples, following (Ding et al., 2006; Nie et al., 2010) we consider to use a robust loss func-tion to minimize the following objective: Denote X = [ X 0 , X 1 , . . . , X K ], and A = [ A 0 , A 1 , . . . , A K ] where A 0 = [ a u 1 , . . . , a u a 1 , . . . , a l n k , we can write J 2 in a more succinct form using matrices as following: Because the reconstruction error terms in Eq. (4) and Eq. (5) are not squared, the outlier samples have less influences and our objectives are more robust. Learning adaptive dictionary. Because the  X  1 -norm regularizations used in Eqs. (1 X 5) flatly enforce sparsity, all the basis vectors, i.e ., the underlying data patterns, in the learned dictionary D are evenly treated and used in the learning process. To cap-ture all potential data patterns, following the theory of compressed sensing (Cand`es &amp; Wakin, 2008), the dictionary is routinely designed to be over-complete thereby redundant, which makes the subsequent tasks computationally inefficient. Several attempts (Lee et al., 2007; Mairal et al., 2009; 2008; 2010) have been successfully made to address this to learn a compact dictionary with smaller dictionary size. A crucial is-sue of these methods is that the dictionary size has to be specified by heuristics. The important issue to determine the optimal dictionary size was never taken into account. In this paper, motivated by (Bradley &amp; Bagnell, 2009; Jia et al., 2010) we present a princi-pled method to seek the optimal dictionary basis vec-tors. Most importantly, following the same idea, the supervision information can be incorporated with no additional parameter introduced.
 Suppose we have an over-complete dictionary D , the basis vector selection can be formalized as: where D X is the optimal compact dictionary and m is its size. However, three problems impede us to solve Eq. (6) directly. First, D is not known in a priori, which also needs to be learned. Second, the under-lying high-level patterns, i.e ., the number of dictio-nary basis m , are also not known beforehand. Last, Eq. (6) is a combinatorial optimization problem, which is NP-hard. To tackle these difficulties, we first rewrite Eq. (6) in its equivalent form as follows: where k M k 2 , 0 is defined as the number of non-zero rows of the matrix M .
 Recent theoretical progresses (Tibshirani, 1996; Cand`es &amp; Wakin, 2008) show that k M k 2 , 1 is the min-imum convex hull of k M k 2 , 0 . When M is row-sparse enough, one can always minimize k M k 2 , 1 to obtain the same result as minimizing k M k 2 , 0 . Thus, we propose to learn D and A from X by minimizing the following objective: In Eq. (8), the second term uses the  X  2 , 1 -norm reg-ularization, which, different from the flat penalty in-troduced by the  X  1 -norm regularization as in Eqs. (5 X  7), penalizes all n representation coefficients ( i.e ., all entries in a i ) corresponding to one single basis vec-tor of D as a whole, and compute the  X  1 -norm over a = a 1 2 , . . . , k a r k 2 T . Consequently, sparsity is conferred on a , and the basis vectors in D correspond-ing to the non-zero entries of resulted a are automati-cally selected for succeeding data representation. De-note D X = d i | a i the columns (basis vectors) of D that correspond to the nonzero entries of a , we may construct D X  X  R p  X |D X | by using all d i  X  D X as its columns. As a result, D X is compact and only the relevant basis vectors specific to the input data are selected, whose number automat-ically determines the dictionary size. As shown later (in Section 3 of supplementary document due to space limit), we only need to roughly specify a preliminary size of D , which does not impact the dictionary quality of D X in a large selection range.
 Learning discriminative dictionary. In self-taught learning, because we have both unlabeled and labeled data, we could take advantage of the supervision infor-mation in labeled data to make the learned dictionary discriminative thereby benefit the succeeding classifi-cations. Instead of using an additional term to in-corporate label information as in most, if not all, prior studies (Mairal et al., 2009; 2008; 2010), we enforce the structured sparsity on the coefficient matrix A upon the supervision knowledge, such that no extra param-eter is required. Specifically, we learn D and A from X by minimizing the following objective: Upon solution, let D k = d i | a i k 2 &gt; 0 where a i k the i -th row of A k , we construct the k -th class spe-cific dictionary D k  X  R p  X |D k | using all d i  X  D k as its columns. Obviously, D 0 is the dictionary learned for the unlabeled data and D k (1  X  k  X  K ) is discrimina-tively specific to the data belonging to the k -th class, although all of them are constructed from the globally learned super dictionary D . Again, the size of D k is automatically determined by |D k | .
 Because the labeled and unlabeled data come different distributions in self-taught learning, it is reasonable to use  X  2 , 1 -norm to group the unlabeled data together in dictionary learning. If our model is applied to semi-supervised learning problems, the  X  1 -norm should be used between labeled and unlabeled data. From this point, we can also see the differences between self-taught learning and semi-supervised learning. Finally, we call J RD in Eq. (9) as the proposed Ro-bust and Discriminative Self-Taught Learning (RD-STL) approach, because the learned dictionaries D k (1  X  k  X  K ) ( D 0 is not used for classification) are both robust to outlier training samples and adaptively discriminative with respect to the classes in the target domain. Our approaches bridges the unlabeled (aux-iliary domain) and labeled (target domain) data and transfers knowledge from the former to the latter as shown in Figure 1, where, crucially, we allow data to come from different distributions. 2.3. Optimization Algorithm and Its Analysis Because our new objective J RD in Eq. (9) comprises multiple terms of  X  2 , 1 -norms, it is difficult to solve in general by existing optimization algorithms. Hence we derive a alternately iterative algorithm to solve the problem 1 , which employs the same mechanism of the iteratively re-weighted method (Gorodnitsky &amp; Rao, 1997; Nie et al., 2010; Wang et al., 2011; 2012b;c; 2013) to deal with the non-smooth  X  2 , 1 -norm terms. First, when fixing A , we need to solve the following optimization problem: Then, when we fix D , J RD in Eq. (9) is decoupled into the following subproblems for each k (0  X  k  X  K ): We alternately solve the problems in Eq. (10) and Eq. (11) to minimize the objective J RD in Eq. (9). Our algorithm is described in Algorithm 1, whose con-vergence is guaranteed by the follow theorem. Algorithm 1 An efficient iterative algorithm to solve the objective value of Eq. (9).
 Theorem 1 Algorithm 1 decreases the objective value J RD in Eq. (9) in each iteration till converges. where i = t or t + 1. In each iteration t , according to the Step 2 in the Algorithm 1, we know that According to Step 3 we know, Based on Eq. (12) and Eq. (13), we know Because it can be verified that (Wang et al., 2012d) for function f ( x ) = x  X  x 2 2  X  , given any x 6 =  X   X  R , f ( x )  X  f (  X  ) holds, together with the definitions of U and Adding Eqs. (14) X (16) in the both two sides, we have Note that, the equalities in Eqs. (12 X 17) hold if and only if the objective value converges. Because J RD in Eq. (9) is obviously lower bounded by 0, the ob-jective value of J RD is decreased in each iteration till converges, which completes the proof of Theorem 1. 2.4. Classification of Test Images Given a test image x in target domain and the learned dictionaries D k (1  X  k  X  K ), we can compute the sparse representation of x for the k -th class, a ( k ) , by reconstruction error of x with respect to the k -th class same way, we can compute the reconstruction errors e i for labeled images. Then we can compute the adaptive decision boundary (Wang et al., 2009; 2012a) to classify the test image, which can be applied to both single-label and multi-label data sets.
 Transfer learning and self-taught learning. From machine learning perspective of view, our approach be-longs to the important topic of transfer learning, which aims to make use of knowledge, either unsupervised or supervised, from another domain with different distri-bution to improve the learning in the current domain of interest. We refer readers to (Pan &amp; Yang, 2009) for a comprehensive survey.
 Self-taught learning is an emerging branch of transfer learning, which was first formalized in (Raina et al., 2007) and further developed in (Dai et al., 2008; Raina, 2009; Lee et al., 2009). Self-taught learning aims to utilize unlabeled data with as minimum restrictions as possible. The proposed approach is motivated by and closely related to (Raina et al., 2007), yet different from it in a number of important aspects as detailed in Section 2.2, including (1) joint data utilization, (2) ro-bustness to outliers samples that abound in unlabeled images by nature, (3) dictionary discriminativity and (4) optimal dictionary size selection.
 Sparse coding and dictionary learning. Sparsity is one of the intrinsic properties of real world data (Tibshirani, 1996), which makes it useful in many ma-chine learning and computer vision tasks, such as face recognition (Mairal et al., 2009), image classification (Bengio et al., 2009), digital art authentication (Mairal et al., 2010), and many others.
 Recent studies (Lee et al., 2007) have demonstrated that decomposing a signal using a few atoms of learned dictionary often leads to state-of-the-art results in real world applications, which aroused considerable inter-est in the machine vision community (Lee et al., 2007; Bengio et al., 2009; Mairal et al., 2010; 2009). Al-though a variety of aspects of dictionary learning have been addressed by these previous works, none of them takes into account the dictionary robustness problem. Moreover, these methods typically pre-specify the dic-tionary size heuristically or by prior knowledge, while how to determine the optimal dictionary size in a prin-cipled way is much less studied (Bradley &amp; Bagnell, 2009; Jia et al., 2010). In addition, existing supervised dictionary learning methods routinely employ an ad-ditional term to incorporate the labeling information, which inevitably complicates the learning models and makes them less practically useful. Contrastly, our new RD-STL approach gracefully solves all these im-portant yet challenging problems in a unified frame-work via joint  X  2 , 1 -norm minimizations, which makes our model of particular use in real-world applications. In this section, we experimentally evaluate the pro-posed approach, where our goal is to examine its ca-pability to improve the classification performance in the target domain by taking advantage of unlabeled data that come from an inexpensive source with dis-tributions (possibly) different from the target data. Unlabeled images in auxiliary domain. We ran-domly downloaded 5000 images from the LabelMe data set and use them as unlabeled images in the aux-iliary domain. Because the more than 10 thousands images in the LabelMe data set come from numerous resources, including Internet, video clips, daily photo, etc ., it is an ideal source for unlabeled images in self-taught learning.
 Labeled and test images in target domain.
 We use TRECVID 2005 , MSRC-v2 and NUS-WIDE-Object images data sets as target data sets, which are broadly used in computer vision studies. The details of the data sets are supplied in Section 1 of the supplementary document due to space limit. Our goal is to classify the test images in these data sets using the proposed RD-STL model. 4.1. Study of the Size of the Preliminary In the proposed method, a preliminary dictionary D is learned, from which we adaptively select discrimi-native basis vectors specific for each class. Therefore, although the sizes of the ultimate output dictionar-ies D k (0  X  k  X  K ) are automatically determined by the learned patterns in A k (0  X  k  X  K ), we still need to pre-specify the size of D , same as in existing re-lated works (Raina et al., 2007; Raina, 2009; Bengio et al., 2009; Lee et al., 2007; Mairal et al., 2009; 2008; Zhang &amp; Li, 2010; Pham &amp; Venkatesh, 2008; Mairal et al., 2010). However, different from these prior stud-ies that directly use D for data representation and classification, the qualities, i.e ., the subsequence clas-sification accuracies, of learned adaptive dictionaries D k (0  X  k  X  K ) do not heavily rely on the size of D . As shown in Figure 2, when the sizes of the preliminary dictionaries vary in a large range, the classification ac-curacies of the proposed method remain considerably stable. This demonstrates that our new method is able to adaptively learn class specific dictionary for classifi-cation, which do no rely on the preliminary dictionary size as long as it is not too small. Empirically, when | D |  X  2 K , the subsequent classification accuracy is generally satisfactory. In all our experiments, we set | D | = min { 1000 , n } .
 4.2. Improved Image Categorization We compare our approach to the following related methods: supervised learning method (1) SVM as baseline; two widely used semi-supervised learning methods including (2) transductive SVM (TSVM) (Joachims, 1999) method and (3) the Green X  X  func-tion (GF) method (Ding et al., 2007); and three trans-fer learning methods including (4) knowledge transfer by words (KTW) method (Li et al., 2009), (5) self-taught clustering (STC) method (Dai et al., 2008) and (6) self-taught learning (STL) method (Raina et al., 2007). STL method needs to use SVM to classify the learned target data representations. We implement these compared methods and fine tune their param-eters following their original works. For SVM and TSVM methods, we use the Gaussian kernel ( i.e ., K ( x i , x j ) = exp  X   X  k x i  X  x j k 2 ), and fine tune  X  and the regularization parameter C in the range of ods are single-label classification methods while the target image data sets are multi-label data sets, follow-ing (Wang et al., 2010a) we employ the one-vs .-other strategy to deal with multi-label data.
 In addition, we also compare our approach against two most recent multi-label classification methods including (7) multi-label feature transform (MLFT) (Wang et al., 2010b) method and (8) Multi-Label Least Square (MLLS) (Ji et al., 2010) method. We implement five versions of the proposed approach to evaluate the usefulness of its component terms as following: (A) the simplest joint self-taught learning method using J 1 in Eq. (3), denoted as  X  X -STL X ; (B) robust self-taught learning method using J R in Eq. (5), denoted as  X  X -STL X ; (C) robust and adaptive self-taught learning method using J RA in Eq. (8), denoted as  X  X A-STL X ; (D) Discriminative self-taught learn-ing method but not taking into account robustness against outlier samples that minimizes J D ( D , A ) ( X  X  DA ) T STL X ; and (E) the proposed RD-STL approach using J
RD in Eq. (9). Note that, the first three methods are unsupervised learning methods, therefore we employ SVM to classify the learned target data representa-tions, same as the STL method (Raina et al., 2007). For the last two methods, we classify unseen images using the rules introduced in Section 2.4. For all the five methods, we fine tune the parameter  X  by search-ing the grid of 10  X  5 , . . . , 10  X  1 , 1 , 10 1 , . . . , 10 Performance metrics. Because we experiment with multi-label data sets, following (Wang et al., 2009; 2010a;b), we use the four standard multi-label classifi-cation performance metrics, macro averaged precision and F1 score, and micro averaged precision and F1 score, to evaluate the compared methods.
 Experimental results. We perform standard 5-fold cross-validation to evaluate the compared methods on the three target data sets. An internal 5-fold cross-validation is conducted in the training data of each of the 5 trials to fine tune the parameters of the compared methods. The experimental results are reported in Table 1, from which we have a number of interesting observations as following.
 First, the proposed methods are consistently better than other compared methods, which demonstrate their effectiveness in the task of automatic image cat-egorization.
 Second, SVM, TSVM and GF methods do not have satisfactory classification performance. This can be explained as follows. SVM is a supervised method, which can be learned only from the target data while the large amount of auxiliary data are not used. Al-though the two semi-supervised methods employ both axuliary and target data, they assume them to come from a same distribution, which, however, is not true in both this experiment and many real world applica-tions. That is, a simple mixture of the auxiliary and target data can not leads to satisfactory classification performance.
 Third, the two transfer learning methods, KTW and STC, also do not work well in the experiments. This is because typical transfer learning methods, such as the two used in our experiments, require labeled images in auxiliary data and aim to transfer such knowledge. When prior knowledge are not available in auxiliary data, these two methods actually perform unsuper-vised clustering on the target data, though with the aid from the auxiliary data. These results clearly show the necessity of STL.
 Fourth, compared to STL method, joint self-taught learning by J-STL method does not essentially im-prove the classification accuracy, which can be seen by the fact that the target data are much less than the unlabeled auxiliary data.
 Five, R-STL, RA-STL and RD-STL show much better results than other compared methods, which demon-strate that enhancing robustness against the noises and outliers in the unlabeled source data does im-prove the classification performance significantly, as expected. In addition, although labeling information is used in D-STL method, its performance is inferior due to not taking into account robustness. Finally, robustness plus discriminativity, i.e ., the propose RD-STL approach, achieves the best classification perfor-mances, which concretely confirm that these two issues are the most important impact factors to the classifi-cation performance of self-taught learning. (See more experimental results and discussion on the robustness of the proposed RD-STL model in Section 4 of the supplementary document due to space limit.) Last, but not least, although RA-STL method does not outperform R-STL method very much in terms of classification accuracy, the dictionary size of the for-mer is much smaller than that of the latter. The sizes of the learned dictionary D X for the three data sets are 46, 29 and 26 respectively, which are much smaller than the preliminary dictionary size for D as 1000, 591, and 1000 respectively. The same observation also ap-plies to the proposed RD-STL approach. We explain this observation as follows. In traditional sparse learn-ing, motivated by compressed sensing, dictionaries are generally designed to be over-complete. However, the number of underlying patterns of most real-world data is usually small. From information theory perspective, many basis vectors in the learned dictionary are indeed redundant, which might be detrimental to the subse-quent sparse solver. To address this, our new method uses data adaptation via the  X  2 , 1 -norm regularization to find out the most representative dictionary basis vectors, which leads to a small number of significant dictionary bases and reduces the computational loads in subsequent data representations for test data. To tackle the difficulty of lacking training data in real-world applications, we proposed a novel RD-STL approach to leverage unlabeled images. Different from traditional semi-supervised learning and trans-fer learning methods, our new approach places signif-icantly fewer restrictions on the unlabeled data. We addressed two important issues in existing self-taught learning methods, including the robustness against noisy and outlier samples in unlabeled data and the usage of supervision information in the target data, by a joint  X  2 , 1 -norms minimization framework. Promising results of extensive empirical studies demonstrated the effectiveness of the proposed approach.
 Corresponding Author: Heng Huang (heng@uta.edu) This work was partially supported by NSF CCF-0830780, CCF-0917274, DMS-0915228, IIS-1117965.
