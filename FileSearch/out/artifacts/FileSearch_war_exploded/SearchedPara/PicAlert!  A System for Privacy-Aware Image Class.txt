 Photo publishing in Social Networks and other Web2.0 ap-plications has become very popular due to the pervasive availability of cheap digital cameras, powerful batch upload tools and a huge amount of storage space. A portion of uploaded images are of a highly sensitive nature, disclosing many details of the users X  private life. We have developed a web service which can detect private images within a user X  X  photo stream and provide support in making privacy de-cisions in the sharing context. In addition, we present a privacy oriented image search application which automati-cally identifies potentially sensitive images in the result set and separates them from the remaining pictures.
 H.3.5 [ Online Information Services ]: Web-based services image analysis, privacy, classification, diversification
With increasing availability of content sharing environ-ments such as Flickr, and YouTube, the volume of private multimedia resources publicly available on the Web has dras-tically increased. In particular young users often share pri-vate images about themselves, their friends and classmates without being aware of the consequences such footage may have for their future lives [1, 5]. Users of photo sharing sites often lack awareness of privacy issues. Our recent study [6] revealed that up to 20% of publicly shared photos on Flickr are of sensitive nature. Existing sharing platforms often em-ploy rather lax default privacy configurations, and require users to manually decide on privacy settings for each single resource. Given the amount of shared information, this pro-cess can be tedious and error-prone. This is especially true for large batch photos uploads. Furthermore, image search engines do not provide the possibility to directly search for private images which might already be available on the web.
In this work we demonstrate the PicAlert! 1 privacy ori-ented image search application. PicAlert! is able to identify and isolate images in a Flickr result set that are potentially sensitive with respect to user privacy. The application is based on a web service that automatically identifies a pri-vacy degree of an image through classification of the content and context of the image. It could be directly integrated into social photo sharing applications like Flickr or Face-book, or into browser plugins in order to support users in making adequate privacy decisions in image sharing. Thus, the application illustrated in the demo is two-fold: warn-ing the user about uploading potentially sensitive content on the one hand (Figure 2a) and privacy-oriented search on the other hand (Figure 2b).

We are aware that building alarm systems for private con-tent and enabling privacy-oriented search can be seen as contradicting goals; privacy-oriented search is not negative per-se, as it can be used for retrieving private content users are comfortable to share, and, more importantly, can help with the early discovery of privacy breaches. However, as with almost every technology, it requires sensible handling and constructive usage.
This section describes the main components of the Pi-cAlert! system. The system architecture is illustrated in Figure 1. Firstly, through crowd-sourcing , we build a train-ing set of private and public images. In the next step we ex-tract visual, and, if available, textual features which provide hints for the privacy degree of an image. We then train a SVM classifier which is used by our Search and Alert system for identifying potentially sensitive visual content. Finally, the user can access the application from arbitrary clients including desktops and mobile devices. In the following we provide a brief overview of the system components and show how results are presented to the user. A fully detailed de-scription of the underlying scientific approach can be found in our recent work [6]. ate dataset with labeled private and public image examples, we performed a user study in which we asked external asses-sors to judge the privacy of photos available online as an an-notation game. To this end, we crawled 90,000 images from Flickr, using the  X  X ost recently uploaded X  option to gather photos uploaded in a time period of 4 months. At each step of the game we presented five photos to a participant of the study. For each photo, the participants had to decide if, in their opinion, the photos belonged to the private sphere of the photographer. Specifically, we asked the participants to imagine that images presented to them were photos they took with their own cameras, and mark these images as X  X ri-vate X ,  X  X ublic X , or  X  X ndecidable X . We provided the following guidance for selecting the label:  X  Private are photos which have to do with the private sphere (like self portraits, fam-ily, friends, your home) or contain objects that you would not share with the entire world (like a private email). The rest are public . In case no decision can be made, the picture should be marked as undecidable . X  Over the course of the experiment, 81 users between ten and 59 years of age labeled 37,535 images. Each picture was labeled private or public if at least 75% of the judges were of the same opinion. Overall the dataset contained 4,701 images labeled as private, and 27,405 images labeled as public; the remainder were marked as undecidable.
 dimensional arrays of color pixels. This representation is difficult to use directly for classification because it is highly multidimensional and subject to noise. Instead, a process known as feature extraction is typically used to make mea-surements about the image content. Image features come in many forms, from the very low-level, to so-called high-level features. Low-level features are typically formed from sta-tistical descriptions of pixels, whilst high-level features are those that have a directly attributable semantic meaning. For this application, we have selected a range of image fea-tures that could potentially be used in building a classifier that can discriminate public and private images automati-cally. In particular we observed that the occurrence of faces in a picture is strongly associated with a high degree of pri-vacy although a considerable number of faces also can be found in public images. Intuitively, color may be an indica-tor for certain types of public and private image. For exam-ple, public images of landscape scenes are very likely to have a specific color distribution. The edges within an image are a very powerful feature for discriminating between different in/outdoor types of scene, and are useful for privacy classi-fication. Finally the SIFT descriptor [4] turned out to be the most powerful feature for our application. Private and public photos typically tend to be taken in specific contexts. For example, pictures can be taken in public places like sta-diums, supermarkets and airports, or in private places like home, car, or garden. Accordingly the object parts con-tained in a photo, like sport equipment, furniture, human and animal body parts are represented as SIFT features and could be different and thus give us insights about an image X  X  privacy. For efficiency reasons we limited the visual features used for the demonstration application to face detection and SIFT features. Additionally, we made use of textual features including the image tags and title.
 domly restricting the initial image set described in Section 2 to a subset of 9402 images with an equal number of public and private images. The balanced set helps to capture gen-eral classifier properties independently of the a-priori class probabilities of the dataset. In the next step we built clas-sifiers using the SVMlight [2] classification software. The results of the classification experiments for selected visual features described in Section 2 are presented in Section 3 we estimated the likelihood of image privacy using the out-put of the SVM classifier trained on a set of images labeled as  X  X ublic X  or  X  X rivate X  by the users. We use the Flickr API as the underlying search provider for our PicAlert! search service. The user interface of the application simply consists of a text box and a keyword search can be performed press-ing the  X  X earch X  button. The difference to other engines is mainly in the search result representation. PicAlert! divides the results into two sets:  X  X ublic X  and  X  X rivate X . Addition-ally, each set is divided into three subsets according to the classifier confidence intervals and is denoted by color. The green color corresponds to a strong classifier confidence, yel-low to moderate and red to a weak confidence. Figure 2 shows an example for the results representation for the query  X  X hristiano ronaldo X . In the left ( X  X ublic X ) part we observe that the majority of pictures are related to sporting events, whilst the right ( X  X rivate X ) part is mostly dominated by pho-tos about Ronaldo X  X  private life.
Figure 3: P /R curves for the features and their combination. tion approach, from the initial dataset we randomly sampled 60% as training data for building our classifiers, and 40% as test data, with each data set containing an equal proportion of public and private instances. Our quality measures for the classification are the precision-recall curves as well as the precision-recall break-even points for these curves. The break-even point (BEP) is equal to the F 1 measure and the harmonic mean of precision and recall. The results of the classification experiments for the visual features described in Section 2 and the combination of visual and textual fea-tures are shown in Figure 3. The visual features only lead to the BEP of 0.74. The text features provide a short but con-cise summary of the image content and result in a BEP of 0.78. Finally, the combination of the visual and textual fea-tures leads to an additional performance boost with a BEP of 0.80, showing that textual and visual features can comple-ment each other in the privacy classification task. However, classification with only visual features alone also produces promising results, and is useful if limited or no textual an-notations are available, as is the case for many photos on the web.
 quality we randomly chose 50 image-related queries from an MSN search engine query log 2 . For each query, we com-puted privacy-oriented rankings using the pre-trained clas-sifier. The list of test photos in descending order of their user-assigned privacy value was considered as ground truth for our experiments. We compared the order of the auto-matically generated rankings using Kendall X  X  Tau-b [3]. We chose the Tau-b version in order to avoid a systematic ad-vantage of our methods due to many ties produced by the high number of photos with equal user ratings. The original Flickr ranking does not consider the privacy of the images in the search results. This was reflected by a small  X  b value of -0.04. In contrast, our methods show a clear correlation with the user-based privacy ranking. The combination of textual and visual features provides the best ranking performance (  X  =0.33).
Privacy Oriented Image Search Demonstration: Firstly the user types an arbitrary query into the search text field of the search interface. The results are separated into pub-lic and private sets according to the privacy value estimated by the classifier (Figure 2b). We can observe that the pro-portion of the private results is strongly query dependent (e.g.  X  X irthday X  X esults in more private pictures than X  X ree X ). The user can move the mouse pointer over a result image and see additional information including the privacy value computed by the classifier. Clicking on the image opens the corresponding Flickr page.

Classification Web Service Demonstration: We can select photos from our personal local file system (or memory sticks of visitors) and upload it to PicAlert! through the graph-ical upload control. The classification result is shown as a percentage value (Figure 2a) with a text message. In order to visually support the user, traffic lights are displayed with colors corresponding to the classifier decisions. The user can move the mouse over the table with the visual features de-termined in her picture and the features are visualized by squares and stars determining the position and the rotation of the selected feature. The user can also repeat the process with a picture from Flickr, or an image denoted by an ar-bitrary URL. In addition to the graphical interface there is also an XML-based web service interface available.
The demo described in this paper introduces PicAlert! -a search engine for privacy oriented image search as well as web service for supporting user decisions regarding im-age privacy. This web service can be integrated into arbi-trary social network and image sharing platforms, as well as browser plugins or mobile devices and prevent the user from publishing potentially sensitive visual content about herself.
The popularity of mobile devices equipped with high def-inition cameras continues to increase. We plan to study pictures taken with mobile phones where we expect a larger proportion of private images. Apart from employing ad-ditional visual features, we further plan to include context recognition using smartphones and their sensors for GPS location, temperature, or acceleration.
This work is partly funded by the European Commission under the grant agreement 270239 ( ARCOMEM ) and 287704 ( CUBRIK ) as well as by the NTH School for IT Ecosystems. [1] S. B. Barnes. A privacy paradox: Social networking in [2] T. Joachims. Making large-scale support vector [3] W. H. Kruskal. Ordinal measures of association. [4] D. Lowe. Distinctive image features from scale -[5] V. Schleswig-Holstein. Statistische erfassung zum [6] S. Zerr, S. Siersdorfer, J. Hare, and E. Demidova.
