 In this work a novel algorithm, named DOLPHIN, for detecting distance-based outliers is presented.

The proposed algorithm performs only two sequential scans of the dataset. It needs to store into main memory a portion of the dataset, to efficiently search for neighbors and early prune inliers. The strategy pursued by the algorithm allows to keep this portion very small. Both theoretical justification and empirical evidence that the size of the stored data amounts only to a few percent of the dataset are provided.

Another important feature of DOLPHIN is that the memory-resident data are indexed by using a suitable proximity search ap-proach. This allows to search for nearest neighbors looking only at a small subset of the main memory stored data.

Temporal and spatial cost analysis show that the novel algorithm achieves both near linear CPU and I/O cost. DOLPHIN has been compared with state of the art methods, showing that it outperforms existing ones.
 H.2.8 [ Database Management ]: Database Applications Algorithms, Performance Anomaly detection, data mining, distance-based outliers
There exist several approaches for the problem of singling out the objects mostly deviating from a given collection of data [6, 5, 18, 12, 17, 1, 22]. In particular, distance-based approaches [18] exploit the availability of a distance function relating each pair of objects of the collection. These approaches identify as outliers the objects lying in the most sparse regions of the feature space. Copyright 2007 ACM 978-1-59593-803-9/07/0011 ... $ 5.00.
Distance-based definitions [18, 23, 3] represent an useful tool for data analysis [19, 15, 21]. They have robust theoretical foun-dations, since they are a generalization of different statistical tests. Furthermore, these definitions are computationally efficient, since distance-based outlier scores a re monotonic non-increasing func-tion of the portion of the database already explored.

In recent years, several clever algorithms have been proposed to fast detecting distance-based outliers [20, 23, 7, 4, 16, 24]. Some of them are very efficient in terms of CPU cost, while some others are mainly interested in minimizing the I/O cost. Nevertheless, it is worth to notice that none of them is able to simultaneously achieve the two previous goals when the dataset does not fit in main mem-ory.

In this work a novel technique for mining distance-based outliers in an high-dimensional very large disk-resident dataset, with both near linear CPU and I/O cost, is presented.

The proposed algorithm, DOLPHIN, performs only two sequen-tial scans of the data. It needs to maintain in main memory a subset of the dataset and employs it as summary of the already seen ob-jects. This subset allows to efficiently search for neighbors of data set objects and, thus, to fast determine whether an object is an inlier or not. An important feature of the method is that memory-resident data is indexed by using a suitable proximity search approach. Fur-thermore, DOLPHIN exploits some effective pruning rules to early detect inliers, without needing to find k neighbors for each of them. Importantly, both theoretical justification and empirical evidence that the amount of main memory required by DOLPHIN is only a small fraction of the dataset is provided. Therefore, the approach is feasible on very large disk-resident datasets.

The I/O cost of DOLPHIN corresponds to the cost of sequen-tially reading two times the input dataset file. This cost is really negligible even for very large datasets. As for the CPU cost, both experimental results and analytical studies show that the algorithm performs in near linear time.

DOLPHIN has been compared with the state of the art methods, showing that it outperforms existing ones of at least an order of magnitude.

The rest of the work is organized as follows. In Section 2 the contribution of the work is stated. Subsequent Section 3 describes the DOLPHIN algorithm. Section 4 analyzes the spatial and tempo-ral cost of DOLPHIN. Section 5 presents a thorough experimental activity, including comparison with state of the art outlier detection methods. Finally, Section 6 depicts conclusions. Distance-based outliers have been first introduced by Knorr and Ng [18].

D EFINITION 2.1. Let DS be a set of objects, k a positive inte-ger, and R a positive real number. An object o of DS is a distance-based outlier (or, simply, an outlier) if less than k objects in within distance R from o .
 Objects lying at distance not greater than R from o are called neigh-bors of o . The object o is considered a neighbor of itself.
This definition is well founded, since it generalizes several sta-tistical outlier tests [18]. Some variants of the original definition have been subsequently introduced in literature. In particular, Ra-maswamy et al. [23], in order to ra nk the outliers, introduced the following definition: given two integers k and n , an object o is said to be an outlier if less than n objects have higher value for D o ,where D k denotes the distance of the k th nearest neighbor of the object. Subsequently, Angiulli and Pizzuti [3, 4, 2], with the aim of taking into account the whole neighborhood of the objects, proposed to rank them on the basis of the sum of the distances from the k nearest neighbors, rather than considering solely the distance to the k th nearest neighbor. Last defin ition was also used by Eskin et al. [15].

The three above definitions are closely related. In particular, there exist values for the parame ters such that the outliers found by using the first definition are the same as those obtained by us-ing the second definition, but not the third one. In this work we will deal with the original definition provided in [18], even if we will compare also with approaches following the definition given in [23].

Knorr et al. [18, 20] presented two algorithms. The first one is a block nested loop algorithm that runs in O ( dN 2 ) time, where N is the number of objects and d the dimensionality of the data set. The second one is a cell-based algorithm that is linear with respect to N , but exponential in d . This last method is fast only if d is small. On the other hand, the nested loop approach does not scale well w.r.t. N . Thus, efforts for developing efficient algorithms scaling to large datasets have been subsequently made.

In [23] the authors presented two novel algorithms to detect out-liers. The first assumes the dataset is stored in a spatial index, like the R  X  -tree [8], and uses it to compute the distance of each dataset object from its k th nearest neighbor. Pruning optimizations to re-duce the number of distance computations while querying the index are exploited. The authors noted that this method is computation-ally expensive and introduced a partition-based algorithm to reduce the computational cost. The second algorithm, first partitions the input points using a clustering algorithm, and then prunes the parti-tions that cannot contain outliers. E xperiments were reported only up to ten dimensions.

Bay and Schwabacher [7], introduced the distance-based outlier detection algorithm ORCA. Basically, ORCA enhances the naive block nested loop algorithm with a simple pruning rule and ran-domization, obtaining a near linear scaling on large and high di-mensional data sets. The major merit of this work, is to show that the CPU time of the their schema is often approximately linear in the dataset size.

Ghoting et al. [16], in order to improve performances of ORCA, proposed the algorithm RBRP (Recursiv e Binning and Re-Projection). The method consists of two phases. During the first phase, a divi-sive hierarchical clustering algorithm is used to partition objects into bins, i.e. group of objects likely to be close each other. Then, objects in the same bin are thus reorganized according to the pro-jection along the principal component. During the second phase, the strategy of ORCA is employed on the clustered data, obtaining improved performances.

Recently, Tao et al. [24], pointed out that for typical values of the parameters, ORCA has quadratic I/O cost. Then, they presented an algorithm, named SNIF (for ScaN with prIoritized Flushing), in-tended to work with dataset that do not fit into main memory, and whose major goal is to achieve linear I/O cost. The proposed tech-nique retrieves the outliers by scanning the dataset three or two times. Roughly speaking, SNIF accommodates in memory both a sample set of objects of fixed size s and a fixed number of other dataset objects. In particular, the sample set is employed to build a summary of the dataset, represented by s spheres of radius R/ 2 centered in the s objects, which is used to early prune inliers. The authors show that the I/O cost of their algorithm is low and insen-sitive to the parameters, but time performances of the method were not deeply investigated.

This work presents a novel distance-based outlier detection al-gorithm, named DOLPHIN (for Detecting OutLiers PusHing data into an INdex), whose goal is to achieve both near linear CPU and I/O cost on very large disk-resident datasets, with a small usage of main memory. It gains efficiency by integrating pruning rules and state of the art database index technologies .

It must be preliminary noted that, none of the existing methods is able to put together the above goals. Some algorithms exploit indexing or clustering [23, 16], but require to build the index, or to perform clustering, on the whole dataset, and, in some cases, to store the clustered data in main memory. On the other hand, the technique of detecting outliers by directly exploiting existing in-dexing techniques [9, 8, 10, 11, 13] in order to search for the k th nearest neighbor of an object, suffers of the drawback that all the dataset objects have to be stored into the index structure. Besides, note that the approach of computing the k nearest neighbors of each object is not very efficient for outlier detection, since, for a lot of objects, this task can be avoided by using clever algorithms. Fur-thermore, the approach in [7] works directly on disk-resident data and is efficient in CPU time, being able to achieve roughly near lin-ear time for some combinations of the parameters, but, as pointed out in [24], its I/O cost may be quadratic. On the other hand, the ap-proach in [24] keeps low the I/O cost, but it is not as efficient from the point of view of the CPU cost (for example, note that, SNIF compares each dataset object to all the s centroids, but s =1 , 000 , or greater, is a typical value for this parameter), and cannot be used in non metric spaces.

DOLPHIN detects outliers in disk-resident datasets. It performs two sequential scans of input dataset file. During the first scan, it maintains in main memory a data structure storing a small subset of the dataset objects, together with some additional information. This memory-resident data structure represents a summary of the already seen objects, and it is used to determine whether the object currently read from disk is an inlier or not. If it cannot be deter-mined that the current object is an inlier, then it is added to the memory-resident data. At the same time, objects already stored in main memory could be recognized as inliers and may be discarded. By retaining a moderate fraction of proved inliers, DOLPHIN is able to effectively exploit the triangular inequality to early prune inliers, without the need of computing k distances per object.
The contribution of this work can be summarized as follows:
In this section the algorithm DOLPHIN is described. The algo-rithm makes use of a data structure called DBO-index (where DBO stands for Distance Based Outlier) defined next.
 Let DS be a disk-resident dataset. First of all the definition of DBO-node is provided.

D EFINITION 3.1. A DBO-node n is a data structure containing the following information: A DBO-index is a data structure based on DBO -nodes, as defined in the following.

D EFINITION 3.2. A DBO-index INDEX is a data structure stor-ing DBO-nodes and providing a method range query search , that, given an object obj and a real number R&gt; 0 , returns a (possibly strict) superset of the nodes in INDEX associated with objects whose distance from obj is not greater than R . 1
Figure 1 shows the algorithm DOLPHIN. The algorithm per-forms only two sequential scans of the dataset.

During the first scan, the DBO-index INDEX is employed to maintain a summary of the portion of dataset already examined. In particular, for each dataset object obj , the nodes already stored in INDEX are exploited in order to attempt to prove that obj is an in-lier. The object obj will be inserted into INDEX only if, according to the schema described in the following, it will be impossible to determine that it is an inlier. Note that, by adopting this strategy, it is guaranteed that INDEX contains at least all the true outliers encountered while scanning the dataset.

After having picked the next object from the dataset, first of all, a range query search with center obj and radius R is performed into INDEX , and, for each DBO-node n index encountered during the search, the distance dst between obj and n index .obj is computed.
More precisely, assume that the method range query search is im-plemented through two functions, i.e. getFirst ( obj , R ), returning the first node of the result set, and getNext ( obj , R ), returning the next node of the result set, so that candidate neighbors are com-puted one at a time.
 Since n index .rad is the radius of a hyper-ball centered in n and containing at least k  X  1 dataset objects other than n if dst  X  R  X  n index .rad then within distance R from obj there are at least k objects and obj is not an outlier. In this case the range query is stopped and the next dataset object is considered.
Thus, this rule is used to early prune inliers. The more densely populated is the region the object lies in, and the higher is the prob-ability of being r ecognized as an inlier through this rule. This can be intuitively explained by noticing that the radius of the hyper-spheres associated to the objects lying in its proximity is inversely proportional to the density of the region. This is the first rule used by the algorithm to recognize inliers. Since other rules will be used to reach the same goal, this one will be called Pruning Rule 1 (PR1 for short).

Otherwise, if dst  X  R then the list nn index .nn ( nn curr resp.) of the nearest neighbors of n index .obj ,( n curr is updated with n.obj ( n index .obj resp.). In particular, updating a n.nn list with a neighbor obj of n.obj , consists in inserting in n.nn the pair ( obj, dst ) ,where dst is the distance between obj and nn.obj . Furthermore, if after this insertion n.nn contains more than k  X  1 object, than the pair ( obj ,dst ) in n.nn having the greatest value for dst must be deleted from n.nn .

After having updated the nearest neighbors lists, if the radius n index .rad becomes less than R ,then n index .obj is recognized as an inlier. These objects are called in the following, for clarity, proved inliers . In this case there are two basic strategies to adopt. According to the first one, the node n index is removed from INDEX since it is no longer a candidate outlier (recall that an ob-ject is inserted into INDEX only if it is not possible to determine that it is an inlier). This strategy has the advantage of releasing space as soon as it is not strictly needed, and maybe of making cheaper the cost of the range query search (when its cost is related to the size of INDEX ), but it may degrade inlier detection capa-bilities since the PR1 becomes ineffective. Indeed, if this strategy is used, the field n.rad of each node n stored into INDEX is al-ways +  X  , otherwise the node n has to be cancelled from INDEX . According to the second strategy, the node n index is maintained into the index since it can help to detect subsequent dataset inliers through the PR1.

Between the above two strategies, there is also a third intermedi-ate one, that is to maintain only a percentage of the proved inliers. In particular, even though the latter strategy makes the PR1 effec-tive, it must be said that it may introduce an high degree of redun-dancy . Being real data clustered, often objects share neighbors with many other dataset objects. Thus, it is better to maintain not all the proved inliers, but only a portion of them, say p inliers cording to this third strategy, if n index .rad is greater than R before updating n index .nn , but becomes less or equal to R after updat-ing n index .nn , then, with probability p inliers , the node n maintained into INDEX , while with probability (1  X  p inliers is removed from INDEX . This pruning rule will be referred to, in the following, as PR2. The effect of the parameter p inliers size of INDEX and on the ability in early recognizing inliers, will be studied in the following.

As for the current dataset object obj ,if n curr .rad becomes less or equal to R , then it is recognized as an inlier. In this case the range query is stopped, the object in not inserted into INDEX (this is the third pruning rule of inliers, PR3, for short, in the following), and the next dataset object is considered.

This completes the description of the first dataset scan. When the first dataset scan finishes, INDEX contains a superset of the dataset outliers. The goal of the second scan is to single out the true outliers among the objects stored in INDEX . Since the proved inliers stored in INDEX at the end of the first scan are no longer useful, they are removed from INDEX before starting the second dataset scan.

During the second scan, for each dataset object obj , a range query search with center obj and radius R is performed into INDEX . This returns at least all the objects n index .obj of INDEX such that obj lies in their neighborhood of radius R . Thus, if dst , the dis-tance between n index .obj and obj ,islessorequalto R , the list of the nearest neighbors of n index .obj can be updated with obj .If n index .rad becomes less or equal to R then n index .obj is a proved inlier and it is removed from INDEX .

At the end of the second dataset scan, INDEX contains all and only the outliers of DS . It can be concluded that, provided INDEX is a DBO-index, DOLPHIN returns all and only the outliers of after two sequential scans of DS .
It immediately follows from the description of the algorithm, that the I/O cost of DOLPHIN corresponds to the cost of sequentially reading two times the input dataset file . This cost is really negligi-ble even for very large datasets.

As for the CPU cost, it is related to the size of INDEX .Nextitis investigated how the size of INDEX behaves during the execution of the algorithm.
Interestingly, it can be provided evidence that, for meaningful combinations of the parameters k and R ,evenintheworstcase setting where objects are not clustered and are never removed from INDEX , the size of any DBO-index INDEX at the end of DOL-PHIN is only a fraction of the overall dataset, and that, during the algorithm execution, the size of INDEX follows at most a logarith-mical growth w.r.t. the dataset size.

Let N be the number of objects of the dataset DS .Say p m the probability that the current object of DS will be inserted into INDEX when it has size m , and assume that p inliers is one, so that no node inserted into INDEX is removed during the first scan.
Let Y m be a random variable representing the number of objects to be scanned to insert a novel object into INDEX when it already contains m objects. Assuming that the neighbors of a generic ob-ject are randomly picked objects of the dataset, i.e. that no relation-ship exist among the neighbors of the dataset objects, the problem is equivalent to a set of independent Bernoulli trials, and Hence, the expected number of objects to be scanned before insert-ing a novel object, when the index has size m is Consequently is the expected number of dataset objects to be scanned in order to insert m nodes into INDEX . It can be concluded that the expected size of INDEX at the end of the first phase is S N =max { m  X  N and s m  X  N } .

Now we are interested in validating the above analysis by study-ing the growth of this function, and in empirically demonstrating that the value S N is a worst case, since the size of INDEX is no-ticeable smaller for p inliers less than one.

For simplicity, assume in the following that each dataset object has approximately x neighbors. Also, assume that the outliers form a small fraction of the dataset, so that their presence can be ignored in the analysis. With this assumption, the probability that an inlier of
DS , but out of INDEX , is inserted into INDEX (recall that it is supposed the neighbors of a generic object are randomly picked objects of the dataset) is which is the proba bility, conditioned to the fact that the current object is an inlier, that among the m objects of INDEX there are less than k  X  1 neighbors of obj ( p 1 = ... = p k  X  2 =1 ,by definition).

Two synthetical datasets and a radius R such that x is almost con-stant for all the objects, were considered. The first dataset, named Circle , is composed by 1 , 000 points equally ranged over a circum-ference of diameter 1 . 0 , plus a single outlier in the center of the circle. For R =0 . 3 each point has x =95 neighbors. The sec-ond dataset, named Clusters , is composed by two well-separated uniform clusters, having 499 points each, plus two outliers. For R =0 . 4 each object has x = 499 neighbors, that are all the ob-jects of the cluster it belongs to.

Figure 2(a) shows, for the Circle dataset, the probability p inserting an inlier into INDEX , computed by using formula (2) with N =1 , 000 , x =95 ,and k =5 (solid line) and k =20 (dashed line). Note that there exists a limit on the index size be-yond which the proba bility of inserting beco mes close to zero. Fig-ures 2(b) and 2(c) show the expected size of INDEX versus the number of dataset objects processed (dashed-pointed line) com-puted by using formula (1). It is clear by these curves that the size of INDEX grows logarithmically in the number of dataset ob-jects. Figures 2(b) and 2(c) also show the actual size of INDEX for varying values of the parameter p inliers ,thatis p inliers (solid line), p inliers =0 . 1 (dashed line), and p inliers line).

Interestingly, if objects inserted in INDEX are never removed ( p inliers =1 ), then the observed final size of INDEX is below the value S N . This behavior can be explained by noting that in real data common neighbors are biased. Moreover, if p inliers is decreased, then the final size of INDEX may be noticeably smaller than the value S N , even a little fraction of the overall dataset. This behavior is confirmed by Figure 2(d), showing the size of INDEX at the end of the first phase of DOLPHIN as a function of p inliers for k =5 (solid line) and k =20 (dashed line).

Even though one may expect that by deleting all the proved in-liers ( p inliers =0 ) the size of INDEX should be smaller (see Figure 2(b) for an example of this behavior), it was observed that, in terms of maximum size of the index, the best value of p either a value close to 0 . 1 or exactly zero, depending on the char-acteristics of the dataset.

Since, for meaningful combinations of the parameters k and R , very often the mean number of objects lying in spheres of radius R is high if compared with k , as we shall see, a value for p slightly greater than zero is optimal in practice in terms of execu-tion time, and, sometimes, also in terms of index size. As an exam-ple, see Figure 2(c). For p inliers =0 ,after INDEX has accumu-lated enough objects to recognize inliers, the algorithm deletes the proved inliers into INDEX and forgets what has already seen. The size of the index becomes thus oscillating. The greater is the value of k , and the greater is the fluctuation of the size. On the contrary, for p inliers =0 . 1 , after having accumulated in INDEX enough objects to recognize inliers, a large portion of proved inliers is re-moved, but, since the algorithm has learned the dense regions of the feature space (this information is stored together with the proved inliers leaved into the index), the PR1 is applied efficiently and the size of the index stabilizes on a small fraction of the dataset. Using a greater value for p inliers has the effect of increasing the size of INDEX , but does not augment the number of objects pruned by the PR1.

This behavior is much more evident on the dataset Clusters .Fig-ures 2(e), 2(f), 2(g), and 2(h) report, on the Clusters dataset, the same kind of experiments above described ( R =0 . 4 , x = 499 ). For p inliers =0 , the fluctuation is now more pronounced as the ob-jects are strongly clustered and the parameter k is relatively high. Note that, for p inliers =0 . 1 the final size of INDEX is a small fraction of the dataset. It can be observed in Figure 2(h) that for p inliers =0 the size of the index is exactly 2 k ,astherearetwo clusters and at least k objects have to be seen in each cluster in order to recognize all the inliers.

Summarizing, in the worst case the growth of INDEX is log-arithmical, but in practice its size does not reach the value S (we measured this value only by simulating a dataset where near-est neighbors are randomly picked objects). Furthermore, as real data is clustered, by properly tuning the parameter p inliers small fraction of the dataset is inserted into the index. As will be confirmed in the following, a value p inliers approximately 0 . 1 is a good trade-off between index size (amount of redundant informa-tion into the index) and execution time (efficient application of the PR1).
DOLPHIN uses as INDEX data structure a pivot-based index [13]. A pivot-based index is a data structure performing proxim-ity search in any metric space. It makes use of a certain number of objects (also called pivots ), usually selected among the objects stored into the index. Distances among pivots and objects stored into the index are precalculated at indexing time. When a range query with center obj and radius R is submitted to the index, the distances between the pivots and the query object obj are com-puted. The precalculated distances are exploited to recognize the index objects lying at distance greater than R from obj . For each index object obj , if there exists a pivot p , such that | dist( obj ,p ) | &gt;R , then, by the triangular inequality, it is known that dist( obj, obj ) &gt;R ,and obj is ignored. Otherwise it is re-turned as candidate neighbor of obj . By using this kind of tech-nique the range query search returns a list of candidates that is a superset of the objects that truly satisfy the query. The perfor-mances of pivot-based indexes are related to the number of pivots employed. In particular the larger is the number of pivots, the more accurate (and then smaller) is the list of candidates returned, but the cost of querying and building the index clearly increases.
Now we want to depict a qualitative analysis of the expected temporal cost of DOLPHIN. The execution time of the first scan of DOLPHIN is given by the sum of the following three terms 2 where N is the number of dataset objects, C query is the mean tem-poral cost of executing a range query search during the first phase, S query is the mean number of candidate neighbors examined per dataset object during the first phase, d is the cost of computing a distance, N ins ( N del , resp.) is the number of insertions (deletions, resp.) into INDEX during the first scan, and C ins ( C del the mean cost of insertion (deletion, resp.) during the first phase.
The cost of the second scan can be expressed with a similar for-mula.

Consider the first term N  X  ( C query + S query  X  d ) of Formula (3). It follows from the discussion of previous section, that we can roughly approximate the maximum size of INDEX to O (log N ) , and, hence, also the term S query is upper bounded by O (log N ) . The cost C query of executing the range query search amounts to computing the distances between a dataset object and all the pivots plus the cost of pruning index objects. Since the number of pivots we used is logarithmic in the size of the index this cost is upper bounded by O ( d log log N + d log N ) . As a whole the term N ( C query + S query  X  d ) can be approximated by O ( dN log N ) .As for the cost of removing an object from a pivot-based index, note that it is constant (practically it consists in flagging as empty the entry of an array), thus the term N del  X  C del of Formula (3) can be
This formula ignores minor costs due to non dominating opera-tions, like updating the list of nearest neighbors and so on. ignored. Finally, as for the insertion an object obj into the index, it requires to compute the distances among obj and all the pivots. However, since insertion is always performed after the range query search, these distances are already available and, then, insertion has virtually no cost.

Summarizing, the temporal cost of the algorithm can be roughly approximated to O ( dN log N ) . Basically, this expression assumes that all the objects in the dataset are compared with all the objects in INDEX and, then, it does not take into account that the range query search returns only a subset of the nodes of INDEX .Furthermore, the above analysis does not take into account that DOLPHIN does not need to find k neighbors since it is able to exploit the triangular inequality (through the PR1) to early prune inliers.

In [7], authors showed that, if the dataset is randomized, then the expected number of objects to be compared with each dataset object in order to find its k nearest neighbors is a constant depend-ing only on the values of k and x . Basing on this property, ORCA performs in near linear CPU time. The above upper bound on the number object comparisons is also applicable to DOLPHIN, since INDEX stores a random sample of inliers together with the true outliers. Nevertheless, DOLPHIN greatly reduces this number by exploiting both range searching and pruning rules. Furthermore, ORCA performs a block nested loop reading of disk pages which may lead to a quadratic I/O cost, while DOLPHIN needs only two sequential readings of the dataset.

This expected behavior will be confirmed by experimental re-sults reported in the following section.
Experiments are organized as follows. First of all, it is analyzed the course of the size of INDEX . Then, it is determined how the parameter p inliers affects the execution time, and a study of the sensitivity to the parameters R and k is accomplished. Next, DOL-PHIN is compared with other outlier detection algorithms, and, fi-nally, experiments on a massive dataset are presented.
 Datasets employed. Datasets employed in the experiments are summarized in the following table and briefly described next. Color Histogram contains image features extracted from a Corel image collection 3 . DARPA 1998 consists in network connection records, from five weeks of training data, of intrusions simulated in a military network environment [14] (also referred to as Weeks in the following). Forest Cover Type contains forest cover type data determined from US Forest Service (USFS) Region 2 Resource In-formation System (RIS) data 4 . Household is released by the US Census Bureau and contains the annual expenditure of American families on electricity, gas, and water, as described in [24]. Land-sat contains normalized feature vectors associated with tiles of a collection of large aerial photos 5 . Server is an extract of the KDD Cup 1999 data, as described in [24]. Finally, Mixed Gauss is a synthetic dataset described in the last part of the section. Course of the index size. According the methodology suggested in [24], in most of the experiments reported in the following, for the parameter k it will be employed a value ranging from the 0 . 02% to the 0 . 1% of the dataset size, while, for the parameter R ,thevalue employed will range in the interval [ R min ,R max ] ,where R ( R max , resp.) is the radius corresponding to exactly one outlier (the 0 . 1% dataset size of outliers, resp.) when k is set to the 0 . 05% .
Now, it is studied the course of the size of INDEX during the execution of DOLPHIN on the two real datasets Household and Landsat . In particular, Figures 3(a) and 3(e) show, for three values of k in the range above mentioned, the number of outliers versus the radius R . These curves provide an idea of the severity of the problem in correspondence of various combinations of the param-eters R and k .
 Figures 3(b), 3(c), 3(d), and 3(f), 3(g), 3(h) show the size of INDEX versus the percentage of objects read from the input dataset. Note that in all cases, as predicted, the growth of the size of INDEX slows down as the percentage of dataset objects seen increases.
On the Household dataset, by using k =1 , 000 and R =2 , 600 (for these parameters there are more than 2 , 000 outliers, see Figure 3(a)), when p inliers =1INDEX contains at most the 2% of the dataset objects, while for p inliers equal to 0 or 0 . 1 the maximum size of INDEX is approximatively the 0 . 5% of the dataset (see Figure 3(d)). For p inliers =0 the size of INDEX is oscillating, while for p inliers =0 . 1 it is more stable, confirming the analysis of the previous section. From these curves it is clear that, on this dataset, in terms of index size, setting p inliers to 0 . 1 is better than to 0 , as the former value avoids fluctuations of the size. For smaller values of k , the maximum size of INDEX sensibly decreases (see Figures 3(b) and 3(c)). For example, when k = 200 the size is always below the 0 . 5% .

As for the Landsat dataset (see Figures 3(f), 3(g), and 3(h)), the maximum size of INDEX is always directly proportional to the value of the parameter p inliers . This behavior will be observed also on other datasets. For R =0 . 451 and k = 275 (see Figure 3(h)), in the worst case, the size of index reaches the 2% , but it is about the 1% for p inliers =0 . 1 , and about the 0 . 5% for p inliers Execution time and effectiveness of pruning rules. Figure 4 shows the execution time 6 of DOLPHIN on the Household and Landsat datasets, together with the number of times the pruning rules PR1, PR2, and PR3 are applied during the first scan of the algorithm. From the top to the bottom, curves displayed are ob-tained by setting p inliers to 0 , 0 . 1 ,and 1 , respectively. Note that p inliers =0 gives the slowest performance, while p inliers gives the fastest one (see Figures 4(a), 4(e), 4(i), for the Household dataset, and 4(c), 4(g), 4(k), for the Landsat dataset).
In order to understand this behavior, it is useful to study how fre-quently the rules used to prune inliers, i.e. PR1, PR2, and PR3, are used (see Figures 4(b), 4(f), 4(j), and 4(d), 4(h), 4(l)). For p inliers =0 , almost all the object are pruned by the PR2, that is almost all the objects read from disk are, firstly, inserted into INDEX , and, subsequently, deleted from INDEX after having seen their k neighbors. On the contrary, by using p inliers almost all the inliers are pruned by the PR1, but also the PR2 and PR3 may be effective, even if the number of objects pruned by the last two rules is more than an order of magnitude smaller. Fi-nally, using a greater value for p inliers , has the effect of increasing the size of INDEX , but without significantly augmenting the num-ber of objects pruned by the PR1. Thus, due to the presence of redundant objects, the range query performs worse, and the total execution time increases. Interestingly, by forgetting most of the information already seen, both the spatial and temporal complexi-ties are improved. The best trade-off between space occupancy and execution time appears to be reached for p inliers  X  0 . 1 , and this value will be used in the subsequent experiments.

Note that when the parameter k is relatively small, p inliers can give performances similar to p inliers =0 . 1 (see, e.g., Figures 4(c) and 4(g) for k =55 ). Thus, in some cases, deleting all proved inliers may provide advantages in terms of space 7 with a moderate loss in terms of execution time. Nevertheless, as k increases, delet-ing all the proved inliers may greatly degrade performances. See, for example, Figures 4(a) and 4(e) for k =1 , 000 .
 Sensitivity to parameters R and k . Figure 5 shows the behav-
We used a Pentium IV Dual Core 3.4GHz based machine with 1 GByte of main memory and the Linux operating system.
Indeed, the number of nodes in INDEX is fewer, and it is not required to store the list n.nn in the nodes n of INDEX . ior of DOLPHIN on the datasets ColorHistogram , DARPA 1998 , Forest Cover Type ,and Server for various values of k and R .
Figures 5(a), 5(e), 5(i), and 5(m) show the number of outliers found. The curves of execution tim e (see Figures 5(b), 5(f), 5(j), and 5(n)) confirm the behavior previously observed on other datasets. The algorithm has good performances even when large values of k and small values of R are employed, and, consequently, a consid-erable number of outliers is found.

The maximum size of INDEX (see Figures 5(c), 5(g), 5(k), and 5(o)) is always a small fraction of the dataset, up to the 1 . 5% or 5% depending on the dataset and the parameters. There is a peak of the 8 . 5% for the Forest Cover Type dataset in correspondence of k = 581 and R = 496 . 8 . This is due to the very large number of outliers detect ed, indeed, about 5 , 000 objects of the dataset are recognized as outliers. Even in this case, if a smaller number of outliers is searched for, e.g. one t housand, then the maximum index size is about the 4% .

As for the pruning rules (see Figures 5(d), 5(h), 5(l), and 5(p)), the PR1 is effective on all the combinations of the parameters. For Forest Cover Type with k = 581 , when the radius R decreases, the PR3 is applied as frequently as the PR1. This indicates that an high fraction of the data lies in relatively sparse regions of the space for that value of R , and explains the very high number of outliers. Comparison with other methods. Figure 6 shows the comparison with the distance-based outlier detection algorithms SNIF, ORCA, and RBRP.

We compared DOLPHIN with SNIF 8 and ORCA 9 through scal-ing analysis. Figures 6(a), 6(b), and 6(c) show the execution time of DOLPHIN, SNIF, and ORCA on the DARPA 1998 , Forest Cover Type ,and Server datasets, respectively. The parameter k was set to the 0 . 02% of the dataset size, while R wasfixedtothevalue R min previously described. The number of centroids employed by SNIF was 1 , 000 while the memory buffer used was the 10% of the dataset size, as suggested by the authors. As for ORCA, we set the cutoff value to R , and the number of outliers to be found to a value greater than the number of distance outliers present in the dataset. All the experiments showed the same behavior, that is DOLPHIN is faster than ORCA of about one order of magnitude, while ORCA is faster than SNIF. In two experiments DOLPHIN is faster than SNIF of about two orders of magnitude, while it the remaining one of about one order of magnitude.

We performed on the DARPA 1998 dataset the same type of ex-periment above described, but using an implementation of DOL-PHIN that uses the naive index . The curve of the execution time of this implementation (called DOLPHIN-naive) is reported in Figure 6(d) together with the curves of DOLPHIN using the pivot-based index (there called DOLPHIN-pivot) and of ORCA. It is clear that DOLPHIN gains in efficiency by exploiting indexing techniques, though, even if it is not used, it always maintains great perfor-mances and performs noticeably better than ORCA. This can be explained since the I/O cost of DOLPHIN is lower than that of ORCA, and since, even if DOLPHIN uses the naive index, it is still able to apply the pruning rules (specifically, the PR1)
We compared DOLPHIN also with RBRP, even if it must be re-called that RBRP indexes all the dataset into the main memory .We considered the experimental results described in [16] on the Col-orHistogram and Forest Cover Type datasets 10 . Figures 6(e) and
We used a machine similar to that there employed in order to com-6(f) show the execution time of DOLPHIN, RBRP, and ORCA, for various values of k when the number n of outliers to mine is 30 . In order to run DOLPHIN, we computed the radiuses R corre-sponding to various combination of the parameters k  X  [2 , 30] and n =30 , and measured its execution time. The curves show that, on this type of experiment, DOLPHIN outperformed RBRP of at least one order of magnitude.
 Experiments on massive datasets. We considered the Mixed Gauss dataset, composed by 18 , 000 , 000 objects consisting in points of R 30 . The dataset is composed of 10 gaussian clusters, having dif-ferent sizes, whose centers are randomly generated in the square [  X  25 , +25] 30 , and whose variances are randomly chosen in the range [0 . 5 , 2] ,plus 1 , 000 randomly generated points in the square [  X  30 , +30] 30 . The dataset occupies more than 2 GBytes of sec-ondary memory and cannot be entirely stored in the main memory of the machine.

We fixed the parameter R to 25 . 0 , 11 and gradually increased the pare execution times.
This value amounts to about the 7% of the maximum estimated distance separating two points in the dataset. value of the parameter k . Table 1 shows the results of these experi-ment. Interestingly, the memory usage was very limited due to the small number of objects that are to be stored in INDEX . The num-ber of outliers found is significative, confirming that the parameters used are meaningful.
In this work it is shown that distance-based outlier detection is possible on very large disk resident datasets with both near linear CPU and I/O cost and simultaneously gaining efficiency by exploit-ing database indexing technology. The algorithm DOLPHIN, here described, outperforms existing methods by at least one order of magnitude.
