 Spatial datasets, containing geo-referenced data, are growing at a very high speed. Detecting changes in spatial datasets is important for many fields such as early warn-ing systems that monitor environmental conditions or sudden disease outbreaks, epi-demiology, crime monitoring, and automatic surveillance. 
To address this need, this paper introduces a novel methodology and an algorithm that discover patterns of change in spatial datasets. We are interested in finding what patterns emerged between two datasets, O old and O new , sampled at different time frames. Change analysis centers on identifying changes concerning interesting regions spectives is introduced. The approach employs supervised density functions [6] that are considered interesting by this approach. Interesting regions are identified using contouring techniques. 
The contributions of this paper include: 1. A novel clustering algorithm called DCONTOUR is introduced. To the best of 2. A framework for change analysis in spatial dataset is presented that compares in-2.1 Supervised Density Estimation (x, y) is the location of object o and z X  X enoted as z(o) is the value of the variable of interest of object o. In the following, we will introduce supervised density estimation techniques. Density estimation is called supervised because in addition to the density based on the locations of objects, we take the variable of interest z(o) into considera-tion when measuring density. The density estimation techniques employ influence v  X  density estimation, our approach employs weighted influence functions to measure the density in datasets O: the influence of o on v is weighted by z(o) and measured as a product of z(o) and a Gaussian kernel function. In particular, the influence of object o  X  O on a point v  X  F is defined as: 
If  X  o  X  O z(o)=1 holds, the above influence function becomes a Gaussian kernel function, commonly used for density estimation and by the density-based clustering algorithm DENCLUE [5]. The parameter  X  determines how quickly the influence of o on v decreases as the distance between o and v increases. The overall influence of all (v), which is defined as follows:
In summary, supervised density estimation does not only consider the frequency with which spatial events occur but also takes the value of the variable of interest into consideration X  X n general, density incr eases as frequency and z(o) increase. 2.2 Change Analysis through Contour Clustering We have developed a contour clustering algorithm named DCONTOUR that com-bines contouring algorithms and density estimation techniques. Fig. 1 gives the pseudo-code of the algorithm.
 each grid intersection point. Step 2 will call the density function O( D ) times where D is the number of grid cells. In general, objects that are far away from a point contribute very little to the density of the point. Therefore, in order to speed up step 2, we implemented an  X  X pproximate X  density function that only considers the influence of objects belonging to neighboring grid cells rather than all the objects in the dataset. Step 3 computes contour intersection points on grid edges. Since the density function is defined in the whole space and is nonlinear, binary search on cell-edges is used in intersection points for d =4.5 are constructed. As far as the right edge of the lower left exists on this edge; interpolating between 4.1 and 5.5, a point on this edge is sampled and its density is computed which turns out to be 4.8. Because 4.8 is larger than d , we continue the binary search by sampling a point south of this point. The binary search threshold  X . Finally, in step 4, we connect contour intersection points b found on cell edges and continue this process on its neighboring cells until a closed polygon is formed or both ends of the polyline reach the grid boundary. Step 4 uses an algorithm that was proposed by Snyder [3] to compute contours from intersection points.
Traditional contouring algorithms operate on datasets of the form ((x,y),u) where u is a measurement of an attribute of interest at the location (x,y), and use interpolation to infer values of u in locations that are not sampled. DCONTOUR, on the other hand, creates contour polygons for a given density intensity using supervised density maps as its input. A contour polygon acts as a boundary of interesting regions that are above (or below) a specific density threshold; objects surrounded by each individual poly-gon are defined as a cluster.
 In the next two sections, a change analysis approach is introduced that applies DCONTOUR to O old and O new , and analyzes change with respect to the obtained con-tour polygons. This section introduces basic predicates that capture different relationships for change analysis. Given two clusterings X and X X  for O new and O old , respectively, relationships between the regions that belong to X and X X  can be analyzed. Let r be a region in X and r X  be a region in X X . In this case, agreement between r and r X  can be computed as follows:  X  Agreement(r,r X )= |r  X  r X  X /|r  X  r X  X  
In general, the most similar region r X  in X X  with respect to r in X is the region r X  for which Agreement(r,r X ) has the highest value. In addition to agreement, we also define predicates novelty, relative-novelty, disappearance and relative-disappearance below. that have been obtained for time t+1.  X  Novelty (r X ) = (r X  X (r  X  Relative-Novelty(r X ) = |r X  X (r  X  Disappearance(r) = (r X (r X   X  Relative-Disappearance(r) = |r X (r X 
Novelty measure captures regions that have not been interesting in the past. On the other hand, disappearance is used to discov er regions where those characteristics are disappearing. Relative-novelty and relative-disappearance measure percentages of novelty and disappearance. We claim that the above and similar measurements are we introduced so far can be used as building blocks to define more complex predicates.
 they can be used to analyze changes between the old and new data based on different types of clustering. The change analysis approach that we introduced in sections 2 and 3 uses polygons as cluster models. Consequently, in our particular approach the op-computes the size (area) of a polygon r. For example, agreement between two poly-gons r and r X  is computed as the ratio of the size of the intersection between r and r X  over the size the union of r and r X . We demonstrate our methods on an earthquake dataset which is available on http://earthquake.usgs.gov/. Information recorded includes the location (longitude, latitude), the time, the severity (Richter magnitude) and the depth (kilometers) of earthquakes. We uniformly sampled earthquakes dated from January 1986 to Novem-ber 1991 as dataset O old and earthquakes between December 1991 and January 1996 as dataset O new . Each dataset contains 4132 earthquakes. 
In this section, we discuss a case study that analyzes changes in strong positive or negative correlations between the depth of the earthquake and the severity of the earthquake. Accordingly, the variable of interest, z(o) is defined as follows: and  X  severity and  X  depth are the standard deviation of the earthquake severity and depth, that the constructed density function now contains hotspots (areas high positive den-sity) and cool spots (areas of high negative density), which identify regions of positive and negative correlation, respectively. Fig. 3.a shows the results of running DCON-TOUR once with a negative density threshold and once with a positive threshold. For a better viewing of the figures, see http://www.cs.uh.edu/~ceick/kdd/CRET08.pdf. 
In Fig. 3.b shows the intersection regions of the two datasets (filled by orange are positive-correlated areas and filled by green are negative-correlated areas). Using the agreement predicate, we compute that red polygon #0 in O old has overlap with red respect to to dataset O old . For example, we only observe small changes between the red polygon #1 in O old and O new ; the additional scope of the O new polygon is the un-novel polygons are listed in Table 1. We can see that red polygon #4, blue polygon these regions are new regions that only exist in dataset O new . This can be verified by serve novel negative correlation regions of significant size (62.66 and 54.74, repeti-tively) in South America (blue polygon #1) and New Zealand (blue polygon #2). In summary, as we have shown in this demonstration, the relationships between two datasets can be analyzed quantitatively with the help of change predicates that oper-ate on polygons.
 Our change analysis approach relies on clustering analysis. In 2006, a framework for space was proposed by Fleder et al. [6]. A framework for tracking external and inter-nal cluster transitions in a data stream wa s introduced by Spiliopoulou et al [7] in the same year. In 2007, a technique for mining evolutionary behavior of interaction graphs was proposed by Asur et al. [1]. In general, these methods [1, 4, 7] can detect known or objects must be characterized by nominal attributes. The advantage of our approaches is that we can detect various types of changes in data with continuous attributes and unknown object identity. 
Existing contour plotting algorithms can be seen as variations of two basic ap-proaches: level curve tracing [8] and recursive subdivision [2]. Level curve tracing algorithms scan a grid and mark grid-cell boundaries that are passed by the level curve. Contour polygons are created by connecting the marked edges. Recursive sub-division algorithms start with a coarse initial grid and recursively divide grid cells that are passed by the level curve. DCONTOUR, uses level curve tracing. Developing techniques for discovering change in spatial datasets is important and providing methods to detect change for cont inuous attributes and for objects that are not identified apriori are advantages of the techniques we describe here. In this paper, based on a set of predicates are proposed. A novel contour clustering algorithm named DCONTOUR that combines supervised density functions with contouring algorithms is introduced to automate this task. 
In general, our work is a first step towards analyzing complex change patterns. The novel contributions of this paper includes: 1) using density functions in contouring algorithm; 2) change analysis is conducted by interestingness comparison; 3) degrees of change are computed relying on polygon operations; 4) a novel change analysis approach is introduced that compares clusters that are derived from supervised density functions.

