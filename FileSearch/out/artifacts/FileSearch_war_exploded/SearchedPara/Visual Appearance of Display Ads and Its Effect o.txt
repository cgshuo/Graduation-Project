 One of the most important categories of online advertising i s dis-play advertising which provides publishers with significant rev -enue. Similar to other categories, the main goal in display a d-vertising is to maximize user response rate for advertising cam-paigns, such as click through rates (CTR) or conversion rate s. Pre-vious studies have tried to optimize these parameters using objec-tives such as behavioral targeting. However, there is no pub lished work so far to address the effect of the visual appearance of a ds (creatives) on user response rate via a systematic data-dri ven ap-proach. In this paper, we quantitatively study the relation ship be-tween the visual appearance and performance of creatives us ing large scale data in the world X  X  largest display ads exchange sys-tem, RightMedia. We designed a set of 43 visual features, some of which are novel and others are inspired by related work. We extracted these features from real creatives served on Righ tMedia. We also designed and conducted a series of experiments to eva luate the effectiveness of visual features for CTR prediction, ra nking and performance classification. Based on the evaluation result s, we se-lected a subset of features that have the highest impact on CT R. We believe that the findings presented in this paper will be very useful for the online advertising industry in designing high-perf ormance creatives. It also provides the research community with the first ever data set, initial insights into visual appearance X  X  ef fect on user response propensity, and evaluation benchmarks for furthe r study. I.4.7 [ Computing Methodologies ]: Image Processing and Com-puter Vision X  Feature Measurements Online Advertising, Visual Features, Creative Recommenda tion  X  This work was done while the first author was an Intern at Yahoo ! Labs.  X  This work was done while she was working at Yahoo! Labs.
The Internet revolution has transformed how people experie nce information, media and advertising. Web advertising, alth ough nonexisting twenty years ago, has become a vital component o f the modern Internet, where advertisements are delivered fr om ad-vertisers to users through different online channels. Rece nt trends have shown that an increasingly large share of advertisers X  bud-gets are devoted to the online world, and online advertising spend-ing has greatly outpaced some of the traditional advertisin g me-dia, such as radio and magazine. Display advertising is one t ype of online advertising which, together with search advertis ing, con-tributes the majority of the revenue for many large Internet com-panies. In display advertising, display ad instances are sh own to the user on webpages in different formats such as image, flash , and video. Each display ad instance is called a creative. By show ing the creatives, advertisers aim to either promote brand awarene ss among users (brand advertising) or receive desirable responses f rom users (performance advertising), such as the action of purchasin g, click-ing or signing up for a promotion list from the advertiser X  X  w ebsite. In performance advertising, the advertiser strives to opti mize their ad X  X  performance metrics such as the effective cost per clic k (eCPC) or effective cost per action (eCPA), which in turn relates to maxi-mizing the user response rate on the creatives as measured by click through rates (CTR) or conversion rates (CVR). There are sev eral factors that greatly influence the user response rate of disp lay ad-vertising campaigns: 1) the position of the ads on the webpag e; 2) the relevancy of the ads to the online users, which is general ly cap-tured by the targeting profiles of the advertising campaigns ; 3) the relevancy of the ads to the webpage content and 4) the quality and visual appearance of the creatives.

The problem of predicting the user response rate for online a ds, especially CTR, has been studied by several researchers in t he last few years. One major research focus has been in predicting cl icks by studying the relationship between CTR and the aforementi oned ad factors (and their combinations). For example in [2], the authors considered the ad X  X  relevancy to the content of the webpage i n pre-dicting CTR. They show that improving the ad X  X  content relev ancy is more efficient than considering the content of ads by thems elves [26]. Although it is generally believed that visually appea ling ads can perform better in attracting online users, as a result of which advertisers always care about the creative designs, there i s no, to the best of our knowledge, published work so far to quantitat ively study the effect of visual appearance of creatives on campai gn per-formance in online display advertising. This motivates us t o inves-tigate the correlation between the visual features of the cr eative and CTR, regardless of other ad factors, and to predict creative perfor-mance based on its visual appearance alone.

Our proposed approach consists of two main steps, 1) feature extraction and 2) correlation investigation. We first extra ct some informative visual features from the creatives. We introdu ce 43 visual features classified into three categories, 1) global features which characterize the overall properties of a given creati ve, 2) lo-cal features representing the properties of specific parts within a given creative and 3) advanced features which are a group of fea-tures developed based on more complicated algorithms such a s the number of faces and number of characters in a creative. We the n develop three regression approaches to predict the CTR base d on these features. The study is conducted using real creatives and their performance data from the world X  X  largest display ads excha nge system, RightMedia. Based on the weights of developed featu res, we further select a subset of features that have high impact o n the creative X  X  CTR. The benefit of this work is three-fold. First , our findings on the visual features and their relationship to CTR can provide useful recommendations to designers on what featur es to consider while designing creatives, and/or can help in auto mated creative generation. Second, the visual features and the re gression methods developed here can be used in addition to the traditi onally investigated ad factors (such as ad relevancy, position etc .) for im-proving CTR prediction in online ads selection. Third, it pr ovides the research community with the first ever data set, initial i nsights into the effect of visual appearance on user response propen sity, and evaluation benchmarks for further study.

The paper is organized as follows. Section 2 introduces the r e-lated work. We introduce the visual features in Section 3. Th e regression and feature selection results for CTR predictio n are pre-sented in Section 4, followed by our conclusion in Section 5.
The relationship between various print ad characteristics and mea-sures of advertising effectiveness has been studied by adve rtising researchers for almost a century. A wide variety of characte ristics have been investigated. These characteristics are roughly in two categories: mechanical and content-based. The mechanical char-acteristics include ad size, number of colors, proportiona l of illus-trations to copy, the absence of borders, and type size. The c ontent factors include message appeal like status, quality, fear a nd fantasy, attention-getting techniques like free offers, presence o f women, and psycholinguistic variables like product or personal re ference in headline, interrogative or imperative headline, visual rhetorics, among others. See [21] for summaries.

Even though the online advertising has taken a large market s hare of the advertising industry, and the whole industry is stead ily and continuously shifting to the online domain, study on the eff ective-ness of the counterpart of print ads online, generally calle d display ads, is limited. We list the studies of several factors below .
Some existing studies try to investigate the effect of sever al dif-ferent factors on the performance of display advertising ca mpaigns. These factors include targeting and obtrusiveness [9], adv ertise-ment size (large vs. small) and ad exposure format (intrusiv e vs. voluntary) [4], cognitive impact from ad size and animation [19], emotional appeal and incentive offering in the ads [8], repe tition of varied execution vs. single execution [31].

To the best of our knowledge, we are not aware of any study on the relationship between the visual appearance and the perf ormance of creatives in online display ads. We try to tackle this prob lem by first defining a set of visual features and then evaluating the ir effects on ad performance, specifically CTR in our experiments, from the actively served ad campaigns on the world X  X  largest ad excha nge system, RightMedia. Below, we present some previous comput a-tional studies on image properties which provide us inspira tion in designing our visual features.

There are several studies that try to investigate a specific p roperty of images (photos or paintings) using computational approa ches. Such properties include quality and aesthetic in photos [20 , 16, 30, 7] or in paintings [18], saliency [15], composition [10, 25] , color harmony [5] and memorability [13].

Initial work on image quality evaluation concentrated on ev alu-ating and reconstructing low graded, compressed or degrade d im-ages by simple noise model [6, 1]. However, in most of the beau ty evaluation work, including this paper, we assume that high q uality images are available and we are interested in evaluating the visual aesthetic of images based on visual features.

Recently some researchers tried to evaluate the beauty of an im-age based on its visual features. In [16] the authors aim to cl assify the pictures into professional and snapshot photos using so me basic features including spatial distribution of edges, color di stribution and hue count, etc. In [7] the authors introduced a regressio n based approach for rating photos based on their beauty, using feat ures such as average pixel density, colorfulness, saturation hu e, and the rule of thirds. In addition to these studies, in [20] the auth or pro-posed an approach to classifying images into high and low qua lity. The main idea comes from the fact that a professional photogr a-pher makes the background blurry and the subject distinguis hable in the image. By separating the blurry part of the image from t he subject, they design a set of well-motivated features from b oth the subject and the whole image such as the clarity contrast of th e sub-ject, lighting, simplicity, color harmony and composition geome-try. They show that the combination of these features can pro vide a promising performance. All of the above work tries to extra ct visual features from photos. Recently Li et al. [18] tried to extract some features from paintings to evaluate their beauty and cl assify them into high and low quality. They introduced a set of globa l and local features, 40 in total, to capture the painting properties such as the brightness contrast between segments, the brightness c ontrast across the whole image and the average saturation for the lar gest segment of the image.

Computational approaches have also been used to investigat e other visual properties of an image. In [13] the authors stud ied what properties of images make them more memorable. They found th at statistical properties of an image such as mean hue, mean sat u-ration, intensity mean, intensity variance, intensity ske wness and number of objects do not have any non-trivial correlation wi th mem-orability in their generated data set. However, they found t hat if they label the objects and scenes in the images, they can find a non-trivial and interesting correlation between images and the ir memo-rability. For example, their results show that the attendan ce of hu-man being, close up objects and human scale objects in an imag e improve its memorability more than natural scene. This resu lt is not possible to be applied to our work since it requires large amo unts of supervision to tag different parts of the images. However , we evaluate the impact of the number of human faces in an image in our work.

Color harmonization is another approach for making an image more appealing. In [5] the authors proposed to harmonize the col-ors in a given image using harmonization templates from [32, 29], which include 8 different harmonized color templates. We also used color harmony models to evaluate the hue distribution o f an image in our experiments.

In summary, existing work in related areas has focused prima r-ily on properties of an image, photo or painting. In contrast , we examine creatives in online display ads, which contain both graph-ical features and text. In addition, some of the existing app roaches require significant amount of supervision in their feature e xtrac-tion step, which is not possible in large scale applications where we need to learn from large data sets with minimum amount of supervision. Finally, we would also like to extract a set of f eatures that are visually understandable and can be practically con trolled to guide the human designers or automatic creative generators (like in smart ads) to produce high-performance creatives. These ob jectives make our problem novel and interesting for the online advert ising industry. In this section we introduce a set of 43 different visual features. We categorize the developed features into three different s ets, 1) global features, 2) local features and 3) advanced features . A com-plete list of the features can be found in Table 3. Below we des cribe the detailed definition of the proposed features in each cate gory.
In the following sections we use I to indicate an image and use | I | to indicate the size of the image measured by the number of pixels. We use variable x to denote an arbitrary pixel when we do not care about its location in the image. Otherwise we use ( i, j ) to denote the pixel in the i -th row and j -th column in the image.
Global features are a set of features which represent the ove r-all properties of the whole image. We describe the details of 19 different global features in this section.
We describe 3 features extracted from the gray level histogr am of the image, namely the gray level contrast f 1 , number of domi-nant gray level bins f 2 , and the standard deviation of the gray level values among all pixels f 3 .

The gray level contrast is the width of the middle 95% mass in the gray level histogram [16]. From the original gray level h is-togram, we prune the extreme 2 . 5% from the 0 side and 2 . 5% from the 255 side. Gray level contrast feature f 1 is calculated as the width of the remaining histogram.

We count the number of dominant bins in the gray level his-togram as our second feature. Suppose the set G = { g 0 , g indicates the set of 256 bins in the gray level histogram such that g is the number of pixel in i -th bins. We define the number of dom-inant gray level bins as f 2 = P 255 k =0 1 ( g k  X  c 1 max 1 (  X  ) is the indicator function and c 1 is a threshold value which is set to be 0 . 01 in this paper. 1
The last gray level feature, f 3 , is defined as the standard devi-ation of gray level values of all pixels in the image. It is use d to capture the variance of the gray level distribution.
To avoid distraction from objects in the background, profes sional photographers tend to keep the background simple. In [20], t he authors use the color distribution of the background to meas ure this simplicity. We use a similar approach to measure the sim -plicity of color distribution in the image. For a given image , we quantize each RGB channel into 8 values, creating a histogram H rgb = { h 0 , h 1 ,  X   X   X  , h 511 } of 512 bins, where h i number of pixels in i -th bin. We define feature f 4 to indicate the number of dominant colors as f 4 = P 512 k =0 1 ( h k  X  c
This parameter, and similar ones in the rest of the paper, is s et inspired by related works such as [20].
 where c 2 = 0 . 01 is the threshold parameter. We also calculate the size of the dominant bin relative to the image size as f 5 This feature indicates the extent to which one of 512 colors is dom-inant in the image.
 By replacing the RGB color map with HSV (Hue, Saturation, Value) color map and using the above methods in calculating f ea-tures f 4 and f 5 , we obtain two other features f 6 and f
The concept of color harmony in this paper is based on 8 dif-ferent harmonic color distributions (illustrated in Figur e 1) that are based on the hue of the HSV color wheel [14, 32]. These distri-butions are called i, V, L, I, T, Y, X, N . Note that each distribution can be rotated by 0  X   X   X  360 degrees. The specific size of color harmony distributions are set as follows: the large sectors of types V, Y and X are 26% of the disk ( 93 . 6  X  ); the small sectors of types i, L, I and Y are 5% of the disk ( 18  X  ); the largest sector of type L is 22% of the disk ( 79 . 2% ); the sector of type T is 50% of the disk ( 180  X  ). The angle between the centers of the two sectors is 180 for I , X , Y , and 90  X  for L .

Let us define the set of 8 distributions as D = { d 1 , d We say  X  ( d i  X  , x ) indicates the hue of the closest point in the i -th distribution to x after  X  degree rotation, where x is any arbitrary pixel in the image. We compute the distance between the hue di s-tribution of our image I and the distribution d i  X  D as:  X  ( I, d i ) = arg min where hue ( x ) and sat ( x ) indicate the hue and saturation at pixel x , and k  X  k denotes the arc-length distance. We are interested in the best fitting model d  X  which has the least  X  (  X  ) value, d arg min d i  X  ( I, d i ) . We define feature f 8 =  X  ( I, d it tells us how different is the hue distribution of image I from the best fitting model of color harmony.

Some models are superset of other models in Figure 1 conclud-ing that the  X  (  X  ) value of some smaller models are higher than some larger models given any image I , e.g.  X  ( I, d i )  X   X  ( I, d  X  ( I, d T ) . Therefore, if an image hue distribution fits into some small models, type i, V, L, I , it fits into larger models as well. This can emphasize the color harmony property of the images which can fit into a few models rather than just one model. We consider th is property as one potential positive property of the image. To quan-tify this property, we introduce a new feature, f 9 , which indicates the average color harmony deviation from the best two fitted m od-els given an image I . In general, in addition to the deviation from the best fitted model illustrated by feature f 8 , we consider the de-viation from the second best fitted model as well, and the aver age of these two deviations is returned as f 9 . Clearly, for the images fitting into small color harmony models, we will have f 8 very close to each other. However, for the images which fit int o the largest model, we will have f 9 considerably larger than f lieve these two numerical features can represent the color h armony property of an image appropriately.
We extract a set of features based on the color coherence of pi x-els resulting in connected coherent components [24]. A conn ected coherent component in an image is defined as:
We denote the set of connected coherent components and their color index as P = { ( P 1 , h 1 ) , ( P 2 , h 2 ) ,  X   X   X  ( P the set of pixels in the i -th component, and h i is its corresponding color in the HSV color histogram with 512 bins. We use | P denote the number of pixels in P i . We extract the following features based on the above definition: In this section we introduce three features based on the hue i n HSV color space. We quantize hues in an image in a similar way as in [18] by eliminating the pixels with saturation and valu e less than 0 . 2 . This will eliminate all the pixels with white or black colors. Then we calculate the hue histogram of remaining pix els with 20 different bins, 18  X  for each bin, which results in H { h 1 , h 2 ,  X   X   X  , h 20 } where h i indicates the set of pixels in i -th bin. We then extract the following features:
We use the lightness L in the HSL color space to calculate fea-ture f 18 and f 19 . In the HSL color space, L value is small when the color is white and is large when the color is black. The L value in HSL color space can be calculated as follows: where r ( x ) , g ( x ) , b ( x ) denotes the R, G, B values of pixel x in RGB color space. We calculate two lightness features as:
Local features represent a set of features extracted from sp ecific parts of the image rather than the whole image. We apply the no r-malized cut segmentation method [27] to partition the image into 5 smaller segments. Let S = { S 1 , S 2 ,  X   X   X  , S 5 } indicate the set of 5 different segments where S i is the set of pixels in segment i . Note that a segment is considered as noise and is dropped if it is sm aller than 5% of the image. We develop the following features based on the segmentation result.
Two features are extracted from segment size as follows:
Similar to section 3.1.5, we generate the hue histogram of ea ch segment. We define the set of hue histograms of all 5 segments as H cates the set of pixels that fall in the j -th bin of i -th segment. Then we extract five features to capture different hue properties . Below we describe the formal definition of developed features:
Two features are extracted based on the largest segment colo r harmony. Feature f 28 is the minimum deviation from the best fitted color harmony model for the largest segment, and feature f average deviation of the best two fitted color harmony models for the largest segment. The details of color harmony models hav e been introduced in section 3.1.3.
Three segment lightness features are extracted using simil ar method as in section 3.1.6:
In this section we develop a set of features based on more com-plicated algorithms. Most of the advanced features are base d on the saliency map of the image which determines the visually sali ent ar-eas in the image that are more likely to be noticed by the human s. We also extract two additional features related to the numbe r of characters and number of faces in an image. Below we describe the details of these features.
Saliency computation is a well known phenomenon in human vision where attention tends to be drawn to interesting part s of an image that appear visually different from the rest of the ima ge (e.g., a red coke can in a green background appears salient and is imm edi-ately noticed, while the same coke can in an orange-reddish b ack-ground is not salient and less likely to be noticed). We compu te saliency according to the algorithm described in [12]. Figu re 2 shows the saliency output of the algorithm presented in [12] for a Figure 2: The saliency map of an image. Left: original image. Right: saliency map. sample creative. The areas with higher lightness in the sali ency map indicate more salient part of the image.

The saliency algorithm returns a matrix  X  (also referred to as saliency map) where  X  ( i, j ) represents the saliency value of pixel ( i, j ) . We also extract a binary image based on the saliency map, by setting a threshold  X  to the saliency map where the pixels with saliency value larger than  X  are set to 1 and the rest of the pixels are set to 0 . Similar to [12], the parameter  X  is set as  X  = 3  X   X  where  X   X  = 1 /n P i,j  X  ( i, j ) is the average saliency value in the image. After this binarization, we have some connected components with value 1. These components indicate saliency areas, and the o ther parts of the image are considered as background. Then we extr act the following features based on the saliency results, salie ncy map and binary saliency map.
Figure 3: The four interested points based on rule of third.
We consider the number of characters in an image as feature f We tried a number of OCR toolbox and one of them provides us with appropriate results considering the number of charact ers in ads[23]. Note that we are interested in the number of charact ers in the image regardless of its meaning. To evaluate the accurac y of the OCR toolbox, we counted the true number of characters in 100 random images and compared it to the returned number of chara c-ters from the OCR toolbox. We found strong linear correlatio n of 0 . 80 , suggesting that our toolbox is reasonably accurate in eval u-ating the number of characters in images. Note that extracti ng the exact text from ad creatives is challenging as they often app ear in different fonts, sizes and orientations.
The last feature, f 43 , captures the effect of the human face ap-pearance on creative performance. In [13] the authors concl uded that the human appearance in an image could make the image mor e memorable. This motivates us to test whether face appearanc e af-fects creative performance. We count the number of faces in a n image using an available toolbox [17]. Our toolbox is reason ably accurate and has a correlation more than 0 . 9 with the true number of faces in images in our experiments with a sample size of 100 .
In this section we present the algorithms and experiments we designed to evaluate the relationship between visual featu res and the performance of creatives in online display advertising .
We extracted creatives of advertising campaigns from the wo rld X  X  largest online advertising exchange system, RightMedia. W e fil-tered out animated creatives because our features are desig ned for static images. We also calculated the average CTR of these cr e-atives from online serving history log during a two-month pe riod.
As discussed in Section 1, the performance of creatives is de -termined by many factors. One important factor is the ad posi tion in the webpage. Generally the available position of a creati ve on a webpage is determined by the creative X  X  size. To remove the im-pact on performance introduced by ad position (and size), we create two different data sets, each of which consists of creatives with the same size. The first data set, ID 2 , consists of 6272 creatives with size 250  X  300 pixels, and the second data set, ID 6 , includes 3888 images with 90  X  730 pixels. All of the creatives have a minimum of 100 K impressions guaranteeing that their CTRs have converged to their true values. We believe this large number of impress ion (minimum of 100 K ) can also guarantee that the calculated CTRs are not biased toward other effective factors such as user be havior or webpage content. The CTR distribution of each data set is s hown in Figure 4.

To evaluate the effect of proposed features in each creative cat-egory, We further created two sub-categories from data set I D 2 :  X  X ating X  with 927 images and  X  X raveling X  with 599 images. Since there are not many images in these two categories, we conside r the images with a minimum of 20 k and 10 k impressions for  X  X ating X  and  X  X raveling X  respectively.
The main goal of this work is to study the relationship betwee n the performance of creatives and their visual features. In t he first step we try to predict CTR from visual features using regress ion methods. We used three different regression algorithms to p re-dict CTR, 1) Linear Regression (LR), 2) Support Vector Regre ssion with RBF kernel(SVR), and 3) Constrained Lasso (C-Lasso) wh ich is a modification to Lasso [28].

We used LIBSVM [3] to implement the SVR and performed cross validation to determine the parameters of the model. W e describe our constrained Lasso optimization approach as fo llows. Suppose we have a set of n creatives at disposal and the visual fea-tures of these creatives are represented as a matrix A  X  R that A = ( a 1 , a 2 ,  X   X   X  , a n ) where a k  X  R d is a column vector representing the d dimensional visual features of creative k . In our experiment d = 43 . The CTR values of the n creatives are repre-sented as a vector y = ( y 1 ,  X   X   X  , y n )  X   X  R n where each y CTR of the k -th creative. We bound the CTR of each creative by y min  X  y i  X  y max where y min and y max can be obtained from online serving history log. To predict CTR of the creatives, we try to solve the following optimization problem: where k  X  k 2 F is Frobinius-2 norm and k  X  k 1 is  X  1 norm, also called lasso. We call the above optimization problem as constraine d Lasso (C-Lasso) and we used [11] to find the solution of this optimiz ation problem. Note that the proposed C-Lasso approach performs b etter than Lasso in our application.
In this section we present different evaluation methods to a na-lyze the efficacy of the developed visual features in predict ing the performance of creatives.
To evaluate the CTR prediction accuracy of the algorithms, w e run each algorithm for 200 independent runs where in each run 80% of each data set is selected randomly for training and 20% for testing. The accuracy evaluation results are reported o ver the prediction of the test data. Mean Squared Error (MSE) is used to measure the prediction accuracy for each algorithm as follo ws: where n is the number of test samples, y k is the true CTR of the k -th creative calculated from history log, and  X  y k is the predicted CTR. To meaningfully interpret the MSE value, we introduce t wo baseline approaches, Random and Constant Mean (CM) policy. Table 1: The prediction accuracy of each method against Ran-dom policy.

The Random policy simply samples from the CTR distribution of the training data to predict the CTR of each testing creative , while the CM policy assigns a constant value, c m , to all ads where c is the mean CTR of the training data. Table 1 shows the average results over 200 independent runs for each algorithm. Each entry is the MSE value of the random policy divided by MSE value of each algorithm with its variance via different runs. Results sho w that we can perform up to 3 . 27 times better than Random policy with small variance in predicting the CTR from visual features on ly. All learners perform consistently better than baseline CM as we ll. This result demonstrates the non-trivial impact of visual appea rance of the creative on its advertising performance.
We introduce a ranking criterion to investigate the ability of us-ing visual features to rank the creatives by their CTRs. Give n a test set of creatives, suppose c  X  1 , c  X  2 ,  X   X   X  , c  X  ages with the lowest CTR values and c + 1 , c + 2 ,  X   X   X  , c the k images with the highest CTR. Therefore we have k 2 pairs ( c i , c wish to know whether our prediction of CTR using visual fea-tures preserves the ranking of pairs ( c  X  i , c + j ) . To test this, we change the value of k as a function of test data size. We then mea-sure the percentage of match between the predicted ranking o f cre-atives, and the truly observed ranking in the test data. The r esults over 200 independent runs are shown in figure 5 for different data sets. The x  X  axis indicates the value of  X  such that k =  X n for in the data set, and y  X  axis represents the percentage of correctly ranked pairs.
 Results show that SVR consistently outperforms other learn ers. As we increase the size of k , the percentage of correctly ranked pre-dictions decreases for all learning algorithms. This is as e xpected, since differentiating the images of creatives which have CT Rs close to the mean of the CTR distribution, using visual features on ly, is very difficult even for a human. Interestingly, the results s how that by just using visual features, we can preserve more than 90% of the ranking for data set ID 2 (for  X  = 0 . 1 ). This number remains high at 75% when we consider all top-half images against low-half im-ages for all data sets (  X  = 0 . 5 ). This is an encouraging result that demonstrates the utility of visual features in predicting t he ranking of CTR.
Previous studies in beauty evaluation [7, 16, 18] mostly try to classify the images into high and low quality category rathe r than assigning scores to their beauty based on visual features. S imilarly, we evaluate the performance of classifying the creatives in to high ( +1 ) and low ( -1 ) CTR category using visual features only. We use support vector machine with RBF kernel as our classifier. Sim ilar to the previous section, we randomly separate 80% of data as train-ing and use the rest as testing data. Then, we train our classi fier on creatives that belong to the top and bottom 30% in CTR. In fact, we are disregarding 40% of data that are close to the training data CTR mean,  X  t , to reduce the noise for the classifier. Similar to the ranking experiments, we filter our test set by focusing on the k creatives with highest CTR values (labeled as positive) and the k creatives with the lowest CTR values (labeled as negative), where k =  X n is varied by changing  X  . We obtain the classification accu-racy by comparing the predicted classes to the true classes o btained from real CTR values. Figure 6 demonstrates the average clas si-fication accuracy over 200 independent runs where each run uses randomly selected training and testing data. The x -axis indicates the value of  X  and y -axis represents the classification accuracy for each data set given a fixed value of  X  . As seen in the figure, us-ing visual features yields a classification accuracy of 70% when  X  = 0 . 5 . Together with the previous results on predicting and rank-ing CTR, these results show the efficacy of using visual featu res of creatives in predicting CTR.
The above analysis shows that visual features are useful in p re-dicting the performance of creatives in online advertising . A natu-ral question is to identify the visual features that have str ong impact on ad performance. Such information could be very useful in m any areas. For example, human graphic designers may use this inf or-mation to guide their design of high-performance creatives . Smart ads system may use this information to dynamically generate cre-atives that are more appealing to online users. Ad exchange s ystem may use this information to determine which creative will wi n in the auction marketplace for each advertising opportunity. In this section we conduct a series of experiments to select such imp ortant visual features.

We first calculate the Linear Correlation (LC) and Mutual Inf or-mation (MI) between all features and CTR in each data set. Mu-tual information can provide us with the information of non-linear correlation between features. Note that, to calculate the m utual information between any pair of features ( X, Y ) , we discretized each feature and CTR values into 50 equal intervals.The results are shown in table 3. The top 5 features in each data set with highest absolute values are highlighted in bold. The table shows tha t there is no feature with high linear correlation or mutual informa tion ex-cept f 12 in data set ID 6 . Thus we use Forward Feature Selection (FFS) to select the top k features.
 Before running FFS, we first cluster the features based on the Normalized Mutual Information (NMI) of all feature pairs. W e discretize each feature into 50 equal intervals, and calculate NMI as follows: where H ( X ) is the entropy of random variable X . Then we cluster the features using the average linkage algorithm [2 2]. Two clusters are merged into one if their average NMI is at least 0 . 2 . This results in 20 clusters for data set ID 2 and 21 clusters for data set ID 6 . The resulting clusters are shown in Table 3. In the table, S represents a set of features in cluster i . We now apply a simple change to the FFS algorithm to select the top k clusters rather than features. After selecting a feature by FFS, all the correlat ed features that belong to the same cluster are removed from the next step s of FFS. The selected top k = 10 clusters are shown in table 2. Note that clustering the features in the above manner helps s elect different features (or feature sets) that are less correlat ed with each other. For example, all color harmony features are in the sam e cluster S 4 . Therefore by selecting one of the features from this cluster, we indicate the importance of color harmony in CTR, and by removing the highly correlated features at each step in FF S, we can guarantee to select a set of features which are less corre lated with each other. Below we investigate some of the selected cl usters that are common to both data sets.

Table 2 shows that S 1 is the best feature set (or cluster) for data set ID 6 and the second best set for data set ID 2 which illustrates the importance of set S 1 . S 1 consists of the gray level features f and f 2 of the image. The scatter plot of both features in data set ID 2 is shown in Figure7 (the scatter plot in data set ID 6 is similar). Figure 7 shows that for creatives with small value in both fea tures, high CTR value is unlikely, and creatives with high CTR value s should have high values in these two features. This is consis tent with the intuition that creatives with higher contrast shou ld perform better. Note that having high values in these two features do es not guarantee a high CTR value.
 S 5 is the best feature set for data set ID 2 and the fourth for ID6. It only includes f 10 which is the number of connected coherent components. The scatter plot of f 10 in both data sets are shown in figure 8. The scatter plot shows that creatives with more than 15 connected coherent components in data set ID 6 and more than 20 in data set ID 2 are unlikely to achieve a CTR higher than 0 . 01 . In other words, this suggests that cluttered creatives contai ning many objects tend to have lower CTR.

The number of characters, S 19 in data set ID 2 and S 20 in data set ID 6 , is interestingly the third important feature set in both da ta sets. Figure 9 shows the scatter plot of the number of charact ers in both data sets. It can be seen that the creatives with higher n umber of characters are unlikely to achieve high CTR values in both data sets, once again suggesting that textual clutter is undesir able.
The next selected categories is S 17 which is the 4 -th selected category in ID 2 and the 5 -th in ID 6 . S 17 represents the number of connected components in saliency binary map, distance be tween salient components, distance of saliency areas from the cen ter of image and rule of third closest point. This indicates the imp ortance of saliency features as well as considering professional ph otogra-phy rules such as the rule of third in designing ads. Intuitiv ely, a small number of salient components, closer to the center of the creative, and consistent with the rule of third are desirabl e features in a creative. Finally, S 13 , which contains features describing the number of hues and the contrast of hues in the largest segment of the image, is the 5 -th important common category considering both data sets. Note that the scatter plot of the last 2 selected categories have been omitted due to space limit. In summary, our top 5 se-lected categories include the features from all proposed fe ature cat-egories, global, local and advanced features, indicating t he impor-tance of each of them in predicting the creatives CTR.
In this paper we investigated the relationship between the u ser response rate and the visual appearance of creatives in onli ne dis-play advertising. To the best of our knowledge, this is the fir st work in this area. We designed 43 visual features for our experiments. We extracted the features from large scale data produced by t he world X  X  largest ad exchange system. We tested the utility of visual features in CTR prediction, ranking and classification. The experi-mental results demonstrate that our proposed framework is a ble to outperform baseline consistently, indicating the efficacy of visual features in predicting CTR. We also performed feature selec tion to select the top visual feature categories that have strong est im-portance for increasing CTR. The findings from this work will be useful for ads selection and developing visually appealing creatives with higher user response propensity in online display adve rtising. [1] A. C. Bovik, L. K. Cormack, J. K. Aggarwal, C. Bajaj, G. D. [2] D. Chakrabarti, D. Agarwal, and V. Josifovski. Contextu al [3] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support [4] P. Chatterjee. Are unclicked ads wasted? enduring effec ts of [5] D. Cohen-Or, O. Sorkine, R. Gal, T. Leyvand, and Y.-Q. Xu. [6] N. Damera-venkata, S. Member, T. D. Kite, W. S. Geisler, [7] R. Datta, D. Joshi, J. Li, and J. Z. Wang. Studying aesthet ics [8] N. Donthu, R. Lohtia, T. Osmonbekov, and T. Xie. Emotiona l [9] A. Goldfarb and C. Tucker. Online display advertising: [10] B. Gooch, E. Reinhard, C. Moulding, and P. Shirley. Arti stic [11] M. Grant and S. Boyd. CVX: Matlab software for disciplin ed [12] X. Hou and L. Zhang. Saliency detection: A spectral resi dual [13] P. Isola, J. Xiao, A. Torralba, and A. Oliva. What makes a n [14] J. Itten. The Art of Color . 1960. [15] L. Itti, C. Koch, and E. Niebur. A model of saliency-base d [16] Y. Ke, X. Tang, and F. Jing. The design of high-level feat ures [17] S. Krishna. Open cv viola-jones face detection, 2008. [18] C. Li and T. Chen. Aesthetic visual quality assessment o f [19] H. Li and J. L. Bukovac. Cognitive impact of banner ad [20] Y. Luo and X. Tang. Photo and video quality evaluation: [21] E. McQuarrie and D. Mick. Visual rhetoric in advertisin g: [22] F. Murtagh. A survey of recent advances in hierarchical [23] D. Orlando. Optical character recognition, 2007. [24] G. Pass, R. Zabih, and J. Miller. Comparing images using [25] L. L. Renjie, C. Lior, W. D. Cohen-or, L. Liu, R. Chen, [26] M. Richardson. Predicting clicks: Estimating the [27] J. Shi and J. Malik. Normalized cuts and image [28] R. Tibshirani. Regression shrinkage and selection via the [29] M. Tokumaru, N. Muranaka, and S. Imanishi. Color design [30] H. Tong, M. Li, H. jiang Zhang, J. He, and C. Zhang. [31] I. Yaveroglu and N. Donthu. Advertising repetition and [32] Y.Mastuda. Color design. In Asakura Shoten , 1995.
