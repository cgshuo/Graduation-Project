 Keywords: social recommendations, metric learning, collaborative filtering, ma-trix factorization. Recommender systems now play an increasingly remarkable role in information filtering. Typically, recommender systems are predicated on collaborative filter-ing (CF), a technique relying on collective historical common ratings to predict items which will be positively rated by the active user [1]. However, most users rate few of the millions of items. The lack of common ratings will result in a degradation in recommendation accuracy. With the growing popularity of the online social platform, social recommender systems emerged [2]. These system-s merge both rating information and social relations into recommendation, and consider that users can be affected by their friends in decision making [3]. There-fore, the preference of users having few ratings can be inferred from that of their friends. It has been proven that social recommender systems can generate more accurate recommendations especially for so-called cold start users [4]. trix factorization) [5], a basic model which has been extensively used for its scal-ability and efficiency. Generally, matrix factorization decomposes the user-item rating matrix into two low dimensional matrices using the known ratings. After that, the latent factors of the new matrices are used to complement the primitive matrix with their inner products. And the inner products can be considered as a type of interactions between users and items. Unlike traditional matrix factor-ization based recommender systems, social recommender systems capture social information as another input of the recommendation method. Thus, in social recommender systems, the interactions among users have to be explored. Ma et al. in [6] proposed a representative method co-factorizing the rating matrix and the relation matrix into three low rank matrices. In the method, social infor-mation and rating information can be connected through the shared user latent feature space. However, the meaning of latent factors are still ambiguous since the training process of matrix factorization is like a black box.
 is based on matrix factorization as well. The principle of the proposed method is that the distance reflects likability. However, in our model we use Mahalanobis distance to replace Euclidean distance to measure the gap since we consider that all dimensions in the low dimensional space are correlative. Therefore, distance metric is incorporated in our method. As an important topic, distance metric learning [7] has been applied in many domains, including information retrieval, supervised classification, and clustering [8 X 10]. To the best of our knowledge, few work has combined distance metric learning and collaborative filtering. Different from the process of the general distance metric learning, our model needs to train the samples (latent factors) and the distance metric at the same time, which makes the model scalable. Finally, all users and items are embedded in a unified space. Users are spatially close to their friends and their liked items, and be far away from their disliked items. The distance between users and items can be used to generate recommendations. The experiments conducted on real-world dataset show that our method significantly improves the quality of social recommendations.
 the proposed method incorporating matrix factorization and distance metric learning. Section 3 reports the experimental results. In section 4, the related literatures are briefly introduced. Finally, in section 5 we conclude this paper and point out some potential future work. Traditional recommender system techniques ignore the effect of social relation-s among users. With the rapid development of social networks, incorporating social information into recommender systems becomes more and more impor-tant. In this section we put forward a Social recommendation model connecting F actorization and D istance metric learning called SocialFD . 2.1 Problem Definition In recommender systems, users can be defined as the set U = { u 1 ,...u m } , and items can be defined as the set I = { i 1 ,...i n } . Ratings given by users on items are marked with the matrix R = [ r u,i ] m  X  n , and r u,u denotes the rating from user u on item i . In reality, the density of the available ratings is often less than 1%. To relieve the data sparsity problem, social information are incorporated now. In a social network, each user has some friends denoted by the vector N u . The user X  X  missing ratings, to some degree, can be inferred from that of his friends. Regarding the edges in the social graph as trust statements which are real numbers in [0, 1], we mark all trust statements from users with a adjacent matrix T = [ t u,v ] m  X  m . The task of a social recommender can be summarized as follows: given a user u and an item i , using the known information in R and T to predict the r u,i . 2.2 Distance Metric Learning Distance metric learning is crucial in real-world application. Previous work [8 X 10] has shown that a good distance metric can remarkably improve the performance of the learners relied on spatial data. According to the availability of the training samples, algorithms for distance metric learning can be divided into two cate-gories: supervised distance metric learning and unsupervised distance metric learning. Generally, the training samples of supervised distance metric learn-ing will be cast into pairwise constraints. Then the supervised distance metric learning can be further divided into two subclasses: the global distance metric learning and the local distance metric learning. In our work, we concentrate on applying the former to recommender systems. The target of the global distance straints in a global sense. Let the distance metric denoted by matrix A  X  R k  X  k , and the distance between any two data points x and y expressed by In Eq.1, A has to be a positive semi-definite matrix to keep the distance non-negative and symmetric. The global optimization problem with constraints can be stated as where S denotes the set of equivalent constraints in which x and y belong to the same class, and D denotes the set of inequivalent constraints in which x and y belong to different classes, and  X  is a constant to restrict the minimum distance between data points in different classes.
 2.3 The SocialFD Model Most of the existing social recommender systems are based on matrix factoriza-tion. However, in the model of matrix factorization, the meaning of the decom-posed latent factors are ambiguous. To make the recommendations understand-able and reliable, we consider that something interpretable should be fused into the latent factors.
 the main idea of distance metric learning is to learn a desired distance metric can prominently make data points with the same class label closer, and discriminate data points in different sets with larger distance. However, in SocialFD, it aims to minimize the distance between each user and his positively rated items and his friends, and to maximize the distance between each user and his negatively rated items.
 models are the latent factors which are not prepared at first, and labels are classified into two types (like and dislike) according to the rating expressed by users. Note that, we consider if a user rate an item with a higher score, it shows the item is positively rated; on the contrary, if a user rate an item with a lower score, it shows the item is negatively rated. And the sets of pairwise constraints are constructed as follows: given a user and an item, if the user positively rated the item, the pair will be distributed to the set of equivalent constraints; if the user negatively rated the item, they will be distributed to the set of inequivalent constraints.
 the distance metric simultaneously. The overall process is depicted in Fig.1. Firstly, we initialize two k -rank matrices filled with random values denoting the user latent matrix and the item latent matrix respectively, and defines a matrix  X 
R k  X  k to be the distance metric. The Mahalanobis distance between users and items can be calculated by the inner products of the differences of latent factors and the distance metric. During the training stage, constraints are imposed to guarantee that users should be spatially close to their friends and their liked items, and be far away from their disliked items. And the positions of users and items are decided by the ratings and social relations jointly. Therefore, if some users are lack of ratings, their social connections can help to find the best locations for them. Finally, the obtained latent factors can be interpreted as coordinates in the low dimensional space, and the distance calculated can be used to generate understandable recommendations.
 fined as where  X  represents the overall average rating, b u and b i indicate the deviations of user u and item i , A  X  R k  X  k , and k is the same as the dimension of x and y , which is much less than the dimension of the primitive rating matrix. Instead of learning a positive semi-definite matrix A , H  X  R k  X  k can be learnt with A = HH T . However, H does not need to be positive semi-definite, which makes the problem can be solved with generic approaches. To obtain a good distance metric, the loss function of SocialFD is defined as where P is the set of pairs contains user u and his positively rated items, N is the set of pairs contains user u and his negatively rated items, the middle three terms are constraints used to adjust the distance into an appropriate range,  X  controls the magnitudes of the biases, and  X  and  X  are algorithmic parameters to control the influence of the constraints.
 problem [7, 11, 12]. In our work, we use stochastic gradient descent, because it works very efficiently in case of redundant data. Updates for the parameters in each step can be defined as b u  X  b u +  X  ( e ui  X   X b u ) b i  X  b i +  X  ( e ui  X   X b i ) y i  X  y i +  X  ( e ui  X   X  )( x u  X  y i )( HH T + H T H ) x u  X  x u  X   X  (( e ui  X   X  )( x u  X  y i )  X   X  X
H  X  H  X   X  ( e ui  X   X  ) H ( x u  X  y i ) T ( x u  X  y i )  X   X  X  X where e ui is the gap between the real rating and the predicted result,  X  is the learning rate, and the exact operator of the plus-minus sign is determined by the sign of the term related to distance in Eq. 4.
 because distance is more interpretable than interaction. And latent factors in SocialFD can be explained as the coordinates of users and items. As for the training cost, apart from the latent factors, SocialFD merely has an additional distance metric matrix with k  X  k elements to be learnt. Since k is a small number which is consistent with the dimension of the latent factor of users and items, the cost will not be computationally expensive.
 ing advantage. It is flexible in incorporating additional knowledge. In previous content, we assume that all datum collected are ratings and social connections. However, in real situations, the profiles of users and items consist of more texts, which can be collected as well to help improve the quality of recommendations. For example, the preference of a user can be blended in his opinions for some commodities, and the property of an item can be fused into the item description. Therefore, some NLP models can be used, such as word2vec [13], FastText [14], and WordRank [15], to generate distributed representations for the opinions and descriptions. Then, the semantic representations can replace the initial random vectors x and y in SocialFD or concatenate with the random vectors. The new representations may help to learn a better distance metric for SocialFD as they contain more characteristics of users and items, meanwhile, they are pre-trained, which can cut off the training time of Social. However, in matrix factorization, it is difficult to integrate the well-trained semantic representation. In this section, we present the experimental results. Two types of experiments are conducted. Firstly, the recommendation quality of the baselines and SocialFD is compared. Secondly, whether the change of the distance in SocialFD is desired or not is confirmed. 3.1 Experimental setup In this subsection, we introduce the datasets, the evalution metrics, and the baselines used to compare with SocialFD.
 the most popular social networks in China. Douban Movie provides the latest movie info, and users can record the movies they wish to watch and rate what they watched. Furthermore, they can share the reviews to their friends. The statistics of the dataset released by [16] are shown in Table 1.
 sure the prediction error of all methods. Besides, we also use ranking-based metrics: Precision@50, Recall@50, and F1@50, to measure the quality of the recommendation list, which is more important to users.
 method with the following methods.  X  PMF : this method is proposed by Salakhutdinov and Minh in [17], and is  X  SoRec : this is the method proposed in [6]. It is a social trust-aware rec- X  SocialMF : this is the method proposed in [18]. It is the most relevant work  X  RSTE : this is the method proposed by Ma et al. in [19], and it is a linear In all experiments, we set the parameters of these methods according to their best performance. 3.2 Performance for Predicting Missing Ratings Predicting missing ratings in the rating matrix is the primary goal of most rec-ommendation methods. In this section, we compare the performance of SocialFD with that of the baselines. We set the step size  X  = 0.05,  X  = 0.2,  X  = 2, and  X  = 0 . 1 for SocialFD. And the reduced dimension d is set at 20, and the regu-larization parameter  X  is set at 0.001 for all the methods.
 rithm proceeds. We can clearly observe that SocialFD outperforms the baselines. From Table 2, we can compare all methods involved in a more intuitive sight. In Table 2, we list the best RMSE of all methods, and the number in brackets is how many iterations past by the time the best performance was reached. Despite the fact that SocialFD is not fine tuned, it is obvious that SocialFD beat other methods by fairly large margins. Compared with PMF, SoRec, SocialMF, and RSTE, SocialFD reduces the RMSE by 3.40%, 3.42%, 5.21%, and 2.73% on 80% training data, and by 2.94%, 3.25%, 5.21%, and 2.47% on 90% training data, respectively.
 mendation list. Thus, we prefer the ranking metrics rather than the RMSE. In the preprocessing stage, we binarize the explicit rating data by keeping the rat-ings of four or higher. In the prediction stage, we use the distance k x u  X  y i k 2 A to generate ranking scores for users on all items. Sorting the ranking scores for all users, we can get the recommendation lists. Table 3 shows the lists measured by the ranking metrics. SocialFD transparently beats other methods on almost all the metrics except Recall@50. On 80% training data, RSTE wins by lesser superiority. However, it can not deny that using distance to reflect likability is a promising idea. 3.3 Change of the Distance The goal of SocialFD is to make users be spatially close to their friends and their liked items, and be far away from their disliked items. In SocialFD, constraints for the distance are binding to help to reach the objective. In this part, we will confirm that whether the obtained distance is desired or not. Settings for SocialFD are the same with those in section 3.2, and the experiment is conducted on 80% training data.
 user and his positively rated items Positive distance . Similarly, Negative distance is defined as well. The Y-axis in Fig. 3 (a) is the ratio of the negative distance to the positive distance. We can observe that, the curve in Fig. 3 (a) increases explosively at first, after 10 iterations, the curve gradually reaches a stable state. Finally, the ratio of the negative distance to positive distance converges at about 12. Fig.3 (b) shows the change of the average distance among users with social connections. We can see the curve has a converse trend with that in Fig.3 (a). With the proceeding of the iteration, the average distance becomes shorter, and after 30 iterations, it starts to ascend. Eventually it reaches a flat state. So far, we can draw a conclusion that SocialFD do find appropriate locations for users and items. In general, CF-based recommendation systems can be categorized into two class-es: memory-based and model-based [4]. Compared with memory-based CF, model-based CF has a more holistic objective to uncover latent factors that explain observed ratings [5], for the reason they are very competitive if not the best, and are widely adopted to build recommender systems [1].
 information, lots of social recommendation method based on matrix factorization are proposed [18 X 23]. Among them, the most relevant research to ours are [18] and [20].
 SocialMF is that a user X  X  preference should be similar with that of his friends. Thus, in the training process, it concentrates on forcing a given user X  X  latent factors approximate those of his friends. In [20], a method taking both trust and distrust into consideration was proposed. The authors deem that each user X  X  latent factors should be close to those of his friends, and differ widely from those of distrusted users. It seems that the principle of the two methods are similar to that of SocialFD. However, these methods still regard latent factors as the representation of characteristics of users which are lack of explicit sense. idea of the model is that all items and users can be embedded in a unified Euclidean space, and the learnt latent factors of users and items should reflect the negative correlation between the distance and the given rating. It means, the higher a given rating is, spatially the more closer the user and the item are. However, whether the Euclidean distance can measure the gap between users and items is questionable. As is well known, appropriately designed distance metrics can significantly benefit KNN classification accuracy compared to the standard Euclidean distance [25, 26]. In addition, no constraints are brought up to guarantee that the obtained distance is desired, and it all depends on the weak correlation with the ratings which may include some noises. This paper is motivated by the assumption that distance can reflect likability. Based on the intuition, we proposed a novel recommendation method called SocialFD connecting distance metric learning and matrix factorization. The method aims to embed users and items into a unified space and make users be spatially close to their friends and their liked items, and be far away from their disliked items. The positions of users and items are decided by the rat-ings and social relations jointly, which can help to find appropriate locations for users who have few ratings. The distance eventually obtained are used to gener-ate understandable and reliable recommendations. The experiments show that, SoicalFD outperforms the-state-of-art methods in recommendation accuracy. dations for the users, we do not take the distrust into consideration. Generally speaking, negative opinions contains more information than positive opinions. Fusing the distrust into the distance-based social recommender can help to lo-cate users more precisely. That is the potential direction we will explore in the future. In addition, we note that few work combines distance metric learning with the link prediction. We consider that the same idea of this paper can be extended to the area of the link prediction.
 This research is supported by the Basic and Advanced Research Projects in Chongqing (cstc2015jcyjA40049), the National Key Basic Research Program of China (973) (2013CB328903), the National Natural Science Foundation of China (61472021), and the Fundamental Research Funds for the Central Universities (106112014 CDJZR 095502)
