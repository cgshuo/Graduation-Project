 It is a commonly accepted hypothesis that adaptation of beha vior results from changes in synap-tic efficacies in the nervous system. However, there exists l ittle knowledge about how changes in synaptic efficacies change behavior and about the learning p rinciples that underlie such changes. Re-cently, one important hint has been provided in the experime ntal study [1] of a monkey controlling a neuroprostethic device. The monkey X  X  intended movement v elocity vector can be extracted from the firing rates of a group of recorded units by the population vector algorithm, i.e., by computing the weighted sum of their PDs, where each weight is the unit X  X  normalized firing rate [2]. 1 In [1], this velocity vector was used to control a cursor in a 3D virtu al reality environment. The task for the monkey was to move the cursor from the center of an imaginary c ube to a target appearing at one of its corners. It is well known that performance increases wit h practice when monkeys are trained to move to targets in similar experimental setups, i.e., the fu nction of recorded neurons is adapted such that control over the new artificial  X  X imb X  is improved [3]. I n [1], it was systematically studied how such reorganization changes the tuning properties of recor ded neurons. The authors manipulated the interpretation of recorded firing rates by the readout sy stem (i.e., the system that converts firing rates of recorded neurons into cursor movements). When the i nterpretation was altered for a subset of neurons, the tuning properties of the neurons in this subs et changed significantly stronger than those of neurons for which the interpretation of the readout system was not changed. Hence, the ex-periment showed that motor cortical neurons can change thei r activity specifically and selectively to compensate for an altered interpretation of their activity within some task. Such adjustment strategy is quite surprising, since it is not clear how the cortical ad aption mechanism is able to determine for which subset of neurons the interpretation was altered. We r efer to this learning effect as the  X  X redit assignment X  effect.
 In this article, we propose a simple synaptic learning rule a nd apply it to a model neural network. This learning rule is capable of optimizing performance in a 3D reaching task and it can explain exclusively on local variables and a global scalar reward si gnal R ( t ) . The learning rule is reward-modulated Hebbian in the following sense: Weight changes at synapses are driven by the correlation between a global reward signal, the presynaptic activity, a nd the difference of the postsynaptic po-tential from its recent mean (see [4] for a similar approach) . Several reward-modulated Hebbian learning rules have been studied for quite some time both in t he context of rate-based [5, 6, 7, 8, 4] and spiking models [9, 10, 11, 12, 13, 14, 15, 16]. They turn ou t to be viable learning mechanisms in many contexts and constitute a biologically plausible alte rnative [17, 18] to backpropagation based mechanisms preferentially used in artificial neural networ ks. One important feature of the learning rule proposed in this article is that noisy neuronal output i s used for exploration to improve perfor-mance. It was often hypothesized that neuronal variability can optimize motor performance. For example in songbirds, syllable variability results in part from variations in the motor command, i. e. the variability of neuronal activity [19]. Furthermore, th ere exists evidence for the songbird system that motor variability reflects meaningful motor explorati on that can support continuous learning [20]. We show that relatively high amounts of noise are benefi cial for the adaptation process but not problematic for the readout system. We find that under rea listic noise conditions, the learning rule produces effects surprisingly similar to those found i n the experiments of [1]. Furthermore, the version of the reward-modulated Hebbian learning rule t hat we propose does not require ex-traneous information about what is noise and what is signal. Thus, we show in this study that reward-modulated learning is a possible explaination for e xperimental results about neuronal tuning changes in monkey pre-motor cortex. This suggests that rewa rd-modulated learning is an important plasticity mechanism for the acquisition of goal-directed behavior. In this section, we briefly describe the experimental result s of [1] as well as the network that we used to model learning in motor cortex. Neurons in motor and premo tor cortex of primates are broadly intended arm movement from recorded neuronal activity in in these areas. The tuning curve of a direction tuned neuron is given by its firing rate as a functio n of movement direction. This curve can be fitted reasonably well by a cosine function. The preferred direction (PD) p i  X  R 3 of a neuron i is defined as the direction in which the cosine fit to its firing rat e is maximal, and the modulation depth is defined as the difference in firing rate between the maximum of the cosine fit and the baseline (mean). The experiments in [1] consisted of a sequence of fou r brain control sessions: Calibration, Control, Perturbation, and Washout . The tuning functions of an average of 40 recorded neurons were obtained in the Calibration session where the monkey moved its hand in a center out reachi ng task. Those PDs (or manipulated versions of them) were later used for decoding neural trajectories. We refer to PDs used for decoding as  X  X ecoding PDs X  (dPDs) in o rder to distinguish them from measured PDs. In Control , Perturbation , and Washout sessions the monkey had to perform a cursor control task in a 3D virtual reality environment (see Figure 1B). The cursor was initially positioned in the center of an imaginary cube, a target position on one of the corners of the cube was randomly selected and made visible. When the monkey managed to hit the target position with the cursor or a 3s time period expired, the cursor position was reset to t he origin and a new target position was randomly selected from the eight corners of the imaginar y cube. In the Control session, the measured PDs were used as dPDs for cursor control. In the Perturbation session, the dPDs of a randomly selected subset of neurons (25% or 50% of the record ed neurons) were altered. This was Figure 1: Description of the 3D cursor control task and netwo rk model for cursor control. A) Schematic of the network model. A set of m neurons project to n total noisy neurons in motor cortex. The monkey arm movement was modeled by a fixed linear m apping from the activities of the modeled motor cortex neurons to the 3D velocity vector of the monkey arm. A subset of n neurons in the simulated motor cortex was recorded for curso r control. The cursor velocity was given by the population vector. B) The task was to move the cur sor from the center of an imaginary cube to one of its eight corners. achieved by rotating the measured PDs by 90 degrees around th e x , y , or z axes (all PDs were rotated around a single common axis in each experiment). We term thes e neurons rotated neurons. Other dPDs remained the same as in the Control session ( non-rotated neurons). The measured PDs were used for cursor control in the subsequent Washout session. In the Perturbation session, neurons adapted their firing behavior to compensate for the altered d PDs. The authors observed differential effects of learning for the two groups of non-rotated neuron s and rotated neurons. Rotated neurons tended to shift their PDs in the direction of dPD rotation, th us compensating for the perturbation. For non-rotated neurons, the change of the preferred direct ions was weaker and significantly less strongly biased towards the rotation direction. We refer to this differential behavior of rotated and non-rotated neurons as the  X  X redit assignment effect X .
 Network and neuron model: Our aim in this article is to explain the described effects in the simplest possible model. The model consisted of two populat ions of neurons, see Figure 1A. The input population modeled those neurons which provide input to the neurons in motor cortex. It consisted of m = 100 neurons with activities x neurons in motor cortex which receive inputs from the input p opulation. It consisted of n total = determine the monkey arm movement in our model. A small numbe r of them ( n = 40 ) modeled recorded neurons used for cursor control. We denote the acti vities of this subset as s The total synaptic input a inputs: where w from a uniform distribution in the interval [  X  0 . 5 , 0 . 5] at the beginning of each simulation.  X  models some exploratory signal needed to explore possibly b etter network behaviors. In cortical neurons, this exploratory signal could for example result f rom neuronal or synpatic noise, or it could be spontaneous activity of the neuron. An independent sampl e from the zero mean distribution D (  X  ) was drawn as the exploratory signal  X  determines the variance of the distribution and hence the am ount of noise in the neuron. A nonlinear function was applied to the total synaptic input, s neuron i at time t . We used  X  : R  X  R is the piecewise linear activation function  X  ( x ) = max { x, 0 } in order to guarantee non-negative firing rates.
 Task model: We modeled the cursor control task as shown in Figure 1B. Eigh t possible cursor target positions were located at the corners of a unit cube in 3D spac e which had its center at the origin of the coordinate system. At each time step t the desired direction of cursor movement y  X  ( t ) was computed from the current cursor and target position. By con vention, the desired direction y  X  ( t ) had unit Euclidean norm. From the desired movement direction y  X  ( t ) , the activities x of the neurons that provide input to the motor cortex neurons were computed and the activities s lation activity vector (see below).
 In order to model the cursor control experiment, we had to det ermine the PDs of recorded neurons. Obviously, to determine PDs, one needs a model for monkey arm movement. In monkeys, the trans-formation from motor cortical activity to arm movements inv olves a complicated system of several synaptic stages. In our model, we treated this transformati on as a black box. Experimental findings suggest that monkey arm movements can be predicted quite wel l by a linear model based on the activities of a small number of motor cortex neurons [3]. We t herefore assumed that the direction of the monkey arm movement y arm ( t ) at time t can be modeled in a linear way, using the activi-ties of the total population of the n total cortical neurons s and a fixed randomly chosen 3  X  n total linear mapping Q (see [23]). With the transformation from motor cortex neurons to monkey arm movements being defined, t he input to the network for a given desired direction y  X  should be chosen such that motor cortex neurons produce a mon key arm move-ment close to the desired movement direction. We therefore c alculated from the desired movement direction input activities x ( t ) = c Q , W total denotes the matrix of weights w such that the activities of the neurons in the simulated moto r cortex could directly be interpreted as rates in Hz [23]. This transformation from desired directio ns to input neuron activities was defined initially and held fixed during each simulation because lear ning took place in our model in a single synaptic stage from neurons of the input population to neuro ns in the motor cortex population in our model and therefore the coding of desired directions did not change in the input population. As described above, a subset of the motor cortex population w as chosen to model recorded neurons that were used for cursor control. For each modeled recorded neuron i  X  X  1 , . . . , n } , we determined the preferred direction p i  X  R 3 as well as the baseline activity  X  fitting a cosine tuning on the basis of simulated monkey arm mo vements [1, 23]. In the simulation of a Perturbation session, dPDs  X  p i of rotated neurons were rotated versions of the measured PDs p i (as in [1], one of the x , y , or z axis was chosen and the PDs were rotated by 90 degrees around t his axis), whereas the dPDs of non-rotated neurons were identic al to their measured PDs. The dPDs were then used to determine the movement velocity y ( t ) of the cursor by the population vector algorithm [1, 2, 23]. This decoding strategy is consistent w ith an interpretation of the neural activity which codes for the velocity of the movement. Adaptation of synaptic efficacies w if the actual decoding PDs  X  p i do not produce optimal cursor trajectories. Assume that sub optimal not in the desired direction y  X  ( t ) . The weights w the angular match R desired direction y  X  ( t ) : R exactly in the desired direction, it is 0 if the cursor moves p erpendicular to the desired direction, and it is -1 if the cursor movement is in the opposite direction.
 We assume in our model that all synapses receive information about a global reward R ( t ) . The general idea that a neuromodulatory signal gates local syna ptic plasticity was studied in [4]. In that study, the idea was implemented by learning rules where the w eight changes are proportional to the covariance between the reward signal R and some measure of neuronal activity N at the synapse. Here, N could correspond to the presynaptic activity, the postsyna ptic activity, or the product of both. The authors showed that such learning rules can explai n a phenomenon called Herrnstein X  X  matching law. Interestingly, for the analysis in [4] the spe cific implementation of this correlation based adaptation mechanism is not important. We investigat e in this article a learning rule of this type: where  X  a kernel 4 . We refer to this rule as the exploratory Hebb rule (EH rule) i n this article. The important feature of this learning rule is that apart from variables wh ich are locally available for each neuron ( x j ( t ) reward signal R ( t ) is provided by some neural circuit which evaluates performa nce of the system. In our simulations, we simply used the angular match R of the rule are based on correlations between deviations of t he reward signal R ( t ) and the activation a ( t ) from their means. It adjusts weights such that rewards above mean are reinforced. The EH rule (2) approximates gradient ascent on the reward signal b y exploring alternatives to the actual behavior with the help of some exploratory signal  X  ( t ) . The deviation of the activation from the recent mean a based on neuron activations P Here we make use of (1) the fact that weights are changing very slowly and (2) the continuity of the task (inputs x at successive time points are similar). Then, (2) can be seen as an approximation of This rule is a typical node-perturbation learning rule [6, 7 , 22, 10] which can be shown to approxi-mate gradient ascent, see e.g. [10]. A simple derivation tha t shows the link between the EH rule (2) and gradient ascent is given in [23].
 The EH learning rule differs from other node-perturbation r ules in an important aspect. In many node-perturbation learning rules, the noise needs to be acc essible to the learning mechanism sepa-rately from the output signal. For example, in [6] and [7] bin ary neurons were used. The weight updates there depend on the probability of the neuron to outp ut 1 . In [10] the noise term is directly incorporated in the learning rule. The EH rule does not direc tly need the noise signal. Instead a temporally filtered version of the neurons activation is use d to estimate the noise signal. Obviously, this estimate is only sufficiently accurate if the input to th e neuron is temporally stable on small time scales. In this section, we explore the EH rule (2) in a cursor control task that was modeled to closely match the experimental setup in [1]. Each simulated session consi sted of a sequence of movements from the center to a target position at one of the corners of the ima ginary cube, with online weight updates during the movements. In monkey experiments, perturbation of decoding PDs lead to retuning of PDs with the above described credit assignment effect [1]. I n order to obtain biologically plausible from experiments (see [23]). Analysis of the neuronal respo nses in the experiments showed that the variance of the response for a given desired direction scale d roughly linearly with the mean firing rate of that neuron for this direction. We obtained this beha vior with our neuron model with noise that is a mixture of an activation-independent noise source and a noise source where the variance scales linearly with the activation of the neuron. In partic ular, the noise term  X  drawn from the uniform distribution in [  X   X   X  ( x ( t )) = 10 + 2 . 8 data. We note that in all simulations with the EH rule, the inp ut activities x way that the output of the neuron at time t could be interpreted directly as the firing rate of the neuron Figure 2: One example simulation of the 50% perturbation exp eriment with the EH rule and data-derived network parameters. A) Angular match R time point is plotted. B) PD shifts drawn on the unit sphere (a rbitrary units) for non-rotated (black traces) and rotated (light cyan traces) neurons from their i nitial values (light) to their values after training (dark, these PDs are connected by the shortest path on the unit sphere). The straight line in-dicates the rotation axis. C) Same as B, but the view was alter ed such that the rotation axis is directed towards the reader. The PDs of rotated neurons are consisten tly rotated in order to compensate for the perturbation. Figure 3: PD shifts in simulated Perturbation sessions are in good agreement with experimental results (compare to Figure 3A,B in [1]). Shift in the PDs meas ured after simulated perturbation sessions relative to initial PDs for all units in 20 simulate d experiments where 25% (A) or 50% (B) of the units were rotated. Dots represent individual data po ints and black circled dots represent the means of rotated (light gray) and non-rotated (dark gray) un its. at time t . With such scaling, we obtained output values of the neurons without the exploratory signal in the range of 0 to 120Hz with a roughly exponential distribu tion. Having estimated the variability of neuronal response, the learning rate  X  remained the last free parameter of the model. To constrain this parameter,  X  was chosen such that the performance in the 25% perturbation task approximately matched the monkey performance.
 We simulated the two types of perturbation experiments repo rted in [1] in our model network with 40 recorded neurons. In the first set of simulations, a random set of 25% of recorded neurons were rotated neurons in Perturbation sessions. In the second set of simulations, we chose 50 % of th e recorded neurons to be rotated. In each simulation, 320 targ ets were presented to the model, which is similar to the number of target presentations in [1]. Resu lts for one example run are shown in Figure 2. The shifts in PDs of recorded neurons induced by tra ining in 20 independent trials were compiled and analyzed separately for rotated neurons and no n-rotated neurons. The results are in good agreement with the experimental data, see Figure 3. I n the simulated 25% perturbation experiment, the mean shift of the PD for rotated neurons was 8 . 2  X  4 . 8 degrees, whereas for non-in [1] where the PD shift of rotated (non-rotated) units was 9 . 9 ( 5 . 2 ) degrees. The effect is more pronounced in the 50% perturbation experiment (see below). We also compared the deviation of the movement trajectory from the ideal straight line in rotatio n direction half way to the target 6 from early trials to the deviation of late trials, where we scaled the results to a cube of 11cm side length deviation was 9 . 2  X  8 . 8 mm, which was reduced by learning to 2 . 4  X  4 . 9 mm. In the simulated 50% perturbation experiment, the mean shift of the PD for rot ated neurons was 18 . 1  X  4 . 2 degrees, whereas for non-rotated neurons, it was 12 . 1  X  2 . 6 degrees (in monkey experiments [1] this was 4 . 8  X  5 . 1 mm in late trials. Here, the early deviation was stronger tha n in the monkey experiment, while the late deviation was smaller.
 In these rules the weight change is proportional to the covar iance of the reward signal and some measure of neuronal activity. We performed the same experim ent with slightly different correlation-based rules (compare to (2)). The performance improvements were simila r to those obtaint with the EH rule. However, no credit assignment effect was observed with thes e rules. In the simulated 50% perturba-tion experiment, the mean shift of the PD of rotated neurons ( non-rotated neurons) was 12 . 8  X  3 . 6 ( 12 . 0  X  2 . 4 ) degrees for rule (4) and 25 . 5  X  4 ( 26 . 8  X  2 . 8 ) degrees for rule (5). In the monkey experiment, training in the Perturbation session also induced in a decrease of the modulation depth of rotated neurons. This resulted in a decr eased contribution of these neurons to the cursor movement. We observed a qualitatively similar resultin our simulations. In the 25% perturbation simulation, modulation depths decreased on a verage by 2 . 7  X  4 . 3 Hz for rotated neurons. Modulation depths for non-rotated neurons increased on ave rage by 2 . 2  X  3 . 9 Hz (average over 20 independent simulations). In the 50% perturbation simulat ion, the changes in modulation depths were  X  3 , 6  X  5 . 5 Hz for rotated neurons and 5 . 4  X  6 Hz for non-rotated neurons. 7 Thus, the relative contribution of rotated neurons on cursor movement decreas ed.
 Comparing the results obtained by our simulations to those o f monkey experiments (compare Figure 3 to Figure 3 in [1]), it is interesting that quantitatively s imilar effects were obtained when noise level and learning rate was constrained by the experimental data. One should note here that tuning changes due to learning depend on the noise level. For small e xploration levels, PDs changed only slightly and the difference in PD change between rotated and non-rotated neurons was small, while for large noise levels, PD change differences can be quite dr astic. Also the learning rate  X  influences the amount of PD shift differences with higher learning rate s leading to stronger credit assignment effects, see [23] for details.
 The performance of the system before and after learning is sh own in Figure 4. The neurons in the network after training are subject to the same amount of nois e as the neurons in the network be-fore training, but the angular match after training shows mu ch less fluctuation than before training. Hence, the network automatically suppresses jitter on the t rajectory in the presence of high explo-ration levels  X  . We quantified this observation by computing the standard de viation of the angle between the cursor velocity vector and the desired movement direction for 100 randomly drawn noise samples. 8 The mean standard deviation for 50 randomly drawn target dir ections was always decreased by learning. In the mean over the 20 simulations, t he mean STD over 50 target directions was 7.9 degrees before learning and 6.3 degrees after learni ng. Hence, the network not only adapted its response to the input, it also found a way to optimize its s ensitivity to the exploratory signal. Jarosiewicz et al. [1] discussed three strategies that coul d potentially be used by the monkey to com-pensate for the errors caused by perturbations: re-aiming, re-weighting, and re-mapping. Using the re-aiming strategy, the monkey compensates for perturbati ons by aiming for a virtual target located in the direction that offsets the visuomotor rotation. The a uthors identified a global change in the activity level of all neurons. This indicates a re-aiming st rategy of the monkey. Re-weighting would suppress the use of rotated units, leading to a reduction of t heir modulation depths. A reduction of modulation depths of rotated neurons was also identified in t he experimentals. A re-mapping strat-egy would selectively change the directional tunings of rot ated units. Rotated neurons shifted their PDs more than the non-rotated population in the experiments . Hence, the authors found elements of all three strategies in their data. These three elements of n euronal adaptation were also identified in our model: a global change in activity of neurons (all neuron s changed their tuning properties; re-aiming), a reduction of modulation depths for rotated neuro ns (re-weighting), and a selective change of the directional tunings of rotated units (re-mapping). T his modeling study therefore suggests that all three elements can be explained by a single synaptic adap tation strategy that relies on noisy neu-ronal activity and visual feedback that is made accessible t o all synapses in the network by a global reward signal. It is noteworthy that the credit assignment p henomenon is an emergent feature of the learning rule rather than implemented in some direct way. In tuitively, this behavior can be explained in the following way. The output of non-rotated neurons is co nsistent with the interpretation of the readout system. So if this output is strongly altered, perfo rmance will likely drop. On the other hand, if the output of a rotated neuron is radically different, thi s will often improve performance. Hence, the relatively high noise levels measured in experiments ar e probably important for the credit assign-ment phenomenon. Under such realistic noise conditions, ou r model produced effects surprisingly similar to those found in the monkey experiments. Thus, this study shows that reward-modulated learning can explain detailed experimental results about n euronal adaptation in motor cortex and therefore suggests that reward-modulated learning is an es sential plasticity mechanism in cortex. The results of this modeling paper also support the hypothes es introduced in [24]. The authors pre-sented data which suggests that neural representations cha nge randomly (background changes) even without obvious learning, while systematic task-correlat ed representational changes occur within a learning task.
 Reward-modulated Hebbian learning rules are currently the most promising candidate for a learning mechanism that can support goal-directed behavior by local synaptic changes in combination with a global performance signal. The EH rule (2) is one particula rly simple instance of such rules that exploits temporal continuity of inputs and an exploration s ignal -a signal which would show up as  X  X oise X  in neuronal recordings. We showed that large explor ation levels are beneficial for learning while they do not interfere with the performance of the syste m because of pooling effects of readout elements. This study therefore provides a hypothesis about the role of  X  X oise X  or ongoing activity in cortical circuits as a source for exploration utilized by lo cal learning rules.
 Acknowledgments This work was supported by the Austrian Science Fund FWF [S91 02-N13, to R.L. and W.M.]; the European Union [FP6-015879 (FACETS), FP7-216593 (SECO), F P7-506778 (PASCAL2), FP7-231267 (ORGANIC) to R.L. and W.M.]; and by the National Insti tutes of Health [R01-NS050256, EB005847, to A.B.S.].
