 Query results caching is an efficient technique for Web search en-gines. In this paper we present User-Aware Cache, a novel ap-proach tailored for query results caching, that is based on user characteristics. We then use a trace of around 30 million queries to evaluate User-Aware Cache, as well as traditional methods and theoretical upper bounds. Experimental results show that this ap-proach can achieve hit ratios better than state-of-the-art methods. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search process ; H.3.4 [ Information Storage and Retrieval ]: Systems and Software X  Performance evaluation (effi-ciency and effectiveness) Performance, Experimentation Web search engines, query results, caching, prefetching.
Caching is an effective technique to reduce user response time and back-end server workload. Millions of queries are submitted by users daily to Web search engines, and they all expect low laten-cy to receive answers. Results caching and index caching are two basic approaches for improving the performance of large scale We-b search engines. Results cache stores the previous search results which were recently computed to resolve future queries, while in-dex cache stores the posting lists of the involved query terms to resolve future query results computing. In addition to these ap-proaches, Web search engines m ay also prefetch a search engine results page (SERP) which is the listing of Web pages returned by the Web search engines in response to a query that it predicts to be requested in the near future. Lempel and Moran [2] present proba-bility driven cache (PDC) which is based on a probabilistic model of Web search engine query streams, and examine the prefetching  X 
This work was supported by the National Natural Science Foun-dation of China (Grant No. 61070111).
 users X  requested pages, also termed as PV are within five, and 67% of the requests received by the Web search engines are submitted by only 20% of users. Thus, we can draw the following conclusions: different user X  X  contribution to Web search engine is different.
Usually, the capacity of a caching system is far less than the vol-ume of requests received by Web search engines, and a user X  X  query results page which is prefetched may be flushed out before the next reference to it, especially for a small size caching system. In order to decrease the impact of caching capacity on those loyal users, we divides a fixed amount of available cache into two parts and use one part as a cache for caching results for the queries submitted by the special users group which is pre-defined by Web search en-gines and the other part as a cache for the rest of the queries. It is not necessary that both parts of the cache use the same replacemen-t and prefetching policy, but in this study we use the same policy which is LRU replacement and pre-SDC prefetching policy. Note that User-Aware Cache is formed by the two parts as a whole, and a query results page can only exist in one part. When received a query submitted by a user, a results page should first be looked up in the user X  X  corresponding part.
As shown in figure 1, the distribution of number of query results pages browsed by users has significant long tail characteristic. The finding implies that there is a high possibility that some users ref-erence the query results pages frequently. We describe one feature that can be extracted from the dataset and used for selecting a sub-set of all users for the partition. The feature in this paper is listed below:
We use a query log from a famous Chinese Web search engine [3] which contains around 30 m illion queri es of about 5.8 million people for a period of 2-mont hs (from 09/01/2006 to 10/31/2006). The first 5 million queries constitute the training set to warm up the cache. The remaining about 25 million queries are reserved as the test set. We choose 14,748 users according to UFQF as a special users group and use the cache whose size is 10% of the total capacity of the cache to cache the queries submitted by this group.

The first experiment aims to compare the hit ratio of the user-aware cache with the hit ratio of the cache using local optimal replacement policy which is widely used in the literature and the upper bound [1] which is achieved on the test set of our query log when prefetching is not used. Local optimal replacement policy works as follows: when a results page needs to be evicted, the cache would evict the page whose next ref erence will occur farthest in the next W times requests. W is the constant length of sliding window, and we set the value of W equal to the cache size in our experiment. Figure 2 shows the result of this experiment.

In Figure 2, cache size is given as the number of queries that are cached. It can be seen that there is a significant hit ratio difference between the cache with local optimal replacement policy and the user-aware cache. Especially when the cache size is larger than 150K, the user-aware cache hit ratio is larger than the upper bound on the hit ratio that is achieved if the availability of the cache is
