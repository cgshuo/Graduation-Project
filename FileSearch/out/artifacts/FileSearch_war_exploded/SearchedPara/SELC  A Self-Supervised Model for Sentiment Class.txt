 This paper presents the SELC Model ( SE lf-Supervised, L exicon-based and C orpus-based Model) for sentiment classification. The SELC Model includes two phases. The first phase is a lexicon-based iterative process. In this phase, some reviews are initially classified based on a sentiment dictionary. Then more reviews are classified through an iterative process with a negative/positive ratio control. In the second phase , a supervised classifier is learned by taking some reviews cl assified in the first phase as training data. Then the supervised classifier applies on other reviews to revise the results produced in the first phase. Experiments show the effectivene ss of the proposed model. SELC totally achieves 6.63% F 1 -score improvement over the best result in previous studies on the same data (from 82.72% to 89.35%). The first phase of the SELC Model independently achieves 5.90% improvement (from 82.72% to 88.62 %). Moreover, the standard deviation of F 1 -scores is reduced, which shows that the SELC Model could be more suitable fo r domain-independent sentiment classification. H.3.1 [ Information Systems ]: INFORMATION STORAGE AND RETRIEVAL  X  Content Analysis and Indexing. Algorithms, Performance, Experimentation. Information retrieval, opinion mining, sentiment classification. There are a lot of product reviews on the Web. In those reviews, people evaluate the products they used before and express their feelings about the products. The anal ysis of reviews is helpful for both consumers and the producers. In particular, assigning the positive and negative sentiment va lues to product reviews is referred to as sentiment classifi cation. Here, the polarities include positive and negative polarities. Generally, there are two types of approaches tackling the sentiment classification task according to the knowledge they used. One is corpus-based [2, 3, 6, 9, 10] and the other is lexicon-based [4, 13, 15, 16]. The corpus -based approaches are usually supervised, i.e., requiring traini ng sets, and performing well when the training set is large enough and correctly labeled. On the contrary, the lexicon-based appr oaches are mostly unsupervised, requiring only a few seed words su ch as  X  X xcellent X  or  X  X oor X . Compared with the corpus-based approaches, lexicon-based ones have the advantage of domain-independence because it is much easier to acquire a few seed words than correctly label a large training set, and some researchers even showed that the seed words can be automatically generated [16]. Further study [1] showed that corpus-based and lexicon-based approaches could be complementary to each other. In particular, corpus-based ones usually achieve higher precision on positive reviews while lexicon-based ones usually achieve higher precision on negative reviews. In other words, corpus-based approaches tend to classify a review as negative while lexicon-based approaches tend to positive. The two tendencies are classification bias respectively. The integration of the two types of approaches seems very prom ising. However, the direct integration like [1] is a kind of supervised approach in essence because it still needs a small-s cale manually annotated corpus. We attempt to build a model to have the following features: z be domain-independent, which means nothing of the model z exploit the complementarities between lexicon-based and z do not need to manually annotate corpus in the integration The SELC Model is proposed to m eet the above requirements. It is built based on a lexicon-based approach. Therefore it is domain independent. Several innovati ons, including positive/negative ratio control, the use of a general sentiment dictionary and the enlargement of negation word lis t, are adopted to overcome the positive classification bias of lexicon-based approaches. Then the SELC Model introduces a corpus-based approach to revise the result of the lexicon-based one. In the revising process, the corpus-based approach takes some reviews classified by the lexicon-based one as training da ta. Although the training data is machine-generated, most reviews of the training data are correctly labeled (above 93% precision in the experiments), because the lexicon-based approach is well designed. As such, the performance of the corpus-based a pproach is still reliable, and the whole performance is improved. The SELC Model achieves an overall F 1 -score of 89.35% on data sets of ten domains, with an im provement of 6.63% over the best result (82.72%) in previous studies on the same data [16]. The rest of this paper is organi zed as follows. Section 2 surveys related work. The overview of our approach is presented in Section 3. Then Section 4 and 5 de scribe the details of the SELC Model. Experiments are descri bed in Section 6. Section 7 discusses the experiment results and gives an error analysis. The final section gives conclusions and proposes future work. Document sentiment classificati on methods might be classified into corpus-based methods and lexicon-based methods according to the knowledge they used. The in tegration of these two methods is a new direction. Most corpus-based sentiment classifiers use standard machine learning techniques such as SVM and NBm [5]. Different factors affecting the machine learning process were investigated. For instance, linguistic, statistical and n-gram features are used in [10]. Semantically oriented words are used to identify the polarity at the sentence level in [6]. A graph-based technique is used in [3] to identify and analyze only subjective parts of texts. Selected words and negation phrases were investig ated in [8]. Such approaches work well in situations where large labeled corpora are available for training. But the performance of corpus-bas ed methods generally decreases when training data is insuffici ent or acquired from a different domain [2] [9], topic [9] or time period [9]. To solve that problem, unsuperv ised and weakly supervised methods can be used to take advantage of a small number of annotated in-domain examples a nd/or unlabelled in-domain data. For instance, the method of [2] trains a model on a small number of labeled examples and large quantities of unlabelled in-domain data. In [11], structural correspondence learning is applied to the task of domain adaptation for se ntiment classification of product reviews. Similarly, the authors of [14] suggested combining out-of-domain labeled examples with unlabelled ones from the target domain in order to solve the domai n-transfer problem. So far, the performance of such methods is inferior to the supervised approaches with in-domain training. Lexicon-based methods are usually unsupervised. Some of them use general sentiment word lists acquired from the Internet or dictionaries. It is showed in [4] that lexicon-based methods perform worse than statistical m odels built on sufficiently large training sets in the movie review domain. [12] shows that the performance of systems using general word lists is comparable to that of supervised machine lear ning approaches on some domains such as product reviews. Other methods use seed words to replace the word list, and then enrich the seed words by more sentiment words and phrases. For instance, the method in [13] uses two human-selected seed words ( poor and excellent ) in conjunction with a very large text corpus. The semantic orientation of phr ases is computed as their association with the seed words (measured by point-wise mutual information). The sentiment of a document is calculated as the average semantic orientation of all such phrases. In [16], seed words are automatically generate d based on a linguistic pattern, which is called negated adverbial construction . Experimental results show that this method achieves similar performance to supervised methods. In [1], a corpus-based classifier trained on a small set of annotated in-domain data is integrated with a lexicon-based system trained on WordNet . The experiments show that the hybrid method brings significant gains in accuracy and recall over both the individual corpus-based and lexicon-based method. Although the approach is very promising, it still requires a certain amount of annotated corpus and therefore a supervised method in essence. Moreover, their experiments are conducted on a corpus with equal number of positive and negative examples. The effectiveness of their approach on unbalanced dataset still needs to be verified. The complementation property of corpus-based and lexicon-based methods, i.e., one classifier make s an error, while the other one gives the correct answer, was initially exploited in [1]. However, the reason behind this phenomenon was not revealed. Here we attempt to give an explanation. In many cases, people are accustom ed to directly use positive or negative words to express their positive or negative sentiment. This is referred to as direct sentiment expression . However, in many other cases, people convey positive feeling with negative words and convey negative feeling with positive words, with the help of negative constructions . This is referred to as indirect sentiment expression . Between the two kinds of indirect sentiment expression, conveying negative feeling with positive words in negative constructions is more popular. This is referred to as indirect expression of negative sentiment (IENS). For instance, in most cases, people say  X  X  X  bu-hao  X  not good X  to express unsatisfactory feeling and say  X  X  X  X  bu-tai-gao  X  not very tall X  to convey similar meaning with  X  ai  X  short X  . As shown in Table 1, the frequency of IENS (3,554), is much higher than that of the indirect expression of positive sentiment in Chinese (616) and is very close to that of the direct expression of negative sentiment. The popularity of IENS is just th e reason of the former difference between corpus-based methods and lexicon-based methods. In lexicon-based methods, the polarities of words are assigned in a dictionary in advance. IENS means that positive words are used frequently even in negative documents but negative words are scarcely used in positive documen ts. Therefore, positive words sometimes predominate even in negative documents, and therefore lexicon-based methods are apt to classify a document as positive. To improve the result of lexicon-based methods, more constraints for classifying a docum ent as positive should be added. For instance, the negation constructions used in [16] is such kind of constraints. In corpus-based methods, the polarities of words are learned automatically by machine learning methods. Since both negative words and positive words might be frequently used to convey negative sentiment, yet only positive words are frequently used to convey positive sentiment, it is eas y for a corpus-based method to learn negative expressions. Theref ore, corpus-based methods are apt to classify a document as negative. The SELC Model is proposed to exploit the complementarities between lexicon-based and corpus -based methods to improve the whole performance. This model cons ists of two phases. In Figure 1, Phase 1 blocks are grouped in the solid-line frame and Phase 2 blocks in the dash-line frame. Phase 1 is a lexicon-based iterative process. In this phase, a sentiment vocabulary is initialized by a general sentiment dictionary. The vocabulary is used to classify reviews. Then more sentiment words are found from the classified reviews and update the vocabulary. The new vocabulary then helps classify more reviews. By this iterative process, the vocabulary and classified reviews are updated (and generally enlarged) step by step. In the iterative process, a new technology, i.e., positive/negative ratio control, is introduced. That control ranks the reviews and keeps the same number of top-ranked positive and negative reviews in each iteration. Because of the ratio control, the iterative process completes when the set of classified positive or negative reviews does not enlarge any more. All the reviews having been classified at this point form the Classified Set (part A in Figure 1). There are still some reviews left unclassified, which compose the Uncertain Set . Then current vocabulary is used to classify the reviews of Uncertain Set without ratio control. No iteration either. The result is marked as part B in Figure 1. supervised model and the results of Phase 1. In Phase 2, the The statistical data are got from 7,792 Chinese product reviews. supervised model (SVM in Figure 1) takes the Classified Set as training data. The achieved model is then used to classify the reviews of Uncertain Set . The supervised model only applies on the Uncertain Set , but not the whole set of reviews, because the Uncertain Set is not classified as well as those reviews in the Classified Set , where ratio control makes a strict restriction and therefore keeps a high precision. That is also the reason of the model, even though the data is m achine-classified, but not human-labeled. Finally, the results of the corpus-based model are integrated with the results of Phase 1 (part C of Figure 1). Phase 1 can be used independently. It is referred to as the Basic SELC Model. The result of the Basic SELC Model is A and B part in Figure 1. Accordingly, the complete model is referred to as the Standard SELC Model, whic h is abbreviated as the SELC Model. The result of the SELC Mode l is A and C part in Figure 1. The details of the two phases are described in the following two sections. Based on a Chinese sentiment dictionary and a negation list, Phase 1 of the SELC Model uses an iterative process to enlarge the sentiment vocabulary and improve overall accuracy mutually and gradually. Phase 1 includes six steps, which are introduced in the following. The sentiment vocabulary, denoted by V sen , includes a list of items, each of which is assigned with a sentiment score. V initialized by a sentiment dictionary, which usually includes a lot of positive and negative words. A positive word is assigned with score +1, while a negative word is assigned with score -1. Monosyllabic words are filtered from V sen because most of them are too ambiguous to provide reliable sentiment. First, each review is divided in to zones by punctuation marks. Second, for a zone, each item in current V sen is checked occurring in the zone or not. If an item does occur in the zone, it is taken as an effective item of the zone. Third, each effective item of a zone is scored by Equation (1), current zone, S d is the item X  X  score in current V negation check coefficient with a default value of 1. If the lexical item is preceded by a negation within the current zone, N -1. Then the scores of all the effective items of a zone are summed up as ZoneScore (the sentiment scor e of the zone). If the ZoneScore ZoneScore of a zone is smaller than zero, it is classified as negative. Otherwise, it is left unclassified. Finally, the scores of all zones in each review are summed up as ReviewScore (the sentiment score of a review). 2 Sort all reviews in descending order by their 3 Tagging: Figure 2 Review Sentiment Classification with Ratio Control Basically, a review is classified as positive if its ReviewScore is greater than zero, or negative if its ReviewScore smaller than zero. This policy looks good but would cau se sentiment bias for items. In each iteration process, since there are generally different numbers of positive and negative reviews, the strength of sentiment polarity of items may be biased. For example, if there are 20 positive reviews and 10 negative reviews, and the word  X  X  X  occurs in all the 30 reviews, it w ill have a sentiment score of 10, and be judged as a positive item. But in fact, such a word may have no sentiment polarity. To overcome the bias caused by unequal number of positive and negative reviews, a ratio control is introduced. It requires the numbers of positive and negative reviews classified in each iteration to be the same. Denote the number of reviews with a positive ReviewScore as C positive number of reviews with a negative ReviewScore as C negative review sentiment classification with ratio control is realized in the following way (see Figure 2). The sentiment vocabulary V sen is updated (and usually enlarged) classified reviews is taken as a candidate item. The difference between each candidate item acting as a positive item and a negative item are measured by Equation (2). F p and F n denote the frequencies of the candidate item in positive reviews and negative reviews respectively. If the item is preceded by a negation in current zone and the current re view is positive, its corresponding frequency F p is reduced by one, or vice versa. Therefore, the value of F p and F n might be a negative number. Only when the difference is evident enough, the candidate item difference score is not less than 1, it can be added into V Notice that those items occurring only in positive (or negative) reviews can be included in V sen , as their difference score is 1. Then the sentiment score of each item in V sen is recalculated according to Equation (3). This step is used to determ ine when the iterative process completes. If there is no difference in the classification result between two iterations, the iterativ e process completes. When the iteration process completes, the system goes to the Uncertain Set Processing Step. Otherwise, it goe s to Step 1 and a new iteration starts. For an unclassified review R, 1 If ZC positive &gt; ZC negative , R is tagged positive. 2 Else if ZC positive &lt; ZC negative , R is tagged negative. 3 Else: The ratio control requires the numbers of negative and positive documents to be equal in the ite ration process. Therefore, when the iteration retraining completes, there are still a few reviews left unclassified. Denote the number of positive zones in a document as ZC positive and the number of negative zones in a review as ZC negative . Denote the review to be classified as R. Then, the Let N be the length of a zone, a lexical item is a sequence of 
Chinese characters excluding punctuation marks, from unigram to N-gram, in an enclosing zone. reviews of Uncertain Set are classified in the following way (see Figure 3). We choose SVM as the machine-learning method to implement the corpus-based supervised me thod. The model uses a general sentiment dictionary as the feature set. TFIDF measure (see Equation (4)) is used to compute weights. This phase is specially designed to process reviews in the Uncertain Set . In this phase, the results of the corpus-based model (CB result) and the results of th e first phase (LB result, Lexicon-Based result) are integrated together. As mentioned in Section 3, the lexicon-based model classifies most reviews and left some reviews as the Uncertain Set when the iterative process completes. The corpus-based model takes those classified reviews as training data and those reviews in the Uncertain Set as test data. Because of the positive classification bias of lexicon-based methods a nd the negative classification bias of corpus-based methods (see S ection 1), lexicon-based methods usually can achieve high precision on negative reviews while corpus-based methods usually can achieve high precision on positive reviews. Therefore, the two kinds of results are integrated in the following way (see Figure 4). 
Given a review, 1 If the two results were the same, they would be taken as 2 Else if the LB result were negative, it would be taken as 3 Else the CB result would be taken as the final result.
 The experiments in this paper we re conducted on the data sets of 7,779 product reviews written in Chinese. All the reviews concern with ten domains (sub-corpora 3 ): Monitors, Mobile phones, Digital Cameras, MP3 players, Computers parts, Video cameras and lenses, Networking, Office e quipment, Printers, Computer peripherals. In the following, they are indexed as C1 to C10 respectively. Each sub-corpus has equal number of positive and negative reviews. For all the experiments in this paper, the HowNet Sentiment Dictionary 4 is used as the sentiment dictionary. The dictionary contains 4566 positive words and 4370 negative words. It is provided by Zagibalov and Carroll (http://www.informatics.sussex. ac.uk/users/tz21/coling08.zip) http://www.keenage.com/download/sentiment.rar WEKA 3.4.11 (http://www.cs.waikato.ac.nz/  X  ml/weka ) is used as the implementation of S upport Vector Machine (SVM) classifiers. The result reported in [16] (see left column of Table 2) is taken as the baseline of SELC. The overall F 1 -score is 82.72% in [16], and the standard deviation of the F 1 -scores on ten sub-corpora is 5.22%. In Step 1 and Step 3 of Phase 1, an enlarged negation word list containing ten negations is used: {  X  bu  X  not  X ,  X  would not  X ,  X  X  X  mei-you  X  don X  X  have  X ,  X  mei  X  don X  X  have  X ,  X  sui-ran  X  although  X ,  X  sui  X  although  X ,  X  X  jin-guan  X  although  X  X ,  X  que  X  don X  X  have  X ,  X  X  X  que-fa  X  don X  X  have  X ,  X  don X  X  have  X  X . The results of the Basic SELC Model are shown in the right column of Table 2. It achieves an overall F 1 -score of 88.62%, which improves 5.90% over the base line. The standard deviation of the F 1 -scores on ten sub-corpora is only 2.35%, which improves 2.87% over the baseline. The drop on the standard deviation shows that the Basi c SELC Method is more domain-independent than the baseline. Moreover, the average iteration number of the Basic SELC Model is 5.6, with a decrease of 5.9 over that of [16] (11.5). Table 2 Comparison between baseline and Basic SELC Model As mentioned in Section 4.7, there are several novel aspects in the Basic SELC Model, which affect the performance simultaneously. To check their individual effect, three variant models were implemented. They are referred to as V1, V2 and V3 respectively. In V1, the ratio control is removed. In V2, the HowNet Sentiment Dictionary is replaced by the seed set automatically generated in [16]. In V3, the ten negations are replaced by the six negations of [16]. Table 3 shows that both the ratio control and the HowNet Sentiment Dictionary take great effect on the performance, i.e., improving 13.40% and 6.52% F 1 -score respectively. The enlargement of negation word list also improves 1.14% F 1 Table 3 The Results of Three Variants of the Basic SELC We implement a classifier base d on SVM, taking the words in HowNet Sentiment Dictionaries as features. This is referred to as SVM-HowNet classifiers. The Basic SELC Model without the Uncertain Set Processing Step is referred to as the Basic SELC* Model ( X  X  X  part of Figure 1). The results of the Basic SELC* Model, the Basic SELC Model and SVM-HowNet classifier on negative and positive reviews are shown in Table 4. The Basic SELC* Model achieves similar precisions on negative and positive reviews (93.51% and 92.95%). It shows that the novel technologies in this model have effectively overcome the positive classification bias of lexicon-based methods. However, for the Basic SELC Model, the differen ce of precision is still evident between on negative reviews (93.14%) and positive reviews (85.71%). The bias is mainly caused by the processing of Uncertain Set . The results of the SVM-HowNet classifier in 10-fold cross-validation mode are also shown in Table 4. Those results fit for the analysis in Section 1. That is, a corpus-based classifier tends to classify a review as negative (with higher precision on positive reviews (88.96%) and higher reca ll on negative reviews (89.43%) respectively). Table 5 shows the results of th e Basic SELC Model, the SVM-HowNet classifier and their integrated results on Unclassified Set. It shows that the integrated results improve 7.71% and 12.15% over the SVM-classifier and the Basic SELC Model respectively. The improvement is appreciable. However, since the SVM-classifier only applies on the Uncertain Set , which only takes a small proportion (about 9%) of the entire set, the overall improvement of the SELC Mode l is not so prominent. The SELC Model achieves an overall F 1 -score of 89.35% (see Table 6), with an improvement of 6.63% over the baseline (82.72% of [16]) and 0.73% over the Basic SELC Model (88.62% in Table 2). Table 4 Results of the Basic SELC* Model, the Basic SELC Model and SVM-HowNet Classifier on Negative and Positive Table 5 Results of the Basic SELC Model, SVM-HowNet Classifier and Their Integrated Results on Uncertain Set The corpus used in the above expe riments consists of half positive documents and half negative docum ents, i.e., the positive/negative ratio is 1:1. That is the usual way of corpus construction [1, 4, 7 16]. But that is not always the state of real-world data, in which positive reviews might predominate and even take a proportion of more than 80% [16]. Therefore, corpora with positive/negative ratio of 6:4, 7:3 and 8:2 are constructed respectively based on the 1:1 corpus. For instance, in the 6:4 case, one third of the negative reviews are randomly selected and removed. The results (Table 7) show that both the Basic SELC Model and HUCL Mode l perform consistently well on the three cases (with an F 1 -score between 86.68% and 89.70%). Model on Corpora with Different Ratios between Positive and A set of factors involved in the Basic SELC Model enables substantial performance gains. A ll those factors contribute to overcome the positive classifica tion bias of lexicon-based methods. First, the ratio control is introduced into the iteration process. The ratio control can help balance the negative/positive items in the iteration process. For instance, if the ratio of positive documents is too large, accordi ngly, the ratio of positive items will also increase. In such a cas e, the ratio control can decrease the increasing speed of positive words and therefore help overcome the positive classifica tion bias of lexicon-based methods. Second, in the Initiation Step, a general sentiment dictionary is used to replace a seed set generated automatically (see [16]). A seed set usually contains a small number of words while a dictionary contains a lot of word s. By introducing more sentiment step and propagated in the following iterations. In addition, a seed set may not balance between positive and negative words. For example, the seed set generated in [16] only contains positive words but no negative words. Thus, negation words like  X  not  X  are relied on to judge negativ e reviews. However, negation words are ambiguous some times. For example,  X  X  X  X  X  X  X  X  X  X  bu-zhi-dao-shi-fou-qing-chu  X  do not know whether it is clear or not  X  is not the same as  X  X  X  X  bu-qing-chu  X  not clear  X . Since a general dictionary contains a lot of negative words, the dependence on negation words is much decreased. Third, among the ten negations,  X  X  X  ,  X  ,  X  X  X  and similar meaning with  X  .  X  X  X  ,  X  and  X  X  are conjunctions them transform the sentiment of the following words to their opposite. Six negations are used in [16]: {  X  ,  X  X  X  bai-tuo  X  get rid of  X ,  X  X  X  mian-qu  X  excuse  X ,  X  X  X  bi-mian  X  avoid  X  X . But only three of them,  X  ,  X  X  X  and  X  X  X  , are negation words. The remaining three words  X  X  X  ,  X  X  X  and  X  X  X  usually directly convey negative sentiment, but not transform the sentiment of their following words. As the negation list is enlarged properly, the chances of classifying a review as negative increases accordingly. Therefore, this change also helps overcome the positive classification bias of lexicon-based methods.
 In Phase 2, the utilization of supervised method further improves the overall performance. Although the training data used in Phase 2 is tagged automatically in Phase 1, the supervised method performs effectively because of the high precision of the result of Phase 1. Most of the errors are caused by ambiguous sentiment words such as  X  duo  X  many  X  and  X  shao  X  few X  . The sentiments of those words usually vary within different contexts. For instance,  X  you-dian-duo  X  many advantages  X  conveys positive sentiment but  X  X  X  X  que-dian-duo  X  many shortcomings  X  conveys negative sentiment. Longer context generally causes more errors. This paper contributes to the res earch on sentiment classification, domain adaptation and the development of ensembles of complementary classifiers, esp ecially on product reviews written in Chinese. Specifically, we (1) propose a novel ensemble approach (the SELC Model), wh ich successfully integrates a corpus-based model with a lexi con-based approach, (2) present several strategies to overcome th e positive classification bias of lexicon-based methods, including the use of a positive/negative sentiment dictionary to replace a seed word set generated automatically, and the enlargement of negation word list. Experiments show the effectiveness of the SELC Model. Moreover, the standard deviation of F1-scores on ten domains is reduced, which shows that the SELC Model could be more suitable for domain-independent sentiment classification. Although our method achieves signi ficant improvement over the previous study, there are still several other avenues that might be explored in future work. First, the use of linguistic knowledge in sentiment classification needs further study. There are many complicated constructions involve d in the indirection expression of negative sentiment, and negati on word is only one kind of them. For instance, the verb  X  X  X  shi-xian  X  achieve  X  usually conveys positive sentiment and  X  X  X  bi-mian  X  avoid  X  negative sentiment, but they are not considered as sentiment words in most sentiment dictionaries. Second, although e xperiments were conducted only on Chinese corpus in this pa per, our model is language-independent theoretically. Therefore, we attempt to apply the model on corpus in other languages. [1] Alina Andreevskaia and Sabine Bergler. 2008. When [2] Anthony Aue and Michael Gamon. 2005. Customizing [3] Bo Pang and Lilian Lee. 2004. A sentiment education: [4] Bo Pang, Lilian Lee, and Shrivakumar Vaithyanathan. 2002. [5] Ethem Alpaydin. 2004. Introduction to Machine Learning . [6] H. Yu and V. Hatzivassil oglou. 2003. Towards Answering [7] Hang Cui, Vibhu Mittal, and Mayur Datar. 2006. [8] J.C Na, H. Sui, C. Khoo, S. Chan, &amp; Y. Zhou. 2004. [9] Jonathon Read. 2005. Usi ng emoticons to reduce [10] Kushal Dave, Steve Lawren ce, and David M. Pennock. [11] Mark Drezde, John Blitzer, and Fernando Pereira. 2007. [12] Michael Gamon and Anthony Aue. 2005. Automatic [13] Peter Turney. 2002. Thumbs up or thumbs down? Semantic [14] Songbo Tan, Gaowei Wu, Huifeng Tang, and Zueqi Cheng. [15] Taras Zagibalov and John Ca rroll. 2008a. Unsupervised [16] Taras Zagibalov and John Ca rroll. 2008b. Automatic Seed 
