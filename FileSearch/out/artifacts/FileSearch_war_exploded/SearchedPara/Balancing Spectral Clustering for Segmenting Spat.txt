
In most cases, the behavior of a multi-agent system is built up from independent, smaller components. Segment-ing complex joint behaviors of multi-agent systems into such smaller, independent elements is of utmost importance since such segmentation can be used for automatic plan ex-traction, plan recognition or subgoal selection in learning tasks. Identifying the boundaries between these elements is not trivial, as the observations tend to be noisy and usually the amount of available data is immense, and it is unclear how to steer between separating data into chunks separated in time, or splitting the data in the space of the parameters.
Clustering provides a way to form boundaries be-tween components through similarities between observa-tions. When compared to statistical approaches, this has the advantage that we can work even on a single data set. Collected data about multi-agent systems are frequently in the spatial domain, like in the case of robotic teams (like the popular RoboCup), observations of CCTV cameras or computer games. An emerging approach to clustering is spectral clustering [14, 9, 1], which is shown to be able to catch human impression about grouping two-dimensional point formations very efficiently [14, 18]. Spectral cluster-ing is also appealing because it is related to manifold learn-ing [6, 4], which is about finding low-dimensional repre-sentations of data along geometrical constraints. We may expect that spatial multi-agent behavior is subject to such constraints and therefore manifold learning may be able to reduce dimensions effectively. Based on the convincing perceptual grouping performance of the algorithm, spectral clustering is a good start for finding spatial groups in data collected about multi-agent systems. However, it is still an open question how to extend the clustering into the temporal domain in a plausible manner.
If u and v are points in the full set V to be clustered, the point-to-point similarities form the N  X  N sized w ( u, v ) affinity matrix if we have N points to cluster. Spectral clus-tering concerns the minimal normalized cut of the affinity graph, which is the graph corresponding to the affinity ma-trix with edge weights defined between points u and v as w ( u, v ) [14]. If the set of graph nodes, noted by V ,areto be cut into two separated sets A and B , the normalized cut is defined as follows: NCUT ( A, B )= where Since V = A B and A B =  X  , ASSOC ( A, V )= ASSOC ( A, B )+ ASSOC ( A, A ) .Inotherwords, normalized cuts are trying to find cuts of the graph where the ASSOC ( A, B ) cut value is minimal, but the ASSOC ( A, A ) intra-cluster affinities of the two sets are maximal. Normalized cuts are superior to minimum cut ap-proaches because they take into consideration the intra-set dependencies as well.

It was shown that the eigenvector decomposition of the affinity matrix can be used for finding approximate solu-tions to the NP-complete minimal normalized cut problem [14]. This is why this method is called spectral cluster-ing. As explained by Markov random walks [6], when one considers only the first few eigenvectors of this decompo-sition, the number of eigenvectors retained can be seen as a scaling parameter to the clu stering. Other recent works showed that spectral clustering is deeply connected to non-linear dimensionality reduction methods like ISOMAP or locally linear embedding (see [13] for a review) or kernel PCA methods [2], and can be seen as a method searching for block-diagonal groupings of the affinity matrix [3].
The simplest way to extend any clustering method into time is to cluster points with time added as an extra dimen-sion. In the case of multi-agent systems these points form observations of individual agents, which are in the form of u :( s u ,t u ) ,whereand s u is an agent X  X  spatial position and t is the time when the observation was made.
 The original spectral clustering approaches typically use Gaussian affinities over the points to be clustered [14, 18]: where d ( u, v ) is the Euclidean distance between points u and v and  X  is a scaling parameter. H owever, treating time and space uniformly may lead to undesired consequences as the structure of the data is usually different in these di-mensions. In real-life problems we usually record data with much better resolution in space than in time. Observations of agents tend to form relatively sparsely placed  X  X hreads X  lying along the temporal axis, o r separated  X  X eedles X  lying along the spatial axis depending on how we convert seconds into meters. Thus we recommend using different  X  S and  X  T scaling parameters for space and time:
We also have different expectations about how spatial and temporal clusters should change when the circum-stances of the data recording is changing. We desire the same clusters to form when the same behavior is shown on different spatial and temporal scales or the behavior is spatially rotated, as the internal structure of the behavior remains the same. Data recording usually samples obser-vations at predefined intervals, so the problem of tempo-ral scaling is even more intricate, as replay speeds does not only affect the distance of observations, but the temporal density of observations as well. This influences the outcome of the clustering as densely populated graphs are harder to cut. From the behavioral per spective, this means that the segmented behaviors tend to change by the sampling rate of the data, which is not desirable.

A solution for the scaling problem was proposed in [18] where the distance of local neighbors was used as a local scaling parameter, although it is not capable of dealing with the other issues arising in the behavioral context. In this paper we suggest making spectral clustering invariant to these measures by using hierarchical subdivision and pre-processing the data before each step. This in turn implies that we cannot use a single eigenvector decomposition any-more to extract all the clusters together. Instead, we cut only once then we pre-process again the resulting two clusters. This modification increases the computational requirements up to a constant factor only (which is the number of clusters we want to extract). Shi and Malik recommended doing it-erative subdivision in their original paper as the approxima-tion of the normalized cut problem is the best when using the first two eigenvectors only [14], however, most works on this field exploit the first eigenvectors together to esti-mate all clusters in one step. Recently other bi-partitioning spectral approaches were also proposed [8, 12].

Before applying the normalized cut, we spatially rescale the observations into a unit diameter circle centered at x = 0 ,y =0 . The scaling factor is determined by the largest spatial distance between the observations. This makes the clustering invariant to spatial rotation and scaling, as the affinity measure is invariant to rotations. To counter the problem of varying sampling frequency, we define a default temporal sample number N T in time. We rescale the clus-ter into the 0..1 temporal domain and resample each trajec-tory to contain observations only at the k/ ( N T  X  1) ,k  X  0 ..N T  X  1 time instances. Resampling is done by linear interpolation of the closest observations of the same agent.
This step also helps with reducing the computational com-plexity as N T is usually much smaller than the number of observations in each trajectory. It also helps with smooth-ing the data, which in turn will have a more fitting tempo-ral resolution for the current cut. After the preprocessing step the clusters are similarly bounded in space and time and has a uniform sampling frequency 1 . This similarity be-tween clusters makes the value of normalised cuts directly comparable, thus we can always advance with the iterative subdivision at that available cluster where the normalized cut X  X  value is minimal.
 tering temporal if the cut mainly includes edges that only connect observations which have different temporal value (but belong to the same agent), and spatial if the cut has mostly edges which belong to different agents at the same time. We now have the problem of choosing  X  T and  X  S appropriately to balance spatial and temporal normalized cuts. Obviously they cannot be set to arbitrary values as atoosmall  X  T paired with a large  X  S will make the algo-rithm prefer exclusively temporal cuts and vice versa. As we fixed the number of temporal observations in the graph by defining N T , setting  X  T to a proper value is easy, as it depends on the neighborhood density of each observation in time, which is constant. It is then reasonable if we search for  X  S as a function of N T and  X  T .
 ine a case where we expect the spatial/temporal normal-ized cuts X  value to be the same (that is, we do not prefer either of them). This balance depends on the relation be-tween the expected spatial density of observations and the (already fixed) temporal density of observations, although it is unclear how the expected spatial density depends on  X  S .
Therefore we determine a minimal desired spatial group size N S which characterize the number of agents which is required to form a group when they are lined up, and try to calculate  X  S according to this measure. Assuming these agents standing still, we can place the observations into a N
T  X  N S grid. Balancing requires choosing  X  S in a way that the value of spatial and temporal normalized cuts is the same in this grid-shaped graph which represents our sce-nario (Fig. 1).
 both even. Because of symmetry reasons a spatial normal-ized cut will split this graph exactly at the middle of group.
Alternatively, if a temporal normalized cut is done, it is go-ing to be made at the halving time of the time range of all observations. Both cases imply that the two terms of Eq. 1 is equal. Let us concentrate on temporal cuts first. If we define y T =exp(  X  1 /N 2 T  X  2 T ) and y S =exp(  X  1 /N 2 S  X  2 S ) ,
Figure 1. The scenario for balancing spatial and temporal cuts. The grid illustrates the positions of observations where N S agents are standing in a line and this situation is ob-served through N T time points. The affinity matrix is formed between all the grid points.

The two sets belonging to temporal cuts are marked by A and B , while the sets marked by
A and B in the case of spatial cuts. the sum of intra-cluster weights can be written as ASSOC ( A, A )= ASSOC ( B, B )= while the (non-normalized) cut value is ASSOC ( A, B )= Using these equations in Eq. 1 results in where and thus NCUT T ( A, B ) does not depend on the spatial scaling. Eqs. 6 and 7 can be rewritten by counting the number of | t  X  t | occurences: and term is larger with at least an y ( N T / 2) 2 T factor, and as y T &lt; 1 , we expect it to be small. Putting Eqs. 8 and 9 into Eq. 5 and neglecting a small constant in the denominator we have the approximation for NCUT T ( A, B ) . We can replace the sums with Gaus-sian integrals if y T is small and N T is large enough: and poral normalized cut value. The same steps can be made for the NCUT S ( A ,B ) spatial normalized cut with re-placing all T indices with S and the other way around. NCUT T ( A, B )= NCUT S ( A ,B ) yields in a rule for setting  X  S with respect to the N T ,N S , X  T parameters: where expected. To summarize, we replaced  X  S with N S ,whichis the expected minimum group di ameter and is much easier to determine in a given practical problem. Groups contain-ing more than N T agents in a line are easier to cut tempo-rally, while groups of lower density are easier to separate spatially. The full algorithm X  X  pseudocode is shown in Al-gorithm 1.
 Algorithm 1 Spatio-temporally bala nced spectral cluster-ing Require: N T ,N S , X  T parameters, M number of clusters, D initial set of observations. Returns M clusters. Set  X  S according to Eq. 13
Cut D to determine its children and cutting cost put D into the L list of produced clusters for M times do end for output children of S  X  L clusters for which S was not yet selected for cut
Recording agent positions only are not enough for catch-ing all behavioral aspects of a multi-agent system. We may assume that a log of events is also available, which can be seen as a history of low-level interactions. We may assume that each event has a relative importance measure and we know the participants of that event. For example, in the case of a strategic computer game, we may assume that we can record when a unit fires at an enemy and who this en-emy was. In most problems lots of similar low-level events are possible to define, and a human expert can set a relative importance to each of these events in quite a natural way.
Infusing events of different importance into spectral clustering can be done by exploiting the fact that the affin-ity measure is only required to be symmetric and positive: we simply increase the affinity connecting the observations of the event to a higher value. We also know that affinities created by Eq. (4) are falling between 0 and 1 , therefore we can think of simple spatio-temporal connections as having a value of 1 when scaling event importance. It is reasonable to add a temporal  X  X epth X  to t he event as well, which means setting the affinities to the agents X  next and previous nodes to the importance as well. If we need to superimpose mul-tiple events, we can simply add their importance measures. In our algorithm we transform the events at the preprocess-ing step into the rescaled and resampled set of observations. Having an even spatio-temporal structure helps with defin-ing event importance as they do not need to be rescaled with varying cluster size.
As we are exploring a novel domain of clustering where we could not find publicly available test cases, we decided to generate our own test data and compare the results with our expectations about behavioral changes. We used a real-time strategy game, wh ere human players can move the units according to their commands. Two players and one type of unit was present modeling tanks, which could move and fire. The environment was described with a two-dimensional heightmap. Units fired automatically on the nearest target if they could find any. Human players were able to select target positions for movement for each unit in-dependently. The game accepted commands in a  X  X aused X  state when the flow of time was frozen, thus a human player is able to substitute more players, thus effectively model-ing an full multi-agent system. We created multiple maps and played battles to produce m ulti-agent behavioral data. We used the algorithm described in the previous sections to produce components of behavior. We used the algorithm of [18] to produce the normalized cuts without the auto-matic scaling feature. The following parameters were used: N
T = 100 ,N S =8 , X  T =0 . 01 , while we varied the num-ber of requested clusters according to the scenario played. Spatio-temporal observations were made by 1 update/sec frequency. We defined 4 events: 1. SEE: a unit becomes visible to another one, 2. HIDE: a unit becomes invisible to an other one, 3. FIRE: a unit fires, 4. HURT: a unit X  X  health is decreased by a hit. We assigned an importance of 2 to SEE and HIDE events, while FIRE/HURT got 4.
We created scenarios where the behavior was governed by simple plans, and compared the result of the algorithm on these scenarios with our original intentions. Although these results are somewhat subjective, they give an impres-sion about the cap abilities of the suggested method. We found that with enough (but not too large) number of re-quested clusters the algorithm was always able to detect the boundary we identified as prior spatial or temporal separa-tion. The algorithm in some cases also created false bound-aries, but this is acceptable from the plan recognition view-point as combinations of smaller behaviors can be explored to recognize larger plans.

Figure 2 shows two scenarios, one with different number of clusters requested. 5 blue and 4 red units were placed on the first map. 4 blue units were grouped initially in the upper left corner, 2 red units were placed in the upper right corner, a red unit was placed in to the lower right corner and a red and a blue unit was placed in the lower left corner. The four blue units first engaged the two reds in the upper half of the scene, which resulted in the destruction of both red units and the corresponding loss of a single blue unit. Meanwhile, the red unit in the lower right took a defensive position and the single red and blue units tried to destroy each other in a duel. The three blue units took a right turn and destroyed the defending red one, and joined the last blue unit to destroy the last red one. The scenario had 4399 points to cluster in total. By asking for 4 clusters, it can be seen that the elements of this description are well captured.

In the second scenario 5 blue and 8 red units were placed on different sides of a mountain range. The red units tried to encircle the blue group on the other side by setting up a trap by attacking first by two tanks which later fled; then all red units attacked the blues from all directions. With 3 requested clusters the algorithm was capable of separat-ing the encirclement maneuver, the  X  X rap X  maneuver and the endgame. Further subdivisions split up the initial encircling maneuver of the red units into subparts. Results for 3 and 8 clusters are depicted on the second and third subfigure of Fig. 2.

To compare the algorithm with other approaches, we show on Figure 3 two simple examples where our algorithm can find a proper solution while more traditional methods like vanilla K-means cannot. Sp ectral clustering is able to form non-convex clusters, and this important property re-mains valid when we extend our data with the temporal dimension (Fig. 3(a) and (b)). It is also unclear how to add events to methods based on cluster prototypes like K-means, which can make a cruci al difference when such ad-ditional information is available like in our behavioral iden-tification domain (Fig. 3(c) and (d)).

An important future step for the algorithm would be to determine the optimal number of clusters based on signifi-cant changes in the normalized cut values. It would be also important to adjust the subdivision order regarding to the desired granularity of the clusters. For example, the algo-rithm does not pref er splitting up the e ndgame in the second scenario, as this part contai ns much more events then the initial part.
Regarding computational complexity, the algorithm X  X  hardest part is the eigenvector decomposition, which takes O ( n 3 ) time and O ( n 2 ) space in the most general case, where n is the number of points to be clustered. If we can approximate affinities with sparse structures, the spec-tral clustering algorithm can be kept linear in the number of cluster prototypes, can be extended with extra information like events. points to be clustered [14]. The results shown on Fig. 2 took just a couple of seconds on an average desktop computer to compute with MATLAB.
 related methods) for grouping spatio-temporal actions [16, 10, 5, 11, 17], but all of these are applied to different prob-lem domains, like video segmentation, and therefore do not consider the requirements outlined in the previous sections. For example, [17] clusters the points of spatio-temporal gra-dients of video sequences. This method is not applicable in our case because with taking the derivatives we cannot detect contextual temporal changes (when for example a standing agent plays a role in one group behavior for a time then a different role in a second behavior). Spectral clus-tering has been applied previously for improving learning systems by subgoal selection [7, 15, 19], however, all of these works addressed only the spatial and not the temporal domain. clustering into the temporal domain for breaking up the be-havior of a multi-agent system in space and time. The algo-rithm is invariant against presenting behaviors with different spatial scaling, rotation, replay speed and varying sampling frequency, which is not true for the vanilla spectral cluster-ing algorithm. We provided a way to choose the parameters of the algorithm which balance temporal and spatial sepa-ration based on the expected group size. The ideas were demonstrated with the segmentation of multi-agent behav-ior in a strategic game, where we found that the output of the algorithm coincides with the human-provided segmen-tations. The technique can be used in analyzing multi-agent behavior, for automatic subgoal extraction or may help with plan extraction or recognition. fence through DIF DTC Phase 2 is gratefully acknowl-edged.

