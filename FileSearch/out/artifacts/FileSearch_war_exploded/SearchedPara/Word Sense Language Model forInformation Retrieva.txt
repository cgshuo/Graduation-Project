 Natural languages are inherently full of ambiguity and synonymity. One word can be used in various contexts with different meanings, while dissimilar words may represent a same meaning in certain contexts. The variance of word meanings in natural language has posed problems for the applications related to the Natural Language Processing (NLP).

The field of Information Retrieval (IR) is no exception to this problem. For example, if a retrieval system encountered the word  X  X ank X  in a query, should the system regard the word as the meaning of  X  X ither side of rivers X  or  X  X he place where money is deposited X  ? Besides, a system would perform better if it finds words as  X  X esume X  when a user inputs phrases like  X  X urriculum vitae X . IR systems based on keywords usually suffer from problems out of variance meanings of words.

For that matter, it seems to be reasonable to assume that an IR system will improve its performance if the documents are represented by words and word senses rather than the former only. Besides, word senses, defined in thesaurus, can be viewed as knowledge representation. It is obvious that every thesaurus published owes much to expert staffs of lexicographers, who contribute to refining knowledge of inner connections between words in a language. IR systems must benefit from this kind of knowledge if they make the most of resources like thesauri. Research of years ago focused on this point of using word senses in information retrieval. Classical methods were most based on empirical methods. And some of experiments on disambiguated collection showed a drop in retrieval performance (e.g. [1][2]).

In recent years, language modeling approaches for IR has been prevailing, which are based on statistical models with solid mathematics foundation. Their improvement in performance makes them the state-of-the-art methods in IR evaluations.

In this paper we present a word sense language modeling method, taking word senses into account within a language model framework. The word sense model has a close connection with classic language models but the starting point towards retrieval is diverse. Experiments were conducted using TREC-Mandarin collection and TREC-5/6 topics. The collection was labeled with word sense codes defined in Tongyici Cilin, a well-known Chinese thesaurus in NLP.
The remainder of this paper is organized in this way: Section 2 reviews previ-ous methods using word senses in IR; Section 3 presents the word sense language model; Section 4 and Section 5 describe series of experiments and analysis. Our conclusion on the attempt use of word senses in language model and future work come in Section 6. There has been a lot of work dealing with combination of word sense with infor-mation retrieval.

The first work where a word sense based algorithm was used with an IR system was done by Weiss [3]. He tested the algorithm on five handpicked words in the Aviation Data Internet (ADI) collection. Resolving ambiguities before information retrieval, Weiss showed that he improved performance of his IR system by 1% for the five test words. Krovetz and Croft [2] established more interesting results, giving information about the relation between Word Sense Disambiguation (WSD) and IR. They concluded that WSD did not have a very important impact on IR, but that disambiguation could be beneficial to IR when there were a few words in common between the query and the document. Voorhees [4] presented a method using WordNet to disambiguate word sense for text retrieval. Retrieval experiments comparing the effectiveness of sense-based vectors which are based on IS-A relations contained in WordNet with stem-based vectors show stem-based vectors to be superior overall. Voorhees concludes that the IS-A relation does not fit to word sense selection for IR. In 1994, Mark Sanderson [1] used a technique that introduces additional sense ambiguity into a collection, doing a resea rch that goes beyond previous work in this field to reveal the influence that ambiguity and disambiguation have on a probabilistic IR system. And in late 1990s, O. Uzuner [5] developed a WSD algorithm which will be used in disambiguating natural language queries to an IR system. In 2003, Stokoe et al [6] make a study, exploring the using of word sense disambiguation in retrieval effectiveness and subsequent evaluation of a statistical word sense disambiguation system which demonstrates increased precision from a sense based vector space r etrieval model over traditional tf-idf techniques.

A large amount of work dealing with language modeling for information re-trieval has been done since 1998. The basic approach for using language models for IR assumes that the user has a reasonable ideal of the terms that are likely to appear in the  X  X deal X  document that can satisfy his/her information need, and the query terms the user chooses can distinguish the  X  X deal X  document from the rest of the collection (e.g. [7]). The query is generated as the piece of text rep-resentative of the  X  X deal X  document. The task of the system is then to estimate, for each of the documents in the collection, which is most likely to be the ideal document. Liu et al gives a nice review of statistical language modeling for IR [8]. 3.1 Word Sense Representation When concerning with the word sense, we need to two assumptions [9]: (1) Only one sense of a word is used in each occurrence; (2) Each word has a fixed number of senses.
 It is necessary to find a practical way to represent word senses in IR systems. There are mainly two ways: one is to pick up representative words for word senses and the other is to design a coding system for word sense representation. We follow the latter way. In our system, we use a thesaurus called Tongyici Cilin, which has assigned a unique code to a word sense. For the sake of further discussion, we will describe the details about the thesaurus.
 Tongyici Cilin (Cilin for short) is a well-known Chinese thesaurus in Chinese Natural Language Processing (NLP). It was first published approximately in the 1980 X  X . Cilin contains more than 70,000 of words, all of which are arranged into three-level categories according to the word senses of words. The top level of Cilin consists of 12 main classes, denoted by a single capital letter. The second level of Cilin consists of 94 classes which are labeled by two lowercase letters. At the third level, concepts have been classified into 1,428 classes named after two-bit numbers as the labels. Information Retrieval Laboratory (IR-Lab, HIT) extended Cilin from three levels to five levels with more than 30,000 old words replaced or added (see Figure 3.1). The fourth level in the latest version has been extended for concept clusters, labeled b y a single capital letter, for words with closer meaning compared to the third level. The deepest level in which words are nearly synonyms stands for atomic concepts. As a whole, every word sense can be coded uniquely within a tree structure. Our work has been based on the extended version of Cilin.
 Every word sense has been assigned an eight-bit code for five levels. Look at Table 1. It defines bits and symbols for each level. There are three extra flags at eighth bit of codes for future extension. All the words in the same class of the fifth level category can be regarded as of similar meaning. For example, given the word  X   X  X   X  (xiaoshi/hour), we can find the synonyms such as  X   X   X   X  (zhongdian/hour),  X   X  X  X   X  (zhongtou/hour) and  X   X   X  (shi/time or time unit).
Three-level codes of word sense in the thesaurus Cilin are usually used for labeling because this level is a balance of similar meanings and distinguishable characteristics. Figure 2 is an example of a tagged sentence with word sense codes in Cilin:
In other languages, similar forms of word sense codes for synonyms in thesauri are available, such as Roger X  X  Thesaurus, WordNet and the like. Those codes, though differ from code form or definition of Cilin mentioned above, can also work in applications of word sense language model for IR. It is just like that the language models work on both English words and Chinese words. 3.2 The Word Sense Language Model In the language modeling approaches to information retrieval, it is a common way to estimate multinomial models over terms for each document D in the collection C , the whole set of documents to be searched. Given a query Q ,documentsare ranked respect to the probability that P ( Q | D ) could be observed as a sample from the document D models. The word sense language model goes further. It takes the procedure of retrieval as a two-stage generation: (1) a sequence of word sense representation is generated; (2) each word sense representation produces respective words in the query.

The procedure goes as a natural way. In language modeling for IR, the query is usually viewed as a specific representation of a user X  X  information need. We assume that the user constructs a query in two steps: he or she forms meanings of the information need in the mind first and then choose proper words and expressions in order to write out exact query phrases or paragraphs. The word sense retrieval model follows as the user X  X  way by calculating the probability of a document generating the query at the word sense level first and then probability from senses to query words.

The model calculates the probability of by covering all possible word sense tagging forms: where S stands for any possible word sense resolution schemas.

It is nearly impossible to enumerate all possible schemas in (1) to calculate the probability and difficult to estimate so many parameters. One assumption would simply this model [10]: following the common practice in statistical language modeling, we can assume that there exists a primary word sense resolution which dominates the sum over all possible resolutions. We will just use S representing S  X  for simplicity below. The equation (1) can be approximately simplified as follows: such that S  X  =argmax
We can find that equation (2) is consist of two parts: one is the language model of word sense codes P ( S | D ) and the other P ( Q | S, D ) is a model describing the generation of query Q given a word sense resolution S and documents D .
Since there has been a large amount of work dealing with language models in information retrieval, any reasonable language model in IR could be applied in modeling on word sense codes. One of the most popular language models for IR is based on an assumption that each term is dependent on previous terms, which is also called history. Let S be the word sense code sequence for query Q where s i is the i th word sense code corresponding to the i th word in Q .Then the word sense code language model can be rewritten as:
If the history is limited as size N with a Markov assumption, the equations can be approximated as follows:
When concerning with the generation model P ( S | D ), we make an assumption that every word sense generates a term independently. Following that assump-tion, the model can be rewritten as:
Thus by combining two models (4) (5), we get the ranking strategy function based on word sense language model:
Usually, a logarithm form is needed:
In later experiment, we carried out a unigram model of P ( S | D ), which yields: 3.3 Compare with Other Models In this section, we will discuss differences and similarities between the word sense language model and some of previo usly proposed retrieval models based on language modeling.

The word sense language model is different from traditional approaches in IR based on word senses. Most of these approaches focus on disambiguates of word senses with a vector space model, retrieving on sense codes compared with those on words. The weighing strategies are usually empirical. Our model, based on language model, provides a combination within a statistical model.

Our model has a close with recent language modeling approaches for IR such as translation model and dependency language model for IR.
If we take the procedure from a word sense to a concrete word as a translation progress, our model is quite similar with translation model for IR proposed by A. Berger in [11]. But the start point is different. Berger viewed the information retrieval as a translation from documents to query, the modeling of which needs to estimate translation probabilities between terms in the same language. The estimation proves to be hard because it is necessary to provide a large enough corpus, which must include sufficient information on synonymies and related words, for training parameters. The wor d sense language model takes it natural from word senses to words within thesauri. The estimation is relatively easier than translation model because it is easier to label words with sense codes than to find synonymies by hand.
 The word sense language model is also close to dependence language model for IR proposed by Gao et al [10]. But both of the two models work with different starting points and knowledge. The dependence language model uses structural information, such as dependency links , for better performance. The word sense language model makes the most of word senses for both parameters smoothing at the sense level and clustering of synonymies at the generating procedure. Besides, Gao X  X  model aims to capture long distance dependency relations while our model tries to exploit abstract word senses for IR.

The reason why those models are more or less similar is that they are all derivations or modifications of a classic model  X  Hidden Markov Model (HMM), which provides a framework for combining language model with knowledge of linguistics. In equation (3), two main categories of parameters are needed to be estimated as follows. 4.1 Estimating S  X  Recall that S  X  is the most probable resolution of word senses to given sentences or phrases. To determine such resolution, a module of word sense disambiguation (WSD) could be used. Much attention has been paid to the research of WSD, which studies how to select correct word senses within a context. WSD is quite difficult because word senses have to be determined by considering contexts, which is hard to model and analysis. Borrowing methods, we implement a tagger for word sense resolution using Na  X   X ve Bayesian model [12]:
The model was trained with 11,331 hand-labeled sentences. Those sentences are all Chinese and the sense codes are based on three-level codes in Tongyici Cilin  X  the thesaurus introduced above. There are 1,791 words with ambiguous senses in the training data, as shown in Table 2.

In this implement, most words were labeled as the word sense code with the largest probability. The precision of this implement of word sense resolution is 75% approximately. 4.2 Estimating P ( s i | D )and P ( q i | s i ,D ) We use a two-stage smoothing method, one of the state-of-the-art approaches, to estimate the unigram probability [13].  X  P ( s i | D )=(1  X   X  ) P ( s i | D )+  X P ( s i | C ) . =(1  X   X  ) where  X  is a parameter of the Dirichlet distribution, and  X  is a constant discount.
And the equation for generation query terms can be estimated in a similar way: 5.1 Experiment Setup Our experiment is based on a collectio n of Chinese corpus: TREC Mandarin (LDC2000T52). For Chinese track in TREC-5 and TREC-6, the collection of TREC-Mandarin consists of the People X  X  Daily and Xinhua News articles in-cludes 164,761 documents, the volume of which is about 170 MB. Before index-ing, the whole collection will be labeled with word sense codes of Cilin using a tagger trained out of hand-marked word sense corpus, as we mentioned before.
The topics used for evaluation are provided by TREC as well as relevance judgment for test and evaluation of Chinese text retrieval. Topics in Chinese are similar with those in English and other languages in TREC Tracks. Each topic consists of several fields: document number or ID, title, description and narrative. We constructed queries by merging the title, description and part of narrative. 5.2 Results with Labeled Collection We carried out several methods: tf-idf (with words), tf-idf (with word sense codes and words), the word sense language model method and a general language method (unigram) on the labeled collection.

Table 3 shows the results of methods for TREC Mandarin topics 1-54. In the figure we see the eleven point recall/precision results as well as the non-interpolated average preci sion and R-precision.

The results of the first two columns were obtained by using Lemur toolkit. The first column was based on Chinese word s only. We use a module for Chinese word segmentation with an accurate higher than 95%. The experiment of the second column is based on a pair of words and sense code like this form  X  word / sense code  X . From Figure 3.1, two results are shown as  X  X f-idf(word) X  and  X  X f-idf(WS) X , based on words and sense codes with words respectively. They are only baseline results for comparison. It is interesting that the tf-idf based on word sense codes with words performs a little better than results on words only. The reason might be that word sense resolution reduces noisy by labeling a null sense ( X -1 X ) to those out-of-vocabulary terms, such as punctuation and some of unknown words.
Column 3 shows the results based on our model. We implemented a unigram word sense language model in the experiment (named WSLM).

The fourth column is the result of unigram based on words. A unigram lan-guage model for IR [14][15] is used in the experiment for comparison:
From the result in Table 4 and Figure 5.2, we can see that WSLM performs better than tf-idf approaches with 12.56% and 7.62% increases but a little worse than unigram based on words only with 5.82% decrease. We expected that the word sense language model would help improve IR performance due to synonym knowledge and smoothing effect to some extent. But the results turn out to be opposite. After careful analysis, we find one of main reason leading to this result is that incorrect sense resolution has a much deleterious effort on a retrieval performance, causing mismatches of terms in the documents and the query. For example, we explored a few ambiguous words in the 54 topics first. The Chinese word  X   X   X  seems to be an interesting word for case study here. It carries out at least two meanings: (1) among and within something, such as  X   X  X  X   X  ( X  X uring a conference X ); (2) short for China, such as  X   X  X  X  X  X   X  (Sino-America relationships). These two meanings are distinguishable. Therefore, according to the assumption mentioned before that only one sense of a word is used in each occurrence, the word  X   X   X  should be labeled with different codes due to its context. Among the 54 topics, CH12, CH23, CH32, CH33, CH46, CH50 and CH54 contain the ambiguous word and the word sense tagger fails to distinguish senses of it within restricted contexts. Most of the word meaning  X  X hina X  in occurrences were labeled with the former sense as  X  X mong, within and the like X . The case is the same in the collection because we use a same implement of sense tagger. The incorrect resolution results in biased distributions of word senses which cause mismatch between relative documents and the query. It is unrealistic to amend all the incorrectly labeled word senses in such a large collection by hands. If we just modified part of the documents, it can not reflect the real situation in retrieval and yet the real degree of effectiveness of the word sense model. Acute word sense resolution is needed in the word sense language model. 5.3 Results with Combination Does the word sense based method turn out to hinder the process of retrieval only? Though from the compare with unigram language model it cause a minor due to low precision of word sense resolution, it might be unfair to conclude that the model is totally weak and of no use. It is possible that the sense model describes the documents from a different logical view, which can contribute to boost retrieval results. We carry out an experiment, combining two results of language model based on words and word sense codes to a final result using a linear interpolation: where r ( D ) is a normalized rank function of a retrieval model.
 Figure 5.2 shows the combined result. Table 5 presents MAP, P@10 and R-Precision of two models and the combined result separately. Figure 4 shows scores with different  X  . It is interesting to find out that there is relative improvement over both the word sense language model and the unigram language model for retrieval.

From those results, we can see that WSLM provides another logical view towards retrieval, which can be used in boosting retrieval performance rather than hindering. This result shows positive effectiveness of word sense in retrieval. Otherwise, the combination of result must have gone worse.
 We presented a word sense language model for IR. This language model takes word sense codes as sense representation for computing into account, which is able to handle synonymy and reduce data sparseness because diverse words can be treated as a same sense and the space of sense codes is relatively smaller than the space of words. The experiment results show that word sense language model performs better than traditional approaches such as tf-idf based, though a minor decrease on average scores compared to a unigram language model based on words for IR. Close analysis finds that the accurate of word sense resolution highly concerns with the performance of this model. However by dominating two results from word sense language model and unigram, we obtain improvement over either of results. This result indicates that word sense language model and word-based language model views the documents from different aspects, which can boost the retrieval result together.

We hold a belief that information retrieval needs linguistic knowledge to achieve its ultimate goals. From this start point, we explore a method com-bining thesaurus-based knowledge into a statistical model for IR, which is quite different from traditional approaches. In the future we conduct more experiments to seek for the effectiveness of this kind of model. This progress owes much to development and research in natural language processing as well as research in statistical approaches in IR, such as language modeling.
 Acknowledgements. This research has been supported by the National Nat-ural Science Foundation of China via Grant No.60435020, No.60575042 and No.60503072.

