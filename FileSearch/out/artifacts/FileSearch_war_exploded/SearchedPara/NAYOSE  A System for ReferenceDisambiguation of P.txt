 Have you ever had trouble when you have used a common person/place name as a query in a search engine? For example, when you want to know about a person  X  X eorge Bush X  who is not the president but an ordinary person, many pages describing about the president must bring you trouble. According to the circumstances, we have to look for once more which Web page has the informa-tion about the target person/place among too many search results. This problem frequently occurs when the different people (or places, and organization) have the same name. We can find the target Web page, but this often forces us to do hard and time consuming work.

Let us now describe this problem in more detail. Each string appearing as a name on a Web page has a reference to a certain entity in the real world, i.e., each name refers to an entity. A problem occurs when the same name appears on many Web pages, where we do not know whether the same name refers to the same entity or different entities. This problem is the subtask of the co-referencing task [5] in the field of natural language processing. Although it has been recognized in the past, research on it has actively been done in recent years. However, it is not clear whether the previous research is suitable for practical use since most of the experiments were done with artificial data sets.

To rectify this undesirable situation, we considered the NAYOSE System on the Web. NAYOSE means reference disambiguation of names in Japanese. For simplicity, we have described reference disambiguation as NAYOSE in the rest of the paper. Reference disambiguation results in page clusters, which makes an target information accessible. We also propose two algorithms to improve system performance. The system is aimed at practical use. To achieve this, we used real-world data sets that were composed of the top 100 -200 results from search engines. The queries input to search engines were not restricted to person names, as we used some place names in the experiments. As a result of an experiment, we found our proposed method significantly outperformed the baseline by 0.22 in the overall F-measure.

The remainder of this paper is organized as follows. We first discuss related works in Section 2. In Section 3, we define the task and discuss our methodology for solving it. In Section 4, we propose two new methods for disambiguating references, which are Local Context Matching and Named Entities Matching .We describe our system in Section 5, and we show the results of our evaluation in Section 6. We conclude the paper in Section 7. There have been several important works that tried to solve a reference disam-biguation problem. Bagga and Baldwin [1] applied the vector space model to calculating similarity between names using only co-occurring words. Based on this, Niu et al. [6] presented an algorithm using information extraction results in addition to co-occurring words. However, these methods had only been tested on artificial small test data. Therefore, it is doubtful that these methods are suit-able for practical use. Mann and Yarowsky [4] employed a clustering algorithm to generate person clusters based on extracted biographic data. However, this method was also only tested on artificial test data. Wan et al. [7] proposed a sys-tem that rebuilt search results for person names. Their system called WebHawk was aimed at practical use like ours, but their task was somewhat different from ours. Their system was designed for actual frequent queries. Their algorithm for the system was specialized for English per son-name query, consisting of three words: family name, first name, and middle name. They mainly assumed queries into consideration, which may have impr oved accuracy. However, it would not be suitable for other types of names such as those in Japanese (consisting of two words) or place names.

As another approach to this task, Bekkerman and McCallum [2] proposed two methods of finding Web pages referring to a particular person. Their work consists of two distinct mechanisms: the first based on link structure and the second using agglomerative/conglomerative double clustering. However, they fo-cused on disambiguating an existing social network of people, which is not the case for searching for people in reality. In addition, based on our experience, as the number of direct links between pages that contain the same name were fewer than we expect, information on link structures would be difficult to use to resolve our task. Although there may be indirect links (i.e., one page can be found from another page via other pages), it is too time consuming to find them. 3.1 Task Definition Our task, which is the reference disambiguation of names appearing on Web pages, is formalized as follows. The query (target name) is referred to as q .The set of Web pages obtained by inputting query q to a search engine is denoted by P = { p 1 ,p 2 ,  X  X  X  ,p k } . Each Web page p i has at least one string q . Then, the j th appearance of string q on Web page p i is assumed to be s ij .Each s ij world having the name q .Now,thesetof s ij is assumed to be S . We define function  X  : S X  X  . Function  X  means mapping from the name appearing in the document to entities in the real world. In other words,  X  means mapping from a string to an entity. Our purpose is to find function  X   X  that will approximate function  X  .

The modeling above permits the same string q appearing in the same docu-ment to refer to different entities. Web pages with such properties actually exist. However, these pages are quite rare, and dealing with them makes the system more complicated. We therefore decided to ignore these pages. Therefore, We as-sumed that all of the same string q on a certain Web page d i would refer to the supposition means that the same name appeared on one page only refers to one entity. Therefore, this results in a simpler model i.e.,  X  : P X  X  . In this research, our aim was to estimate  X  . The problem here is n (that appears in the definition of
E ) is not known previously. In other words, we do not know how many distinct entities have the string q . We actually estimated  X  by clustering Web pages.
Our system works as follows. Given query q , the system retrieves Web pages that have string q using a search engine and does the reference disambiguation task. Finally, the output of the system is a set of page clusters, each of which refers to the same entity. Although queries have been limited to people X  X  names in previous methods, our aim was to accept not only people X  X  names but all general proper nouns such as place names and organization names. To achieve this goal, the system does not require any knowledge about the query. 3.2 Baseline System We first implemented a simple system as our baseline. Note that all we need to do is to cluster Web pages. We adopted Aggl omerative Hierarchical Clustering (AHC) with the Bag of Words Model to calculate similarity between pages. The string sequence for the page in Bag of Words Model (so-called Vector Space Model ) is represented as a vector whose elements are the weights of words, and word i on page p j is weighted as where tf( i, j ) is the frequency of word i on page p j ; D is the total number of pages; and df( i ) is the number of the pages containing word i . The cosine of the angle between the two resulting vectors is then used as the context similarity measure.

We evaluated this baseline system using the test set described in Section 6.1 and found the F-measure was lower than 0.5. The main problem is shortcoming with the Bag of Words Model , which only focuses on the frequency of words. Other significant information in the words is ignored, such as word positions or word meanings. We therefore propose two methods to overcome this kind of shortcoming. Now, we propose two methods for calculating similarity. One method is Local Context Matching using location information of words on Web pages, and the other method is Named Entities Matching using the meanings of surrounding words on the pages. 4.1 Local Context Matching As discussed in the previous section, the Bag of Words model cannot utilize word positions. Local Context Matching copes with this shortcoming by giving nearby words (i.e., words close to the query) higher scores than others. Here,  X  is the window size and is currently set to three.
Note that  X  ( d x )=  X  ( d y ) means two pages, d x and d y , are to be in the same cluster (see Section 3.1) and clustering is done as follows. Let G be an undirected graph with vertex set V and edge set E .Eachvertex v i  X  V corresponds to page d i .Theresultof Local Context Matching gives edge set E .Eachedge e the algorithm. Then, graph G = V, E has some connected components. Each connected components means one cluster of Web pages all of which refer to the same entity.

In the case of a person X  X  name, personal data such as his/her age, affiliation, and position will appear near the target name. Therefore, we expect to extract important features by Local Context Matching for disambiguating references and checking whether the pages refer to the same entity or not without having to use information extraction methods. All we need to do is focus on the words near the query string.

The stop word list in Step 1.3 prevents meaningless words from exerting an in-fluence. The list, which was made by the hand, consists of stop words in Japanese, such as: shi ,and san (mean  X  X r. X  and  X  X s. X  in Japanese), namae (meaning  X  X ame X ), and nen , tuki ,and hi (meaning  X  X ear X ,  X  X onth X , and  X  X ay X ). 4.2 Named Entities Matching Named Entities (NEs) are generally more discriminating (i.e. document specific) than general words. We attempted to determine the same person by using NEs. For example, person names can be disambiguated by using heuristics such as:  X  If the target person X  X  name and another person X  X  name co-occur on many  X  The organization name that appears near the position of the person X  X  name  X  The same person names co-occuring with the same date refer to the same Place names can be disambiguated in the same way.

Although these heuristics are not necessarily correct, they indicate that the probability of referring to the same entity is very high. The method of deter-mining whether the same name appearing on many pages refers to the same entity using such criteria is called Named Entities Matching . NEs characterize documents very strongly, and typically represent their main topics. Therefore, if NEs can be correctly used, they can be expected to become powerful clues for determining whether the same names refer to the same entity or not.
To find out NEs, we used Sen 1 as not only a Japanese morphological analyzer but the NE tagger which tags each proper noun in obedience to context, such as  X  X erson-name (family name) X   X  X erson-name (first name) X ,  X  X lace-name X , or  X  X rganization-name X . Sen works faster than information extraction systems, and provides more general information. According to our manual benchmarking 2 , Sen achieved 0.8371 F-measure as the NE tagger for person names and 0.7969 F-measure for place names.

The algorithm for Named Entities Matching we used in our system is presented below.
 This is where  X  and  X  are parameters for weighting. Having constrains  X  ( d x )=  X  ( d y ), clustering is done in the same way as Local Context Matching . We describ e our NAYOSE System in this section. One problem we found in dealing with Web pages is that there were several noisy pages that were inap-propriate for our task, such as those page with no meaning and those which refers to multiple entities. We defined these as junk pages . We also defined a rule to filter these out. The NAYOSE System is outlined at the end of this section. 5.1 Filtering Junk Pages When the system tries to automatically disambiguate references, some Web pages have a negative influence that decreases efficiency. As previously men-tioned, these are called junk pages .
 Wan et al. [7] have pointed out that it is important to filter junk pages out. Though their task was different from ours, they coped with pages in which the target name referred to non-person entities as junk pages. Since our system was designed to receive proper nouns as general as possible, we determined junk pages as follows. If a Web page conforms to more than one of following properties, the page is determined to be a junk page: J1. The page has disappeared from the Web (i.e., if  X  404 not found  X  X ppears),
J2. The page does not contain the query string, J3. Most of the page is occupied by the enumerations of names or numbers, and J4. The same name on the page refers to multiple entities.

J1 and J2 are for changes in Web pages. Our system collects Web pages by using results from a search engine. Because there is a time lag between pages cached by the search engine and original page, we need to check if the page we collect actually contains the query string. If the page does not have the query string, it is regarded as a junk page.

J3 is a page that is hard to use. In many cases, it does not have enough information for each person on the page. However, a few pages do have useful information. It is not easy to distinguish these useful pages from junk pages. Therefore, none of the pages extracted under J3 should be dumped. But they are marked as  X  X 3 X  and treated in a special manner as later mentioned.
J4 is a page that is beyond the scope of our task where we have assumed one page would refer to only one entity.
 We defined the following rules to filter out junk pages: F1. The URL contains Japanese characters, F2. The title contains the string  X  X earch result X  ( kensaku kekka , in Japanese), F3. Named entities appear too frequently, and F4. There is no string corresponding to the query.

Each rule copes with certain junk pages. The F1 and F2 rules are for junk pages J4, the F3 rule is for J3, and the F4 rule is for J1 and J2. The F1 and F2 rules are based on our experience. We found the pages on which the same name refers to multiple entities were mostly the output automatically generated by some systems. Therefore, these page may have the title contains the string  X  X earch result X  or have the URL contains Japanese characters such as: where %E4%B8%AD%E5%B7%9D%E8%A3%95%E5%BF%97 is the Japanese string  X  X iroshi Nakagawa X  encoded for URL. We regarded the encoding string %80-%FF for URL were regarded as a Japanese character.

According to junk page properties, the F1, F2, and F4 rules dump junk pages, and the F3 rule marks junk pages J3 with the label  X  X 3 X . It is feared that J3 pages have meaningless and noisy NEs which lead to errors in Named Entities Matching. Therefore, NEs in these  X  X 3 X  labeled pages are ignored in Named Entities Matching.

We have preliminarily examined our filtering rules. We checked 1362 Web pages and found 20 pages (1.5%) conformed J4. In addition, 78 pages in the rest of 1342 pages (5.8%; because the F1 and F2 rules dump J4 pages and the F3 rule does not dump.) conformed J3. Although junk pages do not appear so frequently, these pages often lead to critical clustering errors.

We used precision (P), recall (R), and F-measure (F) for the metrics. The metrics were calculated as follows: let J be a set of junk pages and let S be a set of pages which were regarded as junk pages by filtering rules, Table 1 summarizes results of our preliminary experimentation. Note that the F4 rule which was for unavailable pages was excepted from this experimentation since it is no doubt that the rule works clearly. Since the F1 and F2 rules have the same target J4, we grouped the rules together. We see filtering rules work effectively. Recall is 1.0 as shown in Table 1. That means that the rules filtered all junk pages out perfectly at least in this preliminary experiment. Some pages were dumped by errors. However, the number of pages dumped by errors is very small in all pages because junk pages are minority of retrieved pages. 5.2 Outline of Nayose System There is an overview of the NAYOSE System in Fig. 1. The system works as follows. It: 1. Receives a query from an user, 2. Retrieves Web pages X  URLs with a search engine 3 using the query and ob-3. Downloads all top k pages, and executes preprocessing (junk page filtering, 4. Calculates the similarity between Web pages and does clustering, 5. Outputs the results. 6.1 Data Set As far as we know, no gold standard for the task has yet been proposed. We originally developed the test set for this task for this reason.

We first input Japanese person-name queries and Japanese place-name queries into a search engine. Part of the person queries and all the place queries were chosen from ambiguous popular names. For example, the person name  X  X aro Kimura X  is a very common name in Japan: we found there were many people called  X  X aro Kimura X  such as a famous commentator, a member of the Diet, a translator, and a schoolmaster. As another example, the place name  X  X ujimicho X  is found throughout Japan. Some other person queries were selected from persons in our laboratory, and other person name queries were generated automatically.
Second, we tried to extract Web pages containing these names. We retrieved these pages with a search engine. If the query hit many pages, we collected the top 100-200 Web pages. All junk pages were labeled as  X  X  { 1-4 }  X , and treated with the filtering rules.
 Finally, these pages were manually annotated 4 . As a result, we collected 3859 Web pages on 28 person names and 9 place names, and all page references were clarified. 6.2 Evaluation Precision (P), recall (R), and F-measure (F) were used as the evaluation met-rics in our experiments. All metrics were calculated as follows [3]. Assume C = { a set for the result of clustering, where C i and D j are sets of pages. For each correct cluster C i (1  X  i  X  n ), we calculated precision, recall, and F-measure for all clusters D j (1  X  j  X  m )as
The F-measure of C i (F i ) was calculated by F i =max j F ij .Using j = argmax j F ij ,P i and R i were calculated as P i =P ij , R i =R ij .
The entire evaluation was conducted by calculating the weighted average where weights were in proportion to the number of elements of clusters, cal-culated as where |C| = n i =1 | C i | . The weighted average precision and recall were also calculated in the same way for the F-measure.
 We investigated which of the Bag of Word model ( BoW ), Local Context Matching ( LC ), Named Entities Matching ( NE ) or their combinations were the best. We compared the following methods:  X  X oW (Baseline) X ,  X  X C X ,  X  X C, BoW X , X  X E X , X  X E,BoW X , X  X E,LC X , X  X E,LC,BoW X .Combinationsoftwo or three methods means using different methods together. More precisely, the result of the combination of LC and NE is given by considering graph G =
V, E NE  X  E LC where G LC = V, E LC is the result for LC and G NE = V, E NE is the result for NE. When BoW was combined with NE/LC methods, NE/LC methods were applied first, and BoW was then applied to the NE/LC results. Table 2 lists the results of the pre-experimentation that revealed that applying NE/LC methods before BoW were more effective than applying NE/LC methods after it.

Table 3 lists the results of an average of 37 queries. According to the results, all the methods that involve at least one proposed methods (NE/LC) showed higher performance than the baseline. As we intended, Named Entities Matching and Local Context Matching achieved high performance by using significant in-formation about words in the pages, such as word meanings and word positions. The combination of Named Entities Matching and Local Context Matching out-performed the baseline by a significant 0.22 in the overall F-measure. In addition, the highest precision of almost 0.95 was obtained by only using Named Entities Matching , which contributed to the high F-measure of NE and LC .
 Using the Bag of Words Model improved the recall, but decreased precision. Since the drop in precision was more than the gain in recall, the overall F-measure decreased. We observed calculating similarity with the Bag of Words Model often induced mistaken cluster merging and caused serious drop in precision.
More detailed results are listed in Tables 4 and 5. They reveal similar tenden-cies: the combination of NE and LC yields the highest F-measure. A precision score of NE for person queries was over 0.92. However, these methods are less efficient for place than for person queries. We introduced the reference disambiguation system NAYOSE that we had de-veloped in this paper. It is aimed at accurately classifying Web pages by entity without assuming knowledge concerning queries. We first proposed two methods for calculating similarity to improve the accuracy of reference disambiguation, i.e., Local Context Matching and Named Entities Matching . We next defined junk pages as those with a thin meaning on the Web, and we explained the mechanism to remove these. As we intended, we showed two methods were very effective in our evaluation. The combination of Local Context Matching and Named Entities Matching outperformed the previous algorithm by 0.22 in the overall F-measure.

In our future work, we have to make the system more adaptive for any types of query, such as a place-name or an organization-name. Our experimentation showed our proposed methods were not effective enough to make high quality clusters for a place-name query. Therefore, we will explore new methods for calculating and clustering.

