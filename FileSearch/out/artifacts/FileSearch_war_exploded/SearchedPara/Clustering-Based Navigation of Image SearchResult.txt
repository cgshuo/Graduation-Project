 With the information explosion in the past decade, large collections of images have been made available on the Internet. Traditionally, people who were search-ing for particular types of images submit their queries to some trained librarians and waited for a few days for the results. This situation has been greatly im-proved since now we can simply type our query terms on an image search engine or the web interface of professional photo libraries, and the results will return within seconds.
 ities are also undergoing a considerable progress in hardware and software. The rapid development makes it possible for users to access various kinds of services on Internet anywhere and anytime. Since visual contents such as images provide rich and vivid information preferred by users, mobile image search is becoming a big application in foreseeable future. Tom Yeh [23] demonstrated an example of such application, in which mobile image search act as a director to help people in unfamiliar sites.
 It has been studied under different contexts, such as personal albums or profes-sional libraries. However, none of them has taken web images into consideration. The characteristics of data sets can heavily affect the effectiveness of presenta-tion approaches. For example, home photos would be best browsed in a chronicle order [17][18], by location [20], or by person [26]. As for professional photo li-braries, they contain more accurate annotations and usually have been classified manually into different categories.
 number of approaches have been proposed to improve the retrieval performance, including Text-based method as Google [8] and Altavista [1], Content-based sys-tems as [7] and [19], and Link-based method as PageRank [15] and PicASHOW [11]. However, the presentation of search results has been less studied. A simple ranking-based interface is still the most frequently used presentation in com-mercial systems. Unfortunately, since the performance of current image retrieval systems is far from satisfactory, a large number of irrelevant images are often retrieved along with relevant ones. So a great deal of manual page navigation is required to find the best match from the retrieval results. Only in very recently, the problem of web image search results navigation and browsing has been stud-ied in [13][21]. It has shown that the new presentation method can help users to explore image search results more naturally and efficiently. However, web image search results navigation on mobile devices is still an open question. presentations on mobile devices. The novel contributions of our work include: 1) We analyze user X  X  information need and information accessing patterns in mobile search scenario; 2) a method is proposed to help user to explore the search results effectively; 3) the navigation operations are designed to make the new interface easy to learn and simple to use.
 several key concepts, which guides our proposed method in this paper. Section 3 discusses two image clustering strategies, i.e. clustering based on visual cues and clustering based on textual labels, used for search results navigation. Section 4 proposes a new high density image presentation method, which is designed specifically for small screen factors of mobile devices. Based on those techniques, we re-design navigation operations for smart phone system, a kind of poplar mobile devices in people X  X  daily life, in Section 5. We give the experiment results in Section 6. Finally, concluding remarks and discussions are in Section 7. Since mobile devices generally suffer from limited resources, like small screen factor, interaction facilities and computational power, we can expect different navigation pattens between the users of mobile and desktop image search ser-vices. For example, for desktop users, user can input the query very quickly and get the results back with high speed network and powerful desktop machine in few seconds. Also user can refine the query easily to get further results until sat-isfied with the results. While, for mobile device users, it is more difficult to input a detail and exact query with small keyboard, waiting for a long list returned results is also annoying due to the bandwidth limitation on moving, small screen space makes it impossible for user to catch the whole results in a few clicks, etc. Current commercial image search engines only provide general search and brows-ing interfaces and do not take into account the special capability constrains of mobile devices in search results presentation design. For example, in those search interfaces, it needs too many navigation operations (scrolling and clicking) to get the target results, zooming in/out operations are required frequently in order to get a clear view of images of high dimension on small screen, etc.
 tion gained against the costs of performing activity in human-computer interac-tion tasks. Cognitive systems engaged in information foraging will exhibit such adaptive tendencies, when feasible, to maximize gains of valuable information per unit cost. The theory has been applied to Web navigation [5] as well as the image browsing on mobile devices [12].
 aging on search results. Clustering analysis can partition image collection into groups of image subsets such that the attributes of images in the same cluster are similar. The images of the same cluster are organized in a web page, one page for each cluster. At the same time, the images which stands for the profile of each cluster are extracted and presented to users as cues for page naviga-tion. While browsing the search results, people can usually scan the represen-tation images first, and decide which cluster the target images belongs to, and then move forward to the correspondent page and find target images. Therefore, clustering-based presentation can speed up search process by taking advantage of previewing representation images. It enables the user to navigate toward the interested subset images directly. Different from traditional CBIR systems, both the content features, which are visual presentation of the image, as well as the textual features, which are regard as the semantic meaning of the image, are available for web image search sys-tems. Generally speaking, visual feature is the most intuitive cue for navigation. Clustering based on the visual features of image can provide good guidance for user to navigate among search results. On the other hand, it is an accurate way to reveal the semantic meaning of the image through those textual labels of the image. Therefore, two presentations can be generated for search results naviga-tion. It is not an easy task to discover the optimal search results clustering for different queries. A solution to this problem is to provide multiple choices and let user decide their favorite clustering methods. 3.1 Visual Based Image Clustering To represent the content information of each image, an extensible attention model proposed in [4][14] has been applied in many areas, such as mobile im-age browsing [12], progressive image delivery [9] as well as image retrieval [22]. Instead of treating an image as a whole, it detects each region-of-interest in the image separately. Since these regions can be regarded as the key regions which represent the semantic content of the image, clustering based on the key regions oftheimagecanprovidethevisualcuesaswellassemanticcuesfornavigation.
 age, such as color features for example, correlogram, color moments, and texture features, for example, Gabor wavelet feature. Since color and texture features can reveal different aspects of images, their combination may be useful to rep-resent the image. In our system, we employ Color Texture Moments (CTM) proposed by Yu et.al [24], which integrates the color and texture characteristics of the image in a compact form. CTM adopt local Fourier transform as a tex-ture representation scheme and derive eight characteristic maps for describing different aspects of co-occurrence relations of image pixels in each channel of the color space. Then it calculates the first and second moments of these maps as a representation of the natural color image pixel distribution, resulting in a 48-dimensional feature vector. Also it would be important to note that the CTM features can be extracted in advance to speed up the clustering processing. vector space. Model selection is determined by a heuristic way. In order to reduce the number of operation at the first overview step, we set the number of clusters from 6 to 12, so users can catch the overview of search result collection with a few clicks. Figure 1 shows an example of saliency region based clustering using the key words  X  X awaii X .
 3.2 Textual Based Image Clustering An alternative way is to cluster web image search results based on the textural labels of each image. These textual labels include text close to that image, image file name, URL of the image, alternate text of the image in web page source, and title of the web page.
 based, DOM based and vision based. Widow based method treats html source as a text stream. For each image, it uses a fixed-length window to extract the text before and behind the image. DOM based method extracts the surrounding text from HTML DOM tree. In HTML DOM tree, an image is always a leaf node, DOM based method uses the text of the sibling nodes as the surrounding text of the image. VIsion-based Page Segmentation (VIPS) algorithm as proposed in [3] treats the web page from 2-D view, extract the semantic structure of a web page based on its visual presentation. Such semantic structure is a tree structure; each node in the tree corresponds to a block. Compared with DOM based methods, the segments obtained by VIPS are much more semantically aggregated. More-over, each node in VIPS tree will be assigned a value to indicate how coherent of the content in the block based on visual perception. Thus, it is easy to decide which block should be the right image block according to the DoC value. becomes the same problem of web search results clustering [25]. We use linear regression method to extract the saliency phrase of each image cluster. wants to find images of  X  X DA X . The returned results are classified automatically into subcategories. The textual labels of the four categories shown in Figure 2 are: (a) palm, devices; (b) staff; (c) technology, design; and (d) tom hardware guide mobile. In order to generate a effective overview of each cluster, most important infor-mation of the cluster should be extracted and presented on the small screen space. In this section, two high density presentation methods are proposed to assist browsing on small screen. The most informative parts of each image and the most informative images of a cluster are displayed with optimal resolution. Therefore, it can reduce the zooming and scrolling operations required for users to get clear over view of each cluster. 4.1 Smart Thumbnail Generation It is demonstrated that small degree of cropping will not affect the user un-derstanding the content of an image [10]. Cropping-based thumbnail generation method proposed in [4] can be employed in our system to optimize the scaling ratio of each image shown on the screen. In our system, smart thumbnail gen-erated base on attention model is applied to the the images presented to users. Figure 3 shows an example of smart thumbnail generated by attention model based cropping method. 4.2 Space Efficient Layout Algorithm To help users navigate among different clusters efficiently, several images of each cluster are selected to represent the content of the cluster and serve as cues for navigation.
 Representation Images Selection. For visual based image clustering method, we choose the distance between each image and the corresponding cluster center in visual vector space as the ranking function. For textual label based image clus-tering method, we choose the co-occurrence evaluation as well as the thumbnail size as the ranking criteria.
 preference as well as the properties of the devices, such as screen size, aspect ratio, etc.
 High Density Layout Design. In order to accommodate the represent images on limited screen space, a layout algorithm is employed in our system to optimize the scaling ratio of each image. A similar algorithm is designed under the ordered presentation constrain in [6]. This constrain comes from the facts the video shot should be placed according to their time information in the original video. As for our problem, it is free from such constrain since no time information available for web image search results. Table 1 shows the description of layout algorithm. NP problem. However, due to the limited screen size, we can not put too many images on the screen at the same time while user still can catch the content the images. When M is small (less than 5), we can iteratively adjust the design to get the maximum scaling ratio. Therefore, the problem can be solved by finding line breaks in each permutation order of M images.
 r m ax search process, we add an extra pre-processing step in advance by getting rid of those smart thumbnails with aspect ratio far from that of screen outline. Figure 4 shows examples of layout design for three and four representation images in (a) and (b) respectively. Smart phone system is a kind of poplar mobile devices in people X  X  daily life. In this section, we design the image search results navigation operations for smart phone based on the methods discussed in the previous sections.
 an example of query  X  X DA X . The user X  X  task is to find different design of PDA devices. The details of each step will be discussed in the following sub-sections. 5.1 The Start Page A simple and easy to understand start page is very important for search engine [2]. This is especially true for mobile devices, which often suffers from the limited input capabilities. The start page is shown in Figure 5 (a), an input box and a button to trigger the search process is provided on this page. Suppose a user who wants to buy a new PDA is interested in the latest design of such mobile devices. S/he can enter the key word  X  X DA X  X t this page and the results will be returned to him as a list of clustered results, as shown in Figure 5 (b). presentation page. The default presentation interface was set to be the visual based clustering presentation, because we believe it is more intuitional for user to navigate based on visual cues, especially for novice users. However, the textual based clustering can be generated by a simple switching operation. This provides another choose for expert users, who can make a judgment on query type and select the best presentation strategy. As for the user searching  X  X DA X , clustering based on visual information may not be a good presentation method. So s/he can switch to textual based clustering presentation methods to quickly access the results in clusters labelled with  X  X alm, devices X  X nd  X  X echnology, design X  X s shown in Figure 5 (d). 5.2 The Results Presentation Pages The returned images are presented in result pages. Two steps are provided to help users to understanding the search results, i.e. an overview page and detail view pages of each cluster.
 shown in Figure 5 (b) and (d). The cluster presentation is generated for users to get the information of each cluster and decide whether to continue to investigate the details of the cluster. This is an optimized one column view and only up-down scrolling is required to explore this page. For each up/down scrolling operation, a clustering box is moved to the center of the screen, so users can catch the entire results in few clicks. The layout relationship between the boxes of each cluster is determined by the importance of the cluster, that is, the ranking of the images within the cluster.
 view page of the cluster will be generated and transmitted to the client, as shown in Figure 5 (c) and (e). Still, this is an optimized one column page and only up-down scrolling is required to explore it. The layout relationship of the image within the each cluster is determined by the importance of the image, that is, the ranking score of each image within that cluster. By clicking each image of the detail view page, user will navigate to the corresponding web page containing the image. A backwards operation by clicking the  X  X ackward X  X ey on the keyboard is easy to employ to move back to the overview page.
 We implemented the new browsing system using C# and ASP.Net on Windows operation system. In order to evaluate the new presentation method for search results navigation on mobile devices, an initial controlled user study experiment has been carried out. We compare our method with Google image search inter-face. Experiment results are presented and discussed in this section. 6.1 Subjects and Queries There were four participants for our experiment. They were recruited from nearby universities. Three of them were master students and one of them is an undergraduate student. Before study, they were asked to performed image search tasks on desktop machine. Six queries were used in comparing differ-ent types of interfaces, which are PDA, Apple, Java, Hawaii, Orange, and Pie. Among them, the query  X  X DA X  X as provided to allow subjects to practice and get familiar with the interfaces. 6.2 Tasks Each user was asked to complete all the six queries in the same order. For each query, they tried to find a few images most relevant to the query terms. The interface presentation order was varied for each user: two users were given the ranking-based, then the clustering-based approach; the other two saw the clustering-based first, and then the raking-based approach. This balanced order-ing meant that all interfaces were used equally any query-interface biases were reduced. In order to reduce any performance influence due to familiarity and experience, the subjects were first asked to try all the functions of different in-terfaces for a sufficient amount of time. The user interactions and corresponding time stamps were recorded for later analysis. A small questionnaire was given to the subjects after the searching task, in order to get their feedback on the interface design. The questions were: 6.3 Results Results show that the subjects thought that web image search on mobile devices would be useful for those circumstances that desktop machine is not available to access, for example travelling to unfamiliar sites, shopping, or waiting friends at coffee house. Some of them also searched images just for fun, for example, searching for photos related to the latest movie or some famous people. seconds for each query using the clustering-based interface and 268 seconds for the raking-based interface. As we expected, the new approach outperformed the raking-based interface by reducing 19% of the total search time.
 browsing on mobile devices. They said that visual based clustering was in good accordance with human perception, therefore, was helpful to narrow down the searching process. While, it is not very convenient to find images of interest by textual based clustering, this is partly because the textual label is not as intuitive as visual cues. The subjects thought the presentation image selection is a key factor related to the browsing performance and should be improved in future. In this paper, we proposed a web image search results navigation strategy based on image clustering to increase the usability of image search on mobile devices. By clustering result images based on visual and semantic cues, user can catch the overview of the search results with only a few clicks so as to speed up the navigation process. Initial experiment results show the effectiveness of the new method.
 ing topic to find an optimal clustering methods which can use both the visual and textual cues for search results re-organization. Also, an long term user study should be carried out to validate the usability of the new design. We will continue to investigate these directions in future work.

