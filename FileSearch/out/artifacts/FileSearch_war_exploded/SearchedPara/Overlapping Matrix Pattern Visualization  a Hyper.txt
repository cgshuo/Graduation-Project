 resents the expression level of the gene under a specific condition. Often, this matrix can be converted into a bi-nary matrix by considering that each gene is either  X  X n X  or  X  X ff X . The typical pattern discovery task, often referred t o as bi-clustering [14], would find  X  X omogeneous X  submatri-ces, which are composed subsets of genes and conditions: the genes are coregulated or coexpressed under the condi-tions in the corresponding submatrices. Recently, there is a lot of interest in discovering overlapping bi-clusters [8; 13]. Considering we have a list of most interesting submatrices (bi-clusters) which overlap each other, how can we reorder the rows and columns of the entire matrix so that we can vi-sually inspect the relationship between these submatrices ? Transactional Data Visualization: The shopping-basket data is one of the most studied data types in data mining. Here each transaction corresponds to a row and each item corresponds to column. The element of the binary matrix records if the transaction purchased the item or not. Re-cently, there is an increasing interest in summarizing the data using a set of  X  X ense X  binary matrices [26; 5; 27]. In a nutshell, the dense submatrix contains almost all 1 s, and a list of them can cover all the 1 s in the entire matrix with small false positive rate. Thus, the dense submatrix is also closely related to the approximate frequent itemset patter n. Given this, a similar problem occurs: how can we visualize the entire matrix so that the dense submatrices of interests and their relationships can be inspected?
Clearly, this task is very important in its own right and complementary to some of the most critical and widely used data mining tasks, such as bi-clustering and association ru le mining. However, it is not a typical data mining task, but be-longs to the area of visual data mining or information visual-ization [11; 4]. Visual data mining can be largely partition ed into two categories: data visualization [11] and pattern vi su-alization [28; 25]. In the first category, the goal is to provi de the user an overview of the data. This is especially impor-tant for the high dimensional data and other types of struc-ture or text data, where a direct 2 D view does not exist. In this study, we will visualize high-dimensional transactio nal data through its matrix representation. Note that matrix vi -sualization has been a useful tool for visualizing relation al datasets, such as graphs [11]. In the second category, we are interested in a visual representation of those already disc ov-ered patterns or other mining models, such as association Here, for a hyperrentagle H j , max t u  X  T j  X  T ( t u ) and submatrix appearing in the entire matrix, respectively. Si m-column and the first column of H j appearing in the entire matrix, respectively.
 Basically, we define the visualization cost of each hyper-rectangle using the perimeter of the rectangle to enclose all the rows and columns of the submatrix. More precisely, the cost is the half of the perimeter. Then, we define the total visualization of the set P as the sum of the cost of all the hyperrectangles in P . Another reasonable goodness mea-sure is the area of each rectangle covering the submatrix. We choose the perimeter for technical purposes, which will allow us to process the row order and column order inde-pendently. The advantage of this choice will be seen more clearly later.

The central problem of this paper is thus formulated as follows.
 Definition 2 (Matrix Optimal Visualization (MOV) Problem) Given a database DB with a set of hyperrectan-gle P , we would like to find the optimal orders  X  T and  X  I , such that visual cost ( P,  X  T ,  X  I ) is minimized:
We note Grothaus et. al [8] consider a rather similar question to ours: to produce a two-dimensional data lay-out for discovered overlapping biclusters of gene expres-sion. Their method would allow repeated rows and columns from the original matrix for display purposes. Their goal is to seek a layout which would result in the smallest size (in terms of area: the number of rows times the number of columns) of the visualization matrix. They provide a heuris -tic algorithm for this purpose. Our problem is clearly diffe r-ent since we do not allow repeated rows or columns in the matrix. We believe the redundant rows and columns would very likely make the relationship between different overla p-ping submatrices confusing.
In this paper, we make the following contributions: 1. We propose and formulate the submatrix pattern visu-2. We discover an interesting link between the MOV 3. We present a novel iterative algorithm which utilizes including VLSI design [1], graph drawing [17], modeling of nervous activity in the cortex[15], single machine job scheduling[2][22], and etc.

It is well known that minimum linear arrangement prob-lem is NP-hard [6]. There are polynomial time algorithms for computing exact solutions of MinLA for some special graph families. But for general graphs, as of this date the best algorithm with bounded results is an approxima-tion algorithm with an O ( logn ) approximation factor [21]. However, there are quite a few heuristic algorithms for the minimum linear arrangement problem. Among them [10; 3; 12; 19; 18; 20; 23] turn out to be very successful.
We show that our matrix optimal visualization problem can be converted to a pair of hypergraph ordering problems in the following way: Given a database DB = ( T , I ) ( T is the set of all transactions and I is the set of all items) with a set of hyperrectangles P = { H 1 = { T 1  X  I 1 } , H 2 = { T 2  X  I 2 } , , H p = { T p  X  I p }} , we create two hypergraphs in the following way:
Hypergraph HG 1 = ( V 1 , X 1 ) , where V 1 = T and X 1 = { T 1 , T 2 , ..., T p } .

Hypergraph HG 2 = ( V 2 , X 2 ) , where V 2 = I and X 2 = { I 1 , I 2 , ..., I p } .

Then we have
From the definitions we can see that hyper cost ( HG 1 ,  X  T ) is not affected by  X  I and hyper cost ( HG 2 ,  X  I ) is not affected by  X  T . There-fore, to solve our problem we can convert it into two independent hypergraph ordering problems .

Now we are interested in effectively solving the hyper-graph ordering problem. But unfortunately, we find it is a NP-hard problem, as stated in the following lemma: Lemma 1 Given a hypergraph HG = ( V, X ) , it is NP-hard to find an order  X  such that hyper cost ( HG,  X  ) is minimized.
 Proof: We can reduce the minimum linear arrangement problem, which is NP hard [6], to this problem. The min-imum linear arrangement problem can be formulated as: For example, in figure 2(b), given an order  X  (0)  X   X  (1)  X   X  (2)  X   X  (3)  X   X  (4)  X   X  (5)  X   X  (6) , the graph cost is 3 | + 1  X  X  5  X  3 | + 1  X  X  3  X  1 | = 16 . The cost of a subgraph of G , for example a path in G , can be defined the same way as the cost of G . Second, we apply a MinLA algorithm on G to find a good order  X   X  . Third, we convert hypergraph HG into another graph G  X  based on the new order  X   X  . Then we apply the MinLA algorithm on G  X  again and repeat these steps until we find a good enough order for HG , or there is no improvement.

Algorithm 1 formally describes this strategy. Note that our algorithm can start with any order  X  . A detailed example is available in section 3.1.
 Algorithm 1 Hyper Ordering (Hypergraph HG , Order  X  ) 1: old hyper cost  X  M AXIM U M N U M BER 2: new hyper cost  X  M IN IM U M N U M BER 4: while old hyper cost &gt; new hyper cost do 5:  X   X   X   X  ; 6: old hyper cost  X  hypercost ( HG,  X  ) ; { hypercost 7: Transform hypergraph HG based on the order  X  into 8:  X   X   X  M inLA ( G ) ; { graph cost ( G,  X   X  )  X  9: new hyper cost  X  hyper cost ( HG,  X   X  ) ; 10: end while
To show the effectiveness of algorithm 1 combining with algorithm 2, we have theorem 1 showing that the cost of HG is always decreasing unless there is no improvement of cost reduction.
 Theorem 1 Assuming algorithm 1 calls algorithm 2 in step 7, then hyper cost ( HG,  X   X  )  X  hyper cost ( HG,  X  ) at the end of each while loop in algorithm 1.
 Proof: To prove this theorem, we will refer to lemma 2 and lemma 3, which are proved subsequently. First, by lemma 2 we have Second, by calling a MinLA algorithm in step 8 of algo-rithm 1 1 , we have Finally, Lemma 3 implies Combining (  X  ) , (  X  X  X  ) and (  X  X  X  X  ) , we prove this theorem. 2
Note that all of these steps are within one while loop. In the next iteration, a new graph G will be produced from the hypergraph HG using the newly generated order  X   X  . Thus, we can see the hypergraph order will keep improving in terms of the hyper cost until no improvement is possible. Lemma 2 The graph G generated by algorithm 2 has the same cost as hypergraph HG = ( V, X ) , i.e. hyper cost ( HG,  X  ) = graph cost ( G,  X  ) .
 Proof: For a hyperedge x  X  X in HG where | x | = k and x i is the i th vertex in x , its corresponding hyperedge-path in G contains edge x i x i +1 where 1  X  i  X  k  X  1 and  X  ( x i )  X   X  ( x i +1 ) . Therefore, we have 2 Lemma 3 Given an order  X  , the cost of a hyperedge x  X  X of hypergraph HG = ( V, X ) is no more than the cost of a hamiltonian path p with the vertex set x , i.e. hyperedge cost ( x,  X  )  X  graph cost ( p,  X  ) . Algorithm 3 Hyper to Graph Cycle (Hypergraph HG , Or-der  X  ) 1: Create a graph G ; { Let w i,j be the weight of the edge 2: for all x  X  X do 3: sort vertices in x according to their ranking in  X  , i.e., 4: for i = 1 to k  X  1 do 6: end for 8: end for Lemma 5 Given an order  X  , the cost of an hyperedge x of hypergraph HG = ( V, X ) is no more than 1 2 cost of a hamiltonian cycle c with the vertex set x , i.e. hyperedge cost ( x,  X  )  X  1 2 graph cost ( c,  X  ) .
Although for a hyperedge x , its corresponding hyperedge-cycle c contains only one more edge than its cor-responding hyperedge-path p , c embodies richer informa-tion than p . In section 4, we show that hyperedge to cycle conversion is practically more efficient than hyperedge to path conversion.

Figure 4.  X  (2)  X   X  (4)  X   X  (5)  X   X  (6) . (a) is a valid cycle. (b) is not a valid cycle because interval 4  X  5 is covered by four edges.

A natural extension of the hyperedge to cycle conver-sion is converting a hyperedge into multi cycles. We would convert each hyperedge in HG into d valid cycles in G . A valid cycle should satisfy two conditions: (1) It passes each vertex in the hyperedge exactly once and return to the starting vertex, i.e. it is a hamiltonian cycle. (2) Ex-actly two of its edges contain an interval  X  i  X  i +1 . See fig-ure 4 for a valid cycle and invalid cycle. From the pre-vious analysis, one can conclude that we can generate a graph G from a hypergraph HG and an order  X  such that hyper cost ( HG,  X  ) = 1 d  X  graph cost ( G,  X  ) for some d . Similar theorem (as to theorem 1 or 2) and lemmas (as to lemma 2,3 or lemma 4,5) also hold for the hyperedge to multi cycles conversion.
 Now we are interested in exploring the extreme case: What is the maximum number of valid cycles a hyperedge time if a hyperedge is converted into d arbitrary valid cy-cles. The second function solves the minimum linear ar-rangement problem and its running time depends on what the minimum linear arrangement algorithm it is.

Conclusively, the total running time of our hypergraph ordering algorithm (i.e. algorithm 1) is O ( | X | 2 | V | 2 ) + O ( | X || V | ) O ( M inLA ) if we convert hyperedges into paths convert each hyperedge into maximum valid cycles, or hyperedge into d arbitrary valid cycles. O ( M inLA ) is the time complexity of the minimum linear arrangement algo-rithm used by algorithm 1.
In this section, we report our experimental evaluation on four real datasets and one synthetic dataset. All of them are publicly available from the FIMI repository 2 . The basic characteristics of the datasets are listed in Table 1. In our ex-periments, all hyperrectangles are generated by a submatri x pattern ranking algorithm [27], and we apply an state-of-the-art MinLA algorithm implemented by Safro et al. [23]. Its running time is linear to | V | + | E | , and thus, it can be applied to very large graphs. All algorithms were imple-mented in C++ and run on a 2.2 GHz Opteron with 2GB of memory.

In our experimental evaluation, we are interested in the following questions: (1) How are the visualization effects of hyperrectangles on different datasets? (2) How effective are the three different conversions, i.e. converting hyperedge into a path, a cycle, and maximum number of valid cycles? (3) How good is the scalability of our algorithms?
To answer these questions, we performed a list of exper-iments, which we summarized as follows.
 Group 1 : We show and compare the visualization effects of the top 10 ranked hyperrectangles on five datasets by these three different conversions.
 Group 2 : We compare the visual cost ( P,  X  T ,  X  I ) (i.e. hyper cost ( HG 1 ,  X  T ) + hyper cost ( HG 2 ,  X  I ) of three different conversions. They are the cost our algorithms try to minimize.
 Group 3 : We compare the running time of our algorithms on both small and large datasets, and on the same dataset with different number of hyperrectangles for the scalabili ty study.
Figure 7. experimental results reordering 20 hyperrectangles (hyperrectangles best viewed in color)
Figure 9. Cost and runtime (cont X  X  from Fig. 8) 4.3 Running time
From the analysis of section 3.3, our methods have a worst case polynomial time complexity. In experiments we find the while loop of the algorithms finishes in only a few rounds. Thus in practice our algorithms (not counting MinLA) finish in a reasonable time, approximately linear to | V || X | . The runtime graphs of Figure 8 show the run-ning time related to three different conversions on differe nt datasets. In our algorithms we call the MinLA algorithm many times to get an improved graph order. We distinguish the running time of our algorithm with the running time of MinLA (in multiple times) of [23] in figure 8. We can see that in most cases the running time of our algorithms is almost negligible in comparison with MinLA of [23] with only one exception, the kosarak dataset. We believe this is due to its unusually high number of unique items, which is much higher than other datasets. In addition, the running time of our algorithms remains almost constant when the number of hyperrectanges increases.
