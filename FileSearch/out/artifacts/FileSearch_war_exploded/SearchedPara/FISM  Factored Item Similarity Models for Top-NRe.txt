 The effectiveness of existing top-N recommendation meth-ods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A com-prehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The ex-perimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser.
 H.2.8 [ Database Applications ]: Data Mining recommender systems; topn; sparse data; item similarity
Top-N recommender systems have been widely used in E-commerce applications to recommend ranked lists of items so as to help the users in identifying the items that best fit their personal tastes. Over the years, many algorithms have been developed to address the top-N recommender problem [12]. These algorithms make use of the user feedback (purchase, rating or review) to compute the recommendations. Typi-cally these algorithms represent the feedback information as a user-purchase matrix and act on it. The existing meth-ods can be broadly classified into two classes: collaborative filtering (CF) based methods and content based methods. User/Item co-rating information is utilized in collaborative methods to build models. One class of CF methods, re-ferred to as nearest-neighborhood-based methods, compute the similarities between the users/items using the co-rating information and new items are recommended based on these similarity values. Another class of CF methods, referred to as model-based methods, employ a machine learning algo-rithm to build a model (in terms of similarities or latent factors), which is then used to perform the recommendation task. The state-of-the-art methods for rating prediction and top-N recommendation problem learn the relationship be-tween items in the form of an item similarity matrix [8, 5, 11, 7]. In content based methods [6, 9], the features associated with users/items are used to build models.

Recently, a novel top-N recommendation method has been developed, called SLIM [7], which improves upon the tra-ditional item-based nearest neighbor collaborative filtering approaches by learning directly from the data, a sparse ma-trix of aggregation coefficients that are analogous to the tra-ditional item-item similarities. SLIM has been shown to achieve good performance on a wide variety of datasets and to outperform other state-of-the-art approaches. However, an inherent limitation of SLIM is that it can only model re-lations between items that have been co-purchased/co-rated by at least some users. As a result, it cannot capture tran-sitive relations between items that are essential for good performance of item-based approaches in sparse datasets.
In this paper we propose a method, called FISM , which learns the item-item similarity matrix as a product of two low-dimensional latent factor matrices. This factored rep-resentation of the item-item similarity matrix allows FISM to capture and model relations between items even on very sparse datasets. Our experimental evaluation on multiple datasets and at different sparsity levels confirms that and shows that FISM performs better than SLIM and other state-of-the-art methods. Moreover, the relative performance gai-ns increase with the sparsity of the datasets.

The key contributions of the work presented in this paper are the following: (i) extends the factored item-based methods to the top-N (ii) estimates the factored item-based top-N models using (iii) estimates the factored item-based top-N models using (iv) investigates the impact of various parameters as they
The rest of the paper is organized as follows. Section 2 introduces the notations used in the paper. In Section 3 the relevant existing methods are presented. Section 4 mo-tivates the need for a better model and contrasts the pro-posed approach against existing schemes. In Section 5, the details of FISM models are presented. Section 6 provides the evaluation methodology and the data set characteristics. In Section 7 the results of the experimental evaluation are pro-vided. Finally, Section 8 provides some concluding remarks.
In this paper, all vectors are represented by bold lower case letters and they are row vectors (e.g., p , q ). All matrices are represented by bold upper case letters (e.g., R , W ). The i th row of a matrix A is represented by a i . We use calligraphic letters to denote sets (e.g., C , D ). A predicted value is denoted by having a  X  (tilde) over it (e.g.,  X  r ) and an estimated value is denoted by having a  X  (hat) over it (e.g.,  X  r ).

C and D are used to denote the sets of users and items, respectively, whose respective cardinalities are n and m (i.e., | C | = n and | D | = m ). Matrix R will be used to represent the user-item implicit feedback (purchase/review) matrix of size n  X  m . Symbols u and i are used to denote individual users and items, respectively. An entry ( u,i ) in R , denoted by r ui , is used to represent the feedback information for user u on item i . R is a binary matrix. If the user has provided feedback for a particular item, then the corresponding entry for which the user has provided feedback as rated items and those for which the user has not provided feedback as unrated items.
The methods developed in this work are motivated by two classes of methods that were recently developed for top-N recommendation and rating prediction.

The first method, SLIM, proposed by Ning et. al. [7], predicts the recommendation scores of a user u for all items as where r u is the rating vector of u on all items and S is a m  X  m sparse matrix of aggregation coefficients.

Matrix S can be considered as an item-item similarity ma-trix, and as such the recommendation strategy employed by SLIM is similar in nature to that of the traditional item-based nearest-neighbor top-N recommendation approaches [3]. However, unlike these methods, SLIM directly esti-mates the similarity values from the data using a simul-taneous regression approach, which is similar to structural equation modeling with no exogenous variables [10]. Specif-ically, SLIM estimates the sparse matrix S as the minimizer for the following regularized optimization problem: where k S k F is the matrix Frobenius norm of S and k S k is the entry-wise ` 1 -norm of S . In Equation 2, RS is the estimated matrix of recommendation scores (i.e.,  X  R ). The constraint diag( S ) = 0 conforming to the structural equa-tion modeling is also applied to ensure that r ui is not used to compute r ui . The non-negativity constraint is applied on S so that the learned S corresponds to positive aggregations over items. In order to learn a sparse S , SLIM introduces the ` 1 -norm of S as a regularizer in Equation 2 [13]. The matrix S learned by SLIM is referred to as SLIM X  X  aggre-gation coefficient matrix. Extensive experiments in [7] have shown that SLIM outperforms the rest of the state-of-the-art top-N recommendation methods.

The second method is called NSVD and was developed by Paterek in [8]. This is a factored item-item collaborative filtering method developed for the rating prediction prob-lem. In this method, an item-item similarity was learned as a product of two low-rank matrices, P and Q , where P  X  R m  X  k , Q  X  R m  X  k , and k m . This approach ex-tends the traditional item-based neighborhood methods by learning the similarity between items as a product of their corresponding latent factors. Given two items i and j , the similarity sim ( i,j ) between them is computed as the dot product between the corresponding factors from P and Q item i is both predicted and estimated as where b u and b i are the user and item biases and R the set of items rated by u . The parameters of this model are estimated as the minimizer to the following optimization problem: minimize where  X  r ui is the estimated value for user u and item i (as in Equation 3).

In another method based on NSVD, Koren proposed a hy-brid approach called SVD++ [5]. This method merged the idea of latent factor models and traditional neighborhood based models to learn similarities between users or items. Both these models (i.e., NSVD and SVD++) were evalu-ated by computing the root mean square error (RMSE) on the test ratings in the Netflix competition data set. Hence the goal of these models was to minimize the RMSE and only the non-zero entries of the rating matrix were used in training.
In real world scenarios, users typically provide feedback (purchase, rating or review) to only a handful of items out of possibly thousands or millions of items. This results in the user-item rating matrix becoming very sparse. Meth-ods like SLIM (as well as traditional methods like ItemKNN [3]), which rely on learning similarities between items, fail to capture the dependencies between items that have not been co-rated by at least one user. It can be shown that the min-imizer in Equation 2 will have s ij = 0, if i and j have not been co-rated by at least one user. But two such items can be similar to each other by virtue of another item which is similar to both of them (transitive relation). Methods based on matrix factorization, alleviate this problem by projecting the data onto a low dimensional space, thereby implicitly learning better relationships between the users and items (including items which are not co-rated). However, such methods are consistently out-performed by SLIM [7]. To overcome this problem, our proposed item-oriented FISM method uses a factored item similarity model similar in spirit to that used by NSVD and SVD++. Learning the similarity matrix by projecting the values in a latent space of much smaller dimensionality, implicitly helps to learn transi-tive relations between items. Hence, this model is expected to perform better even on sparse data, as it can learn rela-tionships between items which are not co-rated.

Comparing FISM with NSVD, besides the fact that these two methods are designed to solve different problems (top-N vs rating prediction), their key difference lies in how the fac-tored matrices are estimated. FISM employs a regression ap-proach based on structural equation modeling in which, un-like NSVD (and SVD++), the known rating information for a particular user-item pair ( r ui ) is not used when the rating for that item is being estimated. This impacts how the diag-onal entries of the item-item similarity matrix corresponding to S = PQ T influence the estimation of the recommenda-tion score. Diagonal entries in the item similarities matrix correspond to including an item X  X  own value while comput-ing the prediction for that item. NSVD does not exclude the diagonal entries while estimating the ratings during learning and prediction phases, while FISM explicitly excludes the di-agonal entries while estimating. This shortcoming of NSVD impacts the quality of the estimated factors when the num-ber of factors becomes large. In this case it can lead to rather trivial estimates, in which an item ends up recommending itself. This is illustrated in our experimental results (Sec-tion 7), which show that for a small number of factors, the two estimation approaches produce similar results, whereas as the number of factors increases moderately, FISM  X  X  esti-mation approach consistently and significantly outperforms the approach used by NSVD.
In FISM , the recommendation score for a user u on an un-rated item i (denoted by  X  r ui ) is calculated as an aggregation of the items that have been rated by u with the correspond-ing product of p j latent vectors from P and the q i latent vector from Q . That is, where R + u is the set of items rated by user u , p j and q the learned item latent factors, n + u is the number of items rated by u , and  X  is a user specified parameter between 0 and 1.

The term ( n + u )  X   X  in Equation 5 is used to control the de-gree of agreement between the items rated by the user with respect to their similarity to the item whose rating is being estimated (i.e., item i ). To better understand this, consider the case in which  X  = 1. In this case (excluding the bias), the predicted rating is the average similarities between the items rated by the user (i.e., R + u ) and item i . Item i will get a high rating if nearly all of the items in R + u are similar to i . On the other hand, if  X  = 0, then the predicted rating is the aggregate similarity between i and the items in R + u . Thus, i can be rated high, even if only one (or few) of the items in R u are similar to i . These two settings represent different extremes and we believe that in most cases the right choice will be somewhere in between. That is, the item for which the rating is being predicted needs to be similar to a substan-tial number of items to get a high rating. To capture this difference, we have introduced the parameter  X  , to control the number of neighborhood items that need to be similar for an item to get the high rating. The value of  X  is expected to be dependent on the characteristics of the dataset and its best performing value is determined empirically.

We developed two different types of FISM models that use different loss functions and associated optimization meth-ods, which are described in the next two sections.
In FISMrmse , we compute the loss using the squared error loss function, given by where r ui is the ground truth value and  X  r ui is the estimated value. The estimated value  X  r ui , for a given user u and item i is computed as where R + u \{ i } is the set of items rated by user u , excluding the current item i , whose value is being estimated. This exclusion is done to conform to regression models based on structural equation modeling. This is also one of the im-portant differences between FISM and other factored item similarities model (like NSVD and SVD++) as discussed in Section 4.

In FISMrmse , the matrices P and Q are learned by mini-mizing the following regularized optimization problem: minimize where the vectors b u and b i correspond to the vector of user and item biases, respectively. The regularization terms are used to prevent overfitting and  X  ,  X  and  X  are the regular-ization weights for latent factor matrices, user bias vector and item bias vector respectively.

Following the common practices for top-N recommenda-tion [2, 7], note that the loss function in Equation 6 is com-puted over all entries of R (i.e., both rated and unrated). This is in contrast with rating prediction methods, which compute the loss over only the rated items. However, in order to reduce the computational requirements for opti-mization, the zero entries are sampled and used along with all the non-zero values of R . During each iteration of learn-ing,  X   X  nnz ( R ) zeros are sampled and used for optimization. Here  X  is a constant and nnz ( R ) is the number of non-zero entries in R . Our experimental results indicate that a small value of  X  (in the range 3  X  15) is sufficient to produce the best model. This sampling strategy makes FISMrmse com-putationally efficient.

The optimization problem of Equation 8 is solved using a Stochastic Gradient Descent (SGD) algorithm [1]. Algo-rithm 1 provides the detailed procedure and gradient update rules. P and Q are initialized with small random values as the initial estimate (line 6). In each iteration of SGD (Lines 8  X  26), based on the sampling factor (  X  ), a different set of zeros are sampled and used for training along with the non-zero entries of R . This process is repeated until the error on the validation set does not decrease further or the number of iterations has reached a predefined threshold.
 Algorithm 1 FISMrmse :Learn. 1: procedure FISMrmse Learn 2:  X   X  learning rate 3:  X   X  ` F regularization weight 4:  X   X  sample factor 5: iter  X  0 6: Init P and Q with random values in (-0.001, 0.001) 7: 8: while iter &lt; maxIter or error on validation set de-9: R 0  X  R  X  SampleZeros( R ,  X  ) 10: R 0  X  RandomShuffle( R 0 ) 11: 12: for all r ui  X  X  0 do 13: x  X  ( n + u  X  1)  X   X  X 14: 15:  X  r ui  X  b u + b i + q T i x 16: e ui  X  r ui  X   X  r ui 17: b u  X  b u +  X   X  ( e ui  X   X   X  b u ) 18: b i  X  b i +  X   X  ( e ui  X   X   X  b i ) 19: q i  X  q i +  X   X  ( e ui  X  x  X   X   X  q i ) 20: 21: for all j  X  X  + u \{ i } do 22: p j  X  p j +  X   X  ( e ui  X  ( n + u  X  1)  X   X   X  q i  X   X   X  p 23: end for 24: end for 25: iter  X  iter + 1 26: end while 27: 28: return P , Q 29: end procedure
As a second loss function, we consider a ranking error based loss function. This is motivated by the fact that the Top-N recommendation problem deals with ranking the items in the right order, unlike the rating prediction prob-lem where minimizing the RMSE is the goal. We used a ranking loss function based on Bayesian Personalized Rank-ing (BPR) [11], which optimizes the area under the curve (AUC). Given user X  X  rated items in R + u and unrated items in R  X  u , the overall ranking loss is given by where the estimates  X  r ui and  X  r uj are computed as in Equa-tion 7. As we can see in Equation 9, the error is computed as the relative difference between the actual non-zero and zero entries and the difference between their corresponding estimated values. Thus, this loss function focuses not on estimating the right value, but on the ordering of the zero and non-zero values.

In FISMauc , the matrices P and Q are learned by mini-mizing the following regularized optimization problem: minimize where the terms mean the same as in Equation 8. Note that there are no user bias terms (i.e., b u ), since the terms cancel out when taking the difference of the ratings. For each user, FISMauc computes loss over all possible pairs of entries in R + u and R  X  u . Similar to FISMrmse , to reduce the computational requirements, zero entries for each user are sampled from R  X  u based on sample factor (  X  ).

The optimization problem in Equation 10 is solved us-ing a Stochastic Gradient Descent (SGD) based algorithm. Algorithm 2 provides the detailed procedure. The scalability of these methods consists of two aspects. First, the training phase needs to be scalable, so that these methods can be used with larger datasets. Second, the time taken to compute the recommendations needs to be reduced and ideally made independent of the total number of recom-mendable items. Regarding the first aspect, the training for both FISMrmse and FISMauc is done using SGD algorithm. The gradient computations and updates of SGD can be par-allelized and hence these algorithms can be easily applied to larger datasets. In [4], a distributed SGD is proposed. A similar algorithm with modifications can be used to scale the FISM methods to larger datasets. The main difference is in computing the rows of P that can be updated inde-pendently in parallel. There are also software packages like Spark 1 which can be used to implement SGD based algo-rithms on a large cluster of processing nodes.

For computing the recommendations efficiently during run time, methods like SLIM enforce sparsity constraint on S while learning and utilizes this sparsity structure to reduce the number of computations during run time. However, in FISM , the factored matrices learned are usually dense and as such, the predicted vector  X r u will be dense (because PQ T is dense). Sparsity in  X r u can be introduced by com-puting S = PQ T and then setting the smaller values to zero. One systematic way of doing this is to selectively re-tain only those non-zero entries which contribute the most to the length of the item similarities vector represented by the column in S to which the entry belongs. The impact of this sparsification is further explored in the experimental results.
We evaluated the performance of FISM on three different real datasets, namely ML100K, Netflix and Yahoo Music. http://spark-project.org/ Algorithm 2 FISMauc :Learn. 1: procedure FISMauc Learn 2:  X   X  learning rate 3:  X   X  ` F regularization weight 4:  X   X  number of sampled zeros 5: iter  X  0 6: Init P and Q with random values in (-0.001, 0.001) 7: 8: while iter &lt; maxIter or error on validation set de-9: for all u  X  C do 10: for all i  X  X  + u do 11: x  X  0 12: t  X  ( n + u  X  1)  X   X  X 13: Z  X  SampleZeros(  X  ) 14: 15: for all j  X  X  do 16:  X  r ui  X  b i + t  X  q T i 17:  X  r uj  X  b j + t  X  q T j 18: r uj  X  0 19: e  X  ( r ui  X  r uj )  X  (  X  r ui  X   X  r uj ) 20: b i  X  b i +  X   X  ( e  X   X   X  b i ) 21: b j  X  b j  X   X   X  ( e  X   X   X  b j ) 22: q i  X  q i +  X   X  ( e  X  t  X   X   X  q i ) 23: q j  X  q j  X   X   X  ( e  X  t  X   X   X  q j ) 24: x  X  x + e  X  ( q i  X  q j ) 25: end for 26: end for 27: 28: for all j  X  X  + u \{ i } do 29: p j  X  p j +  X   X  ( 1  X   X  ( n + u  X  1)  X   X   X  x  X   X   X  p j 30: end for 31: end for 32: 33: iter  X  iter + 1 34: end while 35: 36: return P , Q 37: end procedure ML100K is the subset of data obtained from the Movie-Lens 2 research project, Netflix is a subset of data extracted from Netflix Prize dataset 3 and finally Yahoo Music is the subset of data obtained from Yahoo! Research Alliance Web-scope program 4 . For each of the three datasets, we created three different versions at different sparsity levels. This was done to specifically evaluate the performance of FISM on sparse datasets. For each dataset, we started by randomly choosing a subset of users and items from the main dataset. These datasets are represented with a  X -1 X  suffix. Keeping the same set of users and items, the first sparser version of the datasets with the  X -2 X  suffix are created by randomly removing entries from the first datasets X  user-item matri-ces. The second sparser version of the datasets with the  X -3 X  suffix are similarly created by randomly removing en-tries from second datasets X  user-item matrices. Note that all http://www.grouplens.org/node/12 http://www.netflixprize.com/ http://research.yahoo.com/academic relations these datasets have rating values and we converted them into implicit feedback by setting the positive entries to 1. The characteristics of all the datasets is summarized in Table 1. To evaluate the performance of the proposed model 5-fold Leave-One-Out-Cross-Validation (LOOCV) is employed. F-randomly selecting one item for each user and placing it in the test set. The rest of the data is used as the training set. Such a training set is used to build the model and the trained model is then used to generate a ranked list of size-N items for each user. The model is then evaluated by comparing the ranked list of recommended items with the item in the equal to 10.

The recommendation quality is measured using Hit Rate (HR) and Average Reciprocal Hit Rank (ARHR) [3]. HR is defined as where #users is the total number of test users and #hits is the number of users for which the model was successfully able to recall the test item in the size-N recommendation list. The ARHR is defined as where pos i is the position of the test item in the ranked recommendation list for the i th hit. ARHR represents the weighted version of HR, as it measures the inverse of the position of the recommended item in the ranked list.
We chose HR and ARHR as evaluation metrics since they directly measure the performance of the model on the ground truth data i.e., what users have already provided feedback for.
We compare the performance of FISM against that achiev-ed by ItemKNN (cos) [3], ItemKNN (cprob) [3], ItemKNN (log) 5 , PureSVD [2], BPRkNN, BPRMF [11] and SLIM [7]. We also compare the performance of a set of FISM models in which the estimated value of  X  r ui is given by Equation 5 (  X  r ui ) which also includes item i . This is done to access the performance improvements by the new estimation approach. This set of methods constitute the current state-of-the-art for top-N recommendation task. Hence they form a good set of methods to compare and evaluate our proposed approach against.
The experimental evaluation consists of two parts. First, we study the effect of various model parameters of FISM on the recommendation performance. Specifically, we look at how bias, neighborhood agreement, induced sparsity, esti-mation approach and non-negativity affect the top-N per-formance. Due to the lack of space, we present these studies only on the ML100K-3 (represented as ML100K), Yahoo-2 (represented as Yahoo) and Netflix-3 (represented as Netflix) datasets. However the same results and conclusions carry over to the rest of the datasets as well. These datasets are chosen to represent the datasets from different sources and at different sparsity levels. Unless specified all results in the first set of experiments are based on FISMrmse .

Second, we present the comparison results with other com-peting methods (Section 6.3) on all the datasets. We also compare the performance of FISM for different values of N (as in top-N ) and finally we compare the performance of FISM with respect to data sparsity.
In FISM  X  X  model, the user and item biases are learned as part of the model. In this study we compare the influence of user and item biases on the overall performance of the model. We compare the following four different schemes, NoBias -where no user or item bias is learned as part of the model, UserBias -only the user bias is learned, ItemBias -only the item is learned and User &amp; ItemBias -where both user and item biases are learned. The results are presented in Table 2. The results indicate that the biases affect the overall performance, with item bias leading to the greatest gains in performance.
In this study, we compare the effect of neighborhood agree-ment on the recommendation performance. Keeping the rest of the parameters constant, we did a full parameter study for different values of the normalization constant (  X  ). The results for both FISMrmse and FISMauc methods are pre-sented in Figure 1. From the results, we can see that the best performance is obtained when the value of  X  is in the range 0 . 4 to 0 . 5, indicating that, on average, for the items to be rated high and hence recommended, a substantial num-ber of neighborhood items need to have a high similarity value. Another interesting result to note is that the perfor-mance of the FISMauc is more stable than the corresponding FISMrmse  X  X  performance for the different values of  X  . This can be attributed to the fact that FISMauc minimizes the
Part of Mahout library (http://mahout.apache.org/) ranking loss, where the user related biases (number of items rated) is to a large extent nullified. Figure 1: Effect of neighborhood agreement on performance.
Figure 2 shows FISM  X  X  performance on the sparsified S matrix. The x -axis represents the density of S after spar-sifying the matrix as explained in Section 5.3. We can see that there is only a minimal reduction in the recommenda-tion performance up to a density in the range 0 . 1 to 0 . 15. At the same time, the average time required to compute the recommendations for each user reduces drastically. This gain in recommendation efficiency comes at a very small cost in terms of recommendation performance, which may justify it X  X  use in applications in which high-throughput recommen-dation rates are required.
To study the effect of FISM  X  X  estimation approach, which excludes the item X  X  own rating during estimation, we com-pare the performance of FISM with an approach which is the same as FISM except that it includes the rating X  X  own value during estimation. We call this method FISM (F), where F corresponds to similar approaches used in factorization ( F ) based schemes for rating prediction (NSVD and SVD++).
Keeping the rest of the parameters constant, the number of latent factors k is varied and the performance of FISM and Figure 3: Effect of estimation approach on performance. FISM (F) is compared. Figure 3 shows the results for differ-ent datasets. We can see that, for smaller values of k , the performance of both the schemes is very similar. However, when the value of k is increased, FISM starts to perform bet-ter than FISM (F) and the gap between the performance of the methods increases as the value of k increases. This con-firms the fact that the estimation approach used by FISM is superior to that used by approaches like NSVD and SVD++ and helps to avoid trivial solutions when the number of fac-tors becomes large.
SLIM enforces non-negativity constraint to ensure that the learned item similarities correspond to positive relation-ships. SLIM has also shown that the adding such a con-straint helps to improve the recommendation performance. In FISM , no such explicit constraint is enforced. We im-plemented the FISMrmse and FISMauc algorithms with non-negativity constraints and, to our surprise there was no im-provement in the performance. In fact, the performance dropped considerably (HR of 0.0933 for ML100K and 0.0848 for Yahoo, compared to 0.1281 and 0.0974 without the con-straints).
To gain some insights on this issue, we observed the prop-erties of S = PQ T during the learning process. In particular, we observed the number of negative and non-negative entries in S during each iteration of the learning process. The ob-servations are plotted in Figure 4. We can see that initially the number of negative and non-negative entries is similar, but as the model starts to learn, the number of negative en-tries decreases drastically. The best performance is obtained when the number of negative entries is significantly smaller compared to the number of non-negative entries (of the or-der 1:3). This shows that, even though the non-negativity constraint is not explicitly enforced in FISM , the model still learns the majority of the similarity values as non-negative entries.
Table 3 shows the overall performance of FISM in com-parison to other state-of-the-art algorithms for the top-N recommendation task. For each of the methods, the fol-lowing parameter space was explored and the best perform-ing model in that parameter space is reported. For all the ItemKNN based methods and PureSVD, parameter k was selected from the range 2 to 800. For ItemKNN (cprob), the  X  parameter was selected from the range 0 to 1 with a step size of 0 . 05. For BPRkNN, the learning rate and  X  were increment of 10. For BPRMF, the number of latent factors was selected from the range 2 to 800 and the learning rate from the range 10  X  5 to 1 . 0 with a multiplicative increment of 10. For FISM , both  X  and  X  were selected from the range 10
The results in Table 3 show that FISM performs better than all the other methods across all the datasets. For many of these datasets, the improvements achieved by FISM against the next best performing schemes are quite sub-stantial. In terms of the two loss functions, quite surpris-ingly, the RMSE loss ( FISMrmse ) achieved better perfor-mance than the AUC loss ( FISMauc ). This is contrary to the results reported by other studies and we are currently investigating it.

Note that for all the results presented so far, the number of top-N items chosen is 10 (i.e., N = 10). Figure 5 shows the performance achieved by the various schemes for different values of N . These results are fairly consistent with those presented in Table 3, with FISM performing the best.
To better illustrate the gains achieved by FISM over the other competing approaches as the sparsity of the datasets increases, Figure 6 shows the percentage improvement achie-ved by FISM against the next best performing scheme for each dataset across the three sparsity levels. These results show that, as the datasets become sparser, the relative per-formance of FISM (in terms of HR) increases and, on the sparsest datasets, outperforms the next best scheme by at least 24%.
In this paper, we presented a factored item similarity based method ( FISM ) for the top-N recommendation prob-lem. FISM learns the item similarities as the product of two matrices, allowing it to generate high quality recom-mendations even on sparse datasets. The factored repre-sentation is estimated using a structural equation modeling approach, which leads to better estimators as the number of factors increases. We conducted a comprehensive set of experiments on multiple datasets at different sparsity lev-els and compared FISM  X  X  performance against that of other state-of-the-art top-N recommendation algorithms. The re-sults showed that FISM outperforms the rest of the methods and the performance gaps increases as the datasets become sparser. For faster recommendation, we showed that spar-sity can be induced in the resulting item similarity matrix with minimal reduction in the recommendation quality. [1] L. Bottou. Online algorithms and stochastic [2] P. Cremonesi, Y. Koren, and R. Turrin. Performance [3] M. Deshpande and G. Karypis. Item-based top-n [4] R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sismanis. [5] Y. Koren. Factorization meets the neighborhood: a [6] R. J. Mooney and L. Roy. Content-based book [7] X. Ning and G. Karypis. Slim: Sparse linear methods [8] A. Paterek. Improving regularized singular value [9] M. Pazzani and D. Billsus. Content-based [10] J. Pearl. Causality: models, reasoning and inference , [11] S. Rendle, C. Freudenthaler, Z. Gantner, and [12] F. Ricci, L. Rokach, B. Shapira, and P. Kantor. [13] R. Tibshirani. Regression shrinkage and selection via Figure 6: Effect of sparsity on performance for various datasets.
