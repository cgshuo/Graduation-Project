  X  , Jie Yin  X  and Xindong Wu  X  X  corresponding bag label, which results in inherent ambiguity of instance labels in positive bags. We call the instances with ambiguous labels ambiguous instances .

To handle the MIL ambiguity problem, different super-vised methods have been proposed over the years. Since labels of instances in positive bags are not available, a straightforward approach is to transform the MIL into a stan-dard supervised learning problem by labeling all instances in positive bags as positive [2]. However, these MIL methods are based on the assumption that the positive bags consist of fairly rich positive instances. Moreover, mislabeling the negative instances in positive bags as positive may limit the discriminative power of the MIL classifier. To account for this drawback, another group of MIL methods [3], [4], [5], [6], [7] focuses on selecting a subset of instances from positive bags to learn the classifier. In the training phase, except for the selected instances, the remaining instances in positive bags are excluded from training. For example, RW-SVM [7] designs an instance selection mechanism to select one instance from each positive bag. Together with the negative instances from negative bags, these selected instances in positive bags are used to build the classifier. However, the discriminative ability of these approaches may be restricted. This is because only a subset of the instances is used to learn the classifier, while quite a number of remaining instances in positive bags, which may contribute to the construction of classifier, are excluded from the classifier learning.

In this paper, we propose a novel multiple instance learning method, termed SMILE (Similarity-based Multiple Instance LEarning). It appropriately utilizes the ambiguous instances in positive bags to improve MIL accuracy. Instead of excluding a number of ambiguous instances in positive bags from training, SMILE explicitly deals with ambiguous instances by considering their similarity to both the positive and negative classes. Specifically, we assign two similarity weights to each ambiguous instance towards the positive and negative classes. Then, we incorporate these ambiguous instances, together with their similarity weights, into an extended formulation of support vector machines (SVM). Based on a heuristic learning framework (see Section IV-E), is used to train the classifier straightforwardly. However, this method relies on the positive bags being fairly rich in positive instances. Rather than learning the classifier at one time, mi-SVM [3] and MILBoost [13] train the classifier iteratively to refine the classification boundary. In mi-SVM [3], the labels of instances in positive bags are initialized as positive, and then the classifier is trained repeatedly until each positive bag has at least one instance which is classified as positive by the classifier. Obviously, mi-SVM focuses on obtaining 100% training accuracy of positive bags. However, if labelling noise of the positive bags exists, the accuracy of mi-SVM may be greatly reduced. In MILBoost [13], all instances initially get the same label as the bag label for training the first classifier and each instance is assigned a weight indicating its label. At each round, the instance weights are updated by a line search to maximize the log likelihood function and subsequent classifiers are trained. However, the MILBoost is based on the framework of Boosting and may sometimes be less robust [14]. In the experiments, we explicitly compare the robustness of our proposed method and MILBoost.

The second category of works [8], [9] design mechanisms to map a bag of instances into a  X  X ag-level X  training vector, and each instance serves as a dimension in the new feature space. Typical examples include MILES [9] and DD-SVM [8]. In MILES, the bag is embedded into a new feature space. The 1-norm SVM is used to select the important features (instances) for prediction. In DD-SVM, it learns a collection of instance prototypes according to a Diverse Density (DD) function and the instance prototypes are used to map a bag into a point in a new feature space. Then, the standard SVM is used to build the classifier for separating the  X  X ag-level X  points. However, DD-SVM and MILES may transform the MIL into a high dimensionality problem. This is because the dimension of the  X  X ag-level X  training vector is equal to the total number of instances in the training set. If the number of instances is large, the  X  X ag-level X  training vector may turn out to be extremely high dimensional. Moreover, both DD-SVM and MILES include the computation of DD function, which is  X  X ery sensitive to noise X , as pointed out by [6].
The third category of works [4], [5], [6], [7], [9] focus on selecting a subset of instances from positive bags to learn the classifier. For example, the DD method [4] aims to find one data point (target concept), which is nearest to the instances in positive bags and is farthest from the negative bags. A test bag is classified as positive if the distance between the selected data point and any of its instances is below a threshold. EM (Expectation-Maximization)-DD [5] chooses one instance which is most consistent with the current hypothesis in each positive bag to predict an unknown instance. MI-SVM [3] adopts an iterative framework to learn the classifier. At each iteration, only one instance from each positive bag is selected. Together with instances in negative bags, the selected instances are used to learn the classifier. problem: subject to constraints (2), where C is a parameter which balances the margin and classification errors. By introducing the Lagrange function [20], w and b are solved, and the decision classifier (Equation (1)) is then obtained.
For a test instance x ,if D w,b ( x ) &gt; 0 , it is classified into the positive class; otherwise, it belongs to the negative class.
In our paper, each ambiguous instance is associated with two similarity weights. However, the standard SVM in Equation (3) can not handle two weights for one instance. To solve this problem, we present an extended formulation of the standard SVM. It can effectively incorporate both similarity weights into the optimization procedure. Y a positive bag with positive label Y + i =+1 ; B  X  i denotes a negative bag with negative label Y  X  i =  X  1 . N + and N  X  are the numbers of positive and negative bags, respectively.
Each bag contains a set of instances. The j th instance in B + i and B  X  i is denoted as B + ij and B  X  ij , respectively. n i and n in B + i and B  X  i . For the sake of convenience, we line up the instances in all bags together, and re-index the instances as { ( x i ,y i ) } . Hence, the training set is transformed into D = { ( x i ,y i ) } , i =1 , 2 ,...,l , where l is the total number of training instances.

For an instance x , we convert it to a similarity-based data model defined as follows: where m + ( x ) and m  X  ( x ) represent the different similarity of x towards the positive and negative classes, respectively. We have 0  X  m + ( x )  X  1 and 0  X  m  X  ( x )  X  1 . { x , 1 , 0 } means that x belongs to the positive class, while { x , 0 , 1 } similarity of x towards the positive and negative classes are both considered.

Using the above similarity-based data model, we can convert a multiple instance learning problem into a single instance learning problem. This makes it possible for the supervised learning methods adapted to solve the MIL problem.
 A. SMILE framework
Given a set of training instances, the objective of SMILE is to build a classifier using both the positive and negative bags. The classifier is thereafter applied to classify the where | S | denotes the sample size of S ;  X  ( x i ) is the image of instance x i in the feature space and where K ( ., . ) is a mercer kernel function.

It can be observed that, if an instance x is close to S , the single set-based similarity between x and S is naturally high. By contrast, its single set-based similarity with S becomes low. It is easy to see that the value of similarity R (  X  ,  X  ) falls into the range of [0 , 1] .
 Definition 2: (Similarity) Given instance x , subsets S + and S  X  , the similarity Q of instance x towards S + is defined as follows: Q ( x  X  S + | S +  X  S  X  )= where S + and S  X  are subsets containing the training in-stances from positive bags and negative bags, respectively. Since the similarity of x is related to the relative location of S + and S  X  , its similarity with S + and S  X  are both considered in Equation (6). In Equation (6), R ( x ,S + ) is the single set-based similarity of x and S + . If the value of R ( x ,S + ) is larger, it indicates that x more likely belongs to S + . R ( x ,S  X  ) represents the similarity between x and S  X  , and hence 1  X  R ( x ,S  X  ) can be considered as the dissimilarity of x with S  X  .
 Definition 3: (Positive Candidate) For the positive bag B + i ( i =1 ,...,N + ), an instance x is selected as the initial positive candidate, if it satisfies Similar to MILD [6], we select one instance from each pos-itive bag as the positive candidate. Intuitively, the instance, which is most similar to instances in the other positive bags and has least similarity to those in the negative bags, is more likely to be a positive candidate, compared with the rest instances in the same bag. Therefore, the instance with maximum value in (7) is chosen to be the positive candidate.
After positive candidates have been determined, we can further divide S + into two subsets S + p and S + a . S + p contains the positive candidates, while S + a includes the rest of uns-elected positive bag instances, whose labels are relatively ambiguous compared to the positive candidates.
 C. Similarity Weight Generation
This section introduces the method to generate similarity weights for training instances. First, according to the MIL data model presented in Section III, the instances in subset S  X  are assigned with m + ( x )=0 and m  X  ( x )=1 , while those in S + p have m + ( x )=1 and m  X  ( x )=0 . notations in the following:
Based on the above definitions, the Wolfe dual of (10) can be obtained as follows: min F (  X  )=
Moreover, w can be obtained by differentiating the La-grangian function with w, b and  X  , as shown in the following: w =
After solving the dual form (15) and substituting w into the classification problem, the classifier for classifying the instances can be obtained in (17).

L ( x i )= where  X  ( x i ) is a test instance; L ( x i ) represents the predicted label of  X  ( x i ) .

The objective of MIL is to classify the bags. Based on the description of the MIL problem, the classifier for classifying the bags is obtained as follows:
L ( B )= where B is a test bag; L ( B ) denotes the predicted label of B ; | B | is the number of instances in B . From (18), it can be seen that only if all the instances in the bag are predicted negative, i.e. L ( x i )=  X  X  B | , bag B is predicted as negative. Otherwise, if not all the instances are negative, i.e. L ( x i ) &gt;  X  X  B | , bag B will be classified as positive. 3) Repeat the above two steps until the following stop-The SMILE approach is presented in Algorithm 1.

Extensive experiments have been conducted on three benchmark datasets: MUSK, image retrieval and text cat-egorization datasets 1 . The three datasets in total include 12 subsets, which have been commonly used in previous MIL works [3], [7].
 A. Baseline Methods
In our experiments, SMILE is compared with four base-line approaches: EM-DD [5], DD-SVM [8], mi-SVM [3] and MILBoost [13].

The first one is EM-DD [5] which focuses on selecting one instance from each bag to predict an unknown instance. The second one is DD-SVM [8] which maps a bag of instances into a  X  X ag-level X  vector and constructs a  X  X ag-level X  classifier, so that all points in positive bags contribute to the prediction. Chen et al. [8] have shown that DD-SVM obtains much better accuracy than MI-SVM [3] and we mainly discuss DD-SVM in our experiments. The third one is mi-SVM [3] which aims at achieving 100% training accuracy of positive bags. The fourth one is MILBoost [13] in which each instance is assigned a weight and the instance weights are updated iteratively to train the classifier. Following the setting in [24], Naive Bayes is used as the base classifier in MILBoost, since  X  X t is not straightforward to incorporate the instance weights (of MILBoost) into an SVM solver X  [24]. These baseline methods are used to test the ability of SMILE on several real-world MIL datasets. we let C 1 = C 2 and C 3 = C 4 , and each of them is selected from 2  X  5 to 2 5 . Following the experimental setting in [24], MILBoost is run through 30 boosting iterations which end up with an ensemble of 30 classifiers.
 C. Musk Dataset The Musk dataset contains two subsets: Musk1 and Musk2. Musk1 has 47 positive bags and 45 negative bags with about 5 instances per bag. Musk2 has 39 positive bags and 63 negative bags. The number of instances in each bag is much larger, ranging from 1 to 1,044 (about 64 instances per bag on average). Each instance is represented by a 166-dimensional feature vector.
 As shown in Table I, the average accuracy on Musk1 and Musk2 datasets utilizing 10-fold cross-validation is given. From Table I, the classification accuracy of SMILE on Musk 1is 91 . 3% , which outperforms most methods, except for the APR method. The reason APR has the highest accuracy is that the APR method has been designed particularly for the drug activity prediction problem [3], [6]. On the Musk2 dataset, SMILE obtains the best classification accuracy at 91 . 6% which is 5 . 9% , 8% higher than MILBoost and mi-SVM, respectively. Though DD-SVM has similar accuracy as SMILE on Musk2, SMILE significantly outperforms DD-SVM at 5 . 5% on Musk1.
 In addition, it is seen that the accuracy of EM-DD on Musk1 and Musk2 datasets is 84 . 8% and 84 . 9% respectively, which is lower than SMILE by around 6 . 7% on average. This is because EM-DD only focuses on selecting one instance from each bag for prediction, while a large number of remaining instances in bags, which can be used to boost MIL accuracy, is neglected. In contrast to EM-DD, SMILE explicitly utilizes these ambiguous instances and achieves markedly better classification accuracy than EM-DD. D. Image Retrieval Dataset The image retrieval dataset consists of 3 subsets: Elephant, Tiger and Fox. In each subset, it contains 100 positive bags and 100 negative bags of about 1300 instances. Each bag represents an image and the instances in a bag represent different segmented blobs of the corresponding image.
The experimental results on Tiger, Elephant and Fox datasets by using the RBF and Poly kernels are reported in Table II. As mentioned earlier, the results with Poly kernel in our experiments have already included those of linear classification accuracy than all of them. Let us take the TST2 subset as an example. On the TST2 subset, MIL-Boost, DD-SVM (with RBF kernel) and mi-SVM (with RBF kernel) obtain the three lowest accuracy at 77 . 5% , 73 . 7% and 74 . 3% , respectively, while SMILE (with RBF kernel) reaches as high as 85 . 3% , which is around 10% higher than MILBoost, DD-SVM and mi-SVM on average. The better performance of SMILE over MILBoost, DD-SVM and mi-SVM further implies the effectiveness of SMILE in utilizing the ambiguous instances.
 F. Sensitivity to Labelling Noise
We investigate the noise sensitivity of SMILE and the baseline methods on 12 benchmark subsets. Following the similar settings in [6], we generate the labelling noise in the datasets. Firstly, we randomly pick up d % positive bags and d % negative bags from the training set. Secondly, we change the labels of the selected positive and negative bags, i.e. relabel the positive bags as negative and label the negative bag as positive. Lastly, all the selected bags are put back to the training set. By doing so, the training set has 2  X  d % bags with noisy labels (called noisy bags ).

After the method of generating labelling noise is de-termined, we follow the operation in [6] to generate the noisy datasets. Specifically, for each of the 12 subsets, 20 noisy datasets are randomly generated under a particular percentage of labelling noise. Then, each noisy dataset is split into training and test sets of equal size. Due to the space limitation, the average classification accuracy of all the noisy datasets in Musk, image retrieval and text categorization datasets is presented, as shown in Figure 2 (a)-(c). The results of mi-SVM, DD-SVM and SMILE are reported under the RBF kernel.

In Figure 2 (a)-(c), it can be seen that SMILE is more robust than all the baseline approaches (EM-DD, MILBoost, mi-SVM and DD-SVM). When the percentage of labelling noise increases from 0% to 40% , SMILE has the lowest decrease of classification accuracy on all three datasets. In contrast to SMILE, mi-SVM seems to be the most sensitive to labelling noise. For example, in Figure 2 (c), the classification accuracy of mi-SVM declines rapidly with the increase of noise level. This may be because mi-SVM fo-cuses on obtaining 100% training accuracy of positive bags. If labelling noise of positive bags exists, the classifier which is learnt for obtaining 100% training accuracy of positive bags, may be severely biased by the noise. Moreover, EM-DD, DD-SVM and MILBoost appear to be more sensitive to the noise than SMILE. This is because EM-DD and DD-SVM involve the computation of DD, while it is pointed out by [6] that DD is  X  X ery sensitive to noise X .
 G. Running Time Analysis The average training time of EM-DD, MILBoost, mi-SVM, DD-SVM and SMILE on the sub-datasets of Musk,
Quite a few existing multiple instance learning methods exclude ambiguous instances in positive bags from the construction of a classifier. In this paper, we have proposed a novel MIL method -SMILE (Similarity-based Multiple Instance LEarning). SMILE explicitly deals with ambiguous instances by assigning different similarity weights towards the positive and negative classes. It further incorporates such ambiguous information into a heuristic classification frame-work. Experiments on three real-world datasets, consisting of 12 subsets in total, have shown that SMILE achieves markedly better classification accuracy than comparable MIL methods on most of the datasets.

In the future, we plan to extend this work in several directions. Firstly, we would like to develop more efficient SVM learning techniques to further improve training effi-ciency. Similar to other SVM-based techniques, we need to solve a non-convex optimization problem. Therefore, in this work, we employ an iterative learning framework to obtain the solution. We will look into other possibilities of utilizing more efficient learning techniques to enhance the scalability of our proposed method. Secondly, we will investigate other methods for generating instance similar-ity weights in different application problems. A desirable method should incorporate some domain knowledge into boosting the performance.
 This work is supported by QCIS Center of UTS, Australian Research Council (DP1096218, DP0988016, LP100200774 and LP0989721), the US National Science [13] P. Viola, J. C. Platt, and C. Zhang. Multiple instance [14] Y. Freund and R. Schapire. Experiments with a new [15] Z. Zhou and J. Xu. On the relation between multi-[16] S. Andrews and T. Hofmann. A cutting-plane algorithm [17] S. Andrews and T. Hofmann. Disjunctive programming [18] X. Xu and E. Frank. Logistic regression and boosting [19] J. Wang and J.-D. Zucker. Solving the multiple instance [20] V.N. Vapnik. Statistical learning theory. John Wiley [21] J. Bezdek and R. Hathaway. Convergence of alternating [22] J. Bi and T. Zhang. Support vector classification with [23] S.S. Keerthi and S.K. Shevade. Smo algorithm for [24] Y. Zhang, A.C. Surendran, J.C. Platt, and [25] C.C. Chang and C.J. Lin. Libsvm: A library for
