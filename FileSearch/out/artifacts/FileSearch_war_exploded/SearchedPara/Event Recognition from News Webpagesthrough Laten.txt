 News webpages increasingly become an essential component of web contents nowadays, and as a result, news flood surges in the Internet. Within the domain of modern information retrieval, news search plays an important role. Contem-porary news search is based on document-level retrieval. However, from our ob-servation news documents are not indivisible: they always contain more than one event. An event is defined as  X  X omething that happens at a specific time and location X  X 1]. Events within the same news document are related but to some extent independent from each other. Therefore not all of them are relevant to issued queries. Search engi nes can instead return fine-g rained event-level results to facilitate more accurate search from news webpages and  X  X uery-event X  match will be more successful than full document in news retrieval. Furthermore, event recognition techniques can s timulate other relevant researches due to its poten-tial use for Topic Detection and Tracking (TDT). The fine granularity of event representation motivates more accurate task results.

We illustrate a news report from Xinhua News 1 in Fig.1. The article can be divided into several events and we zoom in three of them: new death caused by Swine Flu in Singapore; retrospection of the first infection in Singapore; a confirmed patient in Malaysia. These events are related but independent. By appropriate event recognition, one can find the most relevant event description with less jeopardized noises. If the news report is compared as a  X  X ish X  then these constituent events are ingredients to form the dish, but they are latent and need to be mined. Therefore we name t hem as  X  X atent Ingredients X  (LIs). LIs are atomic for event-level retrieval.

The first challenge for event recognition is to distinguish  X  X vents X  from plain texts. We look into discourse structure and event representation to locate which parts of texts contain events. A more important challenge is to precisely de-tect event boundaries after we recognize the potential area of events. This is quite different from existed segmentati on techniques, e.g. majorly dependent on inter-sentence similarity measurement but ours is event-oriented. Since there are multiple features to affect the procedure, a balance among all features present special difficulties. We manage to decide whether an event shifts or continues with appropriate solutions. We provide two models to address the challenges.
The rest of this paper is organized as fo llows: in Section 2 we revisit related work. In section 3 we modify the classic TextTiling algorithm into Temporal Textiling Model (TTM). We describe our innovative LIs Growth Model (LGM) based on sentence feature analysis in S ection 4. Section 5 presents rich experi-ments and corresponding results. We draw conclusions in Section 6. 2.1 Discourse Structure Analysis We extract atomic events as LIs, similar to key paragraph extraction [6,7]. Dis-course analysis in journalism deals with similar problems. Ponte and Croft used a Gaussian Length Model to weight potential segment length with the prior probability defined in [15]: where  X  is the estimated mean length,  X  is the estimated standard deviation and k is a constant for scaling purpose. Grimes proposed a segmentation stan-dard based on time, space, character and theme [8]. In news this standard can be mapped to temporal expressions, entities (location and person) and seman-tic contexts. Bestgen et al indicated temporal information was used to signal thematic shift in discourse structures [4,5]. We will use these conclusions as the basic assumptions in this work. 2.2 Segmentation Techniques Text segmentation techniques have gained emphasis through all these years and kept on progressing. Salton discussed the decomposition of text into segments and themes where a segment is a contiguous block of text discussing a single subtopic [16]. Hearst discussed a method named  X  X extTiling X  to segment expos-itory texts into multi-paragraph subtopics which they call  X  X iles X  [12,10]. The text is initially broken up into blocks of size N and then a similarity curve of adjacent blocks is computed using cosine similarity to identify topic bound-aries by calculating relative similarity difference. A great variety of research works [11,9,2,18] furthered deeper on classic TextTiling. Hidden Markov Mod-els (HMMs)[17,13] approaches broke texts using a sequential Markov stochastic decision process which generates text fr agments relevant to a particular query. In recent years as topic model proved its i mportance and rese archers connected segmentation techniques with topic analysis [14,3].

Our approaches are different from previous ones. Firstly we cannot use a fixed block size because in our datasets, document length varies significantly due to different representation of news. Yet the c omparison between neighboring blocks in fixed size is not enough. Besides, our approach is independent of specific queries, unlike HMMs. Finally, our approaches are more event-centered than topic models. We consider more news elem ents with the help of lexical thesaurus and deal with the problem of few key t erms in common between sentences. Based on Bestgen X  X  conclusion [4] and a ccording to our statistics of human an-notated data, 87.23% LIs start from a sentence with temporal information. As illustrated in Fig.1, temporal expressions play a vital part in indicating LIs ex-traction. We treat the sentence with a timestamp as a head sentence and the LIs extraction starts from it. 3.1 Timestamp Extraction To identify the head sentences we need to locate temporal expressions. There are specific and non-specific temporal expressions. Specific temporal expressions are meaningful in that they satisfy news elements criterion a nd indicate events while non-specific ones do not. Specific temporal expressions can be classified as explicit ones, which are simple to recognize, and implicit ones which need semantic inference from reference time po int by calculating elapse. Expressions such as  X  X omorrow X  indicate time offsets. Secondly time value can be time points or time intervals. We assign publish time to the whole news article and make references when encounter new time t ags during sequential processing within each LI.

We implement a time tagger based on GATE 2 to recognize temporal expres-sions. The tagger extracts them, discards non-specific ones, makes semantic in-ference and regulates with uniform format (mm/dd/yyyy). In this work, we use temporal expressions to denote those specific ones. 3.2 Temporal TextTiling We modified the classic TextTiling algorithm, which uses inter-sentence similar-ity. Previous TextTiling specifies a fixed size of block as the unit of comparison, and adjacent blocks are compared. Howev er, this measure ca nnot be directly ap-plied to our scenario due to the character of news representation as mentioned in Section 2. Therefore we regard a sentence as a block.

After extracting and regulating temporal expressions, we locate the first head sentence ( s h ) to be the beginning of an LI. All pairs of adjacent sentences from s h are assigned a similarity value and thes e values are examined for peaks and valleys. Peak values imply two sentences cohere well wherea s valleys indicate potential boundaries. We choose the first boundary from s h as the end of this LI and move on to the next head sentence with temporal expressions. Given two sentences s 1 and s 2 , similarity between sentences is calculated by a cosine measurement, where w ( t, s )istheweightofterm t in sentence s . Term Weighting. w ( t, s )ismeasuredby tf.idf from standard information retrieval in previous TextTiling. In [9] a twist term weighting is introduced: w ( t, s )isthe tf value (term frequency) of t within the block, and here the block means the sentence. However, only term frequency cannot ensure the terms in common are rare in other parts of the document but the global tf.idf mechanism basedonthewholecollectionwou ld make the vector too sparse. Thus tf.isf (term frequency-inverse sentence frequen cy) weighting strategy is utilized. Still there may be a problem. tf within a sentence is often too small and successive multiplication of tf.isf weights may cause an underflow. So we implement a novel term weighting strategy dtf.isf . dtf is measured within the local document D ,and isf in D indicates whether t is a distinguishing term or not. The four term weighting strategies are compared in our experiments to evaluate their performances in the task of LIs extraction. As specified above, we start LIs extraction from a head sentence s h with tem-poral expressions, the indicators of topic drifting. Neighboring contexts tend to describe the same event due to the semantic consecutiveness of natural languages: human discourse is consistent. An LI expands by absorbing sentences that stick to the event. We assume there are two factors deciding relevance to the event. Naturally one is the context similari ty between the pending sentence ( s p )and every sentence from the expanding LI ( s L ). The other factor is the probability for s L to belong to LI. Here we denote significance to be the probability of being likely to be relevant to LI. These two fa ctors can be formulated in Equation 3 as follows, where | LI | denotes the number of sentences in the expanding LI: 4.1 Context Similarity Similarity is always an important measurement in text processing. We employ pre-process techniques for accuracy, including Part-of-Speech tagging, stemming, stop word removal and named entity recognition. Like the Temporal TextTiling Model, similarity values are measured on sentence level using Equation 2.
We will next move on to the sentence feature analysis according to the news principles. Each of these lexical elements is essential for LIs extraction. We present the symbols that would be mentioned later in Table 2.
 4.2 Distance Restriction According to the Gaussian Length Model, the tendency to agglomerate attenu-ates as distance becomes l arger from head sentence s h ( | s h | =0). The length of LI Len follows Gaussian distribution. P ( X  X  O ) represents the probability for s p to contain a common event with the expanding LI, which is a decay caused by distance, namely di stance restriction f d ( x )( x = | s p | ). f ( x ) is illustrated in Fig.2. However, Equation 4 based on statistical distance is incomplete. Considering Grimes X  theory, besides theme (semantic context) similarity, space and chara cter (i.e. named entities) and time (i.e. temporal ex-pressions) have influences and should all be taken into consideration. We treat these standards homogeneously and they share similar decay function. 4.3 Named Entity Influence Named entities, such as person, location or organization names, are usually uti-lized in text mining problems. They are different from plain terms. Relevant named entities in two sentences indicate a probable common event. Therefore we need to identify such entities, which are either entities from current LI (de-noted as e L ) or entities connected to e L through a path by WordNet( e W ). The structure of WordNet is illustrated in Fig.3. Distance from entity A to entity E is 5 with a path { A,B,root,C,D,E } . Relevant entities form a dynamically growing set during LI expansion. e L is initiated from e s h and iteratively updated by adding e s p when s p is added to LI:
A sentence containing relevant entity(ies) will raise the probability to share the event with LI despite the distance restriction. We use f e ( x ) to define the named entity influence and it is illustrated in Fig.2 too. dist is the distance between e s p and e L , which is measured by the length of the shortest path in WordNet. If entities are exactly matched, dist will be 0, then f there are various entities in e L ,and dist is the average distance dist of all entity pairs.  X  is a scaling factor between 0 and 1. 4.4 Temporal Proximity We consider temporal proximity contribute to common events as well. Re-mention of adjacent temporal information might strengthen event continuous-ness, but if two timestamps are too far away, a new event might begin here. When new temporal expressions are iden tified, we need to decide whether a new LI starts or the original LI still expands. We introduce time decay to measure the temporal proximity in Equation 6 and it is also illustrated in Fig.2:  X t means the temporal distance between the new time value t n and the times-tamp t 0 in s h . When refers to expressions designating time intervals,  X t means the closest time distance between the two. T d is the time span of the news doc-ument.  X  is a also scaling factor between 0 and 1.

We use a significance to measure the probability of being the same event and all features mentioned above impact the significance score. Note that in the expanding LI, there may be more than one s e or s t and hence there may be more than one f e ( x )or f t ( x ). For the completeness of an LI, we choose the maximum f ( x )and f t ( x ). Equation 7 takes the arithmetic average score of all significance.
We combine both similarity and significance in Equation 3 and obtain a rele-vance score from all sentence pairs between s p and s L .Weadd s p into LI when relevance score exceeds a threshold. This LIs extraction model is like a growing snow ball instead of the parallel process of Temporal TextTiling Model (TTM). Therefore we name it as LIs Growth Model (LGM). 5.1 Data Description Since there is no existing standard test set for LIs extraction, we opt to construct our own test sets which consist news da tasets and golden standards. We con-struct two separate datasets manually for LIs extraction. One is based on news documents from Automatic Content Extraction 2004 corpus ( ACE 04). Consid-ering these news reports are years away from now, we collect recent news pages from Xinhua news website ( Xinhua ). We sample 1000 news documents from the datasets according to their length distribution, 500 from each, all in English. 5.2 Evaluation Metrics In performance evaluation we use the P recision and Recall criterion in infor-mation retrieval. Firstly we consider the sentence level performance among LIs. Suppose L 1 is an LI given by human with m sentences and L 2 by computer with n sentences. We treat L 1 and L 2 as a pair when L 1 contains the head sentence s h of L 2 . Sentence level precision ( p sent ) within is calculated by checking how many sentences in L 2 are found in L 1 and the recall ( r sent ) is to check how many sentences in L 1 are retrieved. We use formalized evaluation metrics as follows: Moreover, we also consider the event level performance to measure how many LIs are missed or falsely alarmed. Suppose there are a LIs in document D found by man, b LIs in D by computer and | L 1 | X  X  L 2 | is the number of matched LI pairs. Event level precision ( p event ) indicates how many LIs are correctly found and the recall ( r event ) is to measure how many events are found by the algorithms. The final F-score in a document D is calculated by the harmonic mean of F sent from all LIs within this document and F event .
 5.3 Parameter Tuning There are several free parameter s in our LIs extraction models.  X  ,  X  and k are fitted to Formula 1 by the LI length statistics. From our statistics of LIs length from 1000 reports, we choose k = 15,  X  =7,  X  =2inFormula1.

Next we examine the influence of scaling factor  X  and  X  under a specific threshold. During every  X  X raining and testing X  process, we vary  X  from 0 to 1 with the step of 0.1 and make the same move to  X  .WechecktheF-score when these two parameters change in Fig.4 and get a best  X  and  X  value pair (  X  best and  X  best ) under each given threshold. In Xinhua we can see that when  X  exceeds a certain value the F-sc ore improves significantly (  X  =0.5 in Fig.4) under all  X  but  X  shows little and unstable influence of the overall performance. The best F-score in Fig.4 is achieved when  X  =0.3 and  X  =0.6.In ACE 04 we observe the best F-score is achieved when  X  =0.6 and  X  = 0.5 and the performance varies slightly when  X  and  X  are restricted in a particular region. In general the effect of  X  is weaker than that of  X  despite of different datasets, but  X  is more sensitive to datasets than  X  is.

To the decision of threshold value, we notice relevanceScore sometimes varies significantly from document to document . Therefore, we measure the threshold more locally, within each document. In every news article, we locate all poten-tial head sentences and check the relevanceScore of each sentence following. Hence we obtain all relevanceScores with a range in [ relScore , relScore ]and the threshold is computed by ( relScore +  X   X  ( relScore  X  relScore )) where  X  varies from 0 to 1 at a step of 0.1. Take LGM of Equation 7 as an example, the parameter tuning procedure is listed in Table 3. 5.4 Performance and Discussion We examine the performance of temporal information extraction. We randomly sample 100 reports and generate timestamps by humans. The time tagger ex-tracted 483 temporal expressions, 441 correctly inferred. The accuracy is 91.30%.
We compare the performance of LIs extraction models. We choose TextTil-ing as Baseline -1, and Temporal TextTiling Model (TTM) as Baseline -2. Four features are used in LGM extraction: (1) context similarity; (2) distance restric-tion; (3) named entity influence; (4) temporal proximity. Among them, features (2)(3)(4) influence the significance of a sentence. We tried different combinations of these weights with similarity. LGM -D means LIs growth model with only dis-tance restriction, LGM -DN denotes LIs growth model with distance restriction and named entity influence, LGM -DT includes both distance restriction and temporal proximity and finally the full LGM, LGM -F , takes all three features into consideration. Within all these measures, the four term weighting strategies, tf, tf.idf, tf.isf and dtf.isf are utilized to see if they bring any benefits. Due to restricted page limits, we present detail results from Xinhua in Table 4 and overall performance for both datasets in Fig.5.

From Table 4 we can see different behaviors of the two LIs extraction frame-works. Baseline -1 and Baseline -2 show obvious weakness in LIs extraction. The reason for this phenomenon is most likely that TextTiling is not designed for event-oriented purpose but for expos itory texts, so it performs especially dreadful in event level precision becaus e most LIs detected by it are not events. However, it discards no sentences and s o recall is extremely high. TTM performs better in that it takes temporal expressions into account which are proved to be valuable. Event-level recall for TTM drops slightly. By comparing four varieties of LGM, we find generally considering all features brings the maximum bene-fits. The distance restriction is reasonable and brings better results compared to two baselines. The entity influence is relatively limited and it hardly improves sentence-level recall. We believe it is due to the incompleteness of WordNet which has not been updated for a long time but news happens anytime. The correlated entities cannot find a path to each other in WordNet and this probably leads to the failure of relevant entity influence. Recall is greatly enlarged by the effect of temporal proximity and the importance of temporal information is reconfirmed.
The four term weighting strategies have different results as well. Generally tf.idf performs worst among all these strategies. The reason may be that our evaluation metrics are based on local contexts so that introduction of global information from the whole collection may cause bias. There do not exist the situation that one always prevails over the others for the rest three weighting methods but at most times our innovative dtf.isf beats the other two. We assume this outcome can be ascribed to the local context consideration in doc-ument D as well as term distinguishing from sentence level pattern, like tf.isf . Therefore it is useful to discover unc ommon terms and raise their weights. In this paper, we build a framework to address the novel problem of event recog-nition from news webpages. We implement two models of LIs extraction for event recognition, utilizing multiple features, either semantical or syntactical. We then provide evaluation metrics to measure t he effectiveness of event extraction from news articles and conduct the evaluation methods to two real world datasets. According to the results, among all features we used, distance restriction would be helpful compared with only context similarity utilized in baselines. Unexpect-edly, relevant entity influence does not benefit much. Temporal information is proved to be quite essential in LIs extraction task and generally the mixture of all four features brings the best performance in balance.

In the future, our research can be directed to find a substitution of WordNet, such as Wikipedia which is more frequently renewed and thus, up to date. What is more, the hierarchical structure of language thesaurus is not yet used. We treat relationships between adjacent entities equally while in fact they should be distinguished. With structural information and a better content organization of the thesaurus, the effect of relevant entities might be improved.
 Acknowledgments. This work is partially supported by NSFC Grant No. 60933004, National Key Technology R&amp;D Pillar Program in the 11th Five-year Plan of China (Research No.: 2009BAH47B00) and the Open Fund of the State Key Laboratory of Software Development Environment Grant No. SKLSDE-2010KF-03, Beihang University. We also thank for the discussions with Pan Gu.
