 Temporal Text Mining (TTM) is concerned with discovering temporal patterns in text information collected over time. Since most text information bears some time stamps, TTM has many applications in multiple domains, such as summa-rizing events in news articles and revealing research trends in scienti c literature. In this paper, we study a particular TTM task { discovering and summarizing the evolutionary patterns of themes in a text stream. We de ne this new text mining problem and present general probabilistic meth-ods for solving this problem through (1) discovering latent themes from text; (2) constructing an evolution graph of themes; and (3) analyzing life cycles of themes. Evaluation of the proposed methods on two di erent domains (i.e., news articles and literature) shows that the proposed methods can discover interesting evolutionary theme patterns e ectively. Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Clustering General Terms: Algorithms Keywords: Temporal text mining, evolutionary theme pat-terns, theme threads, clustering
In many application domains, we encounter a stream of text, in which each text document has some meaningful time stamp. For example, a collection of news articles about a topic and research papers in a subject area can both be viewed as natural text streams with publication dates as time stamps. In such stream text data, there often exist in-teresting temporal patterns. For example, an event covered in news articles generally has an underlying temporal and evolutionary structure consisting of themes (i.e., subtopics) characterizing the beginning, progression, and impact of the event, among others. Similarly, in research papers, research topics may also exhibit evolutionary patterns. For example, the study of one topic in some time period may have in-uenced or stimulated the study of another topic after the time period. In all these cases, it would be very useful if we can discover, extract, and summarize these evolutionary theme patterns (ETP) automatically. Indeed, such patterns not only are useful by themselves, but also would facilitate organization and navigation of the information stream ac-cording to the underlying thematic structures.

Consider, for example, the Asian tsunami disaster that happened in the end of 2004. A query to Google News (http: == news.google.com) returned more than 80,000 online news articles about this event within one month (Jan.17 through Feb.17, 2005). It is generally very dicult to nav-igate through all these news articles. For someone who has not been keeping track of the event but wants to know about this disaster , a summary of this event would be extremely useful. Ideally, the summary would include both the major subtopics about the event and any threads corresponding to the evolution of these themes. For example, the themes may include the report of the happening of the event, the statistics of victims and damage, the aids from the world, and the lessons from the tsunami. A thread can indicate when each theme starts, reaches the peak, and breaks, as well as which subsequent themes it in uences. A timeline-based theme structure as shown in Figure 1 would be a very informative summary of the event, which also facilitates navigation through themes. Figure 1: An example of theme thread structure
In addition to the theme structure, revealing the strength of a theme at di erent time periods, or the \life cycle" of a theme, is also very useful. Consider another scenario in the literature domain. There are often hundreds of papers published annually in a research area. A researcher, espe-cially a beginning researcher, often wants to understand how the research topics in the literature have been evolving. For example, if a researcher wants to know about information retrieval, both the historical milestones and the recent re-search trends of information retrieval would be valuable for him/her. A plot, such as the one shown in Figure 2, which visualizes the evolution patterns of research topics, would not only serv e as a good summary of the eld, but also mak e it much easier for the researc her to selectiv ely choose appro-priate pap ers to read based on his/her researc h interests. Figure 2: An example of theme strength in IR
In both scenarios, we clearly see a need for disco vering evolutionary theme patterns in a text stream. In general, it is often very useful to disco ver the temp oral patterns that may exist in a stream of text articles, a task whic h we refer to as Temporal Text Mining (TTM). Since most information bears some kinds of time stamps, TTM can be exp ected to have man y applications in multiple domains.

Despite its imp ortance, however, TTM has not been well addressed in the existing work. Most existing text mining work does not consider the temp oral structures of text [7, 8]. There are some previous studies on TTM [10, 19, 11, 14], but the prop osed metho ds are generally inadequate for generating the evolutionary theme patterns as sho wn in the two examples above. A detailed discussion of related work is given in Section 6.

In this pap er, we study the problem of disco vering and summarizing the ETPs in a text stream. We de ne this problem and presen t general probabilistic metho ds for solv-ing the problem through (1) disco vering laten t themes from text, whic h includes both interesting global themes and salien t local themes in a given time perio d; (2) disco vering theme evolutionary relations and constructing an evolution graph of themes; and (3) mo deling theme strength over time and analyzing the life cycles of themes. We evaluate the pro-posed metho ds on two data sets { a collection of 50 day's worth of news articles about the tsunami event (Dec.19, 2004 { Feb.08, 2005) and the abstracts of the ACM KDD confer-ence pap ers from 1999 through 2004. The results sho w that our metho ds can disco ver man y interesting ETPs from both data sets. In addition to news summarization and literature mining, the prop osed TTM metho ds are also directly ap-plicable to man y other application domains, suc h as email analysis, mining user logs, mining customer reviews.
The rest of the pap er is organized as follo ws. In Section 2, we formally de ne the general problem of ETP disco very. In Section 3, we presen t our approac hes to extracting themes and constructing a theme evolution graph. In Section 4, we further presen t a hidden Mark ov mo del based metho d for analyzing the life cycles of themes. We discuss our ex-perimen ts and results in Section 5. Finally , Section 6 and Section 7 are related work and conclusions, resp ectiv ely.
The general problem of ETP disco very can be form ulated as follo ws.

Supp ose we have a collection of time-indexed text docu-men ts, C = f d 1 ; d 2 ; :::; d T g , where d i refers to a documen t with time stamp i . Eac h documen t is a sequence of words from a vocabulary set V = f w 1 ; :::; w j V j g . We de ne the follo wing concepts.
 De nition 1 (Theme) A theme in a text collection C is a probabilistic distribution of words that character-izes a seman tically coheren t topic or subtopic. Formally , we represen t a theme by a (theme-sp eci c) unigram language mo del , i.e., a word distribution f p ( w j ) g w 2 V . Naturally , w 2 V p ( w j ) = 1.

Using a word distribution to mo del topics is quite com-mon in information retriev al and text mining [5, 9, 2]. High probabilit y words of suc h a distribution often suggest what the theme is about. For example, a theme about the aid from the US to help reco very from the tsunami disaster may have high probabilities for words suc h as \U.S.", \million", \aid", \Bush", etc.

De nition 2 (Theme Span) A theme span is de-ned as a theme spanning a given time interv al l and is represen ted by h ; s ( ) ; t ( ) i , where s ( ) and t ( ) are the starting and termination time stamps of l , resp ectiv ely.
A theme span is a useful concept for asso ciating time with themes. For the purp ose of TTM, a theme is almost alw ays tagged with a time span. We thus use \theme" and \theme span" interc hangeably whenev er there is no ambiguit y. We call a theme span that spans the entire text stream a trans-collection theme . Thus if = h ; s; t i is a trans-collection theme, we must have s = 1 and t = T . We use to denote the set of all theme spans.

De nition 3 (Ev olutionary Transition) Let 1 = h spans. If t ( 1 ) s ( 2 ) ( 1 terminates before 2 starts) and the similarit y between theme span 1 and 2 is above a give threshold, we say that there is an evolutionary transition from 1 to 2 , whic h we denote by 1 2 . We also say that 2 is evolved from 1 , or 1 evolves into 2 . We use E to denote all the evolutionary transitions, so that if ( 1 ; 2 ) 2 E , then 1 2 .

The concept of evolutionary transition is useful for de-scribing the evolution relations between theme spans. With this concept, we can now de ne a particularly interesting theme pattern called a theme evolution thread .

De nition 4 (Theme Evolution Thread) Let be a set of theme spans, a theme evolution thread is a sequence of theme spans 0 ; 1 ; :::; n 2 suc h that ( i ; i +1
Intuitiv ely, a theme evolution thread characterizes how a family of related themes evolve over time. Since a text stream generally has multiple suc h theme threads, we now de ne another concept called theme evolution graph to char-acterize the overall theme evolution patterns of a text stream. De nition 5 (Theme Evolution Graph) A Theme Evolution Graph is a weigh ted directed graph G = ( N; E ) in whic h eac h vertex v 2 N is a theme span, and eac h edge e 2 E is an evolutionary transition. The weigh t on an edge indicates the evolution distance. Clearly , eac h path in a theme evolution graph represen ts a theme evolution thread.
An example of a theme evolution graph is sho wn in Fig-ure 3, where eac h vertex is a theme span extracted from a sub collection obtained through non-o verlapping partitioning of the stream into n sliced interv als. Eac h edge is an evolu-tionary transition. The thic kness of an edge indicates how close the two themes being connected are and how trustful
Figure 3: An example of a theme evolution graph the corresp onding evolutionary transition is; a thic ker edge indicates a closer distance between the themes and a more trustful transition. For example, the distance of 12 23 is smaller than that of 11 21 , and the former is more trustful. We also see a theme evolution thread from 12 , through 23 , and all the way to n 2 .

Giv en a text stream C , a ma jor task of the general ETP disco very problem is to extract a theme evolution graph from C automatically . Suc h a graph can immediately be used as a summary of the themes and their evolution rela-tions in the text stream, and can also be exploited to or-ganize the text stream in a meaningful way. Sometimes, a user may be interested in a speci c theme. For example, a researc her may be interested in a particular subtopic. In this case, it is often useful to analyze the whole \life cycle" of a theme thread. Thus another task of ETP disco very is to compute the strength of a theme at di eren t time perio ds so that we can see when the theme has started, when it is terminated, and whether there is any break in between. The ETP disco very problem is challenging in man y ways. First, it is a completely unsup ervised task; there's no train-ing data to discriminate theme spans. This indicates a great adv antage of any techniques for ETP disco very { no/minim um prior kno wledge about a domain is assumed. Second, com-pared with the problem of novelty detection and event trac k-ing, whic h aims to segmen t the text and nd the boundaries of events [3, 18, 13], the ETP disco very problem involves a more challenging task of mo deling the multiple subtopics at any time interv al for an event, and aims to disco ver the changing and evolutionary relations between the theme spans. Finally , the analysis of theme life cycles requires the system to deco de the whole collection with themes and mo del the strength variations of eac h theme along the time line in a completely unsup ervised way.

In the next two sections, we prop ose and presen t proba-bilistic approac hes for disco vering ETPs and analyzing the life cycles of themes, resp ectiv ely.
Giv en a stream of text C = f d 1 ; d 2 ; :::; d T g , our goal is to extract a theme evolution graph from C automatically . At a high-lev el, our metho ds involve the follo wing three steps: 1. Partition the documen ts into n possibly overlapping sub collections with xed or variable time interv als so that C = C 1 [ ::: [ C n and C i = f d t i ; :::; d t i + l i 1 lection of l i documen ts in the time span [ t i ; t i + l general, t i &lt; t i +1 , but it may be that t i + l i 1 &gt; t C 's may be overlapping. The actual choice of the interv al lengths l i and whether C i 's should overlap are determined by speci c applications. 2. Extract the most salien t themes i = f i; 1 ; :::; i;k eac h sub collection C i using a probabilistic mixture mo del. 3. For any themes in two di eren t sub collections, 1 2 i and 2 2 j where i &lt; j , decide whether there is an evolu-tionary transition based on the similarit y of 1 and 2 .
Step 1 is trivial; below we describ e Steps 2 &amp; 3 in detail.
We extract themes from eac h sub collection C i using a sim-ple probabilistic mixture mo del as describ ed in [20]. In this metho d, words are regarded as data dra wn from a mixture mo del with comp onen t mo dels for the theme word distri-butions and a bac kground word distribution. Words in the same documen t share the same mixing weigh ts. The mo del can be estimated using the Exp ectation Maximization(EM) algorithm [6] to obtain the theme word distributions.
Speci cally , let 1 ; :::; k be k theme unigram language mo dels (i.e., word distributions) and B be a bac kground mo del for the whole collection C . A documen t d is regarded as a sample of the follo wing mixture mo del: p ( w : d ) = B p ( w j B ) + (1 B ) k j =1 [ d;j p ( w j where w is a word in documen t d , d;j is the mixing weigh t for documen t d for choosing the j -th theme j suc h that j =1 d;j = 1, and B is the mixing weigh t for B . The pur-pose of using a bac kground mo del B is to mak e the theme mo dels more discriminativ e; since B gives high probabilities to non-discriminativ e and non-informativ e words, we exp ect suc h words to be accoun ted for by B and thus the theme mo dels to be more discriminativ e. B is estimated using the whole collection C as p ( w j B ) = The additional parameters to estimate are = f j ; d;j j d 2 C ; 1 j k g . The log-lik eliho od of C i , log p ( C i j ) is where c ( w; d ) is the coun t of word w in documen t d .
According to the EM algorithm, we can use the follo wing iterativ e updating form ulas to estimate all the parameters. f z d;w g is a hidden variable and p ( z d;w = j ) indicates that the word w in documen t d is generated using theme j given that w is not generated from the bac kground mo de. p ( z d;w = j ) = p ( z d;w = B ) = B p ( w j B ) p
The algorithm is only guaran teed to nd a local maxim um of the likeliho od. We use multiple trials to impro ve the local maxim um we obtain. We use 1 j C salience of theme j in C i and select the most salien t themes from C i by using an empirically set threshold. We obtain the theme spans for C i by attac hing the time span of C i all the selected salien t themes.

The same mo del can be applied to the whole collection C to extract trans-collection themes; we will do that in Sec-tion 4 to analyze the life cycles of trans-collection themes.
With the theme spans extracted from all the sub collec-tions, we now turn to the disco very of evolutionary transi-tions. To disco ver any evolutionary transition between two theme spans, we use the Kullbac k-Leibler div ergence [4] to measure their evolution distance. Let 1 = h 1 ; s ( 1 ) ; t ( and 2 = h 2 ; s ( 2 ) ; t ( 2 ) i be two theme spans where t ( s ( 2 ). We assume that 2 has a smaller evolution distance to 1 if their unigram language mo dels 2 and 1 are closer to eac h other. Since the KL-div ergence D ( 2 jj 1 ) can mo del the additional new information in 2 as compared to 1 , it app ears to be a natural measure of evolution distance be-tween two themes.
 Note that the KL-div ergence is asymmetric and it mak es more sense to use D ( 2 jj 1 ) than D ( 1 jj 2 ) to measure the evolution distance from 1 to 2 .

For every pair of theme spans 1 and 2 where t ( 1 ) s ( 2 ), we compute D ( 2 jj 1 ). If D ( 2 jj 1 ) is above a thresh-old , we will infer that 1 2 . The threshold allo ws a user to exibly con trol the strength of the theme transitions.
Once we extract the theme spans from all the sub collec-tions and iden tify all the evolutionary transitions, we essen-tially have a theme evolution graph.
The theme evolution graph discussed above gives us a micro cosmic view of the ETPs { rev ealing the ma jor theme spans within eac h time interv al and their evolutionary struc-tures. To obtain a macroscopic view of the ETPs, it would be useful to extract the global evolutionary patterns of themes over the whole text stream and analyze the \life cycle" of eac h speci c theme.

De nition 6 (Theme Life Cycle) Giv en a text collec-tion tagged with time stamps and a set of trans-collection themes, we de ne the Theme Life Cycle of eac h theme as the strength distribution of the theme over the entire time line. The strength of a theme at eac h time perio d is mea-sured by the num ber of words generated by this theme in the documen ts corresp onding to this time perio d, normal-ized by either the num ber of time points (giving an absolute strength ), or the total num ber of words in the perio d (giving a relative strength ). The absolute strength measures the ab-solute amoun t of text whic h a theme can explain, while the relativ e strength indicates whic h theme is relativ ely stronger in a time perio d.

We now presen t a metho d based on Hidden Mark ov Mo d-els (HMMs) [17] to mo del and deco de the shift between trans-collection themes in the whole collection. Based on the deco ding results, we can then compute the theme strengths and analyze theme life cycles in a straigh tforw ard way.
We rst give a brief introduction to HMMs. An HMM can be characterized by a set of hidden states S = f s 1 ; :::; s a set of observ able output sym bols O = f o 1 ; :::; o m tial state probabilit y distribution f i g n i =1 , a state transition probabilit y distribution f a i;j g n j =1 for eac h state s output probabilit y distribution f b i;k g m k =1 for eac h state s An HMM de nes a generativ e probabilistic mo del for any sequence of sym bols from O with parameters satisfying the follo wing constrain ts: (1) n i =1 i = 1; (2) n j =1 a i;j
To mo del the theme shifts in our text stream, we assume that the collection, whic h is represen ted as a long sequence of words, is stochastically generated from an HMM constructed in the follo wing way. We rst extract k trans-collection themes from the collection using the mixture mo del de-scrib ed in the previous section. We then construct a fully connected HMM with k + 1 states, of whic h k states cor-resp ond to the extracted k themes and the other one cor-resp onds to a bac kground theme language mo del estimated based on the whole collection. The entire vocabulary V is tak en as the output sym bol set, and the output probabilit y distribution of eac h state is set to the multinomial distri-bution of words given by the corresp onding theme language mo del. A 3-theme HMM is sho wn in Figure 4.

The bac kground state, whic h corresp onds to the bac k-ground theme mo del, aims to accoun t for non-discriminativ e words, while the con ten t words and subtopics are mo deled by the states corresp onding to the trans-collection themes. Since the extracted themes are discriminativ e, we may rea-sonably assume that eac h theme can only shift to another theme through the bac kground mo del. The unkno wn pa-rameter set in the HMM is = f i ; a i;i ; a i;B ; a B;i g can be estimated using an EM algorithm called Baum-W elch algorithm [17].

After the initial state probabilities and transition proba-bilities are estimated, the Viterbi algorithm [17] can be used to deco de the text stream to obtain the most likely state sequence, i.e., the most likely sequence of theme shifts, as sho wn in Figure 5.

Once the whole stream C = f d 1 ; :::; d T g is deco ded with the lab els of themes, we can use a xed-size sliding windo w of time to measure the strength of eac h theme at a time The absolute and relativ e strengths of theme i at time t is computed as:
The use of a sliding windo w also avoids the \rep ort dela y" problem in the news domain. where ( d t 0 j ; i ) = 1 if word d t 0 j is lab eled as theme i ; otherwise ( d t 0 j ; i ) = 0. W is the size of the sliding windo w in terms of time points.
 The life cycle of eac h theme can then be mo deled as the variation of the theme strengths over time.

The analysis of theme life cycles thus involves the follo w-ing four steps: (1) Construct an HMM to mo del how themes shift between eac h other in the collection. (2) Estimate the unkno wn parameters of the HMM using the whole stream collection as observ ed example sequence. (3) Deco de the col-lection and lab el eac h word with the hidden theme mo del from whic h it is generated. (4) For eac h trans-collection theme, analyze when it starts, when it terminates, and how it varies over time. Tw o data sets are constructed to evaluate the prop osed ETP disco very metho ds. The rst, tsunami news data, con-sists of news articles about the event of Asia Tsunami dated Dec. 19 2004 to Feb. 8 2005. We downloaded 7468 news articles from 10 selected sources, with the keyw ord query "tsunami". As sho wn in Table 1, three of the sources are in Asia, two of them are in Europ e and the rest are in the U.S. Table 1: News sources of Asia Tsunami data set
The second data set consists of the abstracts in KDD con-ference pro ceedings from 1999 to 2004. All the abstracts were extracted from the full-text pdf les downloaded from the ACM digital library 2 . 2 articles were excluded because they were not recognizable by the pdf2text soft ware in Lin ux, http://www.acm.org/dl giving us a total of 496 abstracts. The basic statistics of the two data sets are sho wn in Table 2. We inten tionally did not perform stemming or stop word pruning in order to test the robustness of our algorithms.

On eac h data set, two exp erimen ts are designed: (1) Par-tition the collection into time interv als, disco ver the theme evolution graph and iden tify theme evolution threads. (2) Disco ver trans-collection themes and analyze their life cy-cles. The results are discussed below.
Since news rep orts on the same topic may app ear ear-lier in one source but later in another (i.e., \rep ort dela y"), partitioning news articles into overlapping , as opp osed to non-o verlapping sub collections seems to be more reasonable. We thus partition the our news data into 5 time interv als, eac h of whic h spans about two weeks and is half overlapping with the previous one. We use the mixture mo del discussed in Section 3 to extract the most salien t themes in eac h time interv al. We set the bac kground parameter B = 0 : 95 and num ber of themes in eac h time interv al to be 6. The varia-tion of B is discussed later. Table 3 sho ws the top 10 words with the highest probabilities in eac h theme span. We see that most of these themes suggest meaningful subtopics in the con text of the Asia tsunami event. Figure 6: Theme evolution graph for Asia Tsunami
With these theme spans, we use KL-div ergence to further iden tify evolutionary transitions. Figure 6 sho ws a theme evolution graph disco vered from Asia Tsunami data when the threshold for evolution distance is set to = 12. From Figure 6, we can see sev eral interesting evolution threads whic h are annotated with sym bols.

The thread lab eled with a may be about warning systems for tsunami. It is interesting to see that the nation covered by the thread seems to have evolved from the U.S. in perio d l , to China in l 2 , and then to Japan in l 3 . In thread b , themes 3, 4, and 5 in perio d l 1 indicate the aids and nan-cial supp ort from UN, from local area, and special aids for children, resp ectiv ely. They all sho w an evolutionary transi-tion to theme 2 (donation from UK) and theme 3 (aid from US) in l 2 . The latter theme further evolves into theme 5 in l , whic h is mainly about money supp ort from US. Thread c begins with music-related events and aids from UK. It shifts to talk about concerts in Hong Kong and then Japan with the purp ose of raising funds for donation. Thread d is about the personal exp eriences of surviv ors. It starts with theme 5 in l 2 , goes through theme 6 in l 3 , theme 3 in l 4 , and nally evolves into theme 3 in l 5 . There are also sev eral short but noticeable theme evolution threads. For example, thread e is about cric ket matc hes for donation, while thread f is about deaths and losses in the disaster.

In the latest two time interv als, most themes are no longer about the tsunami event, indicating that the event was prob-ably receiving diminishing atten tion in these two perio ds, whic h can be seen more clearly later from the analysis of the life cycles of themes. There are two politics-related short theme threads (i.e., g and h ). In thread g , theme 1 in l about political issues (\reb els" and \peace"). It splits into two themes in l 5 , about North Korea and the Aceh peace talk, resp ectiv ely. Theme 2 and theme 5 in l 4 represen t crit-icisms on the Iraq a air (one for military issues and one for the high exp enditure/cost). In l 5 , they merged into a single theme, whic h men tions the budget on Iraq and Afghanistan issues. Interestingly , by linking bac k to the articles, it turns out to be arguing for shrinking the budget on the war issues and o ering more aid for the disaster.

Note that multiple threads may share one or more com-mon themes, resulting in thread ambiguit y. For example, themes 2, 3 and 4 of l 1 all have a high similarit y to theme 2 of l 2 . In the analysis above, we only included theme 2 of l in thread c , because themes 3 and 4 do not app ear to be sim-ilar to theme 2 of l 2 in the same way as theme 1 of l 3 is. A very interesting future researc h direction would be to study how we can automatically perform thread disam biguation.
Our second exp erimen t aims to mo del the life cycles of trans-collection themes. In this exp erimen t, we use two indi-vidual sources (CNN and Xinh ua News) instead of the whole mixed collection to avoid \rep ort dela y". The ve trans-collection themes extracted from CNN and Xinh ua News are sho wn in Table 4.

The ve themes from CNN roughly corresp ond to (1) re-searc h and lessons about the tsunami; (2) personal exp e-rience of surviv ors; (3) Special aid program for children; (4) general rep orts and statistics; (5) aids and donations from the world, esp ecially from the U.S. The ve themes from Xinh ua roughly corresp ond to (1) statistics of death and missing; (2) rep orts and stories at the scene; (3) dona-tions from China; (4) aids and donations from the world; (5) researc h and lessons about the tsunami. Some themes (e.g., CNN-theme1 and XINHUA-theme5) are common to both sources, while some others (e.g., CNN-theme5 and XINHUA-theme3) clearly re ect the di eren t regions of the two sources.

In Figure 7 we plot the absolute strengths of the trans-collection themes over time for CNN ( W = 10). We see that the absolute strengths of all ve themes are increasing in the rst 10 days after Dec. 24, 2004. Rep orts on aids for children and aids from the world begin to deca y after that. General rep orts and statistics starts to deca y around Jan 10 for the rest of the time. Around Jan. 7th, the theme Figure 7: Absolute strength life cycles in CNN data on the researc h and lessons about tsunami starts to increase again. The same pattern is disco vered in rep orts on personal exp eriences, whic h is probably because surviv ors had come bac k to their home coun try around that time. Both themes drop sharply around Jan. 17. After Jan. 22, all 5 themes retain a low strength level, indicating the event was receiving diminishing atten tion. The normalized strengths of themes in the CNN data sho w similar patterns.

In Figure 8, we sho w the absolute and normalized strengths of the ve trans-collection themes over time in Xingh ua News ( W = 10). We see that, in the rst week beginning Dec. 25th 2004, all 5 themes are increasing rapidly , but they all begin to deca y around Jan. 10th except for stories and rep orts at the scene, whic h increases again after a roughly 10-da y perio d of mild decreasing. The theme about death statistics begins to deca y all the time after Jan. 16. Both aids from China and the researc h and lessons about tsunami presen t a second rise in late Jan uary , although not as sig-ni can t as the rst one. In the normalized strength plot, it is easy to see that before Jan 3rd, the dominating theme is theme 5. In the next 10 days, aid from the world is most signi can t. In the follo wing 20 days, \on-scene stories" is the dominating theme, although its absolute strength is de-creasing for most of the time. In the last time perio d when the overall coverage of the topic had signi can tly decreased, Aids from China is relativ ely stronger than other themes. Comparing CNN and Xinh ua, we see the life cycles of the correlated themes in the two data sets exhibit comparable patterns but with some di erences.
The publication year naturally suggests a non-o verlapping partition of the KDD abstract data. We thus treat all the abstracts published in one year as one time interv al. The theme spans extracted from eac h year using the mixture Figure 8: Absolute (top) and normalized (bottom) strength life cycles in Xinh ua News mo del with B = 0 : 9 are sho wn in Table 5. The num ber of themes sligh tly di ers from year to year because we apply a threshold to select only the most salien t themes as de-scrib ed in Section 3. Similar to what we have seen on the news data, the themes here are also mostly meaningful in the con text of KDD publications. The three themes in the year of 1999 are about asso ciation rule mining, clustering, and classi cation resp ectiv ely, whic h are all traditional data mining topics, compared with the new topics, suc h as spa-tial data mining (theme 1) and gene and microarra y mining (theme 2), extracted in the year of 2004.

A theme evolution graph extracted using an evolution dis-tance threshold of = 12 : 5 is sho wn in Figure 9, where we see sev eral interesting theme threads.

Thread a starts with theme 3 in 1999 (ab out classi ca-tion). It rst evolves into theme 1 in 2001 (typical classi -cation techniques suc h as SVM), and then evolves into web classi cation in 2002. The next theme span on this thread is about clustering and random variables, whic h has some in uence on theme 1 in 2004. Another evolution thread ( b ) starts with asso ciation rule mining in 1999, and transits into frequen t item set in 2001. Both themes sho w strong evolu-Figure 10: Normalized strength life cycles in KDD user to con trol the pattern analysis results. We now discuss them in some detail.

In the mixture mo del for theme extraction, B con trols the strength of our bac kground mo del, whic h is used to \ab-sorb" non-informativ e words from the themes. In general,
B should be set to re ect a user's kno wledge about the noise (i.e., the non-informativ e common words) in the text stream; the more noise we believ e our data set has, the larger B should be. Our exp erimen ts have sho wn that, in ordinary English text, the value of B can be set to a value between 0 : 9 and 0 : 95. Within this range, the setting of B does not a ect the extracted themes signi can tly, but it does a ect the top words with the highest probabilities; a smaller B tends to cause non-informativ e common words to sho w up in the top word list. Parameter k represen ts the exp ected num ber of subtopics in a sub collection. In our exp erimen ts, we determine the num ber of themes by using a relativ ely large k and drop a theme j , if the value of 1 j C is signi can tly low.
 Another parameter is the evolution distance threshold . This parameter has a \zo oming" e ect for the disco vered theme evolution graph. A tigh ter (smaller) would only al-low us to see the strongest evolutionary transitions, whereas a looser (larger) would allo w us to examine some weak er evolutionary transitions as well.

Yet another parameter is the size of sliding windo w W , whic h con trols the amoun t of supp orting documen ts when computing the strength of theme at time t and a ects the smo othness of the life cycle curv e. A small W introduces less smo othing and would allo w us to see the temp oral pat-terns in high resolution, but may also mak e it dicult to see the overall trend. A larger W would give a smo other curv e, but may hide some interesting local variation patterns. Re-garding the \rep ort dela y" problem in the news domain, a reasonable value for W app ears to be 7-15 days (3-7 days at eac h side of time t ).
While TTM has not been well studied, there are sev eral lines of researc h related to our work. For example, in Klein-berg's work on disco vering burst y and hierarc hical struc-tures in streams [10], text streams are con verted to temp o-ral frequency data and an in nite-state automaton is used to mo del the stream. Detection of novel topics and trends in text streams has been studied by sev eral researc hers [3, 18, 19, 11, 13, 14], but their focus is to iden tify emerg-ing trends rather than summarize the complete evolutionary theme patterns in a given text stream as we do.

An interesting related work to our analysis of theme life cycles is [16], where Perkio and others used a Multinomial PCA mo del to extract themes from a text collection and they used a hidden theme-do cumen t weigh t, whic h is similar to d;j in Section 3, to compute the strength of a theme. The ma jor di erence between our work and theirs is that we mo del the theme transitions in a con text-sensitiv e way with an HMM, whic h presumably captures the natural pro ximit y of similar topics better.

Text clustering is another well studied problem relev ant to our work. Speci cally , the asp ect mo dels studied in [9, 20, 2] are related to the mixture theme mo del we use to extract themes. However, these works do not consider tem-poral structures in text. Nallapati and others studied how to disco ver sub-clusters in a news event and structure them by their dep endency , whic h could also generate a graph struc-ture [15]. A ma jor di erence between our work and theirs is that they perform documen t level clustering, while we per-form theme level word clustering. Another di erence is that they do not consider the variations of subtopics in di eren t time perio ds while we analyze life cycles of themes.
Since a theme evolution graph and theme life cycle can serv e as a good summary of a collection, our work is also partially related to documen t summarization (e.g., [12, 1]). Allan and others presen ted a news summarization metho d based on ranking and selecting sen tences obeying temp oral order [1]. However, summarization intends to retain the ex-plicit information in text in order to main tain delit y, while we aim at extracting non-ob vious implicit themes and their evolutionary patterns.
Text streams often con tain laten t temp oral theme struc-tures whic h re ect how di eren t themes in uence eac h other and evolve over time. Disco vering suc h evolutionary theme patterns can not only rev eal the hidden topic structures, but also facilitate navigation and digestion of information based on meaningful thematic threads. In this pap er, we pro-pose general probabilistic approac hes to disco ver evolution-ary theme patterns from text streams in a completely unsu-pervised way. To disco ver the evolutionary theme graph, our metho d would rst generate word clusters (i.e., themes) for eac h time perio d and then use the Kullbac k-Leibler div er-gence measure to disco ver coheren t themes over time. Suc h an evolution graph can rev eal how themes change over time and how one theme in one time perio d has in uenced other themes in later perio ds. We also prop ose a metho d based on hidden Mark ov mo dels for analyzing the life cycle of eac h theme. This metho d would rst disco ver the globally inter-esting themes and then compute the strength of a theme in eac h time perio d. This allo ws us to not only see the trends of strength variations of themes, but also compare the relativ e strengths of di eren t themes over time.
 We evaluated our metho ds using two di eren t data sets. One is a stream of 50 days' news articles about the tsunami disaster that happ ened recen tly in Asia, and the other is the abstracts of the KDD conference pro ceedings from 1999 to 2004. In both cases, the prop osed metho ds can gener-ate meaningful temp oral theme structures and allo w us to summarize and analyze the text data from temp oral per-spectiv e. Our metho ds are generally applicable to any text stream data and thus have man y poten tial applications in temp oral text mining.

There are sev eral interesting directions to further extend this work. First, we have only considered a at structure of themes; it would be interesting to explore hierarc hical theme clustering, whic h can give us a picture of theme evolutions at di eren t resolutions. Second, we can dev elop a temp oral theme mining system based on the prop osed metho ds to help a user navigate the stream information space based on evolutionary structures of themes. Suc h a system can be very useful for managing all kinds of text stream data. Finally , temp oral text mining (TTM) represen ts a promising new direction in text mining that has not yet been well-explored. In addition to evolutionary theme patterns, there are man y other interesting patterns suc h as asso ciations of themes across multiple streams that are interesting to study .
We thank Tao Tao for his constructiv e technical com-men ts and Hang Su for helping collect the tsunami data. We are grateful to the three anon ymous review ers for their extremely useful commen ts. This material is based in part upon work supp orted by the National Science Foundation under award num bers CAREER-I IS-0347933 and ITR-I IS-0428472. [1] J. Allan, R. Gupta, and V. Khandelw al. Temp oral [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Laten t [3] S. Boykin and A. Merlino. Mac hine learning of event [4] T. M. Cover and J. A. Thomas. Elements of [5] W. B. Croft and J. La ert y, editors. Language [6] A. P. Dempster, N. M. Laird, and D. B. Rubin. [7] R. Feldman and I. Dagan. Kno wledge disco very in [8] M. A. Hearst. Untangling text data mining. In [9] T. Hofmann. Probabilistic laten t seman tic indexing. [10] J. Klein berg. Burst y and hierarc hical structure in [11] A. Kon tostathis, L. Galitsky , W. M. Pottenger, [12] R. Kumar, U. Mahadev an, and D. Sivakumar. A [13] J. Ma and S. Perkins. Online novelty detection on [14] S. Morinaga and K. Yamanishi. Tracking dynamics of [15] R. Nallapati, A. Feng, F. Peng, and J. Allan. Event [16] J. Perkio, W. Bun tine, and S. Perttu. Exploring [17] L. Rabiner. A tutorial on hidden mark ov mo dels and [18] K. Rajaraman and A.-H. Tan. Topic detection, [19] S. Roy, D. Gevry , and W. M. Pottenger.
 [20] C. Zhai, A. Veliv elli, and B. Yu. A cross-collection
