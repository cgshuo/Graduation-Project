 Word ambiguity and vocabulary mismatch are critical prob-lems in information retrieval. To deal with these problems, this paper proposes the use of translated words to enrich document representation, going beyond the words in the original source language to represent a document. In our approach, each original document is automatically translated into an auxiliary language , and the resulting translated doc-ument serves as a semantically enhanced representation for supplementing the original bag of words. The core of our translation representation is the expected term frequency of a word in a translated document, which is calculated by av-eraging the term frequencies over all possible translations, rather than focusing on the 1-best translation only. To achieve better efficiency of translation, we do not rely on full-fledged machine translation, but instead use monotonic translation by removing the time-consuming reordering com-ponent. Experiments carried out on standard TREC test collections show that our proposed translation representa-tion leads to statistically significant improvements over us-ing only the original language of the document collection. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval models ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Machine trans-lation Algorithms, Experimentation, Performance, Theory
Words , or stemmed words, are the most popular index terms used in modern information retrieval (IR) systems due to their high simplicity. However, there are critical chal-lenges that retrieval systems face with the use of words, one of which is word ambiguity in a query and a document. The meaning of a word changes with its context. For example, the word interest may be used to mean  X  X uriosity, X  or  X  X  charge for borrowing money, X  depending on the surrounding context. Another challenge is vocabulary mismatch between a query and a document. Since there are many alternative ways to represent the same concept, such as using synonyms or paraphrases, a document may not contain a query word but may still be relevant to the query. For example, find , observe ,or detect can possibly mean the same thing as dis-cover .

To deal with these problems, many studies in IR have investigated word sense disambiguation (WSD) on queries and documents [20, 40, 34, 35, 13, 29, 36, 16], or have performed query expansion [15, 23, 43, 9, 10, 42, 2, 26] or document expansion [3, 24, 21] by appending semanti-cally related words into the original query or document. Some of these approaches (e.g., pseudo-relevance feedback) have shown marked improvements in retrieval performance. However, most existing works in the literature are basically monolingual approaches which are restricted to the use of the original source language of the document collection, without taking advantage of potentially rich semantic information drawn from other languages. Through other languages, var-ious ways of adding semantic information to a document could be available, thereby leading to potentially more im-provements than using the original source language only.
Taking a step toward using other languages, we propose the use of translation representation by alternatively repre-senting the original document content with the words of an additional language (i.e., an auxiliary language ), one that is different from the language of a given collection (i.e., the source language). In our approach, each original document is  X  X utomatically translated X  into an auxiliary language, and the resulting translated document serves as a semantically enhanced representation for supplementing the original bag of words. Specifically, the vocabularies of the source and auxiliary languages are connected in a many-to-many re-lation via translation, which could bring about important benefits in dealing with the two addressed problems. First, there are multiple candidate words in an auxiliary language that are translated to a source word. Therefore, the word ambiguity problem can be resolved, during the process of choosing a correct translation in a given context of a source word. Conversely, various different source words that refer to similar concepts or senses are translated into only a few words or a single word in an auxiliary language. Thus, the vocabulary mismatch problem in the source language is to some extent ameliorated by using translated words in the auxiliary language.

To achieve better efficiency in translation, instead of rely-ing on full-fledged machine translation (MT), we propose a simplified method of constructing the translation represen-tation. Since there is no need for a full translation in our ad-hoc retrieval task, we only estimate the expected term frequency of a word in the translated document, by tak-ing the average of the term frequencies of the word over all possible translated documents. Our core assumed setting is monotonic translation in which the word order in the source sentence is not changed after translation. This assumption enables us to exclude the time-consuming reordering mod-ule from the decoding process. In order to extensively apply monotonic translation into any pair of grammatically dissim-ilar languages (e.g., English and Chinese), we additionally employ a distorted language model for an auxiliary language in which the word order follows the grammatical order of the original source language, not of the auxiliary language. Based on these simplified settings for translation, the trans-lation representation could be more efficiently constructed without relying on full-fledged MT.

Experimental results obtained on standard TREC collec-tions show that the use of the proposed translation repre-sentation consistently outperforms baseline retrieval meth-ods that use the collection language only. Our comparison is made against three different baselines  X  a commonly used baseline, query expansion based on pseudo-relevance feed-back, and document expansion based on cluster-based re-trieval.
Word ambiguity has been extensively investigated in infor-mation retrieval using WSD. The initial research efforts on WSD for information retrieval were performed using man-ual sense annotation [20, 13], on artificially created pseudo-words [34], and on automatic sense disambiguation or clus-tering [40, 35, 29]. More recent work has scaled up the use of WSD to a large test collection [36] and two medium-size test collections [16], reporting improved retrieval performances using WSD compared to baseline word-based indexes.
Query expansion adds new expansion terms into the original query, which has been one of the most effective approaches to resolve the vocabulary mismatch problem. Expansion terms are selected from hand-crafted thesauri such as WordNet [10], co-occurrence based similarity the-sauri [15], highly-ranked retrieved documents (i.e., pseudo-relevance feedback) [23, 43], highly-ranked retrieved pas-sages [2, 26], or external collections such as the Web or Wikipedia [9, 42].

Document expansion has a similar motivation as query expansion, but expansion is applied to documents and not to the query [24, 21]. Expansion terms are selected from the cluster that a document belongs to [24], or from documents most similar to the given document [21].

An interesting work related to ours is Berger and Lafferty [3], which suggested the use of a translation model for the information retrieval task. However, no translation was ap-plied between different languages. Instead, expansion was performed by adding words to a document, or reweighting words, so as to better match a given query. Their translation approach is therefore closer to document expansion.
Most approaches for monolingual retrieval tasks have been restricted to the use of the original collection language only, except for a few recent studies [12, 8]. As is the case with our study, they also utilized multilingual information by us-ing an additional language in order to improve monolingual retrieval. However, they used an external auxiliary language collection , which is not automatically translated from the originally given collection. Gao et al. [12] expanded an original document by using similar documents from an ex-ternal auxiliary language collection. Chinnakotla et al. [8] enriched the original expanded query by using additional expanded queries resulting from applying pseudo-relevance feedback on external auxiliary language collections, show-ing improved performances on CLEF test collections. Com-pared to our approach, these two methods are closer to monolingual-based approaches using external collections [9, 42] of the same language as the original collection. Unlike these approaches, we do not rely on an external collection but instead automatically create new translated documents, and thus our resu lts are obtained within the given test col-lection only.

Recently, Trieschnigg et al. [39] used a concept -based rep-resentation in order to enrich th e original word-based repre-sentation, thereby proposing the translation of the original word language to a concept language . While their use of con-cept language in part has a similar motivation to ours, their translation models are based solely on the use of translation at the lexical level (i.e., word-to-concept), and thus their method is very different from our context-dependent style of translation.
Cross-lingual information retrieval (CLIR) addresses the problem of retrieving documents written in a language dif-ferent from the query language [30]. Even though a common approach in CLIR is to perform query translation (QT) us-ing a bilingual dictionary [32], there were studies showing that combining both QT and document translation (DT) improved retrieval performance in CLIR by using bilingual representations in both the source and target language [28, 19, 7, 4]. McCarley [28] trained a statistical MT system from a parallel corpus, applied it to perform QT and DT, and showed that the combination of scores from QT and DT drastically improved either method alone. Similar results have been reported using either a full-fledged MT system [4] or a simple translation algorithm [7]. Kraaij et al. [19] used the translation model of IBM Model 1 [5], obtained from an automatically constructed parallel corpus from the web, and also reported that the combination of QT and DT improved either method alone.

These hybrid approaches in CLIR resemble ours in that we also use translated words of both queries and documents. The major difference, however, is that our goal is to improve monolingual IR and not CLIR. Furthermore, some of these approaches perform translation without taking into account the surrounding context of a source word [19, 7], while our proposed translation model is context-dependent and thus produces different translated words depending on the con-text of a source word.

To the best of our knowledge, the work most similar to ours is Franz and McCarley [11], who also applied auto-Figure 1: The word  X  biological  X  and its paraphrased or synonymous words, and their corresponding translated Chinese words. matic translation for monolingual retrieval but using French as the auxiliary language. However, their method did not achieve any statistically significant improvement over a base-line retrieval that used monolingual representation. More-over, they only considered the 1-best translation, while we use the expected frequency of a word computed from all possible translated representations.
To illustrate why translation is helpful in handling the word ambiguity and vocabulary mismatch problems, con-sider the following TREC query Q335  X  Adoptive Biologi-cal Parents  X , and focus on the ambiguous word  X  biological  X . The many-to-many translation relations for biological and its paraphrased or synonymous words between English and Chinese are depicted in Figure 1.

As shown in Figure 1, biological has two different Chinese translations,  X   X   X  (sh  X  engw` u) X  and  X   X   X  (q  X  insh  X  eng) X , which correspond to its two different senses in WordNet, respec-tively: (1)  X  X ertaining to biology or to life and living things X  ( X   X   X   X : s h  X  engw` u), and (2)  X  X f parents and children; related by blood; biological child X  ( X   X   X   X : q  X  insh  X  eng). Therefore, word ambiguity in the source language is dealt with during the process of selecting a correct translation between two candidates.

Moreover, the word biological in the query context can be equivalently replaced with natural or birth ,(e.g., natural parents , birth parents ) as paraphrased expressions, but the Chinese translation for all of them is only a single word,  X   X  (q  X  insh  X  eng). X  This provides a good example to illustrate that the vocabulary mismatch problem in a source language can often be overcome if we use translated words in an aux-iliary language.
Our approach of using translation representation for a monolingual retrieval task is summarized in Figure 2. Each document in the source collection is translated using the pro-posed method of expected frequency estimation, producing bilingual document representations (Section 5). When a new test query is given, the query is translated using the same translation procedure, constituting bilingual query represen-tations (Section 5). Next, initial retrieval on both represen-tations is performed (Sections 6.1 and 6.2), and the two resulting relevance scores are combined to produce a ranked Figure 2: Overview of our approach of using trans-lation representation. list of retrieved documents (Section 6.3). Using the retrieved documents, pseudo-relevance feedback is performed for both representations, and the two resulting relevance scores of documents are again combined (Section 6.4). Furthermore, we also apply document expansion on bilingual representa-tions, as an alternative option for the initial retrieval (Sec-tion 6.5).
In this paper, source language refers to the language of a given document collection, and auxiliary language refers to an additional language used as the translation representa-tion. Our translation model takes a phrase as translation unit, which refers to a contiguous sequence of words, con-ceptually including a single word. Auxiliary word , auxiliary phrase ,and auxiliary sentence refer to a possible translation of a source word, phrase, and sentence, respectively.
Suppose that a source sentence is given by e = e I 1 = e  X  X  X  e I ,where | e | = I is the length of the source sentence. We do not produce a full translation but instead use the ex-pected frequency of a word in the translated auxiliary sen-tence for the given source sentence. The expected frequency is defined as follows.

Definition of expected frequency : Suppose F is a ran-dom variable, the range of which is F , the set of all sentences of the auxiliary language. Given source sentence e ,the ex-pected frequency of an auxiliary word w in the translation of e is the conditional expectation of c ( w, F )giventheevent e , as follows: where c ( w, f ) is the number of word occurrences of w in the auxiliary sentence f ,and P ( f | e ) is the sentence translation probability of e translating into f .
Let us first describe a word-based model for computing the expected frequency of Eq. (1). We use simplified monotonic translation allowing only forward translation among possible translations in [38]. The word order is not changed during translation, and a source word at position i (i.e., e i )istrans-lated to an auxiliary word at the same position i .Inthis setting, the translation problem is exactly the same as the tagging problem of a hidden Markov model (HMM), where each state corresponds to an unknown auxiliary word and state translation is modeled by an n -gram language model. Thus, the expected frequency of Eq. (1) for the word-based model can be effectively calculated using the EM algorithm, which is based on the forward-backward algorithm of HMM.
We now generalize the word-based model to formulate a phrase-based translation model.
A word lattice for a source sentence e is defined as a con-nected, directed acyclic graph G e =( V e , E e ) [27]. Here, the set of vertices { 0 , 1 ,  X  X  X  ,I } consisting of all source word positions, where 0 indicates a specialized sentence-starting state #, and E e is the set of edges. Each edge  X   X  X  e is labeled with a translated auxiliary phrase and it is denoted by ( i, j,  X  f ). i and j denote the starting and ending vertices of the source phrase e j i +1 = e i +1  X  X  X  e j ,and  X  f denotes an auxiliary phrase, that is, a translation of the source phrase e i +1 . The source and auxiliary phrases associated along the for an edge  X  =( i, j,  X  f ),  X  e [  X  ]= e j i +1 and  X 
A translation path  X  on G e is the sequence of edges  X  =  X   X  X  X   X  |  X  | ,where |  X  | is the number of edges in the path Each edge  X  i in the path immediately follows the previous edge  X  i  X  1 ; the starting position of each edge  X  i is equal to the ending position of the previous edge  X  i  X  1 .Apath  X  is called a complete translation path on G e if  X  translates all source words e 1  X  X  X  e I , so that the head of  X  1 is 0 and the tail of  X  is I . The set of all complete translation paths is referred to as  X . Given a path  X  , the sequence of auxiliary phrases along the path is denoted by  X  f [  X  ]whichmeans  X  f [  X  1 ] , Similarly, the sequence of source phrases on the path  X  is denoted by  X e [  X  ]whichmeans  X  e [  X  1 ] ,  X  X  X  ,  X  e [  X 
Word lattice example : Figure 3 shows an example of a word lattice, where the source language is English and the auxiliary language is German. There are 7 edges consisting of  X  1 ,  X  X  X  .  X  7 , and their source and auxiliary phrases are goes to  X  X nd  X  f [  X  2 ]= X  er geht nach  X , and so on. This lattice contains five complete translation paths:  X  = {  X  1 ,  X  X  X  where  X  1 =  X  1  X  3  X  5  X  7 ,  X  2 =  X  1  X  4  X  5  X  7 ,  X  3  X   X  4  X  6 ,and  X  5 =  X  2  X  7 . Among these paths, source phrases and auxiliary phrases of  X  1 and  X  3 are  X e [  X  1 ]= X  he  X  X  goes  X   X  to  X  X  house  X  X nd  X  f [  X  1 ]= X  er  X  X  geht  X  X  auf  X  X  hause  X ,  X e [  X  he  X  X  goes  X  X  to house  X  X nd  X  f [  X  3 ]= X  er  X  X  geht  X  X  zu haus  X .
The path probability p (  X  ) is defined as the joint proba-Figure 3: An example of a word lattice ( I =4), where the source language is English and the auxil-iary language is German. Here, each  X  i is an edge, defined as  X  1 =(0 , 1 ,  X  er  X  ) ,  X  2 =(0 , 3 ,  X  er geht nach  X  ) ,  X  =(1 , 2 ,  X  geht  X  ) ,andsoon. bility of the source phrases and auxiliary phrases along the decomposes p (  X  )into: Note that p (  X  ) in Eq. (2) consists of two main parts  X  the translation part p (  X e [  X  ] p (  X  f [  X  ]). First, the translation part, p (  X e [  X  ] the translation probability from the auxiliary phrases  X  the source phrases  X e [  X  ], based on the phrase segmentation underlying the path  X  . To estimate the translation proba-bility, we make two simplifying assumptions. (1) Monotonic translation: As mentioned in the introduction, this ensures that the order of the auxiliary phrases in the translated sen-tence is the same as the original order of the source phrases. (2) Independent translation: Each source phrase is sepa-rately translated into an auxiliary phrase independent of the other source phrases. Based on these two assumptions, p (  X e [  X  ]
Second, the language model part, p (  X  f [  X  ]), denotes the probability that the auxiliary sentence  X  f [  X  ]alongthepath  X  is generated from the auxiliary language model. We uti-lize the trigram language model to estimate p (  X  f [  X  ]), as it is widely used in statistical machine translation [17]. Let the auxiliary sentence of  X  be given by the word sequence f ,  X  X  X  ,f J . Then, p (  X  f [  X  ]) is decomposed into trigram prob-abilities as follows: 1
The part needed for computing the expected frequency defined by Eq. (1) is the sentence translation probability p ( f | e ). In this paper, p ( f | e ) is defined as the ratio of the probabilities of the paths generating f in the word lattice to the sum of all path probabilities in G e , as follows:
In Eq. (3) , we use the sentence-starting state # to define f and f  X  1 . For example, p ( f 1 | f  X  1 ,f 0 )and p ( f 2 p ( f 1 | # , #) and p ( f 2 | # ,f 1 ), respectively. where  X ( f )  X   X  denotes the set of the complete translation paths, where each path generates f .

A naive implementation to compute the expected fre-quency will be extremely inefficient, since the number of all possible translations is exponential with respect to the number of source words. To tractably estimate the expected frequency of Eq. (1), we compute the edge posterior p (  X  for each edge  X  in the lattice G e : where  X (  X  )  X   X  denotes the subset of complete translation paths through the edge  X  . The edge posterior is computed ef-ficiently using a variant of the forward-backward algorithm, as presented in [41].

Finally, E e [ c ( w, F )] is computed in terms of the edge pos-teriors as follows: where c ( w,  X  f [  X  ]) is the number of word occurrences of w in the auxiliary phrase  X  f [  X  ] labeled on the edge  X  .
The problem in using our simplified monotonic translation of Section 5.2 and Section 5.3 is that the word order of the trigram f i  X  2 ,f i  X  1 ,f i is not consistent with the grammatical order of the auxiliary language. Therefore, our monotonic translation is acceptable only when the auxiliary language is grammatically similar to the source language.

In order to allow monotonic translation for a pair of gram-matically dissimilar languages, we use a distorted language model for the auxiliary language, in which the auxiliary sen-tence follows the word order of the source language and not the auxiliary language. To estimate the distorted language model, we constructed a reordered auxiliary language cor-pus, by making the word order of each auxiliary sentence maximally consistent with the word order of the source lan-guage.

The details of the reordering procedure are given as fol-lows. Suppose a pair of source and auxiliary sentences is ment in which e i is aligned to f j ,and A = { ( i, j ) } of word alignments for the given sentence pair. The outcome of the reordering procedure is the reordered position for f denoted by b j . To determine b j ,let B j be { i | ( i, j ) set of all positions of source words that are aligned to f in the alignment set A . The reordered position b j is then obtained as follows: where a ( j )isargmin k {| j  X  k || B k =  X  X  .

Once b j is computed for all auxiliary words, we reorder each auxiliary sentence such that f i precedes f j if b i To ensure the uniqueness of reordering, when b i = b j ,we make f i precede f j for i&lt;j .

Example of reordering : Figure 4 shows an example of the reordering procedure. Each arrow denotes a word alignment from e i to f j .For f 2 , f 3 ,and f 4 , b j is simply computed from the set of word alignments B j . For instance, for the auxiliary word f 4 , B 4 = { 1 , 2 } ,and b 4 is 2, according to Eq. (4). For another word f 1 , however, B 1 is the empty Figure 4: Example of the reordering procedure. r ( f ) indicates the reordered auxiliary sentence for the givenpairofalignedsentences ( e , f ) . set. To handle this case, the definition given by Eq. (4) states that we first find the nearest auxiliary word f a (1) where B a (1) is not empty, and then use its reordered position b a (1) as b 1 . In this example, the word f a (1) is f 2 , resulting in b 1 = b 2 .
We utilized the SRILM toolkit [37] with Kneser-Ney smoothing for estimating the auxiliary language models. Two types of translation probabilities p (  X  e |  X  f ) for the word-based and phrase-based models were obtained from the word translation table of GIZA++ [31] and the phrase translation table of Moses [18], respectively. We used the word align-ment output of GIZA++ to construct the reordered auxil-iary language corpus described in Section 5.4. For the word-based model, we allowed null translation, and thus utilized a slightly modified version of the forward-backward procedure. For the phrase-based model, the maximum length of source phrases was fixed at 7. We only selected the top M auxiliary words (or phrases) for constructing the bilingual dictionaries obtained from GIZA++ and Moses for each source word (or phrase), ranked by the translation probability P (  X  f |
We removed the translation candidates with very low probabilities at each word position j . To achieve this, we introduced G ( w, j )= the sum of the frequencies of word w , over all paths ending at position j ,where Q ( w, i, j ) is defined as follows: which conceptually corresponds to the partial expected count of w in the case where the source phrase is restricted to e j i +1 . We then applied the cut-off threshold  X  to G ( w, j ), below which it is excluded (i.e., G ( w, j ) &lt; X  ) when comput-ing the expected frequency of w . In addition, we kept only at most the top T values of G ( w, j ) at each position j .In this paper, M ,  X  ,and T were fixed at 10, 0.001, and 10, respectively.
We use the language modeling approach for the retrieval method. The language modeling approach ranks documents according to the likelihood that a query is generated from the document language model [33, 14], or more generally, the negative KL divergence between the query model P ( w | q ) and document model P ( w | d ) [22]: where q and d represent a query and a document, respec-tively.

We adopt Dirichlet-prior smoothing to estimate p ( w | d )as follows [43]: where c ( w, d ) is the term frequency of w in document d , is the total number of words in d , p ( w |C ) is the background collection model, and  X  is a smoothing parameter. The query model p ( w | q ) is estimated by using MLE: c ( w, q ) /
We now extend the retrieval model described in Section 6.1 in order to support translation representation with ex-pected frequencies. Let  X  be the translation operator,  X  ( d ) the translated representation resulting from applying the translation operator  X  for a given document d ,and Sent ( d ) the set of sentences in d obtained by sentence segmenta-tion. The term frequency of word w in  X  ( d ), denoted by c ( w,  X  ( d )), is defined as follows: The length of  X  ( d ), denoted by |  X  ( d ) | , is the expected length of the translated document, which is defined by P w  X  X  F c ( w,  X  ( d )), where V F is the vocabulary of the auxil-iary language.

By replacing c ( w, d )and | d | in Eq. (7) with c ( w,  X  ( d )) and |  X  ( d ) | , we obtain the following smoothed model for  X  ( d ): where w is a word in V F ,and p ( w |  X  ( C )) is defined by where C refers to the set of documents in a given collection. Similar to p ( w |  X  ( d )), we estimate the query model p ( w for the translation representation of the query q by using document d with respect to query q using Score (  X  ( q ) , X  ( d )) based on their translation representations.
To produce a single ranked list from two relevance scores using Eq. (6), that is, Score ( q , d ) on the source language and Score (  X  ( q ) , X  ( d )) on the auxiliary language, we use the following linear combination: where  X  is an interpolation parameter.
We further apply query expansion for multilingual repre-sentations. We choose pseudo-relevance feedback, because it is one of the most effective query expansion approaches. Theprocedureisasfollows:
For pseudo-relevance feedback in step 2, we adopt RM3, a variant of the relevance language models of [23], which is one of the most effective and robust pseudo-relevance feed-back methods in the language modeling framework [25]. To be more specific, suppose D init is the set of the initially retrieved documents. Then, the expanded query model P ( w | q ) used by RM3 is estimated based on the following formula [25]: P ( w | q )=  X P ( w | q )+(1  X   X  ) where  X  is an interpolation parameter for combining an orig-inal query with an expanded query, and P ( d | q )isthepos-terior probability of d , conditioned on having observed q . The posterior probability P ( d | q ) can be rewritten in terms of Score ( q , d ) as follows: For re-scoring the documents in step 3, we re-apply Dirichlet-prior smoothing as described in Eq. (7).
Document expansion (or cluster-based retrieval) can also be applied to multilingual representation, where the repre-sentation of each document is enriched with a set of similar documents called a cluster [24, 21]. Suppose cluster Clu is a set of documents similar to d ,and d clu is the cluster document representation of d . Then, cluster-term frequency of d clu for word w is defined as follows: We now additionally introduce d clu to indicate the cluster-enhanced document representation of d ,whichisthe weighted representation of the original source document d and its cluster d clu as follows: where  X  clu is the weight of document representation to clus-ter representation. To estimate the smoothed cluster lan-guage model, we adopt two-stage smoothing [24]: (1) The cluster-based model is first smoothed with the background collection model. (2) The original document model is fur-ther smoothed by the smoothed cluster model. Starting from the basic form given by Eq. (7), two-stage smooth-ing is derived by replacing term frequencies c ( w, d )bythe cluster-enhanced frequencies c ( w, d clu ) as follows: where | d clu | and | d clu | are the length of d clu and d spectively.

Similarly, we could define the translation representation  X  ( d clu ) for the cluster-enhanced document d clu by setting the term frequency c ( w,  X  ( d clu )) of word w as follows: with the following definition of c ( w,  X  ( d clu )): Given bilingual cluster-enhanced representations, we again use Score E + F ( q , d clu ) for combining the two relevance scores obtained from the bilingual representations.
To define Clu d , we use the method suggested by [21], where Clu d is a large virtual document comprising a con-catenation of the k most similar documents to d ( d itself can be included among the k documents). In this paper, k is fixed to 50. We apply Eq. (6) to find similar docu-ments, with  X  fixed to 1,500 and by taking the document as a query. Note that finding similar documents is only based on the source language, and thus Clu d is shared by both the source and auxiliary language.
For evaluation, we used three different standard TREC collections  X  ROBUST, WT2G, and WT10G. Table 1 shows the basic statistics for each test collection, where NumDocs is the number of documents, NumWords is the total number of word occurrences in each collection, and TopicSet is the range of topic numbers used for training and testing.
All experiments were based on the Lemur toolkit (version 4.12) 2 . When indexing English documents, we performed standard preprocessing on queries and documents by ap-plying Porter X  X  stemmer and removing stopwords using the standard INQUERY stoplist [1]. We used only the words in the  X  X itle field X  of a query topic for all our evaluations. For translating English documents and queries, we used the Penn Treebank tokenizer to preprocess them 3 .

MAP (mean average precision) was used as the evalua-tion measure. For each query, our evaluation was based on http://www.lemurproject.org http://www.cis.upenn.edu/  X  treebank/tokenizer.sed the top 1,000 retrieved documents. We reported statistical significance using paired t -test at 0.95 confidence level.
There are several parameters for each retrieval method:  X  ,  X  clu ,  X  ,and  X  . For ROBUST and WT10G, given a test set consisting of 50 queries, each parameter was selected by tuning on the other queries in the same test collection. For example, parameters for Q301 X 350 in ROBUST were tuned using Q351 X 450 and Q601 X 700 in the same ROBUST collection. For WT2G, we applied 5-fold cross validation, by dividing the 50 queries into 5 folds consisting of 10 queries each. For cluster-based retrieval, instead of directly tuning  X  , we tuned  X  by setting  X  =  X  (  X  clu + 1), so that the final value for  X  is more similar to the value of  X  used in the baseline retrieval.

For preparing the translation representation, we consid-ered Chinese as the auxiliary language, and applied the pro-posed translation models from English to Chinese over the collection. To obtain the translation probabilities p (  X  e used a subset of the parallel corpora used in [6], containing approximately 2.5M sentence pairs, 72M English tokens, and 65M Chinese characters. We removed long sentences con-taining more than 40 tokens when applying GIZA++ and Moses. Using the parallel corpus, we created two types of Chinese translation representations:
The major goal of our experiments is to examine whether the use of translation-enhanced document representation leads to improvements in retrieval performance, compared to using only the given collection language. Comparisons are made on three retrieval methods using the following lan-guage models:
Throughout this section, we refer to the original source representation by E , and refer to the Chinese translation representation obtained from Word and Phrase by C Word and C
Phrase , respectively.
Table 2 shows a comparison of the results obtained us-ing monolingual and bilingual representations on the setting of LM without query expansion and document expansion across three different collections. In Table 2, E denotes the baseline LM performed using Eq. (7), all of which used only the English queries and documents; C X denotes the run of LM using Chinese translation representation, where X could be Word or Phrase; and E + C X denotes the run of LM with the combination of monolingual and bilingual representation E and C X . Table 2: Comparison of bilingual representation with monolingual representation on the setting of LM. The mark * indicates statistical significance over E .
 Table 3: Comparison of bilingual representation with monolingual representation on the setting of RM3. The symbols * and + indicate statistical sig-nificance over two baselines LM and RM3 using only English representation, respectively.

R ROBUST WT2G WT10G 5 10 15 20 30
Our translation models ( E + C Word and E + C Phrase ) signifi-cantly improve the baseline E for most test collections. Com-paring the two translation types Word and Phrase ,wesee that the phrase-based model ( E + C Phrase ) gives the best re-sults in combination for all test collections, and its improve-ments over E are statistically significant for all three test col-lections, especially achieving an increase of more than 2.5% in MAP on the ROBUST test collection. Interestingly, even our models using only the auxiliary language ( C Phrase and C
Word ) often show better performances than E in ROBUST and WT2G for C Phrase , and in ROBUST for C Word .
Table 3 shows the comparison results of monolingual and bilingual representation on the setting of RM3 described in Section 6.4. In Table 3, E denotes the baseline RM3 using only the original English representation, and E + C X denotes the run of RM3 based on the bilingual representation of E and C X . The number of expanded terms for pseudo-relevance feedback in Section 6.4 was fixed to a maximum of 100. For the original English representation, the smoothing parame-ter  X  used for computing Eq. (11) was fixed to 1,500. For Chinese translation representation, different values of  X  were used for P ( w | d )and P ( d | q ) of Eq. (11), by fixing to 0 and Table 4: Comparison of bilingual representation with monolingual representation on the setting of CLM. The symbols * and + indicate statistical sig-nificance over two baselines LM and CLM using only English representation, respectively.
 1,500, respectively. 4 The smoothing parameter  X  at the sec-ond retrieval was fixed to 1,500 for both representations.
Applying RM3 alone without bilingual representation sig-nificantly improves the baseline E ,whichisalsoknownfrom previous results on RM3 [25]. Importantly, further improve-ments over RM3 are obtained by utilizing the translation words, in both word and phrase translation types, and these improvements are statistically significant especially on RO-BUST and often on WT2G and WT10G. Comparing the two translation types, the phrase-based model ( E + C Phrase )gives better retrieval performances than the word-based model
Table 4 shows the comparison results of monolingual and bilingual representation on the setting of CLM using the document expansion method of Section 6.5. In Table 4, E denotes the baseline CLM using the original English repre-sentation only, and E + C X denotes the run of CLM based on the bilingual representation of E and C X .

Document expansion without translation representation (i.e., E in Table 4) is highly effective on the ROBUST col-lection, achieving more than 2.5% MAP increase over the baseline LM (i.e., E in Table 2), with statistical significance. However, its improvements on the other web test collections of WT2G and WT10G are insignificant. Additionally us-ing the Chinese translation representation ( E + C X )achieves further improvements over CLM. Specifically, our phrase-based model ( E + C Phrase ) achieves about 2% further increase of MAP over the baseline CLM ( E ) on ROBUST, finally leading to a noticeable increase of 4.5% MAP over the base-line LM. Even on the web collections of WT2G and WT10G, which are not improved by CLM, our phrase-based model ( E + C Phrase ) leads to statistically significant improvements, achieving about 2% increase in MAP on WT2G and about 1.5% increase in MAP on WT10G.
Figure 5 shows the curves of retrieval performances us-ing our translation-enriched representations ( E + C Word E + C Phrase ) with respect to the parameter  X  used in Eq. (10), across LM, CLM, and RM3. In Figure 5, we chose 1,500 for the smoothing parameter  X  ,fixed R to 10 for RM3, and used the best values for the other additional parameters for each test collection (  X  clu in CLM and the interpolation pa-
Without this heuristic modification, since we do not re-move any stopword for Chinese translation representation, the original RM3 of Eq. (11) gives common words unneces-sarily high probabilities. Table 5: Comparison of our translation models ( C Word and C Phrase ) to full-fledged MT ( C MT ) on the setting of LM, CLM, and RM3 on the ROBUST test collec-tion. The symbols * and + indicate statistical sig-nificance over the baseline LM and the expansion-based baseline (CLM or RM3) using only English representation, respectively.
 rameter between the origina lqueryandinRM3,etc.). Two single monolingual representations E and C X correspond to the case of  X  =1 and  X  =0, respectively.

We see that the best value of  X  depends on the per-formance difference between E and C X for each retrieval method. The best value of  X  is larger when E produces a better performance than C X . Despite the variations across different retrieval methods, the common range of the best  X  is between 0.4 and 0.8. In particular, the phrase-based model ( E + C Phrase ) achieves in most cases the best improve-ments (at least the significant improvements) over the base-line ( E )when  X  is around 0.4 X 0.6.
We now evaluate how different the results of our transla-tion models are, compared to the results from a full-fledged MT system. To build a full-fledged MT system, we used Moses on the same parallel corpus in Section 7 based on the default feature weights without any development data set. For our evaluation, since applying our MT system to TREC collections requires substantial time, we only considered the ROBUST collection. We used the 1-best translation gener-ated by Moses.

Table 5 shows comparison results of three bilingual rep-resentations on the setting of the bilingual-based retrieval ( E + C X ) for LM, CLM, and RM3 on the ROBUST test collection. In Table 5, Chinese translation from the full-fledged MT system is referred to by C MT . Full-fledged MT shows almost similar performances as the word-based model ( E + C Word ) for all three retrieval methods of LM, CLM, and RM3. The phrase-based model ( E + C Phrase )achieves slightly better performances than the full-fledged MT model ( E + C MT ) on the settings of LM and CLM. The general ten-dency is that as some expansion method (i.e., query or doc-ument expansion) is performed, the full-fledged MT model shows closer performance to that of the phrase-based trans-lation models. This is because MT adopts the 1-best transla-tion, in contrast to our translation models exploiting the N-best translations in calculating expected frequencies. That is, our models internally have the default expansion effect, whereas the full-fledged MT model does not, before perform-ing query or document expansion. Without combining with the original representation, we also applied MT in the set-ting of the non-combined model ( C X ) by setting  X  =0in Eq. (10), and observed that the full-fledged MT model only achieved MAP of 0.1905 and 0.2305 in the case of LM and CLM, respectively. The performance is worse than that of our translation models in Table 2 and Table 4.

As a result, our proposed translation models perform at least as well as or better than the full-fledged MT system. However, there is one issue to be handled in estimating the distorted language model: the corpus used for learning the distorted language model is currently limited to only the auxiliary part of the available parallel corpus, and thus its size is far smaller than that for traditional MT. Resolving the corpus size limitation for estimating the distorted language model would be a subject worthy of further investigation.
In this paper, we proposed the use of translation represen-tation, encouraged by the fact that a translated word in an auxiliary language can be taken in a disambiguated sense, or can act as a concept to capture various different expressions in the source language. We used a simplified translation model with monotonic translation to automatically translate all documents in the test collection, producing multilingual representations. Then, the relevance score of a document was calculated by combining multiple evidences derived from multilingual representations. Experimental results on stan-dard TREC English test collections showed that by using English-to-Chinese translation, our approach achieves im-provements over baseline monolingual retrieval, and the im-provements are in many cases statistically significant.
For future work, we would like to extend the current ex-periments by considering other Western languages, for ex-ample, English-French, English-German, etc. We want to see how strongly the linguistic diversity between source and auxiliary languages affects retrieval performance. Acknowledgments This research was done for CSIDM Project No. CSIDM-200804 part ially funde d by a grant from the National Research Foundation (NRF) administered by the Media Development Authority (MDA) of Singapore. We would like to thank the anonymous reviewers for their valu-able comments.
