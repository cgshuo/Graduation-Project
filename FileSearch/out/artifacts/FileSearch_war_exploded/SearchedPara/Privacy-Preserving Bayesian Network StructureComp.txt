 As more and more activities are carried out using computers and computer networks, the amount of potentially sensitive data stored by business, governments, and other parties in-creases. Different parties may wish to benefit from coop-erative use of their data, but privacy regulations and other privacy concerns may prevent the parties from sharing their data. Privacy-preserving data mining provides a solution by creating distributed data mining algorithms in which the underlying data is not revealed.

In this paper, we present a privacy-preserving protocol for a particular data mining task: learning the Bayesian network structure for distributed heterogeneous data. In this setting, two parties owning confidential databases wish to learn the structure of Bayesian network on the combi-nation of their databases without revealing anything about their data to each other. We give an efficient and privacy-preserving version of the K2 algorithm to construct the structure of a Bayesian network for the parties X  joint data. Categories &amp; Subject Descriptors: H.2.8 [Database Applications]: Data Mining General Terms: Security Keywords: Bayesian Network, Privacy-Preserving Data Mining, Distributed Databases
The rapid growth of the Internet makes it easy to col-lect data on a large scale. Data, including sensitive data, is generally stored by a number of entities, ranging from in-dividuals to small businesses to government agencies. By sensitive data, we mean data that, if used improperly, can harm data subjects, data owners, data users, or other rel-evant parties. Concern about the ownership, control, pri-vacy and accuracy of such data has become a top priority
This work was partially supported by the National Sci-ence Foundation (CCR-0331584) and by the Stevens Wire-less Network Security Center (WiNSeC).
 in technical, academic, business, and political circles. In some cases regulations and consumer backlash also prohibit different organizations from sharing their data with each other [3]. Imagine a setting where one research center has a DNA sequence database about a large set of persons and those persons X  medical histories are stored in databases of one hospital. The research center wants to determine cor-relations between DNA sequence and specific diseases. Due to privacy concerns and regulations such as HIPAA [14], the hospital cannot provide any information about individuals X  medical histories to the research center.

Traditionally, data mining requires all data to be gath-ered into a central site where a specific algorithm can be run on the joint data. Clearly this is undesirable from a pri-vacy perspective. Distributed data mining (cf. [17]) removes the requirement to bring all data to a central cite, but has usually been motivated by reasons of efficiency, and typi-cally even these algorithms communicate some information about the data beyond the output of the desired computa-tion, often including a sample of individual data elements. Privacy-preserving data mining, introduced independently by Agrawal and Srikant [2] and Lindell and Pinkas [18], pro-vides data mining algorithms in which the goal is to compute or approximate the output of a particular algorithm applied to joint data, without revealing anything else, or anything else important, about the data.

Bayes networks, which we describe in more detail in Sec-tion 2, are a powerful data mining tool. They can be used for tasks including classification, hypothesis testing, and auto-mated scientific discovery. Bayes networks consist of a struc-ture and associated probabilities. In this paper, we present a privacy-preserving data mining algorithm for learning the structure of Bayes networks; we do not address the compu-tation of the associated probabilities. Privacy-preserving data mining . Privacy-preserving data mining, introduced by Agrawal and Srikant [2] and Lindell and Pinkas [18], allows certain data mining computations to take place while providing some protection for the un-derlying data. There has been a large body of work on privacy-preserving data mining algorithms, including as al-gorithms for association rules [20, 15], clustering [21], naive Bayes classifiers [16, 22], statistical analysis [5, 9], and find-ing common elements [1, 11].

The privacy-preserving naive Bayes classifiers are the most closely related to our work. However, naive Bayes classifica-tion makes the assumption that different attributes satisfy certain independence properties (and when this assumption holds, naive Bayes classifiers are very accurate). In the more common case that there are dependencies among subsets of attributes, Bayes networks yield more accurate models of the data they represent.

Cryptographic methods for privacy-preserving data min-ing, as introduced by Lindell and Pinkas [18] for decision trees, use cryptography to provide strong privacy guaran-tees. Such solutions are also provided in principle by the very elegant and powerful paradigm of general secure mul-tiparty computation (cf. [12]), but specifically tailored can be much more efficient than applications of the general so-lution, particularly when the inputs to the computation are large such as in data mining algorithms. Randomized meth-ods, introduced by Agrawal and Srikant [2], typically are substantially more efficient than cryptographic techniques, but have less strong privacy guarantees. In general, allowing more information leakage can yield solutions that are more efficient.

In a privacy-preserving protocol, one is attempting to mir-ror the privacy that parties would obtain by each sending their databases to a trusted third party, who is trusted not to share received data with anyone. The third party then applies the desired algorithm to the combination of two databases, and sends back only the result to the par-ties. However, since such a mutually trusted party often does not exist, the goal of secure distributed computation is to provide the same privacy properties in the absence of the trusted third party, using a distributed protocol. In the case where inputs are databases, which may be quite large, these distributed protocols can potentially provide an efficiency advantage over the straightforward trusted third party so-lution as well as a privacy advantage.
 Distributed Bayes Network Learning Algorithms . Yaman-ishi [23] presented a distributed algorithm for cooperative Bayesian learning for homogeneous, or horizontally parti-tioned, data sets. In that solution, different Bayesian agents estimate the parameters of the target distribution, and a population learner combines the outputs of those Bayesian models.

Chen, Sivakumar, and Kargupta [6] showed a method for learning Bayesian networks from distributed heterogeneous data sets. In their approach, each distributed site learns their local Bayesian network. Then each site identifies some its own records and transmits those records to a central site (or to the other parties). Note that while more efficient than our solution, this method is not privacy-preserving.
We consider the problem of learning Bayesian network structure from distributed heterogeneous binary data (i.e., vertically partitioned data) in an efficient and privacy-pre-serving manner. That is, we consider a setting, as in [6], in which a dataset is distributed among two parties, with different features at each party. The parties are assumed to have a common primary key for the data set (such as an ID). Attributes for each data record are binary, and can be thought of as reflecting the presence or absence of the attribute for that record. Each attribute is  X  X wned X  by a single site, meaning that the values for that attribute are known only by that party. In this scenario, the two par-ties wish to cooperate by learning the structure of Bayesian network on the combination of their two databases, without revealing the individual values in their databases to each other.

We give an efficient solution for privately computing an approximation of a typically used BN score function for het-erogenous distributed data. We then use this private com-putation to compute a BN using a distributed version of the widely used K2 algorithm [8]. All intermediate values the parties compute are uniformly distributed random shares that sum together to the actual intermediate value. In our solution, which uses cryptography, the parties learn not only the final Bayes network structure, but also, in intermediate steps, the relative ordering (though not the exact values, which are hidden by secret sharing) of a score function ap-plied to various intermediate networks. It remains open to understand the extent that this might breach the privacy of the data, as well as to find solutions that do not leak this information.

Our protocols are secure against passive adversaries (also called semi-honest adversaries). In this setting, corrupted parties try to infer as much as they can from the messages they receive, but they correctly follow their specified pro-tocols. It remains open to extend our solutions efficiently to active adversaries (also called malicious or Byzantine , in which corrupted parties can deviate arbitrarily from their specified protocols.

We discuss Bayesian networks, the K2 algorithm, and our modifications to the K2 scoring function in more detail in Section 2. In Section 3, we describe our privacy-preserving distributed Bayesian network structure learning protocol. We conclude with additional discussion in Section 4.
A Bayesian network (BN) is a graphical model that en-codes probabilistic relationships among variables of interest. This can then be used for data analysis, and is widely used in data mining applications [13, 8].

Formally, a Bayesian network for a set of variables V = ( x 1 ,...,x m ) is a pair ( B s ,B p ), where B s = ( V,E ), called the network structure , is a directed acyclic graph (DAG) whose nodes are the set of variables, and B p is a descrip-tion of local probability distributions associated with each variable, described further below. The graph B s describes conditional independence assertions about variables in V : an edge between two nodes denotes direct probabilistic re-lationships among the corresponding variables. Together, B s and B p define the joint probability distribution for V . We use x i to denote both the variable and its corresponding node, and  X  i to denote the parents of node x i in B s . The absence of an arc between x i and x j denotes conditional in-dependence between the two variables given the values of all other variables in the network. In particular, given struc-ture B s , the joint probability for any particular instantia-distributions B p are the distributions corresponding to the individual terms in this product. The set of conditional dis-tributions B p = { p ( x i |  X  i ) , x i  X  V } are called the parameters of Bayesian network. If variable x i has no parents, p ( x is the marginal distribution of x i .

In the distributed two-party database setting we consider, two parties Alice and Bob each hold confidential databases, D
A and D B , respectively. Each database is organized as a relational table. The variable (attribute) sets in D A and D are denoted by V A and V B , respectively. We assume the data is vertically partitioned: there exists a key K (SSN, bank account, etc.) that is common to both D A and D B , where K  X  V A  X  V B , such that K takes on the same set of values in D
A and D B . We assume that each possible key value occurs exactly once in each database and hence the key can be used to join the two databases together. 1 We further assume that Alice and Bob have each sorted their data by this attribute. Here we solve the problem for the case where each variable (other than the key) is binary, taking on only values 0 and 1, reflecting presence or absence of the corresponding attribute. We assume the variables of interest are the set V = V A  X  V B  X  { K } . That is, Alice and Bob wish to compute the Bayesian network structure of the variables in their com-bined database D A ./ D B , except for the common key, with-out revealing any individual record and ideally not revealing any partial information about their own databases to each other except the information that can be derived from the final Bayesian network structure and their own database. However, our solution does reveal some partial information, in that it reveals the relative ordering of certain quantities.
Given a database, determining the BN structure that best represents the database is NP-hard [7], so heuristic algo-rithms are typically used in practice. One of the most widely used structure learning algorithm is the K2 algorithm [8], which we use as the starting point of our distributed privacy-preserving algorithm. The K2 algorithm is a greedy heuris-tic approach to efficiently determining a good Bayes net-work representation of probabilistic relationships between variables from a database of records containing observations of those variables.

The K2 algorithm begins with a graph consisting of just nodes representing the variables of interest, with no edges. For each node in turn, it then incrementally adds edges whose addition most increases the score of the node, ac-cording to a specified scoring function. When the addition of no single parent can increase the score, this algorithm stops adding parents to the node. In order to keep the DAG structure of the graph, nodes are assumed to be ordered, and only nodes earlier in the ordering can be considered as possible parents. In addition, the number of parents for any node is restricted to some maximum u . Given a node x , Pred( x i ) denotes all the nodes less than x i in the node ordering.

Somewhat more formally, V is a set of m discrete vari-ables, where a variable x i in V has r i possible value assign-ments: ( v i 0 ,...,v i r each record contains a value assignment for each variable in V . In our case, D = D A ./ D B , and the variable set V is all the variables of D except the common key K . The K2 algorithm produces a Bayesian network structure B s whose nodes are the variables in V . Each node x i  X  V has a set of parents  X  i .
If Alice and Bob X  X  databases have an overlapping but not identical set of keys, a private intersection protocol [1, 11] could be used first to identify the common keys without revealing the keys held by only one party. This leaks the set of common key values, but this seems an acceptable or even desirable leakage in many settings, where one wants to know exactly which data was used in creating the resulting Bayesian network.

Some bookkeeping is needed for the algorithm to progress properly, and in particular for Alice and Bob to agree on the control flow in the distributed version. Specifically, given a set of variables, we assume there is a canonical ordering of the variables and their possible values. Given the set of parent variables  X  i of a node i , we denote the j th unique instantiation of  X  i by  X  ij . We denote by q i the number of unique instantiations of  X  i . Then  X  ijk is defined to be the number of records in D in which variable x i is instantiated as v i k and  X  i is instantiated as  X  ij . Finally, define N P
In constructing the BN structure, the K2 algorithm uses the score function f ( i, X  i ) to determine which edges to add to the partially completed structure: The K2 algorithm [8] is as follows: Input: an ordered set of m nodes, an upper bound u on the number of parents for a node, and a database D con-taining n records.
 Output: Bayesian network structure B s (whose nodes are the m input nodes, and whose edges are as defined by the values of  X  i at the end of the computation)
For i = 1 to m { }
We make a number of changes to the scoring function that do not significantly affect the outcome of the K2 algorithm, but that work better for our privacy-preserving computa-tion. Denote the variables (other than the common key K ) in D A by ( a 1 ,...,a m a ) and in D B by ( b 1 ,...,b m a + m b = m . Since all the variables are binary, it follows that r i 1 = 0, r i 2 = 1, and r i = 2.

Then, Equation 1 can be rewritten as follows: We refer to the collection of  X  ij 0 and  X  ij 1 for all possible i and j as  X  parameters .
We make two changes to the scoring function f ( i, X  Since it is only used for comparison purposes, we work in-stead with a different score function that has the same rela-tive ordering. Finally, we then use an approximation to the simpler score function.

First, we applying the natural log to f ( i, X  i ), yielding f ferent scores:
According to Stirling X  X  approximation, for any `  X  1, ` ! =  X  ij 0 +  X  ij 1 + 1 and combining Equation 4 with Stirling X  X  approximation, we have: f 0 ( i, X  i ) = Since the constant ln of different f 0 ( i, X  i ) and z ` is a sufficiently small factor (as bounded by Stirling X  X  approximation), we omit them to ob-tain a new score function g ( i, X  i ) that approximates the same relative ordering as f ( i, X  i ): In our privacy-preserving version of K2 , we use g ( i, X  the scoring function. Note that this approximation itself does not inherently leak information because it is a private approximation, in the sense of Feigenbaum et al. [10].
Our distributed privacy-preserving structure learning pro-tocol is based on the K2 algorithm, using the variable set (except the common key) of the combined database D A ./ D
B , without revealing the individual data values of each party to the other.

In the original K2 algorithm, all the variables are in one central site, while in our setting the variables are distributed in two sites. Hence, we must compute score function across two sites. Remembering that ` =  X  ij 0 +  X  ij 1 + 1, we can see from Equation 6 that the score relies on the  X  parameters.
Other than the distributed computation of the scores and their comparison, our control flow is as given in the K2 al-gorithm. (For efficiency reasons, it is preferable to com-bine the comparisons that determine which possible parent yields the highest score with the comparison to determine if this score is higher than the current score, but logically the two are equivalent.) Note that this method leaks relative score values by revealing the order in which the edges were added, but it does not reveal the actual scores. Instead, we use privacy-preserving protocols to the random shares of the scores.
 Overall, our algorithm executes jointly between Alice and Bob as follows: Input: an ordered set of m nodes, an upper bound u on the number of parents for a node, both known to Alice and
Bob, and a database D containing n records, vertically partitioned between Alice and Bob.
 Output: Bayesian network structure B s (whose nodes are the m input nodes, and whose edges are as defined by the values of  X  i at the end of the computation)
For i = 1 to m { }
Note that throughout the protocol execution, the cur-rent values of  X  i are always known to both Alice and Bob, while we use privacy-preserving protocols so that the values g ( i, X  i ) are always shared between Alice and Bob. In the following subsections, we present a privacy-preserving pro-tocol to compute random shares of the  X  parameters (Sec-tion 3.1) X  X hich in turn uses a privacy-preserving scalar product protocol (Section 3.2) X  X nd a privacy-preserving protocol to compute random score shares from the  X  pa-rameter shares (Section 3.3). We also discuss in Section 3.4 how to use existing privacy-preserving protocols to compare the shared scores.
In this section, we describe the privacy-preserving scalar product protocol that is used as an important subroutine to design the privacy-preserving structure learning BN pro-tocol on distributed heterogeneous data. Atallah and Du presented a secure two-party scalar product protocol against semi-honest adversaries [4]. However, that protocol leaks the sum of the elements of one party X  X  vector to the other party. Here, we give a protocol specific to binary data (which is all we require in our use of it) that does not suffer this leakage, and is more efficient than that of [4] in the special case of binary data. Our protocol makes use of additive homomor-phic public key encryption, such as Paillier X  X  scheme [19]. A public key encryption scheme is additive homomorphic if, given encryptions e ( x ) and e ( y ) of two plaintexts x and y , one can efficiently compute an encryption e ( x + y ) of their sum. It also follows that given a constant c  X  N and an encryption e ( x ), one can compute e ( c  X  x ) = e ( x ) In our protocol, there are two parties, Alice and Bob. Alice has one binary vector, Z A = ( a 1 ,...,a n ) and Bob has one binary vector Z B = ( b 1 ,...,b n ). The goal is to privately compute the scalar product Z A  X  Z B = P n i =1 a i b i . At the end of this protocol, Alice and Bob have random shares of the result Z A  X  Z B . Input: Alice has a binary vector Z A = ( a 1 ,  X  X  X  ,a Bob has a binary vector Z B = ( b 1 ,  X  X  X  ,b n ).
 Output: Alice learns Z A  X  Z B + R and Bob learns R , where
R is a random number determined by Bob. 1. Alice generates a cryptographic key pair ( PK , SK ) of a 2. Alice encrypts her elements with PK and sends the 3. Bob generates a random number R , uniformly dis-4. Bob computes P = e ( R )  X  Q n i =1 y i , where y i = e ( a 5. Alice decrypts P to get d ( P ) = R + P n i =1 a i  X  b
Proposition 1. Assuming both parties follow the proto-col, the scalar product protocol is correct.

Proof. At the end of the protocol, Alice has d ( P ) = d ( e ( R )  X  Q n i =1 y i ). By the homomorphic properties of e , it follows that d ( P ) = R + P n i =1 a 0 i , where a 0 i = a a = 0 if b i = 0. Hence, Alice gets R + P n i =1 a i  X  b i has R . We can see that Alice and Bob obtain random shares of the scalar product of the two vectors, as desired.
Proposition 2. Assuming both parties follow the proto-col and the encryption scheme is semantically secure, the scalar product protocol protects the privacy of each party.
Proof. After executing the protocol, Bob has the en-crypted vector of Alice and Alice X  X  public key PK . Since the encryption scheme is semantically secure, Bob can not distinguish between e (0) and e (1) with probability better than 1 / 2. Hence, Alice X  X  privacy is protected. Bob X  X  privacy is protected since Bob only sends the encrypted output value to Alice.

The communication complexity of this scalar product pro-tocol is cn bits where c is the bit length of an encrypted item. Computation complexity of this protocol is n encryptions and at most n multiplications. In contrast, the protocol for the general case [4] has more than 2 c X n bits communication overhead and  X n encryptions and decryptions, where  X   X  2 is a security parameter.
In this section, we describe how to compute shares of the  X  parameters defined in Section 2.1 in a privacy-preserving manner. Recall that  X  ijk is the number of records in D A D
B where x i is instantiated as k  X  X  0 , 1 } and  X  i is instanti-ated as  X  ij (as defined in Section 2.1), and recall that q the number of possible sequences of values that the variables in  X  i can take on. The  X  parameters include all possible  X  and  X  ij 1 that appear in Equation 6 in Section 2.2.
Let 1  X  i  X  m , 1  X  j  X  q i , and k  X  { 0 , 1 } . We say a transaction in D A (respectively D B ) is compatible with i,j,k if within its variables, any of x i and  X  occur are instantiated as specified by x i = k and  X  i spec-ified by  X  ij . For example, suppose in a particular trans-action Alice has attributes { t,a 1 ,a 2 ,a 3 ,a 4 } and Bob has { t,b 1 ,b 2 ,b 3 ,b 4 ,b 5 } where t is the value of the common key variable shared by Alice and Bob. Further suppose input x i = a 1 = 0 and  X  i = { a 2 ,a 3 ,b 2 ,b 4 ,b 5 } is instantiated as  X  ij = { a 2 = 0 ,a 3 = 1 ,b 2 = 1 ,b 4 = 1 ,b 5 = 1 } . For Alice X  X  database, if one transaction has { a 1 = 0 ,a 2 = 0 ,a 3 then this transaction is compatible with the i,j, 0. In Bob X  X  database, the transaction { b 2 = 1 ,b 4 = 1 ,b 5 = 1 } is com-patible with i,j, 0.

Note that in the degenerate case, all variables for x i and  X  belong to one party, who can locally compute the corre-sponding parameter without any interaction with the other party. The following protocol computes  X  ijk parameters for the general case in which attributes including x i and  X  i distributed among two parties.
 Input: D A and D B held by Alice and Bob, respectively,
Values 1  X  i  X  m , 1  X  j  X  q i , and k  X  { 0 , 1 } , plus the current value of  X  i and a particular instantiation  X  ij of the variables in  X  i are commonly known to both parties. Output: two random shares of  X  ijk . 1. Alice and Bob generate two all-0 binary vectors of 2. For i = 1 to n , if the i th transaction in D A is com-3. Alice and Bob execute the privacy-preserving scalar
Our goal in this subprotocol is to privately compute two random shares of g ( i, X  i ), as defined by Equation 6 in Sec-tion 2.2. There are four kinds of sub-formulas to compute: ` =  X  ij 0 +  X  ij 1 + 1. Alice and Bob can compute random shares for  X  ij 0 and  X  ij 1 using the protocol of Section 3.2. We where a ij 0 , a ij 1 and b ij 0 , b ij 1 are random shares held by Alice and Bob respectively. To get two random shares of g ( i, X  i ), we can first generate two random shares of each sub-formula for Alice and Bob, then Alice and Bob can add their random shares of sub-formulas together to get the ran-dom shares of score function g ( i, X  i ).

Sub-formula (4) can be written as a ij 0 + b ij 0 + a b ij 1 + 1. Hence, two random shares of (4) can be com-puted locally by Alice and Bob as a ij 0 + a ij 1 + 1 and b b ij 1 . Sub-formula (1) can be written as ln ( a ij 0 + b ln ( a ij 1 + b ij 1 ). Similarly, sub-formula (2) can be written as b ij 0 + b ij 1 + 1 can be regarded as two private inputs by Alice and Bob. Then the problem of computing random shares for sub-formulas (1) and (2) can be reduced to the problem of computing two random shares for ln( v 1 + v 2 ) where v 1 v 2 are private inputs of two parties. The ln( v 1 + v 2 ) prob-lem can be solved by the privacy-preserving ln x protocol of Lindell and Pinkas [18]. Similarly, the problem of generat-ing two random shares for sub-formula (3) can be reduced to the problem of computing random shares of x ln x in a privacy-preserving manner, which again is solved by Lindell and Pinkas [18]. After computing random shares for sub-formulas (1) X (4), Alice and Bob can locally add their respective random shares together to compute random shares of g ( i, X  i ).

Proposition 3. Assuming the parties are semi-honest, this protocol correctly and privately computes two random shares of g ( i, X  i ) .
In our privacy-preserving protocol specified at the start of Section 3, Alice and Bob need to determine which of a number of shared values is maximum. That is, we require the following privacy-preserving computation: Input: a vector ( r a 1 ,r a 2 ,...,r a x ) held by Alice, and a vec-tor ( r b 1 ,r b 2 ,...,r b x ) held by Bob.
 Output: i and x i such that r a i + r b i  X  r a j + r b j j  X  x .

In this case, x is at most u + 1, where u is the restric-tion on the number of possible parents for any node, and in any case no larger than m , the total number of attributes in the combined database. Given that generally m will be much smaller than n , this can be privately and efficiently computed using Yao X  X  two-party general secure multiparty computation solution [24]. We presented a privacy-preserving protocol for learning Bayesian network structure on distributed heterogeneous data. The overall complexity of our solution depends on the number n of database records, the number m of attributes, and the limit u on the number of possible parents for any node. Like the original K2 algorithm, our algorithm requires computation that is exponential in u (in order to compute the  X  parameters for all possible 2 u instantiations of binary values to the set of parents of a given node). In the K2 al-gorithm, the inner loop runs O ( mu ) times. Each time the inner loop is executed, there are O ( u ) scores to compute, each requiring O ( m 2 u )  X  parameters to be computed. In our version, the computation of each  X  parameter, includ-ing the scalar product protocol, requires O ( n ) communica-tion and computation. This is the only place that n comes into the complexity. Everything else, including combining the  X  parameters into the score and the secure maximum protocol, can be done in computation and communication that is polynomial in m and 2 u .

We view our work as an initial step. There are a num-ber of remaining directions to explore. In particular, more understanding of the extent of the information leaked by our solution is needed, as well as experimental or analytical validation of our use of g as a score function instead of f . It also remains open to improve the efficiency: in particu-lar, it would be desirable to have communication complexity sublinear, perhaps polylogarithmic, in n and m . Other di-rections for future work include how to privately learn the Bayesian network structure in the multiparty case, learning the probabilities B p , and handling malicious adversaries.
