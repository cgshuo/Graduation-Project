 of these factors can be specified as parameters when run-ning AssocGen. We also compared the performance of the algorithms as the minimum support was varied for several datasets of different sizes. 
We compared SPAM with SPADE and PrefizSpan via two different methods. First, we compared the three al-gorithms on several small, medium, and large datasets for various minimum support values. This set of tests shows that SPAMoutperforms SPADE by about a factor of 2.5 on small datasets and better than an order of magnitude for reasonably large datasets. PrefixSpan outperforms SPAM slightly on very small datasets, but on large datasets SPAM outperforms PrefixSpan by over an order of magnitude. The results of these tests are shown in Figures 6 to 11. 
The primary reason that SPAMperforms so well for large datasets is due to the bitmap representation of the data for efficient counting. The counting process is critical be-cause it is performed many times at each recursive step, and SPAM handles it in an extremely efficient manner. For short datasets, the initial overhead needed to set up and use the bitmap representation in some cases outweighs the ben-efits of faster counting, and because of this PrefizSpan runs slightly faster for small datasets. As candidate sequences become longer, we recurse more levels down the tree and counting becomes more and more important. Overall, our runtime tests show that SPAMexcels at finding the frequent sequences for many different types of large datasets. 
Our second method of testing compared the performance of the algorithms as several parameters in the dataset gen-eration were varied. We investigated the impact of different parameters of the data generation on the running time of each algorithm. The parameters that we varied were the number of customers in the dataset, the average number of transactions per customer, the average number of items per transaction, the average size of itemsets in the maximal se-quences, and the average length of the maximal sequences. For each test, one parameter was varied and the others, in-cluding minimum support, were kept fixed. The results of these tests are shown in Figures 12 to 15. 
Our experiments show that as the average number of items per transaction and the average number of transactions per customer increases, and as the average length of maximal se-quences decreases, the performance of SPAM increases even further relative to the performance of SPADE and PrefixS-pan. This performance increase is due to similar factors as in the case of increasing dataset size. While SPAM contin-ues to outperform SPADE and PrefixSpan as the average size of the itemsets in the maximal sequences and the num-ber of customers in the dataset increaseds the discrepancy between the running times did not increase as significantly as with the other parameters. The reasonfor the low inrease in performance is that an increase in these parameters does not make efficient counting more important as much as does the increase of the other parameters; however, SPAM is still much faster than SPADE and PrefixSpan in all cases with relatively large datasets. 
Because SPAM uses a depth-first traversal of the search space, it is quite space-inefficient in comparison to SPADE. We can make an estimation of the blow-up in space require-[10] R. Srikant and R. Agrawal. Mining Sequential [11] R. Srikant and R. Agrawal. Mining sequential [12] M. J. Zaki. Spade: An efficient algorithm for mining 
