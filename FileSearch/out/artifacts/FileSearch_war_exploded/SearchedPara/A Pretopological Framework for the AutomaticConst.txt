 In this paper, we present a new approach for the automatic generation of lexical-semantic structures from texts. In par-ticular, we propose a pretopological framework to formalize and combine various hypotheses on textual data in order to automatically derive a structure similar to common lexical-semantic knowledge bases such as WordNet. In addition, we define a new metric to intrinsically evaluate structures. Categories and Subject Descriptors: I.2.4 [ Artificial Intelligence ]: Knowledge Representation Formalisms and Methods; I.2.7 [ Artificial Intelligence ]: Natural Language Processing General Terms: Algorithms, Experimentation Keywords: Lexical-Semantic Structures; Pretopology; Evaluation
Coding the semantic relationships between concepts of discourse into a lexical-semantic structure may enrich the reasoning capabilities of Information Retrieval and Natural Language Processing applications. However, their develop-ment is largely limited by the efforts required for their con-struction. To reduce the amount of work needed, many re-search have appeared in recent years to learn such structures from texts, fostering new surveys in the field [1, 5]. Learn-ing lexical-semantic resources from texts instead of manually creating them has undeniable advantages. First, creating resources from texts within a domain may fit the semantic component neatly and directly, which will never be possible with general-purpose resources. Second, the cost per entry is greatly reduced, giving rise to much larger resources than an advocate of a manual approach could ever afford.
Different learning methods have been proposed to auto-matically build lexical-semantic structures. They can be grouped into three main classes: the similarity-based meth-ods [12, 3], the set-theoretical approaches [9, 4] and the associative frameworks [13, 7]. In this paper, we aim at learning terminological ontologies following the associative framework but relieving the frequency problem evi-denced in [13, 7]. For that purpose, we propose to analyze the topology of the graph structure between terms induced by associative measures. Within this context, we propose an unsupervised methodology based on Pretopology, which automatically learns lexical-semantic structures. Thus, from a given set of terms from potentially different domains and any domain corpus, we assess the asymmetric proximity be-tween terms using asymmetric similarity measures. From the resulting proximity matrix, we present a Pretopological framework to obtain a non-triangular directed acyclic graph corresponding to the semantic structure of the domains.
The evaluation of learned structures is a rather compli-cated task. Indeed, [14] claims that there are several possi-bilities of conceptualizations for one domain that might dif-fer in their usefulness for different groups of people, but not in their soundness and justification. In this paper, we pro-pose an exhaustive intrinsic evaluation of the learned lexical-semantic structures by comparing them to the state-of-the-art approach [13]. For that purpose, we take as baseline the work done by [11] and propose an alternative solution to overcome some evidenced drawbacks as well as we present an original methodology for a  X  X air X  comparison.
The links between elements of a population can be mod-eled in several ways, e.g. Topology. However, topological axioms and properties are too restrictive to model a space in concrete terms. Instead, Pretopology models proximity in a more general way. So, we propose to use this theoreti-cal framework to model a  X  X exical space X  with pretopological relations and derive a structure with propagation strategies.
We can define a pretopological space by a family of neigh-borhoods. Let ( E, a ) be a pretopological space [2] where a ( . ) is a pseudo-closure function and E a non-empty set. A neighborhood N ( x ) of x  X  E is a subset of E containing x and a family of neighborhoods N ( x ) for x can be defined by the union of neighborhoods as N ( x ) = { N  X  E | x  X  N } . We then construct the pseudo-closure function based on the fam-ily of neighborhoods as  X  A  X  P ( E ) , a ( A ) = { x  X  E |  X  N  X  N ( x ) , N  X  A 6 =  X  X  . Within our context, a pretopological space is defined by a vocabulary E (set of terms) and a pseudo-closure operator a ( . ) supposed to model the propa-gation of semantic dependencies over term sets. The way to define the family of neighborhoods is crucial for the mod-eling. For example, the approach proposed by [13] can be instantiated in our pretopological framework by consider-ing a family composed of two neighborhoods N OHC ( x ) = { N
O ( x ) , N HC ( x ) } matching the two properties (high confi-dence and order respectively) used in the subsumption def-inition of [13] i.e. N HC ( x ) = { y  X  E | P ( y | x ) &gt; t } and N O ( x ) = { y  X  E | P ( y | x )  X  P ( x | y ) } .

As the pseudo-closure function is not idempotent, its suc-cessive applications lead to the achievement of closed sub-sets. These closed subsets represent interdependent subsets related to the pseudo-closure function. As a consequence, a structure is induced by the elementary closed subsets and maximal closed subsets can be seen as the less homogeneous groups of E . The nature of these particular subsets is in-teresting in terms of space analysis, as we can consider an inclusion relation between them, leading to a structural anal-ysis algorithm. Such a structure can be obtained with the pretopological algorithm proposed by [10]. In particular, we proposed a top-down version of this algorithm in [6]. So, when using N OHC , the algorithm provides a non-triangular directed acyclic graph that is exactly the final structure ob-tained by [13]. In the next section, we take advantage of this general framework to propose new neighborhoods rele-vant for lexical space modeling.
Various pretopological neighborhoods may exist to model the proximity relations between elements in the vocabulary.
A k -Nearest Neighbors pretopological space ( k -NN) con-sists in defining the neighborhood of an element x by the subset composed of the k elements having the highest prox-imity with x . For the lexical application, we choose as neigh-borhood for a term x , the terms y with the highest confi-dences using P ( y | x ). As such, we define the following fam-ily of neighborhoods: N kNN ( x ) = { N kNN ( x ) , N O ( x ) } where N kNN ( x ) = { y  X  E | y  X  kN N E ( x ) } . The family N kNN to a pseudo-closure operator a ( . ) such that a ( x ) is the set { x } extended by its more general terms ( N O ), which have x among its k best direct predecessors ( N kNN ).
The second modeling is based on a statistical property observed on lexical structures. Given a benchmark struc-ture S r as reference and a corpus on the domain of S we performed an analysis on the distribution of the confi-dence values along the paths from a root to a leaf on the reference. Several intuitive hypotheses have been tested and one of them appeared to be statistically relevant. Let x , x 2 , . . . , x n be a path in the reference structure such that x i subsumes x i +1 . We observed that a term x i in the path has a higher minimal confidence with its predeces-sors than its successors have with their own predecessors. This statement can be formalized by the following property:  X  i, min { P ( x j | x i ) } i  X  1 j =1  X  min { P ( x j | x this property locally on a triplet ( w, x, y ), y is a neighbor of x if and only if any w satisfies the property to be a suc-cessor of x in the path ( x, y ) i.e. N DRN ( x ) = { y  X  E | X  w  X  a new family of neighborhoods is proposed N DRN ( x ) = { N
DRN ( x ) , N O ( x ) } . In particular, the pseudo-closure oper-ator derived from N DRN extends a term singleton { x } with its more general terms ( N O ) satisfying the extended ultra-metric property ( N DRN ). The interesting property of N DRN is that it is free of parameter. However, it leads on practice to over-sized neighborhoods. A way to adjust the neighbor-hoods consists in introducing the high confidence parame-ter such that N HC DRN ( x ) = { N DRN ( x ) , N O ( x ) , N Another solution that avoids the threshold problem is pre-sented in the next section.
As mentioned above, the Directed Relative Neighborhood produces over-sized neighborhoods. However, it could be used as a relevant  X  X ilter X  and force other neighborhood func-tions to select elements satisfying a property observed on expected structures. In that sense, we define a new neigh-borhood that combines on the one hand the structural ben-efits and the simplicity of the parametrization of the kN N approach and on the other hand the statistical property of the DRN topology such that N kN DRN ( x ) = { y  X  E | y  X  kN N N DRN ( x ) ( x ) } . Finally, the new family of neighborhoods is given by N kN DRN ( x ) = { N kN DRN ( x ) , N O ( x ) } .
Two benchmarks have been used as references to tackle two different semantic relationships: synonymy and meronymy. First, we used the UMLS 1 from which four dis-tinct sub-domains have been selected (cardiovascular (CS), digestive (DS), respiratory (RS) and nervous (NS)). In par-ticular, each sub-domain is represented by its own lexi-cal structure present in the meta-thesaurus using the hy-pernym/hyponym relation. The second reference ontology was obtained from WordNet by considering all geographical places deriving from the concept  X  X nited States of Amer-ica X  by means of the meronymy relation. We call it GEO-WordNet. For each reference, we retrieved the proximities between terms from two different corpora. For the UMLS, we used (1) PubMed 2 and (2) BioMed 3 . For the GEO-WordNet, we exploited the Glasgow Herald (GH95) and Los Angeles Times (LAT94) both used in the GeoCLEF evalua-tion campaigns 4 , where toponyms have been identified with the Stanford Named Entity Recognition (NER) [8] and dis-ambiguated using a conceptual-density based method. [11] proposed a way to compare ontologies at the struc-tural level (the J 1 measure). Given a set of terms E and two http://www.nlm.nih.gov/research/umls/ http://www.ncbi.nih.gov/pubmed/ http://www.biomedcentral.com/ http://ir.shef.ac.uk/geoclef ontologies O 1 and O 2 structuring E , the general principle is to compare for each entry x  X  E the matching between the super/subconcepts of x in O 1 and the super/subconcepts of x in O 2 . This evaluation approach is also suitable in our con-text by quantifying the matching between the predecessors P red S ( x ) and successors Succ S ( x ) of a term x in the two lexical structures S 1 , S 2 . However, the main drawback of J is its insensitivity to the direction of the relations into the structures. Such, two structures with full inversion would have a perfect matching according. To avoid the inversion problem, we propose to consider separately predecessors and successors in the matching evaluation. A new J 2 matching index is proposed as the (geometric) mean of two Jaccard indices for which a perfect matching of 1 implies strictly identical structures as shown in Equation 1.

J 2 ( S 1 , S 2 ) = 1 | X | X
In order to evaluate the acquired structure with the in-trinsic J 2 measures, we need to fix the parameter k or the threshold t depending on the pretopological space used. In our experiments, we noticed two generic phenomena: (1) the best structures are obtained with small-sized neighborhood and (2) the size of the neighborhoods must be comparable to be fair in the comparison of the different pretopologi-cal spaces. The first observation corroborates the intent of [13] to filter only very high confidence values by means of a strong threshold (e.g. t = 0 . 8). This is illustrated by Figure 1 that reports the J 2 scores obtained by the N OHC pretopological space when the number of confidence values retained grows (i.e. threshold t decreases). Furthermore, such a threshold cannot be universal and must be adjusted for each corpus. For example, the proportion of confidence values greater than 0 . 8 is about 1% for the CS sub-domain of the UMLS on the BioMed corpus, but only 0 . 07% for the GEO-WordNet observed on the LAT94 corpus.

Based on these findings, we chose two heuristics for the parametrization of the pretopological spaces. Let n be the size of the vocabulary E to structure, the threshold t is ad-justed in such a way that only n (first heuristic) and 2 n (sec-ond heuristic) confidence values exceed t . The two heuristics are used for high confidence-based pretopological spaces (i.e. N
OHC and N HC DRN ). For the nearest neighbors-like spaces (i.e. N kNN and N kN DRN ) neighbors with comparable sizes are obtained with parameters k = 1 and k = 2 respectively. Table 1 reports the structural evaluation of each acquired structure compared to the corresponding reference.

Important variations on the J 2 index are observed depend-ing of the benchmark and the corpus. Very poor matching are obtained for example on the RS with PubMed where the scores are sometimes lower than 0.10 and strong promising matching are obtained for example on the NS sub-domain and the Geographical domain where the scores are closed or higher than 0.40. Such variations can be explained by the nature of the reference used and especially the kind of semantic relations into consideration. Some of the domains are structured based exclusively on the Part-of relation (e.g. Geo-WordNet) or the Is-a relation (e.g. NS sub-domain), while other references mix up both types of relations such Figure 1: J 2 scores with the baseline approach of [13] on the BioMed corpus: CS, DS, NS and RS sub-domains in the top-down order. as the CS sub-domain (and the global UMLS reference by extension). It seems to be incontestable that such an het-erogeneity in the semantic structuring of the vocabulary is a problem that current approaches do not transcend.
The corpus used and the way to exploit the text collection also have a significant impact on the quality of the retrieved statistics and then on the acquired lexical structure. In-deed, the matching scores are lower overall when using the PubMed corpus compared to BioMed. It is mainly due to the fact that only abstracts of the scientific papers have been used for the statistics computation with PubMed whereas full text retrieval has been performed on BioMed, thus pro-viding more confidence in the extracted statistics.
Table 1 also reports the comparison between the struc-tures obtained from different pretopological spaces. Bold values in the table distinguish the modeling that leads to the best matching for a benchmark and a corpus. It is interest-ing to observe that even if the ultrametric topological space ( N
HC DRN ) never leads to the best matching, the filter per-formed by this space is profitable to the nearest neighbors-like space since the N kN DRN modeling obtains best results on four experiments. As a summary one can notice that the new proposed N kN DRN modeling outperforms the baseline proposed by [13] in two thirds of the experimented contexts and sometimes with strong improvements as for example on the geographical benchmark with a score increased by 87% at the very most.
In this paper, we presented a new framework to auto-matically build terminological ontologies based on the for-malism of Pretopology. In particular, Pretopology proposes a well-founded mathematical framework to model the de-gree of generality/specificity as well as the semantic close-ness between terms based on an asymmetric proximity mea-sure. Unlike similarity-based and set-theoretic approaches, we deal with asymmetry in NLP based on the associa-tive framework, which allows domain and language inde-pendency and opens new research directions. In particular and compared to the work of [13], we proposed to focus on the topology of the structure obtained from the prox-imity measure thus avoiding isolated terms and simplifying the parametrization. We also proposed an exhaustive in-trinsic evaluation of the learned lexical-semantic structures based on a new metric called the J 2 index, which proposes a solution to the ontology inversion problem untreated by [11]. We validated our model based on two benchmarks: the UMLS referential medical ontology over the PubMed and BioMed corpora, and the GEO-WordNet referential over two news stories collections. We compared it to the best-so-far state-of-the-art methodology proposed by [13]. The results showed that the pretopological structuralist formal-ism outperforms the methodology of [13] in the majority of the cases. [1] C. Biemann. Ontology learning from text  X  a survey of [2] M. Brissaud. Les espaces pr  X etopologiques.
 [3] P. Cimiano, A. Hotho, and S. Staab. Comparing [4] P. Cimiano, A. Hotho, and S. Staab. Learning concept [5] P. Cimiano, A. M  X  adche, S. Staab, and J. V  X  olker. [6] G. Cleuziou, G. Dias, and V. Levorato. Acquisition de [7] G. Dias, R. Mukelov, and G. Cleuziou. Unsupervised [8] J. Finkel, T. Grenager, and C. Manning.
 [9] B. Ganter and R. Wille. Formal Concept Analysis: [10] C. Largeron and S. Bonnevay. A pretopological [11] A. Maedche and S. Staab. Measuring similarity [12] G. Paa X , J. Kindermann, and E. Leopold. Learning [13] M. Sanderson and D. Lawrie. Building, testing, and [14] B. Smith. Ontology. In The Blackwell Guide to
