 Distance metric learning plays a very crucial role in many data mining algorithms because the performance of an al-gorithm relies heavily on choosing a good metric. However, the labeled data available in many applications is scarce an d hence the metrics learned are often unsatisfactory. In this paper, we consider a transfer learning setting in which some related source tasks with labeled data are available to help the learning of the target task. We first propose a convex formulation for multi-task metric learning by modeling the task relationships in the form of a task covariance matrix. Then we regard transfer learning as a special case of multi-task learning and adapt the formulation of multi-task met-ric learning to the transfer learning setting for our method , called transfer metric learning (TML). In TML, we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation. To solve the convex optimization problem, we use an alternat-ing method in which each subproblem has an efficient solu-tion. Experimental results on some commonly used transfer learning applications demonstrate the effectiveness of our method.
 I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database Applications X  Data mining Algorithms Metric Learning, Transfer Learning, Multi-Task Learning
Many data mining algorithms, e.g., k -means clustering algorithm and k -nearest neighbor classifier, work by relying on a distance metric. In order to deliver satisfactory resul ts, finding a good distance metric for the problem at hand often plays a very crucial role. As such, metric learning [25] has received much attention in the research community [12, 25, 5, 22, 8, 26, 6, 7, 27, 29, 13]. Many metric learning methods have been proposed. From the perspective of the underly-ing learning paradigm, these methods can be grouped into three categories, namely, supervised metric learning, uns u-pervised metric learning, and semi-supervised metric lear n-ing. Supervised metric learning learns a metric for some supervised learning task, such as classification, so that da ta points from the same class are kept close while those from different classes are far apart [12, 22, 8, 7, 29, 13]. It has al so been used for regression by exploiting the manifold struc-ture contained in the labeled data [24]. Unsupervised metri c learning utilizes some information contained in the data to learn a metric for some unsupervised learning task, such as clustering [6]. Semi-supervised metric learning, which ca n be viewed as a combination of the supervised and unsupervised paradigms, utilizes both label information from the labele d data and geometric information from the unlabeled data to learn a good metric for classification or clustering. The nee d for semi-supervised metric learning arises from the fact th at the labeled data available in a number of real-life applica-tions is scarce because labeling data is very laborious and costly. With only limited labeled data, the metrics learned are often unsatisfactory. Semi-supervised metric learnin g tries to exploit additional information from the unlabeled data to alleviate this problem which is known as labeled data deficiency problem here.

The focus of this work is on supervised metric learning for classification applications. However, we consider situ a-tions similar to those for semi-supervised metric learning in which there is deficiency in labeled data. While the amount of labeled data available in one learning task is limited, it is not uncommon that there exist other related learning tasks with labeled data available. Unlike semi-supervised learn ing which exploits unlabeled data, multi-task learning [4, 12, 20] and transfer learning [18] seek to alleviate the labeled dat a deficiency problem by utilizing some related learning tasks to help improve the learning performance. In some sense, they mimic human learning activities in that people may learn faster when several related tasks are learned simultaneous ly, e.g., playing different games. In essence, people often appl y the knowledge gained from some previous learning tasks to help learn a new task. Even though both multi-task learning and transfer learning utilize information from other relat ed learning tasks, there exist some differences between them in both the problem setting and the objective. In transfer learning, the learning tasks are usually classified into two types: source task and target task. It is assumed that there is enough data in the source tasks but not in the target task. The objective of transfer learning is to utilize the informa -tion in the source tasks to help learn the target task with no need for improving the performance of the source tasks. On the other hand, there is no distinction between the tasks in multi-task learning and the objective is to improve the performance of all tasks simultaneously.

Even though there exist differences between multi-task learning and transfer learning, a central issue common to both is to accurately characterize the relationships betwe en tasks. Given the training data for multiple tasks, there are two important aspects that distinguish between differ-ent methods for characterizing the task relationships. The first aspect is on how to obtain the relationships, either from the model assumption or automatically learned from data. Many multi-task and transfer learning methods make some prior assumptions. For example, the latent data representa -tion is shared by different tasks [4, 1] or the learning mod-els in different tasks have similar model parameters [9, 14]. Obviously, learning the task relationships from data auto-matically is the more favorable option because the model assumption adopted may be incorrect and, worse still, it is not easy to verify the correctness of the assumption from data. The second aspect is on what task relationships can be represented by a method. Generally speaking there are three types of task relationship: positive task correlation, neg ative task correlation, and task unrelatedness. 1 Positive task cor-relation is a useful task relationship to characterize beca use similar tasks are likely to have similar model parameters. For negative task correlation, knowing the model parame-ters of one task will reduce the search space for the model parameters of a negatively correlated task. As for task un-relatedness, identifying outlier tasks can prevent them fr om impairing the performance of other tasks since outlier task s are unrelated to other tasks.

In this paper, we study metric learning under the trans-fer learning setting in which some source tasks are availabl e in addition to the target task. Based on a method called regularized distance metric learning (RDML) [13], we pro-pose an extension for transfer learning called transfer metric learning (TML). Different from conventional transfer learn-ing methods, we first propose a convex formulation for multi-task metric learning by modeling the task relationships in the form of a task covariance matrix which can model pos-itive, negative and zero task correlations. Then we regard transfer learning as a special case of multi-task learning i n that the source tasks are equally important and indepen-dent, and adapt the formulation of multi-task metric learn-ing to the transfer learning setting for the formulation of TML. In TML, we learn the metric and the task covariances between the source tasks and the target task under a uni-fied convex formulation. As in multi-task metric learning, the task covariance matrix can also model positive, negativ e and zero task correlations. To solve the convex optimizatio n problem, we use an alternating method in which each sub-problem has an efficient solution. Experimental results on some commonly used transfer learning applications demon-strate the effectiveness of our method. task correlation.

The remainder of this paper is organized as follows. We first briefly introduce some background for metric learning and the related work in Section 2. We then present our multi-task metric learning and TML algorithms in Sections 3 and 4, respectively. Section 5 reports experimental result s on some transfer learning applications. Finally, some con-cluding remarks are given in the last section.
Suppose we are given a labeled training set { ( x i , y i where the i th data point x i  X   X  d and its class label y { 1 , . . . , C } . In RDML [13], the learning problem is formu-lated as follows: min s.t.  X   X  0 , (1) where is the regularization parameter which balances the empirical loss and the regularization term,  X   X   X  F denotes the Frobenius norm of a matrix, y j,k is equal to 1 when y and y k are identical and  X  1 otherwise,  X   X  0 means that  X  is a positive semidefinite (PSD) matrix,  X  x j  X  x k  X  2 ( x to the hinge loss used in the support vector machine (SVM). Here b is a constant, satisfying 0  X  b  X  1, which denotes the classification margin. In [13], b is set to 0.
 In [13], an online method is used to learn the optimal  X  and some properties of RDML, such as the generalization error, are studied. Moreover, theoretical analysis shows t hat RDML is robust against the number of feature dimensions.
To the best of our knowledge, [28] is the only previous work on transfer metric learning. In [28], it is assumed that there exist labeled data points for the target task as well as some prior information from the source tasks in the form of a metric matrix learned from each source task. The authors extended information-theoretic metric learning (ITML) [8 ] to transfer metric learning by treating the metric matrices learned from the source tasks as prior information to reg-ularize the learning of the target task. The optimization problem for transfer metric learning in [28], which is calle d L-DML, is formulated as follows: min s.t. M  X  0 where tr(  X  ) denotes the trace of a square matrix and  X   X   X  denotes the 2-norm of a vector. Here S = P y x )( x i  X  x j ) T , D = P y 1 , . . . , K ) is the available metric matrix for the k th source task. The first and second terms in the objective function of problem (2) are derived from the log-determinant regulariz a-tion function as used in [8] and k is the weight that reflects the utility of the metric of the k th source task. The third term is to keep the data points in the same class as close as possible and the fourth term is to keep the data points from different classes far apart. The last term is to penal-ize the complexity of  X  . Here  X  plays an important role in this formulation since there may exist outlier tasks in real applications and by learning  X  L-DML can identity them. However, each element of the vector  X  is non-negative and so it cannot model the negative transfer situation [19]. More-over, the constraint P K k =1 k = 1 is not very reasonable. Consider a special case in which there is only one source task. Then 1 = 1 even if this source task is an outlier task. When there are multiple source tasks and all of them are outlier tasks, we should set all i to zero but then the constraint P K k =1 k = 1 cannot be satisfied. Furthermore, problem (2) is not convex, making it easy to get trapped in (bad) local minima during the optimization procedure.
There exist some methods for transfer dimensionality re-duction [21, 16, 17], where dimensionality reduction can be viewed as a special case of metric learning in that the metric learned is not of full rank. However, transfer dimensionali ty reduction is different from transfer metric learning and the se methods are not applicable here. For example, [21] used a transformation matrix for dimensionality reduction in the source tasks for subspace clustering in the target task and so the target task is an unsupervised learning task. Also, [16, 17] proposed dimensionality reduction methods for do-main adaption in which the target task has no labeled data, and so it is different from the setting here where we utilize the metric matrices learned from the source tasks to help the learning of the target task from labeled data.
In this section, we propose a multi-task metric learning method which can learn the task relationships between all pairs of tasks.

Suppose we are given m learning tasks { T i } m i =1 . For the i th task T i , the training set D i consists of n i data points represented in the form of ( x i j , y i j ), j = 1 , . . . , n  X  d and its corresponding class label y i j  X  { 1 , . . . , C the superscript denotes the task index and the subscript denotes the instance index in each task.

The optimization problem for multi-task metric learning is formulated as follows: where y i j,k is equal to 1 when y i j = y i k and  X  1 otherwise, vec(  X  ) denotes the operator which converts a matrix into a vector in a columnwise manner, and 1 and 2 are the regu-larization parameters.  X  is a task covariance matrix which describes the relationships between tasks and so it is a PSD matrix. The first term in the objective function of prob-lem (3) measures the empirical loss for the training sets of the m tasks, the second term penalizes the complexity of each  X  i , and the last term measures the task relationships between all pairs of tasks based on each  X  i . The last con-straint in (3) is to restrict the scale of  X  to prevent it from reaching a degenerate solution.

From a probabilistic viewpoint, RDML can be seen as obtaining the maximum a posteriori (MAP) solution of a probabilistic model where the likelihood corresponds to th e first term in the objective function of problem (1) and the prior on the metric is Gaussian prior corresponding to the second term. Similar to RDML, our multi-task metric learn-ing is also a MAP solution of a probabilistic model where the likelihood is the same as that in RDML for each task and the prior on the metrics of all tasks is matrix-variate normal distribution [11].

We will prove below that problem (3) is a convex opti-mization problem by proving that each term in the objective function is convex and each constraint is also convex.
Theorem 1. Problem (3) is convex with respect to W , b and  X  .
 Proof It is easy to see that the first two terms in the objective func-tion are convex with respect to (w.r.t.) all variables and th e constraints in (3) are also convex. We rewrite the third term as tr( W X   X  1 W T ) = P t W ( t, :)  X   X  1 W ( t, :) T where W ( t, :) is the t th row of W . Since W ( t, :)  X   X  1 W ( t, :) T trix fractional function as in Example 3.4 on page 76 of [3], it is convex w.r.t. W ( t, :) and  X  when  X  is a PSD ma-trix (which is satisfied by the first constraint of (3)). Since W ( t, :) is a row of W , W ( t, :)  X   X  1 W ( t, :) T is also convex w.r.t. W and  X  . Because the summation operation can pre-serve convexity according to the analysis on page 79 of [3], tr( W X   X  1 W T ) = P t W ( t, :)  X   X  1 W ( t, :) T is convex w.r.t. W , b and  X  . So the objective function and the constraints in problem (3) are convex w.r.t. all variables and hence prob -lem (3) is jointly convex.  X 
Even though problem (3) is convex with respect to {  X  i } and  X  jointly, it is not easy to optimize it with respect to all the variables simultaneously. Here we propose an alternati ng method to solve the problem more efficiently. Specifically, we first optimize the objective function with respect to  X  fixed, and then optimize it with respect to  X  when {  X  i } are fixed. This procedure is repeated until convergence. Since the original optimization problem is convex, the solution found by this alternating procedure is guaranteed to be the globally optimal solution [2].

Because multi-task metric learning is not the focus of this paper, we leave the detailed optimization procedure to Ap-pendix A.
Based on the multi-task metric learning problem formu-lated in the previous section, we propose a transfer metric learning formulation as a special case which can learn the task relationships between all source tasks and the target task.

Suppose we are given m  X  1 source tasks { T i } m  X  1 i =1 target task T m , for m &gt; 1. In the target task, the training set contains n m labeled data points { ( x m j , y m j ) } fer learning, it is assumed that each source task has enough labeled data and can learn an accurate model with no need to seek help from the other source tasks. So the source tasks are considered to be independent since each source task does not need help from other source tasks. So, similar to the set-ting in [28], we assume that the metric matrix  X  i for the i th source task has been learned independently. We hope to use the metric matrices learned to help the learning of the targe t task because the labeled data there is scarce.
Based on problem (3), we formulate the optimization prob-lem for TML as follows: min Since we assume that the source tasks are independent and each source is of equal importance, we can express  X  as where I a denotes the a  X  a identity matrix,  X  m denotes the task covariances between the target task and the source tasks, and ! denotes the variance of the target task. Ac-cording to the last constraint in problem (4), we can get From Theorem 1, it is easy to show that problem (4) is also jointly convex with respect to all variables. Moreover, fro m the block matrix inversion formula, we can get = where 0 d denotes the d  X  1 zero vector, a =  X  ( m  X  1)  X   X  matrix here, denote the parameter matrix of the source tasks. Then we can get Moreover, according to the Schur complement [3], we have
 X   X  0  X  X  X  !  X  m  X  1 1  X  !  X  T m  X  m and ( m  X  1) I m  X  1 1  X  ! which is equivalent to
Then problem (4) can be simplified to where the last term in the objective function can be simpli-fied as in Eq. (5).

Compared with the L-DML method in [28], our method has some advantages. First, the formulation of TML is con-vex and so there is guarantee to find the globally optimal solution. Second, similar to multi-task metric learning pr o-posed in the previous section, TML can model positive, neg-ative and zero task correlations in a unified formulation but L-DML cannot model negative task correlation. As an ex-treme case, we can deal with the situation in which all source tasks are outlier tasks, but L-DML cannot handle it due to the constraint P K k =1 k = 1 in problem (2).

Moreover, compared with problem (4), there is no PSD constraint on  X  in problem (6) making it simpler than prob-lem (4). In the next section, we will discuss how to solve problem (6).
As in multi-task metric learning, problem (6) is a convex problem and we still use an alternating method to solve it. Specifically, we first optimize the objective function with respect to  X  m when  X  m and ! are fixed, and then optimize it with respect to  X  m and ! when  X  m is fixed. This procedure is repeated until convergence. As before, the solution foun d ,  X  2 and predefined learning rate , y m k ) } ; where S + ( A ) projects matrix A into the positive by this alternating procedure is globally optimal [2]. In wh at follows, we will present the two subproblems separately. Optimizing w.r.t.  X  m when  X  m and ! are fixed
Utilizing Eq. (5), the optimization problem with respect to  X  m is formulated as min where M is a matrix such that vec( M ) =  X   X  s  X  m . It is easy to show that M is a combination of  X  i ( i = 1 , . . . , m  X  1) as
Similar to [13], we can use an online learning method to solve problem (7) and the algorithm is depicted in Table 1. This algorithm is similar to that in [13] except the initial step for  X  (0) m . In [13], the initial value for  X  (0) m matrix but here it is  X  2  X  the metrics learned from the source tasks where each com-bination weight is the task covariance between a source task and the target task. This agrees with our intuition that a positively correlated source task will have a large weight o n the initial value for  X  m , an outlier task has negligle contri-bution and a negatively correlated task even has opposite effect.
 Optimizing w.r.t.  X  m and ! when  X  m is fixed
Utilizing Eq. (5), the optimization problem with respect to  X  m and ! is formulated as We impose a constraint as  X   X  X   X  1  X   X  T  X  1 t I d 2 and the objec-tive function becomes min 1 t . Using the Schur complement, we can get By using the Schur complement again, we get We write  X   X  T  X   X  =  X  11  X  12  X  T  X  equivalent to Let U and 1 , . . . , m  X  1 denote the eigenvector matrix and eigenvalues of  X  11 with 1  X  . . .  X  m  X  1  X  0. Then and Combining the above results, problem (8) is formulated as where f j is the j th element of f . By introducing new vari-ables  X  j and r j ( j = 1 , . . . , m  X  1), (9) is reformulated as Since and ! (1  X  ! )  X  ( m  X  1)  X  T m  X  m  X  X  X  problem (10) is a second-order cone programming (SOCP) problem [15] with O ( m ) variables and O ( m ) constraints. In many applications, m is very small and we can use a stan-dard solver to solve problem (10) very efficiently.
We set the initial value of ! to 1 m and that of  X  m to a zero vector which corresponds to the assumption that the target task is unrelated to the source tasks.

After learning the optimal values of  X  m , we can make prediction for a new data point. Given a test data point x  X  for the target task T m , we first calculate the distances between x m  X  and all training data points in T m based on the learned metric  X  m and then use the k -nearest neighbor classifier to classify x m  X  , where we choose k = 1 for simplicity in our experiments.
We study TML empirically in this section by compar-ing it with two metric learning methods, ITML 2 [8] and RDML [13], and another metric learning method for trans-fer learning, L-DML [28]. We use the CVX solver [10] 3 to http://www.cs.utexas.edu/users/pjain/itml/. solve problem (10). We set the learning rate in Table 1 to 0.01. For ITML, RDML and L-DML, the best parameters reported in [8, 13, 28] are used.
The wine dataset 4 is about wine quality including red and white wine samples. The features include objective tests (e.g., PH values) and the output is based on sensory data. The labels are given by experts with grades between 0 (very bad) and 10 (very excellent). There are 1599 records for the red wine and 4898 for the white wine and so there are two tasks, one for red wine classification and the other for white wine classification. Each task is treated as the target task and the other task as the source task. To see the effect of varying the size of the training set, we vary the percentage o f the training data used from 5% to 20%. Each configuration is repeated 10 times. The mean and standard deviation of the classification accuracy are reported in Fig. 1(a) and 1(b ). From the results, we can see that the performance of L-DML is comparable with that of ITML and RDML and TML is always the best one for both tasks.
The handwritten letter classification applicaton 5 consists of seven tasks where each task is a binary classification prob -lem. The corresponding letters for each task are: c/e, g/y, m/n, a/g, a/o, f/t and h/n. Each data point has 128 fea-tures corresponding to the pixel values of the handwritten letter images. For each task, there are about 1000 positive and 1000 negative data points. The experimental settings are the same as those for wine quality classification above. The results are plotted in Fig. 2(a) to 2(g). From the results , we find that the performance of L-MDL is worse than that of ITML and RDML on some tasks (4th, 6th and 7th tasks). This may be due to the fact that the objective function of L-MDL is non-convex and hence it is easy to get trapped in bad local minima. TML shows the best performance on almost every task.
The USPS digit dataset 5 contains 7291 examples each of 255 features. There are nine classification tasks, each cor-responding to the classification of two digits. The experi-mental settings are the same as those for handwritten letter classification. The results are reported in Fig. 3(a) to 3(i) . Similar to handwritten digit classification, L-MDL is worse than ITML and RDML on some tasks and TML is better than other methods on almost all tasks.
In this paper, we have proposed a transfer metric learn-ing method to alleviate the labeled data deficiency problem in the target learning task by exploiting useful informatio n from some source tasks. The learning of the distance met-rics from the source tasks and the relationships between the source tasks and the target task is formulated as a convex optimization problem which can be solved efficiently. In our future research, we will extend TML to the semi-supervised setting by exploiting useful information contained in the u n-labeled data as well. and the others are source tasks.
 This research has been supported by General Research Fund 622209 from the Research Grants Council of Hong Kong. [1] A. Argyriou, T. Evgeniou, and M. Pontil. Convex [2] D. P. Bertsekas. Nonlinear Programming . Athena [3] S. Boyd and L. Vandenberghe. Convex Optimization . [4] R. Caruana. Multitask learning. Machine Learning , [5] H. Chang and D.-Y. Yeung. Locally linear metric [6] J. Chen, Z. Zhao, J. Ye, and H. Liu. Nonlinear [7] J. V. Davis and I. S. Dhillon. Structured metric [8] J. V. Davis, B. Kulis, P. Jain, S. Sra, and I. S. [9] T. Evgeniou and M. Pontil. Regularized multi-task [10] M. Grant and S. Boyd. CVX: Matlab software for [11] A. K. Gupta and D. K. Nagar. Matrix Variate [12] T. Hastie and R. Tibshirani. Discriminant adaptive [13] R. Jin, S. Wang, and Y. Zhou. Regularized distance [14] W. Kienzle and K. Chellapilla. Personalized [15] M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret. [16] S. J. Pan, J. T. Kwok, and Q. Yang. Transfer learning [17] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. [18] S. J. Pan and Q. Yang. A survey on transfer learning. [19] M. T. Rosenstein, Z. Marx, and L. P. Kaelbling. To [20] S. Thrun. Is learning the n -th thing any easier than [21] Z. Wang, Y. Song, and C. Zhang. Transferred [22] K. Q. Weinberger, J. Blitzer, and L. K. Saul. Distance [23] K. Q. Weinberger and L. K. Saul. Fast solvers and [24] B. Xiao, X. Yang, Y. Xu, and H. Zha. Learning [25] E. P. Xing, A. Y. Ng, M. I. Jordan, and S. J. Russell. [26] D.-Y. Yeung and H. Chang. A kernel approach for [27] D.-Y. Yeung, H. Chang, and G. Dai. A scalable [28] Z.-J. Zha, T. Mei, M. Wang, Z. Wang, and X.-S. Hua. [29] D.-C. Zhan, M. Li, Y.-F. Li, and Z.-H. Zhou. Learning
We present here the optimization procedure for solving problem (3). We use an alternating method with two sub-problems to be presented separately below.
 Optimizing w.r.t.  X  i when  X  and {  X  }  X  i are fixed
We first define  X   X  and  X   X  1 as Then the third term in the objective function of problem (3) can be rewritten as where  X  X  X  X  2 denotes the 2-norm of a vector and M is a matrix such that vec( M ) =  X   X   X  i  X  i . Note that the third term in the last equation above is independent of  X  i . It is easy to show that M is a symmetric matrix. The optimization problem with respect to  X  i becomes It is easy to see that this problem is a convex semidefinite programming (SDP) problem since the objective function is convex with respect to  X  i and the constraint is a PSD constraint on  X  i . Even though solving an SDP problem is computationally demanding with poor scalability, we can adopt the technique in [23] and use gradient projection to solve it.
 Optimizing w.r.t.  X  when {  X  i } are fixed When {  X  i } are fixed, the optimization problem for finding  X  becomes Then we have where A =  X   X  T  X   X  . The first equality holds because of the last constraint in problem (12) and the last inequality hold s because of the Cauchy-Schwarz inequality for the Frobe-nius norm. Moreover, tr(  X   X  1 A ) attains its minimum value (tr( A 1 2 )) 2 if and only if for some constant a and tr(  X  ) = 1. So we can get the following analytical solution:
