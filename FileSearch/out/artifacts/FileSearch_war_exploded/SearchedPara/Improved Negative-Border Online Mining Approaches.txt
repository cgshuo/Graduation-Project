 Some researchers have recently developed incremental mining and online mining approaches to maintain association rules without re-processing an entire database whenever the database is updated [3][4][6][10] or user-specified parameters are changed [1]. In general, data under decision-support consideration usually evolve in a systematic way. For example, the data in a data warehouse may be inserted or deleted in a block during an interval of a month. In the past, we proposed the multidimen-sional pattern relation (MPR) [11] to structurally and systematically store additional context information and mining information for each inserted block of data. MPR is conceptually similar to the construction of a data warehouse for OLAP [7][13], except it is not used to store data but mined patterns. We also extended the mining informa-tion in MPR by including negative pattern sets (candidate sets which are not large) and developed a negative-border online mining (NOM) approach based on the ex-tended multidimensional pattern relation (EMPR) especially for blocks of data with different item sets [12]. 
The NOM approach needs to calculate the appearing counts and the non-appearing upper-bound counts of the candidate itemsets derived from matched tuples. A straightforward way for finding these values is to process matched tuples one after one for each candidate itemset. The computation cost will, however, become large along with the increase of the itemsets kept in EMPR and the candidate itemsets to be considered. In fact, in the NOM approach, many candidate itemsets with the same subsets can be processed at the same time. On the other hand, many itemsets kept in the matched tuples are useless for calculating the counts of candidates since they are not the subsets of candidates and can be omitted. In this paper, we thus try to use appropriate data structures and design effi cient algorithms to improve the perform-ance of the NOM approach. 
At first, the problem of calculating the appearing and upper-bound counts of can-didate itemsets in a matched tuple is conceptually modeled by a graph and converted into a directed-minimum-spanning-tree problem. The spanning-tree-count-calculating (STCC) algorithm is then proposed to find the directed minimum spanning tree . The lattice data structure [1] is utilized to organize and maintain all candidate itemsets such that the candidate itemsets with the sa me proper subsets can be considered at the same time. Consequently, by the STCC algorithm, the proposed lattice-based NOM (LNOM) approach requires only one scan of the itemsets for each matched tuple in Phase 1. In addition, the hashing technique is used to filter out a part of itemsets in the matched tuples which are useless for calculating the counts of candidates. The compu-tational time can thus be further reduced. 2.1 The Extended Multidimensional Pattern Relation (EMPR) Each tuple in EMPR comes from a block of data in the database to be processed. EMPR consists of two major types of information. One is the context information used to represent the contexts of each individual block of data. The other is the mining information used to record the available information mined from each individual block of data by a batch mining algorithm. Given an initial minimum support s , the set of previously mined large itemsets with supports for a block of data D is called a supports is called a negative pattern set ( nps ) for D . The latter consists of the itemsets which are candidates but do not have enough supports [8]. Example 1: Table 1 shows an EMPR based on an initial minimum support set at 5%. The tuple with ID = 1 shows that seven large itemsets ( A , 10%), ( B , 11%), ( C , 9%), discovered from 10000 transactions under the contexts of Region = CA , Branch = San Francisco and Time = 2003/10 . 2.2 The Negative-Border Online Mining (NOM) Approach Assume an EMPR based on an initial minimum support s includes m tuples { t 1 , t 2 , ..., t }. Given a mining request q which consists of a set of contexts cx q , a new minimum support s q ( s q  X  s ) and a new minimum confidence conf q , the NOM approach can effectively and efficiently derive the association rules simultaneously satisfying s q , conf q and cx q by three consecutive phases, generation of candidate itemsets , reduction of candidate itemsets , and generation of association rules . 
The phase for generation of candidate itemsets first selects the tuples in EMPR sat-isfying cx q (called matched tuples), collects the itemsets kept in these matched tuples per-bound count of a candidate itemset x can be represented as follows: t . nps denotes the negative pattern set in t i , t i . trans denotes the number of transactions tion of candidate itemsets calculates the upper-bound supports of candidate itemsets and adopts two pruning strategies to reduce the candidate number. The upper-bound where Match_Trans denotes the number of transactions in the matched tuples. The first pruning strategy will remove the candidate itemsets whose upper-bound supports are less than s q . The second pruning strategy will put the ones which appear in all the matched tuples and have upper-bound supports larger than or equal to s q into the set of final large itemsets. Finally, the phase for generation of association rules re-processes, if necessary, the remaining cand idate itemsets against the underlying data-base, and derives the association rules satisfying conf q from all the final large itemsets found. Example 2: For the EMPR given in Table 1, assume a mining request q wants to get the patterns with the contexts cx q of Region = CA and Time = 2003/10 and satisfying the minimum support s q = 5.5%. Phase 1 finds the set of candidate itemsets {{ A }, { B }, { C }, { AB }, { AC }, { BC }, { ABC }}, which is the union of the itemsets appearing upper-bound supports of these candidate itemsets are calculated. According to the maining candidate itemsets need to be furthe r processed in Phase 3 for this example. The NOM approach needs to calculate the appearing counts and the non-appearing upper-bound counts of the candidate itemsets derived from matched tuples. Assume k is the number of matched tuples, m is the average number of itemsets in the k matched tuples, and n is the number of candidate itemsets generated from the k matched tuples. The computation cost will be O( knm ) when the candidate itemsets are processed one by one. It will become large along with the increase of the itemsets kept in EMPR and the candidate itemsets to be considered. 
In fact, many candidate itemsets with the same subsets can be calculated at the same time. For example, in Tuple 3 of Example 2, the appearing count of the candi-date itemset { C } and the upper-bound counts of the candidate itemsets { AC }, { BC } and { ABC } can be calculated at the same time because they have the same subset { C }. On the other hand, many itemsets kept in matched tuples are useless for calculat-ing the counts of candidates. For example, in Example 2, the itemsets { D }, { F }, { AF } and { BF } are not the subsets of the candidate itemsets and can be omitted. The problem of calculating the appearing and upper-bound counts of candidate item-sets in a matched tuple t can be conceptually modeled by a graph. Let G = ( V , E ) be a directed graph, where V is the set of vertices representing all candidate itemsets and E is the set of directed edges representing a-proper-subset-of relationships between possible upper-bound count of the candidate itemset v estimated from the candidate itemset u . Given a new vertex r representing the pseudo starting vertex, we make a tuple(s), then w ( r , u ) = 0 if there exists one item contained in u but not contained in t and w ( r , u ) = t . trans * s  X  1 otherwise, where s is the initial minimum support for deriv-ing EMPR. 
For each vertex other than r in G X  , the smallest weight on all its incoming edges is its tight upper-bound count. The count-calculation problem can thus be easily thought of as the directed-minimum-spanning-tree problem [5], which wishes to find a rooted algorithm is thus proposed based on the above concept for efficiently finding the counts of all candidate itemsets in a tuple. The STCC algorithm first selects an item-set appearing in t and with the smallest support. It then estimates the upper-bound count of each itemset reachable from the selected one in the graph, and thus avoids recalculating the counts of these traversed vertices in the future. This requires only one scan of the itemsets in t if they have been sorted according to their supports. 
The STCC algorithm can be efficiently implemented by the lattice data structure [1], which organizes all candidate itemsets in a systematic way. For each candidate u lattice-based NOM approach (called LNOM) can not only restrict the number of can-didate itemsets to be examined, but also easily consider candidate itemsets with the same proper subsets at the same time. Many itemsets kept in matched tuples, especially negative itemsets, may be useless for calculating the counts of candidate itemsets. Negative itemsets are formed by excluding large itemsets from the candidates which are generated in a level-wise way [10]. In general, the set of candidate itemsets generated level-wisely is usually much generation [2][9]. In this section, we shall utilize the hashing technique to filter out a part of useless itemsets to be considered in Phase 1. 
Take the direct hashing function as an example. Each bucket of the hash table con-sists of only an integer to represent how many candidate itemsets have been hashed into this bucket. 0 denotes that no candidate itemsets have been hashed into this bucket. After a hash table is constructed from all the candidate itemsets, it can then be tuple is selected, the NOM approach calculates its hash value and finds its corre-sponding bucket. If the value stored in the target bucket is equal to 0, the itemset must wise, rescanning the candidate itemsets is necessary to determine whether it is a can-didate. Furthermore, the corresponding value in the bucket of the itemset which is assured to be a candidate will be decreased by one. The next itemset of the same tuple is then checked according to the modified hash table, which can thus raise the prob-ability for a useless itemset to be filtered out. After a tuple is processed, the hash table is restored to its original state, which is then used for another tuple. The algorithm of LNOM approach with a di rect hashing function is stated below. The experiments were conducted in Java on a workstation with dual XEON 2.8GHz processors and 2048MB main memory, running the RedHat 9.0 operating system. Several synthetic datasets were used. The synthetic datasets were generated by a gen-generated and used in our experiments. Each dataset was treated as a block of data in the database. For example, Group 1 contained ten blocks of data, from T20I8D100KL 1 to T20I8D100KL 10 , each consisting of 100000 transactions averaging 20 items and generated according to 400 to 490 maximal potentially large itemsets with an average size of 8 from a total of 200 items. 
An EMPR was first derived from each group of synthetic datasets. These are sum-marized in Table 3. 
For showing the influence of the number of negative itemsets on execution time, the NOM algorithms using no negative itemsets ( NOM (0)) and all negative itemsets ( NOM (A)) from the stored negative pattern sets in the EMPR were run. Fig. 1(a) to Fig. 1(d) shows the execution times for the two NOM algorithms on Groups 1 to 4, where the query support is set at 2.4%. For Group 1, most candidate itemsets ap-peared in nearly all tuples in EMPR such that the negative itemsets provided little help in calculating counts of candidates. This can be easily seen from Fig. 1(a) that the execution time by NOM (0) was less than that by NOM (A). For Group 2, most candidate itemsets appeared in only one or few tuples in EMPR. The effect of nega-tive itemsets on finding tight upper-bound supports thus become apparent. However, since the computation cost in Phase 1 was much larger than that in Phase 3, the execu-tion time by NOM (0) was still less than that by NOM (A) as shown in Fig. 1(b). Even so, it can be observed from Fig. 1(c) and Fig. 1(d) that NOM (0) did not always outper-form NOM (A) for Groups 3 and 4, This phenomena is especially when the size of candidate itemsets is small and the size of underlying data is large. 
The performance of the NOM algorithm with a direct hashing function was then evaluated. Let NOM (AH) denote running NOM (A) with a direct hashing function. The execution times on Groups 1 to 2 are shown in Fig. 2(a) and Fig. 2(b), where the query support is set at 2.4% and the size of the hash table is about 10K. It can be eas-ily seen that the computation time in Phase 1 of the NOM algorithm can be efficiently reduced by the hashing technique. Next, experiments were made to show the effect of using the lattice data structure on the NOM algorithm. The execution time of the NOM algorithm was compared with that of the LNOM algorithm with and without a direct hashing function. The query support is set at 2.4% and the size of the hash table is about 10K. The results for Groups 1 to 2 are also shown in Fig. 2(a) and Fig. 2(b), where LNOM (A) and LNOM (AH) respectively denote running LNOM algorithm with and without a direct hashing function. It is easily seen that the execution time by the LNOM algorithm was always much less than that by the NOM algorithm. For providing ad-hoc, query-driven and online mining supports, the NOM approach utilized three phases to acquire interesting association rules by aggregating related mining information from EMPR. In Phase 1, for each candidate itemset, the NOM approach needs to find its smallest-support subset from the information of itemsets kept in each related mining information to calculate its appearing count or its upper-bound count. When the candidate itemsets are processed one by one, this cost is con-siderably tremendous. For overcoming this problem, in this paper, we have developed a lattice-based NOM (LNOM) approach to consider candidate itemsets with the same proper subset at the same time, and utilized the hashing technique to reduce the num-ber of itemsets kept in the matched tuples to be considered. This research was partially supported by the National Science Council of the Republic of China under Grand No. NSC93-2752-E-009-006-PAE. 
