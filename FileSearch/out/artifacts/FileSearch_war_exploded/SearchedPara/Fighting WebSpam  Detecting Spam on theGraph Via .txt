 Detecting spam is one of the most important problems for improving the quality of search engine [3] [4]. Starting with the topology of the web, one can view the Web Pages as a connected directed large-scale graph on which Web Spam can be detected via the properties of the link-spam structure. On the other hand, the Web Pages can be represented as V ector Space Model(VSM) to capture their semantical information, such as E mail spam filter in classical text mining community. In general, these techniques are independent each other. Moreover, how to fuse these dual prior information into a unified framework to reinforce detecting system is an interesting issue.

In this paper, we present a novel fusin g strategy to boost the performance of the spam detection system v ia exploring the two aspects of Web Pages: that is, link features from hyperlink and semantical features from the k -way graph Lapla-cian based on content information. Our main contributions include: 1) Construct a similarity graph ( G sim ) to measure the similarity relationship via combining constraint graph ( G c )and nearest neighborhood graph ( G NN ). 2) Label the most confident nodes from multi-vie w graph under the consistency criterion for improving the robustness of detectio n system. 3) Construct a new spectral space to integrate content features and link information. The rest of this paper is organized as follows: Section 2 describes the related work. Section 3 depicts our proposed strategy for learning on the Web graph with partial labeled nodes. The detailed experimental results on EC ML challenge dataset are presented in Section 4. We draw a conclusion for this paper in Section 5. In this section, we give a brief review on Web Spam studies. Methods for the detection of link-based spam explore link structures and spam link form on the graph, then re-rank score on the revised graph, such as propagating trust or distrust through links [4], or deleting links that look suspicious from the statistics characters. On the other hand, some statistics on link structures on web graph can be considered as the characters of the related pages in bag-of-word fashion. Hence, It is easy for us to t ransform a link spam detection problem into a typical machine learning issue.

For the purpose of going further to boost the performance of the learned clas-sifier, Castillo et al. proposed a spam detection system that combines link-based and content-based features [3]. They apply stacked graphical model obtained by base classifier to implement some topology analysis.

Recently, Zhou et al. considered discr ete analysis on directed graph for de-tecting web spam, and constructed a discrete analogue of classical regularization theory via discrete analysis with different transductive methods [6]. In the lit-erature [5], Kamvar et al. presented a spectral learning algorithm with some constraints for clustering or classification. Their work demonstrated that the compacted spectral space offers a new pow erful representation for data. In this paper, we will focus on spam detection on graph in semi-supervised fashion. To describe conveniently, Web Spam det ection problem is defined as follows: Problem Statement 1. Given a set of hosts(pages) { v i } n 1  X  X  ,thecorre-sponding link graph G link from the hyperlinks and label set V L = { v i } l 1 ; Y L  X  X  . for each host(pages), we know its low-level content information in bag-of-words manner. The detection goal is to predict labels Y U  X  X  = { 1 ,  X  1 } for the rest hosts(pages) V U  X  X  .
 Following Zhou et al. work [6], we model the data relation as two typical graphs, which capture content-based features and link-based features respectively. Dif-fering from Zhou X  X  work in which a markov mixture was constructed from multi views [6], we focus on the graph construction itself and then implement a co-training phase from multi views.

As aforementioned in the introduction, our method can be divided into three stages: 1) Construct two informative graphs, 2) Label some unlabeled data with a very high level of confidence and under the consistency criterion, 3) Analyze the rest of unlabeled data in the fusing spectral space.
 3.1 Construct an Informative Similarity Graph In our approach, the nodes in Link-Graph G link and Similarity-Graph G sim are the page objects. In general, A Link-Graph is available directly by crawling sys-tem and the edges in the Link-Graph are obtained from hyperlinks. A natural question raising here is how to create an appropriate graph to incorporate the content information in our detecting system. Let a tuple G sim =( V, E S ,W S )de-note a semantical Similarity-Graph ,where W S =[ w ij ] N  X  N is the weight matrix with the ( i ; j )-th element w ij indicating the strength of immediate connectivity between vertices v i and v j . For the purpose of data classification, the vertex set v i coincides with the set of data points (labeled or unlabeled), and w ij is a quantitative measure of the closeness of data points v i and v j .

Similar to Graph-based algorithm in semi-supervised learning, the edges in the Similarity-Graph measure the similarities between nodes. To capture the lo-cal and global semantical structure, the k -nearest neighbor graph is a common selection. Generally, there are two techniques to determinate the nearest neigh-bor: k -NN and -NN. For the simplification, we only consider k -NN graph in this paper. It should be mentioned that they are not symmetric on measure space, sometimes we force it to be a symmetric graph for computation convenience. Let N ( v i )bethesetofthe v i nearest neighbors,then the edge e ( N ) ij is defined by
On the other hand, noticing the importance of the label propagation in within-classes, we construct a with-class constraint graph G ( C ) to depict the label prop-agation in the same class. the edge e ( C ) ij is defined by In contrast to G NN , G C is bidirectional and symmetric.

Now, A weight Similarity-Graph can be written as: G sim =  X G NN  X  (1  X   X  ) G C , where the symbol  X  depicts the Entry-wise sum, that is, and  X  is a trade-off factor. In practice, we choose the parameter  X  using cross validation trick( it is set as 0.5 in this paper). A strength of this model lies in the fact that it incorporates labeled data to alleviate the noise effect, whereas the majority of graph deal strictly with the spatial relationship in unsupervised learning. 3.2 Label Propagation under t he Consistency Criterion The motivation for this phase is driven by the fact that the more labeled train-ing data we have, the better performance is achieved. So, why not label some unlabeled data with high confidence to improve the preformance of the detec-tion system? On the other hand , the idea of our algorithm is consist with the common semi-supervised learning assumptions: 1) nearby points are likely to have the same label; 2) points on the same structure (such as a cluster or a sub-manifold) are likely to have the same label.

Inspired by the success of co-training method, we conduct belief propagation on the multi view graphs. If one node is labeled the same class label from the dif-ferent graphs, we call it as confidence node and label its class label assuredly. To implement label propagation on the similarity graph, we apply spectral cluster-ing on the G sim in this phase. The benefit from spectral clustering is that it can capture multi-topical distribution if we choose an appropriate cluster number. However, it is harder to determinate the optimal cluster number in principle. For webspam detection task, we select a num berbiggerthan2inourexperiments. Then, we category unlabeled data accord ing to clustering results and labeled data in the corresponding cluster.

For Link-Graph, we can conduct TrustRank algorithm [4] to score each node, and category all unlabeled nodes into spam and good hosts(pages). From the results of above procedure, we continue to find all confidence nodes in term of the consistency criterion. Let L con denote the confident nodes set. We can rearrange a new labeled set  X  L = L  X  L con and a new unlabeled one  X  U = U \ L con by label propagation, then we get a new Similarity Graph  X  G sim combining G NN and new constrain graph  X  G C . For the rest of unlabeled data , we infer their class label on the fusing spectral space which is conducted by the new Similarity-Graph  X  G sim and Link Graph. 3.3 Spectral Space Analysis So far, we have a Similarity Graph  X  G sim ,LinkGraph G link and the new labeled set  X  L to represent the data information. Now, we conduct a fusing framework to capture these useful prior information. Remember that the spectral vectors encode the fidelity of a cluster, we can utilize these graph matrices to build a compressing spectral space.

For Link Graph, we calculate the TrustRank scores and SpamRank Scores [2] using the new labeled set  X  L .Let A be an n  X  n adjacency matrix for a given web graph such that A ji = 1 if page i links to page j and A ji =0otherwise,a TrustRank [4] is defined as where T is a stochastic matrix which is related to the adjacency matrix A ,  X   X  [0 , 1] is a given scalar and d is a non-negative, L vector. The vector P trust can be computed by the power iteration and is the stationary distribution vector of Link Graph with a biased random walk.
Similar to the TrustRank algorithm, we can get spam score vector P spam using a different personalized vector and propagation direction according to in-link directionality. Actually, both P trust and P spam are the different attributions in spectral space for the special nodes. Recall that new Similarity-Graph  X  G de-scribes the semantical characters, we can resort to Laplacian operator to measure the semantical attribut ion in the spectral space.

Finally, the discussion above allow us to integrate these attributes of each node into a unitary vector. New low-dimensionality representation contains sufficient discriminative information for detecting spam. Consequently, we can detect spam in the new space using the classical classification algorithm or something else. In summary, we give the corresponding algorithm below: Algorithm 1. Spectral Space Analysis To illustrate the effectiveness of our algorithm, we conduct the proposed algo-rithm on the corpus 1 from the ECML/PKDD Web spam challenge(see [1] for more details). In our experiments, firstl y, we apply feature selection processing for the purpose of reducing problem size. By applying information gain scor-ing on the labeled data, 9862 features are selected from the original 4,924,007 features as a concise representation.

All parameters related Li nk-Graph are configured by the default value, such as the parameter  X  in TrustRank/SpamRank is chosen as 0.85. For the simplicity, we apply the standard KNN classification to infer the remained unlabeled data in the last phase of our method on the low-dimensionality spectral space. Since there are about four times as many non-spam hosts as spam hosts in Webspam challenge data,, spam detection is a highly unbalanced classification is-sue. In addition, as a cost-sensitive prob lem, classifying a normal host into spam is much worse than classifying a spam host into normal. Hence, we need to mea-sure algorithmic performances via preci sion, recall and classi fication accuracy, rather than a single evaluation index.
For a comparison purpose, we firstly use a standard SVM classifier, based on content features, as one baseline cla ssifier in supervised learning manner; we also report the result of the fusing SpamRank and TrustRank strategy for Webspam detection, this method is based on Link-Graph; as a comparison of the performance, a Transductive learning algorithm on the multi-view graph is applied the same dataset. Experimental results is reported in Table 1.
From Table 1, we observe that the baseline classifier obtains the highest pre-cision, but it is difficult to accept that t he recall is less than 10 percent. It also means that content features are useful for detecting Webspam. Compara-bly, the semi-supervised learning outperforms the supervised learning according to accuracy index and the classifier based combining features perform well. Our proposed algorithm utilizes both link and content features and improves the overall performance of the detection system. The proposed method integrates unlab eled data and labeled data into a uni-fied learning framework. Empirical studies show that it is competitive with the start-of-the-art detecting system in terms of some standard evaluation indexes. For future work, we will extend the proposed algorithm to the out-of-sample case and explore an efficiency approximation algorithm to alleviate computation complexity.

