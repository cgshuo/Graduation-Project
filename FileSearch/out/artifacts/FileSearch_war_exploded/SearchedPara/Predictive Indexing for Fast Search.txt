 The Problem. The objective of web search is to quickly return the set of most relevant web pages given a particular query string. Accomplishing this task for a fixed query involves both determining the relevance of potential pages and then searching over the myriad set of all pages for the most relevant ones. Here we consider only the second problem. More formally, let Q  X  R n be an input space , W  X  R m a finite output space of size N , and f : Q  X  W 7 X  R a known scoring function . Given an input (search query) q  X  Q , the goal is to find, or closely approximate, the top-k output objects (web pages) p 1 ,...,p k in W (i.e., the top k objects as ranked by f ( q,  X  ) ). The extreme speed constraint, often 100ms or less, and the large number of web pages ( N  X  10 10 ) makes web search a computationally-challenging problem. Even with perfect 1000-way paralleliza-tion on modern machines, there is far too little time to directly evaluate against every page when a particular query is submitted. This observation limits the applicability of machine-learning methods for building ranking functions. The question addressed here is:  X  X an we quickly return the highest scoring pages as ranked by complex scoring rules typical of learning algorithms? X  Predictive Indexing. We describe a method for rapidly retrieving the top elements over a large set as determined by general scoring functions. The standard method for mitigating the computational difficulties of search is to pre-process the data so that far less computation is necessary at runtime. Taking the empirical probability distribution of queries into account, we pre-compute collections of web pages that have a large expected score conditioned on the query falling into particular sets of related queries { Q i } . For example, we may pre-compute and store the list of web pages that have the highest average score when the query contains the phrase  X  X achine learning X . To yield a practical algorithm, these sets should form meaningful groups of pages with respect to the scoring function and query distribution. At runtime, we then optimize only over those collections of top-scoring web pages for sets Q i containing the submitted query.
 Our main contribution is optimizing the search index with respect to the query distribution. The em-pirical evidence presented shows that predictive indexing is an effective technique, making general machine learning style prediction methods viable for quickly ranking over large numbers of objects. The general methodology applies to other optimization problems as well, including approximate nearest neighbor search.
 In the remainder of Section 1 we describe existing solutions to large-scale search, and their applica-bility to general scoring functions. Section 2 describes the predictive indexing algorithm and covers an example and lemma suggesting that predictive indexing has significant advantages over existing techniques. We present empirical evaluation of the method in Section 3, using both proprietary web advertising data and public data for nearest neighbor search. 1.1 Feature Representation One concrete way to map web search into the general predictive index framework is to represent Specifically, we associate each word with a coordinate: A query (page) has a value of 1 for that coordinate if it contains the word, and a value of 0 otherwise. We call this the word-based feature representation , because each query and page can be summarized by a list of its features (i.e., words) that it contains. The general predictive framework supports many other possible representations, including those that incorporate the difference between words in the title and words in the body of the web page, the number of times a word occurs, or the IP address of the user entering the query. 1.2 Related Work Given the substantial importance of large-scale search, a variety of techniques have been developed to address the rapid ranking problem. Past work that has referenced the query distribution includes (Cheng et al., 2006; Chierichetti et al., 2008). Here we describe two commonly applied methods related to the predictive index approach.
 Fagin X  X  Threshold Algorithm. Fagin X  X  threshold algorithm (Fagin et al., 2003) supports the top-k i th coordinate of the query q , and g i : W 7 X  R are partial scores for pages as determined by the i th feature 1 . For each query feature i , construct an ordered list L i containing every web page, sorted is attained by projecting the scoring rule onto individual coordinates. Given a query q , we evaluate web pages in the lists L i that correspond to features of q . The algorithm maintains two statistics, upper and lower bounds on the score of the top-k th page, halting when these bounds cross. The lower bound is the score of the k th best page seen so far; the upper bound is the sum of the partial partial scores, the upper threshold does in fact bound the score of any page yet to be seen. The threshold algorithm is particularly effective when a query contains a small number of features, facilitating fast convergence of the upper bound. In our experiments, we find that the halting con-dition is rarely satisfied within the imposed computational restrictions. One can, of course, simply halt the algorithm when it has expended the computational budget (Fagin, 2002), which we refer to as the Halted Threshold Algorithm .
 Inverted Indices. An inverted index is a datastructure that maps every page feature x to a list of pages p that contain x . When a new query arrives, a subset of page features relevant to the query is first determined. For instance, when the query contains  X  X og X , the page feature set might be {  X  X og X ,  X  X anine X ,  X  X ollar X , ... } . Note that a distinction is made between query features and page features, and in particular, the relevant page features may include many more words than the query itself. Once a set of page features is determined, their respective lists (i.e., inverted indices) are searched, and from them the final list of output pages is chosen. One method for searching over these lists is to execute Fagin X  X  threshold algorithm. Other methods, such as the  X  X eighted-And X  algorithm (Broder et al., 2003), use one global order for pages in the lists and walk down the lists synchronously to compute page scores. See (Zobel &amp; Moffat, 2006) for an overview of inverted indices applied to web search. Standard approaches based on inverted indices suffer from a shortcoming. The resulting algorithms query. They require, for each query q , that there exists a small set 2 X q of page features such that the score of any page against q depends only on its intersection with X q . In other words, the scoring rule must be extremely sparse, with most words or features in the page having zero contribution to the score for q . In Section 3.1, we consider a machine-learned scoring rule, derived from internet advertising data, with the property that almost all page features have substantial influence on the score for every query, making any straightforward approach based on inverted indices intractable. Furthermore, algorithms that use inverted indices do not typically optimize the datastructure against the query distribution and our experiments suggest that doing so may be beneficial. Suppose we are provided with a categorization of possible queries into related, potentially overlap-ping, sets. For example, these sets might be defined as,  X  X ueries containing the word  X  X rance X , X  or  X  X ueries with the phrase  X  X ar rental X . X  For each query set, the associated predictive index is an ordered list of web pages sorted by their expected score for random queries drawn from that set. In particular, we expect web pages at the top of the  X  X rance X  list to be good, on average, for queries containing the word  X  X rance. X  In contrast to an inverted index, the pages in the  X  X rance X  list need not themselves contain the word  X  X rance X . To retrieve results for a particular query (e.g.,  X  X rance car rental X ), we optimize only over web pages in the relevant, pre-computed lists. Note that the predic-tive index is built on top of an already existing categorization of queries, a critical, and potentially difficult initial step. In the applications we consider, however, we find that predictive indexing works well even when applied to naively defined query sets. Furthermore, in our application to approxi-mate nearest neighbor search, we found predictive indexing to be robust to cover sets generated via random projections whose size and shape were varied across experiments.
 We represent queries and web pages as points in, respectively, Q  X  R n and W  X  R m . This setting is general, but for the experimental application we consider n,m  X  10 6 , with any given page or query having about 10 2 non-zero entries (see Section 3.1 for details). Thus, pages and points are typically sparse vectors in very high dimensional spaces. A coordinate may indicate, for example, whether a particular word is present in the page/query, or more generally, the number of times that word appears. Given a scoring function f : Q  X  W 7 X  R , and a query q , we attempt to rapidly find that are among the top l for l  X  k . We assume queries are generated from a probability distribution D that may be sampled. 2.1 Predictive Indexing for General Scoring Functions Consider a finite collection Q of sets Q i  X  Q that cover the query space (i.e., Q  X  X  X  i Q i ). For each Q web page p for the (related) queries in Q i . The hope is that any page p has approximately the same score for any query q  X  Q i . If, for example, Q i is the set of queries that contain the word  X  X og X , we may expect every query in Q i to score high against pages about dogs and to score low against those pages not about dogs.
 For each set of queries Q i we pre-compute a sorted list L i of pages p i 1 ,p i 2 ,...,p i N ordered in descending order of f i ( p ) . At runtime, given a query q , we identify the query sets Q i containing q , and compute the scoring function f only on the restricted set of pages at the beginning of their associated lists L i . We search down these lists for as long as the computational budget allows. however, approximate these scores by sampling from the query distribution D . Algorithm 1 outlines the construction of the sampling-based predictive indexing datastructure. Algorithm 2 shows how the method operates at run time.
 Note that in the special case where we cover Q with a single set, we end up with a global ordering of web pages, independent of the query, which is optimized for the underlying query distribution. Algorithm 1 Construct-Predictive-Index(Cover Q , Dataset S )
L j [ s ] = 0 for all objects s and query sets Q j . for t random queries q  X  D do end for for all lists L j do end for return { L } Algorithm 2 Find-Top(query q , count k ) i = 0 top-k list V =  X  while time remains do end while return V While this global ordering may not be effective in isolation, it could perhaps be used to order pages in traditional inverted indices. 2.2 Discussion We present an elementary example to help develop intuition for why we can sometimes expect predictive indexing to improve upon projective datastructures such as those used in Fagin X  X  threshold q linear scoring function defined by where I is the indicator function. That is, p i is the best match for query q i , but p 3 does not score highly for either query feature alone. Thus, an ordered, projective datastructure would have Suppose, however, that we typically only see query q 3 . In this case, if we know t 1 is in the query, we infer that t 2 is likely to be in the query (and vice versa), and construct the predictive index On the high probability event, namely query q 3 , we see the predictive index outperforms the projec-tive, query independent, index.
 We expect predictive indices to generally improve on datastructures that are agnostic to the query distribution. In the simple case of a single cover set (i.e., a global web page ordering) and when we wish to optimize the probability of returning the highest-scoring object, Lemma 2.1 shows that a predictive ordering is the best ordering relative to any particular query distribution. Lemma 2.1. Suppose we have a set of points S , a query distribution D , and a function f that scores queries against points in S . Further assume that for each query q , there is a unique highest scoring h ( s ) . For any fixed k , list according to h (  X  ) . We evaluate predictive indexing for two applications: Internet advertising and approximate nearest neighbor. 3.1 Internet Advertising We present results on Internet advertising , a problem closely related to web search. We have ob-tained proprietary data, both testing and training, from an online advertising company. The data are comprised of logs of events, where each event represents a visit by a user to a particular web page p , from a set of web pages Q  X  R n . From a large set of advertisements W  X  R m , the commercial system chooses a smaller, ordered set of ads to display on the page (generally around 4 ). The set of ads seen and clicked by users is logged. Note that the role played by web pages has switched, from result to query. The total number of ads in the data set is | W |  X  6 . 5  X  10 5 . Each ad contains, on average, 30 ad features, and a total of m  X  10 6 ad features are observed. The training data consist of 5 million events (web page  X  ad displays). The total number of distinct web pages is 5  X  10 5 . Each page consists of approximately 50 page features, and a total of n  X  9  X  10 5 total page features are observed.
 We used a sparse feature representation (see Section 1.1) and trained a linear scoring rule f of the form f ( p,a ) = P i,j w i,j p i a j , to approximately rank the ads by their probability of click. Here, w i,j are the learned weights (parameters) of the linear model. The search algorithms we compare were given the scoring rule f , the training pages, and the ads W for the necessary pre-computations. They were then evaluated by their serving of k = 10 ads, under a time constraint, for each page in the test set. There was a clear separation of test and training. We measured computation time in terms of the number of full evaluations by the algorithm (i.e., the number of ads scored against a given page). Thus, the true test of an algorithm was to quickly select the most promising T ads to fully score against the page, where T  X  { 100 , 200 , 300 , 400 , 500 } was externally imposed and varied over the experiments. These numbers were chosen to be in line with real-world computational constraints.
 We tested four methods: halted threshold algorithm (TA), as described in Section 1.2, two variants of predictive indexing ( PI-AVG and PI-DCG ), and a fourth method, called best global ordering (BO), which is a degenerate form of PI discussed in Section 2.1. An inverted index approach is prohibitively expensive since almost all ad features have substantial influence on the score for every web page (see Section 1.2).
 PI-AVG and PI-DCG require a covering of the web page space. We used the natural covering sug-gested by the binary features X  X ach page feature i corresponds to a cover set consisting of precisely those pages p that contain i . The resulting datastructure is therefore similar to that maintained by the TA algorithm X  X ists, for each page feature, containing all the ads. However, while TA orders ads tioned on the page containing feature i . PI-DCG and BO optimize the expected value of a modified indicator function. Here, r ( p,a ) = j indicates that ad a has rank j according to f ( p,a ) over all ads in W . BO stores a single list of all ads, sorted by expected DCG f ( p,a ) , while PI-DCG stores a list for each page feature i sorted by E p  X  D i [DCG f ( p,a )] . We chose this measure because: All three predictive methods were trained by sampling from the training set, as described in 2.1. Figure 3.1 plots the results of testing the four algorithms on the web advertising data. Each point in the figure corresponds to one experiment, which consisted of executing each algorithm on 1000 test pages. Along the x -axis we vary the time constraint imposed on the algorithm. The y -axis plots the frequency, over the test pages, that the algorithm succeeded in serving the top scoring ad for position 1 (Figure 1(a)) and for position 10 (Figure 1(b)). Thus, vertical slices through each plot show the difference in performance between the algorithms when they are given the same amount of serving time per page. The probabilities were computed by off-line scoring of all 6 . 5  X  10 5 ads for each test page and computing the true top-10 ads. Serving correctly for position 10 is more difficult than for position 1 , because it also requires correctly serving ads for positions 1 through 9 . We see that all three methods of predictive indexing are superior to Fagin X  X  halted threshold algorithm. In addition, the use of a richer covering, for PI-DCG and PI-AVG, provides a large boost in performance. These latter two predictive indexing methods attain relatively high accuracy even when fully evaluating only 0.05% of the potential results. Figure 1: Comparison of the first and tenth results returned from the four serving algorithms on the web advertisement dataset.
 Our implementation of the predictive index, and also the halted threshold algorithm, required about 50ms per display event when 500 ad evaluations are allowed. The RAM use for the predictive index is also reasonable, requiring about a factor of 2 more RAM than the ads themselves. 3.2 Approximate Nearest Neighbor Search A special case application of predictive indexing is approximate nearest neighbor search . Given a set of points W in n -dimensional Euclidean space, and a query point x in that same space, the nearest neighbor problem is to quickly return the top-k neighbors of x . This problem is of considerable interest for a variety of applications, including data compression, information retrieval, and pattern recognition. In the predictive indexing framework, the nearest neighbor problem corresponds to minimizing a scoring function, f ( x,y ) = || x  X  y || 2 , defined by Euclidean distance. We assume query points are generated from a distribution D that can be sampled.
 To start, we define a covering Q of the input space R n , which we borrow from locality-sensitive approximate nearest neighbor problem. Fix positive integer parameters  X , X  . First, we form  X  random partitions of the input space. Geometrically, each partition splits the n -dimensional space on  X  random hyperplanes. Formally, for all 1  X  i  X   X  and 1  X  j  X   X  , generate a random unit-norm n -vector Y ij = ( Y ij 1 ,...,Y ij n )  X  R n from the Gaussian (normal) distribution. For fixed i  X  { 1 ,..., X  } and subset J  X  { 1 ,..., X  } define the cover set Q i,J = { x  X  R n : x  X  Y ij  X  random planes.
 Given a query point x , consider the union U x = S { Q ing x . Standard LSH approaches to the nearest neighbor problem work by scoring points in the set Q x = W  X  U x . That is, LSH considers only those points in W that are covered by at least one of the same  X  sets as x . Predictive indexing, in contrast, maps each cover set Q i,J to an ordered list of points sorted by their probability of being a top-10 nearest point to points in Q i,J . That is, the we then consider those points in W with large probability h Q i,J for at least one of the sets Q i,J that cover x .
 We compare LSH and predictive indexing over four data sets: (1) MNIST X 60,000 training and 10,000 test points in 784 dimensions; (2) Corel X 37,749 points in 32 dimensions, split randomly dimensions; and (4) Optdigits X 3823 training and 1797 test points in 65 dimensions. The MNIST data is available at http://yann.lecun.com/exdb/mnist/ and the remaining three data sets are available at the UCI Machine Learning Repository ( http://archive.ics.uci.edu/ ml/ ). Random projections were generated for each experiment, inducing a covering of the space that was provided to both LSH and predictive indexing. The predictive index was generated by sampling over the training set as discussed in Section 2.1. The number of projections  X  per partition was set to 24 for the larger sets (Corel and MNIST) and 63 for the smaller sets (Pendigits and Optdigits), while the number of partitions  X  was varied as an experimental parameter. Larger  X  corresponds to more full evaluations per query, resulting in improved accuracy at the expense of increased computation time. Both algorithms were restricted to the same average number of full evaluations per query. Predictive indexing offers substantial improvements over LSH for all four data sets. Figure 2(a) displays the true rank of the first point returned by LSH and predictive indexing on the MNIST data set as a function of  X  , averaged over all points in the test set and over multiple trials. Predictive indexing outperforms LSH at each parameter setting, with the difference particularly noticeable when fewer full evaluation are permitted (i.e., small  X  ). Figure 2(b) displays the performance of LSH and predictive indexing for the tenth point returned, over all four data sets, with values of  X  varying from 5 to 70 , averaged over the test sets, and replicated by multiple runs. In over 300 trials, we did not observe a single instance of LSH outperforming predictive indexing.
 Recent work has proposed more sophisticated partitionings for LSH (Andoni &amp; Indyk, 2006). Ap-proaches based on metric trees (Liu et al., 2004), which take advantage of the distance metric struc-ture, have also been shown to perform well for approximate nearest neighbor. Presumably, taking advantage of the query distribution could further improve these algorithms as well, although that is not studied here. Predictive indexing is the first datastructure capable of supporting scalable, rapid ranking based on general purpose machine-learned scoring rules. In contrast, existing alternatives such as the Thresh-old Algorithm (Fagin, 2002) and Inverted Index approaches (Broder et al., 2003) are either substan-tially slower, inadequately expressive, or both, for common machine-learned scoring rules. In the special case of approximate nearest neighbors, predictive indexing offers substantial and consistent improvements over the Locality Sensitive Hashing algorithm. Figure 2: Comparison of the first and tenth results returned from LSH and predictive indexing.
