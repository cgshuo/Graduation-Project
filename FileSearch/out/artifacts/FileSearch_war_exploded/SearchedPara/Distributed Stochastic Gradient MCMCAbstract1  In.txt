 Department of Computer Science, University of California, Irvine Babak Shahbaba BABAKS @ UCI . EDU Department of Statistics, University of California, Irvine Max Welling M . WELLING @ UVA . NL Machine Learning Group, University of Amsterdam Probabilistic inference methods that can operate on a very large data scale are becoming increasingly relevant in an era that data volume grows exponentially. Two promis-ing directions in this respect are stochastic gradient vari-ational inference (Hoffman et al., 2010) and stochastic gra-dient MCMC algorithms (Welling &amp; Teh, 2011; Ahn et al., 2012; Patterson &amp; Teh, 2013). The main innovation for both classes of algorithms is that only a small mini-batch of data is necessary for every update, allowing many more up-dates per time interval. In the context of MCMC this leads to much shorter burn-in times and faster mixing speeds. In this paper we are concerned with parallelizing stochas-tic gradient MCMC algorithms. The most straightfor-ward, embarrassingly parallel implementation would be to copy the full dataset to each worker, run separate Markov chains and use their results as independent samples (see e.g. (Wilkinson, 2006; Laskey &amp; Myers, 2003; Ahn et al., 2013)). However, the size of modern day datasets can be so large that a single machine cannot store the full dataset. In this case, one can still parallelize most MCMC algo-rithms by performing data-specific computations (e.g. the gradient of the log-probability for one data-case) locally on each relevant worker and combining these computations in a master server. The disadvantage of these methods is how-ever that they lead to very high communication costs. We argue that MCMC algorithms based on stochastic mini-batches have a key property that make them ideally suited for parallelization, namely that each Markov chain can in-dependently generate samples for a variable amount of time , which can later be combined. The reason is that each chain can draw mini-batches from its local pool of data in order to generate samples. Chains must jump to other ma-chines (synchronously or asynchronously) in order to gen-erate unbiased estimates of the posterior in the limit, but the time spend on each worker is flexible provided that the chain X  X  hyper-parameters are properly adjusted to remove potential bias. This flexibility leads to less communication (because chains can run longer on individual workers) and entirely removes the problem that fast workers are blocked by slower workers because they depend on their results in order to proceed.
 We present distributed stochastic gradient Langevin dy-namics (D-SGLD) and apply it to topic modeling. In this setting, we show that relative to the current fastest se-quential MCMC sampler (Patterson &amp; Teh, 2013), and the fastest approximate distributed MCMC samplers (Newman et al., 2007; Ahmed et al., 2012; Smola &amp; Narayanamurthy, 2010), D-SGLD achieves equivalent perplexities at least an order of magnitude faster.
 Let X = { x 1 ,...,x N } be a dataset of N i.i.d. data points assumed to be sampled from a parameterized distribution p ( x |  X  ) where  X   X  R d has a prior distribution p (  X  ) . We are interested in collecting samples from the posterior dis-tribution p (  X  | X )  X  p ( X |  X  ) p (  X  ) . As discussed above, we assume that the dataset X is too large to reside in a sin-gle machine. Therefore, it is partitioned into S subsets, called shards : X 1 ,...,X S such that X =  X  s X s and N = P s N s . We assign shard X s = { x s 1 ,...,x s N worker s , where s = 1 ,...,S . We refer to the posterior distribution based on a specific shard as local posterior : p (  X  | X s )  X  p ( X s |  X  ) p (  X  ) .
 The score function or the gradient of the log likelihood given a data point x is denoted by g (  X  ; x ) =  X   X  log p (  X  ; x ) . We also denote a mini-batch of n data points by X n when sampled from X and by X n s when sampled from shard X s . Additional time index t is used sometimes to distinguish mini-batches sampled over iterations: X n s,t . The sum and mean of scores over all elements of a set, X , are denoted by G (  X  ; X ) = P x  X  X g (  X  ; x ) and  X  g (  X  ; X ) = respectively. We now review two approaches to scale up MCMC algorithms; one by using mini-batches and the other by using distributed computational resources. 2.1. Mini-batch-based MCMC The stochastic gradient Langevin dynamics (SGLD) pro-posed by Welling and Teh (2011) is the first sequential mini-batch-based MCMC algorithm. In SGLD, the param-eters are updated as follows:  X  Here t is the step size and  X  t  X  N (0 , t ) is the in-jected Gaussian noise. The gradient of the log-likelihood, G (  X  t ; X ) , over the whole dataset is approximated by scal-ing the mean score,  X  g (  X  t ; X n t ) = 1 n P x  X  X n puted based on a mini-batch X n t of size n N . SGLD does not use accept-reject tests because as the step size goes to zero the acceptance rate tends to one. Therefore, SGLD requires only O ( n ) computations to generate each sample, unlike traditional MCMC algorithms that require O ( N ) computations per iteration. Because computing  X  g (  X  t in parallel within a multi-core worker is straightforward, throughout the paper we assume that each worker is single-core.
 We can generalize the SGLD update rule in Eqn. (1) by replacing the mean score  X  g (  X  t ; X n t ) to a general form of score estimator f (  X  t ,Z ; X ) , where Z is a set of auxiliary random variables associated with the estimator. According to Welling &amp; Teh (2011), an estimator f (  X  t ,Z ; X ) is guar-anteed to converge to the correct posterior if (i) f (  X  t is an unbiased estimator of  X  g (  X  t ; X ) = 1 N P x  X  X (assuming the variance of f is finite) and (ii) the step size is annealed to zero by a schedule satisfying P  X  t =1 t =  X  Definition 1. We define an estimator f (  X ,Z ; X ) as a valid SGLD estimator if it is an unbiased estimator of  X  g (  X  ; X ) , i.e., E Z [ f (  X ,Z ; X )] =  X  g (  X  ; X ) , where E Z denotes expec-tation w.r.t. the distribution p ( Z ; X ) , and it has finite vari-ance V Z [ f (  X ,Z ; X )] &lt;  X  .
 For an alternative way to speed-up MCMC by using a mini-batch-based Metropolis-Hastings (MH) test, refer to Korat-tikara et al. (2014); Bardenet et al. (2014). 2.2. Distributed Inference in LDA Distributing the workload using a cluster of workers is an-other way of speeding up MCMC. In this paper we are interested in topic models for which a number of dis-tributed MCMC algorithms have already been developed (our method is more generally applicable however). In ap-proximate distributed LDA (AD-LDA) by Newman et al. (2007) the computation cost per sample is reduced to O ( N by allowing each worker to perform collapsed Gibbs sam-pling only on its local shard. AD-LDA also corrects (ap-proximately) the biases in the local copies of the global states by allowing for regular global synchronization. However, AD-LDA suffers from some shortcomings. First, it becomes slower as the dataset size increases, unless ad-ditional workers are provided. Second, due to the global synchronization, it suffers from the  X  X lock-by-the-slowest X  problem, meaning that some workers are blocked until the slowest worker finishes its task. Lastly, running parallel chains usually adds large overhead. Yahoo-LDA (Y-LDA) (Ahmed et al., 2012) performs asynchronous updates to resolve the block-by-the-slowest problem. However, the unbounded asynchronous updates could deteriorate perfor-mance (Ho et al., 2013). 3.1. SGLD on Partitioned Datasets We begin the exposition of our algorithm with the follow-ing question:  X  X s an SGLD algorithm that samples mini-batches from randomly chosen local shards valid? X  The number of possible combinations of mini-batches that can be generated by this procedure is significantly smaller set than that of the standard SGLD. The answer will clearly depend on quantities like the shard sizes and shard selec-tion probabilities. We now introduce an estimator  X  g d in the proposition below as an answer to the above question (the proof is provided in the supplementary material).
 Proposition 3.1. For each shard s = 1 ,...,S , given the shard size, N s , and the normalized shard selection fre-quency, q s , such that N s &gt; 0 , P S s =1 N s = N , q and P S s =1 q s = 1 , the following estimator is a valid SGLD estimator, where shard s is sampled by a scheduler h ( Q ) with fre-quencies Q = { q 1 ,...,q S } .
 For example, we can (1) choose a shard by sampling s  X  h ( Q ) = Category ( q 1 ,...,q S ) , (2) sample a mini-batch X n s from the selected shard, (3) compute mean score  X  g (  X  ; X n s ) using that mini-batch, and then (4) multiply the mean score by N s Nq SGLD update rule becomes  X  We can interpret this as a correction to the step sizes for the  X  g (  X  t ; X n s for shards that are relatively larger in size and/or used less frequently than others. This implies that every data-case contributes equally to the mixing of the chain. Note that Q represent free parameters that we can choose depending on the system properties. 3.2. Traveling Worker Parallel Chains Now assume that the shards are distributed between the workers, so from now on selecting shard s is equivalent to choosing worker s . We note that running the above algo-rithm occupies only a single worker at a time. Therefore, assuming single-core workers, it is possible to run C (  X  S ) independent and valid SGLD chains in parallel , i.e., one chain per worker.
 This approach, however, has some shortcomings. First, the communication cycle is still short O ( n ) because each chain is required to jump to a new worker at every iteration. Sec-ond, it can suffer from the block-by-the-slowest problem if its next scheduled worker is still occupied by another chain due to workers X  imbalanced response delays. The response delay , denoted by d s , is defined as the elapsed time that worker s spends to process a O ( n ) workload. In the fol-lowing sections, we present our method to address these issues. To deal with the  X  X hort-communication-cycle X  problem, we propose to use trajectory sampling : instead of jumping to another worker at every iteration, each chain c takes  X  consecutive updates in each visit to a worker. Then, af-ter  X  updates, only the last (  X  th) state is passed to the next worker of the chain. Trajectory sampling reduces commu-nication overhead by increasing the communication cycle from O ( n ) to O (  X n ) . Furthermore, instead of transferring all samples collected over a trajectory to the master, we can store them in a distributed way by caching each trajectory at its corresponding worker. This keeps the packet size at O (1) regardless of the trajectory length, and mitigates the memory problem caused by storing many high-dimension samples at a single machine.
 In trajectory sampling for parallel chains, we employ a scheduler h c ( Q ) for each chain c to choose the next worker from which the next trajectory is sampled. Note here that the scheduler is now called with an interval  X  . Because there are a total of C such schedulers (one per chain), the schedulers should avoid two situations in order to be ef-ficient: (1) collision (i.e., multiple chains visit a worker at the same time), and (2) jump-in-place (i.e., jumping to the current worker) can negatively affect mixing across shards. One way to avoid these issues is to set Q uni-form, and simply use a random permutation (or, cyclic ro-tation) to assign chains to workers. That is, we can sam-ple the chain-to-worker assignments by ( s 1 ,...,s C ( h 1 ( Q ) ,...,h C ( Q )) = RANDPERM ( S ) . Here, s c denotes a worker that chain c is scheduled to visit; we assume C = S for simplicity.
 Similar to the effect of step sizes in standard SGLD, trajec-tory lengths can also be used to control the level of approx-imation by trading off computation time with asymptotic accuracy. As both the trajectory length and the annealed step sizes { t } can affect the equilibrium distribution of the chain, we consider first that is fixed. Then, with a long trajectory, we can reduce the communication overhead at the cost of some loss in asymptotic accuracy. In fact, it is not difficult to see that in this case our method samples from a mixture of local posteriors, 1 S P S s =1 p (  X  | X end of the spectrum where long trajectory lengths are used, and it approaches the true posterior at the other end of the spectrum with short trajectory lengths ( is small enough). Note that this is indeed the desired behavior when deal-ing with massive datasets. That is, as N  X   X  , the lo-cal posteriors become close to the true posterior and thus the error decreases by the central limit theorem (provided X s is a uniform random partition of X ):  X  g (  X  ; X increases, we can increase the trajectory length accordingly without a significant loss in asymptotic accuracy. The fol-lowing Corollary 3.2 states that for any finite  X  , trajectory sampling is a valid SGLD (assuming the step sizes decrease to zero over time).
 Corollary 3.2. A trajectory sampler with a finite  X   X  1 , obtained by redefining the worker (shard) selection process h ( Q ) in Proposition 3.1 by the process h ( Q , X  ) below, is a valid SGLD sampler. h ( Q , X  ) : for chain c at iteration t , choose the next worker s c t +1 by where  X  h ( Q ) is an arbitrary scheduler with selection prob-abilities Q . Using trajectory sampling, we can mitigate the short-communication-cycle problem. Moreover, if response de-lays are balanced, we can set Q to be uniform and use a random permutation scheduler to keep the block-by-the-slowest delay small. However, for imbalanced response delays, using uniform Q would lead to long block-by-the-slowest delays (See, Fig. 1 (a)). In this section, we propose a solution to balance the workloads by adapting Q to the worker response delays.
 The basic idea is to make the faster workers work longer until the slower workers finish their tasks so that the overall response times of the workers become as balanced as pos-sible. For instance, twice longer trajectories can be used for a worker that is twice as fast. More specifically, we achieve this by (1) having uniform worker selection and (2) setting the trajectory length  X  s of worker s to  X  s = q s worker s ), and  X   X  is a user-defined mean trajectory length: E worker selection probability 1 /S ).
 In other words, we select a worker uniformly and perform trajectory sampling of length  X  s , which is proportional to the relative speed of the worker, q s . (If  X  s is not an integer, we can either adjust  X   X  to make it integer or take simply the closest integer.) Note that using unequal trajectory lengths across the workers remains a valid SGLD because the step sizes are properly corrected by Eqn. (2) where q s  X   X  s . This is illustrated in Figure 1 and stated in Corollary 3.3. Corollary 3.3. Given  X  s , where 1  X   X  s &lt;  X  for s = 1 ,...,S , the adaptive trajectory sampler, obtained by redefining the worker (shard) selection process h ( Q ) in Proposition 3.1 by the process h ( Q , {  X  s } ) below, is a valid SGLD sampler. h ( Q , {  X  s } ) : for chain c at iteration t , choose the next worker s c t +1 by s where  X  h (1 /S ) is a scheduler with uniform selection proba-bilities.
 Our method can deal with temporal imbalances as well. To this end, the master needs to monitor the changes in response delays; when a substantial change is detected, a new trajectory plan can replace the old one. Note that al-though this online adaptation affects the Markov property, it can still converge to correct target distribution assuming that the adaptation satisfies the Corollary 3.3 and the re-sponse delays converge fast enough. Refer to Andrieu &amp; Thoms (2008) for the details of the  X  X ast enough X  condi-tion. Pseudo code for the proposed D-SGLD method is presented in Algorithm 1. Here, we introduce one approach that could reduce the variance of the gradient estimator in Eqn (2) by having some interactions among the chains. The basic idea is to  X  X ie X  a group of chains by averaging their correspond-ing samples. More specifically, consider R  X  S chains forming a group and staying at a state  X  t at time t , i.e.,  X  t =  X  t for r = 1 ,...,R . After an update using the stan-dard SGLD update rule in Eqn. (1), we have R different states  X  1 t +1 ,..., X  R t +1 . By averaging the new states, we have  X   X  Here we used 1 R P R r =1  X  log p (  X  r t ) =  X  log p (  X  Algorithm 1 D-SGLD Pseudo Code 1: function M ASTER ( S,C,  X   X  ) 2: while sampling do 3: Monitor response delays { d s } 4: if { d s } are changed enough then 6: end if 7: Assign workers ( s 1 ,...,s C )  X  RANDPERM ( S ) 8: for each chain c parallel do 10: end for 11: end while 12: end function 13: function SAMPLE TRAJ ( c, X , X  s ) 14: Initialize  X  1  X   X  15: for t = 1 :  X  s do 16: Sample a mini-batch X n s and noise  X   X  X  (0 , ) 18: end for 19: Set trajectory, T c  X  (  X  1 ,..., X   X  s  X  1 ) 20: Store (append) trajectory,  X  c s  X  [ X  c s ,T c ] 21: Send the last state  X   X  s to the master 22: end function although the averaged noise  X   X  t = 1 R P R r =1  X  r t has smaller variance N (0 , t R ) than the standard SGLD, we can recover a valid SGLD with additional noise 1  X  t  X  N (0 , R  X  1 R so that  X   X  t +  X  t  X  N (0 , t ) . By the central limit theo-rem, the variance of the estimator of  X  g (  X  t ; X ) reduces from Although this approach leads to a valid SGLD with reduced variance in the gradient estimation, unfortunately it is diffi-cult to perform the trajectory sampling in this case since it requires communication among chains at each update. One way to bypass this issue is to employ the averaging strategy only at the end of each trajectory during the burn-in period. Alternatively, we can also gradually reduce the number of chains being coupled. Note that although coupling chains imposes algorithmic dependency, it is weaker than other algorithms (e.g., AD-LDA) that require synchronizations for all workers since (i) the number of dependent chains, R , in our method is relatively small ( R &lt; S ), and (ii) the response delays are already balanced by the adaptive tra-jectory sampling. 4.1. Simple Demonstration We first illustrate our proposed method based on sam-pling from a multivariate normal posterior distribution ob-tained by assuming a normal prior N (  X  x ;  X  0 ,  X  0 ) on the d -dimension mean  X  x of a normal distribution N ( x ;  X  x ,  X  from which we have observed N samples. Because this is a conjugate prior, the posterior distribution is also a normal distribution.
 To examine the bias correction effect, we allocated a total of 20,000 data points to a cluster of 20 workers. Further-more, we made the shard sizes { N s } highly imbalanced by setting N s = 500 for 10 workers and setting N s = 1500 for the remaining 10 workers. Then, to impose a higher level of imbalance, we also used the small shards 7 times more often than the large shards by setting the trajectory lengths for the small shards to 70 and those for the large shards to 10. We set the step size to 10  X  7 and the mini-batch size to n = 300 .
 In Fig. 2 (a) and (b), the black dotted circles represent the 2-d marginal covariance centered at the mean of the 20 local posteriors. Note that these are rescaled such that small circles represent the local posteriors based on small shards, whereas the large circles represent the local poste-riors based on large shards. Also, the red circle represents the true posterior, and the dotted blue circle represents the empirical distribution based on our samples. As we can see, our algorithm corrects the bias. We have evaluated our method for various dimensions (up to d = 100 ) and found similar results.
 The effect of trajectory lengths is also tested in Fig. 2 (c) and (d) using two different trajectory lengths,  X  = 10 , 000 and  X  = 200 , for a cluster of 4 workers. Here, the shard size was set to 2,000 for each worker, the trajectory lengths were kept the same for all workers, and the step size, , was set to 2  X  10  X  6 . As described in section 3.2.1, we can see that D-SGLD samples from a mixture of the local posteriors with long trajectory lengths and becomes close to the standard SGLD posterior as the length decreases. 4.2. Distributed Latent Dirichlet Allocation Next, we evaluate our method based on an important dis-tributed inference problem, namely, large-scale LDA, by comparing the following algorithms: (a) AD-LDA : In AD-LDA, to obtain a single sample, each worker s performs collapsed Gibbs iterations only on the full local shard (and is thus approximate), and then syn-chronizes its local topic assignments n s kw (for topic k and word w ) at the master to obtain the global state n kw based on the update n kw  X  n kw + P S s =1 ( n kw  X  n s kw ) . Then, the local state is updated by the new global state, n s kw  X  n It is shown that in practice AD-LDA shows comparable perplexities to the standard collapsed Gibbs sampling. (b) Async-LDA (Y-LDA): Unlike AD-LDA, Y-LDA (Ahmed et al., 2012; Smola &amp; Narayanamurthy, 2010) per-forms asynchronous updates for the global state by the up-a copy of the old local state at the time of previous syn-chronization. Because Y-LDA is a specific implementa-tion optimized along with many other dimensions, we im-plemented an algorithm called Async-LDA which replaces the update of AD-LDA with the asynchronous update of Y-LDA. Async-LDA was used to compare with the load balancing ability of D-SGLD. (c) SGRLD : Stochastic gradient Riemannian Langevin dy-namics (SGRLD) (Patterson &amp; Teh, 2013) is a specific SGLD sampler designed to sample from the probability simplex using Riemannian manifold. For LDA, SGRLD achieved fast mixing rate and resulted in the state-of-the-art performance. Note that SGRLD runs on a single machine without communication overhead. Specifically, SGRLD samples from a W -dimension topic probability simplex  X  k and the mean score  X  g (  X  kw ; X n t ) in the update rule is ob-tained by  X  g (  X  kw ; X n t ) = where the expectation is computed by running a collapsed Gibbs sampler on the topic assignments z d in each docu-ment d separately. Refer to Patterson &amp; Teh (2013) for the full update equation.
 Following Patterson &amp; Teh (2013), we set the mini-batch size to 50 documents, and for each update of Eqn. (7) we ran 100 Gibbs iterations for each document in the mini-batch. The step-sizes were annealed by a schedule t = a (1 + t/b )  X  c . As we fixed b = 1000 and c = 0 . 6 , the entire schedule was set by a which we choose by running parallel chains with different a  X  X  and then choosing the best. (d) D-SGLD : Our algorithm, D-SGLD for LDA, is built upon SGRLD. To use SGRLD as our base sampler, we only need to multiply the bias correction factor N s Nq We used cyclic rotation as the chain-to-worker scheduler and set the trajectory length  X  = 10 for all workers while we kept other parameters the same as for SGRLD by de-fault.
 In particular, to see the effect of the variance reduction (i.e., sample averaging), we implemented three differ-ent versions of D-SGLD, (i) Complete Coupling (D-CC), (ii) Complete Independent (D-CI), and (iii) Hybrid (D-Hybrid). D-CC couples all chains; whereas, D-CI runs in-dependent chains without any interaction among them. D-Hybrid partitions the chains into groups and the averaging is performed only for the chains in the same group. When the variance reduction is used, it was performed at the end of each trajectory; we did not inject any additional noise for correction.
 Additionally, we used the following settings for all al-gorithms. The predictive perplexities were computed on 1000 separate holdout set, with a 90/10 (training/test) split, and LDA X  X  hyper-parameters were set to  X  = 0 . 01 and  X  = 0 . 0001 following Patterson &amp; Teh (2013). The num-ber of topics K was set to 100 . Parallelism within a worker is not considered, although D-SGLD can be easily paral-lelized within a worker.
 We evaluate these methods based on the following datasets: (i) Wikipedia corpus, which contains 4.6M articles of ap-proximately 811M tokens in total. We used the same vo-cabulary of 7702 words as used by Hoffman et al. (2010). (ii) PubMed Abstract corpus contains 8.2M articles of ap-proximately 730M tokens in total. After removing stop-words and low occurrence (less than 300) words, we ob-tained a vocabulary of 39,987 words. For our Python im-plementation, each of the datasets has 47GB memory foot-print.
 Perplexity . We first compare the above algorithms in terms of the convergence in perplexity over wall-clock time on 20 homogeneous workers dedicated to the given task only. For D-Hybrid, we set the number of groups, G , to 5 and 3 for Wikipedia and Pubmed respectively. For Wikipedia, we set the group size to R = 4 . For Pubmed, we set the sizes of the three groups to 7,7, and 6. To examine the effect of the variance reduction strategy, it was continued until the end of the experiment, as opposed to stopping at some point. The step size parameter a was set to 0.0001 for Wikipedia and to 0.0005 for Pubmed.
 In Fig. 3 (a) and (b), we first see that all the variants of D-SGLD significantly outperform both AD-LDA and SGRLD. Note that AD-LDA ran in an ideal setting where each worker has equal workloads (in terms of shard size) resulting in negligible block-by-the-slowest delays. As shown in Table 1, D-SGLD required substantially shorter times than AD-LDA and SGRLD to reach the same per-plexity level that AD-LDA achieves after running 10 5 sec-onds (27.7 hours) indicated by the black horizontal dotted line. Throughout the experiments, Async-LDA always per-formed worse than AD-LDA given balanced workloads. For the three different versions of D-SGLD, we see that D-CC and D-Hybrid (which use the sample averaging) con-verge faster than D-CI (which uses independent chains). However, when we couple too many chains as shown in D-CC, it could lead to some lose of accuracy (possibly, due to the bias by the coupling). Hence, in the following ex-periments, we only use hybrid D-SGLD; a proper group configuration is chosen by cross-validation. Fig. 4 shows other effects of the group configuration by increasing group size ( R ) and number of groups ( G ).
 Dataset size . In D-SGLD the computation cost per sample O ( n ) is independent of N . AD-LDA, on the other hand, becomes slower as N increases. To see the effect of N , we examined the algorithms on random subsets of the full dataset with different sizes, 100K, 1000K, and full, using 20 homogeneous workers. For N =[100K, 1000K, full], the initial step sizes a were set to respectively a =[0.005, 0.0005, 0.0001] for Wikipedia and a =[0.01, 0.005, 0.0005] for Pubmed.
 As shown in Fig. 5, for Wikipedia, D-SGLD showed sim-ilar convergence in perplexity (they increase slightly as the size of datasets decreases) while providing better re-sults than AD-LDA in all settings. However, for Pubmed, which has a larger vocabulary and is expected to have a larger number of topics, D-SGLD was not better than AD-LDA for the small (100K) dataset while still had better performance for larger datasets. In fact, SGRLD seemed to work less efficiently (and so does D-SGLD) for rather small datasets as shown by Patterson &amp; Teh (2013) based on the NIPS corpus. Nevertheless, we found that (results not shown here) D-SGLD outperforms a single SGRLD based on a 100K dataset.
 Number of workers . We also varied the number of work-ers while fixing the dataset size to the full. In Fig. 6, we show the results for three cluster sizes, S = [20 , 40 , 60] . As expected, AD-LDA improves linearly by increasing the number of workers (i.e., by reducing local shard sizes). For D-SGLD, we fixed G to 5 and increased only the group size R to 4 , 8 , 12 . Although more workers imposed more com-munication overhead during sample averaging, D-SGLD showed its scalability by keeping the performance at a sim-ilar level (for Pubmed, it is improved). From this result, we calculated the number of workers required by AD-LDA to show a similar speed as D-SGLD with 20 workers. As shown in the Fig. 6, AD-LDA needs 2000 workers for Wikipedia and 800 workers for Pubmed to obtain a sim-ilar speed as D-SGLD. (This simple calculation does not include the communication overhead.) Load balancing . We also examined D-SGLD X  X  ability to balance the workloads and thus mitigate the block-by-the-slowest problem on 20 workers. To do this, we added dummy delays to half of the workers to make them D times slower. We denote this setting by (1: D ) and used three set-tings: D = [1 , 5 , 10] . The actual response delays then be-came equal, for example, by setting the trajectory length to 10 for slow workers and to D  X  10 for fast ones. The initial step size a was set to 0.005 for all settings of Wikipedia and to 0.001 for all settings of Pubmed. Here, we used 100K Wikipedia and 1000K Pubmed corpus because the Async-LDAs (as well as AD-LDA) were too slow for the full datasets. As shown in Fig. 7, D-SGLD with load-balancing through adaptive trajectory sampling converges much faster than those without load-balancing; it also con-verges faster than Async-LDA.
 Number of topics . We tested the effect of the number of topics K by examining K =[100,200,300,400,500] on 20 homogeneous workers. As shown in Fig.8, although the packet size increases for large K , D-SGLD consistently outperforms SGRLD for all K . We have introduced a novel algorithm,  X  X istributed stochastic gradient Langevin dynamics (D-SGLD) X . Us-ing D-SGLD, the advantages of the sequential mini-batch-based MCMC are extended to distributed computing envi-ronments. We showed that (i) by adding a proper correction term, our algorithm prevents the local-subset-bias while (ii) reducing communication overhead through trajectory sampling and adaptive load balancing. Furthermore, (iii) it improved convergence speed using a variance reduction strategy. Finally, in several experiments for LDA, we have shown at least an order of magnitude faster convergence speed of D-SGLD over the state of the art both in sequen-tial mini-batch-based MCMC and distributed MCMC. We believe that D-SGLD is just one example of a much larger class of powerful MCMC algorithms that combine sam-pling updates based on mini-batches with distributed com-putation.
 We thank A. Korattikara, S. Patterson, Y. W. Teh, J. Foulds and the reviewers for their valuable comments and sugges-tions. This work is supported by NSF grant IIS-1216045 and Amazon AWS in Education Grant award.

