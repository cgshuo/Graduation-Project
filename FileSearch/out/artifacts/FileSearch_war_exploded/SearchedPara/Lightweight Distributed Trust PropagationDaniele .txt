
Using mobile devices, such as smart phones, people may create and distribute different types of digital content (e.g., photos, videos). One of the problems is that digital content, being easy to create and replicate, may likely swamp users rather than informing them. To avoid that, users may or-ganize content producers that they know and trust in a web of trust. Users may then reason about this web of trust to form opinions about content producers with whom they have never interacted before. These opinions will then determine whether content is accepted. The process of forming opin-ions is called trust propagation . We design a mechanism for mobile devices that effectively propagates trust and that is lightweight and distributed (as opposed to previous work that focuses on centralized propagation). This mechanism uses a graph-based learning technique. We evaluate the ef-fectiveness (predictive accuracy) of this mechanism against a large real-world data set. We also evaluate the computa-tional cost of a J2ME implementation on a mobile phone.
Researchers are realizing that mobile devices may en-gage people in many different ways. For example, mobile devices allow people to take photos or shoot videos and dis-tribute them to their local communities at very low cost. Content distribution may help to engage people in, for ex-ample, urban planning or creative expression [4, 19]. But what happens if everybody is distributing content? In that case, to paraphrase Italo Calvino, we would live in an un-ending rainfall of content [5].

To avoid content overload, we need new ways of filter-ing content (of deciding which content to accept). Conven-tional wisdom holds that one such way is to maintain a web of trust [11, 24] of content producers. A web of trust is a network of trust relationships: we trust (link to) only a handful of other people; these people, in turn, trust (link to) a limited number of other individuals; overall, these trust relationships form a network (a web of trust) of individu-als linked by trust relationships. Based upon this web of trust, individuals may form opinions of other individuals (in technical parlance, they propagate trust in other individ-uals) from whom they have never received content before. Individuals then decide whether to accept content according to these opinions.

Section 2.2 will show that existing ways of propagat-ing trust cannot be readily applied in mobile computing because they are usually designed to work on a centrally stored web of trust and to run on high-end machines. Thus we set out to design a novel way of propagating trust that works in distributed settings (e.g., P2P networks) and runs on (resource-constrained) mobile phones. Our core contri-butions include:  X  A new trust propagation model that exploits a graph- X  Evaluation of the accuracy of our proposition on a real  X  Evaluation of its robustness against simulated uncoop- X  Evaluation of the computational overhead of a J2ME We now describe our research problem more formally. We will then demonstrate that existing solutions are not suitable for mobile devices. Finally, we will briefly intro-duce our proposed solution.

Figure 1. (a) A simple web of trust represent-ing the statement  X  C rates 2 its trust in D  X . (b) A web of trust of four people connected by their trust relationships.
One may represent the statement  X  C trusts D  X  X saweb-of-trust of two persons and one trust relationship going from C to D (Fig. 1(a)). The relationship may also be labeled with a rating representing the extent to which C trusts D in a given range of trust values (for example, in Fig. 1(a), C rates its trust for D as 2 in a discrete range { 1 , 2 , 3 } consider the web of trust in Fig. 1(b), where we have four people A , B , C and D . Not everyone has interacted with everyone else. For example, A and B have never interacted (no link between them). For the sake of argument, suppose that A now wishes to interact with B and, as a consequence, it has to form an opinion about B . A maydosobypredict-ing its trust for B . The goal of this paper is to study how a mobile user A may form an opinion about another user B without prior interaction.
To form an opinion about B , A may use the ratings of its past experiences [6, 17, 18]. However, that is not possible if A has never interacted with B . In that case, literature suggests that A may create a web of trust from third-party ratings and, based on that, may then set its trust ( propagate its trust )for B .
 There is substantial literature on how to propagate trust. That literature breaks roughly into two camps. In the first, techniques assign a global trust value to each user. That is, A  X  X  trust in B corresponds to a global trust value in B .By global, we mean a trust value that is accepted and shared by all users. In peer-to-peer networks, EigenTrust [13] assigns a global trust rating to each peer similar to how Google X  X  PageRank [16] ranks web pages. Global ratings are then used by peers to exclude untrustworthy peers (which send inauthentic files) and to sel ect peers from whom to down-load files. As a consequence, the number of inauthentic files in the network decreases. In a free software developer com-munity, Advogato [15] assigns a global trust to each com-munity member. It does so by arranging ratings in a web of trust and by composing ratings between members using max flow from designated trusted members. The idea of max flow is that between any two nodes, the quantity of trust flowing from one node to another cannot be greater than the weakest rating somewhere on the path between the two nodes. This way of composing ratings has proved to be at-tack resistant -it successfully isolates unreliable members. More recently, Ziegler and Lausen [24] proposed to rank all users by spreading  X  X ctivation models X  (by arranging rat-ings in a matrix and finding the principal eigenvector), while Dell X  X mico[7]focusedonpeer -to-peer networks and pro-posed to rank peers by using link-analysis techniques in a fully distributed setting.

By contrast, in the second literature camp, techniques as-signapairwise( local ) trust rating to each pair of users. That is, A assigns a personalized trust rating in B . Personalizing trust is beneficial because it makes it possible for two indi-viduals to have different opinions about the trustworthiness of the same person (which may well happen in reality). In 2003, Golbeck et al. [9] proposed different algorithms for propagating trust in this way. For example, they proposed a variation of max flow that accounts for path length. To Domingos et al. [20] and Guha et al. [11] goes the merit of presenting the first comparative studies of different trust propagation algorithms in which pairwise ratings are com-puted. These algorithms have been evaluated against Epin-ions [1], a large collection of binary ratings 2 .Bybinarywe mean that each rating simply expresses whether an individ-ual trusts another individual or not. Despite being evaluated on binary ratings, these algorithms are general in the sense that they can take discrete ratings (not necessarily binary).
Most of the work on assigning pairwise trust ratings is based on a simple, yet effective mechanism: A finds all paths leading to B ; for each path, A then concatenates the ratings along the path; A finally aggregates all path concate-nations into a single trust rating for B . Algorithmically, this is equivalent to A arranging trust ratings into a matrix and, over a series of iterations, propagating trust by, for example, direct propagation: if A trusts C and C trusts B ,thentrust propagates from A to B . The resulting matrix values are then rounded into a single trust rating. Unfortunately, this way of propagating trust suffers from two main limitations:  X  Literature has proved direct trust propagation to be ex- X  Direct trust propagation does not scale on mobile de-
It thus seems that a different way of propagating trust in mobile computing scenario s is needed. But what sort of method should we use?
Our problem is to find a way of propagating trust that is both effective and scalable . To do so, we propose to use a class of semi-supervised lear ning techniques that have been proved to be effective when applied to various problem do-mains (e.g., to predict movie reviews [10], to recognize dig-its [12], to classify text [23]).

These techniques work on a graph in which: not links but nodes are either rated or unrated, and those nodes are
Figure 2. Predictive Accuracy. The fraction of correct predictions for naive prediction (ran-dom guess) and direct trust propagation. then connected to each other if they are related (the tech-niques consider that two nodes are related if their ratings are similar ). Informally, these techniques exploit knowl-edge already present in the graph (rated nodes) to construct a function that is capable of predicting unrated nodes. To choose the most effective function (the function with the highest predictive accuracy), the techniques impose that: on input of each rated node in the graph, the chosen function returns the node X  X  actual rating (this serves to choose a func-tion that is consistent with existing ratings); given two con-nected nodes x i and x j , the chosen function returns f ( similar to f ( x j ) (this serves to choose a function that as-signs similar ratings to connected nodes).

Let us now imagine a graph whose nodes are trust rela-tionships (we call this graph  X  X elationship graph X  ). A node is rated if the corresponding relationship in the web of trust is known and rated (e.g., in Fig. 3(a), C  X  B is known and rated, so that in the relationship graph the node repre-senting this relationship will be rated). By contrast, a node is unrated if the corresponding relationship is unknown and has to be predicted (e.g., A  X  B in Fig. 3(a)). Predicting a trust relationship thus means finding a function that effec-tively rates the corresponding node. Finding such a function is exactly the problem solved by the semi-supervised learn-ing techniques described above. In order to exploit these techniques, we first need to represent (part of) a web of trust as a relationship graph. We explain how to do so in the following section.
To describe our model, we refer to our running example of how A may propagate its trust in B given the web of trust shown in Fig. 3(a). The following four steps are required, each of which is described in the following subsections: 1. A determines the trust relationships that our propaga-
Figure 3. (a) A web of trust and (b) the cor-responding relationship graph for predicting
A  X  B  X  X  rating. 2. A restricts its attention to the subset of the web of 3. From this subset, A builds a relationship graph (Sec-4. A finally applies the machine learning technique to de-
Before describing these steps in details, we spell out our assumptions :  X  We opt to target a class of applications in which users  X  We consider the web of trust to be a network in which  X  We consider that anonymous tokens identify users.
To begin with, A determines the trust relationships that our propagationscheme may find relevant for predicting A  X  X  trust in B , that is, those relationships related to A  X  B .As defined in Section 2.3, two relationships are related if their ratings are similar . Hence we consider related any:  X  Two relationships with the same rater. For example, Figure 4. (a) A  X  X  view of the web of trust. (b)
A schematic representation of a relationship graph. On that graph, our algorithm predicts x i  X  X  rating.  X  Two relationships in which the same person is rated. To use our propagation scheme for predicting its trust for B , A needs to know part of the web of trust. To see which part is needed, we must consider the two steps through which A predicts its trust for B . In so doing, we will re-fer to Fig. 4(a) and consider the following sets: S 1 ,thatis, the set of ratings of A  X  X  outgoing relationships; and S 2 is, the set of all ratings from nodes that have rated B . Step 1. A determines the trust relationships related to
Step 2. A determines the extent to which each pair of those
Overall, to use our propagation scheme for predicting its trust in B , A needs the ratings of the relationships in S in S 2 . The former are readily available, as we can assume that A stores locally the ratings it has produced. And the latter are received from B . In fact, those ratings have been generated by the people who have rated B ; therefore, B may have all the ratings of the relationships in S 2 ,asithas received them from its raters. As a result, each user stores a very small subset of the web of trust  X  she stores the ratings she generates plus t hose generated by her raters.
At this point, A knows which trust relationships are re-lated to the one that has to be propagated, and the extent to whichtheyareso; A can then build a relationship graph. The key idea is to create a graph whose nodes include the trust relationship to be predicted plus related relationships. Fig. 3(b) shows one such graph whose nodes are: A  X  B (trust relationship to be predicted), A  X  C , A  X  D ,and C  X  B (related relationships). Nodes are linked and the label on a link expresses the extent to which the two linked nodes are related.

More generally, there are n trust relationships x ,...,x n ,ofwhich r are rated ( x 1 ,y 1 ) ,..., ( x r ,y and u are unrated x r +1 ,...,x r + u (an  X  X nrated X  relation-ship is a relationship that has no rating on the web of trust). The numerical ratings are defined as being y 1 ,...,y r  X  where L = { l 1 ,...,l p } with l 1 &lt; ... &lt; l p . For example, a system with p =3 possible rating levels may have L = { 1 , 2 , 3 } . Our problem is now to build a connected graph G =( V, E ) with nodes V corresponding to the n trust relationships. We do so step by step with reference to an example (Fig. 3(b)) and to a general representation (Fig. 4(b)). To understand the rationale behind this con-struction, we must remember our end goal of finding a predictive function f : V  X  R on G capable of assigning ratings to unrated nodes (note that f assigns a real value to a trust relationship; this value will then be mapped to the nearest discrete rating in L ). In particular, let x i be the trust relationship we wish to predict (e.g., A  X  B in Fig. 3(b)) among the unrated ones.  X  The node x  X  The node x  X  Each rated node x
The coefficients in a relationship graph are thus M , a , b , k ,and k . M is set to an arbitrary large number ( 10 6
Figure 5. A relationship graph and corre-sponding matrices. In the relationship graph, there are two rated nodes x 1 : A  X  D and x 2 :
C  X  B ; and two unrated nodes x 3 : A  X  C and x 4 : A  X  B . The prediction algorithm populates the rating matrix y , the diagonal dongle matrix C , and the weight matrix  X  W . Then, it computes the predictive function f .
 The remaining coefficients will be set by cross validation (Section 4.1).
Having the relationship graph, A now has to find a func-tion that predicts all unrated nodes in that graph, including that of interest (e.g., A  X  B ).

Let us formalize the problem and the construction of its solution. We have a graph G of n nodes x i ,i  X  [1 ,n ] , r of which have ratings y i , and the remaining u ( x dices of the rated nodes and U those of unrated nodes. Our problem is to seek a function f that rates each of the un-rated nodes (the nodes whose indices are in U ). Section 2.3 mentioned that to choose a function that rates effectively , one has to impose that: on input of each rated node in the graph, the chosen function returns the node X  X  actual rating (that has been done in the previous Section 3.3 by setting the coefficient M to a large number); on input of either of two connected nodes, the chosen function X  X  outputs are similar. The latter condition is equivalent to saying that (refer to Fig. 4(b)): for any pair of related nodes x i and x j , the differ-ence of their ratings f ( x i ) and f ( x j ) should be minimum. In other words, ( f ( x i )  X  f ( x j )) 2 should be minimum. This expression represents the rating difference over one edge . One may compute the difference over the graph by sum-ming the rating differences of all edges. We denote this difference as L ( f ) . We will see that such a difference de-pends on the chosen function f . Our problem is to find the function f for which the difference over the graph is mini-mum. We do so in Appendix A and find that such a function in the reported ranges. is f = C + L and the three steps of the algorithm for computing f (refer to Fig. 5): 1. Populate 3 matrices: 2. Compute: the symmetrized version of  X  W : W = 3. Finally, compute f = C + L
That concludes the description of our model. In the next section, we turn to evaluating it.
The goal of our algorithm is to predict trust ratings on portable devices. To ascertain the effectiveness of our algo-rithm at meeting this goal, our evaluation ought to answer three questions: (1) (Predictive Accuracy) How accurate is our algorithm in predicting trust ratings? (2) (Prediction Robustness) What is the impact of uncoop-erative users upon the algorithm X  X  accuracy? (3) (Overheads) What time, storage, and communication overheads does our algorithm impose on a mobile phone?
To see whether our algorithm effectively predicts trust and whether it is usable on portable devices, we need a large-scale deployment . Only so can we separate statisti-cal significant answers from plausible insights gained by a small-scale deployment. Plus, a deployment needs to be evaluated in the long-term to see whether our algorithm is robust against, for example, uncooperative users.
Unfortunately, we do not have a long-term evaluation of a large-scale mobile computing deployment. We do, how-ever, have a large rating data set from the Advogato com-munity that has been around for more than a decade 5 .Us-ing this data set (described next), we evaluate whether our algorithm is effective in predicting real trust ratings (Sec-tion 4.1). Then, to evaluate how robust our algorithm is, we emulate how users may rationally turn to be uncooper-ative (Section 4.2). Finally, we implement our algorithm to assess whether it is usable on a mobile phone (Section 4.3).
To begin with, let us describe the Advogato data set. Ad-vogato is a community discussion board for free software developers. Using the Advogato X  X  trust metric [15], each
Figure 6. Predictive accuracy of four algo-rithms. user has a single (global) trust value computed by compos-ing other users ratings. There are three possible ratings: ap-prentice, journeyer, and master. Global trust is used to con-trol access to the discussion board:  X  X pprentices X  can only post comments, whereas  X  X ourneyers X  and  X  X asters X  are able to post both stories and comments. From this community, we have extracted 55,455 trust relationships.
We evaluate the predictive accuracy of our algorithm by using leave-one-out cross validation.
 Validation Execution. The cross validation unfolds as follows. We take Advogato X  X  web of trust. We mask one trust relationship and then predict the relationship X  X  rating in four different ways. We repeat this on all relationships. In doing this, we measure the predictive accuracy , i.e., the fraction of correct predictions.

The four ways of predicting the rating of a masked re-lationship A  X  B that we have compared are: naive pre-diction (random guess); median of ratings about B ; direct trust propagation (as described in Section 2.2); and our al-gorithm . Since we cannot assume complete knowledge in mobile settings, we consider that our algorithm does not know the whole web of trust, but predicts A  X  B on in-put of only the ratings known by A (as described in Sec-tion 3.2). Instead, we allow distributed trust propagation to know all paths (and corresponding ratings) between A and B because it is the only way it can be carried out.
Our propagation algorithm has five parameters. We tune each parameter in the range shown in Table 1. This leads to 1250 possible combinations . For each combination, we compute the predictive accuracy.

Figure 7. Fraction of unknown predictions as a function of uncooperative users (users who are not willing to make their ratings avail-able).
 Validation Results. For our algorithm, we first computed the optimal parameters (par ameters for which the accuracy is highest) as described above: they turn out to be  X  =1 ,  X  =  X  X onfidence interval X , f and k = k =20 (a relationship graph should contain at most 20 edges). We expect that these values will apply in other domains; that is because they, informally speaking, specify reasonable and intuitive choices. More specifically, they indicate that to predict the rating of a trust relation-ship, the learning algorithm has: to consider relevant those relationships that include people who perform or rate alike (  X  =1 ); to estimate relevance by aggregating ratings using the confidence interval of their average (  X  =  X  X onfidence in-terval X ); to consider a small fraction of those relevant rela-tionships ( f r =0 . 1 , f u =0 . 2 ); to weight the actual ratings more than the ratings it predicts during the learning process (  X  =0 . 1 ).

This preliminary analysis allow us to move on to answer the key question: how would the predictive accuracy of our algorithm compare to that of any of the algorithms previ-ously mentioned. Fig. 6 shows that direct trust propagation performs better than naive prediction, but is comparable to a median of ratings. It also shows that our algorithm X  X  accu-racy is as high as 82.9%. In all cases in which our algorithm failed to predict (17.1%), the actual rating and the predicted rating differed by one only (with L = { 1 , 2 , 3 } ).
All trust propagation techniques rely on knowing rat-ings. In mobile computing, this translates into users making available their ratings. For privacy reasons, some users may well decide not to do so. Being this plausible, we now eval-uate how our algorithm would cope if different fractions of users did not disclose their ratings. Again, we measure pre-dictive accuracy by cross valid ation: we mask one trust rela-tionship and then predict its rating upon the limited knowl-edge of the nodes subject of the trust relationship; we do so for all relationships that link any pair of cooperative users (users willing to make their ratings available). That is be-cause we consider that users willing to be subject to predic-tion are also willing to cooperate.

Fig. 7 shows the fraction of predictions for which a relationship graph is not defined (percentage of unknown predictions) as a function of the fraction of uncooperative users. If at most 60% of the users are not willing to make their ratings available, the remaining users can still propa-gate their trust, and they do so with a high predictive accu-racy ( 82 . 9% ). However, as Fig. 7 shows, if the number of uncooperative users reaches a cr itical point (if it is higher than 60%), the remaining users are abruptly unable to form a relationship graph. In other words, if at least 40% of the users make their ratings available, those users can still ef-fectively propagate trust. For one possible explanation of this result, consider that the web of trust is a social network and that social networks are robust because they are scale-free. Albert et al. [2] studied the fraction of nodes that must be removed at random from a scale-free network to break it into pieces: they  X  X emoved as many as 80% of all nodes and the remaining 20% still hung together, forming a highly interlinked cluster X  [3] 6 . Communication and Storage Overheads. Both commu-nication and storage overheads are minimal. As described in Section 3.2, any device stores the ratings of its outgo-ing relationships plus those of its incoming neighbors in a table. Each tuple of this table corresponds to a trust rela-tionship, i.e., to two identifiers (of the connected persons) and one rating. Hence, say that the size of a tuple is roughly 10B. Even with 50 incoming and 50 outgoing edges (which is pessimistically high), the table size is 30KB. Also, for a single trust propagation, the data to be sent is less than 30KB.
 Computational Overhead. We ran a J2ME implementa-tion of our algorithm on a Nokia 3230 mobile phone whose features include: Symbian operating system 7.0, 32 MB of memory, 32-bit RISC CPU (123 MHz). In Section 4.1, we evaluated that a relationship graph should contain 20 nodes at most. We run our algorithm in this worst case scenario. We minimized background activities by shutting down all applications other than our algorithm. The computation overhead, given as the mean of 10 runs, is as low as 2.8 milliseconds.
Based on the previous results, we now discuss some open questions.

Privacy Concerns. By exchanging their web of trust, users reveal their social ties (people with whom they have interacted), and some users may not feel comfortable doing so for privacy concerns [14]. Our design alleviates these concerns for two reasons. First, users are identified by anonymous tokens. Second, one inherent property of dis-tributed trust propagation is that users X  ratings are not made available on public servers, but each user discloses her rat-ings whenever she finds convenient to do so. Moreover, dur-ing our evaluation, we found that if at least 40% of the users make available their ratings, those users can still propagate their trust without relying on any other user (Section 4.2).
Sybil Users. Given that users X  identifiers correspond to anonymous tokens, one may rightly point out that user-token bindings need to be certified to avoid sybil attacks [8], in which a malicious user takes on multiple identities and pretends to be multiple, distinct users. In mobile comput-ing, user-token bindings cannot be certified by a central au-thority. However, those bindings may be statistically guar-anteed by mechanisms similar to SybilGuard [22]. If those mechanisms will prove ineffective, one might be interested in knowing whether our model is robust against sybil at-tacks. We evaluate the predi ctive accuracy of our algorithm as follows: we mask one trust relationship A  X  B ;we create n sybil identities who highly rate B ; we then predict A  X  B  X  X  rating. We do so for all trust relationships. Re-gardless of n , the prediction accuracy remains unchanged ( 82 . 9% ). The reason for this result is that sybil users are not connected in the same way as real users are and, as a con-sequence, their ratings do not influence trust propagation.
Distrust. Previous work has shown that introducing dis-trust may be beneficial to trust propagation [11]. Despite not explicitly modeling distrust, we may introduce it by simply adding an additional rating level. For example, if we have 3 possible ratings, we may simply add a fourth rat-ing representing distrust.

Dynamic Ratings. Since ratings may change over time, we have allowed for rating tables to be updated either re-actively or proactively and th e storage and communication overheads of doing so are minimal (Section 4.3).
We proposed a model that makes it possible for mobile users to predict their trust for content producers from whom they have never received content before. The model scales (it entails minimal storage and communication overhead) and is effective (its predictive accuracy on a large data set is as high as 82.9%). That accura cy remains unchanged even if most of the users were not to make available their ratings. The model also runs on portable devices (a J2ME imple-mentation spends at most 2.8ms for one propagation on a Nokia phone). To further evaluate our model, we are cur-rently designing controlled experiments to be run in a large-scale deployment.

Acknowledgments: We thank Mark Herbster for ex-plaining us different ways of learning over graphs. We also thank Matteo Dell X  X mico, Neal Lathia, Ilias Leontiadis, Paolo Garza, Tania Cerquitelli, and the anonymous review-ers for their contributions, and Microsoft Research Cam-bridge for its financial support.
 Given the graph described in Section 2 and shown in Fig. 4(b), the loss L ( f ) over the whole graph is
L ( f )= where: Expression (3) can be written as: Being C and L symmetric, the gradient is: To solve the optimization problem min f L ( f ) ,wesetthe gradient to zero,  X  L ( f )
