 This paper is concerned with automatic extraction of titles from the bodies of HTML documents. Titles of HTML documents HTML titles are often bogus. It is desirable to conduct automatic extraction of titles from the bodies of HTML documents. This is an issue which does not seem to have been investigated previously. In this paper, we take a supervised machine learning approach to address the problem. We propose a specification on HTML titles. We utilize format information such as font size, position, and font weight as features in title extraction. Our method significantly outperforms the baseline method of using the lines in largest font size as title (20.9%-32.6% improvement in F1 score). As application, we consider web page retrieval. We use the TREC Web Track data for evaluation. We propose a new method alone; the use of extracted titles is particularly helpful in the task of named page finding (23.1% -29.0% improvements). H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Search Process ; D.2.8 [ Software Engineering ]: Metrics -complexity measures, performance measures Algorithms, Experimentation, Performance Information Retrieval, HTML Document, Metadata Extraction 
In this paper we address the issue of automatically extracting titles from the bodies of HTML documents. 
Titles are the  X  X ames X  of documents and thus are very useful information for document processing. In HTML documents, and  X &lt;/title&gt; X .. However, usually people do not do it carefully. We have evaluated the title fields of HTML documents in the TREC Web Track data set containing 1,053,111 HTML documents. We have found that about 33.5% of the title fields are somewhat bogus (see Section 6 for details). documents. They tend to be more reliable, because they are more noticeable to readers and thus usually are more carefully created by the authors. One question arises here: can we extract titles from the bodies and use them in web applications? We address the problem in this paper. 
To the best of our knowledge, no previous work has been conducted on exactly this problem. Title extraction from the bodies of HTML documents is not easy as it appears to be. There is much variability in the format and content of web pages. It was not clear whether it would be possible to conduct the extraction application. 
The key issues to the task are to define a specification of HTML titles and to define features for the extraction. We take a machine learning approach to address the problem. We propose a specification on HTML titles. The specification takes the  X  X ost conspicuous X  description in the document as a title and is defined mainly based on format information. We annotate titles in sample documents and take them as training data, train a classification model, and perform title extraction using the model. In the model, we mainly utilize format information such as font size, position, font weight as features. There are in total 245 features defined. As classification model, we employ Perceptron with Uneven Margins. We also propose a new retrieval method for web page retrieval. The Okapi-based method combines text, title, and extracted title. It conducts normalization on each type of score calculated with each type of data, and combines the normalized scores using linear combination. 
Experimental results indicate that for HTML title extraction our method can significantly outperform the baseline: one that always uses the lines in the largest font sizes as titles (20.9%-32.6% improvement in F1 score). 
Experimental results, on the TREC Web Track data, also named page finding in TREC (23.1% -29.0% improvements). 
Other empirical findings include that font size is the most important feature for HTML title extraction. A model trained in one domain can be applied to another domain with nearly no drop in accuracy. motivation and setting of our work. In Section 4, we describe our method of title extraction and in Section 5, we describe our method of web page retrieval using extracted titles. Section 6 gives our experimental results. We make concluding remarks in Section 7. 
Web information extraction has become a popular research area recently and many issues have been intensively investigated [10]. 
Automatic extraction of web information has been studied for method of extracting data records from web pages [16]. Reis et al. investigated the issue of extracting news articles [20]. Craven proposed a method of extracting summaries from web pages [6]. 
Web information extraction has also been conducted with different data units. For instance, Breuel has proposed parsing web pages as trees of HTML tags (called the DOM tree) and pulling out information from the trees [2] (See also [14, 20]). Song et al. have proposed to divide web pages into a number of blocks and conduct information extraction based on the blocks [22]. Specifically, they have developed a method of identifying important blocks in a page. 
Web information extraction can be either domain specific or domain independent. In a specific domain, one can assume that can be used in learning and extraction [7, 14]. For instance, Kosala et al. have observed that news articles at a web site usually share the same template and they have attempted to perform information extraction from news articles using the template [14]. 
In general, there are two approaches to web information extraction: namely, the rule based approach and the machine learning based approach. The machine learning based approach is more widely employed [3, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 20, 22, 25]. 
To the best of our knowledge, there has been no previous work on title extraction from HTML body, particularly on open domain and by using format information. Our work is close to [2, 20, 25] in the sense that we also use DOM tree, but it is also different in that we target title extraction. Our work also differs from the work on block-based extraction [22]. Important block identification may help title extraction, but not in a straightforward way (e.g., a title may exist in a small and  X  X nimportant X  block). 
In information retrieval, previous work has shown that the use of title fields, anchor texts, and URLs of web pages (HTML documents) can enhance web page retrieval. Cutler et al. have proposed using the structures in HTML documents to improve HTML document retrieval [9]. Specifically, they linearly combine term frequencies in several fields extracted from an HTML document. In TREC-2002, several participants [1, 4, 25] have HTML fields such as title field, bold text, etc. in ranking [25, 26]. Amitay et al. have proposed eliminating documents whose title fields do not contain any query word in document retrieval [1]. In TREC-2003, more than half of the participants have considered the use of richer representations/surrogates based on document structures [5]. For instance, Ogilvie and Callan have tried to make use of different document representations from different sources in language models for the named page and homepage finding tasks [18, 19]. See also [24]. 
It has been not clear previously whether and how extracted titles can be used for enhancing web page retrieval. 
We consider the problem of automatically extracting titles from the bodies of HTML documents (web pages). We assume, in this paper, that we conduct title extraction on the general domain and thus we can only utilize domain independent information (mainly format information) in the extraction. 
We first consider what can be defined as titles of HTML documents. We give a  X  X pecification X  on the titles. The specification defines titles mainly from the viewpoint of document format. Intuitively, a title of an HTML document is the  X  X ost conspicuous X  description in the document. In the example in figure 1, one title is  X  X ational Weather Service Oxnard X  and the other title is  X  X os Angeles Marine Weather Statement X . In the example in figure 2, one title is  X  X tate Assembly  X  District 34 X  and the other title is  X 1998 California General Election Certified List of Candidates X . 
The specification is as follows. 1. Number 2. Position 3. Appearance 4. Neighbor 5. Content 6. Other 
In this paper, we take a machine learning approach to address the problem. Our method consists of two phases: training and extraction. There is the same pre-processing for training and extraction. There is also a post-processing for extraction. 
The input of preprocessing is a document. In the pre-processing, we extract units from the input document. The output of pre-processing is a sequence of units (instances). A unit contains not only content information (linguistic information) but also format information. Figure 3 shows the units obtained from an HTML document. Specifically, we parse the body of the HTML document and construct a DOM (Document Object Model) tree. Figure 4 shows an example DOM tree. We take all the leave nodes that contain  X  X exts X  in the DOM tree as units.
In learning, the input is sequences of units, and each sequence corresponds to one document. We take labeled units (titles and others) in the sequences as training data and construct a model for identifying whether a unit is a title. document. We employ the model to identify each unit in the sequence to find whether it is a title. The model assigns a score to each unit. 
In post-processing of extraction, we extract titles using heuristics. The output is the extracted titles of the document. Specifically, we choose the consecutive units with the highest scores as the first title, and then choose the consecutive units with the second highest scores as the second title, provided that the scores are larger than zero. 
We describe the model in a general framework. The input is sequences of instances n x x L 1 with aligned sequences of labels 1 . Instances represent original data, i.e., units. Labels Suppose that of instances, and sequence of labels. If the Y s are independent from each other, then we have 
Each conditional probability model is a classifier. In this paper, as classifier we employ an improved variant of Perceptron, called Perceptron with Uneven Margin [15]. This version of Perceptron can work well especially when the number of positive training instances and the number of negative training instances differ largely, which is exactly the case for the current problem. 
The main characteristic of our method is that we mostly utilize format information for extraction. Title extraction mainly based on format information is not an easy task, because the formats (e.g., layouts) of web pages (HTML documents) can vary largely. 
We manage to use as many effective features as possible. 
We consider the use of the following information in the design of features. 1. Rich format information 2. Tag information 3. Position information 4. DOM tree information 5. Linguistic information 
With the information above, we create four types of features which can help identify the position (Pos), appearance (App), neighbor (Nei), and content (Con) of a title. There are in total 245 binary features. Table 1 gives example features for each type. Table 2 shows the number of features for each type. Pos Unit in top 0.2, top 0.4, or rest of page Pos Unit width &lt; 0.1, 0.2, 0.3, or 0.4 of page width Pos First unit in DOM tree App Is unit tagged with H1,..., H6, or no H* tag App Is first, second, or third H* tagged unit App Is top or second level H* tagged unit in DOM tree App Is only H* tagged unit in DOM tree App Largest, or second largest font size App Percentage of unit font size &lt;0.02, 0.02~0.10, etc App Alignment of unit is center, left, right, or justify App Is unit in bold face App Unit is italic App Unit is underlined App 
App Percentage of units in same background color is 
App Percentage of units in same font family is &lt;0.05, App In bullet (i.e., tagged with LI) App Begin with newline Con All characters, or first characters capitalized Con Number of characters is &lt;8, 8-64, 64-96, &gt;96 
Con Begins with  X  X ubject: X ,  X  X ntroduction X ,  X  X itle X , Nei Previous or next unit is tagged as HR, BR, etc 
Nei Font size is larger than root, node, previous leaf, 
Nei Alignment of previous node is left and current is 
Nei If the same level units have same font size, font 
We propose a linear combination method for using extracted titles in document retrieval. Our method takes BM25 as basic function and is unique in its way of normalizing the BM25 scores. 
Given an HTML document, we extract information from it and The extracted title field contains the title extracted by our method. We also create an additional field in which we combine the  X  X ombTitle X . We consider four methods for document retrieval with different uses of the fields. BasicField 
In this method, a document is represented by all the texts in the title and body. Given a query, we employ BM25 to calculate the score of each document with respect to the query: S (1) 
Here, i denotes a word in the query q ; i tf and frequency and document frequency of i respectively; dl is document length, and avdl is average document length; are parameters. We set 7 . 0 , 1 . 1 BasicField+CombTitle 
We calculate the BM25 score of the combined field CombTitle (i.e., view it as a document), with 95 . 0 , 4 . 0 calculate the BM25 score of BasicField as in the baseline method. We next conduct normalization on both the BM25 score of the combined field and that of the baseline method. We next linearly combine the two scores, s BasicField ' S and Here  X  is coefficient ranging from 0 to 1. BasicField+ExtTitle 
We employ a similar method to that of BasicField+ComTitle, in which instead of using the combined title filed, we use the extracted title field. BasicField+Title 
This is a similar method to BasicField+ComTitle, in which instead of using the combined title filed, we use the title field. 
As data sets, we used the .GOV data in the TREC Web Track and the data from an intranet of Microsoft. We call the former TREC and the latter MS, hereafter. There are 1,053,111 web pages in TREC and about 1,000,000 web pages in MS. We randomly selected 4,258 and 4,137 HTML documents from the two data sets respectively. We manually annotated titles in the randomly selected HTML documents. The annotation was based on the specification in Section 3. There were 3,332 HTML documents with annotated titles in TREC, and there were 2,641 HTML documents with annotated titles in MS (R ecall that an HTML document can have no title). 
We used  X  X recision X ,  X  X ecall X ,  X  X 1-score X , and  X  X ccuracy X  in evaluation of title extraction results. In the evaluation, if the extracted title can approximately match to the annotated title, then we view it as a correct extraction. We define the approximate match between the two titles t1 and t2 in the following way. lengths of t1 and t2 respectively. 
We tried to see how many title fields in the HTML documents are correct. We found that there are 33.5% of HTML documents in the TREC data set having bogus titles. There are three cases: 1. Empty title field There are 60,524 pages (5.8%) which have nothing in the title fields, i.e., empty between  X &lt;TITLE&gt; X  and  X &lt;/TITLE&gt; X . 2.  X  X ntitled X  title field 
There are 4,964 pages (0.8%) which have  X  X ntitled X  or  X  X ntitled document X  in their title fields. 3. Duplicated title field 282,826 pages (26.9%) fall into this type. Many web sites contain web pages sharing the same title field but having different contents. In our investigation, a title filed is considered duplicated if it is repeated more than N times in a web site. N is determined heuristically on the basis of M the total number of pages in the web site. There are five rules: We conducted title extraction experiments on the two data sets. 
For our method (denoted as Perceptron for short), we conducted 5-fold cross validation, and thus all the results are averaged over 5 trials. 
As baseline methods, we used that of always extracting the We also evaluated the titles in title fields denoted as  X  X itle-field X . 
Tables 3 and 4 show the results. The results indicate that our method significantly outperforms the baseline methods and title-extraction is not enough. Our learning-based method can make an effective use of various types of information in title extraction. Table 3. Performances of title extraction methods on TREC Approach Precision Recall F1-Score Accuracy (Baseline) 
First unit 
Title-field 
Perceptron Approach Precision Recall F1-Score Accuracy (Baseline) 
First unit 
Title-field 
Perceptron The performance of title extraction in MS is better than that in TREC. We found that the HTML documents in MS have fewer patterns than those in TREC and that is the reason for the higher performance. 
We further investigated the relation between the titles in title results. We see that our method can still achieve a relatively high performance when title-fields are incorrect. In this case, the extracted titles are particularly useful. We also see that when title-fields are correct, we have better performance, but still cannot conduct the extraction completely correctly. The result indicates that the task of title extraction is not easy. Table 5. Accuracies of title extraction with respect to different 
We conducted web page retrieval experiments on the TREC data. 
In the experiment, we used the queries and relevance judgments of Web Tracks in TREC-2002, TREC-2003, and TREC-2004. The queries have been classified into three types, i.e. named-page finding (NP), homepage finding (HP) and topic distillation (TD) table 6. The topic distillation queries of TREC-2002 were not used because the specification in it is different from those in TREC-2003 and TREC-2004. 
We first performed the experiment using the queries of TREC-BaseField+CombTitle, BaseFiled+ExtTitle to the TREC data and evaluated the results in terms of Mean Average Precision. Figures 5, 6, and 7 show how the performances of the three methods NP, HP, and TD. The baseline method is BaseField and its performance is obtained when alpha equals 1. The results indicate that the best of BaseField+CombTitle outperforms the baseline However, BaseField+ExtTitle can only beat the baseline for NP and TD, but cannot beat the baseline for HP. Furthermore, BaseFiled+CombTitle is always better than BaseFiled+Title. The BaseFiled+CombTitle. 
We also note that when alpha equals 0, all the three methods turn out to be one without using BaseField. For all the three tasks, the performances of CombTitle alone are close to or better than the baseline. The result implies that CombTitle, a combination of HTML document. 
Table 7 shows the best result for each met hod in each task. The baseline of BasicField in  X  X -test X . For NP, the improvement of BasicField+CombTitle over BasicField is statistically significant, but the improvement of BasicField+Title over BasicField is not. For HP and TD, the improvements of both BasicField+Title and significant. We next conducted web retrieval experiments on the data of TREC-2002 and TREC-2004, using the optimal values of alpha obtained from TREC-2003. Table 8 shows the result. Again, for NP BasicField+CombTitle significantly outperforms BasicField and outperforms BasicField+Title. For HP, although the improvement of BasicField+CombTitle over BasicField is BasicField+Title, indicating that the use of extracted titles does BasicField+Title and BasicField+CombTitle are small for TD. 
Table 7. Best retrieval results (average precision) on TREC-
Table 8. Retrieval results (average precision) on TREC-2002 
Finally, we combined BasicField+CombTitle and the use of anchor text and URL. We conducted an experiment on TREC-2004 data. Table 9 shows the final result [23]. 
We conclude that extracted titles are useful for web page retrieval. 
To investigate the ability of domain adaptation of our extraction model, we conducted two experiments. In the first experiment, we applied the model trained with the TREC data to the MS data. In the second experiment, we swapped the training and test data sets. Table 10 shows the results. Testing From the results, we see that the cross domain performance is performance in MS is better than that in TREC. The results domains, and thus it is possible to construct a domain independent model for title extraction. 
We investigated the contribution of each feature type in title extraction. We employed all the 245 features (All), or each of the four types: App, Con, Pos, and Nei to train a model and conduct title extraction. Furthermore, we further categorized App into seven subtypes: Font Size, Font Weight, Color, Alignment, Background Color, Font Style, and Font Family, and employed each subtype in model training and title extraction. 
Figure 8 shows the F1-score of title extraction with different significant features, and among the App features, the Font Size features are most important. The results indicate that one type of format information alone is insufficient for accurate title performance in extraction achieved by our method (in Section 6.4): many types of format information are used. automatically extracting titles from the bodies of HTML documents, and have investigated how the extracted titles can help improve web page retrieval. 
We have proposed a specification of HTML title. We have used a machine learning approach to address the problem. We mainly use format information including rich format, tag, position, and DOM tree information for the extraction. 
Our experimental findings include (1) Our method can work significantly better than the baseline methods for title extraction. (2) We can construct domain-independent model for title extraction. (3) Using extracted titles can indeed improve web page retrieval, particularly name page finding of TREC. (4) Many types of format information are useful for title extraction. 
We thank Dmitriy Meyerzon, Ming Zhou, and Wei-Ying Ma for their encouragements and supports. We thank Hugo Zaragoza, Nick Craswell and the anonymous reviewers for their comments to this paper. [1] Amitay, E., Carmel, D., Darlow, A., Lempel, R., and Soffer, [2] Breuel, T.M. Information Extraction from HTML Documents [3] Chidlovskii, B., Ragetli, J., and de Rijke, M. Wrapper [4] Collins-Thompson, K., Ogilvie, P., Zhang, Y., and Callan, J. [5] Craswell, N. and Hawking, D. Overview of the TREC 2003 [6] Craven, T.C. HTML Tags as Extraction Cues for Web Page [7] Crescenzi, V., Mecca, G. and Merialdo, P. Roadrunner: [8] Crescenzi, V., Mecca, G. and Merialdo, P. Wrapping-[9] Cutler, M., Shih, T. and Meng, Y. Using the Structure of [10] Eikvil, L. Information Extraction from World Wide Web -A [11] Evans, D.K., Klavans, J.L. and McKeown, K.R. Columbia [12] Freitag, D. Machine Learning for Information Extraction in [13] Freitag, D. and McCallum, A. Information Extraction with [14] Kosala, R., Bruynooghe, M., Bussche, J.V. and Blockeel, H. [15] Li, Y., Zaragoza, H., Herbrich, R., Shawe-Taylor, J. and [16] Liu, B., Grossman, R. and Zhai, Y. Mining Data Records in [17] Muslea, I., Minton, S. and Knoblock C. A Hierarchical [18] Ogilvie, P. and Callan, J. Combining Structural Information [19] Ogilvie, P. and Callan, J. Combining Document [20] Reis, D., Golgher, P., Silva, A. and Laender, A. Automatic [21] Robertson, S., Zaragoza, H. and Taylor, M. Simple BM25 [22] Song, R., Liu, H., Wen, J.-R. and Ma, W.Y. Learning Block [23] Song, R., Wen, J.-R., Shi, S., Xin, G., Liu, T.-Y., Qin, T., [24] Yau, H.S. and Hawker, J.S. SA_MetaMatch: Relevant [25] Zhang, M., Song, R., Lin, C., Ma, L., Jiang, Z., Jin, Y., Liu, [26] Zhang, M., Song, R. and Ma, S. DF or IDF? On the use of 
