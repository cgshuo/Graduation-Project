 (NLP) community. Many research tasks rely on accurate classification. For example, sentiment classification [4][10] is essentially a text classification problem, and it clas-sifies documents into positive or negative category. 
In most cases, a variety of supervised classification methods can perform well. But when training data and test data are from different domains, the supervised classifica-tion methods often cannot perform well [8,11,12]. The reason is that training data do not have the same distribution as test data, so test data could not share the information considered as the most valuable resources for classification. However, such resources in different domains are very imbalanced. In some traditional domains or domains of concern, many labeled data are freely available on the web, but in other domains, la-beled data are scarce and it involves much human labor to manually label reliable data. So, the challenge is how to utilize labeled data in one domain (that is, source domain) for classification in another domain (that is, target domain). This raises a fundamental and important task, domain adaptation. 
Realizing the challenges posed by domain adaptation, some researchers have ex-plored a number of techniques to improve the performance of domain adaptation. However, the difficulties for domain adaptation are as follows: the first one is that the distribution of the target domain is not same with that of the source domain, and hence much as possible, and moreover, follow the intrinsic structure revealed by target do-main as much as possible. 
In light of the difficulties for domain adaptation, we propose a novel system algo-rithm which is composed of two stages. The first stage is called transition stage, where choose some high-quality seeds from the target domain which are most confidently structure of the target domain by employing the manifold-ranking process to compute the manifold-ranking score for every document that denotes the degree of belonging to a category. So we can label the target-domain data based on these scores. 
Our contribution is as follows. First, while existing domain-adaptation approaches typically rely on a generative model, our approach associates two domains to get some high-quality seeds from the target domain, and then follows the structure embodied by manifold-ranking-based approaches typically start with manually labeled seeds, our target domain. 
For evaluation, we use the proposed algorithm for sentiment classification problem, show that our approach can dramatically improve the accuracy when transferred to another target domain. 2.1 The Transition Stage 2.1.1 Overview At this stage, we take into account these two objectives: we aim to (1) get the labels of the target-domain documents while utilizing the information of the source domain, and then (2) identify the high-quality documents which are most confidently labeled. 
As we know, the features of source domain can be divided into two categories: domain-specific and nondomain-specific, and only nondomain-specific features can be used as a bridge between the source domain and the target domain. That is, we can use convenience, we call nondomain-specific features as  X  X eneralization features X . As and target domain have the same distribution, which couldn X  X  be satisfied in do-main-adaptation problems. So we use an adapted Prototype classifier to solve this utilizing Frequently Co-occurring Entropy (FCE) [11], and then we only use these every unlabeled document to denote its extent to each category, and then the score is source-domain data. The final score for classification is achieved when the algorithm ends, so the target-domain data can be labeled based on these scores. 2.1.2 Frequently Co-occurring Entropy In order to pick out generalization features, we use Frequently Co-occurring Entropy (for simplicity, we call it as  X  X -score X  in this work) proposed in [11]. The criteria behind The formula that satisfies these criteria is as follows: target domain respectively: target domain respectively; | D S | and | D T | is the number of examples in the source do-main and the target domain respectively. And according to [11],  X  is set to 0.00001. 
After computing the f-score of every word, we rank the words in descending order according to their f-scores. Then, we choose the first K FEATURE documents as generali-zation features. = P
T ( w ), a parameter  X  is introduced. Therefore, the formula is modified as follows: where  X  is set as 0.0001 according to [11]. 2.1.3 Prototype Classifier Since we have got generalization features, we process both source-domain and tar-get-domain data so that they only contain generalization features. After that, we assign every unlabeled document a score to repres ent its degree of belonging to a category, and the score is a real number between -1 and 1. Here, we assume that we classify the documents into two categories: category 1, and category 2. Therefore, when the score is score is near -1, the higher the  X  X ategory 1 X  degree is, when the score is between 0 and 1, the document should be classified as  X  X ategory 2 X . The closer its score is near 1, the algorithm [7] as an example here. And its process in our context can be described as follows: where |.| is the cardinality of a set. 2.1.4 Identify the High-Quality Documents Next, we find the high-quality documents from the target domain. To do this, we make use of the score which denotes its corresponding document X  X  extent to  X  X ategory 1 X  or  X  X ategory 2 X . Firstly, we rank the target-domain documents in descending order ac-cording to their scores. So the more forward the document is ranked, the more likely it belongs to category 2; the more backward the document is ranked, the more likely it belongs to category 1. Then, we choose the first K documents and last K documents as the high-quality documents. In the rest of the paper, we will refer to these high-quality documents as seeds. 2.2 The Transmission Stage important for domain adaptation, as discussed before. Now that we have a small, high-quality seed set which embodies the intrinsic structure of the target domain, we can make better use of the seeds by utilizing the manifold-ranking method and having it improve the performance of domain adaptation. 
The manifold-ranking method [13] is a universal ranking algorithm and it is initially used to rank data points along their underlying manifold structure. The prior assump-scores; (2) points on the same structure (typically referred to as a cluster or a manifold) are likely to have the same ranking scores. An intuitive description of manifold-ranking is as follows: a weighted network is formed on the data, and a positive rank score is assigned to each known relevant point and zero to the remaining points which are to be weighted network. The spread process is repeated until a global stable state is achieved, and all points obtain their final ranking scores. 
Given that we now have a high-quality seed set, we build the weighted network whose points denote documents in target domain. Also, we integrate the scores of the seeds into the manifold-ranki ng process. So the manifold-ranking process used for domain adaptation can be formalized as follows: (1  X  i  X  K ) are the seeds which are labeled  X  X ategory 2 X , the second K points x ( K +1  X  j  X  2 K ) are the seeds which are labeled  X  X ategory 1 X , and the remaining points x (2 K +1  X  u  X  n ) are unlabeled. Let 2 : R F  X   X  denote a ranking function which [ Y as  X  X ategory 2 X  and Y i2 =1 is x i is labeled as  X  X ategory 1 X . The manifold ranking algo-rithm used for domain adaptation goes as follows: 1. Compute the pair-wise similarity values between points using the cosine measure. 2. Connect any two points with an edge if their similarity isn X  X  0. We form the affinity 5. Let F* denote the limit of the sequence { F ( t )}. Then every document x j In the manifold-ranking algorithm, the weight matrix W is normalized symmetrically in and its initial ranking scores. According to [13], in our experiment, we set  X  to 0.6. It is worth mentioning that self-reinforcement is avoided since the diagonal elements of the affinity matrix are set to zero in the second step. Moreover, the information is spread symmetrically since S is a symmetric matrix. Zhou et al. [13] proves that the sequence { F ( t )} converges to In the above formula,  X   X   X  = 1 . Note that although F* can be expressed in a closed tional efficiency. Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any point falls below a given threshold (0.00001 in this study).  X  X ategory 2 X ; if Y i1 &lt; Y i2 , assign the document the label  X  X ategory 1 X . We evaluate our two-stage algorithm in the field of sentiment classification. In order to highlight the domain-specific nature of sentiment expression, we use reviews not only from different web sites, but also from domains with less similarity. Aimed at Chinese applications, we conduct the experiments based on the characteristics of the Chinese, and verify the performance on Chinese web reviews. However, the main proposed approach in this paper is language independent in essence. 3.1 Experimental Setup For evaluation, we use three Chinese domain-specific data sets from on-line reviews, which are: Book Reviews 1 (B, from http://www.dangdang.com/), Hotel Reviews 2 (H, from http://www.ctrip.com/) and Notebook Reviews 3 (N, from http://www.360buy.com/). Each dataset has 4000 labeled reviews (2000 positives and 2000 negatives). We choose one of the three data sets as source-domain data, and another data set as target-domain data. 3.2 Baseline Systems In this paper we compare our approach with the following baseline methods: [7], for the sentiment transfer. And it only uses source domain documents as training data. Results of this baseline are shown in column 1 of Table 1. As we can see, accuracy ranges from 61.25% to 73.5%. 
TSVM: This method applies transductive SVM for the sentiment transfer which is a widely used method for improving the classification accuracy. In our experiment, we use Joachims X  X  SVM-light package (http://svmlight.joachims.org/) for TSVM. We use a linear kernel and set all parameters as default. This method uses both source domain data and target domain data, obtaining the results in column 2 of Table 1. As we can see, accuracy ranges from 61.42% to 77.17%, which are better than Proto. 
EM: We implement the EM algorithm [6] based on Prototype classifier. Specifically, we train the Prototype classifier on the data labeled so far, use it to get the sentiment scores of unlabeled documents in the target domain, and augment the labeled data with K most confidently labeled documents. We test values for K E from 10 to 300, an in-crease of 20 each, and reported in column 4 of Table 1 the best results. As we can see, since EM is based on Prototype, its accuracy ranges from 65.7% to 76.5% which are better than other baselines except Manifold. 
Manifold: Our last baseline implements the manifold-ranking procedure [13] adaptable for sentiment transfer. Specifically, we begin by training a prototype classi-fier on the training data. Then we use the similarity scores between the documents and negative central vector to separately initialize the ranking score vectors of the test data. Finally, we choose K M documents that are most likely to be positive and K M documents that are most likely to be negative as seeds for manifold-ranking. We test values for K M from 10 to 300, an increase of 20 each, and reported in column 5 of Table 1 the best results. As we can see, accuracy ranges from 66.5% to 78.4% which are better than all other baselines.
 3.3 Our Approach In this section, we compare the adapted Prototype classifier (Adapted Proto in Table 1) There is a parameter, K , in our two-stage approach. We set K to 290 to show we choose 2 K seeds for manifold-ranking algorithm. 
Results of the adapted Prototype classifier are shown in column 3 of Table 1. As we can observe, the adapted Prototype classifier produces much better performance than Proto. The greatest average increase of accuracy is achieved by about 3% compared to effective to share information between source domain and target domain. 
Results of our approach are shown in column 6 of Table 1. As we can observe, our approach produces much better performance than all the baselines. The greatest aver-age increase of accuracy is achieved by about 6.5% compared to Proto. The great im-provement compared with the baselines indicates that our approach performs very effectively and robustly. Table 1 shows the average accuracies of Adapted Proto and TSVM are higher than Proto: the average accuracy of Adapted Proto is about 3% higher than Proto, and the average accuracy of TSVM is about 2.6% higher than Proto. As we know, Adapted Proto and TSVM utilize information of both source domain and target domain while utilizing the information of only one domain for improving the accuracy of sentiment transfer. 
Seen from Table 1, the average accuracies of the last three columns are higher than transfer approach is more effective for sentiment transfer. 
Meanwhile, the average accuracy of Manifold based on Adapted Proto showed in increase of accuracy of Manifold based on Adapted Proto is achieved by about 1.3% compared to Manifold based on Proto, which proves that Adapted Proto can choose higher quality seeds that embody the intrinsic structure of the domain for next stage. 
Table 1 shows the Manifold based on Proto approach outperforms EM: the average accuracy of Manifold based on Proto is abou t 1.3% higher than EM based on Proto, and the greatest increase of accuracy is achieved by about 13% on the task  X  X -&gt;N X  com-pared to EM based on Proto. This is caused by two reasons. First, EM is not dedicated for sentiment-transfer learning. Second, the manifold approach can follow the intrinsic structure of the target domain better. 4.1 Classification Classification is a traditional and widely-used problem, which includes two steps. The first [22]~[24]) is used when labeled data are not sufficient to build a classifier. It uses both a corporate them into Na X ve Bayes classifier. Lanquillon [23] put forward a framework to utilize unlabeled data using an Expectation-Maximization-like scheme. Joachims [24] exploited the unlabeled date to modify SVM. same distribution. So the classifier built by the labeled data could be well applied to the unlabeled data. But in our domain adaptatio n problem, the labeled and unlabeled data are from different domains, and often have different distributions. This is inconsistent with the basic requirement of typical classification, and the effect methods cannot be directly used in our problem. 4.2 Domain Adaptation Domain adaptation aims to utilize labeled data from other domains or time periods to help current learning task, and the underlying distributions are often different from each other. 
In the past years, many researchers have been working on this field and have pro-consensus regularization framework [9] and so on. DaumeIII and Marcu [14] studied Gaussian model. Then they presented an instantiation of this framework to Maximum Entropy classifiers and their linear chain counterparts. Xing et al. [15] proposed a novel algorithm, namely bridged refinement. They took the mixture distribution of the generalization stage, they got a set of features generalizable across domains, and at the second adaptation stage, they picked up usef ul features specific to the target domain. Then they also proposed a number of heuristics to approximately achieve the goal of generalization and adaptation. Recently, some researchers attempted to address sentiment domain adaptation [3][12]. 
Some studies rely on only the labeled documents to improve the performance of sen-customize a sentiment classification system to a new target domain using a small amount of labeled training data. Tan et al. [11] proposed Frequently Co-occurring Entropy to pick Adapted Na X ve Bayes to train a classifier suitable for the target-domain data. 
Moreover, some studies rely on only the sentiment words to improve the perform-ance of sentiment transfer (e.g. [1]). Andreevskaia and Bergler [1] presented a senti-ment annotation system that integrated a corp us-based classifier trained on a small set of annotated in-domain data and a lexicon-based classifier trained on WordNet. 
However, most of the existing studies rely on only utilizing the information from the structure of the target domain. 
In this paper, we design an algorithm for domain adaptation by taking into account structure of the target domain. information between the source domain and the target domain, and follow the intrinsic structure of the target domain to improve the performance of domain adaptation. Spe-transition stage, we (1) share the information between the source domain and the target get-domain documents, (2) utilize the scores to identify a small number of most con-nearby neighbors to compute the ranking score for every unlabeled document, (4) label the target-domain data based on these scores. 
Experimental results on three domain-specific sentiment data sets demonstrate that our approach can dramatically improve the accuracy, and can be employed as a high-performance domain adaptation system. 
In future work, we plan to evaluate our algorithm to many more tasks. Also, we plan to try more algorithms for each stage of our algorithm. This work was mainly supported by two funds, i.e., 60933005 &amp; 60803085, and two other projects, i.e., 2007CB311100 &amp; 2007AA01Z441. 
