 The intent-oriented search divers ification methods developed in the field so far tend to build on generative views of the retrieval system to be diversified. Core algorithm components  X  X n particu-lar redundancy assessment X  are expr essed in terms of the proba-bility to observe documents, rather than the probability that the documents be relevant. This has been sometimes described as a view considering the selection of a single document in the under-lying task model. In this paper we propose an alternative formula-tion of aspect-based diversificat ion algorithms wh ich explicitly includes a formal relevance model. We develop means for the effective computation of the new formulation, and we test the resulting algorithm empirically. We report experiments on search and recommendation tasks showing competitive or better perfor-mance than the original diversification algorithms. The relevance-based formulation has further intere sting properties, such as unify-ing two well-known state of the art algorithms into a single ver-sion. The relevance-based approach opens alternative possibilities for further formal connections and developments as natural exten-sions of the framework. We illustrate this by modeling tolerance to redundancy as an explicit confi gurable parameter, which can be set to better suit the characteristics of the IR task, or the evaluation metrics, as we illustrate empirically. H.3.3 [ Information Search and Retrieval ]: Information Search and Retrieval  X  retrieval models Algorithms, Measurement, Performance, Experimentation, Theory Diversity, relevance m odels, language models, generative models The value of diversity as a funda mental dimension of information utility has started to be cared for in the Information Retrieval (IR) research community for over a decade [4]. Diversity-enhancement methods have been developed [1,7,21,27,29], diversity evaluation methodologies and metrics have been proposed [1,8,24,29], and a diversity task has been included in the latest TREC campaigns [9]. Theories of IR diversity build on a revision of the classic docu-ment independence assumption in IR: the marginal utility of a document indeed highly depends on  X  X n general, decreases with X  the relevance of the documents the user has previously seen. Considering this, IR systems X  out put diversification is posited as an effective strategy to cope with the uncertainty (ambiguity and/or incompleteness) involved in user queries, as imperfect expressions of true user needs. By trading diminishing marginal relevance for increased query aspect coverage, diversification strategies seek to maximize the range of users (the precise poten-tial intents behind the query) who will get at least some relevant document, thereby improving the overall gain [1,7,10,21]. Two trends can be broadly distinguished in the diversification methods reported in the literature, based on whether or not they use an explicit representation of query intents [22]. Whereas intent-oriented methods include an explicit query aspect space in their formulation, implicit diversification schemes typically rely at some level on inter-document si milarity, under the assumption that dissimilar documents should cover diverse query aspects. Interestingly, intent-implicit appr oaches generally build  X  X s far as their formalization goes X  on an explicit relevance model, often lending from the Probability Rank ing Principle [7,27,29]. Where-as, in contrast, the intent-explicit methods tend to elaborate, in their problem statement, formalization, and algorithmic formula-tion, on generative views of the retr ieval system to be diversified, where relevance is implicit [1,2 1,25]. Core algorithm components  X  X n particular redundancy assessm ent X  are expressed in such approaches in terms of the probability to observe documents, rather than the probability that the documents be relevant. This has been sometimes desc ribed as a view considering the selection of a single document in the underlying task model [28]. In this paper we propose an alte rnative formulation of aspect-based diversification algorithms which explicitly includes a for-mal relevance model. Our research has a theoretical motivation in seeking an alternative, nuanced understanding of the intent-explicit diversity problem, and the resulting variants in the formu-lation and development of aspect -based diversification methods. On the other hand, the explicit relevance approach has advantages of its own. We report experime nts in search and recommendation tasks where the approach shows competitive or better perfor-mance than its original counter parts. Moreover, the relevance-based formulation opens the way fo r further extensions and elabo-rations with models involving an explicit representation of rele-vance. As a particular case, we show that the framework provides a sound basis for tuning redundancy penalization in a principled way, as a smooth consistent exte nsion of the di versity model. The rest of the paper is organized as follows. We briefly introduce and discuss intent-oriented divers ification schemes in the next section, paying specific attention to their document-oriented gen-erative formal foundation. We introduce our relevance-based revision of such schemes after that in section 3, including details for the development, estimation and computation of the compo-nents of our resulting diversification framework. We empirically test the effectiveness of our appr oach in section 4. Section 5 de-scribes a formal extension of the proposed framework to model and adjust the diversification to different degrees of tolerance to redundancy. We discuss the results and implications of our ap-proach in section 6, and conclude with a summary and final com-ments in section 7. The different views on relevance implied by the Probability Rank-ing Principle (PRP) [20] and the Language Modeling (LM) ap-proaches to IR [16] raised interest and debate in the research community by the turn of the past decade [23]. The absence of a clear explicit notion of relevance in the early LM formulations has been often considered to involve an underlying assumption of single relevant document selection [3]. Even though  X  X r precisely because X  there does not seem to be a unique common understand-ing on such issues in the field, and a unique view on whether or how LM actually capture relevance, we see theoretical  X  X nd po-tentially practical X  interest in exploring new formulations of the diversity problem  X  X nd the deri vation of algorithms thereupon X  which explicitly build on the probability of relevance. As stated in the introduction, we focus on approaches to diversity which are founded on an explicit representation of query intents. As two prototypical representative instances of this approach, we focus on IA-Select [1] and xQuAD [21] as the algorithms of reference for our study. Both have proved to be quite effective in IR diversity tasks, outperform ing prior non-explicitly intent-oriented approaches (see [22] for a comprehensive empirical analysis and comparisons). We start by briefly reviewing the formulation of these diversification schemes, and the fundamental principles on which they build, in order to contrast them later to a relevance-based alternative. The definition of the IA-Select approach is developed in [1] around a quality component  X  (  X  |  X , X  ) broadly defined as the likelihood that a document  X  satisfies the query  X  given the user intent  X  . The diversification problem is stated as finding a subset of documents  X  X f a given size X  th at maximizes the probability that at least one of them is relevant. This is formulated as finding the set  X  that minimizes: While solving this problem is NP-Hard, the authors provide a practical approximation to the optimal solution by greedily re-ranking a baseline set of documen ts picking one document at a time that maximizes the following objective function: where  X  is the set of documents that were selected in the previous quantifying to what extent the document  X  responds to the user need expressed by  X  when the intended sense of the query is  X  . The authors do not enforce a strict probabilistic rigor in the devel-opment of this component, and in fact omit an explicit specifica-tion, thus leaving its implementa tion somewhat open to different realizations of the expressed prin ciple. For their own experiments, the implementation of  X  (  X  |  X , X  ) is hinted as the product of a baseline retrieval scoring function (t he system to be diversified) by the probability that  X  belongs to category  X   X  X hich may be read as  X  (  X  |  X  ) . No explicit probability of relevance is introduced in their development and  X  X f we may indulge on a rather informal note X  one might find in the  X  (  X  |  X , X  ) notation some reminiscence of a probability distribution over documents. xQuAD does have a quite precise probabilistic formulation [21]. It is stated and developed upon a do cument generative model formu-lation, whereby the resulting key terms of the algorithms reflect the probability to obser ve documents, rather than the explicit probability of the latter to be relevant. Specifically, the xQuAD scheme consists of a greedy al gorithm with the same essential structure as IA-Select, but with a differently defined objective function: That is, the objective is a linear combination of the probability to observe a document given the query (which may be understood as the baseline retrieval function), and the probability to observe the document given the query, assumi ng  X  X trictly sticking to the probabilistic notation X  no previously selected document had be observed given the query (which repr esents the marginal utility of the document). The marginal utility component is in turn devel-oped by marginalizing over the set of query intents, which after some Bayesian derivations and mild conditional independence assumptions results in: 1 Thus the xQuAD algorithm is formulated and developed upon (conditional) document distributions, as ultimately embodied in the  X  (  X  |  X  ) and  X  (  X  |  X , X  ) components. Therefore neither IA-Select, nor xQ uAD, or other explicitly in-tent-oriented diversification schemes that we are aware of, include relevance as an explicit magnitude or random variable. Taking up from a more literal interpretation of Agrawal X  X  initial problem statement, we investigate a revision of the IA-Select formulation by defining  X  (  X  |  X , X  )  X  X  (  X  |  X , X , X  ) , where  X  is the binary relevance random variable (and  X  is used as a shorthand for 1= X  ). With this formulation, the objective function to be maxim-ized in the problem statement (equation 1) then explicitly be-comes: The original version of xQuAD [21] would use  X  (  X  |  X  ) rather than  X  (  X  |  X , X  ) . Later publications [22] present however the lat-ter form, which we have also fo und to work better in our exper-iments, whereby we favor it here. Our analysis and considera-tions apply just the same to both variants in any case. And the marginal utility objective function for the greedy approx-imation algorithm (equation 2) gets then defined as:  X  (  X  |  X , X , X  )  X  X = (  X  |  X  )  X  (  X  |  X , X , X  )  X  X  X  X 1 X  (  X  |  X   X   X , X , )  X  In order to implement this formulation we need a means to esti-mate  X  (  X  |  X , X , X  ) . Before addressing that, we formulate a similar revision of the xQuAD algorithm. For this algorithm we actually reconsider the own initial formula-tion of the approach. Rather than expressing the objective function in terms of document probabilities as in equa tion 3, we define the objective function on an explic it relevance model, as: where  X   X  means  X  is relevant  X  X hat is,  X  (  X   X  X   X  means no document in  X  is relevant. Taking this starting point, by similar steps to the original xQuAD, we derive:  X  (  X   X   X  X ,  X  |  X  )  X  X = (  X  |  X  )  X  (  X   X   X  X ,  X  |  X , X  ) where we have assumed  X   X  and  X   X  are conditionally independent given  X  and  X  . Substituting all this in the objective function gives:  X  (  X  |  X , X , X  ) = ( 1 X  X  )  X  (  X  |  X , X  ) + It is easy to see that the above function becomes the relevance-based version of IA-Select (equation 4) when  X =1 . We hence notably find that, on a relevance model foundation, xQuAD turns out to be a generalization of IA-Sel ect. We shall thus deal with the two reformulations as a single approach henceforth. We now turn to the problem of estimating the two models in-volved in the new objective function, so as to come up to an effec-tively computable form for the latter. Two main components: the aspect model  X  (  X  |  X  ) , and the rele-vance model  X  (  X  |  X , X , X  ) , need to be estimated in order to com-pute the objective function  X  (  X  |  X , X , X  ) of our diversification approach. First, for the relevance model, by applying Bayes X  rule we have: The  X  (  X  |  X , X  ) component can be obtained from the retrieval sys-tem, as we shall discuss late r in the next subsection. The marginalization of the cond itional aspect distribution with respect to relevance gives  X  (  X  |  X , X  )  X = (  X  |  X , X , X  )  X  (  X , X | X  ) +  X  (  X  |  X  X , X , X  )  X  X 1 X  (  X , X | X  )  X  . Therefore by substitution in the numerator above, the relevanc e model can be rewritten as: Now we assume that under non-re levance, aspects are independ-ent from documents and queries, that is  X  (  X  |  X  X , X , X  )  X  X  (  X  |  X  X  ) . In other words, given non-relevanc e, we consider there is no particular relation the aspect is en forced to meet with respect to the query and the document  X  X ther than not forming a relevant tuple. Since most aspect / documen t / query tuples are not related in practice, as relevance is highly sparse, such negative condition can be considered as negligible. Comparable assumptions can be found in probabilistic developments in the literature (see e.g. [29])  X  X nly with no aspect variable invol ved. Furthermore, we assume no particular bias between aspects towards relevance or non-relevance, i.e. we approximate  X  (  X  |  X  X  )  X  X  (  X  ) . The aspect prior can be estimated from the coverage of aspects in the document collection, if the latter is consider ed as a fair representative sample space for users X  information need intents. Or, in the absence of further information, the prior can be taken as uniform. Now,  X  (  X  |  X , X  ) for equation 6 can be approximated in different ways, depending on the nature of the aspect space and the availa-ble observations. When aspects consis t of categorical data in such a way that  X  (  X  |  X  ) can be directly estimated from the data, we use the approach: using Bayes X  rule, marginalization over aspects (in the denomina-tor), and assuming again conditi onal independence of documents and queries given a query aspect (if a uniform aspect prior is we take this approximation when ODP is used as the aspect space for search diversification (see se ction 4.1). We use it in movie and music recommendation tasks as well, where movie genres and artist tags, respectively, are taken as the aspect space (section 4.2). When aspects belong to the query space,  X  (  X  |  X  ) can be estimated from the baseline retrieval function (as suggested e.g. in [21,22]), in a similar way as  X  (  X  |  X  ) is estimated for queries (see equation 8 below). In that case, we take the approach: using Bayes X  rule and assumi ng conditional independence of documents and queries given a query aspect. Note that this inde-pendence assumption is rather mild in this context, since the estimation of  X  (  X  |  X  ) applies to documents sampled from the result set for  X   X  X .e.  X  (  X  |  X  ) in practice is meaning  X , X  X  X  X  X  which is a form of blind relevance feedback approximation to  X  (  X  |  X , X  ) ,  X   X  being the set of documents returned for  X  that are to be diversified. In our experiment s, we shall use this approximation when TREC subtopics (manually provided by human assessors for each query) are taken as the aspect space by the diversification algorithm (see section 4.1). The generative model  X  (  X  |  X  ) in equation 7 can be either estimat-ed (more or less) directly from th e baseline search system  X  X hen the retrieval function implements a language model X  or it can be approximated from a relevance model as (see e.g. [3] for this type of derivation): Finally, as to the estimation of  X  (  X  |  X  ) , we consider two alterna-tives. For categorical aspects, we marginalize over documents in the result set: where we assume conditional independence of query aspects and queries given a document in  X   X  , and we use the estimate for  X  (  X  |  X  ) discussed above (e.g. equation 8). For manually-provided query subtopics (TREC data), we assume a uniform distribution  X  (  X  |  X  )  X  X 1  X   X  , where  X   X  is the number of subtopics of query  X  . Estimating the explicit probability of relevance of a document for a query has been researched in the IR literature from different points of view, distinguished from each other by the source from which relevance distributions are estimated. Retrieval systems based on the PRP rank documents by decreas-ing probability of relevance ) X , X | X ( X  given a query [20]. Howev-er, rather than directly estimatin g this probability, these systems compute a function that is equivalent in rank to  X  (  X  |  X , X  ) , and easier to estimate. The retrieval function is obtained by a series of monotonous operations on the proba bility of relevance, which involve lossy transformations, in th e sense that it is not possible to recover  X  (  X  |  X , X  ) back from the final expression. There is thus not in general an analytic approach to obtain an explicit relevance model from a PRP retrieval system [3]. On the other hand, a number of st udies have researched the rela-tion between retrieval function sc ore distributions and relevance [2], and some have devised approaches to estimate the probability of relevance from score values [18]. In essence, these approaches analyze the distribution of the sc oring function, and their corre-spondence with known relevance in formation, thus training a model of relevance given system scores, by regression on the available data [18]. We propose a similar but quite eas ier approach to estimate the probability of relevance, which ju st requires the availability of either precision estimates, or cl ick statistics, for the retrieval system being diversified. Rather than mapping scores to probabili-ties of relevance, we use a common relevance estimate for all queries, based only on the posit ion of documents. Namely, we estimate the probability of relevance by: where  X   X  (  X , X  ) is the rank position of document  X  in the result list returned by the baseline retrieval  X  in response to query  X  . Note that this step involves, in a way, a form of rank-based retrieval system output normalization wher e (similarly to e.g. rank-sim normalization [17]) we onl y use the document order  X  by the system, regardless of the score values. After this step, estimating the probability of rele vance of a document for a query amounts to estimating the probability of relevance at each rank position  X   X  (  X  |  X , X  ) for the retrieval system  X  . To simplify the notation, we shall henceforth drop the  X  s  X  subscript from  X  (  X  |  X , X  ) , but it should be implicitly understood, as this distribu-tion estimate is system-dependent. If relevance judgments are available to train the relevance model or, equivalently, we have an estimate of precision at  X  of the retrieval system (for  X  ranging up to the size of the document set to be diversified), the positional relevance probability can be estimated as: where  X   X   X @ denotes the precision at  X  of the system on query  X  . In our experiments we estimate precision by splitting the set of test queries (with their relevance judgments) into two disjoints subsets of equal size for 2-fold cross-validation. For the queries in one subset, we approximate  X  (  X  |  X , X  )  X  X  (  X  |  X  ) using an average precision estimate  X   X   X @ X  X   X @ , computed in the complementary query subset. As an illustrative example, Figure 1 shows the average relevance distribution estimate resulting for the Lemur Indri search system and the pLSA recommender  X  X hich we use as baselines in our experiments in section 4. The precision estimates are taken from the TREC 2009/10 diversity task data for Lemur, and from the MovieLens 2 dataset for pLSA (more details in section 4.2). For Lemur, the distribution decreases from  X  (  X  | 1 )  X 0.21 to around 10  X  X  by 200=  X  . pLSA displays a higher relevance probability due to the nature of the recommendation task on this dataset. Compared to more involved methods such as the regression tech-niques described in [18], this appr oach is equivalent to simply using the raw relevance data (a histogram of positional relevance) without regularization, rather than a parameterized fit (e.g. by a logistic function). A positional relevance model  X  (  X  |  X  ) can also be built from simple click statistics for the baseline retrieval system [19]. Assuming a cascade browsing model [15], and the simplifying assumption that a document is clicked if and only if it is relevant, we may consider the approximation: where  X  (  X  X  X  X  X  |  X  ) is the probability that a document at position  X  is clicked, and  X  (  X  X  X  X  X  |  X 1 X  ) denotes the event that the user continues (does not stop) browsing after position  X 1 X  . This term can in turn be decomposed by marginalization into the relevance and non-relevance cases: http://www.gro uplens.org/node/73 Figure 1. Relevance distribution estimate on the top 200 positions for different retrieval systems on different datasets ( y axis displayed in log scale) . The estimates for Lemur and pLSA are based on  X  X  X  measurements, whereas the AOL curve is derived from click statistics from the AOL query log. The Lemur curve is computed on TREC 2009/10 diversity task data. The relevance curve of pLSA is derived from a recommendation task on MovieLens data (see section 4.2). Assuming the probability to stop is independent from the position of the document given its relevance, and combining equations 10 and 11 we get:  X  (  X  |  X  )  X  Starting from  X  (  X  | 1 )  X  ~ (  X  X  X  X  X  | 1 ) , the above equation provides a recursive means to estimate the probability of relevance at each position in the ranking by just having some statistics (e.g. from a query log) of the ratio of clicks at each position, i.e. a background estimate of  X  (  X  X  X  X  X  |  X  ) . The two remaining parameters represent a user model (as has been well-studied before, see e.g. [15]), where  X  (  X  X  X  X  X  |  X  X  ) reflects the user X  X   X  X atience X , and  X  (  X  X  X  X  X  |  X  ) is related to how many relevant documents the user is willing to get. This user model allows to account for the position bias in click statistics, and can be estimated in different ways. In the absence of  X  (  X  X  X  X  |  X  ) =1  X  X  single relevant document is enough X  and  X  (  X  X  X  X  |  X  X  ) =0  X  X he user never gives up until finding a relevant document X  has been found to be acceptable for many purposes [8,15], which in our case just yields: If click data became too sparse below a certain position,  X  (  X  X  X  X  X  |  X  ) might be estimated by re gression techniques from this point on, since we need an estimate of  X  (  X  |  X  ) for as many posi-tions as the diversification system is intended to rerank. As an illustrative example, Figure 1 shows the relevance curve derived from the AOL query log dataset using this approach, which we shall also test in our experiments. The curve is not significantly far below Indri on TR EC 2009/10 (in fact it is above it in the top ten). Since AOL can be assumed to be a well opti-mized engine, this (small) difference can be attributed to a diver-gence in user behavior beyond the first web search results page (i.e. the behavior on the first and subsequent pages do not fit the same model), and/or the imprecis ion of the model. On the other hand, the AOL curve reflects pract ical (and personal) utility for real Web users, which is probabl y more demanding than topical (less subjective) relevance as applied by TREC assessors. The estimation of relevance models continues to be a research topic in the IR field, and our approach might benefit from any improvement on this point  X  X he more accurate the relevance mod-el, the better the diversification algorithm can be expected to perform. Interestingly however, ev en with rough relevance proba-bility estimates like the ones described here, the relevance-based diversification method seems to achieve good performance. Test-ing our framework with simple appr oaches as defined in equations 9 and 12, we already observe comparable or better results than the formulations based on ge nerative models, as we report in the next section. We have tested our relevance-ba sed diversification framework on two IR domains: ad-hoc search, as defined in the TREC Web track diversity task [9], and movie recommendation [24]. In order to test our framework on search diversity, we use the data from the TREC diversity task, namely, the ClueWeb collection category B, the topic data, and the relevance assessments from the TREC 2009 and 2010 editions [9]. We use the Lemur Indri re-trieval model 3 (version 5.2) as the baseline search engine. We rerank the top 100 documents re turned by the search system by the original a) IA-Select and b) xQuAD algorithms, and c) by our relevance-based reformulati on. We test two query aspect spaces for diversification: 1) the Open Directory Project (ODP) categories as in [1], and 2) the subtopics manually provided in the TREC 2009/10 diversity task, as a reference for comparison. We do not apply an exhaustive optimization or tuning of the diversifi-ers, since the goal of the experiment is the comparison of alterna-tives, rather than reaching the maximum performance possible. To this respect, our results are roughly comparable in range to those reported e.g. in [21]. With ODP categories, we use the Textwise 4 classification service to estimate  X  (  X  |  X  ) , by normalization of the score returned by the classifier. For TREC subtopics, we derive an estimate by submitting them as queries to the baseline search system, as discussed earlier in section 3.3. We use a simple uniform aspect prior estimate, and compute the rest of components as described in that section. We test both equations 9 and 12 to estimate the rank-relevance model  X  (  X  |  X  ) , using relevance judgments from the TREC dataset and AOL click statistics, respectively. TREC relevance information is used in a 2-fold cross-validation, where the relevance judgments of TREC 2009 are used to estimate  X @ X  and derive  X  (  X  |  X  ) in TREC 2010 topics, and vice-versa. Figure 2 compares the performance of the original xQuAD algo-rithm and the relevance-based reformulation (RxQuAD, using relevance judgments  X  X quation 9 X  for the  X  (  X  |  X  ) estimate), meas-ured by ERR-IA, for  X  ranging from 0 to 1. It can be seen that the relevance-based approach consiste ntly outperforms the original xQuAD version. The plots also give an idea of the sensitiveness of the algorithms to the choice of the  X  parameter. It is interesting to notice that using TREC subtopics, the best result is reached for  X =1 , that is with maximum divers ity. This makes sense, as the diversifiers use a  X  X elevance-safe X  aspect space, inasmuch as http://lemurpr oject.org/indri http://textwise.com Figure 2. Comparative performance (measured by ERR-IA) of relevance-based diversific ation (RxQuAD) and xQuAD, ranking over values of  X  . The algorithms are tested on TREC 2009/10 data for ClueWeb category B, using ODP (left) and TREC subtopics (right) as the query aspect space, and TREC relevance judgments for the  X  (  X  |  X  ) estimate. subtopics are tightly related to the query, and therefore diversify-ing for them does not result in such a potential relevance loss tradeoff as with ODP categories. Table 1 shows the comparative results on a more complete set of diversity metrics, computed with the evaluation script from the TREC diversity task. We also show subtopic precision at r (S-precision@ r ) [29] where r is the subtopic recall (S-recall) in the set of documents being diversifie d. In other words, S-precision@ r is the number of subtopics in the reranked set, divided by the first position where all the subtopics ha ve been covered  X  X t thus com-plements S-recall@20 with a measure of how early in the ranking all possible aspects are covered. Note that  X  -nDCG, ERR-IA, and nDCG-IA account for both diversity and relevance, whereas S-recall and S-precision@ r are pure diversity metrics. For xQuAD and our approach, the results correspond to the best  X  in terms of ERR-IA, selected manually with a precision of 0.1. It can be seen that the relevance-oriented approach improves the two original diversifiers with ODP categories on all metrics (ex-cept on subtopic recall for the clic k-based configuration against xQuAD). With TREC subtopics, IA -Select is considerably effec-tive  X  X hich we believe is due to the mostly single-valued aspect coverage per document, a situation where IA-Select seems to work particularly well X , and has similar effectiveness to our ap-proach, with some advantage on S-precision@ r . Our approach performs better than xQuAD on this aspect space in all cases though. In general, the best resu lts for our framework are obtained with the baseline-specific estimate of  X  (  X  |  X  ) (equation 9) on TREC relevance judgments ( X  X rel s X  rows in Table 1), as one might expect. We may however obs erve that the results obtained with the AOL click statistics ( X  X li cks X  rows) are almost as good as the results with the relevance ju dgments. This suggests that our approach is not particularly dema nding or sensitive to the nature of the required relevance information to estimate  X  (  X  |  X  ) . In order to test our approach on a different domain other than ad-hoc search, we conduct additio nal experiments on recommender system tasks. For this purpose we use two well-known datasets: the 1M version of the MovieLens collection, which includes one million ratings (on a 1-5 scale) by 6,040 users for 3,900 items; and an extract from Last.fm provided by  X . Celma [6], including the full listening history of 992 users up till May 2009. The Last.fm data involves 176,948 artists and a total of 19,150,868 user ac-cesses to music tracks. We use two recommender system base-lines: a probabilistic Latent Sema ntic Analysis (pLSA) recom-mender [14], which is among the top performing on this data; and a simple non-personalized re commender which recommends movies by popularity (i.e. by th e number of ratings), which has shown to be competitive in these settings [11]. We follow the adaptation of the diversity problem to recommen-dation scenarios proposed in [25], by which items (here movies and music artists) are taken as th e equivalent of documents, and users play the part of queries. M ovie genre is used as the equiva-lent of query aspects in MovieLen s, and social tags (assigned to artists by Last.fm users) are used for the same purpose in the music dataset. MovieLens include s 19 genres, whereas in Last.fm we use a total of 123,819 different tags. The user-item interaction data (user ratings in MovieLens, artist playcounts in Last.fm) is split into training and test sets, following common experimental practice in the Recommender Systems field [13], where the test data are used as the equivalent of relevance judgments. In our experiments we take five random 80-20% splits of the MovieLens data and repeat for 5-fold cross-validation. In Last.fm we do a temporal 60-40% data split of the song access records based on their timestamp (see [6] for further details on the evaluation methodology we adhere to). Since the aspect space is categorical, and aspects are associated to items in a binary way (movies either belong or do not belong to a genre, and similarly for artist tags ), we take the simple approxima-tion  X  (  X  |  X  )  X   X   X  X  X   X   X   X   X  X  X   X   X   X   X   X  , where  X   X  X  X   X  =1 when  X   X  X as X  the aspect (genre or tag)  X  , and zero otherwise. In other words, we assume a uniform conditional aspect distribution among the set of aspects covered by each item. Different from the search setting, we estimate th e background aspect prior from the overall distribution of aspects in the set of items, given that the item-aspect association is explicit, manual, reliable, and therefore can be considered fairly informative. We estimate  X  (  X  |  X  ) by equation 9, using test ratings as relevance judgments for the com-putation of  X @ X  , with a random 2-fold split of test users. We use very slight variations of the deriva tions in section 3. 3, better suit-ed for model estimation on reco mmendation input data. We also found it effective to normalize th e top-level diversity component in the xQuAD schemes before its linear combination with  X  (  X  |  X , X  ) (equations 3 and 5). We use a distribution-based normali-zation technique [12] for both versions (the original xQuAD and our variation) which showed to be effective in our experiments. Figure 3 shows the performance of our relevance-based algorithm (RxQuAD) compared to xQuAD on MovieLens (left) and Last.fm (right), in terms of ERR-IA, for  X  ranging from 0 to 1. The two collections are quite different both in their volumetric statistics (size, etc.), the nature of the user-item interaction data (movie ratings vs. music track playcounts), and the nature and distribution of item aspects (editorial genres vs. community-contributed tags), which accounts for the different behavior of the algorithms with respect to the  X  parameter. In particular, the performance of our approach shows a drastic drop from  X  = 0.9 to 1 in MovieLens, whereas it improves consistently with  X  on Last.fm, peaking at  X  = 1 (which corresponds, as pointed out in section 3.2, to the rele-vance-based version of IA-Select). We attribute this difference to the fact that the baseline performance on Last.fm is quite low, whereby diversifying involves a lower relevance loss (hence the optimum improvement with ma ximum diversification). Mov-ieLens allows for better baselin e performance, whereby moderat-ing the diversity degree is more appropriate, and an extreme di-versification results in a drastic accuracy loss. Overall the im-provement respect to xQuAD is clear. Table 2 shows results on further me trics, showing also the diversi-fication of the popularity-based recommender baseline, in addition to pLSA. As in the experiment s in search diversity, the  X  parame-ter in xQuAD and RxQuAD is chosen to optimize for ERR-IA on each dataset. We see that our approach is consistently better in most cases. Only over pLSA in MovieLens we observe mixed results, with xQuAD producing better values on  X  -nDCG and nDCG-IA respectively, while RxQuAD is best on ERR-IA, and pure diversity  X  X s meas ured by S-precision@ r and S-recall. RxQuAD achieves clearer improvements on the popularity base-line. So it does on Last.fm for both baselines  X  X xcept on nDCG-IA against popularity. This s uggests that RxQuAD finds more room for improvement over the original algorithms on weak baselines (popularity recommendation vs. pLSA) and/or difficult datasets (Last.fm compared to MovieLens), with a low baseline effectiveness, whereas on a strong baseline run, there is no clear winner. We also observe that the IA-Select algorithm is not al-ways effective on these recommendation tasks. We attribute this to the strong redundancy penalizati on of IA-Select (as we shall discuss later), which may involv e a loss of relevant documents, particularly over a strong baseline like pLSA. The ineffectiveness is mostly observed in terms of  X  -nDCG, a metric which (by a default  X  = 0.5) applies a softer redundancy discount which IA-Select may mismatch. Furthermore, because of the  X  (  X  |  X  ) term, items with multiple aspects (whi ch abound in Last.fm) are demot-ed by IA-Select, which explains some low subtopic recall values. RxQuAD is indicated next to each row and dataset block. Figure 3. Comparative performance (measured by ERR-IA) of relevance-based diversific ation (RxQuAD) and xQuAD, ranging over values of  X  . The algorithms are tested on the MovieLens 1M dataset (left), us ing movie genre as the query aspect space; and Last.fm (righ t) using social tags as infor-mation need aspects. pLSA is the baseline recommender sys-tem diversified in the two top graphics, and the popularity-based item recommender in the bottom ones. Beyond the interest and potential advantages of the relevance-based diversification model as a stand-alone development, an explicit relevance model provide s the basis for the introduction and derivation of further extens ions on a formal probabilistic basis. We show this by extending our framework with an explicit model of the tolerance to redundancy : different tasks, or different users, introduce different cond itions on how redundancy should be handled and penalized. We show next how this can be accounted for by a smooth generaliz ation of our framework. Let  X  X  X  X  denote, as in section 3.4, a binary random variable that is true when a user, in some retrieved document list browsing con-text, stops reading documents. And let  X  X  X  X   X  denote the fact that a user stops browsing at some point after reading some documents in a set  X  . We may refine the xQuAD diversity component as defined in terms of the user stopping before reaching  X  . This re-sults into a nuanced reformulation of the objective function:  X  (  X  |  X , X , X  ) = ( 1 X  X  )  X  (  X  |  X , X  ) + This form of the objectiv e generalizes the original one by abstract-ing from the reasons why a document  X   X  X n the context of a par-ticular ranking X  would not add value to the effective utility of the result list. Now, as we did in section 3.4 (e quation 11, but here with further conditioning variables), we may marginalize the stopping proba-bility with respect to relevance: where again different simplifications can be considered. First, within the objective function for greedy document selection, we should consider  X  (  X  X  X  X  |  X   X   X  X , X , X , ) =0 for  X   X   X  X  of the next document (which the objective function means to assess) would not be an issue if the user had stopped browsing already somewhere in  X  . Another reasonable simplification is to assume the user X  X  decision to stop at a specific document only depends on finding relevance, i.e.  X  (  X  X  X  X  |  X   X   X , X , X , )  X  X  (  X  X  X  X  |  X  ) whereby the model reduces to: This way the original diversification algorithm is generalized to a form where an additional parameter  X  (  X  X  X  X  |  X  ) represents the user tolerance to redundancy  X  X r in so me sense, how many documents it takes for the user to be satisfied:  X  (  X  |  X , X , X  ) = ( 1 X  X  )  X  (  X  |  X , X  ) + The introduction of this additiona l parameter allows to better match this characteristic of users and/or retrieval tasks. It allows to control (raise or soften) the penalization that should be applied to documents possessing aspects that are already covered in the original formulation of xQuAD. The latter implicitly assumes vant document (zero tolerance to redundancy), which reflects again an implicit assumption that users are willing to select a single document  X  X hich is often not the case. An equivalent parameter might be inserted in the original xQuAD formulation to soften redundancy penalization, but it would lack the formal justification that the relevance-based approach enables. Furthermore, the xQuAD redundancy penalization is already rather mild compared to RxQuAD, since the discounting term of the novelty component is base d on document probabilities  X  (  X  |  X  ) , which tend to range on much lower values (since they should sum to 1 over all documents covering an aspect) compared to a Ber-noulli relevance distribution  X  (  X  |  X , X , X  ) . The addition of a toler-ance parameter to xQuAD would only make this worse  X  X nless it ranged beyond [0,1], which would bring the scheme even farther from a formal probabilistic basis. On the other hand, tolerance to redundancy has also been explicitly modeled and introduced in the context of metric formalization upon user models [5,8,15,24]. Therefore the use of this parameter in our diversification algorithm has the potential of a better optimization for such metrics by bringing the diversification model closer to the principles and assumptions which are built into the metrics. In order to illustrate the effect of adjustable redundancy, we dis-play as a heat map in Figure 4 the performance values of the generalized RxQuAD with different values of  X  (  X  X  X  X  |  X  ) , meas-ured by  X  -nDCG with different values of  X  (also reflecting differ-ent degrees of redundancy tolerance). For this test, we select the TREC subtopics in the search task (with  X  (  X  |  X  ) estimated on relevance judgments), and the MovieLens dataset for the recom-mendation task. We keep the same values for  X  as were selected in the previous experiments, and the pLSA baseline in the recom-mendation task. It can be observed that the redundancy penaliza-tion effect of  X  (  X  X  X  X  |  X  ) is consistent with the equivalent parame-ter in the metric, i.e. the values evolve on a diagonal pattern: higher  X  (  X  X  X  X  |  X  ) values in the algorithm perform better for higher  X  in the metric, and vice versa. The MovieLens graphic is smoother as the results are averaged over about 6,000 users (vs. 100 topics in TREC), and averaged again over 5 folds. Figure 4. Parameterized tolerance to redundancy in the RxQuAD diversification algorithm by  X  (  X  X  X  X  |  X  ) , evaluated with corresponding metric configurations (  X  parameter in  X  -nDCG), by increments of 0.1. The values are displayed as a heat map where the darker colors (rank-normalized per col-umn) represent higher  X  -nDCG values. The left map shows results for search diversity (over Indri) on ClueWeb with TREC subtopics, and the right map shows results recommen-dation diversity (over pLSA) on MovieLens with genres. A diagonal trend can be observed in the relative metric values. In practical terms, using a relevance model in the redundancy component results in a higher redundancy penalization than is applied with a document genera tion model in xQuAD, as dis-cussed in the previous section. Adding to one over all documents, whereby subtopic coverage may tend to overdo redundancy in the overall effect of the algorithm. In contrast, the conditional Ber-noulli relevance distribution  X  (  X  |  X , X , X  ) does not add to one in general over documents (unle ss the model assumes a unique relevant document), and may thus range over a significantly high-er scale. Our relevance-oriented formulation hence enables a stronger redundancy penalization. Th is strength can be softened if needed, by the generalization fo r redundancy adaptation described in the previous section. Compared to the original xQuAD, IA-Select goes to the opposite extreme in redundancy penalization: according to the approach described by Agrawal et al [1 ], redundancy is penalized by  X  (  X  |  X  ) , which may have values clos e to 1 when documents cover a single aspect with high probability. The effect is that once an aspect is covered by some document in  X  , any other document covering this aspect is considered to add near zero marginal utility [28]. As a particular consequence, there is little discrimination between degrees of redundancy (i.e. an aspect that has been cov-ered just once vs. further times before), and once all aspects have been covered, the diversified ranking degrades to the original order defined by the baseline retrieval system (see [26] for further analysis). Our relevance-oriented formulation does not result in such extremes either, as far as the probability of relevance, even at the high rank positions does usua lly not get as close to 1 as  X  (  X  |  X  ) may get. In practice, IA-Select may also soften the penalization by multiplying  X  (  X  |  X  ) by the baseline retrie val function. The penali-zation is also milder when documents cover several aspects, in which case  X  (  X  |  X  ) ranges over lower values. The algorithm im-plementation designer has no explic it control over these factors though  X  X n contrast with our proposed extension for redundancy adjustment X , which may also acc ount for the instability of IA-Select across heteroge neous experiments observed in section 4. Besides these considerations, a relevance-based redundancy as-sessment better matches the stru cture of redundancy-sensitive metrics such has ERR-IA and  X  -nDCG, which are formalized in terms of probabilities of relevance [8]. This may partly account for the observed improved performance. The introduction of an explicit redundancy control parame ter allows further gauging how aggressive the novelty-seeking component should be, enabling a finer adjustment to the role of redundancy in specific IR tasks and metrics. Modeling tolerance to redundancy illustrates the potential ad-vantages that an explicit releva nce model brings about. Tolerance to redundancy could be introduced in the original formulations of IA-Select and xQuAD as well e.g. as a scalar parameter in the redundancy penalization component, but it is not clear how this might be given a principled  X  X ot simply heuristic X  justification. As noted by Welch et al [28],  X  common to a majority of prior research [on search diversification] is the single relevant docu-ment assumption  X , which makes it difficult to explicitly formalize variable degrees of acceptable re dundancy. The lack of this limita-tion might be credited as a virtue of an explicit relevance model. Though it has also been argued that a document generative model does not intrinsically negate the selection of several relevant documents [16], it is not clear how this multiple selection could be explicitly reflected upon a generativ e model. Welch et al [28] actually address this by explici tly modeling the number of rele-vant documents that the user is seeking to get. The alternative we show here has a considerably simpler development and does not require the introduction of this additional, somewhat artificial variable (the number of sought documents). Instead, our approach builds on models of user behavior, which are being extensively researched in the field (e.g. [8,15] among many other works). A tradeoff of the relevance model is that it needs to be trained on relevance information  X  X  tradeoff which is shared with PRP ap-proaches in contrast to language modeling to build information retrieval systems. We have shown however that the need for training in our framework is not demanding in terms of the in-volved complexity, the data requirements, or the required accura-cy, since a simple approach with few data proves to be good enough to produce quite competitive results. Furthermore, a rough rank-relevance estimate from a commercial search engine click log showed to be sufficient to obtain almost as good results as with expensive editorial relevance judgments. IR diversification approaches proposed so far in the field use either an explicit representation of information need aspects, or an explic-it relevance model, but not both. We have proposed and developed a revision of prior intent-oriented diversification schemes with the introduction of an explicit relevance model in the formulation of the approach. We observe that an explicit relevance model results in comparable or even better performance than prior approaches in terms of diversity evaluation metr ics, in different application do-mains (search and recommendation) on different datasets. The approach thus favorably compares to its original alternatives, and might open new lines for effectiveness improvements. From a theoretical st andpoint, the relevance-oriented formulation provides an alternative  X  X erhaps more direct X  description of the diversity problem, whereupon th e algorithmic scheme can be directly derived. The relevance-based foundation may be better suited for the description of diversification processes and their underlying principles: marginal utility, diminishing returns, rela-tive value of documents, and so fo rth. Concepts such as relevance and utility find clear, unambiguous and more direct reflection in the framework itself. Furthermor e, the formulation provides a more direct match of metric sc hemes in which relevance models underlie [5,8,15,24], therefore potentially providing for a better optimization against such metrics. An additional side-effect of the relevance-oriented formulation is the unification of the IA-Select and xQuAD approaches into a common scheme. The proposed framework opens moreover new directions for further formal developments where relevance is an intrinsic variable. As a particular case, we show the formal exten-sion of our framework to describe and adjust the algorithm to different degrees of tolerance to redundancy, the consistency of which is empirically validated. This work was supported by the national Spanish projects TIN2011-28538-C02-01 and S2009TIC-1542. [1] Agrawal, R., Gollapudi, S., Halv erson, A., and Ieong, S. Di-[2] Arampatzis, A. and Robertson, S. Modeling score distribu-[3] Bache, R., Baillie, M., and Crestani, F. Language models, [4] Carbonell, J. G. and Goldstein, J. The Use of MMR, Diversi-[5] Carterette, B. An analysis of NP-completeness in novelty and [6] Celma,  X . and Herrera, P. A New Approach to Evaluating [7] Chen, H. and Karger, D. R. Less is More. 29 th Annual Inter-[8] Clarke, C. L. A., Craswell, N., Soboroff, I., and Ashkan, A. A [9] Clarke, C. L. A., Craswell, N. , Soboroff, I, and Cormack, G. [10] Clarke, C. L. A., Kolla, M., Cormack, G. V., Vechtomova, [11] Cremonesi, P., Koren, Y., Turri n, R. Performance of recom-[12] Fern X ndez, M., Vallet, D., and Castells, P. Using Historical [13] Herlocker, J. L., Konstan, J. A., Terveen, L. G., and Riedl, J. [14] Hofmann, T. Latent semantic models for collaborative filter-[15] Hu, B., Zhang, Y., Chen, W., Wang, G., and Yang, Q. Char-[16] Lafferty, L., Zhai, C. Probaba listic Relevance Models Based [17] Lee, J. H. Analyses of multiple evidence combination. 20 [18] Nottelmann, H. and Fuhr, N. From Retrieval Status Values to [19] Pan, B., Hembrooke, H., Joachim s, T., Lorigo, L., Gay, G., [20] Robertson, S. E. The Probab ility Ranking Principle in IR. [21] Santos, R. L. T., Macdonald, C., and Ounis, I. Exploiting [22] Santos, R. L. T., Macdonald, C., and Ounis, I. On the Role of [23] Spark-Jones, K., Robertson, S. E., Hiemstra, D., Zaragoza, [24] Vargas, S. and Castells, P. Rank and Relevance in Novelty [25] Vargas, S., Castells, P., and Vallet, D. Intent-Oriented Diversity [26] Vargas. S., Castells, P., and Va llet, D. On the Suitability of [27] Wang, J. and Zhu, J. Portfolio theory of information retriev-[28] Welch, M. J., Cho, J., and Olston, C. Search result diversity [29] Zhai, C., Cohen, W. W., and La fferty, J. Beyond independent 
