 The volume of microblogging messages is increasing expo-nentially with the popularity of microblogging services. With a large number of messages appearing in user interfaces, it hinders user accessibility to useful information buried in dis-organized, incomplete, and unstructured text messages. In order to enhance user accessibility, we propose to aggregate related microblogging messages into clusters and automati-cally assign them semantically meaningful labels. However, these messages provide inadequate term co-occurrence infor-mation for capturing semantic associations due to their short length. To address this problem, we propose a novel frame-work for organizing unstructured microblogging messages by transforming them to a semantically structured representa-tion. The proposed framework first captures informative tree fragments by analyzing a parse tree of the message, and then exploits external knowledge bases (Wikipedia and WordNet) to enhance their semantic information. Empirical evaluation on a Twitter dataset shows that our framework significantly outperforms existing state-of-the-art methods. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Clustering ; D.2.8 [ Database Man-agement ]: Database Applications X  Data Mining Algorithm, Performance, Experimentation Microblogging, Accessibility, Clustering, Labeling
Microblogging services such as Twitter 1 are increasingly used for communicating breaking news, information shar-h ttp://www.twitter.com/ ing, and participating in events. This emerging medium has become a powerful communication channel in recent digi-tal revolutions. However, the accessibility of these messages has been very limited so far. Tweets and retweets of a user X  X  followees appear alongside the user X  X  own tweets in reverse chronological order. People often have only enough patience to skim through the first 20 -50 messages. When the mes-sages become overwhelming, it is impractical for a user to quickly gauge the main subjects from their followees X  posts.
To make a large collection of microblogging messages ac-cessible to users, current web systems need to provide not only accurate clusters for subtopics in microblogging mes-sages, but also meaningful labels for each cluster. Enhanc-ing the accessibility of microblogging messages entails two tasks: (1) cluster microblogging messages into manageable categories, and (2) assign readable and meaningful labels for each cluster of messages. Unlike standard text with many sentences or paragraphs, microblogging messages are noisy and short . In addition, microbloggers, when com-posing a message, may use or coin new abbreviations or acronyms that are uncommon in conventional text docu-ments. Furthermore, these short messages do not provide sufficient contextual information to capture their semantic meanings. Traditional text mining methods, when applied to microblogging messages directly, lead to unsatisfactory results.

In this paper, we present a novel framework to enhance the accessibility of microblogging messages. The proposed framework improves message representation by mapping mes-sages from an unstructured feature space to a semantically meaningful knowledge space. First, we use tree fragments extraction to generate informative words and phrases. Then, to overcome the extreme sparsity of microblogging messages, we map the selected terms to structured concepts derived from external knowledge bases that are semantically rich. By conducting feature selection, we are able to cluster all messages more accurately and generate human-comprehensible labels efficiently from related concepts.
In this section, we introduce the proposed framework for clustering and labeling microblogging messages.
We now formally define two major tasks in the problem of enhancing accessibility of microblogging messages.
Task 1: Microblogging Message Clustering. Let Fi gure 1: (a) The parse tree of  X  X ny tips for keeping fit? X . (b) Tree fragments of the subtree covering  X  X eeping fit X ; the fragments with dotted line frame are extracted tree fragments for  X  X eeping fit X .
 M = { m 1 , m 2 , . . . , m n } be a corpus of n microblogging mes-sages. Among these n messages, there are k latent topics or subtopics. We aim to cluster the n messages into k clusters { c 1 , c 2 , . . . , c k } with their latent topics as centroids.
Task 2: Cluster Labeling. For each cluster c i , we aim to generate human readable cluster labels { l i 1 , l i 2 which are semantically similar to the latent topic of c i
Many NLP techniques have achieved great success by ex-tracting tree fragments that occur in a parse tree to enrich text representation. A parse tree (or syntactic tree) is an or-dered and rooted tree that represents the syntactic structure of a string according to a formal grammar. Figure 1 (a) illus-trates an example of a parse tree generated by OpenNLP 2 . In the Figure,  X  X P X  and  X  X P X  represent verb phrase and noun phrase 3 , respectively.

Given a microblogging message, a parse tree has been con-structed to retain the syntactic information. Furthermore, we need to extract useful information from the parse tree to improve message representation. To better utilize the syn-tactic structure of a parse tree, Wang et al. [6] proposed to employ tree fragments as syntactic features.

Figure 1 (b) presents an illustration of the tree fragments for subtree X  X eeping fit X . Basically, we divided our algorithm into two steps: Subtree Selection and Fragment Selection .
Subtree Selection: As shown in Figure 1 (a), given a microblogging message, we first construct a parse tree according to its lexical tokens. Note that the number of subtrees is extremely large, which leads to the  X  X urse of di-mensionality X  X nd expensive computational cost for real web applications. Thus, we need to develop an efficient way to ensure the generated subtrees are not only informative but h ttp://incubator.apache.org/opennlp/
Full list of the abbreviations can be found in http://en.wikipedia.org/wiki/Parse tree/ als o effective. As we know, when people speed-read through a text, they do not fully parse the sentence but instead look for  X  X ey phrases X  contained in the text. Among these key phrases, the nouns and verbs are considered to be more im-portant than articles, adjectives or adverbs [6]. Thus, we utilize VP (Verb Phrase), NP (Noun Phrase), VB (Verb) and NN (Noun) rooted subtrees to extract tree fragments in next step.

Fragment Selection: As shown in Figure 1 (b), one sub-tree may generate a lot of tree fragments, which will result in redundancies. To avoid introducing redundant information to text representation, we only choose the tree fragments whose leaf nodes are constructed by words or phrase.
In order to transform the syntactic feature space to a se-mantic feature space, we collect the extracted tree fragments as a basis and construct semantic space for mapping. For each tree fragment, we apply semantic knowledge according to its syntax property. Phrase-level tree fragments are in-formative to represent a subtopic of the microblogging mes-sage. In this way, we can retrieve accurate Wikipedia pages for these tree fragments. The word-level tree fragments are too general to map accurately to concepts in Wikipedia. We thus utilize WordNet as complement to deal with the word-level tree fragments.

Particularly, if a tree fragment is from the phrase-level, we build an  X  X ND X  query 4 which requires the retrieved pages to contain every term in the phrase. We utilize the title and bold terms (links) of the retrieved articles, combined with key phrases as semantic features. For example, for the actor  X  X olin Firth X , we may obtain extrinsic concepts  X  X he King X  X  Speech X  and intrinsic concepts  X  X ngland X  by mining the re-lated Wikipedia pages. For the tree fragments from the word level, we employ WordNet synsets to extract similar con-cepts. For example, we can obtain  X  X uto X ,  X  X utomobile X  and  X  X utocar X  for the fragment  X  X ar X . With a semantic mapping, we can handle phrase-level synonymy problems by mapping two different phrases onto the same semantic concept.
We conduct feature selection to avoid aggravating the  X  X urse of dimensionality X . A single message contains a large number of tree fragments, including phrase-level ( t 1 ) and word-level ( t 2 ) tree fragments. We empirically set the upper bound of selected tree fragments as the number of non-stop words ( N ) contained in the message.

We then collect m tree fragments from Syntactic Decom-position and n semantic concepts from semantic knowledge bases, and construct a ( m + n ) dimensional feature space for clustering. As a large number of external features would have a negative impact on the quality of the text represen-tation, the number of semantic concepts is determined by: where  X  is the ratio of semantic concepts to the feature space for clustering. In the experiments, we empirically set  X  = 0 . 5.
F or more detail about query syntax, please refer to http://wiki.apache.org/solr/SolrQuerySyntax T able 1: Clustering results using different text rep-resentation methods on Twitter Dataset Wik iWN Metho d 0 . 513 (+4 .08%) 0 . 569 (+4.70%)
To normalize the weight of each feature, we reformulate the weighting policy proposed by Zhang and Lee [7]. For tree fragments f i extracted from original parse tree, f i weighted according to the size and depth of a tree fragment: where s ( i ) is the number of generated tree fragments consid-ering the tree fragment as a subtree and d ( i ) is the depth of the tree fragment root in the entire parse tree. For example, the tree fragment in Figure 1 (b) has s ( i ) = 3 and d ( i ) = 3. With this weighting scheme, the focus of the message can be measured according to its depth. Weight scores for all tree fragments are normalized. In addition, weights of semantic features from external knowledge bases are determined by their tf  X  idf values. Weight scores for all semantic concepts are normalized. The result is that messages are represented in a refined feature space.
Traditional labeling methods do not guarantee readability of the extracted labels. It is natural and effective to generate textual labels from the generated Wikipedia concepts, which have wide knowledge coverage and stably high quality.
We can map each tree fragment f i to several semantic con-cepts, which are extracted as label candidates { l i 1 , l For each labeling candidate l ij , the informativeness score is measured by: where W f i is a weight of the  X  X arent X  tree fragment defined in Equation 2, tf ij and idf ij measure the weights among all the candidates. Finally, the labels with highest Info score are extracted as cluster labels.
In this section, we empirically evaluate the effectiveness of the proposed Microblogging Message Management ( M 3 ) framework.
We crawled the hot queries published by Google Trends 5 between Jan. 1st 2008 and Dec. 31st 2010. Thirty hot queries of diverse topics are selected from Google Trends. h ttp://www.google.com/intl/en/trends/about.html/ Each hot query is considered to be a trending topic, and we crawl the top five query suggestions from Google as subtopics of this topic. The ground truth is obtained based on the following assumption: the messages returned by a query suggestion construct a cluster and the query sugges-tion is highly semantically associated with the correct label of this cluster. Thus, we have 150 topics from two levels (30 groups and 5 subtopics in each group). Based on the query suggestions (subtopics), we use Twitter Search API 6 to crawl 100 tweets for each query suggestion and construct a dataset containing 150 categories. As the API will not re-turn exactly 100 tweets for each query, it leaves 11362 tweets after text preprocessing.
To evaluate the performance of the proposed clustering module, we use F 1 measure and Accuracy as the performance metrics, and compare the following methods:
Note that our proposed text representation framework is independent of any specific dimensionality reduction and clustering methods. Similarly, we can easily apply this text representation framework to many clustering methods, such as K-means , LDA , NMF etc. In the experiments, K-means is employed and we set number of clusters k = 150.
The experimental results of the different methods on the dataset are displayed in Table 1. Based on the results, we make the following observations: (1) BOT augments the performance of BOW model on the dataset. We believe that this is because of the utiliza-tion of syntactic information from the original messages. We note that WN Meth od , Wiki Meth od , SemKnow also achieve better performance as compared to BOW model. It demon-strates that the integration of semantic concepts from exter-nal knowledge bases improved the quality of the representa-tion of microblogging messages for clustering. (2) An interesting finding is that WikiWN Me thod achieves comparable results with other baselines, which is beyond the observations of previous work [2]. WikiWN Metho d works well without the integration of features from the original message. It shows that the combination of semantic fea-tures complement each other and contribute to the overall result. h ttp://search.twitter.com/api/ T able 3: Lists of top-5 labels generated from M 3
Ap ple Trailers T railer ( 3) Among all the methods, M 3 achieves the best perfor-mance. We apply t-test to compare M 3 with the best base-lines WikiWN Meth od and SemKnow . The results demon-strate our approach significantly outperforms the two meth-ods with p  X  value &lt; 0 . 01.
We treat the cluster labeling task as a ranking problem, which is to rank all of the concepts from Wikipedia and find the best matched label for a cluster of microblogging mes-sages. The subtopics used for crawling microblogging mes-sages are considered to be ground truth for cluster labeling. We use NDCG as the evaluation metric. We compare the performance of following methods:
We compare the ranking performance of our proposed framework with the other three methods. Table 2 shows NDCG@10 score of the four methods on the dataset.
From Table 2, we can observe that M 3 outperforms all the baselines. It demonstrates that the generated labels from M 3 not only cover more potential topics hidden in the mi-croblogging messages, but also give the most relevant labels a higher ranking. Among the three baselines, Wiki achieves the best performance. We believe that the improvement stems from the structure and meaningful concepts provid-ing by Wikipedia.
To illustrate the usability of our proposed framework, we show an example of top-5 generated textual labels for a trending topic  X  X pple X  in Table 3. In the table, subtopics listed in the left side are considered  X  X orrect labels X . The underlined labels are  X  X dentical X  to correct labels and those with daggers are  X  X nflections X  of correct labels. We observe that while the labels for all clusters seem to represent the subtopics well, only the last cluster fails to achieve correct la-bel within top-5 labels, although most of labels are highly re-lated to subtopic  X  X pple Support X . The failure is mainly be-cause that there is no corresponding Wikipedia page named  X  X pple Support X .
In this paper, we proposed a novel framework to improve the performance of microblogging message clustering and labeling. The original short and noisy texts were mapped into a semantic space to improve the quality of text rep-resentation for clustering. In addition, with help of abun-dant structured features from Wikipedia, the task of cluster labeling was solved without introducing significant compu-tational cost. Empirical evaluations demonstrated that our framework significantly outperformed existing state-of-the-art methods.

This work suggests some interesting directions for future work. It would be interesting to explore if integrating so-cial network information can improve the quality of message clustering. Moreover, NLP and external knowledge bases can be valuable to help understand microblogging messages, if we can find effective ways to use them.
 This work is, in part, supported by ONR (N000141010091), AFOSR (FA95500810132) and Yahoo! Faculty Research and Engagement program. [1] S. Banerjee, K. Ramanathan, and A. Gupta. Clustering [2] E. Gabrilovich and S. Markovitch. Feature generation [3] A. Hotho, S. Staab, and G. Stumme. Wordnet improves [4] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting [5] P. Treeratpituk and J. Callan. Automatically labeling [6] K. Wang, Z. Ming, and T. Chua. A syntactic tree [7] D. Zhang and W. Lee. Question classification using
