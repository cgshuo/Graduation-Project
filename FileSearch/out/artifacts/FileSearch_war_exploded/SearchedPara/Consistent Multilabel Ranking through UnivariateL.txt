 Krzysztof Dembczy  X nski 1 kdembczynski@cs.put.poznan.pl Wojciech Kot lowski 1 wkotlowski@cs.put.poznan.pl Eyke H  X ullermeier 2 eyke@informatik.uni-marburg.de The problem of multilabel classification (MLC) has received increasing attention in machine learning re-search in recent years (Schapire &amp; Singer, 2000; Elis-seeff &amp; Weston, 2001; Dekel et al., 2003; Dembczy  X nski et al., 2010). In contrast to conventional (single-label) classification, where each instance is associated with a unique class label, MLC allows an instance to be-long to several classes simultaneously. In other words, the  X  X round truth X  is now a subset of positive labels instead of a single label. Correspondingly, more com-plex models need to be trained for predictive purposes, and their predictions need to be evaluated in terms of generalized loss functions.
 Instead of producing predictions in terms of label sub-sets, one often prefers a multilabel ranking , that is, a ranking of labels from most likely positive to most likely negative. A prediction of that kind is commonly evaluated in terms of the rank loss , namely the fraction of incorrectly ordered label pairs; a positive and a neg-ative label are incorrectly ordered if, in the predicted ranking, the former does not precede the latter X  X s it actually should do.
 Many methods for MLC are based on the direct min-imization of the number of conflicts, that is, pairwise ranking errors; more specifically, since the rank loss is highly discontinuous, such methods typically seek to minimize a convex surrogate. Interestingly, this ap-proach has recently been called into question by Gao &amp; Zhou (2011) (following the earlier results of Duchi et al. (2010)), who showed that the most commonly used convex surrogates of that kind are inconsistent. In this paper, we complement this negative result by a positive one. More specifically, we prove that com-mon convex surrogates used for binary classification, namely exponential and logistic losses, are consistent for the minimization of rank loss. Surprisingly, our surrogates are even simpler than existing ones for rank-ing, as they are univariate loss functions; thus, be-ing defined on single labels rather than label pairs, it comes with additional advantages in terms of complex-ity. Instead of directly proving convergence, we give a much stronger result by deriving regret bounds and convergence rates.
 The paper is organized as follows. In the next section, we introduce the setting of multilabel classification and elaborate on the rank loss for performance evaluation. Our main theoretical result is presented in Section 3 and discussed against the background of (Gao &amp; Zhou, 2011) in Section 4. The theoretical contribution of the paper is complemented by some computational exper-iments in Section 5, prior to concluding with a sum-mary in Section 6. In this section, we explain the MLC problem more formally and, along the way, introduce the notation used throughout the paper.
 Let X denote an instance space, and let L = {  X  1 , X  2 ,..., X  m } be a finite set of class labels. We as-sume that an instance x  X  X  is (non-deterministically) associated with a subset of labels L  X  2 L ; this sub-set is often called the set of relevant (positive) labels, while the complement L \ L is considered as irrele-vant (negative) for x . We identify a set L of relevant labels with a binary vector y = ( y 1 ,y 2 ,...,y m ), in which y i = 1 iff  X  i  X  L . The set of possible label-ings is denoted Y = { 0 , 1 } m . We assume observations to be generated independently and randomly accord-ing to a probability distribution P ( X = x, Y = y ) (later denoted P ( x, y )) on X  X Y , i.e., an observation y = ( y 1 ,...,y m ) is the realization of a corresponding random vector Y = ( Y 1 ,Y 2 ,...,Y m ).
 A multilabel classifier h assigns a (predicted) label subset to each instance x  X  X . More generally, we allow the output of the classifier to be a vector of real numbers h ( x ) = ( h 1 ( x ) ,...,h m ( x ))  X  R m , which means that h is an X  X  R m mapping. A score vector of this kind can not only be turned into a label subset (binary vector y  X  { 0 , 1 } m ) via thresholding, but can also be used for ranking the labels  X  i in a natural way, namely by sorting them in decreasing order according to their respective scores s i = h i ( x ). 2.1. Loss, Risk and Regret The prediction accuracy of h is measured in terms of its risk , that is, its expected (classification) loss L ( h ,P ) = E [ ` ( Y , h ( X ))] = where ` : Y X  R m  X  R is a loss function . In addition, it will be convenient to use an expected loss conditioned on an instance x  X  X  : L ( h ,P | x ) = E [ ` ( Y , h ( x )) | x ] = X so that L ( h ,P ) = E [ L ( h ,P | X )].
 The risk of a classifier is not always a good indica-tor of its true performance, as it does not account for the hardness of the problem. In fact, even the opti-mal classifier h  X  (which has access to the distribution P ( x, y )) will normally have a non-zero risk. We call h  X  the Bayes classifier . For each x  X  X  , this classifier minimizes expected loss conditioned on x : We note that in general, h  X  is not unique. However, the risk of h  X  , denoted L  X  ( P ), is unique, and is called the Bayes risk . It offers a reasonable baseline for com-parison and suggests to define the regret of a classifier h as follows: Occasionally, we will also use the regret conditioned on an instance x , denoted Reg( h ,P | x ). Later on, when analyzing the risk and regret for particular loss func-tions, such as rank loss, we will use more specific no-tations like L rnk and Reg rnk , which indicate the loss function that risk and regret are referring to. 2.2. Rank Loss In this paper, we focus on the rank loss , which is among the most important loss functions in MLC and has at-tracted much attention in recent years (Dembczy  X nski et al., 2010; Gao &amp; Zhou, 2011): ` rnk ( y , h ) = w ( y ) where J  X  K is the standard { false , true }  X  { 0 , 1 } map-ping (for the sake of clarity, we will suppress depen-dence on x in the notation, whenever it is clear from the context). Treating the classifier X  X  output as a rank-ing, the rank loss compares the true label subset with this ranking, in which all relevant labels ideally pre-cede all irrelevant ones. More specifically, the rank loss counts the number of label pairs violating this condition and multiplies it by a positive weight w ( y ). In other words, the  X  X enalty X  or  X  X ost X  for a mistake on a label pair is given by w ( y ) and may thus depend on properties of the true labeling y .
 Typically, w ( y ) is a normalization constant equal to the reciprocal of the total number of pairwise compar-isons between labels, thus accounting for the fact that the maximum number of possible mistakes depends on the number of positive labels in y . Yet, we shall not make any specific assumptions about about w ( y ) throughout the paper, except that it is non-negative and bounded: 0  X  w ( y )  X  w max for all y . 1 Let us determine the Bayes classifier for the rank loss. To this end, it is convenient to introduce the following quantity: where i,j  X  { 1 ,...,m } and u,v  X  { 0 , 1 } . Note that  X  uv ij reduces to the marginal probability P ( Y i = u,Y j = v | x ) if w ( y )  X  1. For a more general weight function w (  X  ),  X  uv ij combines the probability of the label combination ( Y i = u,Y j = v ) with the poten-tial penalty in case these labels are ranked incorrectly. Thus, it can be seen as a kind of importance of this label combination.
 By definition,  X  uv ij =  X  vu ji for all ( i,j ) and where W = E [ w ( Y ) | x ] = P y w ( y ) P ( y | x ) (which is a condition similar to the normalization property of a probability distribution). Then, the conditional risk can be written as follows:
L rnk ( h ,P | x ) = X To proceed further, we define  X  u i =  X  u 0 ij +  X  u 1 any j 6 = i (one readily verifies that this quantity does not depend on j ).  X  u i plays a role comparable to the marginal probability P ( Y i = u | x ). We have  X  0 i  X  i = W for all i and The Bayes classifier ranks labels according to the  X  1 i , i.e., a vector h  X  = ( h  X  1 ,...,h  X  m ) is a Bayes prediction if h  X  i &gt; h  X  j whenever  X  1 i &gt;  X  1 j , h  X  i = h  X  i =  X  using (6), we see that the Bayes classifier thus defined minimizes every term in the sum in (5). This result extends the result by Gao &amp; Zhou (2011) defined in terms of  X  10 ij . The Bayes risk conditioned on x is given by The equality  X  1 i  X   X  1 j =  X  10 ij  X   X  01 ij in (6) is not only useful but also remarkable. In order to understand its meaning, it is convenient to consider the special case w ( y )  X  1, in which the  X -values reduce to conditional probabilities (Dembczy  X nski et al., 2010). In this case, (6) becomes The decision whether label  X  i should be ranked ahead of  X  j or the other way around depends on the sign of the left-hand side: If the joint probability of ( Y 1 ,Y j = 0) is higher than the joint probability of ( Y i 0 ,Y j = 1), the answer should be affirmative, otherwise not. According to the above equation, the answer can be found by just looking at the marginal probabilities P ( Y i = 1 | x ) and P ( Y j = 1 | x ). This is remarkable, as it means that the dependency between Y i and Y j can safely be ignored X  X  key observation for our main result in the next section. We prepare our main result, to be presented in Section 3.3, by two auxiliary results.
 First, in Section 3.1, we show that rank regret de-pends solely on the marginal weights  X  u i , and that we are allowed to replace the original distribution P by any other distribution P 0 , as long as they both lead to the same marginal weights  X  u i . In particular, we can choose P 0 , for which labels are (conditionally) in-dependent.
 Second, in Section 3.2, we provide the basic argument for the use of univariate loss functions, showing that, under the assumption of independence, such losses are sufficient for the consistent ranking of objects. This result will be shown, not for MLC directly, but in the context of the related problem of bipartite ranking. The final step in Section 3.3 will therefore consist of transferring this result back to the setting of MLC, using the trick from Section 3.1 and the fact that ex-pected univariate losses depend on distribution only through the marginal weights  X  u i . 3.1. Label Dependence Does Not Influence The main problem in the analysis of the regret (3) is the conditional dependence of labels given x . As already mentioned, however, this dependence does not seem to play an important role in the minimization of rank regret. In the following, we shall make this observation more explicit by showing that rank regret depends solely on the marginal weights  X  u i : Lemma 3.1. For every x  X  X , and every multilabel classifier h : Reg( h ,P | x ) = X Proof. According to (5) and (7), Reg( h ,P | x ) can be written as where Since only one of the first three terms can be nonzero, B ij will not change if we add  X  11 ij to the first three terms and subtract it from the last term:
B  X  Lemma 3.1 implies that the rank regret of any mul-tilabel classifier h will not change if we replace the original distribution P and weight function w by any other distribution P 0 and function w 0 , as long as they lead to the same marginal weights  X  u i . In particu-lar, we can choose P 0 to be a product distribution, for which labels are (conditionally) independent, and the constant weight function w 0 ( y ) = W for all y . As we shall see in Section 3.3, this will effectively result in a bipartite ranking problem for every x .
 Before exploiting this finding in Section 3.3, we provide a second building block of our main result, showing that the minimization of specific univariate losses is sufficient for the proper ranking of objects under the assumption of independence. To this end, we refer to the related though slightly simpler setting of bipartite ranking. From now on, it will be more convenient to encode labels as  X  1 and +1, i.e., y i  X  X  X  1 , +1 } instead of { 0 , 1 } . 3.2. Univariate Loss Minimization is Sufficient The bipartite ranking problem (Cohen et al., 1999; a sense in-between MLC and standard binary classifi-cation. Like in the latter, there is only a single binary class label, but like in MLC, performance is measured in terms of rank loss instead of classification error. However, instead of ranking labels given an instance, the problem is to rank the instances themselves. More specifically, consider a simple binary classifica-tion problem with training examples (  X  x,  X  y )  X   X  { X  1 , +1 } . A classifier  X  h is a real-valued function  X  h :  X  X  X  R , and performance is measured in terms of a bipartite rank loss defined on pairs of labels: This is a non-normalized version of the rank loss, which is more useful for our purposes; in the litera-ture, it is common to use a normalized version, which differs from the non-normalized one by a product of class priors (Cl  X emen  X con et al., 2008).
 Given the loss, we can define risk and regret by tak-ing expectations over the pairs of instances which are generated i.i.d.:
L br (  X  h,  X  P ) = E [ ` br ((  X  Y ,  X  Y 0 ) , (  X  h (
Reg br (  X  h,  X  P ) = L br (  X  h,  X  P )  X  inf be the standard exponential and logistic losses for binary classification. For these losses, we can again define risks L exp (  X  h,  X  P ) ,L log (  X  h,  X  lowing theorem relates bipartite ranking regret to re-grets in terms of exponential and logistic loss: Theorem 3.1.
 Theorem 3.1 is very similar to Theorem 4.1 in (Kot lowski et al., 2011), except that the latter involves a normalized version of the bipartite rank loss and so-called balanced loss functions. Nevertheless, in order to show Theorem 3.1, the proof from (Kot lowski et al., 2011) can be adapted quite easily. Here, we omit a de-tailed presentation of the modifications required due to space restrictions. 3.3. Minimizing Rank Loss in MLC The exponential loss and the logistic loss introduced above are commonly used in standard classification. A straightforward extension of these losses to the MLC setting, taking multiple labels and instance weights into account, is given as follows: The minimization of these losses comes down to solv-ing m independent classification problems, one for each label. Any algorithm for classification with exponen-tial or logistic surrogate, such as AdaBoost or logis-tic regression, can be used for this purpose, provided it allows for handling weighted instances. Despite its simplicity and efficiency, this approach provides a con-sistent way of minimizing the rank loss, as shown by the following result.
 Theorem 3.2. Let Reg exp ( h ,P ) and Reg log ( h ,P ) be the regrets for exponential and logistic losses, respec-tively. Then where C  X  m Proof. The idea of the proof is to reduce an MLC prob-lem, conditioned on an instance x , to a bipartite rank-ing problem, which then allows us to exploit Theorem 3.1. More specifically, for a given x , we define a bi-partite ranking problem by setting  X  X = { 1 ,...,m } ; that is, the objects (instances) to be ranked now cor-respond to the label indices of our MLC problem and are of the form  X  x = i , ( i = 1 ,...,m ). Moreover, we define a distribution  X  P on  X  X  X { X  1 , +1 } as follows: that where  X  B ij is defined as:  X  B where the last equality is valid because the term  X  1 i W cancels and because of (8). Using the above and Lemma 3.1, we see that
Reg br (  X  h,  X  P ) = Theorem 3.1 relates Reg br (  X  h,  X  P ) to Reg ` ( being the exponential or logistic loss. What remains, therefore, is to trace back Reg ` (  X  h,  X  P ) to Reg ` where the latter regret is based on the original distri-bution P and the multilabel versions (11 X 12) of expo-nential and logistic loss. The following equalities hold: where we have, respectively, risks based on the mul-tilabel loss and risks based on standard classification loss on the left-hand and right-hand side. Due to (15), we get Taking (16), (9 X 10), and (17) together gives where C = m that W  X  w max , taking the expectation with respect to x on both sides, and applying Jensen inequality E [ f ( X )]  X  f ( E [ X ]) for the concave function f ( x ) =  X  x .
 One might be concerned by the possibly large con-stant C = m ing whether it could perhaps be improved. However, C is indeed expected to appear in the bound and does actually not weaken it. Instead, it only compensates for the difference in the scale of both sides of (13) and (14). Indeed, the rank regret on the left-hand side scales like O ( m 2 W ), while the square root of ex-ponential/logistic regret on the right-hand side scales like O ( O ( m the difference.
 Another question is whether the square-root conver-gence in (13 X 14) could be improved. The answer is negative: Bartlett et al. (2006) already showed for bi-nary classification (which can be casted as a special MLC ranking problem) that the square-root bound is unavoidable in the worst case. This section is meant to look at the result of Gao &amp; Zhou (2011) against the background of our findings so far, trying to support a more intuitive understanding. As mentioned earlier, these authors consider pairwise convex surrogate losses of the form where  X  is a convex, differential, non-linear, and non-increasing function, and show that no such loss is con-sistent for multilabel ranking. Given the existence of pairwise losses that are actually consistent for bipar-tite ranking , this result appears to be surprising at first sight, all the more since, in our proof, we are using a reduction to bipartite ranking, too.
 The reason for inconsistency becomes more apparent when looking at the conditional expected loss:
L  X  ( h ,P | x ) = A necessary condition for consistency is that the Bayes classifier h  X  for  X  -loss is also the Bayes ranker, i.e., To ease understanding, it is again convenient to con-sider the special case w ( y )  X  1, in which the  X -values reduce to conditional probabilities (and, therefore, are more easily interpretable). In our approach of uni-variate loss minimization, (20) is indeed valid: Ac-cording to (6), the equality  X  1 i  X   X  1 j =  X  10 ij holds true. Moreover, by applying a convex loss func-tion  X  , the prediction h  X  i of the Bayes classifier is a nonlinear yet monotone transformation of the condi-tional probability  X  1 i = P ( Y i = 1 | x ): The larger the probability of the conditional class, the larger the score produced by the Bayes classifier. Consequently, sign( h  X  i  X  h  X  j ) = sign( X  1 i  X   X  1 j ) = sign( X  Thus, loosely speaking, our approach guarantees con-sistency because the (Bayes) decision of how to rank two labels  X  i and  X  j , which depends on the sign of  X  ij  X   X  01 ij , remains unaffected by both of our measures: the consideration of univariate marginals  X  1 i instead of the bivariate ones  X  10 ij and  X  01 ij (label dependency does not matter), as well as the transformation implied by the convex surrogate afterward.
 Now, although the first argument of the irrelevance of label dependence does in principle remain valid in case of pairwise loss, consistency is essentially lost in the second step. In fact, the use of a convex surrogate loss has a much more involved effect in the pairwise case, since the (nonlinear monotone) transformation now applies to the differences  X  1 i  X   X  1 j = P ( Y i 1 | x )  X  P ( Y j = 1 | x ) of conditional probabilities instead of the conditionals themselves. Therefore, since each  X  i simultaneously participates in several such differ-ences, the minimization of (19) results in a compli-cated solution h  X  , where h  X  i generally depends on all  X  jk (1  X  j,k  X  m ), and not only on  X  (2011) exploit this observation to show that, for any  X  defined as above, the pairwise marginals  X  10 jk can be chosen such that the Bayes classifier h  X  is not the Bayes ranker. The only case in which (19) admits a simple solution for certain losses  X  is when the labels are independent, and this is exactly the case of bipar-tite ranking, for which consistency is known to hold. We note that Gao &amp; Zhou (2011) (following Duchi et al. (2010)) showed consistency (but not regret bounds and convergence rates) of some specific pair-wise surrogate losses, one of which can be rewritten as a univariate linear surrogate with regularization. To verify our theoretical claims we performed experi-mental studies on synthetic and benchmark data. We measured the performance of the algorithms in terms of the rank loss (4) with weights defined as: w ( y ) = ( s y ( m  X  s y ))  X  1 , where s y = P i y i . (21) This is a popular choice, as the weights are the inverses of the total number of pairwise comparisons between labels. Thus, the value of the rank loss is between 0 (perfect ordering) and 1 (reversed ordering).
 The main goal of the experiment is to verify whether simple algorithms based on univariate surrogate losses (11) and (12) are competitive to state-of-the-art al-gorithms that minimize the rank loss using convex pairwise surrogates (18). Note that minimization of (11) and (12) reduces to solving m independent clas-sification tasks with weighted training examples. In other words, each task is solved by using an algo-rithm that minimizes the ordinary exponential or lo-gistic loss on a set of weighted training examples. We used AdaBoost.M1 to minimize the exponential loss and logistic regression to minimize the logistic loss. We refer to this reduction framework as Weighted Binary Relevance (WBR). We compared WBR with two well-known algorithms for multilabel ranking, Ad-aBoost.MR (Schapire &amp; Singer, 2000) and log-linear models for label ranking (LLLR) (Dekel et al., 2003). These two algorithms seek to minimize the rank loss by using convex surrogates defined on label pairs (18). AdaBoost.MR uses the exponential and LLLR the logistic surrogate. Let us underline that both Ad-aBoost.MR and LLLR use weights (21) in their sur-rogates, so that all the algorithms are tailored for the same performance measure.
 In boosting algorithms, we used decision stumps as weak learners. For AdaBoost.M1, we selected the number of decision stumps from { 10 , 20 , 50 , 100 , 200 } , while for AdaBoost.MR, the total number of de-cision stumps from { 10 , 20 , 50 , 10 2 ,..., 10 4 , 2  X  10 The regularization parameter in logistic regres-sion was tuned in the range { 10  X  3 , 10  X  2 ,..., 10 We ran LLLR with different numbers of iterations should not favor any of the methods, as all algorithms have a single parameter to choose. 5.1. Synthetic Data We designed synthetic data to show a difference in the performance of the algorithms in the cases of label de-pendence and independence, respectively. The model is based on latent variables f = ( f 1 ,f 2 ,...,f m ): where x is a two-dimensional feature vector uniformly drawn from a unit disk, A is an m  X  2 matrix of lin-ear coefficients, and is an m -dimensional noise vector whose coordinates are drawn from N (0 , 0 . 25). The la-bels are obtained from the latent variables according to where M is an m  X  m mixing matrix introducing de-pendencies between labels, and J  X  K applies to each el-ement of the vector separately. A single model is thus determined by the choice of A and M . The indepen-dent label case is obtained for M being the identity I . We generated 10 random models, with rows of A drawn uniformly from a 2-dimensional unit sphere. For each model, we considered the case of indepen-dent ( M = I ) and dependent labels (entries of M drawn independently and uniformly from [  X  1 , 1]). In each case, we trained all 4 algorithms on training sets of different sizes n , varying n from 100 to 16000 exam-ples. For each n , 10 training sets of a given size were generated (thus, there are 100 repetitions for any given training set size n ). For testing, we used a dataset con-taining 50 000 examples.
 The results are given in Fig. 1. We compared the algo-rithms based on exponential loss separately from those for logistic loss. The results shown in Fig. 1 are nicely in agreement with what we expect from our theoret-of label independence, where both pairwise and uni-variate loss minimization are consistent, the methods perform more or less en par. However, in the case where labels are not independent, and hence the pair-wise approach is no longer consistent, our approach of univariate loss minimization shows small but con-sistent improvements. In the case of exponential loss, the picture is not entirely clear, 3 but the univariate approach seems to outperform its competitor based on pairwise loss for large enough training data. Weaker performance of the exponential loss follows from the fact that the stumps used as base learners in boosting do not exactly match the true (linear) model. 5.2. Benchmark Data We also performed an experiment on commonly used benchmark datasets. 4 We chose 4 datasets of moder-ate size, with around 10 labels, and one large dataset with 101 labels and more than 30K training examples. The datasets are described in Table 1. To facilitate comparison of the results presented in this paper, we used the original split for training and test sets. The results are given in Table 2, again separately for dataset #train #test #attr. #lab. min ave. max image 1200 800 135 5 1 1.24 3 emotions 391 202 72 6 1 1.96 3 scene 1211 1196 294 6 1 1.06 3 yeast 1500 917 103 14 1 4.23 11 mediamill 30993 12914 120 101 0 4.36 18 dataset AB.MR WBR-AB LLLR WBR-LR image 0.2081 *0.2041 *0.2047 0.2065 emotions 0.1703 *0.1699 0.1743 *0.1657 scene *0.0720 0.0792 0.0861 *0.0793 yeast 0.2072 *0.1820 *0.1728 0.1736 mediamill 0.0665 *0.0609 0.0614 *0.0472 exponential and logistic loss. The picture conveyed by these results is less clear than it was for the synthetic datasets. In fact, since the true nature of the data is not known (i.e., whether or not the labels are indepen-dent), is is difficult to draw clear conclusions. Never-theless, one can safely say the simple reduction algo-rithms trained independently on each label are com-petitive to state-of-the-art algorithms defined on pair-wise surrogates. Again, this is in complete agreement with our theoretical results. In this paper, we have shown that common univariate convex surrogates are consistent for mutlilabel rank-ing. We proved explicit regret bounds, relating rank-ing regret to univariate loss regret, which not only help to answer the question of consistency, but also inform about the rates of convergence.
 For several reasons, our results should be of interest to the machine learning community. Most notably, because they are arguably surprising in light of (Gao &amp; Zhou, 2011), where inconsistency is shown for the most popular pairwise surrogates. Moreover, on the more practical side, our results motivate simple and scalable algorithms for multilabel ranking, which are plain modifications of standard algorithms for classifi-cation (such as logistic regression or AdaBoost). Acknowledgments. Krzysztof Dembczy  X nski is sup-
