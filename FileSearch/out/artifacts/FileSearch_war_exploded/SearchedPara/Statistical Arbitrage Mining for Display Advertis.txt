 We study and formulate arbitrage in display advertising. Real-Time Bidding (RTB) mimics stock spot exchanges and utilises computers to algorithmically buy display ads per impression via a real-time auction. Despite the new au-tomation, the ad markets are still informationally inefficient due to the heavily fragmented marketplaces. Two display impressions with similar or identical effectiveness (e.g., mea-sured by conversion or click-through rates for a targeted audience) may sell for quite different prices at different mar-ket segments or pricing schemes. In this paper, we pro-pose a novel data mining paradigm called Statistical Ar-bitrage Mining (SAM) focusing on mining and exploiting price discrepancies between two pricing schemes. In essence, our SAMer is a meta-bidder that hedges advertisers X  risk between CPA (cost per action)-based campaigns and CPM (cost per mille impressions)-based ad inventories; it statis-tically assesses the potential profit and cost for an incom-ing CPM bid request against a portfolio of CPA campaigns based on the estimated conversion rate, bid landscape and other statistics learned from historical data. In SAM, (i) functional optimisation is utilised to seek for optimal bid-ding to maximise the expected arbitrage net profit, and (ii) a portfolio-based risk management solution is leveraged to reallocate bid volume and budget across the set of campaigns to make a risk and return trade-off. We propose to jointly optimise both components in an EM fashion with high effi-ciency to help the meta-bidder successfully catch the tran-sient statistical arbitrage opportunities in RTB. Both the offline experiments on a real-world large-scale dataset and online A/B tests on a commercial platform demonstrate the effectiveness of our proposed solution in exploiting arbitrage in various model settings and market environments.
 Statistical Arbitrage, Real-Time Bidding, Display Ads  X  Half the money I spend on advertising is wasted; the trou-ble is I don X  X  know which half.  X   X  John Wanamaker (July 11, 1838 -December 12, 1922) c  X 
A popular quotation from John Wanamaker, a pioneer in advertising and department stores, illustrates how difficult it was to quantify the response and performance in advertising a hundred years ago. Over the last twenty years, advance-ment of the World Wide Web has fundamentally changed this by providing an effective feedback mechanism to mea-sure the response through observing users X  search queries, navigation patterns, clicks, conversions etc. Recently, Real-Time Bidding (RTB) has emerged to be a frontier for In-ternet advertising [27, 17]. It mimics stock spot exchanges and utilises computers to programmatically buy display ads in real-time and per impression via an auction mechanism between buyers (advertisers) and sellers (publishers) [32].
Such automation not only improves efficiency and scales of the buying process across lots of available inventories, but, most importantly, encourages performance driven ad-vertising based on targeted clicks, conversions etc., by using real-time audience data. As a result, ad impressions become more and more commoditised in the sense that the effective-ness (quality) of an ad impression does not rely on where it is bought or whom it belongs to any more, but depends on how much it will benefit the campaign target (e.g., underlying Web users X  satisfactions and their direct responses) 1 .
According to the Efficient Market Hypothesis (EMH) in finance, in a perfectly  X  X fficient X  market, security (such as stock) prices should fully reflect all available information at any time [13]. As such, no arbitrage opportunity exists, i.e., one can neither buy securities which are worth more than the selling price, nor sell securities worth less than the selling price without making riskier investment [18]. However, due to the heavily-fragmented, non-transparent ad marketplaces and the existence of various ad types, e.g., sponsored search, display ads, affiliated networks, and pricing schemes, e.g., cost per mille impressions (CPM), cost per click (CPC), cost per action (CPA), the ad markets are not informationally efficient. In other words, two display opportunities with similar or identical targeted audiences and visit frequency may sell for quite different prices. While exploiting such price discrepancies is still debatable in the advertising field, the following four arbitrage situations exist:
Our discussion is limited to performance driven ads and direct responses such as clicks and conversions only, whereas for the purpose of branding, the quality of publishers still play an important role in defining the ad inventory quality. II Guaranteed delivery and spot market arbitrage.

III Publisher volume I/O arbitrage. A publisher can
IV Pricing scheme arbitrage. In RTB, different counter-
Scientifically, this is of great interest as it presents a new type of data mining problem, which demands a principled mathematical formulation and novel computational solution to mine and exploit arbitrage opportunities in real-time dis-play advertising. Commercially and socially, principled ad arbitrage algorithms would not only ensure the business more smooth and risk free (e.g., III &amp; IV), but also make the ad markets more transparent and informationally more efficient (e.g., I, II &amp; IV) by connecting otherwise segmented markets to correct the misallocation of risks and prices, and eventu-ally reach an  X  X rbitrage free X  equilibrium.

In this paper, we formulate Statistical Arbitrage Mining (SAM) and present a solution in the context of display adver-tising. We focus on modelling discrepancies between CPA-based campaigns and CPM-based ad inventories (IV above), while the arbitrage models for the remaining cases can be obtained analogically. The studied arbitrage is a stochastic one due to the uncertainty of market supply/demand and users responses. The probability distribution of the arbi-trage net profit from an ad display opportunity is estimat-ed by user response predictors [21] and the bid landscape forecasting models [8], trained on historic large-scale data. Essentially, the proposed Statistical Arbitrage Miner is a campaign-independent RTB bidder, which assesses the arbi-trage opportunity for an incoming CPM bid request against a portfolio of CPA campaigns, then selects a campaign and provides a bid accordingly. Different from previous work on per-campaign RTB bidding strategies [28, 34], we introduce the concept of meta-bidder , which performs the bidding for a portfolio of ad campaigns, similar to a hedge fund holding a set of valid assets in financial markets. In our SAM frame-work, (i) functional optimisation is utilised to seek for an optimal bidding function to maximise the expected arbitrage net profit, and (ii) a portfolio-based risk management solu-tion is leveraged to reallocate the bidding volume and budget across multiple campaigns to make a trade-off between arbi-trage risk and return. We propose to jointly optimise those two components in an EM fashion with high efficiency to make meta-bidder successfully catch the transient statistical http://www.milliondollarhomepage.com/ arbitrage opportunities in RTB. Experiments on both large-scale datasets and online A/B tests demonstrate the large improvement of our proposed SAM solutions over the state-of-the-art baselines.
Display Advertising Optimisation. Before the emerg-ing of the auction-based RTB market, most research work on display advertising optimisation is about ad inventory allocation on behalf of publishers in order to maximise the revenue with the guaranteed delivery constraints [2, 14]. The authors in further [3] propose an automatic model for pricing the guaranteed contracts based on the prices of the targeted individual user visits in a spot market. With the arrival of ad exchange and RTB, a lot of work emerges on auction-based optimisation for display advertising. On the publisher side, the placement-level reserve price optimisation is studied in [31]. The authors in [16] suggest that the publisher could act as a bidder on behalf of its guaranteed contracts so as to make smart inventory allocations among the guaranteed and non-guaranteed contracts. One step further, the pricing model of guaranteed contracts with the alternatives of RTB spot market is proposed in [7]. On the advertiser side, the bid optimisation for campaign performance improvement is studied. The authors in [20] propose a budget pacing scheme embedded in a campaign conversion revenue optimisation framework to maximise the campaign revenue. The authors in [28, 34] focus on a bidding function formulation to max-imise the campaign clicks. Bid landscape forecasting models [8] are studied to estimate the campaign X  X  impression volume and cost given a bidding function.

The authors in [5] study auction mechanisms consider-ing arbitrage between CPC and CPM pricing schemes. The study aims for designing an auction mechanism on behalf of the ad exchange and yielding truthful bidding from ad-vertisers and truthful CTR reporting from arbitrageurs. By contrast, our work focuses on developing a statistical method for mining and exploiting arbitrage opportunities between CPA and CPM.

Statistical Arbitrage in Finance. In financial mar-kets, as a trading strategy, statistical arbitrage is a quan-titative approach to security trading. It utilises statistical methods with high-frequency trading systems to detect sta-tistical mispricing of securities caused by market inefficiency to make profit with a large number of transactions [18].
Drawing an analogy with the statistical arbitrage of se-curity pairs trading [15] in finance, in our paper, the cam-paign X  X  CPA contract and its performance in RTB spot mar-kets can be regarded as a pair of correlated securities. S-tatistically speaking, if the campaign X  X  performance in an RTB market ensures that the average cost to acquire a con-version (i.e., eCPA) is lower than the payoff from the C-PA contract, then a statistical arbitrage opportunity exists. Such opportunity could also be considered to be caused by informational inefficiency of the advertising market where the advertisers fail to lower their CPA payoff when their campaigns in RTB spot market have a good performance.
Modern Portfolio Theory in Finance. As Nobel Prize work [24], modern portfolio theory (MPT) originates from modelling uncertainty of the return of financial assets. MPT utilises the mean-variance analysis to make an investment solution for any tradeoff between the expected return and the risk, or w.r.t. a reference investment [29].

Recently, MPT has been introduced into information re-trieval (IR) fields to model the expectation and uncertainty of users X  preference on the retrieved documents for search en-gines [30] or from recommender systems [33]. To our knowl-edge, there is no work adopting MPT into the revenue op-timisation in online advertising. In our paper, we present a novel way of using MPT and it is naturally integrated into our bid optimisation framework.
In this section we formulate and solve the SAM problem in the context of RTB display advertising. Our paper is intended to be self-contained, but for a detailed introduction of RTB and its ecosystem, we refer to [32, 35].
Let us suppose there is an ad agent acting on behalf of advertisers to run their ad campaigns. To hedge advertisers X  risk, quite often an ad agent gets paid on the basis of the per-formance: receive a payoff each time a placed ad eventually leads to a product purchase (cost-per-action, CPA) 3 . Note that it remains active research to determine whether and how much a purchase action is attributed to the previously ads shown to the user. In this paper, we adopt the last-touch attribution model commonly used in the industry  X  the last ad impression before the user X  X  conversion event is assigned with the full attribution credit [9]. To run the campaigns and place the ads, the agent then goes to the RTB market to purchase ad impressions. In RTB, the ad agent pays the cost for each ad impression displayed (cost-per-mille, CPM) on the basis of second-price auction. In essence, the ad agent is an arbitrageur, making a profit so long as the payoff by conversions (CPA) is higher than the cost (CPM) of acquir-ing relevant users to making the purchase. Potentially, the agent could in parallel run a large number of campaigns from various advertisers to scale up their profit. Note that the ad agent builds their business by taking the risk from the uncertainty of market competitions and user behaviours. For the entire ad ecosystem, it is healthy as it protects both advertisers and publishers by introducing an intermediary layer that exploits (and ultimately remove) the discrepan-
A notable example is mobpartner.com who explicitly offers payoffs (CPA deals) for anyone who can acquire the needed customers programmatically.
 Figure 1: An ad agent running a meta-bidder (arbi-trageur) for statistical arbitrage mining. cies between market segments (in this case, the two pricing schemes, CPA and CPM).
 Traditionally, these arbitrages are accomplished manually. With statistical approaches, it is possible that the above operations can be automatically done by an intelligent meta-bidder across campaigns, where for a certain CPA campaign, the meta-bidder seeks cost-effective ad impressions with high conversion possibility and low market competition.

Mathematically, we formulate the problem below: Sup-pose there exist M CPA-based campaigns. Each campaign i has set its payoff for a conversion as r i . Over period T , the meta-bidder keeps receiving bid requests at time t  X  { 1 ,...,T } , where each bid request is represented with high dimensional feature vector x t and if won, it is charged based on CPM. For each of the incoming bid requests, the Statisti-cal Arbitrage Mining (SAM) problem is to select a campaign and specify its bid such that over the period T the expected total arbitrage net profit (accumulated payoff minus cost) is maximised.

We consider the following process. When a bid request comes, the meta-bidder samples campaign i with probability v to participate the RTB auction, where P M i =1 v i = 1. Once campaign i is selected, the meta-bidder then estimates its conversion rate (CVR), denoted as  X  ( x t ,i ), i.e., if the ad is placed in this impression, how likely the underlying user will see the ad and eventually convert (purchase) [21]. After that, the meta-bidder generates the bid price via a bidding function b (  X ,r i ) depending on CVR  X  ( x t ,i ) and conversion payoff r i [34]. The notations are summarised in Table 1; an illustration on how the SAMer works is given in Figure 1.
Given campaign selection probability v and bidding func-tion b (  X ,r ), the meta-bidder X  X  total arbitrage net profit is given by summation over bid requests and campaigns: where w ( b ) is the probability of winning an RTB auction given bid b . Product w ( b ) v i specifies the probability a cam-paign is selected and wins the auction; (  X r i  X  b ) is net profit for the winning campaign. The total cost upper bound is C ( v ,b (  X ,r )) = where bid price b is the maximal possible cost for a campaign to be placed due to the second price auction [31].

Next, we need to model how likely we will see an ad im-pression with feature x t in the future. We assume x p ( x t ); that is for a relatively short period, the bid request feature is drawn from an i.i.d. built from historic data. The whole model needs to be re-trained periodically with the latest data. Detailed empirical study on the re-training fre-quency for dynamic arbitrage will be given in Section 4.4. Taking the integration over x gives the expected net profit:
E [ R ( v ,b (  X ,r ))] = T = T istic relationship between x and its estimated CVR  X  ( x ,i ), also given in [34]. Similarly the total cost is rewritten as
E [ C ( v ,b (  X ,r ))] = T
Finally, the SAM is cast as a constrained optimisation problem: to find campaign selection probability v and bid-ding function b (  X ,r ) to maximise the expected arbitrage net profit with budget and risk constraints: where we use variance Var[ R ] to measure the risk of the net profit and h is a parameter for an upper tolerable risk.
We propose to solve the problem (Eq. (5)) in an EM fash-ion. In particular, the campaign selection probability v is re-garded as the latent factors to infer and the bidding function b (  X ,r ) is regarded as the parameter used to maximise the optimisation target. In E-step, we fix the current estimat-ed bidding function b (  X ,r ) and solve the optimal campaign selection probability v with the constraints Eqs. (7), (8), &amp; (9). In M-step, we fix the campaign selection probability v and seek for the optimal bidding function b (  X ,r ) to maximise the target under the budget constraint Eq. (6). When the EM iterations get converged, all the constraints are satisfied and the target is maximised. The following Section 3.2 will describe the detailed solution of optimal bidding function (M-step), and Section 3.3 will discuss the solution of cam-paign selection probability v (E-step).
With the fixed v and the budget constraint at Eq. (6), we have a functional optimisation problem in M-step: The Lagrangian L ( b (  X ,r ) , X  ) = T Figure 2: Linear winning function w ( b (  X  )) and beta CVR pdf p  X  (  X  ) .

Taking its functional derivative w.r.t. b (  X ,r ), we have  X  L ( b (  X ,r ) , X  )
A sufficient condition of making this derivative be zero is for all campaign i . With the specific functional form of win-ning function w ( b ) we can derive the optimal SAM bidding function. Below we show solutions in two special cases.
Here we make a simple example of linear winning func-tion form (see Figure 2(a)) based on the assumption of the uniform market price 4 distribution in [0 ,l ]: where the function domain is also [0 ,l ]. l is the upper bound of bid price and there is no need to bid higher than l .
Replacing Eq. (15) into Eq. (14) gives the optimal arbi-trage bidding function b sam1 as
To calculate optimal  X  , a sufficient condition of the partial derivative  X  L ( b (  X ,r ) , X  ) / X  X  = 0 in Eq. (12) is
Taking Eqs. (15) and (16) into Eq. (17) gives where if we denote  X   X  R  X   X  2 p  X  (  X  ) d X  , we have
Replacing Eq. (19) into Eq. (16) gives the final solution of bidding function
Market price refers to the highest bid price amongst the competitors for each auction [1]. From a bidder X  X  perspec-tive, it can win an auction if the its bid price is higher than the market price on this auction. where surprisingly the bidding function does not depend on r . This is because the linear forms of w ( b ) in Eq. (15) and b sam1 (  X ,r ) in Eq. (16) make  X  factorised out from r/ (1 +  X  ) in Eq. (18), which in turn removes the factor of r/ (1 +  X  ).  X  depends on the probabilistic distribution p  X  (  X  ), e.g., the beta distribution Beta(2,8) as shown in Figure 2(b), and can be calculated with empirical data.
We now consider a more practical winning function used in [34], which is based on a long tail market price distribution p ( z ) = l/ ( z + l ) 2 with parameter l . As such, the winning function is
The real-world data analysis on winning bids in [34] demon-strates the feasibility of adopting the winning function in Eq. (21) in practice. Taking Eq. (21) into Eq. (14) gives the optimal arbitrage bidding function b sam2 as which is in a concave form w.r.t. CVR  X  .
 Solution of  X  . It is possible that the optimal situation does not exhaust the budget and we can leverage the training data to tune the empirically best  X  as a parameter. However, if we assume that the bid request volume T is large enough to exhaust the budget, then the optimal case is an equality condition for Eq. (11). To calculate the optimal  X  , the Euler-Lagrange condition of  X  is Eq. (17). With Eq. (22), we explicitly regard  X  as an input of bidding function b (  X ,r, X  ) and rewrite  X  L ( b (  X ,r ) , X  ) / X  X  = 0 from Eq. (12) as
In most situations except some special cases like Section 3.2.1,  X  has no analytic solution. For numeric solution, we can rewrite Eq. (23) as
X which has the same solution with the minimisation problem
If we have a very large number N i of observations of  X   X  X  for each campaign i , we can write the above equation as where we can use (mini-)batch descent or stochastic gradient descent to solve  X  by the following iteration:  X   X   X   X   X  , until convergence. Usually, as b (  X ,r, X  ) has a monotonic re-lationship with  X  and w ( b (  X ,r, X  )) monotonically increases lationship with  X  . For example, with the bidding function as Eq. (22) and the winning function as Eq. (21), the fac- X  , which makes the optimal solution quite easy to find.
Fixing the resolved optimal arbitrage bidding function b (  X ,r ) from previous M-step, we can optimise the campaign selec-tion probability v and check whether it is better to reallocate the volume for each campaign.

We here introduce the concept of SAM net profit margin  X  in RTB display advertising. The net profit margin is the ratio of the net profit of the advertising, either from one campaign or a set of them (meta-bidder), divided by the advertising cost during the corresponding period. In fact,  X  = R/C = ROI  X  1.  X  is a random variable with expectation and variance. By modelling  X  i for each campaign i , the optimal campaign selection can be solved by portfolio-based risk management methods.
With optimal arbitrage bidding function b (  X ,r ) by Eq. (14), we calculate the expectation and variance of the net profit margin  X  i for each campaign i by where R i ( v i =1 ,b ) and C i ( v i =1 ,b ) are as in Eqs. (1) and (2) with v i = 1 and v j = 0 for all other campaign j . Both  X  and  X  2 i ( b ) can be estimated from MCMC methods: (i) repeat N times on sampling T bid requests from the training data the expectation and variance using these N observations of R Suppose there are M campaigns in the meta-bidder with CPA contracts. For each campaign i , as discussed in Sec-tion 3.3.1, there is a variable of achieved net profit margin  X  given the bidding function b (), and its expectation is  X  and standard deviation is  X  i ( b ). As such, the vector of ex-pected net profit margins for these M campaigns is and the covariance matrix for the net profit margins of the element where  X  i,j  X  [  X  1 , 1] is the net profit margin correlation fac-tor between campaign i and j , which can be calculated by routine given the net profit margin time series of the two campaigns i and j [24].

We call such probabilistic campaign combination as cam-paign portfolio . With the campaign selection probability v , the campaign portfolio expected net profit margin and its variance are
Generally, the arbitrage net profit margin may change w.r.t. the allocated volume: the more bid request volume, the more Algorithm 1 Statistical Arbitrage Mining for Display Ads statistical arbitrage opportunities, and the higher margin. For simplicity, we assume that the net profit margin dis-tribution does not change much w.r.t. the auction volume allocated to the campaign during a short period. The em-pirical results in Section 4.3 will demonstrate the eligibility of the assumption.
The E-step of the original optimisation problem Eq. (5), with the fixed bidding function and constraint Eqs. (7), (8), &amp; (9), can be rewritten by taking the Lagrangian as where the Lagrangian multiplier  X  acts as a risk-averse pa-rameter to balance the the expected net profit margin and its variance. This optimisation framework is widely used as portfolio optimisation [30, 33].

When the risk, i.e., the variance of the net profit margin, is not considered,  X  is set as 0. Then the campaign i with the highest  X  i ( b ) will be always selected, i.e., v i = 1, while v = 0 for all other campaigns j .

Finally, the overall operations to get the optimal campaign selection probability v and the arbitrage bidding function b (  X ,r ) are summarised in Algorithm 1. Theoretically, just like the EM algorithms for likelihood maximisation, every EM iteration in our case will at least not drop the expected net profit (Eq. (5)). In practice, v and b (  X ,r ) will get con-verged within 5 EM iterations. For E-step, the computa-tionally costly parts are the MCMC methods for evaluating the margin of M individual campaign (Eqs. (27) and (28)), where the time complexity is O ( MNT ), and the campaign correlation calculation (  X  i,j in Eq. (30)), which is O ( M For M-step, the bidding function is derived with closed form; the calculation of  X  by numeric descent methods Eq. (26), which depends on the data values but is normally much ef-ficient. The performance in Section 4.4 will demonstrate the capability of our proposed solution for highly efficient re-training in dynamic arbitrage tasks.
We conduct our experiments 5 based on two real-world large-scale bidding logs collected from two DSP companies.
The experiment code has been published at https:// github.com/wnzhang/rtbarbitrage . iPinYou RTB dataset was published after iPinYou X  X  glob-al RTB algorithm competition in 2014. This dataset con-tains the bidding and user feedback log from 9 campaigns during 10 days in 2013, which consists of 64.75M bid records, 19.50M impressions, 14.79K clicks and 16K CNY expense. The dataset disk size is 35GB. According to the data pub-lisher [23], the last three-day data of each campaign is split as the test data and the rest as the training data. More statistics and analysis of the dataset is available in [35].
BigTree RTB dataset is a proprietary dataset from our partner DSP company BigTree Times Co. This dataset is collected from Nov. 2014 to Feb. 2015 for 3 iOS mobile game campaigns. It consists of 10.85M impressions and 46.38K actions 6 with $0.083 CPA. We use this dataset to train the model and conduct online A/B test on BigTree DSP during Feb. 2015.

Both datasets are in a record-per-line format, where each line consists of three parts: (i) the features for this auction, e.g., the time, location, IP address, the URL/domain of the publisher, ad slot size, user interest segments etc.; (ii) the auction winning price, which is the threshold of the bid to win this auction; (iii) the user feedback on the ad impression, i.e., click, conversion or not.
Evaluation procedure. We adopt the evaluation pro-cedure similar to the previous work on bid optimisation [34, 35]. In addition, for the evaluation related to the campaign sampling process (via v ), we follow an offline evaluation scheme similar to previous work on evaluating interactive systems [22]. As in the historic data, the user X  X  feedback is only associated with the winning campaign of the auction, there is no corresponding user feedback if a different campaign is sampled. As such, based on the bid request i.i.d. assumption made before, for each round, we first sample a campaign i , then pass the next test data record of this campaign to the bid agent for bidding. If there is no more test data left for this campaign, i.e., the bid requests are run out, the test ends.

Budget constraints. It is easy to see that if we set the budget the same as the original total cost in the test log, then simply bidding as much as possible for each auction will exactly run out the budget and get all the logged clicks. In our work, to test the performance against various bud-get constraints, for each campaign, we respectively run the evaluation test using 1 / 2 , 1 / 4 , 1 / 8 ,..., 1 / 256 of the original total cost in the test log as the budget.

Payoff setting. To set up various difficulties in arbi-trage, for our offline experiments, we manually adjust the CPA payoff for each iPinYou campaign. Specifically, for each campaign i , we set a high and a low CPA payoff in order to test the algorithms X  performance under an easy and a hard arbitrage situation, denoted as r easy i and r hard i , respectively: where eCPA i is the original average cost for acquiring each conversion of campaign i in the training data without any ar-bitrage strategy. In addition, the conversion data in iPinYou is unavailable for 7 out of 9 campaigns. To have more tests done, we thus regard the user clicks as a proxy for the desired actions (conversions) in our offline experiment.
According to the advertiser X  X  contract, here the action is defined by users X  landing on the game X  X  page on app store.
To complement the offline tests, in our online experiments, we directly adopt the CPA payoff specified by genuine ad-vertisers to test the real business case.
We compare the following baseline and state-of-the-art bid-ding strategies in our experiment. Their parameters are tuned on the training data.
 Constant bidding ( const ). A constant bid regardless bid Random bidding ( rand ). Randomly choose a bid value in Truth-telling bidding ( truth ). If there is no budget con-Linear bidding ( lin ). In [28], the bid value is linearly pro-Optimal real-time bidding ( ortb ). This is an optimal bid-Statistical arbitrage mining ( sam1, sam2 ). These are the SAM with competition modelling ( sam1c, sam2c ). In
For campaign selection strategies, we compare the uniform campaign selection, i.e., v = 1 /M , and the portfolio -based campaign selection, where portfolio will be denoted as greedy when  X  in Eq. (32) is set as 0. The conventional campaign selection scheme based on internal auctions [32] will be com-pared in online A/B test in Section 4.5.
We use the net profit as the prime evaluation measure, which is calculated as #conversions * cpa_payoff -cost . We also evaluate the net profit margin for each strategy, which is calculated by the net profit divided by the cost. In addition, we report the number of impressions and conver-sions as well as the cost for each strategy.
In Table 2, we report the overall performance on the tested 9 campaigns from the iPinYou dataset. We see that samx bidding strategies outperform all others regarding to the net
The work [6] is on sponsored search with generalised second price auctions. By setting the slot number for each keyword auction as 1 and the CTR as 1.0, the opt bidding strategy can be used for our display advertising scenario.
 Table 2: Single-campaign overall performance.

Figure 3: Single campaign arbitrage performance. profit. sam2 further outperforms sam1 particularly in the hard payoff settings due to its more practical winning func-tion. In addition, samxc strategies still make high arbitrage profit with the market competition modelling, which demon-strates the potential of samx strategies in a real market com-petition environment.

Furthermore, we monitor the performance change on the arbitrage net profit and margin of each algorithm w.r.t. the budget setting in Figure 3. For the page limit, we only report the results with the easy payoff setting, while the results on the hard payoff setting are similar. The value on the x-axis means the proportion of the original total cost in the test data divided by the test budget. The higher the proportion is, the less the budget is. From Figure 3 we have the follow-ing observations. (i) sam1 and sam2 outperform the rest in almost all the profit and margin comparisons with different budget settings. (ii) Under the higher budget setting, e.g., 2 or 4 budget proportions, truth produces comparable profit as samx . This is because when the budget is abundant, the tight budget constraint (i.e., the equation in Eq. (11)) is unnecessary to meet in order to maximise the net profit. Under such situation, the bidding problem will get back to the classic second price auction problem, where the truth-telling bidding strategy is optimal [11]. (iii) Under the lower budget setting, e.g., 64, 128 and 256 budget proportions, the profit from truth drops significantly because of the budget constraint is quite important and the optimal bidding strat-egy is never truth-telling. On the contrary, lin and ortb act almost the same as samx . This is reasonable because under the lower budget settings, the budget is always exhausted. With the cost the same as the budget, the more conversions the more arbitrage profit. We test 6 campaign portfolios from the iPinYou dataset. Each portfolio contains 4 campaigns with the data from the same period. For each portfolio, after the convergence of EM iterations, the empirically optimal v and bidding function b (  X ,r ) are deployed in the campaign portfolio X  X  test stage, where the auction volume and the budget are set as the same as in the training stage. Compared with the previous single campaign part, this part of experiment focuses more on the campaign portfolio selection, where the uniform , greedy and portfolio selection methods are compared.

The overall results with 1/32 budget setting are reported in Table 3. For the comparison among the bidding strate-gies, samx overall outperforms others in both payoff settings. Figure 4 provides more detailed analysis. The profit trend against the budget setting, as shown in Figures 4(a) and 4(b), is consistent with the single campaign setting. The competitor model setting does not significantly drop the ar-bitrage net profit as shown in Figure 4(c). Specifically, when the budget gets lower, the profit drop percentage gets lower. The reason is that fewer auctions are won with lower budget so that the market does not change much. To compare cam-paign selection, Table 3 shows that portfolio selection con-stantly outperforms uniform and greedy selection. Compared with uniform , greedy allocates all the auction volume and the budget onto the campaign evaluated as with the highest arbitrage net profit margin, which theoretically maximises the expected net profit. However, the result that portfo-lio outperforms greedy indicates there exists a return-risk tradeoff point which practically generalises better than the maximum expectation solution. Furthermore, Figure 4(d) shows the change of total profit from the 6 tested campaign portfolios based on sam2 against the portfolio risk-averse parameter  X  in Eq. (32). Here setting  X  as a small enough value is equivalent to the greedy campaign selection. As we can see, as  X  increases from 10  X  3 , the net profit first rises to the peak value and then drops significantly. Among the different budget setting, we can observe a trend from Figure 4(d) that is the more budget, the higher the optimal  X  is. For 1/256 budget setting, the optimal  X  is 0.01, while 0.1 is optimal for 1/4 budget setting. This may be due to the fact that more budget brings more auction volume across a longer period, importing more risk, which is required to be carefully hedged.

In addition, we present a case study on a campaign port-folio (3358, 3386, 3427 and 3476 are four campaign IDs). Its return-risk analysis plot is shown in Figure 4(e) and the corresponding campaign selection probability allocation is shown in Figure 4(f). In Figure 4(e) the dark blue points stand for the expected net profit margin and its standard de-viation for 4 individual campaigns. As we can see, campaign 3358 has the highest expected margin as well as the highest risk while campaign 3386 is the most stable one but with the lowest expected margin. The best empirical portfolio selection is shown as the vertical dashed line in Figure 4(f), where 94.9% auction volume is allocated to campaign 3358 and 4.1% is allocated to campaign 3427. However, if the meta-bidder is more risk-averse, other two campaigns can be included in order to further reduce the standard devia-tion. The parameter  X  in Eq. (32) provides a flexible way to adjusting such risk and return trade-off.
In practice, as the market competition and the user be-haviour change across the time, the meta-bidder should dy-namically change its bidding strategy and campaign selec-tion. In this part of experiment, we test the capability of our proposed sam2 bidding strategy with dynamic campaign portfolio selection over a 72 hour test period. The arbi-trage bidding function and campaign selection probability Figure 5: Dynamic multi-campaign arbitrage net profit distribution with different update frequency. are updated periodically, and we refer the interval between two updates as one round. Specifically, at the beginning of each round, we re-train the arbitrage bidding function and campaign selection probability using Algorithm 1 based on the bidding data collected from previous round. A problem here is that how frequent the update should be? It is ap-parent that if the round period is too long, it is difficult for the meta-bidder to catch the transient statistical arbitrage opportunities; if the round period is too short, the training data could be sparse and the model might overfit the data.
We test the dynamic multiple campaign arbitrage on 5 portfolios, each of which consists of 4 campaigns with the data logged within the same period. For each test cam-paign portfolio, we try the different update frequencies as well as different risk-averse  X   X  X . The box plots [26] of the arbitrage net profit distribution with different update fre-quencies under two payoff settings are shown in Figure 5. From the results we observe that (i) the positive net profit values over all cases demonstrate the capability of sam2 to make dynamic arbitrages. (ii) In both payoff settings, the dynamic SAM (period no more than 24 hours) have much better performance than the static SAM (period equals to 72 hours, i.e., only one update), which indicates the importance of dynamically re-training the models to catch the latest market situation. (ii) Among the different frequencies of dynamic updating, updating every 6 hours leads to the high-est arbitrage net profit. We believe this is a trade-off point between the abundance and recency of the training data. Note that the optimal update frequency may be different for other campaigns or different training settings.
In addition, Figure 6 presents a case study of the 72 hour dynamic 4-campaign arbitrage with the model updated for every 6 hours. In each round, the calculated campaign selec-tion probability (i.e., the volume allocation) from portfolio optimisation, the estimated net profit margin of each cam-paign, the empirical net profit and cost are depicted. We observe that the estimated margin for each campaign varies over time, which results in the change of campaign volume allocation across the time. The empirical profit shows the same trend with the estimated campaign margin, which to some extent highlights the effectiveness of the margin esti-mation in our model. Moreover, the cost in each round (i.e., 6 hours) is different, not necessarily be the average budget allocated for each round. It is possible that if the market is too competitive to make arbitrage profit, the resulting cost and profit could be both much low.
Our SAM algorithm has been deployed and tested in a live environment provided by BigTree DSP. The model training follows the scheme in Section 4.3. Specifically, with Algo-rithm 1, we obtain the empirically optimal sam2 bidding Figure 6: A case study of dynamic multi-campaign arbitrage performance and the corresponding mar-gin estimation and volume allocation.
Figure 7: Online performance on BigTree DSP. function b (  X ,r ) and campaign selection probability v for the meta-bidder based on the 3-campaign training data described in Section 4.1.1, where the hyperparameter  X  in Eq. (32) is set as 0.1. As a control baseline, we deployed another meta-bidder with the basic linear bidding function [28, 21] and the internal auction-based campaign selection scheme [32], denoted as base . During the online A/B test, every received bid request from the router of BigTree DSP will be randomly assigned to either of the two meta-bidders, which returns the bid response, including the selected campaign ad and the bid price, back to the ad exchange for auction. The online test is conducted during 23 hours between 13 and 14 Feb. 2015 with $60 budget for each meta-bidder.

Figure 7 presents the overall online performance of sam and the baseline algorithm base . The online results on the commercial DSP verify the effectiveness of our algorithm in a real commercial setting: sam leads to $30.6 arbitrage net profit with $60 budget, which is a 51.1% margin and a 31.8% improvement over the base bidder setting. An interesting observation is that in spite of the higher CPM, sam brings lower eCPA than base , which ultimately leads to higher arbi-trage net profit. This suggests that despite the market price and arbitrage margin are different across the campaigns, our SAM algorithm would be able to successfully identify and target to the cases that have higher arbitrage margin from those high value impressions (reflected by their high CPM).
In this paper, we conducted the first study on statistical arbitrage mining in RTB display advertising. We proposed a joint optimisation framework to maximise the expected arbitrage net profit with budget and risk constraints, which is then solved in an EM fashion. In the E-step the bid vol-ume is reallocated according to the individual campaign X  X  estimated risk and return, while in the M-step the arbitrage bidding function is optimised to maximise the expected arbi-trage net profit with the campaign volume allocation. Aside from the theoretical insights, the offline and online large-scale experiments with real-world data demonstrated the ef-fectiveness of our proposed solution in exploiting arbitrage in various model settings and market environments. We believe this would open up a whole new set of research ques-tions that intersect between financial methods such as high-frequency trading [15], risk-management [24, 12] and data mining methodologies for display advertising and beyond. In the future work, we plan to further improve the dynamic nature of the SAM model and extend it to mine arbitrage in other domains such as cloud computing and e-commence. Acknowledgement. We thank the engineers Tianchi Zhu, Jie Liu, Lei Gong, Yanjun He and Zhao Yang for helping conduct the online experiment on BigTree DSP. [1] K. Amin, M. Kearns, P. Key, and A. Schwaighofer. [2] A. Bhalgat, J. Feldman, and V. Mirrokni. Online [3] V. Bharadwaj, W. Ma, M. Schwarz, [4] D. Bloomfield. High-speed ad traders profit by [5] R. Cavallo, R. P. McAfee, and S. Vassilvitskii. Display [6] N. Chaitanya and Y. Narahari. Optimal equilibrium [7] B. Chen, S. Yuan, and J. Wang. A dynamic pricing [8] Y. Cui, R. Zhang, W. Li, and J. Mao. Bid landscape [9] B. Dalessandro, C. Perlich, O. Stitelman, and [10] B. Edelman. The design of online advertising markets. [11] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet [12] E. J. Elton, M. J. Gruber, S. J. Brown, and W. N. [13] E. F. Fama. Efficient capital markets: A review of [14] J. Feldman, M. Henzinger, N. Korula, V. S. Mirrokni, [15] E. Gatev, W. N. Goetzmann, and K. G. Rouwenhorst. [16] A. Ghosh, P. McAfee, K. Papineni, and [17] Google. The arrival of real-time bidding. 2011. [18] S. Hogan, R. Jarrow, M. Teo, and M. Warachka. [19] Y. J. Hu. Performance-based pricing models in online [20] K.-C. Lee, A. Jalali, and A. Dasdan. Real time bid [21] K.-C. Lee, B. Orten, A. Dasdan, and W. Li.
 [22] L. Li, W. Chu, J. Langford, and X. Wang. Unbiased [23] H. Liao, L. Peng, Z. Liu, and X. Shen. iPinYou global [24] H. Markowitz. Portfolio selection. The journal of [25] R. P. McAfee and S. Vassilvitskii. An overview of [26] R. McGill, J. W. Tukey, and W. A. Larsen. Variations [27] S. Muthukrishnan. Ad exchanges: Research issues. In [28] C. Perlich, B. Dalessandro, R. Hook, O. Stitelman, [29] W. F. Sharpe. The sharpe ratio. Streetwise X  X he Best of [30] J. Wang and J. Zhu. Portfolio theory of information [31] S. Yuan, J. Wang, B. Chen, P. Mason, and S. Seljan. [32] S. Yuan, J. Wang, and X. Zhao. Real-time bidding for [33] W. Zhang, J. Wang, B. Chen, and X. Zhao. To [34] W. Zhang, S. Yuan, and J. Wang. Optimal real-time [35] W. Zhang, S. Yuan, and J. Wang. Real-time bidding [36] W. Zhang, Y. Zhang, B. Gao, Y. Yu, X. Yuan, and
