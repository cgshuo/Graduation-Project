 1. Introduction
Search engines, such as Ask, Google, Microsoft Live, and Yahoo!, use Internet spiders to index Web pages that users can engines, we must develop better ways to understand searchers X  behaviors.

To analyze searchers X  behaviors, some researchers use specific software on searchers X  computers to investigate searching laboratory studies or client-side monitoring techniques (e.g., Hotchkiss, 2004 ). However, these methods typically involve subjective elements, small number of participants, and have large variance in the results due to sampling bias.
Using the large amounts of searcher behavior information now available on Websites and search engines can address these shortcomings. For example, search engine transactional logs contain significant amounts of useful information con-cerning Web search engine customers as well as customers of other commercial organizations.
A search engine X  X  transactional log is an electronic record of interactions that have occurred during a searching episode between a Web search engine and searchers who are seeking information on that Web search engine (Jansen, 2006, p. 408 ).
Generally, transactional logs contain data such as the client computer X  X  Internet Protocol (IP) address, submission time, searcher query, and vertical searched, among other fields. These huge datasets of recorded Web searchers X  behaviors could events. This potential motivates our research.
 and the quantity of data needed to analyze searchers X  behaviors. However, one needs to subject these logs to rigorous data interactions ( Jansen, 2006 ); however, search logs are temporal streams of information from which one can possibly make within a particular time range, to develop a predictive model for Web searching.

Given that transaction logs record the interactions between searcher and search engine, they are an excellent record of log from the search engine Dogpile ( www.dogpile.com), which is a top 10 ranked Web search engine. Jansen and Spink (2005) have shown that searcher behavior across search engines is very similar, so we believe that the methodology and re-sults of this research will be applicable to a wide range of search engines.
 and the methodology employed. Then, we present our results using transaction log analysis (TLA) reporting on query length,
Average (ARIMA) time series analysis method to do a one-period-ahead prediction on the log data. We then explore relation-ships between different fields in the dataset using the Box X  X enkins model approach. Finally, we provide comprehensive con-clusions and discussion of findings. 2. Literature review
Companies interested in Web searcher behavior face the daunting task of scrutinizing enormous amounts of data. For example, Nielsen/NetRatings measures the search behavior of approximately 500,000 people worldwide ( Sullivan, 2006 ), and transitional logs of this size are significant challenges.
 Some researchers have investigated TLA as an approach for examining both server and client-side interactions (e.g., Park, from research that examines characteristics and interactions with a Korean-based search engine from the perspectives of session length, query length, query complexity, and content viewed among the Web search engines. Results were similar to other search engines, with allowances for searching in Hangul. However, this line of research is primarily descriptive.
Exploring different methodologies that are more inferential, such as developing predictive models using automated data
Heckerman and Horvitz (1998) describe a Bayesian approach to modeling the relationship between words in a searcher X  X  into the Bayesian models.

 X zmutlu, Spink, and  X zmutlu (2002) analyze contextual information in search engine query logs to develop a topic iden-work, and then the neural network was used to identify topic changes in the data log. The researchers report that topics shifts were estimated correctly, with a 77.8% precision in the overall database.
  X zmutlu, Spink, and  X zmutlu (2004) report results from a comprehensive, time-based Web study of US-based Excite and sources with respect to times.

Beitzel, Jensen, Chowdhury, Grossman, and Frieder (2004) review a query log of hundreds of millions of queries that con-query disambiguation, routing, and caching algorithms.
 automatic indexing. Automatic indexing models assume the uniformity of query characteristics; however, this approach might work less effectively in cases where the query characteristics vary with respect to time. It could be beneficial for the development of a new indexing method where the prioritization of the results is altered with respect to when a query is submitted.

Yates, Benavides, and Gonz  X  alez (2006) present a framework for using query logs to identify searcher interest. The
However, with unsupervised learning, one can validate the goals and categories used, refine them, and then select the most appropriate for the searcher X  X  needs.

Although these approaches provide greater insight into the searching characteristics of Web searchers, they still focus the temporal trends inherent in search logs. 3. Research objectives
Our research objectives follow:
If we can detect the dynamic behaviors of searchers through a large amount of online activities, we can force the response into the designed target by changing the Web searching system design factors. Therefore, statistical time series analysis may be a useful technique to analyze transaction logs, provide predictions on searcher behavior, and give guidance for examining searchers X  interactions. Time series analysis could extend existing research to find the relationship among the different aspects of searchers X  behaviors. 2. Identify characteristics of trends in Web search engine usage based on attributes recorded in search engine logs.
Time-based transactional log analysis could be an efficient way to understand searchers X  behaviors. Investigating patterns of Web searchers X  behaviors based on a time series analysis method could provide worthy results on searchers X  daily searching behaviors, which can promote the efficiency of search engines advertisement and information retrieval func-among different fields of information. 3. Isolate predictive relationships among Web search engine usage attributes recorded in search engine logs.
Given that transaction log data is temporal in nature, time series analysis can isolate trends that occur within the data
Times series analysis permits the development of predictive models among attributes in transaction logs. 4. Methodology
In this research, we use statistical time series analysis to examine and develop a prediction model using a Dogpile search engine transactional log. Our goal is to model and analyze searchers X  behaviors on Web search engines over time. Addition-tionships among the different aspects of searchers X  behaviors.

We first discuss the use of a proportional sampling method to reduce billions of records into over a thousand equidistance we use the ARIMA method to do a one-period-ahead prediction on the data and discover relationships among the different engine design, and future research.

Time series analysis detects the internal structure (such as autocorrelation, trend, or seasonal variation) of data points future events based on known past events or to predict future data points before they are measured. A classic example of time series analysis is the opening price of a share of stock based on its past performance.

The basic requirement for the use of temporal data in a time series analysis is that the sequence of data points, measured analysis of rhythmic variance, seasonal adjustment, and abnormal detection. Non-linear dependence on previous data points is also of interest because of the possibility of producing a chaotic time series.

Models for time series data can have many forms. Three broad classes of practical importance are the autoregressive (AR) models, the integrated (I) models, and the moving average (MA) models. These three classes depend linearly on previous (ARMA) and autoregressive integrated moving average (ARIMA) are common combinations of these three models.
An ARIMA model can be expressed as A p ( B )(1 B ) d Y t = C der; and d is the degree of differencing needed to achieve a stationary process.
 cuses on mathematical modeling of systems of a diverse nature and analyzing their dynamic behavior. Using control theory the foundation for control theory by providing a method to detect the dynamic behavior among the data, which is indispens-able to discovering the relationship between interested fields.

This exploration of relationships is also applicable for Web searching. To do this, we use transfer function theory. A tion. The transfer function can be expressed as A r ( B ) Y element equal to 1, and B s ( B ) is a polynomial of order s with first element equal to b output delay.

However, disturbances normally enter into the process and usually are not controllable, in contrast with X is controllable. To model the disturbances, Box and Jenkins (1976) proposed to add a noise term N MA( p , d , q ) of the transfer function model:
One can code this model in statistical software packages, such as SAS and SPSS. In our study, we use the SAS software package version 9 to implement the ARIMA time series analysis. 5. Research design 5.1. Data collection
In this study, we used a Dogpile (www.dogpile.com) transaction log collected on 15 May 2006 and representing a snap-cessing and cleaning (Jansen, 2006 ). Table 1 shows the fields included in this log.
 Additionally, we calculated three extra attributes for each record, presented in Table 2 .

Concerning the searcher intent field, Jansen, Booth, and Spink (2008) define and present a comprehensive classification and automatic identification of searcher intent for Web searching with an accuracy of 74%. They categorized searches based on intent in terms of the type of content specified by the query and other searcher expressions and operationalized these sified Web search engine queries. Using the same implementation approach, we also automatically classified the searcher intent of queries.
 As reported in ( Jansen et al., 2008 ), the algorithm used to classify each query was: Algorithm: Web Query Classification based on User Intent
Assumptions : 1. Transaction log is sorted by IP address, cookie, and time (ascending order by time). 2. Search engine result page requested are removed. 3. Null queries are removed. 4. Queries are primarily English terms.
 Input :
Record R i with IP address (IP i ), cookies ( K i ), query Q
Record R i +1 with IP address (IP i +1 ), cookies ( K i +1 I : conditions of information query characteristics N : conditions of navigational query characteristics T : conditions of transactional query characteristics Variable : B: Boolean//(if query matches conditions,  X  X es X  else  X  X o X )
Output : Classification of User Intent, C begin Move to R i (this module establishes the initial boundary condition) Store values for IP i , K i , Q i , F i , and QL i Compare (IP i , K i , Q i , F i , and QL i )to N If B then C = I While not end of file Elseif Compare (IP i , K i , Q i , F i , and QL i )to T end loop 5.2. Sampling strategy
This processing left us with a dataset of 4,193,956 records, with 13 fields per record. However, even some of the most cords whose unique record identification number X  X  last digit was a one, which is a proportional method to get 10% of the
After getting the proportional sample, we used Matlab connected to a SQL server to do the statistical calculation based on length and the SERP number that the link clicked belongs. 5.3. Selection of time intervals
With time series analysis, we had to ensure that each period we were analyzing had an equal period so that the length of The data are based on the 24-h daily transitional log (from 00:00 to 24:00), which means each time slot contained 80 s.
From this part of the data preparation, we could tell that only the average grouped query length and average rank for each them into numerical indicators. Moreover, we do not use the non-stationary data because we could not predict whether the data would drift away over time. 6. Results 6.1. Basic data analysis 6.1.1. Interactions with the search engine
Fig. 1 shows the number of interactions between the searchers and the search engine within each group used for the time analysis. Namely, the population flow goes up during the daytime and goes down during the nighttime. There were extreme data fluctuations that happened at about the 70th and 270th periods (i.e., a superabundant of submissions at these time start of work period, etc.).

Our results are similar to those in the time-based analysis of the Excite and AlltheWeb search engines studied by  X zmutlu ing their information needs later in the day relative to earlier in the day. 6.1.2. Browser usage
We also analyzed the popularity of different browsers through calculating the number of browsers used among the time through the day. 6.1.3. Vertical accessed
Fig. 3 shows the results from the analysis of the vertical types assessed by the searchers. People use the Web vertical rather than image or audio verticals, and the rate of searching images and audios is not affected by time. Video and news searching was relatively almost non-existent. 6.1.4. Searcher intent reflect the intent of the searcher to perform a particular action like purchasing a car or downloading a screen saver.
Most Web queries belong to the informational level, and transactional and navigational information are a relative small iod, while rates for transactional queries vary during different periods. 6.1.5. Rank of clicked link
Figs. 5 and 6 present the average rank entered by the searchers based on the total number of records and the number of links clicked within each time group. To calculate the data about the number of opened Web pages, we gathered from all the records the rank of clicked links. To calculate the data about the average rank entered by the searchers, we summed up all links entered was six. If we only considered the links that had been opened, the average rank for the links entered was approximately 10.

This result shows that people generally just consider the information shown on the first SERP and usually spend some tell that searchers X  behavior on clicking the links with different rank is not affected by time.
We analyzed the navigation of result pages, which is shown in Fig. 7 , and derived similar findings as from the rank anal-ysis, namely that most people simply look at the first page and do not view SERP after the second page. Moreover, we could ing the different periods. 6.1.6. Query length
Fig. 8 shows that the average length of query per time slot is about 2.9 terms, and the length does not change with the  X zmutlu (2004) is 2.9, and the number reported by Spink, Jansen, Wolfram, and Saracevic (2002) is 2.4. The change in the in prior work ( X zmutlu et al., 2004 ). However, we note extreme outliers at various timeslots. 6.1.7. Clicks on sponsored and organic links Now, we look at the findings concerning the clicking on sponsored links and organic links. From the time series plots (see ingly, from 22:00 to 24:00, people nearly always clicked on organic links instead of sponsored links. During some periods, however, the click thru rate on sponsored links significantly increased, to more than 30%. 6.2. Extended data analysis (Predictive behavior of searchers)
Extending the basic data analysis, we used the time series analysis methodology to calculate one-step predictions as to what would happen from one time slot to the next. As discussed in Section 4, we used Matlab and SAS together to conduct characteristics. 6.2.1. Keywords in the queries follows the ARIMA(1,2) time series model with AR model at lag 1 and MA model at lag 2. Using the minimum mean square ination of the abnormal data: 6.2.2. Average rank of clicked result 1) with one order of differencing, and AR model at lag 1 and MA model at lag 1( A which has AR model with lag 1, integrate model with lag 1 and MA model with lag 1. Using the MMSE estimation, we get the final model as shown in 6.2.3. Predictive model The ARIMA analysis generally will have significant meaning if we find the relationship among different fields of data.
From the basic analysis, we could tell that only average grouped query length (see Fig. 8 ) and average rank (see Fig. 7 ) with the transfer function, we first normalized the original data to ensure a zero mean (see Figs. 15 and 16 ). pattern would show a second-order dynamical process).
 residuals after fitting the transfer function model. We kept fitting the disturbance model until no dynamics showed in the 18).
 by formula (3).

Now, we present the fitted model, which is
From the above model, we see that the output ( average rank ) has a one-period-ahead relationship with the input ( average length ) were more likely to click higher ranked links (i.e., top ranked results) in the following period.
This could explain some people X  X  potential searching behaviors. More importantly, it shows the potential of the time ser-ies analysis approach to investigating and developing predictive models of other behaviors of Web searchers. 7. Discussion and implications
This study analyzed the transaction log from the Dogpile Web search engine in order to explore the characteristics of searchers X  behaviors, validate the use of time series analysis for Web log analysis, and develop a predictive model of Web potential commercial value and demonstrated that time series analysis is both worthwhile and feasible for detecting the trends of search engine customers.

For the basic analysis of this log, we found or confirmed that people use search engines more frequently in the daytime tration of searchers for the search engine within nearby time zones of the Web server.

We also found that people prefer to use the IE browser more than other browsers, and the proportion among different tion of the two. Again, there was no variance due to a temporal factor.

People search for informational needs much more often than they do for transactional and navigational needs. The propor-variance due to time.

Ten percent of searchers look at sponsored links while 90% of searchers look only at organic links. From 22:00 to 24:00, advertising campaigns.

Based on our research results, Web search engine companies can design the information retrieval techniques more effi-ciently and arrange information storage spaces to support these behaviors.

For the extended analysis, we focused on the predictive aspects of two fields, which were average query length and aver-data followed the MA (2) and ARIMA (1,1,1) models for the one-period-step-ahead prediction.

The Box X  X enkin transfer function model shows that these two numeric fields of data have a close, predictive relationship between each other. Namely, if people in a given period typed in fewer query terms, then they were more likely to click on results based on the characteristics of the searcher query.
 icant and insightful results that can impact the development of future Web search engines and can lead to greater under-standing of Web searching. 8. Conclusion and future research this study is valuable for both its results and methodology.

This research has several strengths and important implications. This study extends the existing work in TLA by incorpo-one can identify the relationship among searching attributes across time periods, permitting search engines to generate show that users who enter the shortest queries are more likely to click the top most ranked results. such as a search logs in conjunction with searcher studies or multiple logs across many search engines. References
