 There is an enormous amount of behavioral data generated and stored by billions of individuals across countries and cultures. It has become necessary to use broader combinations of tools to analyze this immense and rich stream of information. The goal is to use this data to gain a better understanding of the systems that generate it. Insight into these systems can help inform the social sciences from economics to sociology as well as provide policy makers with critical answers that may be used to better allocate scarce resources or implement beneficial social programs. In this article, we present a novel application of tools and analytical techniques developed from a variety of disciplines that may be used to identify patterns and signals that capture fundamental dynamics of a social system. To capture relationships in both space and time, cross-and auto-correlation measures are combined with autoregressive models and results from random matrix theory to analyze behavioral data.
 The dataset used in the course of this study consists of criminal events within the City of Philadelphia from the year 1991 through 1999. It contains nearly one-million individual criminal offense reports detailing the time, place, and police response to theft, robbery, and burglary-related crimes. In addition to these minor offenses, for the year 1999, the dataset includes almost every crime, including major offenses, reported in the city from petty theft through homicide. For these reported crimes, we examine spatial, temporal, and incident information. The goal of our analysis is to explore the spatiotemporal dynamics of criminal events with the hope of identifying patterns in their aggregation that may be useful in predicting and preventing future criminal activity. Beyond applications to criminology, however, we feel that these techniques can be applied to a wide range of systems that exhibit complex correlations in many dimensions and on multiple scales.

Existing work from the fields of criminology, sociology, psychology, and economics tends to explore relationships between criminal activity and socioeconomic variables such as education, community disorder, ethnicity, etc. [Weisburd et al. 2009; Lafree 1999]. In general, constraints on the availability of data meant these studies were lim-ited to aggregate statistics for large populations and vast geographic regions. Wilson and Kelling X  X  article in the March, 1982 edition of The Atlantic popularized  X  X roken win-dows X  and  X  X ocial disorganization X  theories that, for the first time, explicitly introduced flow and system dynamics into crime research. These theories proposed that crime was a consequence of urban decay and lack of community ownership in neighborhoods and that these processes worked on a local level [Kelling and Wilson 1982]. Neglected areas not only attract criminals (the neglect is a sign of lack of police presence), but also act as a feed-forward mechanism by damaging community morale.

Following the introduction of these theories, attempts have been made to study crime on the neighborhood level and explore crime  X  X ot spots X  [Sampson et al. 1997]. Some studies have even shifted focus from high crime areas to high risk people, tracking individuals for a period of time and assessing their propensity to commit crime and its relationship to various socioeconomic indicators [Krivo and Peterson 2000]. These studies tend to be small in size and labor intensive, requiring that neighborhoods be surveyed and tracked for long periods of time.

In this research we address a gap. Statistical methods have been used to characterize large, aggregate datasets over long periods of time, while sociological studies have been performed at microscales. There remains a need for a high-resolution quantitative anal-ysis of large crime datasets. Using offense reports generated by a police department, we explore how crime here and now affects crime there and then, while also focusing on building a general set of tools to analyze behavioral datasets for spatiotemporal systems. The dataset is used in two parts. The first contains nearly one-million theft-related crimes from the year 1991 through 1999 while the second consists of almost all two-hundred thousand reported crimes within the City of Philadelphia during 1999 across all types. In total, crimes were reported at 42,000 unique locations across the city and were time stamped with the hour they occurred. In addition to time and place, a detailed description of the crime (i.e., theft under $200, aggravated assault with a handgun, etc.) is provided. A type crime report appears in our dataset as the example from Table I (note this data as been generated randomly for anonymity purposes and is not an actually report). While there are undoubtedly many interesting questions we might ask, the primary goal of this research is to better understand the spatio-temporal structure of criminal events from this data.

The spatial resolution of this data is high enough that a block/neighborhood analysis of crime is possible. Plotting the geocoded events reveals features of the city such as the street-grid, parks, bridges, rivers, etc. (Figure 1). While the time of each report is known to within the hour, offenses within a geographic area are generally aggregated to daily, weekly, or monthly counts, ensuring that time series are sufficiently populated. A time series displaying citywide theft-related crimes for 1999 reveals features on multiple scales. Seasonal trends, such as increases in crime during hot summer months as well as singular events such as holidays are visible (Figure 2). Finally, when applicable, offense reports are aggregated by type (Figure 3) so relationships between crimes can be tested. Though data on crime other than theft are only available for 1999, the two-hundred thousand crimes reported that year still represent a very rich and detailed dataset with which we can examine interactions between different types of crime. Behavioral information must be transformed into variables that can be manipulated numerically. While time and place readily lend themselves to such analysis, the type of crime being reported must be inferred from its police description. While the first part of the dataset contains theft-related crimes only, for richer 1999 data, crimes are aggregated into six broader categories by parsing police descriptions for keywords as described in Table II. Aggregation ensures that there are sufficient numbers of events to populate time series, while still making use of nearly 75% of the data available in that year.

In order to better measure crime densities, a lattice is laid over a map of the city and crimes are aggregated to the nearest grid point. In general, any mesh size can be used; our analysis is performed with 50 X 100 grid locations across the city. This spac-ing roughly corresponds to neighborhood and census track sizes, allowing for possible comparison to demographic census tract data. For every lattice point, a time series is constructed for each category when data is available. With nearly ten years of data available, time scales from hours to years are examined. These time series are nor-malized to have zero mean and unit variance to make use of various statistical tests and to capture changes in crime rates rather than the absolute number of incidents. Overall, the time series produced are mostly stable and stationary, having roughly constant mean and variance. Those that have obvious serial correlations are removed from analysis. Using the conditioned data, we will develop analytical tools to achieve the following. (1) Identify both spatial and temporal relationships. (2) Choose the best scale on which to examine these relationships. (3) Interpret the source of the correlation structure.

To address these goals, we combine time-series analysis with results from random matrix theory to quantify the magnitude and significance of correlation in the data. In the process, we draw upon knowledge of similar problems found in neuroscience (correlating spike-train data) and financial economics (finding signal in noisy time-series data) [Kami  X  nski et al. 2001; Mayya and Santhanam 2007; Tumminello et al. 2010; Laloux et al. 1999; Plerou et al. 2002].

Though many methods for detecting correlation in space and time exist, the nature of criminal acts and the type of data being used lent itself to the particular tools used in this article. For example, while we are looking for correlations in space, it is important that techniques are able to detect nonlocal correlations, wherein two neighborhoods on opposite sides of the city are similar in crime profiles because of socio-economic reasons despite being separated geographically. For this reason, we rule out models that can capture only local diffusion. Multivariate auto-regressive (MVAR) models that regress time series of a particular location onto other locations and across many lag periods can detect such a structure, but given the extremely large number of spatial locations and the length of time series, these models quickly become too large and intractable [L  X  utkepohl 2007; Wooldridge 2008].

There is an additional desire to speak of specific details of the correlation structure rather than just the distribution of crimes in space or time. Models concerned with speciation in heterogeneous landscapes may provide insight into properties of the distribution of phenomena or events in nonlinear environments (population density, socio-economic factors, etc.), but they have more difficulty telling stories of particular realizations of these distributions.

Finally, there is also the problem of noise. Our dataset, while large, is very noisy and any tools and methods used must be able to find and separate signal with confidence. The methodology that follows has the advantage that there is both an analytic as well as computational null model. Random matrix theory provides analytical results on the limiting distributions and statistics of covariance matrices, while artificial crime data can reliably be simulated using a poisson process in order to achieve a compu-tational null model. With these considerations in mind, the following algorithm and methodology was combined to satisfy our modeling and statistical requirements. We begin by using basic data analysis techniques and statistics to better understand the data. In general, crime is not distributed uniformly across the city. Instead, the spa-tial structure is consistent with descriptions of crime  X  X ot spots. X  These hot spots are small regions within the city that regularly experience above average levels of crime. Characterizing the nonuniform spatial distribution of crime is important when at-tempting to find relationships between types of crime. For example, North Philadelphia has a high-density of drug-related crimes, while Center City Philadelphia is a hotbed for theft. We wish to use quantitative tools to measure interactions between locations.
In the time domain, we can identify general periodicities within the data through basic Fourier analysis. Ignoring space for a moment, we consider the city in its entirety, creating a time series of citywide crime sampled hourly. From these methods we can quantify distinct seasonal trends. Cycles exist from hourly to yearly scales. These periodicities visually coincide with time series showing increases of crime during hot summer months, or decreases in certain types of crime on weekends that produce weekly trends. Cycles on smaller scales such as days may come from differences in night and day crime rates and hourly frequencies may be due to police procedure. This analysis, however, is blind to any measure of auto-or cross-correlation that may occur between locations within the city.

Running basic regressions on these citywide time series a number of interesting observations are made. Regressing citywide drug offenses on day of the week, for example, reveals significant correlation. Considering only the day of the week, we are able to account for nearly 60% of the variance in daily drug offenses (Table III). With Sunday being the omitted group, coefficients on dummy variables corresponding to Monday X  X aturday are interpreted as the change in criminal activity between Sunday and that particular day of the week. Thus we conclude Sunday X  X  have the lowest drug-related crime rates while the middle of the week (Tuesday, Wednesday, and Thursday) show the highest. This is in sharp contrast to violent crimes, which show an increase on weekends, dropping during weekdays. We also note that violent crimes are 4 X 5 times more frequent than drug crimes.

While in absolute terms most crime occurs during weekdays, observation of these inverse relationships for certain types of crimes reveals the need to carefully choose the amount of aggregation applied to analysis. It remains unclear, however, if these rela-tionships exist because of some fundamental differences in those committing drug offenses versus violent offenses, or of they are some artifact of police strategy or organization.

We also note that environmental factors have small, but statistically significant impacts on crime rates. Using daily weather records in 1999 as kept by the National Oceanic and Atmospheric Administration (NOAA), we are able to regress crime rates on environmental factors. While these effects aren X  X  overwhelmingly strong, they are statistically significant. We find that temperature increases can be associated with an increase in crime and that precipitation leads to a decrease. Comparing the coefficients of these effects for different crime types, we find interesting differences.
In order to compare coefficients between crimes that occur with differing frequency, we regress the log of occurrences on both temperature and precipitation. The coeffi-cient then represents the percentage change in crime rates due to an increase of one degree Fahrenheit or one inch of precipitation, respectively. We find that drug-related crimes, which may be driven by psychological or physiological needs, are not affected by weather, while violent crimes, which may be driven by passion and environment, respond significantly to increases in temperature or precipitation.

Though these basic statistics provide insight into the types of relationships that exist within the data, they remind use that complex relationships exist on multiple scales in both space and time. We continue with more advanced methods, capable of teasing these relationships out despite noisy data. In order to perform higher-resolution analysis, we make use of the scalable lattice described in previous sections. Having laid this lattice over the city, we create a time series for each point. The time series are then normalized. We select two time series, y 1 and y 2 , from the conditioned data and look for correlations between them. The cross-correlation, r 1 , 2 , is a measure of similarity between a pair of time series. Mathematically, this quantity is defined as the expectation of the inner product between determine lagged correlation by shifting one series by a number of lags, m. The lagged cross-correlation, r 1 , 2 ( m ), is given by modification to the previous formula, r 1 , 2 ( m ) =
The cross-correlation values are normalized to lie between  X  1 and 1, where r 1 , 2 = 1is corresponds to exact correlation between two time series. A cross-correlation sequence is defined as the sequence of cross-correlation values over a range of lags. Examining the cross-correlation sequence for two time-series, we can identify the existence of a significant relationship as well as quantify its power over a number of lags. Not only can these measures detect the flow of crime from one area to another, they can also quantify its speed and direction.

We must also define a plausible test for significant correlations to differentiate be-tween real and random connections. To achieve this, we create a null model for each pair of time series. Each series is randomly permuted, preserving the mean and distribution of counts, but scrambling the order and this any correlations in time. The new cross-correlation value is then computed. Repeating this process a large number of times, we construct a distribution of cross-correlation values from which confidence intervals can be constructed. If the cross-correlation between the original time series deviates from the random distribution at a given confidence level, we consider it significant.
These cross-correlation methods may be used to look for relationships between crimes. We may ask if an increase in theft-related crimes leads to violent crimes in the future. For a given node, we create a time series of daily crime rates for each type of crime for the year 1999. Next, we construct the cross-correlation sequence for this pair of series across a number of lags (in most cases lags up to 30 days were included). To visualize these correlations we create a matrix where each column represents the cross-correlation sequence for a given location (Figure 6).

As an example, we have included automobile thefts in both the  X  X hefts X  category and the  X  X utomobile X  category. Unsurprisingly, we see significant correlation between the two crime types at exactly zero lag. The lack of significant correlation for other time lags indicates no other significant relationships where theft in one location leads to violence in that same location at a later time.
 Having established a measure of correlation and corresponding null mode1 to asses significance, we seek to couple this analysis with spatial dimensions. We would like to detect correlations not only in time, but also in space.

To do this, we form a K  X  T matrix, Y , where K is the number of time series taken from the location and T is the length of each time series. Keeping track of which location each time series corresponds to, we can associate real city locations with correlations. The delayed correlation matrix for a specific lag m , C ( m ), is then constructed by matrix multiplication C ( m ) = 1 T YY T ( m ), where T is a regular matrix m = 0 corresponds to zero lag.

To illustrate this procedure, we test for correlations in drug-related offenses be-tween different neighborhoods across time over the year 1999. Conditioning the data as described before, time series are constructed for 35 lattice points. These points are neighborhoods with enough crime to sufficiently populate daily time series. The zero-lag cross-correlation measuring real-time correlation is displayed in Figure 7(a).
Entry C ij of this matrix represents the cross-correlation between the time series of drug-related crimes from locations i and j . Examining this matrix, no strong patterns or regions of high correlation are immediately visible. It should be noted that the number i and j correspond to time-series labels and not actual location coordinate, but the labeling of neighborhoods is such that locations i and i + 1 are usually close spatially. Further more, when applying the tests for significance outlined in the previous section, we find that very few of these correlations can be deemed significant from random correlation.

The unstructured correlation matrix suggests that daily neighborhood crime rates may not be highly correlated spatially. This example, though, does not consider any lagged correlations that may exist between locations. Constructing matrices for lagged cross-correlation of up to 30 days (1 month), however, reveal similar results. We do not find any immediate spatial correlation structure or flows across space and time for daily drug-related crime levels.

The lack of correlation structure only shows an inability to visually identify corre-lation structure on daily time scales, but says nothing of correlation structure on the scale of weeks and months. Performing the same analysis using weekly theft crime rates from 1991 through 1999, Figure 8(b) reveals much more significant correlation. When comparing lagged cross-correlation matrices over a number of lags cycles of high correlation match yearly seasonal trends seen in Fourier spectrum, but with added spatial resolution.

Even on short time scales, however, the data is noisy enough that identifying signif-icant patterns may be difficult given a largely random background. To quantify the varying degrees of correlation in the matrices, we enlist solutions to similar problems found in fields such as financial economics (markets, stocks, equities, etc.) and climate forecasting [Tumminello et al. 2010; Laloux et al. 1999]. Work in these areas suggests that the correlation structure of systems can be characterized by exam-ining the eigenvalue spectra of correlation matrices. Much success has been found test-ing the significance of these metrics using results from Random Matrix Theory (RMT).
To test for nonrandom structure in our correlation matrices, we consider two related groups of matrices, Gaussian and Wishart. Entries of a Gaussian matrix, G , are drawn from a standard normal and a Wishart matrix, W , is formed by matrix multiplication of a Gaussian matrix and its transpose, W = GG T [Edelman 1988]. The key observation is the direct analogy between formulation of the Wishart matrix and cross-correlation matrix. We use these random matrices as null models to our cross-correlation measures.
Various analytical results for the distribution of eigenvalues of a random Wishart matrix can be found in Edelman [1988], Sengupta and Mitra [1999], and Utsugi et al. [2004]. The eigenvalue density,  X  (  X  ), is defined as the density of eigenvalues below  X  . Given a correlation matrix whose entries are drawn from the standard normal distribution, the eigenvalue density as K and T go to infinity is given by the Marcenko-Pastur Law where Q = T / K  X  1and  X  max mi n = 1 + 1 / Q  X  2 1 / Q [Laloux et al. 1999].
In other words, we can establish significant correlation structure by comparing eigen-value spectra from the data to those of a random null model. If we find eigenvalues significantly outside theoretical thresholds, we conclude there is signal buried in the noise. The eigenvectors associated with these significant eigenvalues are then inter-preted as individual factors contributing to the correlation structure of the system. For example, the largest eigenvalue (and corresponding eigenvector) in the case of financial data is identified as the  X  X arket X  factor, having equally weighted components. Mayya et al. have obtained similar analytical results for lagged cross-correlation matrices [Mayya and Santhanam 2007]. Examining the eigenvalue spectrum of our daily drug data from 1999, we find a weak signal. The spectra corresponding to the correlation matrix of drug-related crimes is shown in Figure 8(a). While the majority of eigenvalues cannot be distinguished from noise, there does exist a large significant eigenvalue.

Next we examine the spectra for a series of lagged correlation matrices. Plotting the magnitude of the largest eigenvalue for each lagged correlation matrix and comparing this to the largest value expected from random data, we see a strong cyclic signal with a period of 7 days (Figure 8). This analysis suggests that significant correlation structure is present on a weekly cycle.

In addition to the magnitude of eigenvalues, we also examine the distribution of com-ponents within each eigenvector. Again borrowing from results in financial economics, we adopt use of the Inverse Participation Ratio (IPR) to examine the component struc-[Biely and Thurner 2008]. A large IPR implies that only a few components contribute to the eigenvector, while a small IPR indicates participation of many components. It is possible to determine clustering structure from such analysis. For example, in fi-nancial data, the eigenvector corresponding to the large  X  X arket X  eigenvalue has a low IPR, identifying itself as a force that affects all stocks equally. Other eigenvectors, with larger IPRs, have components that correspond to various sectors of the market [Biely and Thurner 2008]. For crime data, these components correspond to locations across the city so a cluster of eigenvector components would correspond to a cluster of neighborhoods.

Examining the IPRs for significant eigenvectors in lagged correlation matrices, our results show that the eigenvector corresponding to the largest eigenvalue has a low IPR and can thus be interpreted as a  X  X arket X  force. For the remaining significant eigenvectors, we find that they too have low IPRs, suggesting there is little clustering or community structure (Figure 9).

Remembering the strong correlation found between day of the week and the number of reported crimes from basic regressions outlined before, we find that it is possible recreate this eigenvalue signal by constructing artificial time series using the regres-sion coefficients from Table III and a Poisson random number generator. Beyond this single, large market eigenvalue, we cannot distinguish any other significant structure in the spectrum of correlation matrices generated by daily drug-related crime rates. Having identified the only a small correlation structure occurring on the scale of days, we next look at crime on a weekly scale. As shown in Figure 8(b), much more pronounced correlation exists. For this data, we construct 108 time series corresponding to locations across the city. Examining the eigenvalue spectrum for the zero-lag correlation matrix of weekly theft data from 1991 X 1999, we find more significant eigenvalues than in the daily drug data (Figure 10).

Again looking at the IPR values for these eigenvectors, we find that the large market eigenvector persists, but now there are other significant eigenvectors (both above and below the predicted min and max) that tell different stories. Figure 11(a) shows eigen-vectors associated with large eigenvalues generally have low IPRs that correspond to factors that influences more spatial regions, while significant small eigenvalues have the highest IPRs, suggesting they are generated by a acting on only a few components (locations around the city).

Looking closer at the eigenvectors that contribute to the information contained in our correlation matrices, we examine the components of each, u i = ( u 1 , u 2 ,..., u k ). The theoretical distribution of components as derived from RMT is a normal distribution with zero mean and unit variance [Plerou et al. 2002].
For the correlation matrices of weekly theft time series from  X 91 X  X 99 at 108 city loca-tions, Figure 11(b) compares the component distribution to the theoretical distribution. We find that the eigenvector associated with the largest eigenvalue has nearly all pos-itive components. Coupling this with the low IPR, we see why it is possible to identify it as a market force. It has a large positive bias across all locations of the city. Other significant eigenvectors also have nonuniform distributions. We compare these to an eigenvector from the random part of the spectrum that shows good agreement with RMT results.

In order to accurately quantify and interpret structure in the remaining significant eigenvalues, we must first remove the dominating influence of the largest. Because the strong  X  X arket X  eigenvector acts as on all locations across the city with the same bias, we can recreate this global influence by projecting the citywide crime time series onto the eigenvector u 108 . 1 This time series can be viewed as an estimate of citywide crime based on the most prominent factor. Denoting the original normalized time series as y ( t ), we construct the projection. Comparing this time-series with the original weekly citywide crime we find strong agreement over nearly ten years of weekly data with the correlation coefficient of
Y ( t ) Y 108 ( t ) = . 95.
Having established a reasonable proxy for the market forces acting on crimes rates at all locations, we regress the location time series on this global force to and use residuals that are free from its influence. For the time series associated with each location y i ( t ), we perform the following regression where  X  i and  X  i are location-specific fit parameters. The residual time series, ( t ) are then used to compute the same correlation matrices and spectral analysis as described previously, but this time with the absence of global trends.

We now take the significant eigenvectors of the residual correlation matrices and examine their component structure. Large components of specific eigenvectors corre-spond to locations across the city that are all similarly biased by whatever force is associated with the vector. When we plot the largest 10% of components for the re-maining significant eigenvectors geographically, we find that large components of each vector are strongly correlated spatially.

Figure 12 shows the spatial distribution of large components for different residual eigenvectors. The vector associated with the second largest eigenvalue, u 107 , acts pri-marily on neighborhoods in high crime areas near south-central Philadelphia, while the next largest is made up of three neighborhoods located on different edges of the city. Taking the random eigenvector, u 87 , we see that the locations are distributed more uniformly in space.

Analysis on this weekly reveals a rich structure spatially. Performing similar pro-cedures using monthly time series reduces the amount of correlation, suggesting that the weekly time scale is the correct choice for analysis of neighborhood crime trends.
The problem of scale selection is one that can be dealt with naturally given the algo-rithms applied in this article. While Fourier analysis, regressions, and cross-correlation measures all give indications as to the amount of signal in the data, none provided our analysis with a satisfactory selection of scale. For example, the largest frequency in the FFT of citywide theft counts is found at once-per-three-hours. This result most likely has something to do with police procedures such as shift changes, but selecting the hourly scale for all subsequent analysis would surely return time series too noisy and unpopulated for use.

By using results from random matrix theory as a null model, we can easily measure how much signal can be distinguished from noise by observing eigenvalues above predicted maximums. Furthermore, changes in both spatial and temporal scales affect this spectrum in the same way: increasing or decreasing the number and magnitude of significant eigenvalues. We can select scales by sweeping over time from hours to months, and space from a small lattice to a large one, and track only the number and magnitude of significant values. Selecting the combination that maximizes these deviations allows us to extract that most signal from noisy data, aggregating as much, but not more, than necessary.

We can refine these statements even further by noting that whatever social phenom-ena is behind these significant eigenvectors (or principle factors), they are independent in some way. Whatever force is driving crime rates in the locations corresponding to large components of the second eigenvector is separate enough either in cause or manifestation from the force behind the third vector. This is a level of interpretation currently not offered by the majority of tools aimed at explaining causal relationships. The underlying social dynamics of these factors, however, remain unknown, a point we hope to address in future work. What is important, however, is that this analysis suggests that there is good reason to treat crime differently within different neighbor-hoods and policing strategy may be improved by introducing more local autonomy into strategy.
 In this article, we have presented a novel application of quantitative tools from fields such as mathematics, physics, and signal processing that can be used to analyze spatial and temporal patterns behavioral datasets. Basic analytic and statistical techniques revealed periodicities and cycles within the data that were then explored further by higher-resolution techniques. Due to a low signal-to-noise ratio, we adopted results from random matrix theory to construct a suitable null model to construct significance tests. These tests revealed definite structure in the eigenvalue spectra of our correlation matrices.

Given the large portion of daily crime rates that can be explained by regressing data onto the day of the week, it is possible that these results reflect police procedures such as scheduling more officers on Mondays than Sundays. Differences in high crime days across types of crime, however, may suggest different types of crime may represent unique aggregate behaviors. Another interesting result from our analysis is the lack of correlation between these different crime types. Broken windows and social disorgani-zation theories postulate that an influx of minor offenses such as graffiti and vandalism might lead to an increase of more serious crimes such as assaults or gun violence. We find no evidence of this. This is not to say, however, no relationship exists. Due to data constraints, we have only looked for interaction on time scales of up to 30 days. It may be that these types of flows happen on the monthly or yearly time scale.

With ten years of theft crime data, we are able to look for correlations on a weekly scale. Examining the eigenvalue and eigenvectors of correlation matrices, we perform a sort of principle factor analysis where significance is determined by comparison to results from random matrix theory. We find that the largest eigenvalue and corre-sponding eigenvector can be interpreted as a citywide force that acts on all locations equally.

Removing the influence of this dominating factor, we find a number of significant eigenvalues and vectors. Examining the component structure of these eigenvectors, we find that they correspond to neighborhoods or sets of neighborhoods that share correlated crime rates. We draw an analogy to similar methods used in the analysis of finance markets where the eigenvalue spectrum also contains a  X  X arket X  influence, and other significant eigenvalues are associated with specific industries and market sectors. The added value in this type of analysis is the ability to identify correlations due to different eigenvectors as representing independent forces.

We believe there is valuable policy and prevention insight to be gained from this work. We have demonstrated that daily crime rates are of little use when attempting to find significant correlation structure, while weekly crime rates may be a much richer choice. Along with the selection of a proper time scale, we have identified sets of neighborhoods whose crime rate are driven in sync. These connections are not entirely visible to simple correlation measures and may include neighborhoods at opposite ends of the city. They can also be attributed to different forces suggesting policy that work in certain areas may not be relevant to others. Adoption of police procedures that take these relationships in account may lead to more effective law enforcement.

Aside from the results gained by using these techniques on crime data, we hope that they can and will be put to use in more situations calling for multiscale analysis. Not only do they prove reliable even given very noisy data, but there are strong theoretic and experimental null hypotheses to verify the significance of results. Already, these methods have been shown capable of performing reliable factor analysis of financial markets and crime rates, two very complex behavioral systems.

In the future, we hope to extend these results to find components of temporal cor-relation as well as the spatial structure shown here. Incorporating lagged correlation matrices may shed light on lead-lag relationships in the spread of crime across the city.
