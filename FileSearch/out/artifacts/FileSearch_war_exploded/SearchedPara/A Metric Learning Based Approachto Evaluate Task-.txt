 Evaluating time series similarity has been an important research problem and plays a very crucial role in many data mining algorithms. There is a considerable amount of methods for measuring the similarity between time series. Generally speaking, these methods evaluate the similarity based on surface patterns of time series: two time series are more similar if they share more similar surface patterns. For example, DTW [1] and LCSS [2] applies dynamic programming technique to capture common patterns which allows for time shifting between the two time series. These methods are widely used and serve as a foundation in various data mining tasks such as [3,4].

However, these methods are usually developed in a general setting but not based on the specific tasks. Take time series classification as one example, the major aim is to identify the discriminative patterns between inter-class time series. A good similarity evaluating method should not only capture large intra-class similarity of time series but also discriminate inter-class time series. Many applications have their own specific focus and characteristics, therefore general methods for evaluating time series similarity may not work well in specific tasks.

To address this problem, a promising resear ch direction is to develop task-specific similarity evaluation methods for time series. That is the research topic we focus on in this paper. Specifically, we take time series classification as the major task and study a real task: user churn prediction for online games. We take real data of a very large Chinese online game platf orm, i.e., Renren Games 1 . For each user, we can observe multiple time series each of which corres ponds to the records of a feature within a given time span, e.g. daily online playing time. Our problem can be summarized as follows: given a time series consisting of log information from a user, we would like to judge whether it is from an normal user or an abnormal user who will churn from current game later.

To model task-specific time series similarity, we turn to a widely adopted technique in machine learning community, i.e. metri c learning. Metric learning aims to learn a linear transformation of the original feature space (or learn a Mahalanobis distance metric) based on the specific objective func tion which is derived from specific tasks. Metric learning methods can be formulated in either a supervised (or semi-supervised) or an unsupervised way. In a supervised way, most metric learning methods attempt to learn a distance metric from side information which is often available in the form of pairwise constraints, that is, pairs of similar data points and pairs of dissimilar data points [5]. The information of similarity or dissimilarity between a pair of examples can be easily collected from the labeled information in supervised classification. We follow the supervised approach of metric learning an d try to incorporate task-specific labeled information. With labeled information, we expect the derived metric can better adapt to our churn prediction task.

In this paper, we propose two novel methods based on metric learning to evaluate task-specific time series similarity. The first model is formulated to capture global sim-ilarity constraints (i.e. must-links between all the instance pairs within the same class), and global dissimilarity constraints (i.e. cannot-links between all the instance pairs from different classes). Compared to the first model, the seconde model is formulated in a local way. For each data instance, we build homogeneous and heterogeneous neigh-borhood and only model constraints between it and the other instances from its neigh-borhood. We construct our evaluation set based on real Renren Online Game data and we select several state-of-the-art time series similarity evaluation methods as baselines. Extensive experimental results show that our proposed methods are very effective. Time Series Similarity Evaluation. There is a large body of existing techniques for measuring the similarity between different time series. The Euclidean measure sums the Euclidean distance between points in each time series. Recently, dynamic program-ming based measures are shown to be both effective and efficient, include Dynamic Time Warping(DTW) [1], Edit distance with Real Penalty(ERP) [6], the Longest Com-mon Subsequence(LCSS) [2], and Edit Distance on Real sequences(EDR) [3]. Another line is to use dimension reduction techni ques, such as Singular value decomposition (SVD) [7] and Discrete Wavelet Transform [8]. They are closely related to our meth-ods since the essence of our methods is dime nsion reduction, too. To the best of our knowledge, these methods usually work in an unsupervised way and it is difficult to incorporate useful task information.
 Time Series Classification. Time series classification h as been an important topic and attracted much attention from research communities [9,10,4,11]. Although many algo-rithms have been proposed, it has been shown [10] that k -nearest-neighbor ( k -NN), especially when k =1 , with Euclidean distance is a very robust baseline and difficult to beat. Our major focus is not to propose new methods for time series classification but examine whether the task-specific similarity can improve the classification performance or not. Therefore, we follow the method presented in [10], using k -NN as our classi-fier. By combining the classifier with differ ent similarity measures, we can compare the classification performance and c heck which measure performs best.
 Metric Learning. Our methods are highly built on the related research of metric learn-ing [12,5,13]. The most prominent form of metric learning is to learn the Mahalanobis metric. Its computation can be seen as a two-step process: in the first step we perform a linear projection of the instances and in the s econd step we compute their Euclidean dis-tance in the projected space. Since many dat a mining algorithms rely on the underlying similarity measure, metric learning provides a principled approach to automatically de-rive a reasonable measure according to speci fic tasks. In this paper, our focus is how to adapt existing metric learning methods to evaluate task-specific time series similarity. We focus on the task of time series classification. In this section, we propose two metric learning algorithms to evaluate task-specific time series similarity 2 .
 a time series of length L represented as a column vector, where each value  X  s i is a real number on the i th timestamp. Let Y denote the label set. Without loss of generality, we consider the two-class classification problem, i.e. Y = { +1 ,  X  1 } , where  X +1 X  denotes a training set of N labeled examples (or data instances) with a time series of s i as input and corresponding class label y i  X  X  .Let S test = { ( s i ) } M i =1 denote a test set of M unlabeled examples for which we would like to predict the class labels. We further assume that examples in training set and test set are of the same length L .
The essence of metric learning is to learn a Mahalanobis distance which is defined as follows where  X  is defined to be a symmetric positive semi-definite matrix of size L  X  L .Since  X  is a symmetric positive semi-definite matrix, we can find a non-square matrix W of size L  X  l , with l  X  L , such that  X  = WW T . Then the Mahalanobis distance where x i = W T s i is a transformed time series of length l . Thus W actually defines a mapping from the original input space to a low er dimension space. In this way, learning an optimal distance metric is equivalent to finding an optimal projection matrix. We expect the similarity derived on the projection space can help improve the performance of time series classification.

In the following, we present the proposed methods for evaluating task-specific time specific task, and incorporate them into the metric learning framework. The first method is to consider these constraints on the entire data set while the second method is to consider these constraints onl y based on each example X  X  neighborhood. 3.1 Global Metric Learning With the labels attached to each time series, we can define two sets of constraints called as must-link and cannot-link respectively, denoted by M and C : Our main idea is to maximize the average dis tance between inter-class examples but minimize the average distance between intr a-class examples. We define the objective function as follows where d  X  (  X  ,  X  ) is the Mahalanobis distance between two time series defined in Eq. 1 ,N M and N C represent the numbers of must-links and cannot-links respectively. We can see the above equation tries to seek a trade-off be tween a small average intra-class distance and a large average inter-class distance.

By substituting  X  with WW T , we can expand Eq. 2 as follows With some derivations, we can further rewrite  X  with the help of trace operator in linear algebra where tr(.) denotes the trace of a matrix, C and M are constraint matrices defined as Based on the above discussion, we can formulate our global metric learning algorithm as where the constraint W T W = I is to restrict the scale of W . The solution to Eq. 3 is the largest l eigenvectors of C  X  M and the optimal value of the objective function is the sum of the largest l eigenvalues of ( C  X  M ) [5,14]. We denote this method as GMLS (Global Metric Learning for evaluating time series Similarity). 3.2 Local Metric Learning In the above method, given an example, we have to consider the distance constraint or inter-class distance. The assumption is a bit too restrictive, indeed, an example is not necessarily similar to all the other examples which have the same label. To relax the assumption, we further propose a local metric learning method for evaluating time series similarity, denoted as LMLS .

We still use previous must-link and cannot-link constraint sets, but only consider these constraints between examples in a local neighborhood. First, we propose two kinds of neighborhood, namely cannot-link neighborhood and must-link neighborhood . We u s e N C i to denote the i th time series X  cannot-link neighborhood which consists of k nearest time series of s i with different labels. And we use N M i to denote the i th time series X  must-link neighborhood which consists of k nearest time series with the same label. We can apply previous time series similarity measures to build the neighborhood of a time series, in this paper, we use Euclidean distance due to its simplicity and ef-ficiency. With these definitions, we can define the discrimination criterion for the i th time series as which tries to make time series with the s ame label more compact and those with dif-ferent labels more diverse in a local neighborhood.

By going through all the examples in the training set, we can learn an optimal dis-tance metric by maximizing the following objective function Similar to GMLS, with the substitution of  X  = W T W and the application of trace trick, we can rewrite our objective function as where tr(.) is the matrix trace and C N and M N are neighborhood based constraint matrices defined as Based on the above discussion, the distance metric learning problem can be formulated as The solution of W is the biggest l eigenvectors of ( C N  X  M N ) . In this section, we present experimental setup and results. 4.1 Experimental setup Construction of the Test Collection. We construct the test collection using the real data from  X  X uan Shi Tian Xia X , a popular online game issued by RenRen Games 3 .We study an important task in online gaming service: churn prediction of users. In this task, a label  X +1 X  indicates  X  X ormal user X  while a l abel  X -1 X  indicates  X  X hurn users X . Given a user, the server keeps her log information of various features within a time span, e.g., per day X  X  playing time, which can be represented as a time series. With a time series as input, our task is to predict whether it is from an normal user or a churn user. Therefore, the task of churn prediction becomes time series classification.

In this paper, we consider a two-month time span: from June 1st, 2012 to July 31st, 2012. A user is considered to be active if he has logged to play this game at least 40 days in this time span. We only focus on active users and extract their log information of various features. Then we examine the log of August, 2012: if a user did not log to play game anymore, she is labeled as a churn user; otherwise, she is labeled as an normal user. Finally, we randomly select 500 normal users and 492 churn users.
By discussing with domain experts from Ren ren Games, we select six major features which are potentially important indicators to user churn behaviors. We summarize basic explanations of these features in Table 1. So for each user, we can generate six time series corresponding to daily activity statistics of these six features. Note that all the log information is accurate to day, and all the time series over these two months are of length 60. We scaled each time series by dividing the its largest numeric value. We totally have 992  X  6 = 5952 time series with labels and we further group these time series by features. For each feature, we randomly partition the data set into five folds, four folds are used as the training set , and one fold is used as the test set . Methods to Compare. In this paper, our major focus is to examine whether task-specific similarity measure can beat general similarity measures for time series clas-sification. We adopt k -NN as the classifier and compare the performance with different measures. We consider a few widely used methods to evaluate time series similarity. The first baseline measure is the Euclidean measure (EUC). Then we consider dynamic programming based methods include Dynamic Time Warping (DTW) [1], Edit distance with Real Penalty (ERP) [6], the Longest Common Subsequence (LCSS) [2], and Edit Distance on Real sequences (EDR) [3]. We select these methods since they are shown to be effective and efficient. Among these five baselines, Euclidean distance and ERP are metric, and they obey triangle inequality, which is an important property for indexing [3]. Note that our distance learning method naturally leads to measures which are met-ric 4 . For non-metric measures, it has been shown that EDR is more robust to noise than DTW and LCSS [3], in this paper, we also have similar findings, so we only report the results of EUC, ERP and EDR due to the space limit. Besides these baselines, we also consider a few dimension reduction methods for time series similarity as comparisons: Singular value decomposition (SVD) [15] and D iscrete Wavelet Transform (DWT) [8]. These two methods are unsupervised dimension reduction methods. SVD seeks a low-dimension representation for original time series, to achieve this , we use all the data for SVD. These similarity measures have some parameters to tune. We use a grid search method to find the parameter setting which leads to the optimal average performance using five-fold cross-validation.
 Evaluation Metrics. We use the following widely adopted measures for classification: Recall , Precision and F1 score . For each feature, we compute the values of these three metrics and only report the results of F1, since using the other two metrics lead to similar findings. Finally, we further average F1 scores of these six features. 4.2 Experimental Results Performance Comparison. In Table 2, we present the results of k -NN classifier with different similarity measures. To check the stability of different measures, we vary the neighborhood size k in k -NN. We can have the following observations: 1) The value of k affects the performance of all the si milarity (distance) measures. k =10 gives the best performance and the re sults are relatively stable when k&gt; 10 . 2) Among all the baselines, EUC performs worst. EDR and SVD overall work better than others. The reason why SVD performs well may be we perform it on the entire data set, including training set and test set. 3) LMLS performs best in terms of average F1 scores. By zooming into the de-tailed results for single feature, we can see that LMLS performs best for the first three features while GLMS performs best for the las t two features. Note that the major dif-ference between LMLS and GLMS is that LMLS only considers distance constraints between an example of training set and corresponding examples in its neighborhood while GLMS considers distance constraints in the entire training set. It indicates that for some features we need large neighborhood to capture correlation between examples where GLMS is more suitable, but overall a localized neighborhood is more effective since it only considers the distance constraints between very similar examples in the original space. 4) All the methods achieve their optimal performance on the feature group , i.e., the number of groups that a user is engaged in the game. We have tried merging the time series of six features into a long time series, and then performed the classification task for all the methods. The corresponding optimal performance for each method is not significantly better than that is obtained based on only the feature group . It indicates group is a very important feature in collaborative online games.

Our proposed methods GMLS and LMLS nearly achieve all the optimal performance for these six features, and LMLS achieves the best average F1 score. It indicates the effectiveness of our proposed algorithms. Different from EDR and ERP, GMLS and LMLS do not explicitly consider local time shifting in the original time series. GMLS and LMLS first project time series into a ne w space where the task-specific objective function can achieve (local) optimal (i.e., Eq. 3 and 4), and they have more flexibility to adapt to specific tasks. Our methods provide a principled approach to incorporate task-specific information into time series similarity measures while general measures cannot do it at all.

Since the performance of k -NN classifier depends on the size of training set, we vary the size of training set to see how it affects different methods. We fix k =10 in the k -NN classifier since we have found that it gives corresponding optimal performance for all these methods. Recall we have divided the entire data set into five folds, we random select one fold as test data and then vary the size of training set. We present the results in Table 3. We can observe that LMLS still performs best in terms of average F1 score and the performance increases with more training data. An interesting thing is that baselines achieve their best with 3-fold training data. A possible explanation is that these baselines are general measures which do not rely on training data so that we may not obtain better performance with more training data.
 Efficiency Analysis. In practice, efficiency is an important issue for time series mea-sures. DTW, ERP, LCSS and EDR are dynamic programming ways to compute the dis-tance between two time series. Given two time series of length L , these algorithms have the same time complexity: O ( L 2 ) ; our methods GMLS and LMLS have the time com-plexity O ( L 2 l + l ) ,where l is the dimension number in the projected space and usually much smaller than the original length L . For GMLS and LMLS, we have the additional cost to learn transformation matrix W . Given the size of training set is N , the time complexity for learning W is O ( N 2 L + L 3 ) for GMLS and O ( N 2 L + N log N + L 3 ) for LMLS, where O ( L 3 ) is the time cost for solving eigenvectors. Although the cost is high when L is large, given a task, we can learn W in an offline way and compute the time series similarity in an ef ficient online way. In our task, for each feature, we need to learn a particular transformation matrix W for 992  X  4 5 = 793 time series in training set. We implement LMLS and GLMS in Python, and the total running time to learn W on the entire data set for six feature are 252 . 2 seconds and 577 . 5 seconds respectively for GLMS and LMLS.
 Qualitative Analysis of Our Method. To get an intuitive idea of why our method works, we select four example time series: two are from normal users while the other two are from churn users. Given a time series x , we can project it to a low-dimension space, i.e., x = W T x . We set the projected dimension number to 10. We present the original times series and the corresponding transformed time series in Figure 1. We can see that our methods clearly capture a few important discriminative patterns for both classes. We also present the pairwise distance before and after the transformation in Table 4. We can see that after transformation, our method results in much smaller intra-class distance while inter-class distance does not change too much.
 Parameter Tuning. There are two parameters to tune in LMLS: size of local neigh-borhood k local 5 and projected space dimension number l . We first find the optimal pa-rameter setting using a grid search method: k local =10 and l =5 . Then we fix one parameter and then vary the other. We present the results in Figure 2. In Figure 2(a), we can see our method generally works well when k local &gt; 5 . In Figure 2(b), we can see our method achieve good performance when l is set to a small value, e.g., 5 and 10. Dealing with Unequal-Length Time Series. Until now, we only focus on time series of the same length. In practice, the length of time series can be varying. In this part, we examine how the performance of our methods on unequal-length time series. We randomly select 1 3 of examples in training set and test set. We remove the first 20 entries in the original time series, so these time series only have 40 entries. We select ERR and EDR as comparisons since they perform well and can deal with unequal-length time series. Since metric learning cannot deal with unequal input in essence, we turn to a heuristic method. We add 20 zero entries at the beginning of these 40-length time series, therefore these time series have the length of 60 again. We present the results in Table 5. We can see that all the methods perform worse compared to the performance on equal-length time series, but our proposed method LMLS still perform best in terms of average F1 score. It indicates the robustn ess of LMLS. Indeed, LMLS does not capture simple surface patterns but can reveal the dis criminative patterns in the latent space. We will investigate more principled methods to deal with unequal-length time series in the future. In this paper, we investigate how to develop task-specific time series similarity mea-sures. We adopt metric learning as the principled approach to evaluate time series simi-larity. The major merit of metric learning is that we can seek a distance function which helps improve the performance of the specific task. We propose two metric learning based methods: one is based on global metric learning and the other is based on lo-cal metric learning. We use the data from a large online game and study the problem of user churn prediction. Given a user, we extract the information of six prominent fea-tures from user logs and build corresponding time series for each feature in a two-month time span. Our task is defined to be time series classification, i.e., given a time series from a user, we want to predict whether it is from a normal user or a user who would churn later. We adopt k -NN as the classifier and select a few widely used similarity measures as comparisons. Extensive experiments show that our proposed methods are very effective.

Although there are a large body of studies on evaluating time series similarity, they seldom consider task-specific information, e.g., supervised information, when develop-ing similarity measures. Our study provides a promising solution to this problem and we believe our work will inspire more follow-up studies.

There can be two promising directions to improve current work. First, in real online games, the data set is usually imbalanced, we can consider designing the new objec-tive function which can deal with imbalanced classification, e.g., incorporating class weights. Secondly, the current work can be extended to deal with semi-supervised clas-sification in the case when very few labeled instances are available.
 Acknowledgments. The authors are partially supported by RenRen Games Grant QXWJ-YX-201206017 and NSFC Grant 61272340, 61073082. Xin Zhao was sup-ported by Microsoft PhD Fellowship (Asia). We thank the three anonymous reviewers for their insightful comments.

