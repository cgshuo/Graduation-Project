 As thousands of web news are posted on the Internet everyday, it is a challenge to retrieve, summarize, classify or mine this enormous repository e ff ectively. Keyphrases can be seen as condensed represents of web news documents which can be used to help these applications. However only a small minorities of documents have author-assigned keyphrases and manually assigning keyphrases for each document is very laborious. Therefore it is highly desirable to extract keyphrases automatically. In this paper we consider this task in web news scenario.

Most existing work on keyphrase extraction from a web news document only con-siders the internal information, such as the phrase X  X  Tf-idf, position and other syntactic information, which neglects the external information of the document. Some researches also utilize background information. For example, Wan and Xiao proposed a method, which selected similar documents for a given document from a large documents cor-pus, to improve the performance of keyphrase extraction [14]. Mihalcea and Csomai used Wikipedia to provide background knowledge for this task [11]. However both of these work needs to retrieve topic-related documents as external information, which is a non-trivial problem. Fortunately, nowadays many web news sites provide various so-cial tools for community interaction, including the possibility to comment on the web news. These comments are highly related to the web news documents and naturally bound with them. The motivation of our work is that comments are valuable resource providing background information for each we b news document, especially some use-ful comments contain rich information which is the focus of the readers. Hence, in this paper we consider exploiting comments inf ormation to improve keyphrase extraction from the web news documents.

Unfortunately, although the main entry and its comments are certainly related and at least partially address similar topics, they are markedly di ff erent in several ways [16]. First of all, their vocabulary is noticeably di ff erent. Comments are more casual, conver-sational, and full of jargon. They are less carefully edited and therefore contain more misspellings and typographical errors. There is more diversity among comments than within the single-author post, both in style of writing and in what commenters like to talk about. Simply using all the comments as external information does not improve the performance of keyphrase extraction (see section 5.2). Therefore, we propose several methods to select useful comments, based on some criterions such as textual similarity and helpfulness of the comment. The experimental results show our comment selection approaches can improve keyphrase extraction for web news. Especially our machine leaning approach which integrates many f actors of comments can significantly improve this task.
 The rest of this paper is organized as follo ws. Section 2 introduces the related work. Section 3 describes the framework of our approach to extract keyphrases from a web news document. In section 4 we propose the strategies for selecting useful comments. Section 5 presents and discusses the evaluation results. Lastly we conclude the paper. Most existing work only uses the internal information of a document for keyphrase ex-traction. The simplest approach is to use a frequency criterion (or Tf-idf model [12]) to select keyphrases in a document. This method was generally found to give poor perfor-mance [3]. However, Hasan recently conducted a systematic evaluation and analysed some algorithms on a variety of standard eval uation datasets, his results indicated that Tf-idf remained o ff ering very robust performance across di ff erent datasets [4]. Another important clue for keyphrase extraction is the location of phrase in the document. Kea [2] and GenEx [13] used this clue for their studies. Hulth added more linguistic knowl-edge, such as syntactic features, to enrich term representation, which were e ff ective for keyphrase extraction [5]. Mihalcea and Tarau firstly proposed a graph-based ranking method for keyprase extraction [10] and cu rrently graph-based ranking methods have become the most widely used approaches [3,8 ,9]. However, all the approaches above never consider the external information when extracting keyphrases.

Another important information, which can be used for keyphrase extraction, is ex-ternal resource. Wikipedia 1 has been intensively used to provide background knowl-edge. Mihalcea and Csomai used the link structure of Wikipedia to derive a novel word feature for keyphrase extraction [11]. Grineva et al. utilized article titles and the link structure of Wikipedia to construct a semantic graph to extract keyphrases [3]. Xu et al. extracted the in-link, out-link, category, and inbox information of the documents related the article in Wikipedia for this task [15]. All approaches using Wikipedia significantly improve the performance of keyphrase extraction. Another external resource is neigh-bor documents. Wan and Xiao proposed an idea that a user would better understand a topic expressed in a document if the user reads more documents about the same topic [14]. He used a textual similarity measure (e.g., cosine similarity) to find documents topically closed to the document from a large documents corpus. These neighbor doc-uments are beneficial to evaluate and extract keyphrases from the document. However using the external resource introduced above needs to retrieve topic-related documents, which is a non-trivial problem. Unlike these resources, we exploit comments of web news as external information. This information is topic-related to the original docu-ment. Moreover, the characteristic of naturally bound with the original news makes the comments easier to obtain. A web news document has two parts: an article and comments. The article contains the text of event written by the author. Comments can be seen as the discussion of the article including the attitude of readers. Most of comments are topic-related to the article. Especially some comments contain rich information which is focused by the readers. We call the comments, which provide additional information for readers to better understand the content of the article, useful comments . Intuitively, these useful comments are expected to be beneficial to evaluate and extract the salient keyphrases from the article. However traditional keyphrase extraction methods only consider the information of the article and ignore its comments information. This study we propose an approach exploiting comments informatio n to improve keyphrase extraction for the web news documents.

Figure 1 gives the framework of our approach for keyphrase extraction. First we segment a web news document into the article part and the comments part based on its natural structure. Next, since not all comments are helpful for keyphrase extraction (see section 5.2), we use a comments selector , based on some strategies, to select useful comments from the comments part. Then we in tegrate the selected comments with the article part to form a new document. At last we use a keyphrase extractor to extract phrases from the new document. The extracted phrases, occurred in the article, are taken as keyphrases. Our approach can be easily incorporated with any state-of-the-art keyphrase extractor to extract keyphrases from web news.

Since some comments contain noise information such as advertisement, irrelevant texts and texts only containing meaningless word emoticons. For example, a comment  X  X ho cares! X  just reflects a reader X  X  attitude to the news without any useful informa-tion for other readers to understand the article. Hence, the key point of our approach is to find the useful comments for keyphrase extraction. We propose three strategies to select useful comments, which are expected to find the article X  X  keyphrases with higher accuracy. The first is selecting comments which is similar to the original article, called Similar Comments Selector . The idea of this approach is the same as Wan and Xiao [14]. Many web news sites provide ratings setting about the comments for other readers (e.g, thumb up or thumb down votes). These meta ratings information can help filter useful comments more e ffi ciently. We call the approach based on ratings information Helpfulness Comments Selector . Furthermore, since existing technologies of natural language processing and machine learning provide strong supports to mine the poten-tial knowledge, we use these technologies to select useful comments, called KeyInfo Comments Selector . Next section we will introduce the three comments selectors in detail. 4.1 The Similar Comments Selector Wa n and Xiao proposed a method to select similar documents for a given document to improve the performance of keyphrase extrac tion [14]. Their assump tion is that multiple documents within an appropriate cluster context usually have mutual influences and contain useful clues, which can help to extract keyphrases from each other. For example, two documents about the same topic  X  X art hquake X  would share a few common phrases, e.g.  X  X arthquake X ,  X  X ictim X , and they can pr ovide additional knowledge for each other to better evaluate and extract salient keyphrases from each other.

The similar comments selector adopts the same idea to find useful comments. Firstly it uses the widely used cosine measure to evaluate document similarity between the web news article and its comments. The term weight is computed by Tf-idf. Then the selector chooses top N comments with the highest similarity values as the useful comments for the web news keyphrase extraction. 4.2 The Helpfulness Comments Selector Due to the lack of editorial and quality control, comments on web news vary greatly. The low-quality comments may hurt the pe rformance of keyphrase extraction. Many web news sites also allow readers to vote for the helpfulness of each comment and provide a function to assess the quality. The helpfulness function h is usually defined as follow: where Num thumbup is the number of people, who consider the comment is helpful. Num thumbdo w n is the number of people, who consider the comment is unhelpful. This function actually provides a direct and convenient way to estimate the utility value of a given comment. Therefore, we use the helpfulness of comments based on this function to select useful comments. The top N comments with highest scores voted by at least 5 users are selected for the following keyphrase extraction step. 4.3 The KeyInfo Comments Selector A simple idea is that given an article, if the comments include more keyphrases, they are more likely to be useful comments than the other comments which have less or no keyphrase, since these comments contain more information which the readers focus on. Intuitively, integrating these useful comments into original article is expected to im-prove the performance of keyphrase extrac tion. However, we can not obtain the accurate number of keyphrases in each comment, since it is the final purpose of the task. Fortu-nately, some factors of comments are related to the probability of comments containing more keyphrases such as the textual similarity and helpfulness of comments. Moreover, existing natural language processing technologies can help us find many factors related to the probability of comments containing ke yphrases, and using machine learning tech-nologies, based on these factors, can also estim ate the probability accurately. Therefore, we propose another comments selector called KeyInfo comments selector using natural language processing and machine learning technologies.

The principle of the KeyInfo comments selector is that if a shorter comment contains more keyphrases, it is more likely to improve the performance of keyphrases extraction from the web news when integrating it into the original article. We define a function k called keyInfo function as follow: where Num ke y phrase is the number of keyphrases in the comment and Num w ord is the number of words in the comment. We choose the top N comments with highest score of k as the useful comments for keyphrase extraction.

The key point of this approach is to predict the value of Num ke y phrase .Wetake this prediction as a regression-learning problem. Firstly, some web news and their comments are collected as training data. These news documents have been originally annotated keyphrases. Then using these gold standard keyphrases, each comment X  X  Num ke y phrase can be easily obtained. Some features, which can potentially help to pre-dict the Num ke y phrase , are designed for each comment. Next each comment is repre-sented by a feature vector. Then a classical regression tool-simple linear regression (SLR) implemented in WEKA 2 is used to train a prediction model, called KeyInfo model. Lastly, give a new comment represented as a feature vector, this model can pre-To the features for each comment, textual si milarity and helpfulness are not enough. Since the most similar comments are similar to the original entire news article text, the probability of containing keyphrases in each part of the article text, however, is di ff er-ent. For example, the headline of article, the beginning and the end part of article may have higher probability than another parts of text. If a comment is more similar to these key parts of the article, it is more likely to be useful comment for keyphrase extrac-tion. Additionally, for the comments with high score of helpfulness, the phenomenon of  X  X ich-get-richer X  might hurt the performace of this approach. The reason is that, how fast a comment accumulate votes depe nds on the number of votes they already have [7] and this led to a bias to the comments with more user voting. Therefore, we develop more features, based on natural language processing technologies, for the Key-Info model. These features are designed to m aintain the advantages and overcome the disadvantages of two approaches introduced above. Table 1 shows all the features for the KeyInfo Model. All developed features are classified into five categories: Structural , Similar , Lexical , Syntactic , Semantic ,and Meta-data .Weuse Stanford Log-linear Part-Of-Speech Tagger 3 to tag the comment and use General Inquirer 4 for sentiment analysis. We empirically evaluate our approach for keyphrase extraction from a web news docu-ment, especially comparing the performance of various strategies to select useful com-ments for this task. In addition we conduct in-depth analysis of the di ff erences among useful comments sets chosen by di ff erent comments selectors. 5.1 Experimental Setup The AOL Corpus. We construct our own keyphrase extraction data set by collecting 60 web news posted on the AOL websites 5 . All these news are world news posted from November 16th 2010 to November 26th 2010. Every news document contains at least 20 comments. The main reason we choose AOL web news for the experiment is that every web news document has its own tags. We take the tagged phrases that occur in the article as gold standard keyphrases. Table 2 provides an overview of the AOL corpus. Evaluation Metric. For the evaluation of keyphrase extraction results, the automatic ex-tracted keyphrases are compared with the gold standard keyphrases. The precision p = are used as evaluation metrics, where count correct is the total number of correct keyphrases extracted by the extractor, count extrator is the total number of automatic extracted keyphrases, and count g old is the total number of gold keyphrases.
 The Keyphrase Extractors. Most state-of-the-art keyphrase extractors can be used in our approach. Hasan conducted a systematic evaluation and analysed many unsu-pervised keyphrase extraction methods on a variety of standard evaluation datasets. He found that Tf-idf and SingleRank extractors give very robust performance across di ff erent datasets [4]. Therefore, we use these two keyphrase extractors in our experi-ment. A publicly available implementation of these two extractors can be downloaded 6 .
Tf-idf Keyphrase Extractor assigns a score to every term in a document based on its frequency (term frequency, tf) and the number of other documents containing this term (inverse document frequency, idf). Given a document the extractor first computes the Tf-idf score of each candidate word, then ext racts all the longest n-grams consisting of candidate words and scores each n-gram by summing the Tf-idf scores of its constituent unigrams, and finally output the top N n-grams as keyphrases.

SingleRank Keyphrase Extractor is expanded from TextRank Keyphrase Ex-tractor [10,14]. Both of these two extractors take a text represented by a graph, in which each vertex corresponds to a word type and the edge connects two vertices if the two words co-occur within a window of W words in the associated text. The goal is to compute the score of each vertex, which re flects its importance. The two extractors use the word types that correspond to the highest-scored vertices to form keyphrases for the text. Some graph-based ranking algorithms such as Google X  X  PageRank [1] and HITS [6], which compute the importance of vertices, can be easily integrated into the TextRank model and SingleRank model. There are some di ff erences between these two extractors. First, each edge has a weight e qual to the number of times the two corre-sponding word types co-occur within a window of W words in a SingleRank graph, while each edge has the same weight in a Tex tRank graph. Second, SingleRank only uses high score sequence nouns and adjectives words to form keyphrases, but any high score sequence words can form keyphrases in TextRank. 5.2 Evaluation of the Proposed Approaches First we investigate all the comments information can help keyphrase extraction. We integrate all comments into their related articles in our AOL corpus to form a new dataset. We extract 20 keyphrases in each news document for evaluation using Tf-idf Keyphrase Extractor and SingleRank Keyphrase Extractor respectively. Table 3 shows the result. We can see that, compared the approaches extracted keyphrases from original article ( Base Tf-idf and Base SingleRank ), the approaches adding all com-ments into the article ( All Tf-idf and All SingleRank ) decrease the performance of extracting keyphrases. We conducted a paired t -test between the results of these meth-ods and found statistically significant di ff erences (at p = 0.05). All these means simply using all comments can not help for keyphrase extraction.

Next we investigate some useful comments can help keyphrase extraction. We ranked all the comments based on keyInfo function k . We use the gold keyphrases in each article to calculate the accurate Num ke y phrase value for each comment. For each web news document, we choose the top 15 comments with high value of k and integrate them into the original article (called Oracle Tf-idf and Oracle SingleRank ), which achieve the best result of keyphrase extraction in our experiment (see Table 4). Moreover, they are oracle tests and the results are significantly di ff erent (at p = 0.05). It means there is a subset of useful comments, which can help for keyphrase extraction, in comments part for each web news (see Figure 1).

At last we investigate the performance of our three comments selectors, choosing top 15 high score comments, for keyphrase extraction. The Similar Tf-idf (SingleRank) and Helpfulness Tf-idf (SingleRank) methods used the measures of comments X  sim-ilar and helpfulness score to choose the comments. To KeyInfo Tf-idf (SingleRank) approach, we used 5 new AOL web news comments excluding AOL corpus to train a regression model, which can predict the Num ke y phrase of each new comment. The 5 new documents contain 524 comments and each document has gold standard keyphrases. We extract all features in Table 1 to represent each comment as a feature vector for training. The trained model can be used to predict the KeyInfo score of a new com-ment. Table 5 gives the comparison results of various selecting methods for keyphrase extraction. We can see that the performance of most methods integrating comments outperform the Base Tf-idf(SingleRank) for keyphrase extraction. It shows comments information indeed can help for keyphrase extraction. We conducted a paired t -test be-tween the results and found all methods significantly improve the keyphrase extraction (at p = 0.05) except Helpfulness Tf-idf . Especially the KeyInfo Tf-idf (SingleRank) achieves the best result. It shows similar and helpfulness information are helpful for se-lecting useful comments. Moreover, using more knowledge, extracted based on natural language processing and machine learning technologies, can collect more useful com-ments. All these shows exploiting comments information are e ff ective for keyphrase extraction.

We are interested in the detail of comment s selected by these three selectors. We compare three selected comment sets with the comments selected based on the accurate Num ke y phrase value (see Oracle Test). All of comparisons use the top 15 high score comments for each document. Table 6 gives the result. We can see that the KeyInfo selector collect the largest most useful co mments. It demonstrates our machine learning approach is e ff ective to find more comments with high function K value for keyphrase extraction.
 In this paper we propose a novel approach to use comments information for keyphrase extraction from web news documents. Since comments are full of noisy and low-quality data, simply integrating comment into an original article does not improve the perfor-mance of this task. Therefore we give three strategies to select useful comments. The ex-perimental results show that our comments selection approaches can improve keyphrase extraction from web news. Especially our m achine leaning appro ach which considers many factors of comments can significantly improve this task.
 Acknowledgements. This research is supported by the National Natural Science Foun-dation of China (Grant No. 61170156 and 61202337) and a CSC scholarship.

