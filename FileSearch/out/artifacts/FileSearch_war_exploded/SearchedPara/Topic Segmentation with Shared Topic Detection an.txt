 Topic detection and tracking [26] and topic segmentation [15] play an important role in capturing the local and se-quential information of documents. Previous work in this area usually focuses on single documents, although similar multiple documents are available in many domains. In this paper, we introduce a novel unsupervised method for shared topic detection and topic segmentation of multiple similar documents based on mutual information (MI) and weighted mutual information (WMI) that is a combination of MI and term weights. The basic idea is that the optimal segmen-tation maximizes MI(or WMI). Our approach can detect shared topics among documents. It can find the optimal boundaries in a document, and align segments among docu-ments at the same time. It also can handle single-document segmentation as a special case of the multi-document seg-mentation and alignment. Our methods can identify and strengthen cue terms that can be used for segmentation and partially remove stop words by using term weights based on entropy learned from multiple documents. Our experimental results show that our algorithm works well for the tasks of single-document segmentation, shared topic detection, and multi-document segmentation. Utilizing information from multiple documents can tremendously improve the perfor-mance of topic segmentation, and using WMI is even better than using MI for the multi-document segmentation. H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Clustering ; H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; I.2.7 [ Artificial Intelligence ]: Nat-ural Language Processing X  Text analysis ; I.5.3 [ Pattern Recognition ]: Clustering X  Algorithms;Similarity measures Copyright 2007 ACM 978-1-59593-597-7/07/0007 ... $ 5.00. Algorithms, Design, Experimentation Topic segmentation, shared topic detection, topic alignment, mutual information, multiple documents, term weight
Many researchers have worked on topic detection and track-ing (TDT) [26] and topic segmentation during the past decade. Topic segmentation intends to identify the boundaries in a document with the goal to capture the latent topical struc-ture. Topic segmentation tasks usually fall into two cate-gories [15]: text stream segmentation where topic transition is identified, and coherent document segmentation in which documents are split into sub-topics. The former category has applications in automatic speech recognition, while the latter one has more applications such as partial-text query of long documents in information retrieval, text summary, and quality measurement of multiple documents. Previous research in connection with TDT falls into the former cat-egory, targeted on topic tracking of broadcast speech data and newswire text, while the latter category has not been studied very well.

Traditional approaches perform topic segmentation on doc-uments one at a time [15, 25, 6]. Most of them perform badly in subtle tasks like coherent document segmentation [15]. Often, end-users seek documents that have the simi-lar content. Search engines, like, Google, provide links to obtain similar pages. At a finer granularity, users may ac-tually be looking to obtain sections of a document similar to a particular section that presumably discusses a topic of the users interest. Thus, the extension of topic segmenta-tion from single documents to identifying similar segments from multiple similar documents with the same topic is a natural and necessary direction, and multi-document topic segmentation is expected to have a better performance since more information is utilized.

Traditional approaches using similarity measurement based on term frequency generally have the same assumption that similar vocabulary tends to be in a coherent topic segment [15, 25, 6]. However, they usually suffer the issue of identify-ing stop words. For example, additional document-dependent stop words are removed together with the generic stop words in [15]. There are two reasons that we do not remove stop words directly. First, identifying stop words is another is-sue [12] that requires estimation in each domain. Removing common stop words may result in the loss of useful informa-tion in a specific domain. Second, even though stop words can be identified, hard classification of stop words and non-stop words cannot represent the gradually changing amount of information content of each word. We employ a soft clas-sification using term weights.

In this paper, we view the problem of topic segmentation as an optimization issue using information theoretic tech-niques to find the optimal boundaries of a document given the number of text segments so as to minimize the loss of mutual information (MI) (or a weighted mutual information (WMI)) after segmentation and alignment. This is equal to maximizing the MI (or WMI). The MI focuses on measur-ing the difference among segments whereas previous research focused on finding the similarity (e.g. cosine distance) of segments [15, 25, 6]. Topic alignment of multiple similar documents can be achieved by clustering sentences on the same topic into the same cluster. Single-document topic segmentation is just a special case of the multi-document topic segmentation and alignment problem. Terms can be co-clustered as in [10] at the same time, given the number of clusters, but our experimental results show that this method results in a worse segmentation (see Tables 1, 4, and 6). Usu-ally, human readers can identify topic transition based on cue words, and can ignore stop words. Inspired by this, we give each term (or term cluster) a weight based on entropy among different documents and different segments of docu-ments. Not only can this approach increase the contribution of cue words , but it can also decrease the effect of common stop words , noisy word ,and document-dependent stop words . These words are common in a document. Many methods based on sentence similarity require that these words are removed before topic segmentation can be performed [15]. Our results in Figure 3 show that term weights are useful for multi-document topic segmentation and alignment.
The major contribution of this paper is that it introduces a novel method for topic segmentation using MI and shows that this method performs better than previously used cri-teria. Also, we have addressed the problem of topic segmen-tation and alignment across multiple documents, whereas most existing research focused on segmentation of single documents. Multi-document segmentation and alignment can utilize information from similar documents and improves the performance of topic segmentation greatly. Obviously, our approach can handle single documents as a special case when multiple documents are unavailable. It can detect shared topics among documents to judge if they are multiple documents on the same topic. We also introduce the new criterion of WMI based on term weights learned from mul-tiple similar documents, which can improve performance of topic segmentation further. We propose an iterative greedy algorithm based on dynamic programming and show that it works well in practice. Some of our prior work is in [24].
The rest of this paper is organized as follows: In Section 2, we review related work. Section 3 contains a formulation of the problem of topic segmentation and alignment of multiple documents with term co-clustering, a review of the criterion of MI for clustering, and finally an introduction to WMI. In Section 4, we first propose the iterative greedy algorithm of topic segmentation and alignment with term co-clustering, and then describe how the algorithm can be optimized by us-Figure 1: Illustration of multi-document segmenta-tion and alignment. ing dynamic programming. In Section 5, experiments about single-document segmentation, shared topic detection, and multi-document segmentation are described, and results are presented and discussed to evaluate the performance of our algorithm. Conclusions and some future directions of the research work are discussed in Section 6.
Generally, the existing approaches to text segmentation fall into two categories: supervised learning [19, 17, 23] and unsupervised learning [3, 27, 5, 6, 15, 25, 21]. Super-vised learning usually has good performance, since it learns functions from labelled training sets. However, often get-ting large training sets with manual labels on document sentences is prohibitively expensive, so unsupervised ap-proaches are desired. Some models consider dependence be-tween sentences and sections, such as Hidden Markov Model [3, 27], Maximum Entropy Markov Model [19], and Condi-tional Random Fields [17], while many other approaches are based on lexical cohesion or similarity of sentences [5, 6, 15, 25, 21]. Some approaches also focus on cue words as hints of topic transitions [11]. While some existing methods only consider information in single documents [6, 15], others uti-lize multiple documents [16, 14]. There are not many works in the latter category, even though the performance of seg-mentation is expected to be better with utilization of infor-mation from multiple documents. Previous research studied methods to find shared topics [16] and topic segmentation and summarization between just a pair of documents [14].
Text classification and clustering is a related research area which categorizes documents into groups using supervised or unsupervised methods. Topical classification or clustering is an important direction in this area, especially co-clustering of documents and terms, such as LSA [9], PLSA [13], and approaches based on distances and bipartite graph parti-tioning [28] or maximum MI [2, 10], or maximum entropy [1, 18]. Criteria of these approaches can be utilized in the is-sue of topic segmentation. Some of those methods have been extended into the area of topic segmentation, such as PLSA [5] and maximum entropy [7], but to our best knowledge, using MI for topic segmentation has not been studied.
Ourgoalistosegmentdocumentsandalignthesegments across documents (Figure 1). Let T be the set of terms { t 1 ,t 2 , ..., t l } , which appear in the unlabelled set of docu-ments D = { d 1 ,d 2 , ..., d m } .Let S d be the set of sentences for document d  X  D , i.e. { s 1 ,s 2 , ..., s n d } .Wehavea3Dma-trix of term frequency, in which the three dimensions are random variables of D , S d ,and T . S d actually is a random vector including a random variable for each d  X  D .The term frequency can be used to estimate the joint probability distribution P ( D, S d ,T ), which is p ( t, d, s )= T ( t, d, s ) /N where T ( t, d, s )isthenumberof t in d  X  X  sentence s and N is the total number of terms in D .  X  S represents the set of among multiple documents, where the number of segments |  X 
S | = p . A segment  X  s i of document d is a sequence of ad-jacent sentences in d . Since for different documents s i discuss different sub-topics, our goal is to cluster adjacent sentences in each document into segments, and align similar segments among documents, so that for different documents  X  s is about the same sub-topic. The goal is to find the opti-mal topic segmentation and alignment mapping and Ali d ( X  s i ): {  X  s 1 ,  X  s 2 , ...,  X  s p } X  X   X  s 1 D ,where  X  s i is i th segment with the constraint that only adjacent sentences can be mapped to the same segment, i.e. for d , { s i ,s i +1 , ..., s j } X  X   X  s q } ,where q where p is the segment number, and if i&gt;j , then for d ,  X  s q is missing. After segmentation and alignment, random vector S d becomes an aligned random variable  X  S .Thus, P ( D, S d ,T )becomes P ( D,  X  S, T ).

Term co-clustering is a technique that has been employed [10] to improve the accuracy of document clustering. We evaluate the effect of it for topic segmentation. A term t is mapped to exactly one term cluster. Term co-clustering involves simultaneously finding the optimal term clustering mapping Clu ( t ): { t 1 ,t 2 , ..., t l } X  X   X  t 1 ,  X  t 2 l , l is the total number of words in all the documents, and k is the number of clusters.
We now describe a novel algorithm which can handle single-document segmentation, shared topic detection, and multi-document segmentation and alignment based on MI or WMI.
MI I ( X ; Y ) is a quantity to measure the amount of infor-mation which is contained in two or more random variables [8, 10]. For the case of two random variables, we have Obviously, when random variables X and Y are indepen-dent, I ( X ; Y ) = 0. Thus, intuitively, the value of MI de-pends on how random variables are dependent on each other. The optimal co-clustering is the mapping Clu x : X  X   X  X and Clu y : Y  X   X  Y that minimizes the loss: I ( X ; Y )  X  I ( which is equal to maximizing I (  X  X ;  X  Y ). This is the criterion of MI for clustering.

In the case of topic segmentation, the two random vari-ables are the term variable T and the segment variable S , and each sample is an occurrence of a term T = t in a particular segment S = s . I ( T ; S ) is used to measure how dependent T and S are. However, I ( T ; S )cannotbecom-puted for documents before segmentation, since we do not have a set of S due to the fact that sentences of Document d , s  X  S d , is not aligned with other documents. Thus, instead of minimizing the loss of MI, we can maximize MI after topic segmentation, computed as: where p (  X  t,  X  s ) are estimated by the term frequency tf of Term Cluster  X  t and Segment  X  s in the training set D . Note that here a segment  X  s includes sentences about the the same topic among all documents. The optimal solution is the mapping Clu t : T  X   X  T , Seg d : S d  X   X  S ,and Ali d :  X  S  X   X  S ,which maximizes I (  X  T ;  X  S ).
In topic segmentation and alignment of multiple docu-ments, if P ( D,  X  S, T ) is known, based on the marginal dis-tributions P ( D | T )and P (  X  S | T ) for each term t  X  categorize terms into four types in the data set: Entropy based on P ( D | T )and P (  X  S | T ) can be used to iden-tify different types of terms. To reinforce the contribution of cue words in the MI computation, and simultaneously re-duce the effect of the other three types of words, similar as the idea of the tf-idf weight [22], we use entropies of each term along the dimensions of document D and segment  X  S , i.e. E D (  X  t )and E  X  S (  X  t ), to compute the weight. A cue word usually has a large value of E D (  X  t ) but a small value of E We introduce term weights (or term cluster weights) where E D (  X  t )= d  X  D p ( d |  X  t ) log | D | 1 p ( d |  X  E powers to adjust term weights. Usually a = 1 and b =1 as default, and max  X  t  X   X  T ( E D (  X  t )) and max  X  t  X  used to normalize the entropy values. Term cluster weights are used to adjust p (  X  t,  X  s ), and where p w (  X  t )and p w ( X  s ) are marginal distributions of p
However, since we do not know either the term weights or P ( D,  X  S, T ), we need to estimate them, but w  X  t depends on p ( X  s | t )and  X  S , while  X  S and p ( X  s | t ) also depend on w is still unknown. Thus, an iterative algorithm is required to estimate term weights w  X  t and find the best segmenta-tion and alignment to optimize the objective function I w concurrently. After a document is segmented into sentences Figure 2: Algorithm: Topic segmentation and align-ment based on MI or WMI. andeachsentenceissegmentedintowords,eachwordis stemmed. Then the joint probability distribution P ( D, S can be estimated. Finally, this distribution can be used to compute MI in our algorithm.
Our goal is to maximize the objective function, I (  X  T ; I (  X  T ;  X  S ), which can measure the dependence of term occur-rences in different segments. Generally, first we do not know the estimate term weights, which depend on the optimal topic segmentation and alignment, and term clusters. More-over, this problem is NP-hard [10], even though if we know the term weights. Thus, an iterative greedy algorithm is de-sired to find the best solution, even though probably only local maxima are reached. We present the iterative greedy algorithm in Figure 2 to find a local maximum of I (  X  T ; I (  X  T ;  X  S ) with simultaneous term weight estimation. This algorithm can is iterative and greedy for multi-document cases or single-document cases with term weight estimation and/or term co-clustering. Otherwise, since it is just a one step algorithm to solve the task of single-document segmen-tation [6, 15, 25], the global maximum of MI is guaranteed. We will show later that term co-clustering reduces the ac-curacy of the results and is not necessary, and for single-document segmentation, term weights are also not required.
In Step 0, the initial term clustering Clu t and topic seg-mentation and alignment Seg d and Ali d are important to avoid local maxima and reduce the number of iterations. First, a good guess of term weights can be made by using the distributions of term frequency along sentences for each document and averaging them to get the initial values of w where where D t is the set of documents which contain Term t . Then, for the initial segmentation Seg (0) , we can simply segment documents equally by sentences. Or we can find the optimal segmentation just for each document d which maximizes the WMI, Seg (0) d = argmax  X  s I w ( T ;  X  S ), where w = w (0)  X  t . For the initial alignment Ali (0) , we can first assume that the order of segments for each d is the same. For the initial term clustering Clu (0) , first cluster labels can be set randomly, and after the first time of Step 3, a good initial term clustering is obtained.
After initialization, there are three stages for different cases. Totally there are eight cases, | D | =1or | D | &gt; 1, k = l or k&lt;l , w =0or w = 1. Single document segmen-tation without term clustering and term weight estimation ( |
D | =1 ,k = l, w = 0) only requires Stage 1 (Step 1). If term clustering is required ( k&lt;l ), Stage 2 (Step 2.1, 2.2, and 2.3) is executed iteratively. If term weight estimation is required ( w = 1), Stage 3 (Step 3.1, 3.2, and 3.3) is exe-cuted iteratively. If both are required ( k&lt;l,w =1),Stage2 and 3 run one after the other. For multi-document segmen-tation without term clustering and term weight estimation ( |
D | &gt; 1 ,k = l, w = 0), only iteration of Step 2.2 and 2.3 are required.
 At Stage 1, the global maximum can be found based on I (  X 
T ;  X  S ) using dynamic programming in Section 4.4. Simul-taneously finding a good term clustering and estimated term weights is impossible, since when moving a term to a new term cluster to maximize I w (  X  T ;  X  S ), we do not know that the weight of this term should be the one of the new cluster or the old cluster. Thus, we first do term clustering at Stage 2, and then estimate term weights at Stage 3.

At Stage 2, Step 2.1 is to find the best term clustering and Step 2.2 is to find the best segmentation. This cycle is repeated to find a local maximum based on MI I until it con-verges. The two steps are: (1) based on current term clus-tering Clu  X  t ,foreachdocument d , the algorithm segments all the sentences S d into p segments sequentially (some seg-ments may be empty), and put them into the p segments  X  S of the whole training set D (all possible cases of different segmentation Seg d and alignment Ali d are checked) to find the optimal case, and (2) based on the current segmentation and alignment, for each term t , the algorithm finds the best term cluster of t based on the current segmentation Seg d and alignment Ali d . After finding a good term clustering, term weights are estimated if w =1.

At Stage 3, similar as Stage 2, Step 3.1 is term weight re-estimation and Step 3.2 is to find a better segmentation. They are repeated to find a local maximum based on WMI I w until it converges. However, if the term clustering in Stage 2 is not accurate, then the term weight estimation at Stage 3 may have a bad result. Finally, at Step 3.3, this algo-rithm converges and return the output. This algorithm can handle both single-document and multi-document segmen-tation. It also can detect shared topics among documents by checking the proportion of overlapped sentences on the same topics, as described in Sec 5.2.
In many previous works on segmentation, dynamic pro-gramming is a technique used to maximize the objective function. Similarly, at Step 1, 2.2, and 3.2 of our algorithm, we can use dynamic programming. For Stage 1, using dy-namic programming can still find the global optimum, but for Stage 2 and Stage 3, we can only find the optimum for each step of topic segmentation and alignment of a docu-ment. Here we only show the dynamic programming for Step 3.2 using WMI (Step 1 and 2.2 are similar but they can use either I or I w ). There are two cases that are not shown in the algorithm in Figure 2: (a) single-document segmen-tation or multi-document segmentation with the same se-quential order of segments, where alignment is not required, and (b) multi-document segmentation with different sequen-tial orders of segments, where alignment is necessary. The alignment mapping function of the former case is simply just Ali d ( X  s i )= X  s i , while for the latter one X  X  alignment mapping function Ali d ( X  s i )= X  s j , i and j may be different. The com-putational steps for the two cases are listed below: Case 1 (no alignment):
For each do cument d : (1) Compute p w (  X  t ), partial p w (  X  t,  X  s ) and partial p out counting sentences from d . Then put sentences from i to j into Part k , and compute partial WMI
PI w (  X  T ; X  s k ( s i ,s i +1 , ..., s j )) where Ali d ( s i ,s i +1 , ..., s j )= k , k  X  X  1 , 2 , ..., p n ,and Seg d ( s q )= X  s k for all i  X  q  X  j . (2) Let M ( s m , 1) = PI w (  X  T ; X  s 1 ( s 1 ,s 2 , ..., s M ( s m ,L )= max i [ M ( s i  X  1 ,L  X  1) + PI w (  X  T ; X  s where 0  X  m  X  n d ,1 &lt;L&lt;p ,1  X  i  X  m +1, and when i&gt;m , no sentences are put into  X  s k when compute PI tation). (3) Finally M ( s n d ,p )= max i [ M ( s i  X  1 ,p  X  1)+
PI w (  X  T ; X  s p ( s i , ..., s n d ))], where 1  X  i  X  n I w is found and the corresponding segmentation is the best. Case 2 (alignment required):
For each do cument d : (1) Compute p w (  X  t ), partial p w (  X  t,  X  s ), and partial p PI w (  X  T ; X  s k ( s i ,s i +1 , ..., s j )) similarly as Case 1. (2) Let M ( s m , 1 ,k )= PI w (  X  T ; X  s k ( s 1 ,s 2 , ..., s k  X  X  1 , 2 , ..., p } .Then M ( s m ,L,k L )= max i,j [ M ( s where 0  X  m  X  n d ,1 &lt;L&lt;p ,1  X  i  X  m +1, k L  X  Set ( p, L ) , whichisthesetofall p ! L !( p  X  L )! combinations of L segments chosen from all p segments, j  X  k L ,theset of L segments chosen from all p segments, and k L/j is the combination of L  X  1segmentsin k L except Segment j . (3) Finally, M ( s n d ,p,k p )= max i,j [ M ( s i  X  1 ,p where k p is just the combination of all p segments and 1 i  X  n d + 1, which is the optimal I w and the corresponding segmentation is the best.

The steps of Case 1 and 2 are similar, except in Case 2, alignment is considered in addition to segmentation. First, basic items of probability for computing I w are computed excluding Doc d , and then partial WMI by putting every possible sequential segment (including empty segment) of d into every segment of the set. Second, the optimal sum of PI w for L segments and the leftmost m sentences, M ( s m ,L ), is found. Finally, the maximal WMI is found among differ-ent sums of M ( s m ,p  X  1) and PI w for Segment p .
In this section, single-document segmentation, shared topic detection, and multi-document segmentation will be tested. Different hyper parameters of our method are studied. For convenience, we refer to the method using I as MI k if w =0, and I w as WMI k if w =2oras WMI k if w =1,where k is the number of term clusters, and if k = l ,where l is the total number of terms, then no term clustering is required, i.e. MI l and WMI l .
The first data set we tested is a synthetic one used in previous research [6, 15, 25] and many other papers. It has 700 samples. Each is a concatenation of ten segments. Each segment is the first n sentence selected randomly from the Brown corpus, which is supposed to have a different topic from each other. Currently, the best results on this data set is achieved by Ji et.al. [15]. To compare the perfor-mance of our methods, the criterion used widely in previous research is applied, instead of the unbiased criterion intro-duced in [20]. It chooses a pair of words randomly. If they are in different segments ( dif f erent )fortherealsegmen-tation ( real ), but predicted ( pred ) as in the same segment, it is a miss . Iftheyareinthesamesegment( same ), but predicted as in different segments, it is a false alarm .Thus, the error rate is computed using the following equation: p ( err | real, pred )= p ( miss | real, pred, diff ) p ( dif f + p ( false alarm | real, pred, same ) p ( same | real ). We tested the case when the number of segments is known. Table 1 shows the results of our methods with different hyper parameter values and three previous approaches, C99[25], U00[6], and ADDP03[15], on this data set when the seg-ment number is known. In WMI for single-document seg-mentation, the term weights are computed as follows: w  X  t 1  X  E  X  and WMI l both outperform all the previous approaches. We compared our methods with ADDP03using one-sample one-sided t-test and p-values are shown in Table 2. From the p-values, we can see that mostly the differences are very Table 1: Average Error Rates of Single-document Segmentation Given Segment Numbers Known Table 2: Single-document Segmentation: P-values of T-test on Error Rates significant. We also compare the error rates between our two methods using two-sample two-sided t-test to check the hypothesis that they are equal. We cannot reject the hy-pothesis that they are equal, so the difference are not sig-nificant, even though all the error rates for MI l are smaller than WMI l . However, we can conclude that term weights contribute little in single-document segmentation. The re-sults also show that MI using term co-clustering ( k = 100) decreases the performance. We tested different number of term clusters, and found that the performance becomes bet-ter when the cluster number increases to reach l . WMI k&lt;l has similar results that we did not show in the table.
As mentioned before, using MI may be inconsistent on op-timal boundaries given different numbers of segments. This situation occurs especially when the similarities among seg-ments are quite different, i.e. some transitions are very obvious, while others are not. This is because usually a document is a hierarchical structure instead of only a se-quential structure. When the segments are not at the same level, this situation may occur. Thus, a hierarchical topic segmentation approach is desired, and the structure highly depends on the number of segments for each internal node and the stop criteria of splitting. For this data set of single-document segmentation, since it is just a synthetic set, which is just a concatenation of several segments about different topics, it is reasonable that approaches simply based on term frequency have a good performance. Usually for the tasks of segmenting coherent documents for sub-topics, the effec-tiveness decreases much. The second data set contains 80 news articles from Google News. There are eight topics and each has 10 articles. We randomly split the set into subsets with different document numbers and each subset has all eight topics. We com-pare our approach MI l and WMI l with LDA [4]. LDA treats a document in the data set as a bag of words, finds its distribution on topics, and its major topic. MI l and WMI l views each sentence as a bag of words and tag it with a topic label. Then for each pair of documents, LDA determines if they are on the same topic, while MI l and Table 3: Shared Topic Detection: Average Error Rates for Different Numbers of Documents in Each Subset WMI l check whether the proportion overlapped sentences on the same topic is larger than the adjustable threshold  X  . That is, in MI l and WMI l , for a pair of documents d , d , S d is the set of sentences of d ,and | S d | isthenumberof sentences of d ,then d and d have the shared topic.
For a pair of documents selected randomly, the error rate is computed using the following equation: p ( err | real, pred )= p ( miss | real, pred, same ) p ( same + p ( false alarm | real, pred, diff ) p ( dif f | real ), where a miss means if they have the same topic ( same ) fortherealcase( real ), but predicted ( pred )asonthesame topic. If they are on different topics ( dif f ), but predicted as on the same topic, it is a false alarm .
The results are shown in Table 3. If most documents have different topics, in WMI l , the estimation of term weights in Equation (3) is not correct. Thus, WMI l is not expected to have a better performance than MI l , when most documents have different topics. When there are fewer documents in a subset with the same number of topics, more documents have different topics, so WMI l is more worse than MI l .We can see that for most cases MI l has a better (or at least similar) performance than LDA. After shared topic detec-tion, multi-document segmentation of documents with the shared topics is able to be executed.
For multi-document segmentation and alignment, our goal is to identify these segments about the same topic among multiple similar documents with shared topics. Using I w is expected to perform better than I ,sincewithoutterm weights the result is affected seriously by document-dependent stop words and noisy words which depends on the personal writing style. It is more likely to treat the same segments of different documents as different segments under the effect of document-dependent stop words and noisy words. Term weights can reduce the effect of document-dependent stop words and noisy words by giving cue terms more weights.
The data set for multi-document segmentation and align-ment has 102 samples and 2264 sentences totally. Each is the introduction part of a lab report selected from the course of Biol 240W, Pennsylvania State University. Each sample has two segments, introduction of plant hormones and the content in the lab. The length range of samples is from two to 56 sentences. Some samples only have one part and some have a reverse order the these two segments. It is not hard to identify the boundary between two segments for hu-man. We labelled each sentence manually for evaluation. The criterion of evaluation is just using the proportion of the number of sentences with wrong predicted segment la-bels in the total number of sentences in the whole training Table 4: Average Error Rates of Multi-document Segmentation Given Segment Numbers Known Table 5: Multi-document Segmentation: P-values of T-test on Error Rates for MI l and WMI l #Doc 51 34 20 10 5 2
P-value 0.19 0.101 0.025 0.001 0.000 0.002 set as the error rate: p ( error | predicted, real )
In order to show the benefits of multi-document segmenta-tion and alignment, we compared our method with different parameters on different partitions of the same training set. Except the cases that the number of documents is 102 and one (they are special cases of using the whole set and the pure single-document segmentation), we randomly divided the training set into m partitions, and each has 51, 34, 20, 10, 5, and 2 document samples. Then we applied our meth-ods on each partition and calculated the error rate of the whole training set. Each case was repeated for 10 times for computing the average error rates. For different partitions of the training set, different k values are used, since the num-ber of terms increases when the document number in each partition increases.
From the experiment results in Table 4, we can see the following observations: (1) When the number of documents increases, all methods have better performances. Only from one to two documents, MI l has decrease a little. We can observe this from Figure 3 at the point of document num-ber = 2. Most curves even have the worst results at this point. There are two reasons. First, because samples vote for the best multi-document segmentation and alignment, but if only two documents are compared with each other, the one with missing segments or a totally different sequence will affect the correct segmentation and alignment of the other. Second, as noted at the beginning of this section, if two doc-uments have more document-dependent stop words or noisy words than cue words, then the algorithm may view them as two different segments and the other segment is missing. Generally, we can only expect a better performance when the number of documents is larger than the number of seg-ments. (2) Except single-document segmentation, WMI l is always better than MI l , and when the number of documents is reaching one or increases to a very large number, their performances become closer. Table 5 shows p-values of two-sample one-sided t-test between MI l and WMI l .Wealso can see this trend from p-values. When document number = 5, we reached the smallest p-value and the largest difference between error rates of MI l and WMI l . For single-document Table 6: Multi-document Segmentation: Average Error Rate for Document Number = 5 in Each Sub-set with Different Number of Term Clusters #Cluster 75 100 150 250 l
MI k 24.67% 24.54% 23.91% 22.59% 15.77% segmentation, WMI l is even a little bit worse than MI l , which is similar as the results of the single-document seg-mentation on the first data set. The reason is that for single-document segmentation, we cannot estimate term weights accurately, since multiple documents are unavailable. (3) Using term clustering usually gets worse results than MI l and WMI l .(4) Using term clustering in WMI k is even worse than in MI k , since in WMI k term clusters are found first using I before using I w . If the term clusters are not correct, then the term weights are estimated worse, which may mis-lead the algorithm to reach even worse results. From the results we also found that in multi-document segmentation and alignment, most documents with missing segments and a reverse order are identified correctly.

Table 6 illustrates the experiment results for the case of 20 partitions (each has five document samples) of the training set and topic segmentation and alignment using MI k with different numbers of term clusters k . Notice that when the number of term clusters increases, the error rate becomes smaller. Without term clustering, we have the best result. We did not show results for WMI k with term clustering, but the results are similar.

We also tested WMI l with different hyper parameters of a and b to adjust term weights. The results are pre-sented in Figure 3. It was shown that the default case WMI l : a =1 ,b = 1 gave the best results for different par-titions of the training set. We can see the trend that when the document number is very small or large, the difference between MI l : a =0 ,b = 0 and WMI l : a =1 ,b =1be-comes quite small. When the document number is not large (aboutfrom2to10),allthecasesusingtermweightshave better performances than MI l : a =0 ,b = 0 without term weights, but when the document number becomes larger, the cases WMI l : a =1 ,b = 0 and WMI l : a =2 ,b =1 become worse than MI l : a =0 ,b = 0. When the document number becomes very large, they are even worse than cases with small document numbers. This means that a proper way to estimate term weights for the criterion of WMI is very important. Figure 4 shows the term weights learned from the whole training set. Four types of words are cate-gorized roughly even though the transition among them are subtle. Figure 5 illustrates the change in (weighted) mutual information for MI l and WMI l . As expected, mutual infor-mation for MI l increases monotonically with the number of steps, while WMI l does not. Finally, MI l and WMI l are scalable, with computational complexity shown in Figure 6.
One advantage for our approach based on MI is that re-moving stop words is not required. Another important ad-vantage is that there are no necessary hyper parameters to adjust. In single-document segmentation, the performance based on MI is even better for that based on WMI, so no extra hyper parameter is required. In multi-document seg-mentation, we show in the experiment, a =1and b =1 is the best. Our method gives more weights to cue terms. However, usually cue terms or sentences appear at the be-ginning of a segment, while the end of the segment may be Figure 3: Error rates for different hyper parame-ters of term weights.
Figure 5: Change in (weighted) MI for MI l and WMI l . much noisy. One possible solution is giving more weights to terms at the beginning of each segment. Moreover, when the length of segments are quite different, long segments have much higher term frequencies, so they may dominate the segmentation boundaries. Normalization of term frequen-cies versus the segment length may be useful.
We proposed a novel method for multi-document topic segmentation and alignment based on weighted mutual in-formation, which can also handle single-document cases. We used dynamic programming to optimize our algorithm. Our approach outperforms all the previous methods on single-document cases. Moreover, we also showed that doing seg-mentation among multiple documents can improve the per-formance tremendously. Our results also illustrated that us-ing weighted mutual information can utilize the information of multiple documents to reach a better performance.
We only tested our method on limited data sets. More data sets especially complicated ones should be tested. More previous methods should be compared with. Moreover, nat-ural segmentations like paragraphs are hints that can be used to find the optimal boundaries. Supervised learning also can be considered. The authors want to thank Xiang Ji, and Prof. J. Scott Payne for their help.
