 In large networks, the connected triples are useful for solv-ing various tasks including link prediction, community de-tection, and spam filtering. Existing works in this direction concern mostly with the exact or approximate counting of connected triples that are closed (aka, triangles). Evidently, the task of triple sampling has not been explored in depth, although sampling is a more fundamental task than count-ing, and the former is useful for solving various other tasks, including counting. In recent years, some works on triple sampling have been proposed that are based on direct sam-pling, solely for the purpose of triangle count approxima-tion. They sample only from a uniform distribution, and are not effective for sampling triples from an arbitrary user-defined distribution. In this work we present two indirect triple sampling methods that are based on Markov Chain Monte Carlo (MCMC) sampling strategy. Both of the above methods are highly efficient compared to a direct sampling-based method, specifically for the task of sampling from a non-uniform probability distribution. Another significant advantage of the proposed methods is that they can sample triples from networks that have restricted access, on which a direct sampling based method is simply not applicable. H [ Information Systems ]: Miscellaneous; I [ Computing Methodologies ]: Miscellaneous Triple Sampling, Approximate Triangle Counting, Markov Chain Monte Carlo Sampling
For a long time, scientists from a wide variety of dis-ciplines, including social sciences, information science and  X  T his research is supported by Mohammad Hasan X  X  NSF CAREER Award (IIS-1149851) bioinformatics are using networks for modeling complex re-lations among different entities. They also invented various measures of interest relating to graph topology for under-standing the underlying dynamics that drive these relations. For instance, clustering coefficient and transitivity [20] met-rics are invented for denoting the clustering tendency of the vertices in a network, centrality indices are used for under-standing the diverse roles of the vertices, and modularity is used for discovering communities. Most of the existing methods for computing the above metrics have a super-linear time complexity, which is deemed costly for today X  X  large networks reaching the planetary scale in size. So, there have been growing interests to obtain efficient algorithms for computing these metrics in linear or sub-linear time through sampling based methods.

Triples, which are defined as paths of length two are im-portant building blocks of social networks. Two prominent theories for temporal evolution of social networks are ho-mophily and transitivity ; according to the homophily the-ory, people tend to choose friends that are similar (to some extent) to themselves and according to the transitivity, peo-ple who have common friends tend to become friends them-selves [11]. Transitivity accounts for a social network to have a large number of triangles than a random network of sim-ilar size. To measure the conformity of a network with the transitivity theory, network metrics, such as, transitivity, or clustering co-efficient are used. They simply capture the tendency of X  X losing the triangle X  X y adding the missing edge in an open triple. This tendency is more prevalent inside a network community as the nodes in a community connect more often with other members in the community. Thus, the role of a triple in defining the network structure makes it an important entity while analyzing a social network.
The importance of transitivity and its obvious connec-tion to the triangles in a network also contributed to the regained interest in the seemingly simple task of triangle counting [8]. Besides computing transitivity in social net-works, there are other usages of the triangle counting task. In [5], the distribution of triangles is used to uncover hidden thematic structure in the World Wide Web. Bar-Yossef et al. [2] show that triangle count can be used for query plan optimization in databases. However, for large networks with millions of vertices and edges, all the exact methods for tri-angle counting can be deemed as expensive; so, the major-ity of the recent efforts of triangle counting either adopt a method for approximate counting [19] or design a parallel or distributed framework for solving the counting task in sub-linear time [18].
Surprisingly, a relatively small number of the existing work s consider sampling of triples (or triangles); nonetheless, sam-pling is more fundamental than counting as the earlier can be used for solving various tasks, including counting. Schank et al. [16] proposed one of the earliest works for uniform sam-pling of triples, which they use for approximating the tran-sitivity index of a network. Recently, Seshadhri et al. [17] reinvented the same method for triangle count approxima-tion. Both of these works adopt a direct sampling strat-egy for which critical information regarding the network, such as vertex count, and the degree of each of the vertices are required before the sampling can be commenced; un-fortunately, for a restricted network such information are not available. Besides, these methods only perform uniform sampling of triples for approximating triangle counting or transitivity, whereas in this work we are considering sam-pling triples from an arbitrary distribution.
Our objective is to obtain an efficient method for sampling triples from an arbitrary (user defined) probability distribu-tion (say, f ) defined over the set of triples in a network. The distribution f can be defined implicitly; for instance, one can only define a weighting function w (  X  ) over the set of triples, and f is simply the probability vector obtained from the weights of each of the triples. Any locally computable weight function should be admissible. Such a function can be formed by the topological properties of the vertices in the triples, or in case, the graph contains vertex or edge la-bels, the weight function can be designed based on the label composition of the vertices or edges of the triples.
To obtain a direct method for the sampling task that is defined in the above paragraph, we first need to compute f (probability mass function) from the weight function, and then obtain the cmf (cumulative mass function) of f . Ob-viously, this requires the knowledge of the entire sampling space (total number of vertices, edges, and triples). For a restricted graph, which can only be crawled by following the edges of the input network, such information is not avail-able, so direct sampling is infeasible for solving the above sampling task on a restricted network.

The motivation for considering a restricted network comes from real-life consideration. Say, an analyst is using a crawler for crawling a Web graph, and he does not have the resources to store the entire graph in memory/disk. Under this set-ting, he may want to sample a set of triples (from a uniform distribution) alongside crawling so that he can approximate the transitivity of the Web graph. Clearly, without storing the entire network, he has no knowledge of the number of vertices, or edges in this network, let alone the number of triples. Also, for a hidden network, a user may not have ac-cess to an arbitrary node in the network for security reason, rather the desired node can only be accessed from another node which is one-hop away from it; such scenarios are com-mon in real-life and are considered in some of the recent works that compute various network properties (degree dis-tribution, average degree) by random walk over real-life net-works, such as, Facebook [7].

Even if a network is not restricted, an indirect sampling method can be more desirable than a direct sampling method, both from viability and efficiency consideration. We will show in this paper that an MCMC based method is signif-icantly more efficient than a direct sampling method, for weighted sampling where the probability distribution vector ( f ) is not readily available, because in such a case, compu-tation of f and cmf ( f ) (cumulative mass function of f ) are required for direct sampling (see Section 4.2 for details); this fixed cost can be expensive, as the number of triples in large networks are, typically, in the order of billions.
In this work, we propose two methods for indirect triple sampling using Markov Chain Monte Carlo (MCMC) strat-egy. MCMC performs a random walk over the sample space such that the desired probability distribution (in this case, f ) aligns with the stationary distribution of the random walk. Since MCMC computes the transition probability ma-trix of the random walk locally (on demand), it does not compute f explicitly; consequently, it does not need any in-formation regarding the size of the sample space. As long as a state of the random walk can be visited from one of the neighboring states, an MCMC-based sampling works, which makes it an ideal candidate for sampling from a re-stricted network. Also, an MCMC-based method computes the transition probability matrix on-line, so it can accommo-date addition or deletion of vertices (or edges) in a dynamic network, even when the sampling process is running. The sampling methods that we propose are called vertex-MCMC, and triple-MCMC: the former is more accurate and the latter is more versatile. Both the methods can sample from an arbitrary distribution, yet vertex-MCMC is par-ticularly suitable (both efficient and accurate) for sampling from a uniform distribution. So, we use it for approximating triangle count in a large network. In experiment section, we show that the performance of vertex-MCMC is almost as good as a direct sampling based method. On the other hand, triple-MCMC method is more suitable for sampling from non-uniform distribution; our experiments with one of the real-life graph show that it is 170 times faster than a direct sampling method with a better sampling quality.
The popularity of sampling based techniques has grown in recent years for analyzing large graphs. For example, sampling is used for finding interesting subgraphs [1], com-munities [10], and graphlet frequency distribution [15, 14].
Triple sampling is considered in the context of approx-imate counting of triangles (or computing transitivity) in the following works [16, 4, 17]. Both [16] and [17] obtain uniform sampling of triples using a direct sampling method, which we will discuss in Section 4.2. Buriol et al. [4] pro-pose a collection of streaming algorithms for triple sampling, also with the intention of triangle approximation. One of their methods, named, 3-pass-incident-stream, is conceptu-ally similar to the direct sampling method of [16, 17]. Buriol et al. also consider another 3-pass method for arbitrary edge streaming; it samples triples by first sampling an edge, and then sampling a vertex, both uniformly. A triple that is obtained this way belongs to one of the following sets exclu-sively: disconnected triples (set T 1 ), connected open triples (set T 2 ), or triangles (set T 3 ). From the size of each of these sets, the authors find an approximation of the triangle count in a graph. To the best of our knowledge, no works exist that consider sampling of triples from a user-defined arbitrary sampling distribution.

A set of recent works [9, 7] considers the task of sam-pling from restricted networks that can only be crawled. The most notable among these is the work by Leskovec and Faloutsos [9] which used a collection of random walk meth-ods, namely, BFS (breadth-first search), forest-fire, simple random walk (SRW), and snowball sampling for obtaining a representative sample of the restricted network. One can apply the above random walk methods for sampling a rep-resentative networks of appropriate size and return all the triples from that network as the sampled triples. However, such a sampling of triples does not guaranty uniform sam-pling of triples; furthermore, the user has no control over the probability distribution by which the triples would be sam-pled in the above approach. On the other hand, the MCMC method that we propose in this work can sample from any arbitrary user-defined distribution.

There are other recent works that adopt MCMC sampling strategy. Bhuiyan et al. [15] use it for sampling graphlets, Maiya et al. [10] use it for sampling community structure, and Gjoka et al. [7] use it for finding an approximate de-gree distribution of Facebook network. However, each of these works have a different objective and they sample from different population. Besides, none of these works samples from an arbitrary user-defined distribution.
Let G = ( V, E ) is a graph, where V is the set of vertices and E is the set of edges. Each edge e  X  E can be denoted by a pair of vertices ( u, v ) where, u, v  X  V . A graph without a self-loop or multi edge is a simple graph. In this work, we consider simple, connected, and undirected graphs. We use n to define the number of vertices in G , d ( v ) to define the degree of a node v , and d max to denote the maximum degree value for a vertex over the entire graph.
A triple ( u, v, w ) at a vertex v is a path of length two for which v is the center vertex. If the other two vertices ( u and w ) are also connected by an edge, the triple is called a closed triple (triangle), otherwise it is called an open triple. A triangle actually contains three closed triples, one centered on each of its vertices.

We use the symbol  X  v to represent the set of triples that are centered at the vertex v . The set of triples in a graph G = ( V, E ) is  X , which is the union of the set of triples at each of its node, i.e.,  X  = triple is open or closed (in terms of its induced embedding in the graph G ), we can partition the set  X  into  X   X  (open triples) and  X   X  (closed triples). Note that, each of the nodes of a triangle in a graph G contributes one distinct triple in the set  X   X  . To represent the set of open and closed triples centered at a vertex v , we will use  X   X  v and  X   X  v , respectively. If  X  ( G ) is the number of triangles in the graph G , then Example: Graph in Figure 1 has eight triples. Five of them are open and the remaining three are closed. Also the graph has exactly one triangle.

Given a graph G ( V , E ), the total number of triples in G ,
Newman, Watts and Strogatz [13] defined the transitivity of a graph G (say,  X  ( G )) as the fraction that represents the number of closed triples divided by the number of all the triples over the entire network.
Using Equation 1 and Equation 3, the triangle count (  X  ( G )) of a network can be obtained from the transitivity of the net-work as below:
Following Equation 3, the transitivity of a graph,  X  ( G ), is the probability that an arbitrary triple in G is closed. This probability can be approximated using uniform triple sampler. For this, we sample a set of triples  X  (  X   X ) from G using a uniform distribution, and count the number of closed tripled in that set (say,  X   X  ). Then, we define a random variable  X  a ( G ) = |  X   X  | |  X  | . The following lemma holds: Lemma 1. E [  X  a ( G )] =  X  ( G )
Proof : form the uniformity assumption, E |  X   X  | =  X  ( G )  X  |  X  | . Then, E [  X  a ( G )] = E  X  ( G ) .

Thus, the expectation of the variable  X  a ( G ) provides an unbiased estimate of the transitivity, which can subsequently be used in Equation 4 for finding an approximate triangle count in the graph G .
The main goal of the Metropolis-Hastings algorithm is to draw samples from some distribution  X  ( x ), called the target distribution , where,  X  ( x ) = f ( x ) /K ; here K is a normalizing constant which may not be known and difficult to compute. MH algorithm can be used together with a random walk to perform Markov Chain Monte Carlo (MCMC) sampling. For this, the MH algorithm draws a sequence of samples from the target distribution as follows: i. It picks an initial state (say, x ) satisfying f ( x ) &gt; 0. ii. From current state x , it samples a point y using a distri-bution q ( x, y ), referred as proposal distribution . iii. Then, it calculates the acceptance probability ,  X  ( x, y ) = min  X  ( y ) q ( y, x )  X  ( x ) q ( x , y ) , 1 and accepts the proposal move to y w ith probability  X  ( x, y ). The process continues until the Markov chain reaches to a stationary distribution.
Assume,  X  is the set of triples in a large network G . Now, for a user defined non-negative weight function, w :  X   X  R we can define a probability distribution over the set of triples ( X ) by normalizing the weights, i.e, for a triple t  X   X , its probability is assigned as w ( t ) P pling is to sample triples from  X  using the above probability distribution. We can represent the probability distribution using a probability mass function, f , which simply assigns a probability value to each of the triples in  X . If the weights of all the triples are the same, then the above sampling becomes a uniform sampling of triples. For triple sampling, we also consider the scenario that the given network is restricted such that it is not explicitly visible, but can be crawled. More formally, in a restricted network, we can perform a random walk over the network, where at any given state of the walk, the currently visiting vertex, along with its adja-cency list is available to us.

In this paper, we propose, explain and compare two MCMC based algorithms for solving the sampling problem that we define in the previous paragraph. The first among these two is vertex-MCMC which we discuss in Section 4.3, and the second among these two is triple-MCMC, which we dis-cuss in Section 4.4. In the following we will discuss a direct sampling approach first to prove that for a restricted graph direct sampling is not feasible.
A direct sampling method for sampling a triple from  X  first constructs the probability mass function ( f ) over the sample space (if not given) using the weight function, and from that it constructs the cumulative mass function (say, F ) of f . Then it uses the inverse-transform method to sam-ple an object from the sample space. More formally, if the sampled object is x , then x = F  X  1 ( U ) where U  X  Uni (0 , 1). For computer implementation, we can simply store the func-tion F in a vector of size |  X  | considering an arbitrary (but constant) ordering of triples, and then choose an index from the vector uniformly using binary search, and return the triple corresponding to that index. For a restricted network, construction of F is impossible, so direct sampling method is not applicable for such a network.

Authors of [16] and [17] use a slightly modified version of direct sampling for sampling triples. Theirs X  is a two-step sampling process. The first step samples a vertex v from a multinomial distribution,  X  , which is constructed by summing f (  X  ) of each of the triples at the vertex v . Mathematically,  X  ( v ) = P v  X  V P  X  ( v ) = 1. The second step samples a triple from the set of triples at vertex v ( X  v ) using another multino-mial distribution,  X  v . If t  X   X  v , then P  X  v ( t ) = f ( t ) P v ( t )  X  P  X  ( v ) = are O ( n 3 ) triples in a graph, the cost of construction of cmf s of  X  and  X  v  X  X  is O ( n 3 ), and the cost of sampling by inverse-transform is logarithm of the sample space (cost of binary search). Overall complexity of sampling k triples is O n 3 + k (lg n + lg d max ) , where n is the number of ver-tices, and d max is the largest degree value for a vertex in the graph. Clearly, such a method is very inefficient.
However, note that the authors of [16] and [17] considered uniform distribution only. For this, P  X  ( v ) = |  X  v | |  X  | of the  X  v  X  X  is trivially a uniform distribution. So, Z ( cmf of  X  ) can be computed in O ( n ) time using equation 2 considering that the degree of a vertex is available in O (1) time; we simply need to add the terms d ( v ) 2 in the above equation cumulatively for each of the vertices. Overall complexity of sampling k triples is then O ( n + k lg n ). Thus, the direct sampling of triples is efficient for uniform sampling, but not for arbitrary sampling.

Example: For uniform triple sampling of the graph pre-sented in Figure 1, we choose a vertex with the distribution  X  . Under this, the vertex 3 is selected with probability 3 / 8, as there are three triples for which vertex 3 is the center. If vertex 3 is selected, we randomly choose two vertices from the adjacency list of 3 (2 , 4 , 5) and construct one of the three possible triples and return. Consequently, the probability of triple (3 , 4 , 5) being selected is (3 / 8  X  1 / 3 = 1 / 8), which is equal to 1 / |  X  | , as desired.
 Algorithm 1 t riple sampling vertex-MCMC 1: p rocedure tripleSampling2 ( G ( V, E ) , k, { w ( i ) } 2: S  X   X  3: u = An arbitrary starting vertex from V . 4: while | S |6 = s do 5: v  X  SelectNodeMCMC ( u, { w ( i ) } i  X   X  )  X  see 6: Select a triple t  X   X  v using t  X   X  v 7: S.add ( t ) 8: end while 9: return S  X  Return a set of s triples. 10: end procedure
W e have seen in previous section that sampling a triple from an arbitrary distribution requires the construction of the cmf of  X  . For a restricted graph this is an infeasible task due to the lack of availability of the required information. Besides, the construction of the cmf of  X  takes O ( n 3 ) time, which is a fixed cost that is required to be paid up before the sampling process starts.

Our first indirect method to address the above limita-tions is to use an MCMC sampling method that does not construct  X  explicitly. We call it vertex-MCMC; the justi-fication of this name will be clear in short time. Vertex-MCMC sampling uses a similar approach as the two-step direct sampling, but unlike the latter, it replaces the first-step (sampling a vertex from  X  ) with an indirect sampling via MCMC. The second step of vertex-MCMC sampling re-mains unchanged from the two-step direct sampling method. More details of vertex-MCMC is given below.

For any MCMC algorithm, we need to define the states, the state transition process, the transition probability ma-trix, and the desired probability distribution. For vertex-MCMC, the set of states are the vertex-set V a nd the tran-sition over the states happens along the edges ( E ). So the MCMC process is simply a random walk on the graph G . However, the stationary distribution of this walk is  X   X  identical to the desired distribution of vertices for a two-step sampling. To achieve the desired sampling distribution we will use Metropolis-Hastings (MH) algorithm.

Assume that MCMC random walk of a vertex-MCMC based triple sampler is visiting a vertex v . As was discussed in Section 3.3, MH algorithm uses a proposal distribution ( q ) to make a trial move; vertex-MCMC chooses q to be uniform over the neighborhood of v , in other word, it chooses one of the vertices (say, u ) from the adjacency list of v uniformly. Therefore, the proposal distribution q ( v, u ) = 1 /d ( v ); here d ( v ) is the number of nodes adjacent to node v . q ( v, u ) rep-resents the probability of an adjacency node u to be selected from current node v . Similarly, q ( u, v ) = 1 /d ( u ). Now, us-ing Equation 5, the acceptance probability of the proposal move is as shown in Equation 6. = min Algorithm 2 M CMC node sampling 1: p rocedure SelectNodeMCMC ( current, { w ( i ) } i  X   X  3: next = Uniform from adj ( current )  X  Proposal step 6: if uniform (0 , 1)  X  acceptance then 7: return next 8: end if 9: return current 10: end procedure
Algorithm 1 illustrates the vertex-MCMC algorithm. The s ampling process starts from an arbitrary seed vertex (Line 3). To sample the next vertex from  X  , the method calls the subroutine shown in Algorithm 2, which is simply an implementation of MH algorithm, where the sample space is the vertex set, and the target distribution is  X  . Once a vertex is selected on Line 5, vertex-MCMC computes the cmf of  X  v , and uses the direct sampling method to sample a triple using  X  v (Line 6). The process continues until the desired number of triples are obtained. The complexity of vertex-MCMC for sampling k triples is O ( kd max ), as weight computations, and neighbor selection in Algorithm 2 can be performed in O ( d max ) time.
 Why vertex-MCMC method works for a restricted graph? The answer to this question is that the transition decisions of the random walk of vertex-MCMC are made using informa-tion that is locally available. More precisely, the transition decision of vertex-MCMC X  X  random walk is made in Line 6 of Algorithm 2 using information computed in Line 2 and Line 4; these lines compute the sum of weights associated to the triples of current and next nodes, this computation can be accomplished within the scope of a restricted graph. Besides, vertex-MCMC method avoids the construction of the cmf of  X  vector, which makes it computationally more efficient than a direct sampling based method, the latter has a quadratic complexity with respect to the number of ver-tices in the network. Vertex-MCMC is also suitable for the case of a dynamic network.
 Lemma 2. The random walk over the graph G ( V, E ) in Algorithm 1 converges to a stationary distribution which is equal to  X  .

Proof : To achieve a unique stationary distribution, a ran-dom walk needs to be ergodic which can be proved by show-ing that the walk is finite, irreducible and aperiodic [12]. The state space of the random walk in Algorithm 1 is finite with size | V | . We also assume that the input graph G is connected, so in this random walk any state u is reachable from any state v with a positive probability and vice versa, so the random walk is irreducible. Finally the walk can be guaranteed to be aperiodic by allocating a self-loop proba-bility at every node 1 . This prove that the random walk achieves a unique stationary distribution. Now, consider two adjacent vertices u, v  X  V in graph G . Using Equa-tion 6, the transition probability from v to u , P vu = 1 /d ( v )  X  min A ssuming that the stationary distribution probability of the node v is  X  ( v ) = P  X  ( v ) , then  X  ( v )  X  P vu = min S imilarity, the transition probability from u to v is, P min P uv = min  X  ( u )  X  P uv . Thus the detailed balanced condition holds using  X  as the stationary distribution. Since, detailed balanced con-dition is a sufficient condition for an ergodic Markov chain to achieve the given stationary distribution, the random walk in Algorithm 1 achieves the stationary distribution  X  over the vertices of G .
 We proved that the MCMC sampling of Algorithm 1 chooses a vertex v from the  X  distribution on convergence. Then the Algorithm samples a triple t centered at v using  X  v distribu-tion (On Line 6). Thus using the correctness of the two-step direct sampling method, the sampled triple t is obtained from the desired distribution f (which is proportional to the weight w ( t )). We will discuss the convergence of random walk in more details in Section 4.5.
 Uniform sampling using vertex-MCMC: , P  X  ( v ) = d ( v )
We do not show the pseudo-code of uniform triple sam-pling using vertex-MCMC. But, it is easy to obtain by mak-
T his is required only from a theoretical standpoint; in our experiment we do not allocate any self-loop probability ex-plicitly. ing minor changes in Algorithm 1 and Algorithm 2. In Line 2 and Line 4 of Algorithm 2, we can compute the vertex weights in O (1) time using the degree value of the corre-sponding vertex; the acceptance probability (Line 5) changes as shown in Equation 7. Finally, the Line 6 in Algorithm 1 requires to sample a triple from a uniform distribution in-stead of  X  v , which also takes O (1) time. Due to the above changes, vertex-MCMC is faster in uniform sampling setting than weighted sampling setting. However, the theoretical complexity of the uniform triple sampling is still O ( kd although the weight computation cost is constant, we still need to find a neighbor of the currently visiting vertex, which in the worst case can take O ( d max ) time. Our second indirect sampling method is named triple-MCMC, which performs MCMC walk over the triples. Triple-MCMC avoids computing cmf for both the distributions (  X  and {  X  v } v  X  V ). In fact, triple-MCMC is completely oblivious about the total number of triples in the graph. The set of states for this sampling algorithm is the set of all the triples,  X . Thus the random walk proceeds over the set of triples along a neighborhood graph which is defined below.
The neighbor of a triple is another triple with two common vertices. Thus, the triple-MCMC sampling obtains a se-quence of dependent samples, where a sampled triple shares two vertices with the previous sampled triple. To compute the neighbor-set of a triple t , we need to find the other triples that can be obtained by replacing exactly one of the vertices of t .

Example: Suppose we are performing an MCMC walk on the graph shown in Figure 2 ( a ). Let h v 2 , v 3 , v currently visiting triple (triangle that is shown in bold line). In Figure 2 ( b ) we show the information of all its neighbors. The list labeled by v 2 contains the vertices that can be used to replace vertex v 2 to get a valid neighboring triple and sim-ilarly for the list labeled by v 3 and v 8 . If the MCMC random walk chooses to go to the neighboring triple by replacing the vertex v 8 with v 1 , the next sampled triple becomes a path h v 1 , v 2 , v 3 i . On the other hand, if the vertex v 3 is replaced by v 7 , we get the closed triple h v 2 , v 7 , v 8 i where the center of the triple is taken as v 7 , which is the lastly added vertex of the triple. The transition between triples happens only between the neighboring triples. For example, the transi-tion probability between h v 2 , v 3 , v 8 i , and h v 4 , v as they are not neighbors of each other according to our neighborhood definition.

Let X  X  assume that the random walk of triple-MCMC is vis-i ting a triple t . For proposal distribution (say q ), we choose one of the triples from t  X  X  neighborhood (say, s ) uniformly. triple t . Using Equation 5, the acceptance probability of the proposal move is obtained as below:  X  ( t, s ) = min
We show a pseudo-code in Algorithm 3. Since, the random walk is performed over the triple space, we initialize the walk with an arbitrary triple t p , any path of length 2 suffices (Line 3). Now, for the currently visiting triple, t p , we want to find the next triple using MH algorithm. For this, we first find all the neighboring triples of t p (Line 5). Reader may review the Figure 2 to refresh the notion of the neighboring triples. This computation requires finding unions or intersections of the adjacency lists of the current triple X  X  vertices, and its complexity is O ( d max ). Then a neighboring triple (say, t is selected uniformly from all the neighbors, and accepted with the probability computed on Line 8. If the move is rejected, the currently sampled triple is sampled again. The process continues until k samples are obtained. The overall cost of obtaining k samples is O ( kd max ).
 Lemma 3. The random walk over the triples of G ( X ) in Algorithm 3 converges to a stationary distribution with is proportional to w ( t ) Proof : The proof is almost identical to the proof of Lemma 2. We first show that the walk is ergodic. The state space  X  is finite, because the number of triples is finite. We also as-sume that the input graph G is connected, so in this random walk any triple y is reachable from another triple x with a positive probability and vice versa, so the random walk is irreducible. Finally the walk can be made aperiodic by allo-cating a self-loop probability at every node. Thus the random walk reaches a stationary distribution. Similar to the proof of Lemma 2, we can show that the random walk satisfies the detailed balanced condition for the stationary distribution f (proportional to w ). Since the detailed balance condition is sufficient for an ergodic random walk to reach the given sta-tionary distribution, the lemma is proved.
 Algorithm 3 t riple sampling triple-MCMC 1: p rocedure tripleSampling3 ( G, k, { w ( i ) } i  X   X  2: S  X   X  3: t p  X  a random triple  X  A length 2 path is sufficient 4: while | S |6 = s do 5: t q  X  RandomNeighborT riple ( t p ) 6: n p  X  NeighborCount ( t p ) 7: n q  X  NeighborCount ( t q ) 9 : if uniform (0 , 1)  X  acceptance then 10: S.add ( t q ) 11: t p  X  t q 12: else 13: S.add ( t p ) 14: end if 15: end while 16: return S  X  Return a set of s triples. 17: end procedure
F or uniform sampling, the weight of an open triple is 1 and the weight of a closed triple is 3 (a triangle represents three triples), i.e., for uniform sampling in Equation 8, we set w ( s ) and w ( t ) to be 1 or 3 depending on whether the cor-responding triple is open or close. MH algorithm guarantees that the Algorithm 3 using the above acceptance probability yields a uniform triple sampler.
Convergence analysis is important for any MCMC sam-pling based method because through such analysis we can estimate the mixing time (number of walks to converge to the stationary distribution overcoming the influence of the starting state) of a Markov chain. Mixing time depends on (i) the neighborhood structure of the space on which the walk is performed, and (ii) the desired target distribution. A method to measure the convergence rate is to find the spectral gap of the transition probability matrix P . P has n real eigenvalues 1 =  X  0 &gt;  X  1  X   X  2  X  . . .  X   X  n  X  1 Then, the spectral gap is defined as  X  = 1  X  max {  X  1 , |  X  Since the absolute values of all the eigenvalues are less than one (based on Perron-Frobenius theorem) with the largest eigenvalue  X  0 be exactly one, the spectral gap is always be-tween 0 and 1. The higher the spectral gap, the faster the convergence [3]. For triple sampling in a restricted graph, the entire transition matrix P is not available, so it is infea-sible to measure the spectral gap.

However, if the objective of MCMC sampling is to measure a metric over the sampling population, some experimental methods are available to study the convergence of the chain solely based on the convergence of the metric value. One such method is called Geweke diagnostics [6]. Both vertex-MCMC, and triple-MCMC sampling can be used to approx-imate  X  ( G ), the transitivity of the graph G , so this metric can be analyzed for convergence study using Geweke diag-nostics. It works as follows: we consider X to be a single sequence of triple samples. Also let, X i = 1 if i th sample of the sequence is a triangle and X i = 0 otherwise. Then the expected value of the random variables in the sequence X gives as unbiased estimate of transitivity, i.e., E [ X ] =  X  ( G ).
Geweke considers two subsequences of samples, X a form the beginning part of X (typically first 10%) and X b from the last part of X (typically last 50%). From these two sub-X a ans X b goes further apart as the number of samples is increased. Consequently, the correlation between the subse-quences decreases. After convergence, there is no correlation between X a and X b , and z becomes normally distributed with mean 0 ( E [ X a ] = E [ X b ] =  X  ( G ), so, E [ X a 0) and variance 1. The number of iterations that it takes for the z-score to fall between [-1, 1] is considered the mixing time. However, one should run the experiment for at least a few distinct walks, and declare convergence when z -scores from all the walks fall within the [  X  1 , 1] range. In Section 5.4 we will show that only a few hundred walks are sufficient to achieve convergence even on a graph having more than a million of vertices.
In our experiments we first show the performance of uni-form triple sampling. Then we show the performance of triple sampling from a nonuniform distribution. Finally, we Table 1: Small real-life Networks used in sampling q uality experiments.
 Table 2: Large real-life Networks used in approxi-m ate triangle count experiments. demonstrate that, uniform sampling of triples can be applied for approximating triangle count, which provides an appli-cation driven method for measuring sampling effectiveness.
All the graphs 2 listed in Table 1 and 2, are undirected, unweighted, simple and connected. We pre-process them to ensure these properties. The specification of the graphs (ver-tex count and edge count) may not match with the source, as in source, for some networks an undirected edge is repre-sented by two directed edges in opposite directions; in our representation, for such edges we discard one edge of the edge-pairs. Additionally, we ensure that the graph is con-nected as MCMC algorithms perform a random walk over the graph. However, for all the graphs that we use, the largest connected component of a graph retains more than 90% of the edges.
Our first experiment compares the performance of uni-form triple sampling of vertex-MCMC with that of the direct sampling method discussed in Section 4.2 (We skip triple-MCMC for this experiment as it can be easily demonstrated that for uniform sampling, vertex-MCMC is more efficient than triple-MCMC). For this comparison we simulate both the methods on an input graph by sampling triples (with re-placement); then we study the statistics of sample count , a random number representing the frequency at which a triple is sampled. For each of input graphs, we run the sampler for |  X  | X  i iterations, where  X  is the set of distinct triples in that graph. By definition, sample count follows a binomial distribution B ( k, m, p ), where m = |  X  | .i and p = 1 |  X  | this distribution, the median sample count will be identical to the mean, which is m.p = |  X  | .i. 1 |  X  | = i a nd the variance distribution resembles a normal distribution. We run this experiments using i =50 on smaller graphs that are listed in Table 1. Performing this experiment on large graphs is in-feasible, because for this experiment we need to store the o btained from http://snap.stanford.edu,http: //socialnetworks.mpi-sws.org/,http://www.cise. ufl.edu/research/sparse visit count of all the triples in the memory, and the number o f such triples is in the order of billions for large graphs.
Figure 3: Frequency h istogram of the visit counts on ca-Hepth network using (a) Di-rect triple sampling (b) vertex-MCMC triple sampling.

In Figure 3, we show the frequency histogram of sam-ple counts for the ca-Hepth network. In this plot, x -axis shows different sample count values, and y -axis represents the number of distinct triples that achieves that value for its sample count. The shape of the histogram is a perfect nor-mal graph, which is expected from an ideal iid distribution. Besides, the median value for both the cases is also 50, as ex-pected (note that i =50). The histograms of other networks are almost identical, hence are not shown. We report the variance of sample counts in Table 3 for both the sampling algorithms on all 3 small networks. As we can see in this table, for Ca-Hepth network, using vertex-MCMC uniform sampler, the variance is 59 . 37, but the same is 49 . 93 for a di-rect triple sampler. For all the networks, the direct method X  X  performance is almost identical to an ideal case ( equal to 50). For vertex-MCMC method, variance of sample count is slightly bigger, yet very close to its true value. The higher value of variance for vertex-MCMC can be attributed to the nature of indirect sampling where a sample is constrained to be within the neighborhood of the previous sample.
In this experiment we verify the quality of sampling when the triples to be sampled follow a non-uniform distribution. We compare Direct sampling with both vertex-MCMC and triple-MCMC algorithms. In this experiment we use the small graph dataset listed in Table 1 for the reason dis-cussed in Section 5.2. Here, our objective is to sample triple t in proportion to w ( t ). For this experiment, we consider w ( t ) = |N ( t ) | , i.e., a triple is sampled with the probabil-ity proportional to the size of its neighborhood. One moti-vation of choosing such a sampling distribution can be to sample triples from a community or a dense region of a graph; in such a neighborhood, a triple will be surrounded by many triples, so |N ( t ) | will be high for a triple t in a dense neighborhood. For the above choice of target distribution, the acceptance probability of vertex-MCMC is,  X  ( v, u ) is min  X  ( t, s ) is 1.

For a network with |  X  | triples, the desired distribution over  X  can be expressed as a vector f of size |  X  | , here, f ( t ) = w ( t ) W . For each of the graphs, we run each sam-pler for |  X  | X  i times (we choose i = 10 for our experiment). The distribution f can be approximated by the sample fre-quency of each of the triples. Therefore, b f ( t ) = count ( t ) here, count ( t ) is the number of times the triple t was sampled and b f is the approximation of f that is obtained by the sam-pling algorithm. The performance of a sampling method can be measured by the correlation between f and b f . Table 4 shows that all the three methods achieves ex-cellent value for the correlation (more than 0.85). Interestingly, direct method some-times perform worse than the other meth-ods; our investigation shows that this is because of the precision issue of the floating-point while handling very small probabilities. More precisely, Ca-Hepth network has 227 , 919 triples, and the cu-mulative mass probabilities (which sums to 1) is stored in a vector of that size; in this vector the difference between successive cells are sometimes as small as 10  X  8 , and to per-form well a uniform random number generator X  X  precision has to be good for that many decimal points, which appar-ently is not true for existing random number generators. In all our experiments we use Boost random number generator library that has much better performance that those avail-able in standard C++ library. In Figure 4, we compare f vs b f for all the three methods using scatter plots for one of the graphs (ca-Grqc). The superiority of triple-MCMC over other sampling methods is easily visible in this figure. Figure 4: T arget distribution vs achieved distribu-
Table 5 shows the execution time for sampling 1 k and 10 k triples from the networks using different sampling algo-rithms. As the table shows, Triple-MCMC is much better than Vertex-MCMC and the direct method. For example, Triple-MCMC takes only 0 . 08 second to sample 1 k triples from ca-Cond network, whereas Direct method and Vertex-MCMC takes 145 . 5 and 82 . 65 seconds respectively. This is because, triple-MCMC does not need to compute the cmf  X  and  X  v explicitly. Computing  X  is a fixed cost for the direct sampling method. Vertex-MCMC distribute this fixed cost over the iterations because it computes the  X  of each vertex only on demand. On the other hand, triple-MCMC com-putes w ( t ) of a specific triple only on demand. If we take more samples, the difference between the direct sampling and vertex-MCMC slowly diminishes, as with many itera-tions, both the methods can amortize the fixed cost over those iterations. Here, it should be noted that, cmf  X  v is not Table 5: Execution times of the algorithms for sam-p ling 1 k triples and 10 k triples.
 Table 6: Mixing time to achieve convergence accord-i ng to Geweke diagnostics explicitly stored in memory. Storing  X  v will require memory in the order of O ( |  X  | ), which is same as enumerating the whole set of triples. And if enumeration is possible, then we do not need to sample triples in the first place.
In this experiment, we use Geweke diagnostics for study-ing the mixing time of vertex-MCMC and triple-MCMC methods while sampling from a uniform distribution. This experiment is not shown for user-defined distribution, be-cause mixing time is different for different choices of distri-bution.

For this experiment, we use ten distinct walk sequences for each dataset. For each sequence, we compute z -score starting from 100 X  X h walk and declare convergence when all ten z -scores fall in [  X  1 , 1] range. In Table 6 (column 2 and 3) we report the mixing time that we compute from Geweke diagnostics. For all the graphs that we use, the mixing time is only a few hundreds for vertex-MCMC and a few thou-sands for triple-MCMC, which is very good considering the size of these networks. The triple-MCMC takes more time to mix as the neighborhood graph on which this method performs the random walk is much larger than the same for the vertex-MCMC X  X  walk. In this experiment, we compare the performance of vertex-MCMC algorithm with direct triple sampling [16, 17], and one of the sampling method by Buriol et al. [4] 3 . Note that, recent works [17] have shown that the direct sampling method is the best among the existing methods for approx-imate triangle counting; so we do not include other triangle counting methods such as DOULION [19] in this experi-ment. However, we do include Buriol et al. X  X  method in this comparison, because it is also a triple sampling method like vertex-MCMC. We exclude triple-MCMC in this comparison as when performing uniform sampling its execution time is t his method is actually proposed for arbitrary edge stream setting, but for fair comparison we implement it as a non-stream in memory method. not competitive with these methods (although it is the best choice for weighted sampling). The task assigned to each sampling method is to approximate the triangle count by sampling triples from uniform distribution. Here, we use the sampled set of triples to approximate triangle count using the idea that was explained in Section 3.1. For our experi-ment, we use 9 large real-life networks; name and statistics of these networks are shown in Table 2.

The performance of approximate triangle counting is mea-sured by two metrics: execution time and accuracy. Typ-ically, the method that wins in accuracy loses in running time. So, to make the comparison easy, we compare the ac-curacy (plotted on y axis) of different methods against dif-ferent running time (plotted on x -axis). However, do note that for a given value for time, the number of triples that the methods sample differ. We show the results in Figure 5(a-c). We fitted the data with Bezier curve to show the trend of the algorithms. All the accuracy and execution times are average value that are computed from 10 runs of the algo-rithms. We can see that the direct sampling method per-forms the best, even for a small number of samples, and its performance improvement remains almost flat as the sample count increases; on the other hand, vertex-MCMC improves sharply as the number of samples increases, and for some graphs its performance even surpasses the performance of direct sampling. So, vertex-MCMC is particularly suitable for large graphs, where a sampling method can afford to take many sample, and yet can be competitive with an exact al-gorithm. For instance, in wiki20060925 graph, both direct sampling and vertex-MCMC obtain 90% counting accuracy for a 6 seconds execution time, but the exact method that uses an efficient edge iterator algorithm takes 67 seconds to execute. The charts in this figure also confirm that Buriol et el. X  X  method is not competitive with either of these methods.
The accuracy of a direct sampling-based method is better than that of a vertex-MCMC based method. This is be-cause the latter performs indirect sampling in which a pair of consecutive samples are dependent. So, it X  X  result has high variances and it requires more samples in order to en-sure uniformity of sampled set of triples. However, MCMC based methods can work perfectly on restricted or dynamic networks, whereas direct sampling based methods are not applicable to those.
In this section, we compare our triple sampling method with various network sampling methods that are proposed in Leskovec et al. [9]. These methods create a small net-work from a large network through node (or edge) sampling with an objective that the sampled network would preserve various properties of the large network. For the purpose of this experiment, we select the transitivity (  X  ( G )) property, i.e., we investigate whether the exact transitivity value com-puted from the sampled network using the above methods is a good approximation of the actual transitivity value of the original network. For node based sampling, we sample a graph by sampling 5% of the nodes and then take the graph induced by the sampled node set. Similarly for edge based sampling, we sample 5% of the existing edges. The detailed description of all the network sampling methods can be found in [9]. over 10 executions.

The result is shown in Table 7 using average error metric, which is obtained by averaging over 10 executions. As we can see, none of the network sampling methods (9 methods, from RN to FF) is able to preserve the transitivity met-ric of the large network for an acceptable accuracy. The best among those is the RN (random node sampling) with a 6.8% error in the flicker dataset. On the other hand, vertex-MCMC achieves much better accuracy by sampling only 5%  X  X  V | number of triples from each of the graphs (see the last column in Table 7).
In this work, we propose two MCMC based algorithms for sampling triples form a large network. We show exper-imental results that demonstrate that both the algorithms achieve excellent performance while sampling triples from a large network using a given distribution. Direct sam-pling method X  X  performance is almost identical to an ideal sampler, but it is costly, specifically while sampling from a weighted distribution. On the other hand, the MCMC sampling methods that we propose is faster as it does not compute the cmf of the desired distribution. More impor-tantly, MCMC sampling methods can sample triples from networks that are restricted or dynamic, for which direct sampling methods fail.
