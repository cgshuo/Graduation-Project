 as a gating signal, together with a differential Hebbian emu lation of CL. interchanged under these conditions.
 the learning rule, e.g. by ways of a threshold [9].
 factor and remaining fully compatible with neuronally plau sible operations. 1.1 Emulating RL by Temporal Difference Learning R ( s i ) = Every time the agent encounters a state s learning [12, 1]. 1.2 Differential Hebbian learning with a local third factor timing dependent plasticity, [13]).
 third modulatory factor M each input u change of the corresponding weight  X  is then: where u the post-synaptic activity of a model neuron with weights  X  that our modulatory signal M We are going to analyze the weight change of weight  X  u local third factor M can occur. Although this time window could be located anywhe re depending on the input u should be placed at the end of the state s successor.
 Therefore we will use u i ) when pointing to functional development.
 Furthermore we define the time period between the end of a stat e s state s M i ( t ) corresponding state s are displayed in detail in fig. 1 B. 2.1 Analysis of the differential equation which consists of a homogeneous and an inhomogeneous part: where the modulator M  X  cc ( t ) . Together we have  X  ( t ) =  X  ac ( t ) +  X  cc ( t ) . In general the overall change of the weight  X  and s As a consequence, the derivatives of  X  on the right hand side of Eq. 4 can be neglected. The solution of the auto-correlation  X  ac O + S + L (fig. 1 B) is therefore: to the first order: where we have defined  X  in the following way: which is independent of i since we assume all state signals as identical. This leads us to: which yields assuming a time shift between signals u an overall weight change of whereas the third factor was being present between t = O + S and t = O + S + L (fig. 1 B). Additionally we defined  X  as follows: which, too, is independent of i .
 T and S . 2.2 Analysis of the network Fig. 1 A where we have one intermediate state transition (fro m s to value unequal to zero.
 Therefore three-factor differential Hebbian will influenc e two synaptic connections  X  states s Fig. 1 B shows a realistic situation of state transitions lea ving the old state s state s neurons.
 s controls the occurrence of the modulatory factor M synapse  X  the states s by u ( t ) = Eq. 7 and 11 are indicated.
 We will start our considerations with the weight change of  X  state s correlation ( s signal u sign from Eq. 6 to Eq 7). The cross-correlation (  X  cc of the following state s state signal u contributions for the  X  ( s In general the weight after a single trial is the sum of the old weight  X  Using Eq. 8 and Eq. 11 we can reformulate Eq. 13 into Substituting  X  =  X   X   X  and  X  =  X  / X  we get At this point we can make the transition from weights  X  thus this index will capture the reward state s this gives us an equation almost identical to Eq 1: Hebbian learning are indeed asymptotically equivalent. 2.3 Analysis of  X  and  X  negative value of  X  to oscillating weight pairs (  X  conditions and demand that 0 &lt;  X   X  1 and  X  &gt; 0 . shape of the signal u is given by u ( t ) = ( fulfilled.
 into a rising and a falling phase.
  X   X  -values for a particular value of L .
 This is indicated by the patterned area in fig. 2.
 for which no overlap between two consecutive signals and the third factor exist (  X  = 0 ). for a wide parameter range. (compare [1]). This is shown, including the weight developm ent, in panel (B). shape is given by u ( t ) = [15].
 will be an important issue when constructing such networks. between conventional Hebbian approaches and reinforcemen t learning. convergence for states that provide a reward: We get V ( s )  X   X V ( s to TD learning: V ( s )  X   X V ( s reality.
 Our results rely in a fundamental way on the third factor M we will get using differential Hebbian learning to emulate T D-learning. [15] C. Watkins and P. Dayan. Technical note:Q-Learning. Mach. Learn. , 8:279 X 292, 1992. [23] P. Dayan. Matters temporal. Trends. Cogn. Sci. , 6(3):105 X 106, 2002.
