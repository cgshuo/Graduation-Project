 5000 Forbes Ave, Pittsburgh, PA, 15213 Most existing automatic taxonomy induction systems exploit one or more features to induce a taxonomy; nevertheless there is no systematic study examining which are the best featu res for the task under various conditions. This paper studies t he impact of using different features on taxonomy induction for different types of relations and for terms at different abstraction levels. The evaluation shows that different conditions need dif ferent technologies or different combination of the techno logies. In particular, co-occurrence and lexico-syntactic patt erns are good features for is-a , sibling and part-of relations; contextual, co-occurrence, patterns, and syntactic features work w ell for concrete terms; co-occurrence works well for abstract terms.
 H.3.1 Content Analysis and Indexing. Experimentation, Verification. Ontology Learning, Taxonomy, Semantic Feature. Automatic taxonomy induction is an important task i n the fields of Natural Language Processing, Knowledge Management, and Se-mantic Web. It can be conducted for different types of relations, such as is-a , sibling , and part-of . It can also be conducted for terms with different levels of abstractness, includ ing concrete terms and abstract terms . Existing work on automatic taxonomy induction falls into two main categories: pattern-based and clustering-based . Pattern-based approaches [1][3][5] define lexical-syntactic patt erns for relations, and use these patterns to discover insta nces of relations. The approaches are known for their high accuracy in discovering relations. However they cannot find relations which do not explicitly appear in text. Clustering-based approaches [6][7] hierarchically cluster terms based on similarities of their meanings usually represented by a vector of features. The ap proaches complement pattern-based approaches by their abilit y to discover relations which do not explicitly appear in text. H owever, they cannot generate relations as accurate as pattern-ba sed approaches. The common types of features used in clustering-app roaches include contextual , co-occurrence , and syntactic dependency . A recent clustering-based approach [7] proposed to in corporate lexico-syntactic patterns as one type of features in the clustering-framework, and it is shown to achieve better accura cy for the task. These heterogeneous features play an important role in automatic taxonomy induction since they represent various tec hnologies in this field. However, there is no systematic study e xamining which features are the best for the task under various co nditions. This paper presents such a study. In particular, it studies the impact of various features on taxonomy induction fo r different types of relations and for terms at different abstr action levels. The fourth set of feature is lexical-syntactic patterns . We use (11) Hypernym Patterns proposed by [1] and [5], (12) Sibling Patterns which are basically conjunctions, and (13) Part-of Patterns proposed by [1] and [3]. Each feature function retu rns a vector of scores for the two input terms, one score per patte rn. A score is 1 if the terms appear with that pattern in text, 0 ot herwise. Table 1 lists all the patterns used in this work. The last set of features is miscellaneous . We use (14) Word Length Difference to measure the length difference between two terms, and (15) Definition Overlap to measure the word overlaps between term definitions by querying Google with  X  X  efine: term  X . The gold standards used in the evaluation are 50 hy pernym taxonomies from WordNet [2] and 50 from ODP (Open D irectory Project), and 50 meronym taxonomies from WordNet. I n WordNet taxonomies, we use the word senses within a particular taxonomy to eliminate ambiguity. In ODP taxonomies, we parse the topic lines, such as  X  X opic r:id=`Top/Arts/Movi es X  X , in the XML databases to obtain relations such as is_a(movies, arts) . We also use two auxiliary datasets: Wikipedia corpus and Google Corpus . Wikipedia corpus is the entire Wikipedia corpus downloaded and indexed by Indri. Google corpus is a collection of the top 1000 Google documents obtained by queryi ng Google using each term, and each term pair. In particular, both corpora are split into sentences and used to generate conte xtual, co-occurrence, syntactic dependency and pattern featur es. We evaluate the quality of automatically generated taxonomies by comparing them with the gold standards in terms of F1-measure for the relations. Leave-one-out cross validation i s used to average the system performance over different training and testing datasets; the averaged F1-measure is reported acros s 50 runs. This section studies the effect of using 15 heterog eneous features (grouped in 5 categories) for different types of re lations. Each category is utilized one by one. Table 2 shows the F1-measure of using various features on automatic taxonomy induct ion on WordNet datasets for is-a, sibling , and part-of relations. Bold font indicates that good performance in a column. Table 2 shows that co-occurrence and lexico-syntact ic patterns work equally well and significantly improve taxonom y induction for all three types of relations. Contextual featur es work well for identifying sibling relations, but not for is-a and part-of . Syntactic features show the similar results as contextual fea tures because four out of five syntactic features, ( Modifier Overlap, Subject Overlap, Object Overlap, and Verb overlap ) are surrounding context to a term. The row of  X  X ll X  shows the F1-measure when combining all the features for the task, and it con sistently achieves the best performance for all the three relations. This section studies the impact of different featur e categories on terms at different abstraction levels. The F1-measu re is evaluated for terms at each level of a taxonomy, not the whol e taxonomy. Tables 3 and 4 demonstrate the F1-measure of using each feature category alone on each abstraction level. Columns 2 -6 are indices of the levels in a taxonomy. The larger the indices are, the lower the levels. Higher levels contain abstract terms, w hile lower levels contain concrete terms. L 1 is ignored here since it only contains the root. Bold font indicates good performance in a column. Both tables show that abstract terms and concrete t erms favor different sets of features. In particular, contextu al, co-occurrence, pattern, and syntactic features work well for terms at L 4 -L 6 , i.e., the concrete terms; co-occurrence works well for te rms at L 2 -L 3 , i.e., the abstract terms. 
