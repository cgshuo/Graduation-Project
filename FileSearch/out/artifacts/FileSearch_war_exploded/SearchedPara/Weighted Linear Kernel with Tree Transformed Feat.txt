 Malware detection from network traffic flows is a challenging problem due to data irregularity issues such as imbalanced class distribution, noise, missing values, and heterogeneous types of features. To address these challenges, this paper presents a two-stage classification approach for malware de-tection. The framework initially employs random forest as a macro-level classifier to separate the malicious from non-malicious network flows, followed by a collection of one-class support vector machine classifiers to identify the specific type of malware. A novel tree-based feature construction approach is proposed to deal with data imperfection issues. As the performance of the support vector machine classifier often depends on the kernel function used to compute the similarity between every pair of data points, designing an appropriate kernel is essential for accurate identification of malware classes. We present a simple algorithm to construct a weighted linear kernel on the tree transformed features and demonstrate its effectiveness in detecting malware from real network traffic data.
 C.2.3 [ Computer-Communication Networks ]: Network Operations-Network Monitoring Feature Construction, Kernels, Malware Detection.
Malware detection is an important problem given the es-calating cost and severity of cyber crimes such as phishing, spamming, data and identity theft. Malware is a malicious software program stealthily deployed by attackers to com-promise a computer system (including its applications, data, and network infrastructure) by exploiting its security vul-nerabilities. Such programs have potential to disrupt the normal operations of the system, while giving the attackers unauthorized access to the system resources and allowing them to gather information covertly from users without their consent. With their ever increasing sophistication, the need for more advanced tools in the ongoing war against malware threats is a priority for businesses and governments.
In this paper, we present a malware detection framework that uses a set of layer-3 and layer-4 network traffic features such as bytes per second , packets per flow ,and packet inter-arrival times . Our goal is to classify the specific types of malware based on their network flow characteristics rather than the content of their packets. This enables us to clas-sify the flows even when they are encrypted. However, there are several challenges in classifying the network traffic flows. First, the disproportionate number of non-malicious and ma-licious network flows present significant difficulties for classi-fiers to accurately detect each flow type. Another challenge is dealing with network data that contains features of dif-ferent types, noise, and missing values. The missing value problem arises since each flow may generate a different num-ber of features depending on the flow duration and number of packets transmitted.

To address these challenges, this paper presents a novel supervised learning framework for detecting malware. A two-stage classification approach is employed to address the imbalanced class problem. A macro-level classifier is initially used to discriminate the malicious from non-malicious flows. Next, among those flows classified as malicious, a collection of one-class support vector machine (SVM) classifiers will be invoked to identify the specific type of malware found in the malicious flows. Such classifiers require specification of a kernel function to determine the similarity between ev-ery pair of data points. Defining an appropriate kernel is a daunting task since standard kernels such as the radial basis function (RBF) and polynomial kernels are not designed to handle data with heterogeneous features and missing values. To overcome this problem, we propose a tree based transfor-mation approach to create new features from the irregular data and learn an appropriate kernel by maximizing their correlation to the ground truth class similarity matrix.
We employ a two stage classification approach in our frame-work for the following reasons. First, as the flows predom-inantly belong to the  X  X ood X  class, it would be difficult to build a global model that effectively discriminates all the classes. In fact, the global model is likely to have a strong bias towards predicting most flows as  X  X ood X , resulting in a high false negative rate for the malware classes. Secondly, given that millions of packets may flow through a router ev-ery hour, it is necessary to downscale this traffic into smaller processable chunks before applying a large number of sophis-ticated classifiers to determine the type of malware.
Towards this end, a random forest [1] is used as the ini-tial macro-level classifier to distinguish the malicious flows from non-malicious ones. Random forest is an ensemble of decision tree classifiers, which predicts the class by combin-ing outputs produced by individual tree classifiers. Random forest reduces the variance of the classification function by constructing each tree from a random subset of features. Next, if a network flow is classified as malicious, a collection of one-class SVM classifiers will be applied to determine the specific type of malware. Details of the micro-level classifi-cation step is given in Section 2.2.
Let D = { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,..., ( x n ,y n ) } X  X  X Y training data, where x i  X  X  denote the feature set derived from layer-3 and layer-4 network protocol information and Y = { 1 , 2 , .....k } denote the set of k distinct classes (includ-ing the  X  X ood X  class). One of the key challenges in develop-ing an effective classifier for the network data is dealing with imperfections of the data. As shown in Table 1, some of the extracted features are strongly correlated with each other. Furthermore, a large flow with many packets tend to have more features (size of packet #5, size of packet #6, and so on.) compared to one with smaller number of packets. This leads to the missing value with non-applicable feature prob-lem (e.g., a network flow that transmits 5 packets will not have a feature value for size of packet #10). The easiest way to deal with missing values due to non-applicable features is to eliminate training instances having at least one feature with missing value. However, this reduces the amount of data available for training a reliable classifier. In fact, if we had discarded instances with missing values from the ISP data used in our experiment, we would be left with only 7% of the original flows.

The goal of our feature transformation step is to project the data into a metric space so that standard classification techniques can be applied to the transformed data. Sec-ondly, the data should be transformed in such a way that in-stances belonging to different classes are projected to differ-ent regions of the transformed space. To achieve these goals, we employ a tree-based approach to construct the new fea-tures (see Algorithm 1). An advantage of using a tree-based classifier is that it can automatically handle missing values due to non-applicable features during the tree construction process by treating  X  X napplicable X  as another separate value that can be used as splitting criteria for propagating the data instances to the different children of a node.
For each class c , we build p trees by labeling the instances belonging to class c as  X  1 and data from other remaining classes as +1. The predictions made by each tree on the training instances becomes a new feature, which has the ca-pability to separate instances belonging to class c from the rest of the data. We also need to introduce randomness Algorithm 1 Tree-Based Feature Transformation
Input : D = { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) , ... ( x n ,y n
Output : { F c } k 1 : Collection of n  X  p transformed data matrix where each F c contains p features that separate class c from rest of the data. for c =1to k do end for return { F c } k 1 into the tree construction process in order to avoid gener-ating the same tree for each class. This is accomplished by bootstrapping the instances and subsampling their features instead of using the whole training set for building the trees. This helps reduce the correlations among the newly gener-ated features. Let F c be the set of p tree-based features generated to separate class c from rest of data.
 where the value for each feature f c i is obtained by applying the i -th tree induced from class c (denoted as h i c )totheorig-inal features of a data instance. The trees are then applied to all the instances in the training and test sets to transform them to a new representation that contains k  X  p nonlinear features. The full set of transformed features is denoted by Each F c represents a subspace of the transformed space F with the unique property that instances belonging to class c should be well separated from the rest of the data.
We employ a collection of one-class SVM classifiers [2] to identify the malware type associated with each malicious network flow. A one-class SVM is built for each malware type i by labeling its instances as +1 and instances belong-ing to other classes as  X  1. The classifier constructs two con-centric hyperspheres such that the inner sphere encloses as many instances from malware type i as possible. The outer sphere is constructed in such a way that instances that do notbelongtotype i lie outside of it. The radial distance between the two hyperspheres is called the classifier X  X  mar-gin, which is the objective function to be maximized by the learning algorithm.

There are many desirable properties using 1-class SVM as our micro-level classifiers. Firstly, each classifier is a pair of simple hyperspheres defined by their respective centers and radii. Thus, the space required to store the models and time required to evaluate a new test sample is linear in the number of classes. Secondly, the proposed approach mimics the functionality of the nearest neighbor classifier but with a reduced number of distance comparisons needed. Thirdly, the approach incorporates the rigor of sophisticated discrim-inative classifiers as regions belonging to different classes are neatly enclosed in hyperspheres with minimal overlap with other spheres.

One-class SVM classifiers require specification of a kernel function to determine the similarity between data points. RBF and polynomial kernels are two popular choices of ker-nel functions, but they may not work well with irregular data that contains heterogeneous and non-applicable features. To circumvent this problem, our framework constructs the ker-nel based on the tree-based feature set F describedinthe previous section. Certainly, one can apply the RBF or poly-nomial kernel function directly to the features in F c to create the kernel matrix needed for constructing the hypersphere of class i . This approach is effective only if each tree in the feature set F c is uncorrelated and is equally important in the construction of the kernel matrix. If some trees are cor-related or superior than others, it would be useful to learn a set of weights for the tree-based features when computing the kernel.

Let  X  x denote the tree-based feature vector for each data point. Here, we investigate an approach to learn a weighted ( X  x i ,  X  x j ), where the weight matrix W is estimated by aligning it against the  X  X round truth X  kernel defined as follows.
Given the ground truth kernel G and the transformed data matrix  X  X , we learn the weight matrix W by minimizing the following objective function.
 The first term is minimized when the matrices G and  X  XW  X  X are in agreement with each other. The second term W 2 ij is a regularizer term added to keep the model parsimonious. We solve for W by taking the partial derivative of the objective function with respect to W and equating it to zero. After rearranging the equation 1 ,wehave W =  X  X T G  X  X .The weighted linear kernel will be used as input to the one-class SVM classifier to construct its hyperspheres. For testing, the similarity between any test instance  X  x  X  to a training instance  X  x is given by the following weighted linear kernel The test instance is classified based on its distance to the center of the hypersphere for each one-class SVM.
This section presents the experimental results comparing the performance of different aspects of the proposed frame-work. The framework is evaluated using real network flow We set  X  =1forourexperiments.
 Table 1: Examples of flow-level features generated by the Narus Semantic Traffic Analyzer (STA).

Name Feature Description dir direction (client to server or server to client) #pkts total number of packets #pkt-p total number of packets without payload bytes total number of bytes transferred pay bytes total number bytes from all payloads
 X  t flow duration sz max/min/avg/sdev packet size py max/min/avg/sdev payload size IAT average inter-arrival time
Flag TCP flags (acks, fins, resets, pushs, urgs, etc) sz X size of packet X ( X =1,2,  X  X  X  ,10)
IAT X inter arrival time of packet X pay X payload size of packet X data from an Internet service provider in Asia. Table 1 describes a subset of the 108 flow-level features extracted from the data using a commercial tool called Narus Semantic Traffic Analyzer (STA). Some of the challenges in using such features for classification include dealing with (1) heteroge-neous features (i.e., mixture of continuous and categorical types), (2) correlated features, and (3) missing values due to inapplicable features (e.g., the features sz 9 and sz 10 inapplicable to flows that contain less than 9 packets).
We use an industry standard IDS/IPS system to gener-ate the class label for each flow by analyzing their corre-sponding payload. In all, the IDS system has identified 36 different types of malicious flows. The flows that were un-labeled by the IDS system are assigned to  X  X ood X  category. The dataset contains 216,899 flows, out of which only 4,394 of them (  X  2%) were labeled as malicious and categorized into one of the 36 known malware. It should be noted that some of the  X  X ood X  flows may actually be malicious as they were not detected by the current IDS system. Thus, our ex-perimental study reports only the classification performance on the known malware classes since the performance on the  X  X ood X  class may not be reliable. Extending our framework to new class detection is a subject for future work.
The overall data is partitioned into two disjoint sets, one for model building (training set) and the other for model evaluation (test set). The training set contains 2,103 mali-cious flows from the 12 most prevalent malware classes with an equal number of flows belonging to the  X  X ood X  class. The test set includes 2,099 malicious flows belonging to the 12 most prevalent malware classes and the rest of the  X  X ood X  flows that were not flagged by the IDS.
First, we evaluate the effectiveness of applying a tree-based feature transformation approach in dealing with net-work data that contains missing values due to non-applicable features. The raw data contains  X  1 as a token for missing values. We compare the proposed approach against differ-ent data imputation methods. For brevity, we use 1-NN classifier to classify the network flows as either  X  X ood X  or  X  X alicious X . The baseline methods for comparison include (1) Raw , where we compute a modified Euclidean distance without considering the inapplicable/missing features, (2) OMI , where the missing values are imputed with the over-all feature mean, (3) CMI , where the missing values are Table 2: Comparing the classification performance of tree-based features against other baseline ap-proaches for handling data imperfection issues.
 Table 3: Confusion matrix for macro-level classifica-tion using random forest.
 imputed with the feature mean for the particular class, and (4) ( LKNN ), where the missing values of an instance are estimated based on the value of its closest neighbors com-puted using non-missing values. Table 2 shows the results obtained when applying the 1-nearest neighbor classifier to the raw, imputed, and tree-transformed features. The clas-sification results are reported in terms of their precision, recall, and F1-score. As can be seen from this figure, the proposed tree-based feature transformation approach gave significantly higher precision, recall, and F1 score compared to other baseline methods.
Next, we evaluate the effectiveness of using the random forest classifier to filter the suspicious flows from other non-malicious ones. We summarize the results in a 2  X  2 confusion matrix (see Table 3). The results suggest that the random forest classifier can effectively detect known malwares in the test set. However, it also misclassifies some of the unknown ( X  X ood X ) flows as potentially malicious as their flow prop-erties resemble those of the known malware. Furthermore, although random forest works well for binary classification, as will be shown in the next section, it is not as effective when used as a micro-level classifier. These results justify our rationale for using a two-stage classification framework.
Once the binary classifier has isolated all the malicious flows from the observed traffic, we apply the collection of one-class SVM classifiers to identify the malware type. As mentioned earlier, each one class SVM is designed to con-struct hyperspheres that separate instances of a specific mal-ware type from other classes using a special kernel designed for that particular class. We now present the results of ap-plying the collection of one-class SVM classifiers on the ma-licious network flow data. We compare their performance against random forest as the micro-level classifier. Unlike one-class SVM, which is inherently a binary classifier, the decision tree classifiers in random forest are applicable to multi-class problems, without the need to binarize the classes first. In addition, we consider two types of kernels X  X ne based on radial basis function (RBF) applied to the original raw features while the other is based on the proposed su-pervised weighted linear kernel (WL). Table 4 shows the F Table 4: Comparison between F1 measure for detecting known malwares using random forest method, RBF methods on raw features and the pro-posed weighted linear kernel on tree-based features. Class # Training # Test RBF WL Random scores reported by the different methods on each known ma-licious classes. The results suggest that the one-class SVM classifier with weighted linear kernel is most effective in iden-tifying the majority of the known malware classes compared to random forest and one-class SVM with RBF kernel on raw features. Furthermore, out of the 429  X  X ood X  flows that were misclassified as malicious by the macro-level classifier, more than half of them (  X  54%) were not enclosed in any of the hyperspheres constructed for the known malware classes. This suggests that the micro-level classifier can potentially reduce the misclassification of the macro-level binary clas-sifier. In addition, some of the misclassified  X  X ood X  flows may actually correspond to previously unknown malware, but more investigation is needed to verify this.
This paper presents a malware detection approach based on features derived from the layer 3 and layer 4 network flow characteristics. Although the features are more resilient to payload encryption, they have other issues that hamper the applicability of more sophisticated learning algorithms. In this paper we propose a two-phase classification framework with tree-based features to handle the data imperfection is-sues. A weighted linear kernel is developed on the tree-transformed features to effectively train the one class SVM used in identifying the malware type. Experimental results suggest that the proposed framework is more effective than applying random forest on the overall data as well as one-class SVM with RBF kernel on the original features.
Prakash Mandayam Comar and Pang-Ning Tan X  X  research are supported in part by Office of Naval Research grant num-ber N00014-09-0663. [1] L. Breiman. Random forests. Machine Learning , [2] P.-Y. Hao, J.-H. Chiang, and Y.-H. Lin. A new maximal
