 KIRI L. WAGSTAFF, JULIAN PANETTA, and ADNAN ANSAR, RONALD GREELEY, MARY PENDLETON HOFFER, and MELISSA BUNTE, As of January 2011, there were more than 700,000 orbital images of Mars available on the Planetary Data System X  X  Imaging Node (from Mars Odyssey, Mars Express, Mars Global Surveyor, and Mars Reconnaissance Orbiter). The number of images queued up for analysis is so large (and continually growing) that there is a compelling need for automated methods to spot interesting surface features and highlight them for expert review. These features include surface phenomena such as dark slope streaks [Sullivan et al. 2001], dust devil tracks [Balme et al. 2003], new impact craters and gullies [Malin et al. 2006], ground ice excavated by fresh impact craters [Byrne et al. 2009], and more. Of particular value is the ability to automatically identify features that exhibit change, that is, appearances, disappearances, and alterations.

Existing work in this area suffers from two main limitations. To date, most ap-proaches to automated surface feature identification have focused on a single specific feature type, such as craters [Bandeira et al. 2007; Burl et al. 2001; Ding et al. 2010; Florez-M  X  endez 2003; Sawabe et al. 2006] or valleys [Molloy and Stepinski 2007]. While these methods can achieve high precision in detecting the feature type of interest, they are blind to the occurrence of any other features, including the emergence of new phenomena (limitation 1). As a result, new feature types to date have only been dis-covered serendipitously through manual examination of relatively few images, as in the case of new impact craters and gullies [Malin et al. 2006] and excavated ground ice [Byrne et al. 2009]. Conversely, state-of-the-art automated change detection is pri-marily achieved without any consideration of the features sought, by registering two images taken at different times and then performing a pixel-wise comparison to iden-tify any changes at the finest possible granularity [Radke et al. 2005]. Limitation 2 is that often the difference map (or change mask) output requires almost as much time to interpret (through manual effort) as the original pair of images would have.
We propose dynamic landmarking, a new approach to surface feature identification and change detection that addresses both of these limitations. At a high level, our focus is on a content-based approach to analyzing images of planetary surfaces, as distinguished from most prior work that has focused on a pixel-based approach. Our method generates a map of visual salience across the image which is then converted into closed contours (landmarks). This approach is dynamic in that the landmarks are not predefined; instead, they emerge dynamically from the current image X  X  contents and context. We compute descriptive attributes for the landmarks (e.g., size, shape, albedo) and then employ machine learning methods such as decision trees to model and classify the landmarks into one of several known categories. We also permit the classification of a landmark as unknown if it is not well modeled by a known category, which enables the discovery of new landmark types (addressing limitation 1). We have developed an automated method of comparing the landmarks identified in each of a pair of images to quickly detect any changes. Landmark analysis can also be used to interpret a difference map and report the type of changes that are present (e.g., new crater). Both kinds of change detection eliminate much of the manual review other-wise required (addressing limitation 2). At the very least, the result of this analysis provides an immediate focus of attention, directing manual review efforts to the most likely regions.

In this article, we present the details of dynamic landmarking and evaluate it on images of Mars collected by five high-resolution orbital cameras. Using a decision tree classifier, we observe 93.5% accuracy in landmark classification with a highly inter-pretable decision tree model as the result. We demonstrate the successful detection of both new features (fresh impact craters and new dark slope streaks) and vanishing features (disappearing dust devil tracks and bedforms). We also explore the ability to detect changes using images from different instruments, which is much more chal-lenging, but increases the available temporal coverage and enables tighter bounds on the time that a change occurred.

There are several benefits of the dynamic landmarking approach to image analy-sis. First, it greatly accelerates the process of analyzing new images to determine the interesting features they contain, as well as any changes that may be present. Sec-ond, it affords the possibility of detecting entirely new surface features that are not currently known. Third, it enables content-based searching of image archives, for ex-ample,  X  X ist all HiRISE images containing dark slope streaks. X  Fourth, it provides an interpretable summary of any changes in an area that has been imaged multiple times. Finally, it can potentially be used in an onboard setting to enable in situ detection of and response to features and changes of high scientific interest. Dynamic landmarking can be used both to identify surface features and to detect changes. In this section, we review existing work on both topics and explain how our approach differs. As previously noted, much effort has been invested in developing automated method for finding particular features of interest, especially craters. Crater-finding methods have employed template matching [Bandeira et al. 2007; Burl et al. 2001], edge and circle detection [Florez-M  X  endez 2003], Haar-like image texture features and boosting techniques [Ding et al. 2010], and more.

To permit the identification of surface features beyond a prespecified list of known types, we adopt a general approach and detect all salient surface features. Salience (defined more precisely in the next section) is the degree to which a region within the image stands out visually from its surroundings. Computing salience across the im-age yields a salience map. The concept of a visual salience map was first introduced by Koch and Ullman [1985] as a biologically motivated model of bottom-up human visual attention. This map was conceived as the combination of response maps for in-dividual features, such as discontinuities in color, intensity, orientation, and so on. Itti and Koch [2000] used an iterative normalization of each feature X  X  map, by repeatedly applying Difference of Gaussian (DoG) filters to the feature values, prior to summing them into a single global salience map. They found that the system was faster than human analysts at the task of finding military vehicles in cluttered, natural scenes. The same authors evaluated different strategies for fusing the feature inputs into the master salience map [Itti and Koch 2001]. When a specific type of target was sought, tuning per-feature weights based on training examples was most effective. However, in the absence of supervision, the best per formance again came from the DoG iterative normalization approach. These basic, low-level measures of salience frequently cor-relate with image content deemed interesting by human annotators [Elazary and Itti 2008].

Work has also been done on identifying interest points or other distinctive locations in an image, with the goal of enabling robust matching between two images of the same object. Typically these interest points are locations with large intensity gradients, such as the corners and edges identified by the Harris corner detector [Harris and Stephens 1988]. Today, the most common such approach is the identification of Scale-Invariant Feature Transform (SIFT) keypoints [Lowe 2004], which are extracted from an image by applying a pyramid of DoG filters (at different scales) to the image itself. Other approaches make use of intensity histograms to detect distinctive structures and textures [Lee and Chen 2009].

Our salience-based approach differs from these methods in two ways. First, we adopt a statistical definition of salience that emphasizes the deviation of a given pixel from its neighbors. Most prior work in this vein has focused on the use of entropy as the statistical measure of salience [Gilles 1998]. Kadir and Brady [2001] noted that the performance of this approach is very sensitive to the scale of analysis (size of the analysis window) and proposed a new algorithm that also performed automated selection of the appropriate scale for each region. We have found other histogram-based statistical measures to out-perform entropy on the task of identifying surface features.

The second way in which our approach is distinguished is that the goal is to identify salient regions that correspond to meaningful surface features, rather than match-ing keypoints which may have no semantic meaning. The salient regions we seek are closed contours around features with a meaningful spatial extent, so that descriptive properties, such as size, shape, and albedo, can be computed. These in turn enable the classification of the detected features. The work of Achanta et al. [2009] also seeks to identify salient regions. However, their test images were composed by human pho-tographers and typically contain a single prominent object (e.g., frog, flower, leaf) as the center of attention. The image is therefore constructed to guide the eye to the dominant salient object. As a result, their approach is optimized for such images and, therefore, is biased towards finding a small number of large, uniformly salient regions. These assumptions do not suit orbital planetary images of Mars, which are the focus of our study. In these images, which can cover vast expanses of the planetary surface, salient regions are likely to be small and rare. No human photographer composed these images; therefore, identifying the salient regions can be challenging even for human analysts, requiring significant effort in zooming and panning to find items of interest. We have emphasized local measures of salience that can be applied exhaus-tively to the image under study to pull out these small but important salient regions. Traditionally, change detection in a pair of images proceeds by first registering the images and then performing a difference or ratioing operation to highlight any changed pixels.

The state-of-the-art for image registrati on can be divided roughly into those algo-rithms that derive a dense pixel-by-pixel correspondence between images and those that use a sparse correspondence to extract a mathematical transformation (mapping) between the images. Dense methods are most effective when there is little perspective distortion between the two images. These methods commonly employ a Fast Fourier Transform (FFT) to correlate two images and identify where and how they match. A related technique uses mutual information [Viola and Williams 1997; Chen 2003], which is similar to standard correlation but employs an information-theoretic similar-ity metric based on image entropy instead of raw pixel values. This is especially suited to imagery acquired from instruments with ve ry different spectral responses (e.g., vis-ible vs. thermal). However, unless the relative viewing geometry is already known, searching for the best pixel-based registration can be computationally expensive.
Common methods for comparing the registered images include image differencing, in which the pixel values from one image are subtracted from another and any nonzero results are flagged as changes, and image ratioing, in which the pixel values are ra-tioed and any values not equal to 1 are flagged as changes. This basic approach tends to be extremely sensitive to any noise or changes in environmental (e.g., illumination) or sensor (e.g., camera design) attributes, often leading to a plethora of false positive detections [Radke et al. 2005]. More sophisticated methods that can compensate for differences in illumination angles may filter the images to remove the low-frequency component corresponding to base illumination [Toth et al. 2000]. Finally, the registra-tion process itself can provide clues as to where changes have occurred: for example, a low correlation score indicates a poor match even after registration, increasing the likelihood that something has changed. However, sensitivity to noise and high compu-tational cost continue to be open issues for this kind of approach.

We propose a different, landmark-based approach with two possible avenues for change detection: (1) identify regions of high salience (landmarks) and then compare the landmarks in each of a pair of images to find changes, or (2) perform a stan-dard change detection analysis and then identify landmarks in the difference map of changed pixels to provide an interpretation of changes. The first method enables faster operation by avoiding a costly pixel-level registration of the entire image; instead, only the landmarks need be compared to detect changes. The second method is appropriate when small pixel-level changes need to be detected and provides the additional benefit of a semantic interpretation of what has changed. We have developed a landmark-based approach to image analysis that identifies areas of high visual salience (landmarks), extracts additional information about each one, and classifies the landmarks into known (and unknown) categories. The image can then be annotated with a catalog of landmarks it contains. This process is shown in Figure 1. In this example, two of the landmarks that were found were classified as craters, and two were classified as unknown, due to their irregular shapes. Section 3.1 describes different methods for computing salience, and Section 3.2 explains how to perform landmark classification. We can also identify landmarks in two images of the same region taken at different times and compare them to detect any changes (Section 3.3). The nature of regions that will be identified by the dynamic landmarking approach is dictated by the definition of salience used to generate the salience map. We explored three statistical measures of salience that are defined over a local window within the image. Our goal was to evaluate the simplest possible salience measures, with an eye towards the possibility of future incorporation into the onboard setting. All three are less computationally expensive than, for example, the Difference of Gaussians approach [Itti and Koch 2000].

The first salience measure uses entropy [Shannon 1948] to estimate the salience of awindowof w x w pixels centered on location x , y .
 where i ranges over the possible intensity values for pixels in the image (for our 8-bit data, there are 256 values), and P w ( i ) is the probability of observing intensity i within the enclosing w x w window. We estimate these probabilities using a histogram that tallies the occurrence of each pixel value within the window, normalized by the number of pixels in the window. A high entropy value indicates a large amount of contrast within the window, while low entropy indicates a relatively homogeneous window.
While entropy captures the degree of local inhomogeneity, it is an absolute mea-sure that is insensitive to the context outside of the window. If the image consists entirely of high-entropy windows (e.g., random noise), then none of them are salient with respect to the image as a whole. Therefore, we also developed a salience mea-sure that compares the distribution of intensity values in the window ( w x w )tothe distribution of values in a larger enclosing window ( v x v , v&gt;w ) by computing the KL-divergence [Kullback 1959] between the two distributions.

This measure reports high salience when the distribution of values in the smaller window deviates significantly from that of the larger enclosing window.

One drawback of entropy-based (and KL-divergence-based) measures is that they treat each possible pixel value (histogram bin) equally. That is, a 10 x 10 window composed of 99 pixels with intensity 1 and one pixel with intensity 2 has the same entropy as a window with 99 pixels of intensity 1 and one pixel with intensity 255. Yet the latter may be far more visually salient.

To address this limitation, we created a salience measure that is sensitive to the values of the histogram bins. It compares a single central pixel p x , y to its surrounding context window in a contrast-weighted fashion.
 where M is the maximum possible salience value for any pixel using the specified window: M = i ( N  X  1) P ( i ), and N is the number of histogram bins. Salience is the sum of the intensity difference between the central pixel p x , y and the bin value i , weighted by the number of items in that bin, P ( i ).

For all three methods, the salience map is generated by calculating the appropriate salience value for each x , y location within the image.

In general, we found that no single method always performed the best in finding interesting surface features. Each one is sensitive to different types of features. For example, the entropy salience measure (Equation (1)) is particularly good at identi-fying high-contrast features like dark slope streaks. However, the contrast-weighted pixel salience measure (Equation (3)) tends to provide the most reliable overall perfor-mance for a larger class of features.

Given a salience map produced by any of these methods, we create landmarks by constructing closed contours around areas of high salience in the map. The contours are determined by a salience threshold s , which can be selected in a variety of ways. Rather than using a constant threshold for all images, we select the threshold adap-tively, taking into account the distribution of salience values across the entire map. We sort the unique salience values, then set s to be the median of the values higher than the median (the upper quartile). In postprocessing, we typically filter out landmarks with area less than a given number of pixels (which depends on the minimum size of the features of interest). Contour-based landmarks in themselves can be very informative in identifying inter-esting regions within an image (as compared to, e.g., simple interest points). We take the analysis process one step further and classify each landmark into one of several landmark types, thereby ascribing a semantic meaning to each one.

To enable classification, we first calculate the following attributes for each of the landmarks: mean and standard deviation of intensity, area, perimeter, and several shape attributes derived from an ellipse-fit (length of the semimajor and semiminor axes, eccentricity, orientation, error in the ellipse fit, and  X  X uggedness X  or angular-ity) [Casta  X  no et al. 2007]. Each landmark is therefore represented by a feature vector in
Given a list of manually classified landmarks, we train a machine learning classifier to be able to distinguish between the landmark types of interest. In this study, we explored four kinds of classifiers: decision trees [Quinlan 1993], naive Bayes, neural networks [Rumelhart et al. 1986], and support vector machines (SVMs) [Cortes and Vapnik 1995]. All of the algorithms were implemented in Java by the Weka machine learning system [Hall et al. 2009]. Our data set consisted of 767 landmarks manually classified as one of three landmark types: craters, dark slope streaks, or dust devil tracks. Importantly, these landmarks were both outlined and classified manually.
We performed a 10-fold cross-validation experiment to assess how well each classi-fier performed on this task. The dataset was divided into ten equal parts (folds). Each fold in turn was treated as the held-out test set by training a model on the remaining nine folds and then evaluating it on the held-out fold. Combining results on all ten folds yields an estimate of the model X  X  generalization performance. The results are given in Table I. The Naive Bayes classifier, which models each class independently, performed the worst. It classified a large number of the dust devil tracks as dark slope streaks, underscoring the difficulty of separating these two landmark types. The sup-port vector machine improved greatly on this performance, although when employing a linear kernel (similarity measure), it classified all of the dark slope streaks as dust devil tracks. With a Gaussian kernel, which is able to model nonlinear classes, perfor-mance improved to 93.4% (given a search over several  X  values). The best performance was achieved by a neural network.

The decision tree result is particularly interesting because it generates an inter-pretable model of the classification process (see Figure 2). The attribute deemed most informative was  X  X ccentricity X . Landmark s with low eccentricity next have the stan-dard deviation of pixel intensity checked; if this value is low, the landmark is classified as a dust devil track. If it is high, the landmark is deemed a crater. This is a reason-able and meaningful result: craters are nearl y circular features (low eccentricity) with a combination of bright and dark pixels due to shadows cast within the crater (high standard deviation in intensity).

Landmarks with high eccentricity (i.e., el ongated) may be dust devil tracks or dark slope streaks. The model distinguishes them by checking their mean pixel intensities and other attributes. Dark slope streaks many be of low intensity (dark), relatively small area, and a long semi-minor axis; or they may be brighter, with a high standard deviation in intensity, a relatively small perimeter, and a long semi-major axis. The latter case arises from manually outlined dark slope streaks in which the enclosing polygon includes some of the bright surface surrounding the streak (increasing mean intensity and increasing the standard deviation). Dust devil tracks, in this dataset, tend to be much larger and more diffuse than the dark slope streaks.

Another key aspect of this approach to landmark classification is the ability to clas-sify a new landmark as unknown. Each of the learned models will assign a new land-mark this classification if it cannot confidently place it in one of the three known cat-egories. No matter how many types of landmarks are defined and provided to the system for training, it is always important to retain this ability to flag sufficiently novel or unusual features for further manual review. Dynamic landmarking can be used to detect changes in two ways: (1) detect landmarks independently in each image, then compare the two landmark sets to find any differ-ences; or (2) register the two images together, subtract to find changed pixels, and then convert the changed pixels into interpretable landmarks. The first strategy is useful for fast detection of changes in visually salient landmarks, while the second approach is useful for detecting subtle pixel-level changes. 3.3.1. Detecting Landmark Changes. The process of detecting changes based on the landmarks in each image is shown in Figure 3. First, we detect landmarks indepen-dently in each image, then extract the same attributes used for landmark classifica-tion, as described in the previous section. In the next step, we construct a Relative Landmark Graph (RLG) that represents the adjacency relationships between landmarks. The RLG is a graph G =( V , E ) in which there is one vertex in V for each landmark in the image, and there is an unweighted edge in E from v 1 to v 2 if the landmark represented by v 2 is one of v 1  X  X  nearest neighbors. More precisely, we specify a scale parameter r such that the number of nearest neighbors used by the RLG is k = | V | / r , and the connectivity scales with the size of the graph. Each vertex v  X  V is associated with the attributes of its landmark.

The RLG preserves relative position rather than the absolute x,y pixel coordinates of each landmark, increasing the robustness of the system by enabling the matching of landmarks between images that may exhibit a shift or rotation in field of view. The RLG is conceptually similar to the Attributed Relational Graph (ARG) [Graciano et al. 2003], which was developed for matching facial features in digital video sequences, although the ARG is a fully connected graph rather than a neighborhood-based graph like the RLG, the attributes used for the vertices differ, and we make use of a very different graph matching process.

Our approach to detecting changed landmarks is to identify a mapping between the RLG 1 (from image 1) and RLG 2 (from image 2), then flag anything unmatched as either a newly appeared landmark or a landmark that has vanished (see Algorithm 1). This mapping is identified by computing a maximum weight perfect matching on a specially constructed bipartite graph G m .Let V 1 be the vertices from RLG 1 and V 2 be the vertices from RLG 2 . Because the algorithms used to find such a matching require that the two sets of vertices being matched have the same size, we let X = V 1 plus | V 2 | dummy vertices, and Y = V 2 plus | V 1 | dummy vertices. This allows for the degenerate case in which no landmarks in V 1 match any landmarks in V 2 , and so all landmarks are assigned to dummy vertices. Thus, | X | = | Y | = | V 1 | + | V 2 | , and the vertices of G m are X  X  Y .

Each edge in G m (which, note, are different from the edges in the individual RLGs as just defined) is weighted according to the similarity between the two landmarks rep-resented by the vertices that the edge connects. Rather than defining the similarity of two vertices in terms of the landmarks alone, we sought to also include informa-tion from the connectivity of the RLG. Inspired by a similar innovation in the work of Riesen et al. [2007], we developed a similarity measure between two landmark Algorithm 1: Detect landmark changes vertices v 1 and v 2 that combines raw landmark-based similarity ( Sim F )withRLG neighborhood similarity ( Sim N ).
 where N ( v ) is the set of neighboring vertices connected to v in its RLG . Landmark similarity Sim F is computed using the attributes described in Section 3.2 to construct an attribute vector F ( l ) for each landmark l . The vectors are normalized to have a zero mean for each individual attribute. Neighborhood similarity Sim N is the score obtained when recursively computing the best bipartite matching between the nodes in v 1 and v 2  X  X  neighborhoods, respectively. This score is the sum of all edge weights matching M is obtained by computing the best bipartite matching between X and Y , subject to an affine constraint: the matching must only result in translation, rotation, scaling, or shear between the two images.

Early experiments with computing similarity based solely on the feature vectors ( Sim F ) indicated that it can yield very unintuitive results, since landmarks that are similar in shape and appearance but in very different locations in the images may be matched together. In contrast, Sim N requires that there be a good match between the two landmarks X  neighborhoods and is therefore more robust against isolated spurious matches.

We compute a candidate bipartite matching M using the Hungarian (Munkres) al-gorithm [Kuhn 1955]. The original version of this algorithm has complexity O ( n 4 ); we employed a more efficient variant that runs in O ( n 3 ) [Edmonds and Karp 1972]. We then refine this candidate matching to enforce the affine transformation constraint. We employ a simplified version of the RANSAC algorithm [Fischler and Bolles 1981] to search for the optimal affine transform using the candidate matching as  X  X eeds X . That is, we repeatedly randomly select three matched landmark pairs obtained from the Hungarian matching algorithm and compute a hypothesized transform T that maps the three landmarks from L 1 to their matches in L 2 . We compute the error E of transform T based on the distance from each landmark in L 1 to its closest landmark in L 2 .
 We repeat this process on the order of 100 times and select the best transform found, so Finally, each landmark is matched with its corresponding overlapping landmark in the other image, if one exists. If not, the landmark is added to the set C v of vanished landmarks (if it only appears in L 1 )or C n of new landmarks (if it only appears in L 2 ). 3.3.2. Interpreting Pixel Changes as Landmarks. An alternative approach to using land-marks in conjunction with change detection is to first detect changes at the pixel level, then identify landmark regions within the resulting difference map.

To detect and automatically interpret pixel changes, we first perform a traditional image registering and diffe rencing process. The images we match are typically ortho-projected and are assumed to have known scale and known orientation. The initial match is accomplished by image correlation using either the Fast Fourier Transform (FFT) or a mutual information [Chen 2003; Viola and Williams 1997] matcher to adjust for relative shift only. The latter is appropriate when the images come from different sensors and may be highly dissimilar in appearance due to differences in illumination or sensor response. To allow for error impreci sion in the specified scale and orientation of each image, we perform an explicit search around these values to find the best match between the images. If the ortho-proje ctions are perfect X  X ccurately taking into account imaging geometry, spacecraft motion , and local topography X  X hen this initial match will be accurate down to the individual pixel level. However, in our experience with Mars orbital images, this is typically not the case, even for map-projected image products. Small differences in the image processing pipelines used for each instrument can result in registration errors on the order of tens of pixels, which translates to tens or hundreds of meters of mismatch, depending on the instrument resolution. Such a result is inadequate for automated differencing and landmark analysis.

We therefore developed a match refinement process that improves on the standard registration. First, we identify a sparse set of keypoints in the pair of images. In most cases, corner detectors [Harris and Stephens 1988] work well for keypoint find-ing, but any of the salience measures defined in Section 3.1 could also be employed (using single-pixel peaks in salience rather than landmark contours). These keypoints are matched to each other across the image pair using either normalized cross cor-relation or mutual information as a similarity metric. The former is computation-ally cheaper while the latter may be required in cases of appearance dissimilarity. Mismatches are eliminated using basic geometric constraints on the point correspon-dences. The matched keypoints then serve as vertices in a triangulation of each image, and corresponding triangular facets are warped to each other using cubic interpola-tion. The resulting image transformation produces significantly improved pixel-level registration.

Once a good registration is available, we pe rform a standard differencing analysis, yielding a real-valued map of the intensity change for each pixel in the image. We then apply landmark identification to the difference map to identify salient changed regions, which are output as landmark changes.
 We evaluated this approach to change detection on several Mars orbital image datasets, both comparing images from the same instrument and comparing images from different instruments. We employed image data collected by five different instruments on four Mars orbiters. The primary difference between these cameras is their maximum spatial resolution, given in Table II. Identifying changes between images with different resolutions can be challenging, and we specifically sought to test this case. The cameras have other relevant differences, such as viewing geometry and sensitivity, that add to the diffi-culty of the change detection problem. The data from each of these instruments is publicly available online.

To conduct an evaluation of change detection, we compiled a catalog of overlapping image pairs. NASA X  X  Planetary Data System (PDS) provides cumulative index files (cumindices) that summarize the parameters for each orbital image collected by these imagers. For most cameras, the cumindex contains the geographic coordinates of the four image corners, which can be used to determine overlap relationships. Using the assumption that the edges of the images are straight lines, we analyzed the index files of each instrument to identify all pairs of overlapping images. The algorithm identifies image pairs by looking for edge intersections, and in case one image lies completely within another, by determining whether the four corner points lie inside or outside the other image in the pair. If a point lies inside a closed polygon, the angles of the polygon segments (as seen from the point) sum to 2  X  ; if it is outside, they sum to zero.
The same method can in theory be applied to find overlaps between images taken by different cameras. Howeve r, the cumindex entries and coordinate systems are not uniform across instruments, so a straightforward application of this method yields approximate but not precise results. Each candidate overlapping pair that involved two different instruments was manually checked to confirm true overlap. We explored three surface features of intere st, each of which give rise to contemporary changes on the surface of Mars: fresh impact craters, dust devil tracks, and dark slope streaks. 4.2.1. Fresh Impact Craters. The present-day impact crate ring rate is high enough for new impacts to occur over the duration of ongoing space missions. Malin et al. [2006] identified new impacts by the ejecta that appeared between two images taken from Mars orbit. They then followed up with observations at higher resolution that resolved the crater itself, dispelling any doubt that the ejecta were caused by an impact. The appearance of new crater ejecta is another ongoing surface process that can be studied with automated change detection. Later, Byrne et al. [2009] observed recent impact craters that revealed excavated subsurface ice, of interest to current and future Mars investigations. Over several months, the ice was observed to retreat and sublimate, providing data about the depth and stability of subsurface ice. Additional detections of such new craters would improve our understanding of subsurface ice location and distribution. 4.2.2. Dust Devil Tracks. In the current Martian environment, the dominant active process of modification is the interaction of the atmosphere with the surface through wind [Geissler 2005; Sagan et al. 1972]. It is likely that aeolian, or wind, processes have been active throughout the geological evolution of Mars. Global, regional, and lo-cal dust storms have been recorded through tel escopic and spacecraft observations for decades. In the past few years, images from the Mars Exploration Rovers (MER) and from orbiters such as Mars Odyssey, Mars Express, and Mars Reconnaissance Orbiter, have demonstrated that atmospheric vortexes, or dust devils, play an important role in the generation of dust storms, with perhaps as much as half of the atmospheric dust load being injected by dust devils [Whelley and Greeley 2008]. This estimate is based on the study of dust devil tracks (albedo features left by the passage of dust devils) extrapolated globally.

Much remains to be learned about the role of dust devils as a mechanism for surface modification and their significance for atmospheric science. While MER and orbiter data provide important insights into dust devils, there is a need for a rapid and effi-cient method for the detection of active dust devils due to the large volume of images being acquired. There is also a need for mapping and monitoring the tracks through time. The Watch routine [Casta  X  no et al. 2008] implemented on MER enables real-time detection of active dust devils from a ground perspective. We seek a similarly automated approach to identifying and cataloguing dust devil tracks from orbit. 4.2.3. Dark Slope Streaks. Slope streaks are downhill mass movements on Mars that are common in dust-covered areas of Mars. T hey are typically less than one kilometer long and less than a hundred meters wide. Sullivan et al. [2001] first discovered that new slope streaks had appeared in overlapping MOC images, indicating that they were the result of an active and ongoing process on Mars today. Given the subsequent accu-mulation of many more such examples, the formation of these streaks is now known to be common. The entire slope streak population is believed to renew every few decades to few centuries [Aharonson et al. 2003; Sch  X  orghofer et al. 2007]. Slope streaks may also be a significant form of sediment transport [Phillips et al. 2007].

Slope streaks can be darker or lighter than the surrounding area, although most of those currently known are dark. Bright slo pe streaks have not been observed to form in sudden events; instead they may represent faded dark slope streaks [Sch  X  orghofer et al. 2007]. In this study, we focus on dark slope streaks.

The nature of the material that flows downhill as well as the events that trigger new slope streaks are still being debated. A synthesis of the voluminous existing and future streak observations would improve our understanding of the formation mecha-nism and the nature of the materials involved. Specifically, we seek to understand the constraints on the time periods and other conditions under which the streaks form, as well as information about their spatial relationship to other features, particularly those experiencing change. We conducted several tests of dynamic landmarking with the joint goals of analyzing a variety of feature types for different scientific goals and in a variety of settings (images from the same instrument or different instruments).
 4.3.1. Fresh Impact Craters. Fresh impact craters are of scientific interest because of their frequency and because it was recently discovered that they can reveal subsurface ice [Byrne et al. 2009]. We selected a region of western Acidalia Planitia with known impact crater activity to evaluate landmark-based change detection. Figures 4(a,b) show subregions of two CTX images before and after an impact cratering event. We applied dynamic landmarking independently to the two images. The detected land-marks are shown in blue in Figures 4(c,d). After performing the landmark match-ing process described in Section 3.3.1, we plotted the unmatched landmarks in red in Figures 4(e,f). Figure 4(f) shows a zoomed-in view of new landmarks. The minimum landmark size was 50 pixels, so the smallest features were not identified as land-marks. There were also no false positives detected; all of the identified changes were genuine ones.

We also applied the trained landmark classifier described in Section 3.2 to assign a type automatically to the detected changes. The decision tree incorrectly classifies the new landmarks as dust devil tracks instead of craters because the new landmarks have very high eccentricity ( &gt; 0 . 7) and a relatively low standard deviation in their intensities ( &lt; 30). Examining the decision tree in Figure 2, it is clear that such land-marks cannot be assigned to the crater class . The decision tree was trained on craters that are mostly circular (low eccentricity) and that have a high standard deviation in intensity due to interior shadows cast by the crater rim. The new impact craters deviate significantly from this kind of crater, and they indicate the need for a new landmark category.
 We used the same change detection approach to analyze fresh impact craters in HiRISE images of a nearby region (not shown). The craters were present in both images, but changes were still detected X  X hich turned out to be the sublimation of ground ice that had been excavated by t he impact craters. These results sup-port the claim that dynamic landmarking effectively detects both appearances and disappearances. 4.3.2. New Dust Devil Tracks. We studied several orbital images of regions of dust devil activity to characterize the relevant changes. Unlike impact craters, dust devil tracks can both appear and vanish in the course of a Martian season. One area of particu-lar interest is the El Dorado dune field in the Columbia Hills of Gusev crater, where dust devil activity has been documented not only from orbit but also from the ground through the Mars Exploration Rovers.

We analyzed 171 pairs of HiRISE images of the El Dorado dune field. The images were taken over the period from November 22, 2006, to February 15, 2010. Dust deviltrackchangestendtobemoresubtlet han fresh impact craters, lacking sharply defined edges. We therefore employed the second approach to change detection, which involves a registration and differencing step followed by landmark identification in the difference map (Section 3.3.2). Some of the image pairs (particularly those taken close in time) showed no changes at all. Others showed significant dust devil activity which left new tracks and, in some cases, erased old ones.

Figures 5(a,b) show an example pair of HiRISE El Dorado images. These images are separated by two Martian years and show evidence of significant changes in the dis-tribution of dust devil tracks (dark, diffuse streaks across the dune field). Figure 5(c) shows the corresponding difference map, in which areas of relative brightening are shown in yellow and those with relative darkening are shown in blue. (The black border represents the edges of the triangulation calculated by matching keypoints be-tween the images.) Most prominent is the appearance of a new, dark track going from the middle left to the lower center of the image, but other changes are also evident, including both new tracks and the fading of old tracks.

A New Discovery. While analyzing the HiRISE image pairs, we discovered an un-expected feature change that was unrelated to our study of dust devil tracks. Near the eastern edge of the dune field, the dynamic landmarking system identified several compact, localized features that showed unusual brightening and darkening behav-ior. Figures 6(a X  X ) show zoomed-in views of this region at three different times. The associated difference maps are given in Figures 6(d,e) and show that the spots first brighten and then darken. While quite visible at this level of magnification, these fea-tures would likely otherwise have gone entirely unnoticed at a typical level of exami-nation. We used landmark detection in the difference image to identify these regions of change, yielding Figure 6(f). Manual examination confirmed that these are genuine changes, with no false positives. The automated analysis served to direct attention to an unexpected area.

The spots appear to be on or part of slight topographic highs, possibly extensions of larger bright bedforms and outcrops that can be seen to the south and east of this region, including Home Plate. If so, they could be exposed carbonates [Morris et al. 2010] or hydrothermally influenced su lfate salts [Schmidt et al. 2008]. Image PSP 001513 was taken in southern fall, while PSP 003900 was taken in the following spring. Spring winds could have removed a dust layer, revealing the brighter bed-forms. Image PSP 009174 was taken in early winter after an intervening dust devil season [Greeley et al. 2010] and summer dust storm, so there would have been an excess of atmospheric dust which blanketed the surface when the winds died down. Further investigation is ongoing.

This discovery illustrates the exploratory power of dynamic landmarking: while seeking changes of one particular type, it is still possible to discover other changes along the way. 4.3.3. New Dark Slope Streaks. A detailed manual survey of Nicholson Crater, using numerous overlapping images, was carried out by King et al. [2010]. The goal of the survey was to catalog all appearances of dark slope streaks so as to constrain their time of formation as tightly as possible. With good bounds on the formation time, we can determine whether there is a relationship between streak formation and the Martian season, which would help inform models of the formation process. Using seven THEMIS, three CTX, one HiRISE, and two HRSC images spanning three Mars years, 17 new streaks or streak groups were identified, along with hundreds of persisting streaks. There was no seasonal dependence to the formation rates, suggesting that the streaks are not related to, for example, warming temperatures or melting water. There was also little spatial correlation, s uggesting that the streaks are not due to regional events, such as meteorite impacts or quakes. Possible mechanisms that are consistent with the observations would be dust disturbances caused by passing dust devils or sudden dust layer collapses.

We followed up on this manual survey with an automated analysis of the same area. This study also provided the opportunity to test our system X  X  ability to detect changes in images collected by different instruments. The merits of using multiple instruments have long been recognized, but differences in resolution, geometry, and spectral response are still significant challenges.
 For these images, we again used the change detection process described in Section 3.3.2. We compared two sets of images of the north rim of Nicholson Crater; both sets consisted of an HRSC-CTX pair.
 The change detection analysis identified several changes in both pairs. An example of the results for Pair 2 is shown in Figure 7. There are significant differences in spatial resolution, illumination, and camera geometry between the two instruments (HRSC and CTX), as shown in Figures 7(a) and (b). The registration and differencing process yielded the difference map shown in Figure 7(c), in which pixels that are darker in the later image are tinted blue and those that are brighter in the later image are tinted yellow. Ignoring the broad illumination variation, we can see that there is a new dark slope streak that has appeared near the center of the field of view. The field of view shown here is only a tiny fraction of the full images that were analyzed, zoomed in for illustration. In addition to the new dark slope streak, it is also evident that some of the dark slope streaks near the right side of the image have undergone some brightening. This is typical for dark slope streaks which fade over time due to dust deposition. Importantly, the multitude of persisting slope streaks, which are present in both images, do not appear in the difference image (i.e., they are correctly ignored as unchanging). This greatly accelerates the process of reviewing the area manually since it focuses attention on the true changes and diminishes everything else.
The complete analysis of both pairs of images led to the discovery of additional new streaks, including streaks that were missed during the manual survey of this area. The difference imaging highlighted the four known new streaks previously identified manually for these images, plus six additional new streaks that had been overlooked or considered ambiguous (four of these streaks were smaller than the minimum streak size sought). Two additional new streak-like features were determined to be likely shadows. We summarize these results as Overall, the thorough and precise nature of the analysis convincingly demonstrated the ability to automatically detect these changes and could provide a valuable advance for any future dark slope streak study by re ducing the manual time and effort required to identify newly forming streaks. This article presents dynamic landmarking, a new approach to orbital image anal-ysis that supports two common analysis goals: interpretation of interesting surface features and change detection. Dynamic landmarking focuses on the identification of visually salient landmarks within an image. These landmarks can be automatically classified to provide a semantic interpretation of the image X  X  contents, and landmarks obtained from different images can be compared to detect any changes. For subtle features that are of low visual salience but high scientific interest, such as dust devil tracks, dynamic landmarking can be applied to the output of a traditional registra-tion and differencing process to direct atte ntion to local regions of significant change. This is particularly useful for very large images, such as those collected by CTX and HiRISE.

We have presented quantitative results evaluating the performance of several dif-ferent landmark classifiers and illustrative examples of the ability of dynamic land-marking to detect changes X  X oth appearances and disappearances. In the future, we plan to evaluate the system more extensively on a larger suite of images, ideally in parallel with human analysts so that we can directly compare the nature and extent of changed features that are found by manual and automated approaches.

To date we have implemented dynamic landmarking in a ground-based setting, ana-lyzing archived images that have already been transmitted from Mars to Earth. How-ever, the same kind of approach could be used onboard spacecraft to inform and direct the planning process. The spacecraft could identify landmarks in each image, classify them, and prioritize the images for downlink based on their contents and the current science priorities of the mission. The detection of a particularly high-interest feature type could cause an onboard planner to schedule a repeat observation of the same location to obtain an additional image with higher spatial or spectral resolution. Fur-ther, dynamic landmarking could potentially enable onboard change detection. While it would be infeasible to permanently store every image in onboard memory to permit later comparison when the same area is imaged, it is quite possible to store only the landmarks identified in each image in a compact catalog form. When the same area is imaged later, the extracted landmarks c an be directly compared and any changes noted and used to inform additional planning.

Our focus in this article has been on images collected by Mars orbiters, motivated by the rich variety of such instruments and datasets currently available. Other inter-esting places within the solar system to apply dynamic landmarking include Europa, where surface changes in the ice structures are hypothesized but have not yet been observed [Phillips et al. 1998]; Enceladus, with its active jets caused by cryovolcan-ism [Porco et al. 2006]; and Io, with several active volcanoes that create both plumes and new surface deposits [Morabito et al. 1979]. Upcoming missions, such as the pro-posed Jupiter Europa Orbiter (JEO), could provide a platform for initial onboard ex-periments with dynamic landmarking.

More information about this work can be obtained at http://landmarks.jpl.nasa .gov/ .

