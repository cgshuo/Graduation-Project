 Online debate platforms, like Debatepedia 1 , Twit-ter 2 and many others, are becoming more and more popular on the Web. In such applications, users are asked to provide their own opinions about selected issues. However, it may happen that the debates become rather complicated, with several arguments supporting and contradicting each others. Thus, it is difficult for potential participants to understand the way the debate is going on, i.e., which are the current accepted arguments in a debate. In this pa-per, we propose to support participants of online de-bates with a framework combining Textual Entail-ment (TE) (Dagan et al., 2009) and abstract argu-mentation theory (Dung, 1995). In particular, TE is adopted to extract the abstract arguments from natural language debates and to provide the rela-tions among these arguments; argumentation theory is then used to compute the set of accepted argu-ments among those obtained from the TE module, i.e., the arguments shared by the majority of the par-ticipants without being attacked by other accepted arguments. The originality of the proposed frame-work lies in the combination of two existing ap-proaches with the goal of supporting participants in their interactions with online debates, by automat-ically detecting the arguments in natural language text, and identifying the accepted ones. We evaluate the feasibility of our combined approach on a set of arguments extracted from a sample of Debatepedia. TE was proposed as an applied framework to cap-ture major semantic inference needs across applica-tions in NLP, e.g. (Romano et al., 2006; Barzilay and McKeown, 2005; Nielsen et al., 2009). It is de-fined as a relation between two textual fragments, i.e., the text ( T ) and the hypothesis ( H ). Entailment holds if the meaning of H can be inferred from the meaning of T, as interpreted by a typical language user. Consider the pairs in Example 1 and 2. A system aimed at recognizing TE should detect an entailment relation between T1 and H (Example 1), and a contradiction between T2 and H (Example 2).
As introduced before, our paper proposes an approach to support the participants in forums or debates to detect the accepted arguments among those expressed by the other participants on a certain topic. As a first step, we need to (i) automat-ically recognize a participant X  X  opinion on a certain topic as an argument, as well as to (ii) detect its relationship with the other arguments. We therefore cast the described problem as a TE problem, where the T-H pair is a pair of arguments expressed by two different participants on a certain topic. For in-stance, given the argument  X  X he use of cell-phones while driving is a public hazard X  (that we consider as H as a starting point), participants can support it expressing arguments from which H can be inferred (Example 1), or can contradict such argument with opinions against it (Example 2). Since in debates arguments come one after the other, we extract and compare them both with respect to the main issue, and with the other participants X  arguments (when the new argument entails or contradicts one of the arguments previously expressed by another participant). For instance, given the same debate as before, a new argument T3 may be expressed by a third participant with the goal of contradicting T2 (that becomes the new H (H1) in the pair), as shown in Example 3.

TE provides us with the techniques to detect both the arguments in a debate, and the kind of relation underlying each couple of arguments. The TE sys-tem returns indeed a judgment (entailment or con-tradiction) on the arguments X  pairs, that are used as input to build the argumentation framework, as de-scribed in the next Section. Starting from a set of arguments and the attacks (i.e., conflicts) among them, a (Dung, 1995)-style argu-mentation framework allows to detect which are the accepted arguments. Such arguments are consid-ered as believable by an external evaluator who has a full knowledge of the argumentation framework, and they are determined through the acceptability semantics (Dung, 1995). Roughly, an argument is accepted, if all the arguments attacking it are re-jected, and it is rejected if it has at least an argument attacking it which is accepted. An argument which is not attacked at all is accepted.

Aim of the argumentation-based reasoning step is to provide the participant with a complete view on the arguments proposed in the debate, and to show which are the accepted ones. In our framework, we first map contradiction with the attack relation in ab-stract argumentation; second, the entailment relation is viewed as a support relation among abstract argu-ments. The support relation (Cayrol and Lagasquie-Schiex, 2011) may be represented as: (1) a relation among the arguments which does not affect their ac-ceptability, or (2) a relation among the arguments which leads to the introduction of additional attacks.
Consider a support relation among two argu-ments, namely A i and A j . If we choose (1), an at-tack towards A i or A j does not affect the acceptabil-ity of A j or A i , respectively. If we choose (2), we introduce additional attacks, and we have the follow-ing two options: [Type 1] A i supports A j then A k attacks A j , and [Type 2] A i supports A j then A k at-tacks A i . The attacks of type 1 are due to inference: A i entails A j means that A i is more specific of A j , thus an attack towards A j is an attack also towards A . The attacks of type 2, instead, are more rare, but they may happen in debates: an attack towards the more specific argument A i is an attack towards the more general argument A j . In Section 4, we will consider only the introduction of attacks of type 1.
For Examples 1, 2, and 3, the TE phase returns the following couples: T1 entails H, T2 attacks H, T3 attacks H1 (i.e. T2). The argumentation module maps each element to its corresponding argument: H AF (Figure 1) shows that the accepted arguments are { A 1 ,A 2 ,A 4 } , meaning that the issue  X  X he use of cell-phones while driving is a public hazard X  ( A 1 ) is considered as accepted. Figure 2 visualizes the com-plete framework of the debate  X  X se of cell phones while driving X  on Debatepedia. Accepted arguments are double bordered.
 We experiment the combination of TE and argumen-tation theory to support the interaction of online de-bates participants on Debatepedia, an encyclopedia of pro and con arguments on critical issues. Data set. To create the data set of arguments pairs to evaluate our task 3 , we randomly selected a set of topics (reported in column Topics , Table 1) of De-batepedia debates, and for each topic we coupled all the pros and cons arguments both with the main ar-gument (the issue of the debate, as in Example 1 and 2) and/or with other arguments to which the most recent argument refers, e.g., Example 3. Using Debatepedia as case study provides us with already annotated arguments ( pro  X  entailment 4 , and cons  X  contradiction ), and casts our task as a yes/no en-tailment task. As shown in Table 1, we collected 200 T-H pairs, 100 used to train the TE system, and 100 to test it (each data set is composed by 55 entailment and 45 contradiction pairs). 5 Test set pairs concern completely new topics, never seen by the system. TE system. To detect which kind of relation un-derlies each couple of arguments, we used the EDITS system (Edit Distance Textual Entailment Suite), an open-source software package for recog-nizing TE 6 (Kouylekov and Negri, 2010). EDITS implements a distance-based framework which as-sumes that the probability of an entailment relation between a given T-H pair is inversely proportional to the distance between T and H. Within this frame-work, the system implements different approaches to distance computation, providing both edit dis-tance algorithms and similarity algorithms.
 Evaluation. To evaluate our combined approach, we carry out a two-step evaluation: we assess (i) the performances of the TE system to correctly assign the entailment/contradiction relations to the pairs of arguments in the Debatepedia data set; (ii) how much such performances impact on the goals of the argumentation module, i.e. how much a wrong as-signment of a relation between two arguments leads to an incorrect evaluation of the accepted arguments.
For the first evaluation, we run the EDITS sys-tem off-the-shelf on the Debatepedia data set, ap-plying one of its basic configurations (i.e. the dis-tance entailment engine combines cosine similarity as the core distance algorithm; distance calculated on lemmas; stopword list included). EDITS accu-racy on the training set is 0.69, on the test set 0.67 (a baseline applying a Word Overlap algorithm on tokenized text is also considered, and obtains an ac-curacy of 0.61 on the training set and 0.62 on the test set). Even using a basic configuration of EDITS, and a small data set (100 pairs for training) performances on Debatepedia test set are promising, and in line with performances of TE systems on RTE data sets.
As a second step of the evaluation, we consider the impact of EDITS performances on arguments ac-ceptability, i.e., how much a wrong assignment of a relation to a pair of arguments affects the computa-tion of the set of accepted arguments. We identify the accepted arguments both in the correct AF of each Debatepedia debate of the data set (the gold-standard, where relations are correctly assigned), and on the AF generated basing on the relations assigned by EDITS. Our combined approach ob-tained the following performances: precision 0.74, recall 0.76, accuracy 0.75, meaning that the TE sys-tem mistakes in relation assignment propagate in the AF , but results are still satisfying and foster further research in this direction. DebateGraph 7 is an online system for debates, but it is not grounded on argument theory to decide the accepted arguments. Chasnevar and Maguit-man X  X  (2004) system provides recommendations on language patterns using indices computed from Web corpora and defeasible argumentation. No NLP is used for automatic arguments detection. Carenini and Moore (2006) present a computational frame-work to generate evaluative arguments. Based on users X  preferences, arguments are produced follow-ing argumentation guidelines to structure evaluative arguments. Then, NL Generation techniques are ap-plied to return the argument in natural language. Un-like them, we do not create the arguments, but we use TE to detect them in texts, and we use Dung X  X  model to identify the accepted ones. Wyner and van Engers (2010) present a policy making support tool based on forums, where NLP and argumentation are coupled to provide well structured statements. Be-side the goal, several points distinguish our proposal from this one: (i) the user is asked to write the in-put text using Attempt to Controlled English, with a restricted grammar and vocabulary, while we do not support the participant in writing the text, but we automatically detect the arguments (no language restriction); (ii) a mode indicates the relations be-tween the statements, while we infer them using TE; (iii) no evaluation of their framework is provided. Several research lines are considered to improve the proposed framework: first, the use of NLP to de-tect the arguments from text will make argumenta-tion theory applicable to reason in real scenarios. We plan to use the TE module to reason on the introduc-tion of the support relation in abstract argumentation theory. We plan to extend our model by consider-ing also other kinds of relationships among the ar-guments. Moreover, given the promising results we obtained, we plan to extend the experimentation set-ting both increasing the size of the Debatepedia data set, and to improve the TE system performances to apply our combined approach in other real applica-tions (considering for instance the presence of un-related arguments, e.g. texts that do not entail nor contradict).
