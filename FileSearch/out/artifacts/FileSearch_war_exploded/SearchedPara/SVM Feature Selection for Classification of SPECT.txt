
Alzheimer X  X  disease is the most frequent type of demen-tia for elderly patients. Due to aging populations the occur-rence of this disease will increase in the next years. Early diagnosis is crucial to be able to develop more powerful treatments. Brain perfusion changes can be a marker for Alzheimer X  X  disease. In this article we study the use of SPECT perfusion imaging for the diagnosis of Alzheimer X  X  disease differentiating between images from healthy sub-jects and images from Alzheimer X  X  disease patients. Our classification approach is based on a linear programming formulation similar to the 1-norm support vector machines. In contrast with other linear hyperplane-basedmethods that perform simultaneous feature selection and classification, our proposed formulation incorporates proximity informa-tion about the features and generates a classifier that does not just select the most relevant voxels but the most relevant  X  X reas X  for classification resulting in more robust classi-fiers that are better suitable for interpretation.
This approach is compared with the classical Fisher lin-ear discriminant (FLD) classifier as well as with statistical parametric mapping (SPM).

We tested our method on data from four European insti-tutions. Our method achieved sensitivity of 84.4% at 90.9% specificity, this is considerable better the human experts. Our method also outperformed the FLD and SPM tech-niques. We conclude that our approach has the potential to be a useful help for clinicians.
Alzheimer X  X  disease (AD) is the most frequent type of dementia for elderly patients. Due to aging populations its occurrence will still increase. Even though no defini-tive cure has been found for this disease, reliable diagnosis is useful for excluding other dementias, choosing the right treatment and for the development of new treatments.
AD is diagnosed using the criteria from the National In-stitute of Neurological and Communicative Disorders and Stroke and Alzheimer X  X  Disease and Related Disorders As-sociation (NINCDS-ADRDA) [1]. In practice the main tool for evaluating patients are neuro-psychologic tests, that test abilities like memory and language. The Mini Mental State Examination (MMSE) is the most widely used of these tests [2].

Brain images can also provide some helpful indication of AD. Magnetic resonance imaging (MRI) is used to study possible anatomical changes of the brain [3]. Images show-ing the local perfusion (amount of blood flow) of the brain can be used for the diagnosis of AD because the perfusion pattern is affected by the disease. In this article we will look into the use of cerebral perfusion imaging acquired by sin-gle photon emitting computer tomography (SPECT) using technetium-99m hexamethylpropylene amine oxime (HM-PAO) as the tracer. SPECT imaging is a largely accepted clinical modality for AD diagnosis. Even though the perfu-sion pattern and its evolution is not the same for all patients some hypo-perfusion patterns seem to be typical for the dis-ease. There are three main regions mentioned in literature attained by hypo-perfusion[4], 1. the temporo-parietal re-gion, 2. the posterior cingulate gyri and precunei, and 3. the medial temporal lobe. The first region is known as the predominant pattern for AD, however this region was not found for early AD [5]. The second region is probably more specific and more frequent in early AD [6]. Previous patho-logical studies have suggested that the third region is the first affected by the disease [7], however in practice it is only observed in more advanced stages of the disease [6].
There is not one single perfusion pattern that differenti-ates AD patients form healthy subjects. Thus it might be useful to have tools that could assist physicians in this diffi-cult task. In this article we will present a method that does not need any explicit knowledge about the perfusion pattern of AD patients.

Some approaches for a computer aided diagnosis (CAD) system for the analysis of SPECT images for AD can be found in literature. The first family is based on the anal-ysis of regions of interest. The mean values for these re-gions are analyzed using some discriminant functions (see e.g. [8][9]).

The second approach is statistical parametric mapping (SPM) and its numerous variants. Statistical parametric mapping is widely used in the neuro-sciences. Its frame-work was first developed for the analysis of SPECT and PET studies, but is now mainly used for the analysis of func-tional MRI data. It was not developed specifically to study a single image, but for comparing groups of images. One can use it for diagnostics by comparing the image under study to a group of normal images.

Statistical parametric mapping consists of doing a voxel-wise statistical test, in our case a t-test, comparing the val-ues of the image under study to the mean values of the group of normal images. Subsequently the significant voxels are inferred by using random field theory (see e.g. [10] for a full description of SPM). A largely used freely available im-plementation called SPM99 [11] has been developed and is used in this article as comparison to our approach.
In this article we will propose another approach using as less a-priori information about the pathology as possible, by obtaining it implicitly from image databases. Another important aspect is that our approach is global. that all the information in the image can be used at once in contrast to more local approaches, e.g mono-variate methods like SPM. A multi-variate approach generally increases sensi-tivity at the price of loosing regional specificity (e.g. depict-ing local hypo-perfusion regions). However in the approach presented in this paper compared to our earlier work [12] we use feature selection while trying to add spatial constraints to the classification.

The following section first discusses the pre-processing of the data, next we describe our proposed mathematical programming formulation. Unlike the traditional SVM-like formulations, spatial information about the feature (vox-els) locations is incorporated into the optimization problem. This leads to feature selection where the classifier depends on regions in the brain ins tead of isolated non-connected voxels. In section 3 we present the data we used for our ex-periments. It consists of real brain SPECT images obtained from four different institutions. The results on the data are presentedinsection4anddiscussedinsection5.
We now describe the notation used in this paper. The notation A  X  R m  X  n will signify a real m  X  n matrix. For such a matrix, A will denote the transpose of A and A i will denote the i -th row of A . All vectors will be column vectors. For x  X  R n , x p denotes the p -norm, p =1 , 2 ,  X  .A vector of ones in a real space of arbitrary dimension will be denoted by e . Thus, for e  X  R m and y  X  R m , e y is the sum of the components of y . A vector of zeros in a real space of arbitrary dimension will be denoted by 0 .A separating hyperplane , with respect to two given point sets A and B is a plane that attempts to separate R n into two halfspaces such that each open halfspace contains points mostly of A or
B .
In the classifier based approach we need the assump-tion that the same position in the volume coordinate system within different volumes corresponds to the same anatomi-cal position. This makes it possible to do meaningful voxel-wise comparisons between images. However this assump-tion is not met by the images without pre-processing: First of all, the subject which is being imaged, is not always po-sitioned at the same position in the reference frame of the imaging device. This reference frame defines where e.g. the brain is positioned in the image. Secondly the anatomy does not always have the same shape and size between different subjects. For example, the size and shape of the skull can already be largely different between subjects. This means that we need to spatially register the volumes. In our appli-cation we do not have detailed knowledge of the anatomy of our subjects as only HMPAO-SPECT images of the sub-jects were available. These images are so-called functional images. They only depict the regional blood flow of the subject. The regional cerebral blood flow provides us of course with some gross information about the anatomy, but only based on the fact that there is a relationship between the blood flow, and the underlying anatomy. Understanding this characteristic of HMPAO SPECT images is fundamen-tal for the choice of the registration method.

Because of the limited anatomical information available in the volumes we chose to estimate affine transformations between the volumes and not use transformations with a larger number of degrees of freedom. We used the correla-tion ratio as the similarity measure [13] that we minimized using Powell optimization [14]. To obtain a more robust result we used the following procedure. First of all, we reg-istered all volumes to a single volume, then we calculated a mean volume. This mean volume was first put on the mid-sagittal plane by registering it with a flipped version (see [15]). Subsequently it was made to be symmetrical by tak-ing the mean of itself with a flipped version. Finally all volumes were matched to this volume.

HMPAO SPECT imaging generates volumes that only give a relative measure of the blood flow. The blood flow measure is relative to the blood flow in other regions of the brain. Direct comparison, of the voxel intensities, between images, even different acquisitions of the same subject, is thus not possible without normalization of the intensities.
For all the experiments, we normalize the intensities by applying an affine transformation to the intensities. The transformation parameters are estimated on the training set of each experiment such that the intensities for each voxel position have zero mean and standard deviation of one for all the training subjects. We choose this very common data normalization since it provides numerical stability to the al-gorithms involved.
Because the hypo-perfusion pattern for early AD is not very well defined we choose to develop a method where we do not use any explicit knowledge about the typical perfu-sion patterns. We use implicit knowledge about the perfu-sion patterns by using a database of images of AD patients and normal subjects. To separate the images we use a classi-fier using the voxel intensities as features and this database to train the classifier. Using the voxel intensities as features makes it possible not to introduce any particular knowledge about the exact location of the hypo-perfusion area(s). Thus by using a database of images and the voxel intensities we circumvent the problem of the exact definition of the typ-ical perfusion pattern for early AD. In general the number of images available in the training databases is significantly smaller ( &lt; 100 ) than the number of voxels ( &gt; 1000 the number of features (voxels) is much larger than the num-ber of samples (training i mages). The number of samples is considered to be small if it is about the same or smaller than the number of dimensions. In this case we speak of al-most empty spaces, the small sample size problem or the so called curse of dimensionality. In classical pattern recogni-tion it is believed that no good generalization could be ob-tained for these cases when using the whole feature space [16]. Generalization is the capacity of a classifier to rightly classify a sample never seen before. In order to improve generalization of our final classifier, minimal feature depen-dency (small amount of features) of the classifier is desired. 2.3.1 The Linear Support Vector Machine We consider the problem, depicted in Figure 1, of classi-fying m points in the n -dimensional real space R n ,repre-sented by the m  X  n matrix A , according to membership of each point A i in the class A + or A  X  as specified by a given m  X  m diagonal matrix D with plus ones or minus ones along its diagonal. For this problem the standard sup-port vector machine with a linear kernel [16] is given by the following quadratic program with parameter  X &gt; 0 : Here, the plane x w =  X  +1 bounds the class A + points, while the plane x w =  X   X  1 bounds the class A  X  points as follows: The linear separating surface is the plane x w =  X  midway between the bounding planes (2). The quadratic term in (1) maximizes the distance or  X  margin X  between the bounding planes. Maximizing the margin enhances the generalization capability of a support vector machine [16]. In order to
Figure 1. The approximately bounding planes of equation (2) with a soft (i.e. with some error) margin 2 w proximately separating A + from A  X  are rep-resented by the red, green and blue lines. In this case, the support vectors are the points that lie on the bounding planes. make use of a faster linear programming based approach, instead of the standard quadratic programming formulation (1), we reformulate (1) by replacing the 2-norm by a 1-norm as follows [17]: This SVM  X  1 reformulation in effect maximizes the mar-gin, the distance between the two bounding planes of Figure 1, using a different norm, the  X  -norm, and results with a margin in terms of the 1-norm, 2 w 1 , instead of 2 w 2 [18]. The mathematical program (3) is easily converted to a linear program as follows: Empirical evidence [17] indicates that the 1-norm formula-tion has the advantage of generating very sparse solutions. This results in the normal w to the separating plane x w =  X  having many zero components, which implies that many in-put space features do not play a role in determining the lin-ear classifier. This makes this approach suitable for feature selection in classification problems. We note that in addi-tion to the conventional interpretation of smaller  X  as em-phasizing a larger margin between the bounding planes (2), a smaller  X  here also results in a sparse solution. The  X  X ight X  value of  X  is determined by a tuning procedure where the performance is adjusted to the desired compromise between the classification performance and the sparseness of the so-lution. Next, we will revisit some regularization theory re-sults that would motivate the SVM-like formulation we are proposing in this paper. 2.4 Regularization Theory and SVMs
Let f : n  X  with f ( x )= w x  X   X  the our predic-tion or classification function. Then, Formulation (4) and Support Vector Machine (SVM) formulations in general can be seen as a particular case of regularization networks [19] where the functional R reg [ f ]= R emp +  X G ( Pf ) that is often referred as the regularized risk, is minimized. R reg [ f ] is equal to the empirical risk functional R emp plus a regularization term G ( Pf ) that is usually defined as
Pf 2 .  X  = 1 a called the regularization operator. P maps the the clas-sifier function f into some dot product space [20]. For example, in the case of SVMs, the type of regularization and the class of functions that form the basis for the pre-diction function are intimately related. The SVM algorithm is equivalent to minimizing R reg [ f ] on the family of func-tions f ( x )= i  X  i k ( x i ,x )+ b provided that the kernel chosen as a Green X  X  function of P  X  P [20]. For example, in Formulation (4) the regularization term is G ( Pf )= w 1 . and K ( x i ,x j )= x i x j (the linear kernel). Our proposed formulation also proposed to minimize the regularized risk R reg [ f ] but for a very specific linear regularization opera-tor P that encodes prior information (in the form of spatial information) about the classification task at hand. 2.4.1 The Contiguous Linear SVM (CSVM) There are two drawbacks related to standard SVM formu-lations, especially when they are applied to imaging classi-fication problems. The first drawback is related to the fact that little or no spatial information about the imaging prob-lem is incorporated into the optimization problem to solve, discarding very valuable information that could lead to bet-ter and more robust classifiers. In the case of imaging prob-lems where the features are related to voxel/pixel intensities a relation can be predefined among the voxels using spatial information or previous knowledge about the problem. The second drawback is related to the interpretability of the re-sults. In several applications a feature selection scheme is implemented not only to get sparse models but also to deter-mine which of the input features are relevant for the classi-fication task, leading to insights about the problem in ques-tion. For example in the problem that we are addressing in this article it is easier to interpret a final classifier depending on contiguous voxels defining regions than a subset of inde-pendent voxels with no apparent connection among them. Our goal in this paper is to incorporate spatial information about every voxel into the optimization problem in a man-ner that the final obtained hyperplane classifier depends on regions or clusters of features rat her than on isolated voxels. Let X  X  consider a similarity function r that defines binary re-lations among any two features ( f i ,f j ) of any given training datapoint. Let R be a matrix such that:
We define now,  X  R = R  X  I n  X  n ,  X  R is the symmetric ad-jacency matrix of an undirected graph representing the re-lation among the features according to the relation function r .

R is a pseudo-adjacency matrix of a graph where every node has a self-loop. For most problems in real life R is based on local relations and therefore it is a very sparse ma-trix (see e.g. Figure 2). The function r could be defined in a more general way, where instead of a binary relations it can be a similarity function or any other kind of function encod-ing extra information about the features or the datapoints in the training set.

In our specific case we choose the relation r to be defined by a 3  X  3  X  3 mask defining the 26-closest neighbors of each voxel. Note that this very local simple mask allows to encode the sense of contiguity among voxels in a global sense across the whole volume. This mask size was chosen because it provided excellent results while maintaining the sparsity of the relation r A very simple but effective way to incorporate this extra information about the features into the 1 -norm SVM formulation (4) is to use the relationship matrix R as a regularization operator and then minimize the the regularized risk:
Figure 2. The sparse adjacency matrix R for the mask defining the 26-closest neighbors of each voxel.
 This can be formulated as the following linear programming problem: At a solution of problem (4), v is the absolute value | w | of w . This fact follows from the constraints v  X  w  X  X  X  v which imply that v i  X | w i | ,i =1 ...,n . Hence at optimal-ity, v = | w | , otherwise the objective function can be strictly decreased without changing any variable except v .Inthis new formulation (4) we have at optimality that Pv = | w | this is: In other words this means that the magnitude of the weight w i of the related feature i , not only depends on itself but it also depends on all the features j that are related to i ac-cording to the relation function r . Moreover R can be in-terpreted as a covariance matrix such that the prior over the vector of weights w is given by P ( w )=  X  exp( R  X  1 w 1
The images we used for our experiments were taken from a concurrent study investigating the use of SPECT as a diagnostic tool for the early onset of AD. A detailed description of this data can be found in [21]. Subjects of four different centers, Edinburgh (Scotland), Nice (France), Genoa (Italy), and Cologne (Germany) were included for this study. In total 158 subjects participated, including 99 patients with AD, 28 patients suffering from depression (not used in this article), and 31 healthy volunteers. An example of this data is seen in figure 3. Confirmation of Alzheimer X  X  disease was obtained by clinical follow-up. There was no statistically significant age difference between the AD pa-tients and the healthy subjects. For technical acquisition re-lated reasons images of 7 AD subjects had to be excluded. 3.1.1 Pre-processing Applying the registration procedure as described above re-sults in images of 128 by 128 by 89 voxels, with a voxelsize of 1.71 mm by 1.71 mm by 1.88 mm for all four centers. The SPECT images have an effective resolution of about 7 mm full width at half maximum (FWHM). Therefore we can subsequently subsample the images a factor of two in each dimension by taking the average value over the sub-sampled areas without loosing much information. We only use the voxel intensities for the voxels in the part of the brain that has been imaged for al l subjects. Applying this procedure results in 3816 features per subject available for classification/feature selection. 3.1.2 Experts All real images were rated in four categories (very prob-able, probably, probably not and very unlikely to have AD) by sixteen European expert nuclear medicine physi-cians. The possible ratings were as follows: very probably Alzheimer X  X  disease, probably Alzheimer X  X  disease, proba-bly not Alzheimer X  X  disease and very unlikely Alzheimer X  X  disease. To be able to compare the data from the experts with that of the automatic methods, we considered the first two ratings as positive and the other two as negative.
In all of our experiments we divided the data into two disjoint training and testing sets. The idea is to tune the pa-rameters in our model only using data from the training set, once the final model is fixed, it is tested in the unseen test-ing set. We used leave-one-out cross validation to tune the model parameter  X  of the contiguous SVM. Performance of our Contiguous SVM algorithm, in terms of generaliza-tion ability, is compared with a Fisher X  X  Linear Discrimi-nant (FLD) classifier as previously presented in [12]. The FLD algorithm used here is based on the FLD mathematical programming formulation introduced by Mika et al ([22]). second patient.
 For solving all the optimization problems involved in this paper we used the widely used commercial solver CPLEX 6.5 [23]. Next, we outline the results of our comparative testing. Two set of experiments were performed: 1. We randomly divided the 123 cases into 90 training ex-2. In order to test the generalization performance of our The first experiment resulted in a selection of 253 features grouped in 7 connected areas. Figure 4 shows part of the selected features (a subset that can easily be visualized in 2D). Most selected groups of features are in the ventricles. This is consistent with the general atrophy of the brain ob-served in Alzheimer X  X  disease patients which enlarges the ventricles relative to the other parts of the brain. This result shows the potential of the proposed approach at selecting meaningful grouped features which can be interpreted more easily than traditional feature selection approaches. The experts had an average sensitivity of 56.6% and a specificity of 82.4% for all 123 cases. In the SPM approach we use SPM at a significance level of 0.1 at the cluster level. We consider each image where some significant clusters were found to be a positive result, this leads to a sensitivity of
Table 1. Results for the first experiment for 90 training cases and 33 testing cases ran-domly sampled among the different institu-tions. The training results are based on leave-one out.
 55.9% and a specificity of 77.4% for SPM. Our classifica-tion approach as shown in tables 1 and 2 outperforms both the experts and the SPM approach. Results in table 2 show that even if the performance decreases on the training set due to differences in the way the images were aqcuired at the different institutions the contiguous SVM approach still shows good generalization capabilities.
Based on the experiments described in this article we conclude that our automatic approach to the classification of images performs at least as well as human observers. In general our contiguous support vector machine is more sen-
Figure 4. A single axial image showing the regions picked by the algorithm overlayed on an image of an Alzheimer X  X  disease patient
SPECT image. sitive and more specific. One would need more data, espe-cially of control subjects to be able to state that automatic methods always significantly outperform human observers in clinical practice. We have shown that classification of im-ages using the voxel values as features outperforms the lo-cal SPM approach. We have shown that classification with-out using any specific knowledge related to the pathology is possible. The approach we propose in this article gives only a global decision based on a specific image. However only providing global information might not be sufficient for clinicians. Therefore we proposed a method that might do useful feature selection which might provide useful infor-mation to the clinician, at least at the group level. A trained classifier represents the group of images it was trained on, it does not show which areas where discriminative for any specific single image. Further research should focus on how to obtain subject specific local information while still re-taining the advantage of a global approach. For future work one might want to try the presented approach for differen-tial diagnosis (other dementias versus Alzheimer X  X  disease) which might be an even more important clinical issue. ROC analysis of the classifier as well as of the experts will be use-ful to better compare performances. This will also provide means to handle the differences in operating points for the different experts (e.g. some experts are more specific while others are more sensitive). Also an interesting future direc-tion would be to extend the Contiguous SVM formulation, where a relation among datapoints is considered instead of a relation among the features. This approach can potentially Table 2. Results for the second experiment.
 The classifier was trained on the data from
Genoa (34 cases) and Cologne (34 cases), and tested on the data from Edinburgh (28 cases) and Nice (27 cases). The training re-sults are based on leave-one out.
 be used for a general semi-supervised SVM approach where only some of the labels for the training data are available. We are indebted to Prof. Nicholas Ayache and Prof. Jacques Darcourt for their contributions to this work. [1] G. McKhann, D. Drachman, M. Folstein, R. Katzman, [2] M.F. Folstein, S.E. Folstein, and P.R. McHugh.  X  X ini-[3] K.M. Gosche, J.A. Mortimer, C.D. Smith, W.R.
 [4] I. Goethals, C. van de Wiele, D. Slosman, and R. Dier-[5]W.A.VanGool,G.J.Walstra,S.Teunisse,F.M.
 [6] D. Kogure, H. Matsuda, T. Ohnishi, T. Asada, M. Uno, [7] H. Braak and E. Braak. Diagnostic criteria for neu-[8] M.R. Dawson, A. Dobbs, H.R. Hooper, A.J. McEwan, [9] D. Hamilton, D. O X  X ahony, J. Coffey, J. Murphy, [10] R.S.J. Frackowiak, K.J. Friston, C.D. Frith, and [11] J. Ashburner, K. Friston, A. Holmes, and J.-B. Poline. [12] J. Stoeckel, Malandain G., O. Migneco, P.M. [13] A. Roche, G. Malandain, X. Pennec, and N. Ayache. [14] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and [15] S. Prima, S. Ourselin, and N. Ayache. Computa-[16] V. N. Vapnik. The Nature of Statistical Learning The-[17] P. S. Bradley and O. L. Mangasarian. Fea-[18] O. L. Mangasarian. Arbitrary-norm separating [19] T. Evgeniou, M. Pontil, and T. Poggio. Regularization [20] A. Smola, P. L. Bartlett, B. Sch  X  olkopf, and J. Schuur-[21] D. Soonawala, T. Amin, K.P. Ebmeier, J.D. Steele, [22] Sebastian Mika, Gunnar R  X  atsch, and Klaus-Robert [23] ILOG CPLEX Division, 889 Alder Avenue, In-
