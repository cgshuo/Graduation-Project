 Bo Chen bchen3@caltech.edu Rui M. Castro rmcastro@tue.nl Andreas Krause krausea@ethz.ch ETH Zurich, Universit  X atstrasse 6, 8092 Zurich, Switzerland We consider the problem of function optimization in high dimensions. In many situations one wishes to find the maximum of a function quickly, from (noisy) evalu-ation at a small number of points. This problem occurs in various domains, for instance when learning optimal control strategies for robots (Lizotte et al., 2007), or when optimizing industrial processes that depend on many variables. It is particularly interesting to con-sider the case where the domain of the function f we desire to optimize is high-dimensional (say [  X  1 , 1] D ), but when the values of the function depend only on a reduced, albeit unknown, set of variables. If there are d such  X  X ctive X  variables, where d D , it is some-what plausible that the performance of such a function optimization procedure depends mostly on the intrin-sic dimension d , and only depends mildly on the ex-trinsic dimension D . In this paper we formalize such insight, and provide a suite of algorithms based on Hi-erarchical Diagonal Sampling (HDS), which are able to perform both variable selection and function optimiza-tion in such settings. We provide strong theoretical guarantees, including a sample complexity bound that depends only logarithmically on the extrinsic dimen-sionality, as well as cumulative regret bounds on the performance of joint variable selection and optimiza-tion. We evaluate our proposed algorithms on several benchmark optimization problems.
 Related Work Variable selection and optimization have both been extensively studied separately from each other. In variable selection one seeks an active set of variables, among many others, that explain a response function well. One family of models called sparse linear models study the case where the response function is linear in the variables. For example, Lasso (Tibshirani, 1996) tackles this combinatorial prob-lem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006). Alternative models have been proposed to handle non-linear response functions. Automatic Relevance Determination (ARD, MacKay (1992)) is a Bayesian variable selection procedure that imposes a Gaussian prior on the bandwidths of the variables, which can be combined with a GP likelihood to handle non-linear functions. Yet there is little formal analysis regarding its sample complexity rate. Rodeo (Lafferty &amp; Wasserman, 2008) is an efficient algorithm that simultaneously estimates bandwidths and selects variables in non-parametric regressions. It has favorable theoretical properties of risks and con-vergence rates. Also bearing similarities to our work is Distilled Sensing (Haupt et al., 2011), which attempts to quickly identify large portions of the variable space that are irrelevant, therefore reducing the search complexity as more data is collected, and effectively shedding the dependency on the extrinsic dimension. However, none of these models address the problem of function optimization in an active learning setting. The goal of active function optimization is to optimize an unknown function with as few samples as possible. One line of work called Bayesian global optimization (Ginsbourger &amp; Riche, 2010; Brochu et al., 2010) assumes the unknown function is sampled from a GP. In particular, the GP-UCB (Srinivas et al., 2010) algorithm has been shown to have sub-linear regret and work well emprically. However, dealing with high dimensional domains is a notoriously hard challenge for these approaches. Most of this existing work has considered variable selection and function opti-mization separately. Recently, the problem of joint variable selection and linear optimization has been tackled by (Abbasi-Yadkori et al., 2012), who exploit sparsity to alleviate the curse of dimensionality. Con-currently, (Carpentier et al., 2012) combines compress sensing and bandit theory to achieve sub-linear regret bounds for sparse functions. However, they deal only with linear or approximately linear reward functions whereas our method handles non-linear functions. We focus on functions of bounded domain, which, w.l.o.g., we assume to be [  X  1 , 1] D , where D is called the extrinsic dimension . Let f : [  X  1 , 1] D  X  R be a fixed, but unknown function. The value and loca-tion of the maximum of this function are our main quantities of interest. We assume that this function depends only on a subset of the domain variables, which we call the active variables or active dimen-sions , denoted by A X  X  1 ,...,D } . We are particularly interested in the case where the set of active dimen-sions is rather small relative to the extrinsic dimension, namely d = |A| D .
 Without some regularity assumptions on f , opti-mization would be hopeless. We choose to model smoothness of f by assuming that it is a sam-ple from a Gaussian Process (GP, Rasmussen &amp; Williams (2006)) with zero mean 1 and a squared-exponential 2 kernel K . In order to model the fact that the function depends on only a subset of the variables A , we assume that the kernel is of the x , x 0  X  [  X  1 , 1] D ,  X  2 s is the self variance of the kernel, and b &gt; 0 is the bandwidth corresponding to the active dimensions, respectively.
 Although the function f is modeled as a sample from a stochastic process, we assume it to be fixed through-out the data collection process. In particular we are allowed to collect data of the form y t = f ( x t ) + where t = { 1 , 2 ,... } , t are independent and identi-cally distributed (i.i.d.) normal random variables with zero mean and variance  X  2 &gt; 0 (assumed known), also independent of f . We are interested in developing an algorithm that chooses x t as a function of all the maximum x  X  = argmax x f ( x ) of f as quickly as possible. We evaluate any candidate algorithm in terms of its regret , R T = P T t =1 [ f ( x  X  )  X  f ( x t that the average regret, R T /T is an upper bound on the minimum regret, min t =1 ,...,T [ f ( x  X  )  X  f ( x therefore minimizing the cumulative regret will lead to algorithms with good anytime performance. We propose a two-staged method for variable selec-tion and function optimization, tied together through proper choice of certain parameters as described below. Variable selection is attained by means of a hierarchi-cal diagonal sampling ( HDS ) stage. After the iden-tification of active variables, we apply the GP-UCB algorithm (Srinivas et al., 2010) to optimize over the variables deemed active. 3.1. Hierarchical Diagonal Sampling In a nutshell, the HDS algorithm recursively splits the set of variables into two sets of equal size, and keeps splitting the sets that are more likely to contain active variables. More specifically, HDS sequentially con-structs a tree where each node corresponds to a set of variables, meaning each node can be uniquely iden-tified by a subset of { 1 ,...,D } . Any node that is not a leaf has two children, corresponding to two disjoint subsets of dimensions, each with half of the size of the parent node. Each node in this tree can be in one of three states: active nodes contain at least one active dimension, inactive nodes are guaranteed (w.h.p.) to contain no active dimensions, and for undetermined nodes we have insufficient evidence to draw any con-clusions about their activeness. All the nodes start un-determined, but as more samples are collected, a node will either become active, which implies that at least one of its children is active, or inactive, which renders its entire subtree inactive. Naturally, if a leaf node (which contains a single dimension) is active, then the dimension is deemed an active dimension.
 The crucial step in this algorithm is to determine if a node I  X  X  1 ,...,D } is (in-)active. With that in mind, we construct a one-dimensional projection f I (  X  ) of the function defined as follows: Let x (0)  X  [  X  1 , 1] D denote a randomly chosen background vector (this choice is made before any observations are collected). Define the function x I : [  X  1 , 1]  X  [  X  1 , 1] D such that where z  X  [  X  1 , 1]. The one-dimensional projection of f in I is then simply defined as The function f I : [  X  1 , 1]  X  R is a sample from a one-dimensional GP, with kernel K I where x,x 0  X  [  X  1 , 1] and a I = |A X  I | is the number of active variables in node I . In other words, K I is a squared-exponential kernel whose bandwidth depends on the number of active variables.
 Therefore, to identify if I contains any active variable it suffices to test which kernel best characterizes the landscape of noisy observations of f I . We propose two methods for doing so: the Finite Difference Sequential Likelihood Ratio Test (FDT), and the GP Sequential Likelihood Ratio Test (GPT), each with their respec-tive advantages. 3.2. Finite Difference Sequential Likelihood We use hypothesis testing in order to determine, whether node I contains any active variables 3 . We consider two hypothesis: the null hypothesis H 0 : I contains no active variable; the alternative H 1 : I con-tains at least one active variable. We begin by consid-ering a non-sequential testing approach to this prob-lem.
 Finite Difference Testing: The key idea is the following: If node I contains no active variables, then f I ( x ) should be constant. In contrast, if the node I contains active variables, f I ( x ) should exhibit a significant amount of variation as we vary x . In the following, we formalize this intuition. Suppose we pick two random points x and x 0 , independently and uniformly distributed over [  X  1 , 1]. Consider  X  =  X ( x,x 0 ) = f I ( x )  X  f I ( x 0 ). Both under H 0 E [ X  X  = 0. Further, in the null hypothesis, the variance V [ X  X  = 0 as well. In contrast, under H 1 , V [ X  X  = c &gt; 0. Unfortunately we cannot observe  X ( x,x 0 ) directly due to measurement noise. However, we can try to estimate V [ X  X  by picking n pairs of points x i ,x 0 i inde-pendently at random and computing the test statistic where y ( x i ) and y ( x 0 i ) are all independent noisy point observations of f I (  X  ), corrupted by additive Gaussian noise with zero mean and variance  X  2 . Under H 0 , X n is distributed according to a central  X  2 n distribution with n degrees of freedom. In contrast, under H 1 , X n is distributed according to a non-central  X  2 n,B n distribution with (unknown) non-centrality parameter B n = P i  X  2 i , and  X  i = ( f I ( x i )  X  f I ( x 0 i )) / The following Proposition provides a testing pro-cedure, along with a sample-complexity bound, for distinguishing H 0 and H 1 with arbitrarily low failure probability.
 Proposition 3.1. Let B n = P n i =1  X  2 i , where  X  2 i [0 ,M ] are independent random variables satisfying E [ X  2 i ]  X  c . Consider testing between two hypothesis where in the alternative hypothesis we assume that, conditioned on B n , the distribution of X n is a non-central  X  2 with n degrees of freedom and non-centrality parameter B n . Provided n  X  max there is a thresholding test procedure that guarantees that both type I and type II error are less than  X  . In other words, there is a value  X  n such that P H 0 ( X n &gt;  X  n )  X   X  and P H 1 ( X n &lt;  X  n )  X   X  . Notice that the sample complexity given by Proposi-tion 3.1 crucially depends on the lower bound c on the variance, which can be viewed naturally as parameter-izing the problem difficulty.
 In order to apply this hypothesis testing strategy to our setting, we must ensure that samples from a GP satisfy c = c ( f ) &gt; 0 with high probability over the random function f . We have the following result: Theorem 3.1. Let  X  &gt; 0 and  X  2 s &gt; 0 . Suppose f is a sample from a GP on [  X  1 , 1] with constant mean and covariance k ( x,x 0 ) =  X  2 s exp(  X  X  x  X  x 0 | 2 /h 2 ) , for some h  X  2 uniformly distributed random variables and define  X  = f ( x )  X  f ( x 0 ) .
 There exist constants a &gt; 0 and b &gt; 0 such that with probability at least 1  X   X  over f it holds for the condi-tional variance of  X  that Thus, as long as h is sufficiently small, the variance c of  X  is lower bounded with high probability. Asymp-totically, if h  X  1 =  X (log(1 / X  ) 2 ), then, as  X   X  0, with probability at least 1  X   X  .
 A Sequential Testing Procedure: While pro-viding sample complexity guarantees, the bounds of Proposition 3.1 in conjunction with Theorem 3.1 are very loose in practice. Furthermore, in order to de-termine the threshold  X  n , the lower bound c on the variance must be taken in the worst-case scenario. As a more practical alternative, we consider a sequential testing strategy, which is able to adjust the sample complexity depending on the problem difficulty. The key idea behind our sequential approximation is that under the GP prior, we can characterize the distri-bution of y I ( x )  X  y I ( x +  X  ), the difference for point samples at a distance  X  .
 First, we focus on the concrete case where node I has either no active variables, or a known number of ex-actly a active variables. In this case, the data dis-tribution under each scenario is entirely known. The case a = 1 is the hardest, intuitively because y I varies less the fewer active variables I has. Later we show that the composite case of distinguishing none vs. at least one active variable is of exactly the same diffi-culty. Setting dy I = y I ( x )  X  y I ( x +  X  ), we have that the marginal distribution of this quantity is given by dy
I  X  X  (0 , X  Now suppose a = 1. If we pick  X  at random, then dy I is distributed according to a scale-mixture of Gaussians. Instead, in our sequential test, we simply fix  X  = 3 b . In this case, the variance under H 0 is  X  2 0  X  2  X  2 whereas the variance under H 1 is 2((1  X  1 /e  X  3 )  X  2 s +  X  2 2( . 95  X  2 s +  X  2 )  X   X  2 1 . Thus by estimating the variance of the finite differences for this fixed choice of  X  , we expect to be able to distinguish between H 0 and H 1 . We now employ sequential hypothesis testing using the sequential likelihood ratio test (SLRT) as described in Siegmund (1985). This is an incremental proce-dure that sequentially computes the log likelihood ra-tio (LLR) between two hypotheses, and makes a deci-sion once this ratio crosses two predetermined bound-aries. In our finite differences setting, a pair of samples are collected each time to update the LLR between H 1 and H 0 . The test terminates as soon as LLR is either larger than an upper threshold  X  1 (and we ac-cept H 1 ) or smaller than a lower threshold  X  0 (and we accept H 0 ). The LLR given a collection of T samples { dy I ( x t ) } T t =1 can be computed in an additive fashion: where the LLR for each individual dy I ( x t ) = dy is: Several remarks are in order. First, for a fixed value of dy , under H 1 , E [ LLR ( dy )] is a monotonic func-tion in  X  1 , which indicates that I containing one ac-tive variable is indeed the hardest case. Secondly, the classical SLRT requires independent samples, and under the GP prior, two finite differences dy I ( x ) = y ( x )  X  y I ( x +  X  ) and dy I ( x 0 ) = y I ( x 0 )  X  y I be correlated. However, if | x  X  x 0 | is sufficiently large, dy
I ( x ) and dy I ( x Lastly, since SLRT is carried out separately for each undetermined node in the tree, we would like to invest more samples on nodes that are the most likely to be active so as to reach all the active leaf nodes with minimum sample complexity. For this purpose, we allocate samples one at a time and always pick the node I that has the largest LLR so far. According to Eq. 2, statistics of LLR per finite difference depend only on  X  1 and  X  0 , hence all the nodes for which H 1 is true share the same upward slope for LLR , and the largest LLR naturally is the most likely to reach  X  1 . 3.3. GP Seq. Likelihood Ratio Test (GPT) Instead of making an independence assumption, one can explicitly model the correlation between samples. Knowing the underlying hypothesis completely deter-mines the data distribution, as it follows a GP with known covariance structure determined by K I,a , where this kernel depends on a , the number of active vari-ables in I . To avoid notational clutter, we drop the explicit dependence on node I when its identity is clear from the context.
 We focus first on a single node I . Given past observa-tions of x 1: t  X  1 and y 1: t  X  1 , we can compute the poste-rior distribution of y I t given x t under each hypothesis.  X  a ( x )  X  k a ( x )  X  a ( x )  X   X  k a ( x )  X  [ K a ( x,x 1 ) ,  X  X  X  ,K a ( x,x t  X  1 )] T , Consider the conditional LLR t ( y | x t , x 1: t  X  1 , y denoted by LLR t ( y ) for convenience. Suppose we have sampled at x  X  t and observed y  X  t . Then LLR t ( y  X  t Finally, the LLR of all the observed samples, LLR 1: t is given by: After each observation we compare LLR 1: t with two thresholds  X  1 and  X  0 . If the LLR is above the first one, then we stop sampling and decide the node is active. If below the second threshold, we decide the node is inactive. Finally, if neither of these conditions holds we continue collecting data.
 Sampling Strategy: The only remaining issue for this hypothesis testing procedure is to decide on the next sample. Note that, under H 1 , the conditional dis-tribution of the likelihood ratio for a sample at point x follows a shifted non-central Chi-squared distribution: where w 2  X  0 . 5  X  t 1 ( x t ) 2 / X  t 0 ( x t ) 2  X  1 , w Given that we want to decide as quickly as we can if a node is active, it makes sense to choose the point x t that tends to maximize LLR t ( y t ) the most. A natural choice is to take x t maximizing E ( LLR t ( y t )) + p V ( LLR t ( y t )). This choice is easily justified in light of tail bounds for Chi-squared distributions, such as those in the long version of the paper. Finally, as at each moment we are considering multiple nodes in the tree, we choose the node I that maximizes the above quantity over all nodes. Let UCB ( I,x t ) = E ( LLR I,t ( y t )) + p V ( LLR I,t ( y We choose point x t and node I so to maximize this index. In other words, we choose the node I that is more likely to be deemed active after sampling. The complete procedure is described in Algorithm 1. Fig 1 shows an example of the search tree.
 The following theorem characterizes the accuracy and sample complexity of HDS when using an arbitrary testing procedure block.
 Algorithm 1 Hierarchical Diagonal Sampling Theorem 3.2. Let A 0 denote the set of active dimen-sions identified by the HDS algorithm, also let  X  and  X  denote respectively the false positive and false nega-tive rates for the testing procedure used. All log s are base-2.
 Accuracy: For an arbitrary &gt; 0 , provided  X , X   X  ( /D ) 1 / d log D e the probability of perfect recov-ery is P ( A 0 = A )  X  1  X  .
 Sample Complexity: Let T max be the maximum expected sample usage per node, and N be the sample complexity of the HDS algorithm. The expected sam-ple complexity is bounded by: The proof of the first part expresses the probability of any particular leaf node being correctly classified, and then applies a union bound on the event that all the leaf nodes are classified correctly. For the second part we study how testing errors change the tree gen-erated by HDS under perfect conditions. Since every node incorrectly deemed active can spawn at most 2 inactive children with probability  X  we can get an up-per bound on expected number of active nodes, and in turn, the worst case expected sample complexity. See the extended paper for details.
 Theorem 3.3. Given &gt; 0 , set  X  = 6 d d log D e and  X  = ( / (2 D )) 1 / d log D e . Assume is small enough so that  X  &lt; 1 / 4 . Assume b  X  2 (log(1 / X  ) 2 . Con-sider the HDS algorithm with non-sequential FDT using a fixed sample size per node A log (2 / X  ) , where A  X  max n 2 , 16(1+  X  stants. Then, for a judicious choice of c 1 and c 2 HDS-FDT procedure is correct with probability at least 1  X  , and the sample complexity: Note that A =  X  ((log(1 / ) + log( d d log D e )) 8 ), and N =  X  (log 1 + log( d d log D e )) 8 d ( d log D e + log The proof (given in the extended paper) consists es-sentially in plugging in the results of Theorem 3.1 in Proposition 3.1, and applying theorem 3.2. After identifying the set A of active variables, we fo-cus on optimizing f over these relevant dimensions. In principle, various algorithms can be used for this pur-pose. We consider the GP-UCB algorithm (Srinivas et al., 2010). GP-UCB is a greedy algorithm, which iteratively picks the point where  X  t ( x ) and  X  2 t ( x ) are the posterior mean and variance at input x , conditioned on the first sam-ples x 1 ,..., x t and associated observations y 1 ,...,y  X  ,..., X  T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB , strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al. (2010) bounds the cumulative regret of GP-UCB in terms of the maximum information gain  X  T obtain-able by observing f at an arbitrary set of T inputs x 1: T . Hereby,  X  T is a monotonically increasing func-tion of T , depending on the covariance function and domain of the GP. For the squared exponential kernel it is bounded by O ((log T ) d 0 +1 ), where d 0 is the di-mensionality of the underlying space. The cumulative regret of GP-UCB is bounded by O  X  ( the O  X  notation hides logarithmic factors).
 Straightforward application of GP-UCB without vari-able selection would lead to regret bounds depending on the extrinsic dimensionality d 0 = D . However, after variable selection we can apply GP-UCB only to vari-ables that are deemed active, obtaining a regret bound depending on d 0 = d , the intrinsic dimensionality only. Assume that function value f ( x ) is bounded so that the maximum regret per sample is bounded by C 0 . Let N be the termination time of the HDS procedure, x  X  a global optimum of f and R T = P T t =1 [ f ( x  X  )  X  f ( x the cumulative regret.
 Theorem 4.1.  X  T  X  N  X  , X  o &gt; 0 , set = 1 /T and  X  t = 2 log( Running HDS with FDT and recovery rate 1  X  , followed by the GP-UCB algorithm on the variables deemed active guarantees that with probability  X  1  X   X  o : where A 0 T = 8 / log(1 + b  X  2 ) , and N = O (log(1 / ) 9 ) = O ((log T ) Thus, the regret depends only logarithmically on the extrinsic dimension D .
 The proof (given in the extended paper) bounds the worst case regret separately for the variable selection and optimization phases, assuming that maximum re-gret is incurred during HDS and, if HDS fails, during every round of the GP-UCB procedure. The former cases incurs linear regret for finite numbers of samples, and the latter does so for all samples but with a small probability . When HDS is successful, Theorem 2 of Srinivas et al. (2010) guarantees a sub-linear regret bound for GP-UCB . We compare HDS with a natural baseline called Coordinate-wise Sampling (CWS). CWS computes finite differences along each dimension separately using the same number of samples, and outputs the dimensions with the largest variance. We clairvoy-antly choose the number of samples CWS needs to successfully recover all the active dimensions. Doing so favors the CWS algorithm in comparison to HDS. Functions sampled from a GP: We consider the case where the test function is a sample from a GP with a squared-exponential kernel: b = 0 . 1 and self variance  X  2 s = 1. We vary the total num-ber of dimensions D  X  { 10 , 20 , 40 , 80 , 200 , 400 } ,  X  n  X  { 0 . 05 , 0 . 1 , 0 . 25 , 0 . 36 } , and compare FDT, GPT and CWS in terms of accuracy (recovery probability) and sample complexity. The thresholds {  X  1 ,  X  0 } were optimized using grid search over  X  1  X  { 5 , 10 , 20 } and  X  0  X  { X  5 ,  X  10 ,  X  20 } to ensure maximum recovery accuracy with the minimum sample complexity for the setting of D = 200 , X  2 n = 0 . 1. The optimal value is then used for all settings. We repeat each setting for 20 random trials and report the mean  X  3 standard error. Accuracies of HDS under all settings are 100%. Fig 2 shows how sample complexity varies as a func-tion of dimensionality D and noise parameters  X  2 . As predicted, the complexity grows linearly with log( D ), the logarithm of the extrinsic dimension, and linearly with the noise level. GPT consistently uses about 50% less samples than FDT. In contrast, CWS is less stable and scales linearly as D . Using the oracle parameter setting CWS has little dependence on  X  2 , yet HDS remains more efficient even in highly noisy situations. We also examine the sensitivity of HDS w.r.t. the as-sumption that the noise parameter  X  2 and the band-width b are known. Fig 3 shows accuracy and sample complexity as a function of the ratio between the mis-estimated  X  and the truth. FDT can tolerate over-and under-estimation of the noise level by a factor of 2, while GPT is more stable, withstanding mis-estimation by factors of 0.5 to 10. Both methods are robust w.r.t. b . Sample complexity and accuracy remain constant (FDT: 412 samples, 100% accuracy, GPT, 228 samples, 100% accuracy) when b is mis-estimated by factors of 0.01 to 10.
 Functions embedded in high dimensions: We also take the following low dimensional functions and hide them in a D = 200 dimensional space: Quad: quadratic function ( d = { 2 , 4 , 6 } ). Quad ( x ) = ( P ( x  X  x  X  )) T ( P ( x  X  x  X  ))+  X  2 n where x random vector and P is a diagonal projection matrix: P ii = 1 /b if i  X  X  and P ii = 1 / 100 otherwise. QuadMix: quadratic with linear mixture ( d = { 2 , 4 , 6 } ). Similar to Quad ( x ), QuadMix ( x ) = ( MP ( x  X  x  X  )) T ( MP ( x  X  x  X  )) +  X  2 n where M = (1  X  r mix ) I + r mix . r mix = 1 /D controls how the irrelevant dimensions interfere with the relevant ones.
 Branin: ( d = 2) is a classical test function for un-constrained global optimization. It has a broad global landscape and peaks at (  X  1 ,  X  1).
 Beale: ( d = 2) is a challenging test function. It re-mains flat for 90% in the domain, and gets flatter the closer it gets to the optimum.
 We compare accuracy and sample complexity for the FDT, GPT and CWS. All functions are rescaled to [  X  1 1] and the best parameter set found in the pre-vious section is used 4 . The sample size is limited at 2000 per function. Error bars are obtained from 20 trials. The accuracies for Quad and QuadMix are shown in Table 1. The sample complexity for Quad and QuadMix are shown in Fig 4. The complex-ity for Branin is: FDT (267  X  28), GPT(236  X  12) and CWS (1703  X  96). The complexity for Beale is: FDT(280  X  10), GPT(674  X  44) and CWS (1802  X  82). The results for Quad, QuadMix and Branin agree with the case of GP test functions and the theoret-ical analysis, showing the sample complexity X  X  linear dependence on the relevant dimensions and logarith-mic dependence on the extrinsic dimensionality. HDS (with testing blocks FDT or GPT) does not work for Beale because it is mostly constant, and therefore it is severely different than a typical sample from a GP. Joint Variable Selection and Optimization Fi-nally we compare the optimization performance of our 2-step procedure of HDS followed by GP-UCB against the conventional GP-UCB algorithm on all D dimen-sions. Note that if D is large, GP-UCB becomes in-feasible, in which case our method has a clear advan-tage. Even with small D , however, we show in Fig 5(b) and 5(c) that our method achieves a faster reduction in the average regret R T /T , and obtains better minimum regrets min t [ f ( x  X  )  X  f ( x t )]. We considered the problem of optimizing high dimen-sional functions that only depend on few active vari-ables. We proposed HDS for variable selection and analyzed its sampling complexity in terms of proper-ties of a modular hypothesis testing subroutine. For a classical (non-sequential) subroutine we proved sample complexity bounds, implying strong end-to-end per-formance guarantees for GP optimization in high di-mensions. We also explored two practical alternatives based on sequential hypothesis testing and demon-strated their effectiveness on several high-dimensional optimization problems. We believe that our results provide important insights towards solving high di-mensional optimization problems under uncertainty. Acknowledgments. This work was partially sup-
