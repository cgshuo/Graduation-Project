 As an integral part of Electronic Health Records (EHRs), clinical notes pose special challenges for analyzing EHRs due to their un-structured nature. In this paper, we present a general mining frame-work SympGraph for modeling and analyzing symptom relation-ships in clinical notes.

A SympGraph has symptoms as nodes and co-occurrence rela-tions between symptoms as edges, and can be constructed automat-ically through extracting symptoms over sequences of clinical notes for a large number of patients. We present an important clinical ap-plication of SympGraph: symptom expansion , which can expand a given set of symptoms to other related symptoms by analyzing the underlying SympGraph structure. We further propose a matrix up-date algorithm which provides a significant computational saving for dynamic updates to the graph. Comprehensive evaluation on 1 million longitudinal clinical notes over 13K patients shows that static symptom expansion can successfully expand a set of known symptoms to a disease with high agreement rate with physician in-put (average precision 0.46), a 31% improvement over baseline co-occurrence based methods. The experimental results also show that the expanded symptoms can serve as useful features for improving AUC measure for disease diagnosis prediction, thus confirming the potential clinical value of our work.
 H.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Infor-mation Search and Retrieval symptom graphs, physician notes,random walk,patient records
Electronic Health Records (EHRs) have become a standard prac-tice in modern healthcare delivery. Beyond storing patient records, EHRs are an ever-growing data repository that enables clinical data mining applications, especially comparative effectiveness research. Heterogeneous sets of EHR data are available in both structured and unstructured formats. For example, diagnosis information such as International Classification of Diseases -ICD9 codes 1 tion information such as generic drug names, and lab results are commonly stored in structured formats. Such structured EHR data are readily usable for data mining applications. However, clini-cal notes, arguably the most important part of the patient records, are largely unstructured. Despite the standard practice based on which physicians write the notes, such as SOAP notes(sec 2.1), by and large the information in physician notes remains unstructured, making it a significant challenge to extract and understand clinical concepts both within and across patients. The following example illustrates some of the needs and specific challenges in mining clin-ical notes.
 Clinical motivating example: Congestive Heart failure (CHF), af-fecting 1 in 5 US adults, is the single most costly health problem for Centers for Medicare &amp; Medicaid Services (CMS). With an ag-ing population, the individual and societal burden is expected to increase. CHF is a complex syndrome with multiple pathophysi-ological manifestations that frequently overlap with those of other diseases, making early diagnosis challenging. Thus it is usually di-agnosed in primary care, often as a late stage disease. In order to increase the chance of early diagnosis of CHF, it is important to collect all directly and indirectly relevant symptoms from a patient, and have a good understanding of the criteria for diagnosis. Unfor-tunately, the only criteria currently available were published by the Framingham investigators in 1971 based on clinical data acquired in the 1950 and 60s [11]. Fortunately, clinical notes are excellent sources from which we can potentially extract relevant symptoms to diseases such as CHF.
 Automatic identification of Framingham criteria can greatly en-hance the understanding of their prevalence as well as incidence in a patient population over time. Clinicians are also interested in understanding in general how all signs and symptoms are related to each other in order to possibly expand Framingham criteria to a broader set of symptoms that serve as robust signals for early detection of CHF. The need for extracting clinical signs and symp-toms from patient records and further analyzing them also exists for many other diseases.

In this paper, we study the following questions: How to cap-ture the relations among different symptoms extracted from clinical notes? How to expand a set of known symptoms to other relevant symptoms? How to efficiently update such symptom expansion when the underlying symptom relations change? To the best of our knowledge, no previous work has systematically studied these questions.

To this end, we present a general mining framework SympGraph, that turns patient encounter notes into a symptom graph to system-http://icd9cm.chrisendres.com/ atically reveal all the symptoms and symptom relations buried in the notes. A SympGraph is a graph with extracted symptoms as vertices, and the associations of symptoms as edges. It provides a general representation of symptoms and their relations and helps support many different mining applications under a unified frame-work. As an example of the applications enabled by a symptom graph, we present an important clinical application: symptom ex-pansion which expands a small initial set of known symptoms to a bigger set of relevant symptoms. We present two different algo-rithms for solving symptom expansion in different contexts. When the underlying symptom graph is static, we propose static symptom expansion , which adopts a random walk type of algorithm to rank related symptoms based on their relevance to the initial set. When the underlying symptom graph changes (e.g., due to addition of new symptom relations or updating existing ones), we propose dy-namic symptom expansion , which is based on a novel matrix update method for low rank approximation of the symptom graph.
We evaluate the proposed SympGraph framework on a large-scale real world clinical database with 1 million clinical notes of over 13K patients over 7 years, and the experimental results are quite promising. We show that SympGraph can successfully ex-pand a known set of CHF related symptoms with a high agreement rate compared to physician judgements (average precision 0.46), providing a 31% improvement over baseline methods that do not use SympGraph. We further demonstrate that the expanded symp-toms can help achieve over 10% improvement of area under the curve (AUC) measure for predicting the onset of CHF. In terms of the scalability, we compare static and dynamic symptom expan-sion methods, where interesting workload trade-off is revealed. In general, dynamic symptom expansion is preferred when multiple initial symptom sets are present and underlying relation changes are small.
A clinical note contains unstructured details regarding a patient X  X  encounter with a healthcare professional. The content of the note varies depending upon the type of encounter, and there are many different types of encounters. For example, a note for a Pharmacy Visit , contains information regarding medications and their side ef-fects, while a Physician Visit contains complete details of patient symptoms, medications, social history etc. Other example types of encounters are Laboratory Visit and Case Manager Visit . Of all these, the most important and abundant are the Physician Visit notes. These are generally loosely organized into four SOAP sec-tions: Subjective , Objective , Assessment and Plan . Each section contains a specific kind of information regarding the patient. A sample is shown in Figure 1.
 Subjective: details of a patient X  X  condition in her own words. Also other details such as social history, family history, current medica-tions etc.
 Objective: observable information such as findings from physical examination, test results, vital signs, age, height, weight etc. Assessment: a list of potential diagnoses.
 Plan: information on the subsequent steps of actions of the patient, such as a treatment plan.
Clearly, in order to analyze and mine symptom-related knowl-edge from clinical notes, we first need to go through a Symptom Extraction step, in which we process each encounter to identify the symptom mentions present and filter out negated symptoms. In Figure 1: A sample clinical note, highlighting the four sections Figure 2: UIMA pipeline architecture for symptom extraction the proposed SympGraph framework, we would use the extracted symptoms and their statistical relations to constract a graph, which can then support various analysis tasks, especially symptom expan-sion, an application that we would study in detail in this paper.
Since improving the accuracy of symptom mention extraction is not our focus, we mostly rely on existing techniques and extend them systematically to extract symptom mentions. Specifically, we use the Apache Unstructured Information Management Architec-ture (UIMA) toolkit(http://uima.apache.org/) to construct a Natural Language Processing (NLP) pipeline for the task. The main idea behind a UIMA pipeline is to construct a series of annotators. Each annotator is a program that parses the document text and marks the start and end locations for a certain type of entity in the text. We adopt the UIMA toolkit as it allows us to efficiently create and in-terconnect such annotators. Figure 2 shows the architecture of our UIMA pipeline.

Word, Sentence Annotator At the lowest level we start with annotators, which identify the word, sentence and SOAP section boundaries in the text. These annotations, along with the original text are then supplied to the subsequent levels.

Symptom Annotator Symptom annotator annotates all symp-tom mentions present in the text. Symptoms are identified using MetaMap (http://metamap.nlm.nih.gov/), a tool developed at the National Library of Medicine, for mapping raw English text to stan-dardized medical concepts in the Unified Medical Language Sys-tem (UMLS) metathesaurus(http://www.nlm.nih.gov/research/umls/). UMLS contains over a million medical and general English con-cepts, which are further organized under a hierarchy of 134 seman-tic types. Each concept is assigned one or more high level semantic types. For example  X  X syn X  type, contains all concepts belonging to the category of  X  X isease or Syndrome X .

Since MetaMap returns all types of concepts present in the text, we filter out the returned concepts based on their semantic types. More specifically, we only keep concepts belonging to the follow-ing semantic types as symptom concepts: { sosy, dsyn, neop, fngs, bact, virs, cgab, acab, lbtr, inpo, mobd, comd, anab }
Framingham Annotator The general Symptom Annotator de-scribed above does not accurately identify all mentions of Framing-ham Symptoms for heart failure in the text. Since our experiments are focused on Congestive Heart Failure (CHF), we also built a separate annotator, which identifies Framingham Symptoms more accurately in the text using a dictionary of symptom mentions and simple heuristics. The symptom dictionary was built by manually analyzing clinical records. We used the Framingham Annotator to extract 15 out of 16 Framingham symptoms in total. One symptom -Weight loss  X  4.5 kg in 5 days in response to treatment , needed deeper text analysis and was not extracted.

Negation Annotator Presence of a symptom in a clinical note does not necessarily imply an Assertion which is its presence in a patient. The negation annotator looks at the surrounding text of each symptom annotation and filters out symptom mentions found in negated contexts based on simple heuristics such as presence of negation related words like  X  X enies X ,  X  X ithout X , and  X  X o X . In principle, negative symptom findings can also indicate interesting relationships. However for this work we will only focus on positive symptom occurrences.
From a medical application perspective, it is very important to study clinical signs and symptoms in clinical notes, especially their relations both within a patient and across patients. Recognizing mentions of symptoms in the clinical notes is only the first step; after recognizing all the mentions of potential symptoms, we also need to develop methods for further organization, abstraction, and analysis of the extracted symptoms. A major challenge here is how to support different applications in a general and efficient way. To this end, we propose a general symptom mining framework called SympGraph, which provides a general graph representation of symptoms and their relations extracted from the clinical notes. SympGraph can be regarded as an abstraction of clinical notes from the perspective of symptom analysis and mining in the sense that it contains essential and sufficient information about symptoms and their relations required by many different mining applications.
Below, we first present the overall process of building symptom graphs for clinical notes and then present the algorithms for con-structing and aggregating them.
The construction of symptoms can be done in a multi-level fash-ion as shown in Figure 3. At the patient level, clinical notes of a patient can be modeled as event sequences. The events in this paper are mentions of the symptoms in the clinical notes during a specific time interval (e.g., a day). SympGraph summarizes the ev ent sequences of a patient into a compact graph representation named patient (symptom) graph. A patient graph captures symp-tom co-occurrence relations for a given patient. The distance be-tween patients can be defined based on the similarity of the un-derlying symptom graphs. We can aggregate individual patients X  symptom graphs into a population-level symptom graph.

A symptom graph G is represented as G = { V; E; w } , where every node v  X  V represents a symptom, the edge e = ( v 1 represents the relationship between two symptoms v 1 and v weighting function w : e  X  R + maps the edge e to a positive value w ( e ) .

For a given patient p , such a symptom graph can be constructed, where nodes correspond to the symptoms extracted from p  X  X  clin-ical notes, and edges correspond to the relationship of symptoms exhibited in p  X  X  clinical notes. One simple way to construct the graph is to form edge ( i; j ) in G if symptoms i and j co-occurr in the same encounter note. Or formally, given a sequence of clinical encounters c i of p over time ( 1  X  i  X  C p ), we can construct a symptom to encounter matrix N is the number of encounters for patient p , and the element in N defined as The i -th row vector N i : of N corresponds to the patient p  X  X  en-counters that contain symptom i . The j -th column vector N corresponds to the symptoms extracted from the encounter note j . With the encounter matrix N p , the symptom co-occurrence matrix The nonzero elements in G correspond to all the edges of the symp-tom graph G . Intuitively, the symptoms extracted from the same encounter note are connected to each other, and form a clique. All the cliques from different encounter notes of a patient can be summed together to form the symptom matrix G . The weighting function w ( i; j ) is exactly the element G ij .

Beyond this simple construction, we also extend the formula-tion to a location sensitive construction. The location sensitive idea arises out of the intuition that a physician will likely evaluate the presence of related symptoms in succession and they will likely appear closeby in the clinical notes. Thus if two symptoms are far away from each other in the encounter note, the edge weight be-tween them should be small. If they are close, the weight should be large. In this paper, we use the inverse of the distance as the weight. Such formulation can still be captured by generalizing the multiplication operator as u v T = P 1  X  i  X  C f ( u i ; v i ) = 1 =d and d is the location offset in words between symptom u and v in the encounter i .
 Graph Normalization: In order to alleviate the problem where some symptoms are much more common than others, we further normalize a symptom matrix G constructed using a method de-scribed above through the following where D is a diagonal matrix with D ii = P j N ij . The result-ing matrix  X  G will be Markovian, namely the column sums to 1. In this case, the popular symptoms will be penalized since the out-going edges from them will be normalized. Note that the normal-ization does not preserve symmetric property of the original matrix G . There are other normalization methods that can preserve the symmetric property such as the normalized Laplacian normaliza-tion  X  G = D  X  1 = 2 GD  X  1 = 2 . In this paper, we pick the asymmetric normalization because we believe the relations are not always sym-metric. For example, v is a common symptom with many neighbors including u , but u is only connected to v . In this case, the impor-tance of u to v (i.e., w ( v; u ) ) is small, but the importance of v to u (i.e., w ( u; v ) ) is significant.
 Aggregation: Finally, given a set of normalized symptom graphs G ; G 2 ; : : : ; G K , we can also easily combine them into an aggre-gated symptom graph G by averaging the symptom matrices: Since the symptom matrices G i ( 1  X  i  X  K ) are already normal-ized, the simple averaging will preserve the Markovian property. Aggregation provides a general and flexible way to analyze the data with different  X  X esolutions X ; this in combination with graph anal-ysis algorithms naturally supports many different ways to analyze and exploit symptoms and their relations in a variety of applica-tions.
Given a symptom graph, one important clinical application is to automatically explore and expand an existing set of symptoms. Such expansion is necessary to improve the diagnosis of diseases (one use case is described in Section 1 about extending Framing-ham criteria for CHF diagnosis). To facilitate the discussion, we define the following notations: Let ES be the set of the exist-ing symptoms that one constructed (e.g., symptoms included in the Framingham criteria). Let vector e  X  R S be the indicator vector of the existing symptom set, where Let r  X  R S be the relevance score vector of all symptoms with respect to the existing set ES , which we hope to compute.
Intuitively, to perform symptom expansion, we would be inter-ested in obtaining symptoms that co-occur frequently with the ex-isting set of symptoms. Formally, such co-occurring symptoms can be captured through r = Ge , where highly ranked values in r cor-respond to the most commonly co-occurring symptoms with ES . Mathematically, this can be achieved by a one-step random walk from the existing set ES based on the symptom graph G .
In addition to the immediately co-occurring symptoms, we also perform the expansion recursively through random walk with restart [20]. Intuitively, random walk with restart (RWR) can be regarded as modeling a random particle that with probability c (0 &lt; c &lt; 1) traverses randomly along edges of G , and probability 1  X  c jumps back to one of the initial symptoms in ES . The recursion of ran-dom walk with restart is defined as The solution to the linear system eq-(2) is r = (1  X  c )( I  X  c G ) Many effective algorithms exist to solve eq-(2) when the underly-ing graph G is fixed. One simple and scalable method for solving this linear system is to use the power method to iteratively apply eq-2 with the initialization r = e (referred to as  X  X ower-method X ). Another effective way to solve eq-(2) is to use a low-rank approx-imation, followed by a matrix inversion of size l  X  l (where l is the rank of the low-rank approximation) to get all possible rele-vance scores. This solution [20], called NB_Lin, is summarized in Alg. 1 for completeness, where it is divided into two stages: NB _ LIN _ Pre() and NB _ LIN _ OQ() . In NB _ LIN _ Pre() (steps 1-3), a low-rank approximation is performed for the normalized adjacency matrix A and a matrix inversion  X  (referred to as  X  X ore matrix X ) is computed. Next, in NB _ LIN _ OQ() (steps 4-5), only a small number of matrix-vector multiplications are computed to out-put the ranking vector. Therefore, NB_Lin is much more efficient for the query response, especially when we have multiple queries. (We can view the  X  X eed symptoms X  used for symptom expansion as a  X  X uery X  and the task of symptom expansion as to  X  X etrieve X  additional related symptoms to the query.) Algorithm 1 NB _Lin (repeated from [20] for completeness) Input: The normalized adjacency matrix G , the query vector e Output: The ranking vector for the source node r . 1: Pre-Compute Stage ( NB _ LIN _ Pre() ) 2: do low-rank approximation for G = UV 3: pre-compute and store the core matrix  X  = ( I  X  c VU ) 4: On-Line Query Stage ( NB _ LIN _ OQ() ) 5: output r = (1  X  c )( e + c U X Ve )
In terms of applications, symptom expansion can be used at dif-ferent levels of symptom graphs. At the patient level, users like physicians, nurses or even patients themselves can expand the ex-isting set of symptoms from the current encounter to a more general set of symptoms based on the symptom graph built on the patient history. Those additional symptoms can be used as personalized query suggestions for diagnosis. One can also take the current symptoms from a patient p and perform symptom expansion based on the cluster symptom graph of p to immediately leverage patterns extracted from similar patients like p . Finally, at the population level, symptom expansion enables understanding of typical symp-toms to a disease.  X  X ypical symptoms X  as described in medical books such as Framingham symptoms for CHF are just a small ini-tial set of symptoms for diagnosing a disease such as CHF. Starting from an existing set of symptoms for a given disease, additional sets of symptoms can be obtained based on the population-level symptom graph using random walk with restart. The expansion set of symptoms can then be used as additional features for building predictive modeling for that disease, and also potentially enhance knowledge and understanding about the disease. We will present some initial clinical case studies in section 6 to show that the ex-pansion set of symptoms discovered using our algorithm are indeed helpful for improving the prediction accuracy of the onset of CHF.
In this section, we address the challenges in computing symptom expansion when the underlying symptom graph is changing. We first present our algorithm, and then analyze its accuracy as well as the efficiency.
When the underlying symptom graph G changes over time, the results of symptom expansion would also have to be updated. In the case of very frequent changes, which can happen, e.g., due to additions of many new patient records daily, updating all the results can be computationally expensive. Specifically, let  X  G indicate the change of the symptom graph (i.e.,  X  G + G is the new normalized adjacency matrix). If we still want to apply NB_Lin to update the corresponding ranking vectors straight-forwardly, we need to re-compute the low-rank approximation as well as the core matrix. In other words, the computational cost in NB_Lin_Pre() now becomes part of the on-line query cost in the dynamic case, which might be too expensive.

Thus an interesting question is: how can we update the ranking vector efficiently? To address this issue, we propose an efficient algorithm to update the low rank approximation as well as the core matrix. Our key observation is as follows: for the application of symptom graph,  X  G itself can often be written or approximated by some low-rank approximation with a much lower rank size (say k , then k &lt;&lt; l where l is the rank of G ). In this case, we can eas-ily update the low-rank approximation of the whole, new symptom matrix as well as the core matrix.
 Algorithm 2 Update-R WR Input: The previous low rank approximation U and V , the previ-Output: The updated low rank approximation U and V , the up-1: Update U and V ( Update _ LowRank() ) 2: Re-form or approximate  X  G as:  X  G = XY 3: Update: U  X  [ U X ] ; V  X  V Y 4: Update Core Matrix ( Update _ Core() ) 5: Compute L = ( I  X  c YX  X  c 2 YU X VX )  X  1 6: Compute P = c  X VX ; and Q = c YU X  7: Update  X   X   X  + PLQ PL LQ L 8: Update Ranking Vector ( Update _ Rank() ) 9: Update r = NB _ LIN _ OQ( U ; V ;  X  ; c; e ) The accuracy of the proposed Alg. 2 is summarized in Lemma 5.1.
L EMMA 5.1. Effectiveness of Update-RWR. If G = UV and  X  G = XY , Alg. 2 gives the correct ranking vector.
 P
ROOF . Let A = G +  X  G , we have A =  X  U  X  V , where  X  U = [ U X ] ; and V = V Y .

Let  X   X  = ( I  X  c  X  V  X  U )  X  1 . We have
Applying the block matrix inverse lemma [3] to eq-(3), we can verify that the step 7 in Alg. 2 gives the exact  X   X  matrix.
Then, for the updated ranking vector r , we have Notice that the second to the last step is due to the Sherman-Morrison lemma [15]. This completes the proof. 2 The efficiency of the proposed Alg. 2 is summarized in Lemma 5.2. It can be seen that it is much more efficient by (1) avoiding the re-computation of the low-rank approximation of the new normalized adjacency matrix, which takes O ( m ) time; (2) avoiding directly updating the new core matrix, which takes O ( k + l ) 3 .
L EMMA 5.2. Efficiency of Update-RWR. Let  X  m be the non-zero elements in  X  G , the time complexity of Alg. 2 is O (  X  m + nkl ) , where k and l are the rank of X and U , respectively.
 P
ROOF . Step 2 takes O (  X  m ) time to get the low-rank approximation of the matrix  X  G . Step 3 takes O ( nk ) time. Step 5 takes O ( nk nkl + k 3 ) time. Step 6 takes O ( nkl + l 2 k ) time. Step 7 takes O ( l 2 k ) time. Finally, step 9 takes O ( n ( k + l ) + ( k + l ) Notice that k  X  l  X  n , therefore, the overall time complexity of Alg. 2 is O (  X  m + nkl ) , which completes the proof. 2
The main motivation behind our experiments was to answer the following two questions: (1) Symptom Expansion: How useful are symptom graphs for the symptom expansion task? (2) Dy-namic Update: How does the performance(efficiency/accuracy) of the proposed Update-RWR algorithm compare to the baseline Power method? The following subsections present a detailed de-scription of our dataset, experiment design, evaluation metrics and the obtained results. Our dataset consists of 1 Million encounters of 13K patients. Among them, approximately 500K encounters (case subset) are cases (for 4.6K patients diagnosed with CHF), while the rest (con-trol subset) are controls (8.4K patients without CHF). The case pa-tients are defined by the operational criteria that include two or more mentions of CHF related diagnosis in outpatient visits and one or more mentions of CHF related diagnosis in the problem lists. Ten control patients are matched to each case patient on the age, gender and the clinic. Control patients do not have any CHF diagnosis by the diagnosis date of their corresponding case patient.
Each encounter is associated with a date, a patient ID and the type of visit. After processing the dataset with our UIMA pipeline, nearly 11.8K unique symptoms were extracted with an average of 12.7 positive symptoms and 5.7 negative symptoms per encounter.
To evaluate the utility of a symptom graph for the symptom ex-pansion task, we constructed six symptom graphs using the case subset (500K encounters) of the data. Four of them are constructed by using the four sections of the clinical notes (i.e., subjective, objective, assessment, and plan), respectively (all with location-sensitive weighting). The fifth was built by using text data in all the sections and location-sensitive weighting (LocSenseRWR). The sixth was also built by using all the sections, but with equal symp-tom weighing (EqRWR). That is, in the sixth graph, if two symp-toms appeared together in a clinical note, their edge weight was increased by 1 instead of 1 =d , where d is the location offset in words. The first five allowed us to analyze the utility of different sections for the task. The last one allowed us to analyze the utility of location sensitive heuristic itself.

For evaluating each symptom graph, we started with the 15 Fram-ingham symptoms as the initial vector and generated a ranked list of related symptoms using RWR. The accuracy of this ranked list was then evaluated in two ways -a) by comparing with expert judge-ments, b) by looking at the usefulness of the related symptoms for improving CHF prediction. Test Set Construction The gold standard of related symptoms used for evaluating the ranked lists was generated via pooling [7], an approach used fre-quently in information retrieval evaluation. Each symptom graph provided a single ranked list of symptoms. These ranked lists along with an additional list obtained via a co-occurrence baseline which ranked related symptoms based on how frequently they co-occured with the Framingham symptoms in the clinical notes, were used for judgements. Top 50 symptoms from each ranked list, a total of 175 unique symptoms, were pooled together and judged by two medi-cal experts. Finally, the 72 symptoms labeled as relevant by both experts were deemed as relevant and used for evaluation. The inter-annotation agreement was 81.8% (32 disagreements out of 175). Evaluation Metrics We used three standard information retrieval measures, i.e., Av-erage Precision, Precision@10 and Recall@100, for quantitative evaluation, which are described below.

Average Precision intuitively captures the average of precision at every point when a new relevant symptom is retrieved. A higher AP implies that a greater number of relevant symptoms are being assigned higher ranks in the ranked list. Suppose for some ranking r  X  R , there are k i relevant symptoms. Further let rank ( j ) be the rank of the j th relevant symptom and P ( rank ( j )) be the pre-cision at the rank of the j th relevant symptom. Then Av erage precision of r i is then given by: AP ( r i ) = P
Precision@10 is defined as the percentage of relevant symptoms in the top 10 symptoms of the ranked list. Recall @ K is computed as the ratio of the number of relevant symptoms in the top K re-trieved list to the total number of all relevant symptoms. Comparison of SympGraph construction methods Figure 4 shows the performance comparison of SympGraph with location sensitive heuristic (labeled LocSenseRWR) over two dif-ferent baselines -symptom co-occurrence and SympGraph with equal weighing. All graphs were constructed over the case subset and symptom ranked lists were obtained by using the 15 framing-ham symptoms as the initial vector for RWR. The location sensi-tive method (LocSenseRWR) outperforms the baselines in all three metrics. With an average precision of 0.46, it improves over the two baselines by about 31%. In particular, seven out of top ten symp-toms were found to be relevant and nearly 62% of known relevant symptoms were recovered in top 100 . The results suggest that not Figure 4: Comparison of location sensitive weighing with other baselines (31% improvement in AP over co-occurrence)
Figure 5: Location sensitive graphs over different sections only are symptom graphs useful for the task, but the location sen-sitive heuristic indeed helps improve performance.

Figure 5 shows the performance comparison of SympGraphs con-structed over different SOAP sections using the location sensitive heuristic. Performance varies significantly across sections.Graph based on Assessment section performed the best. This makes sense as the Assessment section primarily contains a concise summary of asserted symptoms and potential diagnoses. On the other hand, as one would expect, Subjective and Objective graphs did not do so well presumably since these sections are usually noisy with a lot of additional details. In practice, well formed section boundaries may not always be available. Therefore inspite of its slightly lower per-formance, we are still most interested in the graph built using the entire notes, and will continue to use it for subsequent experiments.
In order to further evaluate the utility of related symptoms, we defined the CHF prediction task. The goal was to analyze a se-quence of patient medical records and predict if a patient was likely to develop CHF in future, using only the list of related symptoms as features. For this task we used the entire dataset of 1M encounters.
For positive examples (i.e., case patients with CHF), we only used the data from clinical notes before a patient was diagnosed with CHF for constructing the feature vector. For negative exam-ples (i.e., control patients without CHF), we used all available data. Each selected symptom became one feature, and its feature value was the number of occurrences of that symptom in the patient X  X  records.
 We compared the following methods for selecting features: Framingham : Uses 15 Framingham symptoms + 35 randomly se-lected symptoms as features Co-occurrence : Uses 15 Framingham symptoms + 35 additional symptoms that most commonly co-occurred with Framingham symp-toms in the encounters. Table 1: CHF prediction performance.Parenthesis show im-pr ovement achieved by LocSenseRWR over the method LocSenseR WR : Uses the top 50 ranked symptoms obtained from a symptom graph constructed with location sensitive heuristic.
Using the selected features, the model was trained on 90% pa-tients and tested on the rest with 10 fold cross validation. Eval-uation metric used was Area Under the ROC-Curve (AUC). The classification model was an SVM classifier with Gaussian kernel: where x i and x j are data samples and  X  r is the average of pairwise distances among all the data samples. a is chosen from [2 2  X  1 ; 1 ; 2 1 ; 2 2 ; 2 3 ] . The SVM trade off parameter C is chosen from [0 : 01 ; 0 : 1 ; 1 ; 10 ; 100] . We report the best results among all the combinations of a and C .

The results from CHF prediction task are shown in Table 1, which corroborate our observations from human judgement evaluation. The location sensitive graph (LocSenseRWR) outperforms the base-lines, suggesting that the expanded symptoms are useful for the task. Figure 6 shows some of these top expanded symptoms. In particular, coronary arteriosclerosis, hypertension, diabetes etc. are all very related co-morbidity and risk factors to HF and have been confirmed by clinical experts.
In order to evaluate the efficiency of the proposed Update-RWR method we defined two real world update tasks: (1) Symptom Ex-tractor Update : This task assumes that we have just updated our UIMA pipeline to extract a new symptoms from clinical notes. As a result the existing graph must be updated with a new symptom node and all its edges. (2) Patient Update : This task assumes that data for a new patient (a small patient subgraph) has joined and needs to be incorporated into an existing symptom graph.
Both tasks require incorporating a smaller subgraph (represent-ing new information) into an existing symptom graph. We want to evaluate efficiency and effectiveness of Update-RWR algorithm compared to recomputation using the power method.
 All dynamic update experiments were carried out on a 32-bit Windows Vista machine with 3Gb RAM and intel core-2 Duo 2.5 GHz processor. The initial symptom graph G consisted of 11 : 8 K symptom nodes and 1 : 4 million edges. For both patient update and symptom update tasks, individual patient subgraphs usually con-tained less than 1000 edges, while for symptom update task, the symptom subgraphs contained up to 2500 edges. Accuracy Analysis: For accuracy evaluation, the top N ranked symptoms generated by the Update-RWR and the baseline methods (Power method) are compared by using the baseline symptoms as the gold standard. Evaluation metrics used are: Average Precision (AP), Precision at 50 ( P @50 ), and Recall at N .

Intuitively precision at 50 tells us how many of the top-50 symp-toms generated by Update-RWR, were found in the gold standard. Recall at N gives the percentage of gold standard symptoms that were recovered by Update-RWR. Finally AP takes a high value if both precision and recall are high.
 Efficiency Analysis: Recall that both methods start with an ini-tial normalized matrix G as their starting point. For the baseline, adding a new subgraph requires the modified graph matrix to be renormalized. For Update-RWR we need to calculate the U , V ,and  X  once on the initial normalized matrix and update them whenever a new subgraph is added (refer to algorithms 1 and 2). As a result the speedup is evaluated by looking at three different times: Initial one time matrix construction : In case of Update-RWR, this is the time for constructing the matrices U , V and  X  on the large initial matrix as in algorithm 1. For the baseline this time is 0 . This will happen only once.
 Matrix update time : For the baseline, this is the time required to add the new subgraph matrix into the original symptom graph ma-trix and re-normalize the resulting graph. This is the time for com-puting the updated  X  U ,  X  V and  X   X  as in algorithm 2. This will happen every time a new subgraph is added.
 Online Query time : This is the time to perform random walk restart. In case of baseline, it is the time taken for applying the power method. For Update-RWR it is the time for performing the step N B _ LIN _ OQ () in algorithm 1.
Figure 7 presents the results for Symptom Update task for the symptom  X  X NDyspnea X . Results for other symptoms were similar. The task was simulated by constructing a symptom graph without one of the Framingham symptom nodes and later updating it with all of missing symptom X  X  edges. RWR was then run on the updated matrix using the new symptom as the initial vector. The accuracy was compared for top N = 200 symptoms (results for other val-ues of N were similar). The low rank approximation parameter l for the initial normalized matrix G serves to control the trade-off between efficiency and accuracy of the method. The low rank approximation parameter k for the update matrix  X  G did not affect the results as much and was empirically set to 2 . The low rank approximations were obtained using the signular value decompo-sition (SVD [3]) method. Increasing l results in improved average precision and recall@200, which both tend to 1 as l goes beyond 400 . On the other hand even for small values eg. l = 50 the perfor-mance is still reasonably good. In particular, we observed a P @50 of 1 for all data points in Figure 7. This implies at all of the top 50 ranked symptoms by Update-RWR were found in the top 200 baseline symptoms. In addition, 89% symptoms were common in the two lists. Finally AP of 0 : 88 implies that most of the symptoms ranked high by Update-RWR were common to both lists.

In terms of efficiency, we observe that the speedup reduces as l increases. This is because a higher l implies a matrix multipli-cation between dense higher dimensional matrices. Assuming l as 50 we observe that while the difference in matrix update times is not that much, Update-RWR outperforms the baseline significantly in online query performance. We do not compare the performance of Update-RWR with the original N B _ Lin in algorithm 1 as it Figure 7: Symptom update results (speed up values are for on-line query performance) Table 2: Time comparisons for patient update task. All values in secs. Averages are over 50 patient additions. Parenthesis provide standard deviations. would require us to reconstruct the three U , V ,  X  matrices on every update, and as a result the method would perform far worse than the other two, making the comparison not interesting.
 Table 2 presents the different time metrics for Update-RWR and Power method for adding a new patient subgraph and running RWR. The time values are averaged over 50 different patient additions. The value of low rank approximation parameters l and k were fixed at 50 and 2 , respectively. As expected, our proposed method is over 78 times faster than the baseline. This improves efficiency dramat-ically when multiple RWR queries need to be performed. Figure 8 illustrates this point.

Finally, Figure 9 compares the accuracy. Here we update G by repeatedly adding new patients using Update-RWR i.e. for adding x patients, Update-RWR gets applied x times consecutively. The accuracy of the updated matrix after say x patient additions, is eval-uated by comparing against the ideal normalized matrix for those additions, i.e. the one we get after adding all x patient subgraphs to G and renormalizing. We observe that the accuracy continues to remain high inspite of over 400 consecutive new patient additions.
Information extraction from clinical records and medical text in general has been studied in the existing work (see, e.g., [4, 12, 23, 18, 16]). In most cases, standard information extraction techniques have been applied or adapted to the medical domain for recogniz-ing various entities such as diseases [22] and treatments [2]. We however, go beyond symptom extraction to further construct symp-tom graphs and study how to leverage such graphs to convert raw symptom mentions into more useful knowledge.

Graph representations are frequently used to facilitate data min-ing. In most cases, a graph is naturally constructed based on ob-served data where the edges are directly available in an application. For example, Web graphs are often constructed with web pages as nodes and hyperlinks as edges [13, 8]. Also, information network Figure 8: Online RWR query execution times. The scale on x-axis is logarithmic.
 mining has recently been studied (see e.g., [19]), especially bib-liographical network and social networks. A main difference be-tween the proposed SympGraph and these graphs lies in that both the nodes and edges in a SympGraph are extracted computation-ally from text data. An immediate consequence of this difference is that we need to address the issue of uncertainty in the edges of a SympGraph, which raises new challenges in designing graph min-ing algorithms.

Random Walk with Restart (RWR) [20] and related ideas have been applied to many problems such as Personalized PageRank [5] for Web search and image tagging [1]. Thanks to our graph viewpoint for the extracted symptoms, we are able to leverage this powerful tool to discover related patient symptoms. In terms of computation, most of the existing fast algorithms apply to the static graphs. In [21], the authors proposed an efficient on-line algorithm for skewed bipartite graphs, which does not apply to the symp-tom graph. Other remotely related works include dynamic PageR-ank [14, 17], Fast SimRank [10, 9], etc. Our work can be regarded as adding to this line of work a new application of RWR for finding related symptoms in graphs of patient symptoms.

Prediction of patient diseases based on patient records has been studied mostly by using the structured fields in the patient records (see e.g., [6]). Our work aims at tapping into the unstructured text data in clinical notes to extract symptom information, which can be used as extra features for prediction in a statistical prediction model, thus can be regarded as complementary with the study of prediction methods. Our experiment results show that the symptom features generated using the proposed SympGraph can be leveraged to improve the accuracy of prediction of CHF disease.
In this paper, we present SympGraph, a general mining frame-work for extracting and analyzing symptoms in longitudinal clin-ical notes. SympGraph constructs symptom graphs based on co-location relations among detected symptom mentions. Within the general formulation of symptom graphs, we present the important clinical mining application of symptom expansion. We also present an efficient dynamic update method to incorporate updates to the underlying symptom graphs.

Our evaluation on a large-scale real world clinical database with 1 million clinical notes of over 13K patients revealed an improve-ment of over 31% for the symptom expansion task and that the expanded symptoms were indeed useful for predicting the onset of Congestive Heart Failure. In terms of the scalability we show that the proposed dynamic symptom expansion approach is signifi-cantly faster than the baseline Power method when multiple online queries are involved.

It is worth noting that although we mainly explored the use of the proposed SympGraph for symptom expansion at the population level. SympGraph can easily support many other mining applica-tions, particularly due to the possibility of constructing SympGraph in multiple resolutions. Indeed, we can construct SympGraphs cor-responding to any meaningful ways of aggregating patient records (e.g., at the level of individual patients, patient groups, or aggre-gation over different time periods or geographic locations). More-over, in addition to symptom expansion, SympGraph can also nat-urally support many other tasks such as patient stratification and clustering, comparative analysis of patient groups or mine tempo-ral symptom patterns. Given the importance and promise of apply-ing text mining to the health domain, we believe that the proposed SympGraph can serve as a general representation framework for developing sophisticated text mining systems in health domain. [1] T. Bailloeul, C. Zhu, and Y. Xu. Automatic image tagging as [2] S. Doan and H. Xu. Recognizing medication related entities [3] G.H. Golub and C.F.V. Loan. Matrix Computation . Johns [4] H. Harkema, I. Roberts, R. Gaizauskas, and M. Hepple. [5] T.H. Haveliwala. Topic-sensitive pagerank. In WWW , pages [6] B.E. Himes, Y. Dai, I.S. Kohane, S.T. Weiss, and M.F. [7] K. Jones and C.J.V. Rijsbergen. Report on the need for and [8] J.M. Kleinberg. Authoritative sources in a hyperlinked [9] C. Li, J. Han, G. He, X. Jin, Y. Sun, Y. Yu, and T. Wu. Fast [10] D. Lizorkin, P. Velikhov, M.N. Grinev, and D. Turdakov. [11] P.A. McKee, W.P. Castelli, P.M. McNamara, and [12] S. Meystre, G. Savova, K.K. Schuler, and J. Hurdle. [13] L. Page, S. Brin, R. Motwani, and T. Winograd. The [14] A. Pathak, S. Chakrabarti, and M.S. Gupta. Index design for [15] W.W. Piegorsch and G.E. Casella. Inverting a sum of [16] A.R. Post and J.H. Harrison Jr. Protempa: A method for [17] A.D. Sarma, S. Gollapudi, and R. Panigrahy. Estimating [18] G.K. Savova, J.J. Masanz, P.V. Ogren, J. Zheng, S. Sohn, [19] Y. Sun, Y. Yu, and J. Han. Ranking-based clustering of [20] H. Tong, C. Faloutsos, and J.Y. Pan. Random walk with [21] H. Tong, S. Papadimitriou, P.S. Yu, and C. Faloutsos. [22] Y. Wang. Annotating and recognising named entities in [23] H.Xu, S.P. Stenner, S. Doan, K.B. Johnson, L.R. Waitman,
