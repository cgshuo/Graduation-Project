 1. Introduction
Representing relational data by networks is extremely useful and widely implemented. The dyadic relations which compose these networks are viewed as a set of actors and a set of edges between the actors. The edges can vary in many ways, such as being directed or undirected, static or temporal, binary or weighted.
Binary networks, where between each actor an edge either does or does not exist, are encountered more often in the literature, although many such networks are by nature weighted. Weighted networks, also referred to as valued networks, consist of actors connected by edges which can take more than two values. By accounting for the weight, or strength, of the edges, the richness of the data can be better exploited. Examples of analyses of real world weighted networks include food webs ( Krause et al., 2003 ), gene expression data ( Zhang and Horvath, 2005 ), airline networks ( Barrat et al., 2005 ), mobile phone networks ( Onnela et al., 2007 ), and many more.

Often in binary networks it is of interest to compute vari-ous network measures, and recently there has been increasing work in extending these measures to weighted networks. Opsahl et al. (2010) derived for weighted networks measures for degree, closeness, and betweenness. Yang and Knoke (2001) derived a method for computing path length in the case of weighted edges. Opsahl and Panzarasa (2009) developed a method for analyzing the clustering that exists within a network with weighted edges. Other interesting works include Kunegis et al. (2009) , which analyzed the case where edges took values in {  X  1, 0, 1 } , and Newman (2004) , which showed how to model networks whose edges are counts by representing them as multigraphs. To fully model the network, Krivitsky (2012) extended the commonly used exponential ran-dom graph model (ERGM) to account for networks whose dyads are counts; Krivitsky and Butts (2012) extended the ERGM to account for networks whose dyads are rankings.

Network data are most often inherently dynamic, even though it is frequently the case that the data are simply aggregated over time into one static network. Many popular static networks have been extended to longitudinal network data. Examples of this include the temporal exponential random graph model developed by Hanneke et al. (2010) and the separable temporal exponential graph model by Krivitsky and Handcock (2014) , the mixed membership stochas-tic blockmodel for dynamic networks by Xing et al. (2010) , and the latent space model for dynamic networks by several authors includ-ing Sarkar and Moore (2005) , Sewell and Chen (2015b) , Morgan (2014) and Durante and Dunson (2014) .

This paper is focused on network data that is dynamic, weighted, and possibly directed. There are few resources available to the researcher investigating such data. Most approaches in existence focus on latent space models for dynamic undirected networks. Latent space models assume the dependence of the network is induced by a set of latent variables. Such approaches are typically intuitive and have the advantage of producing meaningful visual-izations, allowing the researcher to better understand the network structure as well as the behavior of individual actors.
Sarkar et al. (2007) extended the CODE model of Globerson et al. (2004) for dynamic undirected networks. This method is an approximate filtering algorithm which models the longitudi-nal count networks, embedding the actors in a latent space. This method is not easily generalizable to other sorts of co-occurrence data besides counts, however, and cannot handle directed edges.
Hoff (2011) described a multilinear model for undirected longitu-dinal networks. In this work, Hoff showed how to model undirected edges or ranked edges, where each dyad is an element from a finite ordered set, though it should be feasible to extend his approach to other types of dyads. Sewell and Chen (2015a) developed a latent space model for directed ranked dynamic networks, where each actor ranks each other actor, although it is not obvious how to extend this approach beyond this specific context.

The remainder of the paper is organized as follows. Section 2 extends the latent space model for dynamic networks with valued edges. Section 3 gives a method of estimation. Section 4 describes an approximation to reduce computational cost for large networks.
Section 5 gives simulation results. Section 6 gives the results for analyzing a mobile phone network and world trade data. Section 7 provides a brief discussion. 2. Models
We assume here that each actor exists within some latent space which can be interpreted as a characteristic space, or a social space.
When actors are closer together in this latent space, the probability of a stronger edge is increased (where a  X  X tronger edge X  means a stronger relationship, though the actual form of this is context specific).
 We first introduce some general notation to be used throughout.
Assume we have a set of actors N and a set of edges E . Let n be the number of actors, and let Y t be the n  X  n adjacency matrix of the observed network at time t whose entries y ijt correspond to
X  X  R p be the position vector of the i th actor at time t within the p dimensional latent space. Let X t be the matrix whose i th row is
X . Finally, let be the vector of unknown parameters (which will vary depending on dyadic type).

As in Sarkar and Moore (2005) and Sewell and Chen (2015b) , we assume the latent actor positions transition according to a Markov process, where the initial distribution is (
X | ) = and the transition equation is (
X | X t  X  1 , ) = denotes the multivariate normal probability density function with mean and covariance matrix evaluated at x . While this is the latent dependence structure used throughout the remainder of the paper, other dependence structures could be defined, such as the latent path model given by Morgan (2014) .

In most dynamic network models it is assumed that the dependence structure of the network is fully induced by the latent positions of the actors. This assumption, along with the Markovian properties of the latent positions, leads to the state space temporal dependence structure given in Fig. 1 , as well as the conditional inde-pendence of each dyad within a time period. The ranked networks of the form analyzed by Krivitsky and Butts (2012) and Sewell and
Chen (2015a) are a counter example of where there is an extra dependency constraint in the data, but we will not discuss further these rare data types. What remains then is to derive an appropriate conditional likelihood function, ( Y 1 , . . ., Y T | X 1 Most latent space approaches have the conditional likelihood constructed by writing the logit of the edge probability as a lin-ear form of covariates and a function of the latent variables, i.e., logit( ( y ijt |  X  )) =  X  w ijt + f ( X it , X jt ), where parameters, w ijt is a vector of dyad specific covariates, and f :
R p  X  R p  X  R is a function taking as its arguments two actors X  latent variables. Our generalization of this has the basic form g (
E ( y ijt )) =  X  w ijt + f ( X it , X jt ) , (3) for some link function g . We can utilize the same types of link func-tions found in generalized linear mixed models. For example if our dyads are in the form of continuous data, we may set g to be the identity; this may arise in, for instance, proximity networks (see, e.g., Olgu X n et al., 2009 ), where the distance between individuals is recorded on a regular basis. The common case of modeling binary dyads through the logit link function is yet another example. In Sec-tion 2.1 we will go into detail for the context of count data, using a log link function.
 In some cases, however, the dyads cannot be modeled directly through a link function as in (3) . Instead we can introduce additional latent variables, and then adopt a similar strategy. For example, we may consider a zero inflated model. The zero inflated model is a two component mixture model, where one could introduce additional latent indicator variables which determine whether the observation is coming from the component which is a point mass at zero or the component that has some other density function (e.g., * is the Poisson density). We could then model g ( as in (3) . This situation may arise in large sparse weighted network data, such as company wide email count networks. Zero-inflated models are certainly not the only possibility of this type of data augmentation, as we will see in Section 2.2 .
 For the remainder of the paper we will focus on count data and non-negative continuous edges. We will furthermore utilize the conditional likelihood given by Sewell and Chen (2015b) , deter-mined by f ( X , X jt ) =  X  IN 1  X  t within the latent space, and r = ( r 1 , r 2 , . . . , r itive actor specific parameters constrained such that n i for model identifiability. For the remainder of the paper we will also, for simplicity, ignore the covariate information  X  straightforward to reincorporate such information into the work that follows.
 Each r i can be thought of as the i th actor X  X  social reach. That is, a larger value of r i implies that it is more likely for an edge, either y i  X  t or y  X  it , to take a larger value. These r metric interpretation within the latent space, specifically a radius.
For example, in the context of binary networks, this radius can be understood to imply that actors inside of each other X  X  radii have a greater than 1/2 probability of an edge, and actors outside of each other X  X  radii have a smaller than 1/2 probability of an edge. The coefficients  X  IN and  X  OUT can help in understanding the global struc-ture of the network, insofar as telling us whether activity (tendency to send stronger edges) or popularity (tendency to receive stronger edges) is more important in forming high strength edges. Specifi-the edges are undirected, then setting P ( y ijt |  X  ) = P alent to constraining  X  IN =  X  OUT . See Sewell and Chen (2015b) for more details on parameter interpretation. 2.1. Counts
A commonly encountered dyadic type which can be modeled by (3) is where y ijt is a count. This context may exist in the form of counting the number of phone calls, the number of emails, the number of cosponsored legislative bills, the number of passengers or of flights in airline data, etc. We can use the canonical link for a Poisson random variable to determine the likelihood function in the following way:
P ( y ijt | X t , ) = where log( ijt ) =  X  IN 1  X  likelihood is
P ( Y 1 , Y 2 , . . ., Y T | X 1 , X 2 , . . ., X T , ) = 2.2. Non-negative continuous edges
Here we consider the case of non-negative continuous real val-ued edges. These types of networks can occur in many biological contexts, in economic contexts, in length of phone calls, etc. The latent space framework provides a natural way to think about such a weighted network, in that we can consider two actors with large weighted edges between them as very close in the latent space, and two actors with smaller weighted edges as more separated within the latent space.

By embedding the network into a latent space we can better differentiate between zero valued edges. Consider as an exam-ple a longitudinal sequence of social networks, where the dyadic variable measured is the amount of time two individuals spent speaking with each other: Suppose at a particular time, person i has a weighted edge of zero with two others, persons j and k . Now persons i and j are potential friends though they have not cur-rently met; meanwhile, persons i and k know each other already and strongly dislike each other. In both cases the measured edges between i and j and between i and k will be the same (zero), but we can differentiate them in two ways. First and foremost we can compare edge probabilities (e.g., P ( y ijt = 0) P ( y ikt viewing the latent variables as unobserved actor attributes, we can determine the dissimilarity between each pair (e.g., d ijt key point here is that we are using all the data, not just the data zeros; i.e., we are letting all dyads help inform us as to the position of each actor within the latent space. This can be better understood by considering if i and j have many links to the same actors, then the geometric constraints within the latent space imply that i and j will be close together, whereas the same would not be true if, say, i and k do not have many links to the same actors.

Network data with non-negative continuous edges is a context where there is not an obvious link function g to be applied to the mean of y ijt , but by introducing an additional latent variable we can adopt a similar strategy. In particular, we apply a Tobit model when formulating the likelihood function, letting y ijt = y  X  ijt 1 variable. This type of approach may be most appropriate when the weighted dyads we observe are really proxies for some underlying relationship between the two actors, but we can only observe the effects from positive relationships (e.g., length of phone calls can only serve as a proxy for a relationship between friends, and not between enemies). We then apply (3) to the latent variables y letting g be the identity function, obtaining y | ( X t , ) iid  X  N (0 , 2 ) . (9) With this we have ( y ijt | X t , ) = N ( y ijt | E ( y  X  ijt | X t , ) , 2 where is the standard normal cumulative distribution func-tion, and E ( y  X  ijt | X t , ) =  X  IN 1  X  d ijt /r j +  X  plemented by 2 such that = (  X  IN ,  X  OUT , 2 , r , 2 , 2  X  X  are conditionally i.i.d., we have that the observation equation is P ( Y 1 , Y 2 , . . ., Y T | X 1 , X 2 , . . ., X T , ) = 3. Estimation
To obtain estimates of the latent space positions and of the unknown parameters, we sample via a Markov chain Monte Carlo (MCMC) algorithm from the posterior ( X 1 , X 2 , . . ., X T , | Y 1 , Y 2 , . . ., Y T ) . (12) The general strategy is to find reasonable estimates of the latent positions and of the model parameters to initialize the chain, and then use a Metropolis X  X astings (MH) within Gibbs sampling to obtain the posterior samples.

The prior for r was a Dirichlet distribution. The priors for and, in the case of continuous data, 2 were chosen to be inverse gamma (IG), as these distributions are conjugate for 2 and shape and scale parameters for 2 were set to be equal to 2 +  X  and (1 +  X  ) 2 positive constant 2 0 , and were similarly set for 2 and 2 this parameterization, the prior variances of 2 , 2 and 2 large. The prior set on  X  IN was a normal distribution with mean and (large) variance IN , and similarly for  X  OUT .

In some cases, by taking a preliminary look at the data we can set these hyperparameters to reasonable values; specifically, we may match the prior means to the initialized values given in the next section. This  X  X irst glance X  allows us to form our prior beliefs about the scale of the parameters, as well as about the individ-ual actor effects. This idea follows the same underlying concept as empirical Bayes methodology, in that we are (albeit to a small degree in comparison to standard empirical Bayes methods) using the data to construct the hyperparameters. This idea was used in
Sewell and Chen (2015b) to good effect, and also yielded good results in our analyses. For some other parameters there is not an obvious way in which we can set the hyperparameters in this fashion. As will be described in the simulation study, however, the results were not sensitive to the selection of these hyperparameter values. 3.1. Initialization
We initialized the radii as r =
The Dirichlet hyperparameters a = ( a 1 , a 2 , . . . , a set to be equal to these initial estimates. Doing so sets the prior our prior intuition; additionally, as each a j would be small (averag-prior).

To find initial latent positions, we implemented the general-ized multidimensional scaling algorithm (GMDS), as described in
Sarkar and Moore (2005) . GMDS starts by taking a distance matrix at time 1 and performing classical multidimensional scaling. Then, for each subsequent time period t , t = 2, 3, . . . , T , GMDS balances the position matrix from the previous time point with the classical multidimensional scaling result obtained from the distance matrix at time t .

The original distance matrices can be found in a number of ways, but we offer the following suggestion. We treated the data as binary, where y
We then computed each distance d ijt according to d =
The general idea here is that positive edges indicate a close-ness between the actors; using the radii as measures of closeness accounts for the individual effects as well as keeps the distances on the same scale as the radii, as would seem reasonable based on (4) . With the T distance matrices computed, we can then implement GMDS to obtain initial latent positions.

The initial estimate for 2 was computed (using the initial esti-mates of X 1 ) as 1 np
In our analyses we also used this value to determine the hyperpa-rameter 2 0 , the prior mean of 2 .

We found that the initial value of 2 did not make a noticeable initial estimates for 2 ,  X  IN and  X  OUT and the values of their hyper-parameters did not significantly affect the number of iterations required to reach convergence. 3.2. Posterior sampling We implement a MH within Gibbs sampling scheme. The algo-rithm is 0. Set the initial values of the latent positions and parame-1. For t = 1, 2, . . . , T and for i = 1, 2, . . . , n , draw X 2. Draw 2 from ( 2 | X 1 ). 3. Draw 2 from ( 2 | X 1 , X 2 , . . ., X T ). 4. Draw r via MH. 5. Draw  X  IN via MH. 6. Draw  X  OUT via MH.
 7. Draw 2 via MH.Repeat steps 1 X 7.
 The full conditional distributions needed for steps 2 X 7 are given in the Appendix. Regarding the proposal distributions, X it and  X 
OUT can come from a symmetric proposal (e.g., normal ran-dom walk). For 2 , however, some asymmetric proposal such as a log-normal (what we used in our analyses) or an inverse gamma distribution ought to be used to ensure positive valued proposals; this asymmetric proposal will then need to be accounted for in the acceptance probability. Because of the constraint on r , a Dirichlet proposal is suggested for the radii, which also will be an asymmet-ric proposal. Suggested parameters for this Dirichlet proposal are r curr , where r curr are the current values for r and is some large value.
 One final note is that, as is the case for any such latent space model, the posterior is invariant under rotations, reflections and translations of the latent positions X 1 , X 2 , . . ., X make the MCMC iterations comparable, after each iteration of steps 1 X 7 we perform a Procrustes transformation on the nT rotations, reflections and translations to minimize the difference between a given matrix and some target matrix. In our analyses, we constructed the target matrix from the initialized latent position trajectories. 4. Scalability The MCMC algorithm of Section 3.2 can handle many data sets, including the two that are fully described in Section 6 . However, in cases where the network is very large, the MCMC algorithm may prove to be too slow to be viable. For static binary latent space network models, Raftery et al. (2012) described a method for approximating the log likelihood using case X  X ontrol princi-ples. Sewell and Chen (2015b) also used this method for binary dynamic latent space network models, adapting it slightly to allow for missing data. Here we extend this for models whose dyads can be described by an exponential family of distributions. For the MCMC algorithm, the MH steps required in updating the latent positions, r ,  X  IN ,  X  OUT and other likelihood related param-eters (e.g., 2 in the case of non-negative real dyads) all require
O ( Tn ) terms to be summed. In this discussion we will assume here that a non-relationship between two actors implies that y erwise y ijt is some positive value; the principles discussed next ought to hold even if this is not the case. Generalizing the approx-imation method first proposed by Raftery et al. (2012) , we can reduce this computational cost to O ( Tn ).
 Suppose that, conditional on the latent positions, the y ijt independent with ( y |  X  ) = h ( y ijt ) exp( where ijt is a vector valued function of ( X t , ) and T ( y of sufficient statistics. Then we can rewrite the loglikelihood of ( Y . . . , Y T ) as ( X 1 , . . ., X T , ) =
It is reasonable to assume that as the network gets larger and larger, the number of edges of each node does not grow at the same rate (i.e., the network gets sparser). Hence we make the assumption that then we can, for each i and t , take a subsample { j k } N summation of (18) to reduce the computational cost to linear with respect to n . Then the approximation we use of the log likelihood is ( X 1 , . . ., X T , )  X  where n i , t ,0 = | { j : y ijt = 0 } | . In most cases, T ( y the above can be simplified such that the second summation is only for more details.
 tion. For the context presented in Section 2.1 , we can approximate the log likelihood as ( X 1 , . . ., X T , )  X 
For the context presented in Section 2.2 , we can approximate the log likelihood as (
X 1 , . . ., X T , )  X 
An interesting point is that if we assume that the network becomes more sparse as n grows, then it may be more appropriate to utilize a zero-inflated model, such as was mentioned in Section 2 . Suppose we can augment the data by component indicator vari-ables z ijt  X  { 1, 2 } , such that ( y ijt | z ijt = 1,  X   X  ) can be constructed according to (17) , where  X  is the Dirac delta complete log likelihood (i.e., ( y ijt , z ijt : 1  X  i / = as + constant . (22) Since the z ijt  X  X  are nuisance parameters, we need not sample all of them in the Gibbs sampler, but rather only the z ijt  X  X  correspond-computational cost of O ( Tn ). 5. Simulations
We analyzed simulated data for both count data and non-negative continuous data. In each case we simulated 20 data sets where the number of actors was 100 and the number of time points was 10. The values used in these simulations, given in the next two sections, were chosen to create data that were similar to the real data we analyzed. 5.1. Simulated count data
For each of the 20 simulations, the parameter values were set at  X  IN = 3 and  X  OUT = 1. The transition variance was set to be 2 = 1  X  10  X  6 . The latent positions at time 1 were drawn from a mixture of 10 normals with equal mixture component weights, where the cluster means were drawn randomly from a multivariate normal distribution with mean zero and covari-After the initial latent positions X 1 were drawn, the radii were drawn from a Dirichlet distribution whose i th parame-ter was equal to n (1 / X i 1 ) / max centrally located actors a large individual effect, which reflects reality. Subsequent latent positions X t , t  X  2, were drawn accord-ing to (2) . The adjacency matrices Y 1 to Y T were then generated according to (5) and (6) . The mean proportion of edges that were positive over the simulations was 0.56, ranging from 0.34 to 0.69.

For each simulation we drew 2 0 from U (1  X  10  X  4 , 1  X  10 Both hyperparameters IN and OUT were for each simulation drawn from U (1, 15); IN and OUT were set to be 1000.

To evaluate the simulation results, we compared the estimates of the coefficients  X  IN and  X  OUT with the truth, evaluated the pseudo R , and evaluated the pairwise ratios of estimated distances to true distances corresponding to the latent positions. The pseudo R value is the deviance based pseudo R 2 for count data found, and rec-ommended, in Cameron and Windmeijer (1996) . This is calculated as R rior mean estimates in (6) . To clarify what is meant by the distance ratios, note that for each simulation there are Tn ( n  X  1)/2 distances within the latent space. We calculate all these pairwise distances using the posterior mean latent positions as well as using the true latent positions. So for each simulation we can plot a curve corre-sponding to the distribution of these ratios. We would hope for this curve to be narrow and centered at 1.

The posterior mean estimate, averaged over the 20 simulations, for  X 
IN (  X  OUT ) whose true value was 3 (1), was 2.95 (1.01), ranging from 2.84 to 3.01 (0.969 to 1.06). The pseudo R 2 values X  average was 0.930, ranging from 0.908 to 0.944, implying that the pos-terior means fit the data well. The distributions of the ratios of pairwise distances are given in Fig. 2 (a), where each curve corre-sponds to a simulation. From this figure we see that the picture we obtain from the estimated latent space is close to the true latent space, up to a rotation/translation, for all but perhaps one simu-lation; this outlying simulation still yields a narrow distribution, implying that the picture of the latent space is close to the truth up to a scaling factor. In each simulation we are satisfied with the results; considering that 2 0 , IN , and OUT were randomized in each case, we can conclude that the results are not sensitive to these hyperparameters. 5.2. Simulated continuous data
For each of the 20 simulations, the parameter values were set at  X 
IN = 3,  X  OUT = 1, 2 = 4, and 2 = 1  X  10  X  6 . The latent positions at time 1 were drawn from a mixture of 10 normals with equal mixture component weights, where the cluster means were drawn randomly from a multivariate normal distribution with mean zero space. After the initial latent positions X 1 were drawn, the radii were drawn from a Dirichlet distribution whose i th parameter was equal to n (1 / X i 1 ) / max t  X  2, were drawn according to (2) . The adjacency matrices Y y = over the simulations was 0.480, ranging from 0.293 to 0.590. For each simulation we drew 2 0 from U (1  X  10  X  4 , 1  X  10 from U (1, 5), and both IN and OUT from U (1, 15); both IN were set to be 1000.
 To evaluate the simulation results, we compared the estimates of the coefficients  X  IN and  X  OUT with the truth, evaluated the pseudo
R , and evaluated the pairwise ratios of estimated distance to true distance. In this context of continuous non-negative data, we used the pseudo R 2 value recommended in Veall and Zimmermann (1994) , originally derived by McKelvey and Zavoina (1975) . This is calculated as
R where  X  y  X  ijt =  X   X  IN (1  X   X  d ijt /  X  r j ) +  X   X  OUT 1)) the posterior mean estimate.
 The posterior mean estimate, averaged over the 20 simulations, for  X 
IN (  X  OUT ) whose true value was 3 (1), was 2.96 (1.01), ranging from 2.63 to 3.12 (0.938 to 1.11). The pseudo R 2 values X  average was 0.854, ranging from 0.660 to 0.982, implying that the posterior means fit the data well. The distributions of the ratios of pairwise distances are given in Fig. 2 (b), where each curve corresponds to a simulation. Nearly all of these are narrow and centered near one, implying that the picture we obtain from the estimated latent space is close to the true latent space up to a rotation/translation and sometimes a small scalar. In each simulation we are satisfied with the results; considering that 2 0 , 2 0 , IN , and OUT were randomized in each case, we can conclude that the results are not sensitive to these hyperparameters.
 6. Data analysis 6.1. Friends and family data We consider the Friends and Family data collected by the MIT
Human Dynamics Lab ( Aharony et al., 2011 ). We looked at the mobile phone log, counting the number of calls between each (directed) pair of individuals from October, 2010, to May, 2011.
The context of the study is a community of couples, around half of who have children, where one member of each couple is associ-ated with a nearby major research university in North America. Of the approximately 200 applicants, 130 actors of the network were selected in such a way as to represent the full community and sub-communities. The entire community consists of 400 residents of a young family living community. This study captured many aspects of the subjects beyond just the phone log, and among these we will look at religion and race. For more details on the data and the collection process see Aharony et al. (2011) .

The edges y ijt of the adjacency matrices Y t represent the num-ber of phone calls from subject i to subject j . These counts were binned by month, and hence we had T = 8 time points. We elimi-nated any subjects who averaged less than one phone call, incoming or outgoing, per month. This left 119 subjects. Using counts rather than simply considering whether subject i did or did not call subject j during the t th month gives more insight into how gre-garious each subject is, as well as better insight into how close each actor is to each other actor with whom they conversed via phone.

Initialization was performed according to Section 3 , setting 1  X  10  X  3 , IN = OUT = 10, and IN = OUT = 1000. We ran the MCMC algorithm until we obtained 500,000 samples, using a burn-in of 300,000. Fig. 3 gives the trace plots for  X  IN ,  X  OUT , 2 this we can visually confirm that the MCMC chain has reached convergence.

The pseudo R 2 value was 0.819, implying a very good fit of the data. The posterior means of the coefficients were  X  IN and  X  OUT = 1.29, implying that, in the friendship network structure, popularity is more important than social activity.

Fig. 4 gives a plot of the posterior mean latent positions at times 1, 4, and 8. The actors X  shapes indicate the race (Asian, black, His-panic, middle eastern, or white), and the boxes or circles around or very religious). From these figures we can see that there is some association between race and social position, as well as between religion and social position. To verify this visual inspection, we per-formed a Mantel test between the posterior means of the latent positions and these two exogenous variables at each time point. More specifically, we compared the distance matrix whose entries are given by X it  X  X jt , where X it is the posterior mean of X distance matrix whose entries are 1 if actors i and j are not of the same race and 0 otherwise, as well as to the distance matrix whose Fig. 5 . Thus from this analysis we have empirical evidence that one X  X  social position is associated with race and religious dedication. 6.2. World trade data
World trade data, measuring annual exports/imports between countries in the years 1991 X 2000, was analyzed. The data were obtained through the Economic Web Institute at http://www.economicswebinstitute.org/worldtrade.htm , originally obtained through the IMF Direction of Trade (DOT) Yearbook. Through this site, annual import/export data is available from 1948 to 2000. We selected the most modern subset of this data which provided a reasonable number of countries that were present through all time points (e.g., not considering states that become independent in the midst of the selected time period) as a pedagogical example. The bilateral trade was measured in current millions of U.S. dollars; we analyzed the log of the trade amount, as is common in this context (see, e.g., Ward et al., 2013 ). To account for global inflation/deflation and any other non-relational economic effects, the data was rescaled such that the total quantity of annual world trade is constant. What we end up with then is a network consisting of 107 countries who were all involved in world trade through the 10 years, 1991 X 2000, whose edges are non-negative reals. For more information on the data see Gleditsch (2002) .
 Ward et al. (2013) developed a complex model for world trade data, combining a common economic model for world trade called the gravity model with aspects of the latent space model developed by Hoff (2005) . Their approach used one set of latent variables to model the incidence of trade and another set of latent variables to model the volume of trade. However, if we view the amount of trade between two countries as a positive-valued proxy indicating the strength of the relationship between the two countries X  economies, our approach may be more appropriate. Regardless, as the primary purpose of analyzing the world trade data described above is to serve as a pedagogical example of our more general methodology, we have maintained the more simple model framework of Sewell and Chen (2015b) with our extension for weighted network data, demonstrating the data augmentation scheme of Section 2.2 .
The hyperparameters for the priors of 2 , 2 , 2 , and r were formulated according to the description in Section 3 . We set 1  X  10  X  3 , 2 used, leaving a chain of length 75,000; from this we can visually confirm that the MCMC chain has reached convergence.

The pseudo R 2 value was 0.970, indicating a very good fit of the data. The estimates for  X  IN and  X  OUT were 2.33 and 2.10, respectively, implying that the amount of trade is determined more by the importing country than the exporting country, but only slightly so. If  X  IN had been much larger than  X  OUT then this would have suggested that the importer was in larger control of the trade relationship, and if  X  OUT was much larger than  X  IN we would say the same about the exporter. However, in our case we see that the two coefficients are close to each other, suggesting that the trade relationship is closely balanced.
 Fig. 7 gives plots of the posterior mean latent positions, broken up into three time periods: from 1991 to 1993, from 1994 to 1996, and from 1997 to 2000. Temporal direction is shown via arrows.
The size of the actor corresponds to its r i value. Each color repre-sents a geographical region, where green is Africa, yellow is Asia, dark red is Eurasia, blue is Europe, red is North America and the
Caribbean, sea green is Oceania, and brown is South America. It is apparent that the actors move within the latent space much less during each of these three periods than during the transition from 1993 to 1994 and from 1996 to 1997. These two major shrinkage events occurring both coincide with major events in world trade.
In 1993, the General Agreement on Tariffs and Trade was updated, which would later lead to the creation of the World Trade Organi-zation (WTO) (see http://www.wto.org ). Looking at Fig. 7 , we can see that there is already some shrinkage happening during the year 1993 which then continues going into 1994. Specifically we see that certain continents (Africa, Asia, and Europe) come together dur-ing this time. Europe is arguably the clearest case, and it turns out there is a good reason for this: the European Economic Area was established on January 1, 1994. Regarding the second shrinkage event in 1997, a publication from the WTO states that  X  X he volume of world merchandise exports grew by 9.5 per cent in 1997. X  This is seen visually in Fig. 7 . However, since the original data had been scaled to account for such growth, we conclude that the reason for this growth in world exports is not due to existing relationships getting stronger, but rather to the formation of many more trading relationships. 7. Discussion
Using the weights associated with edges makes better use of data than only incorporating the existence or non-existence of an edge. The weighted data is more informative and should lead to more accurate inference. It also eliminates the need to make an arbitrary user-defined cutoff for determining whether an edge should be one or zero.

We have described a general strategy for applying the latent space model for dynamic networks to data consisting of weighted edges. This can be applied either directly or indirectly through addi-tional latent variables. We have demonstrated the flexibility of the latent space models for dynamic networks by modeling cosponsor-ship count data and non-negative continuous world trade data.
Our latent space models can handle directed edges of many edge types, model both local and global structures, inherently account for transitivity, and yield a rich visualization of the data. An addi-tional note is that using the MH within Gibbs sampling allows edges missing at random or missing completely at random to be incorpo-rated into the model and estimated (see Sewell and Chen, 2015b , for details).
 Acknowledgement
We thank the referees for their valuable ideas and suggestions which have led to the improvement of this paper.
 Appendix A. Full conditional distributions
The full conditional distributions for 2 and 2 are respectively. ( 2 | X 1 )  X  IG(2 +  X  + np/ 2 , (1 +  X  ) 2 0 + 1 2 for  X  , 2 0 , 2 0 &gt; 0.

We let y ijt ( y ijt | X t , ) as given in (5) and (6) if we have count edges, or as given in (10) if we have non-negative real edges. Then the full conditional distribution for X it in these two cases is  X  N ( X it | 0 , 2 I p )  X  N ( X i ( t + 1) | X it , 2 I p  X  N ( X it | X i ( t  X  1) , 2 I p ) , if t = T.
The full conditional distribution for each of the model parame-ters follows the form ( | Y 1: T , X 1: T , \{ } )  X  where \ { } is the set of parameters excluding , and for count data  X  {  X  OUT ,  X  IN , r } and for non-negative real data  X  IN , 2 , r } .
 References
