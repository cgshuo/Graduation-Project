 In web search, information about times between user actions has been shown to be a good indicator of users X  satisfaction with the search results. Existing work uses the mean values of the observed times, or fits probability distributions to the observed times. This implies a context-independence assumption that the time elapsed between a pair of user actions does not depend on the context, in which the first action takes place. We validate this assumption us-ing logs of a commercial web search engine and discover that it does not always hold. For between 37 % to 80 % of query-result pairs, depending on the number of observations, the distributions of click dwell times have statistically significant differences in query sessions for which a given result (i) is the first item to be clicked and (ii) is not the first. To account for this context bias effect, we propose a context-aware time model (CATM). The CATM al-lows us (i) to predict times between user actions in contexts, in which these actions were not observed, and (ii) to compute context-independent estimates of the times by predicting them in predefined contexts. Our experimental results show that the CATM provides better means than existing methods to predict and interpret times between user actions.
 Time modeling; User behavior; Web search
Search engine logs provide a rich source of information about user browsing behavior in web search. Recently, many models have been proposed to explain and predict user clicks on search engine results [13]. While click events are the most widely logged form of user interaction, there are also other behavioral signals that need to be understood, interpreted and modeled, and that can be used for ranking or prediction purposes.

We focus on behavioral signals based on times between user ac-tions. The ability to accurately predict (i) click dwell time (i.e., time spent by a user on the landing page of a search result), and (ii) times from submission of a query to the first/last click on the results and to the next query submission (if none of the results will be clicked) allows us to optimize search engines for constructing re-sult pages and suggesting query reformulations that minimize time it takes users to satisfy their information needs.

Existing work shows that times elapsed between user actions provide means to measure user satisfaction at the result level [18, 30], session level [18, 20] and system level [10, 39]. To interpret times elapsed between user actions, existing work uses mean val-ues of the observed times [1 X 3, 8, 10, 20 X 22, 32, 33, 36, 39], or fits probability distributions to the observed times [30, 31]. This implies a context-independence assumption that the time elapsed between a pair of user actions does not depend on the context in which the first action takes place.

We validate this assumption by comparing the distributions of times associated with the same user action (i.e., submitting a given query or clicking on a given result presented for a given query), but preceded by different sequences of user interactions with the search engine. We find statistically significant differences between these distributions, which we explain by a context bias effect , not previously reported in the literature.

To account for the context bias effect, we propose a context-aware time model (CATM) that allows us to predict probability distributions of times between two user actions in a given con-text (which we represent by a sequence of previous user interac-tions with the search engine). The CATM can be used (i) to predict times between user actions in contexts, in which these user actions were not observed, and (ii) to compute context-independent esti-mates of the times by predicting them in predefined contexts. The context-dependent predictions can be used for personalized rank-ing and personalized query suggestion. The context-independent predictions can be used for predicting result relevance and in other tasks that use historical times between user actions.

We evaluate the CATM on four temporal prediction tasks (i.e., tasks in which we predict the time elapsed between two user ac-tions), and find that the CATM outperforms the standard time mod-eling approach that fits probability distributions to the times ob-served for the first user action. We test the CATM X  X  context-inde-pendent predictions of times between consecutive clicks on a rank-ing task (i.e., to rank a set of results by their relevance to a query), and find that the produced rankings result in better performance in terms of relevance than the rankings produced by the standard time modeling approaches.
 In summary, we make the following contributions in our work.
C1 We introduce the notion of context bias in times elapsed be-
C2 We propose a context-aware time model. Through the use of The rest of the paper is organized as follows. In  X 2 we specify the considered temporal prediction tasks. In  X 3 we propose the context-aware time model. In  X 4 we detail our experimental setup and in  X 5 we present the outcomes of our experiments. We discuss related work in  X 6 and conclude in  X 7.
We describe and motivate temporal prediction tasks that we con-sider in our work. In each task we aim to predict the time elapsed between a pair of user actions. The user actions can be of several types: submission of a query, click on a search result, click on an ad banner, scroll through search results, zoom in on a search result (in mobile search), etc. Here, we focus on user actions of the first two types: submission of a query (Q-action) and click on a search result (C-action), because these user actions occur in all search systems.
To define a temporal prediction task, we need to specify a set of action pairs between which we aim to predict times. When choos-ing these pairs, we follow two principles. 1. We select pairs of user actions for which the time elapsed 2. We select pairs of user actions for which the times elapsed We define four temporal prediction tasks: time-to-first-click , time-between-clicks , time-to-last-click , and time-from-abandoned-query . The pairs of user actions used in each task are shown in Figure 1. Below, we describe them in more detail and provide motivations Q C C Q Q Figure 1: Times between pairs of user actions used in the con-sidered temporal prediction tasks. for our focus on these specific tasks.
 Time-to-first-click is the time between a submission of a query and the first click on search engine results (undefined if there were no clicks on search results). Existing work shows that this time reflects the quality of result presentation: the less time it takes a user to find an attractive result, the better in terms of user experience the search engine result page (SERP) is [38]. The ability to predict time-to-first-click allows us to construct SERPs that are more intuitive to users, i.e., require less time/effort to find relevant results. Practi-cally speaking, the predicted time can be used in any application that uses the average time-to-first-click observed in search engine logs as its more precise alternative. Existing work uses the average time-to-first-click observed for a query-result pair as a feature to predict search task difficulty [3], search goal success [20, 21], ur-gent information needs (e.g., how to stem a severe bleeding) [35]; and the average time-to-first-click observed for a user to cluster users based on their SERP examination strategies [7].
 Time-between-clicks is the time between two consecutive clicks on search engine results (undefined for the last click on search re-sults). We use this time as a proxy for click dwell time (i.e., the time spent by a user on the landing page of a search engine re-sult), which has been shown to be a good indicator of click sat-isfaction [30]. The ability to predict click dwell time allows us to construct SERPs that yield more satisfied clicks, e.g., by using the predicted time-between-clicks as a feature for the search result ranker. Agichtein et al. [1, 2] use average click dwell times to im-prove result relevance. The Yahoo! Learning to Rank dataset [8] uses them as features for ranking. The predicted dwell times can also be utilized in most other applications that make use of the aver-age click dwell times observed in search engine logs, which include prediction of click satisfaction [30], result usefulness [32], search task difficulty [3, 33], search goal success [20, 21], struggling vs. exploring behavior [22, 36].
 Time-to-last-click is the time between a submission of a query and the last click on search engine results (undefined if there were no clicks on search results). Radlinski et al. [38] show that this time reflects the quality of search engine results: the less time it takes a user to find a relevant result, the better in terms of user experience the search engine results are. The ability to predict time-to-last-click allows us to suggest queries that require less time (effort) to satisfy user X  X  information needs. The predicted times can be used as features for query suggestion and for other applications such as prediction of search task difficulty and search goal success (playing a similar role as the average time-to-first-click).
 Time-from-abandoned-query is the time from a submission of an abandoned query (i.e., a query with no clicks) to the next query submission. Song et al. [41] show that this time reflects the quality of search engine results in query sessions with no clicks (thus, it is complementary to time-to-last-click, which is defined in query ses-sions with at least one click). A short time interval indicates user dissatisfaction (negative abandonment): the user could quickly see the problem with the presented results and it took them little time to reformulate the query. A large time interval indicates user sat-isfaction (positive abandonment): the user most likely could find the answer on the SERP, and it took them some time to come up with the next query. The ability to predict time-from-abandoned-query allows us to suggest queries with high chances of positive abandonment and to avoid suggesting queries that are likely to be quickly reformulated. Similar to time-to-last-click, the predicted time-from-abandoned-query can be used for query suggestion, pre-diction of task difficulty, search goal success, etc.
 There are several other times-between-user-actions that have previ-ously been considered in the literature, but that we do not seek to predict in this work for the reasons discussed below.
 Time-between-last-click-and-next-query is the time between the last click on search engine results presented for one query and the submission of the next query. Some previous work uses both this time and the time-between-clicks as a proxy for click dwell time (called server-side click dwell time ) [29, 30]. While both times approximate click dwell time, there are important differences be-tween them: time-between-clicks is a sum of the actual click dwell time and the time to choose the next result to click (which is typ-ically small and exhibits low variance), while time-between-last-click-and-next-query is a sum of the actual click dwell time and the time to formulate the next query (which is sometimes large, and exhibits high variance). Because of these differences in nature, we do not want to model time-between-clicks and time-between-last-click-and-next-query together (see principle 2). We do not create a temporal prediction task for time-between-last-click-and-next-query, as it is very similar to the time-between-clicks task, but the observed times are likely to be more noisy.
 Time-to-first-satisfied-click is the time between a submission of a query and the first click classified as satisfied. This time can be seen as a generalization of time-to-first-click and time-to-last-click: if we classify all clicks as satisfied, time-to-first-satisfied-click re-duces to time-to-first-click; if we classify only the last click as satis-fied, time-to-first-satisfied-click reduces to time-to-last-click. Most work defines satisfied clicks as clicks with dwell times larger than a predefined threshold (e.g., 30 seconds) [18]. Kim et al. [30] pro-pose a method to adjust this threshold individually for each search result. We do not create temporal prediction tasks for all possible definitions of satisfied clicks, because we believe that the temporal prediction tasks for time-to-first-click and time-to-last-click cap-ture the most important phenomena.
Now that we have specified the temporal prediction tasks, we describe our approach to modeling times between user actions. In  X 3.1 we formalize the problem and introduce the notation. In  X 3.2 we describe two frameworks for modeling times between user ac-tions. In  X 3.3 we describe the context-aware time model (CATM).
Let the sequence ( a 1 ,t 1 ) ,..., ( a n ,t n ) be a search history, which consists of user actions a 1 ,...,a n and their timestamps t We aim to design a time model for predicting times  X  i  X  j elapsed from the action a i to the action a j . We consider a proba-bilistic formulation of this problem, where the time  X  i  X  j dom variable with a probability density function f ( x ;  X  ) , where  X  denotes a set of parameters of the probability distribution.
To describe a probabilistic time model we need to specify a prob-ability density function f ( x ;  X  ) and an algorithm to compute its parameters  X  . Common choices for f ( x ;  X  ) are the exponential, gamma and Weibull probability density functions [30, 31]; see Ta-ble 1 for their parameterizations. Below, we discuss the frame-Table 1: Probability density functions and their parameters. works for computing the function parameters  X  .
We describe two frameworks for modeling times between user actions. The first framework, called basic time modeling frame-work , makes the context-independence assumption that time be-tween a pair of user actions depends solely on the first action ID, i.e., for submitting a query (Q-action), a unique identifier of the query string, and for clicking on a search result (C-action), an iden-tifier of the query-result pair. The second framework, called context-aware time modeling framework , does not make the context-inde-pendence assumption and assumes that time between a pair of user actions depends on the first action ID and on the context in which the first action takes place.
Time models operating within the basic time modeling frame-work make the context-independence assumption that time  X  depends solely on the first action ID. We formalize this as  X  f ( x ;  X  =  X ( a i )) , where  X  denotes a mapping from the space of actions A to the space of parameters of the probability density func-tion f ( x ;  X  ) . 1 We learn the mapping  X  by maximizing the likeli-hood of the observed times  X  i  X  j . The corresponding optimization problem can be formalized as follows: Here, we write N to denote the total number of observations, to denote the solution of this optimization problem, and we also change  X  indices to simplify the notation.

Without any constraints on the mapping b  X  , this optimization problem can be further decomposed into a set of per action ID max-imum likelihood estimation (MLE) problems (we apply the loga-rithm function, which is monotonic and therefore does not change the result of the arg max operator): where I a ( x ) denotes the indicator function, i.e., 1 if x = a and 0 otherwise. For the exponential distribution, the MLE of its pa-rameter (Table 1) is the inverse of the mean of the observed times. For the gamma and Weibull distributions, there is no closed form solution for the MLE problem. But it is possible to express one of their parameters as a function of the other one and  X  1 ,..., X  to reduce the MLE problem to minimization of a scalar function.
Existing work on modeling click dwell times [30, 31] operates within the basic time modeling framework and follows the described approach to estimate their parameters.
We argue that considering only the ID of the first action is not enough to accurately model the time  X  i  X  j , and propose, in addition to using the ID of a i , to use the context c i in which the action a takes place. We formalize this as  X  i  X  f ( x ;  X  =  X ( a i  X  denotes a mapping from the Cartesian product of the space of actions A and the space of contexts C to the parameters of the prob-ability density function f ( x ;  X  ) .

Similar to Eqs. 1, 2 and 3, the optimization problem in the context-aware time modeling framework can be formalized as follows: DATA = { ( a i ,c i , X  i ) | a i  X  X  ,c i  X  X  , X  i  X  [0;  X  ) } However, without any additional constraints on the mapping solution of this optimization problem will have very poor gener-alization due to the sparsity of action-context pairs ( a us illustrate this using a few simple definitions of the context c (i) number of previously clicked results, (ii) positions of previ-
Where no confusion can arise, we write a i to denote both the ac-tion performed by a user and the action ID. ously clicked results, (iii) positions of previously clicked results and times between previous clicks. For these definitions of the context c i , we list in Table 2 the number of unique action-context pairs ( a i ,c i ) for which we need to estimate parameters  X  . We see Table 2: Number of unique action-context pairs ( a i ,c i ferent definitions of the context c i ; N denotes the number of results on a SERP; T denotes the number of time intervals we consider.
 Context c i # of unique ( a i ,c i ) None O ( |A| ) Number of previously clicked results O ( |A| X  N ) Positions of previously clicked results O ( |A| X  N N )
Positions of previously clicked results and times between previous clicks O ( |A| X  ( N  X  T ) N ) that the number of b  X  parameters becomes too large to be able to estimate them using the amount of log data that can be generated by search engines.

The natural way to handle this problem is to constrain the family of mappings b  X  in Eq. 7. In  X 3.3, we describe the context-aware time model that operates within the proposed context-aware time modeling framework and provides a way to constrain the family of mappings b  X  .
In  X 3.2 we introduced the context-aware time modeling frame-work that models times between two user actions using the ID of the first action and the context in which it takes place. To construct a model that operates within this framework, we need to specify (i) the probability density function f ( x ;  X  ) , (ii) representation of the context c i , and (iii) constraints on the mapping b  X  (Eq. 7). We also need to describe the solution of the optimization problem (5) X  (7) for the chosen constraints. 3.3.1 Probability density function f ( x ;  X  )
We follow previous work [30, 31] and use the exponential, gamma and Weibull probability density functions.
We represent the context c i , in which the action a i takes place, by a sequence of user interactions with a search engine that preceded the action a i . We list the attributes that we use to describe the user interactions in Table 3.

The first two attributes from the general section distinguish be-tween Q-and C-actions. The third and fourth attributes inform us about the actual times observed between the previous actions and the average times between them. This information is useful to ac-count for the user X  X  reading speed, persistence, etc.

The first attribute from the Q-action section informs us about whether the query is the first in a search session or not. It is useful to distinguish between the cases (i) when a user has just started browsing, and (ii) when a user has been browsing for some time. In  X 5.1 we show that these cases may result in different probability distributions of times from submitting a query to the first click on the results, last click on the results and next query submission (if none of the results will be clicked). The second, third and fourth attributes from the Q-action section inform us about the query X  X  similarity with the previous query.

The attributes from the C-action section inform us about the po-sition of the clicked result. Existing work shows that the position of a result influences users X  trust in the result X  X  usefulness, which Table 3: Attributes we use to describe user interactions with a search engine.
 Is Q-action (0: no, 1: yes)
Is C-action (0: no, 1: yes) log (1 + observed time since previous action ) (0: undefined) log (1 + average time since previous action ) (0: undefined) Is new search session (0: no, 1: yes) Number of terms in issued query (0: undefined) BM25 ( issued query , previous query ) (0: undefined) BM25 ( previous query , issued query ) (0: undefined)
Is click on the 1 st position (0: no, 1: yes) . . . . . .

Is click on the 10 th position (0: no, 1: yes) affects their decisions whether to click or not [13]. We allow for the possibility that the result X  X  position might affect the time from clicking on the result to other actions.
Without any constraints on the mapping b  X  , the solution of the optimization problem (5) X (7) will have very poor generalization due to a very large number of action-context pairs (see  X 3.2.2). To deal with this problem we impose additional constraints on the fam-ily of mappings b  X  . In particular, we limit the family of possible mappings b  X ( a i ,c i ) to the ones that can be decomposed into the mappings b  X  A ( a i ) and b  X  C ( c i ) defined on the space of actions A and the space of contexts C , respectively. Not only does this re-duce the number of effective b  X  parameters from O ( |A|  X  |C| ) to O ( |A| + |C| ) , but it also separates action-specific and context-specific parameters. The latter allows us (i) to estimate times be-tween user actions in contexts in which these user action were not observed; and (ii) to estimate context-independent parameters of times between actions, which can be used for ranking and other prediction tasks that use historical times between user actions.
Now that we have described the constraints on the mapping at the functional level, we need to explain the mapping b mapping b  X  C , and the decomposition of the mapping b  X  into the mappings b  X  A and b  X  C in more detail.
 Mapping b  X  A . The mapping b  X  A is an equivalent of the mapping  X  in the basic time modeling framework. As in that setting, we treat it as a table of per action ID parameters, which we call context-independent parameters of the function f ( x ;  X  ) . Thus, the number of parameters of the mapping b  X  A is O ( |A| ) .
 Mapping b  X  C . The mapping b  X  C describes how to adjust context-independent parameters computed by the mapping b  X  A to account for the context in which the first action takes place. We want this mapping to have O ( |A| ) parameters so as not to increase the asymptotic number of parameters compared to time models that op-erate within the basic time modeling framework. Implementing the mapping b  X  C as a table of per context parameters will lead to a total of O ( |C| ) parameters, which is likely to dominate O ( |A| ) . Thus, we decide to implement the mapping b  X  C using a machine learn-ing algorithm. In particular, we implement it as a recurrent neural network (RNN) with long short-term memory (LSTM) cells [23]. We choose this architecture, because we represent the context c as a sequence of numerical attributes (see  X 3.3.2); and for tasks that involve processing sequential data, RNNs have demostrated strong performance on a wide range of tasks. See examples in lan-guage modeling [34], speech recognition [19] and machine transla-tion [42]. By using the RNN we reduce the number of b  X  parameters to O ( N  X  M ) , where N denotes the number of attributes we use to represent user interactions with the search ( 18 in our work) and M denotes the maximum number of units in the RNN layers ( 256 in our work). As N  X  M |A| , we satisfy the O ( |A| ) requirement. Decomposition of b  X  into b  X  A and b  X  C . A decomposition of into b  X  A and b  X  C describes how to compute the parameters  X  of the probility density function f ( x ;  X  ) from the action-specific parame-ters b  X  A ( a i ) and the context-specific parameters b  X  the action-specific parameters b  X  A ( a i ) to be context-independent estimates of parameters of the probability density function f ( x ;  X  ) for the action ID a i (see the discussion above), and the context-specific parameters b  X  C ( c i ) to be coefficients that inform us about how to adjust b  X  A ( a i ) to account for the context c i way to achieve it is (i) to have two context-specific parameters  X  and  X  for each action-specific parameter  X  i , and (ii) to apply a linear transformation g (  X  i ) =  X  X  i +  X  to compute the context-dependent parameters of the probability density function. We formalize it as: the vector b  X  C ( c i ) , which contains two times more elements than b  X 
A ( a i ) , and the symbol  X  denotes the element-wise product.
Now, we describe an approximate solution of the optimization problem (5) X (7) with the constraints on the mapping b  X  defined in  X 3.3.3. This problem does not have closed form solutions for the mappings b  X  A and b  X  C . Therefore, we propose an iterative algo-rithm to compute them (see Algorithm 1). We use b F ( b  X  A ( a i ) , b  X  C ( c i )) as a generalized version of Eq. 8.
The algorithm initializes the mapping b  X  A with the solution of the optimization problem (1) X (3) in the basic time modeling frame-work (line 1). Then it alternates between learning b  X  C while fixing b  X 
A (line 3) and learning b  X  A while fixing b  X  C (line 4) until con-vergence. In our experiments the process converges after 5  X  10 Algorithm 1 Learn b  X  A (  X  ) , b  X  C (  X  ) 1: b  X  A  X  arg max 2: while not b  X  A , b  X  C converged do 3: b  X  C  X  arg max 4: b  X  A  X  arg max 5: end while 6: return b  X  A , b  X  C iterations (i.e., passes through the loop). It is easy to show that the likelihood does not decrease between the iterations.

To find the best b  X  C while fixing b  X  A (Algorithm 1, line 3), we use the stochastic gradient descent (SGD) algorithm with mini-batches, because this is the most widely used algorithm for training neural networks [4]. The learning rates for each parameter are ad-justed according to the ADADELTA algorithm [44] (we use the de-fault values of = 10  X  6 and  X  = 0 . 95 ). We also use the gradient clipping technique [37] to alleviate the exploding gradient prob-lem [5] (we set the value of the threshold to 1 ).

To find the best b  X  A while fixing b  X  C (Algorithm 1, line 4), we decompose the optimization problem into a set of per action ID MLE problems (similar to Eq. 4): We solve these MLE problems using the limited memory BFGS with bound constraints (L-BFGS-B) algorithm [46]. We use bound constraints to ensure that the distribution parameters  X  take admis-sible values (e.g., the values of the parameters of the exponential, gamma and Weibull distributions need to be positive).
 To summarize, we predict a probability distribution over the time elapsed between a pair of user actions. Unlike existing methods, which rely solely on the first action ID, CATM also considers the context in which the first action takes place. CATM represents this context as a sequence of user interactions with a search en-gine that precede the first action, and employs a recurrent neural network that learns how to adjust the first action ID parameters us-ing this context representation. CATM can be used (i) to predict the time elapsed between a pair of user actions in a context, in which these actions have not been previously observed, and (ii) to obtain a context-independent estimate of the time between two user actions by predicting it in a predefined context.
In this section we describe our experimental setup. We start with the research questions that we seek to answer ( X 4.1). Then we de-scribe the datasets that we use ( X 4.2) and the evaluation method-ology that we follow ( X 4.3). Finally, we describe the experiments that we conduct to answer our research questions ( X 4.4).
We address the following research questions: ( RQ1) Can we observe the context bias effect? More precisely, can we observe a difference in time probability distributions for different contexts in which the first action takes place? ( RQ2) Do the context-aware time models, which besides the first action ID make use of its con-text, provide better means to explain times between user actions than the basic time models, which make the context-independence assumption and rely solely on the first action ID? ( RQ3) Do the context-independent predictions of the CATMs, trained on the time-between-clicks task, provide better means to rank search results than existing methods based on the observed times between clicks?
To construct datasets for the temporal prediction tasks described in  X 2, we collected three months of log data from a commercial web search engine. We use the first two months of the log data to train time models and the last month to evaluate their predic-tion performance. In each dataset, we filter out times associated with actions IDs that occur less than 25 times in the training set. For time-to-first-click and time-from-abandoned-query, we also fil-ter out times larger than 1 minute; for time-to-last-click and time-between-clicks, we filter out times larger than 5 minutes (this com-plies with actual times reported in [38]). The number of observa-tions in the resulted datasets are shown in Table 4. Table 4: Number of observations in the datasets for each tem-poral prediction task.

To compare the performance of ranking models based on time-between-clicks, we also collected relevance labels for 50 , 137 query-result pairs that occur in our time-between-clicks dataset. The rel-evance labels were assigned by trained judges on a scale from 0 to 4, with 0 = bad, 1 = fair, 2 = good, 3 = excellent, 4 = perfect.
We evaluate the performance of time models using the log-like-lihood and the root mean squared error (RMSE) metrics. The log-likelihood metric shows how well a time model explains the observed times between user actions. We report the logarithm of the likelihood function, averaged over all observations in the test set. Larger values of the metric indicate better performance. The RMSE metric shows the average difference between the expected values of the time probability distributions predicted by a model and the observed times-between-actions. Lower values of the met-ric indicate better performance. We also evaluate the time models for predicting time-between-clicks on a ranking task (i.e., to rank a set of results by their relevance to a query). We use the NDCG metric [26], and report its scores at truncation levels 1, 3, 5 and 10. Larger values of the metric indicate better performance.

We perform significance testing in terms of all metrics using a paired t-test; the differences are considered statistically significant for p-values lower than 0.05. Experiment 1. To answer RQ1, for each action ID we split the observed times in two context groups , which correspond to differ-ent sets of previous user interactions, and run the two-sample two-sided Kolmogorov-Smirnov (KS) test [14] to determine whether the observed times were drawn from the same distribution. The null hypothesis states that the observed times were drawn from the same distribution, which means that there is no context bias effect. Rejecting it, at least for some action IDs, will prove the existence of the context bias effect for these action IDs. Not being able to reject it might happen for several reasons. First, the context bias effect may not appear for certain types of queries (e.g., navigational queries) and results (e.g., irrelevant results). Second, we may not have enough data to reject the null hypothesis. Third, we may not have chosen the best context groups.

When choosing a rule to split times-between-actions in two con-text groups based on the context, we give preference to easily inter-pretable and easily reproducible ones. For the time-to-first-click, time-to-last-click and time-from-abandoned-query, we split the ob-served times based on whether the query is the first in the search task or not. We say that a query is the first in the search task if it does not share terms with the previous query in the search session, or if it is the first query in the search session. For the time-between-clicks, we split the observed times based on whether the clicked result is the first item to be clicked on SERP or not.

We use the KS test, because the more popular t-test is not ap-plicable in our setting: it requires the tested samples to be drawn from a normal distribution, which is not the case for time observa-tions. An alternative to the KS test could be the Mann-Whitney U test [14], but following previous work [31] we use the KS test.
Without a sufficient number of observations in both context groups, the KS test would be unable to detect a difference between samples even if one exists. For this reason, we apply the KS test only to actions IDs, for which there are, at least, N observations in both context groups. Using a large value of N improves test sensitivity (increases the number of action IDs for which the null hypothesis can be rejected), but reduces the number of action IDs that we use in our experiment. Thus, we run our experiment for different val-ues of N . In particular, we use N in the range [25 , 200] . Table 5 shows the number of action IDs with, at least, N observations in both context groups for N = { 25 , 50 , 100 , 200 } .
 Table 5: Number of action IDs with at least N = { 25 , 50 , 100 , 200 } observations in each context group for dif-ferent times-between-actions.
 Time between actions 25 50 100 200 Time-to-first-click 60 , 284 24 , 368 7894 1545 Time-between-clicks 18 , 954 8335 3289 1288 Time-to-last-click 59 , 367 23 , 956 7756 1500 Time-from-abandoned-query 22 , 190 9180 2980 569 Experiment 2. To answer RQ2, we compare the performance in terms of log-likelihood and RMSE of the context-aware time mod-els against the basic time models on the four temporal prediction tasks described in  X 2.
 Experiment 3. To answer RQ3, we compare the performance in terms of NDCG of rankings models based on (i) the average values of the observed times between clicks, (ii) the expected values of the probability distributions fitted to the observed times between clicks, and (iii) the expected values of the context-independent probability distributions predicted by the CATMs trained on the time-between-clicks task. To predict the context-independent probability distri-butions we use the following fixed context: (i) the query is the first in the search session; (ii) the result is presented on the top position and is the first item to be clicked; (iii) the time elapsed between the query submission and the click on the result is 4 seconds (the median of the times-to-first-click observed in our dataset).
In this section we present the results of the experiments described in  X 4.4 and provide answers to the research questions stated in  X 4.1.
The results of Experiment 1 are given in Figure 2. The figure shows the percentage of action IDs in each temporal prediction task, for which the Kolmogorov-Smirnov test rejected the null hy-pothesis ( p &lt; 0 . 05 ) in favor of the alternative hypothesis, which states that the times-between-actions in the chosen context groups were drawn from different probability distributions. Equivalently, the alternative hypothesis states that the context bias effect exists. RQ1. Figure 2 shows that for each time-between-actions there is more than 5% action IDs, for which the null hypothesis is rejected. This proves the existence of the context bias effect. Indeed, if times-between-actions did not depend on previous user interactions (null hypothesis was true), the number of action IDs for which the null hypothesis would be rejected had to be 5 % (significance level) of the total number of the tested action IDs. Figure 2: Percentage of actions IDs with observed context bias effect vs. minimum number of observations in context groups.
The percentage of action IDs, for which the context bias effect is detected, increases with the minimum number of observations in each context group (Figure 2). This suggests that the actual num-ber of action IDs for which the context bias effect appears, is even larger than the number of action IDs for which we manage to detect the effect. And with more interaction data, it should be possible to detect the effect in a larger number of times-between-actions.
From the above results we conclude that there is a tangible con-text bias effect, which results in statistically significant differences in time-between-actions probability distributions for different con-texts (in our case, for different sets of previous user interactions).
The results of Experiment 2 are given in Table 6. The table shows the performance of the basic time models and the context-aware time models in terms of log-likelihood and RMSE on four temporal prediction tasks: time-to-first-click, time-between-clicks, time-to-last-click and time-from-abandoned-query ( X 2).
 RQ2. Table 6 shows that the context-aware time models outper-form the basic time models in terms of both the log-likelihood and RMSE metrics on all temporal prediction tasks. The improvements for each task and each distribution are statistically significant with p &lt; 0 . 001 . The improvements in terms of log-likelihood are com-parable with the differences between the basic time models using different probability density functions, and in most cases exceed them. The improvements in terms of RMSE vary, depending on the task, between 0 . 98  X  5 . 32 %.

To further understand the performance difference between the basic time models and the context-aware time models, we plot their performance vs. the actual times-between-actions observed in the datasets. Figures 3 and 4 show the performance on the time-between-Figure 3: Time model performance in terms of the log-likelihood metric on the time-between-clicks task vs. actual times observed in the dataset.
 Table 6: Performance of the basic time models and the context-aware time models on four temporal prediction tasks. Larger values of the average log-likelihood metric and lower values of the root mean squared error (RMSE) metric indicate better performance. Improvements of the context-aware time models over the basic time models using the same probability density functions (exponential, gamma, Weibull) are statistically signif-icant ( p &lt; 0 . 001 ) in terms of both metrics.
 clicks task. We start with Figure 3, which shows the performance in terms of the log-likelihood metric. Here, similar to the differences between the basic time models using different probability density functions, we observe major improvements of the context-aware time models over the basic time models for small times. In Fig-ure 4, which shows the performance in terms of the RMSE metric, we also observe major improvements for small times.

A reader might notice a drop in performance of the context-aware time models compared to the basic time models between 17 and 99 seconds in Figure 4. This is better seen in Figure 5, which plots the differences between the context-aware time models and the basic time models shown in Figure 4. Here, we see that the context-aware time models perform better for times lower than 17 seconds and larger than 99 seconds, and perform worse for times in the range of 17  X  99 seconds. This can be explained as follows. The average time-between-clicks in our dataset is 53 . 44 seconds. A naive time model that always predicts time-between-clicks to be 53 . 44 seconds, would have very low RMSE around 53 . 44 seconds and high RMSE for smaller and larger times (the overall RMSE Figure 4: Time model performance in terms of the RMSE met-ric on the time-between-clicks task vs. actual times observed in the dataset. Figure 5: Performance difference in terms of the RMSE met-ric between the context-aware time models and the basic time models on the time-between-clicks task vs. actual times ob-served in the dataset. performance of this naive approach would be low). The basic time models predict time-between-clicks across the whole time range including small and large times, and have better overall RMSE per-formance. However, this is achieved at the cost of having higher RMSE around the average time-between-clicks (i.e., 53 . 44 sec-onds) compared to that of the naive time model. The proposed context-aware time models, on average, predict time-between-clicks better than the basic time models (and especially so for smaller and larger times, see Figure 5). This is again achieved at the cost of having higher RMSE around the average time-between-clicks (i.e., 53 . 44 seconds). In fact, smaller times-between-clicks usually cor-respond to dissatisfied clicks, and larger times-between-clicks cor-respond to satisfied clicks [18]. Thus, in order to improve user satisfaction with the search, it is more important to predict small and large times-between-clicks rather than to distingush between times close to the average time-between-clicks.

From the above results we conclude that the context-aware time models, which besides the first action ID make use of its context, provide better means to explain times-between-actions that the ba-sic time models, which rely solely on the first action ID.
Table 7 shows the outcomes of Experiment 3, a comparison of the performance of ranking models based on times-between-clicks. RQ3. Table 7 shows that the CATM-based ranking models out-perform the ranking models based on the basic time models and the ranking model that scores search results by the average val-ues of the observed times between clicks. All improvements are Table 7: Performance of ranking models based on the time be-tween clicks. Larger values of the NDCG metric correspond to better rankings. The improvements of the context-aware time models over the existing methods are statistically signif-icant ( p &lt; 0 . 05 ).
 Time model Distribution @1 @3 @5 @10 Average n/a 0 . 651 0 . 693 0 . 728 0 . 812 Basic gamma 0 . 646 0 . 693 0 . 728 0 . 812 Context-aware gamma 0 . 675 0 . 715 0 . 748 0 . 822 statistically significant with p &lt; 0 . 05 . Thus, we conclude that the context-independent predictions of the CATMs trained on the time-between-clicks task provide better means to rank search en-gine results than existing methods.
We discuss two types of related work: behavioral signals used to improve and evaluate web search effectiveness ( X 6.1); and models of user behavior used to interpret these signals ( X 6.2).
Modern search engines log a large number of user behavioral signals to improve and evaluate their effectiveness. We classify them in two groups: behavioral signals based on user actions and behavioral signals based on times between user actions.
 Behavioral signals based on user actions. User clicks provide an important source of implicit user feedback [1 X 3, 8 X 10, 20, 27, 38, 39]. They have been used (i) to infer user preferences over search results, i.e., target values for learning a ranking function [9, 27], (ii) to design features for learning a ranking function [1, 2, 8] and for other applications [3, 20], and (iii) to compare ranking functions [10, 38, 39]. Some work distinguishes different types of clicks: first click [8, 39], last click [8], long dwell time click [8], satisfied click [39] and only click [8]. Next to clicks, some recent work considers mouse cursor movements on SERPs [16, 24, 25]. Behavioral signals based on times between user actions. Click dwell time, i.e., time spent by a user on the landing page of a search result, provides valuable information about user satisfac-tion with the clicked result [30]. Existing work uses it as a fea-ture for ranking [1, 2, 8] and in many tasks related to user satisfac-tion [3, 20 X 22, 30, 32, 33, 36]. Times from a submission of a query to (i) the first click [7, 10, 20, 39], (ii) the first satisfied click [39], and (iii) the last click [10] are used as features to predict user sat-isfaction with the clicked result [20], compare two versions of a search engine [10, 39] and to cluster users based on their SERP ex-amination strategies [7]. Song et al. [41] use the time since a user issued an abandoned query (i.e., a query for which there were no interactions with the search results) to the next query submission for classifying the abandoned query into positively abandoned and negatively abandoned. Dupret and Lalmas [17] use times between search engine visits to compare two versions of a search engine.
Now that we have described the behavioral signals, we focus on their interpretations. To interpret a signal, we need to have a model that explains it. We start with models for explaining behavioral sig-nals based on user actions and then discuss models for explaining behavioral signals based on times between user actions.
 Modeling user actions. The simplest way to interpret click data is to compute click-through rates (CTRs), i.e., the ratios of the total number of clicks and the total number of impressions observed for a group of search engine results. Unfortunately, CTRs suffer from the so-called position bias effect , i.e., results presented at higher po-sitions receive more clicks than results of similar quality presented at lower positions [15, 27, 28], which leads to suboptimal perfor-mance when using CTRs for ranking. To account for position bias, a large number of click models have been proposed [13].

Click models make a few assumptions about user interactions with search results, which ultimately allow them to obtain per query-result scores that show better correlation with relevance than CTRs. Among the most common assumptions are (i) the linear traversal assumption that a user scans search results from top to bottom [15]; and (ii) the examination hypothesis that a user clicks on a search re-sult if, and only if, she examined the search result and is attracted by it [15]. Recently, it has been shown that patterns of user click behaviour can be learned automatically from interaction data [6]. In addition to position bias, recent work examines other types of bias including (i) vertical bias driven by visually salient vertical re-sults (e.g., image results, video results, news results) [11, 12, 43]; (ii) query bias , which occurs if a query does not match the user X  X  information need [45], (iii) duplicate bias , which occurs if a re-sult has been examined earlier in the search task [45]; and (iv) bias driven by individual differences between users [40].
 The notion of context bias, introduced in our work for times be-tween user actions, generalizes the idea of bias in user actions (in particular, clicks and mouse hovers), and the proposed context-aware time model should be able to account for them with appro-priate representations of the context.
 Modeling times between user actions. The simplest way to in-terpret times between user actions is to compute their mean values. The average click dwell time is frequently used as a feature for ranking [1, 2, 8] and other applications [3, 20 X 22, 32, 33, 36]. The average time between a submission of a query to the first click is used both as a feature [20] and as an online metric for compar-ing two versions of a search engine [10, 39]. The average time between a submission of a query and (i) first click classified as sat-isfied, (ii) last click are also used as online metrics for comparing two versions of a search engine [10, 39].

A more sophisticated way to interpret times between user actions is to fit a probability distribution [30, 31]. Liu et al. [31] find that the Weibull distribution provides better goodness-of-fit to click dwell times than the exponential distribution. The authors provide an in-teresting interpretation for the shape parameter of the fitted Weibull distribution, which justifies the task of modeling the full probabil-ity distribution rather than just the mean of the distribution. Our work differs from their work in that we do not make the context-independence assumption that the observed times were drawn from the same probability distribution; we predict the probability distri-butions separately for each click using its context, and the infor-mation about click dwell times observed for the given query-result pair in other contexts. Liu et al. [31] also show that it is possi-ble to predict parameters of the Weibull distribution for a given result using the information about the result X  X  landing page, such as HTML tags, frequent words that occur on the page and times to download/render/parse the page. Our approach differs from their method in that we use contextual, i.e., result-independent, informa-tion; thus, our work is complementary to that of [31].

Kim et al. [30] fit gamma distributions to click dwell times, ob-served in a predefined click segment and labeled as satisfied or dis-satisfied. The authors use the fitted distributions to classify new clicks into satisfied and dissatisfied. In particular, they compute the following features: (i) the differences between the fitted pa-rameters of the satisfied and dissatisfied click dwell time distribu-tions for the clicked result X  X  segment, (ii) their expected values and the difference between them, (iii) the absolute differences between the observed click dwell time and the expected values of the sat-isfied and dissatisfied distributions, (iv) the log-likelihoods of the observed click dwell time according to the satisfied and dissatisfied distributions and the difference between them. The large number of features used in their work shows the advantage of modeling the full probability distribution over modeling just the mean. Similar features, computed from the probability distributions predicted in our work can potentially be used in a broad range of applications. Our work is the first to systematically address the problem of mod-eling times between user actions. We introduce the notion of con-text bias effect and propose a context-aware time model that pre-dicts times elapsed between user actions using both the ID of the first action (which is what existing methods rely on) and the context in which it takes place (our novelty).
We introduced the notion of context bias effect in times between user actions (i.e., a difference in probability distributions of times associated with the same user action, but observed in different con-texts); and proposed a context-aware time model (CATM) that al-lows us to estimate parameters of a probability distribution of the time elapsed between user actions in a given context. CATM X  X  abil-ity to account for user context can be used to predict times between user actions in a context in which these actions have not previ-ously been observed, and to obtain context-independent estimates of times between actions by predicting them in predefined contexts.
We showed that, for 37 % X  80 % of query-result pairs ( q,r ) , de-pending on the number of observations, the distributions of times elapsed between a click on the result r and the next click on the same SERP differed in sessions, in which the result r was the first item to be clicked, and in sessions, in which there were clicks on other results before the result r was clicked. Similarly, we showed that previous user interactions in a search task influence distribu-tions of times between (i) submission of a query and the first click on a SERP, (ii) submission of a query and the last click on a SERP, and (iii) submission of an abandoned query (i.e., a query with no clicks on a SERP) and the next query submission.

We evaluated the context-aware time model on four temporal prediction tasks and a ranking task. The results on the temporal prediction tasks show that the proposed context-aware time model, which makes use of both the ID of the first action and the con-text in which it takes place, provides better means to explain times between user actions than existing methods, which rely solely on the first action ID. The results on the ranking task show that the context-independent estimates of times between consecutive clicks, obtained with the context-aware time model, allow us to construct rankings that result in better performance in terms of relevance than the rankings produced by the mean values of the observed times be-tween consecutive clicks.

As to future work, we plan to consider other representations of the context. Besides using context-independent estimates of times between consecutive clicks as features for ranking, the predictions of context-aware time models can be used in a range of other appli-cations that use the average or predicted times between user actions. These applications include prediction of click satisfaction [30], re-sult usefulness [32], search task difficulty [3, 33], search goal suc-cess [20, 21], urgent information needs [35], struggling vs. explor-ing behavior [22, 36], positive vs. negative abandonment [41] and clustering users based on their SERP examination strategies [7].
