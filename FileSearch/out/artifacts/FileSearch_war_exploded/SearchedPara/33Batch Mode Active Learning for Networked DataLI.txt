 LIXIN SHI, YUHANG ZHAO, and JIE TANG, Tsinghua University Machine learning algorithms often suffer from insufficiently labeled training data. Ac-tive learning aims to, not only, as usual, construct an accurate classifier, but also min-imize the number of labeled instances by actively selecting a few number of instances to query the user. Traditionally, this problem is addressed in a single mode, that is, the active learning algorithm queries the user k times, and each time queries one instance for its label. Following this thread, considerable research has been conducted on how to select the best example to query in each time [Beygelzimer et al. 2009; Harpale and Yang 2008; Rajan et al. 2010].

Recently, there has been a new direction of machine learning field, that is how to learn an accurate model to classify the networked data, for example, the linked Web pages and the friendship network. A number of models have been proposed, such as Conditional Random Fields [Lafferty 2001], Continuous Bayesian network [Nodelman et al. 2003], Factor Graph models [Kschischang et al. 2001; Tan et al. 2010], Collective Learning [Jensen et al. 2004], and Semisupervised Learning over graphs [Zhu 2005]. A few models also try to combine the link-and the node-specific content information in a unified framework for active learning [Bilgic and Getoor 2010; Macskassy 2009; Rattigan et al. 2007; Zhu et al. 2003b]. However, two important issues have been largely ignored in existing work. First, almost all algorithms for learning/classifying the networked data are computationally intensive, due to iterative selection and retraining the model. Suppose a machine needs to query the user k times, when the user inputs a label for the queried instance, she/he may have to wait for a long time for the next query, which is obviously undesirable. Second, most methods only consider the single mode. It is inefficient to retrain the model after querying only one instance and also there might exist information redundancy between the selected instances in different iterations. In this work, we aim to answer the question: how to actively select a set of instances from the networked data and query the users in a batch mode?
Motivating Example. We refer to this problem as the Batch Mode active learning (BMAL) problem for networked data. A simple baseline method to address this prob-lem is to design a metric to measure the informativeness of each candidate instance and then select instances with the highest informative scores. However, this method cannot guarantee an optimal solution, because: (1) simply accumulating candidate in-stances with the highest informativeness score does not necessarily mean the instance set also has the highest informativeness score; (2) such a method cannot take advan-tage of the link information.

In this article, we try to conduct a systematic investigation of the problem of batch mode active learning for the networked data. Figure 1 demonstrates our problem. Suppose we are given a dataset with only one labeled sample (say, with positive label), and the samples are connected in a two-dimension space. We try to select two samples to query the user in a batch mode. If we only consider the content information, then we would tend to select the two center nodes (top-right figure); while if we only consider the link information, we would select two samples with the most links (middle-left fig-ure). By combining the link and content information, our BMAL method suggests two different samples (middle-right figure). The bottom two figures show how a machine learning algorithm updates the classification model when the user provides labels to the queried samples (suppose one positive and one negative).

Challenges and Contributions. Thus the problem becomes how to quantify the informa-tiveness of each candidate instance by combining the content and link information, and how to actively select a number of instances with the highest informativeness and as well the minimum redundancy among them. Comparing with existing work, there are several unique challenges for the batch mode active learning problem.  X  First, as the problem of finding the most informative instances is NP-hard, how to formulate the problem in a unified framework is a challenging problem.  X  Second, a central problem is how to design appropriate criteria to quantitatively measure the informativeness of the data.  X  Third, the active learning algorithm should be efficient, in particular considering the increasing scale of the networked data on the Web.
 To this end, we formally define the problem and propose a general batch mode active learning framework. Specifically, we propose three criteria to respectively capture the maximum uncertainty, maximum impact, and minimum redundancy (which will be ex-plained in Section 2.2). Existing batch mode active learning frameworks are shown to satisfy only one or two of them. We present an objective function based on the criteria and prove that our method respects all three of them both intuitively and theoretically. An efficient algorithm is designed to solve the objective function, and theoretical anal-ysis for the approximation rate of the algorithm is given. We conduct experiments on both synthetic datasets and real-world datasets to validate the effectiveness and effi-ciency of our approach. Experimental results show that the proposed approach clearly outperforms (up to 6%) several baseline methods of single mode active learning and batch mode active learning for the networked data.

Organization. The rest of this article is organized as follows: Section 2 defines the batch mode active learning problem, determines the three criteria, and introduces a basic framework of random walk. Section 3 discusses our model in details, Section 4 presents the active selection algorithm as well as parallelization to it, and Section 5 presents the experiment results. Finally Section 6 discusses some related work and Section 7 concludes our work.
 The input of the BMAL (Batch Mode Active Learning) problem is defined as an (un)directed network (graph) G =( V , E ), where vertices correspond to the data instances and the edge implies relationship between data instances, for example, friendship or the citation relationship. The set of data instances V is comprised of n un-where l n under most circumstances, x i (1  X  i  X  n + l ) is the observed (feature) vector, and y i  X  X  0 , 1 } is the classification label of the i -th data instance.
Following this, we can define the problem of batch model active learning for the networked data as follows.

Problem 1 BMAL ( Batch Mode Active Learning ). Given such a system ( U , L , G )and an integer k , how to select a set of k ( k n ) instances S  X  U to query their classification labels, so that we can maximally improve the quality of the learned classification model for the networked data based on the queried data instances?
To solve this problem, a general objective function is defined for active selection of the data instances from the network.
 Thus, the BMAL problem is equivalent to the set function optimization problem. Now, the task is to well define the function Q ( S ) and to design an efficient algorithm to maximize Q ( S ). Please note that if there is no link information in the network, the problem degrades to a traditional data classification problem. We first define three criteria to measure the informativeness of selected candidate instances, as a guide of designing Q ( S ).  X  Maximum Uncertainty . We are always interested in choosing instances of uncer-tainty to query the user. One intuitive method for the binary classification (positive versus negative) is to choose instances with posterior probabilities of being positive close to 0.5.  X  Maximum Impact . Selected instances should have the maximum impact on other unknown instances. We do not expect to select instances which are isolated in the instance space, for example, outliers. The impact can be considered from two as-pects: the content similarity and the structure similarity among instances.  X  Minimum Redundancy . The selected instances should be diversely distributed in the instance space. In other words, we need to minimize the information overlap between the selected instances.
 Recently, a few methods have been proposed which also try to actively find a batch of instances. To show that existing batch mode active learning methods are not suitable in our BMAL framework, we first evaluate them under these criteria before proposing our method.
 The first kind of batch mode active learning method is based on SVM. Tong and Chang [2001] suggest to choose instances that are close to the decision boundary of the SVM classifier. However, the method may result in undesirable redundancy in the selected instances. This problem is pointed out in Brinker [2003] and a diversity is added in Hoi et al. [2008] and Brinker [2003]. Another kind of batch mode active learning method employs the Fisher information matrix to measure informativeness [Hoi et al. 2006a; Steven et al. 2009]. It maximizes uncertainty and implicitly mini-mizes redundancy, as stated in Hoi et al. [2006b]. However, both of them ignore the impact of the selected instances on other unlabeled instances in the network, thus the selected instances may have no relationship (links) with the other ones. As a result, the user X  X  labeling efforts on these instances cannot be optimally leveraged to infer labels of the other unlabeled instances. There are also some other batch mode active methods, such as Joshi et al. [2010] and Xu et al. [2009]. Different from existing work, we define an objective function strictly based on these three criteria, which is demon-strated essential by both theoretical analysis and empirical evaluation. We introduce a framework of random walk [Zhu et al. 2003a] which is designed for semisupervised learning, that is, learning a classification model with a few labeled data L and a large number of unlabeled data U . Specifically, in this framework, a ( n + l )  X  ( n + l ) pair-wise similarity matrix W is introduced, where each element w ij measures the similarity between feature vector x i and x j . The similarity can be defined in different ways, for example, the Radial Basis Function (RBF). Suppose the expectation of y i ( i  X  U )is f i , that is, the probability that y i = 1 under Bernoulli distribution. There is a nice interpretation of f i based on the random walk theory. We first normalize the weight matrix W to be  X  W , where and  X  w ij =0 , i = j . A random walk system is then defined over all the data instances (points).  X  The transition probability from an unlabeled data point i ( i  X  U ) to any data point  X  All the labeled data points are the absorbing nodes: it transforms to itself with probability 1.
 It can be seen from the preceding definition that all transformations in the system will eventually go into a self-loop at a labeled point. f i is the probability that a particle, starting from unlabeled data point i , will eventually get looped in a labeled point with label 1. A theoretical verification is given in Zhu et al. [2003a]. Here we employ this framework to calculate f i : the transition matrix defined by the random walk system is therefore where O is the zero matrix, I is the identity matrix. And the matrix [ AB ] is the first n lines of  X  W , which correspond to the unlabeled data instances. Specifically, A is the transition matrix between points in unlabeled datasets, and B is the transition matrix from unlabeled data instances to labeled ones.

Correspondingly, we define f u and f l as the expectation vector of all unlabeled data points and labeled data points, that is, Then we have The solution can be given by
This framework will work as a underlying model of the BMAL method. As a sum-mary, Table I lists the notations used throughout this article. Our basic idea is to define an objective function Q ( S ) to combine the three criteria (refer to Section 2.2) together. To this end, we define two functions, H ( S )and C ( S ), respectively represent the maximum uncertainty and the maximum impact. We will show later that this combination will naturally satisfy the minimum redundancy cri-terion. The objective function is defined as a linear combination of the two functions, that is, where  X  is a parameter to balance the importance of two functions.

Maximum Uncertainty. We use entropy to measure the uncertainty of selected in-stances. Joint entropy would be difficult to compute, thus we use the summation of entropies over single data instances. The maximum uncertainty part is defined as the H ( S ) function in Q ( S ). We have where H ( i ) is the entropy of data instance i and f i is the expectation of instance i  X  X  label (refer to Table I).

Maximum Impact. The criterion is to measure how a selected instance can influence the other unknown instances. More accurately, it estimates to which extent labeling one instance can help classify the other unknown instances. This measurement of maximum impact comes from the classical nearest neighborhood classifier. The classi-fier classifies data instance x i into the same class with labeled data instance x j which has the highest impact (distance) on x i .

From the view of the nearest neighbor classifier, the classification result is more guaranteed if the impact is higher. That gives a direct motivation on the maximum impact measurement: to maximize the impact on a single unlabeled data instance x i , we can choose the data instances with the maximum impact over x i from the candi-dates. So we can have a weighted function of summations over all these maximum values to measure the impact where s i serves as a weight factor when counting the impact over instances in the unlabeled dataset; w ij indicates the similarity between instance i and j . There may be better choices other than choosing s i = 1 for all unlabeled data instances, for example, using entropy as the weight. Specifically,
The point is that the use of entropy information here does not overlap with the entropy in H ( S ). This is because different examples are checked by C ( S )and H ( S )in terms of entropy. To achieve a higher flexibility, we introduce a parameter  X  to further balance the importance of the two terms.

Minimum Redundancy. In Eq. (3), we do not have a term to explicitly demonstrate the redundancy over the selected set. In this section, we will prove that the minimum redundancy criterion has already been implicitly satisfied in the definition of Q ( S ). To start with, we give an intuitive impression about why maximizing Q ( S ) will also minimize the redundancy. Given a data instance i  X  U  X  S , let us define the dominant instance dp ( i )as
We will show that maximizing Q ( S ) will cause the dominant instances to get di-versely distributed. If two dominant instances in S are very close to each other, it is likely that they have a similar impact on the other unknown instances, thus removing one of them from S will not cause C ( S ) to decrease a lot. In other words, if we already have one of them, say, vertex i , in the selected set S , we would avoid choosing another similar vertex j in the future, because the increase on Q ( S ) is limited. Redundancy of the selected set can be measured by the following function. Theorem 3.1 explores the relationship between maximizing C ( S ) and minimizing R ( S ).

T HEOREM 3.1. If w is under the definition of RBF function, and S satisfies that  X  j  X  S ,  X  i  X  U  X  S , j = dp ( i ) we have the following estimation of R ( S ) . (1) R ( S )  X  (2) R ( S )  X 
Note that the requirement of S in the theorem is satisfied if we use the greedy algorithm suggested in Section 4. The proof of Theorem 3.1 is given in the Ap-pendix. From Theorem 3.1, we can see that R ( S ) is tightly bounded by terms maximizing i  X  U  X  S w i , dp ( i ) , it approximately minimizes these two terms (because than k ).

In summary, the definition of Q ( S ) in Eq. (3) serves as a measurement of maximum entropy and maximum impact, and it implies minimum redundancy both intuitively and theoretically. Further in Section 5.1, we will use a synthetic dataset to empirically validate the necessity of these three criteria. One of the challenges in BMAL is how to combine the link information into our ap-proach. In this section, we introduce how to address this problem by integrating link information into a similarity matrix .

Similarity Matrix W. Similarities between data instances form a ( n + l )  X  ( n + l ) similarity matrix W . In our problem, the similarity measurement should satisfy the following properties (which are common and easy to satisfy).  X  Larger value of w ij indicates higher similarity.  X 0  X  w ij  X  1, moreover w ij =1ifandonlyif x i = x j . w critical to ensure the diversity of selected instances (refer to the Appendix).
Eq. (1) is a simple similarity definition using RBF. There is one problem left in the definition, that is, how to get the appropriate value of  X  .Higher  X  value will make the matrix ill-conditioned or even singular, while lower  X  value will hurt the discriminative capacity of the similarity matrix W . A possible way to learn the parameter is to find  X  that minimizes average label entropy, that is, Note the definition of H ( i ) by Eq. (4) uses probability f i , which is calculated from W . Interested readers please refer to Zhu et al. [2003a].

Combining Link Information. Now, we introduce how to combine the link information into the similarity matrix. This can be done by extending the similarity measure with a link-based one such as Pagerank.

Pagerank is an algorithm to estimate the importance of each node in a graph. In essence, it calculates a transition matrix based on the graph structure. The transition matrix can be used as the asymmetric similarity between nodes. Generally speaking, the Pagerank model can be explained by a surfer randomly jumping in the graph.  X  The surfer may jump to another node by following links with a equal or weighted probability.  X  The surfer may randomly jump to any node with a probability proportional to simi-larity in feature space.
 Suppose there is a well-defined similarity matrix W that measures the impact solely in feature vector space. Now we want to integrate the link information into it, we can obtain a new definition W where 0  X   X  1, I ( i , j ) is an indicator function standing for whether there is a link between instances i and j and d i is the degree of i , d i = ( i , j )  X  E 1.

In this way, the weight (transition probability) consists of two parts: the link infor-mation and the similarity. is a factor balancing the weight of these two parts. We take data instance (point) v 1 in Figure 2 as an example. Originally the similarities between v 1 and the other 3 points are identical, that is, w 12 = w 13 = w 14 = 1 3 . Suppose the link part of the w 13 are zero. The final weights after combining link information are w 12 = w 14 = 5 12 ,w 13 = 1 6 ,the 1 4 differences are caused by links. Solving the objective function (Eq. (3)) is NP-hard. Several greedy algorithms can be considered to approximate the optimal solution. However, most of them cannot the-oretically guarantee an error bound. In this section, we present an efficient learning algorithm. More importantly, since the Q ( S ) is designed as a monotonic submodular function, the solution of the learning algorithm can have a good error bound. We will give a theoretical analysis to the submodularity and monotonicity of the function Q ( S ). Finally, to scale up to real large datasets, we have developed a parallel implementation of the algorithm.

Algorithm 1 outlines the learning algorithm. The algorithm can be roughly divided into two parts: the first part consists of mainly matrix operations, calculating transi-tion matrix P , probability vectors, and entropy H [ v ] for each instance v ; the second part runs iteratively on the unlabeled dataset U  X  S , with each time selecting a data instance v of the maximum score.

Though we select all the samples one by one, this is a batch mode active selection method. Each time we greedily select a batch of samples to query users, while in the single mode active learning framework, users are queried each time when a single sample is selected.

Given the function Q ( S ) being submodular and monotonic, the algorithm is guaran-teed with an approximation rate of (1  X  1 e ), as shown in Theorem 4.1.

T HEOREM 4.1. The approximation rate of Algorithm 1 is (1  X  be the output of the algorithm and S  X  be the optimal solution, we have
Proof of this theorem (the approximation rate) has been extensively studied, and can be found in Nemhauser et al. [1978]. Here we give the proof of the monotonically submodularity property. Submodularity is an elegant property for set function optimization problems [Kawa-hara et al. 2009; Nemhauser et al. 1978]. Our defined function Q ( S ) satisfies the submodular property.
 T HEOREM 4.2. Q ( S ) is submodular. That is,  X  S 1  X  S 2  X  S,  X  v/  X  S 2 ,
P ROOF .Since H ( S )= v  X  S H ( v ) is an additive function which is submodular, we only have to prove that C ( S ) is submodular.

Suppose S 1  X  S 2  X  S ,then C ( S 1  X  X  v } )  X  C ( S 1 )is Define ( i , S 1 )=max j  X   X  X f ( i , S 1 ) = 0, then there  X  j  X  S 1  X  L ,w ij  X  w i v .Since S 1  X  S 2 ,max j  X 
So we have that i  X  U ( i , S 1 )  X  i  X  U ( i , S 2 ), that is, C ( S ) is submodular. There-fore, we can obtain that Q ( S ) is submodular. The defined function Q ( S )isalso monotonic.
 T HEOREM 4.3. Q ( S ) is monotonic.
 P ROOF .  X  S 1  X  S 2  X  S , it X  X  not hard to see that H ( S ) is monotonic, and for C ( S ), Therefore Q ( S ) is monotonic. With the volume of the dataset process increasing, Algorithm 1 would suffer the lim-itation of memory space and computation power with only one machine. Thus it is necessary to design a parallel algorithm for scaling up to real large dataset. We have several strategies to improve the scalability of the algorithm. First, sparse represen-tation and distributed storage are used to store the similarity matrix W . Second, we have implemented a parallel version of Algorithm 1. Specifically, we employ the MPI (Message Passing Interface) as the parallel programming model, which is a widely-used language-independent parallel library [Gropp et al. 1994].

The first time-consuming part of Algorithm 1 is the matrix multiplication and in-version when computing probability matrix P . How to parallelize matrix operations has been a classical problem. We use the Cannon Matrix-Matrix Multiplication Algo-rithm [Cannon 1969] under the MPI specification [  X  Ozdogan 2006], because of its good efficiency and low storage requirement. Using a similar method, we also implement Matrix-Vector Multiplication [  X  Ozdogan 2006] and Matrix Inversion [Pease 1967] using MPI. The second time-consuming part is the main loop for selecting instances greed-ily. To parallelize it, we employ the master-slave model [Huang and Wang 1997]. The master has two tasks: first, when loops begin, the master divides the whole work into independent jobs; second, the master collects the result of slaves at the end of the loops and broadcasts updated information to all the machines. Specifically, the master divides U  X  S into disjoint subsets S 1 ,  X  X  X  , S p ,andthe i -th machine will start comput-ing C [ v ]in S i and find the maxima concurrently; the master waits for each slave to complete the current round and collects all the results to update for the next round. In this section, we will evaluate the proposed approach for BMAL on both synthetic and real datasets. First, we use synthetic datasets to intuitively study our approach and to demonstrate the importance of combining all three criteria. Then we validate our method on a real-world document classification dataset. Finally, we study the effi-ciency performance of our parallel algorithm. All datasets, codes, and tools to analyze the results are publicly available. 1
The Gaussian Synthetic Dataset. We use a synthetic dataset to validate the effective-ness of our algorithm on the content information and to verify the necessity of all three criteria. The Gaussian synthetic dataset is a dataset with only content information. It is randomly generalized on a 2D plane consisting of 17 Gaussian distributions. Each distribution has been given to class label 0 or 1 randomly. The variance and number of points of each distribution are randomized as well. This synthetic dataset has no link information.

We use this dataset to demonstrate the necessity of all three criteria. We design four tests using different definitions for the objective function representing different subsets of the criteria.  X  Test1, Proposed Method : Use our proposed data method, by Eq. (3).  X  Test2, Maximum Uncertainty : Apply the maximum uncertainty criterion. Let  X  =0, then the objective function is degraded to an entropy function, that is, Q = H ( S ).  X  Test3, Without Maximum Uncertainty : Do not consider the maximum entropy crite-rion. That is let  X  = 1, and then the objective function is degraded to Q = C ( S ).  X  Test4, Without Minimum Redundancy : Do not consider the minimum redundancy criterion. This test shows the subtlety in defining C ( S ) to ensure the diversity. Use a modified definition of C ( S ) as follows and keep the definition of Q ( S ) to be the linear combination of C ( S )and H ( S ). Note that this definition only substitutes the maximum operation with a summation op-eration thus still satisfies the maximum uncertainty and maximum impact criteria, except that the diversity property in Theorem 3.1 does not hold any more.
We use the simple KNN classifier ( k = 3) to learn the classification model. Figure 3 shows the result of the tests. There are 3,612 data instances (points) in this synthetic data on a 2D plane and 11 of them are initially labeled. The task is to actively find an-other 17 data points for labeling. In Figure 3, red and blue points refer to two classes respectively. Initially labeled data points are displayed with  X + X , and the selected data points are labeled with  X   X . From Figure 3, we can easily see that the selected data points in Test2 (3(b)) and Test4 (3(d)) are undesirable and their performance might be inferior than that in Test1 and Test3. This is because in Test2 and Test4, the se-lected instances are similar to each other (instances located together). The accuracy performance also confirms this observation. The four tests demonstrate that all three criteria are necessary.

The Networked Synthetic Dataset. In the networked synthetic dataset, we only gener-ate links without any content information. Specifically, in this dataset, 385 data points in the graph are divided into 19 clusters. Each cluster is a star graph with a center surrounded by a random number of points, and all of the points in the cluster are in the same class. All of the data points have the same feature vector; in other words, only link information can be exploited in this graph. In Figure 4, the initially labeled set is shown using  X + X , the selected dataset using the proposed method is shown using  X   X , and different classes are shown using different colors. We can see that it reason-ably selects all the centers: it satisfies our intuition that the centers have the highest impact and they are distributed diversely enough.

In real dataset, there are often noises and outliers. To further verify our accuracy under such scenarios, we bring two kinds of noises to our dataset: two leaves in dif-ferent clusters are connected with probability p 1 ; for each point in each cluster, it has probability p 2 to be labeled the opposite class. The error rates under different noise settings are shown in Table II, where different rows stand for different p 2  X  X , and differ-ent columns stand for different p 1  X  X . We can conclude that when noises are small, our model has a relatively small prediction error rate ( &lt; 10%); when noises get closer to 50% (which means the label of the nodes have nothing to do with the links), the error rate comes nearer to 50%.
Datasets. We use two citation datasets and one Web page dataset as the real-world datasets to test the proposed method for text classification. Statistics of the three datasets are given in Table III.

The Cora dataset [Sen et al. 2008; Yang et al. 2009] contains 2,708 scientific pub-lications, and the documents are classified into seven categories (fields): Case Based, Genetic Algorithms, Neural Networks, Probabilistic Methods, Reinforcement Learn-ing, Rule Learning, and Theory. After stemming and removing stop-words and words that appear less than 10 times in the dataset, we obtain a vocabulary of 1,433 unique words. There are 5,429 citation relationships between the documents.

The Citeseer dataset [Sen et al. 2008; Yang et al. 2009] contains 3,312 publications, categorized into 6 classes: Agents, AI, DB, IR, ML, and HCI. There are 3,703 unique words after processing, and the number of citations is 4,732.

The WebKB dataset [Sen et al. 2008] contains Web pages from four computer science departments, and there are five categories: course, faculty, student, project, and staff. This is a subset of the original WebKB dataset [Craven et al. 1998]. The webKB dataset contains 877 Web pages and 1,703 unique words. There are 2,868 total links between these pages.

For all three datasets, we cast the multiple classification problem as multiple binary classification tasks: for each category, we take documents of this category as positive instances and all the other documents as negative.

Baselines. We define the following baseline methods.  X  Random : selects the instances randomly with equal probability.  X  Most uncertainty : selects the set with the largest entropy H ( S ).  X  Active Learning Using Gaussian Fields . is an approach suggested by Zhu et al. [2003b] based on a semisupervised learning framework using Gaussian fields and harmonic functions [Zhu et al. 2003b]. As it is a single mode active learning algo-rithm, we run this algorithm k times to select k instances. In this framework, the link information can be introduced using our proposed method in a similar way as in Section 3.2. We will utilize the link information in the tests.  X  Hybrid . is suggested by Macskassy [2009]. It asks for this uncertainty approach and two graphical metrics (betweenness and cluster-finding) to find a selected set, and uses empirical risk to pick the best set among the union of the data instances selected by the three strategies.  X  k-means : suggested by Rattigan et al. [2007]. In the article some active inference methods are compared with each other and k -means is found to be the best one among them. Here we employ the same strategy for active learning, that is, we find vertices using k -means as the labeled set and then train the classifier.
For simplicity, we use Random, MU, GF, Hybrid, K-M to denote the aforesaid base-line methods respectively. We refer to our model as BMAL.

Results. We set the  X  parameter to be 0.5. For the Cora dataset, we randomly pick 5 instances as the initially labeled set L ; for the other two datasets, this number is 10, due to the size of the dataset and the learning difficulty. For the same reason, we define different batch size k =5 , 10 , 5 for Cora, Citeseer, and WebKB datasets respec-tively. The batch mode active learning methods first select k instances based on L , and then repeatedly select k instances based on the union of initially labeled and se-lected instances; the single mode active learning methods iteratively select k instances, and repeatedly query the user and update the model. After the selecting process, we learn the classification model based on the selected data instances by different active learning methods using the same semisupervised learning method. Here we use the NetKit-SRL toolkit [Macskassy and Provost 2007] to learn in the networked dataset. For each dataset, we run the experiment 30 times with different initially labeled sets, and both the average and variance of the accuracy is used for final evaluation.
Figure 5 shows the results on each of the dataset. Due to space limitations, we only draw the variance of the proposed method in the figure. The results show that maximum entropy does not have a good performance over all the datasets. In all three datasets, our method outperforms the strategies based on graph metrics, that is, the hybrid method and the k -means method. The performance of the Gaussian random-field-based method in the three results is a bit unstable: it does not perform well in the Cora and Citeseer datasets, while in the WebKB dataset, its accuracy is close to the proposed method. In the WebKB dataset, the gap between random selection and these methods are not as high as other datasets, probably because it is not so easy in this Web-linked dataset to perform batch mode active learning. Also, from the view of variance, our method has average variances of 0.005, 0.009, 0.01 on the Cora, Citesser, and WebKB dataset, which are much smaller than the other methods.

Why BMAL outperforms others. We empirically show that our BMAL method outper-forms the baselines. The advantage of our algorithm is that it effectively combines the link and content information. We denote BMAL-L as a simplified version of our BMAL method without considering the content information and similarly BMAL-C as BMAL without link information. Figure 7 shows the accuracy of BMAL, BMAL-L, and BMAL-C in different datasets and Figure 6 shows the average accuracies of our method with different k  X  X . Both have shown that combining link and content has greatly increased the classification result. Figure 5 also suggests that by removing the content information, the performance of our method decreases.
Experiment Setup. We use the UCI 20 Newsgroup [Frank and Asuncion 2010] in this experiment. The dataset contains approximately 20,000 newsgroup documents, parti-tioned (nearly) evenly across 20 different categories. Some of the categories are closely related to each other and some are unrelated. We construct four binary classification tasks.  X  comp.sys.mac.hardware(963) versus comp.windows.x(988): 3338 words.  X  rec.sport.baseball(994) versus rec.sport.hockey(999): 3904 words.
  X  comp.sys.ibm.pc.hardware(982) versus comp.sys.mac. hardware(963): 2812 words.  X  talk.religion.misc(628) versus alt.atheism(799): 3360 words.

The four classification tasks stand for different difficulty levels: the first one is easy, the last one is hard, and the left two stand for medium difficulty. In each task, we remove words which appear less than 10 times.

As for the baseline methods, besides Random, MU, GF, we introduce another two methods.

SVM. It is a batch mode active learning method, sampling examples that are closest to the decision boundary of SVM for the query [Tong and Chang 2001]. We use a modified version by Hoi et al. [2008], which incorporates the diversity information as well. This method considers only content-based features.
 Fisher. It is a batch mode active learning method based on an information matrix. We choose the method proposed in Hoi et al. [2006b].

Other settings are similar to the experiments with links, except the learning method. We use the nearest subspace method as the classifier, for it is shown to have a good performance in document classification tasks [Li and Jain 1998].

Results. Figure 8 shows the results of different methods. We only draw the variance of our proposed method because of space limitations.

From these results, we see that the performance of uncertainty is bad in the dataset, even underperforming the random selection in three of the classification tasks. As demonstrated, maximum entropy tends to select similar instances, hence the accuracy is low. Also, the GF method does not perform as well as in the linked datasets. The SVM-based method is not stable: it has a bad performance in the task IBM versus MAC. Though the Fisher information-based method has a high accuracy in the classi-fication tasks, our method performs better than Fisher by accuracy. And our method has an advantage in the variance in the experiments as well. In summary, we can see from the experiments that our method outperforms the baseline methods.
 Finally, we evaluate the efficiency performance of our parallel algorithm by compar-ing with the basic algorithm running on a single machine. First we run our parallel algorithm in a network with 2 computers, each with 4 cores. Table IV shows the run-ning time comparison on the three datasets Citeseer, Cora, and WebKB, which already introduced in Section 5.2. We also generate a large synthetic dataset with 8,000 data instances to better demonstrate the time improvement. From the table we see that the parallel algorithm has a very good efficiency performance, for example, on the Citeseer dataset it achieves a speedup of  X  6 and on the synthetic dataset  X  7.

Figure 9 shows the speedup (the running time of the basic algorithm divides the parallel algorithm) increases as the total number of cores increases. The dashed line is the ideal expectation of speedup. We can see from the figure that on large datasets, the speedup of the parallel algorithm is close to linear. On small datasets such as (selected) WebKB, the algorithm does not gain a good speedup performance, which is reasonable. Table IV lists the running time of our algorithm on different datasets.
Batch Mode Active Learning. Active learning, or selective sampling, has been exten-sively studied for many years (see Settles [2010] for a survey). However, classical single mode active learning methods suffer from a couple of problems: First, retrain-ing is needed after each selection; second, most informative instances selected in each iteration might be highly correlated since redundancy cannot be taken into account. To solve this, a number of approaches have been proposed to perform active learn-ing in batch mode. Generally SVM-based active learning methods [Tong and Chang 2001] repeatedly select the instance closest to the decision boundary, and redundancy is avoided by incorporating diversity [Brinker 2003]. Based on these researches, Hoi et al. [2008] proposed a novel Min-Max SVM batch mode active learning framework. Another method utilizes the Fisher Information matrix. By setting Fisher Informa-tion matrix as the objective function, a set of instances can be efficiently selected. This method has been applied to large scale text categorization [Hoi et al. 2006a], medical image classification [Hoi et al. 2006b] and image retrieval [Steven et al. 2009]. Rather than using heuristic measures, Guo and Schuurmans [2008] directly learn a good clas-sifier by formulating batch mode active learning as an optimization problem, and Shi and Zhao [2010] tried to define active learning from classifier models Xu et al. [2009]. Compared with previous works, our work applies for networked data, aiming to give a clear set of criteria to optimize the result of active learning.

Classification in Networked Data. Recent focus in classification research extends to clas-sify related entities by exploiting dependencies between data instances, which is shown to improve the accuracies under interrelated conditions [Jensen and Neville 2002; Jensen et al. 2004]. Collective learning is the fundamental approach when clas-sifying such networked datasets. It was originally initiated by the work proposing iterative classification in relational data [Neville and Jensen 2000]. Earliest efforts to-wards learning in networked datasets include relaxation labeling [Chakrabarti et al. 1998; Hummel and Zucker 1983], iterated conditional modes [Besag 1986], etc. Since then many methods have been developed for collective learning, such as inductive logic programming [Slattery and Craven 1998], graph-cuts-based formulation [Boykov et al. 2001], belief propagation in the Probabilistic Relational Model [Getoor et al. 2001; Taskar et al. 2001, 2002], iterative classification [He X  and Kushmerick 2004; Lu and Getoor 2003], the region graph method [Yedidia et al. 2005], and so on. Collective learning has applied to various topics such as text categorization [Namata et al. 2009], computer vision [Anguelov et al. 2005], social networks [Liben-Nowell and Kleinberg 2007], etc.

Active Learning for Networked Data. Due to the success of collective inference on networked data, there have been proposals to extend it into semisupervised learning scenarios [Macskassy 2007; Xu et al. 2006]. Following this thread, several attempts have been done to apply active learning in networked data. Some works employ empirical risk minimization, which is shown to be computationally expensive: Roy and McCallum [2001] directly optimize expected future error; while Zhu et al. [2003b] combine semisupervised learning and active learning based on Gaussian random fields and harmonic functions; Macskassy [2009] integrate graph-metrics and empirical risk minimization. Bilgic et al. [2010] proposes an active learning method for networked data built upon uncertainty sampling, committee-based sampling, and clustering. Also, there have been explorations of active learning on special graphs, such as trees [Cesa-Bianchi et al. 2010]. In this article we introduce a novel batch mode active learning framework which is independent of the collective learning model and has been computationally efficient.
 Active Inference. Active learning and active inference are similar in several ways. They both request the classification label of a selected set from users, and improve the accuracy by designing how to select such samples. The fundamental difference is when these labels are collected: active learning requests these labels at training time , while active inference requests these labels at prediction time [Attenberg and Provost 2010]. As a result, when the active learning framework requests labeling, the learn-ing model is still training and updating; but when the active inference framework will have a trained underlying classifier at request time. Compared with active learning, active inference will result in lower cost, but the benefit of active labeling is limited in the sense that it cannot take effect the trained classifier. Several approaches have been proposed about active inference in networked data: Rattigan et al. [2007] in-troduced the active inference concept and studied four different nonrandom selection methods based on network structure exploitation; Bilgic and Getoor [2008] introduced a method based on objective function optimization. Bilgic and Getoor [2009, 2010] pro-posed a novel framework of reflect and correct , by trying to find mistakes of underlying classifiers and correcting them. Also, there has been active inference work in other kinds of dataset, for example, stream data [Attenberg and Provost 2010]. In this article, we study a novel problem of batch mode active learning and propose a unified framework to solve this problem by combining both link and content informa-tion. We define three criteria to measure the informativeness of a set of data instances and design an objective function based on the three criteria. We demonstrate the effec-tiveness of the three criteria on synthetic datasets, and validate our proposed approach on several real-world datasets. Experimental results show that our approach outper-forms several baseline methods for batch mode active learning. We have also developed a parallel implementation and validate its speedup performance on four datasets.
The general problem of batch mode active learning represents a new and interesting research direction in machine learning and data mining. There are many potential future directions of this work. A direct adaptation is to apply the proposed method to active learning for link prediction, an important learning problem over networks. Another interesting issue is to study how to combine the active learning process and the classification model learning process together. Currently, the active learning is considered an independent process from the classification process. However, they are usually intertwined. Combining the two processes together may further improve the classification accuracy. Another potential research is to apply the proposed approach to other applications on social networks (e.g., social influence analysis Tang et al. [2009]), a very important application scenario on the Web to further validate its effectiveness. We will prove a result for general definition of similarity matrix not limited to RBF: For a similarity matrix which is (  X  1 , X  2 )-transitive (defined in Section 3.2), and with (1) R ( S )  X  (2) R ( S )  X 
P ROOF . We will only prove the first inequity, the proof of the second one is very similar.

Sum Eq. (11) over all j  X  X  in S  X  L  X  X  dp ( i ) } ,wehave
Since  X  2  X  1, Now for each j  X  S , we can see that dp  X  1 ( j ) =  X  .Let
Sum Eq. (13) over all i  X  I , should be higher than the average over all i  X  U  X  S  X  X , or,
Therefore R ( S )  X  We now present Lemma A.1 to prove Theorem 3.1.
 L EMMA A.1. The RBF definition of W ( Eq. (1)) is (2 , 1) -transitive.

P ROOF . The following inequity holds for quadratic optimization. The lemma can be directly proven from Eq. (17).

