 M. Senthil Arumugam  X  M. V. C. Rao  X  Aarthi Chandramohan Abstract This paper presents a new and improved version of particle swarm optimization algorithm (PSO) combining the global best and local best model, termed GLBest-PSO. The GLBest-PSO incorporates global X  X ocal best inertia weight (GLBest IW) with global X  X ocal best acceleration coefficient (GLBest Ac). The velocity equation of the GLBest-PSO is also simplified. The ability of the GLBest-PSO is tested with a set of bench mark problems and the results are compared with those obtained through conventional PSO (cPSO), which uses time varying inertia weight (TVIW) and acceleration coefficient (TVAC). Fine tuning vari-ants such as mutation, cross-over and RMS variants are also included with both cPSO and GLBest-PSO to improve the performance. The simulation results clearly elucidate the advan-tage of the fine tuning variants, which sharpen the convergence and tune to the best solution for both cPSO and GLBest-PSO. To compare and verify the validity and effectiveness of the GLBest-PSO, a number of statistical analyses are carried out. It is also observed that the convergence speed of GLBest-PSO is considerably higher than cPSO. All the results clearly demonstrate the superiority of the GLBest-PSO.
 Keywords Particle swarm optimization (PSO)  X  Bench mark problems  X  Inertia weight  X  Acceleration coefficient  X  Mutation operators  X  Cross-over operators  X  RMS variants 1 Introduction Particle swarm optimization (PSO) is a population-based stochastic optimization technique out to be a tough competitor in the field of numerical optimization. Generally, the particle swarm optimization technique has been inspired by the social behavior of bird flocking or fish schooling. This optimization technique is considered as one of the modern heuristic algorithms under the evolutionary algorithms. As stated earlier, the particle swarm optimiza-tion actually simulates the behavior of bird flocking. This can be seen by taking the scenario whereby a group of birds are wondering about looking for food within a certain search space. Assuming that there is only one corner in the search space where the food lies; the birds would not know where exactly the food is. However, these birds do know how far the food is within each iteration. Thus, the best strategy in finding the food will be to follow the bird which is nearest to the food. The brainchild of particle swarm optimization comes mainly from the adaptation of this scenario. Several researches were carried out so far to analyze the performance of the PSO with different settings, e.g., neighborhood settings [ 1 , 3 , 12 ].
The particle swarm optimization is very much similar to the evolutionary computation techniques such as the genetic algorithm in the sense that both systems are initialized with a population with random solutions and searches for the optima by means of several genera-tions. However, there still exists a distinct difference between these two techniques whereby in the case of particle swarm optimization, genetic operators such as mutation and crossover will not be in use. Instead, each possible solution will be referred to as particles. Each of these particles will have a position and velocity vector in the search space and the position vectors actually represent some parameter value. Just like the genetic algorithm, the particle swarm optimization has also a fitness function which takes the particle X  X  position and assigns of genetic algorithm X  X  fitness function.

According to Angeline [ 1 ], the PSO performs well in the early generations, but has prob-lems reaching a near optimal solution in several real-valued function optimization problems Comparisons between PSO and most popular evolutionary algorithm, the Genetic algorithm clude that a hybrid model, which comprises both GA and PSO, could lead to further improve-ments in the performance. The complex task of parameter selection in PSO model is described in [ 19 , 24 ].

In this paper, PSO with new variants for the inertia weight, the acceleration coefficient and the velocity, which are defined in terms of local best (pbest i ) and global best (gbest) values of the particles in the swarm, is considered. Three different variants are also incor-porated individually with the PSO algorithms (cPSO and GLBest-PSO). The algorithms are simulated to solve a set of well-known bench mark problems.
 This paper is divided into six sections. In Sect. 2 , a brief description of PSO is presented. In Sect. 3 , the previous work on the PSO parameters is studied and the new version of PSO, GLBest-PSO, with the new parameters is explained. The design of the fine tuning elements such as mutation, cross-over and RMS variants is discussed in Sect. 4 . In Sect. 5 , the testing of standard bench mark problems through cPSO and GLBest-PSO is done and the results are presented and the conclusions are given in Sect. 6 . 2 Particle swarm optimization algorithms The term swarm intelligence is used to describe algorithms and distributed problem solvers inspired by the collective behavior of insect colonies and other animal societies. Under this prism, PSO is a swarm intelligence method for solving optimization problems. Several new est-neighbor velocity matching and acceleration by distance. When it was realized that the simulation which incorporates the concepts such as nearest-neighbor velocity matching and acceleration by distance could be used as a population-based optimizer, several parameters were omitted, through a trial and error process, resulting in the first simple version of PSO [ 6 , 9 ].

A swarm consists of a set of particles moving within the search space, each representing ( v ). The position at which the best fitness encountered by the particle is known as personal best or local best or (pbest i ), The index of the best particle in the swarm or the best among particle is updated to their best encountered position and the best position encountered by any particle using Eq. ( 1 ): The parameters c 1 and c 2 are set to constant values, which are normally taken as two whereas r ( t ) and r 2 ( t ) are random values and they are uniformly distributed between zero and one. randomly at every iteration. The position of each particle is updated every generation. This is done by adding the velocity vector to the position vector, as given in Eq. ( 2 ).
However, in the first version of PSO, there was no actual control over the previous velocity of the particles. In the latter versions of PSO, this shortcoming was addressed by incorporat-ing two new parameters, inertia weight introduced by Shi and Ebherhart [ 19 ]and constriction factor (  X  ) introduced by Clerc [ 4 ]. One of the most widely used improvements is the intro-duction of inertia weight which is employed to control the impact of the previous history of velocities on the current one. v ( t ) = w  X  v i ( t  X  1 ) + c 1  X  r 1 ( t )  X  ( pbest where w is called inertia weight ; c 1 and c 2 are two positive constants, called cognitive and social parameter, respectively. Recently, Clerc introduced another parameter called constric-tion factor which may help to ensure convergence. The constriction model describes the way of choosing w, c 1 and c 2 so the convergence is ensured. By choosing the values correctly, constriction model is presented in Eq. ( 4 ). v ( t ) =  X (v i ( t  X  1 ) + c 1  X  r 1 ( t )  X  ( pbest where  X  = 2
Eberhart and Shi compared the performance of PSO using the v max clamping to one using increases the rate of convergence. However, when tested on the bench mark problems [ 16 , 23 ], the constriction model failed to reach the specified error threshold for that problem within the allocated number of iterations. Later, it was found that since the particles stay far from the desired range of the search space, the constriction model fails to converge within the stip-ulated iterations. After applying clamping to the constriction model by setting v max = x max , the performance was improved for all the test problems. gence of the algorithm and alleviation of the local minima. An extended study of the accel-c 2 = 2 were proposed, but experimental results indicate that alternative configurations, depending on the problem, may produce superior performance. Recent work reports that it might be even better to choose a larger cognitive parameter, c 1 , than a social parameter, c , but with c 1 + c 2  X  4[ 16 ].

The parameters r 1 and r 2 are used to maintain the diversity of the population, and they are uniformly distributed in the range of zero and one and the values of r 1 and r 2 vary for every iteration. The constriction factor  X  controls the magnitude of the velocities, in a way similar to the V max parameter, used in the first versions of PSO. When both  X  and V max are used, the algorithm results in faster convergence rates. In all experiments in this article, the PSO method described in Eq. ( 4 ) with  X  = 1isused.

In PSO the information exchange takes place only among the particle X  X  own experience and the experience of the best particle in the swarm, instead of being carried from fitness dependent selected  X  X arents X  to descendants as in GA X  X . Moreover, PSO algorithm X  X  direc-tional position updating operation resembles mutation of GA, with a kind of memory built in. This mutation-like procedure is multi-directional both in PSO and GA, and it includes control of the mutation X  X  severity, utilizing factors such as V max and  X  PSO belongs to the selection function. Thus, particles with lower fitness can survive during the optimization and potentially visit any point of the search space. 3 Existing and new inertia weight and acceleration coefficients The role of the inertia weight, w ,inEq.( 3 ), is considered to be critical for the PSO algo-rithm X  X  convergence behavior. Shi and Eberhart investigated the effect of w values in the range between 0 and 1.4, as well as varying w over time [ 19 ]. From the investigations, Shi and Eberhart observed that choosing w  X  X  0 . 8 , 1 . 2 ] results in faster convergence, but when it exceeds 1.2, the algorithm fails to converge consistently, as mentioned in the Ph.D. dis-sertation of Frans Van den Bergh [ 23 ] describing the effect of w by letting c 1 = c 2 = 0. Now,a X  w  X  value greater than 1.0 will cause the particle to accelerate up to a maximum A X  w  X  value less than 1.0 will cause the particle to slowly decelerate until its velocity reaches zero.

When c 1 , c 2 = 0, the behavior of the PSO algorithm is difficult to predict, but based on the results of Shi and Eberhart it would appear that  X  w  X  values close to 1.0 are preferable. Again Shi and Eberhart performed another investigation with the interaction between inertia weight and v max This time it was found that w = 0 . 8 produced better results, even when v max = x max . Further empirical experiments were carried out by Shi and Eberhart, with linearly decreasing inertia weight from 0.9 to 0.4 [ 20 ] which improved the performance of the algorithm considerably.

Accordingly, the parameter w regulates the trade-off between the global (wide-ranging) and local (nearby) exploration abilities of the swarm. A large inertia weight facilitates global exploration (searching new areas), while a small one tends to facilitate local exploration, i.e. fine-tuning the current search area. A suitable value for the inertia weight  X  usually provides balance between global and local exploration abilities and consequently results in a reduc-tion of the number of iterations required to locate the optimum solution. Initially, the inertia weight was constant. However, experimental results indicated that it is better to initially set the inertia to a large value, in order to promote global exploration of the search space, and gradually decrease it to get more refined solutions. The choice of the PSO algorithm X  X  param-eters (such as the group X  X  inertia, acceleration coefficient) seems to be of utmost importance for the speed, convergence and efficiency of the algorithm.

Shi and Eberhart have found a significant improvement in the performance of PSO with the linearly decreasing inertia weight over the generations, time-varying inertia weight (TVIW) which is given in Eq. ( 5 ).
 current iteration number and maxiter is the maximum number of allowable iterations.
Recently, [ 16 ] introduced a time-varying acceleration coefficient (TVAC), which reduces the cognitive component and increases the social component of acceleration coefficient, c 1 are allowed to move around the search space, instead of moving toward pbest. A small value of c 1 and a large value of c 2 allow the particles converge to the global optima in the latter part of the optimization. The TVAC is given in Eqs. ( 6 )and( 7 ). c 2 f are the final values of the acceleration coefficient c 1 and c 2 , respectively.
Simulations were carried out with various constraint optimization problems to find out the best ranges of values for c 1 and c 2 . From the results it was observed that best solutions were determined when changing c 1 from 2.5 to 0.5 and changing c 2 from 0.5 to 2.5, over the full range of search [ 16 ].

In this paper, the inertia weight and the acceleration coefficient are neither set to a constant value nor set as a linearly decreasing time varying function. Instead they are defined as a function of local best (pbest) and global best (gbest) values of the fitness function as given in Eqs. ( 8 )and( 9 ). The average of all the personal best values in that particular generation is termed ( ( pbest i ) average ) .
 The inertia weight in Eq. ( 8 ) is termed global-average local best IW (GLBest IW) and the acceleration coefficient in Eq. ( 9 ) is called global X  X ocal best AC (GLBest Ac). Now, in the proposed method, c 1 and c 2 are equated to GLBest Ac and the velocity equation is modified asgiveninEq.( 10 ). The PSO algorithm with Eqs. ( 8 ) X ( 10 ) is termed GLBest-PSO.
The GLBest IW becomes minimum when gbest is equal to pbest. This in turn allows the particles to search near the global optima and thus The GLBest IW becomes minimum when gbest is equal to pbest. This in turn allows the particles to search near the global optima and thus converges to the near optimal solution faster. Similarly, the GLBest Ac is also equal to two when gbest is equal to pbest, and its value is always around 2. These two parameters help the GLBest-PSO to provide better performance than the cPSO. 4 Fine tuning operators: mutation, crossover and RMS variants Angeline [ 1 , 2 ] introduced a new version of the PSO that incorporates the concept of selec-tion for PSO algorithm. According to Angeline, the current PSO algorithm is in the poor form of selecting the particles by considering the personal best position as additional pop-ulation members. In the gbest PSO model, which was compared by Angeline, a particle line, various mutation operators for a single stage hybrid manufacturing system via cPSO and GLBest-PSO are incorporated [ 17 ]. Later, [ 15 ] chose to investigate the effect of cross-over operator with PSO. Arithmetic cross-over operation (refer to Table 2 ) was carried out between two randomly selected particles producing two new children replacing their parents. This process is repeated for a number of particles with probability P c . Thus, the arithme-tic cross-over of the positions yields two new positions at random locations. The velocity crossover normalizes the length of the sum of the two parent X  X  velocities, so that only the direction and not the magnitude are affected. The results presented by [ 15 ] show that the tions with many local minima, crossover takes the lead. Lovbjerg et al. applied cross over only for gbest model PSO and no comparison with lbest model. In this paper, three differ-ent mutation, cross-over and RMS variants are tested with cPSO (PSO with TVIW) and GLBest-PSO. The results are compared with one other with and with out the fine tuning variants. 4.1 Mutation operators Mutation plays an important role in genetic algorithm (GA). It is designed for fine-tuning capabilities aimed at achieving high precision. Hence, PSO with mutation has the potential to reach a better optimum than the standard PSO. The three mutation operators considered in this paper for fine-tuning the PSO performances are listed in Table 1 . Both the PSO methods (cPSO and GLBest-PSO) are implemented with the three mutations given in Table 1 indi-vidually. The notations such as Xr 1 , Xr 2 , Xr 3 are randomly chosen values within a particle itself whereas Xor 1 , Xor 2 , Xor 3 are the random values from any other two particles which are chosen for interaction.
 (eg., Two-dimensional mutation operator) 4.2 Crossover variants Crossover is the main genetic operator and consists of swapping chromosome parts between individuals. Crossover is not performed on every pair of individuals; its frequency being controlled by a crossover probability ( P c ). There are several crossover methods available, but in this paper three cross-over operators, namely, arithmetic crossover method (AMXO), average convex crossover (ACXO) and root probability cross-over methods are considered for fine tuning the PSO algorithm as presented in Table 2 . 4.3 RMS variants The root mean square (RMS) variants are used to fine tune the PSO algorithm in order to increase the convergence rate. Each of the three RMS variants considered in this paper dif-fers from the other in terms of the number of samples considered in RMS equation. In the first variant, two chromosomes (say parent) are involved and a new chromosome (child) is developed and hence named as 2-D RMS variant. In the second variant, three chromosomes are involved, one from the current particle and the other two are selected randomly from the other remaining particles, to create a new population. The third variant is a hybrid RMS variant in which a group of three chromosomes are considered, and from the combinations of these three and randomly selected particles, three new chromosomes are developed as given in Table 3 . The notations such as Xr 1 , Xr 2 , Xr 3 are randomly chosen values within a particle itself whereas Xor 1 , Xor 2 , Xor 3 are the random values from any other two particles which are chosen for interaction. The randomly selected values Xr 1 , Xr 2 , Xr 3 of the current particle are modified by the RMS variants using their respective mathematical functions as giveninTable 3 . 5 Testing with benchmark problems In order to analyze the validity and effectiveness of the inertia weight (TVIW and GLBest IW), the acceleration Coefficient (TVAC, GLBest Ac) with three mutation operators, three cross-over operators and three RMS variants for cPSO and GLBest-PSO, a few standard bench mark problems are considered. From the standard set of bench mark problems avail-able in the literature, 13 important functions, listed in Table 4 , are considered to test the efficacy of the proposed methods. All the test functions reflect different degrees of complex-ity. Test functions f 1  X  f 3 are unimodal (containing only one optimum) functions where as the remaining functions, f 4  X  f 13 are multimodal (containing many local optima, but only one global optimum).
 All the 13 bench mark problems listed in Table 4 , are simulated through the cPSO (with TVIW and TVAC) and GLBest-PSO (with GLBest IW and GLBest Ac) are simulated with three mutation operators (M1, M2, and M3), three cross-over operators (C1, C2 and C3) and three RMS variants (R1, R2 and R3) individually. Method A refers to PSO (both cPSO and GLBest-PSO) without any fine tuning operators. Two criteria are applied to terminate the simulation of the algorithms: The first one is reaching maximum number of iterations which is set as 2000, and the second is getting a minimum error (say 0.0001). The algorithms are simulated 500 times and the results are recorded. From the recorded simulated results statisti-In order to compare and analyze the 20 methods (10 cPSO methods and 10 GLBest-PSO) considered, five statistical parameters namely, mean (average), best (minimum), worst (max-presented in Table 6 . Different graphical analyses are plotted and shown in Figs. 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 .

The descriptions of the five basic statistical parameters which are considered in this paper are  X  Mean : Average of the optimal fitness values taken through 500 simulation results.  X  Best : The minimum value of optimal fitness among the 500 simulation runs.  X  Wo rst : The maximum value of optimal fitness among the 500 simulation runs.  X  Standard deviation : The square root of the variance. The variance is the second moment  X  Median : The median is the middle of a distribution: half the fitness values are above the 1. Spherical function : A very simple, smooth, strongly convex unimodal function with its global minimum located at x  X  = 0 with f ( x  X  ) = 0. This function has no interaction between its variables. 2. Rosenbrock function : A unimodal function, which has a significant interaction between around a parabola. Algorithms that are not able to discover good directions underperformed in this problem. . Its global minimum of f ( x  X  ) = 0 is located at x  X  = ( 1 , 1 ,..., 1 ). 3. Quartic function : It is a simple unimodal function padded with noise. The Gaussian noise minimum is located at x  X  = 0 with f ( x  X  ) = 0 . 4. Foxhole function : It is an example of a function with many local optima. Many standard optimization algorithms get struck in the first peak. The landscape of this function features a flat surface with 25 deep holes and among them there is only one contains the global optimum equal to 0.998 located at (  X  32,  X  32). 5. Griewank function :  X  Number of variables: n variables.  X  Search domain:  X  600  X  x i  X  600 , i = 1 , 2 ,..., n .  X  Number of local minima: several local minima.  X  The global minima: x  X  = ( 0 ,..., 0 ), f ( x  X  ) = 0 . 6. Rastrigin function : It is a fairly difficult problem due to the large search space ad large number of local optima. The function is a highly multimodal. The local minima are located at a rectangular grid of size 1. The global optima is the global minima: x  X  = ( 0 ,..., 0 ), f ( x  X  ) = 0. 7. Schaffer X  X  F6 function : This is a two-dimensional function consists many local minima arranged in a concentric circle around the global optimum forming an ideal trap for a search-ing algorithm. Its global minimizer is f ( x  X  ) = 0 which is located at x  X  = ( 0 , 0 ) 8. Schwefel function : A multimodal function with very deep sinusoidal indentations. The global minimizer is located near the corner of the search space, so that x  X  = (  X  420 . 9687 ,  X  420 . 9687  X  X  X  X  420 . 9687 )) with f ( x  X  ) =0. 9. Ackley function : A multimodal function with deep local optima. The variables are inde-pendent. The global minimum is x  X  = 0 with f 10. Six-hump camel-back : It is a two-variable unconstrained problem which has upper bounds of 10.0 and lower bounds of  X  10 . 0 on both variables, and has six local minima, all lying well within these bounds, plus a stationary point at the origin that is neither a local mini- X  1 . 0316285. 11. Branin function :  X  Number of variables: n = 2.  X  Search domain:  X  5  X  x 1  X  10 , 0  X  x 2  X  15 .  X  Number of local minima: no local minima except the global ones. x  X  =(0,  X  1), but the peak response value (a corner) is five orders of magnitude larger than those in the large neighborhood of x  X  . 13. Shekel function :  X  Number of variables: Seven variables  X  Search domain: 0  X  x i  X  10 , i = 1 , 2 ,..., 7 .  X  Number of local minima: m local minima.  X  The global minima: x  X  = ( 4 , 4 , 4 , 4 ), f ( x  X  ) = X  10 6 Conclusions The new version of PSO, global X  X ocal best PSO (GLBest-PSO) which incorporates glob-ally and locally tuned parameters (GLBest IW and GLBest Ac) is tested for solving the 13 standard bench mark problems. Three fine-tuning variants, namely, mutation operators, cross-over and RMS variants are also incorporated individually to increase the performance of the PSO algorithms. The simulation results for the 13 bench mark problems with GLBest-PSO are taken and the statistical analyses are carried out. The results are then compared with those obtained through conventional PSO, which adopts a time varying IW and AC. Figs. 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , three conclusions can be made: 1. The performance of both cPSO and GLBest-PSO is improved considerably with the 2. The new version, GLBest-PSO produces a better optimal solution than the cPSO in all 3. The number of average generations required to reach the convergence in GLBest-PSO
It is very obvious that the standard deviation is one of the quality measures of statistical analyses. In order to prove the consistency and stability on the optimal solution, standard deviations of the fitness value which is taken through the 500 simulated runs is computed. If the standard deviation is very small, it implies that the solutions obtained in each of the 500 runs are more or less equal and the differences between the solutions over each run are less. Therefore, if an algorithm provides a very low standard deviation then it can be concluded that the algorithm is consistent. From Figs. 6 and 9 , it can be observed that the GLBest-PSO provides a very low standard deviation than that of cPSO.
 From the results presented, it can be concluded that all the fine tuning elements (M1, M2, M3, C1, C2, C3, R1, R2, and R3) are problem dependent as these operators show different performance on different problems. For example, M2 produce a better result with both cPSO and GLBest-PSO) for sphere function but R1 produce the best for Rosenbrock function. For Quartic function, C3 gives the better results than the other methods, With GLBest-PSO, all the fine-tuning elements are giving more or less the same value for foxhole function but the rate of convergence differs for each method. Mutation operator M3 produces a better optimal solution with faster convergence rate in this method. The fine tuning elements fail to prove with cPSO for solving the Griewank function but their presence considerably improves the performance with GLBest-PSO while solving the Griewank function.

The RMS variants could not be effective for solving the most difficult function, Rastr-igin, whereas all the three cross-over (C1, C2, and C3) operators help the GLBest-PSO to achieve the optimal solution efficiently. The same conclusion can be made for Schaffer X  X  F6 function while this time all the three mutation operators are more effective than the cross-over operators.

The presence of the mutation operators is very much felt while solving the Schwefel func-tion. All the three mutation operators (M1, M2, and M3) with both cPSO and GLBest-PSO yield a near optimal solution while all the other methods are very far behind in finding the optimal solution. Particularly, the operator M3 produces the near optimal solution with faster convergence.
 The fine tuning operators M1, M3 and C3 hold good in solving the Ackley function. Among them C3 not only produces the optimal solution but also with faster convergence. All the 20 methods are very well managed to get the optimal solution for six-hump camel-back function. By considering the convergence speed as the other comparative scale, all the three mutation operators (M1, M2, and M3) dominate the other methods for solving the camel function.

More or less all the methods considered in this paper, solved the Branin function success-fully. This time, all the three RMS variants (R1, R2, and R3) lead the race. For the Goldstein and price function, GLBest-PSO with the operators M3, C1, and C2 produce the exactly the optimal solution and among them C2 makes the algorithm converge faster.
For the last function, Shekel, the effect of the fine tuning operators is not much felt with cPSO whereas all the nine tuning elements produce the optimal solution with GLBest-PSO. The RMS variants motivate the algorithm to converge faster on to the optimal solution.
These are the most significant outcomes of the experiments performed with both cPSO and GLBest-PSO. These combinations of mutation operators, cross-over variant and RMS variants with PSO algorithms have been shown to work efficiently with regard to all the bench mark problems considered in this paper but it is believed that these might be equally efficient with regard to all other problems as well. References Author X  X  biography
