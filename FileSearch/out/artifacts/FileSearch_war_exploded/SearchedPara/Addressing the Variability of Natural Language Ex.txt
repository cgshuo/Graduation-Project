 of natural language expression. Due to flexibility of human language, the same information can be formulated in numerous ways. This has great implication in text summarization and question answering applications where the identification of redundant information is crucial to system performance. Another important issue pertains to the notion of similarity between sentences. Recent development has been made on this issue. In information retrieval field, different levels of topical similarity between sentences are proposed [12][15]. Relevant sentences either address the same specific topics or they might talk about the similar general topics. In natural language processing (NLP), two notions of sentence similarity, semantic equivalence and entailment [9], are understudied. Because they are strongly related, thus, a clear semantically equivalent if they share the exact same meaning. Following this definition, paraphrase sentences are considered the most common form of semantic equivalency. On the other hand, entailment focuses on unidirectional inference. If the meaning of one sentence can be inferred from the ot her sentence, the two sentences are said to be an entailment pair. 
In this paper, we propose the method that takes int o account semantic structure of sentences to measure sentences similarity. Traditio nally, sentences are transformed into a bag of words for sentence similarity computa tion. This results in  X  X emantic has a crucial consequence to the identification of semantic equivalence or entailment sentences in which a specific inference has to be m ade. Our proposed method aims to computing sentence similarity at verb-argument stru cture level. The issue of measuring similarity of sentences is gaining more attention from various research communities. Although the perceived notions of text similarity may differ depending on the application domains, many of them share a common goal of matching up semantically similar sentences. To that end, various techniques have been proposed. First, probabilistic approaches have been adopted to identify topically related sentences [12] [15] [13] in sentence retrieval application. Next, several unsupervised approaches have been proposed for paraphrase recognition tasks [4][9][7] [14]. Recently, natural language processing community has increasingly focused on developing NLP systems to recognize entailment between sentences [8]. For this task, systems that employ extensive linguistic tools, such as logical inference engine and anaphora resolution [11][20], have started to show significant improvement in result over relatively  X  X hallower X  approaches. Nevertheless, this comes with a trade off in computational cost which makes comprehensive NLP systems currently impractical for a large text collection. Motivated by works in related areas [5][19], our work aims to address the shortcoming of existing text similarity measures when applying to sentence similarity task. That is, most techniques either simply treat sentences as single text unit or transform them into a bag of words representation; thus ignoring syntactic and semantic relations between constituents. Specifically, we are not aware of any methods that compute the similarity of sentence pairs at their semantic structure level. The semantic structure of sentences, referred to as verb-argument structure , encodes the relations between individual components and their semantic roles with respect to a given verb in a sentence. The labels of semantic roles are varied depending on the annotation scheme [3] [16]. Generally, rel defines a verb or relation between two or more arguments. Arg0 denotes a prototypical agent, Arg1 indicates a prototypical patient or theme of a given verb, and ArgM represents adjunctive argument (e.g. ArgM-LOC specifies location-related argument). For example, a simple sentence  X  X ohn broke a glass X  can be decomposed into one verb-argument structure [ Arg0 John] [ broke] [ Arg1 a glass]. It consists of two arguments that corres pond to a verb broke . John is labeled with Arg0 indicating that it is a proto typical agent and has a semantic role of breaker while glass is annotated with Arg1 denoting a prototypical pat ient, relation where John is a subject and glass is a dir ect object of this sentence. By measuring semantic similarity of verb-argument stru ctures, we can improve the effectiveness of sentence similarity measures despi te the syntactic variability of language expression. 
Based on the motivation that sentences that express the same meaning, in terms of event or idea, should share similar verb-argument s tructures, we decompose sentences into a set of verb-argument structures instead of c omparing two unstructured text segments. Given two sentences s i and s j , the similarity score between verb-argument where  X  and  X  are coefficients that control the influence of sem antic similarity between verbs and the sum of semantic similarity be tween arguments in verb-argument structures. The question is what is a reas onable weight for verb similarity and argument similarity components? Following a wel l-known psychological experiment of sentence sorting by [10] which sugges ts that verb is one of the main determinants of sentence meaning, we allocate highe r importance factor to verb component than argument components 2 . For s im r e l ( v i k ; v j l ) , we employ WordNet-based gloss overlap measure [1] to compute word sim ilarity score between verbs or utilize sentence-level similarity measures [2], e.g . Jaccard coefficient, phrasal overlap measure, etc., to determine their similarity. 
Finally, the similarity between sentence s i and s j is derived from verb-argument pair which produces the maximum similarity score as specified in equation 3. According to internal validation, deriving sentence similarity score by maximizing sim va consistently produces better performance than line arly combining or averaging sim va . This explains that sentence meaning tends to be d ominated by one major verb-argument structure. 
The whole computation process can be described as f ollows. First, we use semantic role labeler SENNA [6] to annotate each constituent in the sentences with their semantic roles. After the verb-argument structures are extracted by semantic role labeler, verb-argument text is parsed to identify the verb and individual arguments. During the parsing step, we apply syntactic rules to replace single verb with verb phrase if one exists in verb-argument text. In addition, we remove any words that are not part of the longest noun phrases in argument components. For example, given a Corporation] X , a single verb  X  X tands X  will be expanded into a verb phrase  X  X tands for X . Arg1 text contains  X  X BC X  and Arg2 text contains  X  X ritish Broadcasting Corporation X . Moreover, we perform noun denominalization on verb-argument structures of generic sentences, those which contain auxiliary verb, by expanding them into a new verb-argument structure. The expanded structure shares the same set of arguments as the original one while the auxiliary verb is replaced with a verb form of its forward adjacent noun. After that, the denominalized noun is removed from the abbreviation of British Broadcasting Corporation] will be expanded into  X  X  Arg1 BBC] [ abbreviates] [ Arg2 of British Broadcasting Corporation]. 
After verb and argument components are identified, the next step is to determine component ( s im a r g n ( v i k ; v j l ) ).WordNet-based gloss overlap measure is employed to TMP, ArgM-DIR, etc.) into single category and find its maximum score from all possible cross-argument pair comparison (ArgM vs. Arg0, ArgM vs. Arg1, etc.) This is done to deal with the cases where ArgM is not accurately tagged by semantic role labeler. 4.1 Data Sets We use two publicly-available sentence pair data sets, Microsoft Research paraphrase corpus (MSRP) [9] and the third PASCAL recognising textual entailment challenge (RTE3) data set [8], to evaluate the performance of the similarity measures. 
MSRP contains 5,801 sentence pairs (4,076 training pairs and 1,725 test pairs) automatically constructed from various web new sources. Each sentence pair is judged by two human assessors whether they are semantically equivalent or not. Semantically equivalent sentences may contain either identical information or the same information with minor differences in detail according to the principal agents and the associated actions in the sentences. 
RTE3 consists of 800 sentence pairs from the development set and 800 sentence pairs from the test set. Each pair comprises two small text segments, which are referred to as text and hypothesis . Similarity judgment between sentence pairs is based on directional inference between text and hypothesis. If the hypothesis can be entailed by the text, then that pair is considered to be a positive example. 4.2 Evaluation Setting We define five evaluation metrics based on the general notion of positive and negative judgments in information retrieval and text classification as follows. Recall is a proportion of correctly predicted similar sentences compared to all similar sentences. Precision is a proportion of correctly predicted similar sentences compared to all predicted similar sentences. F 1 is a uniform harmonic mean of precision and recall. Accuracy is a proportion of all correctly predicted sentences compared to all literature [14]. 
Three baseline similarity measures are employed to compare the performance with the proposed method. These include Jaccard coefficient ( s im j a c ), Sumo-metric description of these measures, please see [2]. We first compute baseline similarity scores between unstructured sentence pairs. After that, we generate structural similarity scores where each baseline sentence similarity measure is utilized in structural similarity measure having Jaccard coefficient as the underlying method for computing argument similarity scores. 5.1 Experimental Results Table 1 presents a comparison of structural similarity approaches to the traditional structural similarity approaches improve the perfor mance of the corresponding significantly better (F 1 scores increase by 12.67% and 61.25%, respectively ) when applying to verb-argument structures as opposed to unstructured sentences. measures also shows a trend similar to paraphrase recognition task. The use of verb-argument structure has improved the performance of many naive sentence similarity s im o v e r l a p has substantially increased by 560% (from 9.48% to 63.10%), 94.99% (from 31.71% to 61.83%), and 22.34% (from 53.58% to 65.55%), respectively. According to the result, we conclude that structural approach offers greater benefit to similarity computation of highly asymmetric sentences (those in RTE3 data) than those which are more symmetric in length. 5.2 Shallow vs. Deep Semantic Processing The overall result in section 5.1 differs from that of text categorization task [19] where concept-based weighting has significantly improved classification performance over the traditional tf-idf scheme. One reason is that conceptual term frequency aims to capture the importance of a given concept in a document by leveraging the frequency of a concept in verb-argument structures. This approach is better suited for text categorization mechanism in which documents are classified according to their topics represented by terms or concepts in documents. On the other hand, the task of identifying semantic equivalence or entailment pairs requires a deeper understanding of sentence meaning. As shown in section 5.1, deeper semantic measures are able to recognize at least the same or greater number of positive pairs according to F 1 scores than those of vector space approach. The magnitude of improvement is even more of apparent in entailment task in which specific relat ions between constituents have to be identified. 5.3 The Advantage of Structural Approach over Linguistic Measures Linguistic measures, those that employ natural language resources such as WordNet, has been proven to be highly effective in sentence similarity task [14]. However, a major criticism of such approaches is the lack of computational efficiency due to the exhaustive calculation of semantic similarity between word pairs. Therefore, they might not be as robust to employ in the real-world text mining applications as most na X ve measures. In this regard, our approach offers a greater benefit over linguistic measures as it greatly improves the effectiveness of na X ve measures while maintaining their computational efficiency, particularly at sentence processing time. In this paper, we present the method that integrates semantic structure of the sentences to handle variability of natural language expression in sentence similarity task. Traditional similarity measures, which represent sentences as a bag of words, simply judge similarity between sentences according to their common word occurrences. However, due to the complexity of many text mining applications where the similarity judgment at semantic level is required, the performance of na X ve measures are likely to degrade because of their disregard of syntactic construction. Our proposed method aims to address the issue by computing sentence similarity at verb-argument structure level. By annotating sentences with semantic roles, we can better perform similarity calculation between semantically related components. The evaluation results confirm that the inclusion of sentence semantics significantly improves the effectiveness sentence similarity tasks. Given the encouraging result, we plan to evaluate the effectiveness of the proposed measure in several application-specific contexts, such as text summarization and question answering. Acknowledgments. This work is supported in part by NSF Career grant (NSF IIS 0448023), NSF CCF 0514679, PA Dept of Health Tobacco Settlement Formula Grant (No. 240205 and No. 240196) and PA Dept of Health Grant (No. 239667). 
