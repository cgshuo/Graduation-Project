 Different users may be attempting to satisfy different information needs while providing the same query to a search engine. Addressing that issue is addre ssing Novelty and Diversity in information retrieval. Novelty a nd Diversity search models the retrieval task wherein users are interested in seeing documents that are not only relevant, but also cover more aspects (or subtopics) related to the topic of interest. This is in contrast with the traditional IR task in which topical relevance is the only factor in evaluating search results. In this paper, we conduct a user study where users are asked to give a preference between one of two documents B and C given a query and also given that they have already seen a document A. We then test a total of ten hypotheses pertaining to the relationship betw een the  X  X omprehensiveness X  of documents (i.e. the number of subt opics a document is relevant to) and real users X  preference judgmen ts. Our results show that users are inclined to prefer documents with higher comprehensiveness, even when the prior document A already covers more aspects than the two documents being compared, and even when the less preferred document has a higher relevance grade. In fact, users are inclined to prefer documents wi th higher overall aspect-coverage even in cases where B and C are relevant to the same number of novel subtopics. Keywords : diversity; preference judgment; user study In the recent past, more and mo re researchers in information retrieval (IR) evaluation have direct ed their attention to evaluation measures that acc ount for both redundancy and ambiguity in search. Novelty aims at dealing with redundancy in search results, while diversity aims at handling am biguity in queries. Research in that direction has seen such an interest that two different IR evaluation conferences have organi zed diversity retrieval tasks. The Text Retrieval Conference (TREC) included a diversity retrieval task as part of the Web track between 2009 and 2012 [8]. Unlike its ad-hoc counterpart in the same track, the diversity task judged documents based on subtopics as well as to the topic as a whole. In the same manner, the NTCIR11-IMine task incorporates a subtask focused on diversifie d document retrieval for which different user intents must be taken into account [11]. the Web track. All documents are therefore from the ClueWeb09 collection of millions of web pages. We use the publicly available subtopic relevance judgments produced by experienced NIST assessors and based on graded relevance. We use the publicly available subtopic relevance judg ments produced by experienced NIST assessors and based on grad ed relevance. Since documents were not judged for subtopic relevance, we consider the maximum subtopic relevance grade of a documen t to be its topical relevance. For each one of the 10 queries, we obtained triplets from several users. In the next section, we describe the experimental design that yielded the triplets. The framework we adopt in our study for preference judgment is based on the work of Chandar and Carterette [4]. In the framework, an assessor (i.e. user ) is shown thr ee documents, one appearing at the top of the page, one appearing at the bottom left, and the third appearing at the bottom right. We will refer to the top document as D T , and the bottom ones as D 1 and D 2 , in concordance with naming conventions of Chandar and Carterette. Given D T and a query, the assessor is asked to choose between D 1 and D 2 . Essentially the assessor would need to indicate their preference for the second document they would like to see in a ranking by selecting either D 1 or D 2 . Since we have graded topical and subtopic relevance judgments for the documents, we can use that information to determine what subtopics each document is relevant to, as well as the corresponding relevance grades. A document can thus be represented as the set of subtopics it has been judged relevant to. For instance, D i = {S j , S k } means document i is relevant to subtopics j and k. We used Amazon Mechanical Turk (AMT) [1]; an online labor marketplace to collect user judgments. AMT works as follow: a requestor creates a group of Human Intelligence Task (HITs) with various constraints and workers from the marketplace work to complete the tasks. Workers were instructed to assume that everything they know about the topic is in the top document, and they are now trying to find a document that would be most useful for learning more about the topic. No mentions of subtopics, novelty, or redundancy were given to them except as examples of properties assessors might take into account in their preferences (along with recency, ease of reading, and relevance). Each preference triplet consists of three documents, all of which were relevant to the topic; the documents were picked randomly from the data described in Sect ion 2.1. One document appeared at the top followed by two documents below it. The HITs layout Table 1 support our hypoth eses that, a document D 1 with higher aspect coverage, in general, tend to be preferred by users  X  regardless of whether D 1 covers more novel aspects than the document D 2 it is being compared to. In fact, even H 2 and H 3 are true far more often than we expected them to be. According to the results, when D 1 covers more aspects than D 2 and D 1 also has a higher ad-hoc relevance grade than D 2 , D 1 was by far preferred by users. In our expe riment this happened 1384 times (82.78%), and failed to ha ppen 288 times (17.22%). The results also confirm H3 which posits that, for documents with equal ad-hoc relevance grade, users prefer the document with higher aspect coverage. And this happened 144 times (61.54%), and failed to happen 90 times (38.46%). H2 is also true more often than not, i.e. 30 times (76.92%) against 9 times (23.08%). The results, while proving H2 and H3 to be true, also suggest that when the least-comprehensive document has a higher relevance grade than the most-comprehensive document, the bias against the least-comprehensive document is reduced. The second set of hypotheses zooms into special cases where the prior document D T (i.e. document shown at the top) has higher aspect coverage than each of D 1 and D 2 and posits that, even then, the document with higher aspect coverage is preferred by users. The three hypotheses are: H This means, given the prio r document has higher aspect coverage than each of D 1 and D 2 , users still prefer a document with higher aspect coverage and higher ad-hoc relevance grade than a document with lower aspect coverage and lower ad-hoc relevance grade. H This means, given the prio r document has higher aspect coverage than each of D 1 and D 2 , users prefer a document with higher aspect coverage but lower ad-hoc relevance grade than a document with lower aspect coverage but higher ad-hoc relevance grade. H This means given the prior document has higher aspect coverage than each of D 1 and D 2 , for documents with equal ad-hoc relevance grade, users prefer a document with higher aspect coverage than a document with lower aspect coverage. The results shown in Table 1 support hypotheses H 7 through H 9 . In fact, H 7 is true in 1006 cases (84.75%), and fails 181 times (15.25%). This means when D 1 covers more novel aspects than D and D 1 also has a higher ad-hoc relevance grade than D 2 , D 1 was by far preferred by users. H 9 is true in 99 cases (53.51%), and fails 86 times (46.49%). This means when D 1 covers more novel aspects than D 2 but has same ad-hoc relevance grade as D , D 1 was still preferred by users, but not significantly. Also, H is true only slightly more often than it is false. It is true 22 times (75.86%), and false 7 ti mes (24.14%). These results suggest that when the least novel-comprehensive document has less than or equal ad-hoc relevance grade as the most novel-comprehensive document, the bias towards the most novel-comprehensive document is reduced. This final hypothesis puts an emphasis on cases where the two documents being compared are equally  X  X ovel-comprehensive X   X  i.e. cover the same number of new subtopics  X  and posits that even in that case, users are more likely to prefer the one that covers the most number of subtopics. H are more likely to prefer a document that covers the most number of subtopics, even when both documents contain the same number of novel-aspects. In other words, users are biased towards more comprehensive docu ments, even in cases where both documents have the same number of novel-aspects. The result for this hypothesis is perhaps the most interesting one. It shows that, even wh en the two documents being compared are relevant to an equal number of novel aspects, users are more inclined to choose the one with the highest overall subtopic coverage. And this happens in 75.18% of cases. It should be noted that there are very few cases (17 cases) where the preferred document covers more aspects but fewer novel-aspects; and even fewer cases (2 cases) where it contains more novel-aspects but fewer aspects. 
Figure 2. Comparison of prop ortions in which hypotheses are true/false for three cases (considering all-pref, left-pref It is important to note that, in most cases, the document with higher aspect coverage (i.e. more comprehensive) is either more relevant or equally relevant to the other document. There were not many cases where one of the document being compared is more comprehensive but with lo wer ad-hoc relevance. So those cases are underrepresented, possi bly due to the fact that documents with high coverage tend to be very relevant. 
