 A process-related risk measures the likelihood and the severity that a negative out-come, also called fault , will impact on the process objectives [15]. Failing to address process-related risks can result in substan tial financial and reputational consequences, G  X  en  X  erale, which went bankrupt after a e 4.9B loss due to a fraud.

Legislative initiatives like Basel II [3] and the Sarbanes-Oxley Act 1 reflect the need to better manage business process risks. In line with these initiatives, organizations have started to incorporate process risks as a dis tinct view in their ope rational management, with the aim to effectively control such risks. However, to date there is little guidance as to how this can be concretely achieved.

As part of an end-to-end approach for ris k-aware Business Process Management (BPM) [5,6], we proposed a technique to model risks in executable business process models, detect them as early as possible during process execution, and support process administrators in mitigating these risks b y applying changes to t he running process instances. However, the limitation of these efforts is that risks are not prevented ,but rather acted upon when their likelihood exceeds a tolerance threshold . For example, a mitigation action may entail skipping some tasks when the process instance is going to exceed the defined maximum cycle time. While effective, mitigation comes at the cost of modifying the process instance, often by skipping tasks or rolling back previously-executed tasks, which may not always be acceptable. Moreover, we have shown that it is not always possible to mitigate all process risks. For example, rolling back a task may not allow the full recovery of the costs incurred in the execution of the task, for the sake of mitigating a risk of cost overrun.

In light of this, in this paper we present a technique that supports process participants in making risk-informed decisions, with the aim to reduce process risks preemptively. A process participant makes a decision whenever he has to choose the next task to execute out of those assigned to him at a given process state, or via the data they enter in a user form. This input from the participant may influence the risk of a process fault to occur. For each such input, the techni que returns a risk prediction in terms of the likelihood and prediction is obtained via a function estimator which is trained using historical process data such as process variables, resources, t ask durations and frequencies as extracted from the process log. This way the participant can make a risk-informed decision as to which task to execute next, or can learn the predicted risk of submitting a form with particular data. If the instance is subjected to multiple faults, the predictor can return the weighted sum of all fault likelihoods and severities, as well as the individual figures for each fault. The weight of each fault can be determined based on the severity of the fault X  X  impact on the process objectives.

We implemented the function estimator via decision trees and embedded this into a custom service for the YAWL workflow management system. Our service interacts with the worklist handler of the YAWL system to prompt the process participant with risk predictions upon filling out a form or when choosing the next task to execute. We then evaluated the effectiveness of our technique by conducting experiments on a simulated process log of 2,000 traces and using different fault distributions. The results show that the technique was always able to significantly reduce the number and severity of faults upon instance completion.

The remainder of this paper is organized as follows. Section 2 introduces our ap-proach for managing process-related risks and describes a running example. Section 3 defines the notions of event logs and faults which are required to explain our technique. Section 4 describes the proposed technique to reduce process risks which is then evalu-ated in Section 5. Section 6 discusses related work and Section 7 concludes the paper. The technique proposed in this paper belongs to a wider approach for the management of process-related risks. This approach aims to enrich the four phases of the BPM life-cycle (Process Design, Implementation, En actment and Analysis) [9] with elements of risks management (see Fig. 1).

Before the Process Design phase, we add an initial phase, namely Risk Identification , where existing techniques for risk analysis such as Fault Tree Analysis [4] or Root Cause Analysis [11] can be used to identify possible risks of faults that may eventuate during the execution of a business process. Faults and their risks identified in this phase are mapped onto specific aspects of the process model during the Process Design phase, obtaining a risk-annotated process model. In the Process Implementation phase, a more process model, such as content of data variables and resource states. In the Process Enactment phase such a risk-annotated process model is executed.

Finally, information pro-duced during the Process Enactment phase is used in combination with historical data during the Process Diagnosis phase, to monitor the occurrence of risks and faults during the execution of a process instance.
 This monitoring may trigger some form of mitigation in order to (partially) recover the process instance from a fault.
 The technique presented this paper fits in this latter phase, since it aims to provide run-time support in terms of risk prediction, by combining information on risks and faults with historical data.
To illustrate how this technique works, we use the example model shown in Fig-ure 2. The process captured by this model may be subjected to several risks during its execution. The model is defined using the YAWL language. Thus, before explaining this example, we introduce the basic ingredients of YAWL.
 We will not repeat the full definition of a YAWL specification as defined in [18]. Rather, we will only describe those parts th at are relevant to this paper. Each YAWL specification is made up of one or more nets organized hierarchically in a root net and zero or more subnets (each modeling a subprocess). Each net is defined as a set of conditions C (represented as circles), an input condition i  X  C , an output condition o  X  C , and a set of tasks T (represented as boxes). Tasks are connected to conditions via a flow relation F  X  ( C \{ o } X  T )  X  ( T  X  C \{ i } )  X  ( T  X  T ) (represented as a set of arcs). We write T N and C N to access the tasks and conditions of a net N .
Tasks model units of work that are perfo rmed either by pro cess participants ( user tasks ) or by software services ( automated tasks ). An example of an automated task is Receive Confirmation Order in Fig. 2, while an example of user task is Estimate Trailer Usage. Conditions denote states of execution, for example the state before executing a task or that resulting from its execution. C onditions can also be used for routing pur-poses when they have more than one incoming and/or outgoing flow relation. In partic-ular, a condition followed by m ultiple tasks, like condition F TL in Fig. 2, represents a deferred choice , i.e. a choice which is not determined by some process data, but rather by the first process participant that is going to start one of the outgoing tasks of this condition. In the example, the deferred choice is between tasks Arrange Delivery Ap-pointment, Arrange Pickup Appointment and Create Shipment Information Document, each assigned to a different process particip ant. When the choice is based on data, this is captured in YAWL by an XOR-split if only one outgoing flow can be taken, or by an OR-split if one or more outgoing flows can be taken. XOR-join and OR-join capture the merging behavior of their respective splits. Finally, an AND-split captures two or more flows that have to be executed in parallel while the AND-join is used to synchronize parallel flows. Splits and joins are repre sented as decorators on the task X  X  box.
In YAWL trivial conditions, i.e. those having a single incoming flow and a single outgoing flow, can be hidden. To simplify the discussion in the paper, without loss of generality, we assume a strict alternation between tasks and conditions. Under this assumption, the preset of a task t is the set of its input conditions:  X  t = { c  X  C N | C Placing a token in the input condition of a YAWL net initiates a new process instance. The token corresponds to the thread of control and it flows through the net as tasks are executed. Each task execution consumes one token from some of its input conditions (depending on the type of join preceding the task) and produces one token in some of its output conditions (depending on the type of split following the task).
 The execution of completed and running process instances can be stored in an event log: Definition 1 (Event Log). Let T and V be a set of tasks and variables, respectively. Let U be the set of values that can be assigned to variables. Let R be the set of resources that are potentially involved during the execution. Let D be the universe of timestamps. Let  X  be the set of all partial functions V  X  U that define an assignment of values to a sub set of variables in V .An event log L is a multiset of traces where each trace is a sequence of events of the form ( t, r, d,  X  ) ,where t  X  T is a task, r  X  R is the resource performing t , d  X  D is the event X  X  timestamp,  X   X   X  is an assignment of values to a sub set of variables in V .Inotherwords, L X  X  (( T  X  R  X  D  X   X  )  X  ) . 2 Each completed trace of the event log is assigned a fault X  X  severity between 0 and 1 , where 0 identifies an execution with no fault and 1 identifies a fault with the highest severity. To model this, a risk analyst needs to provide a fault function f .Thesetofall such functions is: In many settings, processes are associated with different faults. These faults can be combined together by assigning different weights. Let us suppose to have n faults { f 1 ,...,f n where w i is the weight of the fault f i , with 1  X  i  X  n .
 We distinguish between a fault X  X  severity and a fault X  X  likelihood. The risk is the product of the estimation of the fault X  X  severity at the end of the process-instance execution and the likelihood of such an estimation.

When a process instance is being executed, many factors that may influence the risk and, ultimately, the severity of a possible fault. For instance, a specific order with which a certain set of tasks is performed may increase or decrease the risk, with respect to other orders. Nonetheless, it is opportune to leave freedom to resources to decide the order of their preference. Indeed, there may be factors outside the system that let resources opt for a specific order. For similar reasons, when there are alternative tasks that are all enabled for execution, a risk-aware decision support may highlight those tasks whose execution yields less risk, anyway leav ing the final decision up to the resource. In order to provide decision support for ri sk reduction, it is necessary to predict the most likely fault severity associated with continuing the execution of a process instance with each task enabled for execution. The pr oblem of providing such a prediction can be translated into the problem of finding the best estimator of a function.
 Definition 2 (Function estimator). Let X 1 ,...,X n be n finite or infinite domains. Let Y be a finite domain. Let f : X 1  X  X 2  X  ...  X  X n  X  Y . An estimator of function f is a tuple for which the expected output is y and l is the likelihood of such an estimation. Moreover, for each y  X  Y ,  X  f ( y ) cannot contain identical domain tuples with different The function estimator is trained through a set of observations. An observation instance is a pair ( the observed output. Given a set I of observation instances, the construction of a func-tion estimator is abstracted as a function buildFunctionEstimator ( I ) , which returns a function  X  f .

The function estimator can be easily built using many machine learning techniques.
 In this paper, we employ decision-tree building algo-rithms. Specifically we used the C4.5 algorithm [14] (the latest open-source version of this algorithm). Decision trees classify instances by sorting them down in a tree from the root to some leaf node. Each non-leaf node specifies a test of some attribute x 1 ,...,x n and each branch descending from that node corresponds to a range of possible values for this attribute. In general, a decision tree represents a disjunction of conjunctions of expressions: each path from the tree root to a leaf corresponds to an expression that is, in fact, a conjunction of attribute tests. Each leaf node is assigned one of the possible output values: if an expression e is associated with a path to a leaf node y , every input domain tuple
We link the likelihood of a prediction for  X  f ( y ) to the quality of e as classifying expression. Let # n be number of observation instances ( with respect to  X  ( y ) , likelihood l =# c / # n .
 Example 3. Figure 3 shows an example of a possible decision tree obtained Regarding computational complexity, if decision trees are used, training  X  f with m observation instances is computed in quadratic time [14] with respect to the dimension n of the input tuple, specifically O ( n 2  X  m ) .

As mentioned before, it is necessary to predict the most likely fault severity associ-ated with continuing the execution of a pro cess instance with each task enabled for exe-cution. Function estimators are used for such a prediction. Since tasks consume tokens from their own input conditions, we associat e a function estimator with each condition of the YAWL specification. Given a condition c , the function estimator  X  c for c predicts the risk associated with consuming a token from c by each task t in the postset of c . Example 4. The function estimator  X  f Given a concluded process instance identified by a log trace  X   X  ( T  X  R  X  D  X   X  )  X  ,an observation instance ( in the postset of c . More specifically, the input before the event has occurred, task t , the time elapsed since the execution has started, and the contextual information; the output y is the fault X  X  severity observed for  X  ,i.e. the prefix  X  of the trace  X  before the occurrence of that event. In particular, it contains, for each task in the process specification, the number of times that the task has been performed and the last resource that has executed it. This information is clearly relevant to guarantee predictions with higher likelihood. Indeed, the risk is generally linked to the resources that perform the activities, since some resources may be more prone to be mistaken. Concerning the number of executions of tasks, let us consider the overtime fault in Example 2: the risk reasonably increases with the number of repetitions of certain C = getContextInformation (  X  ) which returns a tuple C containing this information.
In the remainder, we use to denote the operator to concatenate tuples: given two tuples Operator can also be overridden to deal with functions defined on a finite and ordered domain. Let f : W  X  Z be a function defined on an ordered domain W = w 1 ,...,w o . If we denote z i = f ( w i ) with 1  X  i  X  o , f ( z 1 ,...,z o ,x 1 ,...,x n ) .

Algorithm 1 details how the function estimators  X  c mentioned above can be con-structed. This algorithm is periodica lly executed, e.g., every week or every k process instances are completed. In this way, the pr edictions are updated according to the re-cent process executions. The input parameters of the algorithm are a YAWL net N ,an event log with traces referring to past executio n of instances of this process, and a fault function. The output is a function  X  that associates each condition with the opportune function estimator. Initially, in line 1, we initialize function I which is going to asso-ciate each condition c with the set of observation instances relative to execution of tasks observation instances. While replaying, a function A keeps the current value X  X  assign-C of the contextual information (line 5) and compute the elapsed time d (line 6). Then, we build an observation instance J where tuple A ( t i ,r i , d ) C is the observed input and the fault severity f (  X  ) is the observed output. This observation instance is put into the set of observation instances relative to each condition c  X   X  t i . In lines 11-13, we update the current value X  X  assignment during the replay, i.e. we rewrite function A .Fi-nally, in lines 16-19, we build each function estimator  X  c for condition c by the relative observation instances and rewrite  X  s.t.  X  ( c )=  X  c .

At run-time, function  X  is used to predict the risk and, hence, to provide recommen-dations. In fact, function  X  is input for Algorithm 2, which produces the recommen-dations for a set of tasks T relative to a given process instance, in which a sequence  X  of events has occurred. The input of the algorithm also contains a function A that associates each instance X  X  variable v with the corresponding value A ( v ) in the state reached after executing the events in sequence  X  . The algorithm X  X  output is a function that associates each task t  X  X  with the relative risk. For each task t  X  X  , the algo-elapsed d e since the execution has started, an d the contextual information C (line 6). Then, for each function estimator  X  c associated with each condition in the preset of t , we find the expected fault X  X  severity y and the expectation X  X  likelihood l such that  X  ( x 1 ,...,x n ,l )= y .Thevalue y  X  l is the risk associated with the instance if t is per-formed and consumes a token from c . The risk associated with continuing the execution by performing t is the maximum with respect to all conditions from which tokens are consumed when t is executed. We operationalized our technique for the YAWL system by extending a visual plug-in for the YAWL worklist handler and by implementing a new custom YAWL service. The YAWL system [18] is an open source workflow management system which is based on the workflow patterns 3 and uses a service-oriented architecture.
The intent of our technique is to  X  X rive X  participants during the execution of a process instance. This goal can be achieved if participants can easily understand a proposed suggestion. In order to do this, we extended a previous visual plug-in for YAWL [7] for decision support, named Map Visualizer . This plug-in provides a graphical user interface to suggest the tasks to execute, along with assisting during their execution. The tool is based on two orthogonal concepts: maps and metrics. A map may can be a geographical map, a process model, an or ganizational diagram, etc. For each map, tasks can be visualized by dots which are located in a meaningful position (e.g., for a geographic map, tasks are projected onto the locations where they need to be executed, or for a process-model map onto the corresponding tasks in the model). Dots can also be colored according to certain metrics, which determine the suggested level of priority of a task to be executed. Typically, workflow management systems are only equipped with basic client applications where work items available for execution are simply listed, possibly sorted according to given criteri a. When users are confronted with hundreds of items, this visualization does not scale, since it becomes very hard to choose a work item in such a  X  X ungle X . By projecting the work items onto meaningful maps, they are organized in a more systematic way, thus facilitating the choice even when hundreds are offered. The validity of the metaphors of maps and metrics was confirmed through a set of experiments, as reported in [7].

However, de Leoni et al. [7] only define very basic metrics. Here, we have extended the repertoire of metrics with a new metrics that is computed by employing the tech-nique described in Section 4.

Figure 4(a) shows a screenshot of the Map Vi sualizer where a risk-based metric is employed. The map shows the process model using the YAWL notation and dots are projected onto the corresponding element of the model. Each dot corresponds to a dif-ferent task and is colored according to the risk s for the three faults defined before. When multiple dots are positioned at the same coordinates, they are merged into a single larger dot whose diameter grows with the number of dots being amalgamated. According to the analysis reported in [7], the possible colors go from white to black, passing through intermediate shades of yellow, orange, red, purple and brown. The white and black colors identify tasks associated with a ris k of 0 and 1, respectively. The screenshot in Fig. 4(a) refers to a configuration where multiple process instances are being carried on at the same time and, hence, the tasks refer to different process instances. The con-figuration of dots highlights that the risk is lower if the process participant performs the task Estimate Trailer Usage , Arrange Pickup Appointment or Arrange Delivery Ap-pointment for a certain instance. When clicking on the dot, the participant is shown the process instance of the relative task(s). As mentioned in Sections 1 and 4, the activity of compiling a form is also supported. Figure 4(b ) shows a screenshot where, while filling in a form, participants are shown the risk associated with that specific input for that form via a vertical bar (showing a value of 45% in the example). While a participant changes the data in the form, the ris k value is recomputed accordingly.

Besides the extension to the Map Visualizer, we implemented a new custom service for YAWL, namely the Prediction Service . This service provides risk-aware prediction and recommendation. It implements the technique described in Section 4 and constructs decision trees through the implementation of the C4.5 algorithm of the Weka toolkit for data mining. 4 The prediction service communicates with the Log Abstraction Layer de-scribed in [5], to be able to retrieve event logs from textual files, such as from OpenXES event logs, or from the database that is used by YAWL, storing both historical informa-tion and the current system X  X  state. The Prediction Service is invoked by the Map Vi-sualizer to obtain the risk predictions and recommendations. The map visualizer works together with the standard Worklist Handler provided by YAWL to obtain the up-to-date distribution of work to resources. Figure 5 shows the diagram of these connections. We evaluated the technique using the Carrier Appointment example described in Section 2. We used CPN Tools 5 to simulate the process model and the resource behavior. We performed three sets of experiments with different faults. First, we only used a composite fault that includes reputation fault and overtime fault with maximum cycle time d mct of 21 hours. Then, we also included the cost overrun fault. Precisely, we set the d mct to 25 hours, and the minimum process instance cost c min to 85% of the value of the good sold. Finally, we made the overtime and cost overrun faults more stringent by decreasing d mct to 21 hours and c min to 70%.
 For each set of experiments, we randomly generated 2,000 log traces with CPN Tools, which we used to train the function e stimators. In fact, these traces are rela-tive to process instances that do not follow any suggestion, for which we also computed the severity of the different composite fau lts as mentioned in the previous paragraph. Then, we generated 200 new log traces following the recommendations proposed by our tool. Figure 6 shows the results comparing the fault X  X  severity when recommendations are and are not followed. It is worth highlighting how the results are given in terms of severity measured for completed instances. Risks are relative to running instances and estimate the expected fault X  X  severity and likelihood when such instances complete.
In all three experiments, our tool significantly reduced the number of instances ter-minating with faults, as evidenced by the result of the Person X  X   X  2 test (see Table 1):  X  for the second experiment, and  X  2 (1) = 22 . 344 ,p &lt; 0 . 001 for the third experiment. Indeed, based on the odds ratio , the odds of an instance terminating with a fault are respectively 71 . 46 , 6 . 42 ,and 2 . 8 times higher if they are executed randomly than if following our suggestions. Moreover, the overall severity for instances executed ran-domly (first experiment Median =0 . 25 , second experiment Median =0 . 15 and third experiment Median =0 . 3 ) is significantly higher than the overall severity for instances executed following our suggestions (first experiment Median =0 . 1 , second experiment Median =0 . 05 and third experiment Median =0 . 2 )asshowedbythe Mann-Whitney test (see Table 1): U = 261 , 534 . 5 , z =7 . 22 , p&lt; 0 . 001 for the first experiment, U = 129 , 334 . 5 , z =  X  8 . 32 , p&lt; 0 . 001 for the second experiment, and U = 160 , 466 . 5 , z =  X  4 . 63 , p&lt; 0 . 001 for the third experiment. Various risk analysis methods have been defined which provide elements of risk-aware process management. Mean time, academics have recognized the importance of manag-ing process-related risks. However, risk analysis methods only provide guidelines for the identification of risks and their mitigations, while academic efforts mostly focus on risk-aware BPM methodologies in general, rather than on concrete approaches for risk prevention [17]. For a comprehensive review of approaches and methods for managing and analyzing process risks, we refer to the survey in [17].

An exception is made by the works of Pika et a l. [13] and Suriadi et al. [16]. Pika et al. propose an approach for predicting overtime risks based on statistical analysis. They identify five process risk indicators whereby the occurrence of these indicators in a trace indicates the possibility of a delay. Suria di et al. propose an approach for Root Cause Analysis based on classification algorithms. After enriching a log with information like workload, occurrence of delay and involvement of resources, they use decision trees to identify the causes of overtime faults. The cause of a fault is obtained as a disjunc-tion of conjunctions of the enriching information. Despite looking at the same problem from different prospectives, these two approaches result to be quite similar. The main difference between them and our technique is that we use risk prediction as a tool for providing suggestions in order to prevent the eventuation of faults, while they limit their scope to the identification of indicators of risks or of causes of faults. Moreover, both approaches do not consider the data prospective and have only been designed for overtime risks.

Our work shares commonalities with reco mmendation and Decision Support Sys-tems (DSSs), since it provides recommendations to process participants to make risk-informed decisions. Our technique fully em braces the aim of these systems to improve decision making within work systems [2], by providing an extension to existing process-aware information systems. In this area, Dey [8] describes how DSS can be used for risk management. He also uses decision trees despite those trees are manually generated as a final step of brainstorming sessions and used only as a reference when risks occur.
Operational support is an emerging field of research in process mining, which shares commonalities with DSSs. Operational support c oncerns three dimensions: detection, prediction and recommendation [1]. In this paper, we focus on the latter two dimen-sions. Prediction is about forecasting which faults are likely to be reached at the end of the process instance and with what severity. Recommendation concerns enacting the appropriate actions to prevent faults from occurring. We dealt with run-time risk detec-tion in previous work [5]. Regarding prediction, van der Aalst et al. [19] propose an approach to predict the remaining cycle time till the end of the execution of a process instance on the basis of the process control-flow, while Folino et al. [10] use decision trees to improve the remaining cycle time estimation by also taking process data into account. Unfortunately, both approaches only focus on time, which is, in fact, linked to one possible cause of process fault (i.e. the overtime fault). Our technique is more generic since we aim to predict customizable faults relative to d dimensions, e.g. cost or reputation. Westergaard et al. propose protocols and infrastructures for providing recommendations during process executions [12]. However, concrete recommendation algorithms are out of scope. We proposed a technique that allows process participants to make risk-informed deci-sions when taking part in a business process. The technique relies on a risk estimator trained using historical information ext racted from the process log. For each state of a process instance where input is required from a process participant, the estimator determines the severity and likelihood that a fault (or set of faults) will occur if the participant X  X  input is going to be used to carry on the process instance.

We designed the technique in a language-i ndependent manner and implemented it as a Web service. This service can train r isk estimators by importing process logs in the standard OpenXES format or directly fro m the database of a workflow management system like YAWL. The service was linked t o the YAWL system as a proof-of-concept. Specifically, we extended the Map Visualizer plug-in of YAWL so that risk predictions can be visualized as colored circles on top of tasks, indicating the likelihood and severity of faults. We also extended the YAWL user form visualizer. Based on the data inserted by the participant, a risk profile is shown. Thi s way, participants are offered risk-based recommendations when selecting the next task to execute or filling out a form.
We simulated a large process model based on an industry standard for logistics and generated event logs for it. We then executed three experiments with different faults and fault conditions in order to obtain different fault distributions and used this log to train our risk estimator. We simulated ne w process instances according to the recom-mendations provided by our risk estimator and measured the number and severity of the faults upon instance completion. In all experiments we were able to significantly reduce the number of faults and their severities provided that the simulated users followed the recommendations provided by our technique. And while this shows that the technique is effective, it has to be considered as an upper-bound result, since in reality it might not always be feasible to follow the recommendations provided.
 The technique suffers from some limitations that will be addressed in future work. First, it lacks an empirical evaluation of its usefulness with domain experts. We are plan-ning to overcome this problem by performing experiments with risk analysts and pro-cess participants of a large Australian insurance company. Second, the technique does not support user decisions involving inter-instance or inter-process data, but only looks at single business processes. For example, the technique can be extended to support process administrators in taking risk-in formed decisions when (re)allocating resources to tasks, potentially belonging to instances of different processes. Finally, we plan to also investigate different machine-learning techniques to build function estimators, e.g. Bayesian networks or the k-means algorithm, to evaluate the algorithm that provides, in many situations, the most accurate pr edictions and, hence, recommendations.
