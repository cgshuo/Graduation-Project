 Click logs provide a unique and highly valuable source of human judgments on ads X  relevance. However, clicks are heavily biased by lots of factors. Two main factors that are widely acknowledged to be the most influential ones are neighboring ads and presentation order. The latter is re-ferred to as positional effect. A popular practice to recover the ads quality cleaned from positional bias is to adopt click models based on examination or cascade hypothesis origi-nally developed for organic search. In this paper we show the strong evidence that this practice is far from perfection when considering the top ads block on a search engine result page (SERP). We show that cascade hypothesis is the most questionable one because of important differences between organic and sponsored search results that may encourage users to analyze the whole ads-block before clicking. Addi-tionally, we design a testing setup for an unbiased evaluation of click model prediction accuracy.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Performance, Measurement Sponsored search; positional effect; click model; experiment
The main source of income of major search engines is sponsored search. The set of ads to be shown and their order of presentation depend on the bid of the advertiser for the matched keywords and the estimated click-through rate (CTR) of the ads. Thus it is vital to perform CTR prediction as precisely as possible in order to maximize the search engine X  X  revenue by selecting the  X  X ight X  ads to show and keep the ad-selecting mechanism fair for advertisers.
Click logs contain regularly refreshing real users X  assess-ments on relevance of documents and ads circulating in a search engine system. But extracting these judgments from logged data is not a trivial task as clicks are heavily biased with respect to presentation order, neighboring ads, user traits, etc., so the direct estimation of CTR may lead to inadequate results.

One of the most studied problems is position bias. The ex-amination hypothesis [6] suggests that the click occurs iff the link is both relevant and examined. The cascade hypothesis [3] assumes that user scans the results from top to bottom making decisions whether to continue examination or quit the search session based on the relevance of the current link.
Most of the research in positional effects falls into the field of organic search. And the common practice is to adopt or-ganic search click models to advertisements through mod-ifications addressing sponsored search peculiarities such as click sparsity and users X  negative bias [9, 2]. But there is a reasonable doubt that users scanning through sponsored links exercise the kind of behavior just slightly different from that when analyzing organic search results. Mainly because the differences between organic and sponsored results lie far beyond lower clicks rates of ads. At first sight, the top ads block is just an extension of the organic search results. But there are some fundamental distinctions. It is outlined, compact (just 3 or 4 positions at most) and well observed. Another crucial peculiarity is that content of ad block is homogeneous by nature: same goods, similar offers, indis-tinguishable prices, especially, when competition for a set of keywords is intense. Thus users seem to analyze the whole block and compare the offers.

The aim of this paper is to demonstrate conditions under which the cascade-based model fails and is outperformed even by simple examination-hypothesis-based ones which were shown to be inferior in later works [9]. Thus, we ques-tion the practice of applying organic search click models to ads and provide a detailed rationale for modeling much more complicated externalities of neighboring ads. Also we reveal the drawbacks of model assessment techniques utilized in previous works on positional effect that may have caused the misleading results. At Yandex we designed and con-ducted an experiment on a part of search engine audience to collect test data that is really challenging for positional click models. We demonstrate the superiority of this method of evaluating model X  X  performance.
In this section we introduce two main positional hypothe-ses: examination and cascade ones.
Examination hypothesis [6] assumes that given a query q a click on a link u at position i happens iff the link is both relevant and examined. The model assumption is expressed as factorizing the probability of click into two multipliers. One depends only on a link u and a query q thus representing relevance or quality of a document. The other depends solely on position and can be thought of as a penalty for landing this low in the results. Or formally:
P ( C = 1 | u,i,q ) = P ( C = 1 | u,q,E = 1) where C is a binary click event and E is a hidden binary variable taking the value 1 when a link u at position i is examined.
Under the assumption of cascade model [3] user scans the results from top to bottom until she finds a link she was looking for and clicks immediately abandoning the search session. Thus cascade model is formally described by the following set of equations: where E i , C i are binary events that a link at the i -th po-sition is examined and clicked respectively, r u i ,q vance or quality of a link u that landed at position i given query q . More recent cascade-based models basically just remove the unrealistic restriction of one click per query ses-sion by modifying the expression for conditional probability P ( E i +1 = 1 | E i = 1 ,C i ).
In this section we define the click models that will be used in the experiments.
Let X  X  define a simple linear model based on examination hypothesis. The model is defined by the following equation: where  X  u,q , e i , b and  X  are independent Gaussian random variables corresponding to the following quantities respec-tively: relevance of ad u to query q ; penalty for landing on the i -th position; bias; standard normal noise.

Strictly speaking, equation (3) is not in exact correspon-dence with examination hypothesis (1) but fundamentally idea is the same. The probability of click depends on two independent variables:  X  u,q which represents relevance of ad u to query q and e i which estimates how likely the user will examine position i . It is worth noting that this model strongly resembles the adPredictor described in [4]  X  a CTR predicting click model actually implemented in Bing X  X  pro-duction environment.
General Click Model (GCM), described in [9], generalizes cascade model by defining the following transition probabil-ities: where in our case continuous random variables A i , B i , R will be modeled as: where all the summands are independent Gaussian random variables with b -variables being the biases and  X  -variables being standard normal noise.

We chose GCM as a cascade-based model because of its capability to fit a much wider range of user behavior allowing all the transitions probabilities to depend on a current ad-query pair. In contrast with the original paper, we do not introduce any additional user or ad features as our goal is testing the model assumptions on user behavior rather than achieving maximal accuracy.
Both models were implemented under the Infer.NET frame-work [5]. The inference procedure for both models goes in strict correspondence with the [9]:
In this section we proceed on peculiarities of the data set used.
We collect four-day click log data from Yandex search en-gine. We limit ourselves to the top ads block on the first page of a search session. Moreover only sessions with fully packed top ads block are considered  X  at Yandex full block comprises 3 ads. Under this kind of setup the positional ef-fects should be the most pronounced. A total of 11,701,043 sessions are collected with an average of 13.19 impressions per ad and 7.42 impressions for ad-query pair.

A recent research in Yandex [1] showed that there are strong positional effects in the top ads click log data, so training a positional click model is not a pointless task. We collect two different test sets.

Data for the first test set is collected from the experi-ment conducted on a small portion of Yandex search engine audience. During this experiment the top ads block was ran-domly shuffled (uniformly over all 3! permutations) before revealing it to user. In the regular setting ads do not change their positions that often, but in shuffled data each ad will appear on each position almost evenly. So in order to per-form well on such test set a model should accurately predict CTR for every ad on all of the positions. This experimental click log is collected immediately after the last session from train dataset.

As a second test set we take a regular click log from Yan-dex with sessions that happened right after the last session in the training set.
 Each test set comprises 1,491,357 sessions.

To illustrate the difference between two test sets we eval-uate the following statistic. For each ad we measure the dispersion of the number of times this ad appeared at each position and average these dispersions over all ads in the test set. Low values of this statistic demonstrate that ads appear on all of the positions almost uniformly, while high values show that ads tend to stick to a certain position. The first test set has D 1 and for the second test set D 2 , the value of among positions much more uniformly.
We train all the models in consideration on the same train-ing set. Then we conduct two different experiments. The first experiment is designed to show the flaws of the regular test set. The aim of the second is to justify the doubts in the cascade hypothesis in the top ads block.

We use Log-Likelihood (LL) as measure of models X  predic-tion accuracy. The LL of a single ad impression is evaluated as l = c  X  log( p ) + (1  X  c )  X  log(1  X  p ), where c equals 1 if the ad was clicked and 0 otherwise, p is predicted CTR. The LL of test set is an average LL over all the ad impressions over all the sessions. The improvement of LL value l 1 over value l is evaluated as (exp( l 1  X  l 2 )  X  1)  X  100%.
The GCM model (inherently from Cascade Model) as-sumes the top-to-bottom order of examination: the 1-st, the 2-nd and then the 3-rd position. But let X  X  train all the 3! = 6 models considering all possible examination orders.
Evaluation on the regular test set is presented in Fig-ure 1a. All 6 models differ in accuracy negligibly with a bizarre  X 2,1,3 X -order being in the lead. While evaluation on the experimental test set, shown in Figure 1b, clearly states that  X 1,2,3 X -order is the most probable scenario. The ex-planation is simple. In the regular test set the ads appear predominantly in the same positions as in the training set, so the prediction task simplifies significantly as a portion of unseen events is quite small and almost any model of ex-amination can be fit accurately. One can consider this as a lack of independence between train and test data. Whereas the experimental test set puts model assumptions to a real test. It demands from a model to deduce transition and click probabilities from learned distribution at points previously unobserved.
We compare performance of GCM and GLM on two test sets. In order to make our conclusions more assertive we evaluate the relative accuracy of two models on several sub-sets of test sets. We leave in the test set only those sessions Figure 1: Log-Likelihood Improvement of different orders of examination over the baseline  X 1,2,3 X -order on the regular (a) and the experimental (b) test sets. Note the different scales of axes on figures (a) and (b). in which each of the three ads has the number of impres-sions in the training set not less than a certain threshold for values of threshold from 0 to 100.

The LL improvement of GCM over GLM is shown in Fig-ure 2. The improvement is negative, thus GCM is outper-formed by GLM on both test sets under all values of thresh-old. Moreover a distinctive trend can be observed  X  dif-ference between two models increases as we restrict the test set to the ads that have a larger amount of impressions. For ads with a significant amount of statistics a simple linear model (like GLM) becomes quite certain about their  X  X nbi-ased relevance X  by averaging their performance on different positions. With such an estimate on ad quality the straight-forward positional penalty becomes good enough to slightly improve the prediction accuracy. While GCM makes strong assumptions on user behavior which do not seem to hold in practice, thus producing much less accurate results even for ads with a great number of impressions. In other words, the bias of the model assumptions themselves makes a much stronger impact on the learned ad X  X  relevance than the po-sitional effect.

Additionally, Figure 2 shows another advantage of exper-imental test set over the regular one. As we already showed in the experiment #1 even the most odd model assump-tions could perform well on a not perfectly independent test set. This result is further strengthen during the second ex-periment as GCM and GLM perform almost equally on the different subsets of regular test data. Whereas experimen-tal data reveals the flaws of the models much more explic-itly. When the threshold on ads impressions increases GCM looses to GLM with a noticeable margin. Hence the cascade Figure 2: Log-Likelihood Improvement of GCM over GLM hypothesis appears to be even less realistic than examina-tion one producing inaccurate predictions even for ads with sound statistics.
Let X  X  give a rationale for why the cascade hypothesis may not hold in the top ads block.

Firstly, the top ads block itself is compact and emphasized center of attention above the organic search results. With a small number of positions in a full block it is fully observ-able by user instantly and without scrolling. Additionally, sponsored results often include lots of distinctive details like: direct links to refined sections of advertiser X  X  web-site; work-ing hours; an address and a phone number; nearest subway station; pictographs of a company X  X  logo; etc. All these fac-tors motivate user to analyze the full block before clicking, or just immediately steal user X  X  attention to a certain ad even if it is not at the first position. Therefore, users often neither examine results from top to bottom nor click before seeing the lower ads.

Secondly, the contents of ads block are fundamentally dif-ferent from the organic results. The ambiguousness of most search queries encourages to diversify the organic search re-sults to satisfy multiple possible user X  X  intents. Whereas in sponsored search the commercial intent is often precise. And if it is not, search engine is bound by obligation to show only those ads that matched certain keywords in the query. Thus the ads block is much more homogeneous than the or-ganic search results. Especially for popular purely commer-cial queries where competition among advertisers is really intense and tight. So users do not seem to scan through the results until the link matches their intent but tend to choose between similar offers before making a click.
There are two main results of this work. Firstly, we demon-strate that commonly used test sets for positional click mod-els are not challenging enough and can lead to inadequate results. We suggest a testing setup providing much more fair and transparent evaluation results: all the ads should appear at all the positions evenly.

Secondly, we argue that the positional effect in the top ads block cannot be accurately modeled by adopting the organic search click models. We design an experimental setup where the cascade-based model loses in accuracy to the examination-hypothesis-based model that is considered quite unrealistic even in organic search field. Therefore in our future work we will focus on click models that consider complex neighboring ads externalities and allow user to com-pare the offers (like in [7, 8]). [1] D. Arkhangelsky, S. Izmalkov, and D. Khakimova. On [2] A. Ashkan and C. L. A. Clarke. Modeling browsing [3] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An [4] T. Graepel, J. Q. Candela, T. Borchert, and [5] T. Minka, J. Winn, J. Guiver, and D. Knowles.
 [6] M. Richardson, E. Dominowska, and R. Ragno.
 [7] X. Xin, I. King, R. Agrawal, M. R. Lyu, and H. Huang. [8] C. Xiong, T. Wang, W. Ding, Y. Shen, and T.-Y. Liu. [9] Z. A. Zhu, W. Chen, T. Minka, C. Zhu, and Z. Chen. A
