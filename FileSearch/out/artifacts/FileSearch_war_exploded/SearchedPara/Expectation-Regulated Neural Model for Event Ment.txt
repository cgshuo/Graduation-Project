 A Distributed Denial of Service (DDoS) attack em-ploys multiple compromised systems to interrupt or suspend services of a host connected to the Internet. Victims are often high-profile web servers such as banks or credit card payment gateways, and there-fore a single attack may cause considerable loss. The aim of this paper is to build an automatic system which can extract DDoS event mentions from social media, a timely information source for events taking place around the world, so that the mined emerging incidents can serve as early DDoS warnings or signs for Internet service providers.

Ritter et al. (2015) proposed the first work to ex-tract cybersecurity event mentions from raw Twitter stream. They investigated three different event cat-egories, namely DDoS attacks , data breaches and account hijacking , by tracking the keywords ddos , breach and hacked , respectively. Not all tweets con-taining the keywords describe events. For example, the tweet  X  X ive me paypall or i will tell my mum and ddos u X  shows a metaphor rather than a DDoS event. As a result, the event mention extraction task involves a classification task that filters out true events from all tweets that contain event keywords. Two main challenges exist for this task. First, the numbers of positive and negative examples are typ-ically unbalanced. In our datasets, only about 22% of the tweets that contain the term ddos are men-tions to DDoS attack events. Second, there is typ-ically little manual annotation available. Ritter et al. (2015) tackled the challenges by weakly super-vising a classification model with a small number of human-provided seed events.

In particular, Ritter et al. exploit expectation regularization (ER; Mann and McCallum (2007)) for semi-supervised learning from large amounts of raw tweets that contain the event keyword. They show that the ER approach outperforms semi-supervised expectation-maximization and one-class support vector machine on the task. They build a logistic regression classifier, using few human-labeled seed events and domain knowledge on the ratio between positive and negative examples for ER in training. Results show that the regulariza-tion method was effective on classifying unbalanced datasets.

Ritter et al. use manually-defined discrete fea-tures. However, the event mention extraction task is highly semantic-driven, and simple textual pat-terns may suffer limitations in representing subtle semantic differences between true event mentions and false cases with similar word patterns. Recently, deep learning received increasing research attention in the NLP community (Bengio, 2009; Mikolov et al., 2013; Pennington et al., 2014; Kalchbrenner et al., 2014; Vo and Zhang, 2015). One important advantage of deep learning is automatic representa-tion learning, which can effectively encodes syntac-tic and information about words, phrases and sen-tences in low-dimensional dense vectors.

In this paper we exploit a deep neural model for event mention extraction, using word embeddings and a novel LSTM-based neural network structure to automatically obtain features for a tweet. Results on two human-annotated datasets show that the pro-posed LSTM-based representation yields significant improvements over Ritter et al. (2015). In terms of scope, our work falls into the area of in-formation extraction from social media (Guo et al., 2013; Li et al., 2015). The proposed event men-tion extraction system is domain-specific, similar to works that aim at detecting categorized events such as disaster outbreak (Sakaki et al., 2010; Neubig et al., 2011; Li and Cardie, 2013) and cybersecu-rity events (Ritter et al., 2015). Such work typi-cally trains semi-supervised classifiers to determine events of interest due to the limitation of annotated data. On the other hand, a few studies devote to open domain event extraction (Benson et al., 2011; Rit-2012; Chierichetti et al., 2014; Li et al., 2014; Qiu and Zhang, 2014), in which an event category is not predefined, and clustering models are applied to au-tomatically induce event types.

In terms of method, the proposed model is in line with recent methods on deep learning for neu-ral feature representations, which have seen success in some NLP tasks (Collobert and Weston, 2008; Collobert et al., 2011; Chen and Manning, 2014). Competitive results have been obtained in sentiment analysis (Kalchbrenner et al., 2014; Kim, 2014; Socher et al., 2013b), semantic relation classifica-tion (Hashimoto et al., 2013; Liu et al., 2015), and question answering (Dong et al., 2015; Iyyer et al., 2014). In addition, deep learning models have shown promising results on syntactic parsing (Dyer et al., 2015; Zhou et al., 2015) and machine trans-lation (Cho et al., 2014). Compared to syntactic problems, semantic tasks see relatively larger im-provements by using neural architectures, possible because of the capability of neural features in bet-ter representing semantic information, which is rel-atively more difficult to capture by discrete indicator features. We consider event mention extraction as a semantic-heavy task and demonstrate that it can ben-efit significantly from neural feature representations. We take the method of Ritter et al. (2015) as a base-line. Given a tweet containing the keyword ddos , the task is to determine whether a DDoS attack event is mentioned in the tweet. A logistic regression classi-fier is used, which is trained by maximum-likelihood with ER on unlabeled tweets, and automatically gen-erated positive examples from a few seed events. 3.1 Seed Events Ritter et al. (2015) manually pick seed events, repre-sented as ( ENTITY , DATE ) tuples, and treated tweets published on DATE referencing ENTITY as positive training instances. For example, ( GitHub , 2013 July  X  X amosie GitHub is experiencing a large DDos https://t.co/cqEIR6Rz6t X  posted on 2013 July 29 is seen as an event mention since it contains the EN -TITY GitHub as well as matches the DATE 2013 July 29. Those tweets with the word ddos but not match-ing any seed events are grouped as unlabeled data. 3.2 Sparse Feature Representation Each tweet is represented by a sparse binary vec-tor for feature extraction, where the features con-sist of bi-to five-grams containing a name entity or the event keyword. For better generalization, all
Table 1: Features of a tweet by Ritter et al. (2015). words other than common nouns and verbs are re-placed with their part-of-speech (POS) tags. Ta-ble 1 shows an example of contextual features ex-tracted from the tweet  X  X amosie GitHub is experi-encing a large DDos https://t.co/cqEIR6Rz6t X . As can be seen from the table, the features contain shal-low wording patterns from a tweet, which are local to a 5-word window. In contrast, the observed aver-age tweet length is 16 words, with the longest tweet containing 48 words, which is difficult to fully rep-resent using only a local window. Our neural model addresses the limitations by learning global tweet-level syntactic and semantic features automatically. 3.3 Logistic Regression Classification with With the feature vector ~ f s  X  R d defined for a given tweet s , the probability of s being an event mention is defined as: where ~  X   X  R d is a weight vector.

Given a set of event mentions M =  X  m 1 ,m 2 ,...,m j  X  and a set of unlabeled instances U =  X  u 1 ,u 2 ,...,u k  X  , Ritter et al. (2015) train an ER model that maximizes the log-likelihood of positive data while keeping the conditional probabilities on unlabeled data consistent with the human-provided expectations. The objective function is defined as: The expectation regularization term  X (  X  p,  X  p U fined as the KL divergence between the model X  X  pos-terior predictions on unlabeled data,  X  p U human-provided label expectation priors,  X  p : We follow Ritter et al. (2015), using a set of seed events and large raw tweets for ER. However, we take a fully-automated approach to find seed events, since manual listing of seed DDoS events can be a costly and time consuming process, and requires a certain level of expert knowledge.

We leverage news articles to collect seed events, representing events as ( ENTITY , DATE RANGE ) tu-ples. The ENTITY in our seed events is defined as a name entity that appears in either the assailant or victim role of an attack event labeled by frame-semantic parsing, and the DATE RANGE is a date window around the news publication date. We use a date window rather than a definite news publication date because news articles are not always published on the day a DDoS attack happened. Some examples are given in Figure 1.

We parse DDoS attack news collected from frame-semantic parsing system (SEMAFOR; Das et al. (2010)). Tweets are gathered using the Twitter word ddos . Name entities are extracted from both news articles and tweets using a Twitter-tuned NLP
Table 2 shows two example DDoS attack news, where the ENTITY values are included in the vic-tim roles, RBS , Ulster Bank , GovCERT and FBI in the first news, and Essex in the second. It is worth noting that the DDoS attack on RBS, Ulster Bank and Natwest was actually on 2015 July 31. The cor-relation between tweet mentions and news reports are shown in Figure 1, where each bar indicates the Table 2: Example news sentences where victim roles are in italic and ENTITY is in bold.
 Figure 1: Visualization of the numbers of tweets mentioning Ulster bank (on the left) and Essex (on the right) around the news publication dates. number of tweets (y-axis) containing a certain EN -TITY posted on a certain DATE (x-axis). Accord-ing to these, we used a 11-day (-3,7) window cen-tered at the news publication date for extracting pos-itive training instances. Experiments show that our method can find seed events with 97% accuracy. The overall structure of our representation learning model is shown in Figure 2. Given a tweet, two LSTM models (Section 5.1) are used to capture its sequential semantic information in the left-to-right and right-to-left directions, respectively. For deep Figure 2: Architecture of the proposed neural tweet representation model.
 Figure 3: LSTM-based text embedding for word vectors x 1 ,x 2 ,...,x n . semantic representation, each LSTM model can in-clude multiple stacked layers. Neural pooling (Sec-tion 5.2) is performed on each LSTM layer to ex-tract rich features. Finally, features from the left-to-right and right-to-left components are combined using neural tensors (Section 5.3), and the resulting features are used as inputs to a feed-forward neural network for classification (Section 5.4). 5.1 LSTM Models The main goal of our neural model is to find dense vector representations for tweets, which are effec-tive features for event mention extraction. Starting from word embeddings (Mikolov et al., 2013; Pen-nington et al., 2014), a natural way of modeling a tweet is to treat it as a sequence and use a recur-rent neural network (RNN) structure (Pearlmutter, 1989). LSTM (Hochreiter and Schmidhuber, 1997) is a variant of RNNs, which is better at exploit-ing long range context thanks to purpose-built units called memory blocks to store history information. LSTM has shown improvements over conventional RNN in many NLP tasks (Jozefowicz et al., 2015; Graves et al., 2013b; Cho et al., 2014).

A typical LSTM memory block consists of three gates (i.e. input , forget and output ), which con-trol the flow of information, and a memory cell to store the temporal state of the network (Gers et al., 2000). While traditionally the values of gates are decided by the input and hidden states in a RNN, we take a variation with peephole connections (Gers and Schmidhuber, 2000), which allows gates in the same memory block to learn from the current cell state. In addition, to simplify model complexity, we use coupled forget and input gates (Cho et al., 2014).
Figure 3 illustrates the memory block used for our tweet representation. The network unit activations for input x t at time step t are defined by the follow-ing set of equations: Gates at step t : f t = 1  X  i t (5) Cell: Hidden State: h t = o t  X  tanh ( c t ) (8) The W terms in Equations 4 X 7 are the weight matri-ces ( W ic and W oc are diagonal weight matrices for peephole connections); the b terms denote bias vec-tors;  X  is the logistic sigmoid function; and  X  com-putes element-wise multiplication of two vectors. i t , f t and o t are input , forget and output gates, respec-tively; c t stores the cell state, and h t is the output of the current memory block.

Inputs For the inputs x 1 ,x 2 ,...,x n , we learn 50-dimension word representations using the skip-gram algorithm (Mikolov et al., 2013). The train-ing corpus was collected from the tweet archive site, and a total of 604,926,764 tweets were used. Each tweet was tokenized using a tweet-adapted to-kenizer (Owoputi et al., 2013), and stopwords and punctuations are removed. The trained model con-tains 5,251,332 words.
 Layers Recent research has shown that both RNNs and LSTMs can benefit from depth in space (Graves et al., 2013a; Graves et al., 2013b; Sak et al., 2014; Sak et al., 2015). A deep LSTM is built by stacking multiple LSTM layers, with the output sequence of one layer forming the input se-quence for the next, as shown in Figure 2. At each time step the input goes through multiple non-linear layers, which progressively build up higher level representations from the current level. In our tweet representation model, we embody a deep LSTM ar-chitecture with up to 3 layers. 5.2 Pooling Given a LSTM and an input sequence x 1 ,x 2 ,...,x n , using the last state h n as features is a basic repre-sentation strategy for the sequence. Apart from this approach, another common feature extraction strat-egy is to apply pooling (Boureau et al., 2011) over all the states h 1 ,h 2 ,...,h n to capture the most char-acteristic information. Pooling extracts fixed dimen-sional features from h 1 ,h 2 ,...,h n , which has vari-able length. In our model we consider different pool strategies, including max , average and min poolings. For convenience of writing, we refer to the basic fea-ture strategy also as basic pooling in later sections. When there are multiple LSTM layers, the features consist of the pooling results from each layer, con-catenated to give a single vector. 5.3 Neural Tensor Network for Feature Given the pooling methods, we extract features r f and r b for the forward and backward multi-layer LSTMs, respectively. Inspired by Socher et al. (2013a), we use a neural tensor network (NTN) to combine the bi-directional r f and r b  X  R d . The network can be formalized as follows: and b ntn  X  R q are the weight matrix and bias vector, respectively, as that in the standard form of a neural a vector v  X  R q , where each entry is computed by one slice of the tensor: Table 3: The three false positives in the 100 auto-matically extracted mentions, where EVENT ENTI -TIES are in bold.

The NTN combined features are concatenated, and fed into a tanh hidden layer. The output of the layer, ~ f s , becomes the final representation of a tweet, and is used to compute the probability of the tweet being an event mention, as shown in Equation 1. 5.4 Classification The final classifier of the neural network model is Equation 1, consistent with the baseline model. As a result, ER is applied in the same way as Equa-tion 2. The main difference between our model and the baseline is in the definition of ~ f s , the former be-ing a deep neural network and the latter being man-ual features. Consequently, Equation 1 can be re-garded as a softmax layer in our deep neural model, for which all the features and parameters are trained automatically and consistently.

For training, the parameters are initialized uni-formly within the interval [  X  a , a ], where H k and H k +1 are the numbers of rows and columns of the parameter, respectively (Glorot and Bengio, 2010). The parameters are learned using stochas-tic gradient descent with momentum (Rumelhart et al., 1988). The model is trained by 500 iterations, in each of which unlabeled instances are randomly sampled so that the same numbers of positives and unlabeled data are used. 6.1 Data We streamed tweet with the track kayword ddos for five months from April 13 to September 13, 2015. In addition, we extracted tweets containing the word ddos from a tweet archive 5 in the period from September 2011 to September 2014. Using the distant seed event extraction scheme described in Section 4, a total number of 930 mentions cover-ing 45 ENTITY were automatically derived. In order to examine whether the automatically-collected in-stances are true positives and hence form a useful training set, an author of this paper annotated 100 extracted mentions finding that that 3 are false pos-itives, as listed in Table 3. The result suggests that the automatically extracted mentions are reliable.
The remaining tweets were randomly split into a 200-instance development set, a 800-instance test ment and test sets were annotated by a human judge and an author of this paper. The inter-annotator agreement on the binary labeled 1000 instances was measured by using Fleiss X  kappa (Fleiss et al., 2013), and the score, which is 0.85 for the data, represents almost perfect agreement according to Landis and Koch (1977). There were 47 out of the 1,000 tweets that received different labels, for which another hu-man judge made the final decision.

To test the applicability of the proposed men-tion extraction system on other domains, we col-lected 400 sentences containing the keyword ddos from dark web. Again each sentence was annotated by two human judges, and the third person made the final decision on conflicting cases. The inter-annotator agreement kappa score on this dataset is 0.85, consistent with the tweet annotation. Table 4 presents the statistics of the datasets. 6.2 Evaluation We follow Ritter et al. (2015) and evaluate the performance by the area under the precision-recall curve (AUC), where precision is the fraction of re-trieved instances that are event mentions, and re-
Table 5: AUCs of different model architectures. call is the fraction of gold event mention instances that are retrieved. Precision-recall (PR) curves offer informative pictures on the classification of unbal-anced classes (Davis and Goadrich, 2006). 6.3 Development Experiments For the proposed model, we empirically set the LSTM output vector h t , the NTN output V , and the the human-provided label expectation prior  X  p is set to 0.22 since the percentage of positives in the de-velopment set is 22%, and the parameter  X  U is set to 6.3.1 Feature Combination
We first test whether using a NTN to combine the bi-directional representations can give a better performance compared to simply concatenating the two representation vectors. Table 5 gives AUCs of one-layer basic , max , avg and min pooling strategies tested on the tweet development set. We can see that all the four different pooling strategies perform bet-ter when the NTN combination is used. As a result, for the following experiments we only consider us-ing NTNs to combine bi-directional representations.
Next we observe the effect of using different num-bers of LSTM layers in our model. AUCs of basic , max , avg and min pooling strategies with respect to 1, 2 and 3 LSTM layers are presented in Table 5. In most of the cases, the performance of the model increases when the LSTM architecture goes deeper, and we build our final models using 3 LSTM layers. 6.3.2 Pooling Strategies
In the previous experiments, max pooling achieves the highest AUC with the architecture 3-LSTM-layer+NTN, we are interested in whether combining max with other pooling strategies would further increase the performance. Table 6 summa-rizes the AUC of various combinations, according to which we choose max+basic for final tests.
Finally, we test the performance of sparse fea-ture representations as used in the model of Ritter et al. (2015). Figure 4 shows the PR curves of the sparse representation and the best setting max+basic evaluated on the development set. The AUC of using sparse representation is 0.30 while that of the max+basic model is 0.51. The runtime perfor-mances of training with sparse feature representa-tions and neural feature representations are 276.17 and 1137.87 seconds, respectively, running on a sin-gle thread of an Intel Core i7-4790 3.60GHz CPU. 6.4 Final Test Figure 5 presents the PR curves of the baseline sparse feature representation and the final neural model evaluated on the datasets, and Table 7 gives the AUC for these test-set evaluations. From the curves we can see that the sparse representation is comparatively less efficient in picking out negative examples, since at a lower recall the model does not gain a higher precision. In contrast, LSTM-based representation demonstrates a better trade-off be-tween recall and precision. We do not have a strong intuition on why the performance on dark web test set is better than that on tweet test set for the pro-posed model. 6.5 Analysis Table 8 shows the top 5 and bottom 5 ranked dark proposed LSTM-based model, respectively. For each sentence, the human judgment ( P for event mentions and N for non-event mentions) is given, followed by the probability values output by the baseline and the proposed system.

Only one of the top five most probable event-mentioning sentences as decided by the baseline is true positive. On the other hand, all of the top five sentences indicated by the proposed model are true positives. We investigate the contextual features that contribute to the false positive case  X  X hey dealt with the ddos attacks with grace and confidence. X  deter-mined by the baseline, and find that the patterns  X  X T ddos X ,  X  X dos attack | NN X ,  X  X T ddos attack | NN IN X  among the 15,355 contextual patterns, respectively, which have relatively high weights but only carry
Figure 6: Probability distributions on the test sets. limited information. In contrast, the LSTM-based model can capture global syntactic and semantic fea-tures other than words surrounding ddos to distin-guish mentions from non-mentions. From the table we can see that those high-confidence sentences de-termined by the LSTM-based model are more infor-mative compared with those lower ranked sentences.
Figure 6 presents the probability distributions of positive and negative test cases as obtained by the baseline (x-axis) and the LSTM-based model (y-axis), respectively. It can be seen from the fig-ures that the probabilities determined by the LSTM-based model are scattered between 0.0 and 1.0, while those by the baseline are gathered between 0.5 and 0.9, which shows that the proposed neural model can achieve better confidence on classifying event mentions. This demonstrates its stronger dif-ferentiating power as compared with discrete indi-cator features, as hypothesized in the introduction. In addition, for the proposed model a large portion of true positives ( N ) are close to the top in both test sets, while more negatives (  X  ) gather at the bottom of the dark web test set plot, compared to that in the tweet test set. As for the baseline model, many negatives locate around the horizontal centre, with a probability of 0.5, in the tweet test set, which ex-plains why the baseline is relatively less effective on the precision-recall trade-off. We investigated LSTM-based text representation for event mention extraction, finding that automatic fea-tures from the deep neural network largely improve the sparse representation method on the task. The model performance can further benefit by exploiting deep LSTM structures and tensor combination of bi-directional features. Results on tweets and dark web forum posts show the effectiveness of the method. We would like to thank Geoffrey Williams for data annotation, Lin Li for data processing, and anony-mous reviewers for their informative comments. Yue Zhang is the corresponding author.

