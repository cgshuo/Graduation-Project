 Recommender systems use collaborative filtering to generate recommendations by predicting what users might be interested in, given some user X  X  profile. Several prominent online commercial sites (e.g. amazon.com and ebay.com) offer this kind of recommendation services.

There are two different recommendation ta sks typically considered: (i) pre-dicting the ratings, i.e. how much a given user will like a particular item, and (ii) predicting the items, i.e. which N items a user will rate, buy or visit next (topN).

For RSs, nearest-neighbor methods, called collaborative filtering (CF ; [7]), is the prevalent method in practice. On the other hand, methods that rely only on attributes and disregard the rating information of other users, are commonly called the Content-Based Filtering (CBF). They have shown to perform very poorly. Yet, attributes usually contain valuable information; hence it makes it desirable to include attribute information in CF models  X  so called hybrid collaborative/content-based filtering methods.
 There are many proposals on how to integrate attributes in CF for ratings. For instance, few others attempt linear combination of recommendation of CBF and CF predictions [5, 8, 10, 16]. There also exists methods that apply a CBF and a CF model sequentially, i.e. predict ratings by means of CBF and then re-estimate them from the completed rating matrix by means of CF [13]. There are also further proposals on how to integrate attributes when the problem is viewed as a classification problem [3, 4, 19]. As we lose the simplicity of CF, we do not consider those more complex methods here. We have selected three basic methods that predict items and try to keep the simplicity of CF, but still should improve prediction results.

When evaluating these recommendation algorithms, suitable datasets of users and items have always been demanding, especially when diversity of public data is limited. To compare the recommendation quality of different algorithms, it is not enough to evaluate the algorithms on just one or two datasets. Instead, one should investigate the behavior of the algorithms as systematic changes are applied to the data. Although there are already few attempts in generating syn-thetic data for the use in RS, to our best knowledge, there is no prior approach in generating synthetic data for evaluating recommender algorithms that incor-porate attributes.

In this paper, we will make the following contributions: (i) we will propose our Synthetic Data Generator which produces user-item and user/item-attribute datasets and introduce the use of entropy to measure the randomness in the arti-ficial data, (ii) we will survey some of the existing hybrid methods that consider attribute information in CF for predicting items. In addition, (iii) we will con-duct empirical evaluations on three existing hybrid recommendation algorithms and other state-of-the-art algorithms using the generated synthetic data and observe their behavior when the characteristic of attribute data varies. One of the most widely known Synthetic Data Generators (SDG) in data mining is the one provided by the IBM Quest group [2]. It mimics the  X  X eal X  world transactions in the retailing environment. It generates data with a structure and was originally intended for evaluating association rule algorithms. Later on, Deshpande and Karypis used this SDG for evaluating their item-based top-N recommendation algorithm [6]. Popescul et . al have proposed a simple approach by assigning a fixed number of users and items into clusters evenly and draw a uniform probability for each user and item in each cluster [17]. A similar attempt has been done for Usenet News [11, 14] as well as Aggarwal et . al for their horting approach [1]. Traupman and Wilensky tried to reproduce data by introducing skewed data to the synthetic data similar to a real dataset [20]. Another approach is to produce datasets by first sampling a complete dataset and re-sample the data again by missing data effect [12].

The focus of this paper is to investigate SDG for CF algorithms which consider attributes. To the best of our knowledge, there is no prior attempt in examining SDGs for hybrid RS algorithms. The SDG can be divided into two phases: drawing distributions and sampling data. In the first phase, it draws distribution of User Cluster ( UC )andItem Cluster ( IC ), next it affiliates UC or IC with user/item attribute respectively as well as to associate the UC and IC . Using these generated correlations, the users, items, ratings and item/user-attribute datasets can then be produced in the second phase. Fig. 1 presents an overview of how the artificial data are generally structured. 3.1 Drawing Distributions To create the ratings and attributes datasets, we generate five random distribu-tions models:  X  P ( UC ), how users are distributed in N number of UC .  X  P ( IC ), how items are distributed in M number of IC .  X  P ( A | UC )  X  UC , how user attributes (A) are distributed in UC .  X  P ( B | IC )  X  IC , how item attributes (B) are distributed in IC .  X  P ( UC | IC )  X  IC ,how UC are distributed in IC .  X  q be the probability that an item in IC i is assigned to UC j
The SDG first draws P ( UC )and P ( IC ) from a Dirichlet distribution (with parameters set to 1). This asserts that the sum of P ( UC )or P ( IC )formsto one. P ( B | IC ) shows the affiliation of item attributes with the item clusters by drawing from a special Chi-square distribution rejecting values greater than Algorithm 1. Drawing distribution Algorithm 2. Drawing Special  X  2 distribution with specified entropy values 1. Likewise, the correlation between UC and IC , P ( UC | IC ), as well as the correlation between user attr ibutes and user clusters, P ( A | UC ), are done with similar manner. However, the attribute-aware CF algorithms we discuss in this paper do not take user-attributes into account. The overall drawing distributions process is summarized in (Algo. 1.).

By virtue of the randomness in those generated models, it is necessary to control or to measure the informativeness of these random data. Hence, we apply the Information Entropy and compute the average normalized entropy of the models.
 The conditional entropy for the item-attribute data therefore is:
In our experiment, P ( B | IC ) is sampled eleven times for eleven different en-tropy values from 0 to 1 with 0.1 interval. By rejection sampling, P ( B | IC ) is drawn iteratively with various C hi-square degrees of freedom until H ( B | IC ) reaches desired entropies (Algo. 2.). Other types of distribution have also been examined, yet, Chi-square distribution has shown to give the most diverse en-Algorithm 3. Sampling data tropy range. We expect that as the entropy increases, which implies the data is less structured, the recommenda tion quality should decrease. 3.2 Sampling Data Once these distributions have been drawn, users, items, ratings and item-attributes data are then sampled accordingly to those distributions. Firstly, users are assigned to user clusters by random sampling from P ( UC ). Similar procedure, applies for sampling items. The user-item(ratings) data is generated by first sample P (
UC l | IC k ) of users belonging to UC l who prefer items in IC k , then sample q portion of items of IC k to these sampled users. The affiliation between items and attributes is done by sampling P ( B | IC ) of items which contain attribute B .The same procedure can be applied to generate the user-attributes datasets. The overall sampling data process is summarized in (Algo. 3.). Here, we discuss three existing hybrid methods [21], which will be evaluated using the data generated from the SDG. 1. Sequential CBF and CF (Adapted Content-Boosted CF), 2. Joint Weighting of CF and CBF, and 3. Attribute-Aware Item-Based CF.

Sequential CBF and CF is the adapted version of an existing hybrid ap-proach, Content-Boosted CF, originally proposed by [13] for predicting ratings. This method has been conformed to the predicting items problem here. It first uses CBF to predict ratings for unrated items and then filters out ratings with lower scores (i.e. keeping ratings above 4 on a 5-point scale) and applies CF to recommend topN items.
 Joint Weighting of CF and CBF (Joint-Weighting CF-CBF), first applies CBF on attribute-dependent data to infe r the fondness of users for attributes. In parallel, user-based CF is used to predict topN items with ratings-dependent data. Both predictions are joint by computing their geometric mean.
Attribute-Aware Item-Based CF (Attr-Item-based CF) extends item-based CF [6]. It exploits the content/attribute information by computing the similarities between items using attribut es thereupon combining it with the sim-ilarities between items using ratings-dependent data.
All three approaches recommend items that contain the highest frequency of their neighboring items. For the last two algorithms,  X  is used as a weighting factor to vary the significance applied to CF or CBF. In this section, we presen t the evaluation of the selected attributes-aware CF algorithms using artificial data generated by SDG discussed in Section 3 and compare their performances with their corresponding non-hybrid base models, which do not integrate attributes, i.e. user-based and item-based CF, as well as to observe the behavior of the algorithms after supplement of attributes. Metrics. Our paper focuses on the item prediction problem, which is to predict a fixed number of top recommendations and not the ratings. Suitable evaluation metrics are Precision, Recall and F1.

Similar to Sarwar et al. [18], our evaluations consider any item in the recom-mendation set that matches any item in the testing set as a  X  X it X . F1 measure is then used to combine Precision and Recall into a single metric.
 Parameters. Due to the nature of collaborative filtering, the size of neighbor-hood has significant impact on the recommendation quality [9]. Thus, each of the randomly generated data should ha ve an assorted neighborhood sizes for each method. In our experiments, we have selected optimal neighborhood sizes and  X  parameters for the hybrid methods by means of a grid search. See Ta-ble 1. Lambda is used to weight the contribution of attribute-dependent and rating-dependent models. Threshold and max, for the Sequential CBF-CF are set to 50 and 2 accordingly as chosen in the original model [13]. For more detail explanation of the parameters used in those algorithms, please refer to [21] and [13].

As our algorithms do not consider user attributes, our SDG only generates models for item attributes. The parameter settings for our experiments are sum-marized in Table 2.
 Experimental Results. In our experiments, we have generated five different trials. For each trial, we produce one dataset of user-item (ratings) and eleven different item-attributes datasets with increasing entropy from 0-1 with 0.1 interval, by rejection sampling. In addition, to reduce the complexity of the experiment, it is assumed that the correlation between the user and item clusters to be fairly well-structure and have a constant entropy of 0.05. The results of the average of five random trials where only item-attributes with entropy of 0.05 are presented in Fig. 2.

As shown in Fig. 2, Joint-Weighting CF-C BF achieves the highest Recall value by around 4% difference w.r.t. its base method. On the other hand, Attr-Item-based CF does not seem to be effective at a ll as attributes are appended to its base model. It also has a very high standard deivation. This suggests that the algorithms to be rather unstable and unreliable. Although Melville et al. [13] reported that Content-Boosted CF performed better than user-based and pure CBF for ratings, it fails to provide quality top-N recommendations for items in our experiments. Therefore, we will focus our evaluation on the other two algorithms in the rest of the paper.

As the aim of the paper is to examine the behavior of the models as the char-acteristic of data varies, what is more important is to observe the performance as entropy varies. As anticipated, the recommendation quality increases, when there exists more structure in the data. The results of an average of five random trials of item-attribute datasets with eleven various entropies are presented in Fig. 3.

We can see that for both Attr-Item-based CF and Joint-Weighting CF-CBF algorithms, the quality of recommendation reaches its peaks when the entropy approaches zero and it gradually decrea ses as entropy increases. As for Attr-Item-based CF, although it carries th e right entropy trend, its peak does not surpass its base model and the quality drops gradually below its base model, which does not make use of attributes. On the other hand, for Joint-Weighting CF-CBF, the value of recall descends gradually as the entropy raises, still the recall maintain above its base-model until entropy approaches 1 where recall plummets to below its base-line score. The aim of this paper is to conduct an empirical evaluation on three exist-ing hybrid recommendation models and other state-of-the-art algorithms with data generated by the SDG presented in this paper. All algorithms discussed here focus on the predicting items problem. Joint-Weighting CF-CBF, appears to enhance recommendations quality when reasonable amount of informative attributes are presented. The other algorithms do not seem to be sensitive to attributes. Yet, we expect the outcomes could be ameliorated by adding more structural dependency between clusters. In addition, currently the data are only controlled by the entropy of item-attribute datasets; however, other distributions such as the user-item data should also be investigated when various entropies are considered. Further more, more extensive experiments should be done to exam-ine the effect of varying other parameters settings and to conduct an empirical evaluation with models that predict ratings.

