 With the advent of social media, the ways in which people comm u nicate their com-ments, feedback and critiq u es have chan g ed dramatically. They can now post reviews and opinions on disc u ssion topics, prod u cts, services, policies and other iss u es and over 340 million tweets per day [1].  X  X weets X  as one of pop u lar Web data reflects u sers  X  emotions and attit u des on al-most every topic for which they can find readers and listeners [2]. As a res u lt, senti-tions and citizen  X  s g ro u ps [1]. 
Sentiment analysis can be u sed to characterize a u ser  X  s attit u de towards a topic or iss u e of interest based on the identification of patterns of reactions that can be discov-Sentiment patterns hidden within comments, feedback and critiq u es often provide u sef u l information that can be levera g ed for different p u rposes [1]. One example is to obtain the data shared by Internet u sers reflectin g their sentiments toward services or prod u cts to help improve prod u ct or service q u ality. 
Sentiment patterns can be cate g orized into vario u s types, for example, positive, very g ood, g ood, satisfactory, bad, and very bad [6]. Sentiment pattern analysis can be tho ug ht of as a pattern-detection and classification task in which each cate g ory takes on the form of a sentiment pattern [3]. 
Sentiment-classification methods can be broadly cate g orized into two main classes: lexicon-based and machine-learnin g -based methods. The lexicon-based method de-entire text based on handlin g the u se of these words or phrases that appear in the lex-semantic ambi gu ity. 
The other class is a learnin g -based approach that derives the relationship between classification res u lts compared to simple lexicon-based approaches and is widely u sed [9,10]. However, it is diffic u lt to improve the performance of s u ch machine-learnin g methods even there are eno ug h trainin g datasets [11]. Therefore, how to increase the classification acc u racy of machine-learnin g -based methods thro ug h improved know-led g e and desi g n has been a key concern for many researchers [11] . 
Several enhancements, i.e., feat u re selection [12,13,14], ne g ation dealin g [10] ,[15] lem. While these enhancements have been employed previo u sly, how they perform alon g side the different machine-learnin g methods has not been well researched. Therefore, from this paper, we seek to demonstrate how these enhancement tech-niq u es can improve the efficacy and acc u racy in sentiment classification of Web data for the machine-learnin g methods st u died. Amon g the many existin g machine-learnin g -based methods, the methods of na X ve Bayes (NB) [18,19] Maxim u m Entropy (MaxEnt) [20] and s u pport vector machine (SVM) [21,22] are chosen for investi g a-tion in this paper, beca u se these have been commonly applied in text data analysis. channel within which to collect all kinds of cross-sectional data. Web data can be downloaded directly from the web or collected by u sin g vario u s application pro-g rammin g interfaces (A P Is) and web crawlers that are provided by third parties. 
We made u se of two types of dataset: (1) data downloaded directly from third par-ties and (2) data collected u sin g an A P I. 
For the first type of dataset, we downloaded the data from a  X  X witter-sentiment-analyzer X  website which contained 1.6 million pre-classified tweets prepared as part of a research effort [23]. We downloaded ds_10k, ds_20k, ds_40k, ds_200k, ds_400k and ds_1400k which consisted of 10k, 20k, 40k, 200k, 400k and 1.4m pre-classified tweets respectively. 
We also downloaded movie-review data [24] for u se in sentiment-analysis experi-ments. This is a collection of 1000 positive and 1000 ne g ative processed movie-review doc u ments labeled with respect to their overall sentiment polarity. 
Twitter provides an A P I that allows easy access to tweets. Usin g the GET search/tweets reso u rce, we co u ld search for tweets on a specific topic or keyword and limited to a specific g eo g raphical re g ion and also to a specific lan gu a g e. Sentiment patterns derived from p u blic domain social media data may be indica-tors of chan g es that can have ne g ative and potentially serio u s conseq u ences, as is the case with worsenin g social sentiment related to p u blic transportation, the de g radation keyword  X  X RT X  (for  X  X ass Rapid Transit X ) in Sin g apore. We u sed location-collection and analysis of s u ch data can help g overnment a g encies and other or g aniza-tions to u nderstand p u blic attit u des toward u rban transportation services thro ug h sen-timent analysis. 
Since a trainin g data set or a set of pre-classified data was necessary for machine-learnin g -based methods, the collected data need ed to be pre-classified to obtain Sin g apore  X  s MRT service from citizens and residents, two social scientists with do-main expertise in MRT performance were tasked to extract relevant tweets. Ei g ht assistants with different back g ro u nds (e. g . st u dents and researchers from the National They performed the classification tasks independently. 
We compared and analyzed the classifications of the ei g ht annotators and fo u nd that the coincident percenta g es amon g them were between 80.1% and 86.8%. Differ-ent people have different u nderstandin g s for the same tweet. We selected the tweets that the annotators g ave the same classifications and excl u ded the ones that different tained h u man annotated datasets (HA data) to g ether with the downloaded pre-classified data were both u sed to test the enhancement of the classifiers. 
We separated each type of dataset obtained into a trainin g set and a testin g set, con-tainin g three-q u arters and one-q u arter of the entities respectively. Sentiment classification can be described as a process in which a classification al g o-variety of machine-learnin g -based methods, s u ch as na X ve Bayes (NB) classifier, Maxim u m Entropy (MaxEnt) classifier and s u pport vector machine (SVM), etc. 
Na X ve Bayes classifier is a probabilistic classifier that ass u mes the statistical inde-m u la [18,19]: is the prior probability of instance d occ u rrin g . classifier, is a f u nction defined as follows [18,19]: ood of the trainin g data. wei g hts  X  : The difference between these two probabilistic classifiers, Na X ve Bayes and Max-Ent classifier, can be seen from Eqn. 1 and 3. 
SVM is a non-probabilistic classifier that works by constr u ctin g a decision s u rface on a hi g h-dimensional space [21,22]. The principle of the SVM al g orithm is to find a decision s u rface, named hyperplane that optimally splits the trainin g set. The trainin g data are mapped to a very hi g h-dimensional space. Then, the al g orithm finds the g ro u ps [21] . 
The decision f u nction is defined as follows: formance of SVM [21], [26]. We have tested different parameters and fo u nd that for this problem, the best parameter selection is when svm_type is  X  X -SVC X  (m u lti-class classification) and kernel_type is  X  X INEAR X . 
In this paper we explore these three machine-learnin g methods, and inte g rate fea-pare the conformance of the machine-learnin g methods. 
We started with a basic implementation of each of these machine-learnin g classifi-enhancement techniq u es, incl u din g feat u re selection [12,13,14] ne g ation dealin g [10] and emoticon handlin g [16,17]. 3.1 Feature Selection The main diffic u lties of the implementation of the machine-learnin g classifiers are the perform the task u sin g machine-learnin g methods when dealin g with hi g h dimension sions, it also removes irrelevant, red u ndant, and noisy data [13]. 
C h i S q ua re feat u re selection can be described as followin g : contain the feat u re, f , and do not belon g to cate g ory, c . (Eqn. 1) and only top n feat u res were selected. 3.2 Negation Dealing D u rin g h u man comprehension of a sentence, ne g ative words/phrases s u ch as  X  X o not  X  , tence [10]. For example,  X  X ove  X  is a positive word, b u t it does not make the sentence positive in  X  X  do not love this X . Two ways of dealin g with ne g ation words are consi-dered in this paper. (1) Appendin g a NEGATE to the word directly after the ne g a-tion word (NEGdword) and (2) appendin g a NEGATE to all words after the ne g ation word u ntil reachin g a p u nct u ation mark (NEGall). 3.3 Emoticon Handling Analyzin g the collected tweets, it was observed that emoticons were very often u sed by the Twitter u ser and presented the orientation of the sentiment of the tweets [17]. emoticons as shown in Table 1. We considered only these emoticons beca u se they are widely u sed and have no ambi gu o u s meanin g . Analyzin g the data collected, we fo u nd that there were sometimes ne g ative emoticons in positive comments. Typin g errors ass u med that the chance of mistypin g an emoticon was low. ^_^ ^-^ &lt;3 xD XD v.v V_V and false ne g ative ( F n ) assi g ned classes. 
Tp refers to the n u mber of correctly identified positive. Fp is refers to the n u mber of incorrectly identified positive. Similarly, T n refers to the n u mber of correctly iden-tified ne g ative. F n is refers to the n u mber of incorrectly identified ne g ative. and it is g iven by: 
Recall is the n u mber of tr u e positive o u t of the act u al positive doc u ments, and it is g iven by: F-meas u re is a wei g hted method of precision and recall, and it is obtained as: Acc u racy is calc u lated u sin g the followin g form u lae: 
One or more of those items are selected by different research g ro u ps to disc u ss the performance [9], [27]. For real-world data analysis, the acc u racy of the al g orithm is paper, the disc u ssion is foc u sed on the acc u racy of the classifiers. 5.1 Basic Implementation of Machine-Learning Methods Table 2 shows the res u lts obtained by the basic implementation of each of these clas-witho u t levera g in g any enhancement. There is no feat u re selection, ne g ation dealin g , and emoticon handlin g enhancements involved in this basic implementation. 
The res u lts show that the acc u racies of these machine-learnin g methods are similar at abo u t 70%. 
The res u lts of other lar g er datasets are not listed here beca u se they cannot be com-lon g for other classifiers, s u ch as MaxEnt). 5.2 Machine-Learning Methods with Feature Selection and Negation Dealing In order to enhance the efficiency of the ba sic classifiers developed in Section A, only the top n feat u res were selected. This selection ens u red more common or hi g h-freq u ency words were selected. As shown in Table 3, the selection enabled the clas-into memory limits, which we mark as  X - X  in the tables. 
Table 4 and Table 5 show the res u lts obtained by u sin g NEGdword and NEGall techniq u es respectively. 
Comparin g Table 4 and Table 5, the acc u racy of SVM is 74.17% u sin g NEGd-word, hi g her than the 73.65% obtained by u sin g NEGall, when u sin g ds_40k dataset. memory X  problems. 
For NB and MaxEnt classifiers, the acc u racy fl u ct u ated between 72.90% and 77.30% when inte g ratin g NEGword for classifyin g different dataset, while, the acc u -racy fl u ct u ated between 72.97% and 77.28% when inte g ratin g NEGall. The res u lts in shorter sentence str u ct u res that tweets have. 
In order to f u rther investi g ate the effect of the two ne g ation-dealin g techniq u es, we tested both the NEGdword and NEGall desi g n for classifyin g more complicated and lon g er data, s u ch as movie-review data. 
The tweet data was simpler and shorter than the movie-review data since Twitter [27]. 
The res u lts for classifyin g movie-review data are shown in Table 6. For these more complicated data, u sin g NEGall was better than NEGdword for SVM and NB, while different for MaxEnt. 
Overall both NEGall and NEGdword showed similar improved performance of as tweets. B u t, for more complicated data, NEGall and NEGdword co u ld work differently. NEGdword 8000 82.80% 81.20% 81.80% 
NEGall 8000 84.00% 81.60% 81.20% 5.3 Machine-Learning Methods with Feature Selection and Emoticon The pre-classified dataset we downloaded from the web does not incl u de emoticons. As mentioned in Section 3, tweets were extracted u sin g the Twitter A P I, which were classified by ei g ht annotators into positive and ne g ative tweets with and witho u t con-sideration of the text emoticons. The acc u racy of the different classifications is shown in Table 7. 
It is observed from Table 7 that the acc u racy of SVM classifiers increased from 61.11% to 75.00%. The acc u racy of NB classifiers increased from 66.67% to 69.44% and for MaxEnt increased from 72.22% to 75.00%. Th u s, emoticon handlin g has improved the performance of all the classifiers. 5.4 Further Discussions on the Enhancem ent of Machine-Le arning Methods views), the acc u racy of the three classifiers was different, with hi g her acc u racy when tent with o u r previo u s experience that machine-learnin g classifiers are domain specif-ic [12]. It is not easy to create a domain-independent machine-learnin g classifier while trainin g the classifiers on a domain-mixed set of data [8]. 
It is well known that besides domain dependency, there are other disadvanta g es in g the appropriate machine-learnin g method, modifyin g and dealin g with u nbalanced very u sef u l and pop u lar tools for classification tasks. 
C u rrently, we are also workin g on lexicon-based sentiment-classification methods, hybrid methods (combinin g lexicon and machine learnin g ), r u led-based methods, and emotion-pattern methods to develop more powerf u l tools for sentiment classification. O u r experience shows that the cr u cial problem is the acc u racy of the classifiers. hancement and classification methods be established to do the work acc u rately and reliably. This research explores and improves on c u rrent machine-learnin g -based classification methods by inte g ratin g several enhancement desi g ns in the classification process. 
Selection of the most informative feat u res is a cr u cial addition that g reatly increas-es memory efficiency and shortens trainin g time. In dealin g with ne g ation, NEGone and NEGall prod u ce similar performance when dealin g with tweet data, b u t g ive dif-performance of the classifiers. O u r analysis res u lts indicate that in dealin g with tweet datasets, of the three machine-learnin g methods, NB and MaxEnt are the best choices memory footprint. 
This paper demonstrates the viability and applicability of u sin g enhancements for vario u s machine learnin g -based methods. Investi g ations into lexicon-based sentiment classification methods incl u din g the u se of colloq u ial words and other local characte-ristics are in pro g ress. Acknowledgements. The work is s u pported by A*STAR Joint Co u ncil Office Devel-NUS hi g h school of Mathematics and Science and X u efen g BAI from National Uni-versity of Sin g apore for their assistance and inval u able help in cond u ctin g this st u dy.
