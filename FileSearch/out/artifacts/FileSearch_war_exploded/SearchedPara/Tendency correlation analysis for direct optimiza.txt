 Abstract Direct optimization of evaluation measures has become an important branch of measures can really lead to the optimization of the original IR evaluation measures. In this work, we perform formal analysis on this issue. We propose a concept named  X  X  X endency correlation X  X  to describe the relationship between a surrogate measure and its corresponding tendency correlation with an IR evaluation measure, the optimization of it will lead to the dency correlations of the surrogate measures optimized in a number of direct optimization methods. We prove that the surrogate measures in SoftRank and ApproxRank can have arbitrarily strong tendency correlation with the original IR evaluation measures, regardless rogate measures in SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG cannot have arbitrarily strong tendency correlation with the original IR evaluation measures on certain distributions of data. Therefore SoftRank and ApproxRank are theoretically sounder than SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG , and are expected to result in better ranking performances. Our theoretical findings can explain the experimental results observed on public benchmark datasets.
 Keywords Tendency correlation Direct optimization Information retrieval measures Learning to rank 1 Introduction Learning to rank is to automatically learn a ranking model from training data through the (Voorhees and Harman 2005 ) and Normalized Discounted Cumulative Gain (NDCG) evaluate the ranking performance. The approach, however, is also challenging since most ranking model parameters, and thus difficult to optimize (Xu et al. 2008 ).
To tackle this problem, many methods have been proposed, which optimize some et al. 2005 ). The same idea was extended to optimize NDCG and Mean Reciprocal Rank structured SVM was used to optimize these bounds. The IR evaluation measures covered include Winner Takes All (WTA), MRR, Discounted Cumulative Gain (DCG), NDCG, Precision, and Expected Rank Utility (ERU). In Xu et al. ( 2008 ), different concave lower et al. ( 2008 ) were proposed as surrogate measures and were also optimized by structured SVM. In Taylor et al. ( 2008 ) and Guiver and Snelson ( 2008 ), the deterministic relevance NDCG value was used as the surrogate measure for optimization. In Qin et al. ( 2010 ), the discrete positions of the documents were approximated by using a sigmoid function of their relevance scores and then the approximates of MAP and NDCG based on the smoothed positions are used as surrogate measures for optimization.
 accordance with our intuition since all these methods are designed to optimize IR evalu-We believe that the good understanding of these empirical results can help us find the root cause of the effectiveness of a direct optimization method, and select effective algorithms for practical use.

In this work, we argue that different ranking performances of the methods come from the differences in the surrogate measures that they use. In particular, we hypothesize that measures and thus can effectively optimize the IR evaluation measures, while the surrogate measures in some other methods are less correlated and cannot always lead to effective optimization of the IR evaluation measures. In order to test this hypothesis, we propose using the concept of  X  X  X endency correlation X  X , which can quantize the relationship between a surrogate measure and its corresponding IR evaluation measure.

The  X  X  X endency X  X  of a function with respect to two inputs is defined as the difference in the values of the function at the two inputs. A positive value of the difference corresponds to an increasing tendency and a negative value corresponds to a decreasing tendency. For entire input space, denoted as e , can be minimized. Accordingly, we name e with respect to relation between the two functions is strong, otherwise, we say that the tendency corre-lation is weak.

It is clear that the surrogate measures and the IR evaluation measures can be regarded as functions of the documents, their relevance labels, and the ranking model. Therefore, we can use the concept of tendency correlation as defined above to quantify the relationship between a surrogate measure and an IR evaluation measure. In this work, we prove that when the tendency correlation between a surrogate measure and an IR evaluation measure is arbitrarily strong (i.e., e ? 0), the ranking model corresponding to the global optimum of the surrogate measure will converge to the model corresponding to the global optimum of the IR evaluation measure.
 optimization methods. 1 First, we prove that the surrogate measures optimized in SoftRank NDCG , Approx-Rank MAP , and ApproxRank NDCG can have arbitrarily strong tendency correlation with the measure will also have many local optima when it has very strong tendency correlation global optimum of such a surrogate measure, by simply using the gradient based methods adopted in SoftRank NDCG , ApproxRank MAP , and ApproxRank NDCG . In other words, for measure that has strong tendency correlation with the original IR evaluation measure and adjusting the trade-off (through tuning the parameters in these algorithms and using global optimization technologies), these algorithms can eventually perform very well on various datasets. This well explains previous empirical observations.
 Second, we prove that the surrogate measures optimized in SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG cannot always have arbitrarily strong tendency correlation with the original IR evaluation measures, especially on certain kinds of data. In such case, although these methods can effectively find the global optimum of the surrogate measure, based on the structured SVM technology, they may not find the global optimum of the IR evaluation measure at the same time due to their weak tendency correlation. Note that the explains the previous empirical observations that these methods do not perform well on some datasets.

As far as we know, our work is the first to formally and strictly present the theoretical answers to the issue whether the optimization of a surrogate measure can lead to effective optimization of the original IR evaluation measure. Our findings provide a guideline for selecting and tuning direct optimization methods, which is very helpful for the research and development on learning to rank.
 popular IR evaluation measures are introduced in Sect. 2 . In Sect. 3 , popular direct opti-perform discussions around it in Sect. 4 . Based on the  X  X  X endency correlation X  X , we analyze the goodness of the surrogate measures optimized in popular direct optimization methods are discussed in Sect. 7 . 2 Learning to rank for IR ciated with a set of documents d  X  i  X   X f d  X  i  X  1 ; ... ; d  X  i  X  n L x j  X  /  X  q sometimes also call the parameter x a ranking model) is a ranking model that can output a ranked list ^ y given a set of documents x , where X is the input space of the documents and Y is the output space of permutations over the documents. Note that in practice, a scoring function f : R n ! R is usually employed to assign a score to each document first and then the documents are sorted to output the ranked list ^ y . In this case, h  X  sort f .
The goal of the training process is to learn the optimal parameter x through the opti-d in y . If we assume that we can access the label information through y , the above defined objective function can cover the loss functions in most existing learning to rank algorithms as its special cases.

In the test process, given a new query q associated with documents represented as To evaluate the correctness of the prediction, several IR evaluation measures, such as MAP performances.

MAP is defined as the mean of Average Precision (AP) over a set of queries, where AP is defined as follows, with respect to the case when L = 2, documents of query q .
 The definition of NDCG is as below,  X  1  X  r j  X  and DCG max is a normalization factor. If the summation in NDCG is truncated at position k , the corresponding measure is called NDCG@ k .

A lot of learning to rank algorithms have been proposed in recent years, which can be roughly categorized into two approaches. The first approach attempts to obtain the ranking evaluation measures. Typical algorithms include Cossock and Zhang ( 2006 ), Burges et al. second approach attempts to obtain the ranking model by optimizing surrogate loss functions that are highly related to the IR evaluation measures. Typical algorithms include optimization methods. As far as we know, there are no conclusions on whether one optimization methods have become an important branch of learning to rank and are attracting more and more attentions from the researchers in this area. Therefore, it makes sense to perform deep investigation on such kind of methods and provide insights on them to practitioners who will use these methods. Motivated by this, in this paper, we focus on the theoretical analysis on the direct optimization methods. 3 Direct optimization methods Many direct optimization methods have been proposed in recent years. In this section, we DORM NDCG (Le and Smola 2007 ), PermuRank MAP (Xu et al. 2008 ), SoftRank NDCG (Taylor et al. 2008 ), SVM NDCG (Chakrabarti et al. 2008 ), ApproxRank MAP , and Approx-Rank NDCG (Qin et al. 2010 ). For ease of description, we use the following notations. Given corresponding IR evaluation measure. 3
Please note that we have not included LambdaRank (Burges et al. 2007 ) and AdaRank (Xu and Li 2007 ) in our study, alghouth their objective functions are also related to the IR mized by LambdaRank is actually a weighted pairwise loss according to Chapelle ( 2009 ), but not a surrogate function of the IR evaluation measures. Second, there is actually no surrogate measure in AdaRank since the objective function optimized by AdaRank is exactly the IR measure (optimizing the exponential function of the IR measure is math-ematically equivalent to optimizing the IR measure). 3.1 SVM MAP SVM MAP was proposed in Yue et al. ( 2007 ). The key idea is to adopt structured SVM (Yue measure optimized in SVM MAP is 4 where Here C x and C x are the sets of relevant and irrelevant documents, in which the documents otherwise.

By using structured SVM, the ranking model was obtained by resolving the following optimization problem, DORM was proposed in Le and Smola ( 2007 ) which can handle the optimization of many IR evaluation measures, such as WTA, MRR, DCG, NDCG, Precision@n, and ERU, with the help of structured SVM. In this work, we take DORM NDCG as an example, which aims to optimize NDCG. In this specific case, the surrogate measure is a concave lower bound of NDCG, defined as below, where
By using structured SVM, the ranking model was obtained by resolving the following optimization problem, 3.3 PermuRank MAP PermuRank was proposed in Xu et al. ( 2008 ). The key idea is also to adopt structured SVM to optimize concave lower bounds of MAP and NDCG. Here we take PermuRank MAP as an example, in which the surrogate measure is as follows. where Here y y ij equals to ? 1 when d i is ranked higher than d j in y , and -1 otherwise.
By using structured SVM, the ranking model was obtained by resolving the following optimization problem, 3.4 SoftRank NDCG ment score of d j is a random variable S j whose distribution follows Pr  X  S j  X  s  X  X  lowing recursive process. rank of d j is r when there are i documents in the ranked document list. Based on the rank distribution, the surrogate measure, which is a continuous approximation of NDCG, was defined as below, SVM NDCG was proposed in Xu et al. ( 2008 ). The key idea is to adopt structured SVM to optimize a concave lower bound of NDCG. Specifically, the surrogate measure optimized where
By using structured SVM, the ranking model was obtained by resolving the following optimization problem, 3.6 ApproxRank MAP and ApproxRank NDCG evaluation measure from  X  X  X ndexed by positions X  X  to  X  X  X ndexed by documents X  X . The refor-function. For example, the reformulated AP and NDCG are defined as below, where r j  X  evaluation measures come from the non-continuity and non-differentiability of the position function and the truncation function. Therefore, they proposed approximating the position function and the truncation function using smooth functions of document scores as follows, technique was utilized.
For ease of reference, we summarize the above direct optimization methods in Table 1 . 4 Tendency correlation optimize the IR evaluation measure. What is optimized in practice, however, is a surrogate measure. So far, it is unclear whether the optimization of a surrogate measure can lead to theoretical analysis on this, with the proposed concept of  X  X  X endency correlation X  X . 4.1 Definition of tendency correlation First, we define the  X  X  X endency X  X  of a function with respect to two inputs as follow.
As can be seen, the  X  X  X endency X  X  of a function with respect to two inputs is defined as the difference in the values of the function at the two inputs, and the  X  X  X endency direction X  X  is decided by the sign of the difference. Based on this definition, we define the  X  X  X endency correlation X  X  between two functions as below.
 correlation coefficient between them is defined as where coefficient e is small, and weak otherwise.
 F ( z 1 -F ( z 2 )) in the entire input space.

According to the definition, the tendency correlation defined above is invariant to linear When e is small, the tendency correlation is strong. When e = 0, the tendency of ~ F has the k  X  ~ strong tendency correlation with F .

It is clear that the surrogate measures and IR evaluation measures can be regarded as functions of the documents, their relevance labels, and the ranking model. Therefore, the surrogate measure and its corresponding IR evaluation measure.

Note that our definition of the tendency correlation is indeed the worst case disagree-ment between two functions over the entire input space. The advantages of using the worst agreement, are as follows. First, the worst case disagreement is much easier to calculate correlated everywhere in the input space. As a result, their global optima will be very close (see Theorem 1). However, if we only know that the average disagreement is small, it is still possible that the two functions are largely different at some point. As a consequence, we can hardly come to any conclusion about the relationship between the global optima of the two functions. In this regard, the worst case analysis can lead to a stronger conclusion than other analyses. 4.2 Justification of tendency correlation z = 0); and that between ~ F 3 and F is 1.6 (when z 1 =-0.8, z 2 = 0or z 1 = 0, z 2 = -0.8). According to these examples, it seems that the stronger tendency correlation that ~ F has with F , the more likely that ~ F and F achieve their optima at the same point. Actually, this observation can be proved as shown in Theorem 1, when ~ F and F correspond to the surrogate measure and the corresponding IR evaluation measure respectively. evaluation measure (the average IR evaluation measure on the training data) and expected Theorem 1 shows that if the tendency correlation coefficient of the surrogate measure e ? 0, responding empirical (expected) IR evaluation measure. Furthermore, if the learning model that maximizes the empirical surrogate measure over an infinite training set will also this regard, the tendency correlation can be a good tool to evaluate the effectiveness of a surrogate measure.
 P ( x , y ), define where ^ R F  X  x  X  X  1 m relation coefficient between a surrogate measure ~ M and an IR evaluation measure M is e , then similar. Because the tendency correlation coefficient between ~ M and M is e , we have 8 x 1 and 8 x 2 ; 9 k 0 ; e 0 ; ~ M satisfies that According to Eq. ( 3 ) and the definitions of ^ R M and ^ R ~ M , we have According to the definitions of ^ x ~ M and ^ x M , we have Therefore, by setting x 1  X  ^ x M and x 2  X  ^ x ~ M in Eq. ( 2 ), we have In summary, we can prove the first conclusion in Theorem 1. h 5 Tendency correlation analysis on existing direct optimization methods In this section, we perform formal analysis on the direct optimization methods mentioned in Sect. 3 based on the concept of  X  X  X endency correlation X  X . 5.1 Analysis on SoftRank NDCG The analysis on SoftRank NDCG is mathematically summarized in Theorem 1. From the theorem, we can see that the upper bound of the tendency correlation coefficient e is an When r s decreases, the upper bound decreases quickly. For example, assume N = 200, L = 3, and d = 0.1, then we have e B 1,000 when r s = 0.02 and e B 0.02 when r = 0.01. Actually when r s approaches zero, e will also approach zero. In other words, ~ M
SR can have arbitrarily strong tendency correlation with NDCG if r s ? 0, regardless of optimize NDCG when its parameter is appropriately set.
 correlation coefficient between ~ M SR  X  x ; x ; y  X  and NDCG is e . If r s \ d satisfies that
The theorem can be proved by applying Lemma 1 and 2. We leave the proofs of these two lemmas in the appendix due to space restrictions. Lemma 1 For query q , suppose its associated documents and target ranked list are ( x , y ), if 8 x ; ~ M satisfies that then the tendency correlation coefficient between ~ M and M is no greater than e . Lemma 2 For query q , suppose its associated documents and target ranked list are ( x , y ). Assume V i and j ,| f ( x i ) -f ( x j )| C d [ 0, and V q , n q B N . If r s \ d V x , 5.2 Analyses on ApproxRank MAP and ApproxRank NDCG The analyses on ApproxRank MAP and ApproxRank NDCG are summarized in Theorem 3. Actually when a and b approach infinity, e 1 will approach zero. The upper bound of e 2 is a ~ M
AM and ~ M AN can have arbitrarily strong tendency correlation with the original IR evalu-ation measures on any kinds of data by setting a ? ? and b ? ? . Therefore, according to Theorem 1, ApproxRank MAP and ApproxRank NDCG can effectively optimize the original IR evaluation measures when their parameters are appropriately set.

The theorem can be proved by applying Lemma 1 and the theorems given in Qin et al. ( 2010 ). Due to space restrictions, we omit the details here. 5.3 Analyses on SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG Although SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG were proposed in dif-optimization problem as a structured SVM problem. Nevertheless, they all use a cutting techniques to find the most violated constrains in the cutting plane algorithm. Therefore, similar analyses can be obtained for these methods, as shown in Theorem 4 and Lemma 3. have arbitrarily strong tendency correlation with the original IR evaluation measures on guaranteed that we can always effectively optimize the original IR evaluation measures by adopting SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG .
 Lemma 3 Suppose two functions ~ F ; F : Z! R , and the tendency correlation coefficient e D .
 measures mentioned in SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG . For satisfy The methodologies to prove the results on SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG in Theorem 4 are similar. Take SVM MAP as an example, it can be proved by applying the following lemmas. We leave the proofs of these lemmas and that of Lemma 3 to the appendix due to space restrictions.
 Lemma 4 Assume there are only two levels of relevance labels (i.e., L = 2). For any is an indicator function .
 Lemma 5 Assume there are only two levels of relevance labels (i.e., L = 2). For any is an indicator function . 5.4 Summary and discussions The analyses presented in this section are summarized in Table 2 . From the table, we can However, on certain kinds of data, the surrogate measures optimized in SVM MAP , DORM NDCG , SVM NDCG , and PermuRank MAP can never have arbitrarily strong tendency especially considering that we never know the distribution of real data.

Note that in the theorems presented in this section, we have assumed that the learning algorithms can find the global optima of the surrogate measures. However, considering that the IR evaluation measures usually contain many local optima with respect to the ranking optima when it has very strong tendency correlation with the original IR evaluation mea-when performing the optimization. Otherwise, the theoretical results obtained in this section might not hold, and it will become unclear whether the obtained ranking model can max-imize the corresponding IR evaluation measure. In this regard, in practice, we will be faced with the trade-off between choosing a surrogate measure that has strong tendency corre-lation with the original IR evaluation measure and choosing a surrogate measure that can be easily optimized. This trade-off is especially critical for SoftRank NDCG , ApproxRank MAP and ApproxRank NDCG since they utilize gradient ascent techniques, which are easy to be 6 Experimental results we will validate Theorems 2 X 4 by studying the tendency correlations between the surro-gate measures and their corresponding IR evaluation measures on public datasets. Second, choosing a surrogate measure that has strong tendency correlation and choosing a surrogate measure that can be easily optimized. Last, we will validate Theorem 1 by studying the ranking performances of the direct optimization methods on public datasets. 6.1 Datasets The datasets used in our experiments include OHSUMED, TD2003, and TD2004 that are provided in LETOR (Liu et al. 2007 ). 6 The OHSUMED dataset contains 106 queries. For each query, there are a number of associated documents. The relevance degrees of doc-uments with respect to the queries are given on three levels: definitely relevant, partially relevant, or not relevant. There are 16,140 query-document pairs with relevance labels in total. For each query-document pair, 45 features were extracted, including term frequency, inverse document frequency, document length (Baeza-Yates and Ribeiro-Neto 1994 ), BM25 (Robertson and Walker 1994 ), and LMIR (Zhai and Lafferty 2004 ). The TD2003 about 1,000 associated documents. Each query-document pair is given a binary judgment: relevant or non-relevant. There are 64 features extracted for each query-document pair in TD2003 and TD2004, including term frequency, inverse document frequency, document length, BM25, LMIR, PageRank (Lawrence et al. 1998 ), and HITS (Kleinberg 1999 ). The datasets in LETOR have been partitioned into five sets. Five folds are constructed from the the test set. Finally, the average ranking performance over the five folds are reported. 6.2 Tendency correlations of direct optimization methods In this subsection, we will empirically validate Theorems 2 X 4 based on the experiments on OHSUMED, TD2003, and TD2004.

We randomly generated 100 ranking models and constructed 100 9 99 pairs of ranking ( x , y t ), and a pair of models, ( x i , x j ), we calculate e * as follows, 7 e  X  min
According to the definition of tendency correlation, the smaller the value of e * is, the stronger tendency correlation a surrogate measure has with the corresponding IR evalua-tion measure. In Table 3 , we listed the values of e * over all the five folds of OHSUMED, TD2003, and TD2004 for different direct optimization methods. 8 Note that we set b = 100 for ApproxRank MAP during the experiments since we found that the results are not very sensitive to the value of b .

From Table 3 , we can see that the values of e * for ~ M SR decrease with the decrease of r s on OHSUMED, TD2003, and TD2004. The values of e * for ~ M AM and ~ M AN decrease with the increase of a . Furthermore, by appropriately setting the values of the parameters, e.g., r ~ M
AN can have very strong tendency correlation with the original IR evaluation measures when their parameters are appropriately set. On the other hand, regarding the big values of e datasets.
 correlations of popular direct optimization methods in Sect. 5 . 6.3 Trade-off between strong tendency correlation and ease of optimization In Sect. 5 , we have discussed the trade-off between choosing a surrogate measure that has strong tendency correlation with the original IR evaluation measure and choosing a sur-SoftRank NDCG , ApproxRank MAP and ApproxRank NDCG , since the gradient ascent tech-nique adopted by them is easy to be trapped into a local optimum. To tackle the problem, one may make use of some global optimization techniques. For instance, the random restart strategy (Hu et al. 1994 ) is known as a popular global optimization technique and has been original learning algorithms for many times when using the random restart strategy, one may concern its time complexity especially when the training data is huge and the feature dimension is extremely high. However, according to the experimental results presented in this subsection, we found that the ranking performance can be significantly improved with only a few (e.g., less than 30) random restarts. Similar results have also been observed in some other works (Volkovs and Zemel 2009 ; Qin et al. 2010 ). In other words, if our goal is to improve the performance of the learned model, but not to really find the global optimum, it is usually not necessary to conduct a large number of random restarts. As a result, the complexity of random restarts is affordable in most cases, even if the training dataset is large.

In this subsection, we take ApproxRank MAP as an example to study the above trade-off during the training process. Similar results have also been observed for SoftRank NDCG and ApproxRank NDCG . Noticing that the training performance of ApproxRank MAP is not sen-sitive to the value of b , we set b = 100 in our experiments. We adopt the random restart gradient ascent was used for the next iteration when the value of the objective function, training performances of ApproxRank MAP with regards to different values of a .
From the figures, we can see that when a is smaller than 250, the training performances, with or without random restarts, of ApproxRank MAP increase with the increase of a . The explanation of this phenomenon is as follows. On one hand, the tendency correlation of ~ M AM increases with the increase of a , and thus MAP will be more effectively optimized. strong. Therefore, ~ M AM has fewer local optima than MAP and it is more likely for the gradient ascent technique to has more local optima and it becomes more difficult to find the global optimum of ~ M AM . In this case, MAP cannot be effectively optimized even if ~ M AM has very strong tendency correlation with it.

Comparatively, we can see that the training performances with random restarts are much better than those without random restart. For example, when a = 300, the training performance on TD2003 increases from 0.3372 to 0.3652 by utilizing 30 random restarts, which corresponds to a relative improvement of 8.28%. The training performances on OHSUMED with random restart keep increasing for a [ [50, 400], while the training performances without random restart decrease when a [ [250, 400]. All these observations are in accordance with our discussions in Theorem 3.

To sum up, the above results not only validate our discussions in Theorem 3, but also measure that can be easily optimized. 6.4 Tendency correlation and ranking performances In this subsection, we will empirically validate the conclusions in Theorem 1. We selected ListNet (Cao et al. 2007 ), one of the best baselines provided in LETOR (Liu et al. 2007 ), as the representative of the indirect optimization methods. (a)(b)
In Tables 4 , 5 , and 6 , we listed the training performances, in terms of MAP, NDCG@5, and NDCG@10, of all the direct optimization methods and ListNet. In the tables, a bold value indicates a performance improvement over ListNet. For SVM MAP , DORM NDCG , PermuRank MAP , and SVM NDCG , the best c parameters were chosen through cross valida-tion. For DORM NDCG , we chose c  X  r i  X  X  1 log ApproxRank NDCG , the random restart strategy described in Sect. 6.3 was adopted and the Rank MAP , we set b = 100 for all the experiments since the training performances are not ApproxRank MAP , and ApproxRank NDCG reported in the tables were the ones that achieved the best trade-offs according to Sect. 6.3 .

From Table 4 , we can see that the training performances of ApproxRank MAP are always better than those of SVM MAP on OHSUMED, TD2003, and TD2004, and are equal to or better than those of PermuRank MAP on TD2003 and TD2004. These results indicate that it is very likely that ApproxRank MAP can outperform SVM MAP and PermuRank MAP .By further comparing with the training performances of ListNet, we find that ApproxRank MAP can also outperform ListNet on all the three datasets, while SVM MAP and PermuRank MAP cannot always outperform ListNet. These results indicate that, on one hand, the training performances of ApproxRank MAP can be good (and better than other learning to rank approaches) on different kinds of datasets, when a is appropriately set; on the other hand, the training performances of SVM MAP and PermuRank MAP can be bad (and even worse than other approaches) on certain kinds of datasets. These results validate our discussions in Theorems 3 and 4.

From Tables 5 and 6 , we can see that SoftRank NDCG and ApproxRank NDCG can always outperform DORM NDCG and SVM NDCG on OHSUMED, TD2003, and TD2004. These perform DORM NDCG and SVM NDCG . By further comparing with the training performances of ListNet, we find that SoftRank NDCG and ApproxRank NDCG can always outperform ListNet on all the three datasets, while DORM NDCG and SVM NDCG cannot. In addition, we can see that the performance gaps of DORM NDCG and SVM NDCG with respect to ListNet vary a lot across different datasets. This seems to indicate that, on one hand, the training performances of SoftRank NDCG and ApproxRank NDCG can be good (and better than other learning to rank approaches) on different kinds of datasets, when r s or a are appropriately set; on the other hand, the training performances of DORM NDCG and SVM NDCG cannot and 4.

For the next step, we further study the practical performances of these direct optimi-zation methods, by reporting their test performances. The corresponding results are listed in Tables 7 , 8 , and 9 .

From Table 7 , we can see that the test performance of ApproxRank MAP is always the best one on OHSUMED, TD2003, and TD2004, while the test performances of SVM MAP and PermuRank MAP are worse than those of ListNet. From Tables 8 and 9 , we can see that SoftRank NDCG and ApproxRank NDCG always perform better than ListNet, while the test performances of DORM NDCG and SVM MAP are worse than that of ListNet.
 To sum up, the experimental results indicate that SoftRank NDCG , ApproxRank MAP , and ApproxRank NDCG can performs similarly to or even better than ListNet on OHSUMED, TD2003, and TD2004. However, the other direct optimization methods under investigation cannot outperform ListNet. 9 6.5 Summary existing direct optimization methods.  X  The surrogate measures optimized in SoftRank NDCG , ApproxRank MAP , and Approx- X  If a direct optimization method can effectively optimize a surrogate measure that has 7 Conclusions and future work In this work, we have studied the theoretical foundation of the direct optimization of IR evaluation measures. Specifically, we have proposed a quantity named  X  X  X endency corre-lation X  X  to describe the property of a surrogate measure with respect to the corresponding IR evaluation measure. On the basis of  X  X  X endency correlation X  X , we have given a sufficient optimizing a surrogate measure. We have investigated the surrogate measures optimized in they can satisfy the proposed sufficient condition. These theoretical discussions can explain the experimental results observed on public benchmark datasets.

Note that the proposed tendency correlation is based on the linear transformation of the function. A more complex transformation function may help relax the sufficient condition we obtained in the paper. Furthermore, in this paper, we have mainly performed theoretical design of new direct optimization methods that can achieve better trade-off between strong tendency correlation and ease of optimization.
 Appendix Full results of SoftRank NDCG , ApproxRank MAP , and ApproxRank NDCG on values of e * We present the full results of SoftRank NDCG , ApproxRank MAP , and ApproxRank NDCG on values of e * in Tables 10 and 11 .
 Proof of Lemma 1 condition in the lemma, for V x 1 = x 2 , we have Therefore In summary, we can conclude Lemma 1. h Proof of Lemma 2 According to the definitions of ~ M SR and NDCG, we have j ~ M SR  X  x ; x ; y  X  NDCG  X  x ; x ; y  X j 2 L 1 If we can prove | D ( l j ) -D ( r j )| B e 1 and j can be proved. In the rest of this subsection, we will prove these two equations respec-tively. First, we construct a random variable ~ R ij as following, x where s ij = s i -s j and erf  X  z  X  X  2 ffiffi p p On the other hand, since ~ R j p j  X  r  X  can be calculated from ~ R j  X  Proof of |D( l j ) -D(r j )| B e 1 The deterministic rank of document j can be calculated by r j = is an indicator function. The difference between r j and l j is, In above erfc( z ) = 1 -erf( z ). Based on the properties of Normal Distribution, we have Therefore, Combining Eqs. ( 5 ) and ( 6 ), we have According to the mean value theorem, we have where h 2 X  min  X  r j ; l j  X  ; max  X  r j ; l j  X  . h Proof of j First, we prove the following lemma that will be employed in later proof.
 Lemma 6 Assume a discrete random variable R  X  0 ; ... ; n 1 that satisfies E  X  R  X  l to l , then Proof According to the definitions of l 0 and l 00 , we have According to the definition of variance, we have Therefore, Then, we prove j According to Lemma 6, we have, Therefore, 1. If l j B l j 0 , we have 2. If l j [ l j 0 , we have
In summary According to the definition of variance and Lemma 6, we have Therefore Combining Eqs. ( 7 ) and ( 8 ), we have assuming 10 | s ij | C d [ 0 and 2 B n q B N , In order to ensure r 2 j \ 1 5 , we instead ensure the following inequalities Therefore, when r s \ d In summary, | D ( l j ) -D ( r j )| B e 1 and j can conclude Lemma 2.
 Proof of Lemma 3 According to the condition in Lemma 3, we have 9 z 1 ; z 2 ; ~ F and F satisfy that Therefore, V k C 0, we have According to the definition of tendency correlation coefficient, we have In summary, we can conclude Lemma 3. h Proof of Lemma 4 and 5 First, we present two propositions that will be employed for later proof.
 Proposition 1 For query q , suppose its associated documents and target ranked list are ( x , y ). We have irrelevant document (i.e., x j 2 C x ), s ij  X  s i s j  X  f  X  x ; x i  X  f  X  x ; x j  X  . Proposition 2 For query q , suppose its associated documents and target ranked list are ( x , y ). Let For any x 1 and x 2 , we have Based on Propositions 1 and 2, the methodology to prove Lemma 4 and 5 is similar. Here we only present the proof of Lemma 4. we can modify the t th element of each document x * i to ensure that where y  X  sort f  X  x ; x  X  .

In the following, we will prove that we can further modify the t th element of each x * i to have AP( y , y * ) unchanged and ensure According to the definition of ~ y , Eq. ( 12 ) implies that where o  X  1 ; j 6  X  n ; o n  X  2, and o j 0 = 1.
 According to Proposition 1, we denote where to ensure Eqs. ( 13 ) and ( 14 ).
 conclusion of Lemma 4. h Proof of Theorem 4 For ease of description, we denote
According to Proposition 2, Theorem 4 can be proved if we can prove that 8 x 1 6  X  0 ; 8 D [ 0 ; 9 x 2 and ( x * , y * ) that satisfy Without loss of generalization, we just prove that satisfy and m = 1 in Lemma 3. Then in the new coordinate, where x 1 0 = (1, 0, ... ), we construct x 2 = (0, 1, 0, ... ). By selecting t = 2 and m  X  n 1 in Lemma 3, we can further modify ( x ( x , y * ) change the value of the first and second elements of x * i separately, therefore, the final ( x * , y * ) can ensure Eqs. ( 15 )to( 18 ) simultaneously.
 According to the definition of AP, we have when n  X  n p ; p [ 1, we have and therefore can conclude Theorem 4. h References
