 Qiang Liu qliu1@uci.edu Alexander Ihler ihler@ics.uci.edu Wireless sensor networks are becoming ubiquitous, with applications including ecological monitoring, health care, and smart homes. Traditional centralized approaches to machine learning are not well-suited to sensor networks, due to the sensors X  restrictive re-source constraints. Sensors have limited local com-puting, memory, and power, and their wireless com-munication is expensive in terms of power consump-tion. These constraints make centralized data collec-tion and processing difficult. Fault-tolerance and ro-bustness are also critical features.
 Graphical models are a natural framework for dis-tributed inference in sensor networks (e.g., Cetin et al., 2007). However, most learning algorithms are not distributed, requiring centralized data processing and storage. In this work, we provide a general framework for distributed parameter estimation, based on com-bining local and inexpensive estimators.
 This paper is organized as follows. Section 2 sets up background on graphical models for sensor networks and learning algorithms. In Section 3, we propose a framework for distributed learning based on intel-ligently combining results from disjoint local estima-tors. We give theoretic analysis in Section 4 and ex-periments in Section 5. We discuss related work in Section 6 and finally conclude the paper in Section 7. 2.1. Graphical models for sensor networks Consider a graphical model of a random vector x = [ x 1 ,...,x p ] in exponential family form, where  X  = {  X   X  }  X   X  X  and u ( x ) = { u  X  ( x  X  ) }  X   X  X  tors of the same size, and  X  T u ( x ) is their inner product. I is a set of variable indexes and u  X  ( x  X  ) are local suf-ficient statistics. Z (  X  ) is the partition function, which normalizes the distribution. The distribution is asso-ciated with a Markov graph G = ( V,E ), with node i  X  V denoting a variable x i and edge ( ij )  X  E rep-resenting that x i and x j co-appear in some  X  , that is, { i,j } X   X  . Let  X  i = {  X   X  X | i  X   X  } be the set of  X  that includes i . In pairwise graphical models, I = E  X  V . To model a sensor network, we represent the i -th sen-sor X  X  measurement by x i , and assume that the com-munication links between sensors are identical to the Markov graph G , that is, sensor i and j have com-munication link if and only if ( ij )  X  E . Assume that n independent samples X = [ x 1 ,...,x n ] are drawn from a true distribution p ( x |  X   X  ). Due to memory and communication constraints on sensors, the data are stored locally within the network: each sensor stores only data measured by itself and its neighbors, that and N ( i ) is the neighborhood of node i . The goal is to design a distributed algorithm for estimating the true  X  , with minimum communication and low, balanced local computational costs at the sensor nodes. Notation. Unless specified otherwise, we take E (  X  ), var(  X  ), and cov(  X  ) to mean the expectation, variance, and covariance matrix under the true distribution  X  2 ` (  X  ) denote the gradient and Hessian matrix w.r.t.  X  , where we suppress the dependence of ` (  X ,x ) on x for compactness. We use  X  X at X  accents to denote empiri-2.2. M-estimators M-estimators are a broad class of parameter estima-tors; an M-estimator with criterion function ` (  X  ; x ) is In this paper we assume that ` (  X ,x ) is continuous dif-ferentiable and has a unique maximum. If E [  X  ` (  X   X  )] = 0, then under mild conditions standard asymptotic statistics (van der Vaart, 1998) show that  X   X  is asymp-totically consistent and normal, that is, N (0 ,V ), with asymptotic variance (Godambe, 1960) where J = var(  X  ` (  X   X  )) is the Fisher information ma-trix and H =  X  E (  X  2 ` (  X   X  )) is the expected Hessian matrix. ` is said to be information-unbiased (Lindsay, 1988) if J = H . In this case, we have V = H  X  1 = J  X  1 , i.e., the asymptotic variance equals the inverse Fisher information matrix or Hessian matrix. Let s be a ran-dom vector with s = H  X  1  X  ` (  X   X  ,x ). An important intuition for asymptotic analysis is that  X   X   X   X   X  + 1  X  at the large sample limit, so that the asymptotic vari-ance can be rewritten as V = var( s ).
 Empirically, one can assess the quality of an M-estimator by estimating its asymptotic covariance; this can be done by approximating the E (  X  ) and var(  X  ) with their empirical counterparts, and  X   X  with  X   X  , e.g., the asymptotic variance is estimated by  X  V =  X  H  X  1  X  J  X  H where  X  J = 1 n P n k =1 (  X  ` (  X   X  ; x k ))(  X  ` (  X   X  ; x  X  only the Fisher information J need be calculated, avoiding calculating the second derivatives. In prac-tice, these variance estimators perform well only when the parameter dimension is much smaller than the sample size; they are usually not directly applicable to practically sized problems. In this work, we show that by splitting the global estimator into low-dimensional local estimators, we can use covariance estimation on the local estimators to provide important information for combining them. 2.3. MLE and MPLE The maximum likelihood estimator (MLE) is the most well-known M-estimator; it maximizes the likelihood, The MLE is asymptotically consistent and normal, and achieves the Cram  X er-Rao lower bound (is asymptoti-cally at least as efficient as any unbiased estimator). Unfortunately, the MLE is often difficult to compute, because the likelihood involves the partition function Z (  X  ), which is hard to evaluate for general graphical models (Wainwright &amp; Jordan, 2008).
 The maximum pseudo-likelihood estimator (MPLE) (Besag, 1975) provides a computationally efficient al-ternative to MLE. The pseudo-likelihood is defined as where due to the Markov property, each conditional likelihood component only depends on  X   X  i , the param-to sensor i . MPLE remains asymptotically consistent and normal, but is usually statistically less efficient than MLE  X  a sacrifice for computational efficiency. However, cases exist in which the MPLE is also statis-tically more favorable than MLE, e.g., when the model is misspecified (e.g., Liang &amp; Jordan, 2008). There is a weaker version of MPLE, well known in sparse learning (e.g., Ravikumar et al., 2010), that disjointly maximizes the single conditional likelihood (CL) components in MPLE, and then combines the overlapping components using some simple method such as averaging. Very recently, the disjoint MPLE has started to attract attention in distributed estima-tion (Wiesel &amp; Hero, 2012), by observing that the con-ditional likelihoods define local estimators well suited to distributed computing.
 Our work. We address the problem of distributed pa-rameter learning within a paradigm motived by MPLE and disjoint MPLE, in which the sensor nodes locally calculate their own inexpensive local estimators, whose results are communicated to nearby sensors and com-bined. We provide a more general framework for com-bining the local estimators, including weighted lin-ear combinations, a max-voting method, and more advanced joint optimization methods. Powered by asymptotic analysis, we propose efficient methods to set optimal weights for the linear and max combina-tion methods, and provide a comprehensive compari-son of the proposed algorithms. Surprisingly, we show that the simple linear and max combination meth-ods, when leveraged by well-chosen weights, are able to outperform joint optimization in some cases. In particular, the max-voting method performs well on  X  X egree-unbounded X  graph structures, such as stars or scale free networks, that are difficult for many ex-isting methods. In addition, we show that the joint MPLE can be recast into a sequence of disjoint MPLE combinations via the alternating direction method of multipliers (ADMM), and we show that, once it is ini-tialized properly, interrupting the iterative algorithm at any point provides  X  X orrect X  estimates; this leads to an any-time algorithm that can flexibly trade off per-formance and resources, and is robust to interruptions such as sensor failure. Finally we provide extensive simulation to illustrate our theoretical results. function that depends only on local data X A ( i ) and the parameter sub-vector  X   X  i . This defines a M-estimator that is efficient to compute locally by sensor i , unique maximum, which guarantee that  X   X  i  X  totically consistent and normal under standard tech-nical conditions. Further, assume  X  i  X  i = I , so that each parameter component is covered by at least one local estimator and a valid global estimator can be constructed by combining them.
 Although our results apply more generally, in this work which satisfies the conditions listed above. Moreover, such ` i local (  X   X  i ) are information unbiased, i.e., V ( J totic variance by  X  V i local = (  X  J i local )  X  1 , where volves calculating the covariance of the gradient statis-tics and is efficient once |  X  i | is relatively small. If a parameter  X   X  is shared by multiple sensors, perfor-mance can be boosted by combining their information. We propose two types of consensus methods, general-izing disjoint MPLE and MPLE respectively. 3.1. One-Step Consensus.
 collection of estimates given by the sensors incident to  X  . The goal is to construct a combined estimator  X   X   X  as a function of  X   X   X  . Probably the simplest method we show in the sequel, this simple approach usually performs poorly, in part because it weights all the es-timators equally and the worst estimator may greatly degrade the overall performance. Thus, it would be helpful to weight the estimators by their quality. Let  X  w i  X  , as a function of X A ( i ) and  X   X  i local ical measure of the quality of the i -th local estimator for estimating parameter  X   X   X  for example,  X  w i could combine the estimators based on weight  X  w i : linear consensus: max consensus: where the linear consensus takes a soft combination of the local estimators, while the max consensus votes on the best one. It should be noted that the max consensus can be treated as a special linear consensus whose weights are taken be to be zero, except on one local estimator. However, as we show later, the max consensus has some attractive properties making it an efficient algorithm for many problems.
 We prove that linear and max consensus are asymptot-ically consistent and normal, and provide their asymp-totic variance. We also discuss the optimal setting of the weights, in the sense of minimizing the asymptotic mean square error. Remarkably, we show that the op-timum weights, particularly for the max consensus, are surprisingly easy to estimate, making one-step meth-ods competitive to more advanced consensus methods. 3.2. Joint Optimization via ADMM A more principled way to ensure consensus is to solve a joint optimization problem, max where we maximize the sum of  X  ` i local under the con-straint that all the local estimators should be consis-MPLE method in (2) when ` i local are the conditional likelihoods. In this section, we derive a distributed algorithm for (6) that can be treated as an iterative version of the linear consensus introduced above. Our algorithm is based on the alternating direction method of multipliers (ADMM), which is well suited to distributed convex optimization (Boyd et al., 2011), particularly distributed consensus (Bertsekas &amp; Tsit-siklis, 1989).
 For notation, let f i (  X  i  X  troduce an augmented Lagrangian function for (6),
X where  X  i  X   X  an alternating direction procedure on the augmented Lagrangian yields the ADMM algorithm:  X   X   X   X   X   X   X  This update has an intuitive statistical interpretation. First,  X  i  X  tion of the parameter subject to a Gaussian prior with mean (  X   X   X  i  X   X  i  X  wards the average value;  X   X  is then re-evaluated by tak-ing a linear consensus of the local estimators. Thus, the joint optimization can be recast into a sequence of linear consensus steps. Given this connection, it is reasonable to set  X  i  X  to be the weights of linear con-responding one-step estimator. Since linear consensus estimators are asymptotically consistent, we have Theorem 3.1. If we set  X   X  to be asymptotically con-sistent and  X  i  X   X   X  remains asymptotically consistent at every iteration. Therefore, one can interrupt the algorithm and fetch a  X  X orrect X  answer at any iteration, giving a flexible any-time framework that can not only save on computation and communication, but is also robust to accidental failures, such as battery depletion. In this section, we give an asymptotic analysis of our methods, by which we provide methods to opti-mally set the weights of linear and max consensus. For notational convenience, we embed the local es-timator  X   X  i  X  degenerate) estimator of the whole parameter vector  X   X  i = arg max  X  ` i (  X ,X ), by setting  X   X  i Denote by V i the asymptotic variance of the extended estimator, with V i local on its  X  i  X   X  i sub-matrix and zero otherwise. Similarly, let H i extend H i local , and s extend s i  X  sample limit.
 For our results, we generalize to a matrix extension of the linear consensus (4), defined as where  X  W i are matrix weights that are non-zero only on the  X  i  X   X  i sub-matrices; we require that ( P i  X  W i ) is invertible. Note that the matrix extension is not directly suitable for distributed implementation, since it involves a global matrix inverse, but it will provide performance bounds for linear and max consensus and has close connection to joint optimization estimators. Theorem 4.1 (Linear Consensus) . Assume  X  W i p  X  W i and P in (7) is asymptotically consistent and normal, with an asymptotic variance of var ( P i W i )  X  1 P i W i s i Assume H = P i H i is invertible, then the joint op-non-degenerate estimator of the full parameter vector  X  . It turns out  X   X  joint is asymptotically equivalent to a matrix linear consensus with weights  X  W i =  X  H i : Corollary 4.2.  X   X  matrix in (7) with  X  W i =  X  H i has asymptotic variance of var[( P i H i )  X  1 P i  X  ` i (  X  which is the same as that of  X   X  joint .
 For max consensus estimators, we have Theorem 4.3. The  X   X  max in (5) is asymptotically con-sistent. Further, for any  X   X  I , if  X  w i  X  p  X  w i w normal, with asymptotic variance equal to V i 0  X , X  . 4.1. Optimal Choice of Weights In this section, we consider the problem of choos-ing the optimal weights, in the sense of minimizing the asymptotic mean square error (MSE). Note that E the trace of the asymptotic covariance matrix, and so the problem can be reformed to minimize tr( V ). In the following, we discuss the optimal weights for the linear and max consensus separately.
 Weights for Max Consensus. The greedy nature of max consensus makes optimal weights relatively easy: Proposition 4.4. For the max consensus estima-tor  X   X  max as defined in (5) , the weight w i  X  = 1 /V achieves minimum least square error asymptotically. In practice, we can estimate the optimal weights sim-sible in practice.
 Weights for Linear Consensus. By Theorem 4.1, the optimal weights for matrix linear consensus solve where W i are non-zero only on the  X  i  X   X  i submatrix and 1 denotes the identity matrix of the same size as W i . Solving (8) is difficult in general, but if s i pairwise independent and  X   X  i are information-unbiased, the weights W i = H i , asymptotically equivalent to  X   X  joint as shown in Corollary 4.2, achieves optimality. Proposition 4.5. Assume  X   X  i are information-unbiased. If cov( s i ,s j ) = 0 for all i 6 = j , then achieves the optimum MSE as defined in (8) .
 This implies that if the estimators are independent or weakly correlated, the joint optimization estimator  X   X  joint is guaranteed to perform no worse than the lin-ear and max consensus methods (both suboptimal to the best matrix consensus). However, in the case that the local estimators are strongly correlated (usually or max consensus, with properly chosen weights, can outperform the joint optimization method.
 On the other hand, when W i in (8) are constrained to be diagonal matrices, reducing to a set of vector weights w i  X  , the optimization becomes easier. Let w  X  = { w i  X  } i  X   X  and V  X  be an |  X  |  X  |  X  | matrix with V  X  = cov( s between the local estimators on parameter  X   X  . Then, Proposition 4.6. For linear consensus estimator  X   X  linear as defined in (4) , the weights w  X  = V  X  1 e is a column vector of all ones, achieves the minimum asymptotic least square error.
 In other words, the optimal vector weights for linear consensus equal the column sums of V  X  1  X  . In prac-tice, these weights can be estimated by  X  w  X  =  X  V  X  1 (  X  culating V ij  X  requires a secondary communication step bors. Note that this communication step may be ex-pensive if the number of data n is large (although one can pass a subset of samples to get a rougher estimate). It is interesting to compare to the optimal weights for max consensus in Proposition 4.4, where no communi-cation step is required. This is because max consensus fundamentally ignores the correlation structure, while linear consensus must account for it. Some further use-ful insights arise by considering the cases of extremely weak or strong correlations.
 Proposition 4.7. If cov( s i ,s j ) = 0 ,  X  i 6 = j , then the  X   X  linear as defined in (4) achieves the lowest asymptotic MSE with weights w i  X  = 1 /V i  X , X  .
 max consensus selection, might also be a reasonable choice for linear consensus. However, the indepen-dence assumption is always violated in practice. To see what happens when the estimators are strongly correlated, consider the opposite extreme, in which the local estimators are deterministically correlated: Proposition 4.8. If s i ( i = 1 ,...,p ) are determinis-tically positively correlated, i.e., there exists a random vector s 0 , and constants v i  X   X  0 , such that s i  X  = v sensus, under the constraint w i  X   X  0 , is w i  X  = 1 if v  X   X  v j  X  for any j  X   X  and w Since linear consensus with 0-1 weights reduces to max consensus, this result suggests that the optimal max consensus is not much worse than the optimal linear consensus when the estimators are strongly positively correlated. In practice, we find that the local estima-tors defined by conditional likelihoods are always posi-tively correlated, justifying max consensus in practice. 4.2. Illustration on One Parameter Case In this section, we illustrate our asymptotic results in a toy example, providing intuitive comparison of our algorithms. Assume  X  is a scale parameter, esti-mated by two information-unbiased estimators  X   X  i = arg max ` i (  X  ) ( i = 1 , 2). Let h i =  X  E (  X  2 ` i (  X  s v i = ( h i )  X  1 = var( s i ). Let v 12 = cov( s 1 ,s correlation of the two estimators.
 Linear consensus with uniform weights :  X   X  linUnif = (  X   X  1 +  X   X  2 ); the asymptotic variance is: Linear consensus with Hessian weights w i = h i :  X   X  Linear consensus with optimal weights  X   X  linOpt : By Proposition 4.6, the optimal weights for linear consen-asymptotic variance is Max consensus with optimal weights  X   X  maxOpt . By Proposition 4.4, for max consensus the weights w i = h i are optimal. The asymptotic variance is min { v 1 ,v 2 } Claim 4.9. In the toy case, we have  X   X  linOpt  X   X  joint (=  X   X   X   X  a  X   X  b means MSE(  X   X  a )  X  MSE(  X   X  b ) asymptotically.  X  Proof.  X   X  joint  X   X  linUnif is shown by the arithmetic-geometric mean inequality, and the rest since  X   X  linHessian and  X   X  maxOpt are special forms of linear consensus. However,  X   X  linUnif or  X   X  joint are not necessarily inferior or superior to  X   X  maxOpt . Their relative performance de-pends on the correlation and the quality (variance) of the two local estimators. Let  X  12 = v 12 / be the correlation coefficient of the estimators, and  X  = min { v 1 /v 2 ,v 2 /v 1 } the ratio of their variances. Claim 4.10. In the toy case,  X   X  joint (=  X   X  linHessian  X   X   X   X  See Fig. 1 for illustration; this highlights the rela-tive performance of max vs. linear consensus. While  X   X  local estimators perform similarly (  X   X  1) or when the local estimators have low or even negative correlations,  X   X  maxOpt tends to work well when one local estimator is much better than the others (  X  1) or when the lo-cal estimators are strongly positively correlated. This robustness makes max consensus useful for learning in difficult graphs, such as scale free graphs, for which standard methods often perform poorly (Ravikumar et al., 2010; Liu &amp; Ihler, 2011). Fig. 1(b) illustrates how the values of  X  and  X  12 are changed by varying the local potentials in a binary two-node model. Basically,  X   X  maxOpt tends to work better when the magnitudes of the local potentials differ greatly, i.e., when the model is heteroskedastic. small models (for which the asymptotic variance can be exactly calculated) and larger models of more practical size. We use a pairwise Ising model { X  1 , 1 } , with random true parameters generated by  X  test the Joint-MPLE , and the linear consensus with uniform weights ( Linear-Uniform ), with diagonal the optimum vector weights given in Proposition 4.6 ( Linear-Opt ). We also test the max consensus with diagonal weights ( Max-Diagonal(Opt) ), which is opti-mal for max consensus (Proposition 4.4). We quantify the algorithms either by exactly calculated asymptotic the MSE ||  X   X   X   X   X  || 2 calculated on simulated datasets. 5.1. Small Models Two small graphs are considered: star graphs and grids, which have opposite topological properties. For these small models, we estimate the pairwise parame-ters  X  ij with known singleton parameters  X  i . Star graphs. A star graph has an unbalanced degree distribution, peaked at the center node. There has been theoretical and empirical work showing that such degree-unbounded graphs are harder to learn than more regular graphs (e.g., Liu &amp; Ihler, 2011). From our perspective, the difficulty arises because the local estimators of high-degree nodes tend to deteriorate the overall performance. As we suggest in Section 4, the max consensus method is suitable for such graphs, as it can identify and discard the bad estimators. The simulation supports this expectation. In Fig. 2(a), as degree increases, the variance of the local esti-mator of the center node increases quickly compared to the leaves (averaged). Fig. 2(b) shows the exact (solid lines) and empirical (dashed) asymptotic effi-ciencies of the algorithms on star graphs of differ-ent sizes. Linear-Uniform performs worst, since it fails to discount the influence of the worst estimator. Joint-MPLE and Linear-Diagonal perform better but still deteriorate as degree increases, since they down-weight the worse estimators, but only to some extent. In contrast, Max-Diagonal is robust to the increasing degree, and can identify and discard the worst esti-mators. As theoretically predicted, Linear-Opt out-performs Max-Diagonal , but only slightly in this case. Note Linear-Opt is more costly than Max-Diagonal due to the extra communication step. The exact and empirical values in Fig. 2(b) match closely, showing the correctness of our theoretical analysis.
 In Fig. 2(c) we show the effect of singleton potentials. The performance of one-step consensus methods gen-erally decreases with higher magnitude singleton po-tentials, while the Joint-MPLE stays the same. In-tuitively, this is because the local estimators are not able to jointly infer the local potentials, causing prob-lems when those local potentials dominate. Since our analysis is mainly asymptotic, we evaluate how the al-gorithms perform for small sample sizes in Fig. 2(d). As can be seen, the finite sample performance is es-sentially consistent with the asymptotic analysis. 4  X  4 Grid. The algorithms X  performance on grids have the opposite trends; see Fig. 3(a). Joint-MPLE performs best, while max-Diagonal performs rela-tively poorly. This is because grids have balanced de-gree, and all the local estimators perform equally well. We check the finite sample performance of the algo-rithms in Fig. 3(b), which again shows similar trends to our asymptotic results. Finally, we show the con-vergence of ADMM in Fig. 3(c), illustrating that our initialization increases the convergence speed greatly. 5.2. Larger Models We also test our algorithms on larger graphs, includ-ing a 100-node scale free network generated via the Barab  X asi-Albert model (Barab  X asi &amp; Albert, 1999) and a 100-node Euclidean graph generated by connecting nearby sensors (distance  X  . 15) uniformly placed on the [0 , 1]  X  [0 , 1] plane; see Fig. 4. On these models, we estimate both the singleton and pairwise parameters. In Fig. 4(a)-(b) we see trends similar to their smaller analogues, the star graph and 4  X  4 grid, verifying that our analysis remains useful on models of larger sizes. A very recent, independently developed work (Wiesel proach for Gaussian covariance estimation. They pro-pose a similar linear consensus approach (using only uniform weights) and a similar parallel algorithm for joint MPLE, but do not discuss max consensus or lin-ear consensus with general weights, and do not pro-vide a comprehensive theoretical analysis. Another recent work (Eidsvik et al., 2010) uses composite like-lihood for parallel computing on spatial data. Bradley &amp; Guestrin (2011) gave a sample complexity analysis for MPLE and disjoint MPLE, which may be extensi-ble to our algorithms.
 Another line of work approximates MLE by estimat-ing the partition function with variational algorithms (e.g., Wainwright, 2006; Sutton &amp; McCallum, 2009). These methods can perform well at prediction tasks even with a  X  X rong X  model, and can take a message-passing form potentially suitable to distributed set-tings. However, in terms of parameter estimation, these methods introduce a bias due to the approxi-mate inference that is hard to estimate or control. In this work, we present a general framework for dis-tributed parameter learning. We show that the smart one-step consensus methods of the local estimators, especially those that exploit local second-order infor-mation, are both computationally efficient and statis-tically competitive with iterative methods using joint optimization. Particularly, we show that the max com-bination method is well suited to scale-free networks, a well-identified problem for existing methods. Our the-ory of combining estimators is quite general, and can be applied to other contexts to boost statistical per-formance. Future directions include considering model misspecification, finite sample complexity analysis and extension to high-dimensional structure learning. Acknowledgements. Work supported in part by NSF IIS-1065618 and a Microsoft Research Fellowship. n ||  X   X   X   X  || 200 1000 5000 50000
