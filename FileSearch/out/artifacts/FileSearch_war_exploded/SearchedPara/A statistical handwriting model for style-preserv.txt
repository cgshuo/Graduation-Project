 ORIGINAL PAPER Won-Du Chang  X  Jungpil Shin Abstract Synthesizing handwritten-style characters is an interesting issue in today X  X  handwriting analysis field. The purpose of this study is to artificially generate training data, foster a deep understanding of human handwriting, and promote the use of the handwritten-style computer fonts, in which the individuality or variety of the synthesized characters is considered important. Research considering such two properties together, however, is very rare. In this paper, a handwriting model is proposed to synthesize vari-ous handwritten characters while preserving the writer X  X  indi-viduality from a limited number of training data, using a statistical approach. The proposed model is verified in sin-gle-and multiple-stroke characters, such as Arabic numbers, small English letters, and Japanese Kanji letters. Synthe-sized characters are evaluated in three ways. First, they are analyzed visually using the selected samples, and the rela-tionship between the training and synthesized characters is explained. Second, the personalities and varieties of all the data are evaluated using a conventional writer verification method. Third, a questionnaire is developed and administered to evaluate the subjective responses of the users regarding the personal styles of the synthesized characters. The results prove that the proposed model stably synthesizes personal-ized characters by being invariant to the number of train-ing data, whereas the variety increases gradually as the data increase.
 1 Introduction Handwriting synthesis is the artificial generation of human handwriting. This area is not popular among the public, unlike voice synthesis, which has come to be well known in recent years. Although like voice synthesis it also mim-ics human behaviors, the two have a big difference in terms of their purposes. Because the mechanical pattern of written characters is more welcome than that of handwritten ones in many cases whereas human voices are considered more user-friendly than mechanical voices.

The purposes of handwriting synthesis as reflected in the pertinent literatures can be grouped as follows in our opinion: (1) to generate training data automatically for recognition systems [ 35  X  37 ]; (2) to foster an understanding of human handwriting [ 4 , 5 , 17 , 28 , 29 ]; and (3) to promote the use of synthesized characters instead of computer fonts [ 10 , 19 ]. In the first purpose, generating various handwritten charac-ters and helping facilitate the learning procedure are focused on. Instead, the accuracy of generating a human-like pattern is not considered much because some strange patterns do not cause the recognition system to decline considerably. As for the second purpose, the research conducted with such purpose may extend the field of handwriting synthesis by connecting it to the other related fields. The created model can be used for other applications in handwriting-related research fields, such as handwriting recognition, signature verification, and writer identification. Lastly, with regard to the third purpose, as the writing style differs from one per-son to another, it is possible to show one X  X  own characteristics in documents using the personalized handwriting synthesis system.

In this paper, two issues are discussed in line with the second and third purposes: (1) how to vary the shapes of the generated characters (variety) and (2) how to synthesize the characters while preserving the writer X  X  handwriting style (individuality). Variety is connected to the capacity of a hand-writing model in line with the second purpose. If a model can synthesize multiple handwriting styles, it means that the multiple styles are correctly stored in such single model. Variety also has an important role in relation to the third purpose: It helps create more natural documents by pro-ducing characters with different shapes, whereas the static shapes of characters reveal artificially synthesized handwrit-ing shapes.

We think that the individuality is connected to the deli-cateness and precision of a model in relation to the second purpose. If a model can successfully reproduce a person X  X  handwriting, it means that the model can precisely distin-guish a person X  X  handwriting from that of another. In relation to the third purpose,  X  X ndividuality X  means that a user can decorate a document with a more accurate personal style.
The two aforementioned issues seem to be correlated based on the results of previous studies. Although variety may be allowed when synthesizing a person X  X  handwritten-style characters, high variety easily leads to individuality loss, and vice versa [ 6 , 37 ]. The goal of this study was to achieve both a higher individuality and a higher variety by using a novel statistical model.

In the latter part of this paper, a statistical character model that enables the synthesis of multiple characters statisti-cally while keeping one X  X  handwriting style is proposed. The related works are summarized in Sect. 2 from the perspec-tive of the synthesized characters X  variety and individuality. The general architecture is described in Sect. 3 . A statistical stroke model that allows personalized variation is proposed in Sect. 4 , and its extension to the multistroke character is explained in Sect. 5 . Section 6 describes the experiment results, and the conclusions and a description of the future works are presented in the last section. 2 Related works Each individual has his/her own handwriting style. It has been reported that handwritings have similar shapes even on different materials, although the musculature and forces involved widely differ [ 8 ]. Osborn [ 24 ] explained that the individuality starts from childhood. Young schoolchildren write uniformly when they first learn to write. The writing styles change for each person from the time they start to use handwriting practically until they find the easiest way to write. The individuality of people X  X  handwritings has helped arrest a criminal through the screening of 600,000 handwrit-ing samples [ 1 ], and the results of handwriting similarity analysis have assisted the jury in the U.S. [ 34 ].
From another point of view, it is obvious that varia-tions exist in the handwritten characters of the same person. Such variations, however, are not too much that the written characters can already be regarded as having been written by different individuals. A ten-year study on handwritings [ 15 ] reported that the handwriting styles of mature individ-uals aged 21 X 60 only slightly changed. Further, 45 out of 50 handwritings were correctly identified by experts as the same individuals X  handwritings ten years later. Hilton [ 11 ] described this individuality of handwriting variation as fol-lows:  X  X n individual X  X  handwriting is made up of complexity of habitual patterns that are repeated within a typical range of variation around the model patterns. X 
In the research field of handwriting synthesis, using peo-ple X  X  written characters with little change is one of the easi-est ways to synthesize characters. As there are relatively few English letters and as the connections between the charac-ters express one X  X  individuality well, this method is utilized to focus on the connections. Guyon [ 10 ] proposed a juxtaposing method that collects isolated and connected English letters so that the collected handwritten characters can substitute for typed characters. Lin and Wan [ 19 ] proposed a synthe-sis method of English strings. In the juxtaposing method, the connections between the characters are smoothed, and small random movements of the characters X  control points are allowed. These enable the synthesis of a handwritten string while the connection information between the char-acters does not abound. Jawahar and Balasubramanian [ 13 ] introduced a method of synthesizing Indian letters by juxta-posing the strokes to compose a multistroke character. The stroke to juxtapose is chosen randomly from among the train-ing strokes, or the mean stroke with Gaussian random noise is used to synthesize various strokes. Meanwhile, the inter-stroke relations between the consequent strokes are utilized to lay out multiple strokes.

There have been attempts to employ the hidden Markov model (HMM) or the Bayesian network for the aforemen-tioned purpose. These methods first analyze the sample char-acters and generate a probabilistic character model, and then they synthesize the most probable character using the model. As only the most probable character is produced, however, the variances are severely limited in these models. Sin and Kim X  X  [ 33 ] HMM synthesizes Arabic numbers and lower-case English letters. Their single-network HMM produced the numbers in human-like styles, but the synthesized Eng-lish letters were barely readable, and the original writer X  X  individuality was difficult to find therein. Choi et al. [ 4 ] and Choi and Kim [ 6 ] proposed a method of synthesizing Arabic numbers and Korean characters based on a Bayesian network model [ 3 ]. The synthesized characters manifest the writers X  styles, but very little variance is expressed. Although there was an attempt to study the variances in detail [ 5 ], the vari-ances of the synthesized characters were limited to the global shapes. The personalities of the characters were found to decrease as the variance increases.
Allowing global modification is one way of creating variety. The following methods allow variety via global modification, but their capacity to create variety is limited because local changes are not allowed. At the same time, whether global modification preserves the personalities of synthesized characters is also being questioned. Setlur and Govindaraju [ 31 ] proposed a synthesizing method for cursive words using Hollerbach X  X  oscillation theory of handwriting. They converted the xy coordinates of characters into vector spaces and created variety by modifying the parameters in the vector-space diagram. As a result, various character slants and smoothness (related to the writing speed) of synthesized cursive words were reported.
 Wang et al. [ 38 ] proposed a method of synthesizing cursive English words. Affine parameters were calculated between each sample character and a template, and then variation was introduced by modifying the affine parameters and provid-ing some noises when synthesizing. The variation was lim-ited so that the synthesized characters would not lose their individuality.

The use of morphing functions between or among hand-written characters can be classified as a global modification. Devroye and McDougall [ 7 ] and Zheng and Doermann [ 39 ] synthesized English letters, and Mori et al. [ 20 ] synthesized Arabic numbers. The results of the use of these methods have the forms of human handwriting. These methods find corre-sponding points between or among characters and calculate the morphing functions within the characters. A character is synthesized by choosing a morphing parameter, which deter-mines the amount of morphing. In the results, the synthesized characters are the linear variations between or among the characters. The local variations are severely limited in this method, however, and how much the global variations reflect one X  X  individuality remains a question.

Plamondon and Guerfali [ 29 ] proposed a synthesis method using a kinematic model named  X  X elta-lognormal theory X  [ 26 , 27 ], which explains a human handwriting with ago-nist and antagonist systems. This method was exploited for oriental languages [ 17 , 29 ], and it was also utilized to connect synthesized characters smoothly [ 38 ]. It has been proven that this method can extract personal param-eters from a handwritten character and can regenerate var-ious characters by controlling the parameters. However, it is not easy to express local variance using this method. This is because controlling the parameter affects the char-acters X  general shapes and because a way of composing personal features from a number of characters has yet to be found.

Wada et al. [ 37 ] employed a genetic algorithm (GA) to synthesize manifold characters. A computational model and fitness function successfully synthesized various characters, but many of the synthesized characters lost their personali-ties, and some lost even the shape of the letter. 3 General architecture Before describing the proposed handwriting model, sev-eral terms in this paper must be defined for clarity X  X  sake. A  X  X troke X  is defined in this paper as a component written without pen-up, and a character is said to consist of one or more strokes. A stroke is understood as a sequence of points, and a line segment between two points is named a  X  X egment. X  For any two points, the two points are said to be visible to each other if the direct line between them is not blocked by any preceding segment of the latter point. The visible points preceding a point are called  X  X nfluencing points X  of the point.
The general architecture of the proposed approach is shown in Fig. 1 . This approach regards a character as a combination of independent stroke shapes and considers the relationship of their relative positions and sizes. Hence, the shapes of the strokes in the same order are trained to cre-ate independent stroke models, and the relations between the strokes are trained separately to create interstroke mod-els. To synthesize a character, strokes are synthesized from each stroke model, and then their positions and sizes are adjusted using the interstroke model. It should be noted that all the characters were resized before the training so they would have the same width or height as the standard size. The width/height ratio was not changed in the resizing. 4 Statistical stroke model People have their own styles of writing strokes, and certain styles are observed more often than others. One easy way of calculating the probabilities of writing styles is to categorize strokes X  shapes at the stroke level. The stroke data of a writer can be classified, and probabilities can be assigned according to their appearance ratios. Niels and Vuurpijl [ 23 ] classified handwritten characters by calculating the distances between the characters and by generating a dendrogram. This method, however, requires too much training data, and it is difficult to reflect partial writing styles with insufficient data using such method. Figure 2 shows different styles of starting a stroke, where the styles of starting a stroke and the other parts of the stroke are not much related. If characters are categorized at the character level, the whole parts are considered in a package even when they are not related.

To synthesize variable and personalized strokes using a small number of training samples, a statistical approach is proposed. In this approach, the position of a point is influ-enced by the positions of its preceding and spatially close points. At first, it is assumed that the handwritings with the same strokes have the same numbers of points for a writer and that the points at the same order represent perceptually similar parts in the context of the strokes X  shapes. A point adjustment method that satisfies this assumption will be pre-sented in Sects. 3.4 and 3.5. 4.1 Preprocessing A sampling procedure [ 32 ] was employed to reduce the com-plexity of handwriting analysis. This method was selected because of its simplicity and the ease by which it can control the amount of information lost. The algorithm for a stroke is as follows: (1) Remove a point from the stroke if its xy coordinates are (2) Select the end points of the stroke. (3) Sequentially connect the selected points with the line (4) Among the unselected points, find the farthest from the (5) Repeat 3 X 4 until no more point is selected. 4.2 Vector classification To generalize one X  X  handwriting style, a handwritten stroke is considered a set of consequential points, and the points at the same order are classified when a number of strokes are given for training. Each point of a stroke is expressed with the influencing vectors from some of its preceding points, and a stroke is expressed as the sequential set of the points. Here, it is assumed that a point X  X  position is directly influenced by its visible preceding points.

This is because it is believed that the influence of an invis-ible point is much less than the influence of the blocking segment. After the detection of the influencing points for all the training strokes, a point is determined as the representa-tive influencing point (RIP) if more than 40% of the points at the same order are influencing points. Figure 3 illustrates the classification process at an order of a stroke. A point is expressed with a number of directional vectors from its RIPs, so that the points at the same order have the same dimensions. Let these vectors be called  X  X IP vectors. X 
Classification is conducted at each order according to the directions and lengths of the directional vectors. A simpli-fied ART2 (adaptive resonance theory 2) algorithm [ 16 ]was used for classification in this paper because of its simplicity. Unlike K-means, this method does not require the number of clusters in advance but requires tolerance thresholds. Denot-ing  X  as a set of RIP vectors to a point of a training data, the classification algorithm is defined as follows: (1) Set the maximum iteration M and the thresholds (2) For each training data, (3) Repeat step 2 M times and stop if there is no more 4.3 Statistical stroke model and synthesis Based on the information obtained from the vector classi-fication, the probability for each cluster was calculated. To calculate the probability from a writer X  X  styles, the number of transition paths between the clusters of the consecutive orders was counted. Figure 5 shows a handwriting model when a handwritten stroke consists of three segments. The classified vector clusters are arranged at each order in a row, where C ij denotes the j th vector cluster of the i th order. The order 0 denotes the starting point of the handwriting, which is the origin ( 0 , 0 ) for every case, so that every model has only one cluster at the first order. The transition probability is calculated for each cluster at each order. For an instance in the figure, the transitions from C 22 are observed once to C and three times to C 32 , and then the probabilities are 0.25 and 0.75 for each transition, respectively.

To synthesize a stroke, the system synthesizes points order by order sequentially and interpolates them using the
C third-order spline (see Fig. 6 ). At each synthesis of a point, let the t th RIP be denoted as RIP(t) and the coordinates of the preceding synthesized points of the RIPs as G RI P ( t ) . A clus-ter is randomly selected according to the paths and probabili-ties, and the position of a new point is estimated by adding the estimated points differ according to the RIPs, the weighted mean is calculated using the length of the vectors. Assum-ing that the closer RIPs with smaller variations have greater influence, the weight of the t th vector is defined as w( where  X  RI P ( t ) is the standard deviation of the t th RIP vectors among the training data, and  X  and  X  are constants for adjust-ing the importance of C ( t ) and  X  RI P ( t ) . w( t ) s are normal-ized so that the summation of the weights would become one. Figure 7 shows the weights obtained by changing C ( t ) and  X  show gradual decreases as the distance of a point to its influ-encing point increases, where the standard deviation of the RIP vector affects the maximum weights when the positional distance is 0. The weight is also affected by the constants. The use of a higher  X  value makes the decrease steeper, and the use of a higher  X  value makes the effect of the standard deviation stronger by decreasing the maximum weight. In this paper,  X  and  X  were set to 1.1 and 0.5, respectively. They were determined experimentally so that the stroke model would not synthesize abnormal characters. Two things should be noted for the positional distance in Fig. 7 : (1) it is denoted as C ( t ) in Eq. ( 8 ); and ( 2 ) it is the relative distance to the charac-ter size, where the characters are resized so that their widths or heights will be 100, and where the smaller difference is selected. The width/height ratio is preserved via resizing.
Before the calculation, an RIP(t) is disabled if its line seg-any previously synthesized segment. If all the RIPs are dis-abled, a cluster is reselected randomly for the point, or the stroke is regenerated from the starting point if there is no other possibility. 4.4 Dynamic time warping with segment division Matching two sequential signals via dynamic time warping (DTW) is one of the popular ways of finding the correspond-ing points between two similar signals. As it employs the dynamic programming (DP) technique to reduce the time complexity, it is also called  X  X P matching. X  The details of DTW can be found in the results of the study conducted by Ney [ 22 ]. DTW basically involves one-to-many matching, and some points are to be ignored when one-to-one matching is constrained (see [ 18 ]), but one-to-one matching between two strokes is premised on the proposed handwriting model.
Hence, an attempt is made to ensure one-to-one matching without losing the shape information by inserting new points to the strokes. Figure 8 describes the concept of the proposed DTW, where the solid and dashed lines in (a) are parts of two signals. If a 0 and b 0 as well as a 2 and b 1 are aligned, respec-tively, the result of the conventional DTW becomes (b) if skipping a point is allowed. If skipping a point is not allowed, then b 1 will be aligned to both a 1 and a 2 (see Fig. 8 c), and it will not satisfy one-to-one matching. Instead, a new point ( b  X   X   X  b to to create more than one point within a segment. When using this division concept, the conventional DTW equation should be modified. Let us denote the vectors from the ( i  X  1 ) th to the i th points and from the ( j  X  1 ) th to the j th points of signals I and J as P I i and P J j , respectively. The DTW distance between the two subsignals { P I a | 0  X  a  X  i } { g ( 0 , 0 ) = 0 , (9) g ( i , j ) = d ( i , j ) + min where B I k and B J k are the branch values of the slope con-straints in DTW, N is the number of branches, (
B I k , B J k ) | 1  X  k  X  N = ( 1 , 1 ), ( x , 1 ), ( 1 , d ( i , j ) or dist ( P i , P j ) is the Euclidean distance between the two points P I i and P J j , and S S S S
Note that P I i ( P J j ) is divided into B J k ( B I k ) tors to calculate T ( i , j , k ) and that X P m th divided vectors of P I of branches, cannot be determined analytically [ 30 ] and thus has to be decided experimentally according to the purpose of (a) (b) (c) (d) the calculation of the distance, data type, sampling frequency, etc. In this paper, N = 11 is used as it showed stable results. 4.5 Aligning points among a group of handwritten strokes In this section, the problem of how to align points among a number of handwritten strokes is discussed as the corre-sponding points must be found among the training strokes for the proposed handwriting model. The conventional DTW cannot address this problem because it aligns points between two signals and not among a group of signals. Both the one-to-one and one-to-many matching methods cause prob-lems: The former cannot be used because the correspond-ing points become ambiguous, and the latter cannot be used either because it causes shape information loss when a point is skipped (see the example in Fig. 10 ).

Our approach to addressing this problem is to use the DTW that allows segment division, which is proposed in Sect. 3.4. The method ensures one-to-one matching between two sig-nals without ignoring any point, but it may cause another problem. As the task here is to find the perceptually simi-lar corresponding points among many strokes, the following assumption must be satisfied: If points a and b as well as b and c are aligned, then a and c are to be the corresponding points, where a , b , and c are the points of strokes A , respectively, and strokes A and B and B and C are matched sequentially. It is not satisfied, however, if b is a point added via division, and if C has a point similar to a (see Fig. 11 ). This is because the division generates vectors with the same directional values: The directional information of a is lost when b is used as the representative of a .

To address this problem, a method for aligning points among many strokes is proposed. This problem can be addressed by matching strokes via a template that expresses the directional features of the training data. To create the template, one of the training strokes is first selected as a tem-plate, and then the other strokes are matched one by one to the template. At each matching process, a point of the train-ing characters substitutes for the template if it is aligned to a divided point of the template. Here, substituting a point means substituting the point with a vector from the point directly preceding it. Meanwhile, as the alignments among the enrolled strokes are updated simultaneously with the seg-ment division, it can be assumed that the new alignment to the template does not falsify the alignments among the enrolled signals. Figure 12 shows two input characters and the template generated from them. The template includes all the curves in both training characters with the proposed tem-plate generation method. 5 Statistical model of a letter Based on the stroke model in Sect. 3 , a statistical handwriting model that can represent the handwriting of a multistroke let-ter is introduced. The multistroke letters must be considered (a) (b) (c) is designing the handwriting model, including oriental let-ters, because there are few multistroke letters in English but multistroke oriental letters (Korean, Japanese, and Chinese) abound.
 In the related literatures, Plamondon et al. [ 29 ] and Lee and Cho [ 17 ] located a new stroke X  X  starting point using only the relation to its directly preceding stroke X  X  end point. Although this method synthesized the well-shaped multistroke charac-ters by modeling a character holistically, it is easy to place a stroke abnormally if its shape varies. Moreover, there are many strokes of oriental characters that are not consecutive but are related to each other. Jawahar and Balasubramanian [ 13 ] located a synthesized stroke according to its directly preceding and succeeding strokes. This method is apparently effective in locating a stroke at an adequate place when the relations between the consecutive strokes are strong, but it may fail if they are not.

In this paper, the first point of a stroke is located accord-ing to the related points of its preceding strokes, and then the stroke is relocated and resized utilizing the interstroke rela-tions to all the points of the stroke. As a result, the shape of a stroke except the width/height ratio is independent of the interstroke relation, but its size and location depend on such relation. 5.1 Statistical tree for a multistroke letter The fundamental concept of statistical tree generation is to concatenate the stroke trees in Sect. 3.3. A point selected as an influencing point to a point ( s ) if p is prior to s and if the line segment ps does not penetrate any stroke prior to s , except the stroke including s . The influencing points are determined at each training character, and then the RIPs are determined using the same method as that used in Sect. 3.2. Except at the RIPs to the first point of each stroke, however, interstroke RIPs are ignored when constructing the tree and locating points at this step. This is because the shape of a stroke easily becomes abnormal and loses its individuality if interstroke influencing is allowed for the other points. In addition, the weight function of Eq. ( 3 ) for calculating the weighted distance between a cluster ( C i ) and an RIP vector set (v) is rewritten as w( t ) = 1 . 0 / (  X  +  X   X  D s ) D e , (17) D to calculate the distance between a cluster ( C i ) and an RIP vector set ( X ) , where C i ( t ) and  X ( t ) are the t th vectors of each set;  X  and  X  are constants set to adjust the importance of the positional distance and stroke-order difference; and D s is the difference between the stroke-order numbers. 1
Figure 13 shows the effect of the stroke-order difference on the weight function. As in Fig. 7 , the weight decreases gradually as the positional distance or the stroke-order dif-ference increases. It was designed in such a way, however, that even the weight of an RIP vector at a very different stroke order will become high when its positional distance is small. This is because it is believed that the influence of the positional distance is stronger than that of the stroke-order difference. Note that the distance in Fig. 13 is for the character after resizing using the same method as that shown in Fig. 7 . For this paper,  X  and  X  were set to 1.05 and 0.05, respectively. Their values were determined experimentally so that the stroke model would not synthesize abnormal charac-ters. The weight is also affected by the constants. Whereas has the same role as Eq. ( 8 ),  X  determines the importance of the stroke-order difference. As shown in Fig. 13 b, the weights of the RIP vectors at different stroke orders become similar when the value of  X  decreases.

Equation ( 8 ), the weight for estimating a new point X  X  posi-tion, is rewritten as w( where D e = C ( t ) , X  is a constant set to 0.5,  X  RI P ( standard deviation of the t th RIP vectors among the training data. The other denotations are the same as in Eq. ( 17 ). Note that the roles and effects of the constants are the same as those of the constants of Eqs. ( 8 and ( 17 ) because Eq. ( 19 )isamix-ture of such equations. The values of the constants were deter-mined experimentally so that the handwriting model would not synthesize abnormal characters. 5.2 Stroke resizing After synthesizing a stroke, it is resized to imitate the authen-tic interstroke relations because the stroke X  X  points other than the first point are located without considering the relations. The expected width and height values are calculated, respec-tively, using all the intrastroke and interstroke RIPs vectors, including the ones ignored in Sect. 4.1 . The RIP vectors of the training data are added to the coordinates of RIPs X  syn-thesized points, and then the mean coordinates of each point are calculated to determine the expected width and height.
Resizing is conducted so that the synthesized stroke would have the expected width and height, except in the follow-ing two cases: (1) when the synthesized stroke has a very small width or height to avoid abnormal shapes and (2) when the difference between the synthesized stroke X  X  size and the expected value is smaller than a threshold criterion. Note that the resizing process does not falsify the interstroke variation because the expected size depends on both the RIP vectors and the shape of the previously synthesized strokes. 5.3 Stroke relocation The location of a stroke is estimated using interstroke rela-tions, and the stroke is relocated if the estimated location dif-fers more than a threshold criterion from the location of the synthesized stroke. The estimated value of a point X  X  position (
E ) is determined as E = where  X ( t ) is the mean vector of the RIP vectors, starting from RIP(t), among the training data; G RI P ( t ) is the coor-dinate of RIP(t)  X  X  synthesized points; and w( t ) is a weight function for  X ( t ) .Eq.( 19 ) is exploited for w( t ), where D equals  X ( t ) . As the differences between the synthesized and estimated points vary at each point, the movement of stroke ( M ) is defined by calculating the weighted mean of the expected movements at all the points as M ( dx , dy ) = where E i and G i are the i th points of the estimated and syn-thesized strokes, and w i the mean value of the weights for theRIPstothe i th point. The weight of an RIP is calculated using Eq. ( 19 ), where D e equals 0. Note that the weights of the RIP vectors, with the same order of points from the same RIP, are the same for all the training data if D e is 0. 6 Experiment results and discussions In this section, three types of evaluation methods are intro-duced: visual analysis, a method that uses the DTW distance, and questionnaire survey. First, the selected samples of the training data and the synthesized results are shown in figures and are analyzed. Through this analysis, it is verified if the proposed model was synthesized as expected.

However, as it is difficult to objectively evaluate all the synthesized results via visual analysis, an approach to evalu-ating the individuality and variety of the synthesized charac-ters is proposed herein. Although conducting visual analysis has become solely popular [ 10 , 13 , 17 , 38 ] and character rec-ognition performance [ 3 , 33 ] and rating by people [ 19 ]have been tried in the related literatures, it is believed that they are not suitable for this research. The writer X  X  individuality can-not be examined through a recognition test, and the people X  X  rating is subjective especially in the evaluation of variety. Moreover, it is difficult to illustrate all the synthesized char-acters if there are numerous characters.

Our approach to evaluating the individuality and variety of a test set involves the utilization of the DTW distance. DTW, which was introduced in Sect. 3.4, is a popular method for calculating the dissimilarity between two sequential pat-terns. It has shown successful results in terms of verifying the authentic writers of handwritten characters written using a pen-tablet device. Although the reported error rates vary depending on the databases used and on the modification of the algorithms, the error rates are generally under 5% for signature verification [ 9 , 12 ] and 1% for writer verification [ 14 , 21 ].

Further, the questionnaire was introduced to evaluate the proposed model subjectively. This is because the DTW distance can be different from a human X  X  sense, although distance is a popular way of determining a character X  X  indi-viduality. Samples of authentic and synthesized characters were mixed up with the other subjects X  characters and were shown to the subjects. The subjects were then told to choose the characters with similar styles as their own characters, and those with abnormal shapes. Two features can be stud-ied through the results of this questionnaire: the number of subjects who cited the synthesized characters as being simi-lar to their own characters and the number of characters that were cited as having abnormal shapes. 6.1 Experimental data For the experiment, handwritten data were collected, using the Wacom Cintiq 21UX device, from 40 writers. The subject writers consisted of 32 Japanese, two Koreans, two Chinese, and two Taiwanese. All the non-Japanese subjects were stu-dents in a Japanese university and thus had experience in Japanese handwriting. Each subject was asked to write natu-rally using his/her own handwriting style, keeping the writing orders of the strokes and the stroke numbers the same. Each Arabic number, lowercase English letter, and Japanese Kanji letter were written 20 times. Table 1 compares the datasets in the related literatures and those of University of Aizu (UoA), and Fig. 14 shows the handwritten character samples of the 40 subject writers.

The Japanese Kanji letters originated from China, and the letters consist of numerous characters. The most commonly used set includes 1,945 characters, the level 1 JIS (Japanese Industrial Standard) set includes 3,000 characters, and the level 2 JIS set includes 6,000 characters.

In the context of handwriting synthesis, it is believed that what makes Kanji special is the spatial complexity of its characters. Although there are many Kanji letters, most of the strokes in their characters have relatively simple shapes. Most of the strokes are straight lines or simple curves, and even the most complicated strokes show shapes similar to  X  X . X  These simple strokes compose all the complex charac-ters with different interstroke relations. Besides, it should be noted that the complexity increases as the number of strokes increases.
 Hence, 72 characters were selected from the level 2 JIS Kanji list, according to the number of strokes and the interstroke relations between the strokes. For this selection, the classification of Ota et al. [ 25 ], which classifies the relations between consecutive Kanji strokes into 12 groups, was utilized. The stroke-order dependency was removed, the ambiguous groups were eliminated, and additional groups were defined. Table 2 shows the selected letters according to the groups and stroke numbers. Inside denotes the relation when a stroke is surrounded by other strokes, Columns/Rows when two groups of strokes are arranged vertically/horizon-tally, LeftDown-RightUp/LeftUp-RightDown when a stroke exists at other strokes X  left-down/left-up side, Penetrate-center / Penetrate-not-center when a stroke penetrates other strokes X  center/other areas, and Tangent-down / Tangent-up when a vertical stroke X  X  upper/lower end point comes in con-tact with a horizontal stroke. As Kanji letters consist of many strokes, a letter can be included in several groups simulta-neously. Each writer X  X  data for a letter are randomly divided into training and test sets; the former is used to construct handwriting models and the latter is for testing purposes only.
After obtaining all the data, the handwritten characters were preprocessed so that the stroke orders and connections would be the same for a letter of the same writer. First, the characters with a different stroke order were fixed manu-ally by changing the orders. Second, for a writer X  X  letter, the characters with different stroke connections to the others were used only for the test set because the proposed system cannot handle this case for training the model. Finally, the wrong characters such as the characters with redundant/miss-ing strokes were removed from the database. 6.2 Visual analysis Figure 15 shows the authentic and synthesized characters of a writer when five authentic patterns were used for train-ing, and  X  c for Eqs. ( 6 ) and ( 7 ) was set to 0.05. To visually explain the results, one Arabic number, three English letters, and seven Kanji letters of typical examples of a writer were selected from 108 letters. The Kanji letters were chosen as they represent all the stroke relation groups. The Kanji letter at the ninth row represents both the LeftUp-RightDown and Penetrate-center groups, and the last letter represents both the Tangent-down and Penetrate-not-center groups. In this selection, the letters with smaller numbers of strokes were preferred because it would be easier to observe the shapes of the strokes and the interstroke relations in such letters.
As shown in Fig. 8 , the most synthesized characters are well constructed, having the shapes of real handwritten char-acters. Most of the strokes X  shapes are composed of the training data, as intended in the proposed model, creating a difference from the originals but not too much difference that it would spoil their personalities. For example, the sev-enth synthesized character of the number  X 2 X  seems to have similar shapes as the fourth training character at the starting part, the fifth character at the upper curve, the second charac-ter at the succeeding slope and curve, and the first character at the last part of the character. These compositions can be easily observed in the other characters: at the ovals of  X  X  X  and at the sharp and round curves of  X  X  X  and  X  X . X  As the proposed model combines segments of training patterns, it is also possible to generate exactly the same characters for a letter, such as the second and fifth synthesized  X  X . X 
Expressions of the variety and individuality of interstroke relations are apparent in the Kanji letters. A synthesized stroke varies by changing its position, but it varies while pre-serving the interstroke relations of the training data. At the Kanji letter at the fifth row in Fig. 15 , for example, two strokes exist inside a box structure in the training data. The synthe-sized strokes in the box float but stay within the box whenever the strokes X  shapes change, while touching the box often as it is in the training data. The other authentic interstroke rela-tions preserved in the synthesized characters are observed as follows. At the two horizontal strokes at the sixth letter, the left-end point of the right stroke is equal to or lower than the right-end point of the left stroke. The vertical segment of the reversed  X  X  X  shape is located near the x coordinate of the points at the right side of the upper part of the letter at the seventh row. The two horizontal strokes of the subchar-acter  X   X  of the eighth letter are located vertically within the box shape ( ) on the left. The diagonal stroke pene-trates the horizontal stroke at the ninth letter, and the stroke is tangential at the tenth letter. Note that the small part of the diagonal stroke penetrates the second and third synthesized characters of the Kanji letter at the tenth row but that this phenomenon also occurs at the fourth and fifth training data. The two vertical strokes at the last letter generally float within the two horizontal top and bottom strokes and are often tan-gential to or slightly penetrate the bottom stroke as they are in the training data.

Compared to the intrastroke variation, however, the per-sonalities of the interstroke variations are not very evident. The first reason for this is that there are many factors that influence a stroke X  X  size and position, which makes it dif-ficult to discover from where the interstroke relations of the synthesized characters originated. The second reason is the developed resizing and relocation processes. The mean or weighted-mean positions were calculated from the inter-stroke influence points to avoid abnormal character struc-tures, and the interstroke relations are mixed rather than chosen from parts of the training data. 6.3 Evaluation using DTW distance Before the start of the evaluation, two preprocessing proce-dures were adopted for the accurate comparison of the shapes. All the characters were resized before calculating the dis-similarities and varieties so that they would have the same width or height, where the smaller difference was selected. The width/height ratio was preserved via resizing. The maxi-mum width and height of the written characters were used as standards. Further, the points in a character were resampled using the method described in Sect. 4.1 so that the charac-ters X  shapes could be accurately compared, because without resampling, the writing speed can affect the calculation of the distance [ 12 , 32 ].

Based on the DTW distance between two patterns, the dissimilarity between the test and authentic sets is defined to represent individuality, and the dissimilarity among the test sets as variety. The dissimilarities are normalized by the distance among the authentic patterns. The dissimilarity ( and variety ( V ) for a character set of a letter ( T ) of a writer are expressed with the following equations: D ( T ) = D  X  D = V (
T ) =  X  V = D g ( 0 , 0 ) = 0 , (28) p ( i )  X  p ( j ) = p x ( i )  X  p x ( j ), p y ( i )  X  p y ( j where A denotes the authentic characters; A i and T i are the i th characters of datasets A and T , respectively; | T | number of characters in T ; p 1 and p 2 are two different hand-written characters; l and L are the natural numbers; L is a con-stant called  X  X lope length X  in DTW; p ( i ) is the xy coordinates of the character p  X  X  i th point; d(p(i),p(j)) is the Euclidean dis-tance between the two points p ( i ) and p ( j ) ; and | p number of points in the character p . L , the slope length, can-not be determined analytically [ 30 ] and thus must be decided experimentally as N in Eq. ( 12 ). In this paper, L is determined practically and flexibly according to the lengths of the data. This is because the matching distance becomes infinitive if L is too small compared to the length of the data, and because the matching itself can be inaccurate if L is too big. The equation for L is L = [ 3  X  | p where | p 1 | and | p 2 | are the lengths of the longer and shorter data, respectively. D pattern , set and D patterns represent the dis-tances between a character and a character set, and between two sets of characters, respectively. In the above equations, the dissimilarity functions, which are used to verify the writer of a signature, are used. In signature verification research, an unidentified signature is considered authentic if the dissim-ilarity is smaller than a threshold criterion and is rejected if it is bigger. Following this idea, it is reasonable to think that a character is synthesized well if the dissimilarity is as small as the ones of the authentic characters. The method of calculating the dissimilarity of a character (Eqs. 23 and 27  X  30 ) was taken from [ 2 ], and the mean dissimilarity for the synthesized characters is defined as the total dissimilarity for a letter X  X  character set. The proposed variety of a character set (Eq. 26 ) represents the mean of the minimum distances between the characters. As any character with the same shape decreases the variety, it can be used to evaluate how similar the synthesized characters are. Note that the variety of a test-ing character set is normalized by the variety of the authentic characters.

Figure 16 shows the averaged dissimilarities and vari-eties of the synthesized characters according to the num-ber of training patterns and the threshold ( X  c ) in Eqs. ( 6 ) and ( 7 ). The averaged dissimilarities and varieties can be easily obtained by calculating the mean of all the D and V ( T ) sinEqs.( 22  X  30 ) for each writer and letter. The dissimilarities and varieties of the authentic characters and the dissimilarity between the authentic and the other writers X  characters were calculated as indices. The dissimilarity of the authentic characters was calculated between the training and the test datasets. For the test dataset, ten characters were randomly selected from the characters written by other writ-ers to calculate the dissimilarity between the authentic and the other writers X  characters. The dissimilarity and variety were calculated for each letter and then averaged.

The results show that the dissimilarities of the synthesized characters varied near 1.0. This means that the synthesized characters have similar shapes as the authentic characters. Meanwhile, the dissimilarity decreases slightly as the number of training patterns or the classification threshold increases, but the causes are different. In this study, the decrease when the number of training patterns increased was caused mainly by the Kanji characters. Their dissimilarity dropped from 1.03 to 0.99, while the dissimilarity in terms of the numbers and English letters was around 1.03. This is attributed to the stroke resizing and relocation processes. As these two pro-cesses tend to average the features of the training patterns rather than selecting one, the common shapes appear more often when synthesizing characters with more training pat-terns. The cause of the decrease according to the classifica-tion threshold was different from the former. No significant differences were found according to the kind of letter. The features of the training data were averaged naturally if the threshold increased and if the number of available paths of the probability tree decreased. This decrease directly affected the variety; the variety decreased continuously as the thresh-old increased in the results after a short increase. The increase is attributed to the very low thresholds, which prohibit the points at an order to be grouped, but variation occurs only if some points are grouped together. Meanwhile, the variety generally tended to increase as the training data increased. This means that the proposed model learns various styles successfully from a number of characters.

Figure 17 shows the changes in the dissimilarity accord-ing to the diversity of the authentic characters ( X  D ) diversities of the authentic characters were uniformly cate-gorized into ten classes of degrees, and the dissimilarities were calculated for the characters in each class. The most and least diverse authentic characters are shown in Fig. 18 . These results reveal that the proposed model generally keeps its integrity with regard to the diversity of the authentic char-acters, except when the diversity is very low. The reason that the characters in class 1 show high dissimilarity is that the characters have very simple shapes. The characters in class 1 are  X 1, X   X  X , X  and  X  X  X  with straight lines, whereas the same let-ters with cursive styles showed more diversities. As authentic characters have very uniform and simple shapes, small vari-ations easily result with high dissimilarities. 6.4 Evaluation via a questionnaire An additional experiment was conducted with the subjec-tive evaluation. Three authentic characters, three synthesized characters, and six other writers X  authentic characters were presented per letter. As all the characters were resized as in the above experiment using DTW distance, it was difficult to distinguish the characters via the size. The subjects were asked to choose six characters that seem to have their own handwriting styles as well as any character with an abnormal shape. As this experiment was conducted five months after the handwriting collection, the subjects did not remember the exact style they used when they wrote. Twenty subjects participated in this experiment, and the other writers X  char-acters were selected randomly from all the subjects X  data. Table 3 shows the results. No statistical differences are shown between the selection rates of the authentic and synthesized characters, as the subjects X  own styles. The subjects were able to distinguish their own handwriting styles, and it was proven that the synthesized characters preserve the authentic personalities of their writers. It is also possible for a syn-thesized character to lose the letter X  X  shape, however, while preserving the individuality. This was verified by making the subjects select abnormal characters. Most of the selected characters were the other writers X  characters as 1.74% were determined to be abnormal, whereas only 0.40% of the syn-thesized characters were selected as abnormal. This rate is extremely low as it is not very different from the selection rate of the authentic characters.

An ethical issue can be raised from the present study because the study seems to be on the opposite side of writer verification. In our opinion, however, the possibility that the results of this study will be used to commit a crime is very low. First, authentic samples are necessary to synthesize a person X  X  handwriting. At this stage, a criminal can directly use the authentic samples to fool a signature verification system. The criminal may not find any good reason to use the proposed system. Second, most authentication processes occur in real time. If it is required that the signing be done using an electronic pen and tablet, it will be very difficult to find an opportunity to use the synthesized signature data. 6.5 Increasing the variety by selecting an influencing point As synthesizing characters with personal styles is the pur-pose of this paper, the proposed method was focused on allowing variation within a safe range. It is possible, how-ever, to synthesize more diverse characters by adjusting the method of the influencing point selection. A range criterion was introduced for this purpose, and the influencing points were selected within the range. Figure 19 shows the synthe-sized characters varying a threshold. The range criterion r is relatively defined for a character as r = max (w, h )  X   X , (32) where w and h are the width and height of the charac-ter, respectively, and  X  is the varying threshold. As shown, the variety of synthesized characters increased as the range became narrower. This is because the degree of freedom becomes higher with fewer influences from other points. It was also observed, however, that the written styles changed slightly as the threshold changed. The different styles of the loop, corner, and relative positions between the parts of the characters were often shown to have small thresholds. More-over, the spatial structures of the characters were half broken when only the closest points were selected as the influencing points. 7 Conclusions and future works In this paper, a statistical handwriting model that can synthe-size various characters while preserving a writer X  X  style was proposed. The proposed model simplified the handwriting process into one that located the points X  positions sequen-tially, where a point was influenced by some of its preceding points and was expressed with its influencing points. After classifying the points of the training data at each order, the observed transitions between the clusters in the training char-acters were counted, and the appearance probabilities were calculated. In this paper, to simplify the proposed model, it was first assumed that the characters have the same numbers of points as the same letters of the writer. This assumption was later realized by proposing modified DTW and template pattern generation techniques.

The proposed model was designed for both single-and multiple-stroke characters, such as Arabic numbers, small English letters, and Japanese Kanji letters. To synthesize multiple-stroke characters while avoiding abnormal charac-ters or the loss of personal styles, stroke resizing and relo-cation processes considering the interstroke relations were presented herein.

The synthesis results were used to examine the proposed model in three types of experiments: one involving visual analysis by these researchers, a DTW distance test, and a questionnaire survey. They successfully proved that vari-ous characters can be synthesized from a limited number of data and that the personalities are preserved stably in the characters.

Several steps can be taken to extend this work. First, the restriction that the training characters must consist of the same number of strokes must be overcome. In these authors X  opinion, including the stroke segmentation procedure in the learning phase is a possible solution to this. Second, a smooth connection between the adjacent characters can extend this work. As the proposed model considers a character an inde-pendent unit, it is believed that using conventional methods for this purpose will not pose problems. Third, the user X  X  writing effort can be reduced. Although character synthesis in the proposed system requires all the parts of a character, a character may be synthesized using the common radicals in another character. This is because many Kanji letters have common radicals.
 References
 ORIGINAL PAPER Won-Du Chang  X  Jungpil Shin Abstract Synthesizing handwritten-style characters is an interesting issue in today X  X  handwriting analysis field. The purpose of this study is to artificially generate training data, foster a deep understanding of human handwriting, and promote the use of the handwritten-style computer fonts, in which the individuality or variety of the synthesized characters is considered important. Research considering such two properties together, however, is very rare. In this paper, a handwriting model is proposed to synthesize vari-ous handwritten characters while preserving the writer X  X  indi-viduality from a limited number of training data, using a statistical approach. The proposed model is verified in sin-gle-and multiple-stroke characters, such as Arabic numbers, small English letters, and Japanese Kanji letters. Synthe-sized characters are evaluated in three ways. First, they are analyzed visually using the selected samples, and the rela-tionship between the training and synthesized characters is explained. Second, the personalities and varieties of all the data are evaluated using a conventional writer verification method. Third, a questionnaire is developed and administered to evaluate the subjective responses of the users regarding the personal styles of the synthesized characters. The results prove that the proposed model stably synthesizes personal-ized characters by being invariant to the number of train-ing data, whereas the variety increases gradually as the data increase.
 1 Introduction Handwriting synthesis is the artificial generation of human handwriting. This area is not popular among the public, unlike voice synthesis, which has come to be well known in recent years. Although like voice synthesis it also mim-ics human behaviors, the two have a big difference in terms of their purposes. Because the mechanical pattern of written characters is more welcome than that of handwritten ones in many cases whereas human voices are considered more user-friendly than mechanical voices.

The purposes of handwriting synthesis as reflected in the pertinent literatures can be grouped as follows in our opinion: (1) to generate training data automatically for recognition systems [ 35  X  37 ]; (2) to foster an understanding of human handwriting [ 4 , 5 , 17 , 28 , 29 ]; and (3) to promote the use of synthesized characters instead of computer fonts [ 10 , 19 ]. In the first purpose, generating various handwritten charac-ters and helping facilitate the learning procedure are focused on. Instead, the accuracy of generating a human-like pattern is not considered much because some strange patterns do not cause the recognition system to decline considerably. As for the second purpose, the research conducted with such purpose may extend the field of handwriting synthesis by connecting it to the other related fields. The created model can be used for other applications in handwriting-related research fields, such as handwriting recognition, signature verification, and writer identification. Lastly, with regard to the third purpose, as the writing style differs from one per-son to another, it is possible to show one X  X  own characteristics in documents using the personalized handwriting synthesis system.

In this paper, two issues are discussed in line with the second and third purposes: (1) how to vary the shapes of the generated characters (variety) and (2) how to synthesize the characters while preserving the writer X  X  handwriting style (individuality). Variety is connected to the capacity of a hand-writing model in line with the second purpose. If a model can synthesize multiple handwriting styles, it means that the multiple styles are correctly stored in such single model. Variety also has an important role in relation to the third purpose: It helps create more natural documents by pro-ducing characters with different shapes, whereas the static shapes of characters reveal artificially synthesized handwrit-ing shapes.

We think that the individuality is connected to the deli-cateness and precision of a model in relation to the second purpose. If a model can successfully reproduce a person X  X  handwriting, it means that the model can precisely distin-guish a person X  X  handwriting from that of another. In relation to the third purpose,  X  X ndividuality X  means that a user can decorate a document with a more accurate personal style.
The two aforementioned issues seem to be correlated based on the results of previous studies. Although variety may be allowed when synthesizing a person X  X  handwritten-style characters, high variety easily leads to individuality loss, and vice versa [ 6 , 37 ]. The goal of this study was to achieve both a higher individuality and a higher variety by using a novel statistical model.

In the latter part of this paper, a statistical character model that enables the synthesis of multiple characters statisti-cally while keeping one X  X  handwriting style is proposed. The related works are summarized in Sect. 2 from the perspec-tive of the synthesized characters X  variety and individuality. The general architecture is described in Sect. 3 . A statistical stroke model that allows personalized variation is proposed in Sect. 4 , and its extension to the multistroke character is explained in Sect. 5 . Section 6 describes the experiment results, and the conclusions and a description of the future works are presented in the last section. 2 Related works Each individual has his/her own handwriting style. It has been reported that handwritings have similar shapes even on different materials, although the musculature and forces involved widely differ [ 8 ]. Osborn [ 24 ] explained that the individuality starts from childhood. Young schoolchildren write uniformly when they first learn to write. The writing styles change for each person from the time they start to use handwriting practically until they find the easiest way to write. The individuality of people X  X  handwritings has helped arrest a criminal through the screening of 600,000 handwrit-ing samples [ 1 ], and the results of handwriting similarity analysis have assisted the jury in the U.S. [ 34 ].
From another point of view, it is obvious that varia-tions exist in the handwritten characters of the same person. Such variations, however, are not too much that the written characters can already be regarded as having been written by different individuals. A ten-year study on handwritings [ 15 ] reported that the handwriting styles of mature individ-uals aged 21 X 60 only slightly changed. Further, 45 out of 50 handwritings were correctly identified by experts as the same individuals X  handwritings ten years later. Hilton [ 11 ] described this individuality of handwriting variation as fol-lows:  X  X n individual X  X  handwriting is made up of complexity of habitual patterns that are repeated within a typical range of variation around the model patterns. X 
In the research field of handwriting synthesis, using peo-ple X  X  written characters with little change is one of the easi-est ways to synthesize characters. As there are relatively few English letters and as the connections between the charac-ters express one X  X  individuality well, this method is utilized to focus on the connections. Guyon [ 10 ] proposed a juxtaposing method that collects isolated and connected English letters so that the collected handwritten characters can substitute for typed characters. Lin and Wan [ 19 ] proposed a synthe-sis method of English strings. In the juxtaposing method, the connections between the characters are smoothed, and small random movements of the characters X  control points are allowed. These enable the synthesis of a handwritten string while the connection information between the char-acters does not abound. Jawahar and Balasubramanian [ 13 ] introduced a method of synthesizing Indian letters by juxta-posing the strokes to compose a multistroke character. The stroke to juxtapose is chosen randomly from among the train-ing strokes, or the mean stroke with Gaussian random noise is used to synthesize various strokes. Meanwhile, the inter-stroke relations between the consequent strokes are utilized to lay out multiple strokes.

There have been attempts to employ the hidden Markov model (HMM) or the Bayesian network for the aforemen-tioned purpose. These methods first analyze the sample char-acters and generate a probabilistic character model, and then they synthesize the most probable character using the model. As only the most probable character is produced, however, the variances are severely limited in these models. Sin and Kim X  X  [ 33 ] HMM synthesizes Arabic numbers and lower-case English letters. Their single-network HMM produced the numbers in human-like styles, but the synthesized Eng-lish letters were barely readable, and the original writer X  X  individuality was difficult to find therein. Choi et al. [ 4 ] and Choi and Kim [ 6 ] proposed a method of synthesizing Arabic numbers and Korean characters based on a Bayesian network model [ 3 ]. The synthesized characters manifest the writers X  styles, but very little variance is expressed. Although there was an attempt to study the variances in detail [ 5 ], the vari-ances of the synthesized characters were limited to the global shapes. The personalities of the characters were found to decrease as the variance increases.
Allowing global modification is one way of creating variety. The following methods allow variety via global modification, but their capacity to create variety is limited because local changes are not allowed. At the same time, whether global modification preserves the personalities of synthesized characters is also being questioned. Setlur and Govindaraju [ 31 ] proposed a synthesizing method for cursive words using Hollerbach X  X  oscillation theory of handwriting. They converted the xy coordinates of characters into vector spaces and created variety by modifying the parameters in the vector-space diagram. As a result, various character slants and smoothness (related to the writing speed) of synthesized cursive words were reported.
 Wang et al. [ 38 ] proposed a method of synthesizing cursive English words. Affine parameters were calculated between each sample character and a template, and then variation was introduced by modifying the affine parameters and provid-ing some noises when synthesizing. The variation was lim-ited so that the synthesized characters would not lose their individuality.

The use of morphing functions between or among hand-written characters can be classified as a global modification. Devroye and McDougall [ 7 ] and Zheng and Doermann [ 39 ] synthesized English letters, and Mori et al. [ 20 ] synthesized Arabic numbers. The results of the use of these methods have the forms of human handwriting. These methods find corre-sponding points between or among characters and calculate the morphing functions within the characters. A character is synthesized by choosing a morphing parameter, which deter-mines the amount of morphing. In the results, the synthesized characters are the linear variations between or among the characters. The local variations are severely limited in this method, however, and how much the global variations reflect one X  X  individuality remains a question.

Plamondon and Guerfali [ 29 ] proposed a synthesis method using a kinematic model named  X  X elta-lognormal theory X  [ 26 , 27 ], which explains a human handwriting with ago-nist and antagonist systems. This method was exploited for oriental languages [ 17 , 29 ], and it was also utilized to connect synthesized characters smoothly [ 38 ]. It has been proven that this method can extract personal param-eters from a handwritten character and can regenerate var-ious characters by controlling the parameters. However, it is not easy to express local variance using this method. This is because controlling the parameter affects the char-acters X  general shapes and because a way of composing personal features from a number of characters has yet to be found.

Wada et al. [ 37 ] employed a genetic algorithm (GA) to synthesize manifold characters. A computational model and fitness function successfully synthesized various characters, but many of the synthesized characters lost their personali-ties, and some lost even the shape of the letter. 3 General architecture Before describing the proposed handwriting model, sev-eral terms in this paper must be defined for clarity X  X  sake. A  X  X troke X  is defined in this paper as a component written without pen-up, and a character is said to consist of one or more strokes. A stroke is understood as a sequence of points, and a line segment between two points is named a  X  X egment. X  For any two points, the two points are said to be visible to each other if the direct line between them is not blocked by any preceding segment of the latter point. The visible points preceding a point are called  X  X nfluencing points X  of the point.
The general architecture of the proposed approach is shown in Fig. 1 . This approach regards a character as a combination of independent stroke shapes and considers the relationship of their relative positions and sizes. Hence, the shapes of the strokes in the same order are trained to cre-ate independent stroke models, and the relations between the strokes are trained separately to create interstroke mod-els. To synthesize a character, strokes are synthesized from each stroke model, and then their positions and sizes are adjusted using the interstroke model. It should be noted that all the characters were resized before the training so they would have the same width or height as the standard size. The width/height ratio was not changed in the resizing. 4 Statistical stroke model People have their own styles of writing strokes, and certain styles are observed more often than others. One easy way of calculating the probabilities of writing styles is to categorize strokes X  shapes at the stroke level. The stroke data of a writer can be classified, and probabilities can be assigned according to their appearance ratios. Niels and Vuurpijl [ 23 ] classified handwritten characters by calculating the distances between the characters and by generating a dendrogram. This method, however, requires too much training data, and it is difficult to reflect partial writing styles with insufficient data using such method. Figure 2 shows different styles of starting a stroke, where the styles of starting a stroke and the other parts of the stroke are not much related. If characters are categorized at the character level, the whole parts are considered in a package even when they are not related.

To synthesize variable and personalized strokes using a small number of training samples, a statistical approach is proposed. In this approach, the position of a point is influ-enced by the positions of its preceding and spatially close points. At first, it is assumed that the handwritings with the same strokes have the same numbers of points for a writer and that the points at the same order represent perceptually similar parts in the context of the strokes X  shapes. A point adjustment method that satisfies this assumption will be pre-sented in Sects. 3.4 and 3.5. 4.1 Preprocessing A sampling procedure [ 32 ] was employed to reduce the com-plexity of handwriting analysis. This method was selected because of its simplicity and the ease by which it can control the amount of information lost. The algorithm for a stroke is as follows: (1) Remove a point from the stroke if its xy coordinates are (2) Select the end points of the stroke. (3) Sequentially connect the selected points with the line (4) Among the unselected points, find the farthest from the (5) Repeat 3 X 4 until no more point is selected. 4.2 Vector classification To generalize one X  X  handwriting style, a handwritten stroke is considered a set of consequential points, and the points at the same order are classified when a number of strokes are given for training. Each point of a stroke is expressed with the influencing vectors from some of its preceding points, and a stroke is expressed as the sequential set of the points. Here, it is assumed that a point X  X  position is directly influenced by its visible preceding points.

This is because it is believed that the influence of an invis-ible point is much less than the influence of the blocking segment. After the detection of the influencing points for all the training strokes, a point is determined as the representa-tive influencing point (RIP) if more than 40% of the points at the same order are influencing points. Figure 3 illustrates the classification process at an order of a stroke. A point is expressed with a number of directional vectors from its RIPs, so that the points at the same order have the same dimensions. Let these vectors be called  X  X IP vectors. X 
Classification is conducted at each order according to the directions and lengths of the directional vectors. A simpli-fied ART2 (adaptive resonance theory 2) algorithm [ 16 ]was used for classification in this paper because of its simplicity. Unlike K-means, this method does not require the number of clusters in advance but requires tolerance thresholds. Denot-ing  X  as a set of RIP vectors to a point of a training data, the classification algorithm is defined as follows: (1) Set the maximum iteration M and the thresholds (2) For each training data, (3) Repeat step 2 M times and stop if there is no more 4.3 Statistical stroke model and synthesis Based on the information obtained from the vector classi-fication, the probability for each cluster was calculated. To calculate the probability from a writer X  X  styles, the number of transition paths between the clusters of the consecutive orders was counted. Figure 5 shows a handwriting model when a handwritten stroke consists of three segments. The classified vector clusters are arranged at each order in a row, where C ij denotes the j th vector cluster of the i th order. The order 0 denotes the starting point of the handwriting, which is the origin ( 0 , 0 ) for every case, so that every model has only one cluster at the first order. The transition probability is calculated for each cluster at each order. For an instance in the figure, the transitions from C 22 are observed once to C and three times to C 32 , and then the probabilities are 0.25 and 0.75 for each transition, respectively.

To synthesize a stroke, the system synthesizes points order by order sequentially and interpolates them using the
C third-order spline (see Fig. 6 ). At each synthesis of a point, let the t th RIP be denoted as RIP(t) and the coordinates of the preceding synthesized points of the RIPs as G RI P ( t ) . A clus-ter is randomly selected according to the paths and probabili-ties, and the position of a new point is estimated by adding the estimated points differ according to the RIPs, the weighted mean is calculated using the length of the vectors. Assum-ing that the closer RIPs with smaller variations have greater influence, the weight of the t th vector is defined as w( where  X  RI P ( t ) is the standard deviation of the t th RIP vectors among the training data, and  X  and  X  are constants for adjust-ing the importance of C ( t ) and  X  RI P ( t ) . w( t ) s are normal-ized so that the summation of the weights would become one. Figure 7 shows the weights obtained by changing C ( t ) and  X  show gradual decreases as the distance of a point to its influ-encing point increases, where the standard deviation of the RIP vector affects the maximum weights when the positional distance is 0. The weight is also affected by the constants. The use of a higher  X  value makes the decrease steeper, and the use of a higher  X  value makes the effect of the standard deviation stronger by decreasing the maximum weight. In this paper,  X  and  X  were set to 1.1 and 0.5, respectively. They were determined experimentally so that the stroke model would not synthesize abnormal characters. Two things should be noted for the positional distance in Fig. 7 : (1) it is denoted as C ( t ) in Eq. ( 8 ); and ( 2 ) it is the relative distance to the charac-ter size, where the characters are resized so that their widths or heights will be 100, and where the smaller difference is selected. The width/height ratio is preserved via resizing.
Before the calculation, an RIP(t) is disabled if its line seg-any previously synthesized segment. If all the RIPs are dis-abled, a cluster is reselected randomly for the point, or the stroke is regenerated from the starting point if there is no other possibility. 4.4 Dynamic time warping with segment division Matching two sequential signals via dynamic time warping (DTW) is one of the popular ways of finding the correspond-ing points between two similar signals. As it employs the dynamic programming (DP) technique to reduce the time complexity, it is also called  X  X P matching. X  The details of DTW can be found in the results of the study conducted by Ney [ 22 ]. DTW basically involves one-to-many matching, and some points are to be ignored when one-to-one matching is constrained (see [ 18 ]), but one-to-one matching between two strokes is premised on the proposed handwriting model.
Hence, an attempt is made to ensure one-to-one matching without losing the shape information by inserting new points to the strokes. Figure 8 describes the concept of the proposed DTW, where the solid and dashed lines in (a) are parts of two signals. If a 0 and b 0 as well as a 2 and b 1 are aligned, respec-tively, the result of the conventional DTW becomes (b) if skipping a point is allowed. If skipping a point is not allowed, then b 1 will be aligned to both a 1 and a 2 (see Fig. 8 c), and it will not satisfy one-to-one matching. Instead, a new point ( b  X   X   X  b to to create more than one point within a segment. When using this division concept, the conventional DTW equation should be modified. Let us denote the vectors from the ( i  X  1 ) th to the i th points and from the ( j  X  1 ) th to the j th points of signals I and J as P I i and P J j , respectively. The DTW distance between the two subsignals { P I a | 0  X  a  X  i } { g ( 0 , 0 ) = 0 , (9) g ( i , j ) = d ( i , j ) + min where B I k and B J k are the branch values of the slope con-straints in DTW, N is the number of branches, (
B I k , B J k ) | 1  X  k  X  N = ( 1 , 1 ), ( x , 1 ), ( 1 , d ( i , j ) or dist ( P i , P j ) is the Euclidean distance between the two points P I i and P J j , and S S S S
Note that P I i ( P J j ) is divided into B J k ( B I k ) tors to calculate T ( i , j , k ) and that X P m th divided vectors of P I of branches, cannot be determined analytically [ 30 ] and thus has to be decided experimentally according to the purpose of (a) (b) (c) (d) the calculation of the distance, data type, sampling frequency, etc. In this paper, N = 11 is used as it showed stable results. 4.5 Aligning points among a group of handwritten strokes In this section, the problem of how to align points among a number of handwritten strokes is discussed as the corre-sponding points must be found among the training strokes for the proposed handwriting model. The conventional DTW cannot address this problem because it aligns points between two signals and not among a group of signals. Both the one-to-one and one-to-many matching methods cause prob-lems: The former cannot be used because the correspond-ing points become ambiguous, and the latter cannot be used either because it causes shape information loss when a point is skipped (see the example in Fig. 10 ).

Our approach to addressing this problem is to use the DTW that allows segment division, which is proposed in Sect. 3.4. The method ensures one-to-one matching between two sig-nals without ignoring any point, but it may cause another problem. As the task here is to find the perceptually simi-lar corresponding points among many strokes, the following assumption must be satisfied: If points a and b as well as b and c are aligned, then a and c are to be the corresponding points, where a , b , and c are the points of strokes A , respectively, and strokes A and B and B and C are matched sequentially. It is not satisfied, however, if b is a point added via division, and if C has a point similar to a (see Fig. 11 ). This is because the division generates vectors with the same directional values: The directional information of a is lost when b is used as the representative of a .

To address this problem, a method for aligning points among many strokes is proposed. This problem can be addressed by matching strokes via a template that expresses the directional features of the training data. To create the template, one of the training strokes is first selected as a tem-plate, and then the other strokes are matched one by one to the template. At each matching process, a point of the train-ing characters substitutes for the template if it is aligned to a divided point of the template. Here, substituting a point means substituting the point with a vector from the point directly preceding it. Meanwhile, as the alignments among the enrolled strokes are updated simultaneously with the seg-ment division, it can be assumed that the new alignment to the template does not falsify the alignments among the enrolled signals. Figure 12 shows two input characters and the template generated from them. The template includes all the curves in both training characters with the proposed tem-plate generation method. 5 Statistical model of a letter Based on the stroke model in Sect. 3 , a statistical handwriting model that can represent the handwriting of a multistroke let-ter is introduced. The multistroke letters must be considered (a) (b) (c) is designing the handwriting model, including oriental let-ters, because there are few multistroke letters in English but multistroke oriental letters (Korean, Japanese, and Chinese) abound.
 In the related literatures, Plamondon et al. [ 29 ] and Lee and Cho [ 17 ] located a new stroke X  X  starting point using only the relation to its directly preceding stroke X  X  end point. Although this method synthesized the well-shaped multistroke charac-ters by modeling a character holistically, it is easy to place a stroke abnormally if its shape varies. Moreover, there are many strokes of oriental characters that are not consecutive but are related to each other. Jawahar and Balasubramanian [ 13 ] located a synthesized stroke according to its directly preceding and succeeding strokes. This method is apparently effective in locating a stroke at an adequate place when the relations between the consecutive strokes are strong, but it may fail if they are not.

In this paper, the first point of a stroke is located accord-ing to the related points of its preceding strokes, and then the stroke is relocated and resized utilizing the interstroke rela-tions to all the points of the stroke. As a result, the shape of a stroke except the width/height ratio is independent of the interstroke relation, but its size and location depend on such relation. 5.1 Statistical tree for a multistroke letter The fundamental concept of statistical tree generation is to concatenate the stroke trees in Sect. 3.3. A point selected as an influencing point to a point ( s ) if p is prior to s and if the line segment ps does not penetrate any stroke prior to s , except the stroke including s . The influencing points are determined at each training character, and then the RIPs are determined using the same method as that used in Sect. 3.2. Except at the RIPs to the first point of each stroke, however, interstroke RIPs are ignored when constructing the tree and locating points at this step. This is because the shape of a stroke easily becomes abnormal and loses its individuality if interstroke influencing is allowed for the other points. In addition, the weight function of Eq. ( 3 ) for calculating the weighted distance between a cluster ( C i ) and an RIP vector set (v) is rewritten as w( t ) = 1 . 0 / (  X  +  X   X  D s ) D e , (17) D to calculate the distance between a cluster ( C i ) and an RIP vector set ( X ) , where C i ( t ) and  X ( t ) are the t th vectors of each set;  X  and  X  are constants set to adjust the importance of the positional distance and stroke-order difference; and D s is the difference between the stroke-order numbers. 1
Figure 13 shows the effect of the stroke-order difference on the weight function. As in Fig. 7 , the weight decreases gradually as the positional distance or the stroke-order dif-ference increases. It was designed in such a way, however, that even the weight of an RIP vector at a very different stroke order will become high when its positional distance is small. This is because it is believed that the influence of the positional distance is stronger than that of the stroke-order difference. Note that the distance in Fig. 13 is for the character after resizing using the same method as that shown in Fig. 7 . For this paper,  X  and  X  were set to 1.05 and 0.05, respectively. Their values were determined experimentally so that the stroke model would not synthesize abnormal charac-ters. The weight is also affected by the constants. Whereas has the same role as Eq. ( 8 ),  X  determines the importance of the stroke-order difference. As shown in Fig. 13 b, the weights of the RIP vectors at different stroke orders become similar when the value of  X  decreases.

Equation ( 8 ), the weight for estimating a new point X  X  posi-tion, is rewritten as w( where D e = C ( t ) , X  is a constant set to 0.5,  X  RI P ( standard deviation of the t th RIP vectors among the training data. The other denotations are the same as in Eq. ( 17 ). Note that the roles and effects of the constants are the same as those of the constants of Eqs. ( 8 and ( 17 ) because Eq. ( 19 )isamix-ture of such equations. The values of the constants were deter-mined experimentally so that the handwriting model would not synthesize abnormal characters. 5.2 Stroke resizing After synthesizing a stroke, it is resized to imitate the authen-tic interstroke relations because the stroke X  X  points other than the first point are located without considering the relations. The expected width and height values are calculated, respec-tively, using all the intrastroke and interstroke RIPs vectors, including the ones ignored in Sect. 4.1 . The RIP vectors of the training data are added to the coordinates of RIPs X  syn-thesized points, and then the mean coordinates of each point are calculated to determine the expected width and height.
Resizing is conducted so that the synthesized stroke would have the expected width and height, except in the follow-ing two cases: (1) when the synthesized stroke has a very small width or height to avoid abnormal shapes and (2) when the difference between the synthesized stroke X  X  size and the expected value is smaller than a threshold criterion. Note that the resizing process does not falsify the interstroke variation because the expected size depends on both the RIP vectors and the shape of the previously synthesized strokes. 5.3 Stroke relocation The location of a stroke is estimated using interstroke rela-tions, and the stroke is relocated if the estimated location dif-fers more than a threshold criterion from the location of the synthesized stroke. The estimated value of a point X  X  position (
E ) is determined as E = where  X ( t ) is the mean vector of the RIP vectors, starting from RIP(t), among the training data; G RI P ( t ) is the coor-dinate of RIP(t)  X  X  synthesized points; and w( t ) is a weight function for  X ( t ) .Eq.( 19 ) is exploited for w( t ), where D equals  X ( t ) . As the differences between the synthesized and estimated points vary at each point, the movement of stroke ( M ) is defined by calculating the weighted mean of the expected movements at all the points as M ( dx , dy ) = where E i and G i are the i th points of the estimated and syn-thesized strokes, and w i the mean value of the weights for theRIPstothe i th point. The weight of an RIP is calculated using Eq. ( 19 ), where D e equals 0. Note that the weights of the RIP vectors, with the same order of points from the same RIP, are the same for all the training data if D e is 0. 6 Experiment results and discussions In this section, three types of evaluation methods are intro-duced: visual analysis, a method that uses the DTW distance, and questionnaire survey. First, the selected samples of the training data and the synthesized results are shown in figures and are analyzed. Through this analysis, it is verified if the proposed model was synthesized as expected.

However, as it is difficult to objectively evaluate all the synthesized results via visual analysis, an approach to evalu-ating the individuality and variety of the synthesized charac-ters is proposed herein. Although conducting visual analysis has become solely popular [ 10 , 13 , 17 , 38 ] and character rec-ognition performance [ 3 , 33 ] and rating by people [ 19 ]have been tried in the related literatures, it is believed that they are not suitable for this research. The writer X  X  individuality can-not be examined through a recognition test, and the people X  X  rating is subjective especially in the evaluation of variety. Moreover, it is difficult to illustrate all the synthesized char-acters if there are numerous characters.

Our approach to evaluating the individuality and variety of a test set involves the utilization of the DTW distance. DTW, which was introduced in Sect. 3.4, is a popular method for calculating the dissimilarity between two sequential pat-terns. It has shown successful results in terms of verifying the authentic writers of handwritten characters written using a pen-tablet device. Although the reported error rates vary depending on the databases used and on the modification of the algorithms, the error rates are generally under 5% for signature verification [ 9 , 12 ] and 1% for writer verification [ 14 , 21 ].

Further, the questionnaire was introduced to evaluate the proposed model subjectively. This is because the DTW distance can be different from a human X  X  sense, although distance is a popular way of determining a character X  X  indi-viduality. Samples of authentic and synthesized characters were mixed up with the other subjects X  characters and were shown to the subjects. The subjects were then told to choose the characters with similar styles as their own characters, and those with abnormal shapes. Two features can be stud-ied through the results of this questionnaire: the number of subjects who cited the synthesized characters as being simi-lar to their own characters and the number of characters that were cited as having abnormal shapes. 6.1 Experimental data For the experiment, handwritten data were collected, using the Wacom Cintiq 21UX device, from 40 writers. The subject writers consisted of 32 Japanese, two Koreans, two Chinese, and two Taiwanese. All the non-Japanese subjects were stu-dents in a Japanese university and thus had experience in Japanese handwriting. Each subject was asked to write natu-rally using his/her own handwriting style, keeping the writing orders of the strokes and the stroke numbers the same. Each Arabic number, lowercase English letter, and Japanese Kanji letter were written 20 times. Table 1 compares the datasets in the related literatures and those of University of Aizu (UoA), and Fig. 14 shows the handwritten character samples of the 40 subject writers.

The Japanese Kanji letters originated from China, and the letters consist of numerous characters. The most commonly used set includes 1,945 characters, the level 1 JIS (Japanese Industrial Standard) set includes 3,000 characters, and the level 2 JIS set includes 6,000 characters.

In the context of handwriting synthesis, it is believed that what makes Kanji special is the spatial complexity of its characters. Although there are many Kanji letters, most of the strokes in their characters have relatively simple shapes. Most of the strokes are straight lines or simple curves, and even the most complicated strokes show shapes similar to  X  X . X  These simple strokes compose all the complex charac-ters with different interstroke relations. Besides, it should be noted that the complexity increases as the number of strokes increases.
 Hence, 72 characters were selected from the level 2 JIS Kanji list, according to the number of strokes and the interstroke relations between the strokes. For this selection, the classification of Ota et al. [ 25 ], which classifies the relations between consecutive Kanji strokes into 12 groups, was utilized. The stroke-order dependency was removed, the ambiguous groups were eliminated, and additional groups were defined. Table 2 shows the selected letters according to the groups and stroke numbers. Inside denotes the relation when a stroke is surrounded by other strokes, Columns/Rows when two groups of strokes are arranged vertically/horizon-tally, LeftDown-RightUp/LeftUp-RightDown when a stroke exists at other strokes X  left-down/left-up side, Penetrate-center / Penetrate-not-center when a stroke penetrates other strokes X  center/other areas, and Tangent-down / Tangent-up when a vertical stroke X  X  upper/lower end point comes in con-tact with a horizontal stroke. As Kanji letters consist of many strokes, a letter can be included in several groups simulta-neously. Each writer X  X  data for a letter are randomly divided into training and test sets; the former is used to construct handwriting models and the latter is for testing purposes only.
After obtaining all the data, the handwritten characters were preprocessed so that the stroke orders and connections would be the same for a letter of the same writer. First, the characters with a different stroke order were fixed manu-ally by changing the orders. Second, for a writer X  X  letter, the characters with different stroke connections to the others were used only for the test set because the proposed system cannot handle this case for training the model. Finally, the wrong characters such as the characters with redundant/miss-ing strokes were removed from the database. 6.2 Visual analysis Figure 15 shows the authentic and synthesized characters of a writer when five authentic patterns were used for train-ing, and  X  c for Eqs. ( 6 ) and ( 7 ) was set to 0.05. To visually explain the results, one Arabic number, three English letters, and seven Kanji letters of typical examples of a writer were selected from 108 letters. The Kanji letters were chosen as they represent all the stroke relation groups. The Kanji letter at the ninth row represents both the LeftUp-RightDown and Penetrate-center groups, and the last letter represents both the Tangent-down and Penetrate-not-center groups. In this selection, the letters with smaller numbers of strokes were preferred because it would be easier to observe the shapes of the strokes and the interstroke relations in such letters.
As shown in Fig. 8 , the most synthesized characters are well constructed, having the shapes of real handwritten char-acters. Most of the strokes X  shapes are composed of the training data, as intended in the proposed model, creating a difference from the originals but not too much difference that it would spoil their personalities. For example, the sev-enth synthesized character of the number  X 2 X  seems to have similar shapes as the fourth training character at the starting part, the fifth character at the upper curve, the second charac-ter at the succeeding slope and curve, and the first character at the last part of the character. These compositions can be easily observed in the other characters: at the ovals of  X  X  X  and at the sharp and round curves of  X  X  X  and  X  X . X  As the proposed model combines segments of training patterns, it is also possible to generate exactly the same characters for a letter, such as the second and fifth synthesized  X  X . X 
Expressions of the variety and individuality of interstroke relations are apparent in the Kanji letters. A synthesized stroke varies by changing its position, but it varies while pre-serving the interstroke relations of the training data. At the Kanji letter at the fifth row in Fig. 15 , for example, two strokes exist inside a box structure in the training data. The synthe-sized strokes in the box float but stay within the box whenever the strokes X  shapes change, while touching the box often as it is in the training data. The other authentic interstroke rela-tions preserved in the synthesized characters are observed as follows. At the two horizontal strokes at the sixth letter, the left-end point of the right stroke is equal to or lower than the right-end point of the left stroke. The vertical segment of the reversed  X  X  X  shape is located near the x coordinate of the points at the right side of the upper part of the letter at the seventh row. The two horizontal strokes of the subchar-acter  X   X  of the eighth letter are located vertically within the box shape ( ) on the left. The diagonal stroke pene-trates the horizontal stroke at the ninth letter, and the stroke is tangential at the tenth letter. Note that the small part of the diagonal stroke penetrates the second and third synthesized characters of the Kanji letter at the tenth row but that this phenomenon also occurs at the fourth and fifth training data. The two vertical strokes at the last letter generally float within the two horizontal top and bottom strokes and are often tan-gential to or slightly penetrate the bottom stroke as they are in the training data.

Compared to the intrastroke variation, however, the per-sonalities of the interstroke variations are not very evident. The first reason for this is that there are many factors that influence a stroke X  X  size and position, which makes it dif-ficult to discover from where the interstroke relations of the synthesized characters originated. The second reason is the developed resizing and relocation processes. The mean or weighted-mean positions were calculated from the inter-stroke influence points to avoid abnormal character struc-tures, and the interstroke relations are mixed rather than chosen from parts of the training data. 6.3 Evaluation using DTW distance Before the start of the evaluation, two preprocessing proce-dures were adopted for the accurate comparison of the shapes. All the characters were resized before calculating the dis-similarities and varieties so that they would have the same width or height, where the smaller difference was selected. The width/height ratio was preserved via resizing. The maxi-mum width and height of the written characters were used as standards. Further, the points in a character were resampled using the method described in Sect. 4.1 so that the charac-ters X  shapes could be accurately compared, because without resampling, the writing speed can affect the calculation of the distance [ 12 , 32 ].

Based on the DTW distance between two patterns, the dissimilarity between the test and authentic sets is defined to represent individuality, and the dissimilarity among the test sets as variety. The dissimilarities are normalized by the distance among the authentic patterns. The dissimilarity ( and variety ( V ) for a character set of a letter ( T ) of a writer are expressed with the following equations: D ( T ) = D  X  D = V (
T ) =  X  V = D g ( 0 , 0 ) = 0 , (28) p ( i )  X  p ( j ) = p x ( i )  X  p x ( j ), p y ( i )  X  p y ( j where A denotes the authentic characters; A i and T i are the i th characters of datasets A and T , respectively; | T | number of characters in T ; p 1 and p 2 are two different hand-written characters; l and L are the natural numbers; L is a con-stant called  X  X lope length X  in DTW; p ( i ) is the xy coordinates of the character p  X  X  i th point; d(p(i),p(j)) is the Euclidean dis-tance between the two points p ( i ) and p ( j ) ; and | p number of points in the character p . L , the slope length, can-not be determined analytically [ 30 ] and thus must be decided experimentally as N in Eq. ( 12 ). In this paper, L is determined practically and flexibly according to the lengths of the data. This is because the matching distance becomes infinitive if L is too small compared to the length of the data, and because the matching itself can be inaccurate if L is too big. The equation for L is L = [ 3  X  | p where | p 1 | and | p 2 | are the lengths of the longer and shorter data, respectively. D pattern , set and D patterns represent the dis-tances between a character and a character set, and between two sets of characters, respectively. In the above equations, the dissimilarity functions, which are used to verify the writer of a signature, are used. In signature verification research, an unidentified signature is considered authentic if the dissim-ilarity is smaller than a threshold criterion and is rejected if it is bigger. Following this idea, it is reasonable to think that a character is synthesized well if the dissimilarity is as small as the ones of the authentic characters. The method of calculating the dissimilarity of a character (Eqs. 23 and 27  X  30 ) was taken from [ 2 ], and the mean dissimilarity for the synthesized characters is defined as the total dissimilarity for a letter X  X  character set. The proposed variety of a character set (Eq. 26 ) represents the mean of the minimum distances between the characters. As any character with the same shape decreases the variety, it can be used to evaluate how similar the synthesized characters are. Note that the variety of a test-ing character set is normalized by the variety of the authentic characters.

Figure 16 shows the averaged dissimilarities and vari-eties of the synthesized characters according to the num-ber of training patterns and the threshold ( X  c ) in Eqs. ( 6 ) and ( 7 ). The averaged dissimilarities and varieties can be easily obtained by calculating the mean of all the D and V ( T ) sinEqs.( 22  X  30 ) for each writer and letter. The dissimilarities and varieties of the authentic characters and the dissimilarity between the authentic and the other writers X  characters were calculated as indices. The dissimilarity of the authentic characters was calculated between the training and the test datasets. For the test dataset, ten characters were randomly selected from the characters written by other writ-ers to calculate the dissimilarity between the authentic and the other writers X  characters. The dissimilarity and variety were calculated for each letter and then averaged.

The results show that the dissimilarities of the synthesized characters varied near 1.0. This means that the synthesized characters have similar shapes as the authentic characters. Meanwhile, the dissimilarity decreases slightly as the number of training patterns or the classification threshold increases, but the causes are different. In this study, the decrease when the number of training patterns increased was caused mainly by the Kanji characters. Their dissimilarity dropped from 1.03 to 0.99, while the dissimilarity in terms of the numbers and English letters was around 1.03. This is attributed to the stroke resizing and relocation processes. As these two pro-cesses tend to average the features of the training patterns rather than selecting one, the common shapes appear more often when synthesizing characters with more training pat-terns. The cause of the decrease according to the classifica-tion threshold was different from the former. No significant differences were found according to the kind of letter. The features of the training data were averaged naturally if the threshold increased and if the number of available paths of the probability tree decreased. This decrease directly affected the variety; the variety decreased continuously as the thresh-old increased in the results after a short increase. The increase is attributed to the very low thresholds, which prohibit the points at an order to be grouped, but variation occurs only if some points are grouped together. Meanwhile, the variety generally tended to increase as the training data increased. This means that the proposed model learns various styles successfully from a number of characters.

Figure 17 shows the changes in the dissimilarity accord-ing to the diversity of the authentic characters ( X  D ) diversities of the authentic characters were uniformly cate-gorized into ten classes of degrees, and the dissimilarities were calculated for the characters in each class. The most and least diverse authentic characters are shown in Fig. 18 . These results reveal that the proposed model generally keeps its integrity with regard to the diversity of the authentic char-acters, except when the diversity is very low. The reason that the characters in class 1 show high dissimilarity is that the characters have very simple shapes. The characters in class 1 are  X 1, X   X  X , X  and  X  X  X  with straight lines, whereas the same let-ters with cursive styles showed more diversities. As authentic characters have very uniform and simple shapes, small vari-ations easily result with high dissimilarities. 6.4 Evaluation via a questionnaire An additional experiment was conducted with the subjec-tive evaluation. Three authentic characters, three synthesized characters, and six other writers X  authentic characters were presented per letter. As all the characters were resized as in the above experiment using DTW distance, it was difficult to distinguish the characters via the size. The subjects were asked to choose six characters that seem to have their own handwriting styles as well as any character with an abnormal shape. As this experiment was conducted five months after the handwriting collection, the subjects did not remember the exact style they used when they wrote. Twenty subjects participated in this experiment, and the other writers X  char-acters were selected randomly from all the subjects X  data. Table 3 shows the results. No statistical differences are shown between the selection rates of the authentic and synthesized characters, as the subjects X  own styles. The subjects were able to distinguish their own handwriting styles, and it was proven that the synthesized characters preserve the authentic personalities of their writers. It is also possible for a syn-thesized character to lose the letter X  X  shape, however, while preserving the individuality. This was verified by making the subjects select abnormal characters. Most of the selected characters were the other writers X  characters as 1.74% were determined to be abnormal, whereas only 0.40% of the syn-thesized characters were selected as abnormal. This rate is extremely low as it is not very different from the selection rate of the authentic characters.

An ethical issue can be raised from the present study because the study seems to be on the opposite side of writer verification. In our opinion, however, the possibility that the results of this study will be used to commit a crime is very low. First, authentic samples are necessary to synthesize a person X  X  handwriting. At this stage, a criminal can directly use the authentic samples to fool a signature verification system. The criminal may not find any good reason to use the proposed system. Second, most authentication processes occur in real time. If it is required that the signing be done using an electronic pen and tablet, it will be very difficult to find an opportunity to use the synthesized signature data. 6.5 Increasing the variety by selecting an influencing point As synthesizing characters with personal styles is the pur-pose of this paper, the proposed method was focused on allowing variation within a safe range. It is possible, how-ever, to synthesize more diverse characters by adjusting the method of the influencing point selection. A range criterion was introduced for this purpose, and the influencing points were selected within the range. Figure 19 shows the synthe-sized characters varying a threshold. The range criterion r is relatively defined for a character as r = max (w, h )  X   X , (32) where w and h are the width and height of the charac-ter, respectively, and  X  is the varying threshold. As shown, the variety of synthesized characters increased as the range became narrower. This is because the degree of freedom becomes higher with fewer influences from other points. It was also observed, however, that the written styles changed slightly as the threshold changed. The different styles of the loop, corner, and relative positions between the parts of the characters were often shown to have small thresholds. More-over, the spatial structures of the characters were half broken when only the closest points were selected as the influencing points. 7 Conclusions and future works In this paper, a statistical handwriting model that can synthe-size various characters while preserving a writer X  X  style was proposed. The proposed model simplified the handwriting process into one that located the points X  positions sequen-tially, where a point was influenced by some of its preceding points and was expressed with its influencing points. After classifying the points of the training data at each order, the observed transitions between the clusters in the training char-acters were counted, and the appearance probabilities were calculated. In this paper, to simplify the proposed model, it was first assumed that the characters have the same numbers of points as the same letters of the writer. This assumption was later realized by proposing modified DTW and template pattern generation techniques.

The proposed model was designed for both single-and multiple-stroke characters, such as Arabic numbers, small English letters, and Japanese Kanji letters. To synthesize multiple-stroke characters while avoiding abnormal charac-ters or the loss of personal styles, stroke resizing and relo-cation processes considering the interstroke relations were presented herein.

The synthesis results were used to examine the proposed model in three types of experiments: one involving visual analysis by these researchers, a DTW distance test, and a questionnaire survey. They successfully proved that vari-ous characters can be synthesized from a limited number of data and that the personalities are preserved stably in the characters.

Several steps can be taken to extend this work. First, the restriction that the training characters must consist of the same number of strokes must be overcome. In these authors X  opinion, including the stroke segmentation procedure in the learning phase is a possible solution to this. Second, a smooth connection between the adjacent characters can extend this work. As the proposed model considers a character an inde-pendent unit, it is believed that using conventional methods for this purpose will not pose problems. Third, the user X  X  writing effort can be reduced. Although character synthesis in the proposed system requires all the parts of a character, a character may be synthesized using the common radicals in another character. This is because many Kanji letters have common radicals.
 References
