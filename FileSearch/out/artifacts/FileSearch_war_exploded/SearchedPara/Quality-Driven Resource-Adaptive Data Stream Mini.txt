 Data streams have become ubiquitous in recent years and are handled on a variety of platforms, ranging from dedi-cated high-end servers to battery-powered mobile sensors. Data stream processing is therefore required to work under virtually any dynamic resource constraints. Few approaches exist for stream mining algorithms that are capable to adapt to given constraints, and none of them reflects from the re-source adaptation to the resulting output quality. In this paper, we propose a general model to achieve resource and quality awareness for stream mining algorithms in dynamic setups. The general applicability is granted by classifying influencing parameters and quality measures as components of a multiobjective optimization problem. By the use of CluStream as an example algorithm, we demonstrate the practicability of the proposed model. A crucial challenge in data stream mining is to cope with the effects of dynamics [1; 12; 18; 21]. Data stream management systems (DSMS) [2; 16] run several continuous queries, each containing various mining operators. With a changing set of queries, the amount of resources assigned to each of them has to be adjusted. Consequently, the amount of resources for each operator contained in the queries should be adapted, which is the approach that we assume in this work. Stream mining algorithms running on a dedicated machine have to cope with variable stream rates. The usually fixed available resources should be utilized optimally to achieve mining re-sults of highest possible quality in each situation. In wireless sensor networks, where sensors usually have some memory and processing capabilities, local resources are also fixed. Additional constraints are posed by limited bandwidth and battery lifetime of wireless devices.
 Attempts to deal with this challenge led to the development of so called resource-adaptive , or resource-aware, stream-mining algorithms. Such algorithms are aware of the avail-able resources and the dynamically changing variables, such as the stream rate and the patterns discovered in the data stream. Most work in this area has focused solely on min-imizing resource utilization. A major problem is that the effect of these techniques on the mining quality is often ig-This work was partly funded by the Science Foundation Ireland under grant no. SFI/08/CE/I1380 (LION-2). nored, i.e., no user-defined quality constraints are consid-ered and the quality of the mining results is often unknown. Thus, they lack any indication how the adaptation affects accuracy and reliability of the mining results. Further, most existing approaches focus on decreasing the algorithm X  X  re-source requirements. With a look at the mining quality, it should be possible to also increase resource utilization when sufficient resources exist.
 Most stream-mining algorithms follow a three layer approach, as illustrated by the shaded part in Figure 1. The on-line mining component analyzes the incoming data stream, which might be a filtered substream of the raw data stream (obtained by, e.g., sampling or load shedding [6]). The re-sults of the online mining component are stored in a sum-mary data structure provided by the second layer, called synopsis . Examples of synopses are sketches, windows, and dedicated data structures like the pattern tree used in FP-Stream [13] and the snapshot pyramid used in CluStream [1]. Finally, the offline mining component answers user queries by accessing information stored in the synopsis. Thus, the offline mining component is usually not constrained by the one pass requirement as the online component is.
 So far, most of the proposals for resource-adaptive stream mining suggest a specialized solution for particular algo-rithms, i.e., adding resource awareness to the online or syn-opsis component in Figure 1. The field lacks a framework for achieving resource adaptivity for general stream-mining algorithms. In this work, we suggest such a framework, which considers quality awareness as a crucial requirement. The general principle is to identify and appropriately adapt parameters of stream-mining algorithms that influence re-source requirements and mining quality. This results in an extension to the three-layer model as shown on the right of Figure 1. The resource monitoring and observation as-sessment component collects information about the current system state. Based on this, it is decided whether param-eters have to be adapted (cf. Section 7). The actual pa-rameter adaptation takes place in the parameter adaptation component (cf. Sections 5 and 6). The new parameters are set in the stream-mining algorithm and the stream analysis continues until the adaptivity component is activated again. Of course, in addition to the benefits of resource-adaptive stream mining, automated parameter adaptation also en-tails additional resource requirements. We believe that this additional overhead is a very low price for the gained flexibil-ity. In general, we assume that the additional resources are available. Alternatively, special resources might be reserved for this subtask, but an appropriate estimation might pose a problem again. Especially in situations when the work-load of the stream-mining algorithm is high, the overhead imposed by triggering the resource adaptivity component may sum up to a CPU cycle requirement that exceeds the constraints. Throughout this work, we will point out spe-cific issues in this context and briefly discuss methods to overcome them.
 The extended model is resource-aware and quality-driven, meaning that we aim at maximizing the mining quality while observing the given resource limits. To this end, the pro-posed model is based on a multiobjective optimization prob-lem with two conflicting objectives: (1) maximizing mining quality, and (2) minimizing resource utilization. The result of the optimization problem is a set of parameter values. We present a way to solve this optimization problem at certain points in time during the stream mining process and exem-plarily demonstrate how to apply our model to the popular stream mining algorithm CluStream [1].
 The proposed model is designed to extend stream mining algorithms that are not yet resource-adaptive as well as to cover existing approaches for resource awareness. The con-crete contributions of the presented work are: 1. We formalize the data stream mining process, all vari-2. We provide a comprehensive and generally applicable 3. We propose to solve the problem of finding parameter The remainder of this paper is structured as follows. In Sec-tion 2 we briefly present the CluStream algorithm, which we use as a running example. Section 3 describes related work on resource-aware stream mining. Section 4 summa-rizes commonalities of stream-mining algorithms and dis-cusses resource requirements and quality measures. In Sec-tion 5, we present our model for resource-adaptive stream mining and show that the optimal parameter settings can be determined by solving a multiobjective optimization prob-lem. We present an approach to solve such an optimiza-tion problem in Section 6. Section 7 discusses two different adaptivity schedules, answering the question when param-eter adaptation should be conducted. Finally, we conclude in Section 8 and highlight open issues.
To demonstrate the application of our model, we use the clustering algorithm CluStream [1] as a running example, as it has been used previously to demonstrate resource-adaptive extensions [10; 12]. CluStream is a well-known and popular algorithm that we expect many readers to be familiar with. In the following we present a brief summary of the original algorithm. In previous work [9; 10], we also present resource-adaptive extensions to algorithms for fre-quent itemset mining and outlier detection in data streams, using the model presented here.
 The design of CluStream follows the 3-layer model intro-duced in Section 1. In the online mining component, Clu-Stream maintains q micro-clusters, which are updated as new stream objects arrive. q is an input parameter and should be significantly larger than the number of natural clusters in the data, but also much smaller than the number of data points arriving in the data stream [1]. During the initialization phase, the initial q clusters are created using a traditional clustering algorithm for static data sets, e.g., k-means, on the first points of the stream. After that, ex-isting clusters are deleted or merged whenever a new cluster needs to be added.
 At certain points in time, snapshots of the current micro-clusters are stored in a synopsis called pyramidal time frame (PTF). In the offline mining component, users query the PTF by requesting k clusters, k&lt;q , in the past time horizon h before current time t c . A k-means clustering algorithm is used to determine these clusters based on the available snap-shots. The PTF uses a tilted time window model. The i -th level of the PTF contains the  X  l + 1 most recent snapshots taken at clock times that are divisible by  X  i ,  X   X  N ,  X  As an example, if  X  =2and l =2,theneachlevelofthe PTF contains at most 2 2 + 1 = 5 snapshots.
 The accuracy of the clustering depends on the order, i.e., the level in the PTF, of snapshots available for the queried time interval. The beginning of the queried time interval, i.e., t  X  h , has to be approximated by the last stored snapshot t of any order before time t c  X  h . The accuracy of this approximation is bound by the following inequality: R esource adaptivity has been proposed in the context of individual algorithms, e.g., in [10; 17; 18; 20], and as frame-works that facilitate resource adaptivity in arbitrary stream-mining algorithms [10; 12; 15] and in DSMSs [3; 4]. Individual resource-adaptive stream-mining algorithms have been proposed by, e.g., Teng et al. [18] for frequent temporal patterns, Lee and Lee [17] for frequent itemsets, Vlachos et al. [20] for periodicity estimation, and Franke et al. [10] for frequent itemsets and clustering. In these algorithms, the techniques used to facilitate resource adaptivity are specific to the proposed algorithm and cannot be directly applied to other algorithms, i.e., there is no underlying generic model for resource adaptivity. In addition, all but the algorithm in [10] lack quality-awareness and therefore no estimation of the result quality is provided. The emphasis is usually on handling situations where resources are scarce, e.g., in [17; 20], and often only one resource, usually memory or CPU-time, is considered. Only in [10] attention has been paid to facilitate the utilization of excess resources.
 R esource-adaptive operator scheduling in DSMSs has been proposed by, e.g., Babcock et al. [3] and Berthold et al. [4]. In [3] a load-aware operator scheduling strategy is proposed. Using estimates for the selectivity and per-tuple processing time of each operator, operators are scheduled such that the amount of tuples that are present in the DSMS is de-creased as fast as possible. The approach in [4] has similar objectives as our research and focuses on meeting Quality of Service (QoS) requirements for a given query plan. The au-thors present a model that allows to calculate the resource requirements of the operators in a fixed query plan and sub-sequently parameterize the query plan such that QoS re-quirements are met. However, the paper only considers sim-ple operators like joins, aggregation, and grouping, and does not include stream mining techniques.
 General frameworks for resource-adaptive stream mining have been proposed by Jain et al. [14], Karnstedt et al. [15], and Gaber and Yu [12]. In [14] it is proposed to perceive re-source management in stream processing as a filtering prob-lem, and use Kalman Filters to reduce the amount of data that need to be processed. In previous work [15], Karnst-edt et al. proposed a preliminary version of the model for quality-driven resource adaptive stream mining presented in this paper. This model formalizes the techniques used in [10] to create a generic framework that can be applied to a variety of stream mining algorithms. However, the model proposed in [15] does not yet consider parameter adaptation as a multiobjective optimization problem. In [12] a model is proposed that uses algorithm granularity (AG) settings to adapt an algorithm X  X  resource consumption to the amount of available resources. The AG model focuses on situations where resources are scarce. AG has been classified into three classes, which we will detail in Section 4.1, where we reuse the notion of these three classes. The AG model is not quality-aware. Also, AG does not take the correlations be-tween variables in stream mining into account. The model proposed in this paper therefore subsumes the model pro-posed in [12]. The AG model in [12] was used to develop a resource-adaptive clustering algorithm, R A-Cluster, which is an extension of the CluStream algorithm. R A-Cluster uses randomization to decrease the CPU-time demand. In con-trast, our approach aims at adapting the existing variables, thus influencing all resource requirements and enabling us to not only alleviate critical situations where resources are scarce, but also to utilize excess resources. In the following, we summarize characteristics of data stream-mining algorithms. First, we discuss aspects that influence the resource requirements of stream-mining algorithms in Section 4.1. Then, we introduce quality measures that are used to assess the quality of stream mining in Section 4.2. In a data stream mining application several resources are constrained and thus have to be carefully allocated. The main resources are: Main memory The synopsis and all intermediate results CPU cycles Stream processing must keep up with the pace Bandwidth Bandwidth is limited in wireless sensor net-Battery power CPU utilization, memory access, and data We denote the set of all resources by R .If R  X  X  is a constrained resource, there is an upper limit R associated with this resource. Similarly, a lower limit R  X  may be as-sociated with each resource R  X  X  . The sets of all upper and lower limits on resources in R are denoted R and R  X  respectively. Accordingly, we use the notation R  X  to refer to all given constraints, i.e., both, upper and lower limits, of
R . While a lower limit R  X  might appear uncommon, we include it in our model to make it as flexible and gen-eral as possible. For example, the frequent itemset mining algorithm proposed in [17] uses a lower bound on the de-sired memory usage. In general, it is not required that both constraints R and R  X  are defined for each R  X  X  . Three aspects A 1, A 2, and A 3, which roughly correspond to the three basic layers introduced in Figure 1, influence the resource requirements of any data stream-mining algorithm. They represent classes of  X  X uning knobs X  for the resource requirements of a stream-mining algorithm.
 A 1 : Stream properties. Properties of the stream include the stream rate and characteristics of its individual elements, such as value range, distribution, and size. The effective rate of a stream to process can be changed using methods like sampling and load shedding [6]. This reduces the required CPU resources and in some cases the memory requirements (e.g., if a time-based sliding window is used). Filtering is another method that can be used to change aspect A 1, for example, using outlier or burst detection methods. Filtering may change the range and distribution of values, and thus may impact the memory requirements of the synopsis. A 2 : Input parameters. Most stream-mining algorithms have input parameters that influence how well their out-put approximates the actual mining result (cf. Section 4.2). Consequently, these input parameters are one of the main as-pects that determine the trade-off between resource require-ments and output quality. A better approximation of the mining result implies more runtime per stream element and more main memory required to store the synopsis. Conse-quently, changing the input parameters of the online compo-nent directly influences its CPU and memory requirements. The CluStream algorithm uses an input parameter q to set the number of micro-clusters into which the data stream is partitioned. A higher value of q results in higher memory requirements, as each micro-cluster needs to be stored along with its history. Likewise, q influences the CPU require-ments, because for each new element of the data stream q different micro-clusters have to be considered to find the best matching one.
 A 3 : Query parameters. User queries, particularly the query parameters, and, in the case of continuous queries, the fre-quency of result updates influence an algorithm X  X  resource requirements as well. In particular, the offline mining com-ponent is affected. The larger the part of the synopsis that needs to be accessed, the more CPU cycles will be required. If data mining is conducted directly on the sensors in a wire-less network, the bandwidth requirements are also influenced by the the size of the mining result (e.g., the number of output clusters for CluStream) and the frequency of result transmission. Adapting query parameters should only be done if other resource adaptation methods are not sufficient for meeting the given constraints, as it affects the usefulness and interestingness of results to user queries significantly. Note that the list of resources affected by the above aspects is exemplary rather than exhaustive. Changes to any of them usually influence more than one resource at the same time and more than one quality measure (cf. Section 4.2). For example, decreasing q in CluStream will speed up the clustering algorithm and also decrease its memory require-ments. As presented in Section 3, the three aspects were previously identified as algorithm granularity settings [12]. However, this classification is not as general as our frame-work. For example, algorithm processing granularity (APG) only refers to adapting the CPU requirements, while the in-fluence on memory consumption is not considered. Further, the authors rely on randomization and approximation tech-niques to adapt the APG and do not consider to adapt the existing input parameters of the algorithm. The quality of stream mining describes how well the actual mining results, i.e., results that could be achieved when un-limited resources were available, are approximated. Aspects A 1 through A 3, which were detailed in Section 4.1, impact the resource requirements and the achieved quality. To as-sess the mining quality, we use quality measures based on the described parameters. In previous work [10] we identi-fied different classes of quality measures, which are summa-rized in Table 1. This classification is comprehensive, yet extensible without restricting the proposed model. The quality Q of stream mining can be classified into me-thodical quality Q M and temporal quality Q T . The differ-ent measures in Q T are identical for all mining tasks, while Q
M  X  represents classes of quality measures that are specific to the data-mining task and algorithm. For further details, we refer the reader to [10].
 Similar to constraints on resources, upper and lower bounds can be defined for all quality measures Q  X  X  . Specifically, for a quality measure Q  X  X  , Q  X  and Q denote the min-imum and maximum quality, respectively, that needs to be achieved. The desired quality has a strong influence on the amount of resources the stream-mining algorithm requires. In general, the higher the quality should be, i.e., the better the approximation, the more resources are required. Sometimes, more than one quality measure is influenced at the same time. In CluStream, different numbers k of out-put clusters provide different levels of interestingness (i.e., different values for Q Mi ) depending on the number of nat-ural clusters. The value of k also influences Q Ma ,asmore clusters represent a more fine-grained approximation of the stream.
 Example 4.1 Below we list all parameters of CluStream and which class of quality measures they influence. q influences Q Ma A higher number of micro-clusters ap- X  influences Q Tg The more frequently snapshots of the micro-l influences Q Tg The more snapshots are stored for each h influences Q Tg The queried time horizon h determines k influences Q Ma and Q Mi See above.
 We define two quality measures based on CluStream X  X  pa-rameters: Q 1 was already used to evaluate the clustering quality of the original CluStream algorithm in [1]. The authors found that high-quality clustering results can be achieved for a q/k ratio of about 10 . We select a second quality measure Q 2 =  X  l cause it represents the temporal quality in CluStream. As de-scribed in Section 2, the number of snapshots that are stored in each level of the PTF is limited to  X  l + 1 , and the ap-proximation of the queried time interval also depends on the value of  X  l . Given the characteristics of stream-mining algorithms intro-duced in the previous section, the goal of a stream-mining process can be stated as follows: Mine the data stream continuously with the maximum possi-ble quality, such that each quality measure Q  X  X  is within its constraints Q  X  . Input parameters that determine the quality are subject to dynamic resource constraints and have to be chosen such that the requirements for each resource R  X  X  are within its constraints R  X  .
 In this section, we present a framework to model and achieve this goal. For this, we first introduce adaptation factors , i.e., parameters that are used to adapt the resource requirements of an algorithm as well as the quality in Section 5.1. We then define a set of functions to model the correlation of param-eters, quality, resource requirements, and other variables in the stream-mining process in Section 5.2. In Section 5.3, we show that the goal stated above can be expressed as an optimization problem and propose a solution to this prob-lem. Then, in Section 5.4, we list requirements for algo-rithms to be used within the proposed framework. Finally, in Section 5.5, we outline how to apply our framework to a frequent itemset mining algorithm that fulfills these require-ments. As described in Section 4, a lot of variables, e.g., the stream rate and input parameters of the mining algorithm, are present in data-stream mining. Constraints R  X  , R , Q  X  , and Q are also variables, as they are set by users or im-posed by the stream-mining system (e.g., the maximum amount of main memory mem thatcanbeusedbyanalgorithm).
 We categorize all variables into parameters P  X  X  and ob-servations O  X  X  ,with P X  X  =  X  . Parameters P are vari-ables that can be set dynamically, whereas observations O are variables that can only be observed. Some observations can be influenced by changing parameter values. For exam-ple, one cannot directly influence the stream rate of the raw data stream (hence, it is an observation), but application of sampling or load shedding will influence it.
 Variables in data stream mining are not independent of each other. In most cases, a change of one variable X  X  value causes other variables to change as well. For example, if q  X  X  , the number of micro-clusters in CluStream, is changed, the number of required CPU cycles, main memory requirements, and methodical quality Q M change as well. Thus, parame-ters are  X  X uning knobs X  for the data stream-mining process, as they influence resource requirements and quality. In our model, some or all of the parameters in P are selected as adaptation factors , i.e., parameters that are automatically adjusted in order to adapt an algorithm X  X  resource require-ments and the achieved quality. Parameters not chosen as adaptation factors remain constant throughout the lifetime of the stream-mining process. Thus, in the following we only denote adaptation factors as parameters. Consequently, if not all parameters in P are adaptation factors, the remain-ing ones are in the set O of observations (i.e., they are not automatically adjusted).
 Example 5.1 For the CluStream algorithm, we chose two adaptation factors q and l , i.e., P = { q,l } . Although  X  is a parameter as well, it cannot be changed dynamically during the stream analysis as most snapshots maintained in the PTF would become invalid and much of the historical information about data stream would be lost. Thus,  X   X  X  . In addition, parameters h and k remain constant as well, as we do not want to adapt the query parameters. Note that, however, the adaptation of query parameters may be beneficial for other algorithms and is certainly supported by our model.
 As the PTF increases in size as time progresses, variable t , the number of elapsed time units, is also an observation. In summary, CluStream X  X  parameters and observations are as follows: We published a preliminary version of the model presented in this section in [15], which did not consider parameter adaptation as a multiobjective optimization problem. At any given time t ,the system state of a stream mining al-gorithm is defined as the values of all its parameters and observations. To indicate values of variables at a specific point in time, an index is added, e.g., mem t denotes the maximum amount of available memory at time t .
 For a given stream mining algorithm, a function  X  can be defined that, given the system state at time t , determines the resource requirements for a resource R  X  X  at that time: Function  X  defines how to compute the resource require-ments of an algorithm based on values for parameters P and observations O . A separate function is defined for each resource R  X  X  .
 Example 5.2 The signature of  X  for CluStream X  X  main mem-ory requirements mem  X  X  is: CluStream X  X  memory requirements are composed of two parts, the size of the PTF and the amount of memory consumed by the current q micro-clusters. As we derived in [10], the overall memory requirement is given by the following equa-tion and is measured in floating-point numbers: In the above equation, c LRU is a constant and d is the (con-stant) dimensionality of objects in the data stream. Figure 2 depicts function  X  for mem against parameters q and l in million floating-point numbers ( c LRU =20 , d = 2 ). The figure depicts the memory requirements for t = 1 , 000 , 000 and  X  =2 . For the sake of presentation, we limit the values of q and l inFigure2(andalsoinsubsequent figures) to the intervals q  X  [1 , 500] and l  X  [1 , 10] . Using  X  , optimal parameter values can be determined to satisfy resource constraints. Observations O are either taken from the current system state or represent predictions (see Section 7). Similar to  X  , we define a separate function  X  for each quality measure Q  X  X  based on the system state at time t : Example 5.3 We defined two quality measures Q 1 and Q 2 for CluStream. The corresponding functions  X  are as fol-lows: As Q 1 grows linearly with q ,and Q 2 grows exponentially with l , each quality measure depends on one variable. By evaluating  X  and  X  using the same parameter and obser-vation values, we obtain a mapping that assigns each set of quality values to an amount of resources required to achieve these values. Each of these possible combinations is called a configuration : a tuple of values for observations, parameters, qualities, and resource requirements.
 Example 5.4 Figure 3 depicts the mapping of Q 1 and Q 2 (shown on a log-scale) to mem for CluStream. Each point in Figure 3 corresponds to a configuration.
 To keep track of previous values of observations and pa-rameters, we introduce sets P T and O T ,socalled timelined variable values . They are needed to compute the accumu-lated quality of a user-queried time interval. Distinct time intervals [ t i ,t i + i ) can be defined during which variable val-ues did not change. For each variable, the concatenation of all time intervals represents the complete history of this Figure 3: Mapping quality values for Q 1 and Q 2 to main memory requirements of the CluStream algorithm. variable X  X  values. For each parameter P  X  X  , timelined pa-rameter values P T are defined as follows: P
T = { P t i | P t i was effective during time interval [ t P T contains the timelined variable values for all P  X  X  .Set O
T is defined analogously. P T and O T are input for func-tion(s)  X  to compute timelined quality values Q T .These values are used to support time sensitivity in situations where different quality values were effective during the queried time interval. To determine the quality Q [ t i ,t j ] for a queried time interval [ t i ,t j ], we define a function  X  for each quality measure Q  X  X  : Example 5.5 Consider quality measure Q 1 = q/k and a user query for the clustering results of time interval [ t Within this time interval, several different values of q might have been used in the online clustering, resulting in quality values Q 1 ,t i , Q 1 ,t i +1 , etc. To determine the quality of the mining result, function  X  is defined as the minimum of all values of Q 1 ,t k that have been effective: Storing timelined variable values requires additional mem-ory. The amount of memory required should be reduced by merging variable values in the timeline as soon as a quality measure is decreased at some point in time. In the Clu-Stream example, as soon as l is decreased, snapshots on each level are deleted so that only the  X  l + q most recent ones are maintained. As the deleted snapshots can never be recovered, the timeline for parameter l can be deleted as well. Note that for special adaptivity schedules based on forecasting resource consumption (cf. Section 7), the whole timeline of parameter values might be required. However, usually it is feasible to limit the number of previous variable values that are stored, e.g., to the n most recent variable values. The above stated goal of a stream-mining process is an op-timization problem, as the objective is to maximize quality subject to resource and quality constraints. As mentioned, constraints R  X  and Q  X  might not exist for all resources and quality measures. However, we can assume that at least one resource R  X  X  has an upper limit R , since otherwise re-source awareness would not be necessary. Thus, there are multiple objectives, namely to keep resource requirements below R and to maximize all quality measures. Such an optimization problem where several (conflicting) objective functions exist, is called a multiobjective optimization prob-lem , and has been discussed, e.g., by Ehrgott in [8]. The Figure 4: Possible configurations in the presence of resource constraint mem =4 M , or quality constraints Q 1 =10 and Q 2 = 500. optimization problem in our context contains one objective function for each quality measure and each resource, defined by functions  X  and  X  . It can be decided for each R  X  X  and Q  X  X  independently if it should be maximized, minimized, or if it should be constrained by upper or lower bounds. For example, on sensor nodes battery usage should usually be minimized. In contrast, memory consumption should just be constrained, as there is no benefit from using less memory than available.
 Given a system state at time t , a solution to the multiobjec-tive optimization problem yields an optimal configuration. We discuss details of how to solve the multiobjective op-timization problem in Section 6. The parameter values in the optimal configuration are immediately used as the new parameter values of the stream-mining algorithm (cf. Sec-tion 7). Constraints limit the number of possible configu-rations. Specifically, if one or more constraint for R  X  , Q  X  ,and Q is set, some configurations become invalid. Ad-ditionally, constraints  X  can be defined on one or more qual-ity measures, resources, or a combination of both, to further limit the set of possible configurations.
 Example 5.6 For our running example, we choose to max-imize Q 1 and Q 2 and to apply a constraint mem =4 M , i.e., four million floating-point numbers. The resulting pos-sible configurations are depicted in Figure 4 and are marked by + . In the figure, only quality measures Q 1 and Q 2 are illustrated, as the respective parameter values for each con-figuration can be obtained from function  X  . Note that Q 2 again shown on a log-scale. Also note that, for clarity of pre-sentation, not all possible configurations are shown, but only those for which Q 1 is an integer. For example, q =50 yields Q 1 =42 / 20 = 2 . 1 ,butonly Q 1 =2 and Q 1 =3 are shown. Figure 4 also depicts possible configurations (marked by an  X  X  X ) when adding constraints Q for both quality measures, namely Q 1 =10 and Q 2 = 500 . Further, it may be bene-ficial to balance both considered quality measures. This can be achieved by adding a constraint  X  , e.g., like the following: Now that we introduced all components, we define the mul-tiobjective optimization problem that needs to be solved in order to determine an optimal configuration as follows: Note that objective functions  X  are maximized by minimiz-ing  X   X  . This is a common technique when formulating op-timization problems. The proposed model can only be applied to stream-mining algorithms that fulfill the requirements listed below. Instantiate functions of correlation model In order to Query parameters In order to influence an algorithm X  X  Locality of parameter effects It is desirable that the syn-Example 5.7 To explain the concept of local effects of pa-rameters, imagine that at some point in time the value of q in CluStream is increased from q 1 to q 2 . Snapshots taken when q 1 was effective contain exactly q 1 micro-clusters, while snapshots after the parameter adaptation contain q 2 micro-clusters. Thus, when a user-queried time interval only con-tains snapshots taken after q 2 became effective, then the lower quality that resulted from parameter q 1 does not af-fect the result quality of this user query.
 Consequently, it should also be possible to query each of the independent sections in the synopsis separately. Otherwise, the lowest quality ever used determines the quality of the overall mining result. Another way to achieve locality is to choose a synopsis where information expires after a certain amount of time (e.g., like in certain window models). Note that locality of parameter effects is not a strict requirement. Theproposedmodelcanbeappliedinanycase,butthe algorithm will not be able to recover from parameter settings that cause low quality. To demonstrate the broad applicability of our model, we now outline how it can be applied to another fundamental data mining problem, the mining of frequent itemsets. A pop-ular stream-mining algorithm for this problem is proposed in [13]. The algorithm uses an FP-tree like data structure called pattern tree as synopsis. A tilted time window table, similar to CluStream X  X  PTF, is associated with each node in the tree. In this table, the frequencies of the itemset in different time intervals are stored during the online mining phase. In the offline mining phase, an FP-growth algorithm is run on this synopsis to extract frequent itemsets accord-ingtothe query parameters (class A3 cf. Section 4), such as the queried time window. The algorithm from [13] applies some approximations that are typical for frequent itemset algorithms on data streams. First, the true support  X  e of a mined itemset e is approximated using a user-defined pa-rameter  X  (0 , 1), resulting in an approximate support  X   X  for which the following inequality holds: Therefore, represents an input parameter from class A2 (cf. Section 4) that influences the quality of approxima-tion Q Ma . As the pattern tree holds only itemsets having a support of at least , the value of this parameter directly affects the number of nodes in the tree, and thus the re-source requirements. The second aspect concerns the time granularity for which frequent itemsets are determined. A user-defined input parameter b determines the size of the windows to process, and thus the time granularity Q Tg at which mining results can be obtained. Note that this is sim-ilar for algorithms using sliding windows, while the rather seldomly used landmark windows are not well suited for our model as the requirement for locality of parameter effects is not fulfilled. Besides the above mentioned queried time win-dow, the queried minimal support of an itemset represents another query parameter from class A3, influencing Q Mi . Consequently, and b act as adaptation factors for our model. Both parameters influence the memory and CPU re-quirements as well as the mining quality. In every iteration, the algorithm processes a batch of b transactions and finds itemsets having at least support . Only those are stored in the pattern tree. Thus, the value of b affects the number of entries in the tilted time window table, because for larger batches entries are made less frequently. Additionally, item-sets that appear as frequent only in smaller windows will not be added with larger values of b .
 Necessary observations in the context of frequent itemset mining include various stream properties (class A1 cf. Sec-tion 4), such as average length of transactions, total number of items in the stream, and the distribution of the items in the stream. Such properties can, for example, be inferred from a sample of the stream. Note that inaccurate values for these observations will not invalidate our model but only lead to less accurate resource adaptation.
 Having identified parameters and observations from the dif-ferent classes, the remaining task is to define the functions used in the correlation model. This is out of scope for this paper. [10] provides a basis for this by presenting formulas for memory consumption and output quality based on the above discussed parameters.
 Note that the frequent itemset stream mining algorithm in [13], similar to many other such algorithms, provides qual-ity guarantees , i.e., there are no false negatives and the true support of itemsets in the result set is at most lower than the reported frequency (cf. inequality 1). A remarkable ben-efit of our model is that the resource-adaptive algorithm will still provide guaranteed error bounds in the same way as the original algorithm did. Our parameter adaptation will vary the algorithm X  X  error bound, i.e., parameter , accord-ing to the available resources. However, by monitoring these changes it will always be possible to compute the exact value of the error bounds for the computed frequent itemsets. In this section, we describe an approach to find the solu-tion for the introduced multiobjective optimization prob-lem, which corresponds to finding the optimal configura-tion. First, we discuss how to find possible configurations in Section 6.1. In Section 6.2, we then use the notion of Pareto-optimality to determine a set of optimal configura-tions, where each configuration is optimal with respect to at least one of the objectives. Finally, in Section 6.3, we discuss how a single optimal configuration can be determined. A good overview of methods to solve multiobjective opti-mization problems, including benefits and drawbacks of each method, is provided by Freitas in [11]. The work focuses on the application of multiobjective optimization in data min-ing. Other survey papers that present different methods are, e.g., by Coello [7] and Lamont [19]. R ecall Example 5.6, where constraints Q on the quality measures of CluStream were set in order to limit the num-ber of possible configurations. Setting constraints Q 1 =10 and Q 2 = 500 results in about 1800 possible configurations for the parameter settings of CluStream. However, the num-ber of possible configurations is finite only because parame-ters q and l are integers. Considering algorithms that have real-valued parameters, there is an infinite number of possi-ble configurations, and hence the search space is infinite as well. In this case, parameter adaptation can be extremely inefficient, if not impossible at all. We therefore propose to associate a step size P  X  with each parameter P  X  X  that is not an integer, to indicate the minimum increment or decre-ment of this parameter. This limits the number of possi-ble configurations and ensures that parameter adaptation is only done when significant improvements can be achieved. The step size P  X  should be chosen such that the tradeoff be-tween the accuracy with which parameter P can be adapted and the computational effort to find the optimal value of P is acceptable. Naturally, a small step size results in a high number of possible configurations from which the opti-mal one will be chosen. But, the given resource and quality constraints can be met more accurately if a high number of possible configurations exist. Detailed considerations about appropriate values for P  X  are not within the scope of this paper.
 As we will describe in Section 7, the resource adaptivity component itself helps to limit the number of possible con-figurations further. Specifically, an indicator helps to de-termine the reason for activating the parameter adaptation, i.e., if quality measures are not met, resources are underuti-lized, or resource limits exceeded. This information helps to limit the range of parameter values to consider.
 Example 6.1 Assume that CluStream X  X  current parameter values are q = 400 and l =8 . At some point in time, con-straint mem is increased, and thus a new optimal configu-ration is needed. As function  X  for CluStream is monoton-ically increasing (cf. Figure 2), configurations with q&lt; 400 and l&lt; 8 are no candidates for the new optimal configura-tion. Thus, possible configurations are limited to those where either q&gt; 400 or l&gt; 8 (or both) is true. Of course, config-urations having q&lt; 400 and l&lt; 8 are technically still in the set of possible configurations. To formalize this limitation, we add a constraint  X  , which is valid only for the current cycle of the resource adaptivity component, to prevent con-figurations having q&lt; 400 and l&lt; 8 from being used during this particular pass of parameter adaptation.
 A naive approach to find the optimal configuration is to first find all possible configurations and then choose one from this set. This can be done by enumerating all possible parameter values until the corresponding resource consumption exceeds constraints R or Q and falls below R  X  or Q  X  .Thisis easy to do, because functions  X  and  X  usually do not have local maxima, but are monotonically increasing. However, depending on the step size, domain of parameter values, and the values of constraints R or Q , the number of possi-ble configurations may be quite large and thus expensive to compute. In the next subsections, we describe alternative methods to find the optimal configuration. Many of the possible configurations do not need to be con-sidered, as other configurations exist that dominate them. A configuration c 1 is not dominated by any other possi-ble configuration c 2 if c 1 is better with respect to at least one objective, e.g., c 1 has lower resource requirements or a higher value for at least one quality measure. Such non-dominated configurations are called Pareto-optimal and are contained in the Pareto front of all possible configurations. In the database community, the Pareto front of a discrete set is called a skyline [5]. For parameter adaptation, only Pareto-optimal configurations need to be considered. Example 6.2 Recall Example 5.6 and the associated Fig-ure 4. For configurations marked by a  X + X , a resource con-straint mem =4 M was applied. Out of these configura-tions, all Pareto-optimal configurations are highlighted by a (red) circle in Figure 4. Each Pareto-optimal configuration maximizes at least one of the quality measures while obey-ing the resource constraint mem . Note that for the other example illustrated in Figure 4, where both quality measures are constrained, only one configuration is Pareto-optimal, i.e., the one where Q 1 =10 and W 2 = 256 .
 Different algorithms exist to determine the Pareto front of a multiobjective optimization problem. A survey of existing methods was published in, e.g., [7; 19]. A popular approach is to use evolutionary algorithms. In the context of our model, the Pareto front can often be determined analyti-cally. This is because functions  X  and  X  are monotonically increasing, and thus it is straightforward to narrow down the parameter settings for an optimal configuration. Example 6.3 Finding Pareto-optimal configurations for Clu-Stream analytically is very efficient. Assume that at a given point in time, observations are k =20 ,  X  =2 ,and t = 1 , 000 , 000 (again, d =2 and c LRU =20 ). We set a con-straint mem =4 M . Our goal is to find the Pareto-optimal configurations for this setting, specifically parameter values for q and l such that both quality measures Q 1 and Q 2 are optimal with respect to the resource constraint mem . We observe that the number of possible values for param-eter l is very limited, i.e., l =30 already yields up to 1 billion snapshots per level in the PTF, which (heuristically) is sufficient in most cases. As there is only one Pareto-optimal configuration for each value of l , the corresponding value of q can be computed using a transpose of function  X  . Specifically, for each value of l  X  [1 , 30] we compute the corresponding maximum value of q such that the resource constraint mem is obeyed. The Pareto-optimal value of q , given a value of l as well as observations and constants mentioned above, is computed as follows: Each of the configurations in the Pareto front is optimal with respect to at least one objective. Different approaches can be used to decide which of these configurations is actually chosen. In this section, we discuss three such approaches. Weights for all objectives One common approach is to assign a weight to each objective and subsequently com-bine all objectives in one objective function. The sum of all weights usually equals one. The single objective function that is created this way yields a unique solution, which can be computed without determining the Pareto front of all possible configurations. However, choosing the weights for all objectives is hard, as pointed out by Freitas in [11]. We therefore do not recommend to employ this approach unless it is clear how to weight the objectives.
 Leastamountofunusedresources If R exists for at least one resource, we can choose one configuration from the Pareto front for which the resource requirements computed using function  X  are as close to R as possible. That way, the optimal configuration is chosen such that the amount of unused resources is minimized. If constraints exist for more than one resource, one could aim at minimizing the sum, or the sum of squares, of unused resources. In case two or more configurations are equally good in terms of resource utilization, we either choose one at random or follow the approach described below.
 Fewest parameter changes A third approach to select the optimal configuration is to choose the one that causes the least parameter changes. That is, given the current pa-rameter settings of the stream-mining algorithm, we select the new configuration such that either as few as possible pa-rameters change, or that the changes that have to be applied to all parameters are as small as possible. Fewer changes to parameters are beneficial for the overall runtime overhead imposed by parameter adaptation. For example, in Clu-Stream, decreasing the value of q from q 1 to q 2 means that we have to merge q 1  X  q 2 micro-clusters. The overhead de-creases with a decreasing difference between q 1 and q 2 . The three approaches above are just examples of methods to choose an optimal configuration. Of course, other ap-proaches are conceivable. Typically, the decision how the optimal configuration should be chosen depends in the spe-cific application.
 Generally, solving a multiobjective optimization problem can become quite expensive. The runtime of the whole adap-tation process is dominated by this. However, the properties of the objective functions, such as their monotonicity, help to implement efficient approaches. For the example of Clu-Stream, we can find a solution with only few computations. As properties of the objective functions may vary for differ-ent stream-mining algorithms, it is not possible to provide general rules for the cost associated with this step. As a gen-eral guideline, objective functions with according properties and approximating algorithms for solving the optimization problem should be preferred. The initial parameter values are chosen based on initial ob-servations, either based on observing the stream for a short period in the beginning or by assuming values for each of the observations. They have to be chosen such that the initial resource requirements do not exceed the constraints R . Then, there are two aspects of the actual scheduling of parameter adaptation: (1) decide whether to trigger the component, and (2) decide when to evaluate that decision again. For question (1) , we use a function  X  .  X  is used to decide whether parameters have to be adapted and further acts as a guideline for the efficient solution of the optimiza-tion problem. We suggest a simple encoding for  X  :  X  ( P T , O T , Q  X  , R  X  ):= Value  X  = 2 indicates that either the resource requirements are below R  X  for at least one resource R  X  X  ,orthatat least one R  X  X  is underutilized with respect to R .The same applies for 3 and the quality limits, and in analogy for 4 and 5. If quality and resource limits are affected,  X  returns the product of the according values, e.g., 2  X  3=6ifboth, resources and quality, are too low.  X  makes use of functions  X  and  X  to compute resource utilization and quality values. In all cases where  X &gt; 0, the optimization problem has to be solved. If a solution cannot be found in the current state, the failed parameter adaptation is signalized and reaction is left to the system or user. In most cases this is due to R set too low or Q  X  set too high, which can be indicated by the adaptivity component. Consequently, the system or user will likely react by adjusting resource or quality constraints, or by terminating the stream-mining process.
 When new parameter values are set in the stream mining algorithm, some adjustments may have to be applied to the synopsis. This is the case if at least one of the new parameter values decreases the quality or resource requirements of the stream-mining algorithm. Then, elements in the synopsis need to be merged or pruned according to the algorithm X  X  build-in routines. In CluStream, if the number q of micro-clusters is decreased, micro-clusters need to be merged until only q of them are left. The used routine is also frequently used during regular stream processing. Due to their frequent use, such merging and pruning techniques are designed to be very efficient. Thus, adjusting the synopsis to the newly set parameter values is done very efficiently as well. However, it is still beneficial to keep the changes of parameters during parameter adaptation to a minimum.
 We assume that the underlying stream system activates the resource adaptivity component as soon as the resource limits change. However, exhausted limits may result in a system failure. Thus, a crucial question is when to trigger the adap-tivity component while the limits are stable. To prevent a violation of the limits, the adaptivity component should be triggered preventively. One can choose to adapt parameters more prudently, e.g., by setting the effective R to 80% of the amount of resources that are actually available. This de-creases the quality that can be achieved. It is comparable to the approach chosen in [10]. The authors use a filling factor f that reflects the percentage of available resources already consumed. If f is above or below certain thresholds, param-eter adaptation is triggered. An alternative approach was proposed in [12], which calculates the number of time steps remaining until the resources are exhausted. When this is predicted to happen before the adaptivity component will be triggered again, it has to be triggered in the current time step. This relates to the answer for question (2) from above, which is focus of the following subsection. When the adaptation component was triggered, it has to be decided when it should be triggered again. There is a trade-off between the overhead imposed by the additional compu-tations and the benefits of frequently triggering the resource adaptivity component (e.g., the ability to quickly react to changing resource requirements). We propose two differ-ent approaches. Both approaches cannot guarantee that the adaptation will prevent the algorithm from failure due to exhausted resources. Especially in scenarios with frequent and drastic changes in the observations, appropriate and timely predictions for the algorithm X  X  resource consumption are hard to achieve.
 In Situ Adaptivity. We call the first approach in situ adap-tivity because it acts based on the situation at the current point in time. The adaptivity component is activated every  X  time units. The value of the variable  X  is fixed through-out the stream mining process. It is therefore an additional observation, i.e.,  X   X  X  .
 The advantage of this approach is that there is no need to predict the future system state. Thus, it is a simple and easily implemented method to achieve efficient resource uti-lization in most scenarios. But, in situ adaptivity may not be flexible enough to suitably react to changes in the ob-servations. As it does not anticipate future observations, it might fail to act appropriately in situations where there are major changes in observations that result in greatly in-creased or decreased resource requirements. It is therefore best suited for scenarios where observations have fairly sta-ble values. Using a filling factor as described above decreases the risk that resources are exhausted due to unexpected changes of observations, while preserving the simplicity and convenience of the in situ adaptivity approach. Besides the problem of possible failures before  X  time steps have passed, underutilized resources or violated quality constraints might result in a sub-optimal analysis for up to  X  time units. For our running example, we use an in situ adaptivity sched-ule to apply resource adaptivity to the CluStream algorithm. Details about the used schedule as well as an appropriate function  X  are described in Section 7.2.
 Proactive Adaptivity. Alternatively, a prediction for fu-ture resource requirements can be used to determine for how long the current parameter values will be valid. The adap-tivity component is activated after the predicted time span has expired. We call this approach proactive adaptivity . Timelined variable values can be used to predict observa-tions and the parameter adaptation can be based on this anticipated system state, rather than on the current sys-tem state. That means, functions  X  and  X  take predicted observations O t + as input rather than O t . In addition, predicted observations can be used to decide about the va-lidity time span of the current parameter values as described above. The prediction of observations may reveal changes of observations that necessitate parameter adaptation, which is not possible with the in situ approach. Finally, the pre-diction is used to compute the validity time span  X  for the new parameter values. Unlike in the in situ approach, the value of  X  is not constant. In the most straightforward case,  X  is set to  X  = . A longer validity time span is possible if the predicted trend of the observations indicates that all constraints can be met for a longer time. Such a validity time span can also be predicted in the in situ approach, but this would be restricted to using only the current system state. Because the value of the variable  X  changes through-out the stream mining process, it is treated as an additional parameter, i.e.,  X   X  X  .
 Note that it is possible to make parameter values effective in the future, i.e., t +  X  . This can be achieved by setting  X  =  X  and  X  = 0, thus omitting parameter adaptation at the current time. New parameter values are computed at time t +  X  where the predictions are based on more recent observations. Typically,  X &lt; holds, as observations are predicted for time t + . If parameter adaptation is neces-sary, the new parameter values need to be effective before time t + in order to meet resource and quality constraints. A proactive approach is more complex and generates more runtime overhead than in situ adaptivity. It should therefore only be used if observations exhibit fairly erratic changes, which makes in situ adaptivity not appropriate. Proactive adaptivity can benefit from observing such changes and ac-cording patterns over time. The critical part is the actual prediction of observations. If it is inaccurate, the algorithm might crash in the worst case, because resources are ex-hausted. Any technique for predicting observations has to be a fairly lightweight process compared to the actual stream mining algorithm. The complexity of the computation of the anticipated system state depends on the employed method as well as on the number of previous variable values taken into account. A fairly lightweight but effective prediction can be done using linear regression. More elaborate predic-tion schemes may incorporate methods for periodicity esti-mation or burst detection, which could be especially ben-eficial to detect trends in the stream rate as it is one of the most crucial observations. The proactive adaptivity ap-proach promises to be especially useful with respect to the additional overhead that the whole resource adaption im-plies. This is because we may be able to predict when the number of required CPU cycles will exceed the specified re-source constraint, and thus appropriate parameter adapta-tion can take place before the resource becomes exhausted. Without such a prediction, the parameter adaptation my have to take place during the time when CPU cycles are already a scarce resource. For our resource-adaptive version of CluStream, an in situ adaptivity schedule is used. We omit the algorithm here, as it implements the function  X  introduced above in a straight-forward manner. First, the current resource and quality limits are compared to the limits that have been valid be-fore. If they differ, according codes for  X  are returned. This indicates that resource requirements or the mining quality should be increased or decreased. After that, function  X  is used to decide if resources are currently under-or overuti-lized, or will be in the next  X  time units. This is done using the current parameter values and a filling factor f , e.g., if the resource requirements at time t +  X  are less than f =70% of
R ,then  X  = 2. The computation of  X  for time t +  X  is possible, because the size of the PTF is monotonically in-creasing with time. The computation based on t +  X  ensures that all constraints will be met until the adaptivity compo-nent is triggered again at time t +  X  . It is not necessary to check if the quality remains within its limits, as Q 1 Q 2 are constant for fixed parameter values, and thus quality limits are obeyed. In this paper, we presented a model to apply quality-driven resource adaptivity to stream-mining algorithms. First, we identified quality measures as well as parameters and obser-vations of stream-mining algorithms. We then presented a correlation model that captures the correlations of parame-ters, observations, resource requirements, and quality mea-sures. This model is used to formalize the objective func-tions of a multiobjective optimization problem, which is used to determine parameter values that maximize quality mea-sures with respect to given resource and quality constraints. We presented the notion of Pareto-optimal solutions to the optimization problem, where each solution refers to parame-ter values that maximize at least one of the quality measures. Furthermore, we also presented three different approaches to determine a unique optimal solution. Finally, we discussed two approaches for schedules to invoke the resource adaptiv-ity component. We illustrated the feasibility of the model on the basis of the CluStream algorithm.
 Future work has do be done in applying the model to more algorithms and evaluating them in real-world scenarios, where the quality of the mining results can be constrained or judged by a domain expert. Further focus has to be put on the spe-cific sub-tasks of the model, such as alternatives for solving the optimization problem, lightweight prediction approaches for proactive adaptivity, and the actual resource overhead of applying the model. Despite the fact that this introduces another small overhead, we believe that such an approach is mandatory to make stream mining meaningfully applicable in current stream-based application domains with evergrow-ing data volumes and system requirements. [1] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. [2] A. Arasu, B. Babcock, S. Babu, M. Datar, K. Ito, [3] B. Babcock, S. Babu, M. Datar, R . Motwani, and [4] H. Berthold, S. Schmidt, W. Lehner, and C.-J. [5] S. B  X  orzs  X onyi, D. Kossmann, and K. Stocker. The sky-[6] Y. Chi, H. Wang, and P. S. Yu. Loadstar: load shedding [7] C. A. C. Coello. A comprehensive survey of [8] M. Ehrgott. Multicriteria Optimization . Springer Berlin [9] C. Franke. Adaptivity in Data Stream Mining .PhDthe-[10] C. Franke, M. Hartung, M. Karnstedt, and K.-U. Sat-[11] A. A. Freitas. A critical review of multi-objective op-[12] M. M. Gaber and P. S. Yu. A holistic approach for [13]C.Giannella,J.Han,J.Pei,X.Yan,andP.S.Yu.
 [14] A. Jain, E. Y. Chang, and Y.-F. Wang. Adaptive [15] M. Karnstedt, C. Franke, and M. M. Gaber. A model [16] D. Klan, K. Hose, M. Karnstedt, and K. Sattler. Power-[17] D. Lee and W. Lee. Finding maximal frequent itemsets [18] W.-G.Teng,M.-S.Chen,andP.S.Yu.Usingwavelet-[19] D. A. Van Veldhuizen and G. B. Lamont. Multiobjec-[20] M. Vlachos, D. S. Turaga, and P. S. Yu. R esource adap-[21] P. S. Yu. Data stream mining and resource adaptive
