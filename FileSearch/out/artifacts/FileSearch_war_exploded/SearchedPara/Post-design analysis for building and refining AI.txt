 1. Introduction
Over the last decade, both research effort and industry interest have been directed towards the design of intelligent systems and the application of Arti fi cial Intelligence (AI) techniques to solve real-life engineering problems. As intellig ent systems become more complex (e.g., teams of robots, autonomous vehicles, interacting decision support tools), the behavior of the system extends beyond what human programmers can specify and anticipate. Often, these systems require AI technologies that can provide fl exibility, problem solving, anticipation, and robustness in diff erent scenarios and situations. One of the main promising and appealing AI technologies for such requirements is AI Planning ( Ghallab et al., 2004 ). This technology can enhance systems with the capability of automated planning :the abstract process of creating an organized set of actions (a plan) to achieve a desired goal. AI Planning investigates computational tech-niques that reason about actions ( Ghallab et al., 2004 ), an essential component of intelligent behavior, in general and of intelligent, autonomous computer systems, in particular ( Wilkins, 1988 ). support and autonomous systems in complex and large scale problems including manufacturing ( Vaquero et al., 2006 ), space exploration ( Frank, 2008 ; Reddy et al., 2008 ; Gaines et al., 2006 ;
Jain et al., 2003 ), medical decision support systems ( Fdez-Olivares et al., 2009 ), and natural resource management ( Sette et al., 2008 ).
Most of the problems identi fi ed as suitable to being solved with automated planning techniques are characterized by a need for substantial knowledge management, disciplined modeling, rea-soning about actions and a careful consideration of quality metrics and criteria ( McCluskey and Simpson, 2004 ; McCluskey et al., 2003 ).
 engineering challenges such as the development (or re-use) of a powerful AI planning algorithm and the proper modeling of the domain knowledge. The latter consists of the creation of a model that represents (1) the world that surrounds the intelligent system, (2) the ways the system can interact with and change the world and (3) the problem to be solved. Such a knowledge model is used by the AI planning algorithm to reason about the world and act intelligently. Design decisions about knowledge modeling and planning algorithm development drastically affect the quality of the eventual plans. From a knowledge engineering perspective, lack of knowledge, ill-de fi ned requirements and an inappropriate de fi nition of quality metrics and preferences can contribute directly to malformed models and, consequently, to unsatisfactory plans, independent of the planning algorithm.
Traditionally, much of planning research has focused on the development and tuning of planning algorithms to obtain small solve times and higher quality plans. Not much investigation has been done on the knowledge engineering (KE) perspective, espe-cially re-modeling the planning problem based on observations and information that emerge during the design process itself. In most of the research on this fi eld, it is assumed that the knowledge acquisition and modeling is done properly in the early stages of the design. However, given the natural incompleteness of the knowledge, practical experience in real applications such as space exploration ( J X nsson, 2009 ) has shown that, even with a disci-plined process of design, important requirements, often from different viewpoints (e.g. stakeholders, experts, users), still emerge after plan generation.

Tacit knowledge and requirements can be captured from human feedback: opinions about and criticisms of a plan from the various stakeholders. Inclusion of such feedback implies the need for a continuous re-modeling process where models, plans, and feedback are iteratively produced and incorporated into the next round of model re fi nements. However, the capture and use of stakeholder feedback is still an unexplored area in the knowledge engineering for AI planning. Moreover, the extent of impact of such feedback and re-modeling on the planning performance is unknown. It is our thesis in this paper that post-design techniques such as simulation, visualization and virtual prototyping, com-monly used in other disciplines ( Cecil and Kanchanapiboon, 2007 ), can help AI planning application design teams improve their models and applications through the identi fi cation of tacit require-ments, unrecognized inconsistenc ies, and modeling decisions that have unanticipated negative impact on planner run-time and plan quality. Once such issues have been identi fi ed, the model can be re fi ned, as part of the subsequent design iteration, leading to better quality plans and faster plan synthesis.

In this paper, we present a post-design tool for AI planning that combines the open-source KE tool itSIMPLE ( Vaquero et al., 2007 ) and a virtual prototyping environment to support identi fi inconsistencies and hidden requirements. We aim to support designers of automated planning system to understand the mod-eling decisions and their effect on planning algorithms. We describe three case studies showing that post-design not only improves plan quality, but also improves planning performance, even in arti fi cial benchmark problems.

This paper is organized as follows. First, we provide a short background on AI Planning and the concepts and role of knowledge engineering in automated planning system design, especially for plan analysis and post-design. Then, we introduce the postDAM project describing the integration of a knowledge engineering system and a virtual prototyping tool. Next, we present the case studies and the results. We conclude with a discussion of our results. 2. Background 2.1. Arti fi cial intelligence planning
Planning is an abstract process of creating an organized, ordered set of actions, a plan , that can be executed to achieve a desired goal from an initial state. Automated Planning is a branch of Arti
Intelligence that investigates computational techniques and sys-tems to solve such problems ( Ghallab et al., 2004 ). Reasoning about actions, the more general area encompassing AI planning, con-stitutes an essential component of intelligent behavior and an essential part of intelligent and autonomous engineering systems ( Wilkins, 1988 ).

An AI planning algorithm, a planner , is charged with generating a plan that is one possible solution to a speci fi ed problem in a particular domain ( Hendler et al., 1990 ). Traditionally, a planner needs two main inputs in order to generate a plan : the domain model and the problem description (i.e. the description of the problem instance to be solved), all encoded in a formal language. A domain model is a formal description of the application domain which models entities such as the objects, functions, properties, relations, and operator schemata in the domain, explicitly. As the central elements in a domain description, operator schemata characterize actions primarily in terms of their preconditions and effects. Each operator schema characterizes a class of possible actions by containing a set of variables that can be replaced by constants to derive operator instances that describe speci ground, individual actions ( Hendler et al., 1990 ). For example, the operator schema stack(a,b) (where a and b are variables) in the Blocks World domain ( Ghallab et al., 2004 ) represents a class of actions that stacks a block a on top of a block b while stack ( A 1, B 1) represents the ground action (an instance of the stack ( a , b )operator) that put the block A1 on top of block B1.

A problem description is generally characterized by an initial state, S 0 , and a goal condition, S G where the initial state is a representation of the current state of the world and the goal condition is a description of the (partial) state the world should be in when the plan has been executed. The goal condition descrip-tion is usually referred as simply the goal. Collectively, the domain model and the problem description, represent all the domain knowledge and associated requirements that is used by the planner to solve the posed problem. These input information for the planner is called the knowledge model .

Plans are built through the instantiation and sequencing of operator schemata in the domain model. A plan is an organized collection of actions ( Ghallab et al., 2004 ) that is a solution to a given problem if, when executed in the problem ' s initial state, it results in a state that satis fi es the goal. In such an execution, the fi rst action of the plan must be applicable in the initial state (i.e., all the preconditions for this fi rst action hold in the initial state) and each of the following actions in the plan must be applicable in the state arising from the previous one ( Hendler et al., 1990 ). Repeated analysis of the actions  X  applicability can determine whether they can be applied in the order speci fi the plan. More details about AI planning terminology can be found in Ghallab et al. (2004) and Hendler et al. (1990) . 2.1.1. Solving planning problems
Since its origin in the 1970s, research in AI planning has traditionally focused on the development of general-purpose planning algorithms and techniques ( Ghallab et al., 2004 ). Given the domain model and problem description, these algorithms apply search, general heuristics and inference techniques to reason about actions and generate the plans. However, the process of fi nding a plan that solves a planning problem depends not only on the technique or strategy used by the planner, but also on the knowledge model ( McCluskey et al., 2003 ).

The performance of planners is directly related to both the knowledge model and the planning algorithm. The input knowl-edge requires expressive speci fi cation languages to capture all necessary domain characteristics and requirements, as well as the right quality metrics. Planning techniques require high quality implementation and heuristics to achieve a satisfactory use of the input domain knowledge and, consequently, a high quality synth-esis of plans.

During the fi rst two decades, AI planning technology was restricted to small or simple domains (  X  toy  X  problems) due to the available techniques and representation languages. In the 1990s, advances in planning technology allowed more complex applica-tions to be handled ( Ghallab et al., 2004 ) which motivated the research community to establish the standard Planning Domain
De fi nition Language (PDDL) ( McDermott, 2000 ) to unify planner capabilities and representational needs. Both planning techniques advances and representation language standardization opened new directions and opportunities to the planning research 2.1.2. Real-world planning applications
During the last decade, the development of more advanced techniques has intensi fi ed, driven by several technological chal-lenges encountered in real-world problems. Some studies have shown applications of great challenge for the planning systems: control of spacecraft and satellites ( Ghallab et al., 2004 ; Frank, 2008 ), control of instruments in space stations ( Reddy et al., 2008 ), navigation and movement of robots on Mars ( Gaines et al., 2006 ;
Jain et al., 2003 ), clinical decision support systems for oncology therapy planning ( Fdez-Olivares et al., 2009 ), advanced manufac-turing ( Vaquero et al., 2006 ), control activities at oil terminals ( Sette et al., 2008 ), and others. These applications have motivated not only the development of new planners, but also subsequent extensions of the main representation language PDDL to include the expression of, for example, numeric fl uents, metric optimiza-tion, durative-actions, timed-based elements, preferences, and constraints ( Edelkamp and Hoffmann, 2004 ; Gerevini and Long, 2006 ).

The current literature on planning application is encouraging for those who need appropriate tools in real-world problems.
However, there is still a signi fi cant gap between the problems typically studied in the research literature and these applications.
The major challenges in studying these real problems are found in two main areas: (1) the design process that includes knowledge acquisition, modeling, quality metric speci fi cation, and analysis of the domain knowledge model; and (2) the development of high performance planners in these complex domains. Both aspects are necessary to deploy reliable planning systems able to generate plans with the desirable quality. Research focused on the challenge is still in its infancy ( McCluskey et al., 2003 ). 2.2. Knowledge engineering for AI planning system design
Originally, knowledge engineering (KE) for AI planning was seen as a special case of Knowledge-based Systems (KBS), where the need for acquiring, modeling and managing knowledge at the conceptual level has long been accepted ( McCluskey et al., 2003 ).
However, there are peculiarities of planning applications that clearly distinguish knowledge engineering for AI planning from general knowledge-based systems, chie fl y knowledge about actions and its proper acquisition and modeling ( McCluskey and Simpson, 2004 ; McCluskey et al., 2003 ).

While mainstream AI planning research focuses on developing high-performance and reliable planners, KE for planning research focuses on the design process for creating reliable models of real domains ( McCluskey, 2002 ; Vaquero et al., 2007 ). The central claim of this line of work is that the use of a well-structured life cycle to guide design increases the chances of building an appro-priate planning application while reducing possible costs of errors in the future. A simple design life cycle is feasible for the development of small prototype systems, but fails to produce large, knowledge-intensive applications that are reliable and main-tainable ( Studer et al., 1998 ).

Research on KE for planning has led to the creation of tools and techniques to support the design of knowledge models ( Vaquero et al., 2009b ; Simpson, 2007 ). For example, the seminal tool called
Graphical Interface for Planning with Objects (GIPO) ( Simpson et al., 2001 ) is one of the fi rst domain-independent tools in the literature for supporting knowledge acquisition using visualization and diagrammatic approaches. The purpose of the GIPO project is to explore and demonstrate the range and scope of tools required to support the knowledge engineering aspects of planning system creation and validation. Differently from GIPO, the itSIMPLE tool ( Vaquero et al., 2007 , 2009b ) focuses on a disciplined design process of real planning applications while providing an integrated environment that supports knowledge acquisition in its early stages. itSIMPLE integrates a set of languages and tools to support the cyclic design process of a knowledge model from an informal representation to a formal model. itSIMPLE system support engineers andscientistsinmodelingdomainsandproblemsinanobject-oriented approach and analyzing the outcomes of planning activities.
Some existing tools address speci fi c phases of the design process such as model analysis in order to spot malformed models and enhance the performance of planners.
 tools in KE for AI planning that support the creation of planning problems speci fi cations. However, a design process does not guarantee a complete and fl awless model of a planning problem, even with the existing methods and tools available in the AI community ( McCluskey, 2002 ; Vaquero et al., 2009b ). The identi-fi cation of unsatisfactory solutions and unbalanced trade-offs among different quality metrics and criteria indicates a lack of understanding of requirements and preferences in the model ( J X nsson, 2009 ; Rabideau et al., 2000 ; Cesta et al., 2008 ). Such hidden requirements raise the need for iterative re-modeling and tuning process. In some applications, fi nding an agreement or a pattern among emerging requirements is an arduous task ( J X nsson, 2009 ), making re-modeling a non-trivial process. analysis of generated plans with respect to the requirements and quality metrics. Plan analysis naturally leads to feedback and the discovery of hidden requirements for re fi ning the model. We call  X  post-design analysis  X  the process performed after plan generation, in which we have a base model and a set of planners and investigate the solutions they generate. Some of the AI planning research on plan analysis has developed tools and techniques for plan animation ( McCluskey and Simpson, 2006 ; Vaquero et al., 2007 ), visualization (e.g. Gantt charts), and plan querying and summarization ( Myers, 2006 ). However, such work does not explore the effects of the missing knowledge and the re-modeling loop in the system design process. The investigation of modern analysis tools for AI planning (e.g., simulation) is still an emerging fi eld. We believe that techniques such as simulation, visualization, and virtual prototyping, commonly used in other disciplines ( Cecil and Kanchanapiboon, 2007 ), can help design teams identify requirements and inconsistencies in the model, as well understand their modeling decisions and the corresponding impact on plan generation and execution. It is worth mentioning that there exists a handful of speci fi c domain analysis tools that help designers to spot malformed models (e.g., syntax checkers) and enhance the model (e.g., TIM Fox and Long, 1998 ; Cresswell et al., 2002 ). However, they have not addressed and studied the missing knowledge and requirement identi fi cation, and the re-modeling loop considering more realistic scenarios in which humans are in this loop. 3. The Post-Design Application Manager project investigate post-design techniques to increase the quality of knowledge models and plans. The project focuses on combining recently developed tools in KE for AI planning with virtual prototyping. The project proposes a framework that integrates itSIMPLE 1 ( Vaquero et al., 2009b ) and the 3D content creation environment, Blender, 2 for virtual prototyping. Blender is an open source tool, widely used for creating games and animations that provides several mechanisms for the de fi nition and simulation of three-dimensional elements, including their physical properties (such as mass, collision, gravity, inertia, velocity, strength, and sound effects) to mimic real world behaviors.

The integration of these tools aims to close the design loop, from requirements acquisition to plan analysis in the post-design. In this loop, itSIMPLE is responsible for supporting users during design and re-design of the models while Blender, properly integrated with the KE tool, simulates the plans provided by planners.

During model construction in itSIMPLE, designers perform the initial design phases in the Uni fi ed Modeling Language (UML) ( OMG, 2005 ). An important step in this design process is the identi fi cation and speci fi cation of quality metrics, along with their respective importance. These quality metrics are characterized in the form of weighted domain or plan variables, i.e., numeric variables that are directly (or indirectly) related to the quality of plans. Examples of domain and plan variables are: the number of occurrences of a speci fi c action in a plan; the total consumption of fuel; the number of robots used for a particular purpose; and the energy remaining in a battery. The de fi nition of quality metrics in itSIMPLE uses the approach described in Rabideau et al. (2000) .
During simulation in Blender, it is possible to analyze and evaluate different solutions while contrasting them based on the quality metrics. Stakeholders with different viewpoints can communicate during the 3D visualization in order to validate and adjust the model based on their impressions. Fig. 1 illustrates this iterative re fi nement process.

In order to provide an integrated design iteration, a commu-nication channel between itSIMPLE and Blender was developed in which data is sent from the KE tool to the 3D environment as illustrated in Fig. 2 . The data sent by itSIMPLE consist of the domain model, the problem instance and the quality metrics to be considered (all in an XML representation Vaquero et al., 2009b ).
Since users can run several state-of-the-art planners from the itSIMPLE ' s GUI, the generated plans are also sent directly to the 3D simulator.

Blender reads the data from itSIMPLE and generates a virtual prototype of the model based on a library of graphical objects and their physics. These objects are designed in such a way that they can perform and react to the actions de fi ned in the model.
The Blender application reads the main elements of the domain and problem instance such as classes of objects, the objects and their properties, and additional information regarding the graphi-cal position of the elements that has been stated by the user.
Classes are used to identify the necessary graphical elements from the prede fi ned library, while objects, properties and location information are used to instantiate and initiate the graphical elements in the initial scene. All the elements in the problem instance de fi nition are found in the 3D representation. Having the initial state established in the 3D scene, the plan provided by a planner is then simulated (we assume that plan actions are deterministic). In the simulation, the actions are sent to each involved object, step-by-step. Each object is implemented to act based on the instructions that it is given. In each step of the simulation, the values of the metrics are stored to provide a clear view of their changes over the plan.

At the end of simulation, Blender 3D produces a plan report that can be analyzed by users. The report contains the evolution of the chosen quality metrics along with the cost of the plan.
When designing a new application, appropriate graphical elements might not be available in the library for an automatic generation of the scenes on the Blender side. In this case, designers have to create the 3D elements for the new application in Blender based on the classes and properties speci fi ed in the UML model in itSIMPLE. Since we have designed postDAM focus-ing on reusability, designers can create the new 3D elements and put them in the prede fi ned library for reuse. Such a reuse is applied when users aim to create different problem instances in the domain, with different numbers of objects and agents (e.g., one might want to analyze the use of different numbers of robots in a manufacturing problem).

In order to create other types of objects in the 3D library, an object ' s properties and actions must follow the terminology used in the UML model. For example, if a class robot was given the property at and the capacity to move around a map, with precondition and effect, the same behavior and properties must be developed in 3D representation of the robot in the virtual world. In fact, the 3D agent must know how to perform every action that is given to it as an agent. If a robot has to execute an action move from location A to B , the de fi nition of the behavior (implemented using python scripts) must take care of executing the action and making the 3D element go from location A to B (using the speed and motion speci fi ed by the designer in the virtual prototype environment using python).

Each class must have its corresponding 3D element in the library so that the postDAM system can create initial scenes automatically. postDAM imports and instantiates the virtual objects and creates the scene base on the problem instance speci fi cation in UML, allowing designers to study different scenar-ios without having to design initial scenes for each scenario. When the initial scene is created using the new elements in the library, the plan is executed by automatically distributing the actions to the agents in the right order. The postDAM system takes care of distributing the actions and synchronizing them according to the plan generated by planners.

It is also possible to design the virtual prototype of the application without using the prede fi ned library. In this case, the development of the 3D model follows a similar approach as described above (e.g., mapping terminologies and classes), but the automatic scene generation is not used, only the plan execu-tion mechanism. Even in this case, the designer can save time by only focusing on designing the behavior of each 3D element while the execution and synchronization of actions is already provided in the postDAM framework.
 In this paper, we focus on the case studies of the framework. Detailed information about the design and implementation of postDAM and itSIMPLE can be found in Vaquero (2011) , Vaquero et al. (2007 , 2009b) . 4. Case studies
A formal, scienti fi c experiment to evaluate the postDAM frame-work and our thesis is dif fi cult to design as the success of real world application projects depends on external contingencies such as market conditions, cash-fl ow, employee quality and retention, and the political, social, and cultural environment both within and beyond the organization pursuing the project. Furthermore, given the expense of application development, it is unlikely that an organization will allow parallel projects differing only on the independent variable of interest: the use of the postDAM frame-work. However, a purely narrative description of the use of the framework on a project provides little scope for truly testing our thesis beyond a posteriori opinions about how things might have gone differently without the framework. In an attempt to bring some rigor to our evaluations while at the time illustrating the use of the postDAM framework in a reproducible context, we new present case studies using three different domains from the International Planning Competitions (IPC). 3 The IPC is a biennial event, organized at the International
Conference on Planning &amp; Scheduling. It was created in 1998 to provide a forum for empirical comparison of planning algorithms and techniques. The competition not only aims to compare state-of-the-art automated planner performance but also to highlight challenges to the community in the form of problems at the edge of the current technology capabilities.

For each case study we use the following procedure: 1. We created an initial model in itSIMPLE guided by the original
PDDL representation to simulate the design process. Since itSIMPLE generates PDDL output as a communication language to planners, we verify that such output is exactly the same as the original PDDL version of the benchmark domain. In addi-tion, we use itSIMPLE to de fi ne quality metrics for the domain.
This model is called Original . 2. We selected three problem instances to be analyzed in depth from the 30 IPC instances. The selected instances are called the design set . Eight planners were chosen to be run (using default parameters) with a 20-min time-out on each problem instance. 3. Using the virtual prototype, we studied each plan and its 4. We then took the remaining 27 problem instances, called the domains were chosen based on the clear correspondence between objects in the real and virtual world, an important characteristic for virtual prototyping.
 familiar with these domains, we use the PDDL terms and elements to describe the adjustments made in the remodeling process. 4.1. The Gold Miner domain of IPC-6 in 2008. 4 In this domain, a robot is in a mine and has the objective of reaching a location that contains gold. The mine is represented as a grid in which each cell contains either hard or soft rock. There is a special location where the robot can either pickup an unlimited supply of bombs or a single laser cannon.
The laser cannon can be used to destroy both hard and soft rock, whereas the bomb will only penetrate soft rock. If the laser is used to destroy a rock that is covering the gold, the gold will also be destroyed. However, a bomb will not destroy the gold. This domain has a simple optimal strategy in which the robot must (1) get the laser, (2) shoot through the rocks (either soft of hard) until it reaches a cell neighboring the gold, (3) go back to get a bomb, (4) explode the rock at the gold location, and (5) pickup the gold.
We use the propositional typed PDDL model from the testing phase of IPC-6.
 ing the variety of the number of objects and dif fi culty. The ( gold-miner-target-5x5-01 )andthesecond( gold-miner-target-5x5-02 ) instances have a 5 5 mine with distinct positions of gold, bombs, cannon, and soft and hard rocks. The third instance ( gold-miner-target-6x6-05 ) is similar but with a 6 6mine.
 of the robot (weight 2), the bomb usage (weight 1), and the laser cannon usage (weight 1). In itSIMPLE, we speci fi ed these metrics as counters of the actions move , detonatebomb , and fi relaser , respectively. We selected SGPlan5 ( Hsu et al., 2006 ), MIPS-xxl 2006 ( Edelkamp et al., 2006 ; Edelkamp, 2006 ), LPG-td ( Gerevini et al., 2004 , 2006 ), MIPS-xxl 2008 ( Edelkamp and Jabbar, 2008 ),
SGPlan6 ( Hsu and Wah, 2008 ), Metric-FF ( Hoffmann, 2003 ), LPG 1.2 ( Gerevini and Serina, 2002 ), and hspsp ( Haslum, 2008 ) to solve the problem instances. As identi fi ed and described in Coles and
Coles (2011) , SGPlan6 makes use of textual domain features (e.g., speci fi c names of actions and the number of parameters they take) to recognize speci fi c planning problems from the IPC competition.
Textual features recognition is not desirable in our experiment because changes in performance during re fi nement cycle might be due to a change in the way the domain is recognized by SGPlan6, for example, if it no longer recognizes the features, if it starts recognizing some features, or if it thinks it is dealing with an entirely different domain. As our results indicated that SGPlan6 exhibited behavior similar to the other planners in this work, we decided to keep it as part of the selected planners. However, one should be cognizant of the possible role of textual feature recognition when interpreting the results from SGPlan6.
During the fi rst post-design analysis with the original model and the design set, we carefully investigated all 24 generated plans (8 planners times 3 problem instances) through the 3D simulation. Fig. 3 shows an example of the simulation.
 A number of observations were made in the fi rst analysis:
One planner generated invalid solutions in which the robot used the laser at the gold location, destroying the gold.
Some planners provided (valid) plans in which the laser cannon was fi red at an already clear location.
 Unnecessary move actions were present in some plans.

In order to fi x these non-optimal and fl awed behaviors, we re fi ned the original model. Concerning the robot fi ring at the gold, in the original model there was no precondition on the fi operator that explicitly constrains this behavior. We added such a precondition: ( not ( gold-at ?loc )). For the unnecessary occurrences, a second precondition was added to the same fi operator, in this case ( not ( clear ?loc )). We call this set of modi cations A . The planners were run using the resulting model and the same problem instances, resulting in a second post-design iteration.

During the second analysis process, additional observations were collected:
Invalid plans were no longer being generated and the undesir-able fi ring behavior was eliminated.

The laser cannon and the bomb source are located in the same place in the initial state. However, in most of the plans, at the goal state, the laser cannon was left in a different position from the initial one. In realistic scenarios, resources such as the laser cannot be left anywhere  X  a fi xed position (or a set of positions) is usually established for accessing and replacing resources.
As a new requirement, the robot could leave the laser only at the same spot as the bomb source instead of leaving it elsewhere. Unnecessary move actions were still found in some solutions.
These new observations guided the second remodeling. A precondition to the putdownlaser operator was added, forcing the robot to always drop the cannon at the location of the bombs.
The precondition ( bomb-at ?loc ) was used for this purpose. We call this modi fi cation B . The plans generated with model B properly controlled the location where the cannon was left. The combina-tion of the previous and the current set of adjustments is called AB .
As a result of the AB modi fi cation, most of the generated plans for the design set problems converged to the same solution. Given the number of planners and variety of underlying technology, this is an interesting observation in itself. The main issues raised during post-design analysis were eliminated, except for some unnecessary move actions.

To evaluate the effects of remodeling, the Original model was compared to the models A , B , and AB . The selected planners were run on the testing set for each of the four models. Tables 1 and 2 illustrate the comparison concerning run-time (speed) and solva-bility, respectively. Table 1 shows the total time (including time-outs) for each planner to solve all 27 problem instances with each of the four models. In order to determine the speed-up values, we fi rst de fi ne t M p ; k as the time planner p takes to solve problem instance k using model M . We then de fi ne the speed-up ratio for each of the new models ( A , B , AB ) compared to the Original model as follows: r For a particular planner and model, we calculate the mean and the median of the speed-up ratios. The mean speed-up value pre-sented in Table 1 for each model is the mean of means of speed-up ratios over all planners. Similarly, the median speed-up is the median of the medians of speed-up ratios over all problem instances and planners for each model. Model AB shows a signi fi cant speed-up compared to the Original . Even A and B individually provide a signi fi cant speed-up. The maximum speed-up ratios observed on an individual problem instance were 7547 with model A , 5068 with model B and 5185 with model AB . However, we also observed that in some cases the new models were slower than the original. The lowest ratio observed in a problem was 0.26 with model B . Moreover, the lowest ratio observed in the cases where planners halted with no solution in all four models was 0.0003 with model B and AB .

Considering the total time to solve the testing set, all planners perform better in the AB model, except MIPS-xxl 2008. We observed that in some problem instances the MIPS-xxl 2008 halted in less than a second with no solution when dealing with Original model and when solving the modi fi ed version it reached the time-out in these instances. This situation results in the higher run-time.

Table 2 illustrates the number of instances solved by the planners in each model, as well as the percentage improvement of each new model compared to the original. In most cases all problem instances were solved in the AB model, a 20.8% improve-ment compared to Original .
 Improvements are also observed for plan length and quality. By looking at each problem instance and the four plans generated by a particular planner, we can determine the model that gives the best performance on three criteria: run-time, plan length and plan quality (cost). Table 3 illustrates the number of times each model results in the best solution with respect to each of the three criteria for a given planner. For example, LPG-td generated the best plan lengths, compared to the other LPG-td models, in 5 cases with
Original , 24 with A , 10 with B , and 27 with AB . The sum is greater than 27 due to ties. Better plans are usually found with re models. 4.2. The Storage domain
The Storage domain is one of the benchmark domains from the deterministic track of IPC-5 in 2006. 6 It involves moving crates from containers to depots using hoists. Inside a depot, each hoist can move according to a speci fi ed spatial map connecting different areas of the depot, represented by a grid. Transit areas are used to connect depot areas to containers and also depots to depots. The domain has fi ve actions: (1) lifting a crate with a hoist; (2) drop-ping a crate from a hoist; (3) moving a hoist into a depot; (4) moving a hoist from one area of a depot to another; and (5) moving a hoist out of a depot. At the beginning of each problem, all crates are inside the containers, waiting to be transported to the assigned depot. For this case study, we used the propositional version of the PDDL domain model.

The design set for this domain is composed of three problem instances with different numbers of elements. In the fi rst instance (p10), four crates must be allocated in one depot using a single hoist. In the second (p16), six crates must be carried from two containers into two depots by three hoists. The third instance (p20) has ten crates stored in three containers, three depots, and three hoists.

The quality metrics speci fi ed for this domain are the numbers of occurrence of each operator in the plan: move (weight 2), lift (weight 1), drop (weight 1), go-out (weight 3); and go-in (weight 3).
The weights used in this experiment were inspired by the PDDL numeric version of the domain. We selected the same planners used in the previous case study, except LPG 1.2 which was removed due to a bug found while running the design set. Instead we used FF 2.3 ( Hoffmann and Nebel, 2001 ).
 set were analyzed in the virtual prototype platform. Fig. 4 shows the simulation of the fi rst problem instance from the design set. vided by planners were: the containers. In order to constrain that situation, a simple modi fi cation of the parameters of operator drop was made. The original operator has the following PDDL representation ( ?h-hoist ?c-crate ?a1-storearea ?a2-area ? p place ). The adjusted version of the drop operator differs from the original in the last parameter: ? p depot . The parameter p constrains the location where crates can be dropped. We call this modi fi cation A .
 the following observation were acquired: cessary lift and drop cycles of the same crate. The approach was to make the hoist remember the last lifted crate. A new predicate, ( lastLifted ?h-hoist ?c-crate ), was added to the precondition of the lift operator in the form ( not (lastLifted ?h-hoist ?c-crate )) and to the post-condition as ( lastLifted ?h-hoist ?c-crate ) to record the current crate. The precondition constrained the planner not to assign a hoist to lift the same crate again. The added post-condition de fi nes the previously lifted crate. This is just one approach to tackle the issue. More elaborate remodeling could be performed. We call this individual modi fi cation B . The combina-tion of the re fi nements A and B generated the model AB . Note that
A , B and AB do not require modi fi cation of the problem instances, even with the new predicate in B , since the hoists start with no previous lifted crates.

By analyzing the model AB in the post-design framework, the unnecessary lift-drop loops of the sa me crate were reduced drastically.
However, in rare cases some plans exhibited the problem in a different form: two hoists alternatively lift and drop the same crate. The unnecessary move actions were reduced but not eliminated.
Tables 4 and 5 show the impact on run-time and solvability, respectively, when running the selected planners over the testing set with the original and the new models. A and B are again analyzed separately for a view of individual effects. The speed-up is not as impressive as the fi rst case study. The maximum speed-up ratios observed for a single problem instance were 4411 with model A , 4597 with model B and 5194 with model AB . The minimal ratio observed was 0.01 with model B .

Considering the total time to solve the testing set, most of planners perform better in the AB model. Metric-FF and FF 2.3, exceptionally, perform much better with model A . In fact, model A provider the best speed-up median, i.e., planners using this model achieved better performance more often than the other models. As observed in Table, 4 , the median values are very close to 1.0.
Analyzing the data, we observed that planners (e.g., hspsp) reached timeout in several instances (especially for the bigger instances) in both Original and the modi fi ed models; in these cases the ratio is 1.0. However, in many other instances from the testing set the new models surpass the original model with large difference between the run-times, pushing the speed-up mean to greater values.

As shown in Table 5 , we do not have a signi fi cant improvement in the solvability with the new models. The highest ones are the A and AB with a 8.5% improvement on the total number of problems solved.

Table 6 illustrates the model with which each planner provides it best run-time, plan length and plan quality. For example,
SGPlan6 provided the best plan lengths on 4 problem instances with the original model; 10 with model A , 17 with model B , and 18 with model AB . Similarly to the previous case study, the table shows that better plans are found more often using the re models. 4.3. The Settlers domain
The Settlers domain is one of the benchmark domains from the deterministic track of IPC-4 in 2004. 7 It is based on resource-management games, in which resources must be accumulated and used to construct new resource centres, with new specialized production and capabilities. The resources (e.g. timber, stones, ore) can be extracted and combined to construct vehicles (carts, trains and ships), facilities (e.g. sawmill, coalstack, ironworks), and housing in different locations. Plan quality is judged by a linear combination of labour use, pollution and resource consumption.
In contrast to the previous two case studies, this domain has numeric properties which naturally increase the complexity of the problem. Moreover, this benchmark domain has only 20 problem instances. As one of the instances is trivially unsolvable ( p08 ), we considered the remaining 19 instances in this case study.
The design set for this domain is composed by three problem instances with different numbers of elements and dif fi culty levels.
In the fi rst instance ( p02 ), there are fi ve locations in which houses and sawmills must be built using the available resources. In the second ( p05 ), houses, sawmills and coalstacks must be built in some of the six available locations. The third instance ( p12 ) has eight locations in which several facilities, houses and rails must be built.

Based on the domain description from the IPC, the quality metrics speci fi ed for this domain are the labour use, pollution creation and resource use. The weights used in the experiment followed the same values found in the PDDL version of the problems instance. Since this domain involves numeric properties, we selected those planners from the previous case studies that can handle numbers: SGPlan5, LPG-td, SGPlan6, and Metric-FF.
During the fi rst post-design iteration, the generated plans for the design set were analyzed in the virtual prototype platform.
Fig. 5 shows the simulation of the fi rst problem instance from the design set.

The main observations from analyzing the plans provided by planners were:
In some solutions, carts delivered resources to locations that were able to produce them easily. As an example, timber was delivered to a woodland location. Another example would be the coal being unloaded from a cart at a location that has a coalstack already.

Some of the plans included unnecessary move actions. In particular, carts perform a round trip (from p1 to p2 and back) without loading or unloading any resource.
 Some solutions contained unnecessary load and unload actions.
In this case we observed carts that unloaded a particular resource right after loading it. 8
Firstly, we focused on the fact that basic resources were being delivered to locations that could produce them. A simple mod-i fi cation in the precondition of the action unload was made to ensure the following: timber can only be unloaded at locations that are not woodlands; stone can only be unloaded at locations that do not have mountains; wood can only be unloaded at locations that do not have sawmills; and coal can only be unloaded at locations that do not have coalstack. In PDDL terms, the adjusted version of the unload operator has the following addi-tional precondition: ( imply (  X  ?r timber )( not (woodland ?p ))) ( imply (  X  ?r stone )( not ( mountain ?p ))) ( imply (  X  this modi fi cation A .

During the second iteration of simulation with adjustment A , the following observations were acquired: Basic resources were no longer being improperly delivered. the round trips executed by carts and the load  X  unload cycle. For the round trips issue, the approach was to make the vehicle cart remember the last location where it performed a load or unload action. In order to do so, two new predicates were speci fi ( lastPlaceWorked ?v-Vehicle ?p-Place ) for holding the previous place that the vehicle worked; and ( worked ?v-Vehicle ) for identi-fying whether the vehicle performed any load or unload action.
A new action, called movecart2 , was inserted in the model to encompass every possible situation of the cart while leaving a location. The two new predicates were used in the actions load , unload , movecart , and movecart2 . In order to identify that the cart worked in a place, ( worked ? v ) was added to the post-condition of load and unload . Concerning the actions for moving, a cart has two options: movecart and movecart2 (both with the following para-meters: ?v-Vehicle ?p1-Place ?p2-Place lastp-Place ). In the movecart operator we extended the original precondition so that the cart must have worked in the current place to move on to another location, i.e., we added ( worked ? v )( lastPlaceWorked ?lastp ) to the precondition. On the post-condition, we added ( lastPlaceWorked ?p2 )( not ( lastPlaceWorked ?lastp )) ( not ( worked ? v store the last location and clear the previous worked status. In the movecart2 operator, the cart can move from a location at which it did not work; however, the cart cannot go to the same place it worked before ( not (  X  ?lastp ?p2 )). The PDDL representation of movecart2 is as follows: unload so that unload has to be always performed before loading any resource. We added a new predicate ( loading ?v -Vehicle )tothepost-condition of the operator load which allow the identi fi cation of when a vehicle starts to load resources. We also added ( not ( loading ? to the precondition of the operator unload to make sure that after loading the cart cannot unload; instead, the cart is able to unload any resource and then load another one. As above, more elaborate remodeling could be performed. We call this set of modi fi The combination of the re fi nements A and B generated the model AB .
Note again that A , B and AB do not require modi fi cation of the problem instances, even with the new predicates in B . saw that the load  X  unload cycle was eliminated as well as most of unnecessary moves; however the move loops were not fully constrained. Since the modi fi cation prevents carts from going back to location where load or unload was previously performed, it does not prevent, for example, the cart from making a round trip between p1 and p2 while doing nothing at either p1 nor at p2 . This behavior emphasizes the need for additional modi fi cations in the model in order to avoid such behavior; however we will not approach them in this work.

Tables 7 and 8 show the impact on run-time and solvability, respectively, when running the selected planners over the testing set (16 problem instances) with the original and the new models.
A and B are once again analyzed separately for a better view of individual effects. The fi rst aspect to be notice is that, differently from the former two case studies, the overall run-time increases with the modi fi cations: the modi fi cations make planners timeout more often. However, we also encountered interesting speed-ups, but indeed not impressive. The maximum speed-up ratios observed for a single problem instance were 13 with model A , 158 with model B and 275 with model AB . The minimal ratios observed were 0.198 with model A , 0.016 with model B , and 0.033 with model AB . Since the new models caused planners to reach the timeout in many cases (especially for the bigger instances), a decrement on the number of problems solved with the new models. The largest decrement happens in the mode B with  X  48.5%. Table 7 shows clearly that some modi fi cations can make planning harder.

Table 9 illustrates in which model each planner provides it best run-time, plan length and plan quality. For example, LPG-td provided the best plan lengths on 6 problem instances with the original model, 8 with model A , 1 with model B , and 1 with model AB . Better plans are found more often using the re fi ned model A .
Note that in this study, the results are different on plan length and plan quality as the latter considers weights to evaluate the cost of the plans. Concerning the plan quality, we observed that the difference between the costs of plans found for the original model and the modi fi ed ones increases as we move towards the harder instances; the modi fi ed models show much lower costs on hard problems compared to the original model. 5. Discussion 5.1. Knowledge acquisition and extraction
The acquisition, representation and modeling of knowledge and requirements create a number of challenges for knowledge engineers and design teams ( Perez et al., 2006 ). The case studies demonstrate that even in arti fi cial benchmark domains, missing requirements and modeling issues emerge in the post-design analysis. In real AI planning applications, we expect such gaps to be very common due to the higher complexity of the problem and the fact that an expert has not already made decisions about what is relevant and what is not. The knowledge acquisition process in real-world applications is not the pure collection of already existing requirements during the beginning an application design ( Studer et al., 1998 ). Tacit knowledge and hidden and unknown requirements must be discovered and considered. Therefore, knowledge must be built up and structured during an iterative design process; domain modeling is an iterative process in which new observations may lead to a re fi nement of the already built-up model over time ( Studer et al., 1998 ). Moreover, the model itself as well as plans for problems within the modeled domain will guide the further acquisition of knowledge through producing unantici-pated situations and raising questions with currently unknown answers.

In this work, both the KE tool and the 3D simulation environ-ment have an important role in the re fi nement cycle. The use of virtual prototyping, in particular, was a powerful tool for plan validation and the identi fi cation of new requirements. Visual and sound effects can give experts and non-experts a better view of the domain model as well as the planning strategy. The KE tool was also essential in the process, especially in the remodeling phases. A metric-focused analysis, using for example the plan report and evaluation summary, helps the designer to determine the subset of high quality solutions as well as the proper set of quality criteria.

Another important factor on discovering a lack of knowledge in the model and hidden requirements is the presence of different levels of quality over the analyzed plans. The identi fi cation of bad plans, for example, proved to be a powerful guidance on the remodeling process. Bad plans not only raise the need for new constraints on the model, but also help designers to capture users  X  feedback and preferences. In our case studies, the generation of distinct plan qualities was enhanced by using a variety of planners.
Since the lack of knowledge in the model can impact differently on the planners, their different responses also contribute to the identi fi cation of model issues. After the adjustment process these different responses are narrowed as many of the plans converge to the same solution over different planners.

We observed that planners can be very sensitive to the presence or absence of speci fi c knowledge in the model. As an example, in the Gold Miner domain, the adjustment cycle made some of the planners perform impressively better; nevertheless, in the Settler domain, the addition of knowledge negatively affected the planners  X  internal heuristics. In fact, adding missing con-straints does not necessarily result in faster responses from the planners; however, even with a higher run-time the plan quality was improved. 5.2. Case studies and the real world
There is a fundamental mismatch between the target domains of the postDAM framework (i.e., real-world planning applications) and our case studies using IPC domains. A true test of our tool should be in the form of a case study with a real problem (e.g., Cesta et al., 2008 ; J X nsson, 2009 ; Vaquero et al., 2009a ). However, as argued above, such case studies are not reproducible and often rely for success on external factors: signi fi cant interest from the client, success of other parts of the missi on (e.g., landing on Mars), and larger economic forces. System building research is extremely valu-able but sometimes inaccessible and dif fi cult to generalize. Research in AI planning has shifted toward a more empirical style since the beginning of the International Planning Competition, where research innovations can be reproduced and directly compared. This style, too, has substantial bene fi tsascanbeobservedfromthegainsinsolver performance. The design of our case studies was an attempt to bridge the gap between  X  real  X  applications and  X  academic  X  benchmarks and to encourage further research on modeling in planning. We have shownthateveninbenchmarkdomainsthat,byde fi nition, do not include a wealth of unrepresented knowledge, it is still possible to substantially increase solver performance by domain remodeling. 5.3. Modeling and planning
The case studies showed that the planning performance can improve with domain remodeling. We achieved speed-ups through a careful plan analysis and remodeling process, without adjusting the planners. In some cases, we added obvious knowledge to the model, from a human perspective; however, its explicit representa-tion facilitates the search process of the planners. This evidence reinforces that both aspects, mode l and planner, must be carefully designed and re fi ned. A sole emphasis on improving planners, neglecting observations and feedback from the design process itself, can de facto prevent or constrain planning use in real applications. Despite the performance improvements observed on the Gold
Miner and Storage domains, other domains (such as Settlers) indicate that easy improvements are not always available. Appar-ently reasonable changes to the model can lead to reductions in planner speed. Such results are to be expected given the dif of the planning task and the complexity of the planners which are necessarily seen as black boxes by the domain expert. This unpredictability is, in fact, exactly why KE tools are needed: they play a fundamental role in supporting the exploration and com-parison of re fi nements in the design space, giving designers the opportunity to experiment with a variety of models and balance performance criteria (e.g. reliability, system run-time, plan quality) before deploying their planning applications.

AI planning research. The central justi fi cation for building general-purpose planners is that domain experts cannot be expected to also be planning experts. Domain experts should be able to concentrate on modeling the domain, treating the solver as a black-box. In practice, therefore, the only options available to a domain expert are domain and problem remodeling. The use of planning technology by someone who is not a planning expert depends on the extent to which domains can be modeled and re-modeled to allow planning algorithms to achieve satisfactory performance. Yet, we know very little about how domain mod-i fi cations affect planning algorithms and we can provide little advice to domain experts on what changes are likely to be positive. 9 In other areas of problem solving (e.g., constraint programming Rossi et al., 2006 ) strategies for modeling and remodeling to achieve better performance are part of the research literature. In AI planning, such strategies are not currently avail-able. Tools, such as the one presented here, to allow domain experts to investigate changes and planning experts to begin to develop an understanding of the impact of changes on their algorithms are therefore critical. We hope such tools will even-tually contribute to the development of a  X  science  X  of domain modeling as can be seen developing in areas such as constraint programming and mixed integer programming. 5.4. Bene fi ts for planning experts framework is also bene fi cial to planning experts, helping them to assess and understand (1) the behavior of planning algorithms in different planning domains and (2) the potential impact of algo-rithm modi fi cations and tuning.
 performance of FF 2.3 in the four Storage domain models, in which model A provided the best results and Original the worst. The FF search mechanism is divided in two phases: a local search strategy called enforced hill-climbing (EHC), followed by best-fi
EHC encounters a dead-end ( Hoffmann and Nebel, 2001 ). Given the observed results, it is natural to guess that model A is more amenable to EHC, while in Original , B and AB models EHC is falling into dead-ends, requiring a shift to the slower best-fi rst search. Understanding this behavior, may be a source of inspiration for further algorithm development.
 instances in the testing set . In all models ( Original , A , B , and AB ),
EHC solved only the three fi rst problem instances ( storage -1, storage -2, and storage -3) while all the other solved instances were solved after the switch to best-fi rst search. Contrary to our guess, in all unsolved problem instances, FF did not shift to best-search. Apparently, the modi fi cations made in the models actually make the planner shift more quickly to the best-fi rst search and this faster shift is bene fi cial in the Storage domain. across the four models with the EHC turned off. We called this planner
FF-best-fi rst .Theresultsin Table 10 show that we would have better results for FF if we only use best-fi rst search regardless of the model we chose. By itself, we fi nd this observation surprising and interesting and note that it arises out of our domain re-modeling to improve solver performance.
We can go further in trying to explain these results by investigating the changes in plan space topology induced by our different models. The fact that EHC fails when the planner is overwhelmed with dead-ends suggests that we are introducing dead-ends in the modi fi ed models: having more dead-ends than the Original model makes FF 2.3 shift more quickly to best-search and, consequently, to solve more problems by getting closer to FF-best-fi rst . We could use a tool such as Torchlight ( Hoffmann, 2011 ) to study the proportion of dead-ends in each model to test this hypothesis. Unfortunately, we cannot yet do so as Torchlight currently handles only STRIPS-PDDL domain models. While the
Original model meets this criterion, the modi fi ed models add negative preconditions breaking the PDDL-STRIPS representation.
We therefore leave the further investigation of remodeling induced topology changes to future work. 5.5. Post-design analysis vs. post-processing re fi nement
As observed in the case studies, several plans generated by the selected planners contained redundant actions, especially when using the Original model. Some of these redundancies drove the re fi nement process during the post-design analysis and were eliminated in the re-modeling cycles. If plan quality, as opposed to planning speed, is our main interest, an alternative is to use a post-processing tool to remove redundant actions.

To evaluate this alternative we use the ARAS post-processing plan re fi nement tool ( Nakhost and M X ller, 2010 ) in the Gold Miner domain. ARAS is an anytime system that applies two post-processing methods for plan improvement: Action Elimination which improves an existing plan by repeatedly removing sets of irrelevant actions using a greedy algorithm and Plan Neighborhood Graph Search which fi nds a new, shorter plan by creating a plan neighborhood graph and extracting a shortest path.
 We run the ARAS system on all the plans generated from the
Original model ( testing set ) of the Gold Miner case study. For each run we use a 20-min timeout to improve the given plan. Given that
ARAS is a anytime system, it runs for the entire 20-min period for each input plan, but we only consider here the time the system took to generate the best improvement it could get (if any) within the timeout. We call the combination of the results from the
Original model and from ARAS (as a post-processing step) Original +
ARAS . We compared the Original + ARAS with the model AB on the time to solve all 27 problems instances from the testing set and in terms of the number of times each model results in the best solution with respect to plan length for a given planner. Table 11 presents the results from this comparison.

By looking at each problem instance and the four plans generated by a particular planner, we can determine the model that gives the best performance on three criteria: run-time, plan length and plan quality (cost). Table 3 illustrates the number of times each model results in the best solution with respect to each of the three criteria for a given planner.
 ARAS was able to re fi ne almost all plans produced with the
Original model. While overall ARAS fi nds better plan lengths in 23 more planner/instance combinations, the AB model actually achieves the same or more best plans with 5 of the 8 planners.
However, AB produces signi fi cantly worse plans for a large number of instances with Metric-FF and LPG 1.2.

The extra run-time effort is clearly apparent, especially given the outlier of MIPS-xxl 08. In all other cases, the AB model results in a total run-time of one to three orders of magnitude faster than Original + ARAS .

It is important to notice that using post-processing tools for plan re fi nement can only be bene fi cial for plan length or another measure of plan quality. As such tools rely on a plan being found in the fi rst place, run-time and solvability cannot improve. The post-design analysis on the other hand not only provides a comparable plan quality but also reduces planning time and allows more problems to be solved (see Table 2 and note that, of course, the post-processing cannot change the number of problems solved). These results, therefore, reinforce the fundamental role of a post-design analysis. 10 6. Conclusion
We have described a post-design framework to assist the discovery of missing requirements and to guide the model re ment cycle in intelligent system design. In AI planning applica-tions, in particular, we have demonstrated that by following a careful post-design analysis, we can improve not only plan quality but also solvability and planner speed. The modi fi cations made through the observations acquired during post-design resulted in impressive speed-up of state-of-the-art planners. In fact, the concepts of such a framework and post-design analysis can be applied to the design of automated system in general. In a real application, the analysis process that follows design becomes essential for having the necessary knowledge represented in the model and the right understanding of design decisions. Post-design analysis is critical for deployment of AI technology in real-world applications.

In some real applications, such as space exploration, iterative analysis and evaluation of plans and plan execution can also provide rich information about hidden preferences and constraints in the knowledge model. As future work, we plan to study the long-term (i.e., between application) knowledge extraction pro-cess in such accumulated data. The goal is to capture patterns of user preferences and design rationales that can lead to the representation of meta-level knowledge of model quality and of modeling and remodeling strategies.
 Acknowledgment
The authors wish to thank the anonymous referees for their valuable advice. The fi rst author was supported by the CAPES and CNPq in this project.
 References
