 W e present a study of the cluster hypothesis , and of the per-formance of cluster-based retrieval methods, performed over large scale Web collections. Among the findings we present are (i) the cluster hypothesis can hold, as determined by a specific test, for large scale Web corpora to the same extent it does for newswire corpora; (ii) while spam documents do not affect the extent to which the cluster hypothesis holds, they considerably affect the performance of cluster-based, as well as that of document-based, retrieval methods; and, (iii) as is the case for newswire corpora, cluster-based methods can yield better performance than document-based methods for Web corpora.

T he cluster hypothesis states that  X  X losely associated doc-uments tend to be relevant to the same requests X  [20]. The hypothesis gave rise to a large body of work on devising cluster-based retrieval methods. However, tests measuring the extent to which the hypothesis holds [6, 21, 4, 18], as well as cluster-based retrieval methods (see [10] for a sur-vey), were employed upon small scale newswire collections that are composed of well edited documents.

The study we present in this paper is, to the best of our knowledge, the first to (i) explore the cluster hypoth-esis over large scale and noisy Web corpora, (ii) compare cluster-based retrieval methods over such corpora; and, (iii) analyze the effect of spam on the extent to which the cluster hypothesis holds, and on the performance of cluster-based retrieval methods.

The main findings that our extensive empirical exploration reveals are as follows: (i) the cluster hypothesis, as tested using Voorhees X  nearest-neighbor test [21], can hold to the same extent for large scale Web corpora as it holds for newswire corpora; (ii) spam has no effect on the extent to w hich the cluster hypothesis holds, yet it substantially af-fects the performance of cluster-based and document-based retrieval methods; (iii) cluster-based retrieval methods can often outperform document-based retrieval methods over large scale Web corpora; and, (iv) overlapping clusters can be more effective for cluster-based retrieval than hard clusters for both newswire and Web corpora.
S everal tests have been proposed to measure the extent to which the cluster hypothesis holds [6, 21, 4, 18]. We adopt Voorhees X  nearest neighbor test [21] that was shown to be correlated with the performance of some cluster-based retrieval methods [16].

Some cluster-based retrieval methods utilize clusters that are created offline from the entire corpus [6, 3, 12, 10]. How-ever, clustering of large scale Web collections is not feasible. Hence, we study the performance of state-of-the-art methods that utilize query-specific clusters [7, 14, 8], that is, clusters created from the documents most highly ranked by some initial search [22]. Query-specific clusters were used in two capacities. First, for ranking documents by first inducing a ranking over clusters and then transforming it to a ranking over documents [12, 9, 13, 23, 7, 14]. Second, for directly ranking documents by using clusters to smooth documents X  representations (e.g., language models) [12, 8]. We study the performance of state-of-the-art cluster-based methods that represent these two categories.
T he goal of the first set of experiments is examining the extent to which the cluster hypothesis holds in the Web set-ting. To that end, we use Voorhees X  nearest neighbor (NN) test [21]. 1 S pecifically, an initial list D [ n ] q o f n documents is retrieved from corpus D in response to query q using some search algorithm; a document d is scored in response to q by their language-model-based similarity, denoted p d ( q ) . De-tails regarding the estimate p y ( x ) of the similarity between texts x and y are provided in Section 3.1. For each relevant document d in D [ n ] q , we count the number of relevant docu-ments in D [ n ] q t hat are among d  X  X  k  X  1 nearest neighbors in D q ; p d 0 ( d ) is the estimate for the similarity between d and d . The sum of counts over all the relevant documents found
T he nearest neighbor test was shown to be insufficient for testing the cluster hypothesis when a query-biased inter-document similarity measure was employed [18]. In this study we use a query-independent similarity estimate. f or all tested queries is then divided by the total number of the relevant documents.

The goal of the second set of experiments is comparing the effectiveness of several state-of-the-art cluster-based re-trieval methods with that of highly effective document-based retrieval approaches. In what follows we provide a short de-scription of the retrieval methods explored.

Let C ( D [ n ] q ) be a set of clusters created from D [ n ] some clustering algorithm. All cluster-ranking-based meth-ods that we explore first rank the clusters c ( 2 C ( D Each cluster is then replaced by its constituent documents (while omitting repeats if there are) to induce a (re-)ranking of documents in D [ n ] q ; within-cluster document ordering is based on the initial documents X  retrieval scores [12].
The ArithMean cluster-ranking-based method [7, 14] scores cluster c by the arithmetic mean of the initial retrieval scores of its constituent documents: 1 | c | number of documents in c . A geometric-mean-based repre-sentation of a cluster was shown to be more effective than a range of previously proposed representations [14, 17]. Ac-cordingly, another method that we study is GeomMean which assigns cluster c with the score:
A rithMean and GeomMean are based solely on the initial retrieval scores of documents in the clusters. The state-of-the-art ClustRanker method [7] incorporates, in addition, measures of document and cluster biases. A cluster c is scored by  X Cent ( c ) p c ( q ) + (1  X   X  ) Cent ( d ) and Cent ( c ) quantify the centrality of document d with respect to D [ n ] q , and that of cluster c with respect to C ( D [ n ] q ) , respectively. The centrality is computed us-ing a variant of the PageRank algorithm that utilizes inter-document and inter-cluster similarities.

The aforementioned methods are based on ranking of clus-ters as a first step. A different approach is that which uses clusters to directly rank documents. One such method, interpolation-f [10, 8] ( InterpF in short), assigns document d ( 2D [ n ] q ) the score  X p d ( q ) + (1  X   X  )
We compare the performance of the cluster-based retrieval methods specified above with that of two state-of-the-art document-based retrieval approaches. The first is RM3 , a query expansion method that uses the documents in D [ n ] expand the query [11, 1]. The second is the Markov Random Field ( MRF ) method, which utilizes term proximities and which was shown to be highly effective for Web retrieval [15]. RM3 and MRF, as the cluster-based methods, re-rank D [ n ]
E xperiments were conducted using a variety of both Web and newswire TREC datasets, specified in Table 1. AP and TREC8 are mainly composed of news articles. WT10G is a small noisy Web collection, and GOV2 is a crawl of the .gov domain, and hence contains mostly well edited documents. Both categories A and B of the ClueWeb collection were used (ClueWebA and ClueWebB). Two addi-tional experimental settings for ClueWeb, denoted ClueWe-bAF and ClueWebBF, were created following previous work [2]. Specifically, highly ranked documents that were assigned by Waterloo X  X  spam classifier with a score below 70 and 50 in categories A and B, respectively, were filtered out until n documents were accumulated, and the initial ranking of the residual corpus was then used.

We applied Krovetz stemming and removed stopwords (on the INQUERY list) from queries but not from documents, via the Indri toolkit (http://www.lemurproject.org/indri/). Titles of TREC topics served as queries.

The language-model-based similarity between texts x and y , p y ( x ) , is set to exp  X  CE p [ 0] x (  X  ) p [  X  ] i s the Dirichlet-smoothed unigram language model induced from z with the smoothing parameter  X  [10];  X  is set to 1000 [24]. As noted above, this measure is used to create the initial ranking of documents with respect to the query (henceforth Initial ) and to measure the similarities between queries, documents and clusters. A cluster is represented by the concatenation of its constituent documents [12, 7, 8]; the order of concatenation has no effect, because the cluster-based methods use unigram language models that do not consider term proximities.

We use two types of clusters utilized in work on cluster-based retrieval [19, 8]. The first is overlapping k nearest neighbors clusters ( KNN ). A cluster is created for each d ( 2 D [ n ] q ) , and comprises d and its k  X  1 nearest neighbors d i n D [ n ] q t hat yield the highest p d 0 ( d ) . In addition, we use non-overlapping hierarchical agglomerative clusters ( HAC ) based on the complete-link clustering algorithm, wherein clusters are merged bottom-up, and the partition of clus-ters with the smallest difference between k and the average size of the clusters in the partition is chosen. To create HAC clusters, the dissimilarity between documents d i a nd d j
Unless otherwise specified, the initially retrieved list, D c ontains n = 50 documents. As already noted, all the re-trieval methods we study re-rank D [ 50] q s o as to improve upon its initial ranking. Accordingly, we use MAP (at cutoff 50) and the precision at the top 5 ranks (P@5) for evaluation metrics. Performance patterns similar to those of P@5 were observed for NDCG@5; these numbers are omitted due to space considerations. Statistically significant differences are determined using the two tailed t-test with p = 0 . 05.
The parameter k , which controls the size of clusters used in the cluster-based retrieval methods, and the cluster hy-pothesis nearest-neighbor test, is set to 5. The free-parameter values of the various retrieval methods are set for each method, collection and evaluation metric by either (i) selecting the values that optimize average performance over all queries in an experimental setting ( OPT ), or (ii) performing 10-fold cross validation over the queries ( CV ). The first approach is intended for studying the potential performance of the meth-ods when ameliorating the effects of free-parameter values. The goal of using the second approach is evaluating perfor-mance when free-parameter values are learned.
T he parameter  X  in ClustRanker and InterpF is set to a value in { 0 , 0 . 1 ,..., 1 } . The number of nearest neighbors and the dumping factor in the PageRank algorithm used by ClustRanker [7] are set to values in { 4 , 9 , 19 , 29 , 39 , 49 } and { 0 . 05 , 0 . 1 ,..., 0 . 95 } , respectively. We use the sequential de-pendence model of MRF [15] and select the values of its free parameters from { 0 , 0 . 05 ,..., 1 } . The relevance model, RM3 [1], is constructed from all documents in D [ n ] q ; the Dirichlet smoothing parameter, the number of terms and the original-query weight are set to 1000, a value in { 5 , 10 , 25 , 50 } , and a value in { 0 . 1 , 0 . 3 ,..., 0 . 9 } , respectively. T able 2: The cluster hypothesis test. Numbers rep-resent the (average) number of relevant documents among the 4 nearest neighbors of a relevant docu-ment; n is the number of documents in the result list, D [ n ] q , that is analyzed.

The results of the nearest neighbor cluster hypothesis test, for result lists D [ n ] q o f varying sizes n , are presented in Table 2. We can see that the numbers for all the (Web and non-Web) collections decrease with increasing values of n . This finding is consistent with previous reports [19]. The lowest numbers are often observed for WT10G, which is a small noisy Web collection. The highest numbers are reported for GOV2 (for n&lt; 1000), which contains well edited documents. For n&gt; 100, the numbers for AP, a small newswire collection, are as high as those for GOV2.

Although TREC8 is mainly composed of news articles and is much  X  X leaner X  than ClueWebAF, the numbers for these two collections are identical for small values of n . At first glance, this finding might suggest that the cluster hypothe-sis, as measured by the nearest neighbor test, holds to the same degree on these two, rather different, collections. How-ever, a closer look at Table 2 reveals that with increasing val-ues of n , the numbers for ClueWebAF are lower than those for TREC8; furthermore, the numbers for ClueWebAF be-come exactly the same as those for WT10G; both WT10G and ClueWebAF are noisy Web collections.

There are no differences between the numbers for ClueWebB and ClueWebBF, and the differences between the numbers for ClueWebA and ClueWebAF are minor. This finding means that the existence of spam documents in the result list D [ n ] q t hat is analyzed does not affect the degree to which the cluster hypothesis test holds for these collections.
To summarize, the nearest neighbor cluster hypothesis test holds to a greater extent on a clean Web collection (GOV2) than on noisy Web collections (WT10G and the ClueWeb collections). Furthermore, spam has no noticeable effect on the extent to which the test holds. Finally, in some cases the test might hold to a greater extent for Web collec-tions than for newswire collections.
T able 3 presents the performance of the cluster-based and document-based retrieval methods. As a reference compar-ison we use a method termed Optimal which uses a rank-ing of the clusters induced by the true percentage of rele-vant documents they contain as determined using relevance judgments. The performance of Optimal is by far the best in Table 3. This finding, which is in accordance with previ-ous reports on ranking clusters in newswire domains [5, 19, 13], attests to the potential merit of methods that can detect clusters containing a high percentage of relevant documents.
When using KNN clusters, the cluster-based methods out-perform the initial document-based ranking (Initial) in most reference comparisons (corpus  X  evaluation metric); quite a few of the improvements, specifically for InterpF, are statis-tically significant. This attests to the overall effectiveness of cluster-based retrieval.

In comparing the arithmetic mean and geometric mean based representations for clusters, we see that in contrast to findings reported for newswire corpora [14, 17], the former is as effective as the latter. Specifically, ArithMean is at least as effective as GeomMean in half of the relevant comparisons for KNN clusters, and in all relevant comparisons (except for a single case of P@5 for AP) for HAC clusters.

We next explore the relative performance patterns of the cluster-based methods. For KNN clusters, the performance of none of the cluster-ranking-based methods ArithMean, GeomMean and ClustRanker dominates that of the other two; recall that these methods rank clusters and then trans-form the ranking to that of documents. For HAC clusters, ClustRanker often outperforms ArithMean and GeomMean. The InterpF method, which directly ranks documents by utilizing cluster-based information, is more effective in most relevant comparisons than the three cluster-ranking-based methods; the main exception is the comparison with Clus-tRanker for HAC clusters. This finding implies that using clusters to directly rank documents can be more effective than methods that rely on ranking of clusters.

In comparing the performance of the cluster-based meth-ods when using KNN and HAC clusters, we see that using KNN often results in better retrieval performance. This find-ing, which is in line with some previous reports for newswire corpora [8], attests to the potential merits of using overlap-ping clusters with respect to using hard clusters.

As already noted, no (substantial) differences were ob-served for the nearest neighbor test when applying filtering, or not, of spam documents from the result list. Yet, the re-trieval performance of the cluster-based methods, and that of the document-based methods, for the ClueWeb settings is much higher when spam documents are filtered out.
For ClueWebA and ClueWebAF, which are the largest (Web) collections explored, as well as for AP and TREC8, the small scale newswire corpora, the best performance in all experimental settings is attained by a cluster-based method. Cluster-based methods also obtain the best performance for P@5 for WT10G and GOV2, and for MAP for ClueWebB.
 These findings attest to the potential merits of applying cluster-based retrieval, with respect to document-based re-trieval, whether the collection is newswire or Web, and whether it is of small scale or large scale.
W e presented the first empirical study for large scale Web corpora of (i) the extent to which the cluster hypothesis holds, as measured by a specific test, and, (ii) the perfor-mance of cluster-based retrieval methods. Our main find-ings are that the cluster hypothesis can hold on the Web as it holds for newswire corpora; and, that using cluster-based retrieval methods can yield much merit for both settings. Acknowledgments We thank the reviewers for their com-ments. This work has been supported by and carried out at the Technion-Microsoft Electronic Commerce Research Center. Any opinions, findings and conclusions or recom-mendations expressed in this material are the authors X  and do not necessarily reflect those of the sponsors.
