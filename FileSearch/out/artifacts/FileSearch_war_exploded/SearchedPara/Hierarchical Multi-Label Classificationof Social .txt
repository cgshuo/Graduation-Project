 Hierarchical multi-label classification assigns a document to mul-tiple hierarchical classes. In this paper we focus on hierarchical multi-label classification of social text streams. Concept drift, com-plicated relations among classes, and the limited length of docu-ments in social text streams make this a challenging problem. Our approach includes three core ingredients: short document expan-sion, time-aware topic tracking, and chunk-based structural learn-ing. We extend each short document in social text streams to a more comprehensive representation via state-of-the-art entity link-ing and sentence ranking strategies. From documents extended in this manner, we infer dynamic probabilistic distributions over top-ics by dividing topics into dynamic  X  X lobal X  topics and  X  X ocal X  top-ics. For the third and final phase we propose a chunk-based struc-tural optimization strategy to classify each document into multi-ple classes. Extensive experiments conducted on a large real-world dataset show the effectiveness of our proposed method for hierar-chical multi-label classification of social text streams. H.3.3 [ Information Search and Retrieval ]: Information filtering Twitter; tweet classification; topic modeling; structural SVM
The growth in volume of social text streams, such as microblogs and web forum threads, has made it critical to develop methods that facilitate understanding of such streams. Recent work has con-firmed that short text classification is an effective way of assisting users in understanding documents in social text streams [ 25 , 26 , 29 , 46 ]. Straightforward text classification methods, however, are not adequate for mining documents in social streams.

For many social media applications, a document in a social text stream usually belongs to multiple labels that are organized in a hierarchy. This phenomenon is widespread in web forums, ques-tion answering platforms, and microblogs [ 11 ]. In Fig. 1 we show an example of several classes organized in a tree-structured hier-archy, of which several subtrees have been assigned to individual tweets. The tweet  X  X  think the train will soon stop again because of snow . . .  X  is annotated with multiple hierarchical labels:  X  X om-munication, X   X  X ersonal experience X  and  X  X omplaint. X  Faced with many millions of documents every day, it is impossible to manually classify social streams into multiple hierarchical classes. This mo-tivates the hierarchical multi-label classification (HMC) task for social text streams: classify a document from a social text stream using multiple labels that are organized in a hierarchy.

Recently, significant progress has been made on the HMC task, see, e.g., [ 4 , 7 , 10 ]. However, the task has not yet been examined in the setting of social text streams. Compared to HMC on station-ary documents, HMC on documents in social text streams faces specific challenges: (1) Because of concept drift a document X  X  sta-tistical properties change over time, which makes the classification output different at different times. (2) The shortness of documents in social text streams hinders the classification process.
In this paper, we address the HMC problem for documents in social text streams. We utilize structural support vector machines (SVMs) [ 41 ]. Unlike with standard SVMs, the output of struc-tural SVMs can be a complicated structure, e.g., a document sum-mary, images, a parse tree, or movements in video [ 22 , 45 ]. In our case, the output is a 0/1 labeled string representing the hi-labeled as 1 . For example, the annotation of the top left tweet in Fig. 1 is 1100010000100 . Based on this structural learn-ing framework, we use multiple structural classifiers to transform our HMC problem into a chunk-based classification problem. In chunk-based classification, the hierarchy of classes is divided into multiple chunks.

To address the shortness and concept drift challenges mentioned above, we proceed as follows. Previous solutions for working with short documents rely on extending short documents using a large external corpus [ 32 ]. In this paper, we employ an alternative strat-egy involving both entity linking [ 30 ] and sentence ranking to col-lect and filter relevant information from Wikipedia. To address con-cept drift [ 1 , 39 ], we track dynamic statistical distributions of topics over time. Time-aware topic models, such as dynamic topic mod-Figure 1: An example of predefined labels in hierarchical multi-label classification of documents in a social text stream. Documents are shown as colored rectangles, labels as rounded rectangles. Circles in the rounded rectangles indicate that the corresponding document has been assigned the label. Arrows indicate hierarchical structure between labels. els (DTM) [5], are not new. Compared to latent Dirichlet allocation (LDA) [6], dynamic topic models are more sensitive to bursty top-ics. A global topic is a stationary latent topic extracted from the whole document set and a local topic is a dynamic latent topic ex-tracted from a document set within a specific time period. To track dynamic topics, we propose an extension of DTM that extracts both global and local topics from documents in social text streams.
Previous work has used Twitter data for streaming short text clas-sification [29]. So do we. We use a large real-world dataset of tweets related to a major public transportation system in a Euro-pean country to evaluate the effectiveness of our proposed meth-ods for hierarchical multi-label classification of documents in so-cial text streams. The tweets were collected and annotated as part of their online reputation management campaign. As we will see, our proposed method offers statistically significant improvements over state-of-the-art methods.

Our contributions can be summarized as follows: We introduce related work in  X 2; in  X 3 we formulate our research problem. We describe our approach in  X 4;  X 5 details our experi-mental setup and  X 6 presents the results;  X 7 concludes the paper.
In recent years, short text classification has received considerable attention. Most previous work in the literature addresses the sparse-ness challenge by extending short texts using external knowledge. Those techniques can be classified into web search-based methods and topic-based ones.

Web search-based methods handle each short text as a query to a search engine, and then improve short text classification perfor-mance using external knowledge extracted from web search engine results [8, 44]. Such approaches face efficiency and scalability challenges, which makes them ill-suited for use in our data-rich setting [13]. As to topic-based techniques, Phan et al. [32] extract topic distributions from a Wikipedia dump based on the LDA [6] model. Similarly, Chen et al. [13] propose an optimized algorithm for extracting multiple granularities of latent topics from a large-scale external training set; see [37] for a similar method.
Besides those two strategies, other methods have also been em-ployed. E.g., Nishida et al. [28], Sun [38] improve classification performance by compressing shorts text into entities. Zhang et al. [46] learn a short text classifier by connecting what they call the  X  X nformation path, X  which exploits the fact that some instances of test documents are likely to share common discriminative terms with the training set. Few previous publications on short text classi-fication consider a streaming setting; none focuses on a hierarchical multiple-label version of the short text classification problem.
In the machine learning field, multi-label classification problems have received lots of attention. Discriminative ranking methods have been proposed in [36], while label-dependencies are applied to optimize the classification results by [18, 20, 31]. However, none of them can work when labels are organized hierarchically.
The hierarchical multi-label classification problem is to classify a given document into multiple labels that are organized as a hier-archy. Koller and Sahami [19] propose a method using Bayesian classifiers to distinguish labels; a similar approach uses a Bayesian network to infer the posterior distributions over labels after train-ing multiple classifiers [3]. As a more direct approach to the HMC task, Rousu et al. [34] propose a large margin method, where a dy-namic programming algorithm is applied to calculate the maximum structural margin for output classes. Decision-tree based optimiza-tion has also been applied to the HMC task [7, 42]. Cesa-Bianchi et al. [10] develop a classification method using hierarchical SVM, where SVM learning is applied to a node if and only if this node X  X  parent has been labeled as positive. Bi and Kwok [4] reformulate the  X  X ree- X  and  X  X AG- X  hierarchical multi-label classification tasks as problems of finding the best subgraph in a tree and DAG struc-ture, by developing an approach based on kernel density estimation and the condensing sort and select algorithm.
 To the best of our knowledge there is no previous work on HMC for (short) documents in social text streams. Additionally, we present a chunk-based structural learning method for the HMC task, which is different from existing HMC approaches, and which we show to be effective for the traditional stationary case and the streaming case.
We detail the task that we address and introduce important con-cepts, including preliminaries about structural SVMs.
We begin by defining the hierarchical multi-label classification (HMC) task. We are given a class hierarchy ( C,  X  ) , where C is a set of class labels and  X  is a partial order representing the parent relationship, i.e.,  X  c i ,c j  X  C , c i  X  c j if and only if c parent class of c j . We write x ( i ) to denote a feature vector, i.e., an element of the feature space X , and we write y ( i )  X  { 0 , 1 } for the target labeling. Let D be the set of input documents, and | D | the size of D . The target of a hierarchical multi-label classifier, whether for stationary documents or for a stream of documents, is to learn a hypothesis function f : X  X  { 0 , 1 } C from training data is a tree structure. Then, classes labeled positive by y must satisfy the T -property [4]: if a labeled c  X  C is labeled positive in output y , its parent label must also be labeled positive in y . Given the T -property , we define a root class r in the beginning of each C , which refers to the root vertex in HMC tree structure. Thus for each y in HMC, we have y ( r ) = 1 .

Hierarchical multi-label classification for short documents in so-cial streams (HMC-SST) learns from previous time periods and predicts an output when a new document arrives. More precisely, given a class hierarchy ( C,  X  ) and a collection of documents seen so far, X = { X 1 ,...,X t  X  1 } , HMC-SST learns a hypothesis func-tion f : X  X  { 0 , 1 } C that evolves over time. Thus, at time period t,t &gt; 1 , we are given a function f that has been trained during the past t  X  1 periods and a set of newly arriving documents X 0 or 1 . Classes in C that are labeled positive must follow the T -property. Afterwards, f updates its parameters using X t
Concept drift indicates the phenomenon that topic distributions change between adjacent time periods [17]. In streaming classifi-cation of documents [29] this problem needs to be addressed. We assume that each document in a stream of documents is concerned with multiple topics. By dividing the timeline into time periods, we dynamically track latent topics to cater the phenomenon of concept drift over time. For streaming documents, global statistics such as tf-idf or topic distributions cannot reflect drift phenomena. How-ever, local statistics derived from a specific period are usually help-ful for solving this problem [5, 21, 29]. Ideally, one would find a trade-off between tracking the extreme local statistics and extreme global statistics [21]. Thus, in this paper we address the issue of concept drift by tracking both global topics (capturing the complete corpus) and local, latent and temporally bounded, topics over time. Given a document set X t published at time t , we split the topic set Z into Z g t  X  Z l t , with global topics Z g t that depend on all time pe-riods and documents seen so far, and local topics Z l t derived from the previous period t  X  1 only. We then train our temporal classifier incrementally based on those global and local topic distributions.
Structural SVMs have been proposed for complex classification problems in machine learning [22, 23, 35]. We follow the nota-tion from [41]. Given an input instance x , the target is to predict the structured label y from the output space Y by maximizing a discriminant F : X  X Y  X &lt; : where the discriminant F measures the correlation between ( x , y ) , and w indicates the weights of x in F . The discriminant F will get its maximal value when y = f ( x ; w ) , which is set as hypoth-esis function in HMC-SST. We assume the discriminant F to be linear in a joint feature space  X  : X  X  Y  X  R K , thus F can be rewritten as F ( x,y ; w ) =  X  w ,  X ( x , y )  X  . The feature mapping  X  maps the pair ( x , y ) into a suitable feature space endowed with the dot product. Then the function F can be learned in a large-margin framework through the training set { ( x ( i ) , y ( i ) ) } the objective function: such that for all i and all y  X  Y \ y ( i ) : where w T  X ( x ( i ) , y ) indicates the hypothesis function value given x ( i ) and a random y from Y \ y ( i ) . For each ( x ( i ) straints (see Eq. 3) is added to optimize the parameters w . Note that y ( i ) is the prediction that minimizes the loss function  X ( y , y The loss function equals 0 if and only if y = y ( i ) , and it decreases when y and y ( i ) become more similar. Given the exponential size of Y , the number of constraints in Eq. 3 makes the optimization challenging.
We start by providing an overview of our approach to HMC for documents in social text streams. We then detail each of our three main steps: document expansion, topic modeling and incremental structural SVM learning. We provide a general overview of our scenario for performing HMC on (short) documents in social text streams in Fig. 2. There are three main phases: (A) document expansion; (B) time-aware topic modeling; (C) chunk-based structural classification. To sum-marize, at time period t i , we are given a temporally ordered short x i  X  X t i , in phase (A) (see  X 4.2) we expand x t i through entity linking and query-based sentence ranking; we obtain x 0 t by extracting relevant sentences from related Wikipedia articles.
Next, in phase (B) (see  X 4.3), we extract dynamic topics  X  building on an extended DTM model, we extract both global and local topical distributions for x 0 t i ; then, a feature vector for x generated as  X ( x 0 ( i ) , y ) .

Based on the extracted features, we train an incremental chunk-based structural learning framework in (C) in  X 4.4. We introduce multiple structural classifiers to the optimization problem by trans-ferring the set of classes C to another representation using multiple chunks S . Traversing from the most abstract chunk r S  X  S , we define each chunk s  X  S to be a set of chunks or classes. Leaves in S only include classes. For each chunk sc  X  S , we employ a discriminant to address the optimization problem over parameters F sc , where sc  X  X  child chunk/class will not be addressed unless it is labeled positive during our prediction. Accordingly, multiple dis-criminants are applied to predict labels given x t i and update their parameters based on true labels y t i .
To address the challenge offered by short documents, we propose a document expansion method that consists of two parts: entity linking and query-based sentence ranking and extraction.
Given a short document x t at time t , the target of entity linking is to identify the entity e from a knowledge base E that is the most likely referent of x t . For each x t , a link candidate e an anchor a in x t to a target w , where an anchor is a word n-gram tokens in a document and each w is a Wikipedia article. A target is identified by its unique title in Wikipedia.

As the first step of our entity linking, we aim to identify as many link candidates as possible. We perform lexical matching of each n-gram anchor a of document d t with the target texts found in Wikipedia, resulting in a set of link candidates E for each docu-ment d t . As the second step, we employ the commonness ( CMNS ) method from [27] and rank link candidates E by considering the prior probability that anchor text a links to Wikipedia article w : where E a,w is the set of all links with anchor text a and target w . The intuition is that link candidates with anchors that always link to the same target are more likely to be a correct representation. In the third step, we utilize a learning to rerank strategy to enhance the precision of correct link candidates. We extract a set of 29 features proposed in [27, 30], and use a decision tree-based approach to rerank the link candidates.
Given the link candidates list, we extract the most central sen-tences from the top three most likely Wikipedia articles. As in LexRank [15], Markov random walks are employed to optimize the ranking list iteratively, where each sentence X  X  score is voted from other sentences. First, we build the similarity matrix M , where each item in M indicates the similarity between two sen-tences given x t as a query. Given two sentences s have: At the beginning of the iterative process, an initial score for each sentence is set as 1 / | S | , and at the t -th iteration, the score of s calculated as follows: score ( s i ) ( t ) = (1  X   X  ) X where | S | equals the number of sentences in Wikipedia documents that have been linked to the anchor text a in  X 4.2.1 and the damping factor  X  = 0 . 15 . Then the transition matrix f M equals to: where e is a column vector with all items equal to 1 . The iter-ative process will stop when it convergences. Since f M is a col-umn stochastic matrix, it can be proven that the value of score con-verges [43], and a value of score can be derived from the principle eigenvector of f M . We extract the top E x t sentences from the ranked list, and extend x t to x 0 t by including those E x t sentences in x
Concept drift makes tracking the change of topic distributions crucial for HMC of social text streams. We assume that each doc-ument in a social text stream can be represented as a probabilistic distribution over topics, where each topic is represented as a prob-abilistic distribution over words. The topics are not necessarily as-sumed to be stationary. We employ a dynamic extension of the LDA model to track latent dynamic topics. Comparing to previous work on dynamic topic models [5], our method is based on the con-jugate prior between Dirichlet distribution and Multinomial distri-bution. To keep both stationary statistics and temporary statistics, we present a trade-off strategy between stationary topic tracking and dynamic topic tracking, where topic distributions evolve over time.

Fig. 3 shows our graphical model representation, where shaded and unshaded nodes indicate observed and latent variables, respec-tively. Among the variables related to document set X graph, z ,  X  , r are random variables and w is the observed vari-able; | X t  X  1 | , | X t | and | X t +1 | indicate the number of variables in the model. As usual, directed arrows in a graphical model indicate the dependency between two variables; the variables  X  l t Figure 3: Graphical representation of topical modelling, where t  X  1 , t and t + 1 indicate three time periods.

The topic distributions  X  x t for a document x t  X  X t are derived from a Dirichlet distribution over hyper parameter  X  . Given a word w i  X  x t , a topic z w i for word w i is derived from a multinomial distribution  X  x t over document x t . We derive a probabilistic distri-bution  X  t over topics Z t = Z g t  X  Z l t from a Dirichlet distribution over hyper parameters b t : if topic z  X  Z l , then b t =  X  otherwise b t =  X  g . The generative process for our topic model at time t &gt; 1 , is described in Fig. 3.

Due to the unknown relation between  X  t and  X  t , the posterior dis-tribution for each short text x t is intractable. We apply Gibbs col-lapsed sampling [24] to infer the posterior distributions over both, 1. For each topic z,z  X  Z l t  X  Z g t : 2. For each candidate short text x t  X  X t : global and local topics. For each iteration during our sampling pro-cess, we derive the topic z via the following probability: where m indicates the possible values of variable r for the i th word in document d t , and the value m indicates the corresponding kind of topics when r i = m . We set b w,z,t =  X  l t  X   X  w,z,t  X  1 and b w,z,t =  X  g when r i = 0 . After sampling the probability for each topic z , we infer the posterior distributions for random variable  X  w,z,t , which are shown as follows:
Some class labels, specifically for some leaves of the hierarchy, only have very few positive instances. This skewedness is a com-mon problem in hierarchical multi-label classification. To handle skewedness, we introduce a multi-layer chunk structure to replace the original class tree. We generate this chunk structure by em-ploying a continuous agglomerative clustering approach to merge multiple classes/chunks to a more abstract chunk that contains a predefined number of items. Merging from classes, considered as leave nodes in the final chunk structure, our clustering strategy con-tinues until what we call the root chunk , the most abstract chunk, has been generated. Following this process, we agglomerate the set of classes C into another set of chunks S , each of which, denoted as sc , includes s items. During this continuous agglomerative cluster-ing process from classes C to the root chunk , we define successive relations among chunks in S . Each chunk sc  X  X  successive chunks/-classes in S are chunks/classes that exist as items in sc , i.e., chunk sc is a successive chunk of chunk sc pa iff there exist a vertex in sc pa corresponding to chunk sc .

Thus we can think of S as a tree structure. From the most ab-stract chunk r S  X  S that is not included in any other chunk, each layer l of S is the set of child nodes in those chunks that exist in l  X  X  last layer. The leaves of S indicate classes. Then, a structural SVM classifier F sc for chunk sc includes L sc chunks, and its out-put space Y sc refers to a set of binary labels { 0 , 1 }
At each time period t , we divide the HMC for documents in so-cial text streams into a learning process and a inference process, which we detail below.
For the learning process, we train multiple structural SVM clas-sifiers from S  X  X  root chunk r S to the bottom, where the T -property must be followed by each chunk sc  X  S . After generating the chunk structure S , we suppose S has SC chunks with L levels. At time t , we are given a set of training instances T t = { ( x ( x t , y rameters of multiple structural SVM classifiers during the learn-chunk sc . The structural classifier F sc for chunk sc  X  X  ,sc 6 = r learns and updates its parameters after its parent chunk p ( sc ) has received a positive label on the item corresponding to sc . For each chunk sc  X  X  , we utilize the following structural SVM formulation to learn a weight vector w , shown in Equation 9: subject to: where c y t,sc are positive chunks labeled by y ( i ) t,sc indicates the feature representation for x ( i ) t , y ( i )
Traditional SVMs only consider zero-one loss as a constraint during learning. This is inappropriate for complicated classifica-tion problems such as hierarchical multi-label classification. We define a loss function between two structured labels y and y on their similarity as  X ( y sc , y i,sc ) = 1  X  sim ( y sc sim ( y sc , y i,sc ) indicates the structural similarity between two dif-ferent subsets of sc  X  X  child sets c y and c y ( i ) . We compute the simi-larity between y t,sc and y ( i ) t,sc by comparing the overlap of nodes in these two tree structures, as follows: where we set w n,n 0 to be the weight between two chunks n and n each of which is included in c y ( i ) and c y respectively. Since it is intractable to compare two chunks that are not at the same level in S , here we set w n,n 0 to be: To optimize Eq. 9, we adjust the cutting plane algorithm [16, 45] to maintain the T -property. In general, the cutting plane algorithm iteratively adds constraints until the problem is solved by a desired iteratively looks for the most violated constraint for ( x Algorithm 1: Cutting Plane Optimization for Equation 9 y i =  X  ; repeat until no working set has changed during iteration ; Algorithm 1 shows that to maintain the T -property, we adjust the set of positive chunks in  X  y iteratively. The parameter w dated with respect to the combined working set S i { y i } .
The feature representation for  X ( x ( i ) t , y t,sc ) must enable mean-ingful discrimination between high quality and low quality predic-tions [45]. Our topic model generates a set of topical distributions,  X  , where each item  X  ( w | z,t )  X   X  t is a conditional distribution P ( w | z,t ) over words w given topic z . Assuming that each docu-ment X  X  saliency is summed up by votes from all words in the docu-ment, we then define  X ( x , y ) as follows: where n w, y indicates the number of times word w exist in y for the past t  X  1 periods; N x refers to the number of words in documents x whereas N y is the number of words in y .

Given multiple structural SVMs F t,sc that have been updated at time t  X  1 , the target of our prediction is to select y t,sc x from the root chunk r S  X  S to S  X  X  bottom level. Our selection procedure is shown in Algorithm 2. After prediction and learning at time t , our classifiers are given document set X t +1 Given a document x t +1  X  X t +1 , we traverse the whole chunk structure S from root chunk r S to leaves, and output the predicted classes that x t +1 belongs to. Parameters in discriminants F are updated afterwards.
In  X 5.1, we propose 5 research questions to guide our experi-ments; we describe our dataset in  X 5.2 and set up our experiments Algorithm 2: Greedy Selection via Chunk Structure S y =  X  ; for sc = 1 , 2 ,...,SC do end return y in  X 5.3;  X 5.4 gives details about our evaluation metrics; the base-lines are described in  X 5.5.
We list the research questions, RQ1 to RQ5 , to guide the re-mainder of the paper.
 RQ1 As a preliminary question, how does our chunk-based method RQ2 Is our document expansion strategy helpful for classifying RQ3 Does concept drift occur in our streaming short text collec-RQ4 How does our proposed method perform on HMC-SST? Does RQ5 What is the effect of we change the size of chunks? Can we General statistics. We use a dataset of tweets related to a major public transportation system in a European country. The tweets were posted between January 18, 2010 and June 5, 2012, covering a period of nearly 30 months. The dataset includes 145 , 692 tweets posted by 77,161 Twitter users. Using a state-of-the-art language identification tool [9], we found that over 95% tweets in our dataset is written in Dutch, whereas most other tweets are written in En-glish. The dataset has human annotations for each tweet. A diverse set of social media experts produced the annotations after receiving proper training. In total, 81 annotators participated in the process.
The annotation tree for the dataset has 493 nodes. The annota-tions describe such aspects as reputation dimensions and product attributes and service. All annotators use Dutch during the anno-tating process. Unlike many other Twitter datasets with human an-notations, e.g., Amig X  et al. [2], in our dataset those labels are not independent from each other. Instead, each tweet is labeled by mul-tiple hierarchical classes. From the root class, we divide the dataset into 13 individual subsets following the root node X  X  child classes, which are shown in Table 1. In our experiment, not all subsets are included in our experiments: we ignore the subset with the fewest tweets: Citizenship . As all instances in Online Source are annotated by the same labels, we also omit it.
 Author and temporal statistics. Fig. 5 shows the number of au-thors for different numbers of posted tweets in our dataset. Most Table 1: The 13 subsets that make up our dataset, all anno-tations are in Dutch. The second column shows the English translation, the third column gives the number of tweets per subset, the fourth indicates whether a subset was included in our experiments.
 Tag (in Dutch) Translation Number Included Berichtgeving Communications 208 , 503 Yes Aanbeveling Recommendation 150 , 768 Yes Bron online Online source 2 , 505 No Bron offline Offline source 179 , 073 Yes Reiziger Type of traveler 123 , 281 Yes Performance Performance 28 , 545 Yes Product Product 82 , 284 Yes Innovation Innovation 114 , 647 Yes Workplace Workplace 16 , 910 Yes Governance Governance 11 , 340 Yes Bedrijfsgerelateerd Company related 15 , 715 Yes Citizenship Citizenship 628 No
Leadership Leadership 10 , 410 Yes Figure 5: Number of tweets per user in our dataset, where the y-axis denotes the number of tweets and the x-axis denotes the corresponding number of tweets the author posted in our dataset. One user with more than 9000 tweets is omitted to im-prove readability. users post fewer than 200 tweets. In our dataset, 73 , 245 users posts fewer than 10 tweets within the whole time period, and the maxi-mum number of tweets posted by one user is 9 , 293 : this is a news aggregator that accumulates and retweets information about public transportation systems.

One of the most interesting parts of the corpus is the possibility to analyze and test longitudinal temporal statistics. We can display the trends of tweets with various ways of binning. We can look at general developments over long periods of time and bin documents per day and per week. Fig. 6 shows the total number of tweets posted at each hour over 24 hours. Clearly, people commute in the train: the rush hours between 6am and 8am and between 4pm and 5pm correspond to a larger output of tweets. Fig. 6 also gives us statistics on the number of tweets posted per day; many more tweets are posted within the period from November 2011 to March 2012, and a peak of the number of tweets happening around February 18, 2012, a day with a lot of delays (according to the uttered tweets).
Following [33], we set the hyper parameters  X  = 50 / K g + K and  X  l =  X  g = 0 . 5 in our experiments. We set  X  = 0 . 2 and the number of samples to 5000 in our experiment for both docu-Figure 6: Number of tweets in our dataset. (Left): number of published tweets published per hour. (Right): number of published tweets published per day. ment expansion and topic modeling. The number of topics in our topic modeling process is set to 50 , for both Z u 0 and Z our chunk-based structural SVM classification, we set parameter C = 0 . 0001 . For simplicity, we assume that each chunk in our experiments has at most 4 child nodes.

Statistical significance of observed differences between two com-parisons is tested using a two-tailed paired t-test. In our exper-iments, statistical significance is denoted using N ( (weak) significant differences for  X  = 0 . 01 (  X  = 0 . 05 ). For the stationary HMC evaluation, all experiments are executed using 10-fold cross validation combining training, validation and test sets.
We adapt precision and recall to hierarchical multi-label learn-ing following [4]. Given a class i  X  C , let TP i , FP i the number of true positives, false positives and false negatives, re-spectively. Precision and recall for the whole output tree-structure are: We evaluate the performance using macro F 1 -measure (combin-ing precision and recall) and average accuracy . The macro F measure measures the classification effectiveness for each individ-ual class and averages them, whereas average accuracy measures the proportion correctly identified. For simplicity X  X  sake, we abbre-viate average accuracy as accuracy and acc. in  X 6. We list the methods and baselines that we consider in Table 2. We write C-SSVM for the overall process as described in  X 4, which includes both document expansion and topic tracking. To be able to answer RQ1 , we consider NDC-SSVM, which is C-SSVM without document expansion. Similarly, in the context of RQ2 we consider GTC-SSVM and LTC-SSVM for variations of C-SSVM that only have global topics and local topics, respectively.

There are no previous methods that have been evaluated on the hierarchical multi-label classification of streaming short text. Be-cause of this, we consider two types of baseline: stationary and streaming. For stationary hierarchical multi-label classification, we use CSSA, CLUS-HMC and H-SVM as baselines. We implement CSSA [4] by using kernel dependency estimation to reduce the pos-sibly large number of labels to a manageable number of single-label learning problems. CLUS-HMC [42] is a method based on deci-sion trees. H-SVM [14] extends normal SVMs to a hierarchical structure, where the SVM is trained in each node if, and only if, its parent node has been labeled positive. As CSSA and CLUS-HMC need to predefine the number of classes that each document be-longs to, we employ MetaLabeler [40] to integrate with those two baselines.
For the streaming short text classification task, besides H-SVM, we implement NBC and CSHC, a naive bayesian classifier frame-work, which has proved effective in streaming classification [21], and a structural multi-class learning method. Since NBC and CSHC are designed for single-label classification, we introduce a widely-used  X  X ne vs. all X  strategy on multi-label situation [40]. We evalu-ate their performance after document expansion ( X 4.2)
In  X 6.1, we compare C-SSVM to other baselines for stationary hierarchical multi-label classification; in  X 6.2 we examine the per-formance of document expansion.  X 6.3 details the effect of topic modeling on overcoming concept drift;  X 6.4 provides overall per-formance comparisons;  X 6.5 evaluates the influence of the number of items per chunk.
We start by addressing RQ1 and test if our C-SSVM is effective for the stationary HMC task, even though this is not the main pur-pose for which it was designed. Table 3 compares the macro F of C-SSVM to the three HMC baselines. C-SSVM and CSSA tend to outperform the other baselines: for 6 out of 11 tags C-SSVM provides the best performance, while for the remaining 5 CSSA performs best. The performance differences between C-SSVM and CSSA are not statistically significant. This shows that, when com-pared against state of the art baselines in terms of the macro F metric, C-SSVM is competitive.
Next, we turn to RQ2 and evaluate the effectiveness of document expansion for HMC-SST. As described in  X 4, we extend a short Table 3: RQ1: macro F 1 values for stationary comparisons. Communications 0.5073 0.5066 0.4812 0.4822 Recommendation 0.4543 0.4612 0.4421 0.4452 Offline source 0.4245 0.4176 0.4164 0.4161 Type of traveler 0.4623 0.4677 0.4652 0.4615 Performance 0.5221 0.5109 0.5054 0.5097 Product 0.4762 0.4722 0.4686 0.4609 Innovation 0.4991 0.4921 0.4822 0.4812 Workplace 0.4645 0.4725 0.4687 0.4623 Governance 0.4932 0.5025 0.4987 0.4923 Company related 0.4922 0.4972 0.4901 0.4852 Leadership 0.4672 0.4654 0.4624 0.4602 Subset macro-F 1 Acc. macro-F 1 Acc.
 Communication 0.5073 N 0.5164 N 0.4887 0.4972 Recommendation 0.4543 0.4663 0.4542 0.4655 Offline source 0.4245 N 0.4523 N 0.4112 0.4421 Type of traveler 0.4623 0.4731 0.4647 0.4791 Performance 0.5221 N 0.5321 N 0.5013 0.5111 Product 0.4762 M 0.4823 M 0.4612 0.4721 Innovation 0.4991 N 0.5121 N 0.4522 0.4612 Workplace 0.4645 M 0.4724 M 0.4601 0.4695 Governance 0.4932 N 0.5072 N 0.4787 0.4944 Company related 0.4922 N 0.5072 N 0.4772 0.4921
Leadership 0.4672 M 0.4754 0.4601 0.4707 text into a longer document by extracting sentences from linked Wikipedia articles. Table 4 shows an example of the document expansion where the new sentences are relevant to the original text.
Table 5 contrasts the evaluation results for C-SSVM with that of NDC-SSVM, which excludes documents expansion, in terms of macro-F 1 and average accuracy. We find that C-SSVM out-performs NDC-SSVM for most subsets of stationary HMC com-parisons. In terms of macro F 1 , C-SSVM offers an increase over NDC-SSVM of up to 9 . 4 %, whereas average accuracy increases by up to 9 . 9 % significantly. We conclude that document expansion is effective for the stationary HMC task, especially for short text classification.
Our third research question RQ3 aims at determining whether concept drift occurs and whether topic extraction helps to avoid this. Fig. 7 shows the propagation process of an example local topic for the subset  X  X ommunication. X  The upper part of Fig. 7 shows the 5 most representative terms for the topic during 5 time periods. The bottom half of the figure plots fluctuating topical distributions over time, which indicates concept drift between two adjacent periods. Fig. 8 shows the macro F 1 score over time for C-SSVM, C-SSVM with only local topics (LTC-SSVM), and C-SSVM with only globale topics (GTC-SSVM). This helps us understand whether C-SSVM is able to deal with concept drift during classification. We see that the performance in terms of macro F 1 increases over time, rapidly in the early stages, more slowly in the later periods covered by our data set, while not actually plateauing. We also see that the performance curves of LTC-SSVM and GTC-SSVM behave simi-larly, albeit at a lower performance level. Between LTC-SSVM and GTC-SSVM, LTC-SSVM outperforms GTC-SSVM slightly: local whole timeline. topic distributions are more sensitive, and hence adaptive, when drift occurs. Figure 8: RQ3: macro F 1 performance of C-SSVM, LTC-SSVM and GTC-SSVM over the entire data set.
To help us answer RQ4 , Table 6 lists the macro F 1 and average accuracy for all methods listed in Table 2 for all subsets over all time periods. We see that our proposed methods C-SSVM, NDC-SSVM, GTC-SSVM and LTC-SSVM significantly outperform the baselines on most of subsets.
 As predicted, NBC performs worse. Using local topics (LTC-SSVM) performs second best (after using both local and global topics), which indicates the importance of dynamic local topics tracking in our streaming classification. C-SSVM achieves a 3 . 2 % ( 4 . 5 %) increase over GTC-SSVM in terms of macro F 1 (accuracy), whereas the macro F 1 (accuracy) increases 1 . 9 % ( 2 . 2 %) over LTC-SSVM. Compared to CSHC, C-SSVM offers a statistically signif-icant improvement of up to 7 . 6 % and 8 . 1 % in terms of macro F and accuracy, respectively. Figure 9: RQ5: Performance with different numbers of items of each chunk, in terms of macro F 1 (a) and Accuracy (b).
We now move on to RQ5 , and analyse the influence of the num-ber of items per chunk. Fig. 9 plots the performance curves for C-SSVM, LTC-SSVM and GTC-SSVM with varying numbers of items per chunk. While not statistically significant, for both metrics and all three methods, the performance peaks when the number of items equals 6 , i.e., higher than our default value of 4 .
We considered the task of hierarchical multi-label classification of social text streams. We identified three main challenges: the shortness of text, concept drift, and hierarchical labels as classifi-cation targets. The first of these was tackled using an entity-based document expansion strategy. To alleviate the phenomenon of con-cept drift we presented a dynamic extension to topic models. This extension tracks topics with concept drift over time, based on both local and global topic distributions. We combine this with an in-novative chunk-based structural learning framework to tackle the hierarchical multi-label classification problem. We verified the ef-fectiveness of our proposed method in hierarchical multi-label clas-sification of social text streams, showing significant improvements over various baselines tested with a manually annotated dataset of tweets.

As to future work, parallel processing may enhance the effi-ciency of our method on hierarchical multi-label classification of social text streams. Meanwhile, both the transfer of our approach to a larger social documents dataset and new baselines for document expansion and topic modeling should give new insights. Adaptive learning or semi-supervised learning can be used to optimize the chunk size in our task. Finally, we have evaluated our approaches on fixed time intervals. This might not accurately reflect exact concept drift on social streams. A novel incremental classification method focussing on dynamic time bins opens another direction of future research.

