 1. Introduction
In traditional information retrieval (IR) a retrievable unit is a document. With mark-up languages, XML at the head, the structure of a document can be represented. Accordingly, XML information retrieval allows IR systems to provide focused access to documents, and only the relevant parts (elements) of documents are retrieved. A successful XML retrieval system is capable of delivering focused elements, optimal in length and covering exhaustively the topic.

Text matching methods in IR rely on the textual content of the retrievable unit. Compared with full document IR, one problem in XML IR matching is that, especially in short elements, the textual evidence for matching is scant and the meaning of an element arises partly from its context. Hence, matching, based solely on the textual content of an element, does not seem to deliver the best possible results in XML IR. It is necessary to apply supplementary methods to improve the retrieval of focused elements in particular. For instance, in order to remedy the poor matching, auxiliary evidence from the surround-ings (i.e. context) of the element can be collected. We call this method contextualization following Kek X l X inen and others (2009) .

Contextualization relies on the explicit structure of documents. In a document two main structural dimensions can be subsections and paragraphs. This gives natural contexts of different sizes. For example, a paragraph can be viewed in the context of an article, a section, and a possible subsection. Second, the parts of a document follow a sequential order, often referred to as the document order, where text passages follow each other consecutively. The nearby passages are supposed to  X  form the most definitive context but the further passages in the document should be taken into account in contextualization as well.

In the present study, we develop contextualization models and present a classification for them. The main focus is to ex-plore the effect of different contextualization models on different hierarchical levels. We are interested in improving the challenging retrieval of short and focused elements in particular, and we hypothesize that the retrieval of such elements would benefit from contextualization more than the retrieval of broader elements. We propose a general function for con-textualization and show the robustness of the function by testing contextualization models in two XML test beds.
In mainstream XML IR evaluation ( Lalmas &amp; Tombros, 2007 ) heterogeneous result lists are produced and evaluated. In this type of evaluation the task of a retrieval system includes figuring out the proper granularity level (e.g. the paragraph or section level) in addition to good element ranking. In this study, we are interested in ranking elements of specific gran-ularity levels only, so the heterogeneous result list evaluation setting is too complex for our purposes. Therefore, we have developed a specific evaluation setting, which is based on granulation of an XML collection. In granulation, the level of an
XML hierarchy is specified in advance and the retrieval is focused on the set of elements belonging to that level. More spe-ments (no overlap). The result of granulation is a flat list of elements enabling a laboratory setting and the usage of tradi-tional IR evaluation metrics, e.g. precision/recall.

Shortly, the main contributions of this study include the classification of contextualization models, their applications and a general contextualization function (Section 2 ), testing the effect of contextualization models on three granularity levels (Section 4 ) with a, tailored test setting (Section 3 ).

Section 5 concludes the article. 2. Contextualization Contextualization is a method exploiting features in the context of an element ( Arvola, Junkkari, &amp; Kek X l X inen, 2005;
Kek X l X inen et al., 2009 ). It means mixing the evidence from an element and its context in matching. The context of an ele-ment consists of contextualizing elements, which have a relationship and a distance to the contextualized element. The rela-tionship refers to the place of the contextualizing element in the XML hierarchy with regard to the contextualized element.
The distance refers to a structural remoteness between elements. These features affect the weight each of the contextual-izing elements has in contextualization. Contextualization is a re-scoring method, where the initial score of an element is combined with the weighted scores of the contextualizing elements. 2.1. Classification of contextualization models
The classification we propose is based on the relationships among elements in an XML hierarchy. In Fig. 1 the hierarchical or tree structure of an XML document is depicted. Element e1 is the root whereas the elements e2, e4, e7, e8 and e9 are the leaves. The relationships among the elements are given assuming element e5 as a starting point. Elements e3 and e6 are the parent and child of element e5, respectively. Elements e1 and e3 are the ancestors of element e5 whereas elements e6 and e7 are its descendants. A descendant-ancestor pair involves a vertical distance and it is the number of parent X  X hild steps (the length of the path) between them. For example the vertical distance between elements e5 and e7 is 2. In vertical relation-ships, the ancestors form the contexts of an element, i.e. elements e1 and e3 form the vertical contexts of element e5.
Horizontal relationships are more complex than vertical ones. Siblings form their simplest case. They are elements at the same hierarchy level (measured from the root). For example, elements e4 and e8 are the (following and preceding) siblings of element e5. Siblings of the ancestors of an element are also horizontal relatives (possible contextualizing elements) of an element, as well as the descendants of these siblings. In our example, the horizontal relatives of element e5 are e2, e4, e8 and e9.

Unlike vertical distance, a horizontal distance between two elements is equivocal, because it must be defined via indirect relationships. For example in Fig. 1 the horizontal distance between elements e2 and e9 can be two or five measured by sib-ling steps or via leaves respectively. Instead, the horizontal distance is unequivocal in a set of elements where no two ele-ments are in an ancestor X  X escendant relationship, and there is one element from each path from the root to the leaves. In and the distance of elements e4 and e9 is 3. This kind of element set is called a granularity level of an XML document. Gran-ulation is further discussed in Section 3.2 .

From now on we use the following functional notations for relationships among elements: root ( x ) yields the root of the element x, parent ( x ) yields the parent of x, descendants ( x ) yields all descendants of x, ancestors ( x ) yields all ancestors of x, depth ( x ) yields the vertical distance from the root to x, ancestor X  X escendant relationship and there is an element from each path from the root to the leaves.

As introduced above, the context of elements can be viewed in vertical and horizontal directions. In general, we distin-guish three types of contextualization.

Vertical (hierarchical) contextualization is a well-known and common contextualization model in XML retrieval ( Arvola ments. The nearest context of the element is the parent element. Likewise, the furthermost context is the whole document, i.e. the root element. These documents are considered forming the root levels. Thus, the root element possesses no explicit context.

Horizontal contextualization . Apart from the vertical order, the elements have a document order. In the document order the elements form a chain from the first element to the last one, where each element is preceding or following another.
The document order does not allow preceding and following elements to overlap (e.g. Clark &amp; DeRose, 1999 ), hence any two elements have some horizontal distance between them. These preceding and following elements form the context. Thus, in horizontal contextualization the contextualizing elements are independent of the contextualized element, whereas in ver-izontal contextualization can be used also in the event that there is no explicit hierarchy present, thus it is applicable to passage retrieval. To our knowledge, horizontal contextualization has not been studied earlier.

Ad hoc contextualization contains a number of other contextualization methods, where the contextualizing elements are selected from a known structure or even from another document (e.g. via links). A typical usage of this kind of contextual-ization is query specific. For example queries containing source element constraints can actually be considered as a form of contextualization. This is illustrated by a NEXI ( Trotman &amp; Sigurbjrnsson, 2004 ) expression //article[about(.//abstract, contextualization)]//paragraph[about(., systems)] which explicitly requires a specific context for any paragraph about systems with the abstract of the corresponding arti-tative example of ad hoc contextualixation.
 These three contextualization models and their combinations can be used to improve performance in element retrieval.
The effectiveness of vertical contextualization has been proven for heterogeneous element lists. Sigurbj X rnsson and others (2004) showed a significant improvement in results by taking the root level into account in element scoring. Mass and Man-delbrod (2005) scaled the final score of an element in XML IR. The scaling is based on the document pivot factor, the score of the root element, and the score of the element at hand. The mentioned studies hint that taking the root into account with a double score delivers the best results. Apart from root contextualization, Arvola and others (2005) generalized the context to include other ancestor levels as well. They suggested contextualization functions based on the usage of hierarchical context levels, namely the root, parent and all ancestors (root, parent and tower contextualization respectively).
Ogilvie and Callan (2005) applied contextualization in hierarchical language modeling. There, contextualization is applied for the score of each keyword of the query rather than the score of the element. As they do not include descendants in the direct estimation of the model of the element, they utilize children to smooth up parents (smooth up tree). Since we have not regarded descendants as a context but rather included them in elements X  primary scoring, there is no direct counterpart to the smooth up tree in our categorization. In the contextualization phase, parents serve as contextualizing elements for chil-dren (smooth down tree or shrinkage). The process goes through the XML hierarchy, thus the contextualization corresponds archical language modeling approach the strength of the contextualization is adjusted by parameters, which can be chosen 2005 ). 2.2. General re-scoring function Arvola and others (2005) generalized vertical contextualization, whereas now we give a more general re-scoring function RS , which allows any (contextualizing) scores to be added to the initial score. Formally the function is defined as follows: where s x is the initial score for the contextualized element x . f is a constant for the context weighting, i.e. it determines the weight of the context as a whole.

D is a set of contextualizing elements of x , i.e. D # descendants ( root ( x )) ( descendants ( x ) [ { x }). g is a function that maps x with its contextualizing elements and yields the weights associated with the related contextualization.

The g function determines the importance of a contextualizing element. In vertical and horizontal contextualization, this can be based on vertical and horizontal distances between contextualized and contextualizing elements, whereas in ad hoc contextualization it can be based on explicit conditions. In ad hoc contextualization the importance of elements would be given explicitly by a g function having e.g. marking-up conditions. In this study, we concentrate on vertical and horizontal contextualization. 2.3. Vertical contextualization
The role and relation of a contextualizing element are operationalized by giving the element a contextualizing weight. For this purpose, Arvola and others (2005) defined a contextualization vector for vertical contextualization. For the general con-function.

In vertical contextualization we concentrate on three levels, namely, parent , root and ancestor other than the parent or agreed that when there is a single ancestor, only r is taken into account and when there are two, both r and p are taken into account. When there are multiple levels of ancestors, the ancestors in between the root and parent are treated as a single pseudo element by taking the average of all of these element scores multiplied with a . This way the cumulating effect of numerous context levels is excluded, and the special role of the root and parent elements as contexts is acknowledged. In terms of the par tuple, the g function can be defined as follows: tors (e7) = {e1, e3, e5, e6}, and g is
Further, let s e 7 = 0.4, s e6 = 0.4, s e5 = 0.4, s e3 = 0.3, and s follows:
In Section 5 , the values of par and f are optimized and tested for different sizes of elements, i.e. granularity levels. 2.4. Horizontal contextualization
The nature of horizontal contextualization differs from the vertical one. First, vertical contextualization is single-direc-tional but horizontal contextualization is bi-directional based on the preceding and following elements of the contextualized element. Second, there are typically more contextualizing elements in horizontal contextualization. Third, in vertical contex-tualization the contextualizing elements overlap, but in horizontal contextualization a meaningful requirement is that they do not overlap with each other or with the contextualized element.
 As in vertical approach, in horizontal contextualization the weight of a contextualizing element is a function of distance.
We assume that the weight ought to be the lower the further away the contextualizing element is from the contextualized element. Thus the neighbors are expected to form the most important context. In this study, we set the weight array to fol-low a zero centered parabola and we define the weight of a contextualizing element as follows: where a and c are the parabola parameters to be tuned. The function h_distance ( x , y , S ) is defined in Section 2.1 . Fig. 2 illustrates the effect of distance on weight while tuning the parameters ( a and c ).

In order to illustrate the horizontal contextualization let us consider element e2 within the element set {e2, e4, e5, e8, e9} related to Fig. 1 . Now D = {e4, e5, e8, e9} and the distances between contextualised and contextualising element are:
The scores of elements are assumed to be s e2 = 0.2, s e4
The g function is defined by the parabola where a = 0.04 and c = 1 as follows: The total score RS for element e is defined as follows:
As a comparative example, the parabola with the parameter values a = 0.01 and c = 0.5 give the following scores for the function g : context and contextualization magnitude (1) is approximately 0.479. 3. Test collection, relevance assessments and granulation archy levels. 3.1. INEX test collection 2005 ). This includes a document collection, topics, relevance assessments and metrics. The initiative has been running since 2002 and several changes have been made during the years, including the collection, as well as the metrics and the relevance assessment process.

In XML documents, elements overlap with each other. In XML IR, this is a challenge in the result presentation, because when retrieving, say, two overlapping elements, part of the content is retrieved twice. A straightforward solution to prevent this kind of redundancy is to exclude the ancestors and descendants of a retrieved element from the results. This kind of result list is still heterogeneous, while it may contain elements of any granularity ranging from a small text element to the root.
 an element containing any amount of relevant text is relevant, an element is necessarily at least as relevant as any of its descendants. Such interpretation of relevance leads paradoxically to poor performance for systems returning short and focused elements, which, for their part, motivate XML IR. Therefore, in the early INEX evaluation methodology two measures, exhaustivity and specificity, were introduced.  X  X  X xhaustivity is defined as a measure of how exhaustively a document com-ponent discusses the topic of request, while specificity is defined as a measure of how focused the component is on the topic of request (i.e. discusses no other, irrelevant topics) X  X  ( Kazai, Lalmas, &amp; de Vries, 2004, p. 73 ).
In the early INEX ad hoc tracks (2002 X 2004) assessments were done element wise, so that each element in the assess-ment pool was judged for exhaustivity and specificity. Both of the dimensions have a four point scale with 0 meaning not process gives an explicit relevance value for each element, but is considered laborious from the assessors X  perspective pass, assessors highlight text fragments that contain only relevant information. In the second pass, assessors judge the exhaustivity level of any elements that have highlighted parts. As a result of this process, any elements that have been fully will now only have to judge the exhaustivity level of the elements that have highlighted parts (in the second phase). The specificity of any other (partially highlighted) elements will be calculated automatically as some function of the contained relevant and irrelevant content (e.g. in the simplest case as the ratio of relevant content to all content, measured in number of words or characters). X  X  ( Lalmas &amp; Piwowarski, 2005, p. 391 ).

The aim of XML IR is to retrieve not only document components about the subject of the topic but also those at the opti-2008 ). In other words, it is discovered that it is reasonable to return e.g. full documents only.

Another alternative is to use flat, non-overlapping result lists, where the set of retrievable elements is pre-defined, and the elements belonging to the set are considered to be (more or less) at the same hierarchy level. This approach suits the goals of the present study better, because we are not interested in selecting the optimal level. Instead, we want to mea-sure performance at pre-set hierarchy levels. Therefore, for measuring the effect of contextualization at different hierar-chy levels we aim to distinguish three levels of different nature in the collection(s): smallish elements, moderate elements and large elements. For each of these levels, we tailor a separate set of relevance assessments (recall base), based on the relevance assessments in the collection of the INEX. Further, this enables applying TREC style binary relevance  X  an element is relevant if it contains relevant text; otherwise the element is not relevant  X  and standard evaluation measures. In case of small elements, binary relevance is applicable because the variation in specificity is limited; in case of larger elements, binary relevance does not distinguish the obviously greater variation. To overcome this problem we also apply graded relevance based on the combination of exhaustivity and specificity figures in INEX collection. 3.2. Granulating the IEEE collection
In order to measure the effectiveness of contextualization on a specific granularity level, the set of elements belonging to the level ought to be carefully defined. In our experiments, we use the INEX 2004 and 2005 collections and related topics with relevance assessments. The INEX 2004 collection consists of 12 107 XML marked full-text documents, whereas the INEX 2005 document collection includes these plus additional 4712 documents, totalling in 764 megabytes of data. These are scientific documents of the IEEE Computer Society X  X  publications from 12 magazines and 6 transactions. In the INEX (IEEE) cle-section-subsection-paragraph levels, similar to many other XML standards for structured text.

The requirements for each of the three granularity levels are that the retrievable units are structurally non-overlapping and cover all of the text content in the collection. The former requirement enables the usage of conventional evaluation met-rics. This is because (1) The elements are assumed to be independent of each other. (2) There is no granularity level selection in the retrieval (it is forced).

Since the set of retrievable elements is known in advance, these elements can be treated in evaluation as if they were documents. The full coverage of the collection X  X  content naturally means that every bit of (relevant) text can be retrieved.
The definition of a granularity level is highly contractual because of the semi-structured nature of XML and complexity in element naming, In order to find appropriate granularity levels, we have to analyze the schema and the common structure of the collection. However, there is a possibility to achieve an unambiguous granularity level of an XML document starting from the leaves. Namely, selecting those elements that are parents of text elements and whose ancestors do not contain a text ele-2005 ).

The mark-up in the IEEE collection is high-quality, and thus the content element granulation corresponds well to the par-agraph level, covering other small logical text units such as headings and list items. For the section and subsection granu-larity levels we use more contractual selections. These can be specified by explicitly defining the set of retrievable units using XPath expressions. The objective of the granulation process is illustrated in Fig. 3 .
 Next we define the pre-set granularity levels for the collection.

Paragraph/content element granulation: set of lowermost non-overlapping elements having 100% text coverage of the collection.

Minor section (i.e. subsection) granulation : set of lowermost (non-overlapping) sections having 100% text coverage of the collection.
 Major section granulation : set of uppermost (non-overlapping) sections having 100% text coverage of the collection.
In practise minor and major section granulations require explicit definitions following the schema of the underlying col-XPath definition for the minor and major sections for the IEEE collection is given in Appendix A .

It is practically unavoidable to distinguish the granularity levels so that they cover the whole collection X  X  text, contain no overlap, and still do not share the same elements. For instance, if a section does not contain any sub-or super-sections, its text has still to be taken into account in subsection granulation. Therefore we label the section granulations as minor and major sections, which both contain sections without sub-or super-sections, if such exist. However, generally the profiles of granulation vary by average element length. For the major section, the average text length of an element is 4243 charac-ters, for the minor section 2420 and for the content element 121 characters (in the 2005 collection).

The experiments in the next section are based on INEX data with 29 Content-only (CO) topics from 2005 and 34 CO topics from 2004. The collection sizes and recall base characteristics are shown in Table 1 . Corresponding recall bases are built in the following fashion: First, the relevance assessments are made binary, so that any element containing relevant text is con-sidered relevant. Second, as the INEX CO recall base contains elements of practically any kind, only the elements that belong elements only. Thus, there are three different recall bases, one for each granularity level.

Besides binary relevance, we applied graded relevance in evaluation. The contemporary INEX exhaustivity interpretation is liberal considering every element containing relevant text exhaustive. However, in INEX 2005 the exhaustivity dimension lowing the  X  X  X oo small X  X  elements are given a score 1, exhaustive elements a score 2 and highly exhaustive elements a score 3. graded relevance figure by multiplying exhaustivity by specificity. 4. Experiments
In this section we parameterize the general re-scoring function (RS) for the vertical and horizontal contextualization mod-els. For vertical contextualization we test the optimized f and par parameters (see Section 2.2 ) on the three selected granu-weights (Section 2.3 ). In horizontal contextualization, we make a deliberate choice testing the content element level only, because the meaningfulness of horizontal distance depends on the number of elements in a granularity level. The optimal values for the parameters (i.e. training) are obtained with the 2005 and 2004 data and tested with the other data. That is, the best trained parameters with 2004 topics and collection are tested with the 2005 topics and collection and vice versa.
We use binary relevance criterion and report the results with mean average precision (MAP). In addition, we evaluate with graded relevance based on exhaustivity and specificity.
 4.1. Retrieval system
The core retrieval system, TRIX (Tampere Retrieval and Indexing for XML; Arvola, Junkkari, &amp; Kek X l X inen, 2006; Arvola the retrieval system is secondary, because the findings can be falsified or verified with any equivalent partial match XML IR system. However, the good performance of the system entitles its usage to set the baseline high enough. For instance, TRIX was the best performing system within the INEX content-and-structure task with strict interpretation for the target element (SSCAS, VSCAS) in 2005 ( Arvola et al., 2006 ) and with CO-task 2004 when measured with normalized extended cumulated gain ( Kazai, Lalmas, &amp; de Vries, 2005 ).

A basic concept in the system is the content element, which is the uppermost element containing text (see Section 3 ). As ings etc., like in the IEEE collection. Otherwise the definition of the content element should be somewhat modified. In the weighting of keys, which is basically a tf idf modification, document length normalization is replaced by element  X  X ength X  normalization based on the number of descendant content elements and all descendant elements. In many document retrie-val applications, the idf part is calculated on the basis of the number of documents including the key in the collection, and the size of the whole collection. However, some XML collections are not organized according to documents, thus the number of elements is used instead. The weight for element e in relation to key t is calculated as follows: in which: tw ( t, e ) is the weight for key t in element e, tf e is the number of times search key t occurs in e element,
N is the total number of content elements in the collection, n is the number of content elements containing t in the collection, c_elems ( e, t ) yields the number of content elements in the descendants (or self) of e containing t , c_elems ( e ,  X  ) yields the total number of content elements in the descendants (or self) of e .

The constants (2, 0.9, 0.1) have been discovered good in various settings (Arvola et al., 2005, 2006; Kek X l X inen et al., 2005). Eventually, the score of an element is the sum of term weights: 4.2. Vertical contextualization
Thetrainingofthesystemwasdonebyreasonableextensivetestingforallthedata(2004&amp;2005)withanumberofdifferent contextualization parameters. For testing the parameters were applied to the data of the other year. As defined in this study, contextualization has two general dimensions: the overall magnitude of contextualization and the proportions the individual elements. We have simplified the adjustment of the parameters by using one figure for each of the two dimensions; that is, one for the overall magnitude (the f  X  X arameter as such) and the other for the roles of the hierarchy levels (the par parameter).
The magnitude is adopted by using the f parameter directly. However, using one parameter for the roles of the hierarchy
The value of x determines whether the important context is towards the root ( x = 1) or close to the contextualized element side or on the root side or then balanced between these two. Tables 6 X 10 in Appendix B are interpreted so that if the hier-The maximum and minimum values mean that only root or parent is represented in contextualization respectively.
According to the collection schemas, the major level has typically only two context levels ( bdy and article ), whereas the content element level consists of elements of varying depth. The minor section level is in between, but closer to the major section level. Therefore, we adopt the sliders gradually, so that for the major section we apply root and use only the contex-tualization magnitude (i.e. f ). For the minor and content element levels, we adopt the hierarchy dimension so that for the 7 X 10 in Appendix B are interpreted as p , a, and r values as follows: parent has double contextualization weight in comparison to the root.

Table 2 presents the effect of vertical contextualization. The roles of the collections 2004 and 2005 are swapped mutually However, when tested with the 2005 data, the improvement was notable, but not significant, except with the major level.
A low number of topics (29) may have an influence on the result of the statistical test. As Tables 9 and 10 show, many dif-ferent parameter combinations yield quite similar results, having the bias heavily on the root side.

We tested also the robustness of training by comparing the results of the best trained and best tested runs in the same the method appears robust. 4.3. Horizontal contextualization
Horizontal contextualization was tested on the content element level only. The horizontal contextualization model pre-tuning the a and c parameters using contextualization magnitude 1. Table 3 shows the best tested and trained values and we report extensive results with varying a and c values in Tables 11 and 12 in Appendix C .

In training, the greatest benefit was obtained with a = 0.00001, c = 0.025 using the 2004 data and with a = 0.00005, c = 0.035 using the 2005 data. The testing was done for both collections with the values obtained with the training data. Nat-urally, the baseline is the same as with the vertical contextualization. The performance of the presented horizontal contex-contextualization method versus the baseline). The improvement is notable also with the 2005 data, but the improvement is not statistically significant.

Horizontal contextualization does not quite reach the level of vertical contextualization. We compared the best vertical contextualization method to the best horizontal contextualization method. The difference between the two methods is sta-training by comparing the results of the best trained and best tested runs in the same collection . There are no statistically significant differences between the results ( t -test p &lt; 0.05), thus the method appears robust.
 4.4. Graded relevance and topic-by-topic analysis
In Table 4 the normalized discounted cumulative gain (nDCG, J X rvelin &amp; Kek X l X inen, 2002 ) figures are given for the base-line, and vertical and horizontal contextualizations. The nDCG results are in line compared with the MAP results: both show that vertical contextualization enhances performance with the 2004 data, even significantly. With the 2005 data the improvement is notable and statistically significant at nDCG@1500 for all granulation levels. Minor and major sections ben-improvement in 2005 data is insignificant.

The average figures do not reveal the benefit of contextualization for individual topics; therefore a topic-by-topic analysis was performed. The topics are classified according to the percentage unit difference in performance compared between the best tested contextualization and baseline (best  X  baseline).

For vertical contextualization, the percentage of topics with difference greater than or equal to 5% (e.g. notable improve-ment) ranges from about 20% to 65%. In any case, over half of the topics (59 X 94%) benefit from vertical contextualization (see Table 5 , columns 2 + 3 and 5 + 6). Minor section level measured with nDCG seems to benefit most of this contextualization. tent level was tested. 5. Discussion and conclusions
Contextualization is a re-ranking method utilizing the context of an element in scoring. In this study, contextualization is calculated as a linear combination of the weights of an element itself and its contextualizing elements. We developed the contextualization methodology by introducing a classification of three contextualization models: vertical, horizontal and ad hoc contextualization, among which horizontal contextualization is a novel contextualization model. In horizontal con-textualization, the context is based on the document order instead of the hierarchy. Thus, horizontal contextualization is more versatile in a sense that it does not require a hierarchy, and can be used slightly modified in non-structured passage retrieval.
 We introduced a general contextualization function as an umbrella function for all presented contextualization models.
Within the vertical and horizontal models, we introduced implementing methods, through which we tested the effect of con-textualization on retrieval performance. For vertical contextualization, we separated three granularity levels for which we tested contextualization, namely content element, minor and major sections. Horizontal contextualization was tested with the content element level only, because the number of elements on that level allowed investigating the effect of horizontal distance. We experimented with INEX 2004 and 2005 test collections, swapping their roles as training and test collections.
The experiments show that utilizing the context enhances the retrieval of elements on any of the granularity levels. The improvements measured with MAP and nDCG are notable and the results of most topics are improved by contextualization.
The results between the 2004 and 2005 collections show some inconsistency, because the small elements benefit in the 2004 collection but in the 2005 collection the larger elements benefit. The XML document collections were not fundamentally dif-ber of relevant elements per topic (per relevant document) and the effectiveness of contextualization can be found. The 2005 ous difference between the collections is in the relevance assessment process. However, since the recall bases do not differ notably with regard to the number of relevant elements per topic, it is difficult to explain how the assessment process would the same collection (trained results).

The baseline results demonstrate that, in general, getting good performance is more challenging for short elements than for larger elements, at least with the average measures (MAP, nDCG@1500). We see two reasons for that. First, the textual evidence is scanter for the shorter elements. Second, it requires more of a system to accurately point out the small relevant ing at the ratios between the number of relevant elements and the total number of elements in Table 1 . In other words, there are more non-relevant elements per a relevant element at lower granularity levels. A summary of the findings in this study is that the lack of textual evidence can be complemented with contextualization. Vertical contextualization is more effective topical coherence between elements affects the impact. For instance, topically heterogeneous elements e.g. in a general encyclopedia do not benefit from contextualization.
 Acknowledgements
This study was funded by the Academy of Finland under Grants #140315, #115480 and #130482. The authors wish to thank the anonymous reviewers for their helpful comments.
 Appendix A
The full XPath queries for minor and major section retrieval are presented here in this order. All the aliases for sections (sec,ss1,ss2) and back-and frontmatters (bm,fm) are defined as sections. Moreover, in order to get full coverage of the col-lection we added some rare elements (direct children of the bdy element):
A.1. Minor section bdy/dialog | //bdy/reviewer | //bdy/reviewers | //bdy/list.

A.2. Major section //  X  [self::fm or self::bm or self::sec or self::ss1 or self::ss2][not(ancestor::fm or ancestor::bm or ancestor::sec or ances-Appendix B See Tables 6 X 10 .
 Appendix C See Tables 11 and 12 .
 References
