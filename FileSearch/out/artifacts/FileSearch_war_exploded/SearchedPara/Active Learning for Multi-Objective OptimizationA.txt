 This section provides the proofs of Theorem 1, which follows from Lemmas 3 to 12.
 the fol lowing holds with probability  X  1  X   X  : In other words, with probability  X  1  X   X  : Proof. According to Lemma 5.1 in (Srinivas et al., 2012), the following inequality holds: Applying the union bound for i,t  X  N , we obtain that the following holds with probability  X  1  X  n | E | e  X   X  t The lemma holds by choosing n | E | e  X   X  t / 2 =  X / X  t . As suggested in (Srinivas et al., 2010), we can use  X  t =  X  t 2 / 6.
 Lemma 4. If n = 1 and f T = ( f ( x t )) 1  X  t  X  T , then This is directly taken from Lemma 5.3 in (Srinivas et al., 2010). I ( y T ; f T ) defines the mutual information between f and observations y T = f T + T , where T  X  N ( 0 , X  2 I ).
 the fol lowing holds with probability at least 1  X   X  :
X where C 1 = 8 / log(1 +  X   X  2 ) .
 Proof. One of the rectangles of which R t ( x t ) is the in-tersection has a diagonal length of 2  X  1 / 2 t k  X  t  X  1 as a consequence, As  X  t is increasing, we have that with C 2 =  X   X  2 / log(1 +  X   X  2 )  X  1, since s 2  X  C  X  Using C 1 = 8  X  2 C 2 and Lemma 4 we have that the fol lowing holds with probability  X  1  X   X  : Proof. This follows from Lemma 5, since ( P T t w t ) 2  X  T P T t =1 w 2 t by the Cauchy-Schwarz inequality. Lemma 7. Running PAL with a monotonic classifi-cation, it holds that w t decreases with t .
 Proof. As a direct consequence of the sample picking rule, w t  X  1 ( x t )  X  w t  X  1 . On the other hand, w t w Lemma 8. Running PAL with  X   X  (0 , 1) and  X  t = 2 log( n | E |  X  t / X  ) , the following holds:
Pr where C 1 = 8 / log(1  X   X   X  2 ) and  X  t =  X  2 t 2 / 6 . Proof. This is derived from Lemmas 6 and 7, since P Corollary 9. When running PAL with squared expo-nential kernels k i for all 1  X  i  X  n , the fol lowing holds with probability  X  1  X   X  : w T = O Lemma 10. If when running PAL at iteration t 0 , a point x is classified as not Pareto-optimal, i.e. x  X  N the classification of points in U t 0 . This means that no attempt its classification at time t &gt; t 0 . Proof. To attempt the classification of a point x 0  X  U t PAL searches for other points in E that may dom-inate x 0 under different outcomes, considering their corresponding uncertainty regions R t . If a point x is classified as not Pareto-optimal, there exist at least a point x 00  X  ( P t  X  U t ) such that x 00 x . Then x can be ignored since if x x 0 then x 00 x 0 .
 Lemma 11. If when running PAL , at iteration t w t  X  2 , then U t +1 =  X  .
 Proof. We show that if a point is not classified as Pareto-optimal, then it is classified as not Pareto-optimal, when w t  X  2 .
 If a point x is not classified as Pareto-optimal, then there is a point x 0 such that with = ( ,..., ). We define a point v ( x )  X  R n = 16 is equivalent to If there is a point x 0 that meets the relation in (16) and w t  X  2 , then x 0 meets the following condition that classifies x as not Pareto-optimal P t  X  U t , and w t  X   X  . w t is an upper bound of in P t and U t . As shown in Lemma 10, points in N t do not have to be considered in the classification. a The following holds with probability 1  X   X  .
 The hypervolume error obtained by PAL at iteration T when all points have been classified is bounded as: In particular, Proof. Let 1 n = (1 ,..., 1) T and let e i denote the i th canonical base vector, all assumed  X  R n . The length of every (one-dimensional) side of a hyperrectangle as-sociated with a point in  X  P is bounded by the length of its diagonal w T . Hence the distance between the boundaries defined by  X  P o and  X  P p along the direction 1 n is bounded by with side length w t ). a i is the maximum value that f i ( x ) can have, with bound obtained from the width of the confidence re-gions, given the Gaussian process prior distribution. Let a i = a i e i . The projection a i , 1  X  i  X  n , onto the hyperplane H n =  X  1 n  X   X  is an n -simplex S n . V(  X 
P o )  X  V(  X  P p ), and hence  X  T , are bounded by the vol-ume of S n times We compute an upper bound on the volume of S n . The has length a i p 1  X  1 /n . The  X  a i enclose pairwise the same angle; hence the volume of S n is bounded by the volume of a regular n -simplex with radius a p 1  X  1 /n , a = max 1  X  i  X  n { a i } . Using known formulas, this vol-ume is the desired result.
 The second assertion is immediate from (15).
 Note that we can get a bound independent of n by summing over all n in (17) to get Figure 6 shows an example for n = 2, where the sim-plex is a line. The area between the boundaries of  X  P o and  X  P p is hence bounded by length of the simplex S , which is formed by the two sides of length: a 1 p 1  X  1 / 2 and a 2 p 1  X  1 / 2. There-fore,  X  T  X  2 a w T for n = 2.
 Fig. 7 shows the error obtained in f 2 when PAL stops, for different values of . The results for f 1 are shown in Fig. 5. The x -axis shows the total number of eval-uations of f required to obtain the percentage error on the Pareto prediction displayed on the y -axis of the plots.
 We also compare PAL with a variation of PAL that se-lects the points to evaluate at random from the points that have not been evaluated. At every iteration t after initialization, we generate a prediction  X  P t by adding the Pareto-optimal points of the unclassified points (using predictions  X  t ) to the set P t that contains the points that have been classified as Pareto-optimal at iteration t . We then calculate the error and the cost of this prediction as it has been done in Section 6. Fig-ure 8 shows the results for our three data sets when using an = 0 . 001% of each range of f i . PAL shows for all data sets better results than PAL with Ran-dom sampling, with significantly better results found with the SNW data set. This clearly shows the effec-tiveness of our sampling strategy in evaluating points that are relevant to achieve the goal of predicting the
 Marcela Zuluaga zuluaga@inf.ethz.ch ETH Zurich, Clausiusstrasse 59, 8092 Zurich, Switzerland Andreas Krause krausea@ethz.ch ETH Zurich, Universit  X atstrasse 6, 8092 Zurich, Switzerland Guillaume Sergent guillaume.sergent@ens-lyon.fr ENS de Lyon, 46 All  X ee d X  X talie, 69007 Lyon, France Markus P  X  uschel pueschel@inf.ethz.ch ETH Zurich, Clausiusstrasse 59, 8092 Zurich, Switzerland A fundamental challenge in many problems in engi-neering and other domains is to find the right balance amongst several objectives. As a concrete example, in hardware design, one often has to choose between dif-ferent candidate designs that trade multiple objectives such as energy consumption, throughput, or chip area. Usually there is not a single design that excels in all objectives, and therefore one is interested in identify-ing all (Pareto-)optimal designs. Furthermore, often in these domains, evaluating the objective functions is expensive and noisy. In hardware design, for example, synthesis of only one design can take hours or even days. The fundamental problem addressed in this pa-per is how to predict the Pareto-optimal set at low cost, i.e., by evaluating as few designs as possible. In this paper we propose a solution that we call the Pareto Active Learning ( PAL ) algorithm. PAL has several key features. It captures domain knowledge about the regularity in the design space by using Gaus-sian process (GP) models to predict objective values for designs that have not been evaluated yet. Fur-ther, it uses the predictive uncertainty associated with these nonparametric models in order to guide the iter-ative sampling. Specifically, PAL  X  X  sampling strategy aims to maximize progress on designs that are likely to be Pareto-optimal. A set of classification rules iden-tifies designs that are Pareto-optimal and not Pareto-optimal with high probabilty; PAL terminates when all designs are classified. Finally, PAL is parameter-ized to enable an intuitive, user-controlled tradeoff be-tween sampling cost and prediction accuracy.
 A main contribution of this paper is the theoretical performance analysis of PAL that provides bounds on the sampling cost required to achieve a desired accu-racy. These bounds involve the use and quantification of the so-called hypervolume error, a metric that is commonly used in multiobjective optimization.
 Finally, we carry out an extensive empirical evaluation, where we demonstrate PAL  X  X  effectiveness on sev-eral real-world multiobjective optimization problems. Two of these problems (Zuluaga et al., 2012b; Almer et al., 2011) are from different applications in the do-main of hardware design, in which it is very expen-sive to run low level synthesis to obtain the exact cost and performance of a single design. The third prob-lem is from software optimization (Siegmund et al., 2012) where different compilation settings are evalu-ated for performance and memory footprint size. We compare the performance of PAL against a state-of-the-art multi-objective optimization method called ParEGO (Knowles, 2006). Across all data sets and al-most all desired accuracies PAL outperforms ParEGO, requiring usually about 33% less evaluations. 1.1. Related Work We now discuss different lines of related work. Evolutionary algorithms. One class of approaches uses evolutionary algorithms to approximate the Pareto frontier using a population of evaluated de-signs that is iteratively evolved (K  X unzli et al., 2005; Coello et al., 2006; Zitzler et al., 2002). Most of these approaches do not use models for the objectives, and consequently cannot make predictions about un-evaluated designs. As a consequence, a large num-ber of evaluations is typically needed for convergence with reasonable accuracy. To overcome this challenge, model-based (or  X  X esponse surface X ) approaches ap-proximate the objectives by models, which are fast to evaluate. The best among these appears to be ParEGO (Knowles, 2006), which also uses GP models of the objective functions. We will compare against this approach.
 Scalarization to the single-obective setting. An alternative approach to multi-objective optimization problems is the reduction to a single-objective prob-lem (for which a wealth of methods are available). This is commonly done via scalarization, for example by considering convex combinations of the objective functions (Boyd &amp; Vandenberghe, 2004). As a con-crete example, Zhang et al. (2010) proposes a multi-objective evolutionary algorithm framework that de-composes the optimization problem into several single-objective subproblems. A predictive model based on Gaussian processes is built for every subproblem, and sample candidates are selected based on their expected improvement. A major disadvantage of the scalar-ization approach is that without further assumptions (e.g., convexity) on the objectives, not all Pareto-optimal solutions can be recovered (Boyd &amp; Vanden-berghe, 2004). Therefore, we avoid scalarization in our approach.
 Heuristics-based methods. Instead of weighted combinations, numerous domain-specific heuristics have been proposed that aim at identifying Pareto-optimal solutions. These approaches typically combine search algorithms to suit the nature of the problem (D. et al., 2008; Palermo et al., 2009; Zuluaga et al., 2012a) and defy theoretical analysis to provide bounds on the sampling cost. With this work we aim at creating a method that generalizes across a large range of appli-cations and target scenarios and that is analyzable, i.e., comes with theoretical guarantees.
 Single-objective active learning and Bayesian optimization. In the single-objective setting, there has been much work on active learning, in particular classification (see, e.g., Settles (2010) for an overview). For optimization, model-based approaches are used to address settings where the objective is noisy and ex-pensive to evaluate. In particular in Bayesian opti-mization (see Brochu et al. (2010)), the objective is modeled as a sample from a stochastic process (often a Gaussian process). The advantage of this approach is the flexibility in encoding prior assumptions (e.g., via choice of the kernel and likelihood functions), as well as the ability to guide sampling: several different (usually greedy) heuristic criteria have been proposed to pick the next sample based on the predictive uncer-tainty of the Bayesian model. A common example is the EGO approach of Jones et al. (1998), which uses the expected improvement. Recently, Srinivas et al. (2010) analyzed the GP-UCB criterion, and proved global convergence guarantees and rates for Bayesian optimization. We build on their results to establish guarantees about our PAL algorithm in the multi-objective setting. 1.2. Main Contributions In summary, our main contributions include:  X  the PAL algorithm, which efficiently (i.e., with few  X  the analysis of PAL that provides theoretical  X  an experimental evaluation to demonstrate PAL  X  X  We consider a multi-objective optimization problem over a finite 1 subset E (called the design space ) of R d for some d  X  N . This means we wish to simultaneously optimize n objective functions f 1 ,...,f n : E 7 X  R . We use the notation f ( x ) = ( f 1 ( x ) ,...,f n ( x )) to refer to the vector of all objectives evaluated on the input x . The objective space is the image f ( E )  X  R n . 2 Pareto-optimality. The goal in multi-objective op-timization is to identify the Pareto frontier of f . For-mally, we consider the canonical partial order in R n : y y 0 iff y i  X  y 0 i , 1  X  i  X  n , and define the induced order on E : x x 0 iff f ( x ) f ( x 0 ). The set P  X  E of maximal (or Pareto-optimal) points in this order de-termines the Pareto frontier f ( P ). Figure 1 visualizes these concepts for n = 2 objectives.
 The interest of finding Pareto-optimal points in the design space is clear: they represent the best compro-mises amongst the chosen objectives and are the only designs that need to be considered in an application. Problem statement. In many applications, evaluat-ing the objectives f 1 ,...,f n is expensive. Therefore, we wish to identify the Pareto-optimal set P  X  E with-out evaluating all inputs x  X  E . Our goal is to develop an active learning algorithm that iteratively and adap-tively selects a sequence of designs x 1 , x 2 ,... to be evaluated and that uses this evaluation to classify all designs as Pareto optimal or not. The algorithm ter-minates when all designs are classified and returns a prediction  X  P of the Pareto-optimal set P .
 Prediction quality. A fundamental difference be-tween single-and multi-objective optimization is that for the latter it is not obvious which metric to use to evaluate the prediction quality. A very natural pro-posed solution uses the so-called hypervolume (Zitzler et al., 2007), to compute the volumes enclosed by the actual Pareto frontier f ( P ) and its prediction f (  X  P ). Formally, we first assume that all the f i are non-negative (a property that can be established by suit-able shifting if the minimum is known). The hyper-volume V ( P ) of a Pareto-optimal set P  X  E is the volume of the area S p  X  P { y  X  R n : 0 y f ( p ) } en-closed between the origin and f ( P ). In Fig. 1 this area is shaded gray. The hypervolume of an arbitrary set S  X  E is defined similarly after all dominated points in S have been removed. The quality of a prediction  X  P is then given by the hypervolume error which is always positive. The trivial prediction  X  P = E has error 0; thus, an important feature of a reasonable algorithm is that  X  P contains few dominated points. It is clear that prediction is only possible under certain assumptions about f , which are introduced next. Gaussian processes. We model f as a sample from an n -variate Gaussian process (GP) distribution. A GP distribution over a univariate real function f ( x ) is fully specified by its mean function  X  ( x ) and its covariance function k ( x , x 0 ) (Rasmussen &amp; Williams, 2006). The kernel or covariance function k captures regularity in the form of the correlation of the marginal distributions f ( x ) and f ( x 0 ).
 In our multi-objective setting, we model each objective function f i ( x ) as a sample from an independent 3 GP distribution.
 On every iteration t in our algorithm we choose a design x t to evaluate, which yields a noisy sample y t,i = f i ( x t ) +  X  t,i ; after T iterations we have a vec-tor y T,i = ( y 1 ,i ,...,y T,i ). Assuming  X  t,i  X  N (0 , X  2 ) (i.i.d. Gaussian noise), the posterior distribution of f i is a Gaussian process with mean  X  T,i ( x ), covariance k
T,i ( x , x 0 ), and variance  X  2 T,i ( x ): k T,i ( x , x 0 ) = k i ( x , x 0 ) where x , x 0  X  E , k T,i ( x ) = ( k i ( x , x t )) 1  X  t  X  T K distribution captures our uncertainty about f ( x ) for points x  X  E that have not been evaluated yet. We now design an active learning algorithm informed by this uncertainty. In this section we describe our algorithm: Pareto Active Learning ( PAL ). Our approach to predicting Pareto-optimal points in E is to train GP models (see above) with a small subset of E . The models predict the objective functions f i , 1  X  i  X  n , allowing us to identify points in E that are Pareto-optimal with high probability. A point x , that has not been sampled, is predicted as  X  f ( x ) =  X  ( x ) = (  X  i ( x )) 1 6 i 6 n ally  X  ( x ) = (  X  i ( x )) 1 6 i 6 n is interpreted as the uncer-tainty of this prediction. We capture this uncertainty through the hyperrectangle 4 Q  X  ,  X  , X  ( x )= { y :  X  ( x )  X   X  1 / 2  X  ( x ) y  X  ( x )+  X  where  X  is a scaling parameter to be chosen later. We use this uncertainty information to guide our sam-pling and to make a probabilistic assumption on the optimality of every point x . Since we are only inter-ested in Pareto-optimal points, our algorithm aims at sampling the design space E such that the predictions generated for f ( x ) are more accurate for points x that are likely to be Pareto-optimal.
 At every iteration t , the algorithm uses the predictions  X  ( x ) and the uncertainties  X  t ( x ) to classify a point x as Pareto-optimal, or not Pareto-optimal. However, some points may remain unclassified. Then, the next sample to evaluate in the design space is chosen to further reduce the number of unclassified points. The training process is terminated when all points are clas-sified; the points classified as Pareto-optimal are then returned as the prediction  X  P for P .
 The pseudocode in Algorithm 1 outlines our approach. After intialization we iterate until a stopping criterion is met; every iteration t consists of three stages: mod-eling, classification, and sampling. These are discussed next including the stopping criterion.
 Modeling. We use Gaussian process inference to pre-dict the mean vector  X  t ( x ) and the standard deviation vector  X  t ( x ) of any x  X  E considering the former eval-uations. Each point x  X  E is then assigned its uncer-tainty region , which is the hyperrectangle where  X  t +1 is a positive value that defines how large this region is in proportion to  X  t . Hereby R  X  1 ( x ) = R n . In Section 4 we will suggest a value for this pa-rameter. The iterative intersection ensures that all uncertainty regions are non-increasing with t . Within R t ( x ), the pessimistic and optimistic outcomes are min( R t ( x )) and max( R t ( x )), respectively, both taken in the partial order and unique.
 Classification. Our algorithm maintains three sets that partitions E : in iteration t , P t is the set of points that are predicted to be Pareto-optimal, N t the set of points that are predicted to be not Pareto-optimal, and U t the set of yet unclassified points. In each iter-ation t , each x is assigned to exactly one of the these Algorithm 1 The PAL algorithm.
 classes. Our algorithm is monotonic in that P t and N t are non-decreasing sets with respect to t . In other words, as soon as a point x is classified as Pareto-optimal (or not Pareto-optimal), it remains classified as such. Further, our classification is relaxed by a pa-rameter , which informally means inequalities are con-sidered  X  X p to a small error  X , where = ( ,..., ). is an input to the algorithm.
 At iteration t , the points in P t  X  1 and N t  X  1 keep their classification. The only points x to be reclassified are those in U t  X  1 , done as follows:  X  If the pessimistic outcome min( R t ( x )) of x is not  X  If the optimistic outcome max( R t ( x )) of x is dom- X  All other points remain unclassified.
 Intuitively, the parameter speeds up classification at the cost of accuracy, since it makes the requirements less strict. Figure 2 shows for n = 2 and = 0 an example of a classification at some iteration t . Sampling. After the classification is done, a new point x t is selected for sampling with the following selection rule. Each point x  X  E is assigned a value which is the length of the diagonal of its uncertainty region R t ( x ). Among the points x  X  P t  X  U t , the one with the largest w t ( x ) is chosen as the next sample x to be evaluated. We refer to w t ( x t ) as w t . Intuitively, this rule biases the sampling towards ex-ploring, and thus improving the model for, the points most likely to be Pareto-optimal. Stopping criteria. The training process stops after, say, T iterations when all points in E are classified, i.e., when U T =  X  . The prediction returned is  X  P = P T The selection of the parameter used in the classifica-tion rule impacts both the accuracy and the sampling cost T of the algorithm. In this section we analyze the sample complexity of PAL . Of key importance in the convergence analysis is the effect of the regularity imposed by the kernel function k . In our analysis, this effect is quantified by the maximum information gain associated with the GP prior. Formally, we consider the information gain i.e, the reduction of uncertainty on f caused by (noisy) observations of f on the T first sampled points. The crucial quantity governing the convergence rate is i.e., the maximal reduction of uncertainty achievable by sampling T points. Intuitively, if the kernel k im-poses strong regularity (smoothness) on f , few sam-ples suffice to gather much information about f , and as a consequence  X  T grows sublinearly (exhibits a strong diminishing returns effect). In contrast, if k imposes little regularity (e.g., is close to diagonal),  X  T almost linearly with T . Srinivas et al. (2010; 2012) established  X  T as key quantity in bounding the regret in single-objective GP optimization. Here, we show that this quantity more broadly governs convergence in the much more general problem of predicting the Pareto-optimal set in multi-criterion optimization. The following theorem is our main theoretical result. Theorem 1. Let  X   X  (0 , 1) . Running PAL with  X  probability 1  X   X  .
 To achieve a maximum hypervolume error of  X  , it is sufficient to choose In this case, the algorithm terminates after at most T iterations, where T is the smallest number satisfying Here, C 1 = 8 / log(1  X   X   X  2 ) , and  X  T depends on the type of kernel used.
 This means that by specifying  X  and a target hypervol-ume error  X  , PAL can be configured through the pa-rameter to stop when the target error is achieved with confidence 1  X   X  . Additionally, the theorem bounds the number of iterations T required to obtain this result. Later, in Corollary 2, we will specialize the theorem to the case of a squared exponential kernel.
 Our strategy for the proof consists of three parts. In Section 4.1, we first analyze how w t decreases with t . We then relate and w t to ensure the classification of all points and thus the termination of the algorithm. In Section 4.2, we relate w t to the hypervolume error in the predicted Pareto frontier.
 Finally, in Section 4.3 we analyze the scenario in which PAL is run with the squared exponential kernel. 4.1. Reduction in Uncertainty The first step of the proof is to show that with proba-bility at least 1  X   X  , f ( x ) falls for all x  X  E within the uncertainty region (see (5) and (6)): which is achieved by choosing  X  t = 2 log( n | E |  X  2 t 2 / (6  X  )).
 Srinivas et al. (2010) showed that information gain can be expressed in terms of the predicted variances. Sim-ilarly, we show how the cumulative P t k =1 w k can also be expressed in terms of maximum information gain  X  . Since the sampling and classification rules used by PAL guarantee that w t decreases with t , we get the following bound for w t . With probability  X  1  X   X  , where C 1 = 8 / log(1  X   X   X  2 ) and  X  t is as before. This means that, with high probability, w t is bounded by O  X  ( p  X  t /t ), where O  X  is a variant of the O nota-tion that hides log factors. The proof is supported by Lemmas 3 to 7 found in the supplementary material of this paper. Key challenges and differences in compar-ison to Srinivas et al. (2010) include (1) dealing with multiple objectives; (2) the use of a different sampling criterion; and (3) incorporating the monotonic classi-fication scheme.
 We also show that, with probability 1  X   X  , all points will be classified at iteration T if This is proved in Lemma 11 found in the supplemen-tary material of this paper. 4.2. Reduction in Hypervolume Error We derive a bound on the hypervolume error (1) that is achieved once all points have been classified after T iterations and  X  P is returned. As example see Fig. 3, where  X  P has five elements, one of which has been eval-uated (uncertainty due to noise is not shown). With probability 1  X   X  , the points in f ( P ) lie inside the un-certainty regions R T ( x ), x  X   X  P . Hence, in this case  X  = V ( P )  X  V (  X  P )  X  V (  X  P o )  X  V (  X  P p ), where the sets of the optimistic (max( R T ( x )) and pessimistic (min( R T ( x )) outcomes, respectively, of the points in  X  P . The difference is colored gray in Fig. 3. Using w T , the length of the largest diagonal of any R
T ( x ), x  X  where a is defined as in Theorem 1. The proof is pre-sented in Lemma 12, which is found in the supplemen-tary material of this paper. Combining (11) with (10) and (9) yields the results from Theorem 1. 4.3. Explicit Bounds for the Squared Theorem 1 holds for general GP models for f ( x ), with prior  X  and covariance function k ( x , x 0 ). Srinivas et al. (2010) derived bounds for  X  T depending on the choice of kernel for the GP. These can be used to specialize Theorem 1.
 We illustrate this using the squared exponential ker-nel as example, i.e., k ( x , x 0 ) = exp l  X  2 k x  X  x 0 some l &gt; 0. From (Srinivas et al., 2010), for n = 1, there exists a constant K such that For n &gt; 1, since we assume i.i.d. GPs, we thus get and hence the following corollary to Theorem 1. Corollary 2. Let k i for all 1  X  i  X  n be the squared exponential kernels used by PAL . When choosing  X   X  (0 , 1) , a target hypervolume error  X  , and an that sat-isfies (7) , the fol lowing holds with probability 1  X   X  . PAL terminates after at most T iterations, where T is the smallest number satisfying This result suggests that T increases as  X  decreases in the following manner: Asymptotically, for any  X  &gt; 0, as well as fixed n and d , we have T = O ( 1  X  2+  X  ). We now discuss some aspects that arise when imple-menting and using our PAL algorithm.
 Parameterization . For practical usage, two param-eters, namely and  X  t , need to be specified. These pa-rameters relate to the desired level of accuracy of the prediction. Although we provide theoretical bounds, these may be loose in practice, and it may be useful to choose more  X  X ggressive X  values than recommended by the theory. The choice of  X  t impacts the convergence rate of the algorithm, since it scales the uncertainty re-gions R t ( x ). Since the analysis is conservative, scaling down  X  t , possibly to be constant, is a viable option. In contrast, the choice of should pose no problem. One only may consider, in contrast to our simplify-ing assumption, to choose in components of different magnitude, proportional to the range of the objectives. Absolute versus relative values. In our exposition, we consider absolute values for f and thus  X ,w t , and others. In particular for the hypervolume error  X  this poses a problem since, for example, averaging along one objective f i will underemphasize errors for small values of f i . In contrast to the single-objective case, the relative average error in this case cannot be re-trieved from the absolute average error. This problem can be solved by transforming all objectives with the logarithm and then running PAL in the log domain. We take this approach in our experiments later. Kernel hyper-parameters. So far, we have as-sumed, the kernel function is given. Usually, its pa-rameters need to be chosen. Therefore, prior to run-ning PAL , it may be practical to randomly sample a small fraction of the design space, and optimizing the parameters (e.g., by maximizing the marginal likeli-hood). One may also consider updating the hyperpa-rameters as new points are evaluated. We evaluate PAL on three real world data sets ob-tained from different applications in computer science and engineering. We assess the reduction in hypervol-ume error versus the number of evaluations required to obtain it for different settings of the accuracy pa-rameter . Further, we compare with a state-of-the-art multi-objective optimization method based on evo-lutionary algorithms, ParEGO (Knowles, 2006), us-ing an implementation provided by the authors and adapted to run with our data sets. ParEGO also uses GP modeling to aid convergence.
 Before presenting the results we introduce the data sets, discuss the use of log scale, and explain the ex-perimental setup.
 Data sets. The first data set, called SNW, is taken from Zuluaga et al. (2012b). The design space consists of 206 different hardware implementations of a sorting network for 256 inputs. Each design is characterized by d = 4 parameters. The objectives are area and throughput when synthesized for a field-programmable gate array (FPGA) platform. This synthesis is very costly and can take up to many hours for large designs. The second input set, called NoC, is taken from Almer et al. (2011). The design space consists of 259 different implementations of a tree-based network-on-chip, tar-geting application-specific circuits (ASICs) and multi-processor system-on-chip designs. Each design is de-fined by d = 4 configurations. The objectives are en-ergy and runtime for the synthesized designs run on the Coremark benchmark workload. Again, the eval-uation is very costly. The third data set, called SW-LLVM, is taken from (Siegmund et al., 2012). The design space consists of 1023 different compiler set-tings for the LLVM compiler framework. Each setting is specified by d = 11 binary flags. The objectives are performance and memory footprint for a given suite of software programs when compiled with these set-tings. Note that the Pareto-optimal set consists of one point only. The main characteristics of the data sets are summarized in Table 1; note that in all cases n = 2. To obtain the ground truth, we completely evaluated all data sets to determine P in each case. This was very costly, most notably, it took 20 days for NoC alone. The evaluations are plotted in Fig. 4; the Pareto frontiers are emphasized. All the data is normalized so that all objectives are to be maximized. Use of logarithmic scale. As explained in Sec-tion 5, we applied the base-e logarithm to every ob-jective function, thus ensuring that relative instead of absolute values are considered. This also allows us to obtain an average percentage error for the prediction  X  P with respect to each objective, based on the hyper-volume error  X  T .
 Formally, we define the average percentage error after termination for objective 1 as where a 2 = max x  X  E { f 2 ( x ) } ; E T, 2 analogously. Experimental setup. Our implementation of PAL uses the Gaussian Process Regression and Classifi-cation Toolbox for Matlab (Rasmussen &amp; Nickisch, 2010). In our experiments we used the squared expo-nential covariance function with automatic relevance determination. We fixed the standard deviation of the noise  X  to 0.1, and scaled  X  1 / 2 t down by a factor 5 as suggested by Srinivas et al. (2010). The training set was initialized with m = max { 0 . 02 | E | , 15 } sam-ples chosen uniformly at random.
 All of the experiments were repeated 200 times and the average outcomes are shown in the plots. Addi-tionally, several values of were evaluated, we used = ( i ) 1  X  i  X  2 , where i is proportional to the range of f : max x  X  E { f i ( x ) } X  min x  X  E { f i ( x ) } . We start with = 0 . 001% of each range and increase it through dou-bling up to 0 . 512%.
 Quality of Pareto frontier prediction. Fig. 5 shows a set of experiments in which we do both explore the effect of choosing and compare against the evo-lutionary algorithm ParEGO (Knowles, 2006). Every plot in Fig. 5 corresponds to one data set in Table 1. In each case, the x -axis shows the number t of evalua-tions (sampling cost) of f . For PAL this is T (the total number of iterations) plus the evaluations of designs in  X  P that have not been evaluated yet while running PAL . On the y -axis, we show the average percentage error (as defined above) for the first objective. The results corresponding to the second objective function are analogous and can be found in Fig. 7 of the sup-plementary material of this paper.
 ParEGO (green line) uses a heuristic to find the num-ber of samples m of the starting population depending on the characteristics of the design space. Hence the line always starts with a certain minimum number of evaluations. We measure the error at each iteration m &lt; t &lt; 150, and plot ( t, E t, 1 ) and ( t, E t, 2 As expected, the error in all cases decreases with in-creasing number of evaluations. We observe that PAL in almost all cases significantly improves over ParEGO. Only for NoC and high accuracy, the peformance of ParEGO is slightly better. At the other extreme the gains on SW-LLVM are considerable. In most cases, for a fixed desired accuracy, PAL requires about 33% less evaluations than ParEGO.
 The plots also show the effect of choosing on the termination of PAL . As expected a larger causes PAL to stop earlier. Further, the continuous doubling (since the data is in the log domain) of shows to offer fine grain control over termination. In this paper we addressed the challenging problem of predicting the set of Pareto-optimal solutions in a de-sign space from the evaluations of only a subset of the designs. We use Gaussian processes to predict the ob-jective functions and to guide the sampling process in order to improve the prediction of the Pareto optimal set. PAL can be intuitively parameterized to achieve the desired level of accuracy at the lowest possible evaluation cost. We presented an extensive theoreti-cal analysis including bounds for the required number of evaluations to achieve the target accuracy. Finally, we demonstrated the effectiveness of our approach on three case studies obtained from real engineering ap-plications. Our results show that we offer better cost-performance trade-offs in comparison to ParEGO. In most cases, for a desired accuracy, PAL requires about 33% less evaluations. Moreover, we showed that our parameterization strategy provides a wide range of cost-performance trade-offs.
 Almer, O., Topham, N., and Franke, B. A Learning-Based Approach to the Automated Design of MP-
SoC Networks. Architecture of Computing Systems (ARCS 2011 , pp. 243 X 258, 2011.
 Bonilla, E., Chai, K.M.A., and Williams, C.K.I. Multi-task Gaussian Process Prediction. In Conference on Neural Information Processing Systems (NIPS) , 2008.
 Boyd, S. and Vandenberghe, L. Convex Optimization . Cambridge University Press, 2004.
 Brochu, E., Cora, V.M., and de Freitas, N. A Tutorial on Bayesian Optimization of Expensive Cost Func-tions, with Application to Active User Modeling and
Hierarchical Reinforcement learning. Arxiv preprint arXiv:1012.2599 , 2010.
 Coello, C., Lamont, G. B., and Veldhuizen, D. Evo-lutionary Algorithms for Solving Multi-Objective
Problems . Springer-Verlag New York, Inc., Secau-cus, NJ, USA, 2006.
 D., Lanping, Sobti, K., and Chakrabarti, C. Accurate Models for Estimating Area and Power of FPGA Implementations. In Int X  X  Conference on Acoustics,
Speech and Signal Processing (ICASSP) , pp. 1417 X  1420, 2008.
 Jones, D. R., Schonlau, M., and Welch, W. J. Effi-cient Global Optimization of Expensive Black-box Functions. J Glob. Opti. , 13:455 X 492, 1998.
 Knowles, J. ParEGO: a Hybrid Algorithm with On-line Landscape Approximation for Expensive Multi-objective Optimization Problems. IEEE Trans. on Evolutionary Computation , 10(1):50  X  66, 2006. K  X unzli, S., Thiele, L., and Zitzler, E. Modular De-sign Space Exploration Framework for Embedded
Systems. Computers &amp; Digital Techniques , 152(2): 183 X 192, 2005.
 Palermo, G., Silvano, C., and Zaccaria, V. ReSPIR:
A Response Surface-Based Pareto Iterative Refine-ment for Application-Specific Design Space Explo-ration. IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems , 28:1816  X 1829, 2009.
 Rasmussen, C.E. and Nickisch, H. Gaussian Process
Regression and Classification Toolbox Version 3.1 for Matlab 7.x, 2010.
 Rasmussen, C.E and Williams, C. K. I. Gaussian Pro-cesses for Machine Learning . MIT Press, 2006. Settles, Burr. Active Learning Literature Survey. Technical Report 1648, University of Wisconsin-Madison, 2010.
 Siegmund, N., Kolesnikov, S.S., Kastner, C., Apel, S.,
Batory, D., Rosenmuller, M., and Saake, G. Predict-ing Performance via Automated Feature-Interaction
Detection. In Int X  X  Conference on Software Engi-neering (ICSE) , pp. 167  X 177, 2012.
 Srinivas, N., Krause, A., Kakade, S., and Seeger, M.
Gaussian Process Optimization in the Bandit Set-ting: No Regret and Experimental Design. In Int X  X  Conference on Machine Learning (ICML) , 2010.
 Srinivas, N., Krause, A., Kakade, S.M., and Seeger,
M. Information-Theoretic Regret Bounds for Gaus-sian Process Optimization in the Bandit Setting.
IEEE Trans. on Information Theory , 58(5):3250  X  3265, 2012.
 Zhang, Q., Wudong, L., Tsang, E., and Virginas, B. Expensive Multiobjective Optimization by MOEA/D with Gaussian Process Model. IEEE
Trans. on Evolutionary Computation , 14(3):456  X  474, 2010.
 Zitzler, E., Laumanns, M., and Thiele, L. SPEA2:
Improving the Strength Pareto Evolutionary Al-gorithm for Multiobjective Optimization. In Evo-lutionary Methods for Design, Optimisation, and Control , pp. 95 X 100, 2002.
 Zitzler, E., Brockhoff, D., and Thiele, L. The Hy-pervolume Indicator Revisited: on the Design of
Pareto-compliant Indicators via Weighted Integra-tion. In Int X  X  Conference on Evolutionary Multi-criterion Optimization (EMO) , pp. 862 X 876, 2007. Zuluaga, M., Krause, A., P.A., Milder, and P  X uschel, M.  X  X mart X  Design Space Sampling to Predict Pareto-optimal Solutions. In Languages, Compilers,
Tools and Theory for Embedded Systems (LCTES) , pp. 119 X 128, 2012a.
 Zuluaga, M., Milder, P., and P  X uschel, M. Computer
Generation of Streaming Sorting Networks. In De-
