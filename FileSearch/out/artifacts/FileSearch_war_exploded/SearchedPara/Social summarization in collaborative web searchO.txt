 1. Introduction
From a Web search standpoint, the success of a particular result-list depends on a number of factors. Obviously the pages that are retrieved as results are important; missing relevant result pages or including too many irrelevant result pages will vance to the query is also critically important and it is well known that the majority of user attention tends to be focused on the top ranking results. Finally, results should be presented in a way that highlights their likely relevance, not just to that serve to summarize a particular result X  X nd the way that they are generated.

In the past researchers have attempted to improve Web search by concentrating on the selection and ranking of search results. For example, many researchers have called for a more personalized approach to Web search, one which takes advan-tage of the learned preferences of the individual searcher ( Dou, Song, &amp; Wen, 2007 ) or a community of searchers, so as to recommend a ranked list of results that better reflect these interests. This research shares many aspects in common with traditional recommender systems research as it involves the recommendation of items (search results) on the basis of some learned user (or community) preferences. Recently, recommender systems research has begun to look at how recommenda-tions can be explained or justified to users, to help users better understand the reason behind a recommendation, and ulti-mately improve the perceived quality of the recommendations that are made ( McSherry, 2005; Pu &amp; Chen, 2007 ). In this regard our recent work ( Boydell &amp; Smyth, 2007 ) is relevant and provides the starting point for the research presented here.

One important emerging theme in modern information retrieval highlights the inherently collaborative nature of many mation search systems are often designed to support single-user interaction there are many situations where groups of collaboration. Recent work has sought to take advantage of this by building search interfaces that are designed to support a Lee, Foley, &amp; McGivney, 2007; Smyth, 2007; Smyth et al., 2004 ).

In this paper we build on recent work in collaborative web search ( Boydell &amp; Smyth, 2006; Smyth, 2007; Smyth et al., 2004), where the search actions of communities of searchers are harnessed to provide a more community-focussed search experience by, for example, promoting results that have been liked by community members, for similar queries, ahead of organic search results. In this paper however, we describe a different approach to personalization. Instead of (or in addition to the) re-ranking of search results we focus on adapting the result snippets so that they better reflect a community X  X  inter-ests. Result snippets are especially important in Web search because they help the searcher to better understand the result
Card, 1993 ), helping searchers to quickly find meaning in a collection of search results by extracting segments of text from a search result to present at search time. Conventional result snippets are usually query-focused; for example, the snippet text will usually be chosen because it contains a high density of query terms. These techniques do not always produce the most informative snippet texts, however, especially when a particular result might cover many different aspects of a topic some of which may be more or less interesting to the searcher. For example, consider a motoring enthusiast searching with the query many searchers using this query. However, consider a searcher who is interested in finding a parts supplier to source rare parts for their classic Porsche 356 coup X . This searcher may very well use the same query but will not be interested in most parts suppliers, only those that deal or specialise in classic Porsche components. As it turns out the supplier above does deal in this niche market but of course the query-sensitive snippet does not reflect this and so the result may be passed over by our searcher.

In this paper we describe how to generate query-focused snippets that are chosen based on the implicit preferences of a community of like-minded searchers. We do this by mining the selection information (search queries and selected results) that are generated as communities of searchers collaborate while they search. For example, a community of classic-car enthusiasts might receive a more relevant snippet for our example above, such as  X  X  X ll Classic 356 911 912 Porsche Parts for this result other community members have tended to use queries that have generated snippets containing these more technique so that it can be used to generate query-focused, community-based summaries as part of a collaborative web search engine such as ( Smyth, 2007 ). We also evaluate the quality of the generated summaries across eight different search communities, ranging in size and topic, from just over 800 searchers to more than 11,000 searchers. The results indicate that social summaries have the potential to outperform more traditional summarization techniques using standardized ROUGE recall tests ( Lin, 2004 ). 2. Background
The research in this paper touches on a number of areas of interest that fit broadly within the recommender systems re-mit. First and foremost our focus is on the use of recommendation technologies to personalize Web search results. Second, we are especially interested in the information that accompanies Web search results  X  the snippet text  X  by way of expla-nations, and how such snippets might also be adapted for the needs of users. Thirdly, we acknowledge the importance of the search interface as a vital unifying framework in the deployment of any recommendation technology. In the remainder of this paper we will focus mainly on the generation of personalized snippet texts while also touching on issues such as the recommendation of search results and proposing a novel search interface. Before this, however, in this section we will briefly review some important examples of related research, from areas such as personalized search, web page summarization, and search interfaces, to provide a suitable context for our own work.
 2.1. Personalizing search
Many searches fail because the queries lack vital information. For example, most queries fail to include terms that use-fully describe the search context or the preferences of the searcher. Consequently, researchers have recently focused on ways the Inquirus 2 meta-search engine ( Glover, Lawrence, Gordon, Birmingham, &amp; Lee Giles, 2001 ) supplements keyword-based queries with a context category; users explicitly select from a set of categories such as  X  X  X esearch paper X  and  X  X  X omepage X .
Alternatively, implicit context can be automatically inferred. For example, systems such as Watson ( Budzik &amp; Hammond, 2000 ) take advantage of user activity prior to the search to judge context; Watson monitors a user X  X  word processing activ-ities and uses document text as the basis for query terms. In contrast, relevance feedback techniques attempt to use actual search results to focus context on the most relevant search results as opposed to the entire set.

Information about the local context of the query is just one way to supplement vague query terms. Another approach in-volves collecting and using information about a searcher X  X  personal preferences, as they develop over time, in order to pro-vide a more focused set of results that are likely to address the searchers long-term and short-term interests. A wide range of mercial Web search engines such as Google 1 and Yahoo 2 are also now offering personalized search based on user profiles learned from individuals X  search history.
 All these techniques focus on capturing and re-using search context, whether local or long term, of individual searchers.
Most relevant to the social summarization work in this paper is collaborative web search (Boydell &amp; Smyth, 2006; Smyth, 2007), which instead records and harnesses the search experiences of a community of similar searchers and generates rec-ommendations based on community preferences. This approach provides many benefits over individual-based personaliza-tion, such as increased privacy (sensitive search histories are not stored for individual searchers) and the natural sharing of search expertise among similar searchers. Indeed this last point is key to our approach for generating result page snippets that express the preferences of a community of like-minded searchers in relation to a result page, and we will discuss col-laborative web search in more detail in a later section. 2.2. Collaborative information retrieval
First though it is worth making the connection between this collaborative approach to web search personalization and a important body of work in the area of collaborative information retrieval , which focuses primarily on supporting collaboration between searchers. For example, studies in specialised information seeking tasks, such as military command and control tasks or medical tasks, have found clear evidence that search type tasks can be collaborative as information is shared be-tween team members ( Reddy &amp; Dourish, 2002; Reddy et al., 2001; Reddy &amp; Jansen, 2008; Reddy &amp; Spence, 2008 ).
Recent work by Morris (2008) highlights the inherently collaborative nature of more general purpose web search. For example, during a survey of just over 200 respondents, clear evidence for collaborative search behaviour emerged. More than 90% of respondents indicated that they frequently engaged in collaboration at the level of the search process . For example, 87% of respondents exhibited  X  X  X ack-seat searching X  behaviours, where they watched over the shoulder of the searcher to suggest alternative queries. A further 30% of respondents engaged in search coordination activities, by using instant messag-sults of searches. For example, 86% of respondents shared the results they had found during searches with others by email.
Indeed almost 50% of respondents telephoned colleagues directly to share web search results, while others prepared sum-mary documents and/or web pages in order to share results with others.

Thus, despite the absence of explicit collaboration features from mainstream search engines there is clear evidence that users implicitly engage in many different forms of collaboration as they search, although, as reported by Morris (2008) , these collaboration  X  X  X ork-arounds X  are often frustrating and inefficient. Naturally, this has motivated researchers to consider how different types of collaboration might be supported by future editions of search engines. The resulting approaches to collab-orative information retrieval can be usefully distinguished in terms of two important dimensions, time and place . In terms of the former, collaborative search systems can be designed to support sychronous or asynchronous collaborative search. And in terms of the latter, systems can be designed to support either co-located or remote forms of collaborative search.
Co-located systems offer an collaborative search experience for multiple searchers at a single location, often a single PC (e.g. Amershi &amp; Morris, 2008 ) or, more recently, by taking advantage of computing devices that are more naturally collab-orative, such as table-top computing environments (e.g. Smeaton et al., 2007 ). In contrast, remote approaches allow search-ers to perform their searches at different locations across multiple devices; see e.g. Morris and Horvitz (2007a, 2007b) and
Smyth (2007) . While co-located systems enjoy the obvious benefit of an increased faculty for direct collaboration that is en-abled by the face-to-face nature of co-located search, remote services offer a greater opportunity for collaborative search.
Synchronous approaches are often characterised by systems that broadcast a  X  X  X all to search X  in which specific partici-pants are requested to engage in a well-define search task for a well defined period of time; see e.g. Smeaton, Foley, Byrne, and Jones (2008) . In contrast, asynchronous approaches are characterised by less well-defined, ad-hoc search tasks and pro-vide for a more open-ended approach to collaboration in which different searchers contribute to an evolving search session over an extended period of time; see e.g. Morris and Horvitz (2007a) and Smyth et al. (2004) .

This paper is in part, motivated by the importance role that sensemaking plays during Web search. Sensemaking is espe-cially important in the context of collaborative information retrieval approaches, as a way to help groups of collaborating searchers transition from solitary search practices to collaborating sensemaking activities. For instance, the work of Morris and Amershi (2008) looks at different approaches to sensemaking in the context of three different collaborative search pro-totypes, for example. These include various messaging and annotation features as well as search summarization features to help groups of searchers better understand how a particular search investigation was unfolding. Summarization was found to be useful but a number of users expressed a desire for more sophisticated sensemaking features, such as the ability, for example, to edit and manipulate summaries.

More recently, Paul and Morris (2009) describe some of the more sophisticated sensemaking features developed as part of the CoSense collaborative web search system. CoSense explores a number of different information representations and visu-alizations to help sensemaking during search. Searchers have access to various views of the collaboration process and its products. For example, the search strategies view presents searchers with summary information for the group including: the number of pages visited by group members and tag clouds of the prominent terms from these page visits. In contrast, a timeline view presents users with temporal view of group activities including queries submitted, pages visited, comments submitted. Initial studies suggest that these different views, among others, do serve to help users to better understand the evolving search process and its progress. 2.3. Web page summarization
With the advent of the World Wide Web, the need for document summarization has become more mainstream, and has brought new challenges to automatic summarization. In the past many summarization techniques were carefully optimized for particular types of documents (news articles, scientific papers, etc.). Such optimizations are often not feasible or appro-priate in the more content-diverse world of the Web. That said, Web content introduces additional features which may assist and guide the summarization process. For instance, Web pages include information features beyond their core content com-pared to a generic document, such as the structural information implicit in HTML mark-up. Moreover, Web pages do not exist in isolation since the hyper-linked structure of the Web means that each document can be located within a network of inward and outward links. This connectivity information can also be used to guide summarization. The InCommonSense system Amitay and Paris (2000) mines a Web page X  X  context by extracting segments of text surrounding in-links to the page, followed by a filter process that chooses the most accurate segment to return as an extrinsic summary of the page. This con-textual idea is elaborated on by Delort, Bouchon-Meunier, and Rifqi (2003) who look at combining this type of in-linking text with the original page content to produce a more sophisticated summary.

Particularly relevant to this paper is recent work on harnessing search engine click-through data to guide Web page sum-marization. For example, the work of Sun et al. (2005) explains how two traditional summarization approaches can be adapted to incorporate click-through information. In our approach, we also rely on search history to guide Web page sum-marization, except we are interested in constructing summaries that are aligned to the interests of a group of similar search-ers as well as a current target search query, with a view to using these social summaries in place of standard result page snippets in a collaborative web search scenario. The novelty of our approach, however, stems from the use of query-focused snippets in addition to the raw query terms. 2.4. Search interfaces
On the whole, most search engine interfaces tend to follow a conventional format. The standard linear list of search re-other approaches which are relevant to collaborative web search, social summarization and our novel interface proposed in a later section. Personalized search and community-based personalized search in particular provide an extra dimension of information that is not found in standard search, and search interfaces can take advantage of this to provide additional infor-mation to the searcher. The work of Coyle and Smyth (2007) proposes adding community-based explanations to search re-sults from a collaborative web search system. Results that have a community search history associated with them are annotated in the result-list with popularity , recency and related queries information, which is expressed through graphical explanation icons and can be revealed in more detail when the searcher mouses-over these icons. Reports of a live user trial indicate that interactions with these explanation icons correlate closely to the likelihood of the associated result being se-lected, which suggests that the searchers find these additional interface features useful in informing their selections.
An interface design for faceted result grouping in interactive information retrieval by Joho and Jose (2006) is a source of inspiration for our proposed interface that takes advantage of social summarization. As well as showing the standard result-provides the searcher with different perspectives on the returned results. Our interface for a collaborative web search system that uses the social summarization technique described in this paper also allows the searcher to view their search results in different ways: the original result-list returned from an underlying Web search engine, a list of results promoted in line with community preferences that are accompanied by social summaries and a composite social summary of all the promoted re-sults with a unique click-through method for navigating instantly to the relevant section of the result page that the searcher is interested in. 3. Social summarization in collaborative web search
The starting point for our work on community-based social summarization is an approach to Web search, called collab-orative web search ( CWS ). CWS exploits query repetition and selection regularity among communities of like-minded searchers in order to recommend results from some underlying search engine that are likely to be especially relevant for a particular community. A detailed review of CWS is beyond the scope of this paper (see Boydell &amp; Smyth, 2006; Smyth, 2007) but it is worth highlighting some of its features that are important in the context of this work: CWS assumes the availability of a community of like-minded searchers.

Each community is associated with a repository of search knowledge made up of the queries submitted, the results selected, and the terms contained in the snippets of these selected results.

This search knowledge is used to create a community-focused search index that relates query and snippet terms to selected results for that community.

At search time, organic search results provided by some underlying search engine are supplemented by community pro-motions, which are results that are selected from the community index based on the current target query.

The community promotions are ranked based on the frequency of their selection by community members and on the informativeness of their snippet terms.

Fig. 2 shows the CWS architecture. A user u from community C submits their search query q allel to both an underlying Web search engine (such as Google) and the CWS relevance engine. The relevance engine in turn probes the community-focused search index I C with q i to retrieve a set of community-focused search results R combined by the relevance engine with the organic search results R ing R C above R O to produce the final combined result-list R
Fig. 3 shows the result of a search as part of the Google-integrated version of CWS. In this case CWS has been configured to work with Google as its primary source of search results. Fig. 3 shows the results for the query  X  X  X ichael Jordan X , which ordi-narily would be dominated by the basketball star. However, in this case, because the query has been submitted by a member of a Machine Learning community, prior community selections have led to the promotion of results related to the Berkeley professors of the same name. These results have previously been selected by the current searcher, or by other members of the community, for similar queries. Importantly, this is an example of implicit search collaboration in the sense that the searches of other users, when promoted in this way, are potentially helping the current user to search more effectively. 3.1. Snippet-based document surrogates
A key idea in the aforementioned approach to collaborative web search is the notion that each search community is represented by a local search index I C . Let  X  C ; u ; q r selected in response to such a search. It is reasonable to assume that the displayed snippet for this result, s  X  r ; q r can be indexed by using the terms contained within s  X  r ; q queries, q 1 ; ... ; q n , will come to be indexed under a number of different snippets, s  X  r ; q munity of searchers each selected result will come to be represented, for the purpose of local indexing, by a surrogate , S shown in the following equation:
This is illustrated in Fig. 4 , which shows an example result-list in response to  X  C ; u ; q surrogates are updated accordingly. In this case r 1 has only ever been selected for q the single snippet s  X  r 1 ; q i  X  . In contrast, r 3 has been selected previously for another query, q made up of the combination of s  X  r 3 ; q i  X  and s  X  r 3 in their surrogates in the local community index. Result r appear in the local index.

Importantly, this allows each result to be indexed and represented differently for different communities of users. For example, different parts of a document might be more or less interesting to different communities and this will be reflected by the index terms that come to be used in the different local snippet indexes for each community. Documents that are broadly relevant to a community X  X  interests are likely to be retrieved for a wide variety of queries and are likely to be se-lected for many of these queries. The document surrogate will cover a significant portion of the document X  X  contents and the snippet index will reflect this by associating the document with a broad set of index terms. In contrast, other documents may be only relevant for some small part of their contents. These are more likely to be retrieved for a much more restricted very limited. The essential point is that each document surrogate represents a basic community-oriented summary. 3.2. Generating social summaries
Boydell and Smyth (2007) describe how to generate social summaries from snippets which we shall review in the remain-der of this section.

Consider a result page p which has been previously selected by members of a search community for some set of past que-ries  X  q 1 ... q n  X  . Within the CWS community search knowledge we have a set of n query-focused snippets S  X  p ; q first parsed into fragments, then scored based on the frequency of occurrence, and finally re-combined. 3.2.1. Fragment normalization
Each snippet is composed of a set of m sentence fragments (Eq. (2) ) that have been extracted from the text of the target a large collection of sentence fragments. Some of these fragments will be unique but others may be identical to each other. Some fragments might subsume other fragments, while others will overlap.

The final community-focused summaries are generated directly from these sentence fragments and significant overlaps will have an impact on summary quality. We eliminate this redundancy by producing a normalized set of fragments prior to summary formation. More formally, matching sentence fragments are identified according to Eqs. (3) and (4) . If there is a significant overlap between fragments (in practice, t  X  0 : 8 works well) then the shorter fragment is said to be dominated by the longer fragment; see Eq. (5) . To normalize the fragments across the snippets for page p we replace all dominated frag-ments with their maximally dominating partners. In what follows we use S
S  X  p ; q i ; y  X  : 3.2.2. Fragment scoring
For a page p we now have a set of snippets (generated from queries over p ), each made up of a normalized set of sentence fragments. Intuitively, it seems reasonable to assume that fragments which occur more frequently are likely to be more important; after all they are associated with page segments that are linked to the queries for which community members selected p . In this way the scoring model favours aspects of pages that many users are interested in and these aspects will be more prominent in the resulting social summaries. Accordingly, we can compute the score of some fragment, f , as the number of times that f occurs in the snippets generated for p ; see Eqs. (7) and (8) . 3.2.3. Fragment ranking and summary generation
Producing the final summary from the scored, normalised snippet fragments is now straightforward. First, compute the union of all of the normalised fragments (see Eq. (9) ). Second, rank order these fragments in descending order of their fre-quency scores as shown in Eq. (10) .
Fig. 5 gives an overview of social summary generation, showing a result page p that has been previously selected for queries q ; q 2 and q 3 and the query-focused snippets S  X  p ; q 1  X  ; S  X  p ; q are the building blocks for generating a social summary, SS  X  p  X  , in line with the preferences of the community of searchers that selected p . 3.3. An example social summary
Fig. 6 shows the social summary generation for a portion of the Wikipedia page  X  X  X ava Platform X , using the queries java platform and java virtual machine . The snippet produced by a Web search engine for each query q text fragments extracted from the source document, which are related to the query terms. For example, in Fig. 6 a and b we see that the snippet for query q 2 =  X  X  X ava platform  X  is composed of three fragments from the source text: f 1 =  X  X  X he Java platform is the name for a bundle of related programs, or platform, from Sun Microsystems  X  f 2 =  X  X  X ava Platform (formerly Java 2 Platform[1])  X  f 3 =  X  X  X he current version of the Java Platform is alternatively specified as version 1.5 or version 5.0 or version 5  X 
The union of all such fragments from the two snippets generated for q core content for the social summary, and the fragments are scored and rank-ordered according to the method described above to produce the final summary, SS  X  p  X  ( Fig. 6 c). 4. Using social summaries in web search
So far we have described a page summarization technique that is based on the interactions of communities of like-minded searchers. As it stands this technique is very suitable for producing full page summaries, as has been previously shown by Boydell and Smyth (2007) . However it is not yet appropriate for producing result snippets because its summaries are not query-focused. In this section we will explain how this technique can be expanded to produce query-focused sum-maries that can be used as result snippets; and in the next section we go on to evaluate how well these snippets perform relative to alternative approaches.

In addition, in the second part of this section we go on to describe another application of social summarization, this time to produce a so-called composite summary as a way to summarize a collection of results. And in a later section we demonstrate a novel search interface that combines these two different applications of social summarization within a com-munity-based search scenario; see Section 6.2 . 4.1. Query-focused social summarization
Generating result page summaries according to the above procedure will lead to summaries that are aligned with com-munity preferences, as reflected by previous community search history. However, these page summaries are not yet appro-&amp; Sanderson, 1998 ) and so in addition we would like to adapt our summaries for the current target search query.
Consider a page p which has been selected for searches for queries q such as that shown in Eq. (11) which is based on Jaccard X  X  similarity coefficient to produce a modified version of the fragment scoring metric used in the previous section. This time the score that a fragment f accumulates depends not only on its fre-quency of occurrence within the various snippets, but also on the similarity between the target query q led to these snippets (Eq. (12) ).
A query-focused summary can then be produced in the normal way, by rank ordering the fragments in descending order of their scores. In turn, summaries of arbitrary length (up to the total number of available fragments) can be generated by trun-cating the summary after the top k fragments. This approach can be used to associate community and query-focused social summaries with search engine results in place of traditional query-focused snippets. Indeed the approach also facilitates the generation of social summaries where the size of the summary correlates with the predicted relevance of the search result.
For example, top ranking results may be associated with longer (more detailed) social summaries than lower ranking results. 4.2. Composite summaries query-focused snippet and the entire list is ordered by decreasing result relevance. This basic format, apart from some minor best way of displaying search results? Many tasks oblige the searcher to review many results rather than hunt down a single fact within one result page and so arguably the searcher may be better facilitated by an overall summary of the top ranking result pages, rather than a set of individual and disjoint summaries. With this in mind we consider how our social summa-rization technique can be used to produce such a summary, a composite social summary of results which is in line with a search community X  X  preferences and information needs. Such a composite social summary can complement the standard list of results promoted from a community X  X  local snippet index in CWS.

To recap, the first step in generating a social summary for a single promoted result p is to parse the individual text frag-ments from the set of snippets, S  X  p ; q 1 ; ... ; q n  X  , for which p was selected for queries q posite social summary over a number of promoted result pages, p single result X  X  set of snippets but from all the snippets associated with p fragments is normalized in the normal way, except now we may have similar fragments occurring not just between different snippets for different queries, but also between different snippets for different result pages. Likewise, fragments are scored by their frequency across different result pages as well as across different queries which may be influenced as previously shown to produce a query-focused composite social summary. The scored fragment ranking and overall summary generation is just as straight forward, and Eqs. (9) and (10) now become (13) and (14) respectively.
Composite social summaries produced in this manner attempt to capture the salient information in the promoted result pages which is most relevant to community preferences and interests, and to condense this in a form which is more digest-summaries may be displayed as part of a novel collaborative web search interface, but first we present an evaluation of our community-focused social summarization technique. 5. Evaluation
There are two basic considerations with respect to our social summarization technique, from an summary quality stand-point. In the first instance we might consider the quality of the summaries produced in a generic way: we did this in ( Boydell &amp; Smyth, 2007 ), where we compared pages summaries produced by our social summarization technique to those produced by more traditional summarization approaches. Alternatively we might consider the specific hypothesis forwarded in this work: that the summaries produced are tuned to the preferences of a particular community of users, when compared to more generic summarization techniques that are not sensitive to community preferences. It is this issue that we consider explicitly in this evaluation. Specifically, we produce community-focused social summaries for nearly 4500 Web pages across 8 different communities of interest to show how these summaries more accurately capture the context of a particular community than two leading benchmark summarization techniques. 5.1. Experimental data
Ideally we would like to evaluate our techniques using real community search data but unfortunately the availability of comprehensive search logs, with query and selection information, not to mention the query-focused snippets which form the building blocks of our social summarization technique is extremely limited. Instead we have opted for an alternative strat-egy, which relies similarities between community-based Web search and online collaborative bookmarking services in order to generate realistic  X  X earch X  communities to generate social summaries for.

Bookmarking services such as Del.icio.us 3 can provide a reasonable source of search-like log-data if we interpret bookmark tags as queries for specific bookmarked documents; the tags share many of the same basic term distribution characteristics as
Del.icio.us by following sequences of related tags and extracting the bookmark data associated with these tag sequences. For example, consider the construction of an iPod community by starting with  X  X pod X  as a seed tag. For this tag we can extract the top k  X  k  X  100  X  bookmarked pages; for example,  X 50 Fun Things To Do With Your iPod X  is the top page for the ipod tag at the time of writing. This page has been bookmarked by in excess of 1000 people and we can extract the tag-sets used to tag to the total number of people who bookmarked the page. Thus, for example, one particular user has tagged the above page with tion technique to build eight communities of varying sizes shown in Table 1 .

For each page selected by a community member, we still require a set of standard query-focused summaries correspond-ing to the queries (tags) for which the page was selected (bookmarked) so that we may generate social summaries for the page. We used the Lucene 4 query-focused snippet extraction package along with the downloaded page content and the set of queries that led to the page X  X  selection to produce snippets in a similar manner to those returned by popular Web search en-gines. These query-focused snippets provide the building blocks for our social summary generation. 5.2. Evaluation metrics
When evaluating standard summaries, it is normal practice to compare each summary to a corresponding reference (or gold-standard) summary of the target document; often the reference summary is human-generated and produced by a do-main expert as a generic summary of the target document. This was not feasible in the current evaluation because it would require producing individual document summaries that emphasised the biases of particular communities of searchers, and as such would require a level of human effort that is well beyond the scope of our facilities. Instead we chose an alternative approach that could be fully automated.

Each page that was selected in each of the search communities is associated with a set of queries; these are the tags used by the Del.icio.us users to bookmark these pages. We can view these tags as representative of those terms that are relevant to the page in question and that are most important to the particular community with respect to the page. We split these tags (queries) into two separate sets: training queries are those used to generate the social summaries; and test queries are used to evaluate the quality of the resulting summaries by computing the recall of the test terms in the summaries produce by the social approach and the benchmark techniques.

For the purpose of this evaluation we use two leading benchmark summarization systems: Open Text Summarizer (OTS) ( Rotem, 2003 ) and MEAD ( Radev, 2003 ), with respect to these gold standard summaries. Both OTS and MEAD combine shal-low NLP techniques with more conventional statistical word-frequency methods to produce document abstracts from high scoring sentences. For example OTS incorporates NLP techniques via an english language lexicon with synonyms and cue terms as well as rules for stemming and parsing. These are used in combination with a statistical word frequency based method for sentence scoring. Similarly, MEAD harnesses statistical NLP data by using a database of english words and their corresponding inverse document frequency scores calculated from a large document corpus. Once again this information is combined with word occurrence and positional information to extract high scoring sentences.

Thus, for each result page we compare the social summary produced using our technique, and the summaries produced by OTS and MEAD (which are adjusted to be a similar length to the social summary) to the terms contained in the test que-ries using the ROUGE-1 recall evaluation metric ( Lin, 2004 ). ROUGE is a standard package for evaluating summaries and has become the evaluation method of choice for the Document Understanding Conferences summarization research. The ROUGE-1 metric compares unigram term co-occurrence between the candidate and reference summaries and according to Lin and Hovy (2003) is highly effective for single document summarization evaluation tasks and evaluation of short summaries. 5.3. Evaluation results
For each of our eight communities, we performed ten splits of training/test queries and the results of the ROUGE-1 recall evaluation for our social summaries (SS), OTS and MEAD summaries against the reference summaries (test query terms) are shown in Fig. 7 . For each community we see that the SS technique outperforms both OTS and MEAD. For example, in the case of the Skiing community we see that the SS summaries achieve a recall of just under 50%; that is, these summaries contain nearly 50% of the held-back test terms that were used by other community members to tag these pages. In contrast, the OTS and MEAD summaries achieved recall levels of between 36% and approximately 40%. Thus our community-focused tech-nique is capable of generating snippet summaries that have a greater overlap with the community test terms and thus should offer more relevant summaries to community members.

When averaged across all communities we find that SS enjoys a relative benefit of approximately 17.8% and 18.3% in terms of recall improvement, when compared to OTS and MEAD, respectively. Moreover, in all cases we find the benefits enjoyed by the SS technique to be significant at the 95% confidence level when compared to OTS and MEAD, with the appro-priate error bars shown in the figure.

These results speak to the potential for community-based snippets to provide meaningful summaries to community members during search. It should be remembered that these community summaries are generated without recourse to any deep content analysis of natural language summarization techniques. Instead, simply harnessing the selection behaviour of a community of searchers, and the existing snippet-generating machinery of a search engine, is sufficient to focus in on those elements of a result page that are likely make sense to a particular community searcher. 5.4. Evaluation limitations
These evaluation results support the notion that our social summarization technique is capable of generating community-focused result summaries for groups of like-minded searchers. However, as with most evaluations there are limitations that must be acknowledged and considered when evaluating the significance of the results presented. Perhaps the most signif-icant limitation of this evaluation is the lack of explicit human-generated summary judgements. One advantage of this is that it has been possible to evaluate the summaries produced for more than 5000 pages, but the disadvantage is there remains some question over the value and validity of the social summaries produced.

Human evaluators are often used to evaluate automatic summarization techniques to good effect but they have not been used in this study. The primary reason for this is that the present study differs from more conventional summarization stud-ies in at least two ways. First and foremost, we are interested in generating community-focused summaries, that is page summaries that are designed to appeal to the peculiar interests of a specific community of collaborating searchers. This means that the summaries generated for a particular community will really need to be evaluated by members of that com-munity, or a least by judges with overlapping interests. Given that our evaluation covers eight very different and specialized communities, and given that ordinarily one would expect to use a panel of judges for each summarization task, this signals on a stable set of opinions. Unfortunately this scale of evaluation was beyond the scope of this work.

That said, it would be incorrect to discount the present evaluation simply because of the lack of human judges. Remember that the search communities have been produced based on real-user tagging behaviours for users who are intimately con-nected to the communities in question. In addition the evaluation of the social and benchmark summaries is based on the overlap between the generated summary and an unseen set of terms that have also been used to tag pages within a com-munity. The extent to which these terms are present within the community is a legitimate indicator of community relevance since, after all, these very same terms have been used to tag these pages within these communities. The fact that the social summaries contain significantly more of these terms that the summaries produced by the benchmark OTS and MEAD tech-niques is a strong indicator that the these social summaries are at least producing summaries that contain relevant content.
Of course this does not mean, for example, that the social summaries are as readable as those produced by more sophis-ticated natural language based summarization techniques. In fact, preliminary evidence suggests that social summaries are more fragmented than their natural language counterparts. This is certainly a limitation if the objective is to produce doc-ument-style summaries that are to be read as a proxy for a more detailed document. but given that our interest is on pro-ducing more relevant result snippets we view this limitation to less critical in this context.
 further evaluation work. For example, even if human judgements are not feasible across the board it may be possible to pro-duce a more traditional summarization evaluation, using human evaluators, for one or two of the communities. Moreover, the value of social summaries as search results summaries versus more traditional document summaries needs to be explored. 6. Discussion
The primary contribution of this paper has been to explore the generation of community-focused search result summa-ries, to aid in community-sensemaking, as part of a collaborative web search engine. In the main we have concentrated on presenting and evaluating the core summarization technique, with positive results obtained in comparison to a number of conventional summarization benchmarks. In this section we discuss some recent additional work which explores the role of
Web search and, specifically the distinction between implicit and explicit modes of collaboration. The work in this paper has been based on an implicit approach to web search collaboration, as opposed to more popular emplicit approaches. In the following we will consider how the implicit techniques described here might be adapted to accommodate a more explicit form of collaboration. 6.1. Explicit versus implicit collaboration
The work in this paper builds on earlier work on a specific implementation of collaborative information retrieval known as collaborative web search (CWS) ( Boydell &amp; Smyth, 2006; Smyth, 2007; Smyth et al., 2004). Importantly, CWS assumes an implicit model of search collaboration: to wit, the prior searches of members of a search community are used to promote popular community results at search time. However, by default at least, there is no explicit collaboration between commu-nity members, in the sense that the searcher is unaware of which members may have contributed to the promotions that searchers to benefit from the searches of others.

This implicit collaboration is in contrast to a number of alternative models of collaborative information retrieval, which rely on a more explicit approaches to search collaboration; for example, SearchTogether ( Morris &amp; Horvitz, 2007b ) imple-ments a more explicit form of collaboration in which a specific group of searchers come together to collaborate on a specific search task, and spend timely actively communicating and collaborating through the search interface. This type of explicit collaboration during search is very well suited to time-bounded, task-oriented search scenarios whereas, arguably, the im-plicit style of collaboration implemented by CWS is more suitable as a form of background search collaboration operating across many search tasks. More recently the work of Champin, Briggs, Coyle, and Smyth (2009) Smyth, Briggs, Coyle, and
O X  X ahony (2009a, 2009b) describe a combination of explicit and implicit search collaboration in the HeyStaks ( http:// www.heystaks.com ) social search system. Briefly, users can choose to explicitly collaborate on specific search tasks by cre-ating so-called search staks , which as micro-search communities. In turn their implicit search behaviour is used to generate promotions for stak members at search time. Similarly the work of Morris, Teevan, and Bush (2008) Teevan, Morris, and
Bush, 2009 is relevant in this regard. This work looks at techniques for discovering latent groups of like-minded searchers, which may form the basis of task or interest/trait-based communities. This work proposes a number of ways in which group effort can be leveraged during search (e.g. result highlighting, task-splitting, etc.), and demonstrates how groupization tech-niques can improve upon more conventional notions of personalization in Web search, especially for on-task queries.
Of course, in the context of the present paper, there are numerous ways to introduce more explicit forms of collaboration into the search interface. For example, in recent work we have investigated different ways to make the source of search pro-motions explicit, so that the searcher can better understand who is responsible for particular promotions. This, in effect, makes search collaboration more explicit because searchers quickly learn to associated good and bad promotions with par-ticular searchers, helping them to make better judgements about the likely value of a particular promotion; see Briggs and a query  X  X  X BR X  for a community of Machine Learning researchers looking for information on Case-Based Reasoning. The pro-motions presented are for relevant results and have been selected because they have proven to be popular for similar queries by this community. In addition, in this interface the searcher can see the source of particular promotions and popup shown highlights the top three  X  X  X ecommenders X  (that is, other community members) who have previous selected this result in question. These recommenders have been selected on the basis of a trust score which represents how often other searchers have reselected their promotions in the past and forms the basis of a trust-based promotion mechanism presented in Briggs and Smyth (2008) . 6.2. A novel recommendation interface for community-based web search
This paper touches on a number of recent Web search innovations, from a recommender systems standpoint. We have discussed collaborative web search, a community-based approach to Web search in which results that are especially relevant to a community of searchers are recommended alongside organic results from a generic search engine. And of course we have discussed the social summarization technique that is enabled by CWS and how it can be used to produce different types of community-focused summaries, including community-focused result snippets and composite result summaries. We have shown that these summaries serve as compact community-oriented result summaries that would help searchers to better understand the content of a given search result. To bring these various pieces together we have designed a novel recommen-dation interface that integrates organic and recommended search results with social summaries, which we will briefly intro-duce here; see Fig. 9 .

The screen area is divided into three basic parts: 1. The Web Results list shows the (organic) results returned from the underlying Web search engine (Google in the current example), without any community-based re-ranking or result promotions from CWS; this reflects the standard Google result-list. 2. The Promoted Results are the results returned from the community X  X  snippet index by CWS. These are the community rec-ommendations and as such are more in line with the preferences and interests of the community. For each promoted/rec-ommended result, in place of the standard result snippet we present the query-focused social summary for that result page. In this way, each recommended result benefits from a more community-oriented summary of its associated content. 3. Finally, the Promoted Summary is a composite social summary of all of the promoted result. It is designed to provide an concise overview of the set of recommended results and the community preferences and interests for the current query.
This interface is interesting in a number of important ways. First of all, it demonstrates a simple way to combine organic and community search results. In previous implementations of CWS (Boydell &amp; Smyth, 2006; Smyth, 2007) community pro-motions have been mixed-in with organic results, which has the advantage of maintaining a simple result-list, but has the disadvantage that promoted results may not be noticed unless they are separately annotated ( Coyle &amp; Smyth, 2007 ). By sep-arating the organic and promoted results as in Fig. 9 we are helping the searcher to more easily differentiate between the two types of results.

More importantly, perhaps, is the fact that the promoted results also benefit from enhanced snippet texts that have been generated using the social summarization technique and that better reflect the preferences of the search community. For example, the promoted snippets can be longer than the organic snippets, if there has been sufficient past selection activity, and their individual snippet terms may be highlighted with a larger font size if they score particularly highly during social summarization; for example, in the second promoted result the term  X  X Trip X  is highlighted, indicating that many community members have previously selected this result for queries containing this term.

Finally, the  X  X  X romoted Summary X  provides a composite summary of the promoted results. In this example, for conve-nience, there are only three such results and so the promoted summary is perhaps less distinctive, but in general it can be used to summarize arbitrarily larger numbers of promotions to provide the searcher with an instant view of the commu-nity X  X  past selections, with respect to the current query and queries like it. This composite summary is made up of fragments from the promoted result summaries and each fragment is itself a hyperlink to the original fragment source position in the relevant result page; as the searcher mouses-over a fragment, an interactive pop-up box displays with a link to the appro-only one may be relevant for the current query and community search preferences, by allowing the searcher to navigate di-rectly to the topic of interest in the result page.

Rather than presenting a refined prototype, this interface is presented as an example of the type of search interface that might be enabled by social summarization techniques in the context of collaborative web search. Preliminary user studies indicate a positive response to the social summaries provided alongside the promoted results and also to the overall pro-moted summary. However, a more rigorous evaluation is needed before any real conclusions can be drawn and future work will focus on the evaluation of this type of interface across a number of mature search communities. 7. Conclusions
In this work we have described an approach to Web search that is personalized for the needs of a community of like-minded searchers. The basic collaborative web search technique focuses on recommending search results, which come from a traditional search engine, as promotion candidates because they have been previously considered relevant by a community of searchers. The main focus of this paper has not been on the core recommendation technique (this has been previously which accompany search results, can also be adapted to a community X  preferences.

To this end we have described a novel document summarization technique called community-focused social summarization that uses community search behaviour, such as that recorded by a collaborative web search engine, as the basis for gener-ating community-focused result summaries. This is achieved by leveraging the snippet-generation capabilities of standard search engines, enabling result page snippets to be produced that are in line with the preferences and interests of a commu-nity of like-minded searchers. We have presented an evaluation using a number of search communities to demonstrate how the technique can generate summaries that are more community-focused than those produced using standard one-size-fits-all summarization methods. We have also presented a novel collaborative web search interface that leverages our social summarization approach both on the level of an individual result page and as a way of summarizing whole lists of results. Acknowledgement This material is based on works supported by Science Foundation Ireland under Grants 03/IN.3/I361 and 07/CE/I1147. References
