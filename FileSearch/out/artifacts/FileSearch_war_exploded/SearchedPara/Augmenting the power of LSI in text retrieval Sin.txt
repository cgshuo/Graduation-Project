 1. Introduction
The technique of latent semantic indexing (LSI, also known as latent semantic analysis or LSA) has been analysis of these methods and also proposes a novel rescaling technique, namely singular value rescaling (SVR).

This paper is organized as follows: Section 2 introduces some background information about the SVD our novel technique of singular value rescaling. Section 7 describes the experimental results on TREC data sets. Section 8 compares our SVR technique with another scaling technique used in text retrieval, namely iterative residual rescaling (IRR). Section 9 provides a high-level conceptual explanation on how SVR works on top of the conventional SVD technique. Section 10 presents our conclusions. 2. Background document j , after any necessary term weighting has been performed [11] . A value decomposition process, where it is represented as the product of three matrices, A
A is a t d matrix of rank r , U 0 is a t r orthogonal matrix, S s of text retrieval, document vectors can either refer to the column vectors A in V T 0 , and term vectors can either refer to the row vectors A
The same nomenclature of document vectors and term vectors also applies to the dimensionally reduced model that is constructed in the next step: A = USV T , where U is the first k columns of U rows of V T 0 , and S is a diagonal matrix with the k largest singular values from S ture of relations between terms and documents than does the original model, A use the new model to compare two documents, two terms, or to determine the relationship between a term and ferent ways of doing this, however, which we illustrate and analyze in the following sections. 3. An illustrative example
In Table 1 , a term-by-document matrix A 0 is constructed using the highlighted terms shown in Fig. 1 .Ifan
Singular value decomposition is performed on A 0 : SVD  X  A matrices: orthogonal matrix U 0 of dimension 11 8, diagonal matrix S ues 3.1262 P 2.1753 P 2.1225 P 2.0172 P 1.1260 P 1.0933 P 1.0000 P 0.6765, and orthogonal matrix V of dimension 8 9. Now we construct the dimensionally reduced model. Note that so far there is no standard Choosing k = 3, we obtain the following matrices: U of dimension 11 3, S of dimension 3 3 with singular values 3.1262 P 2.1753 P 2.1225, and V T of dimension 3 9. We also re-compute the full 11 9 term-by-document matrix using A = USV T . 4. Standard query method: three philosophies, three versions
There are three different philosophies on how to execute a query q in the dimensionally reduced LSI model, giving rise to three versions of the standard query method: (I) Version A (II) Version B (III) Version B 0
The above three different versions are summarized in Table 2 , along with the simple technique of lexical match, which matches words according to their exact spellings after any necessary stemming is performed.
Now suppose we want to execute the following query: query (ontology, RDF). To start with, we represent it in a form of pseudo-document vector like any normal document vector in the original matrix A
Note that the above vector is a column vector, just like any column vector in matrix A constructed in a way that it resembles a document vector taken from the matrix A document vector.
 relation between two concerned query results in the form of score vectors: similar results as far as our discussion is concerned; however, for consistency we choose Pearson X  X  method.
Query results are shown in Table 3 . Here, the precision rate denotes the percentage of relevant documents sult ) = 0.9924, and a perfect correlation exists between the results of version B and version B tion ( qb _ result , qb 0 _ result ) = 1. Actually, qb 0 threshold 0.5000 for version B and 0.2333 (=0.5000 0.4665) for version B the identical set of documents. Later on, we shall find out the origin of this constant, 0.4665. 5. Analysis of the three versions of the standard query method 5.1. Comparison of version A and version B
For version A, we have:
Therefore, 1 For version B, observing A = USV T , qb = UU T q , and U T
Therefore,
Comparing (1) and (2) shows that the difference between the two query results is a factor of S sidering the normalization effect. Now we can explain the apparently high correlation between the two query results in the previous example. For convenience of discussion, we write out the matrix S below: experiments shortly. When S approaches cI , a difference represented by a factor of S bring about a high correlation between the two query results, as has been observed in the previous example. singular values are probably many times bigger than the smallest few. Therefore the approximate equation
S cI may not stand well, which means that the retrieval results between these two versions may be quite significant.
 matrix U and V T intact. Matrix A is recomputed with the changed S using A = USV here: query (image, indexing), which is represented as q = (0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0)
Table 4 . each other, the less correlated the results. 5.2. Comparison of version B and version B 0
Let qb _ result =( qb _ result i ) T and qb 0 _ result =( qb and where A (:, i ) and V T  X  : ; i  X  are the column vectors of matrices A and V
Dividing (4) by (3) yields
Because k UU T q k / k q k does not depend on i , we have ( qb ... , qb _ result d ) T Therefore, qb 0 _ result =( k UU T sion B and version B 0 , are associated with each other through a constant factor k UU 0.4665 mentioned in Section 3 . The a factor has two ramifications: (II) If a number of queries q 1 , q 2 , ... , q n are executed, there will be n independent values of a : a 6. Seeking the best: looking beyond the current versions
We now strive to identify the better version between version A and version B (or its equivalent version B sion VSU T q . Applying the transpose to the formulas (1) and (2) in Section 5.1 , we have: uct with column vectors in U ; we then adjust this transformed query vector q formed query vector and all the k -dimensional document vectors (column vectors in V cated on the same unit hypersphere, due to normalization. Here we see that S serves as a re-scaling factor between the query vector and each of the compared document vectors.
 mance) has been extracted by the SVD process and is now distributed along the minor ( r k ) dimensions, whose subsequent removal clears away much of the noise. We see here that the importance of a particular in the S -neutral version we scale down the prominent dimensions and scale up the minor dimensions to the indicate a version where S x is applicable):
Since these alternative query methods rescale the singular values that remain intact in the standard query question.
 7. Experimental results on TREC data sets 7.1. Description of the experiments
To test the validity of the ideas presented in this paper, we chose to use the TREC-4 data set CD ordered from the http://trec.nist.gov/ website. In our experiments, we randomly chose 5305 documents from this data stemming, we used the method available at http://www.tartarus.org/~martin/PorterStemmer/ ; for stop words, we used the word list available at http://www.lextek.com/manuals/onix/stopwords1.html . Normalization was term-by-document matrix was of dimension 16,571 5305 and was determined to have a full rank of 5305 through the SVD process.
 tiple queries), it refers to this value of T (or the arithmetic average of T over the multiple queries). 7.2. Results of the experiments
Table 5 summarizes the experimental result for version B, version A and lexical match. The data shown in ues (0.6814 for version B and 0.5718 for version A) at different dimensions (620 for version B and 540 for gence towards the optimum averaged result in that version. In Table 5 a, the row where Dim = 5305 gives original rank, i.e. when no dimensional reduction is performed; the row where Dim = 620 gives the optimal performance of 0.6814 for version B (which proves to be the same as version B Dim = 540 gave the optimal result of 0.5718 for version A. The interesting fact here is that although both approach than version A.
 Table 6 summarizes the experimental result for standard version B along with non-standard versions using
SVR at the determined optimal dimension of 620 for version B. The data shown in this table were averaged over 20 queries. Table 6 a shows that, through applying the SVR technique, version D factor S _ exp = 1.35) gave the optimal averaged result of 0.7215. The improvement ratio of version D
D improvement ratio of 5.9% over averaged results was moderate, the improvement effect has been quite con-sistent among all tested queries.

In order to seek the relationship (if any) between the optimum value of x in S data set, we have randomly selected certain numbers of documents among the given 5305 documents and performed a series of tests whose results are shown in Table 7 . Notice that as the size of the data sets increases (column 1), the optimum reduced dimension also increases (column 2). Interestingly, as a result, the optimum value of x in S x decreases (column 4). However, notice that the decrease of the optimum values of x in S x is not associated with the decrease of improvement ratio: the improvement ratio of using SVR over using the conventional LSI technique alone is between 5.6% and 6.1% across the whole range of data sets (column 6). This might suggest that as data sets get larger, raising the power of x in S and more efficient, so that to achieve the maximum performance, a lesser degree of raise is needed with a larger data set than is the case with a smaller data set. However, the evidence shown here is rudimentary and explorative in nature; both theoretical and empirical research need to be done to find out more about this interesting possibility.
 7.3. Experimental results on three TREC subsets three TREC subsets using the same approach as described in Sections 7.1 and 7.2 : Congressional Records,
Financial Times, and Federal Register. For each subset, we randomly selected 20 standard queries and the tively: 13966x5189, 15129x4771, 14582x5073. The optimal dimensions reached for version B(B as S _ exp continues to increase beyond the optimal value. The improvement ratios of SVR over the conven-tional LSI method are, respectively: Clearly, results on individual subset confirms the result on the superset as described in Section 7.2 . 8. Comparison between SVR and IRR
In this section, we compare SVR with another scaling technique (iterative residual rescaling, or IRR) reported in [1,2] . Ref. [1] claims that IRR performs up to 17.8% higher than does the conventional SVD method in terms of average precision.

Just like SVD-based LSI, IRR may be used as the underlying technique for text retrieval in the vector space. The main difference between SVD and IRR lies in the process where basis vectors are created. In any semantic space representing a collection of documents, there are some so-called outlier document vectors which differ significantly from other non-outlier documents. Ref. [1] argues that while in SVD those few outlier documents are not well-represented, IRR has been able to provide adequate compensation for them by scaling. In IRR, basis vectors are created one by one. First, an initial basis vector, representing the whole document set, is created; then the effect of this basis vector is cleaned away from all the other document vectors, giving rise to residual vectors . Through scaling, the longer residual vectors (especially the outlier vectors) become longer and the shorter ones become shorter. Con-the outlier vectors) than in the case of SVD. This is how IRR provides compensation for outlier vectors by scaling.

Comparing SVR and IRR, we notice the following: the residual vectors are scaled. 2. IRR is a technique independent of SVD; yet SVR is a technique built on top of SVD. times, the number of which is determined by the number of desired basis vectors; each time, the scaling of residual vectors produces the next basis vector.

To compare the effectiveness of IRR with SVR, we executed some experiments using the same data set as described in Section 7 . Scaling factors from 1 to 10 were examined in increments of 1 for the IRR algorithm, which is in line with [1] .In Table 9 , note that IRR achieves the best averaged result over 20 queries at Dim = 520. This best averaged result of IRR (0.6973) is 2.3% better than that of ver-sion B (0.6814), as shown in Table 10 . On the other hand, SVR achieves the best averaged result of 0.7215, which shows an improvement of 3.5% over the technique of IRR. Now let us look at the result in detail: 1. Comparing the 2nd column and the 3rd column in Table 10 , we see that IRR performs better than version
B in 17 of the total 20 queries. Only in queries #05, #9, and #18, does IRR perform worse than version B. 2. Comparing the 3rd column and the 4th column in Table 10 , we see that SVR performs better than IRR in 18 of the total 20 queries. Only in topics #06 and #16, does SVR perform worse than IRR. We also used the P -value = 0.009).

Based on the above analysis, we see that both in averaged results and in individual results, SVR performs better than IRR. The experiments also confirm that IRR does perform better than the best LSI query method of version B, as has been reported in [1] .
 9. A conceptual explanation on singular value rescaling
In this section, we provide a conceptual explanation on the effectiveness of the singular value rescaling technique.

Fig. 5 shows the SVD of a 2 2 matrix, which basically illustrates the geometric fact that the image of the unit sphere under any t d matrix A is a hyperellipse [23] . In fact, assuming that A 2 R has full rank d , from we obtain or where S is a diagonal matrix with singular values s 1 , s We see that Fig. 5 represents a special case of the above equation where i =2.

The effectiveness of the singular value rescaling applied in addition to conventional LSI may be conceptu-singular value the z -semi-axis. LSI works by projecting this three-dimensional ellipsoid along its weakest dimension of z , producing a two-dimensional shape represented by the ellipse in the middle figure. Empiri-which is executed on the original data model.

We contend that we can utilize more of the SVD result than just eliminate the noise on the minor dimen-ium dimension may be properly adjusted by an exponential factor of S _ exp to the new value of r the dimension-reduced-only model of version B.
 the optimal value of S _ exp , there are five possible cases: (I) S _ exp &gt; 1 Then, r 1 =( r 0 ) S _ exp &gt;( r 0 ) (II) S _ exp = 1 Then, r 1 =( r 0 ) S _ exp =( r 0 ) 1 = r (III) 0 &lt; S _ exp &lt; 1 Then, r 0 =( r 0 ) 1 &gt;( r 0 (V) S _ exp &lt; 0 Then, r 1 =( r 0 ) S _ exp &lt;( r 0 ) cussion is based on three dimensions; however, the same argument can be applied to as many dimensions as we between medium dimensions and major dimensions in a scaled-up situation is just like the one between dimen-sion y and dimension x here. The advantage of using a three-dimensional example is that it provides a con-venient visualization.

It is worth noting here an interesting technique called ADE (approximate dimension equalization) [17] , which uses dimension weights to combine three different techniques: VSM (vector space model), LSI and
GVSM (generalized vector space model). ADE uses LSI by equalizing all the singular values in the dimension-computational time by avoiding computing singular values so that it can be easily scaled up when data set advantage over LSI in some cases is because it creatively combines the three underlying techniques through dimension weights, not because of the equalization of singular values, which should somehow bring down its performance but is nevertheless compensated by the other two underlying techniques. 10. Conclusion and future work
In this paper we identified and analyzed three standard query methods (version A, version B and version B the results of version A and version B is a factor of S 2 the dimension-reduced model, (ii) the retrieval results from version B and version B
Equivalency Principle is satisfied, and (iii) version B (B on standardized TREC data set confirmed the latter two findings.

Furthermore, some interesting non-standard versions of quering, through applying the novel technique of to the conventional LSI over (ii) using the conventional LSI alone is 5.9% according to our tests using the TREC data set. The discovery of singular value rescaling bears the practical significance that the current
LSI information retrieval techniques may be significantly improved by simply adopting a novel query method In the end, a conceptual explanation of the effectiveness of SVR is provided.

Finally, we also compared SVR with another scaling technique in text retrieval called iterative residual rescaling (IRR). Experiments on TREC data set show that SVR performs better than IRR. Acknowledgments
We would like to thank Xin Shao, from the Department of Statistics in Anhui University, located in the city of Hefei, China, for his contribution in carrying out some of the programming tasks between June 2006 and July 2007, when this paper was being revised.

References
