 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval  X  Query formulation General Terms: Performance, Experimentation Keywords: information retrieval, term dependence, lan-guage models
Phrase-based queries are known to perform effectively, es-pecially against large-scale and noisy text data such as typ-ically appear on the Web [9, 7, 2]. These methods can cap-ture term dependencies that appear in a query. Meanwhile, a relevance model is a probability distribution over terms that is estimated from the set of relevant documents to ad-dress important notions of synonymy and polysemy [5]. The relevance model is usually estimated with unigrams from the results of pseudo-relevance feedback, i.e., from the top-ranked documents retrieved in response to a query. The combination of phrase-based query structuring and query expansion via the relevance model is promising, because each model has its own advantages: phrase-based query struc-turing attempts to address problems with bag-of-words rep-resentations and the relevance model attempts to address problems with simple word matching. In this paper, we in-vestigate how query structuring with term dependence can improve the performance of query expansion via a relevance model. Some preliminary results can be found in the in-vestigations of our research group [8, 1]. In this paper, we attempt to examine the above point thoroughly.
Metzler and Croft developed a general, formal framework for modeling term dependencies via Markov random fields [7], and showed that the model is very effective in a variety of retrieval situations using the Indri platform [6]. Markov ran-dom fields (MRFs) are commonly used to model joint dis-tributions succinctly. In [7], the joint distribution P  X  ( Q, D ) over queries Q and documents D , parameterized by  X , was modeled using MRFs, and for ranking purposes the poste-rior P  X  ( D | Q ) was derived by the following ranking function, assuming a graph G that consists of a document node and query term nodes: P  X  ( D | Q ) r ank = Q = t 1 ...t n , C ( G )isthesetofcliquesinanMRFgraph G , f ( c ) is some real-valued feature function over clique val-ues, and  X  c is the weight given to that particular feature function. Three variants of the MRF model were assumed: (1) full-independence variant assumes that query terms are independent of each other; (2) sequential dependence variant assumes dependence between neighboring query terms; and model, considering special features of Japanese [1, 2]. The glfd+ model expresses the dependencies between query com-ponents on the basis of the full dependence . It also expresses the dependencies between constituent words within a query component on the basis of the sequential dependence .The two-stage term dependence model should be reasonable for other languages, if query components can be specified in a query, for example  X  X zone hole, human body X .
Lavrenko and Croft formulated relevance models that ex-plicitly incorporated relevance into the language modeling [5]. Following [8], we use the relevance models as a pseudo-relevance feedback function in the framework of inference network-based retrieval models, as briefly described in the following. Given an initial query Q orig , we retrieve a set of # docs fb documents and form a relevance model from them. We then form Q rm by wrapping the # combine op-erator of Indri [6], around the most likely # terms fb terms from the relevance model that are not stopwords. Finally, an expanded query is formed that has the following form: # weight (  X Q orig (1 . 0  X   X  ) Q rm ), where # weight indicates an Indri operator [6]. In this paper, we formulate Q orig us-ing the two-stage term dependence model described in Sec-tion 2 , instead of the usual full-independence ( fi )model.
We used a 100-gigabyte web document collection, NW100G-01 , which consisted of web documents gathered from the .jp domain and thus were mostly written in Japanese. The NW100G-01 was used in a series of NTCIR WEB task [4, 3, 10]. In the experiments described in the following, we only used the terms specified in the title field of each topic state-ment. All the topics were written in Japanese, and so we performed morphological analysis using the MeCab tool 1 to segment the title portion of the topic and to add POS tags. The definition of the title is different from the one used in a series of TREC, 2 for instance, in the following ways: (i)the title field gives 1 X 3 components that were delimited by commas; and (ii)each of these components is supposed to indicate a certain concept, and so it sometimes consists of a single word, but it may also consist of a compound word [4].
For training, we experimented using the glfd+ model with relevance model, as described in Section 3 ,overtherele-vance judgment data used in the NTCIR-3 WEB task [4], changing the weight  X  ,# docs fb and # terms fb . 3 For testing, we used the relevance judgment data that were used in the NTCIR-5 WEB task [10]. For the relevance model, we used the top-ranked 5 and 10 documents (# docs fb ), and 5, 10 and 20 terms (# terms fb ) for feedback. We used the optimized value of the weight  X  , which we obtained from training, cor-responding to each pair of (# docs fb ,# terms fb )above. The results are shown in Table 1 . In this table,  X  X vgPrec a  X  X n-dicates the mean average precision over all the 35 topics.  X %chg f  X  X nd X %chg t  X  were calculated on the bases of (i)each model without the relevance model (i.e., fi alone or glfd+ alone); and (ii)the fi model alone, respectively. As shown in this table, the glfd+ model alone worked 13% better than the fi model alone, as also reported in [2]. The combina-tion of the glfd+ model and the relevance model achieves 8 X 12% improvements over the glfd+ model alone. Combin-ing with the relevance model, the glfd+ model worked 9 X  15% better than the fi model under the same conditions of (# docs fb , # terms fb ). http://sourceforge.jp/projects/mecab/ . http://trec.nist.gov/ .
We also optimazed the parameters for the glfd+ model us-ing the NTCIR-3 WEB test collection, as described in [2].
