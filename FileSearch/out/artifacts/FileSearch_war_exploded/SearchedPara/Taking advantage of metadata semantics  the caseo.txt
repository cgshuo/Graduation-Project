 Olivier Motelet  X  Nelson Baloian  X  Jos X  A. Pino Abstract Learning objects (LOs) are pieces of educational material characterized with a valuable amount of information about their content and usage. This additional information is defined as a set of metadata generally following the IEEE LOM specification. This speci-fication also serves to characterize the relations existing between LOs. LOs whose relations are explicit are regarded as the nodes of a lesson graph. Link types and LO metadata con-stitute the lesson graph semantics. This article proposes to take advantage of lesson graph semantics using a context diffusion approach. It consists in diffusing the metadata-based pro-cesses along the edges of the lesson graph. This technique aims at coping with the metadata processing issues arising when some graph metadata are missing, incorrect, or incomplete. This article also presents a three-layer extensible framework for easing the use of context diffusion in a graph. As part of the framework, two original types of metadata processes are introduced. The first one takes advantage of the metadata attribute similarities between related LOs. The second one focuses on the lesson graph consistency. The framework and the application examples were implemented as an open-source Java library used in the lesson graph authoring tool LessonMapper2. During the lesson authoring process, we show that the framework can bring support not only for generating and validating metadata, but also for retrieving LOs.
 Keywords Learning object metadata  X  Lesson graph  X  Metadata processing  X  Metadata propagation  X  Learning object retrieval  X  Lesson authoring 1 Introduction Ascomputersupportedlearningbecameincreasinglypopular,theneedforqualitymultimedia material increased. However, quality computer-based learning material is hard and expensive cept of learning object (LO) is normally used to describe digital entities aiming at supporting learning/teaching. They are often annotated with metadata describing their characteristics. These metadata are known as learning object metadata (LOM).

Metadata of electronic documents are generally described with the Dublin Core (DC) specification [ 9 ] which includes mostly concrete and objective data such as authors, title, or granularity. They are definitely useful for describing educational resource content, but they lack the pedagogical aspects of the LO, such as its educational purpose, its intended learner profile, its difficulty or its interactivity type. In order to cope with educational concerns, various metadata sets were defined such as DC Educational extension [ 10 ], CANCORE [ 5 ], IMS Metadata [ 18 ], SCORM Metadata [ 36 ], and IEEE LOM [ 21 ]. Among these specifica-tions, IEEE LOM is commonly emphasized as the standard reference from which the other specifications derive.

IEEE LOM specifies about 60 different metadata that should be instantiated for a LO. For some of them, this is a straightforward task, e.g., author, technical format, or language. They the description, the coverage, the interactivity type, the semantic density, the difficulty, the intended end-user role, or the typical learning time of a LO, remain complex to instantiate automatically. Although many repositories for storing and retrieving LOs have been created in the last decade in order to allow LOs to be reused by as many people as possible [ 42 ], it has been observed that LO authors often do not instantiate the LOM values or use default and/or erroneous values if they are forced to instantiate them [ 6 , 30 ].
 Here is where intelligent systems play an important role in computer-based learning: since LOs are normally not used alone but rather in the context of a larger learning unit having a logical coherent structure, the implicit and explicit information contained in the structure can be extracted by automatic methods. As an example, Ochoa [ 32 ] suggests inferring meta-data values from the information available in the learning management system containing material for an e-learning course. Metadata like author-related information and educational context (course level, area, prerequisites, student level, etc.) may be generated. Hatala and Richards [ 16 ] propose a similar approach but they base their implementation on the standard SCORM and IMS Packaging.

Hatala and Richards [ 16 ] also suggest another approach for generating educational meta-data using the metadata semantics of LOs related with a parent X  X hild type of relationship inside a learning unit: missing educational LOM attributes can be suggested by defining a set of specific rules to define educational attributes that children objects may inherit from their parent objects, or the educational attributes that parent objects may accumu-late from their children. Brase [ 3 ] proposes a similar process in order to infer metadata values for the elements of a set of related LOs. Hatala and Richards [ 16 ] note that infer-ence rules valid for a certain community may not be valid for another. Thus the inference system should provide suggestions for metadata values during the metadata creation pro-cess rather than automatically instantiating metadata values. Nevertheless, the quality of the suggested metadata depends on the quality of the metadata of the neighboring LOs. Indeed, neighboring LOs having missing or incorrect metadata entail the processing of inference rules using missing or incorrect inputs. Such processing may result in erroneous data.
This article aims at generalizing the metadata generation approach based on the metadata semantics of the related LOs. First, it conceptualizes the processing of metadata semantics in a lesson graph composed of interrelated LOs. Second, it proposes a framework for coping with the problem of missing, incomplete or incorrect metadata when processing metadata semantics of a lesson graph. Next, this framework is used to support two innovative methods for processing metadata semantics: one method based on attribute similarities and the other one based on graph consistency. These methods were implemented on LessonMapper2, a lesson graph authoring tool. In this tool, they are used to facilitate not only LO metadata generation, but also LO metadata validation, and LO retrieval as described in this article. Finally, the scope and benefits of our model are discussed. 2 Metadata and lesson graph LOM has about 60 attributes describing technical, educational and general aspects of edu-cational resources. Attributes are identified by a list of names separated by slashes, e.g., general/title , where  X  X eneral X  is the category and  X  X itle X  the attribute name. Attributes can be classified in three groups: (1) predefined vocabulary values (e.g., easy and difficult are vocabulary values for the educational/difficulty attribute), (2) free text., (3) primitive e.g., a set of strings for general/keywords .

Many authors have chosen the graph as the most suitable way of structuring the learning material of computer-based learning systems whenever adaptability and flexibility of the learning material is required [ 12 , 26 ]. In a LOM-based lesson graph, the relation attribute of LOM is used to describe the links between the LOs of the lesson. Links are typed, e.g., introducesTo , isPartOf ,or exemplifiedBy . The set of links defines the edges of a lesson graph in which the nodes are the LOs. Such a graph is called LO graph . Figure 1 illustrates a LO graph. In this example, six LOs, labeled from L1 to L6 are part of a programming course with an object oriented language. L1 describes the problem (how to coordinate traffic lights in a crossroad) and L2 presents its implementation as a Java program. This problem aims to teach object instantiation in a program. L3 and L4 refer to documents defining object instantiation and the concept of constructors, respectively. L5 is a node inside the lesson graph whose learning material has not been defined yet. L6 is a LO of coarser granularity and acts as a container for L1 to L5 .

The literature about LO organization and sequencing contains various models [ 2 , 18 , 36 , 41 ]. Nevertheless, most of them can be described as LO graphs with specific edge seman-tics characterizing the required structure and sequencing strategy. Most used LOM relation types were often inspired by the DublinCore [ 9 ] specification. However, these relations were not originally designed for educational authoring, so they are not well suited to cope with the requirements of lesson authoring. We opted for another extended taxonomy proposed by Trigg [ 40 ]. Trigg X  X  taxonomy defines an extensive set of relations supporting narra-tion, that can be used to define a lesson graph. It defines semantical as well as rhetorical relations allowing the author to use those that better match the needs of the specific les-son. We asked a group of lecturers working in the Computer Science Department of our university to organize the content of the introductory computer programming course for freshmen as a lesson graph using a certain set of relations. We specifically left out the too generic relations (e.g., isFollowedBy ) since they give almost no information about a LO context in the graph. Based on their work, we empirically selected a subset of these rela-tions, emphasizing the semantical, rhetorical and organizational aspects of course authoring: introducesTo, assessedBy, supportedBy, abstractedBy, exemplifiedBy, comparableWith, back-groundFor, summarizedBy, resolvedBy, isPartOf . Each of these relations has an opposite: a relation from a LO a to another LO b implies an opposite relation between b and a (e.g., set. 3 Taking advantage of LO metadata 3.1 Classical approach Hatala and Richards [ 16 ]andBrase[ 3 ] present systems taking advantage of the semantics of a set of related LOs in order to infer possible values for some missing elements. These systems are based on a set of rules defining the way to combine the semantics of LOM and the nature of the links between the related LOs.

Figure 2 shows a conceptual model of such systems. This model is based on the metadata values and the relation semantics of a LO graph. The central component of the model are the influence rules . Influence rules express the impact of the graph semantics on the metadata values.
 Definition 3.1 (Influence rule) An influence rule is a triplet from A  X  T  X  I where A is the LOM attribute set, T is the relation type set, and I is the set of influence type.
For instance, [ 16 ] proposes the rule: When there is an ascendancy ( i.e., isPartOf) relation between two LOs, the value of the educational/intentedUserRole attribute of the parent may be suggested to the child . Such statement can be expressed as the influence rule: Definition 3.2 (Contextualized metadata value) Applying influence rules on the metadata of a certain LO results in special data called contextualized metadata values since they are inferred from the context of the LOs, i.e., the metadata values of the other LOs related to it and the semantics of the relations between them.

The contextualized metadata values (CMVs) proposed in [ 16 ] are suggestions of metadata values with a relevance level, e.g., Strong or Medium .In[ 3 ], the generated CMVs are instan-tiated as new metadata values. In these two systems, metadata processing result in different types of CMV. In fact, both systems have their own metadata processing strategy. We define CMV model as a metadata processing strategy. Defining a CMV model consists in specify-ing some influence rules for processing metadata and the nature of the CMVs resulting from applying those rules. 3.2 Diffusion-based approach trast to automatic metadata instantiation) is a difficult task which is generally ignored or made in a hurry. Frequently, authors leave  X  X y default X  values, which may not correspond to real values. Therefore, it is very probable that the LOs of a lesson graph suffer from missing, incomplete, and even incorrect metadata values.

In the existing approaches, the scope of the rules is generally limited to the metadata val-ues of the neighboring LOs. Therefore, computation of the rules may suffer from metadata lack. In [ 16 ], this problem is considered in the inheritance and accumulation rules since they are applied on the whole hierarchy of LOs instead of being limited to the direct parent or children. Nevertheless, this principle is not applied to all the rules. 3.2.1 Context diffusion In order to cope with the lack of metadata, [ 24 ] suggests to diffuse the metadata values over an untyped graph using fuzzy logic. We also propose a diffusion mechanism in order to deal with metadata lack, but unlike Marchiori X  X  work, we use the semantics of the graph. Thus, instead of a fixed propagation mechanism based on fuzzy logic, our propagation mechanism is based on the results of influence rules. In this process, the influence rules are applied not only to the metadata values of the neighboring LOs, but also recursively to the results of applying the rules to these neighboring nodes, i.e., the CMVs. We call this recursive process context diffusion . During context diffusion, influence rules are first applied to the existing values of the graph. Thus, a first set of CMVs is generated. Afterwards, the influence rules are applied to both the generated CMVs and the existing metadata values of the graph. Thus, a new set of CMVs is generated. This process is repeated iteratively until the generated CMVs finally converge; the update process should ensure this convergence.
The context diffusion process increases the scope of the influence rules to the metadata of the whole graph. Therefore, the impact of missing, incomplete, or incorrect metadata values is decreased compared with methods only taking into account a reduced neighborhood.
This process is non-monotonic because the CMVs for a same LO may change at each iteration of the context diffusion process. Defining such non-monotonic process over an existing inference rule system for the semantic web such as Jena [ 19 ] is a non-trivial task. Therefore, we preferred to use a simple push protocol based on update propagation: A mod-ification of the CMVs of a graph LO induces the CMV update of the neighbor LOs. If the updated CMVs are different from those of the previous iteration, the process is repeated to the neighboring nodes. Otherwise, the propagation stops for that node. Two reasons out of the diffusion process can entail the propagation of the CMVs of a LO: (1) a change in the existing LOM values of the LO and (2) a change in the relation semantics linking this LO to other LOs of the graph. 3.2.2 Conceptual model Figure 3 depicts a conceptual model for taking advantage of lesson graph semantics that takes into account context diffusion. Likewise the model of Fig. 2 , the main components are the metadata values and relation semantics of the LO graph, the influence rules and the resulting contextualized metadata values (CMVs). Nevertheless, this model aggregates a new core component: the context diffusion . As described above, the context diffusion is responsible for iteratively applying the influence rules on both existing metadata values and the already inferred CMVs until stabilization of the CMVs is reached.

The generated CMVs are not limited to support LOM generation: the next sections show that CMVs can also be used to facilitate metadata validation and LO graph consistency check-ing during authoring, and to enhance the retrieval of LOs. Nevertheless, these features may depend on the particular teaching style and strategy of the corresponding teacher community. to define influence rules suiting every teaching situation.

For that reason, teacher communities are also part of the model. First, they benefit from the support provided by using the CMVs when authoring and using the lesson graphs. Sec-ond, they customize the influence rules in order to adapt the system to their teaching style and preferences. 3.2.3 Framework In order to support this conceptual model, we introduce a metadata processing framework implementing our context diffusion approach. Figure 4 shows the three-layer structure of this framework. Each layer tries to facilitate the use of our context diffusion approach.
Sincetheperformanceandtheterminationpolicyofcontextdiffusionaredifficulttoimple-ment, the base of the framework, the bottom layer , consists of a generic propagation protocol ensuring such characteristics. It also establishes the scope of the update processes that can be applied to this propagation protocol. This scope defines a set of necessary properties with which the update processes should comply.

The middle layer concerns the implementation of different CMV models, i.e, different metadata processing strategies. Implementing a CMV model means to define the nature of the model CMVs and the update process of these CMVs. This update process must comply with the properties defined in the bottom layer. This layer also specifies the influence rule scope, i.e., the semantic and syntax of the influence rules. In practice, this layer is intended for researchers or engineers wishing to use the diffusion propagation system defined in this article with new type of influence rules and CMVs. The remaining of this article presents two CMV models.

The top layer deals with the definition of customized influence rules according to the semantic and syntax specified in the previous layer. This customization process is intended to teacher communities needing to adapt the metadata processing system to suit their spe-cific context. This customization process may be manual, e.g., new influence rules could be defined using a domain-specific language (DSL) or existing rules could be refined. Custom-ization may also be automatic, e.g., the system could analyze existing lesson graphs in order to deduce the necessary information for customizing the influence rules.

The next section presents the generic propagation protocol, i.e, the bottom layer of the framework. Next, two examples CMV models are introduced. Implementation of the middle and top layers are discussed for each of them. 4 Generic propagation protocol Ensuring the termination of a propagation process is an essential property in order to ease the use of a context diffusion approach. For this reason, the base layer of our framework is responsible for guaranteeing this property. This layer consists of defining the propagation protocol and the scope of the CMV update processes this protocol can support.

This section presents an implementation of this bottom layer that ensures performance and convergence of a context diffusion process in LO-based lesson graphs. First, the properties of CMV update processes that are necessary in order to define an efficient propagation protocol are defined. Then a propagation protocol sufficiently generic to match our needs of semantic processes is described. 4.1 CMV update process characteristics We define an update process as a set of update functions that takes several CMVs as inputs and produces a new CMV.
 The update of one LO j with another LO i is active if it induces a modification of the CMVs of j . Such an active update is noted i  X  j .Wenote j i  X  j the state of the LO j after being updated by i .

The update of one LO j with another LO i is passive if it does not induce modification of the CMVs of j . Such a passive update is noted i /  X  j .

We note i  X   X  j the transitive active update of the LO i on the LO j via a certain number of
We note i /  X   X  j the transitive passive update of the LO i on the LO j . If there is not i  X   X  j ,then i /  X   X  j .
 Definition 4.1 (Stable graph) A LO graph is stable with respect to a certain regular update process if for all LOs i and j , i /  X  j .
 Definition 4.2 (Regular update process) An update process is regular if it complies with the following properties: Stability For any LOs i and j , i /  X  j i  X  j .
 Acyclism For any LO i , i /  X   X  i .
 Asymmetry For any LOs i and j ,if i  X   X  j ,then j /  X   X  i .
 Cumulation For any LOs i , j ,and k ,if i /  X  j and k  X  j ,then i /  X  j k  X  j Initialization There is an initialization procedure for this update process such that any ini-tialized graph is stable.
 Max There is a function Max : CMV  X  CMV  X  CMV for this update process such that for any LOs i and j ,if Max ( i , j ) = i then j /  X   X  i .

Note that in a regular update process, a Max function can always be defined. Indeed, if a Max function cannot be defined, then there exist i and j such that Max ( i , j ) has given no result. This case means that i  X   X  j and j  X   X  i .However,byasymmetryif i  X   X  j then j  X   X  i and conversely. Thus, the previous case cannot occur.

In practice, the update processes developed in our institution and described Sects. 5.1 and and defining the Max functions is straightforward as shown in Theorems 5.1 and 5.3 . 4.2 Update propagation protocol The algorithm of Fig. 5 implements the propagation protocol described in 3.2.1 . This algo-rithm is based on retrieving the Max of the LOs having an update to propagate. This method enables the following theorem: Theorem 4.3 Regular-update propagation of k modification in a stable graph processes has order O ( m + n log n ) O ( Max ) with m the number of relations in the graph and n the number of LOs. Proof Each LO propagates its update only once. We prove this claim by contradiction:
If there is a LO i propagating its update twice, then i is picked up twice in the heap. Thus, i has been twice the Max from the heap. Let H 1 and H 2 be the state of the heap when i is popped for the first and second time, respectively. Let i 1 and i 2 be the states of i in H 1 i 2  X  H 2 ,itexistsaLO l such that l  X  i 1 otherwise i 1 should not reintegrate the heap.
According to the algorithm, all changes in the input graph are due to the propagation of updates registered in the heap. Thus, l was also in the heap. Transitively, it exists j 1  X  H 1 with (1). If j 1 = i 1 ,thenby(2), i 1  X   X  i 1 which is impossible by acyclism property of regular update processes. Therefore, a same LO cannot propagate its update twice. Each edge is visited only once Since each updated LO is propagated only once, the rela-tions between each LO and its respective neighbors are visited only once.
 To t a l C o s t In the Fibonacci Heap, inserting an element costs O ( Max ) . If this element is already in the data structure, the key associated to this element is increased since it was updated by the propagation protocol. This operation also costs O ( Max ) .Removingthe
Max element of the Fibonacci Heap costs O ( Max ) O ( log p ) ,where p is the number of element in the heap. In the worst case, p = n where n is the number of nodes of the graph.
Therefore, since the edges are visited only once, the worst case consists of inserting m times in the Fibonacci Heap with m being the number of edges. Since each node dif-fuses its update only once, the Max of the Fibonacci Heap is removed n times at worst. Consequently, the total cost of the algorithm has order O ( m + n log n ) O ( Max ) .
Note that since the update propagation algorithm depends on O ( Max ) , regular update processes should involve Max functions of low cost. In practice, the Max functions of the update processes developed in our institution and described Sects. 5.1 and 5.2 are based on decimal comparison ( O ( 1 ) ) or set comparison ( O ( set length ) ).
 Theorem 4.4 Regular-update propagation results in a stable graph.
 Proof If the graph resulting from a regular update process is not stable, then there exist i and j such that i  X  j . Since the graph was stable before the update propagation, there was i (2). If (1) occurs, then according to the propagation protocol, the i after has propagated its tionpropertyofregularupdateprocesses.If(1)doesnotoccurbut(2)does,thenbycumulation Consequently, the graph is stable. 4.3 Avoiding propagation side-effect In practice, our propagation system may present an undesirable side-effect when there are decreasing metadata values according to the Max function. Indeed, consider the active prop-agation i  X  j .Let i new be a decreasing value for i such that j i  X  j  X  i new . The memory of the old i value in the CMV of j ( j i  X  j ) may be inconvenient, e.g., if the old i value was incorrect and i new corrects it, it is not acceptable to have the CMV of i modifiedbyaCMV deriving from the old value of i .

In order to cope with this problem, the update process implementation must include the following two rules. First , the update process of a node should not take into account the neighboring CMVs deriving from this node. Applying this rule to our example, we have j lism property of regular update processes. Second , update processes should always take into account all the neighboring CMVs and the existing value of the updated node. Applying this rule to our example, when i new is assigned for i , this new value can update j whereas there should be i new /  X  j i  X  j by asymmetry of regular update processes applied to j i  X  j  X  i new . Therefore, the value of j can reflect the changes of i . In fact this property is natural since j derived from i . Moreover, the asymmetry property remains respected since the first rule forbids j i  X  j /  X  i new . 5 CMV model examples This section describes two implementations of the second and third layer of our framework. In the first implementation, similarities among the attribute values of graph LOs are used to generate suggestions for the missing metadata value of the LOs. In the second one, the graph consistency is analyzed in order to generate restrictions for some of the metadata values a LO should have in order to be consistent with the semantics linking it with the remaining graphs. For both proposals, this section defines (a) the scope of the influence rules and a language to specify them, (b) the nature of the CMVs, (c) a regular update process for these CMVs, (d) an influence rule customization strategy. 5.1 Attribute similarities and value suggestion As stated in [ 16 ], graph semantic analysis may be used to identify similarities between LOM attribute values of related LOs. For instance, in the graph of Fig. 6 ,since L1 introduces L3 we may expect that the general/keyword attribute of L1 and the general/key-word attribute of L3 share some values. In this particular case, the values of this attribute are { instantiation,object,method }for L1 . Therefore it seems reasonable to expect that the general/keyword of L3 contains some of the values instantiation,object,new }. 5.1.1 Influence rule scope relation type X  couple according to the use context. Weighted values are already used in the term classification domain [ 39 , 34 ]. We propose to apply them to the LO graph domain. In our case study, we analyze a repository of lesson graphs (containing about 170 LOs) developed then we found out that there is a probability 0.54 a certain value of the general/key-word attribute of L belongs to the general/keyword attribute of L . In order to get such a value, all the pairs of repository LOs having an introducesTo relation between them are taken into account. Then we calculate the mean of the probabilities where L introduces to L and k is a possible value for the general/keyword attribute. This computation is done on the stemmed version of the attribute values, i.e., their morpho-logical root, in order to avoid common spelling problem (e.g., car and cars have the same stemmed value).

Figure 7 is a reduced view of the lesson graph of Fig. 1 showing the probabilities of same values between neighboring nodes calculated on our corpus for the general/keyword attribute.
 In this application of our conceptual model, influence rules are called suggestion rules . Suggestion rules are functions f : A  X  T  X  X  0 , 1 ] where A is the set of LOM attributes and T is the set of relation types.

According to the weights depicted in Fig. 7 , some values for f are, e.g., 5.1.2 CMV nature It is possible to generate some CMVs called suggestions for the LOs of the lesson graph using the rules introduced above. A suggestion is a set { (v, w(v)) : v  X  V a } associating weights w(v) to all the possible values V a for a certain LOM attribute a .

The weight is 0 when the value is not at all appropriate for the LO, while it is 1 when it describes it perfectly. At the beginning of the context diffusion process, we set w(v) = 0for all possible values v for the a attribute except for the existing values of the attribute which have a weight 1. 5.1.3 Update process Consider an attribute a and let V a be the set of possible values for a . Consider also two LOs L and L , and a relationship of type t connecting L with L as depicted in Fig. 8 .Let for the a attribute.

The suggestion update of L with regards to the suggestions of L consists of replacing the suggestions of L with Theorem 5.1 The suggestion update process is regular.
 Proof Consider a  X  A and v  X  V a .Let p ij be the influence rule p ( a , t ij ) where t ij is the of a for the LO i .If i  X  j , according to the definition of the suggestion update process then p ij  X  w i &gt;w j . The suggestion diffusion process complies with the following properties: Stability i /  X  j i  X  j since p ij  X  w i  X  p ij  X  w i .
 Acyclism i /  X   X  i since from i to i ( p )  X  w i  X  w i for all p  X  X  0 , 1 ] .
 Asymmetry i  X   X  j  X  j /  X   X  i since if from i to j  X  w i &gt;w j ,then from j to i  X  w j  X  w i because p ij  X  w i &lt; p kj  X  w k because w j &lt; p kj  X  w k .
 Initialization By initializing all weights with 0, the graph is stable since for any i and j , p ij  X  w i = 0  X  w j = 0.
 Therefore, the suggestion update process is regular. 5.1.4 Influence rule customization Suggestion rules customization can be mostly automatic. For instance, analyzing authored lesson graphs, it is possible to calculate the probability that an attribute value is repeated between two related LOs.
In order to suit the teaching style of a particular community, this analysis should be per-formed locally. A strategy consists, e.g., in analyzing each lesson graphs added or updated in the local repository used by the community. Nevertheless, this strategy only works if the analyzed repository contains enough lesson graphs to extract statistically significant prob-abilities. Therefore, some default standard probabilities should be taken into when there is insufficient data. 5.2 Graph consistency and value restriction Let us consider the lesson graph of Fig. 9 . It is plausible to think that for a certain teacher community, the fact that L1 introduces L3 may imply that the content of the LO L1 is simpler than the one of L3 (otherwise the lesson graph would not be consistent). In terms of LOM semantics, it means the value of the LOM attribute educational/difficulty of L1 should be lower or equal to the educational/difficulty of L3 .If L1 introduces more than one LO, its level of educational/difficulty should be compatible with (lower than) each element it introduces. Since the value of educational/difficulty is associated to a predefined vocabulary, we can define an order among the terms of this vocabulary to test the consistency.

Similarly, it seems reasonable to imagine that for a certain teacher community, since L6 is a container for L1 and L3 , the content coverage of L6 , i.e., the extent or scope of the content of this LO, should include the content coverage of its children. In terms of LOM semantics, it means the value of the general/coverage attribute of L6 should be a superset for all the general/coverage of its children (including L1 and L3 ). 5.2.1 Influence rule scope The previous assumptions about the consistency of LOM attribute values are special influ-ence rules called restriction rules . When defining restriction rules, we distinguish between two kinds of LOM attributes: 1. the attributes dealing with single value whichareorderedintheLOMspecificationorcan 2. the attributes which have a setofelements as value (e.g., general/coverage or The LOM specification makes such distinction.

When dealing with metadata attributes having a single element as value, the restriction rules are functions taking a metadata attribute name and a relation name as parameter, and returning an element of the set O ={ X  ,  X } X { max , min , V } where V are all the possible val-ues for the LOM attributes. For example, the restriction rule for the educational/dif-ficulty attribute and the introducesTo relation is defined as  X  max v i where v i are the educational/difficulty values of the LOs related with the introducesTo relation.
Table 1 shows other examples of restriction rules. Note that the rules can be modified in order to adapt them to other educational contexts.

Finally, we define the restriction rules as functions  X  : A  X  T  X  O  X  O s where O = attributes.

Therefore, the restriction rules for the propositions done before have the following values: 5.2.2 CMV nature Applying restriction rules to the LO graph results in a set of special CMVs called restriction intervals . A restriction interval for a certain attribute a reduces the range of possible value for a .
 the lower and upper bounds for r a ( L ) , respectively, are elements of V a for single-element
We detect an inconsistency when the value that the user set for the a attribute does not belong to this interval. Another source of anomaly is when the interval becomes incoher-r
At the beginning of the propagation process, the restriction interval for the a attribute and the L LO is initialized to the whole interval of the possible values for a , i.e., [  X  X  X  , + X  ] for single-element values or [  X  , V a ] for element set values where V a is the power set of all the values for a . If the user has set a value for the a attribute, the interval reduces to [ a then the propagation process excludes it. 5.2.3 Update process Figure 10 depicts a step of the propagation process: the changes in the restriction interval for Restriction rules are applied to the inverse of the relation used for propagating the changes: in this case, the relation of type t connecting the L LO (receiving the update notification) to L / 0 (propagating changes) is used. The update process of a restriction rule considers the n + 1 LOs to which L is connected with relations of type t .ThoseLOsaredenoted L i with 0  X  i  X  n ,where n is a natural number.

If the t relation type imposes a restriction rule  X  max for the values of the a attribute (i.e.,  X ( and an upper boundary equal to the maximum of the upper boundaries of the restriction inter-vals of the LOs L i (may lower the upper boundary of r a ( L ) ). The other restriction update functions follow the same principles as defined below.

Consider an attribute a and V a the set of possible values for a . Consider also a LO L and asetofLO L i , and a relationship of type t connecting L with the L i s. If the attribute a has single-element values, then the restriction update process consists of the functions defined in Table 2 . If the attribute a has element set values, then the restriction update process consists of the functions defined in Table 3 .

The intersection between two intervals is defined as We define the min and max functions for the element set values a and b as and Property 5.2 There are three possible causes for a restriction interval to become empty or a composition error to be thrown: (1) there is an incorrect value for the metadata of propagated LO, and/or (2) there are some incorrect relations the LOs of the graph, and/or (3) there is a contradiction between two restriction rules that should be resolved.
 Theorem 5.3 The restriction update process is regular.
 Proof The restriction update process applies on two independent attribute types: single-update process as described in Property 5.2 , the restriction update consists in four indepen-dent processes. Therefore, restriction update process is regular because those four processes are regular as it can be easily shown with a method similar to the proof of Theorem 5.1 .The interested reader can find the complete proof in [ 28 , p. 111]. 5.2.4 Influence rule customization Table 1 shows an example of restriction rules defined in our sample repository. Restriction rules can be defined or existing restriction rules can be refined in order to suit other teaching communities. Rules are defined in a domain-specific language following the grammar shown in Fig. 11 . 5.3 Implementation The framework presented in this article is implemented as an open source Java library avail-able at [ 7 ]. This library is adaptable to any metadata type organized as graphs. The library implements the update propagation algorithm based on Fibonacci heap and the CMV models previously described. It also includes the implementation of the two CMV model applications defined in this article. 6 Framework benefits during lesson authoring This section presents the use of our framework into a lesson graph authoring tool, LessonM-apper2. First, LessonMapper2 is introduced. Next, the framework application for supporting the generation and validation of LO metadata during lesson authoring is discussed. Finally, a mechanism using the framework in order to enhance LO retrieval during lesson authoring is briefly presented. 6.1 LessonMapper2 LessonMapper2 [ 20 ] is a lesson graph authoring tool. In LessonMapper2, each node of the graph is a LO associated with its set of metadata. While LO metadata generation is gener-ally separated from the lesson authoring activity, LessonMapper2 integrates the instantiation of LO metadata into the lesson authoring process. In particular, the metadata instantiation is integrated into the lesson graph authoring interface. Figure 12 showssuchanintegra-tion.

LessonMapper2 applies the framework described in this article on the IEEE LOM metada-associated with each LOM attribute [ 22 ]. Each time LessonMapper2 is launched, it con-nects to the community repository defined by the user. This connection permits to update the suggestion and restriction rules with the ones being defined at the teaching community level. 6.2 Supporting LOM generation and validation during lesson authoring This subsection presents examples of use of our framework in order to facilitate LOM gen-eration and validation during lesson authoring. 6.2.1 Supporting LOM generation Suggestions and restrictions defined with our framework are used to facilitate metadata gen-eration. Figure 13 shows the semantic density of the LOs L6 , L1 ,and L3 . In this example, the user asked for suggestions and restrictions for the educational/semanticDensity attribute of L1 . Consider that the system has been initialized with the restriction rule Therefore, the metadata diffusion framework infers that the semantic density of L1 should be less or equal to the semantic density of L3 .

LessonMapper2 was also initialized with a set of suggestion probabilities derived from usage analysis in a teaching community of our University. Therefore, the system can suggest some possible values for instantiating the semantic density of L1 : (1) medium density, i.e., the value of the semantic density of L6 , (2) low density, i.e., the semantic density of L3 , and (3) very high density, i.e., the semantic density of other LOs not displayed in Fig. 13 but being also part of the lesson and indirectly related to L1 . Suggestions are sized according to their relevance: Suggestions having a high probability of being chosen are shown larger than the other with less probability.

The suggested values that do not comply with the inferred restrictions, are painted in a different color from the color assigned to the values that do. In LessonMapper2, simple drag and drop enables to adopt one of the suggested values if the user considers it as the most appropriate.
 Initial case study In order to verify the suggestion accuracy, we performed two preliminary ing with our system.
 The statistical analysis was based on 170 LOs organized as a large graph developed in our University. Each LO of the graph was studied independently. First, the suggestions for the selected LO were calculated as if it had no instantiated metadata value. Then, the generated suggestions were compared to the instantiated values in order to log the expected sugges-tions, i.e. those matching with the instantiated values, and also the unexpected suggestions, i.e. those not matching with the instantiated values.

For each attribute, we investigated the differences between the distribution of weights for the expected suggestions and for the unexpected suggestions. Figure 14 shows these distri-butions. The data are displayed as boxplots since their juxtaposition permits to investigate the differences between the data sets without any statistical assumption on data distribution [ 25 ].

We observe that the suggestions generated for tangible attributes, such as keyword or coverage , are statistically accurate: the expected suggestions have high weights and the unexpected suggestions have low weights. On the opposite, the suggestions generated for some subjective attributes such as interactivityType or learningResource-Type are not accurate: the weight does not appear correlated with the fact that a suggestion is expected or not. Thus, it is useless to propose such suggestions to the users. However, this behavior does not apply to all subjective attributes. For example, Fig. 14 shows that suggestions for the attributes semanticDensity or difficulty may be sufficiently accurate to be useful for users. Nevertheless, large-scale experiments are needed in order to generalize such results.

We performed a second experiment based on the observation of 11 users working with our system. After a brief introduction to LessonMapper2 and its features X  X ncluding a demon-stration of suggestion usage X  X ach user had to build a LO graph and instantiate the metadata of their LOs. We observed that three users never took benefits of the suggestions in order to instantiate the metadata even when the suggestions were fitting. This phenomenon is likely to be related to an HCI issue. Nevertheless more experiments are needed in order to identify the phenomenon causes. 6.2.2 Supporting LOM validation The validity of the metadata of a certain educational resource has to be ensured in order to facilitate the access to this resource. Valid metadata should satisfy a minimum level of completeness and correctness.

The analysis of completeness of LOM simply consists of checking the number of instan-tiated attributes. Complete LOM have all their attribute instantiated. Correctness evaluation is complex because it deals with the semantics of the metadata values. Available methods focus on determining if a metadata is in correct. They are generally based on comparing the instantiated value with the results of automatic instantiation systems or by checking the con-sistency of the LOM attributes inside the same LO [ 33 , 38 ]. In the context of lesson authoring based on LO graph, we propose a complementary approach based on the restriction inferred with our framework: a LOM value not complying with one of the inferred restrictions is tagged as incorrect.

LOM validation is integrated into the lesson authoring process as a visual tag decorating the graph LOs. As shown in Fig. 15 , in LessonMapper2, all the learning material items of the graph are decorated with tricolor bars representing the proportion of invalid, undefined, and not invalid elements for the LOM attributes of each learning material item. Invalid elements hold values not satisfying the restrictions deduced by the system. Undefined elements have not yet any value assigned. Finally, not invalid elements hold values successfully passing both tests of completeness and incorrectness. 6.3 Using LOM for enhancing LO retrieval 6.3.1 Querying a repository from inside the lesson graph Standard querying is done by searching matching metadata and keywords. To describe L5 of Fig. 1 , we could for example choose  X  X onstructors overloading X  and retrieve the LOs with metadata related to it. This is the approach taken by most information retrieval engines like Lucene [ 23 ].

Querying a LO repository can be done using a purely graphical approach. For instance, consider node L5 of Fig. 1 . This node is not associated with an existing document, instead it is a query node : A query reflecting the need for a LO with certain characteristics is thus expressed as a vertex in the lesson graph. In Fig. 1 , the LOs satisfying the query node L5 are examples of the concepts introduced by L4 . 6.3.2 Using the lesson graph to evaluate potential results Since authoring a lesson consists of adding nodes to the lesson graph, it is natural to integrate this task with the LO retrieval process and to use the implicit information associated with the new node position. This can be seen as associating a context extracted from the graph to the traditional term or metadata search. The framework presented in this article can be used to implement such approach. For instance, in [ 29 ], we propose to modify the ranking of retrieved objects as produced by a Lucene search process with the results of classifiers designed to take the neighbor graph into account.

These new classifiers are based on the suggestions and restrictions produced by the frame-work. When searching a repository, the LOs that comply with the value restrictions associated with the query should be promoted. To implement this idea, a score is computed for each LO as the scores are set to 1.

Suggestions can also serve the ranking process: To estimate the similarity between a query node q and a node e from the repository, we can measure how similar the nodes X  suggestions are. We propose to adapt the traditional cosine measure for this task: where v scans the values of the attribute att and w q (v) and w e (v) are the weights associated with v in the suggestions of q and e , respectively. This measure quantifies the intuition that the value suggestions represent the relation of the node q and e with their neighbors in their respective graphs. In other words, these values summarize the context of the nodes.
The new classifiers obtained using the suggestions and restrictions generated by the frame-work are then combined. Combination is automatically performed by the RankBoost algo-rithm [ 13 ], a machine learning algorithm that searches for an optimal combination of several weak or uncertain classifiers.

Using RankBoost permits to automatically combine our approach with other retrieval methods. For example, in the context of conceptual-graph-based queries, [ 15 ] proposes to count the transformations separating the conceptual graph of the query with the conceptual graph of the result in order to rank the results. Our approach does not deal with this conceptual graph aspect. Consequently, the two approaches may be complementary and could be easily combined with RankBoost. 6.3.3 Experiments A LO repository was implemented within our institution and populated with 170 LOs about a single topic: An introductory Java course. This repository contains fine grained LOs, each corresponding to teaching/learning material for about 5 min. In contrast with the available repositories, relation semantics linking repository LOs are based on the proposal introduced in Sect. 2 (see [ 27 ] for getting access to a repository snapshot).

Eleven teachers of Java Programming, not involved in the project presented in this article, were asked to complete four different lesson graphs about object instantiation and method call . The proposed graphs were purposely incomplete in order to motivate the teachers to complete them. For each situation, they were asked to complete the corresponding lesson graph with two new LOs of their choice. The teachers had to thoroughly describe the required LOs so that the interviewer could identify which repository LO matched the teacher X  X  intent. The matching LOs were not communicated to the teachers. Instead of that, they were asked to search for them in the repository using common keyword queries and locating the expected material inside the graphs, i.e., by defining query nodes . Teachers knew that keyword que-ries were used to search the metadata of the available LOs of the repository and not their content. Eventually, query terms referring to some special vocabulary values were defined in natural language and then replaced by the interviewer with the proper vocabulary value. These experiments gave rise to 88 test cases, including keyword query and position in lesson graph along with the relevant results (see [ 29 ] for details about the experiments). Result analysis Using the queries (composed of a graph with a query node and of a set of keywords), we evaluated two different systems: first, we used only keyword queries and the Lucene IR system. Lucene indexed the metadata of the LOs contained in the reposi-tory. During the preprocessing, metadata values were stemmed and tags were removed. Only metadata were indexed since most of the educational resources of the used repository were multimedia documents with proprietary format where relevant information is difficult to access. Similarly, keyword queries are stemmed.

In the next step, we used the classifiers based on the restrictions and suggestions produced by the framework. Rankboost served to combine these classifiers together with the Lucene including Lucene. We trained and tested RankBoost using a fourfold cross-validation. Each fold corresponded to one of the proposed graphs of the experiment. When testing onefold, the data of the three others were used for training.

Precision-recall analysis for both systems shows that the RankBoost combination of the framework-based classifiers outperforms significantly Lucene alone. Table 4 summarizes tests confirming the statistical significance of this difference being over 4% of precision gain.
 Analyzing the way the various classifiers are combined, it is possible to identify which LOM attributes contribute to enhance retrieval: We observe that the interactivity-Level , interactivityType and semanticDensity classifiers have been singled out by Rankboost as operating on the most helpful attributes.

We could not experiment with other publicly available repositories because they lack semantically rich relations between LOs. Therefore, future work will consist of developing a larger and more heterogeneous repository in order to prove that our approach is scalable. 7Conclusion This article presented a context diffusion approach for taking advantage of the metadata semantics inside a lesson graph based on LOs. It consists in the diffusion of metadata-based processes along the edges of a lesson graph. This diffusion method prevents missing and incomplete metadata from blocking these processes. Moreover, it reduces the impact of incorrect metadata values on the final result of processing LOM since all the available metadata values of the graph can be taken into account in this process.

In order to facilitate the use of this approach, this article introduced a three-layer frame-work organized by technical difficulty. This organization enables the framework to be adapted to new uses not only by researchers or engineers, but also by final users.

In the context of lesson graphs, two types of metadata processes were proposed: one for generating weighted probable LOM values and another for generating restrictions about LOM value scope. Each type of processes can be customized by the end-users. In the first case, processing LOM is configured by a set of probabilities that can be deduced from the analysis of an existing repository of LO graphs. In the second case, rules are defined in a domain-specific language. Both systems have been applied to the lesson authoring context. They facilitate LOM generation and validation, and also enhance LO retrieval.

LOM processing deals with lesson semantics. Therefore, it is strongly related to the teach-ing style of the teacher community using it. For that reason, LOM processing needs to be adaptable in order to suit this teaching style. Since our framework separates the diffusion process from the rule definition, rules can be tailored without having to modify the diffusion process. This feature opens the opportunity for teachers to define the rules themselves. In a visual language. As a future work, we plan to translate the rules defined in this article into such a representation.
Moreover, the framework provides a basic propagation protocol that ensures convergence and minimal performance for the diffusion. In particular, this article formally defined the characteristics of the metadata processes for which the protocol can be applied. This set of characteristics allows the definition of new types of metadata semantic processes without having to ensure convergence: ensuring these characteristics is enough.

Future work will focus on new applications of the framework. In particular, metadata pro-cessing methods in order to ease lesson design are studied. Since the proposed framework can be used with any type of metadata for which a graph can be defined, this work will also focus on other metadata than LOM such as metadata logging the interactions between the teacher, learners and LOs.

While the propagation protocol proposed in this article is generic enough to support our needs, some metadata-based processes may not enter this scope. For such processes, the base layer of the framework should be adapted. For instance, we plan to define a new prop-agation protocol whose termination occurs not only after convergence but also whenever cycles emerge during the diffusion. We also plan to consider those cycles in order to deduce semantic properties about the graph elements.
 References Author Biographies
