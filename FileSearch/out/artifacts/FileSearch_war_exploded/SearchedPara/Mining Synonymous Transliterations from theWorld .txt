 CHUNG-CHIAN HSU and CHIEN-HSING CHEN National Yunlin University of Science and Technology 1. INTRODUCTION A foreign proper name is usually translated to a word in a local language ac-cording to their phonetic similarity in the two languages. Such translated words are referred to as transliterations . With many different translators working without a common standard, a foreign name is often transliterated into different words, referred to as synonymous transliterations , especially person names and geographical names. For example, former Soviet Presi-dent Gorbachev is translated into several different Chinese transliterations including  X  X  X  X  (Gorbachev; ge ba qi fu),  X   X  X  X  (ge ba zhuo fu), and  X  X  X  X  X  X  (ge er ba qiao fu). The Australia city Sydney has transliterations for the Romanization of Chinese transliterations.
 First, they lead to confusion when a pers on reads articles which contain differ-ent transliterations. The person may wonder whether they refer to the same entity. For instance,  X  X  X  X  (xue li) and  X   X  (xi ni) of  X  X ydney X  are completely different Chinese words with different pronunciations although the two sound similar to some extent. Without referring to its foreign name or context in-formation, a person is hardly able to recognize the fact that they both indeed represent the same city. Second, a similar situation happens in communicat-ing with other people. They may wonder whether they are talking about the same target. More importantly, search engines will generate incomplete search results when a person uses one of the transliterations as the query keyword. Consequently, some important information may be missed. For example, us-keyword cannot retrieve the Web pages that use  X  X  X  X  X  X  (ge er ba qiao fu) instead as its transliteration of  X  X orbachev X . The former transliteration generates 133,000 search results while the latter one generates 446,000 as of March 26, 2009. In fact, according to our mining result,  X  X orbachev X  has at least seven transliterations, including  X  X   X  X  (ge ba qi fu),  X  X   X  X  (ge ba zhuo fu),  X  X  X  X  (ge ba qiao fu),  X  X   X  X  (ge ba qi fu),  X  X  X  X  X  (ge ba qi fu),  X  X  X  X  X   X  (ge er ba qiao fu), and  X  X  X  X  X  X  (ge er ba qiao fu). As to  X  X ydney X , the transliteration  X  X  X  X  (xue li), which is mainly used in Taiwan, generates 1,370,000 search results while  X  X  (xi ni), which is used in China, generates 5,730,000 results.
 onymous transliterations from the Web for a given Chinese transliteration. The research results can be applied to construct a database of synonymous transliterations which can be used to expand a search query. As a user in-puts a query, the search engine can automatically expand the query with syn-onymous transliterations or offer suggestions to the user. As a result, it can alleviate the incomplete search problem resulting from the issue of different transliterations of a foreign name.
 mous transliterations from the Web. The first is how to retrieve potential Web pages from the huge collection of pages which may contain synonymous transliterations. The second is how to identify synonymous transliterations from the collected potential Web pages.
 ing of two stages: potential Web snippets collection and synonymous translit-erations identification. In the first stage, given a Chinese transliteration, a set of potential Web snippets are collected by the use of association words which are key words highly relevant to the input Chinese transliteration. To deter-mine association words of a transliteration, we use a measure which integrates several statistical metrics of keyword determination so as to raise the quality of association words.

In the second stage, we proceed to extract synonymous transliterations from the set of collected snippets. Transliterations are unknown to a regular Chinese dictionary. Therefore, known words in the snippets are first discarded and then n -gram terms with a length close to that of the input transliteration are extracted from the remaining text. Synonymous transliterations, if there are any, must be among these n -gram terms. We explore several approaches to eliminate irrelevant n -gram terms and to rank the remaining n -gram terms according to their similarity to the t ransliteration. Experimental results show that the proposed framework is effe ctive for retrieving the set of poten-tial snippets and identifying synonymous transliterations from the collected snippets.
 framework does not need a pre-collected training corpus, which suffers from bias if the collection is not comprehensive, nor involve manual assignment be-tween phonemes, which could be subjective and labor intensive. Moreover, the proposed approach involves processing only Web snippets, of which each snip-pet typically includes one anchor text and two-line text, rather than processing a whole Web page so that the computation load is less demanding.
 Section 2. Section 3 presents the framework and proceeds to describe the de-tailed procedure of collecting the potential Web snippets in which synonymous transliterations may appear. The processes of identifying potential synony-mous transliterations from the collected Web snippets and filtering out false positives are presented in Section 4. Extensive experiments are conducted to determine various parameters and to test the effectiveness of the framework. The experimental results are given in Section 5. Finally, Section 6 gives the conclusions. 2. RELATED WORK The issue of handling proper noun transliterations, in particular, identify-ing pairs of corresponding proper nouns from bilingual corpora has long been studied in CLIR. The study can be classified into two directions, namely, for-ward transliteration and backward transliteration. Forward transliteration is the process of phonetically converting an original proper noun in the source language to a transliterated word in the target language [Jiang et al. 2007; Knight and Graehl 1998; Kuo and Li 2008; Wan and Verspoor 1998]. Backward transliteration works in the opposite direction by converting from a translit-erated word to its original source word [Chen et al. 1998, 2006; Lin and Chen 2000, 2002; Stalls and Knight 1998]. Forward transliteration is more relevant to our work.
 lize mapping rules to generate target transliterations. Rule-based approaches [Wan and Verspoor 1998] adopt linguistic rules for a deterministic generation of translation. However, different Chinese characters may have the same pro-nunciation. As a result, it is difficult to select the best target character for the translation [Jiang et al. 2007]. Statistics-based approaches [Knight and Graehl 1998; Kuo and Li 2008; Virga and Khudanpur 2003] select the most probable translations based on knowledge learned from the training data. Typ-ically, learned mapping rules which can be phoneme-based or grapheme-based are used for the translation. A phoneme-based approach [Knight and Graehl 1998; Lee 1999] first converts the word in the source language to an interme-diate phonemic representation, and then converts the phonemic representa-tion to the word in the target language. A grapheme-based approach [Jeong et al. 1999; Li et al. 2004; Oh and Choi 2006] converts the source graphemes directly to target graphemes without the intermediate transformation. Both statistics-based approaches require a large bilingual corpus or a large number of transliteration pairs for learning the mapping rules.
 various issues of cross-lingual information retrieval. Lu et al. [2002; 2003] proposed approaches to generate translation suggestions for given user queries via mining anchor text and search results. Li et al. [2003] developed an intel-ligent English reading-assistance system that offers word and phrase transla-tion based on multilingual Web data and statistical-learning methods. Zhang and Vines [2004] devised a method to dynamically discover translations of out-of-vocabulary terms. Zhang et al. [2005] proposed a scheme to automatically translate an out-of-vocabulary terms on the fly through cross-lingual query expansion. Fang et al. [2006] proposed an approach to mining English trans-lations of Chinese terms. Given a Chinese term, their method collects effective Web pages based on semantic prediction. Analysis is performed on the Web pages so as to further collect more effective Web pages. Likely English trans-lations in the pages are evaluated acco rding to some predefined features. Wu and Chang [2007] presented a method for learning to find English to Chinese transliterations on the Web. Sublexical relationships between English names and their Chinese transliterations are learned from a set of training data a priori. At run-time, the relationships are used to expand the given English-name query for retrieving Web pages and then are further used to help ex-tract and evaluate candidate Chinese terms. Kuo et al. [2007] assume that Chinese transliteration always co-occur in proximity to their original English words and then proposed a phonetic similarity modeling approach to identify the transliteration pairs by measuring phonetic similarity between candidate transliteration pairs. The phonetic similarity model in essence consists of a syllable-based confusion matrix with its element being the conditional proba-bility p ( es | cs )where es and cs are an English syllable and a Chinese syllable, respectively. The probability can be estimated by several proposed methods with the use of various training data including a labeled English speech data-base or a transliterated bilingual corpus.
 are relevant to our work when we need to compare the similarity between the input transliteration and the extracted n -gram terms. There are several approaches to comparing the similarity of two Chinese words, mainly includ-ing physical-sound-, grapheme-, and phoneme-based approaches [Hsu et al. 2007]. Physical-sound-based approaches measure the similarity of two words based on the similarity between digitalized physical sounds [Hsu et al. 2007]. Grapheme-based approaches [Wagner and Fischer 1974] compare the similar-ity of two strings of Roman alphabets which the two Chinese words are con-verted to by one of the Pinyin schemes such as Hanyu, Tongyong, Wade-Giles, etc. [Wikipedia 2006]. The similarity of two terms is proportional to the ratio of common alphabets occurred in the two strings. Phoneme-based approaches [Kondrak 2003; Kuo et al. 2007; Lin and Chen 2002] are mainly based on the pronunciation similarity between phones. They take into consideration of ar-ticulatory features of phones. For example, in phoneme-based approaches  X  X  X  is more similar to  X  X  X  than to  X  X  X  while in grapheme-based approaches both pairs ( X  X  X ,  X  X  X ) and ( X  X  X ,  X  X  X ) have the same degree of similarity, that is, totally dissimilar due to distinct alphabets.
 learned from a training corpus [Kuo et al. 2007; Lin and Chen 2002; Wu and Chang 2007]. In Lin and Chen [2000], they devise rules to determine the sim-ilarity of each pair phones. Learning can be with or without a pronouncing dictionary. In Lin and Chen [2002], a pronouncing dictionary with a modified Widrow-Hoff learning algorithm was used to determine the similarity between 97 phonemes used to represent 1,574 training pairs of English and transliter-ated Chinese names. Lee et al. [2006] proposed an approach based on a statisti-cal machine transliteration model to exploit the phonetic similarities between English words and corresponding Chinese transliterations. Their method does not require a pronouncing dictionary. The parameters of the model are auto-matically learned from a bilingual proper name list.
 Web as many existing synonymous transliterations as possible for a given Chinese transliteration. Our contributions can be summarized as follows. First, we propose a two-stage framework for the mining task. The framework involves processing only the Web snippets rather than processing the whole Web pages which will be computationally intensive. Second, a novel approach to collecting target snippets which may contain synonymous transliterations is devised. The approach utilizes combinations of association words of the in-put transliteration. In contrast to gene rative models used in forward translit-eration, our approach requires neither training data nor manually assigned phonetic similarity scores. Incomprehensive training data would lead to bi-ased estimation of translation rules [Kondrak 2003]. Manual assignment of phonetic similarity is tedious and would be subjective. Third, several effective filtering methods are proposed to eliminate n -gram terms which are unlikely to be target transliterations. In particular, a physical-sound-based comparison approach is employed to measure the similarity between n -gram terms and the input transliteration. N -gram terms with a low similarity score are considered as noise and eliminated. The approach is effective and simple. In addition, the approach does not need a training corpus, either, as opposed to statistical grapheme-or phoneme-based comparison approaches. Fourth, good parame-ter settings for the various filtering methods are suggested based on extensive experiments. 3. TARGET WEB SNIPPETS COLLECTION 3.1 Observation The original foreign proper noun may appear along with its Chinese translit-eration in the Web pages in the local language. Therefore, one straightfor-ward approach to retrieving synonymous transliterations is to use the foreign word as the query keyword to search engine with search scope limited to only Web pages in the local language. However, this straightforward approach fails to give a satisfactory result in terms of the number of distinct synonymous transliterations retrieved. Most commercial search engines impose a limit on the number of Web pages returned to the user. For example, Google, Altavista, and Yahoo return at most 1,000 pages even though the page count of search results shows there are a lot more pages which match the query. Furthermore, among the synonymous transliterations of a foreign name there may be a few dominant transliterations which appear more frequent than the others. The first returned 1,000 Web pages may contain only those dominant translitera-tions. For instance, the transliteration  X   X   X  X  X  X  X   X  (ge er ba qiao fu) appear tion and the domination phenomenon, the direct approach of using the foreign name as the query term is not effective.
 is through the use of association words , which are co-occurrence words highly relevant to the input transliteration in terms of context. For example, the term  X   X  X   X  (cold war) and the term  X   X  X  X  X   X  (communist) are two important association words of  X   X  X  X  (Gorbachev). As shown in Figure 1, those two association words (doubly underlined) appear along with the transliteration the term  X   X  X  X  X   X  (communist) are used as the query keywords, we are able to acquire Web pages which contain synonymous transliterations  X   X  X  X  X  X  X   X  in the second and the third snippet. Therefore, identifying appropriate associ-ation words for collecting potential Web snippets is a key step to mining syn-onymous transliterations. Once the set of potential Web snippets is collected, the remaining task is then to extract those synonymous transliterations from the collected snippets.
 3.2 The Framework Based on the observation, we propose a framework for mining synonymous transliterations with respect to a given transliteration. Our framework con-sists of two major stages as shown in Figure 2. The first stage is to collect target Web snippets in which synonymous transliterations may appear. In this stage, the transliteration ( TL ) is first inputted for collecting a set of snippets, referred to as core snippets , which will be used to identify association words of the TL . After text preprocess including HTML tags removal, term segmenta-tion, and keyword determination, a set of keywords, called association words , which are highly associated with the TL are extracted. The association words are then used to form search-keywords to retrieve a set of snippets from the Web, referred to as target snippets , which are considered likely containing dis-tinct synonymous transliterations.
 target snippets collected in the previ ous stage. Unknown words are first ex-tracted from the snippets and then several filtering techniques are applied to further eliminate the unknown words which are considered unlikely to be syn-onymous transliterations. To further improve the quality of identified terms, several methods are explored in order to raise the ranking of true synonymous transliterations against other noise terms.
 3.3 Extracting Association Words Using a given transliteration as a search keyword, we download a fixed num-ber of Web snippets (i.e., the core snippets). Association words are extracted from the core snippets. Ideal association words are those which occur fre-quently in the Web pages that contain its transliterations and less frequently in the Web pages not containing its transliterations. Therefore, keyword ex-traction techniques from the field of information retrieval can be employed to extract association words.
 words with respect to a document category by measuring association strength between a word and the category. The methods include Information gain (IG), Mutual information (MI), Chi-square (CHI), Correlation coefficient (CC), Rel-evance score (RS), Odds ratio (OR) and GSS Coefficient (GSS). According to [Huang et al. 2006], a fusion approach which integrates keywords selected by different methods may improve the qu ality of keywords, reduce noise, and avoid overfitting. Therefore, we use a fusion model which adapts and inte-grates six popular keyword selection functions, as shown in Table I, to esti-mate the strength of association between a term t and an input transliteration TL .
 joint and conditional probabilities. Several researchers recently proposed to use the returned count of a query to a search engine for estimating term rela-tionship. Cheng et al. [2004] used the returned page counts from the search en-gine to estimate association strength between two terms. Cilibrasi and Vitanyi [2007] used the returned page counts to measure the information distance so as to estimate the similarity among the names of objects. We adapt their ideas for our needs to measure association strength between a term t and the input transliteration TL .Apairof( t , TL ) represent the positive existence of t in a Web page containing TL while a pair of (  X  t , TL ) indicate the opposite, not occur-ring in the page containing TL . Taking the information gain as an example, in the adapted IG( t , TL ), p ( t , TL ) representing the probability of co-occurrence of t and TL can be estimated via the returned page counts of a query  X  t  X + X  TL  X  X o search engine divided by the total Web page N . N is the estimated total page number and is set to 0.3 billion in our experiment. In RS( t , TL ), d is a small smooth value and is set to 1.

In practice, we first download a fixed number of Web snippets D for a transliteration TL via a search engine. Let T = { t 1 , ..., t k , ..., t K } be the set of known words obtained from the core snippets. The scores on the six functions for association strength between t k  X  T and the TL are measured. The rank of t k with respect to each measure is assigned according to its score. sents the rank of t k under the m th evaluation function. The average rank is defined as A v gR k =( M m =1 r m k ) / M . The words with top average rank are consid-ered significant association words. Table II shows the top 20 association words tion words to be submitted to a search engine for collecting the target snippets, but also be regarded as a set of characteristics relevant to the input transliter-ation. We will use this set of context words later to improve the ranking of a true synonymous transliteration with respect to the input transliteration. 3.4 Forming Search Keywords Based on the ranked association words identified in the previous step, we generate a set of queries. Each query in the set is then used to collect sev-eral hundred snippets. All retrieved snippets together form the set of tar-get snippets which are considered to very likely contain distinct synonymous transliterations.
 as the original foreign word of the transliteration, can effectively retrieve target snippets. Based on this observation, we propose a search strategy which involves two types of entities, namely, the association words and the original foreign word of the transliteration, for collecting the set of target snippets. An issue encountered by this method is how many association words to use in the query. We handle this issue with a parameter and determine the best value empirically by experimentation.
 ( m +1)-term query which is formed by m association words ( AS )of TL plus its original foreign word ( ORI ). We select n top-ranked association words of TL and use combination to generate the set Q m  X  AsOri of queries. The number of queries in the set is C ( n , m ). For instance, given the top four association words, say {  X   X  (cold war),  X  X  X  X  (communist),  X  X  (democracy),  X  X  (people) } , the original name Gorbachev, and m set to 2, each query q  X  Q 2  X  AsOri is there-fore a three-term query. The query set Q 2  X  AsOri includes all two-term combina-tions of the four association words, which has a size of C (4,2) = 6. Specifically, the whole set Q 2  X  AsOri consists of { q 1 =(  X   X  ,  X  X  X  X  , Gorbachev); q 2 =(  X  X  ,  X  X  , Gorbachev); q 3 =(  X  X  ,  X  X  , Gorbachev); q 4 =(  X  X  X  X  ,  X  X  ,Gor-bachev); q 5 =(  X   X   X  ,  X  X  , Gorbachev); and q 6 =(  X   X  ,  X   X  , Gorbachev) } . Each query from the set Q 2  X  AsOri is used to collect a few hundred snippets which are included to form the set of target snippets of the transliteration 4. SYNONYMOUS TRANSLITERATIONS EXTRACTION FROM After collecting target snippets, we apply several processes to extract synony-mous transliterations. The first step is to discard known words. Translit-erations are unknown to an ordinary dictionary. In other words, a word in a dictionary is unlikely to be a transliteration. Therefore, we first discard known words in the snippets with the help of a Chinese dictionary. The remaining text, which is a collection of text fragments, is the source for mining synony-mous transliterations. We proceed to segment the remaining text to n -gram terms. Synonymous transliterations usually have the same or close length. Consequently, the length parameter n shall be in turn set to the values in the range of | TL | X   X  , the possible lengths of ST s. In this study, we set  X  to 1 since most of ST s have a length discrepancy of one to its input TL .
 tions from the set of segmented n -gram terms. The number of n -gram terms segmented from the remaining text after eliminating known words is still huge. Most of the terms are obviously not an ST . To reduce the size, we first compare phonetic similarity between n -gram terms and the TL .Ifan n -gram term does not sound similar to the TL , it can be discarded. The de-tail is described in Section 4.1. Second, an n -gram term which does not align with the TL in the first and the last character can be eliminated. The detail is described in Section 4.2. Finally, in Section 4.3 we take into consideration context information of an n -gramtermandthe TL to improve the ranking of true synonymous transliterations against false positives.
 4.1 N -gram Terms Phonetically Similar to the Transliteration In this study, we use a physical-sound-based approach, namely, the Chinese Sound Comparison method (CSC) [Hsu et al. 2007] to compare the phonetic similarity between an n -gram term and the TL . The reason for choosing the CSC method is that it has the advantage over the conventional grapheme-and phoneme-based approaches in being able to embed more discriminative information in their digitalized sound vectors. This ability helps to raise effec-tiveness of similarity comparison.
 the n th character of A and b m is the m th character of B . N is not necessarily equal to M . A dynamic programming-based a pproach to comparing the simi-larity of smallest distortion for A and B by adjusting the warp on the time axis is employed. The recurrence formula is defined as follows: is the phonetic similarity between Chinese characters a N and b M . length of the words is defined as comparison. We set it to the average length of N and M which was verified for CSC to yield better performance compared to the maximum and the minimum of the lengths [Hsu et al. 2007].
 two Chinese characters, namely, sim ( a n , b m ) which is done by the following for-mula in which IC represents initial consonant. s37, is for the 37 phonetic symbols which are the basic symbols used in Tai-wan to make of the pronunciation of a Chinese character. The other matrix, s412, is for the 412 basic sounds which cover all the pronunciations of Chinese characters without considering tones. Each entry of the matrices stores the similarity score of two phonetic symbols (or two basic sounds). For instance, the similarity of two phonetic symbols  X  (si) and  X  (shi) is sim s 37 (  X  ,  X  ) = 0.66 and the similarity of two Chinese characters (basic sounds)  X  (  X  X  ,sen)and  X  (  X  X  , sheng) is sim s 412 (  X  X  ,  X  X  ) = 0.69. Note that  X  X  and  X  X  are the phonetic symbol representation of the two Chinese characters.
 speech sound comparison. Therefore, we adopt an initial-weighted comparison approach, which involved a balancing adjustment: weighting the initial con-sonants of the characters to balance the bias caused by the final sounds. The similarity matrix of the 37 phonetic symbols is used to provide the similarity data between the initials of the characters. Based on the two similarity matri-ces, the similarity between two Chinese characters is measured by a weighted combination of similarities of their initial consonant sounds and their charac-ter sounds.
 initial consonant and the whole character whereas a n . IC and b m . IC represent the initial consonant ( IC ) of the two characters. The weight w is set to 0.4 empirically [Hsu et al. 2007].
  X  (sen) and  X  (sheng), we first convert them to the representation of their corresponding phonetic symbols, namely,  X  X  (sen) and  X  X  (sheng). They have initial consonants  X  (si) and  X  (shi), respectively. Then, the adjusted sim-ilarity score is calculated according to the formula, sim (  X  X  ,  X   X  )=0 . 4  X 
Each entry of the similarity matrix s37 (s412) represents pronunciation sim-ilarity of two phonetic symbols (basic sounds). The two matrices were con-structed according to digitalized sounds. We recorded the sound of each of the 37 phonetic symbols and the 412 basic sounds and then extracted sound features to form sound vectors by using speech processing techniques. The similarity between any two phonetic symbols (basic sounds) is measured by calculating the similarity of their representing sound vectors by a dynamic programming algorithm. For more details, please refer to Hsu et al. [2007]. 4.2 Filtering Terms by Alignment By using the CSC approach described in Section 4.1, the segmented n -gram terms can be ranked by their CSC score representing their phonetic similar-ity with the TL . True synonymous transliterations usually have high scores. However, an n -gram term with a high score may not be an ST , resulting in a false positive.

Three major types of false positives are identified. First, an unknown term just happens to have high similarity in pronunciation with the TL, for instance, Chinese term. Second, two valid transliterations which are not synonyms but happen to have close pronunciation, for instance,  X  X  X  (Roberts; luo bo zi) lem in which an n -gram term has a significant portion overlapping with the TL and a true ST , yielding a high CSC score. For instance, TL  X  X  X  X  (Gor-bachev; ge ba qi fu) and a four-gram term  X  X  X  X  X  (ba zhuo fu fang) have two overlapping characters  X  (ba) and  X  (fu). In fact, the four-gram term is segmented from the text fragment  X   X  X  X  X  X  X  (Gorbachev visits China; ge (ba zhuo fu), resulting in a high CSC similarity score. The errors of the first two types can be reduced by considering the semantic similarity between the n -gramtermandthe TL which is measured via context terms of the two. The detail will be described in Section 4.3. The errors of the third type can be re-duced by alignment of the TL and the n -gram term. The approach is described in the following.
 transliterations are highly matching with each other at the first and the last character, for instance,  X   X  X  X  (ge ba qi fu),  X  X  X  X  X  X  (ge er ba qiao fu), well at the first and the last character are very likely not synonymous, such as ing technique [Hsu et al. 2007; Sakoe and Chiba 1978] to determine the opti-mal alignment between an n -gramtermandthe TL and eliminate the n -gram terms which do not match well with the TL at the first and the last charac-ter. Figure 3 illustrates the results of the warping in which a diagonal arrow represent a match between two Chinese characters and the arrow path repre-sents the optimal warping of the two words. Figure 3(a) shows a well-matched ST with its TL . In Figure 3(b), the alignment result can rule out  X  X  X  X  X  (ba zhou fu fang) as an ST to the TL  X  X  X  X  (ge ba qi fu). Note that the alignment based on phonetic similarity of Chinese characters can be acquired while computing the CSC score mentioned in Section 4.1. That is, no additional computation is required.
 character exception . Several final foreign phonemes may be ignored in the transliterations by some translators but may not by some other translators. This phenomenon has also been identified by the authors in Kuo et al. [2007]. Consequently, some ST s may have an extra character at the end of the term, resulting in mismatching at the last character, for example,  X  X  X  (Beckham; bei ke han) and  X  X  X  X  X  (Beckham; bei ke han mu). Those final phonemes which might be ignored include  X  X  X ,  X  X  X ,  X  X r X ,  X  X h X ,  X  X  X ,  X  X  X ,  X  X  X , and  X  X  X  and when they are not ignored.
 matching between the last second character of the longer word and the last character of the shorter word when a mismatched last character pair is attributed to this exception. If a matching is found, they are considered synonyms, as shown in Figure 3(c). 4.3 Improving Ranking by Context Matching To consider the context to which a TL and a candidate synonymous translit-eration (or CST ) are related is an appealing direction to further improve the ranking of a true synonymous transliteration ( ST ) against other noise terms. The idea is that an ST is very likely to retrieve similar snippets as a TL .In other words, if the set of snippets returned by using a CST is similar to the set of snippets returned by using a TL ,the CST is possibly an ST of the TL. To realize this idea, we utilize context matching , which compares the similar-ity of two sets of snippets retrieved by the CST and the TL , respectively. The more common association words in both sets, the more similar the CST and the TL are. Specifically, assume AW TL be the vector formed by the set of as-sociation words of TL and AW CST be the binary-valued vector formed by the same set of association words of the TL which value indicates whether an as-sociation word of the TL appears in the set D CST of the snippets collected by submitting the CST as the query keyword. The similarity can be measured by Equation (4): grates with other factors. Note that AW TL can be formed by using the associ-ation words obtained earlier in the first stage of the framework from the core snippets. No additional extraction is needed.
 in the set of retrieved snippets plays a key role in the decision. We therefore design two additional approaches which take the original name into consider-ation. The first approach, Se m alter ( TL , CST ), as indicated in Equation (5), is to assign a predetermined similarity score if D CST contains the original foreign word or otherwise to assign the weighted cosine score. The predetermined sim-ilarity score is set to 0.4 in our experiment. It is determined by the following statistic analysis. Among the set of CST s with their CSC score larger than 0.6, 368 CST s has the original word occurring in the set of returned snippets. One hundred and forty (140) of the 368 are true synonymous transliterations, which represents a probability close to 0.4. The other approach, Se m linear ( TL , CST ), is to linearly combine the weighted scores of the original name and the co-sine measure, as shown in Equation (6). Note that  X  ( O , D CST ) returns 1 if the original foreign name is contained in D CST or 0 otherwise.
 eration pronunciation similarity and Web-page context, is a weighted linear combination of the CSC score S CSC and the semantics score S Se m ,whichisone of the three alternatives as expressed in Equations (4) to (6). That is, acquired by using the CST as the query term. Another possibility is to use the CST plus the original foreign name as the query term. As stated earlier, the appearance of the original foreign na me in a snippet plays a critical role in the decision. The foreign name is likely to appear in a snippet with its translit-eration. Consequently, a CST is more likely to be an ST if the CST appears in a snippet including the foreign name. Moreover, we also observe that the dis-tance between the CST and the foreign name is an important factor. The closer between the two, the more likely the CST is an ST . Based on these observa-tions we devise another approach which involves using a CST plus the original word as a query to collect the set of snippets, denoted by D CST + Ori . Similar to the previous approach, a binary vector AW CST is formed from D CST + Ori .The AW CST is then used to compute the semantic similarity score of the CST and the TL .
  X  ( Ori , D CST + Ori , d ) returns 1 if the original foreign name Ori occurs in at least one snippet of D CST + Ori with a distance to its CST less than d or returns 0 otherwise. The distance is measured by counting the number of Chinese char-acters in between the Ori and the CST . English words and delimiters such as punctuations, bracket, and spaces are ignored in the distance calculation. Note that Ori could occur before or after the CST . 5. EXPERIMENTS 5.1 Experimental Data Two datasets are used for experiments. For the first dataset, referred to as D50, we select a total of 50 Chinese transliterations ( TL s), as shown in Table III, from the dataset used in Hs u et al. [2007]. Their length is 2, 3, or 4, which is most commonly seen in Chinese transliterations. The number of transliterations in each group is 10, 30, and 10, respectively.
 100 list of the world X  X  most influential people [Time 2009]. There are a total of 104 names in the list since there are four entries each which include two names. Ninety-seven names are retained for the experiment. Seven names are ignored, including Ying-Jeou Ma, Jintao Hu, Jeff Han, Jiwei Lou, Dalai Lama, Takahashi Murakami, and Radiohead. The first four have a Chinese last name which has a standard Chinese translation.  X  X alai Lama X , the spiritual leader of Tibet, also has a standard Chinese translation. The sixth one is a Japanese name which is not usually translated using transliterating. The last one is the name of a music band which is not translated to Chinese by its pronunciation but its meaning.
 a few of the names in D97 are less popular to Chinese community and hence they appear in an expectedly limited number of Chinese Web pages. Some of them appeared in Chinese Web pages only after they were selected in the Time 100 list. 5.2 Compare with Other Query Strategies We compare the proposed hybrid query strategy, with which a query consists of association words and the foreign name for collecting the set of target snippets, to other query strategies. The set of target snippets is expected to contain as many synonymous transliterations as possible.
 transliteration is the process of phonetically converting an original proper noun in the source language to a transliterated word in the target language. Backward transliteration works oppositely from a transliterated word to its original source word. Analogously, it is possible to directly search for translit-erations by using the original foreign name. There are several techniques in CLIR that can automatically determine its foreign origin with respect to a given transliteration [Lin and Chen 2000; 2002]. Even a Web page may con-tain several synonymous transliterations in addition to the input translitera-tion. Therefore, two direct approach escanbedesigned. OneistousetheTL and the other is to use the ORI as the query term for retrieving the target snippets.
 can be considered. That is, a query is made out of various combinations of association words; specifically, a query q  X  Q m  X  As is an m -term query which is formed by m association words. To generate a set Q m  X  As of queries for col-lecting target snippets, we select top-ranked association words and generate all the queries from subsets of the association words. For instance, given the top four association words, say {  X  X  (cold war),  X   X   X  (communist),  X   X  (democracy),  X  X  (people) } , of the transliteration  X   X   X  X  (ge ba qi fu) and m =2,aquery q  X  Q 2  X  As is a 2-term query such as q =(  X   X  ,  X  X  X  X  ). The query set Q 2  X  As includes all the six two-term queries generated from the four association words. Specifically, the set Q 2  X  As consists of { q 1 =(  X  X  ,  X   X  X  X  ); q q 5.3 Performance of Query strategies Each of the transliterations ( TL ) in the datasets D50 and D97 was submitted to the Google search engine and the first 20 snippets were collected as the core snippets of the TL . For each TL , its top five association words were determined and used to collect various s ets of the target snippets according to different strategies. Google occasionally suggests with respect to user queries synonymous transliterations, placed in the first line or the last line of the first returned page. We therefore consider their recommendation as well in the experiment. The query methods are summarized in the following list.
Q m  X  As : collecting snippets by using the queries consisting of m association Q m  X  AsOri : collecting snippets by using the queries consisting of m association target snippets, which shall contain as many synonymous transliterations as possible. The total number of distinct synonymous transliterations in the total returned snippets by all the methods is 342 for D50 and 401 for D97, which is 6.84 and 4.13 on average per input transliteration, respectively.
 direct strategy (Q m  X  As ) and the direct strategy (Q Ori and Q TL ). The indirect strategy outperforms the direct strate gy when we use three association words (i.e., the Q 3  X  As method). Among the individual retrieval method, the Q 3  X  AsOri with averages of 5.18 and 3.01 respectively outperforms the other methods. ation occurs in the set of returned target snippets under the employed method, approximately 85% of the input transliterations can retrieve at least one syn-onymous transliteration by using the 3-AsOri method. For uniqueness which indicates how many words are retrieve d uniquely by the method but not by the other methods, 3-AsOri also achieves the best compared to the others. together by all the methods, the 3-AsOri method has the best recall rate (0.76 and 0.73, respectively). The total recall rate by the top three methods together (i.e., 3-AsOri, 2-AsOri and 1-AsOri) is 0.932 (i.e., 319 out of 342) for D50 and 0.925 (i.e., 371 out of 401) for D97, respectively. The results demonstrate the effectiveness of the hybrid strategy.
 as indicated in the Ori columns of Table IV. For instance, the transliterations (Cypress) of D50 have no ST s in the retrieved snippets by the Ori method but they do have by 3-AsOri. There are two main reasons. First, each of the returned snippets has only a line of anchor text plus two lines of excerpted text. Many of the snippets do not contain any transliteration of the original word in such a limited size of the text. Even though the search domain is set to Chinese Web pages only, many snippets contain only excerpted English text and no Chinese. Second, for those which do contain transliterations, lots of the transliterations in the set of returned snippets are identical. In particu-lar, some individual transliterations are very popular such that the returned snippets by the Ori method contain only that transliteration and no others. A stricter query strategy which additionally include association words along with the original foreign name help to bring the Web snippets containing vari-ous synonymous transliterations to the set of the first returned 1,000 pages. text plus three lines of text for each returned snippet but gives only two lines currently. Using the three-line-text snippets, the 2-AsOri method gave the best performance and the 1-AsOri came in the second [Hsu and Chen 2008]. along with their association words in the query outperforms those which do not include the original foreign name. Furthermore, the parameter m (the number of association words included in a query) is better not to be greater than three. Requesting too many association words in a snippet will limit the number of snippets that we can retrieve. 5.4 Performance of Synonymous Transliterations Extraction the confirmation model can recognize the identified candidate synonymous transliterations ( CSTs ) as true synonymous transliterations ( ST s ). Because the 3-AsOri method was more effective in retrieving target snippets in which ST s appear,weusethesetof CSTs extracted from the target snippets by 3-AsOri for further processing.
 compares the phonetic similarity between an n -gram CST term and the TL, together with the filtering rules can eliminate most of false positives. In the case of the D50 dataset, the total n -gram terms segmented from the target snippets is 385,146, which includes 259 synonymous transliterations. All STs (true positives) have a CSC similarity score greater than 0.5. In fact, the least CSC score of a true positive pair is 0.589, as shown in Table VI. More than ninety-nine percent (99.2%) have a CSC score greater than or equal to 0.6. At the same time, false positives can be reduced from 42.6% to 8.3% as the CSC threshold is raised from 0.5 to 0.6, as shown in the third column of Table V. Considering the first-and the la st-character alignment constraint (i.e., discarding an n -gram term if not aligning the first-and the last-character with the TL), we can reduce false positives further with some compromise on the recall rate (indicated by the retained true positive percentage), as shown in the fourth column. It is worth noting that if further taking into account the extra-character exception, we can significantly recover the recall rate from 95.4% to 98.8% while making a compromise with a little increasing on the false-positive rate from 14.9% to 15.8%, as indicated in the fourth and fifth columns.
 is much smaller than that of D50, that is, 114857 versus 385416, although D97 has a larger size of input transliterations than D50. The reason is due to the fact that we mentioned earlier: the transliterations in D50 are more popular to Chinese community compared to those in D97. Therefore, the number of the Web pages collected for extracting n -grams is much larger for D50 than for D97.
 alignment and the exception rules for D50 came from the TL  X  X  X  (Hussein) as shown in Table VI. In these cases, the last character of the shorter term is aligned with the last second character of the longer one; that is, the pairs (  X  (sheng),  X  (sai)) and (  X  (sheng),  X  (xi)) are aligned. However, the addi-tional last characters in the longer STs are not in the list of extra characters mentioned in Section 4.2. Note that the first and the second row are different in the Chinese characters  X  (hou) and  X  (hou). mance of improving ranking by taking context information into account. We evaluate the performance via various measures including average rank, aver-age reciprocal rank, and inclusion rate.
 and the inclusion rate, which are commonly used for performance evaluation in information retrieval, are calcul ated in this study according to the rank of similarity score of a true ST to the TL . ARR puts more weight on top-ranked terms. Assume S is the set of synonymous translations of the TL appearing in the set N of segmented n -gram terms, R ST is the score rank of an ST  X  S compared to the other CST sintheset N ,andTOP n is a sub-set of the set N , each of which has a CSC rank within top n . The measures are calculated as follows. AR =(1 / | S | ) ST  X  S R ST , ARR = ST  X  S (1 / R ST ), and IR n = 100%  X  (1 / | S | ) ST  X  TOPn { 1 } .
 which the CSC score parameter w steps from 0.1 to 0.9 by 0.1, the semantic score parameter  X  issetto0,0.3,0.5,0.7,or1,andtheAW(CMAW),theal-ternative (CMALT), and the linear combination (CMLC) approach are used to take into consideration context information (cf. Equations (4)-(6)). The exper-imental results are shown in the following figures. For the sake of clarity, we do not show in the figures the results of each setting. However, the illustrative results are enough to demonstrate the ge neral tendency. Experimental results indicate that the combination of a larger weight w on the CSC score and a smaller weight  X  on the semantic score yields better performance.
 the CSC score measured from pronunciation similarity is more important than the semantic score measured from Web-snippet context similarity. Figure 4 is the results by the linear combination approach (i.e., Equations (6) and (7)). The results by the alternative and the AW approach reveal similar tendency. Figure 5 reveals that the linear combination outperforms the other approaches. eign name plays in verifying whether a CST is indeed an ST , in the follow-ing experiments the snippets from which we extract context information are retrieved by using the CST plus the foreign name, contrast to the previous experiments in which the snippets are retrieved by using the CST alone. ters  X  , w ,and d ,weset  X  from 0 to 1 and w from 0.5 to 1.0 both with a step of 0.1. The distance parameter d is set to 0, 1, 2, 3, 4, 5, and no limitation (indi-cated by  X  ). Recall that d is the number of Chinese characters in between the foreign name and the CST .
 small value between 0 and 2, as shown in Figure 6. The reason behind this is when a foreign proper noun appears with its transliteration in a document it is often next to or nearby the transliteration.
 with that of the previous experiment. As shown in Figure 7, w set to 0.8 or 0.9 yields better results than the other settings.
 rates of three major configurations, the baseline, onlyCST and CST+Ori. The baseline ranks a CST term based on only the phonetic CSC score while on-lyCST and CST+Ori take context information into account. Different from on-lyCST, CST+Ori forms the query of retrieving the snippets from which context information is extracted by using the CST plus the foreign name. The results by onlyCST and CST+Ori here are under their best parameter setting with respect to the parameters w ,  X  ,and d .
 line model in the top 10 ranking, conforming the inclusion of context in-formation help to identify true synonymous transliterations from candidate synonymous transliterations. The CST+Ori is slightly superior than the on-lyCST, implying the occurrence of the original foreign name in the snippet help to improve ranking of synonymous transliterations against other noise terms. The advantage of the CST+Ori compared to the onlyCST is more apparent in D50thaninD97.
 able to include 83.2% and 94.52% of synonymous transliterations in top 10 for D50 and D97, respectively, while the onlyCST reaches 89.06% and 96.58% for D50 and D97 and the CST+Ori reaches 90.63% and 94.86%, respectively. For D50 all three models reach 100% inclusion rates in top 560 while for D97 all three models reach 100% in just top 70. This is again due to more popu-larity of transliterations in D50. Consequently, they have more synonymous transliterations in the Web and some of them have low ranking. 5.5 Impact on Information Retrieval We conduct an experiment to illustrate the effect of the synonymous-transliterations issue on information retrieval. There are five categories in the most influential people list of the Time magazine top 100. The experimen-tal dataset includes five entries, one from each category. Except the category Leaders &amp; Revolutionaries, the first entry of the other four categories is se-lected, namely, Pitt and Jolie (Heroes &amp; Pioneers), Bloomberg (Scientists &amp; Thinkers), Michaels (Artists &amp; Entertainers), and Nooyi (Builders &amp; Titans). For Leaders &amp; Revolutionaries, the second entry Putin is selected since the first entry Lama is not included in the experimental dataset D97.
 keyword may result in significant loss of information. For instance, the ratio of means the loss of information may be up to 44%. Moreover, the transliteration  X  X  X  (pu jing) for Putin is mainly used in China and Hong Kong but not in Taiwan. In other words, a Taiwanese user may miss up to 86% of Web pages if the user does not know the transliteration  X  X  X  (pu jing).
 6. CONCLUSIONS In this article, we first point out a critical issue in searching the Web involv-ing foreign names, namely, the incomplete search-results problem resulting from the lack of a translation standard on foreign names and the existence of synonymous transliterations. Using only one of the synonymous translitera-tions as search keyword will miss the Web pages which use other translitera-tions for the foreign name. To address this issue, we propose a novel two-stage framework for mining as many synonymous transliterations as possible from Web snippets with respect to a given input transliteration. The research result can be applied to construct a database of synonymous transliterations for auto-matic query expansion or suggesting alternative transliterations so as to help alleviate the incomplete search problem. The results of extensive experiments indicate that compared with using association words of the input translitera-tion alone, association words plus its foreign name is preferred for collecting target snippets which may contain as many distinct synonymous translitera-tions as possible. In addition to the phonetic similarity score, the inclusion of context information helps to improve the ranking of synonymous translitera-tions extracted from the target snippets against other noise terms. Regarding retrieving the snippets for eliciting context information of a candidate term, forming the query by using the candidate term plus the foreign name will yield better results in terms of determining whether the term is a synonymous transliteration.

