 Increasingly, large organizations are experimenting with internal social media ( e.g. , blogs, forums) as a platform for widespread dis-tributed collaboration. Contributions to their counterpa rts outside the organization X  X  firewall are driven by attention from str angers, in addition to sharing among friends. However, employees in a w ork-place under time pressures may be reluctant to participate X  and the audience for their contributions is comparatively smaller . Participa-tion rates also vary widely from group to group. So what influe nces people to contribute in this environment?
In this paper, we present the results of a year-long empirica l study of internal social media participation at a large tech nology company, and analyze the impact attention, feedback, and ma n-agers X  and coworkers X  participation have on employees X  beh avior. We find feedback in the form of posted comments is highly corre -lated with a user X  X  subsequent participation. Recent manag er and coworker activity relate to users initiating or resuming pa rticipation in social media. These findings extend, to an aggregate level , the results from prior interviews about blogging at the company and offer design and policy implications for organizations see king to encourage social media adoption.
 H.5.3 [ Information interfaces and presentation ]: Group and or-ganization interfaces; K.4.3 [ Computers and society ]: Organiza-tional impacts Human Factors social media, contributions, attention, blogs, feedback
In recent years, social media, such as forums, blogs, mi-croblogs ( e.g. , Twitter), and bookmarking services, have lowered the barriers to self-publishing on the Web. The prospect of r e-ceiving widespread attention motivates contributions to s ites like YouTube [18], while attention from particular friends driv es posts to Twitter [19]. The abundance of information and opinions f reely available online makes readers X  attention a scarce resourc e [30]. It has been said that an attention economy drives the Web [12], with myriad contributors competing for readers X  attention.

Recently, organizations and researchers have begun experi ment-ing with the use of internal social media in the workplace, ho ping to reap the benefits of lightweight informal collaboration amo ng em-ployees. Unlike email, which must be targeted to specific rec ipients or distribution lists, social media provide a free broadcas t platform, allowing authors to circumvent traditional organizationa l hierar-chies and connect with geographically or organizationally distant readers.

Internal blogs can facilitate collaboration and knowledge sharing in an enterprise [20]. But large companies often create disi ncen-tives for employees to share knowledge [17]. In an environme nt where time is money, sharing insights for others X  benefit may not be perceived as a good use of one X  X  time. This disparity betwe en benefit and effort required is a common impediment to groupwa re adoption [16]. Moreover, the attention economy, while effe ctive on the Web, may break down in office settings [37]. Among the possible reasons cited are relatively obscure metrics for a ttention (while YouTube provides real-time view counts, not all blog or fo-rum servers do) and a lack of management support.

So what leads people to contribute to these media? Previous semi-structured interviews at HP found visible feedback an d  X  X an-agement buy-in X  to be the top concerns among bloggers [37], w hich motivate the two hypotheses we set out to evaluate with empir ical evidence: H1 Visible feedback encourages employees to continue contrib ut-H2 Visible activity from managers and coworkers motivates em-
We explored various forms of feedback and reinforcement and the effect they have on observed behavior within a corporate envi-ronment using over a year of data on contributions to interna l social media at a large global enterprise. We built a tool to monitor em-ployees X  contributions across the venues described in Tabl e 1. We cross-referenced them with daily snapshots of the employee direc-tory, giving us information about where authors work, what t hey do, and who they report to. Table 1: Participation observed in various social media ven ues at HP during the study period.
In this paper, we present two complementary empirical analy ses of the dataset described in Section 3. Section 4 discusses a l ongi-tudinal time series analysis used to determine how various f orms of feedback affect users X  future contributions. Section 5 u ses an  X  X ctivity event X  model to look at possible influences on user s when they started, continued, or stopped participating in each v enue.
This paper X  X  contribution is a quantitative analysis relat ing orga-nizational and social motivators to user behavior across a v ariety of social media venues, enabling a comparison of various fac tors influencing user participation in the workplace.

Understanding the relative importance of these factors is v alu-able in designing an organization X  X  internal social media s trategy, and fostering a healthy ecosystem of contributors. With eno ugh participation, blogs can be an effective tool to expose taci t knowl-edge and support collaboration [20].
The question of what motivates people to contribute to onlin e communities has inspired a variety of research. Social bene fits derived from a sense of community can be powerful motivators for people to participate in a discussion group [8]. Experie nced members of a community learn to practice the local  X  X etiquet te X  X  the standards of good behavior that build up members X  reputa tion, trust, and social capital. Markers of reputation are the bed rock of how peer-to-peer commercial transactions function on si tes like eBay [29].

The promise of a response is also a potential motivator for co n-tributions. Yet a quarter of all Usenet posts never receive a re-sponse [2]. The politeness or rudeness of a message can help o r hinder its chances of getting a response, depending on the no rms of a forum [7]. Some communities, such as Slashdot, have evolve d so-phisticated moderation and feedback mechanisms to reward c om-menters for valued contributions and discourage undesirab le behav-ior [25].

People are more likely to contribute to online communities i f they feel their contributions are unique, either because th ey X  X e ex-plicitly told so [3] or because their opinions differ from th e major-ity [35].

Wang and Fesenmaier [32] investigated factors motivating c on-tribution in an online travel community and found that effica cy ( e.g. being helpful to others, sharing enjoyment) had the stronge st im-ideas. similar to delicious.com and digg.com . pact followed by relationship building and expectancy (fut ure re-ciprocation). Status only had a minor effect. They also stre ssed in their conclusions that group boundaries are important to av oid free-riders. These results were, however, not obtained in an ente rprise setting and their main method consisted of correlating part icipants X  expressed motivations to their expressed contributions wi thout any temporal distinction.
Lakhani and von Hippel suggest that contributors to the help groups for the Apache web server project may derive intrinsi c ben-efits just from reading the stream of questions and answers po sted by other members [24]. These forums can function as collecto rs for tacit knowledge, much the same way internal corporate bl ogs do [20]. Benkler even suggests that this  X  X ommons-based pee r-production X  model of collaboration is more efficient at mapp ing talent to questions and tasks than traditional organizatio nal hierar-chies [4].

A fair amount of literature has examined social and organi-zational barriers to knowledge sharing and groupware adopt ion. Imbalance between who contributes and who benefits, leading to  X  X ragedy of the commons X  issues, can pose significant chal -lenges [16]. Pay-for-performance incentives pit employee s against each other, discouraging them from spending time on tasks th at don X  X  directly impact their evaluations [17]. Finally, peo ple who are not collocated are less likely to voluntarily collabora te [23].
However, other studies suggest motivations for employees t o adopt internal social media tools. Employee blogging can be a way for people to engage with their organization [14] and mainta in a sense of community with their colleagues [21]. A comprehens ive study by DiMicco et al . found workers at IBM use internal social networking tools to connect with coworkers personally and t o ad-vance their career and project objectives [13]. Temporal an alysis of blog consumption suggests blogging may serve these dual s ocial and professional purposes [36].

A variety of studies have examined the use of and reaction to particular social media tools at IBM, including social book marking [27], people tagging [15], and internal blogging [20]. Kola ri et al . modeled commenting behavior on blogs at IBM as a graph and pro -jected these  X  X onversations X  onto the organization chart t o measure the  X  X each X  of blog posts [22].
A key challenge when identifying motivation for contributi ons to social media is disentangling endogenous from exogenous ef fects. More generally, the issue of distinguishing social influenc e from selection (behavior triggered by influence from peers as opp osed to personal preferences) has been a great concern in the soci al net-work literature [26, 1, 11, 31, 6]. Manski [26] first formulat ed the problem and pointed out difficulties that could only be overc ome with prior knowledge of the reference groups that were studi ed. We tackle this problem by connecting our quantitative resul ts to qualitative results from interviews.

More recently, Anagnostopoulos et al . [1] suggested and exper-imentally evaluated influence in social networks via a coupl e of statistical tests, one based on shuffling and bootstrap tech niques and one based on following directed graphs in the opposite di rec-tion. Our statistical tests, on the other hand, are based on r egression analysis and correlation patterns to highlight temporal ef fects. An-other recent study by Crandall et al . [11] investigated the set of authored pages versus edit page discussions on Wikipedia pa ges as proxies for exogenous and endogenous processes respecti vely. They found an elaborate interplay between these factors mak ing it hard to attribute an observation to a single type of source. A lthough clean separation is not the primary goal of our study we parti ally address the concerns by relating time series to externally k nown events and by studying time series for both aggregate, macro , and the individual, micro , behaviors. We studied a large global technology enterprise, Hewlett-Packard (HP). HP has a variety of social media services avail able to all employees, used for internal collaboration and commu nica-tion. We polled all posts made to them between February 2006 and December 2008, over periods ranging from 13 to 34 months (depending on when we discovered the services). We categori zed them into venues according to the type of content shared and effort required to post (see Table 1). A few high-profile people have re-ceived approval for externally-facing blogs, but the vast m ajority of this content is only accessible inside the firewall and so not eligible for attention from outside the company.

As shown in Table 2, participation rates vary widely by count ry, business group, and job function. While employees speak a va riety of languages, the vast majority of the content we found was wr it-ten in English. It is possible that users not fluent in English are using other collaborative venues we were not able to track, w hich may partially explain the skewed distribution, but we lack s ufficient information about users X  language preferences to make info rmed speculations.

It may be that certain professions, like engineering or mark et-ing, naturally lend themselves more to open collaboration t han the comparatively secretive practices of corporate finance and admin-istration. But the wide variation in participation by group may also suggest social or organizational influences. Perhaps parti cipation is  X  X ontagious X  in organizations or professional communit ies. Or perhaps managers X  behavior exerts pressure on their subord inates, setting an example by their attitude towards social media ve nues, or by explicitly encouraging or discouraging contribution s.
As a first step towards understanding what factors impact ind i-viduals to contribute we study the timing of contributions v ersus various impact factors that indicate a user X  X  posts are being read, for example clicks or comments on previous contributions. T he pri-mary goal of this analysis is to compare impact factors and th ereby give guidance to future improvements in social software des ign. The secondary goal is to establish metrics that can be used in inter-vention analyses and benchmarks against external systems a s well as different interfaces to social media, or before and after major or-ganizational events. Next we outline the method used to eval uate traces of user activity including choice of metrics.
Our general approach is to apply well-proven techniques fro m regression and time series analysis to study correlations o f different factors over time. The primary goal is not to compose a comple te model with all possible explanatory factors to use in actual predic-tions, but rather to highlight structural differences and p atterns in the series that might help us understand which impact factor s have more and which have less of an effect on the contribution fact or by quantifying and comparing correlation metrics between f actors (and systems).

We are particularly interested in comparing hidden versus v is-ible impact factors. In the social media environment we stud ied, the total readership (or  X  X it count X ) of a post is not exposed to content authors, making it a  X  X idden X  factor that neverthel ess in-fluences both exogenous feedback ( e.g. , through off-line channels) and visible feedback. Since users can easily see how many com -ments they have received and who they are from, we consider th em a visible impact factor. It is easy to make different factors visible to users, but if a factor has no impact on the contribution it w ill just clutter the user interface and obfuscate more effective imp act fac-tors. In this paper we compare measurements for hidden click s on documents authored and published with visible comments on t he same documents. Additionally, we are interested in the dive rsity of the different factors, i.e. where the clicks and comments come from. Since our system allows users to authenticate, and we h ave access to the employee database, we can track various employ ee attributes of both the person submitting and the person rece iving a click or a comment, such as their unique employee ID , location (city and country) and organizational unit. These attributes are hard or impossible to track when only the IP address of users are know n, which is a common limitation in public web trace analyses. We could have extracted more attributes, but for the time serie s analy-sis presented here the sparseness of the data makes more deta iled studies unreliable.
 We analyze impact factors both on a micro and a macro level. The micro analysis studies time series of individual users, and col-lects summary statistics of fits of different models that are then ag-gregated on a system level. The macro analysis aggregates th e im-pact and contribution factors for all users into a global tim e series, and then fits a set of models to this series. The reason we study both is that predicting an individual X  X  future contributio ns based on her past behavior is different from predicting the sum of all contri-butions based on aggregated data. Aggregation could mask si gnals (or heterogeneity in signals), as well as highlight signals not di-rectly affecting individuals.

The factors we measure are summarized in Table 3. A user (em-ployee) belongs to exactly one organization unit in a single city and country and may click on a document at most once. However, in a few cases a user X  X  organization is missing in our data. There are 90 organization units in HP, with a median of 761 and an average o f 4090 employees in each.
We split up and collected the data for weekly time periods (se ven days) for all factors over a period of 55 weeks. Posts at HP fol -low definite seven-day cycles, with significantly less activ ity over the weekend; as a result, shorter time periods would be subje ct to significantly more noise depending on whether they stretch o ver a weekend. Other multiples of a week could be used, but 85% of al l comments and 69% of all clicks occur within one week of the ori g-inal post, so this interval likely captures most potential f eedback a user might receive. However, we found that within-workweek pre-dictions were much more accurate than cross-weekend predic tions, so which day was used to demarcate the time series periods aff ected our macro (but not micro) results. After studying all possib ilities, we decided to start new seven-day long periods on Wednesdays to offset the weekend anomaly and to capture the strong withi n-workweek correlations.

About 130 k documents from all venues in the system were au-thored and published during this time, out of which 61 k were com-ments on previous documents. We tracked 50 k clicks from au-thenticated users. The contribution distribution across u sers has a long tail, which has also been observed in a wide variety of ot her on-line communities [34]. Therefore, if we used all the data , the mostly inactive users would dominate the results and would l ikely give misleading design implications.

Our micro analysis is particularly sensitive to these heavy tails since series of mostly empty values would destroy correlati ons from weak signals. To circumvent this problem we establish a user contribution threshold of an average of one contribution ev ery other week during the analyzed period. Only users with more contri bu-tions are considered. Furthermore the micro analysis is onl y done for each user from the point where his or her contributions st arted till the time contribution stopped. If this period is less th an a month, the user will only be considered in the macro analysis. These fil-ters led to a study of 295 users (about 16% of all users receiving clicks from authenticated users) in the micro analysis and (about 50% of all click receivers) in the macro analysis. We a lso note that only about 10% of all users received clicks on their au-thored documents from authenticated users, which was the li miting factor of the scope of this analysis, and which is a direct eff ect of the long tail of contributions.
We employ three sets of metrics on all impact and contributio n factors: correlation structure , contribution correlation and contri-bution predictability .

The correlation structure is represented by the partial autocor-relation function (PACF) [33] for lag k defined as where Z t is the datum observed at time t , and Corr is the corre-lation defined as Cov ( Z t , Z t + k ) / X  where Cov is the covariance and  X  the standard deviation. The conditional terms in Eq. 1 dis-tinguish the PACF from the autocorrelation function (ACF). The PACF is useful in that it gives the correlation between two da ta points with mutual linear dependencies of intervening data points removed. It can also be used as a direct indicator of the numbe r of lags to include in autoregression models [33]. Furthermo re, it is convenient in our analysis because the average value across a large number of tests (one for each user) makes intuitive sense.
Standard time series models assume stationarity in varianc e, i.e. variance is assumed not to change over time. From observatio ns of the time series we saw that the variance was proportional t o the level, e.g. scatter plots are not fully linear but drop off for high values. The typical Box-Cox stationarity transformation [ 5] in this case is to take the square root of the impact factors, which al so worked well for us.

The contribution correlation metric is defined in terms of a lin-ear regression of an impact factor to the contribution facto r (both factors are sampled in the same time interval). The null hypo thesis is that the coefficient  X  1 is 0 in the fitted model where C t is the contribution factor at time t , I t is the impact factor at time t ,  X  0 is the intercept of the regression (level), and stochastic white noise process. To quantify impact we track the value [28] representing how much of the variance of the contr ibu-tion factor can be explained by the variance in the impact fac tor. This yields a value between 0 and 1 , where 1 means that all of the variance can be explained by the impact factor. It is defined a s where Z t is the observed series datum, r t is the modelled datum, and T is the total number of periods modelled. Similar to the PACF metric the R 2 metric has an intuitive aggregate interpretation across users, and more importantly it is designed to compare model fi ts in an unbiased way which is at the core of our method.

The contribution predictability metric is also defined in terms of a linear regression. The null hypothesis is that the coeffi cient  X  ,  X  3 are all 0 in the fitted model: we again collect the R 2 statistic. This value is referred to as the predictive power here and it is later used to order the metrics by level of impact. For this metric we also measure whether the i mpact is significantly positive or negative by using the p -value of the null hypothesis that individual coefficients  X  are 0 and applying the statistic (  X  /  X  ). As an aggregate measure we define: where  X  k is the coefficient of first lag with a significant the 5% significance level. If there are no significant lags Intuitively the contribution predictability metric denotes the impact that the history, up to three weeks back, of clicks and commen ts has on the number of documents published in the current week.

We are not so concerned with causality versus correlation he re since we test the predictability of the contribution factor as well. Our main concern is to quantify and compare which predictor i s better. Furthermore, the time lags help disambiguate the di rection of the impact.
We start the analysis by just studying the AuthoredDocs , To-talClicks and TotalComments factors. Figure 1 shows the time se-ries of the contribution and impact factors aggregated in we ekly periods. Three features stand out. First, the clicks series shows a level shift starting in week 15 which coincides with an inte rnal technology conference that advertised our system. One coul d ar-gue that this shift should be suppressed with differentiati on, but we found that doing so would in fact destroy useful information such as correlations. Since differentiation can be compared to close to 1 , it is also accommodated for in our model. Another rea-son to not differentiate is that it may help some users X  model fits but destroy others and thus create an unwanted bias in our ana lysis.
Second, the document spike at week 35 coincides with a major event (acquisition) for HP that was heavily discussed in the blogo-sphere. This exogenous event also resulted in an unusually l arge number of new users appearing in many of the venues we tracked , who had no prior history we could use to make predictions. We found it clarifying to remove this spike, since it was not cau sed by any previous participation factors but it impacted the cont ribution factor without prior, current or future changes in any of the impact factors, causing anomalies in some of the documents and comm ents statistics.

Finally, the drop at week 52 corresponds to the Christmas hol i-day closure. Because the Christmas break affected all metri cs the same way we chose not to suppress the results from that week ar ti-ficially.

Figure 2 shows the scatter plots with smoothed regression li nes for the regression factor against the regression response ( note that the week 35 contribution anomaly has been suppressed). The r e-gression factors are lagged by one week to represent a predic tive regression setup. We can see that the smoothing algorithm (G aus-sian least squares) failed to draw a regression line for the c licks series which is a first hint that this factor has less impact. N ext we will quantify that visual cue.

The top part of Table 4 shows the micro analysis metrics mea-sured using individual user regressions. The R 2 cp power metric is represented by the mean value followed by the first and third quartile in parentheses; all other metrics just sh ow the mean to conserve space. The heavily skewed contribution dis tri-bution made the 5% significance bounds very wide, which is why we show the quartile bounds in the table. Looking at the micro metrics, the correlation structure has at most one week of me m-ory for all the factors: only PACF(1) shows significant corre lation. Thus, for individual users, only clicks and comments receiv ed very recently on authored documents seem to affect contribution s. The contribution correlation is substantially higher for the TotalCom-ments factor compared to the TotalClicks factor. That is, the same period correlation between comments and documents is highe r than the same period correlation between clicks and documents.
 Finally, the contribution prediction is slightly better fo r Total-Comments compared to TotalClicks , but the AuthoredDocs con-tribution factor is the best predictor (highest R 2 vidual users, past authored documents matter more than feed back in terms of comments and readership such as clicks, when dete r-mining future contributions. Here we also see the first quant itative evidence for comments (visible impact) being more effectiv e than clicks (hidden impact), which we saw qualitatively in Figur e 2.
The bottom part of Table 4 shows the macro analysis results. T he interpretation of the macro results is somewhat different i n that it measures the predictability of the global system contribut ion given the global impact factor. We see substantially more memory i n the time series process correlation structure, in particul ar for the AuthoredDocs and TotalClicks metrics. This can be seen in the aggregate (macro) PACF metrics in Table 4 where the document publication two weeks back and the click traffic three weeks b ack have a non-negligible correlation to the current values. Th is in-crease in memory on the macro scale may be attributed to netwo rk effects not captured in the egocentric micro analysis. The c ontribu-tion correlation shows similar patterns compared to the ind ividual micro metrics but the contribution prediction metrics show a more substantial differentiation. TotalComments predicts better than To-talClicks , but again the AuthoredDocs metric is the best predictor by far.

The main result from the visibility analysis is that comment s have a greater effect than clicks when determining future do cument contribution, which was confirmed both on a micro and on a macr o scale. This result gives support to the first hypothesis, H1 , posed in Section 1.

We also note that our system displays the most popular storie s on the front page. So for the most influential users, clicks are i n some sense at least partially visible. That might explain the fac t that the comment and clicks metrics tend to reverse for the top contri buting users (not shown here). However, we consider clicks hidden b e-cause there is no information on where the clicks originated from, which will play a role in the diversity analysis below, and be cause only a very limited set of users benefit from the front page pop ular-ity exposure.
We now drill deeper into the diversity of the impact by studyi ng attributes of users who click and comment on documents. By im-pact diversity we mean, for instance, how many different cities or countries the comments originated from and how well that pre dicts the future contribution of the user receiving the comments. For this analysis we restrict the presentation to the macro metrics b ecause of space considerations and because the differentiation wa s clearer between the attribute metrics on the macro scale. Table 5 sho ws the results.

Based on the contribution predictability results, the numb er of documents that comments are made on is more effective (gives stronger signal of the level of contribution the following w eek) than the number of documents that have been clicked on (the worst p re-dictor). One could argue that this may partly be explained by there being a higher effort involved in commenting on a new documen t than adding more comments, something that does not hold true for clicks. Comparing geographic metrics with organizational ones we can see that the country and city metrics are slightly better than the corresponding organization unit metrics both for clicks an d com-ments. So geographic diversity tends to be more important th an or-ganizational diversity to motivate contribution. We also n ote again that the impact metrics for comments are consistently highe r than those for clicks. The fact that the macro analysis agrees wit h the micro analysis in this regard is a sign of stability in the res ult that hypothesis H1 is (quantitatively) supported by the data.
The key findings in the time series analysis as to what moti-vated user contribution were: comments are more effective t han clicks ( H1 ); diversity does matter, in particular geographic diver-sity; and previous contributions play a greater role for ind ividual users than feedback and readership factors. Promoting atte ntion from colleagues across geographic barriers, would thus see m to be the most effective way of nurturing and motivating contribu tions in the enterprise social media that we study according to this a nalysis. In terms of sensitivity of the results, we note that omitting a week of data during a contribution anomaly (week 35), resulted in better predictive power across all factors, and also served to diff erenti-ate the results better. The main quantitative difference if the week would have been kept in the data was that the AuthoredDocs factor would not have been the best predictor in the macro metrics, a nd would thus have contradicted the micro analysis, which rema ined unaffected. In general the macro metrics were more sensitiv e to different treatments of the data, whereas the micro analysi s showed less factor differentiation but remained stable.
Activity regression considers how activity in a person X  X  wo rk-group relates to a person becoming active and continuing act ivity. For the purposes of our analysis, an employee X  X  workgroup consists of a person, his or her manager, and all direct repor ts to that manager. These workgroups are a different grouping o f employees than the organization unit discussed in Section 4 .
For each venue, we defined a series of activity events. Definin g whether a person is active is arbitrary. As a simple measure, which captures most of the continued activity of the more active us ers in our data, we consider a person  X  X ctive X  if they had posted t o the venue within the previous 30 days, and  X  X nactive X  otherwise . Using a period of 30 days is a commonly used criterion for lack of act ivity. In our data, about 5% of a user X  X  posts are more than 30 days aft er a prior post in the same venue by that user.

We could also consider other measures of inactivity, such as when people have significantly larger gap between posts then their individual prior history rather than a fixed time (30 days) fo r every-one. This would test whether the analysis significantly conf ounds two distinct processes: an active user deliberately decidi ng to be-come inactive vs. users who have a continuing, but low, parti cipa-tion rate. The former (explicit decisions to change prior be havior) may have more significance, and these two cases may require di f-ferent methods to increase participation.
For the series of activity events, we denote each post as continu-ing or new activity according to whether the person had previously posted in that venue within the last 30 days. We ignore new events within the first 30 days a service is observed, because we don X  t know for certain that the user was inactive for the previous m onth. We add an inactive event for a user after 30 days of no posts.
A large reorganization at HP made the manager relation unsta ble in the directory, and so for this section we restricted our da ta set to events up through September 2008, removing about three mont hs X  worth of data.

We examined the relation between people becoming active and the activity of their managers by recording, for each new event whether their manager was active in the past 30 days in that ve nue, and p AM , the fraction of employees with active managers at the time of the event. Under the null hypothesis that there is no r ela-tion between these properties, the fraction of new events with active managers should be close to that expected by random selectio n with probability
Conversely, we compare manager activity of users who become inactive (i.e, inactive events) with the fraction of active employees who have active managers at the time of the event. If employee s who are already active choose to become inactive with no rela tion to the activity of their manager, we expect the fraction of inactive events with active managers should be close to that expected by random selection with probability
These probabilities vary with time. For our analysis we comp are the observed events with these corresponding probabilitie s at the time of the event.
For employees who become active, Figure 3 compares the ob-served and expected fractions of active managers for the dif ferent venues.

Of the people who become active, about 5  X  10% have active managers at the time; compared to about a tenth that number fo r employees as a whole. We quantify this difference with rando m-ization tests [9]. Specifically, for each new event e we record random fraction Figure 3: Fraction of new events with active managers: ob-served and expected if the events were selected at random fro m among employees at the time. The labels for the points indica te the venue (see the codes in Table 1). The line indicates equal values for the observed and expected fractions, which is wel l to the left of most of the observed values. equal to 1 or 0 if the manager was active or not at the time, re-spectively. We also record the fraction p AM ( e ) , from Eq. 6, at the time of the event. The observed number of events with an activ e manager is n AM = P
To compare with the null hypothesis that there is no relation be-tween these events and manager activity, we generate N = 1000 samples s 1 , . . . , s N . A sample consists of selecting random values, 0 or 1, for each x e where the probability for x e = 1 is We denote the sum of these randomly generated values for samp le i as s i , which is a sample for the number of active managers for the events under the null hypothesis. The set of samples esti mates the distribution of number of active managers we would obser ve under the null hypothesis. If the the actual observed value, differs from most of these samples, the null hypothesis is un likely to account for the observation.

This procedure shows that for all venues except Links, the hi gh fraction of active managers is unlikely to arise from random selec-tion among the population of employees ( p -value less than The Links venue is inconclusive, with only 141 new events, none of which had active managers.

A similar analysis of inactive events shows employees who be-come inactive are slightly less likely than random to have active managers. The difference between observed values and selec tion
P H continuing Figure 4: Proportion of events by active employees (i.e., th e continuing and inactive events) that are continuing events, i.e., continuing participation by the employee, as a function of n um-ber of coworkers active in the prior 30 days and whether the manager is active, according to a logistic regression fit for the Blog venue. Table 6: Parameters of the logistic regression model of Eq. 8 for blogs, and their 95% confidence intervals. with the null hypothesis is significant only for some venues: Blogs, Comments, Forums and Tags (all with p -value less than 10 null hypothesis of no relation between manager activity and a user becoming inactive.

As a specific model of how activity of the workgroup relates to continued participation, we fit a logistic regression to the probabil-ity an event by an active employee is another post ( i.e. , continu-ing ) rather than becoming inactive, based on whether the manage r was active at the time and the number of active coworkers. A lo -gistic model is appropriate to model binary outcomes (in thi s case whether the event is continuing or not) [10]. In contrast to the re-gression model for a continuous outcome in Section 4, with bi nary outcomes the noise model involves independent Bernoulli tr ials, with the probability for success ranging between 0 and 1, dep end-ing on the model parameters. Specifically, we fit a model of the form where c is the number of active coworkers and m is an indicator variable for inactive managers, i.e., is 0 or 1 according to w hether the manager was active or not. A positive value of  X  c means this probability increases as the number of active coworkers inc reases, i.e., the person is more likely to continue activity rather t han be-come inactive. A negative value for  X  m means continuing events are more likely when the manager is active.

For blogs, Figure 4 shows the regression model, with paramet ers in Table 6, relating the probability an event by an active emp loyee is continuing rather than inactive . The estimated value for about 100 times larger in magnitude than  X  c , so this model indi-Table 7: Number of prior posts for continuing and inactive events. Table 8: Number of recent replies for continuing and inactive events. cates whether the manager is active has far more influence tha n the activity of a single coworker in the workgroup.
Using the list of activity events described above, we compar ed continuing and inactive events. As a measure of feedback, visible to the user, for each event we determine the number of recent replies to that person X  X  posts in the venue ( i.e. , within the last 30 days). The feedback is a measure of community interest in the user X  X  participation. We also count the user X  X  prior posts t o the venue, as a measure of the level of the user X  X  participation.
Table 7 compares the average number of prior posts in two venues, Blogs and Forums, with a large number of events. In bo th venues, users involved in continuing events tend to have longer history in the venue, as measured by the number of posts. To quantify the significance of the differences between prior p osts seen in the table, we apply a permutation randomization test . That is, under the null hypothesis of no relation between typ e of event (either continuing or inactive ) and number of prior posts, we generate samples by randomly permuting the number of prio r posts among all these events. We then compare the observed difference in the averages with the distribution of these sa mples. These randomization tests for difference in means in prior p osts between continuing and inactive events indicate the differences seen in the tables are unlikely to arise by chance if there wer e no difference between these event types ( p -value less than
As discussed in Section 4, recent feedback to the user correl ates with continued activity in terms of number of posts. Table 8 pro-vides another view of that relation. The continuing events are as-sociated with larger number of recent replies. Thus not only is the amount of subsequent activity related to feedback, but so is a user X  X  choice to become inactive. The permutation randomiz ation test described above indicates the differences are unlikel y to arise by chance if there were no difference between these event typ es ( p -value less than 10  X  3 ). Activity within a user X  X  workgroup correlates with partici pation. Manager and coworker activity are correlated with employee s be-coming active in the venues we studied, supporting the secon d hy-pothesis, H2 , in Section 1. On the other hand, lack of manager activity is only modestly correlated with employees becomi ng in-active, and only in some of the venues.

We suspect managers X  participation is more important in ven ues that imply discussion ( e.g. , blogs, blog comments, forums) than in venues that more naturally serve as memory archives ( e.g. , links, wikis). Prior interviews with bloggers found that they seek external validation for their invested time [37]. We believe that man agers  X  X eading by example X  has a positive impact on getting their d irect reports to try participating in enterprise social media.

A long history of posts correlates with continued activity, as do having many recent replies. This correlation between conti nued activity and history occurs in a variety of web sites where us ers contribute content, including Digg and Wikipedia [34].
Through an analysis of temporal relations among measures of user activity, feedback and workgroup involvement, we foun d ro-bust correlations between these measures and activity. The se re-sults match the factors people emphasized in prior intervie w stud-ies of a small set of social media users in this company. In ter ms of predicting future participation in a venue, the number of prior posts and of recent posts account for the most variation amon g the factors we studied for individual users. This mirrors other findings that the more people contribute to an online community, the m ore likely they are to continue posting [34]. As additional fact ors, we found comments the user received were more predictive than t otal readership. Thus users X  knowledge that their contribution s are of interest to others in the organization relates to further pa rticipation, in accordance with factors mentioned in the interview studi es:
In terms of readership, measured by clicks, and attention, m ea-sured by comments, we find that diversity, particularly geog raphic diversity, is an important predictor of future participati on. Since readership in general, and its diversity in particular, are not directly visible to users, this observed relationship suggests the r eadership measures are a proxy for the relevance of a user X  X  posts to the com-munity. This study was situated in a large global enterprise ; in smaller, more collocated organizations, the diversity of v isibility may be less of a motivation.

We also found activity within a user X  X  workgroup correlates sig-nificantly with participation, but has a weaker relation wit h users becoming inactive. This suggests direct exposure to social media, via people the user interacts with regularly, is important t o encour-age people to start using the media. But once they start, feed back from throughout the organization becomes significant.

In short, it seems that managers X  participation is a key moti vator in getting people to start contributing to enterprise social media, while comments and a diverse readership are key in getting th em to sustain their contributions. This echoes comments made in i nter-views by employees at HP: Corporate culture may be a factor in what motivates employee s. At HP, as in many large organizations, employees X  performan ce is evaluated principally by their direct managers, so manager s have considerable influence. This effect may be smaller at compan ies that emphasize peer-review performance metrics or have mat rix-style management structures. However, these findings are li kely generalizable to all large companies with manager-driven p erfor-mance evaluations.
These findings suggest that organizations seeking to reap th e benefits of widespread social media usage should encourage m an-agers to  X  X ead by example X  or at least support the practice. I ndeed, a senior vice president at HP received high praise for engagi ng with individual contributors using his internal blog, and inspi red a num-ber of people in his division to experiment with blogs.

Once people have invested time in creating a blog post or soci al network profile, tools should provide some feedback to conte nt au-thors that their content is being seen by others. Making meas ures of attention visible to users will help sustain participati on by those whose posts are seen to be most interesting to the community. This could take the form of simple hit counters or deeper analytic s about readers; for example, Flickr shows how many people viewed ea ch photo, and YouTube now provides details about the pages link ing to a video. But moreover, this work shows that in corporate envi ron-ments, it X  X  not just the raw quantity of attention an author r eceives but also who the readers are. This might suggest providing some basic demographics highlighting the diversity of an author  X  X  read-ership like Google Analytics provides for websites, or samp les of readers X  details similar to how LinkedIn shows the professi ons of visitors to a user X  X  profile.

Another surprising finding in this work is that activity at th e end of a week is relatively less likely to influence behavior the f ollow-ing week, suggesting that to some extent people may forget ab out the previous week X  X  content over the weekend. While more wor k is needed to quantify this effect, it may encourage designer s of cor-porate social media to help remind users of the context of con ver-sations the previous week on Mondays.
Our results, and their correspondence with the interview st ud-ies, suggest factors that may causally influence people to st art and continue participating in social media. An important direc tion for future work is to test the extent to which the observed correl a-tions are in fact causal. For social media within the organiz ation, we can explicitly observe how changes in the organizational struc-ture and the information presented to users affects partici pation. A further possibility is intervention experiments where dif ferent sub-groups of people are provided with different feedback, whic h can give stronger confidence for causal relationships and sugge stions of how to improve the number of participants and design feedb ack to encourage them to provide information relevant to others in the organization.

One direction for elaborating relationships between emplo y-ees and coworkers or managers is to extend the linear regres-sion models to consider nonlinear relations and whether the re is a  X  X ose/response X  relation between participation and, say , how ac-tive a manager is in terms of number of posts rather than just a yes or no feature of whether the manager is active. This could dis tin-guish whether manager activity acts mainly as a positive exa mple or whether a manager X  X  perceived disapproval of employees X  par-ticipation is a more important issue, as expressed in some of the interviews.

We also plan to conduct intervention studies to explore whet her exposing readership data to authors affects their behavior . While this could certainly motivate people whose content is widel y read, it remains to be seen whether revealing that their cont ent is unpopular might discourage other authors. Another area t hat merits exploration is whether the presence of an explicit  X  X  ollower X  network further encourages users to contribute as it does on Twitter [19].
 We thank Sarita Yardi and Bernardo Huberman for helpful com-ments.
