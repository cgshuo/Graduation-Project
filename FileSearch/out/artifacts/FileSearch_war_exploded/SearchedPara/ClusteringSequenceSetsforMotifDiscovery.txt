 Disco vering how DN A-binding proteins called transcription factor s (TFs) regulate gene expression programs in living cells is fundamental to understanding transcriptional regulatory netw orks con-trolling development, cancer , and man y human diseases. TFs that bind to specic cis-re gulatory elements in DN A sequences are essential for mediating this transcriptional control. The rst step motifs .
 We address the problem of disco vering sequence motifs that are enriched in a given tar get set of sequences, compared to a background model (or a set of background sequences). There have been extensi ve research works on statistical modeling of this problem (see [1] for revie w), and recent works have focused on impro ving the motif-nding performance by inte grating additional informa-tion into comparati ve [2] and discriminati ve motif disco very [3].
 one motif, but this assumption is often incorrect. For example, a recent study examining the binding specicities of 104 mouse TFs observ ed that nearly half of the TFs recognize multiple sequence motifs [4]. Second, it is unclear how to select the tar get set on which over-represented motifs are returned. The tar get set of sequences is often constructed from genome-wide binding location data (ChIP-chip or ChIP-seq) or gene expression microarray data. Ho we ver, there is no clear way to partition the data into tar get and background sets in general. Third, a unied algorithm which is applicable to diverse motif disco very problems is solely needed to pro vide a principled frame work for developing more comple x models. ple motifs on multiple sets of sequences. One can vie w our frame work as an extension of the classic sequence models such as the two-component mixture (TCM) [5] and the zero or one occurrence per sequence (ZOOPS) [6] models in which sequences are partitioned into two clusters, depending on the multiple sequence sets into clusters having distinct sequence motifs, which impro ves the motif-nding performance over the classic models by enhancing signal-to-noise ratio of input sequences. We also sho w how our algorithm can be applied into three dif ferent problems by simply changing the way of constructing multiple sets from input sequences without any algorithmic modications. We are given M sets of DN A sequences S = fS 1 ; : : : ; S M g to be grouped according to the type of motif involv ed with, in which each set is associated with only a single motif but multiple binding sites are present in each sequence. A set of DN A sequences S m = f s m; 1 ; : : : ; s m;L of binding sites per sequence, we represent each sequence s m;i as a set of overlapping subsequences s t sequence sets S into K disjoint clusters, where sets in the same cluster are associated with the same common motif.
 For a motif model, we use a position-frequenc y matrix whose entries correspond to probability distrib utions (over the alphabet ) of each position within a binding site. We denote by k 2 R W 4 the k th motif model of length W over , where &gt; k;wl 0 for 8 w; l , and P frequencies over the alphabet within non-binding sites, is dened by a P th order Mark ov chain (represented by a ( P + 1) -dimensional conditional probability table).
 Our goal is to construct a probabilistic model for DN A motif disco very where we identify multiple motifs through searching for patterns which are shared across multiple sets of sequences. Our model binding site-indicating latent variables z m;i ) simultaneously , where these two tasks interact with each other . We assume that the distrib ution of S is modeled as a mixture of K components, where it is not kno wn in adv ance which mixture component underlies a particular set of sequences. We also as-sume that the conditional distrib ution of the subsequence s W two components, each of which corresponds to the motif and the background models, respecti vely . Then, the joint distrib ution of observ ed sequence sets S and (unobserv ed) latent variables Z and T conditioned on parameters is written as: where Z = f z m;ij g and T = f t m g . The graphical model associated with (1) is sho wn in Fig. 2. The generati ve process for subsequences s W weights v = [ v 1 ; : : : ; v K ] &gt; (in volving set clusters) from the Dirichlet distrib ution: indicator t m for S m , according to the multinomial distrib ution p ( t m j v ) = Q K k th motif model k is dra wn from the product of Dirichlet distrib utions: positions of binding sites are governed by the prior distrib ution specied by: where the mixture weights = [ 1 ; 2 ] &gt; satisfy 1 ; 2 0 and 1 + 2 = 1 . Finally , the subsequences s W where where ( l; s 0. Here, the background model is specied by the 0 th -order Mark ov chain for notational simplicity . Several assumptions simplify this generati ve model. First, the width W of the motif model and the number K of set clusters are assumed to be kno wn and x ed. Second, the mixture weights together with the background model 0 are treated as parameters to be estimated. We assume the hyperparameters and are set to x ed and kno wn constants. The full set of parameters and hyper -parameters will be denoted by = f ; ; ; 0 g . Extension to double stranded DN A sequences is obvious and omitted here due to the lack of space.
 Our model builds upon the existing TCM model proposed by [5] where the EM algorithm is applied to learn a motif on a single tar get set. This model actually generates subsequences instead of se-quences themselv es. An alternati ve model which explicitly generates sequences has been proposed based on Gibbs sampling [7, 8]. Note that our model is reduced to the TCM model if K , the number of set clusters, is set to one.
 Our model shares some similarities with the recent Bayesian hierarchical model in [9] which also ing motifs already disco vered, and in our formulation, we try to cluster sequence sets and disco ver motifs simultaneously . We nd the congurations of Z and T by maximizing the posterior distrib ution over latent variables: To this end, we use Gibbs sampling to nd the posterior modes by dra wing samples repeatedly from the posterior distrib ution over Z and T . We will deri ve a Gibbs sampler for our generati ve model in which the set mixture weights v and motif models f k g K con vergence rate and the cost per iteration [8].
 The critical quantities needed to implement the Gibbs sampler are the full conditional distrib utions applying Bayes' rule, Fig. 2 implies that this distrib ution factorizes as follo ws: where Z n m denotes the entries of Z other than Z m = f z m;i g L m and is given by mar ginalizing the set mixture weights v : where N m of (7) depends on the current assignments T n m as follo ws: where N wl = N m Note that N m excluding the ones of the m th set. Similarly , N m bindings sites of the m th set.
 grating over the motif model k , we then have the follo wing factorization: posterior distrib ution of z m;ij is given by: Combining (7) with (10) is suf cient to dene the Gibbs sampler for our nite mixture model. To posterior distrib ution: where N k = P We evaluated our motif-nding algorithm on the three dif ferent tasks: (1) ltering out undesirable noisy sequences, (2) incorporating evolutionary conserv ation information, and (3) clustering DN A sequences based on the learned motifs (Fig. 3). In the all experiments, we x ed the hyper -parameters so that k = 1 and l = 0 : 5 . 5.1 Data sets and evaluation criteria We rst examined the yeast ChIP-chip data published by [10 ] to investigate the effect of ltering out noisy sequences from input sequences on identifying true binding sites. We compiled 156 sequence-sets by choosing TFs having consensus motifs in the literature [11 ]. For each sequence-set, we dened its sequences to be probe sequences that are bound with P -value 0 : 001 . Figure 3: Three dif ferent ways of constructing multiple sequence sets. Black rectangles: sequence sets, Blue bars: sequences, Red dashed rectangles: set clusters, Red and green rectangles: motifs. To apply our algorithm into the comparati ve motif disco very problem, we compiled orthologous sequences for each probe sequence of the yeast ChIP-chip data based on the multiple alignments of seven species of Saccharomyces (S. cere visiae, S. paradoxus, S. mikatae, S. kudria vze vii, S. bayanus, S. castelli, and S. kluyv eri) [12 ]. In the experiments using the ChIP-chip data, the mo-tif width was set to 8 and a fth-order Mark ov chain estimated from the whole yeast inter genic sequences was used to describe the background model. We x ed the mixture weights so that 2 = 0 : 001 .
 We next constructed the ChIP-seq data for human neuron-restricti ve silence factor (NRSF) to deter -mine whether our algorithm can be applied to partition DN A sequences into biologically meaningful clusters [13 ]. The data consist of 200 sequence segments of length 100 from all peak sites with the top 10% binding intensity ( 500 ChIP-seq reads), where most sequences have canonical NRSF-binding sites. We also added 13 sequence segments extracted from peak sites ( 300 reads) kno wn to have noncanonical NRSF-binding sites, resulting in 213 sequences. In the experiment using the ChIP-seq data, the motif width was set to 30 and a zero-order Mark ov chain estimated from the 213 sequence segments was used to describe the background model. We x ed the mixture weights so that 2 = 0 : 005 .
 In the experiments using the yeast ChIP-chip data, we used the inter -motif distance to measure the set only if at least one of the position-frequenc y matrices constructed from the identied binding sites is at a distance less than 0.25 from the literature consensus [14 ]. 5.2 Filtering out noisy sequences Selecting tar get sequences from the ChIP-chip measurements is lar gely left to users and this choice is often unclear . Our strate gy of constructing sequence-sets based on the binding P -value cutof f would be exposed to danger of including man y irrele vant sequences. In practice, the inclusion of solution is to cluster input sequences into two smaller sets of tar get and noisy sequences based on sequence similarity , and predict motifs from the clustered tar get sequences with the impro ved signal-to-noise ratio. This two-step approach has been applied to only protein sequences because DN A sequences do not share much similarity for effecti ve clustering [15 ].
 constructed multiple sets by treating each sequence of a particular yeast ChIP-chip sequence-set as numbers of clusters: K = 1 (without ltering) and K = 2 (clustering into two subsets of true and noisy sequences). We ran each experiment ve times with dif ferent initializations and reported means with 1 standard error . Figure 4 sho ws that the ltering approach ( K = 2 ) outperforms the ZOOPS or TCM models can also handle noisy sequences by modeling them with only a background model [5, 6]. But we allo w noisy sequences to have a decoy motif (randomly occurring sequence Figure 4: Effect of ltering out noisy sequences on the number of successfully identied motifs on the yeast ChIP-chip data. K = 1 : without ltering, K = 2 : clustering into two subsets. patterns or repeating elements) which is modeled with a motif model. Because our model can be reduced to these classic models by setting K = 1 , we concluded that noisy sequences were better represented by our clustering approach than the pre vious ones using the background model (Fig. 4). Two additional lines of evidence indicated that our ltering approach enhances the signal-to-noise ratio of the tar get set. First, we compared the results of our ltering approach with that of other baseline methods (AlignAce [16 ], MEME [6], MDScan [17 ], and PRIORITY -U [11 ]) on the same yeast ChIP-chip data. For AlignAce, MEME and MDScan, we used the results reported by [14 ]; strate gy. We expected that our model would perform better than these four methods because the y try to remo ve noisy sequences based on the classic models. By comparing the results of Fig. 4 and Table 1, we see that our algorithm still performs better . Second, we also compared our model with DRIM specically designed to dynamically select the tar get set from the list of sorted sequences according to the binding P -values of ChIP-chip measurements. For DRIM, we used the result reported by [18 ]. Because DRIM does not produce any motifs when the y are not statistically enriched at the top of the rank ed list, we counted the number of successfully identied motifs on the sequence-sets where DRIM generated signicant motifs. Our method (number of successes is 16) was slightly better than DRIM (number of successes is 15). 5.3 Detecting evolutionary conser ved motifs Comparati ve approach using evolutionary conserv ation information has been widely used to impro ve the performance of motif-nding algorithms because functional TF binding sites are lik ely to be conserv ed in orthologous sequences. To incorporate conserv ation information into our clustering frame work, orthologous sequences of each sequence of a particular yeast ChIP-chip sequence-set were considered as one set and the number of clusters was set to 2 (Fig. 3(b)). The constructed sets contain at most 7 sequences because we only used seven species of Saccharomyces. We used the single result with the highest objecti ve function value of (11) among ve runs and compared it with the results of ve conserv ation-based motif nding algorithms on the same data set: MEME c [10 ], PhyloCon [19 ], PhyMe [20 ], PhyloGibbs [21 ], PRIORITY -C [11 ]. For the ve methods, we used the results reported by [11 ]. We did not compare with discriminati ve methods which are kno wn to perform better at this data set because our model does not use negati ve sequences. Table 1 presents the motif-nding performance in terms of the number of correctly identied motifs for each algorithm. We see that our algorithm greatly outperforms the four alignment-based methods conserv ed across the aligned blocks of orthologous sequences. In our opinion, it is because diverged algorithm performs some what better than PRIORITY -C , which is a recent alignment-free method. 5.4 Clustering DN A sequences based on motifs To examine the ability of our algorithm to partition DN A sequences into biologically meaningful clusters, we applied our algorithm to the NRSF ChIP-seq data which are assumed to have two Table 1: Comparison of the number of successfully identied motifs on the yeast ChIP-chip data for dif ferent methods. NC: Non-conserv ation, EC: Ev olutionary conserv ation, A: Alignment-based, AF: Alignment-free, C: Clustering.
 dif ferent NRSF motifs (Fig. 3(c)). In this experiment, we have already kno wn the number of clusters (
K = 2 ). We ran our algorithm ve times with dif ferent initializations and reported the one with 5. The two motifs correspond directly to the pre viously kno wn motifs (canonical and non-canonical NRSF motifs). Ho we ver, other motif-nding algorithms such as MEME could not return the non-canonical motif enriched in a very small set of sequences. These observ ations suggest that our be used to nd une xpected novel motifs. ing multiple sets of sequences where we cluster DN A sequences and learn motifs interacti vely . We have presented a nite mixture model with two dif ferent types of latent variables, in which one is associated with cluster -indicators and the other corresponds to motifs (transcription factor binding Our empirical results sho w that the proposed method can be applied to various motif disco very prob-lems, depending on how to construct the multiple sets. In the future, we will explore several other extensions. For example, it would be interesting to examine the possibility of learning the num-ber of clusters from data based on Dirichlet process mixture models, or to extend our probabilistic frame work for discriminati ve motif disco very .

