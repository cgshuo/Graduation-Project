 of a partition P = { S is, in the field of machine learning.
 V k all information about MAC clusterings for all parameters in polynomial time in total. case of the parametrized MAC clustering problem in an implic it way. of computational experiments in Section 5, and give conclud ing remarks in Section 6. cost f [ P ] and the number of clusters |P| . 2.1 Definition the given data set. Therefore, it may be said that P  X  is a natural clustering. cost (MAC) clustering problem to [10] are closely related.
 the information about optimal k -clusterings ( k = 1 , . . . , n ). 2.2 Structure property We will investigate the structure of all  X  -MAC clusterings. Denote by R have  X   X  X   X  X  X |P|  X   X  f [ P ]  X  X P|  X  for all  X   X  R in (1) is represented as where h : R h given  X   X  0 . This point will be discussed in Section 4 in detail. h
P : R +  X  R a piecewise-linear concave function on R also Figure 1). In addition, a  X  -MAC clustering can be characterized as follows. h (  X  (  X  )) = f [ P ]  X  X P|  X  (  X  ) . Then P is a  X  -MAC clustering. f [ Q ] / ( |Q| X   X  ) . Therefore, P is a  X  -MAC clustering. take values  X  s interval R P mines h at all  X   X  R  X  I 1 = [  X  (0) ,  X   X  1 ) , I 2 = [  X   X  1 ,  X   X  2 ) , . . . , I d  X  = [  X   X  d  X   X  1 , +  X  ) Lemma 3. Let j  X  X  1 , . . . , d  X  } . For any  X   X  B Lemma 3 implies that if we can find the collection {P the collection {P {P polynomial time algorithm that solves the MAC problem (1) co mpletely. Section 4 precisely.
 F IND P ARTITION can be designed to run in polynomial time.
 Lemma 4. For any  X   X  0 , the procedure F IND P ARTITION (  X  ) runs in O( n SFM ( n )) . submodular function [4, 14].
 Let us call a partition P of V supporting if there exists  X   X  0 such that h (  X  ) = h tion, each P partition of V . Set Q because h (0) = f [ { V } ] = h partition P of V , if |P| = s and  X  R ( k,  X  ) is an interval in R + . All breakpoints of h are included in R (1 , n ) = R + . Suppose that we are given two supporting partitions Q and k &lt;  X  . We describe the algorithm S PLIT ( Q S the decision is negative, the algorithm finds a supporting pa rtition Q which can be given by Q functions h Set h = h Then algorithm gives an affirmative answer, returns Q P Q m = P The algorithm S PLIT can be summarized as follows.

Algorithm S PLIT ( Q
Input : Supporting partitions of V , Q
Output : The information about all breakpoints of h on the interval R ( k,  X  ) . 1 : Set  X  := ( f [ Q 2 : If h (  X  ) = h (positive case), return Q 3 : If h (  X  ) &lt; h (negative case), set m := |P| , Q By performing the algorithm S PLIT ( Q the information of all breakpoints of h is obtained. Therefore, the collection {P Theorem 5. The collection {P in the execution of S PLIT ( Q of S PLIT ( Q { 1 , . . . , n } . Therefore, F IND P ARTITION is called at most 2 n times in total. The main theorem of this paper directly follows from Lemma 3 a nd Theorem 5. (1) for all parameters  X   X  [0 , n ) can be computed in O( n 2 SFM ( n )) time in total. Schrijver [14], and the algorithm described in  X  4.2 is based on that algorithm. 4.1 The Dilworth truncation of an intersecting submodular f unction define f see that f f ( S ) ,  X  6 =  X  S  X  V } , where x ( S ) = Alternatively, the following property is known.
 and P( b g ) = P( g ) . Furthermore, the function b g can be represented as such that x ( { 1 , 2 } ) = f b f b f 4.2 Algorithm that finds a partition of b satisfying b f We know that b f be obtained directly for each S  X  V . To evaluate b f Edmonds [3]. Denote the set of all extreme points of P( b f of y  X  ex(P( b f  X  )) . For example, set x 0 i :=  X  M for each i  X  V , where M =  X  + Let L = ( i we compute  X   X  := max {  X  : x  X   X  1 +  X  e i the greedy algorithm to evaluate the value h (  X  ) = b f Theorem 8 ([3]) . For each  X  = 1 , . . . , n , we have b f Let us see that the greedy algorithm with b f discuss how to compute  X   X  in each iteration. Since x  X   X  1  X  P( b f It follows from Theorem 8 that the value h (  X  ) = b f Procedure F IND P ARTITION (  X  ) Input : A nonnegative real value  X   X  0 .

Output : A real value h 1 : Set P 0 :=  X  . 2 : For each  X  = 1 , . . . , n , do: 3 : Return h Basically, this procedure F IND P ARTITION (  X  ) is the same algorithm as the above greedy algorithm. But now, we compute P  X  in each iteration. Figure 6 shows the computation of P  X  in the  X  -th iteration of the pro-cedure F IND P ARTITION (  X  ) . For each  X  = 1 , . . . , n , P  X  is a partition of V  X  = { i 1 , . . . , i  X  } . Thus, P  X  is a partition of V . Let x be a vector in P( f x Lemma 9. For each  X  = 1 , . . . , n , we have b f tion that any cluster in P  X  is x  X  -tight for each  X  = 1 , . . . , n . Thus, f P The procedure F IND P ARTITION (  X  ) returns h by Lemma 9, we have b f 5.1 Illustrative example sizes of clusters with inclusive relations. 5.2 Empirical comparison algorithm seems to be competitive with the existing leading algorithms for these datasets. the theory of intersecting submodular functions from the vi ewpoint of clustering. Acknowledgments the Sciences X , KAKENHI (20310088, 22700007, and 22700147) , and JST PRESTO program. We would also like to thank Takuro Fukunaga for his helpful comm ents.
