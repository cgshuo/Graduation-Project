 There are two main reasons to learn the structure of graphical models: kno wledge disco very (to interpret the learned topology) and density estimation (to compute log-lik elihoods and mak e pre-dictions). The main dif culty in graphical model structure learning is that the hypothesis space is extremely lar ge, containing up to 2 d ( d 1) = 2 graphs on d nodes. When the sample size n is small, there can be signicant uncertainty with respect to the graph structure. It is therefore adv antageous to adopt a Bayesian approach and maintain an approximate posterior over graphs instead of using a single  X best X  graph, especially since Bayesian model averaging (BMA) can impro ve predictions. There has been much work on Bayesian inference for directed acyclic graphical model (D AG) structure, mostly based on Mark ov chain Monte Carlo (MCMC) or stochastic local search (SLS) [22 , 19, 16, 14]. MCMC and SLS methods for DAGs exploit the important fact that the mar ginal lik elihood of a DAG, or an approximation such as the Bayesian Information Criterion (BIC) score, can be computed very efciently under standard assumptions including independent conjug ate priors, and complete data. An equally important property in the DAG setting is that the score can be quickly updated when small local changes are made to the graph. This con veniently allo ws one to mo ve rapidly through the very lar ge graph space of DAGs.
 Ho we ver, for kno wledge disco very , a DAG may be an unsuitable representation for several reasons. First, it does not allo w directed cycles, which may be an unnatural restriction in certain domains. Second, DAGs can only be identied up to Mark ov equi valence in the general case. In contrast, undirected graphs (UGs) avoid these issues and may be a more natural representation for some problems. Also, for UGs there are fast methods available for identifying the local connecti vity at each node (the node' s Mark ov blank et). We note that while the UG and DAG representations have between UGs and DAGs from a density estimation perspecti ve may be less important [12 ]. Most prior work on Bayesian inference for Gaussian Graphical Models (GGMs) has focused on the special case of decomposable graphs ( e.g. , [17, 2, 29]). The popularity of decomposable GGMs is mostly due to the fact that one can compute the mar ginal lik elihood in closed form using similar assumptions to the DAG case. In addition, one can update the mar ginal lik elihood in constant time after single-edge mo ves in graph space [17]. Ho we ver, the space of decomposable graphs is much smaller than the space of general undirected graphs. For example, the number of decomposable divide the number of decomposable graphs by the number of general undirected graphs, we get the limits the subclass of UGs available for modeling purposes, even for small d . Several authors have studied Bayesian inference for GGM structure in the general case using approximations to the mar ginal lik elihood based on Monte Carlo methods ( e.g., [8, 31, 20, 3]). Ho we ver, these methods cannot scale to lar ge graphs because of the high computational cost of Monte Carlo approximation. In this paper , we propose several techniques to help accelerate approximate Bayesian structural inference for non-decomposable GGMs. In Section 2, we sho w how to efciently compute BIC and Laplace approximations to the mar ginal lik elihood p ( Dj G ) by using recent con vex optimization methods for estimating the precision matrix of a GGM. In Section 3, we present a novel frame work for generating lar ge sets of high-quality graphs which we call  X Neighborhood Fusion X  (NF). This frame work is quite general in scope and can use any Mark ov blank et nding method to devise a set of probability distrib utions (proposal densities) over the local topology at each node. It then species rules for  X fusing X  these local densities (via sampling) into an approximate posterior over whole graphs p ( G jD ) . In Section 4, we combine the complementary strengths of NF and existing SLS methods to obtain even higher quality posterior distrib utions in certain cases. In Section 5, we present an empirical evaluation of both kno wledge disco very and predicti ve performance of our methods. For kno wledge disco very , we measure structural reco very in terms of accurac y of nding true edges in synthetic GGMs (with kno wn structure). For predicti ve performance, we evaluate test set log-lik elihood as well as missing-data imputation on real data (with unkno wn structure). We sho w that the proposed NF and hybrid NF/SLS methods for general graphs outperform current approaches to GGM learning for both decomposable and general (non-decomposable) graphs. lik elihood of a non-decomposable GGM under the G-W ishart prior . Unlik e the decomposable case, here the mar ginal lik elihood can not be found in closed form. Our main contrib ution is the insight that recently proposed con vex optimization methods for precision matrix estimation can be used to efciently nd the mode of a G-W ishart distrib ution, which in turn allo ws for more efcient computation of BIC and Laplace modal approximations to the mar ginal lik elihood.
 We begin with some notation. We dene n to be the number of data cases and d to be the number of data dimensions. We denote the i th data case by x X , with the corresponding scatter matrix S = X T X (we assume centered data). We use G to denote an undirected graph, or more precisely its adjacenc y matrix. Graph edges are denoted by unordered pairs ( i; j ) and the edge ( i; j ) is in the graph G if G having the same zero-pattern as G is denoted by S ++ its inverse or the precision matrix by = 1 . We also dene h A; B i = Trace ( AB ) . The Gaussian lik elihood p ( Dj ) is expressed in terms of the data scatter matrix S in Equation 1. We denote the prior distrib ution over precision matrices given a graph G by p ( j G ) . The standard which is obtained by inte grating p ( Dj ) p ( j G ) over the space S ++ The G-W ishart density in Equation 3 is the Diaconis-Ylvisak er conjug ate form [10 ] for the GGM lik elihood as sho wn in [27]. The indicator function I [ 2S ++ support to S ++ non-decomposable graphs. The G-W ishart normalization constant Z is sho wn in Equation 4. Because of the conjug ate prior in Equation 3, the posterior has a similar form W ( j G; where The resulting mar ginal lik elihood is then the ratio of the two normalizing terms sho wn in Equation 5 (which we refer to as Z The main dra wback of the G-W ishart for general graphs, compared to the HIW for decomposable graphs, is that one cannot compute the normalization terms Z result, Bayesian model selection for non-decomposable GGMs relies on approximating the mar ginal lik elihood p ( Dj G ) . The existing literature focuses on Monte Carlo and Laplace approximations. One strate gy that mak es use of Monte Carlo estimates of both Z the computation time required to nd accurate estimates can be extremely high [20 ] (see Section 6). An effecti ve approximation strate gy based on using a Laplace approximation to Z Carlo approximation to Z which a closed-form expression for the Hessian is deri ved [21 ]. We consider a simpler method which applies the Laplace approximation to both Z Ne vertheless, computing the Hessian determinant has a computational comple xity of O ( E 3 ) , where E is the number of edges in G . Since E = O ( d 2 ) in the worst-case scenario, computing a full Hessian determinant becomes infeasible for lar ge d in all but the sparsest of graphs. Due to the high computational cost of Monte Carlo and Laplace approximation in high dimensions, we consider two alternati ve mar ginal lik elihood approximations that are signicantly more efcient. The rst alternati ve is to approximate Z matrix is replaced by its diagonal (by setting off-diagonal elements to zero). We refer to this method as the dia gonal-Laplace score. The other alternati ve is the Bayesian Information Criterion (BIC) score sho wn in Equation 6, which is another lar ge-sample Laplace approximation where, by analogy to [34], we dene the GGM' s degrees-of-freedom (dof) to be the number of free parameters in the precision matrix. For BIC we use the G-W ishart posterior mode ^ estimate, since the MLE is undened for n &lt; d . But we use a vague and proper prior ( Therefore, all three approximations will require nding the mode of a G-W ishart (for the posterior and/or the prior). In [21 ] an Iterati ve Proportional Scaling (IPS) algorithm [30 ] is proposed to nd the G-W ishart mode. Ho we ver, IPS requires nding the maximal cliques of the graph, which is an NP-hard problem. We will now deri ve a much more efcient G-W ishart mode-nder using con vex optimization techniques. We apply this method to nd ^ the prior and posterior G-W ishart modes when computing Laplace approximations to Z Observ e that we can express the mode of any G-W ishart distrib ution with the optimization problem in Equation 7, where the density is parameterized by graph G , degree and the scatter matrix S . This  X CO VSEL  X  type problem [9] is equi valent to nding the maximum lik elihood precision matrix of a GGM with kno wn structure G , and is a con vex optimization problem. Several new methods for solving this precision estimation problem have been recently proposed, and unlik e IPS the y do not require computing the clique structure of the underlying graph. Hastie et al. [18] present one such method which consists of iterati vely solving a series of least square problems on the free elements of the precision matrix, which has O ( P d The G-W ishart mode in Equation 7 can also be found more directly with a gradient-based optimizer such as L-BFGS [6], by using the implementation con vention that the objecti ve function is 1 for a non-positi ve denite matrix. This technique has been used pre viously by Duchi et al. for the more dif cult problem of ` function is simply set to ( 1 + S ) G , where indicates element-wise multiplication. The elements of the precision matrix corresponding to absent edges in G are x ed to zero, and we the abo ve optimization with the output of few iterations of the block coordinate descent method of [18] (Glasso with kno wn G ) is quite effecti ve, as it requires fewer subsequent L-BFGS steps. In Section 5 we explore the speed vs. accurac y trade-of f of the various mar ginal lik elihood approx-imation schemes discussed abo ve; comparing full-Laplace, diagonal-Laplace and the BIC score functions to the mar ginal lik elihood values obtained with the Monte Carlo method of [3]. In this section we describe a novel frame work we call  X Neighborhood Fusion X  (NF) for generating an approximate posterior distrib ution p ( G jD ) over general graphs. An important adv antage of working with general graphs, instead of decomposable graphs, is that we can leverage simple and stable methods for quickly exploring Mark ov blank ets. One popular method for structural reco very is Glasso which imposes an l time per iteration for each setting of the regularization parameter . Ho we ver, the choice of the parameter is critical, and in practice we often nd that no setting of this parameter leads to good reco very . A related approach, proposed in [23 ], uses l identify the Mark ov blank et (MB) of each node. These Mark ov blank ets are then combined using intersection or union (AND/OR) to give the global graph G .
 These methods essentially produce a single  X best X  graph, but our main interest is in approximating the full posterior p ( G jD ) . Our NF frame work uses a Mark ov blank et nding method to deri ve a set of probability distrib utions over the local topology at each node, and species a rule for combining these into an approximate posterior over graphs. The detailed steps of the generic NF algorithm are: The design choices in the NF frame work are the choice of a sparse linear regression method (and its score function), the choice of a method for combining Mark ov blank ets, and the choice of a graph BIC score induced by regressing node i on N Mark ov blank ets using the AND operator . This essentially constitutes sampling from the  X AND-censored X  pseudo mar ginal lik elihood and is therefore lik ely to produce good candidate MBs that can be fused into high-quality graphs. Note that the uncertainty modeled by the MB proposal density is critical, as it promotes efcient exploration of model space to generate a lar ge variety of high-scoring models. Indeed, the best NF-sampled graphs typically have higher scores than the pseudo  X MAP X  graph obtained by simply intersecting the best MBs [23 ], due to the inherent noise in the linear regression BIC scores and the possibility of over-tting. Moreo ver, our MB proposals can be  X attened X  with a temperature parameter to trade-of f exploration vs. delity of the sampled graphs, though we generally nd it unnecessary to go to such extremes and use a def ault temperature of one. We next consider two further specialized instances of the NF frame work using dif ferent sparse linear regression methods. The rst method uses the full Lasso/LARS regularization path and is called L1MB ( X L1 Mark ov Blank et X ) which we adapted from the DAG-learning method of [28 ]. NF based on these l on the superiority of greedy forw ard/backw ard search over Lasso [33 ] we also use the l method of [24 ] which we call L0MB ( X L0 Mark ov blank et X ). And NF based on L0MB we will call NF-L0MB (or NF-L0 for short). Our experimental results sho w that the impro vement of the l greedy search of [24] over Lasso/LARS translates directly to obtaining impro ved MB proposals with NF-L0MB compared to NF-L1MB. Similar forw ard/backw ard greedy variable selection techniques were put to good use in the  X compositional netw ork X  DAG-to-UG method of [11 ], howe ver not for deri ving proposal distrib utions for parents/MBs as we do here for NF .
 Our overall computational scheme is quite fast by design: nding MB proposals is at most O ( d 4 ) with L1MB/L0MB (although L0MB has a smaller constant for both the forw ard and backw ard passes). Thereafter , we sample full graphs in O ( d 2 ) time (since we are sampling a discrete p.m.f. for d MB candidates at each node) and computing a G-W ishart mode ^ Stochastic Local Search (SLS) can also be vie wed as a mechanism for generating an approximate posterior distrib ution over graphs. Lik e MCMC methods, SLS explores high probability regions of graph space, but unlik e MCMC it computes approximate model probabilities directly for each graph visiting the same graph multiple times is extremely small. We note that SLS represents an orthogonal and complementary approach to structural inference relati ve to the NF frame work presented in Section 3. In this section we discuss SLS for both decomposable and general (non-decomposable) GGMs. Specically , we describe new initialization and edge-mar ginal updating methods for non-decomposable GGMs, and also introduce a highly effecti ve hybrid NF/SLS method.
 SLS with decomposable graphs has the adv antage that its natural scoring function, the mar ginal lik elihood, can be computed exactly under the conjug ate Hyper Inverse Wishart prior . The mar ginal lik elihood can also be updated efciently when local changes are made to the underlying graph. A state-of-the-art SLS method for decomposable GGMs is given in [29], which can be used with an arbitrary score function over the space of general graphs. Here we consider SLS for general graphs G t is chosen at random and ipped with probability q ij . If the resulting graph is admissible and has not been visited before, this graph becomes G t +1 , and we evaluate its score. In the general case, every new graph generated is admissible. In the decomposable case, only decomposable graphs are admissible. We should note that unlik e exhausti ve search methods, this method avoids evaluating the score of all O ( d 2 ) neighboring graphs at each iteration, and instead picks one at random. There are two key modications used in [29] which help this method work well in practice. First, the mar ginal edge probabilities q are more lik ely to be proposed in the future. Second, on each iteration the algorithm chooses to perform a resampling step with probability p step we set G t +1 to G v , where v t , with probability proportional to the score (or exponentiated score) of G v . In a global mo ve we sample a completely new graph (based on the edge mar ginals q for G t +1 . We note that a similar idea of using edge-mar ginals to propose mo ves in DAG space was suggested in [14 ]. In this paper , we set p We now propose a new initialization and updating scheme for non-decomposable SLS based on a set of k initial graphs G 1 obtained from our NF graph-sampling frame work. Our approach vie ws q with prior parameters bution online using p ( q We then ip an edge with probability E [ q SLS' s main dra wback is that, if started from the empty graph as in [29], it will necessarily tak e at least E steps to nd the highest scoring graph, where E is the number of true edges. This means that it will lik ely require a very lar ge number of iterations even in moderately lar ge and dense graphs. An impro ved initialization strate gy is to start the search from the optimal tree, which can be found in
O ( d 2 ) time using the Cho w-Liu algorithm [7]. An even better initialization strate gy, for non-decomposable graphs, is to  X seed X  SLS with a batch of NF-sampled graphs for G 1 start the search by executing a resampling step. In this way, a limited number of SLS steps can effecti vely explore the space around these initial high-quality graphs. We refer to this new method, where NF is used to both initialize the edge-mar ginals and seed the graph history , as hybrid NF/SLS . mar ginal lik elihood approximations in Section 2. For this evaluation we use the Monte Carlo method of [3] as a proxy for the ground truth mar ginal lik elihood. For data dimensions d = 6 ; :::; 16 , we sample 100 random, sparse precision matrices with an average edge density of 0 : 5 . For each sampled precision matrix we generate 10 d observ ations from the corresponding GGM. Using each approximation method, we score all d ( d 1) = 2 neighbors of G obtained from G by single edge ips. We then compute a posterior distrib ution over this set of graphs by normalizing the scores (or exponentiated scores as appropriate). We then compute the Kullback-Leibler (KL) divergence from the Monte Carlo based posterior to each approximate posterior . We also record the time required to score each graph. The scoring methods we use are BIC, full-Laplace and diagonal-Laplace for Z and Z average error of these posterior approximations as a function of data dimensionality d , as measured by KL divergence. In Figure 1(b) we sho w the average time required to score a single graph as a function of graph size d . As expected, full-Laplace is the most accurate and most costly of the approximations next to Monte Carlo. Interestingly , diagonal-Laplace appears to be signicantly more accurate than BIC (for this test) and is in fact only twice as costly . Moreo ver, diagonal-Laplace is already more than 20 times faster than Monte Carlo and full-Laplace at d = 16 . On the diagonal-Laplace score in the remainder of our experiments.
 We next evaluate the NF-L1MB and NF-L0MB methods described in Section 3 (note that we will use the short labels NF-L1 and NF-L0 in the Figures), and SLS for decomposable and general graphs initialized from the optimal tree as described in Section 4 (denoted as DLS-T and GLS-T , respec-tively), and a L0MB-based hybrid NF/SLS method as described in Section 4 (denoted as GLS-NF). We sample 5000 graphs for each of the NF methods and run each of the SLS methods for 5000 steps, also producing 5000 graphs. The hybrid NF/SLS method is initialized with a sample of 100 NF graphs, and then run for 5000 steps. We compute the score for each set of graphs (diagonal-Laplace for non-decomposable and exact mar ginal lik elihood for decomposables). We extract the 100 best graphs by score, and produce an approximation to p ( G jD ) by normalizing the exponentiated scores. under Bayesian model averaging (BMA) with approximate scores of each method. In the follo wing experiments we use a G-W ishart prior degree and unless otherwise noted, a def ault prior scatter matrix of S We examine the two main inferential tasks of prediction and kno wledge disco very . We rst measure the predicti ve ability of each method by computing both test set log-lik elihoods and test set impu-tation log-lik elihoods. For this task we use the  X Mutual Funds X  (MF) dataset used by [29 ] for SLS with decomposable GGMs, with d = 59 , which the y split into 60 months of training data and 26 months of test data. But due to the resulting critical sampling ( n d ), here we use a more stable S of scores for the SLS methods and best scores for the NF and tree methods. Box plots of diagonal-Laplace scores for each method on the MF data are sho wn in Figure 2(a). The corresponding test set log-lik elihoods are sho wn in Figure 2(b). For the imputation experiment, we impute  X missing X  triplets of variables given the values of the remaining variables. We compute the log-lik elihood of patterns and all 26 test cases. The imputation log-lik elihoods are sho wn in Figure 2(c). We can see that NF-L0MB out-performs NF-L1MB on both predicti ve tasks (full and missing). Interestingly , on this small data set SLS for general graphs (GLS-T) performs rather well. But our hybrid NF-L0MB  X seeding X  approach for SLS (GLS-NF) has the best overall BMA performance.
 In the second set of tasks, we evaluate the structural reco very of each method by measuring the true positi ve and false positi ve rates for edge inclusion w.r.t. a ground-truth GGM. The synthetic data sets contain d = 100 nodes, E = 300 edges and n=d ratios of 5 : 0 (Synth-1) and 0 : 5 (Synth-2). Synth-1 is thus generously oversampled while Synth-2 is undersampled. Both synthetic GGMs were generated by moralizing a random DAG. Figures 3(a) and 3(b) sho w plots of TPR vs. FPR for edge reco very . The rates for indi vidual graphs are sho wn as small gre y symbols while the BMA rate is sho wn with a lar ge bold colored symbol. The results sho w that NF-L0MB and GLS-NF (based on seeding GLS with 100 NF-L0MB graphs) are the best methods on both data sets. We also see that NF-L0MB dominates NF-L1MB, while the hybrid GLS-NF dominates both GLS-T and DLS-T .
 For the d = 59 MF dataset in Figure 1(c), NF-sampling 5000 graphs and doing the G-W ishart mode-ts and diagonal-Laplace scoring, tak es a total of 13 mins, and lik ewise 30 mins for the synthetic d = 100 dataset in Figure 3. Generating and scoring 5000 graphs with non-decomposable SLS tak es 37 mins on the MF dataset and 59 mins on the synthetic one. Decomposable SLS tak es 31 mins on MF and 43 mins on the synthetic. All times quoted are for Matlab code running on a 3.16 GHz PC. We offer a practical frame work for fast inference in non-decomposable GGMs pro viding reasonable accurac y for mar ginal lik elihoods. While Monte Carlo methods are the  X gold standard X  (modulo the usual con vergence issues) the y are exorbitantly costly for even moderately lar ge d . For example, scoring all the neighbors of a 150-node graph via SLS required over 40 days of computation in [20 ]. A similar size task would tak e less than 40 mins with our diagonal-Laplace approximation method. As pointed out by [21 ] there may not always be suf cient concentration for a Laplace approximation to
Z 0 to be very accurate, which is wh y the y use MC for this quantity . We chose Laplace for both Z n and Z and BIC for much lar ger graphs than in Figure 1(a). Our Laplace scores also roughly matched the MC values for the Fisher Iris data in [3], selecting essentially the same top-rank ed 16 graphs (see Figure 5 in [3]). Using a diagonal instead of a full Hessian was yet another compromise for speed. We experimentally validated NF on nearly 10 4 synthetic cases ranging in size from d = 10 ; :::; 500 , with various edge densities and n=d ratios, with consistently good results, typied by the two test cases sho wn in Figure 3. Note that the sub-par performance of NF-L1 is not a failing of NF but due to l 1 -based MBs, and superiority of l 0 -based F/B greedy search is not without precedent [25 , 24, 33]. We note that NF can be partially justied as a pseudo mar ginal lik elihood (PML), but whereas most authors rely only on its maximizer [23 ] we exploit the full (pseudo) density . Without the AND lter , NF-dra wn MBs are sampled from a set of  X consistent X  full-conditionals in the sense of Besag [5], and their max-BIC MBs are collecti vely the PML mode (note that here we mean the node regression BIC, not graph BIC). Enforcing AND is a necessary domain truncation for a valid UG which alters the mode. This symmetrized  X pseudo-MAP X  G is often an average-scoring one compared to the best and worst found by NF , which moti vates BMA and justies NF . We can also vie w NF as an over -disper sed proposal density; its weighted graphs a rough proxy for p ( G jD ) . This approximation may be biased but our results sho w it is quite useful for prediction and imputation (and seeding SLS with high-quality graphs). Finally , while use of BIC/Laplace for hypothesis testing is often criticized, it can still be useful for estimation [26 ], and nowhere in our frame work are these scores being used to select a single  X best X  model (whether it be a MB or a G ) due to our reliance on sampling and BMA. We lik e to thank the revie wers for their helpful and encouraging feedback. BMM was supported by the Killam Trusts at UBC and KPM would lik e to thank NSERC and CIF AR. This work was in with the National Aeronautics and Space Administration.

