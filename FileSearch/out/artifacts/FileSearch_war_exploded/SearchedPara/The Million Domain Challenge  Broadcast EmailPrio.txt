 With email overload becoming a billion-level drag on the economy, personalized email prioritization is of urgent need to help predict the importance level of an email. Despite lots of previous effort on the topic, broadcast email, an impor-tant type of emails with its unique challenges and intriguing opportunities, has been overlooked. The most salient op-portunity lies in that effective collaborative filtering can be exploited due to thousands of receivers of a typical broad-cast email. However, every broadcast email is completely  X  X old X  and it is very costly to obtain users X  preference feed-back. Fortunately, there exist up to million-level broadcast mailing lists in a real life email system. Similar mailing lists can provide useful extra information for broadcast email pri-oritization in a target mailing list. How to mine such useful extra information is a challenging problem that has never been touched. In this work, we propose the first broadcast email prioritization framework considering large numbers of mailing lists by formulating this problem as a cross domain recommendation problem. An optimization framework is proposed to select the optimal set of source domains consid-ering multiple criteria including overlap of users, feedback pattern similarity and coverage of users. Our method is thoroughly evaluated on a real world industrial dataset from Samsung Electronics and is proved highly effective and out-performs all the baselines.
  X  Information systems  X  Collaborative filtering; Email Prioritization, Cross Domain Recommendation
This work was partly done when the first author worked as an intern at Samsung Research Canada
Despite 23 years history, email still remains as one of the most important communication tools nowadays, with 2.6 bil-lion users worldwide and over 205 billion emails sent or re-ceived everyday[26]. However, together with the blessing comes a curse. Email overload,  X  X  $650 Billion Drag on the Economy X  described by New York Times[20], is causing se-rious troubles for email users. Based on previous research, 58% of emails are irrelevant or unimportant and a person on average has to waste at least one hour per day to handle them[5][14].

The serious situation of email overload leads to a thriv-ing research field, personalized email prioritization , in which importance labels for non-spam emails are predicted and various literature[41][32] have been working on it. One of the most notable applications of personalized email prioriti-zation comes from Gmail. An email importance ranking al-gorithm[1] is proposed by Google and in the inbox of Gmail, every important email is high-lighted with a yellow marker.
However, broadcast email , an important type of email, has been overlooked in the previous personalized email prioriti-zation literature. A broadcast email is an email message that is sent to a group of receivers, usually by organizations, companies and web services[38] and each group of receivers is called a mailing list . Everyday huge numbers of broad-cast emails are sent to millions of mailing lists, often for group notification (e.g. mails from a university graduate student list) and email marketing (e.g. promo mails from an e-commerce website list). Handling these broadcast emails can be both overwhelming and time consuming and the re-ally important and interesting broadcast emails can easily get swamped. The following characteristics of broadcast emails make methods for prioritization of personal emails inapplicable: The Same Sender In prioritization of personal emails[1][41], Limited Types of User Feedback Various types of user
Despite the above mentioned challenges, broadcast emails also bring a new opportunity. Since each broadcast email is sent to all users of a mailing list, other users X  feedback (view or not) can be very helpful in predicting the priority for a target user. In other words, broadcast email prioritization can be formulated as a collaborative filtering task: for a user, if other users with similar interest have considered the email important (i.e. viewed it), he should likely also consider it as an important email. However, there exists one key challenge. Each email waiting for priority prediction is completely cold . That is to say no viewing action has been observed, since the email has not yet been sent to any users, which makes it impossible to perform collaborative filtering directly [38].
In our recent work [38], an active learning framework was proposed to solve the above mentioned cold start problem of collaborative filtering for broadcast email prioritization. However, the obtained user feedback from active learning is still limited for well addressing the prioritization problem. For example, it cannot well handle new users of a mailing list and new mailing lists, which are very common in real systems and have limited historical data for collaborative filtering. In our previous model from [38], only one mailing list was considered, i.e., each mailing list is modeled inde-pendently without considering the existence of other mailing lists. In a mailing system like Gmail, there exist up to mil-lions of various mailing lists, covering different topics varying from political campaigns to e-commerce promos. The size of the mailing lists is typically large, commonly containing thousands or even millions of receivers. A user may be a member of dozens of mailing lists and mailing lists can have large numbers of shared users. The viewing information ac-cumulated in similar mailing lists can be very useful to en-rich the collaborative filtering evidences of a target mailing list. By resorting to these similar mailing lists, the afore-mentioned new user and new mailing list issues could be significantly alleviated.

In this paper, we propose a new cross domain recommen-dation framework to solve the problem of broadcast email prioritization for many mailing lists. Cross domain recom-mendation systems adopt different techniques to transfer learning from source domains (e.g. book) to target domains (e.g. movie) in order to alleviate the sparsity problem and improve the accuracy of recommendations. The intuition of our approach is that each broadcast mailing list can be regarded as a domain in a cross domain recommendation system. The problem of predicting the priority of emails with the help of extra information from other related mail-ing lists can thus be formulated as the problem of improving the quality of recommendations in the target domain by in-corporating information accumulated from source domains, as in cross-domain recommendation. However, due to the unique characteristics of the broadcast email prioritization task, several challenges exist and make the traditional cross domain recommendation methods fail.
 Million Domain Challenge Most previous cross domain Multi-criteria Source Domain Selection To select the A Dynamic Source Domain Set Size In the cross-domain
To address the above mentioned challenges, we formulate the selection of the set of source domains as an optimization problem considering criteria including overlap of users, feed-back pattern similarity and coverage of users. Two methods are then proposed to solve the optimization problem effi-ciently. A weight regularized matrix factorization method is used to make predictions based on information from both the selected source domains and the target domain.

Our main contributions are as follows: 1. We present the first in-depth discussion of personalized 2. We propose the first cross domain recommendation 3. Our method is thoroughly evaluated on a real life dataset,
Email prioritization focuses on making a personalized pre-diction of the importance label of non-spam emails [41, 15, 11].

Douglas et. al [1] propose a simple linear logistic regres-sion model to do prioritization for gmail, in which the fi-nal prediction is the sum of the global model and the user model log odds. Four categories of features are considered in the model, including social features, content features, thread features and label features. In [41], the authors use personal social networks to capture user groups and to obtain rich features that represent the social roles from the viewpoint of a particular user. They also developed a semi-supervised (transductive) learning algorithm that propagates impor-tance labels from training examples to test examples through a personal email network. In [32], the authors proposed mul-tiple classification and semi-supervised clustering methods for spam detection and email categorization tasks. A so-cial clustering approach is proposed in [15] to predict the email priority based on the relations between its sender and induced social clusters. [24] defines metrics for measuring the social importance of users based on the email elements: from, to and cc, and user actions of replying and reading, which can potentially be used for measuring email prioriti-zation. Horvitz et al. [11] regard the email prioritization prediction task as a classification problem and use Support Vector Machines to predict whether the utility of newly ar-rived emails is high or low. However, due to the previously described characteristics of broadcast emails, i.e. The Same Sender and Limited Types of feedback, these traditional methods designed for normal emails cannot be effectively applied to the broadcast email prioritization task.
Broadcast email prioritization has been overlooked for a long time. Our recent paper [38] is the first work handling this task and we are the first to use collaborative filtering to handle it. As each email waiting for prioritization is com-pletely cold, we propose an active learning framework. The intuition is that a new email is first sent to a small portion of users from the mailing list. Then based on their feedback obtained during a short waiting period, the priority of the email is predicted for the remaining users. Similar cold-start, unbalanced or insufficient data problems have been widely studied in settings like recommendation [36][27] and classi-fication [34][4][33][35]. Since it is not the main contribution of the paper, to make it easier to follow, instead of previous active learning method proposed in [38], in this paper we use a much simpler strategy. It is also worth noting in our pre-vious work [38], each mailing list is treated independently, disregarding the existence of large numbers of other mailing lists, which limits the performance of the method.
The basic idea of cross domain recommendation is to im-prove the quality of recommendations in one domain (known as target domain) by exploiting auxiliary knowledge in other domain(known as source domain)[8]. This technique is par-ticular useful to address the cold-start problem[28] and mit-igating the sparsity problem[31]. Also, [39] claims that cross domain recommendations can make the result more diverse which is very important in real world applications[2].
Recent works on cross domain recommendation can roughly be divided into two categories, content-based approaches [3, 7, 17, 30, 31] and collaborative filtering approaches[9, 16, 12, 28]. For the content-based approach, an early attempt is presented in[3], in which authors come up with a general framework for enhancing the accuracy of user modeling by incorporating data collected from other domains. [17] uses location data in a particular kind of context aware recom-mendation task to improve recommendation qualities. Deep learning is also used in the content-based cross domain ap-proach, Elkahky et al. propose a method which can map users and items to a latent space where the similarity be-tween users and their preferred items is maximized[7]. [31] proposes a Bayesian hierarchical approach based on Latent Dirichlet Allocation (LDA) to transfer user interest cross domains or media.

The other major category of cross domain recommenda-tion method is collaborative filtering based ones. [18, 19, 9] all try to exploit cluster level preference patterns which are similar across domains to improve the recommendation performance. Hu et al. propose a generalized Cross Domain Triadic Factorization model which leverages both explicit and implicit feedback [12]. [21] show that using Factoriza-tion Machines in cross domain collaborative filtering can sig-nificantly improve the recommendation quality in cold start context. Joshi et al. propose an extension to two multi-domain learning techniques and enable them to simultane-ously learn from several metadata attributes[16].

Domain selection problem for cross domain recommenda-tion is an emerging area.[29] proposes the first work consid-ering a large number of domain pairs in cross-domain recom-mender systems by using a Canonical Correlation Analysis approach. In [40] and [22], to cope with the source domain selection burden, authors design algorithms to turn to some online information sources such as social networks or the Wikipedia for help. However, none of the previous works addresses the problem of selecting the optimal set of source domains for a target domain.
The task of this paper is personalized prioritization for broadcast emails. That is to say we want to predict whether a broadcast email is important or not for a given user. There are large numbers of mailing lists in an e-mail system. For simplicity, we assume each broadcast email is only sent to one mailing list and a user can enroll in multiple mailing lists. For a broadcast email waiting for prioritization pre-diction, we define the mailing list which it is sent to as the target mailing list (equivalent to the target domain in cross-domain recommendation) and all the remaining mailing lists as source mailing lists (equivalent to source domains in cross-domain recommendation). In this paper, domain and mail-ing list are used as synonyms. The broadcast email priori-tization problem can be divided into the following three sub problems . 1. Sample the feedback from a small portion of users 2. Find the optimal set of source mailing lists whose extra 3. Predict the priority of the broadcast email with the
For user set U and email set E , we define a binary email importance matrix I based on users X  feedback on emails. I.e., for user u  X  U and email e  X  E ,
We define a mailing list as a set of users M i  X  U and assume that there are n mailing lists in total, denoted by M = { M 1 ,..., M n } . We define the email set E i as the set of emails sent to M i .

For each email e , we record its sender and receiver. For each user u , we record user features like country and time-zone. Given a new email e new to be sent to mailing list M we define the three sub problems mentioned above as: Sampling Users for Feedback Given U , E , I , e new , M t Choose Source Mailing Lists Given U , E , I , M t , E t , Prediction for Remaining Users Given U , E , I , M , In this section, we introduce our Cross-domain Broadcast Email Prioritization ( CBEP ) framework to solve the three sub problems of broadcast email prioritization: user feed-back sampling, optimal source domain set selection and pri-ority prediction. Optimal source domain set selection is the major contribution of this paper and will only be briefly described in this section with details presented in section 5.
In a broadcast email prioritization task, each email wait-ing for priority prediction is completely cold . That X  X  to say no view-email action has been observed, since the email has not yet been sent to any users, which makes it impossible to perform collaborative filtering directly. Thus, we need to first sample the feedback from a small portion of users to solve the cold start problem. Feedback in this paper refers to user X  X  view-email action. There are two types of possible feedback. Positive feedback which means the user has viewed the email, is a relatively clear evidence that this email is im-portant and negative feedback which means the user fails to view the email, is a mixture of cases where the user is unaware of the email or the user thinks the email is unim-portant.

We propose a simple strategy to collect the initial feed-back. For a new email, we send it to all the users without priority labels and we wait for a short period of time. We then predict the priority based on the initial feedback col-lected within this period of time. The only challenge of this strategy is to determine how long we should wait to achieve the best trade-off between gathering enough feedback for accurate priority prediction and making predictions as soon as possible. We employ cross validation to determine the optimal length of the waiting time
Each mailing list can be regarded as a domain and the viewing information accumulated in one domain can be used to improve the quality of recommendations in another do-main, which is especially helpful if the user has few or no views (e.g. a new user to a mailing list) or the target mailing list has little of information (e.g. a mailing list with limited number of users or items). With up to millions of mail-ing lists in a mailing system, how to select the optimal set of source domains to best improve the prediction accuracy creates a million domain challenge.

To solve the million domain challenge, multiple criteria need to be considered. Signals from these criteria come in different format and can be contradictory with each other. Thus we propose to formulate this as an optimization prob-lem. Basically we will search for a binary assignment to each candidate source domain that optimizes the prediction accuracy. Details will be introduced in section 5.
The feedback from the target domain, the selected source domains and the feedback of sampled users will be used for priority prediction. Formally, we define the feedback set used for priority prediction as I 0 = { I M t , E t , I M
We use a weighted low-rank approximation method for the priority prediction. The intuition behind the proposed method is to assign different weights to the feedback based on the source of the information. Given the target do-main M t and a selected source domain M i , we assign larger weight to feedback from the target domain ( I M t , E t ) and the weight of feedback from the source domain ( I M i , E i ) will be determined based on the similarity of the feedback patterns between the target domain and source domain, Sim i ( t ), (de-fined in section 5.1.2). For feedback from source domains, the feedback from the shared users between M i and M will be given larger weights than those from the non-shared users. Details of the weighting scheme are summarized in Table 1. W pos and W neg is the weight for positive feedback and negative feedback which are set to be 5 and 1.  X  is a con-stant used for smooth and  X  is a decay factor which are set to be 0.1 and 0.9 respectively. All the constant parameters are tuned by cross validation.
 Our objective is to minimize the following loss function:
L ( P , Q ) = X for the latent vectors for users { M 0 , M t } and items { E W ij is a non-negative weight for u i and e j and the weighting scheme of non-negative weight matrix W is summarized in Table 1.

Alternating Least Squares (ALS) is used to solve the op-timization problem by fixing P and Q alternatively while optimizing the other parameter.
 trix with the elements of W i. on the diagonal and ID  X  R d  X  d is an identity matrix.
 with the elements of W .j on the diagonal. Details of using ALS to solve matrix factorization problems are discussed in [13].

For each remaining user u i  X  ( M t  X  S ), the priority to e new is predicted as
After estimating I i,e new for all the remaining users, it can be used as a feature in a classification model (e.g. a logistic regression model as proposed in [1]) and additional features like content feature can also be easily added to the classifi-cation model. It is worth noting above mentioned method is just one of the many matrix factorization methods which can be applied to the priority prediction task. The model needs to be re-trained after each new email comes in, which may be infeasible in real life scenarios. However, there are already several methods [37][23] for fast incremental matrix factorization for recommendation with positive-only feed-back, which can be easily applied to the priority prediction task. Since it is not the major contribution of this paper, readers can refer to [37][23] for further information.
For simplicity, the estimated importance feedback I i,e new will be the only feature considered in priority classification of this paper. The intuition of our method for priority classifi-cation is that for each email a certain percentage of users will consider it as important, but the percentage varies among different emails since they are with different topics, written quality etc. An important email will result in more views during the time we wait for user feedback. Thus we can infer the percentage of important emails by the number of views we observed in the sampling phase. We define the percentage of users considering email e new important as: pos ( e new ) is the total number of view-email behaviors ob-served in the waiting time window for e new and pos avg ( M is the average number of view-email behaviors observed in the waiting time window for all the emails from M t . The second term of (6) stands for the average percentage of im-portant emails for M t .

For the top H ( e new ) percent of users according to y i,e we predict e new as important while for others as unimpor-tant.
To solve the optimal source domain set selection problem, we formulate it as an optimization problem. In section 5.1, we first discuss the optimal solution including all the selec-tion criteria. However, since the optimization problem is difficult to solve directly, we propose two approximate solu-tions in section 5.2. In section 5.3, some additional measures are proposed to improve the efficiency.
Formally, given the target mailing list M t , we define a bi-nary vector  X  of size n where each entry  X  i indicates whether the source mailing list M i is selected or not. If a source mail-ing list M i is selected, the corresponding entry  X  i is 1 else 0. Thus our problem reduces to finding  X  that maximizes the objective function introduced in the following sections.
A user can enroll in any number of mailing lists and thus mailing lists can have shared users, i.e. users enrolled in multiple email lists. We prefer source mailing list with a larger number of shared users with the target mailing list for the following reasons. 1. Recent work[6] has confirmed that knowledge between 2. Since similar mailing lists are more likely to attract the We define overlap percentage between source mailing list M i and target mailing list M t as:
The larger overlap i ( t ) is, the larger the number of shared users between the source mailing list.
Users X  feedback patterns vary across domains. For ex-ample, users who share similar feedback in an e-commerce mailing list may share completely different preference in the mailing list of the university. Only source domains with sim-ilar feedback patterns to the target domain will be helpful in cross domain recommendation. Or else, the source do-main may introduce noise to the system and jeopardize the recommendation performance. In this paper, we model the similarity of the feedback patterns between two mailing lists as the average similarity difference of each pair of shared users between the two mailing lists. Intuitively, two mailing lists have similar feedback patterns means that for shared users between the two mailing lists, two users with simi-lar feedback patterns in one mailing list also share similar feedback patterns in the other and vice versa.

Formally, for each mailing list M i , user u can be repre-sented as a binary vector v i,u of size | E i | with each entry indicating whether u has read the corresponding email from E i or not. We define the shared user set between two mail-ing lists i and j as C i,j and their feedback pattern similarity as: sim ( i,j ) = 1  X  1
Larger sim ( i,j ) value indicates larger feedback pattern similarity. Specifically, we denote the feedback pattern sim-ilarity of a target mailing list M t and a source mailing list M i as sim i ( t ) = sim ( i,t ) and sim i ( t ) will be used as a constraint in our objective function.
We aim to select the optimal set of source mailing lists M and each M i  X  M 0 has a set of shared users C i,t with target domain M t . Intuitively, we want the number of shared users between M 0 and M t to be as large as possible so that we can cover and transfer extra information for more users in the target mailing list. That X  X  to say we want to choose a size-k mailing list set M 0 so that the number of shared users between these source mailing lists in M 0 and the target mailing list M t is maximized:
This is actually an unweighted maximum coverage prob-lem, which is NP-hard. Instead of modeling this criteria directly, we propose a constraint related with this criteria. We define the overlap percentage between source mailing lists M i , M j and target mailing list M t as
By introducing the triple-domain overlap overlap i,j ( t ) as an constraint in the objective function, we expect the user sets shared with the target mailing list from different source mailing lists to be as diverse as possible and not to concen-trate on the same set of users.
Combining all the criteria mentioned above, we propose the following objective function: arg max subject to:
The first term in equation (11) ensures the selected mail-ing lists to have large percentage of overlap users with the target mailing list. The second term ensures the selected mailing lists to have similar feedback patterns with the tar-get mailing list. The third term is subject to favoring pairs of mailing lists whose shared user sets with the target mail-ing list have little overlap. Combining the third factor with the first one, we prefer mailing lists that have large over-lap with the target mailing list but small overlap with each other, which provides good coverage of users. It is worth noting that we do not specify the number of source mail-ing lists to be selected, because we think it should be a dy-namic number related with the target domain and should be chosen automatically by the algorithm. We add the fourth prevent it from selecting too many source mailing lists. Se-lecting too many source mailing lists will not only introduce noise but also increase the computational burden of the sys-tem.  X  overlap ,  X  sim , and  X  cov are constant weights for the first three terms which can be learned by cross-validation.  X  is also a constant, which influences the number of source mailing lists selected. The larger  X  is , the more source mail-ing lists will be picked.
The optimization problem (11) is an integer programming problem with both quadratic term and fraction in its objec-tive function, which makes it extremely difficult, if not pos-sible, to be solved directly. So we propose two approximate solutions to solve the problem. Both of them first approx-imate the original optimization problem as a quadratic in-teger programming problem and then further relax the con-straints to make it a quadratic linear programming problem, which can be solved in polynomial time.

For the first approximate solution, we transform the de-nominator of the objective function (11) into a term in the numerator. arg max
The newly added fourth term serves as a penalty to pre-vent the objective function from selecting too many source mailing lists.  X  pen is a constant parameter which can be learned by cross-validation.

The second approximate solution is based on the intuition that since selecting too many source domains will not only increase the computational burden of the system but also introduce noise, we do not want to choose too many source domains. That is to say we can set a upper bound z max as the maximum number of source domains that can be used in a cross domain recommendation. Our optimization problem then can be approximately formulated as arg max
We solve the optimization problem (13) z max times for z k  X  { 1 , 2 ,...,z max } and for every z k , a set of source do-mains  X  k is obtained. We compute the value of the original objective function (11) for each  X  k and select  X  k with the highest value. The corresponding z k is the number of source mailing lists to be selected.

Both approximate solutions transform the original opti-mization problem into an integer quadratic programming problem, which is still NP-hard. We relax the constraints  X   X  X  0 , 1 } to 0 6  X  i 6 1, which makes it a continuous opti-mization problem that can be solved in polynomial time. For the first approximate solution, a threshold  X  will be learned by cross validation and the source domains with  X  i &gt;  X  are selected. For the second approximate solution, the optimal number of source domains can be automatically determined by the solution. We use the  X  X uadprog X  function in MAT-LAB to solve this quadratic programming problem.
Directly calculating the coefficients sim i ( t ) and overlap in objective function (11) may be time consuming. Given target domain M t , the time complexity of calculating sim and overlap i,j ( t ) is O ( n  X  X  C i,t | 2 ) and O ( n 2 be unacceptable in real mailing system because the num-ber of mailing lists and the number of shared users between mailing lists can be very large. The following measures are proposed to improve the efficiency. 1. Only consider source mailing lists with a certain num-2. Randomly sample user pairs for the feedback pattern 3. Optimal source mailing list selection can be performed
In the experiments, we used a real life dataset from Sam-sung Electronics. We collected emails and their view logs from a large business mailing list within Samsung. The mail-ing list sends notifications related to a large internal forum and employees from all around the world receive emails with various topics, like win notices of deals, meeting agendas of customers, business objectives, news and technical issues. When a new thread is posted, a notification will be emailed to all the users. We split the mailing list into 490 sub mail-ing lists based on sections of the forum. That is to say a user belongs to a sub mailing list iff he has interacted with notification emails of threads published in that section. We treat each sub mailing list as a real mailing list in our ex-periments. The dataset contains 6506 broadcasting emails sent to 2433 Samsung employees, generating 333,979 view records. We split the data set into training set (containing 5475 emails and their view logs) and testing set (1031 emails and their view logs) based on a certain time point.
We only record users X  email viewing data and we assume an email is important to a user if the user has viewed it. It is worth noting that the data set is relatively small with only view-email behavior. Accuracy could be better if we can incorporate information like deletions of emails, flagging emails as important and skipping an email. However, due to the privacy concerns, there is no public dataset containing importance judgments for broadcast emails [41].

All data was analyzed and stored in accordance with Sam-sung X  X  privacy policy. Only the view logs of the broadcast emails were extracted and all the users are Samsung Employ-ees. The dataset was completely anonymized by mapping user ids and email ids to integer indices before any analysis.
Since our task is a classification task, we use precision, recall and f-score as the main evaluation metrics. Based on the predicted label from the algorithm and ground truth label from the data set, a prediction is either true positive (tp), true negative (tn), false positive (fp), or false negative (fn). The metrics are defined as
In the experiments, we evaluate the precision, recall and f-score at two levels: Mail Level The mail level precision, recall and fscore of an Mailing List Level The mailing list level precision, recall
It is worth noting in our previous work[38], experiments have already confirmed that by using collaborative filtering, our method can outperform various existing email prioriti-zation methods, including the content-based methods[1][38]. So in this paper, the experimental design focuses on test-ing how different source domain selection strategies affect the performance of email prioritization and evaluating the performance of our major contribution, a cross domain rec-ommendation framework to select an optimal set of source domains from a large numbers of candidate source domains.
Since we propose two approximate methods for CBEP, we refer to the first approximate method as CBEP-A1 (corre-sponding to objective function 12) and the second method Figure 1: Baseline Comparison at Mailing List Level as CBEP-A2 (corresponding to objective function 13). We adapt the following methods for comparison. The first four baselines are four different source domain set selection strate-gies, which we use to replace the optimal source domain se-lection part of CBEP and they all use the same user feedback sampling strategy and classification strategy as described in section 4.1 and 4.3. The weighted matrix factorization method designed for implicit feedback from [25][13] [10] is used for these four baselines. The last baseline is a varia-tion of CBEP by eliminating the weighting scheme in the weighted low-rank approximation process. We set the wait-ing time for gathering user feedback as 45 min for all algo-rithms and set z max = 15 for CBEP-A2.
 Single Mailing List (SML) SML only considers informa-All Mailing Lists (AML) AML considers all the source Overlapping Mailing Lists (OML) OML selects the top Feedback Similar Mailing Lists (FSML) FSML selects CBEP Without Weight (CBEP-SVD) In order to test
In this section, we compare the two approximate solutions to all baselines in terms of precision, recall and f-score at both the mail and mailing list level.
As shown in figure 1 and 2, CBEP-A1 and CBEP-A2 sig-nificantly outperform all the baselines on all the evaluation metrics. SML performs worst, which makes sense since it only considers information from the target domain and dis-regards all the additional information from other mailing lists. Moreover, new users (user who newly enrolled in a mailing list) and cold mailing lists (mailing list with lim-ited number of emails) are common, and SML cannot han-dle these cold start problems. AML performs significantly better than SML since it includes the information from all the other mailing lists. However, considering all the mailing lists deteriorates the prioritization precision due to the noise introduced by the unrelated mailing lists.

OML and FSML choose the set of source domains based on overlap of users and feedback pattern similarity. They both outperform SML by incorporating information from similar domains, and FSML performs better than OML. By selecting a limited number of source domains, FSML can already achieve similar performance as AML. The perfor-mance of CBEP-SVD is not good compared with CBEP-A1 and CBEP-A2, which further confirms our weighting scheme is useful. Both of our methods CBEP-A1 and CBEP-A2 perform significantly better than the best baseline FSML. Compared with FSML, CBEP-A1 improves the f-score by 40% at mailing list level and by 12% at mail level. The improvement comes from three aspects. First of all CBEP can choose an optimal set of source domains based on mul-tiple criteria. Secondly it is able to dynamically determine the number of source domains to be selected. Last but not least, CBEP uses a weighted matrix factorization method and gives different weights to different source domains.
As mentioned in section 5.1, we consider three different factors to select the optimal source domains, namely, overlap of users, feedback pattern similarity and coverage of users. In this section, we remove our three criteria considered in our objective function (11) one at a time by eliminating the corresponding term from (11) and optimizing the objective function based on the remaining terms. In this way, we evaluate how each criteria individually affects the prediction precision. Due to the page limit, we only show the mailing list level results for CBEP-A1 and note that the other results show similar trends.

From the results displayed in Figure 4, we can see all these three factors are useful in boosting the email prioritiza-tion performance. The feedback pattern similarity criterion Figure 4: Number of Selected Source Domains and Prediction Performance vs.  X  pen shows more importance than the overlap of users criterion, which is in accordance with our observation of the results of OML and FSML in figure 1. The coverage of users criterion turns out to be the most important one by allowing the set of source domains to cover more users in the target domain.
One of the advantages of the CBEP framework is its abil-ity to dynamically determine the number of source domains to be selected. That is to say for each target domain, we can get an optimal source domain set size. In this section, we take our first approximation method CBEP-A1 as an example to analyze how the parameter settings affect the number of selected source domains and the precision, recall and f-score of the prioritization algorithm.

In CBEP-A1, the penalty term weight  X  pen affects the number of the source domains to be selected. The larger  X  pen is, the less source domains are selected. In figure 5, we show how the average percentage of source domains se-lected (denoted as percent in figure 4), precision, recall and f-score vary for different settings of  X  pen . It is worth noting that choosing too many or too few source domains can both jeopardize the prediction performance.
Cold mailing lists with limited number of items, users or user feedback are common in real systems. One of the ad-vantages of cross domain recommendation is its ability to solve this kind of cold start problem by incorporating infor-mation from other domains. This can already be verified by the results in figures 1 and 2, in which CBEP-A1 and CBEP-A2 gain more improvement at the mailing list level than at the mail level, since mailing list level implicitly gives more weight to cold mailing lists.

We further verify the good performance of CBEP on cold mailing lists by evaluating CBEP-A1 and SML on the top 50 hottest (in terms of the number of user feedback) mailing lists and comparing these results to the results on all the mailing lists. See Figure 5. We expect precision, recall and f-score should be higher on the top 50 dataset, since these mailing lists have more abundant training data. Surpris-ingly, CBEP-A1 performs even better on all mailing lists. We attribute this to two reasons. On one hand, CBEP in-deed performs well on cold mailing lists by incorporating information from other source mailing lists. On the other hand, for some of the most popular mailing lists, there may already be abundant data so that the marginal utility of the extra information introduced by CBEP diminishes.
In this paper, we introduce the problem of personalized broadcast email prioritization considering large numbers of mailing lists and propose a novel cross domain recommen-dation framework CBEP to solve the problem. To select the optimal set of source domains from the large number of domains, we propose an optimization model that con-siders multiple selection criteria including the overlap of users, feedback pattern similarity and coverage of users. A weighted low-rank approximation method is proposed to make predictions based on information from both the target domain and the selected source domains. Comprehensive experiments are conducted on a real life dataset from Sam-sung Electronics. The results show that our method CBEP outperforms all the baselines and the various optimization criteria considered indeed all help to improve the prediction performance.

Since this is the first work on cross domain recommen-dation for broadcast email prioritization, there is still much room for future research. First, more criteria can be con-sidered in the optimal source domain selection. For exam-ple, since cross domain recommendation works better on cold mailing lists, we may consider to use the number of existed user feedback of the target domain as a criterion. That is to say for a mailing list short of information we choose to select more source domains and for a mailing list already with abundant information we choose to select fewer source domains to avoid noise. Secondly, we use a relatively small real-life dataset in our experiments due to the lack of other dataset. Further experiments should be conducted on a larger dataset with more diverse user feedback to better evaluate our method. This work was supported by the National Basic Research Program of China(973 Program) under Grant 2013CB336500, NSERC Discovery Grant, National Science Foundation of China (Grant No. 61373118, 61522206, 61173186), National Key Technology R&amp;D Program (2014BAK15B02).
