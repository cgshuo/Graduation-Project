 One task in opinion mining is to perform feature-based summarization (FBS), which identifies target features mentioned in the reviews and determine their sentiment. Early approaches in FBS use a predefined sentiment lexicon to check against the extracted terms in reviews [2]. The problem of this approach is that sentiments of opinion words are context sensitive. Improvements have been made by generating lexicons with are domain-specific [3] or feature-specific [1].
An accurate and robust Feature-Opinion Association (FOA) method is crucial for both lexicon generation and sentiment classification. That is because more than one feature and opinion word may b e mentioned in a sentence. It is not necessary that all opinion words appeare d in the sentence are used to describe every feature. An accurate FOA algorithm tells us which feature an opinion word is describing and thus the correct sense of that word can be used.

In this paper, we propose to use a function to compute the relevance score between features and opinion words. We then propose an FOA algorithm to match features and opinion words by maxi mizing the sum of the relevance scores of sentences. The algorithm can be used t o generate a sentiment lexicon and be used in sentiment analysis. Experiment results show that our method is useful in improving the sentiment classification accuracy. In this section, we give definitions to the Feature-Opinion Association problem and present our proposed solution to the problem. 2.1 Feature-Opinion Association We define Feature and Opinion words as follows: Feature can be a component of the product, e.g. Flash, Lenses, or it can be an attribute of the product, e.g. Weight, Size. Products in the same category share a similar set of common features.
 Opinion words in general can be anything that is used to describe a feature. However, due to the difficulties in natural language understanding, it is not easy to perform sentiment analysis on all types of opinion. As with most of the existing works, we limit our scope to handle opinion words that are in the from of adjectives and adverbs.
 Here, we define the Feature-Opinion Association Problem (FOA) as follows: Definition 1. Given a sentence that contains a non-empty set of features F = { f 0 ,f 1 , ..., f n following function is maximized: score of opinion word w to feature f . The key to this association problem is to define a good rel ( f, w ) function. 2.2 Rel Function Here is a list of possible rel functions for the FOA problem:  X  Nearest Opinion Word (DIST)  X  Co-Occurrence Frequency (COF)  X  Co-Occurrence Ratio (COR)  X  Likelihood-Ratio Test (LHR)  X  Combined Method 2.3 Feature-Opinion Association Algorithm We define the Feature-Opinion Association Algorithm (FOAA) to associate opin-ion words to features subject to the rel function in Algorithm 1: Algorithm 1. Feature-Opinion Association Algorithm
In general, each opinion word will be associated to the feature with the highest rel score except in sentences like:  X  X ood lenses, good pictures! X  . Depending on the rel function used, it is possible that the scores for the same pair of feature and opinion word are the same for different appearances of the same opinion word. The algorithm will check if the same opinion word is already associated to a feature, and if so, it tries the next feature until no more features exist. A threshold value is used to prune opinion words that have low rel scores to all features appeared in the sentence. 2.4 Sentiment Lexicon Expansion With the Feature-Opinion Association algorithm, steps for sentiment lexicon expansion become straightforward. Two sets of opinion words (positive and neg-ative) are defined initially as seeds. FOA is applied on each sentence appeared in the training corpus. Same opinion words associated to different feature are treated as different words . Using the linguistic rules proposed by Ding [1], we can compute the orientation score for each word as follows: where c + ve and c  X  ve is the number of times word w is in conjunction with the known positive and negative set respectively. The higher the score, the more likely that the word should be in the positive set and vice vera. Words with absolute score smaller than a threshold T should not be treated as either polarity. In each iteration, Words with the highest and lowest score are added to the two sets respectively. In order to verify our ideas, we collected twodatasetsfromtheinternet.These two data sets are used to conduct our experiments. NLTK 1 is used to perform natural language processing tasks such as sentence splitting and part-of-speech (POS) tagging. Feature list is constructed based on the glossary page of the Digital Photography Review 2 . Synonyms are grouped together and treated as the same feature.
 There are two data sets in our experiment: Corpus Data Set: User reviews of all cameras of popular brands are crawled from Digital Photography Review. This data set contains 400+ different camera models, 17,000+ user reviews and 250,000+ sentences. This data set is used as a statistical database for computing the relevance scores discussed in Section 2. Test Data Set: We used another data set [2,1] for testing. The reviews of 4 different camera models are used. The data set contains over 100 reviews and 1500 sentences. The reviews are re-tagged so that each sentence is attached with the mentioned features and their associated opinion words. 3.1 Feature-Opinion Association Accuracy For each tagged sentence in the test data set, we use the FOA algorithm to match appeared features and opinion words. Therefore, for each feature, there will be a list of opinion words tagged by human and the FOA algorithm respectively. We have defined the following values to count the number of opinion-feature pair that are tagged by either Human or the FOA algorithm:  X  C AA : Both Human and FOA tagged  X  C AN : Only Human tagged  X  C NA : Only FOA tagged  X  C NN : Neither Human nor FOA tagged
Then, the association accuracy can be c omputed by the traditional precision ( p ), recall ( r )andF-score( f ):
We evaluate the accuracy of FOA using each rel function with a range of possible threshold th . For COR, DIST and COR+DIST, the range is from 0 to The results of each data set with the best F-Score is presented in Table 1. We only report the average results of the 4 data set due to space limitations.
From the results we can see that non-combined rel functions are capable of achieving good recalls (around 65  X  79%). However, their precisions are generally quite low. Among all the non-combined rel functions, LHR and DIST performed the best, reaching an average F-Score of 60%. DIST achieved the highest average precision, but it is mainly due to the outliner camera 1 (not shown here). LHR has the highest average recall (nearly 80%).
 The combined rel functions, in general, perform better in terms of the F-Score measurements with LHR+DIST slightly outperforming COR+DIST. The results here indicate the importance of using both types of measurement in the feature-opinion association process. Missing either information will lead to worse association results. 3.2 Sentiment Classification Accuracy We used LHR and LHR+DIST to generate two sentiment lexicons by the algo-rithm discussed in section 2.4. The reason for choosing them is that they per-formed the best in terms of average Pr ecision, Recall and F-Score in the FOA process. The FOA thresholds ( th ) 0, and 9 are selected for LHR and LHR+DIST respectively. They are thresholds that e ach methods achieve the best average F-Score in the FOA process. Opinion words {  X  X xcellent X ,  X  X ood X  } and {  X  X oor X ,  X  X ad X  } are used as the initial seed words for the positive and negative senti-ment respectively. In our experim ent, the orientation threshold T for lexicon generation is set to 0 . 2.

We conducted two set of experiments with identical settings except that one includes FOA while the other does not. Th e sentiment classification process is as follows: For each tagged sentences, all the appeared features and opinion words are extracted. The algorithm computes the sentiment score for each fea-ture mentioned in the sentence solely based on the associated opinion words. Features that are not associated to any opinion words will have their sentiments inferred using two different methods. The first method ( Human and FOA )uses the majority sentiment of other featu res that appeared at the same sentence. The second method ( Human* and FOA* ) falls back to use all opinion words of the same sentence to infer sentiments of these features. This is the same as the case where FOA is not used. Under both cases, we use the opinion aggregation function [1] for sentiment scoring: M ( f ) is the set of opinion words associated to feature f . For the case where FOA is not used ( All ), M ( f ) will be replaced by the set of all opinion words within the same sentence as feature f .( All ) represents the opinion aggregation method proposed in [1]. This give us a direct comparison of FOA versus the Positive words have a score of +1 and negative words have a score of -1. Senti-ments of opinion words are retrieved from sentiment lexicons generated in the above steps. The predicted sentiment orientations are compared against human tags to calculate accuracies. Table 2 s ummarizes the results of our sentiment classification experiments.
 Classification results using human tags. We first compare the sentiment classification accuraci es of all opinion words ( All ) and human association ( Hu-man and Human* ). We can see that the overall a ccuracies increase if we limit the sentiment classifier to use only opinion words that are tagged by human. These agree with our intuitions that blindly using all opinion words actually produces false results.

An interesting observation is that Human* performs better than Human .The reason is that a sentence usually mentions only 1 or 2 features. When there are no associated opinion words, we either cannot find another feature, or the remaining features are not enough to help inferring its sentiment correctly. Falling back to use all opinion words actually helps in this case. Classification results using FOA algorithm. Solely using opinion words that are associated by the FOA algorithm for sentiment analysis ( FOA in Table 6) actually produces poorer results. This is reasonable, given that the accuracies of using human FOA alone ( Human ) are just slightly better than the case where all opinion words are used ( All ). However, if we use the second method to deal with the case where no opinion words are associated to a feature ( FOA* ), the overall accuracy improves and i t consistently outperform All in our experimental data sets. In fact, we can interpret FOA* as a pruning heuristic that tries to tighten the set of opinion words used for sentiment classification whenever pos-sible. The results show that this heuristic is effective in improving the sentiment classification accuracies.

Finally, we observe that using LHR to perform FOA actually performed bet-ter. A possible reason is that LHR is good at achieving high recalls. It extracts most of the feature-related opinion words in the lexicon building process. Al-though its precision is not high, the incorrectly associated opinion words are unlikely to be inferred to carry a sentiment because of the threshold limitations. We have presented a Feature-Opinion Association (FOA) algorithm to improve the sentiment analysis results. The algorithm maximizes the sum of the relevance scores between features and opinion wo rds. We proposed 6 relevance measures that make use of the structural information of sentences as well as the statistical information collected from a commerc ial review web site. The proposed FOA algorithm can be used in both the lexicon generation and sentiment classifica-tion process. The evaluation results show that it is effective in improving the sentiment analysis accuracy over the tradi tional methods where classification is done using all opinion words.
 This work is fully supported by two grants (Project No. CUHK 2050379 and Project No. CUHK 6902498) and is affiliated with the Microsoft-CUHK Joint Laboratory for Human-centric Computing and Interface Technologies.

