 Topical Text Categorization (TC), the task of clas-sifying documents by pre-defined topics, is most commonly addressed as a supervised learning task. However, the supervised setting requires a substan-tial amount of manually labeled documents, which is often impractical in real-life settings.

Keyword-based TC methods (see Section 2) aim at a more practical setting. Each category is rep-resented by a list of characteristic keywords, which should capture the category meaning. Classifica-tion is then based on measuring similarity between the category keywords and the classified documents, typically followed by a bootstrapping step. The manual effort is thus reduced to providing a key-word list per category, which was partly automated in some works through clustering.

The keyword-based approach still requires non-negligible manual work in creating a representative keyword list per category. (Gliozzo et al., 2005) succeeded eliminating this requirement by using the category name alone as the initial keyword, yet ob-taining superior performance within the keyword-based approach. This was achieved by measur-ing similarity between category names and docu-ments in Latent Semantic space (LSA), which im-plicitly captures contextual similarities for the cate-gory name through unsupervised dimensionality re-duction. Requiring only category names as user in-put seems very attractive, particularly when labeled training data is too costly while modest performance (relative to supervised methods) is still useful.
The goal of our research is to further improve the scheme of text categorization from category name, which was hardly explored in prior work. When an-alyzing the behavior of the LSA representation of (Gliozzo et al., 2005) we noticed that it captures two types of similarities between the category name and document terms. One type regards words which refer specifically to the category name X  X  meaning, such as pitcher for the category Baseball . How-ever, typical context words for the category which do not necessarily imply its specific meaning, like sta-dium , also come up as similar to baseball in LSA space. This limits the method X  X  precision, due to false-positive classifications of contextually-related documents that do not discuss the specific category topic (such as other sports documents wrongly clas-sified to Baseball ). This behavior is quite typical for query expansion methods, which expand a query with contextually correlated terms.

We propose a novel scheme that models sepa-rately these two types of similarity. For one, it identifies words that are likely to refer specifically to the category name X  X  meaning (Glickman et al., 2006), based on certain relations in WordNet and Wikipedia. In tandem, we assess the general contex-tual fit of the category topic using an LSA model, to overcome lexical ambiguity and passing refer-ences. The evaluations show that tracing lexical references indeed increases classification precision, which in turn improves the eventual classifier ob-tained through bootstrapping. The majority of keyword-based TC methods fit the general bootstrapping scheme outlined in Figure 1, which is cast in terms of a vector-space model. The simplest version for step 1 is manual generation of the keyword lists (McCallum and Nigam, 1999). (Ko and Seo, 2004; Liu et al., 2004) partly auto-mated this step, using clustering to generate candi-date keywords. These methods employed a standard term-space representation in step 2.

As described in Section 1, the keyword list in (Gliozzo et al., 2005) consisted of the category name alone. This was accompanied by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimen-sionality reduction. In this space, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors. Thus, vector similar-ity in LSA space (in step 3) captures implicitly the similarity between the category name and contextu-ally related words within the classified documents.
Step 3 yields an initial similarity-based classifi-cation that assigns a single (most similar) category to each document, with Sim ( c, d ) typically being the cosine between the corresponding vectors. This classification is used, in the subsequent bootstrap-ping step, to train a standard supervised classifier (either single-or multi-class), yielding the eventual classifier for the category set. Our goal is to augment the coarse contextual simi-larity measurement in earlier work with the identifi-cation of concrete references to the category name X  X  meaning. We were mostly inspired by (Glickman et al., 2006), which coined the term lexical reference to denote concrete references in text to the specific meaning of a given term. They further showed that Input: set of categories and unlabeled documents
Output: a classifier 1. Acquire a keyword list per category 2. Represent each category c and document d 3. For each document d 4. Train a supervised classifier on step (3) output an entailing text (in the textual entailment setting) typically includes a concrete reference to each term in the entailed statement. Analogously, we assume that a relevant document for a category typically in-cludes concrete terms that refer specifically to the category name X  X  meaning.

We thus extend the scheme in Figure 1 by cre-ating two vectors per category (in steps 1 and 2): a reference vector ~c ferring terms for the category name; and a context vector ~c space, as in (Gliozzo et al., 2005). Step 3 then com-putes a combined similarity score for categories and documents based on the two vectors. 3.1 References to category names Referring terms are collected from WordNet and Wikipedia, by utilizing relations that are likely to correspond to lexical reference. Table 1 illustrates that WordNet provides mostly referring terms of general terminology while Wikipedia provides more specific terms. While these resources were used pre-viously for text categorization, it was mostly for en-hancing document representation in supervised set-tings, e.g. (Rodr  X   X guez et al., 2000).
 WordNet. Referring terms were found in Word-Net starting from relevant senses of the category name and transitively following relation types that correspond to lexical reference. To that end, we specified for each category name those senses which fit the category X  X  meaning, such as the outer space sense for the category Space . 1
A category name sense is first expanded by its synonyms and derivations, all of which are then ex-panded by their hyponyms. When a term has no hyponyms it is expanded by its meronyms instead, since we observed that in such cases they often spec-ify unique components that imply the holonym X  X  meaning, such as Egypt for Middle East . However, when a term is not a leaf in the hyponymy hierarchy then its meronyms often refer to generic sub-parts, such as door for car . Finally, the hyponyms and meronyms are expanded by their derivations. As a common heuristic, we considered only the most frequent senses (top 4) of referring terms, avoiding low-ranked (rare) senses which are likely to intro-duce noise.

Wikipedia. We utilized a subset of a lexical ref-erence resource extracted from Wikipedia (anony-mous reference). For each category name we ex-tracted referring terms of two types, capturing hy-ponyms and synonyms. Terms of the first type are Wikipedia page titles for which the first definition sentence includes a syntactic  X  X s-a X  pattern whose complement is the category name, such as Chevrolet for the category Autos . Terms of the second type are extracted from Wikipedia X  X  redirect links, which capture synonyms such as x11 for Windows-X .
The reference vector ~c of the category name and all its referring terms, equally weighted. The corresponding similarity function is Sim ~ d 3.2 Incorporating context similarity Our key motivation is to utilize Sim sis for classification in step 3 (Figure 1). However, this may yield false positive classifications in two cases: (a) inappropriate sense of an ambiguous re-ferring term, e.g., the narcotic sense of drug should not yield classification to Medicine ; (b) a passing reference, e.g., an analogy to cars in a software doc-ument, should not yield classification to Autos .
In both these cases the overall context in the docu-ment is expected to be atypical for the triggered cat-egory. We therefore measure the contextual similar-ity between a category c and a document d utilizing LSA space, replicating the method in (Gliozzo et al., 2005): ~c tors of the category name and the document, respec-tively, yielding Sim
The overall similarity score of step 3 is de-fined as Sim ( c, d )= Sim This formula fulfils the requirement of finding at least one referring term in the document; otherwise Sim ref ( c, d ) would be zero. Sim con ( c, d ) is com-puted in the reduced LSA space and is thus prac-tically non-zero, and would downgrade Sim ( c, d ) when there is low contextual similarity between the category name and the document. Documents for which Sim ( c, d )=0 for all categories are omitted. We tested our method on the two corpora used in (Gliozzo et al., 2005): 20-NewsGroups, classified by a single-class scheme (single category per doc-As in their work, non-standard category names were adjusted, such as Foreign exchange for Money-fx . 4.1 Initial classification Table 2 presents the results of the initial classifica-tion (step 3). The first 4 lines refer to classification based on Sim only the category name in the reference vector ( Cat-Name ) yields particularly low recall. Expansion by WordNet is notably more powerful than by the auto-matically extracted Wikipedia resource; still, the lat-ter consistently provides a small marginal improve-ment when using both resources ( Reference ), indi-cating their complementary nature.

As we hypothesized, the Reference model achieves much better precision than the Context model from (Gliozzo et al., 2005) alone ( Sim For 20-NewsGroups the recall of Reference is lim-ited, due to partial coverage of our current expansion resources, yielding a lower F1. Yet, its higher pre-cision pays off for the bootstrapping step (Section 4.2). Finally, when the two models are Combined a small precision improvement is observed. 4.2 Final bootstrapping results The output of step 3 was fed as standard training for a binary SVM classifier for each category (step 4). We used the default setting for SVM-light, apart from the j parameter which was set to the number of categories in each data set, as suggested by (Morik et al., 1999). For Reuters-10, classification was determined independently by the classifier of each category, allowing multiple classes per document. For 20-NewsGroups, the category which yielded the highest classification score was chosen (one-versus-all), fitting the single-class setting. We experimented with two document representations for the super-vised step: either as vectors in tf-idf weighted term space or as vectors in LSA space.
 First, we observe that for the noisy bootstrapping training data LSA document representation is usu-ally preferred. Most importantly, our Reference and Combined models clearly improve over the earlier Context . Combining reference and context yields some improvement for Reuters-10, but not for 20-NewsGroups. We noticed though that the actual ac-curacy of our method on 20-NewsGroups is notably higher than measured relative to the gold standard, due to its single-class scheme: in many cases, a doc-ument should truly belong to more than one cate-gory while that chosen by our algorithm was counted as false positive. Future research is proposed to in-crease the method X  X  recall via broader coverage lexi-cal reference resources, and to improve its precision through better context models than LSA, which was found rather noisy for quite a few categories.
To conclude, the results support our main contri-bution  X  the benefit of identifying referring terms for the category name over using noisier context mod-els alone. Overall, our work highlights the potential of text categorization from category names when la-beled training sets are not available, and indicates important directions for further research.
 The authors would like to thank Carlo Strapparava and Alfio Gliozzo for valuable discussions. This work was partially supported by the NEGEV project (www.negev-initiative.org).

