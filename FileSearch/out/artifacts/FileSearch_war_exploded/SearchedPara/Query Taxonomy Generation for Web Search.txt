 We propose an approach that organizes the search-result clus-ters into a hierarchical structure, called a query taxonomy, from the user X  X  perspective. The proposed approach is based on an unsupervised classification method, which uses the dy-namic Web as the training corpus. With query taxonomy, users can browse relevant Web documents more conveniently and comprehensibly. Our experimental results verify the fea-sibility and the effectiveness of the proposed approach to query taxonomy generation in Web search.
 Categories and Subject Descriptors: H.5.3 [Group and Organization Interfaces]: Web-based interaction General Terms: Algorithms.
 Keywords: Query taxonomy, Web Search.
In [1], Assisted keyword search, which automatically clus-ters retrieved snippets into a taxonomy, is one of the solutions to the problems faced in directory-based search. But because of the lack of supervision during clustering, the controversial number of clusters and labels of topic clusters in assisted key-word search are always confusing users. For example, some users may be interested in categories of publication and award when they input a query as Gerard Salton ,whileotherusers may be interested in university ,and program committee .
Let Q be a set of queries submitted to search engines by users and D be a set of retrieved documents on the Web. We use a tuple M 1 ( Q, D ) as the model to denote unassisted keyword search. Given a query q  X  Q , the goal of M 1 ( Q, D is to give relevant documents D  X  D higher ranking with respect to the query q . Research on assisted keyword search primarily focuses on clustering similar search results. We further define a 3-tuple model M 2 ( Q, T, D ) for these cluster-based approaches, [3], where T is a set of auto-generated topics created by clustering D or by extracting key terms from D . To improve assisted keyword search, in this paper, we propose a new unassisted keyword search model denoted as
M 3 ( Q, C, T, D ), called query taxonomy model.
The approach are composed of two steps: (1) unsupervised classification, which learns the classifiers for topic classes and (2) topic extraction, which generates topics T . 4: t  X  1 5: for each topic class c  X  C do 9: for each term m in c ( t ) and each c  X  C , c = c do 10: Unique ( m, c ) 12: end for 15: t  X  t +1 16: end while 17: end for 18: return c ( t ),  X  c  X  C .

In unsupervised classification, the first challenge is how to learn the classifier for each topic class, c  X  C , without man-ually labeled training corpus. A previous work [2] has shown that search-result snippets obtained from search engines is possibly an effective source of training corpus for topic classes in hierarchical form.

For the quality of search-result snippets, we propose a boot-strapping algorithm LBA (Learning by Bootstrapping Algo-rithm), as shown in Figure 1, which extracts expanded terms and retrieves snippets from the Web by using the expanded terms as queries iteratively.
Let SR q , composed of titles and descriptions, be a set of retrieved snippets for query q such that | SR q | represents the size of SR q . We propose a score function, TFIDF  X  ( t ), which considers the length and position of each candidate because titles in SR q are more comprehensible and longer terms often provide more concrete meaning.

Moreover, the rate of coverage and compactness are also used to determine the proper number of related topics. We want to select minimum number of candidates with the high-est coverage rate. Two thresholds,  X  1 and  X  2 , are set for the coverage rate and the compactness rate, respectively. After a series of observations, we find that 80% of snippets are cov-ered by top 20% of ranked topics; therefore  X  1 is set at 0.8, and  X  2 is set at 0.2.
We describe a user study to compare M 3 ( Q, C, T, D )with models M 1 ( Q, D )and M 2 ( Q, T, D ). We have developed an experimental system with the proposed model M 3 ( Q, C, T, D called LiveConcept 1 . Two commercial search engines, Google and Vivisimo, were selected as the representations for model M 1 ( Q, D )and M 2 ( Q, T, D ), respectively. From categories countries and cities , 10 queries were randomly selected for the two user-studies.

For user-defined topic classes used in LiveConcept, 6 topic classes and their corresponding associated terms were defined as Table 1. The defined topic classes help users identify dif-ferent topics covered by the search results pertaining to the countries and cities.
 Table 1: Topic classes used in query taxonomy gen-eration.

We compares the performance of LiveConcept M 3 ( Q, C, T, D on informational search and navigational search with two commercial search engines, Google M 1 ( Q, D ) and Vivisimo M 2 ( Q, T, D ).
 Table 2: The questions for evaluating LiveConcept.

Table 2 collects the designed questionnaire in this compar-ison. We asked 35 subjects to score each question in Table 2 in the range from 0 to 10 to express their satisfaction at each search engine, where LiveConcept is divided into ( C + T + and ( T + D ) to examine the effect of the topic classes.
The average score of each question over the 35 subjects is shown in Table 3. It is trivial to find that Google got the best efficiency in navigational search (1b) while LiveConcept did http://wkd.iis.sinica.edu.tw/LiveConcept/ in informational search (2a) This observation matches our ex-pectation that search result clustering with model M 3 ( Q, C, T, D indeed help users search Web interactively than that with models M 2 ( Q, T, D )and M 1 ( Q, D ). Comparing (1a) and (1b), we can find that no matter in model M 3 ( Q, C, T, D M 2 ( Q, T, D ), clustering search results seems not to be useful for searching specific information. This is reasonable because the performance of search result ranking (or high precision) is much more important in navigational search. LiveConcept with classes C achieved higher performance than that with-out C . This is because in model M 2 ( Q, T, D )thesubjects might not be familiar with a dynamically generated list of topics so that they still needed to browse a long ranked list to choose the one(s) relevant to the queries. From (1c), when limiting the number of returned topics, model M 3 ( Q, C, T, D had more chances to select the target topic of the expected information into C .
 Table 3: The results of comparing Google(G), Vivisimo(V), and LiveConcept(L).

Table 3 (2a) shows that model M 3 ( Q, C, T, D ) really fa-cilitated the browsing for the subjects through user-defined topic classes; with the topic classes, the subjects were able to more easily understand the meanings of the selected topics (2b). But the model was difficult to deal with general queries (2c) because some of the subjects did not know how to define their own topic classes.
We have shown that defining topic classes manually alle-viates the serious problems of (1) a lack of comprehension of topics T , and (2) the retrieval of topics T not of interest to users, which are faced by conventional search result clus-tering methods. However, one major concern about model M 3 ( Q, C, T, D ) for online Web searches is its complexity. The execution time needed by the unsupervised classification ap-proach is determined by the processes of Web search for col-lecting training data and term/feature extraction. The other concern is that the classification accuracy of the proposed unsupervised classification method will affect the quality of the generated query taxonomy for browsing. [1] S. Dennis, P. Bruza, and R. McArthur. Web searching: a [2] C.-C. Huang, S.-L. Chuang, and L.-F. Chien.
 [3] K. Kummamuru, R. Lotlikar, S. Roy, K. Singal, and
