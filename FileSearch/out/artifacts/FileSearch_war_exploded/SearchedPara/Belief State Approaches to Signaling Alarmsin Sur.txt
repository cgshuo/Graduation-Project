 Surveillance systems have long been used to monitor in-dustrial processes and are becoming increasingly popular i n public health and anti-terrorism applications. Most early detection systems produce a time series of p-values or some other statistic as their output. Typically, the decision to signal an alarm is based on a threshold or other simple al-gorithm such as CUSUM that accumulates detection infor-mation temporally.

We formulate a POMDP model of underlying events and observations from a detector. We solve the model and show how it is used for single-output detectors. When dealing with spatio-temporal data, scan statistics are a popular me thod of building detectors. We describe the use of scan statistic s in surveillance and how our POMDP model can be used to perform alarm signaling with them. We compare the re-sults obtained by our method with simple thresholding and CUSUM on synthetic and semi-synthetic health data. I.2.6 [ Artificial Intelligence ]: Learning; I.2.8 [ Artificial Intelligence ]: Problem Solving, Control Methods, and Search Algorithms, Experimentation Probabilistic Model, Scan Statistic, Signaling Alarms, Su rveil-lance Systems
Automatic surveillance systems are becoming more pop-ular and are increasingly using data mining methods to perform detection. The observation of industrial manu-facturing processes is one traditional application of thes e systems. Another application is public health monitoring, which has the goal of detecting new disease outbreaks as early as possible. Searching for terrorist activity or atta cks is also becoming important. Applications in that area in-clude monitoring human health and behavioral data to de-tect a chemical or biological attack, or searching for signs of radiation to detect development or deployment of nuclear devices. The RODS lab at the University of Pittsburgh (see www.health.pitt.edu/rods/) is focused both on public heal th monitoring and detection of biological attacks. This paper is based on our work in the RODS lab and thus focuses on these applications, but the algorithms we present are not specific to them. They are appropriate for a variety of mon-itoring tasks.

Modern surveillance systems are characterized by the need to analyze many variables simultaneously. Because of this fact, the traditional method of setting upper and lower boun ds for a single variable are no longer appropriate. Data mining methods are used that must address the complex interac-tions between variables, the dangers of multiple hypothesi s testing, and the computational issues caused by large data sets. See [9] for an overview of detection methods.
Typically, a detection algorithm will take a time-series of many variables as input and produce a time-series of p-values, or some other indication of alarm level, as output. Many of the detection algorithms use sophisticated means such as randomization testing and additional correction fo r multiple hypothesis testing to make their outputs as accu-rate as possible. Often, these outputs are followed up with simple thresholding to determine whether to signal an alarm and call for further investigation. Since the outputs are ge n-erated as a time series it makes sense to combine the infor-mation provided by them temporally in order to make bet-ter decisions about signaling alarms. One popular method of doing this is CUSUM and we describe that algorithm in the next section.

In this paper, we propose a probabilistic model of the pro-cess being monitored and the detection algorithm watching it. Based on those models we can determine the correct be-lief state for the underlying process and the optimal decisi on when considering the costs of signaling and alarm and allow-ing an event to go undetected. We compare this method to CUSUM and thresholding on synthetic data and show its superior performance. Secondly, we describe scan statisti cs and how they are used to construct detection algorithms on spatio-temporal data. We then show how our probabilis-tic model is used with scan statistics and present empirical results on synthetic and semi-synthetic health data.
Figure 1: Two state model of Biological attack
Before presenting our algorithm, we describe a popular method used in signaling alarms. CUSUM was originally developed to detect changes in the quality of output of con-tinuous production process. It can quickly detect a shift in the mean of a process. As the name suggests, CUSUM maintains a cumulative sum of deviations from a reference value r. Let us consider a time series where at time i we have measurement X i . The one-sided CUSUM calculation is as follows:  X  0 is the in-process mean. From the equations above, if the X m values are close to the mean, then the C m values will be some small value. However once a positive shift from the mean occurs, the C m value will increase rapidly. K is known as the slack value or allowance. In the equation above, any values within K units of  X  0 will be effectively ignored. The allowance K is usually set to be the midpoint between the in control process mean  X  0 and the out-of-control process mean  X  1 .

Alerts are raised whenever C m exceeds a threshold de-cision interval H. The Average Run Length (ARL) is con-trolled by this parameter. The ARL is the average number of timesteps before an alert is raised.

The CUSUM algorithm described here has been exten-sively used in biosurvelliance systems. It has been used for influenza survellience [8], detection of salmonella out -breaks [3] and in the Early Aberration Reporting system [2]. CUSUM algorithms have also been extended to incorporate spatial information such as [6] and [7].
We assume a Markov Decision Process model for a ter-rorist attack scenario. Again, we note that the model is not specific to this type of monitoring application. Fig 1 shows the two state model considered for the attack. The first state represents a situation when there is no attack and the second state represents the situation when there is an attack. There are two possible actions at each state, either to investigate or to not investigate. These are represented by the block arrows. If we are in the clear state and choose not to investigate then there is a prior probability p 0 of an attack occurring on that day. At any state if we choose to investigate, we return to the clear state. This action can be Figure 2: The clear (solid) and attak (dashed) state distributions of the underlying variable s and p-values thought of as a reset action where the state is reset to clear. And of course, in the attack state if we do not investigate, we remain in that state.

There is a cost associated with each action. There is a cost of investigation which is same for both the states. If we are in the attack state, and we do not investigate, then there is an associated cost (cost of false negative). In the clear state, if we choose not to investigate, we do not incur any cost.

The problem stems from the fact that at a particular in-stant of time, we do not know our current state. Instead, at each time instant we percieve an observation which is depen-dent on the underlying state. The observation in our case is some informative statistic that is the output of a detection algorithm. This makes the system a Partially Observable MDP (POMDP) (see [4]). In order to fully characterize the POMDP, we need to know the exact distribution of this statistic under each state.

For our purposes we use the p-value that is usually output by a detection algorithm. By definition, the distribution of the p-values under the null hypothesis (there is no attack) should be a uniform 0-1 distribution. Let f clear ( p ) be this distribution. We need to determine f attack ( p ), the distri-bution of p-values under the alternate hypothesis, ie., in the case when there is an attack. For our experiments we have derived this distribution by assuming some form of an underlying distribution. First consider that there is some underlying variable s that is normally distributed. Under the null hypothesis (clear state), it has mean 0, and vari-ance 1. Under the alternate hypothesis (attack state), it has mean M and variance 1. These two distributions are shown in Fig 2. It is possible to derive the distribution of p-values under the alternate hypothesis from these distrib u-tions. f clear ( p ) and f attack ( p ) distributions obtained from the gaussian assuption is shown in Fig 2. The parameter M can be varied to obtain different distributions of f attack As M increases, the distribution f attack ( p ) becomes more skewed towards p=0. Apart from using the normal distri-bution, we also consider the gamma distribution for the un-derlying variable.
We now solve this POMDP using value iteration over the belief states. The POMDP is first converted into a belief state MDP. Each state of the MDP represents a particular belief that we are in the attack state. Since the belief is a re al value ranging from 0 to 1, we have a continuous state MDP. To use value iteration, we discretize this state space into N discrete states labelled 0 to N-1. The state i represents a belief i N  X  1 that we are in the attack state. Typically we use N=100 in our experiments. We start with a particular belief that we are under attack. At each time step, we get an observation p, and we update our belief state. Let us assume that at time instant t we under attack. From our model, we know that there is a prior probability p 0 of there being an attack on that day. So our apriori belief that we are under attack is x 0 = x t +(1  X  x
The transition probability matrix is determined by a ran-dom simulation as follows: The cost function for the belief state MDP can be defined as
C ( b ( x ) , A j ) = (1  X  x )  X  C ( Clear, A j ) + x  X  C ( Attack, A Here b(x) is the belief state where our belief that we are under attack is x. A j is the action, either to investigate, or to not investigate.
We now use the standard value iteration algorithm to solve the MDP. Due to the structure of our two state POMDP, the optimal solution of the belief state MDP has a particular property. There exists a threshold belief b threshold , such that in all the states corresponding to a belief less than b threshold the optimal action is to not investigate. And the optimal action is to investigate in all the states that correspond to a belief more than b threshold .
In our model we have assumed a fixed distribution of the observation parameter once an attack has occured. But in case of an actual attack we might expect that after the at-tack has occured, the distribution of the observed paramete r keeps changing with time. For example the symptoms get more pronounced with time, and the deviation from the clear state distribution becomes more marked. Also the cost of not detecting the attack might not vary linearly with the number of days the attack is not detected. These consider-ations led us to introduce additional states in our basic two
Figure 3: Three state model of Biological attack state model. The difference between two successive days when an attack has occured is going to be most pronounced in the case of the first day as compared to the later days. So we split the attack state into two states. One corresponds to the first day of the attack, and the other corresponds to when the attack is in progress for more than a day. This model is shown in Fig 3.

We have assumed different distributions of the p-values for the three states. Also the cost of not investigating whil e under attack is different in the two cases. Here we have assumes a lower false negatve cost for the first day than the cost when it is underway for more than a day.

It is also possible to extend this model by introducing ad-ditional states for the 2nd day and so on. The complexity of solving the POMDP increases exponenially with the num-ber of states. So we have done empirical tests only upto 3 states.
We simulate the two state model starting from the clear state and going to the attack state with a probability p 0 any day. Once in the attack state, we remain there until alarm is signalled. The state is then reset to clear. The observations (p-values) are generated from either of the tw o distributions f attack ( p ) or f clear ( p ) depending on the current state.

We use Thresholding, CUSUM and the MDP based so-lution independently to signal alarm. In order to evaluate the performance of the algorithms, we measure the number of false positives and the number of days till the attack was detected. To obtain this AMOC curve, we need to control the false positive rate of the differnt procedures through a parameter. In Thresholding, we vary the Threshold p-value below which alarm is signalled. In CUSUM, we vary the decision interval H to obtain different false positive rates . And in the case of the MDP solution, we vary the ratio of the cost of false negative to the cost of investigation.
The simulation is carried on for a 100 year period with 1 day as the unit of time. We have done 100 random runs of this stretch to determine the confidence intervals. The num-ber of false positives per year is plotted against the averag e number of days required to detect an attack.
These results from the simulated data indicate that CUSUM performs better than p-value thresholding. The MDP based approach outperforms both the other methods. For all the experiments using gaussian distribution for the underlyin g Figure 4: Plot of Detection Time vs False Positives assuming p 0 = 0.005 Table 1: Area under the AMOC curves for 2 state model with 95% confidence intervals gaussian 0.01 213.68 gaussian 0.005 219.10 gamma 0.01 205.81 Table 2: Area under the AMOC curve for 3 state model with 95% confidence intervals
Distr. p select POMDP CUSUM Thresholding gamma 0.01 208.39 variable, we have fixed the mean in the clear state mean clear = 0. Also the standard deviations are set to 1. Fig 4 shows the result when the prior probability of attack p 0 = 0.005 and the mean for the underlying variable in the attack state
In our second experiment, we used all the same values for the parameters as in the previous case, but increased the prior probability of attack ( p 0 ) to 0.01. We then calculated the area under the corresponding AMOC curves. The values are shown in row 2 of Table 1.

In our third experiment we used a Gamma distribution for the underlying variable. The parameters for the clear state distribution are taken as  X  = 2,  X  = 1, and those for the attack state are  X  = 2,  X  = 0.85. Row 3 of Table 1 gives the area under the AMOC curves.

In the final experiment we used the three state model described in section 4. The underlying variable is assumed t o have gamma distribution. For the clear state the parameters are  X  = 2,  X  = 1. f attack 1 ( p ) has the parameters  X  = 2,  X  = 0.9, and those for f attack 2 ( p ) are  X  = 2,  X  = 0.85. The results are shown in Table 2. Consider the plot in Fig 5. Each point shows the loca-tion of a patient arriving in the emergency department 1 . The crosses mark points with a particular symptom of in-terest such as respiratory problems. We are interested in determining whether there is some region within this data (such as the circle shown in the plot) that has a higher in-cidence rate of the symptom of interest. This is a typical spatial scan statistic application. Studies of this sort ar e common in the field of public health and are used to deter-mine whether environmental factors are causing higher dis-ease rates in certain areas. In our case, we are interested in early detection of a bio-terrorist attack, which under seve ral delivery mechanisms including airborne, may be clustered spatially. The algorithm for computing the scan statistic i s as follows (adapted from [1, 5]): 1. Compute the likelihood of the data given the hypoth-2. For each candidate region, W , compute the likelihood
This data comes from emergency departments in the Pitts-burgh area. The data has been anonymized and the loca-tions have significant noise added for further privacy prote c-tion. 3. For each region, compute the likelihood ratio: L W /L 0 4. Find the largest likelihood ratio. This is the scan
Having computed the scan statistic for this example, we now turn to the question of what the null distribution of the statistic is under the assumption that there truly is a singl e uniform incidence rate over the whole data set. We simulate the null distribution by randomly shuffling the marks on the dataset and recomputing the scan statistic.

We can also calculate the p-value of each region by com-paring its likelihood ratio with the samples obtained in ste p 3 of the randomization. In our experiments we choose a set of random n regions number of regions.

This is a spatial version of scan statistics. During survel-lience, we obtain new emergency department data each day. We can run this algorithm daily on that data. The simplest way to detect if an attack has occured is to signal an alarm whenever the p-value of any region is below a particular threshold value p threshold . This corresponds to the p-value thresholding as described in the introduction.

Alternatively, we can use CUSUM to signal alerts. This can be done in two ways. Each day, we obtain a p-value for each region under consideration. We choose the mini-mum p-value p min as the p-value for that day. We then run CUSUM with these p-values as the observations. We call this plain CUSUM. Another possibility is to run CUSUM in parallel for each region. We have n regions instances of CUSUM, where each corresponds to a particular region. The p-value of a region on any day is the observation X i used by CUSUM. We signal an alert when any one of these CUSUM values goes above the predetermined threshold. This method will be refered to as regionwise CUSUM.
We also apply our belief state based approach on these p-values. Similar to the regionwise CUSUM, we maintain n regions different belief values, each corresponding to the belief that a particular region is under attack. Each day, these belief values are updated using the p-value of that region on that day.
The base data set used for these experiments has the fol-lowing attributes:
We used two datasets for the experiments. 1. The first is a purely synthetic dataset. We randomly 2. The second dataset is a real emergency department
These data contain no unnatural outbreaks. So in order to test our algorithms we must introduce aritificial outbreaks . In this section we use an outbreak simulation based on mod-ified versions of our data set that matches the modeling as-sumptions we make in the previous section.

We use the two state model described in section 3. We start from the clear state and on any day there is a proba-bility p 0 =0.08 that there is an attack. Once in the attack state, we remain there until alarm is signalled. The state is then reset to clear. In the clear state, we use the part of the original data corresponding to that day. If we are in the attack state, the data is modified as follows: 1. Select the part of the original data set that corresponds 2. Choose a region, W , at random. The region is chosen 3. For each data point, choose a data point from the
For CUSUM and belief state approach, we need to de-termine the f clear ( p ) and f attack ( p ) distributions. In the clear state, the p-values generated for each region does not correspond to the true p-value under the null hypothesis. This is because, we compare the likelihood of each region against the likelihood of the most significant region under the randomizations. So in this case f clear ( p ) is not an uni-form distribution, but is heavily skewed towards p=1. These distributions are learnt from the data. We make an initial pass on the data when we output the p-values of the clear and attacked regions. We estimate the distributions from these values. In a real scenario, historical data can be used to learn these distributions.

For the purpose of our experiments, we need not solve the POMDP explicity. The solution to the POMDP model gives a belief threshold, b threshold as described in section 3.4. To plot the AMOC curves shown here, we can vary this threshold to obtain different points on the curve. The results involving dataset 1 are shown in Fig 6 and Table 3. Table 3 gives the area under corresponding AMOC Figure 6: Plot of Detection time vs False Positives for Dataset 1, with p select =0.1 Figure 7: Plot of Detection time vs False Positives for Dataset 2, with p select =0.2 curves for different values of p select . Fig 7 and Table 4 shows the corresponding results for dataset 2.

The results for dataset 1 indicate that the detection time for the belief state based approach is significantly smaller than that for the other approaches. We see that the region-wise CUSUM does not perform any better than threshold-ing, and the plain CUSUM approach actually does much worse than thresholding. This might be because of the fact that the distribution of the observed p-values is heavi ly skewed. CUSUM works better when these distributions can be approximated by the normal distribution.

The results obtained on dataset 2 are similar. The POMDP approach again outperforms all the other approaches. CUSUM does not give much improvement over thresholding.
We have assumed that successive p-values are indepen-dent. But, this assumption might not hold for many detec-tion algorithms. In that case we need to take the dependency Table 3: Area under the AMOC curves with 95% confidence intervals for Dataset 1 p select POMDP Regionwise Table 4: Area under the AMOC curves with 95% confidence intervals for Dataset 2 p select POMDP Regionwise into account. Since the nature of dependency will depend heavily on the actual algorithm used for detection, this iss ue has to be addressed with regard to specific algorithms.
The procedure described here can be extended to include multiple detection algorithms. It might be used to consoli-date the output of many detection algorithms to determine when to signal an alarm.

Also, while developing this method, we have assumed some definite distributions for an underlying variable. We need to evaluate the performance of the method if our as-sumption is not correct. As already mentioned, in a real life scenario, we might learn the underlying distribution from historical data.
