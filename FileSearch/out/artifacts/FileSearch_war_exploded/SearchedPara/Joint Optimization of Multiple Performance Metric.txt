 The field of online advertising, in essence, deals with the problem of presenting ads to online users in the most appro-priate contexts to achieve a multitude of advertiser goals. A vast amount of work in online advertising has been fo-cused on optimizing banner display advertising campaigns where the main goal lies in direct response metrics, often as clicks or conversions. In this paper, we explore the newly popularized space of online video advertising, where brand recognition is the key focus. We propose a framework based on a feedback mechanism where we optimize multiple video specific performance indicators while making sure the deliv-ery constraints (budget and user reach) of advertisers are satisfied. While our main focus is on improving metrics such as engagement (amount of view time), and viewabil-ity (whether a campaign is within eyesight of a user), we also discuss the possibilities of expanding to other metrics. We demonstrate the benefit of our framework via empirical results in multiple real-world advertising campaigns. To the best of our knowledge, this is the first paper that deals with the unique challenges arising from the nature of online video advertising.
  X  Information systems ! Computational advertising; Expert systems; Online Advertising; Video Advertising; Performance Opti-mization
Online advertising aims to match advertisers with the most beneficial online users through the most appropriate * The authors contributed to this work equally.
 contexts (websites, mobile applications etc.) in order to maximize their campaign specific goals. These campaign specific goals are often one of two kinds: brand recognition metrics, i.e. any metric which serves to indicate whether or not an audience X  X  opinion of an advertiser X  X  product has improved, or whether or not the size of the audience that knows about an advertiser (or a specific product) has in-creased; and direct response metrics, which can be directly measured in terms of monetary value, such as a click or a conversion (product purchase, subscription to a newsletter, etc.) [11].

The online advertising ecosystem is generally accepted to be comprised of components which collectively enable ad-vertisers to reach their aforementioned goals: Demand-side Platforms (DSPs) strive to find opportunities on behalf of advertisers to show an ad (impression) to a user beneficial to a specific advertiser; Supply-side Platforms (SSPs) are pub-lishers (websites or mobile application providers) or inter-mediary platforms (which publishers connect to) that sup-ply advertising opportunities for multiple competing DSPs (often in a second-price auction) to capture and show an ad-vertisement on; Data Management Platforms (DMPs) deal with processing first-party and third-party data for adver-tisers in order to enable business and analytical inferences for more e  X  ective advertising.

By the help of the above three components, the online advertising domain has experienced tremendous growth in the past few years, both in terms of the quality of ads and the amount of Internet tra c allocated to online advertising [19]. In terms of the media type used for advertising, ban-ner display ads have been the main industry standard for the past two decades [4], which are graphic ads designed to achieve user attention, and whose components can also be calibrated for further optimization [9]. In accordance with this trend, a vast amount of literature has been focused to-wards optimizing direct response metrics which are clicks [6] or conversions [11], since it is not trivial to estimate brand recognition metrics for banner ads. This is especially true for evaluating whether the users X  opinions of an advertiser improved or not, which is even more complex.

In this paper, our e  X  orts are mainly focused on optimiz-ing video advertising campaigns where the ads shown to users are in the form of videos, which can have a variety of durations. The key di  X  erence for this type of advertising (compared to display ads) is that brand recognition metrics are used much more commonly compared to direct response metrics. Our focus is on two metrics whose detail is given in the next section: ( i ) Engagement , which depends on the Figure 1: Spend distribution over metric priorities for banner display advertising.
 Figure 2: Spend distribution over metric priorities for video advertising. length of time a video ad is watched, and ( ii ) Viewability , which depends on the location of the video ad inside a web-page or an application. We also propose a feedback-based mechanism that both optimizes the aforementioned two met-rics, and satisfies the advertisers X  delivery constraints. To the best of our knowledge this is the first work that deals with the specific challenges of online video advertising.
The main contributions of this work include:  X  A detailed examination of challenges that arise from  X  A multi-criteria optimization framework specific to video  X  Real-world experiments and results that demonstrate
As aforementioned, we explore the details of video adver-tising in this work, which is inherently di  X  erent compared to banner display advertising. First of all, the advertis-ers that follow the path of display advertising  X  often uti-lize click or conversion optimization campaigns. While the advertisers also wish to receive brand recognition through run-of-network campaigns (RON) where no optimization is * Within this paper, from time to time, we will use the term display advertising , for short, instead of banner display advertising . implied with fixed bid values, aiming to explore new audi-ences via relaxed user targeting constraints, they have no way to measure whether the users were indeed interested in their product, except for the direct response metrics. Please see Figure 1 for the distribution of campaign spending for display advertising on Turn X  X  platform for a 15-week period within 2015 over di  X  erent metric prioritizations which sup-ports our claim. In online video advertising however, the ad-vertisers are mainly concerned with brand recognition. This makes it necessary to use metrics which are more closely tied to evaluating the brand recognition performance of a cam-paign. In this paper we are mainly focusing on three such metrics (the first one specific to video advertising):  X  Engagement metric measures the percentage of the  X  Viewability indicates the goodness of the ad X  X  location,  X  User Reach indicates how many users have watched Figure 2 shows the distribution of spending for the video campaigns within Turn that signals importance on di  X  erent metrics for the same 15-week period as in Figure 1. It can be seen that there is a clear upwards trend of advertisers utilizing viewability and engagement optimization tactics. Furthermore, we can also observe that the amount of budget spent for conversion campaigns holds a much smaller portion of the total video spend compared to display campaigns.
Lack of interest in direct response metric for video adver-tising has both advantages and disadvantages. A significant advantage comes from the fact that several problems arising for campaigns that value conversions are no longer of con-cern. First of all, one of the greatest problems related to con-version prediction/tracking is delayed feedback [2], since it takes a significant amount of time for a user to act (in terms of conversion , i.e. product purchase etc.) after seeing an ad, or clicking it. Secondly, tracking conversions requires a me-thodical way to attribute the conversion to the campaigns that show the ad to the user [17, 5], which is not trivial. This means that when we have a campaign that prioritizes conversions as its performance metric, there will be times when it will not even be able to register those conversions (because they have been attributed to another campaign) for accurate performance estimation.
The main disadvantage of having campaigns that priori-tize brand recognition (not direct response) metrics is the ambiguity in assigning a monetary value to the evaluated metrics. While it is trickier for an advertiser to give a mon-etary value for a click, it is often trivial to see how much monetary value an advertiser should assign to a conversion. For example, the amount of money spent by the user when s/he purchases a product, or the profit made by the adver-tiser for that conversion, can yield a very intuitive monetary value which can be assigned to a certain conversion. This way, we can look at return-on-investment (ROI) for a specific campaign, which is the ratio of monetary value received (via clicks or conversions) by the campaign to the total amount of money spent for impressions by the campaign. Therefore, in some cases, we do not even have to have a great reach (number of unique users which are shown an impression) or delivery (the amount of money spent for advertising via im-pressions), as long as we can get a su cient number of direct responses. This however is not the case for brand recognition metrics. There is no trivial way to assign monetary value to an engagement or view event by a user. Hence, the problem we need to solve for online video advertising includes both optimization of brand recognition metrics, as well as satis-fying user reach and delivery criteria set by the advertiser. Please note that satisfying the delivery constraints of an ad-vertiser campaign by itself is a di cult problem which is severely a  X  ected by the characteristics of the audience that the advertiser wants to reach [7, 18]. This di culty gets further aggravated in video advertising campaigns where we aim to improve brand recognition metrics as well.
As mentioned in the previous section, coming up with a system that optimizes brand recognition metrics as well as delivery is our focus. After the literature survey in the next section, we will first delve into the formal definition of the problem we are trying to solve. We then will present our proposed methodology which aims to perform a constant trade-o  X  between the delivery of a campaign and engage-ment as well as view events received by that campaign.
Based on the domain-specific goals and metrics of suc-cess for online video advertising, we have introduced the challenges that are significantly di  X  erent from those of the current mainstream approach, which is display advertising. As expected, display advertising has also been much more extensively studied in literature. To the best of our knowl-edge, our current work is the first to address the specific challenges arising in online video advertising. However, con-sidering that our work also employs a joint optimization over various metrics, we will detail prior research done and ap-proaches taken to jointly optimize performance and/or deliv-ery metrics in online advertising. Please note that there are very few works detailing optimization e  X  orts in online video advertising, and these in general exist in the substantially di  X  erent context of online video advertising infrastructure. One such work deals with jointly optimizing the allocation of video rates and inserted advertisement duration in a wireless broadcast network to maximize profit [8].

Online Video Advertising: There have been a vari-ety of proposed systems to implement e  X  ective forms of on-line video advertising, focused on insertion scheduling, video context similarity, and user relevancy issues. Inserting ad-vertisements into a video stream is an especially complicated problem, as video advertisements are likely to degrade user experience if done clumsily, reducing the e  X  ectiveness of a campaign and potentially driving away users. Intuitively, advertisements are less disruptive when they are contextu-ally relevant, with one proposed system [12] using advertiser-provided images (relevant to their own brand/message) to be compared against sampled video frames to determine the best candidate advertisements to show in a given video.
Another previous e  X  ort [14] focused on detecting sets of non-intrusive advertisement insertion points within a video, in addition to using contextual and visual-aural relevance to select the best advertisements to place. The authors demon-strated that this approach improved user viewing experi-ence. A similar work [20] chose to introduce the ability to bookmark or delay interaction with an advertisement, in or-der to avoid video viewing interruption partially or entirely. Finally, in [22], the authors focus on user X  X  attention rele-vancy , where assuming a video ad triggered by a user can be considered relevant to a user X  X  attention, they propose a framework that generates semantic concepts from video broadcasts, which are subsequently used to rank video ad-vertisements by relevancy concepts to find the most relevant video advertisements to ones triggered by a user previously. This paper presented findings which suggested that such an approach was regarded as less intrusive and more satisfying.
Compared to previous work in online advertising, our cur-rent e  X  ort di  X  ers in multiple ways. First of all, the listed literature is mostly involved with systems for scheduling and presenting video content, and have access to the ac-tual video content to parse and analyze ahead of time; this is not applicable to a system like ours, which participates in the online advertising auction process in real-time under strict constraints. Additionally, most previous work is evalu-ated based on user studies and subjective measures, without much of a feedback loop or evaluation metric to evolve their systems X  algorithms or models over time. As a DSP, we are essentially solving a di  X  erent set of problems in online video advertising, which are necessarily complicated by the evaluation metrics that we are striving to satisfy.
Joint Optimization in Online Advertising: In our current proposal, we are not claiming to introduce new meth-ods of joint optimization, but rather, demonstrating a novel application for joint optimization of desired metrics in online video advertising and its empirical e  X  ectiveness. To the best of our knowledge, our proposed use of joint optimization over multiple brand recognition metrics for online video advertis-ing is a novel e  X  ort, whereas joint optimization techniques have seen historical use in more traditional areas of online advertising. Perhaps the closest such use to our approach is a framework for the joint optimization of guaranteed de-livery (often a brand advertiser X  X  goal) and pay-per-click (a performance-centric goal) auctions in sponsored search, with the objective of increasing search engine revenue [16]. This e  X  ort demonstrated the e  X  ectiveness of joint optimization compared to many baseline strategies. Additional e  X  orts in sponsored search included jointly optimizing budget alloca-tion and bid price setting, while presenting that it outper-formed both bid price optimization and campaign budget optimization done separately [24].

A multi-objective programming approach [1] to optimiz-ing click-through rate and downstream engagement metrics (e.g. a third-party reported time spent on a page), with constraints on how much click volume can be lost, is analo-gous to our approach, except for direct-response metrics and advertisers. Finally, previous research at the intersection of joint optimization applications and online video advertising seems to exist in a complete di  X  erent facet of the online advertising industry (in this case, the actual provisioners of video tra c, i.e. the wireless video broadcast network itself) [8], and is not applicable to our challenges.
Optimization Goals of Video Advertising. Real-time Bidding enables advertisers to target their ads to spe-cific users and cherry-pick only the impressions they deem most valuable to them. The core of our system is a bid-ding algorithm that computes an appropriate bid for an ad to be submitted to a webpage or mobile app that is being presented to an online user. There is a plethora of e  X  orts in the literature addressing the problem of bid estimation . For traditional display advertising, bid optimization can be modeled as a linear programming problem where the objec-tive is to maximize the expected revenue and the constraint is the budget of an advertiser [3]. The bid or the cost per impression is then modeled as: where the outcome is usually a click or conversion (i.e. di-rect responses, which we mentioned previously to be the main focus of display advertising) and the Goal is defined by the advertiser and indicates the monetary value of such an outcome. User and page dimensions are provided by the incoming bid request. The majority of research is focused on estimating the probability of a click or conversion. Re-searchers typically employ logistic regression and its variants or frequency-based features to estimate this probability [11, 15, 6, 13].

Applying the above approach directly to video advertis-ing is not feasible. First of all, as we explained in sections 1 and 2, video advertising campaigns mainly deal with brand-recognition metrics as a priority, which are harder to assign a monetary value. Furthermore, instead of having one single goal, video advertisers typically have multiple performance metrics that can be challenging to be optimized simulta-neously. Such metrics can be calculated in multiple ways, depending on the advertiser X  X  preferences. Popular ones in-clude engagement rate (ER), viewability rate (VR), user reach (UR), cost per click (CPC), cost per action (CPA), and return-on-investment (ROI). Assuming we get T bid requests X = { x 1 , x 2 ,.., x T } , we can calculate the perfor-mance of a bid model f A for advertiser A as follows: Above,
Optimizing Multiple Goals. Given advertiser A with budget B and optimization goals h 1 , 2 ,.., L i where each element is one of the metrics defined in Equation 2, our ultimate objective can be formulated as in the following:
Definition 1. The video bidding optimization algorithm tries to search for a model f that calculates and submits bids for requests X = { x 1 , x 2 ,.., x T } for advertiser A ,sothat In other words, given the constraints on budget and inven-tory, we seek an optimal bidding strategy to maximize mul-tiple returns for our customers.

Definition 2. Abidmodel f is sound if it satisfies both budget and inventory constraints; a sound model f 1 : x ! dominates another sound model f 2 : x ! R i  X  Asoundmodel f  X  is utopian i  X  f  X  dominates any other sound model f .
 In most cases, given the optimization goals h 1 , 2 ,..., it is infeasible to find a utopian bidding model for the adver-tiser. For example, assume advertiser A wants to optimize both the click rate and the engagement rate. It is clear that they can be contradictory to each other: to maximize clicks, we want to make the ads as eye-catching as possible; how-ever, once the ads get attention, it is inevitable that some users will skip the video play. On the other hand, the video ads could finish without skipping (100% engagement event) if they are invisible but in such cases the click rate will be hurt.

Since utopian bidding models rarely exist for video adver-tising, searching for appropriate models is not as straight-forward as for the conventional optimization problems of display advertising. In some cases, the advertiser is neu-tral about the priority of optimization goals and does not require an absolute ranking order. We can then search for the optimal bidding model by formulating a single-objective optimization problem such that the optimal solution to the single-objective optimization problem cannot be dominated by any sound model of the multi-objective optimization prob-lem. This can be achieved by proper scalarization of the objectives: max Here, w l is the advertiser X  X  preferences for di  X  erent optimiza-tion goals. By choosing di  X  erent parameters for the scalar-ization, we can produce bidding models with emphases on di  X  erent goals. However, in many cases the above scalariza-tion approach is not applicable due to two reasons: first, many advertisers have su cient preference and the opti-mization goals can be ranked in the order of importance; second, the choice of weight w l has a significant impact on the generated bidding model and it is not straightforward for advertisers to choose weighting parameters that make the most sense to them.

In this paper, we focus on the case where an advertiser X  X  optimization goals can be ranked in order of importance. Let X  X  assume, without loss of generality, that the perfor-mance goals are in an order of importance so that 1 is the most important and L is the least important to the adver-tiser. Then searching for the optimal bidding models be-comes solving a sequence of L single-objective optimization problems of the form where y  X  j is the optimal performance value of the above prob-lem with l = j . In other words, in each iteration we estimate the optimal performance value and use it as the constraint in the next iteration. Let us give an example to make this opti-mization scheme clearer -suppose we solve the optimization problem for the first objective, and we find f 1 which gives the optimal 1 ( f 1 ,X )= y  X  1 . Then, in the next iteration, we will find the best f 2 to optimize 2 ( f 2 ,X )= y  X  2 , such that f also satisfies 1 ( f 2 ,X ) 1 ( f 1 ,X )= y  X  1 . We obtain the final bidding model after the L th problem is solved. Please note that this optimization scheme only makes sense if the function f l we find in each iteration is not unique, otherwise we will not update the solution for the rest of the itera-tions (no other f will be feasible for any other iterations). Practically, the nonuniqueness of bidding models f l could be realized as a quasi-random (with respect to optimization goals l +1 , l +2 , etc) choice of the bidding opportunities in which the ad actually participates when the budget could be satisfied by bidding on a fraction of the available to a bidding opportunity.

In this paper, we will discuss how to approximately solve the above problem and calculate the bidding model for video advertising when an advertiser X  X  optimization goals are strictly ranked in order of importance.

Special Case of Dual Goals. In general, the most im-portant goal of display advertising is to acquire as many clicks/actions as possible. It is di  X  erent for online video advertising: like traditional TV advertising, its major pur-pose is branding  X  utilizing video impressions to create a di  X  erentiated name and image of products in order to es-tablish a presence in the consumer X  X  mind, hence attracting and retaining customers. To achieve this, advertisers usually want to maximize user reach (UR) and deliver as many im-pressions as possible. Besides maximizing user reach, video advertisers also tend to want a secondary performance goal, which can further indicate brand-recognition, such as en-gagement rate (ER) and viewability rate (VR). Although less common, as aforementioned, some advertisers do value direct response metrics in video advertising, such as cost per click (CPC) and cost per action (CPA). Thus, the most common case for optimizing video advertising has dual goals: one is UR and another is ER/VR/CPC/CPA.

As an emerging media, the winning price of video adver-tising impressions is usually high and predictable [23]. Given that an advertiser X  X  budget is limited, maximizing impres-sions is then equivalent to spending all of the available bud-get. From this it follows that the optimization problem of dual goals given in (5) can be formulated as: Here, is the secondary (after UR) metric of importance, which are VR, ER, CPC, or CPA. The bidding model needs to spend the entire budget to ensure maximum audience reach. However, solving the above problem directly is chal-lenging: first of all, the expected value for a bid request ( x is hard to forecast, especially for a newly created ad; second, the huge size of bid request patterns, as well as the real-time nature (as we do not have a global view of the bid requests, and these come in a sequence) of online advertising, make di-rect search prohibitively expensive. It is necessary to adopt an e cient approximate solution, which we will introduce in the next section. Our methodology relies on a feedback mechanism that constantly changes the manner with which we optimize the secondary goal, based on the current status of the UR satisfaction (since this is our first priority).
In order to improve both user reach and other performance metrics (e.g. viewability rate, engagement rate, CPC, or CPA), we adopt an approximation of the sequential goal op-timization. Within this approach, advertisers are allowed to set di  X  erent priorities for di  X  erent metric goals. The goal with the highest priority is always assigned to the user reach, hence our algorithm first tries to satisfy the user reach goal (in terms of budget to be delivered). Once we estimate that the primary goal can be satisfied, the algorithm tries to im-prove the second priority goal (e.g. viewability rate), and this process keeps iterating until we find a balance point where the goals are optimized. In each step, the algorithm tries to adjust the bidding model while keeping the higher priority goal satisfied. Such adjustments end when the met-ric with lower priority cannot be improved without trading-o  X  the metric with higher priority.
As discussed above, we first focus on the case of dual goals and later describe case with more then two goals. Our ap-proach to solving the dual optimization problem can be con-sidered as a special case of reinforcement learning [21]: the bidding model makes a bid based on the system dynamics, hoping to achieve optimal rewards; based on the received feedback, we might need to constantly adjust the bidding model. It is a continuous evolutionary process in the Marko-vian environment. Like other reinforcement learning prob-lems, we rely on accurate modeling of the environment to improve the secondary goal of a campaign while optimizing the primary goal. Having such models allows the system to generate virtual experience and predict the consequences of actions before they are taken. Our models of the world consist of two components:  X  Estimation of Impression Need , which is a nu- X  Estimation of Goal Metric , which maps each per-Impression Need for a campaign indicates its user reach satisfaction, and our system then cherry-picks bid requests according to their expected performance for . Here, we give an illustrative example before the formal explanation of our algorithm. Suppose that the advertiser sets the primary campaign goal to be user reach (UR), and the secondary goal to be viewability rate (VR). As we noted above, the user reach goal will be satisfied if Impression Need &lt; 1 (ideally,  X  1). The viewability rate goal is satisfied by introducing a dynamic filtering threshold for the viewabil-ity rate,  X  v . For each bid request, the website and user information is extracted from the bid request parameters, and expected viewability rate v is estimated for the qual-ified campaign utilizing the &lt; ad, website, user &gt; combina-tion. The campaign will not submit a bid for the request if v &lt;  X  v .

The framework for calculating the dynamic filtering thresh-old  X  is given in Algorithm 1, which performs the secondary goal optimization, while satisfying the primary goal of user reach. For every campaign,  X  is calculated periodically in real-time together with . We start with a conservative  X  at the beginning of the campaign to give it a boost in spending. After a new is calculated for a given campaign, the  X  increases accordingly if is in the comfortable deliv-ery mode region, and decreases if is in the risky delivery mode region, and does not change otherwise. These regions (the function classify in Algorithm 1) are calculated based on the hypothesis checking for upper and lower limits for Algorithm 1: Optimization of Dual Goals Input :  X  : Current threshold for the secondary goal
Output :  X  0 : New threshold for the secondary goal 1 calculate Impression Need ; status = classify( ); 3 calculate the moving step based on ; if status is Comfortable Delivery then 5  X  0 =  X  + ; else if status is Risky Delivery then 7  X  0 =  X  -; else 9  X  0 =  X  ;  X  0 = min(1, max(  X  0 ,0)) ; return  X  0 each region. If the user reach or delivery situation is con-stantly good ( is in the comfortable delivery region), then the secondary goal is improved in a methodical manner by consistently increasing the threshold.
We need a proxy variable in real-time to evaluate how well we are satisfying the user reach goals, which is our first priority, of a campaign. Before explaining the design of Im-pression Need, we would like to first explain the life cycle for a bid request, which ends in an advertisement shown (which is the  X  X mpression X  event) to the user. When a Real-Time Bid exchange (RTB exchange, which is a part of the SSP component of the online advertising ecosystem) sends a bid request to the DSP, several campaigns are usually qualified (through passing targeting criteria set by the advertisers) for bidding. These campaigns participate in an internal auction performed by the DSP, where they are evaluated based on multiple criteria set by the advertisers, and the advertise-ment belonging to the campaign with the highest score (for CPA or CPC campaigns this score is proportional to the value returned by Equation 1) is sent (together with the bid price in the bid response) back from the DSP. The bid responses sent to the RTB exchange by several DSPs par-ticipate in the RTB Exchange X  X  auction (which is usually second price ), where the ad with the highest bid wins the auction and is served to the online user.

Usually advertisers want their campaign budgets to be de-livered fully with more or less steady pacing within a day (similar amounts of user reach achieved for di  X  erent periods of the day) [10]. In such a case, in order to ensure steady pacing of the budget, the campaign only participates in fraction of internal DSP auctions for which it qualifies (ac-cording to the targeting criteria set by the advertiser). This dynamic parameter [0  X   X  1] directly reflects an ad-vertiser X  X  need for impressions. We heuristically adjust at time period t + 1 based on  X  X deal X  pacing of the remaining daily budget, the amount of user reach (hence budget spent) in the previous time interval, and tra c: where B t +1 is the budget to be spent at t +1, S t is the spending at t , BidRequest is the number of bid requests (we calculate BidRequest ( t +1), i.e. number of bid requests that is predicted to be achieved in time t +1, using historical data) and WinRate is the average probability of winning a bid. Impression Need, , can be applied to ensure smooth budget pacing within a day while finishing the daily budget by the end of the day (this would indeed qualify as satisfy-ing the user reach, UR, as explained in  X  4). The case when  X  1 indicates a good delivery situation (i.e. the campaign participates in only a very small fraction of qualified internal DSP auctions, because it is comfortably satisfying its UR constraint), and the case when  X  1 (the campaign par-ticipates in all qualified internal auctions) indicates a poor delivery situation, when the campaign has the risk of not satisfying budget constraints in (5) and (6).
Please note that the framework given in Algorithm 1 im-proves the secondary goal if and only if we have a comfort-able delivery pattern for the campaign. When the campaign struggles to attain its delivery or user reach goals, we need a methodical way to increase the bids for the campaign, since higher bid amounts increase a campaign X  X  chances of win-ning the RTB exchange X  X  auctions.

Lemma 1. When the budget is not fully spent, higher bid prices will obtain more impressions.

Proof. Real-time bidding follows a second price auction mechanism, therefore increasing the bid prices would not a  X  ect our cost on those impressions that had been acquired before. On the other hand, given higher bid prices, some bids that we lost before could have been won.
 This in a way causes the campaign to pay higher than its ex-pected value for each impression; however, it also helps the campaign to satisfy its primary goal, which is user reach. There is clearly a trade-o  X  between the primary and sec-ondary goals of a campaign. In this case, our proposed ap-proach calculates the bid ( b ) (for the bid request that this campaign qualifies for) as a function of three parameters, ,  X  v , and the maximum average bid price specified by the advertiser, b m : where b m is provided for a campaign when the advertiser does not want to pay more than b m per served impression on average.

For proprietary reasons and company policy, we are not able to give the exact details of the function f , however, in general, f ( b m , v ,  X  v ) monotonically increases with increas-ing v or b m . We would like to emphasize here that this function f ( b m , v ,  X  v ) is used for brand-recognition metrics (e.g. viewability and engagements) when there is no trivial way to assign a monetary value for the events seen.
We utilize the threshold  X  v as the parameter that describes current delivery situation, instead of Impression Need , ,in f . This is due to the statistical nature of Impression Need which is caused by the internet tra c. We have observed that could fluctuate in a broad range within a day, while the threshold  X  v incrementally changes with time and there-fore has a more smooth behavior that reflects the delivery trends at a larger time scale.

An illustrative example of f is shown in Figure 3. In a comfortable delivery situation (  X  v &gt; 0), the bidding func-tion f ( b m , v ,  X  v ) decreases in the region of small and in-termediate v , therefore shifting the average in-view rate to Figure 3: Illustration of bidding functions of dy-namic model in performance and delivery limits. higher values for won impressions. This has a similar e  X  ect of cherry-picking bid requests with predicted high viewa-bility. In risky delivery situations (  X  v  X  0), the function f ( b m , v ,  X  v ) increases in the region of small and intermedi-ate v , and eventually, at  X  v = 0 reaches maximum value of b m for v = 0. Please note that f ( b m , v ,  X  v  X  0) still increases for increasing v , hence improving the secondary goal of the campaign. Such behavior reflects the fact that the advertiser X  X  primary goal is user reach or delivery, and if delivery is bad, the bidding function should be as high as possible (restricted only by maximum average bid price), even for bid-requests with a small probability of success. Note that for v &gt; 0, the bidding function could be larger than b m only if the average price per impression for the given campaign over several days is less than b m , hence we have some relaxation in bidding.

In the above example, the secondary goal is completely ignored (bid is simply b = b m ) if the campaign has extremely tight targeting and therefore the delivery goal is hard to satisfy ( = 1 and therefore  X  v  X  0) and also if the average price per impression in last several days is close to the limit of b m . On the other hand, if delivery is good (  X  1), the secondary goal is fully considered and  X  v approaches the maximum possible value (constrained by delivery staying in a neutral region), hence cherry-picking good bid requests to improve the secondary goal.
Note that the bid function f described in the previous subsection is for brand recognition metrics (i.e. viewability and engagement). This approach significantly di  X  ers from the bid function for conventional CPC or CPA optimiza-tion goal types. For these goal types, the advertiser sets the maximum average bid price, b m , as well as the dollar goal value, Goal , which indicates the monetary value each click or action is worth. In such a case, due to the second price nature of RTB exchange auctions, the optimal strategy is to bid as given in Equation 1. We can still use the methodol-ogy given in  X  5.1 to receive more clicks and conversions per ad shown to online users by a campaign. However, modifi-cation of the shape of the bidding function of Equation 1 is suboptimal since it may either reduce the return on invest-ment (ROI) below 100% in the case of bidding higher than optimal, or lead to possible underdelivery (user reach goal is not satisfied) in the case of bidding lower than optimal.
In the case of the viewability or engagement goal types, there is no monetary goal value assigned to a view or an engagement event, and therefore there is no consistent ROI definition. This means that we can utilize di  X  erent shapes of the bidding function due to what the advertiser may prefer to optimize towards -higher delivery or higher performance. The extreme case of the delivery optimization bidding func-tion is the constant bidding function, b = b m , whereas the extreme case of the performance optimization bidding func-tion is a function that is very small in the region of small and intermediate v , and increases only in the region of large probabilities of success, v  X  1.

As we detailed in  X  5.3, based on the current delivery situation (described by the dynamic filtering threshold  X  our bidding function dynamically changes in a range -from a constant bidding strategy, i.e. b = b m , in the case of bad delivery, to the secondary goal optimizing bidding strategy in the case of good delivery. As we will demonstrate in the experiments section, this dynamic bidding approach turns out to give a better combination of delivery and performance compared to static bidding functions that are set towards the optimization of either delivery or performance.
Currently we implemented the above goal optimization algorithm with only first and second priority goals. The expansion to larger than two goals makes sense only if the targeting criteria set by the advertiser for a campaign is loose enough compared to its budget (user reach or delivery goal), therefore enough inventory is available for the campaign to enable optimization of more than two goals. While this is an open problem, we will sketch here an idea which may indeed help with optimizing towards multiple goals while the user reach constraint is achieved.

In the case of more than two optimization goals, we believe that the bidding function should be chosen based on the sec-ond priority goal. If the second priority goal is viewability or engagement, then the bidding function from Equation 8 is used. If the secondary goal is a direct response metric such as CPC or CPA, then the bidding function of Equation 1 is used with dynamic thresholding for click-through rate ,  X  or conversion rate ,  X  a . After the second priority goal is im-proved, i.e. if we have high values of  X  2 , we can utilize Im-pression Need to optimize towards the next priority goals by utilizing  X  i where i&gt; 2. (Here  X  i is the dynamic thresh-old for goal i .) At any time period when Impression Need enters a risky delivery region, the thresholds for the lower priority goals should be reduced first until the comfortable delivery region is reached, obeying the goal priorities set by the advertiser.

Practically, the system should estimate some maximum threshold set,  X   X  i &lt; 1, such that achieving  X  i  X   X   X  considered as satisfaction of the goal i . This allows the sys-tem to progress to the next optimization goal. Indeed, for dual-goal optimization with set  X   X  2 , then  X  2 =  X   X  2 and &lt;&lt; 1 could be the final equilibrium state for well-spending cam-paigns, while without  X   X  2 ,  X  2 will increase until reaching the limit of  X  2  X  1 while being still in comfortable delivery zone (but not &lt;&lt; 1 anymore).
In this section, we will present some preliminary results on real-world campaigns that employ the filtering and bid-ding methodologies listed in  X  5. In Figure 4, we demon-strate the delivery and viewability rate for three models: ( i ) dynamic model, ( ii ) static performance model, and ( iii ) static delivery model. Among these, the dynamic model is the sequential goal optimization scheme described in  X  5, where the primary goal is delivery and secondary goal is the viewability rate. The bidding function of this model is dynamically adjusted based on the current delivery sit-uation (which is approximated by the proxy variable  X  v , viewability rate filtering threshold). The two static models given in the figure are the viewability optimization models that are similar to the dynamic model in all aspects (i.e. they have the same mechanism for the cherry-picking of bid requests with threshold  X  v as the dynamic model) ex-cept that the bidding function is static, hence it does not depend on  X  v (bids do not change with the current de-livery situation, i.e. how well we are on track to satisfy the delivery or user reach constraint). The static perfor-mance model has a bidding function which is optimized for higher performance (we only bid high when the predicted viewability rate is significantly high), while the static de-livery model has a bidding function which is optimized for higher delivery (aims for delivery by bidding higher even for bid requests with low estimated viewability). The bid-ding function of the static performance model can be given as f p ( b m , v )= f ( b m , v ,  X  v = 1) (from  X  5). The bidding function of the static delivery model, f d ( b m , v ), has larger values than f p ( b m , v ) in the region of small and interme-diate v (while still f d ( b m , v =0)= f p ( b m , v =0)=0), but these functions have similar values in the region of large .

The dynamic and the two static models were run for the same campaign and the same daily budget during an 11-day period within 2015 (we replicated all the properties of these campaigns, such as targeting, while only tweaking the bidding strategy). We applied a tight targeting constraint on all the campaigns for the first five days to study the performance of all the listed models in a potentially risky delivery situation. In the last six days, a loose targeting tactic has been applied to the campaigns to see the out-come of the models in a comfortable delivery setting. It can be observed from Figure 4(a) that in the first five days, the delivery of the dynamic model is better than both of the static models  X  . In the tight targeting situation, the dy-namic model fully delivers its daily budget while the static delivery model delivers about 80% of its daily budget, and the static performance model delivers less than 30%. While it seems counter-intuitive to see the dynamic model deliver better than the static delivery model, this behavior is ex-pected due to the utilized bidding functions. The dynamic model bids higher (especially in the region of small v ) than both of the static models in a bad delivery situation. Fig-ure 4(b) shows viewability rate for the three models, where we can observe that the dynamic bidding model performs nearly as good as the static performance model. In sum-mary, it is apparent that the dynamic model spends better than both the static models (and, in particular, much better * Please note that due to the company X  X  privacy policy, we have applied a normalizing factor to all the results presented in this section. The Delivery axis in the graphs represents the monetary amount spent on bid requests by each of the campaigns, which is limited by their daily budget. Figure 4: Delivery and viewability rate of the dy-namic and static models applied to the same cam-paign with the same daily budget for 11 days. For the first 5 days, tight targeting has been applied on the campaign, and for the last 6 days, loose targeting has been applied. than the static performance model) and provides a viewa-bility rate very close to the static performance model in the tight targeting case.

If we examine the results from the last six days when the loose targeting criteria were applied to the campaigns, we can see from Figure 4(a) that all three campaigns performed in a very similar manner. This is a consequence of the fact that, in a comfortable delivery situation, the filtering thresh-old  X  v is high and all three models only bid on bid-requests with large v . Since the bidding functions of all three mod-els behave similarly in the region of large v , the delivery and viewability rates of all three models are similar.
We present the delivery as well as the engagement rates of the dynamic model and the baseline static engagement model (which does not adjust its bid values, but rather only applies filtering through  X  e , i.e. engagement rate filtering threshold) in Figure 5 for a 7-day period within 2015. Again, we replicated the same campaign with the same daily bud-get, where only the bidding functions di  X  er. The primary goal of the dynamic model is delivery, and the secondary goal is the engagement rate. The bidding function of the dy-Figure 5: Delivery and engagement rate of the dy-namic and the static models applied to the same campaign with the same daily budget for 7 days.
 For the first 3 days, tight targeting has been ap-plied on the campaign, and for the last 4 days, loose targeting has been applied. namic model is similar to the bidding function of the static model for intermediate and large values of e (predicted en-gagement rate for a bid request). In the region of small e the bidding functions di  X  er. In particular, similar to the viewability case, the bidding function of the dynamic model is equal to b m in the limit of  X  e = 0 and e = 0, while the bidding function of the static model (which is independent of  X  e ) is equal to 0 in the limit of e =0.

For the engagement model evaluation campaigns, we ap-plied three days of tight targeting, and four days of loose targeting, to see the e  X  ects of both comfortable and risky delivery situations. Since the targeting criteria applied to the identical campaigns were extremely tight during the first three days, both models could not satisfy their daily budget, yet the dynamic model still delivered twice as much advertis-ing budget due to bidding higher on bid-requests with small . During the last four days, when looser targeting crite-ria had been applied to the campaigns, both models spent their daily budget and showed similar engagement rates. We can observe from Figure 5(b) that engagement rates stayed pretty much the same during the whole seven days, includ-ing the tight targeting period. This shows that the engage-ment rate for the user set reached by the campaigns was quite homogeneous, and further demonstrates that even by increasing the bid values and delivering higher amounts of budget, the dynamic model indeed did not hurt performance in terms of engagement rate.
In this paper, we focused on the recently popularized domain of online video advertising. We listed the chal-lenges and peculiarities related to video advertising which are inherently di  X  erent compared to the more traditional banner display advertising approach. We also proposed a multi-objective optimization scheme for online video cam-paigns, which has a compelling theoretical foundation in its problem definition but is also quite challenging to im-plement considering the real-time nature of online advertis-ing. We presented a methodology to approximately perform this joint optimization, and demonstrated via real-world ex-periments that the proposed framework improves delivery and brand recognition metrics, such as viewability and en-gagement rates for video campaigns. To the best of our knowledge, this is the first work to examine the di culties that arise due to the nature of online video advertising and present ways to improve advertiser metrics specific to online video campaigns.

As mentioned in the introduction of our methodology, the first future work we would like to propose is extending the number of prioritized goals as opposed to the dual-objective optimization we focused on in this paper. We have pre-sented an initial idea on this work, but nevertheless, this is an interesting direction to follow. Furthermore, we did not perform a deep-dive into the problem of predicting viewabil-ity or engagement rates of bid requests for video campaigns. It is our belief that the e  X  ective methods to be applied for this purpose could prove to be radically di  X  erent compared to the previous e  X  orts in literature on click and conversion estimation, and would be an exciting subject to pursue. We thank many talented scientists and engineers at Turn for their help and feedback in this work. [1] D. Agarwal, B.-C. Chen, P. Elango, and X. Wang. [2] O. Chapelle. Modeling delayed feedback in display [3] Y. Chen, P. Berkhin, B. Anderson, and N. R.
 [4] D. S. Evans. The online advertising industry: [5] S. C. Geyik, A. Saxena, and A. Dasdan. Multi-touch [6] X. He et al. Practical lessons from predicting clicks on [7] A. Jalali, S. Kolay, P. Foldes, and A. Dasdan. Scalable [8] W. Ji, Y. Chen, M. Chen, B.-W. Chen, Y. Chen, and [9] G. G. Karuga, A. M. Khraban, S. K. Nair, and D. O. [10] K.-C. Lee, A. Jalali, and A. Dasdan. Real time bid [11] K.-C. Lee, B. Orten, A. Dasdan, and W. Li.
 [12] W.-S. Liao, K.-T. Chen, and W. H. Hsu. Adimage: [13] H. B. McMahan et al. Ad click prediction: a view [14] T. Mei, X.-S. Hua, L. Yang, and S. Li. Videosense: [15] C. Perlich, B. Dalessandro, R. Hook, O. Stitelman, [16] K. Salomatin, T.-Y. Liu, and Y. Yang. A unified [17] X. Shao and L. Li. Data-driven multi-touch attribution [18] J. Shen, S. C. Geyik, and A. Dasdan. E  X  ective [19] J. Shen, B. Orten, S. C. Geyik, D. Liu, S. Shariat, [20] S. H. Srinivasan, N. Sawant, and S. Wadhwa. vadeo: [21] R. S. Sutton and A. G. Barto. Reinforcement learning: [22] J. Wang, Y. Fang, and H. Lu. Online video advertising [23] W. C.-H. Wu, M.-Y. Yeh, and M.-S. Chen. Predicting [24] W. Zhang, Y. Zhang, B. Gao, Y. Yu, X. Yuan, and
