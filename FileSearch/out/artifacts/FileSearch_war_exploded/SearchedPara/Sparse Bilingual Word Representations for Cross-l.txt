 Multilingual Natural Language Processing lacks techniques to automatically compare and contrast the meaning of words across languages. Machine translation (Koehn, 2010) lets us discover transla-tion correspondences in bilingual texts, but a word and its translation often do not cover the exact same semantic space: distinct word senses might trans-late differently (Gale et al., 1992; Diab and Resnik, 2002, among others); semantic relations and asso-ciations do not always translate, an important is-sue when constructing multilingual ontologies (Fell-baum and Vossen, 2012); and words in parallel text might be translated non-literally due to lexical gaps (Santos, 1990; Bentivogli and Pianta, 2000) or deci-sions of the translator, as becomes clear when com-paring multiple translations of the same source text (Bhagat and Hovy, 2013).

As a result, correct word translations found in par-allel corpora exhibit a variety of relations including equivalence, hypernymy, and meronymy. For in-stance, even after removing noisy examples (John-son et al., 2007) from a Machine Translation bilex-icon induced from parallel corpora (Koehn et al., 2007), we find that the French word  X  X ppartement X  (apartment) is linked to related but not strictly equiv-alent English words, such as  X  X ome X  or  X  X ondo X .
We aim to design models that capture these differ-ences and similarities in word meaning across lan-guages, beyond translation correspondences. As a first step, we introduce cross-lingual lexical entail-ment , the task of detecting whether the meaning of a word in one language can be inferred from the meaning of a word in another language. In mono-lingual settings, lexical entailment has received sig-nificant attention as a representation-agnostic way of modeling lexical semantics, and as a step to-ward textual inference (Zhitomirsky-Geffet and Da-gan, 2009; Turney and Mohammad, 2015; Levy et al., 2015; Pavlick et al., 2015). We hypothesize that the cross-lingual task can help do the same with mul-tilingual texts.

Building on prior work on the monolingual task, we take an unsupervised approach, and use a direc-tional semantic similarity metric motivated by the distributional inclusion hypothesis (Geffet and Da-gan, 2005a; Kotlerman et al., 2010): we assume a word e entails a word f if the prominent context fea-tures of e are a subset of those of f . However, we face a new challenge in the cross-lingual case: how can we represent and compare word contexts across languages? Our solution leverages recent work on sparse representations for natural language process-ing. We develop sparse bilingual word representa-tions that represent contexts based on interpretable dimensions that are aligned across languages.
As we will see, this approach successfully detects cross-lingual lexical entailment (with an F-score of 70%), and significantly outperforms strong base-lines based (1) on machine translation, and (2) on ex-isting dense bilingual word representations. Along the way, we construct a new dataset to evaluate cross-lingual lexical entailment, and also show the benefits of our approach in the monolingual setting. Zhitomirsky-Geffet and Dagan (2009) formalize lexical entailment as a substitutional relationship. Under their definition, given a word pair ( w,v ), w entails v if the following two conditions are fulfilled 1. The meaning of a possible sense of w implies a 2. w can substitute for v in a sentence, such that
As a result, monolingual lexical entailment in-cludes various semantic relations, such as syn-onymy, hypernymy, some meronymy relations, but also cause-effect relations ( murder entails death ), and other associations ( ocean entails water ) (Kotler-man et al., 2010).

We extend this definition to the cross-lingual case by modifying the second condition. Given a word pair ( w 0 ,v 0 ) , where w 0 is a word in language e and v 0 is a word in language f , w 0 entails v 0 if 1. The meaning of a possible sense of w 0 implies 2. Given a sentence T in f containing v 0 , w 0 can
Cross-lingual lexical entailment helps us refine our understanding of semantic mappings across lan-guages: while the French word ouvrier can be trans-lated as worker in English, knowing that worker does not entail ouvrier could be useful in many mul-tilingual applications, including machine translation and its evaluation, question answering or entity link-ing in multilingual texts.

As can be seen in Table 2, lexical entailment is not always preserved by translation: while aspirin entails the English word drug , it does not entail the French drogue , which only refers to the narcotic sense of drug and not to its medicinal sense.
When evaluating lexical entailment, we use the same approach as in monolingual tasks (Baroni et al., 2012; Baroni and Lenci, 2011; Kotlerman et al., 2010; Turney and Mohammad, 2015): given a bilin-gual word pair, systems are asked to make a binary true/false decision on whether the first word entails the second. We describe the collection of gold stan-dard annotations in Section 5.2. We choose to detect lexical entailment without su-pervision. As in the monolingual case, detection can be done using a scoring function which quantifies the directional semantic similarity of an input word pair. On monolingual tasks, despite reaching better performance, supervised systems do not really learn entailment relations for word pairs, but instead learn when a particular word in the pair is a  X  X rototypi-our investigation to unsupervised models. As a re-sult, our approach only requires a small number of annotated examples to tune the scoring threshold.
We use the balAPinc score (Kotlerman et al., 2009), which is based on the distributional inclusion hypothesis (Geffet and Dagan, 2005b): given feature representations of the contexts of two words u and v , u is assumed to entail v if all features of u tend to appear within the features of v .

Formally, balAPinc is the geometric mean of a symmetric similarity score, LIN (Lin, 1998), and an asymmetric score, APinc . Given a directional entail-ment pair ( u  X  v ), balAPinc ( u  X  v ) = Assume we are given ranked feature lists FV u and FV v for words u and v respectively. Let w u ( f ) de-note the weight of a particular feature f in FV u . LIN is defined by APinc is a modified asymmetric version of the Average Precision metric used in Information Re-trieval:
APinc ( u  X  v ) = where,
P ( r,FV u ,FV v ) rel 0 ( f ) =
Thus, to use balAPinc for cross-lingual lexical en-tailment, we need a ranked list of features that cap-ture information about the context of words in two languages. In the monolingual case, features are di-mensions in a distributional semantic space. For the cross-lingual task, we need to represent words in two languages in the same space, or in spaces where a one-to-one mapping between dimensions exists. As we will see in Section 9, there is a wealth of ex-isting methods for learning representations that cap-ture context of words in two different languages in the literature. However, they have been evaluated on tasks that do not require much semantic analy-sis, such as translation lexicon induction or docu-ment categorization. In contrast, detecting lexical entailment requires the ability to capture more subtle semantic distinctions. This requires bilingual repre-sentations to capture both the full range of word con-texts observed in original language texts, as well as cross-lingual correspondences from translated texts.
We propose a new model that uses sparse non-negative embeddings to represent word contexts as interpretable dimensions, and facilitate context com-parisons across languages. This is an instance of sparse coding, which consists of modeling data vec-tors as sparse linear combinations of basis elements. In contrast with dimensionality reduction techniques such as PCA, the learned basis vectors need not be orthogonal, which gives more flexibility to represent the data (Mairal et al., 2009). These models have been introduced as word representations in monolin-gual settings (Murphy et al., 2012) with the goal of obtaining interpretable, cognitively-plausible repre-sentations. We review the monolingual models, be-fore introducing our novel bilingual formulation. 4.1 Review: Learning Monolingual Sparse Previous work (Murphy et al., 2012; Faruqui et al., 2015) on obtaining sparse monolingual representa-tions is based on a variant of the Nonnegative Matrix Factorization problem. Given a matrix X contain-ing v dense word representations arranged row-wise, sparse representations for the v words can be ob-tained by solving the following optimization prob-lem
The first term in the objective 3 aims to factor-ize the dense representation matrix X into two ma-trices, A and D such that the l 2 reconstruction er-ror is minimized. The second term is an l 1 regu-larizer on A which encourages sparsity, where the level of sparsity is controlled by the  X  hyperparame-ter. This, together with the non-negativity constraint, helps in obtaining sparsified and interpretable repre-sentations in A since non-negativity has been shown to correlate with interpretability. Note that the ob-jective function on its own is degenerate since it can be trivially optimized by making the entries of D arbitrarily large and choosing corresponding small values as entries of A . To avoid this, an additional constraint is imposed on D . 4.2 Proposed Bilingual Model Learning bilingual word representations for entail-ment requires two sources of information:  X  Monolingual distributional representations in- X  Cross-lingual correspondences that enable
We formulate the following optimization problem to obtain sparse bilingual representations: argmin subject to A e &gt; 0 ; D e i T . D e i  X  1 , 1  X  i  X  v e
The first two rows and the constraints in Equation 4 can be understood as in Equation 3 -they encour-age sparsity in word representations for each lan-guage. The third row imposes bilingual correspon-dence constraints, weighted by the regularizer  X  x : it encourages words in e and f that are strongly aligned according to S to have similar representations. 4.3 Optimization Equations 3 and 4 define non-differentiable, non-convex optimization problems and finding the glob-ally optimally solution is not feasible. However, var-ious methods used to solve convex problems work well in practice. We use Forward Backward Split-ting , a proximal gradient method for which an effi-cient generic solver, FASTA, is available (Goldstein et al., 2015; Goldstein et al., 2014). FASTA (Fast Adaptive Shrinkage / Thresholding Algorithm) is designed to minimize functions of the form f ( Ax )+ g ( x ) , where f is a differentiable function, g is a function (possibly non-differentiable) for which we can calculate the proximal operator, and A is a lin-ear operator. For the objective function in our model, the l 1 terms form g and the l 2 terms form f .
We have now described all components of the model required to detect bilingual lexical entail-ment: solving objective 4 as described yields sparse representations for words in the two languages that can be compared directly using the balAPinc metric. 5.1 Existing Monolingual Test Suites A comprehensive suite of lexical entailment test beds is available for English (Levy et al., 2015). They were constructed either by asking humans to annotate entailment relations directly (Kotlerman et al., 2010), or by deriving entailment labels from semantic relation annotations (Baroni et al., 2012; Baroni and Lenci, 2011; Turney and Mohammad, 2015). Each test set has 900 to 1300 positive exam-ples of lexical entailment -word pairs ( w,v ) such that w  X  v . All but one are balanced. 5.2 Creating a Cross-Lingual Test Set We select French as the second language: it is a good starting point for studying cross-lingual entailment, as it is a resource-rich language with many available bilingual annotators. We will construct data sets for more distant language pairs in future work.

We aim to construct a balanced test set of posi-tive and negative bilingual entailment examples in the spirit of the existing English test beds. While it is attractive to leverage existing English examples, we cannot translate them directly as entailment rela-tions might be affected by translation ambiguity (as illustrated in Table 2).

We therefore obtain annotated bilingual examples using a two step process: (1) automatic translation of monolingual examples, and (2) manual annotation through crowdsourcing. For a sample of positive ex-amples of entailment w e  X  v e in the monolingual datasets, we generate up to two French translations for v e , v f 1 and v f 2 , using the top translations from BabelNet (Navigli and Ponzetto, 2012) and Google Translate. v f 1 and v f 2 are then paired back with w e , thus generating two unannotated crosslingual exam-ples. Annotation is crowdsourced on Crowdflower 2 : for each example pair ( w e ,v f ) , workers are asked to label it as true ( w e  X  v f ) or false ( w e 6 X  v f ). We select the positive examples annotated with high-agreement, and obtain the same number of negative examples by applying the same translation process 5.3 Crowdsourcing Cross-lingual Entailment Detecting lexical entailment for bilingual word pairs is a non-trivial annotation task, and requires a good command of both French and English. For quality control, we first ask a bilingual speaker in our group to conduct a pilot annotation task, which we use to evaluate workers X  ability to perform the task. In ad-dition, Crowdflower allows us to present this task to only workers who have a proven knowledge of French, and to georestrict the task to countries most likely to have French-English bilinguals.

N Examples 0 ( animal , couleur ), ( animal , reptile ), 1 ( asp , vert  X  ebr  X  e ), ( chancellor , guide ), 2 ( bookmark , marque ), ( postman , ouvrier ), 3 ( cricket , insecte ), ( muse , divinit  X  e ), 4 ( ape , animal ), ( reimbursement , paiement ), 5 ( epistle , lettre) , ( gin , boisson ),
This approach yielded a large number of high-quality annotations quickly. 1680 cross-lingual pairs were presented to five annotators each. 24 pairs did not receive enough judgments. For the remaining 1656 pairs, four or more annotators agreed for 75% of examples (Figure 1).

This result first shows that we can indeed gener-ate a gold standard for the challenging task of cross-lingual lexical entailment using such crowdsourcing techniques. We ensure high-quality annotations by selecting all 945 ( w,v ) where four or more annota-tors agree that w  X  v .

In addition, the degree of agreement sheds light on how the notion of lexical entailment is inter-preted by non-expert annotators. In Table 3, we present randomly selected examples for each agree-ment level. The bottom two rows represent clear positive examples, that are cross-lingual equivalents of hypernymy or synonymy relations: e.g., gin is a kind of drink ( boisson in French). The top row rep-resent clear negative examples, where the two words are unrelated (e.g., art and serpent , which means snake in English) or the directionality is wrong (e.g., animal  X  reptile ). The middle rows where one to three annotators chose to annotate the word pair as negative contain less clear-cut cases, including as-sociation relations (e.g., endurance  X  force ), and examples where entailment judgments requires tak-ing into account more subtle word sense or transla-tion distinctions (e.g., bookmark can be translated as marque for a positive example, but the most frequent sense of marque translates into English as brand , for which the entailment relation does not hold.) We estimate the following models for evaluation on the test sets described in the previous section. 6.1 Sparse Bilingual Model Estimating sparse, bilingual representations as de-scribed in Section 4.2 first requires learning dense monolingual representations in two languages ( X e and X f ). We can in principle use any type of dense representations. We choose to train GloVe (Penning-ton et al., 2014) vectors on a corpus comprised of Gi-gaword and Wikipedia to learn dense representations of 2000 dimensions for English and French. English vectors are trained on a corpus of 4.9B words, while French vectors are trained on 1.2B words.

Second, we construct S by word-aligning large amounts of parallel corpora using a fast implemen-tation of IBM model 2 (Dyer et al., 2013). We com-72M English tokens and 78M French tokens. All corpora are tokenized and lowercased.

We learn 100-dimensional sparse representations with hyperparameters  X  e =  X  f = 0 . 5 , X  x = 10 . 6.2 Contrastive Models We also learn two other sets of 100-dimensional word representations, as a basis for comparison.
First, we learn sparse monolingual English word representations, which will be used in monolingual lexical entailment experiments (Section 7.1). These are trained using the non-negative sparse method de-scribed in Section 4.1, on the same 4.9B word En-glish corpus that was used for learning bilingual rep-resentations.

Second, we learn dense bilingual word repre-sentations using BiCVM (Hermann and Blunsom, 2014), to use as a baseline for our cross-lingual lex-ical entailment experiments (Section 7.2). BiCVM uses sentence aligned parallel corpora to learn rep-resentations for words in two languages, with the objective that when these representations are com-posed into representations for parallel sentences, the Euclidean distance between the parallel sentences should be minimized. We learn English-French vec-tors on the parallel corpora described in Section 6.1. 7.1 Monolingual Tasks We first evaluate the monolingual version of our sparse model on English test sets. While our fo-cus is on the cross-lingual setting, the monolingual evaluation lets us compare a version of our newly proposed approach with existing lexical entailment results (Levy et al., 2015), obtained using dense word representations compared with cosine similar-ity. This is not a controlled comparison, as train-ing conditions are not comparable. Nevertheless it is reassuring to see that sparse word representations are roughly on par with previously published results. This suggests that they indeed provide good features for discovering entailment relations, using both co-sine and balAPinc as metrics 6 .

Results (Table 4) show that sparse representa-tions lead to performance comparable to previous approaches, thus providing a strong motivation for using the same for the crosslingual task. 7.2 Cross-lingual Task
Word Representations Cosine balAPinc We evaluate our proposed approach on the new English-French lexical entailment test set. We eval-uate the impact of choosing a sparse representa-tion by comparing our approach to the dense bilin-gual word representations obtained with the BiCVM model (Section 6.2). We also evaluate the usefulness of bilingual vs. monolingual word representations: given a bilingual example ( w e ,v f ) , we translate v f into English using Google Translate, and then detect lexical entailment using English sparse representa-tions for the English pair ( w e ,v e ) as described in Section 6.2.
Results are summarized in Table 5. First, we ob-serve that balAPinc outperforms cosine for all word representations, confirming that the directional met-ric is better suited to discovering lexical entailment. Second, all sparse models significantly outperform the model based on dense representation, which sug-gests that sparsity helps discover useful context fea-tures. Finally, our proposed approach ( balAPinc with features from sparse bilingual representations) yields the best result overall, perofrming better than the second best model (cosine with features from sparse bilingual representations) by approximately 1.6 points. This difference is highly statistically sig-nificant (at p &lt; 0 . 01 ) according to the McNemar X  X  Test (Dietterich, 1998). Our model also outper-forms translation followed by monolingual entail-ment, confirming the need for models that directly compare the meaning of words across languages, in-stead of using translation as a proxy. 8.1 Examining bilingual dimensions learned One motivation for using sparse representations is that they yield interpretable dimensions: one can summarize a dimension using the top scoring words in its column. Interpreting five randomly selected dimensions learned in our bilingual model (Table 6) shows that we indeed learn English and French di-mensions that align well, but that are not identical -reflecting the difference in contexts observed in monolingual English vs. French corpora, as needed to detect lexical entailment. 8.2 Sparse Vectors Help Capture One advantage of our sparse representations over dense bilingual representations is that they can bet-ter leverage an asymmetric scoring function like balAPinc . Consider the following two pairs from our dataset -(mesothelioma,tumeur) and (tu-mor,m  X  esoth  X  eliome) . The former is a positive exam-ple since mesothelioma  X  tumeur , but the latter is negative (since not all tumors are mesotheliomas.)
Cosine similarity is unable to differentiate be-tween these two cases, assigning a high score to both these pairs, causing both of them to be labeled posi-tive. However, balAPinc with sparse representations teases them apart by giving a high score to the first pair and a low score to the second.

In the bilingual sparse model, mesothelioma and m  X  esoth  X  eliome have only one non-zero entry ( in the dimension corresponding to [ X  X irus X ,  X  X iruses X ,  X  X n-fection X ,  X  X ells X ,  X  X ancer X  X ) whereas tumeur and tu-mor have five non-zero entries in their representa-tions. Based on the distributional inclusion hypothe-sis, this difference in the number of non-zero entries is a strong basis for mesothelioma  X  tumor . 8.3 Benefits of Bilingual Modeling Examining the results of the approach based on translation followed by monolingual entailment con-firms the problems raised by sense ambiguities.
Consider the English word drug , which can be translated into the French drogue when used in the narcotics sense, and m  X  edicament when used in the medicinal sense. Thus the pair (antibiotic,drogue) that is correctly labeled as negative in the cross-lingual case, gets converted to (antibiotic,drug) by translation and is then incorrectly labeled as posi-tive. Similarly, the pair ( coriander, herbe ), which is positive in the crosslingual case, gets translated to ( coriander, grass ) because the French herbe is primarily aligned to the English grass (rather than herb ). The translated pair is labeled negative. Bilingual Word Representations Much re-cent work targets the problem of learning low-dimensional multilingual word representations, using matrix decomposition techniques such as Principal Component Analysis and Canonical Correlation Analysis (Gaussier et al., 2004; Jagarla-mudi and Daum  X  e III, 2012; Gardner et al., 2015), Latent Dirichlet Allocation (Mimno et al., 2009; Jagarlamudi and Daum  X  e III, 2010), and neural distributional representations (Klementiev et al., 2012; Gouws et al., 2015; Lu et al., 2015, among others). However, these models have typically been evaluated on translation induction or document cat-egorization, which, unlike lexical entailment, focus on capturing coarse cross-lingual correspondences. Sparse Word Representations While cooccur-rence matrices and their PPMI transformed variants are early examples of sparse representations, recent work has leveraged Nonnegative Sparse Embedding (NNSE) (Murphy et al., 2012). These models have been augmented to incorporate different types of lin-guistically motivated constraints, such as composi-tionality of words into phrases (Fyshe et al., 2015), or a hierarchical regularizer that captures knowledge of word relations (Yogatama et al., 2015).

Sparse representations have also been used for monolingual lexical entailment in the Boolean Dis-tributional Semantic Model (Kruszewski et al., 2015), which shares our hypothesis on the useful-ness of sparsity in meaning representations. How-ever, they are meant to be used in different settings: while the boolean features can interestingly capture formal semantics, they are not as useful in our unsu-pervised setting, since they do not provide the fea-ture rankings required to use the balAPinc metric. Cross-Lingual Semantic Analysis To the best of our knowledge, lexical entailment has not been pre-viously addressed in a cross-lingual setting. The long tradition of lexical semantic analysis in cross-lingual settings has mostly focused on using trans-lations to characterize word meaning (Diab and Resnik, 2002; Carpuat and Wu, 2007; Lefever and Hoste, 2010; McCarthy et al., 2013, among oth-ers). An exception is Cross-lingual Textual Entail-ment (Mehdad et al., 2010), which aims to detect whether an English hypothesis H entails a text T written in another language. We plan to use our lex-ical models to address this task in the future. In this work, we introduced the task of cross-lingual lexical entailment, which aims to detect whether the meaning of a word in one language can be inferred from the meaning of a word in another language. We constructed a dataset with gold annotations through crowdsourcing, and presented a top-performing so-lution based on novel sparse bilingual word repre-sentations that leverages both word co-occurrence patterns in monolingual corpora and bilingual cor-
A key limitation of this work is that we address lexical entailment out of context, based on word rep-resentations that collapse multiple word senses into a single vector . These could be addressed in fu-ture work by adapting existing methods for learn-ing sense-specific representations for dense vectors (Jauhar et al., 2015; Ettinger et al., 2016; Reisinger and Mooney, 2010; Guo et al., 2014; Huang et al., 2012; Neelakantan et al., 2015) to our sparse rep-resentations, and target cross-lingual textual entail-ment tasks, which focus on full sentences rather than isolated words. We also plan to study lexical entail-ment on more languages and example types, as well as investigate the usefulness of our bilingual repre-sentations in higher level multilingual applications such as machine translation.
 The authors would like to thank Tom Goldstein, Roberto Navigli and Peter Turney for their assis-tance with tools and datasets, Philip Resnik and the CLIP lab at the University of Maryland for stimulat-ing discussions, and the reviewers for their insight-ful feedback. This work was partially funded by an Amazon Academic Research Award.

