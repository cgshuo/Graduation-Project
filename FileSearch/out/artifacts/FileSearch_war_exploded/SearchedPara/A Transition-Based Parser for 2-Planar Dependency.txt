 Dependency-based syntactic parsing has become a widely used technique in natural language pro-cessing, and many different parsing models have been proposed in recent years (Yamada and Mat-sumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Titov and Henderson, 2007; Martins et al., 2009). One of the unresolved issues in this area is the proper treatment of non-projective depen-dency trees, which seem to be required for an ad-equate representation of predicate-argument struc-ture, but which undermine the efficiency of depen-dency parsing (Neuhaus and Br  X  oker, 1997; Buch-Kromann, 2006; McDonald and Satta, 2007).

Caught between the Scylla of linguistically in-adequate projective trees and the Charybdis of computationally intractable non-projective trees, some researchers have sought a middle ground by exploring classes of mildly non-projective depen-dency structures that strike a better balance be-tween expressivity and complexity (Nivre, 2006; Kuhlmann and Nivre, 2006; Kuhlmann and M  X  ohl, 2007; Havelka, 2007). Although these proposals seem to have a very good fit with linguistic data, in the sense that they often cover 99% or more of the structures found in existing treebanks, the de-velopment of efficient parsing algorithms for these classes has met with more limited success. For example, while both Kuhlmann and Satta (2009) and G  X  omez-Rodr  X   X guez et al. (2009) have shown how well-nested dependency trees with bounded gap degree can be parsed in polynomial time, the best time complexity for lexicalized parsing of this class remains a prohibitive O ( n 7 ) , which makes the practical usefulness questionable.

In this paper, we explore another characteri-zation of mildly non-projective dependency trees based on the notion of multiplanarity. This was originally proposed by Yli-Jyr  X  a (2003) but has so far played a marginal role in the dependency pars-ing literature, because no algorithm was known for determining whether an arbitrary tree was m -planar, and no parsing algorithm existed for any constant value of m . The contribution of this pa-per is twofold. First, we present a procedure for determining the minimal number m such that a dependency tree is m -planar and use it to show that the overwhelming majority of sentences in de-pendency treebanks have a tree that is at most 2-planar. Secondly, we present a transition-based parsing algorithm for 2-planar dependency trees, developed in two steps. We begin by showing how the stack-based algorithm of Nivre (2003) can be generalized from projective to planar structures. We then extend the system by adding a second stack and show that the resulting system captures exactly the set of 2-planar structures. Although the contributions of this paper are mainly theoretical, we also present an empirical evaluation of the 2-planar parser, showing that it outperforms the pro-jective parser on four data sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). 2.1 Dependency Graphs Let w = w 1 . . . w n be an input string. 1 An inter-val (with endpoints i and j ) of the string w is a set of the form [ i, j ] = { w k | i  X  k  X  j } . Definition 1. A dependency graph for w is a di-rected graph G = ( V w , E ) , where V w = [1 , n ] and E  X  V w  X  V w .
 We call an edge ( w i , w j ) in a dependency graph G a dependency link 2 from w i to w j . We say that w i is the parent (or head ) of w j and, conversely, that w j is a syntactic child (or dependent ) of w i . For convenience, we write w i  X  w j  X  E if the link ( w i , w j ) exists; w i  X  w j  X  E if there is a link from w i to w j or from w j to w i ; w i  X   X  w j  X  E if there is a (possibly empty) directed path from w i to w j ; and w i  X   X  w j  X  E if there is a (possibly empty) path between w i and w j in the undirected graph underlying G (omitting reference to E when clear from the context). The projection of a node w , denoted b w i c , is the set of reflexive-transitive dependents of w i : b w i c = { w j  X  V | w i  X   X  w j } .
Most dependency representations do not allow arbitrary dependency graphs but typically require graphs to be acyclic and have at most one head per node. Such a graph is called a dependency forest . Definition 2. A dependency graph G for a string w 1 . . . w n is said to be a forest iff it satisfies: 1. Acyclicity: If w i  X   X  w j , then not w j  X  w i . 2. Single-head: If w j  X  w i , then not w k  X  w i Nodes in a forest that do not have a head are called roots . Some frameworks require that dependency forests have a unique root (i.e., are connected). Such a forest is called a dependency tree . 2.2 Projectivity For reasons of computational efficiency, many de-pendency parsers are restricted to work with pro-jective dependency structures, that is, forests in which the projection of each node corresponds to a contiguous substring of the input: Definition 3. A dependency forest G for a string w 1 . . . w n is projective iff b w i c is an interval for every word w i  X  [1 , n ] .
 Projective dependency trees correspond to the set of structures that can be induced from lexicalised context-free derivations (Kuhlmann, 2007; Gaif-man, 1965). Like context-free grammars, projec-tive dependency trees are not sufficient to repre-sent all the linguistic phenomena observed in natu-ral languages, but they have the advantage of being efficiently parsable: their parsing problem can be solved in cubic time with chart parsing techniques (Eisner, 1996; G  X  omez-Rodr  X   X guez et al., 2008), while in the case of general non-projective depen-dency forests, it is only tractable under strong in-dependence assumptions (McDonald et al., 2005b; McDonald and Satta, 2007). 2.3 Planarity The concept of planarity (Sleator and Temperley, 1993) is closely related to projectivity 3 and can be informally defined as the property of a dependency forest whose links can be drawn above the words without crossing. 4 To define planarity more for-mally, we first define crossing links as follows: let ( w i , w k ) and ( w j , w l ) be dependency links in a dependency graph G . Without loss of general-ity, we assume that min ( i, k )  X  min ( j, l ) . Then, the links are said to be crossing if min ( i, k ) &lt; min ( j, l ) &lt; max ( i, k ) &lt; max ( j, l ) . Definition 4. A dependency graph is planar iff it does not contain a pair of crossing links. 2.4 Multiplanarity The concept of planarity on its own does not seem to be very relevant as an extension of projectiv-ity for practical dependency parsing. According to the results by Kuhlmann and Nivre (2006), most non-projective structures in dependency treebanks are also non-planar, so being able to parse planar structures will only give us a modest improvement in coverage with respect to a projective parser. However, our interest in planarity is motivated by the fact that it can be generalised to multipla-narity (Yli-Jyr  X  a, 2003): Figure 1: A 2-planar dependency structure with two different ways of distributing its links into two planes (represented by solid and dotted lines). Definition 5. A dependency graph G = ( V, E ) is m-planar iff there exist planar dependency graphs G 1 = ( V, E 1 ) , . . . , G m = ( V, E m ) (called planes ) such that E = E 1  X  X  X  X  X  E m .
 Intuitively, we can associate planes with colours and say that a dependency graph G is m -planar if it is possible to assign one of m colours to each of its links in such a way that links with the same colour do not cross. Note that there may be multiple ways of dividing an m -planar graph into planes, as shown in the example of Figure 1. Several constraints on non-projective dependency structures have been proposed recently that seek a good balance between parsing efficiency and cov-erage of non-projective phenomena present in nat-ural language treebanks. For example, Kuhlmann and Nivre (2006) and Havelka (2007) have shown that the vast majority of structures present in exist-ing treebanks are well-nested and have a small gap degree (Bodirsky et al., 2005), leading to an inter-est in parsers for these kinds of structures (G  X  omez-Rodr  X   X guez et al., 2009). No similar analysis has been performed for m -planar structures, although Yli-Jyr  X  a (2003) provides evidence that all except two structures in the Danish dependency treebank are at most 3-planar. However, his analysis is based on constraints that restrict the possible ways of assigning planes to dependency links, and he is not guaranteed to find the minimal number m for which a given structure is m -planar.

In this section, we provide a procedure for find-ing the minimal number m such that a dependency graph is m -planar and use it to show that the vast majority of sentences in dependency treebanks are Figure 2: The crossings graph corresponding to the dependency structure of Figure 1. at most 2-planar, with a coverage comparable to that of well-nestedness. The idea is to reduce the problem of determining whether a dependency graph G = ( V, E ) is m -planar, for a given value of m , to a standard graph colouring problem. Con-sider first the following undirected graph: U ( G ) = ( E, C ) where C = {{ e i , e j }| e i , e j are crossing links in G } This graph, which we call the crossings graph of G , has one node corresponding to each link in the dependency graph G , with an undirected link be-tween two nodes if they correspond to crossing links in G . Figure 2 shows the crossings graph of the 2-planar structure in Figure 1.

As noted in Section 2.4, a dependency graph G is m -planar if each of its links can be assigned one of m colours in such a way that links with the same colours do not cross. In terms of the cross-ings graph, this means that G is m -planar if each of the nodes of U ( G ) can be assigned one of m colours such that no two neighbours have the same colour. This amounts to solving the well-known k -colouring problem for U ( G ) , where k = m .
For k = 1 the problem is trivial: a graph is 1 -colourable only if it has no edges. For k = 2 , the problem can be solved in time linear in the size of the graph by simple breadth-first search. Given a graph U = ( V, E ) , we pick an arbitrary node v and give it one of two colours. This forces us to give the other colour to all its neighbours, the first colour to the neighbours X  neighbours, and so on. This process continues until we have processed all the nodes in the connected component of v . If this has resulted in assigning two different colours to the same node, the graph is not 2 -colourable. Oth-erwise, we have obtained a 2 -colouring of the con-nected component of U that contains v . If there are still unprocessed nodes, we repeat the process by arbitrarily selecting one of them, continue with the rest of the connected components, and in this way obtain a 2 -colouring of the whole graph if it exists. Since this process can be completed by vis-iting each node and edge of the graph U once, its complexity is O ( V + E ) . The crossings graph of a dependency graph with n nodes can trivially be built in time O ( n 2 ) by checking each pair of de-pendency links to determine if they cross, and can-not contain more than n 2 edges, which means that we can check if the dependency graph for a sen-tence of length n is 2-planar in O ( n 2 ) time.
For k &gt; 2 , the k -colouring problem is known to be NP-complete (Karp, 1972). However, we have found this not to be a problem when measur-ing multiplanarity in natural language treebanks, since the effective problem size can be reduced by noting that each connected component of the crossings graph can be treated separately, and that nodes that are not part of a cycle need not be considered. 5 Given that non-projective sentences in natural language tend to have a small propor-tion of non-projective links (Nivre and Nilsson, 2005), the connected components of their cross-ings graphs are very small, and k -colourings for them can quickly be found by brute-force search.
By applying these techniques to dependency treebanks of several languages, we obtain the data shown in Table 1. As we can see, the coverage provided by the 2-planarity constraint is compa-rable to that of well-nestedness. In most of the treebanks, well over 99% of the sentences are 2-planar, and 3-planarity has almost total coverage. As we will see below, the class of 2-planar depen-dency structures not only has good coverage of lin-guistic phenomena in existing treebanks but is also efficiently parsable with transition-based parsing methods, making it a practically interesting sub-class of non-projective dependency structures. In this section, we present a deterministic linear-time parser for planar dependency structures. The parser is a variant of Nivre X  X  arc-eager projec-tive parser (Nivre, 2003), modified so that it can also handle graphs that are planar but not projec-tive. As seen in Table 1, this only gives a modest improvement in coverage compared to projective parsing, so the main interest of this algorithm lies in the fact that it can be generalised to deal with 2-planar structures, as shown in the next section. 4.1 Transition Systems In the transition-based framework of Nivre (2008), a deterministic dependency parser is defined by a non-deterministic transition system , specifying a set of elementary operations that can be executed during the parsing process, and an oracle that de-terministically selects a single transition at each choice point of the parsing process.
 Definition 6. A transition system for dependency parsing is a quadruple S = ( C, T, c s , C t ) where 1. C is a set of possible parser configurations , 2. T is a set of transitions , each of which is a 3. c s is a function that maps each input sentence 4. C t  X  C is a set of terminal configurations . Definition 7. An oracle for a transition system S = ( C, T, c s , C t ) is a function o : C  X  T . An input sentence w can be parsed using a tran-sition system S = ( C, T, c s , C t ) and an oracle o by starting in the initial configuration c s ( w ) , call-ing the oracle function on the current configuration c , and updating the configuration by applying the transition o ( c ) returned by the oracle. This pro-cess is repeated until a terminal configuration is Initial configuration: c s ( w 1 . . . w n ) =  X  [] , [ w 1 . . . w n ] ,  X  X  Terminal configurations: C f = { X   X  , [] , A  X  X  X  C } Transitions: S HIFT  X   X  , w i | B, A  X  X  X  X   X  | w , B, A  X  reached, and the dependency analysis of the sen-tence is defined by the terminal configuration.
Each sequence of configurations that the parser can traverse from an initial configuration to a ter-minal configuration for some input w is called a transition sequence . If we associate each config-uration c of a transition system S = ( C, T, c s , C t ) with a dependency graph g ( c ) , we can say that S is sound for a class of dependency graphs G if, for every sentence w and transition sequence ( c is complete for G if, for every sentence w and de-pendency graph G  X  G for w , there is a transition sequence ( c s ( w ) , c 1 , . . . , c f ) such that g ( c A transition system that is sound and complete for G is said to be correct for G .

Note that, apart from a correct transition system, a practical parser needs a good oracle to achieve the desired results, since a transition system only specifies how to reach all the possible dependency graphs that could be associated to a sentence, but not how to select the correct one. Oracles for prac-tical parsers can be obtained by training classifiers on treebank data (Nivre et al., 2004). 4.2 A Transition System for Planar A correct transition system for the class of planar dependency forests can be obtained as a variant of the arc-eager projective system by Nivre (2003). As in that system, the set of configurations of the planar transition system is the set of all triples c =  X   X  , B, A  X  such that  X  and B are disjoint lists of words from V w (for some input w ), and A is a set of dependency links over V w . The list B , called the buffer , is initialised to the input string and is used to hold the words that are still to be read from the input. The list  X  , called the stack , is initially empty and holds words that have dependency links pending to be created. The system is shown in Fig-ure 3, where we use the notation  X  | w i for a stack with top w i and tail  X  , and we invert the notation for the buffer for clarity (i.e., w i | B is a buffer with top w i and tail B ).

The system reads the input from left to right and creates links in a left-to-right order by executing its four transitions: 1. S HIFT : pops the first (leftmost) word in the 2. L EFT -ARC : adds a link from the first word in 3. R IGHT -ARC : adds a link from the top of the 4. R EDUCE : pops the top word from the stack, Note that the planar parser X  X  transitions are more fine-grained than those of the arc-eager projective parser by Nivre (2003), which pops the stack as part of its L EFT -A RC transition and shifts a word as part of its R IGHT -A RC transition. Forcing these actions after creating dependency links rules out structures whose root is covered by a dependency link, which are planar but not projective. In order to support these structures, we therefore simplify the A RC transitions (L EFT -ARC and R IGHT -ARC ) so that they only create an arc. For the same rea-son, we remove the constraint in Nivre X  X  parser by which words without a head cannot be reduced. This has the side effect of making the parser able to output cyclic graphs. Since we are interested in planar dependency forests , which do not con-tain cycles, we only apply A RC transitions after checking that there is no undirected path between the nodes to be linked. This check can be done without affecting the linear-time complexity of the parser by storing the weakly connected component of each node in g ( c ) .

The fine-grained transitions used by this parser have also been used by Sagae and Tsujii (2008) to parse DAGs. However, the latter parser differs from ours in the constraints, since it does not allow the reduction of words without a head (disallowing forests with covered roots) and does not enforce the acyclicity constraint (which is guaranteed by post-processing the graphs to break cycles). 4.3 Correctness and Complexity For reasons of space, we can only give a sketch of the correctness proof. We wish to prove that the planar transition system is sound and com-plete for the set F p of all planar dependency forests. To prove soundness, we have to show that, for every sentence w and transition sequence ( c with c f is in F p . We take the graph associated with a configuration c = ( X  , B, A ) to be g ( c ) = ( V w , A ) . With this, we prove the stronger claim that g ( c )  X  F p for every configuration c that be-longs to some transition sequence starting with c ( w ) . This amounts to showing that in every con-figuration c reachable from c s ( w ) , g ( c ) meets the following three conditions that characterise a pla-nar dependency forest: (1) g ( c ) does not contain nodes with more than one head; (2) g ( c ) is acyclic; and (3) g ( c ) contains no crossing links. (1) is triv-ially guaranteed by the single-head constraint; (2) follows from (1) and the acyclicity constraint; and (3) can be established by proving that there is no transition sequence that will invoke two A RC tran-sitions on node pairs that would create crossing links. At the point when a link from w i to w j is created, we know that all the words strictly located between w i and w j are not in the stack or in the buffer, so no links can be created to or from them.
To prove completeness, we show that every planar dependency forest G = ( V, E )  X  F p for a sentence w can be produced by apply-ing the oracle function that maps a configuration  X   X  | w i , w j | B, A  X  to: We show completeness by setting the following in-variants on transitions traversed by the application of the oracle: 2. [ w i  X  w j  X  A  X  We can show that each branch of the oracle func-tion keeps these invariants true. When we reach a terminal configuration (which always happens af-ter a finite number of transitions, since every tran-sition generating a configuration c =  X   X  , B, A  X  decreases the value of the variant function | E | + |  X  | + 2 | B | X  X  A | ), it can be deduced from the in-variant that A = E , which proves completeness.
The worst-case complexity of a deterministic transition-based parser is given by an upper bound on transition sequence length (Nivre, 2008). For the planar system, like its projective counterpart, the length is clearly O ( n ) (where n is the number of input words), since there can be no more than n S HIFT transitions, n R EDUCE transitions, and n A
RC transitions in a transition sequence. The planar parser introduced in the previous sec-tion can be extended to parse all 2-planar depen-dency structures by adding a second stack to the system and making R EDUCE and A RC transitions apply to only one of the stacks at a time. This means that the set of links created in the context of each individual stack will be planar, but pairs of links created in different stacks are allowed to cross. In this way, the parser will build a 2-planar dependency forest by using each of the stacks to construct one of its two planes.

The 2-planar transition system, shown in Figure 4, has configurations of the form  X   X  0 ,  X  1 , B, A  X  , where we call  X  0 the active stack and  X  1 the in-active stack , and the following transitions: 1. S HIFT : pops the first (leftmost) word in the 2. L EFT -ARC : adds a link from the first word in 3. R IGHT -ARC : adds a link from the top of the 4. R EDUCE : pops the top word from the active 5. S WITCH : makes the active stack inactive and Initial configuration: c s ( w 1 . . . w n ) =  X  [] , [] , [ w Terminal configurations: C f = { X   X  0 ,  X  1 , [] , A  X  X  X  C } Transitions: S HIFT  X   X  0 ,  X  1 , w i | B, A  X  X  X  X   X  0 | w i ,  X  0 , B, A  X  5.1 Correctness and Complexity As in the planar case, we provide a brief sketch of the proof that the transition system in Figure 4 is correct for the set F 2 p of 2-planar dependency forests. Soundness follows from a reasoning anal-ogous to the planar case, but applying the proof of planarity separately to each stack. In this way, we prove that the sets of dependency links cre-ated by linking to or from the top of each of the two stacks are always planar graphs, and thus their union (which is the dependency graph stored in A ) is 2-planar. This, together with the single-head and acyclicity constraints, guarantees that the depen-dency graphs associated with reachable configura-tions are always 2-planar dependency forests.
For completeness, we assume an extended form of the transition system where transitions take the form  X   X  0 ,  X  1 , B, A, p  X  , where p is a flag taking values in { 0 , 1 } which equals 0 for initial config-urations and gets flipped by each application of a S
WITCH transition. Then we show that every 2-planar dependency forest G  X  F 2 p , with planes G 0 = ( V, E 0 ) and G 1 = ( V, E 1 ) , can be produced by this system by applying the oracle function that maps a configuration  X   X  0 | w i ,  X  1 , w j | B, A, p  X  to: This can be shown by employing invariants analo-gous to the planar case, with the difference that the third invariant applies to each stack and its corre-sponding plane: if  X  y is associated with the plane E x , 6 we have: Since the presence of the flag p in configurations does not affect the set of dependency graphs gen-erated by the system, the completeness of the sys-tem extended with the flag p implies that of the system in Figure 4.

We can show that the complexity of the 2-planar system is O ( n ) by the same kind of reasoning as for the 1-planar system, with the added complica-tion that we must constrain the system to prevent two adjacent S WITCH transitions. In fact, without this restriction, the parser is not even guaranteed to terminate. 5.2 Implementation In practical settings, oracles for transition-based parsers can be approximated by classifiers trained on treebank data (Nivre, 2008). To do this, we need an oracle that will generate transition se-quences for gold-standard dependency graphs. In the case of the planar parser of Section 4.2, the or-acle of 4.3 is suitable for this purpose. However, in the case of the 2-planar parser, the oracle used for the completeness proof in Section 5.1 cannot be used directly, since it requires the gold-standard trees to be divided into two planes in order to gen-erate a transition sequence.

Of course, it is possible to use the algorithm presented in Section 3 to obtain a division of sen-tences into planes. However, for training purposes and to obtain a robust behaviour if non-2-planar sentences are found, it is more convenient that the oracle can distribute dependency links into the planes incrementally, and that it produces a dis-tribution of links that only uses S WITCH transi-tions when it is strictly needed to account for non-planarity. Thus we use a more complex version of the oracle which performs a search in the crossings graph to check if a dependency link can be built on the plane of the active stack, and only performs a switch when this is not possible. This has proved to work well in practice, as will be observed in the results in the next section. In order to get a first estimate of the empirical ac-curacy that can be obtained with transition-based 2-planar parsing, we have evaluated the parser on four data sets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Czech, Danish, Ger-man and Portuguese. As our baseline, we take the strictly projective arc-eager transition system proposed by Nivre (2003), as implemented in the freely available MaltParser system (Nivre et al., 2006a), with and without the pseudo-projective parsing technique for recovering non-projective dependencies (Nivre and Nilsson, 2005). For the two baseline systems, we use the parameter set-tings used by Nivre et al. (2006b) in the original shared task, where the pseudo-projective version of MaltParser was one of the two top performing systems (Buchholz and Marsi, 2006). For our 2-planar parser, we use the same kernelized SVM classifiers as MaltParser, using the LIBSVM pack-age (Chang and Lin, 2001), with feature models that are similar to MaltParser but extended with features defined over the second stack. 7
In Table 2, we report labeled (LAS) and un-labeled (UAS) attachment score on the four lan-guages for all three systems. For the two systems that are capable of recovering non-projective de-pendencies, we also report precision (NPP) and recall (NPR) specifically on non-projective depen-dency arcs. The results show that the 2-planar parser outperforms the strictly projective variant of MaltParser on all metrics for all languages, and that it performs on a par with the pseudo-projective variant with respect to both overall at-tachment score and precision and recall on non-projective dependencies. These results look very promising in view of the fact that very little effort has been spent on optimizing the training oracle and feature model for the 2-planar parser so far.
It is worth mentioning that the 2-planar parser has two advantages over the pseudo-projective parser. The first is simplicity, given that it is based on a single transition system and makes a single pass over the input, whereas the pseudo-projective parsing technique involves preprocessing of train-ing data and post-processing of parser output (Nivre and Nilsson, 2005). The second is the fact that it parses a well-defined class of dependency structures, with known coverage 8 , whereas no for-mal characterization exists of the class of struc-tures parsable by the pseudo-projective parser. In this paper, we have presented an efficient algo-rithm for deciding whether a dependency graph is 2-planar and a transition-based parsing algorithm that is provably correct for 2-planar dependency forests, neither of which existed in the literature before. In addition, we have presented empirical results showing that the class of 2-planar depen-dency forests includes the overwhelming majority of structures found in existing treebanks and that a deterministic classifier-based implementation of the 2-planar parser gives state-of-the-art accuracy on four different languages. The first author has been partially supported by Ministerio de Educaci  X  on y Ciencia and FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, Rede Galega de Proce-samento da Linguaxe e Recuperaci  X  on de Infor-maci  X  on, Rede Galega de Ling  X  u  X   X stica de Corpus, Bolsas Estad  X   X as INCITE/FSE cofinanced).

