 The problem of finding commonalities characterizes several Knowledge Management scenarios involving collection of re-sources. The automatic extraction of shared features in a collection of resource descriptions formalized in accordance with a logic language has been in fact widely investigated in the past. In particular, with reference to Description Logics concept descriptions, Least Common Subsumers have been specifically introduced.

Nevertheless, such studies focused on identifying features shared by the whole collection. The paper proposes in-stead novel reasoning services in Description Logics, aimed at identifying commonalities in a significant portion of the collection, rather than in the collection as a whole.
In particular, common subsumers adding informative con-tent to the one provided by the Least Common Subsumer are here investigated.

The new services are useful in all scenarios where features are not required to be fully shared, like the one motivat-ing our research: Core Competence extraction in knowledge intensive companies.
 I.2.4 [ Knowledge Representation Formalisms and Meth-ods ]: Representation Languages; H.3.3 [ Information Search and Retrieval ]: Clustering Algorithms, Management Description Logics, Non-standard Inferences, Informative Com-mon Subsumers
Every scenario characterized by the presence of a collec-tion of resources faces the problem of finding common fea-tures in the collection, regardless of the nature of involved resources. If collected elements are described according to a formal language conveying semantics, the process of identi-fying such commonalities can be automatically performed. In particular, Description Logics [1] offer inference services specifically aimed at identifying concept collection common-alities. Least Common Subsumers(LCS) have in fact been defined [9]  X  originally for the DL underlying Classic [8] X  with the specific purpose of determining the most specific concept description subsuming all of the elements of a given collection.

Usefulness of LCSs has been shown in several different ap-plication fields. As an example, in the bottom-up construc-tion of knowledge bases [3], the knowledge engineer may de-fine several typical objects of the domain, which are then generalized through the computation of their LCS. Such an approach overcomes the drawbacks of classical top-down techniques, in which the general concept descriptions are defined first.

Inductive learning algorithms also employ LCS computa-tion to find a least general concept consistent with a set of positive example, used as basis for learning [10].
The measure of concept similarity in specific information retrieval [20] represents one more application of LCS.
Noteworthy, all above introduced application scenarios share the need of individuating features which are common to all of the elements in a given collection.

In other applications, instead, the issue is determining commonalities of a significant portion of the collection rather than of the collection as a whole. The problem reverts then to finding a concept subsuming a significant number, or per-centage, of elements in the collection. In an organizational scenario, for example, a crucial strategical issue consists in determining the know-how specializing the company. Such a knowledge takes the name  X  X ore Competence X  X 15] in knowl-edge management literature and represents the fields of ex-cellence for a company, e.g. , the competence to invest on in long term strategy. If employee profiles and organization knowledge are formalized in a collection of concept descrip-tions, the management could extract company Core Compe-tence by searching for features shared by a significant num-ber of employees. The degree of significance may be chosen by the management on the basis of organizational needs.
In order to perform such extraction process in a Knowl-edge Representation framework, we need to define concepts which are LCS of k elements in a collection of n descriptions, with k &lt; n . We give the name k -Common Subsumers to such concepts.
 As the LCS of the whole collection is by definition a k -Common Subsumer for every 1 &lt; k &lt; n , we define distin-guished Informative k -Common Subsumers , to denote k -Common Subsumers adding informative content to the LCS. k -Common Subsumers equivalent to the LCS would not justify in fact the introduction of a reasoning service other than the LCS.

Imagine now that the management of a company in the organizational scenario introduced before needs to extract the features common to the biggest number of employees in the company: we define to this aim Best Common Sub-sumers , which are concepts subsuming a number k of el-ements in the collection, where k is the biggest number of subsumed concepts.

If the collection admits an LCS not equivalent to the uni-versal concept, the Best Common Subsumer is obviously the LCS itself. In this case we therefore define the Best Infor-mative Common Subsumers , which are concepts sub-suming the biggest number of elements in the collection less than the cardinality n .
 The rest of this paper is organized as follows: in the next Section we briefly introduce the DL formalism we adopt; then we outline our motivational case study and its formal-ization in DLs. In Section 4 we detail all reasoning services needed for the commonalities extraction process. Solving algorithms are provided in Section 5 w.r.t. different DLs, to-gether with some computational complexity results. A case study illustrating introduced services in the organizational context is presented in Section 6, before closing the paper with conclusions.
We start recalling here basics of the formalism we adopt, based on Description Logics (DLs). DLs are a family of for-malisms and reasoning services widely employed for knowl-edge representation in a decidable fragment of First Order Logic.

The alphabet of each DL is therefore made up by unary and binary predicates, denoted as Concepts Names and Role Names , respectively. The domain of interest is rep-resented through more expressive and complex Concept Descriptions , involving constructors over concept and role names. The set of constructors allowed by a DL character-izes it in terms of expressiveness and reasoning complexity: of course the more a DL is expressive, the harder is inferring new knowledge on its descriptions.

Concept Definitions allow to assign an unique concept name to complex concept descriptions: the so called Unique Name Assumption (UNA) holds in every DL. Names as-sociated to concept descriptions constitute the set of Defined Concepts , distinguished by Primitive Concepts not appear-ing on the left hand side of any concept definition and cor-responding to the concept names. Defined and primitive concepts constitute the set of concept names, which will be referred to by the letter A in the following; C and D will denote instead arbitrary concept descriptions.

Concept Inclusions detail instead specificity hierarchies among concepts, either defined or primitives.

Role Inclusions are also aimed at detailing specificity hierarchies, but among roles.

The set of concepts inclusions and definitions represents the formal representation of the domain of interest, the in-tensional knowledge which takes the name TBox in DL sys-tems and Ontology in the generic knowledge representation framework. TBoxes containing recursive concept definitions are called cyclic ( acyclic otherwise).

The semantic of concept descriptions is conveyed through an Interpretation I = ( X  I ,  X  I ) , where  X  I is a non empty set denoting the domain of I and  X  I is an interpretation function such that:
Possible DL constructors and the related semantics are shown in Table 1, which also shows the constructors allowed by the DLs investigated in this paper.

The behavior of the interpretation function in presence of definitions and inclusions is detailed in Table 2 and can be inductively explained by taking the semantics of allowed constructors into account. Table 2 also shows assertions allowed by all DLs investigated in the paper.

An interpretation I is a model for a TBox T if it satisfies the whole set of assertions in T .

The motivating scenario we here propose needs at least the expressiveness of ELHN sublanguage of DLs for re-sources representation. The full expressiveness of ELHN is explained, with the aid of constructors usage examples, in Table 3.

Ontologies using DL can be easily modeled using lan-guages for the Semantic Web [13, 19, 23]. These languages have been conceived to allow for representation of machine understandable, unambiguous, description of web content through the creation of domain ontologies, and aim at in-creasing openness and interoperability in the web environ-ment. The strong relations between DLs and the above in-troduced languages for the Semantic Web [2] is also evident in the definition of the three OWL sub-languages:
OWL-Lite : allows class hierarchy and simple constraints
OWL-DL : is based on Description Logics theoretical stud-
OWL-Full : using such a language, there is a huge syntac-
The investigations on the problem of finding informative commonalities in concept collections originate from a real need we faced in the implementation of IMPAKT, a novel and optimized semantic-based knowledge management sys-tem, which will be released late this year. IMPAKT is specifically aimed at semantic-based human resources man-agement [11] and provides Core Competence extraction as decisional support service. IMPAKT ensures the scalability
I  X  y  X  C I } x x x
I  X  y  X  C I } x  X  r . &gt; x x | ( x, y )  X  r I } X  n } x x x | ( x, y )  X  r I } X  m } x x x
I x x x x
I x x x x of proposed knowledge management approaches by means of a smart pre-classification of semantic-based information.
In [15] the notion of Core Competence was introduced to indicate the strategic knowledge of a company. A core com-petence is defined as a sort of capability providing customer benefits, hard to be imitated from competitors and possess-ing leverage potential.

Further definitions of Core Competence have been pro-posed in the literature in the attempt of finding methods for detecting such a specializing knowledge [18, 22].
The process of individuating Core Competence is in fact usually characterized by high complexity and low objectivity because of the intangibility of knowledge itself and difficul-ties inherent in formalizing them.

The automation of Core Competence extraction process asks in fact for company know-how to be described according to a language endowed with formal semantics.

Hereafter we use Description Logics for knowledge rep-resentation and, for the sake of simplicity, assume that the only source of company know-how is company personnel. As a result, a company which needs to automatically extract its Core Competence has to formalize the knowledge profiles of employees according to the vocabulary provided by a TBox describing skill management domain.

An excerpt of the inclusions and the assertions composing the TBox at the basis of our case study is given in Figure 1 and Figure 2, respectively.
 Operations Management w SoftwareEngineering w Programming w InformationSystems w OperatingSystems w AssetAllocation w HumanResourcesManagement basicKnowledge w advancedKnowledge
The extraction process is grounded on the reasonable as-sumption that Core Competence, although characterizing a company, has not necessarily to be held by the whole person-nel, but at least by a significant portion of it. A competence shared by all of the employees could be in fact too generic, if the objective is, for example, identifying skills to invest on in long term strategy.

Consider the tiny organizational scenario in which the fol-lowing employees are employed:
Manager  X  AssetManager  X 
Engineer  X  X  X  advancedKnowledge . ( Design u ManagerialEngineer  X  CSEngineer  X  The four profiles are formalized according to the given TBox as shown in Table 4. It is noteworthy that the em-ployees competence descriptions need the full expressiveness of ELHN to convey all the embedded semantics. We there-fore in the following refer to such a DL for modeling our case study.

It is easy to observe that the only characteristic shared by the four employees of our tiny case study is  X  X n advanced knowledge about programming X . Such feature might obvi-ously be too generic to be considered for Core Competence identification. The management of a company needs instead to take into account features shared by significant subsets of the collection made up by the employees; the minimum required number of employees may be set by the manage-ment on the basis of a organizational needs. As an example, if the management accept that three employees have to hold some knowledge to consider it part of Core Competence, we can state that the company has advanced knowledge about object oriented programming as Core Competence. Such a result is more significant than the first one w.r.t. to the objective of determining the fields of excellence of the com-pany.

Of course, the more the extracted knowledge is specific and unknown to the management, the more the automated process we propose is useful for achieving competitive ad-vantage.

Observe that, even though the services proposed in this paper have been specifically devised for solving Core Com-petence extraction needs, they are helpful in all frameworks in which a partial sharing of features in a collection of re-sources is required. Imagine for example the scenario of a medical research laboratory investigating new diseases. If patient health records are formalized in DL w.r.t. an ontol-ogy describing health care domain, the symptoms of patients sharing the final diagnosis may be investigated to find com-mon features. Also in such a scenario a partial coverage of patients collections might be a crucial information for de-tecting symptoms commonly associated to a disease, which could be therefore helpful in diagnosis process.
In the following we start recalling standard services we use in our approach and then proceed to introduce proposed ones. The most important  X  X nd well-known X  service char-acterizing reasoning in DL checks for specificity hierarchies, by determining whether a concept description is more spe-cific than another one or, formally, if there is a subsumption relation between them.

Definition 1 (Subsumption). Given two concept de-scriptions C and D and a TBox T in a DL L , we say that D subsumes C w.r.t. T if for every model of T , C I  X  D I We write C v T D , or simply C v D if we assume an empty TBox.

For example, consider the following concept descriptions, referred to a competence and an employee profile, respec-tively: Knowledge expressed by P 1 is more specific than the one required by T 1 : according to the previous definition C 1 sumes P 1 .

Based on subsumption new reasoning services may be de-fined in DLs. In particular, all of the following services are aimed at finding commonalities in collections of concepts formalized in a generic DL L .

We recall Least Common Subsumer definition by Cohen and Hirsh [10], before introducing new services based on it.
Definition 2 (LCS, [10]). Let C 1 , . . . , C n be n con-cept descriptions in a DL L . An LCS of C 1 , . . . , C n by LCS ( C 1 , . . . , C n ) , is a concept description E in L such that the following conditions hold: (i) C i v E for i = 1 , . . . , n (ii) E is the least L -concept description satisfying (i), i.e. ,
It is well known that, if the DL L admits conjunction of concepts  X  u  X , then the LCS is unique up to concept equiv-alence (since if both E 1 and E 2 are common subsumers of C , . . . , C n , then so is E 1 u E 2 ). Moreover, if union of con-cepts  X  t  X  is allowed in L , then for every set of concepts C , . . . , C n  X  L , their LCS is C 1 t  X  X  X  t C n . Hence, the study of LCS is limited to DLs not admitting union.
In order to deal with partial commonalities, we define now common subsumers of k concepts in a collection of n ele-ments.

Definition 3 (k-CS). Let C 1 , . . . , C n be n concepts in a DL L , and let be k &lt; n . A k -Common Subsumer ( k -CS) of C 1 , . . . , C n is a concept D 6 = &gt; such that D is an LCS of k concepts among C 1 , . . . , C n .

By definition, LCSs are also k -CSs, for every k &lt; n . For this reason we define a particular subset of k -CSs, adding informative content to the LCS computation.

Definition 4 (IkCS). Let C 1 , . . . , C n be n concepts in a DL L , and let k &lt; n . An Informative k -Common Sub-sumer (IkCS) of C 1 , . . . , C n is a k -CS E such that E is strictly subsumed by LCS ( C 1 , . . . , C n ) .

In the following we define concepts subsuming the maxi-mum number of elements in a collection:
Definition 5 (BCS). Let C 1 , . . . , C n be n concepts in a DL L . A Best Common Subsumer (BCS) of C 1 , . . . , C n is a concept S such that S is a k -CS for C 1 , . . . , C every k &lt; j  X  n every j -CS  X &gt; .

The Least Common Subsumer, when not equivalent to the universal concept, is of course the best common subsumer a collection may have: it subsumes the whole collection. As a consequence, the computation of BCSs for collections admitting LCSs not equivalent to &gt; is meaningless. For such collections, we alternatively propose the following service:
Definition 6 (BICS). Let C 1 , . . . , C n be n concepts in a DL L . A Best Informative Common Subsumer (BICS) of C , . . . , C n is a concept B such that B is an Informative k -CS for C 1 , . . . , C n , and for every k &lt; j  X  n every j -CS is not informative.

Proposition 1. If LCS ( C 1 , . . . , C n )  X  &gt; , every BCS is also a BICS.

Even though the services defined above may appear quite similar to each other at a first sight, it has to be underlined that they deal with different problems [12]:
In the following we show how to find commonalities in concept collections formalized in DL in accordance with out-lined services, while determining some complexity results for such services.

In the computation of common subsumers of a collection of concept descriptions C 1 , . . . , C n we assume that all con-cepts C i in the collection are consistent; hence C i 6 X   X  for every C i  X  ( C 1 , . . . , C n ) .

The reasoning services introduced in Section 4 ask for the concepts of the input collection to be written in components according to the following recursive definition:
Definition 7 (Concept Components). Let C be a concept description in a DL L , with C written in a con-junction C 1 u X  X  X u C m . The Concept Components of C are defined as follows: 1. if C j , with j = 1 . . . , m is either a concept name, or 2. if C j =  X  R . D , with j = 1 . . . , m , then  X  R . &gt; is a 3. if C j =  X  R . E , with j = 1 . . . , m , then  X  R . E Observe that we do not propagate universal restriction over existential restriction since existential restriction always sim-plify to a component of the form  X  R . &gt; .

For the computation of the sets of k -CSs, IkCSs, BICSs and BCSs of a collection of concepts we define in the fol-lowing a Subsumers Matrix , for the representation of the collection itself.

Definition 8 (Subsumers Matrix). Let C 1 , . . . , C n be a collection of concept descriptions C i in a Description Logic L and let D j  X  X  D 1 , . . . , D m } be the Concept Compo-nents deriving from all concepts in the collection. We define the Subsumers Matrix S = ( s ij ) , with i = 1 . . . n and j = 1 . . . m , such that s ij = 1 if the component D j subsumes C , and s ij = 0 if the component D j does not subsume C i . Definition 9. Referring to the Subsumers Matrix of C , . . . , C n , we define: Concept Component Signature ( sig D j ) : set of indices Concept Component Cardinality ( T D j ) : cardinality Maximum Concept Component Cardinality ( M S ): Second Maximum Concept Component Cardinality Common Signature Class( Definition 8 hints that the computation of Subsumers Matrix includes an oracle to subsumption. As a consequence the following proposition holds:
Proposition 2. Let L be a DL whose subsumption prob-lem is decidable in polynomial time. Then Subsumers Matrix in L is computable in polynomial time too.

Such a result causes the computation of common sub-sumers in DLs with different complexities for subsumption to be treated separately. We therefore concentrate on the DL needed for modeling our case study, ELHN , in Section 5.1 and provide results for different DLs in Section 5.2.
Nevertheless some considerations are logic independent and preliminary to the determination of common subsumers in every DL.

Firstly, we define the solution sets for the introduced rea-soning services, regardless of the DL employed for the rep-resentation of concepts in a given collection: C 1 x x x C 2 x x C . . . x C n x x x Figure 3: Subsumers Matrix of a collection admit-ting LCS 6 = &gt; BCS : set of BCSs of the collection BICS : set of BICSs of the collection ICS k : set of IkCSs of the collection, given k &lt; n CS k : set of k-CSs of the collection, given k &lt; n
Proposition 3. Given a DL L and a collection of con-cept descriptions in L , for each k &lt; n the solution sets of the collection are such that I k  X  L k . If the collection admits only the universal concept as LCS, then B = BI also holds.
Proposition 4. The following observations on the Sub-sumers matrix represent necessary conditions to determine common subsumers of the collection: 1. Only concept components D j for which T D j  X  k are 2. Only concept components subsuming k concepts but not 3. Only concept components D j for which T D j = PM S 4. Only concept components D j for which T D j = M S , The representation (for k = 2 ) in Figure 3 and 4 shows the introduced necessary conditions and should clarify the differences among introduced services. In particular, notice that in case of a collection admitting LCS 6 = &gt; ( Figure 3), the best common subsumer of the collection is the LCS itself, so only the computation of BICSs makes sense. On the contrary, for a collection admitting only LCS  X  &gt; (Figure 4), BCSs may be computed and are BICSs too.
The commonalities extraction process in the DL we em-ploy to model our case study, relies on computation results for LCS computation. Baader et al. [4] showed that, even for the small DL EL , the shortest representation of the LCS of n concepts has exponential size in the worst case, and this result holds also when a TBox is used to shorten possible repetitions [7]. Such a result affects the computation of the introduced solution sets of common subsumers, as stated in the following theorem.
 C 1 x x x C 2 x x C . . .

C n x x Figure 4: Subsumers Matrix of a collection whose LCS  X &gt; Theorem 1. The computation of the solution sets BCS , BICS , CS k , ICS k for a collection of concept descriptions in ELHN may be reduced to the problem of computing the LCS of the subsets of the collection.

Proof. For computing CS k it is sufficient to compute for every subset { i 1 , . . . , i k } X  X  1 , . . . , n } the concept LCS ( C i 1 , . . . , C i k ) .
 The same holds for ICS k , excluding those LCS ( C 1 , . . . , C which are equivalent to LCS ( C 1 , . . . , C n ) . For the compu-tation of the sets BCS and BICS , instead, we provide an algorithm that uses the one proposed by Kusters and Moli-tor [17] for LCS computation. The algorithm takes as in-put the collection C 1 , . . . , C n represented through its Sub-sumers Matrix. Consider now the Concept Components of the elements C i in the collection: the reduction in Step 2 of Definition 7 causes not all the components to be straightly included in the solution sets BCS and BICS . For example, consider the concept description C 1 = AssetManager u  X  basicKnowledge . Psychology : the resulting concept component is D 1 =  X  basicKnowledge . &gt; and D 2 =  X  advancedKnowledge . &gt; (taking also into account the TBox definitions in Figure 2 ). Even though such com-ponent is selected for the determination of the solution sets according to Proposition 4, it just individuates the concepts in the collection to consider for the determination of BCS and BICS . For each component D j we denote LCS D j the LCS of the C i such that s ij = 1 .

Input : Subsumers Matrix S = ( s ij ) for a collection of
Output : BICS ; BCS if M S = n then else return BCS , BICS ;
Algorithm 1 : An algorithm for Common Subsumers enu-meration in ELHN
Algorithm 1 requires the computation of the LCS of l concepts  X  with l  X  n  X  in lines 3, 6. Similarly to the approach used in [5] we limit the size on the input collection from n to l , and we compute the LCS of the l concepts as shown in [17]. The problem of determining the solution sets of a collection may be then reduced to the computation of the LCS of subsets of the collection itself.
The choice of proposing an algorithm finding informative commonalities in ELHN is due to modeling needs in our case study. We therefore generalize our approach by investigating the computational complexity of introduced services in two different DLs, namely ALN and ALE .

The computational complexity for ALN is lower than the one for ELHN , given that ALN lacks of existential restric-tions, which is the source of exponentiality [7]. In particular, in knowledge domains which can be modeled in ALN the introduced common subsumers can be computed by straight-forwardly applying conditions in Proposition 4, as stated in the following theorem.
 Theorem 2. For a collection of concept descriptions in ALN the necessary conditions for solution sets determina-tion exposed in Proposition 4 are also sufficient. Proof. Let the Common Signature Class concept component D j satisfy one of the necessary condi-tions in Proposition 4 and let LCS D j be the LCS of the k concepts subsumed by D j . If subsumer and not the least one, LCS D j &lt; LCS D j must be equivalent to concept. This means that F subsumes each concept C i sub-sumed by D j hence, according to Definition 7, F must be one of the concept components conjoined in computation of BCS , BICS , CS k and ICS k elements.
When a TBox is present X  X ven a simple one, made of axioms A . = C where A is a name X  X ebel proved that sub-sumption is Pspace -hard even for the simple DL FL 0 [21] Hence, in the following complexity analysis we decouple the contribution of the subsumption tests in the subsumers ma-trix computation from the computation of different intro-duced common subsumers.

The complexity of solution sets computation is object of the following theorem.

Theorem 3. Let C 1 , . . . , C n , T be n concepts and a sim-ple Tbox in ALN , let m be the sum of the sizes of C 1 , . . . , C and let S ( s ) be a monotone function bounding the cost of de-ciding C v T D in ALN , whose argument s is | C | + | D | + |T| . The computation of the solution sets BCS , BICS , CS k , ICS k for a collection of concept descriptions in ALN is then a problem in O ( m 2 + ( S ( m )) 2 ) .
 Proof. We propose an algorithm determining the sets BICS , CS k , ICS k , BCS of a collection { C 1 , . . . , C concepts in ALN , whose Subsumers Matrix is given as in-put. Hence the computation of the Subsumers Matrix can be carried over in polynomial time (see Proposition 2).
However, Nebel himself claims that exponentiality raises from the nesting of the definitions (a concept that defines another that defines another etc.) and that for  X  X ushy but not deep X  TBoxes exponentiality does not arise. A precise characterization of what  X  X ushy but not deep X  means has been given by Di Noia et al. [14].

According to Theorem 2 the determination of the output sets asks then only for the enumeration of Common Sig-nature Classes of the components D j chosen according to conditions in Proposition 4.
 The algorithm for Common Subsumers enumeration in ALN is shown in the following:
Input : Collection Subsumers Matrix S = ( s ij ) for a Output : CS k ; ICS k ; BICS ; BCS
CS k :=  X  ; ICS k :=  X  ; BICS :=  X  ; BCS :=  X  ; foreach D j s.t. T D j  X  k do if M S = n then else foreach D j s.t. T D j = M S do return CS k , BCS , ICS k , BICS ;
Algorithm 2 : An algorithm for Common Subsumers enu-meration in ALN It is straightforward to verify that the algorithm runs in O ( m 2 ) . Given that subsumers matrix can be computed in O ( m 2 + ( S ( m )) 2 ) , the claim follows.

For the computation of BICS and BCS in ALE , we can use Algorithm 1. For computing CS k it is again suf-the concept LCS ( C i 1 , . . . , C i k ) . The same holds for ICS excluding those LCS ( C 1 , . . . , C k ) which are equivalent to LCS ( C 1 , . . . , C n ) . A method for computing the hierarchy of all such LCSs (but for the DL ALC , so without number re-strictions and role inclusions) has been proposed by Baader and Sertkaya[6]. Once such a hierarchy is computed, it is easy to find IkCSs, BICSs, and BCSs. However, we observe that for DLs in Table 1, some theoretical results on LCS are still missing. Since the output of an algorithm computing an LCS in DLs including EL is exponential in the worst case [7], we refer to the usual model of computation of Turing Machines with three tapes: one for input (read-only), one for working memory, and one for output (write-only) [16]. In such a model, space complexity refers to the working memory tape. In this setting we observe that the algorithm proposed by Baader and Turhan [7] for LCS in ALE works in polynomial space, while the algorithm proposed by Kusters and Molitor [17] works in exponential space, since it relies on a normalization step for input concepts, and it is still unclear if such a normalization step can be avoided.
In order to better clarify the proposed services we apply the commonalities extraction process detailed in Section 5 to our tiny example scenario proposed in Section 3.
The input collection therefore is made up by the four pro-files in Table 4. Let 50 % be the required level of competence coverage set by company management to individuate Core Competence. We are hence interested in determining com-petence shared by at least two employees out of the four in the company. Figure 5: Example Collection Subsumers Matrix
In order to compute the set CS 2 , it is sufficient to compute the LCS of all subsets of cardinality 2: LCS ( Antonio, Claudio ) = LCS ( Antonio, Roberto ) =  X  advancedKnowledge . OOP LCS ( Antonio, Daniele ) = LCS ( Claudio, Roberto ) =  X  advancedKnowledge . OOP LCS ( Claudio, Daniele ) =
LCS ( Roberto, Daniele ) = All elements in CS 2 have to be investigated w.r.t. the LCS of the collection to identify Informative 2-Common Subsumers. We need then to compute such a concept: LCS = LCS ( Antonio, Claudio, Roberto, Daniele ) =  X  advancedKnowledge . Programming Each element in CS 2 is more specific than LCS and then belongs also to ICS 2 .

We use instead Algorithm 1 for computing the sets BCS and BICS . The algorithm requires the concept collection Subsumers Matrix as input; so we have to compute it first. The concept components coming from the collection are computed according to Definition 7 and take into account TBox definitions in Figure 2. As a result we have the three concept components as in the following:
The collection subsumers matrix is shown in Figure 5 and is characterized by the following values: M S = 4 , PM S = 3 . By applying Algorithm 1 we have that BCS :=  X  (line 2) and we need to compute, according to line 3, LCS D 1 and LCS D It is straightforward to notice that LCS D 1  X  LCS D 3 , so the only BICS for the collection is: LCS ( Antonio, Claudio, Daniele ) = Engineer u X  advancedKnowledge . ( Programming u (  X  2 hasExperienceYears )) u  X  basicKnowledge . InformationSystems The solution sets coming from the commonalities extraction process are detailed below: BCS =  X 
BICS = CS 2 = ICS 2 = CS 2
Thanks to the commonalities extraction process proposed here, the company in our tiny case study discovered some new information about the fields of excellence characterizing its know-how. In particular, by computing the LCS of the collection of employee profiles, the company management may discover that the whole personnel knows Programming at an advanced level, which is quite a generic sort of infor-mation, probably well known by the company.

More significant and unknown commonalities may be found by computing the set of IkCSs: i) knowledge embedded in Engineer job title together with an advanced knowledge in Java, related to two years of working experience, and a basic knowledge in Information Systems and software engineer-ing; ii) advanced knowledge about object oriented program-ming; iii) advanced knowledge about script languages. Such commonalities are therefore informative w.r.t. the objective of determining unknown fields of excellence in the company.
Moreover the company may discover, thanks to the com-putation of BICSs, that knowledge shared by the maximum number of employees in the company (excluding Program-ming which is shared by all employees) is an advanced knowl-edge of programming related to 2 years of experience, to-gether with the knowledge embedded in Engineer job title and a basic knowledge in Information Systems.

In large knowledge intensive companies, like multinational ones, the proposed approach may hence help to detect hid-den fields of excellence of a company, especially if out of its core business, thus representing a potential source of com-petitive advantage. Motivated by the need to identify and extract so called Core Competence in knowledge intensive companies, and by the limits of LCS in such a framework, we have introduced and exploited informative common subsumers in Description Logics, useful in application fields where there is the need to extract significant informative commonalities in concept collections, and such commonalities are not shared by the entire collection. We have proposed definitions, algorithms to compute such informative common subsumers for various DLs and presented simple complexity results.

Obviously our approach requires competencies  X  X r in gen-eral concept collections X  be modeled in accordance with an ontology, but as semantic-based languages and technologies gain momentum it is reasonable to assume that more and more companies will move towards a logic-based formaliza-tion of their skills and processes and be able to take advan-tage of proposed and other relevant non-standard services. We thank Franz Baader and Sergei O. Kuznetsov for helpful discussions. This work has been supported in part by EU-FP6-IST-26896 project and Apulia Region funded projects PE 013 Innovative models for customer profiling and PS 092 DIPIS . [1] F. Baader, D. Calvanese, D. Mc Guinness, D. Nardi, [2] F. Baader, I. Horrocks, and U. Sattler. Description [3] F. Baader and R. K  X  usters. Computing the least [4] F. Baader, R. K  X  usters, and R. Molitor. Computing [5] F. Baader and R. Molitor. Building and structuring [6] F. Baader and B. Sertkaya. Applying formal concept [7] F. Baader and A.-Y. Turhan. On the problem of [8] A. Borgida, R. Brachman, D. L. McGuinness, and [9] W. Cohen, A. Borgida, and H. Hirsh. Computing least [10] W. Cohen and H. Hirsh. Learning the CLASSIC [11] S. Colucci, T. Di Noia, E. Di Sciascio, F. Donini, and [12] S. Colucci, E. Di Sciascio, and F. Donini. Partial and [13] DAML+OIL. DAML+OIL Specifications. [14] T. Di Noia, E. Di Sciascio, and F. Donini. Semantic [15] G. Hamel and C. K. Prahalad. The core competence [16] D. S. Johnson. A catalog of complexity classes. In [17] R. K  X  usters and R. Molitor. Structural Subsumption [18] C. C. Markides and P. J. Williamson. Related [19] D. McGuinness, R. Fikes, J. Hendler, and L. Stein. [20] R. M  X  oller, V. Haarslev, and B. Neumann.
 [21] B. Nebel. Reasoning and Revision in Hybrid [22] R. R. Nelson. Why do firms differ, and how does it [23] OWL. www.w3.org/TR/owl-features/, 2004.
