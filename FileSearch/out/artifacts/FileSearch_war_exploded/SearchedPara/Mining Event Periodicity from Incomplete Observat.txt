 Advanced technology in GPS and sensors enables us to track physical events, such as human movements and facility us-age. Periodicity analysis from the recorded data is an im-portant data mining task which provides useful insights into the physical events and enables us to report outliers and pre-dict future behaviors. To mine periodicity in an event, we have to face real-world challenges of inherently complicated periodic behaviors and imperfect data collection problem. Specifically, the hidden temporal periodic behaviors could be oscillating and noisy, and the observations of the event could be incomplete.

In this paper, we propose a novel probabilistic measure for periodicity and design a practical method to detect peri-ods. Our method has thoroughly considered the uncertain-ties and noises in periodic behaviors and is provably robust to incomplete observations. Comprehensive experiments on both synthetic and real datasets demonstrate the effective-ness of our method.
 H.2.8 [ Data Management ]: Database Applications -Data Mining; H.4.0 [ Information Systems ]: General Algorithms Periodicity, incomplete observations
Periodicity is one of the most common phenomena in the physical world. Animals often have yearly migration pat-terns; students usually have weekly schedules for classes; and the usage of bedroom, toilet, and kitchen could have daily periodicity, just to name a few. Nowadays, with the rapid development of GPS and mobile technologies, it be-comes much easier to monitor such events. For example, cellphones enable us to track human activities [4], GPS de-vices attached to animals help the scientists to study the animal movement patterns [7], and sensors allow us to mon-itor the usage of rooms and facilities [14].

Data collected from such tracking and sensor devices pro-vides a valuable resource for ecological study, environmental protection, urban planning and emergency response. An ob-servation of an event defined in this paper is a boolean value, that is, whether an event happens or not. An important as-pect of analyzing such data is to detect true periods hidden in the observations.

Unfortunately, period detection for an event is a challeng-ing problem, due to the limitations of data collection meth-ods and inherent complexity of periodic behaviors .
To illustrate the difficulties, let us first take a look at Fig-ure 1. Suppose we have observed the occurrences of an event at timestamps 5, 18, 26, 29, 48, 50, 67, and 79. The obser-vations of the event at other timestamps are not available. It is certainly not an easy task to infer the period directly from these incomplete observations. In fact, the issue with incomplete observations is a common problem on data col-lected from GPS and sensors. For example, a bird can only carry small sensors with one or two reported locations in three to five days. And the locations of a person may only be recorded when he uses his cellphone. Moreover, if a sen-sor is not functioning or a tracking facility is turned off, it could result in a large portion of missing data. Therefore, we usually have incomplete observations ,which are unevenly sampled and have large portion of missing data . Traditional periodicity analysis methods, such as Fourier transform and auto-correlation [11, 15, 1, 7], usually require the data to be evenly sampled , that is, there is an observation at every timestamp. Even though some extensions of Fourier trans-form have been proposed to handle uneven data samples [9, 12], they are still not applicable to the case with very low sampling rate.

Second, the periodic behaviors could be inherently com-plicated and noisy . A periodic event does not necessarily happen at exactly the same timestamp in each periodic cy-cle. For example, the time that a person goes to work in the morning might oscillate between 8:00 to 10:00. Noises could also occur when the  X  X n office X  event is expected to be observed on a weekday but fails to happen.

In this paper, we take a completely different approach to the period detection problem and handle all the aforemen-tioned difficulties occurring in data collection process and periodic behavior complexity in a unified framework. The basic idea of our method is illustrated in Example 1.
EXAMPLE 1. Suppose an event has a period T =20 and we have eight observations of the event. If we overlay the observations with the correct period T =20 ,wecansee that most of the observations concentrate in time interval [5,10]. On the contrary, if we overlay the points with a wrong period, say T =16 , we cannot observe such clusters.
As suggested by Example 1, we could segment the timeline using a potential period T and summarize the observations over all the segments. If most of the observations fall into some time intervals, such as interval [5 , 10] in Example 1, T is likely to be the true period. In this paper, we formally characterize such likelihood by introducing a probabilistic model for periodic behaviors. The model naturally handles the oscillation and noise issues because the occurrence of an event at any timestamp is now modeled with a probability. Next, we propose a new measure for periodicity based on this model. The measure essentially examines whether the distribution of observations is highly skewed w.r.t a potential period T . As we will see later, even when the observations are incomplete, the overall distribution of observations, after overlaid with the correct T , remains skewed and is similar to the true periodic behavior model.
 In summary, our major contributions are as follows. (1) We introduce a probabilistic model for periodic behaviors and a random observation model for incomplete observa-tions. This enables us to model all the variations we en-counter in practice in a unified framework. (2) We propose a novel probabilistic measure for periodicity and design a practical algorithm to detect periods directly from the raw data. We further give rigorous proof of its validity under both the probabilistic periodic behavior model and the ran-dom observation model. (3) Comprehensive experiments are conducted on both real data and synthetic data. The results demonstrate the effectiveness of our method.

The rest of the paper is organized as follows. We formally define our period detection problem in Section 2 and intro-duce our probabilistic measure for periodicity in Section 3. Section 4 discusses the implementaion issues and outlines the algorithm. We report our experimental results in Sec-tion 5, discuss related work in Section 6 and conclude our study in Section 7.
In this section, we formally define the problem of period detection for events. We first assume that there is an ob-servation at every timestamp. The case with incomplete observations will be discussed in Section 3.2. We use a bi-nary sequence X = { x ( t ) } n  X  1 t =0 to denote observations. For example, if the event is  X  X n the office X , x ( t )=1meansthis person is in the office at time t and x ( t )=0meansthis person is not intheofficeattime t . Later we will refer x ( t )=1asa positive observation and x ( t )=0asa negative observation .

DEFINITION 1 (Periodic Sequence). Asequence X = { x ( t ) } n  X  1 t =0 is said to be periodic if there exists some T such that x ( t + T )= x ( t ) for all values of t .Wecall T a period of X .

A fundamental ambiguity with the above definition is that if T is a period of X ,then mT is also a period of X for any m  X  Z . A natural way to resolve this problem is to use the so called prime period .

DEFINITION 2 (Prime Period). The prime period of a periodic sequence is the smallest T  X  Z such that x ( t + T )= x ( t ) for all values of t .

For the rest of the paper, unless otherwise stated, we al-ways refer the word  X  X eriod X  to  X  X rime period X .

As we mentioned before, in real applications the observed sequences always deviate from the perfect periodicity due to the oscillating behavior and noises. To model such devia-tions, we introduce a new probabilistic framework, which is basedonthe periodic distribution vectors as defined below. DEFINITION 3 (Periodic Distribution Vector).
 We call any vector p T =[ p T 0 ,...,p T T  X  1 ]  X  [0 , 1] 0
T and 1 T a periodic distribution vector of length T .Abi-nary sequence X is said to be generated according to p T if x ( t ) is independently distributed according to Bernoulli ( p
Here we need to exclude the trivial cases where p T = 0 T or 1 T . Also note that if we restrict the value of each p { 0 , 1 } only, then the resulting X is strictly periodic according to Definition 1. We are now able to formulate our period detection problem as follows.

PROBLEM 1 (Event Period Detection). Given a binary sequence X generated according to any periodic dis-tribution vector p T 0 , find T 0 .

EXAMPLE 2 (Running Example). We will use a run-ning example throughout the paper to illustrate our method. Assume that a person has a daily periodicity visiting his of-fice during 10am-11am and 2pm-4pm. His observation se-quence is generated from the periodic distribution vector with high probabilities at time interval [10:11] and [14:16] and low but nonzero probabilities at other timestamps, as shown in Figure 3. Figure 3: (Running Example) Periodic distribution vector of a event with daily periodicity T 0 =24 .
As we see in Example 1, when we overlay the binary se-quence with its true period T 0 , the resulting sequence cor-rectly reveals its underlying periodic behavior. In this sec-tion, we make this observation formal using the concept of periodic distribution vector. Then, we propose a novel prob-abilistic measure of periodicity based on this observation and prove its validity even when observations are incomplete.
Given a binary sequence X , we define S + = { t : x ( t )=1 and S  X  = { t : x ( t )=0 } as the collections of timestamps with 1 X  X  and 0 X  X , respectively. For a candidate period T ,let I
T denote the power set of [0 : T  X  1]. Then, for any set of timestamps ( possibly non-consecutive ) I  X  X  T , we can define the collections of original timestamps that fall into this set after overlay as follows:
S where F T ( t )= mod( t, T ), and further compute the ratios of 1 X  X  and 0 X  X  whose corresponding timestamps fall into I after overlay: The following lemma says that these ratios indeed reveal the true underlying probabilistic model parameters, given that the observation sequence is sufficiently long.

LEMMA 1. Suppose a binary sequence X = { x ( t ) } n  X  1 t =0 is generated according to some periodic distribution vector p
T of length T , write q T i =1  X  p T i .Then  X  I  X  X  T , lim Proof. The proof is a straightforward application of the Law of Large Numbers (LLN), and we only prove the first equation. With a slight abuse of notation we write S i = { t : F T ( t )= i } and S + i = { t  X  S + : F T ( t )= i } { x ( t ): t  X  S i } are i.i.d. Bernoulli( p T i ) random variables, by LLN we have where we use lim n  X  X  X  | S i | n = 1 T for the last equality. So, Now we introduce our measure of periodicity based on Lemma 1. For any I  X  X  T , its discrepancy score is defined as: Then, the periodicity measure of X w.r.t. period T is: It is obvious that  X  X ( T ) is bounded: 0  X   X  X ( T )  X  1. More-over,  X  X ( T ) = 1 if and only if X is strictly periodic with pe-riod T . But more importantly, we have the following lemma, which states that under our probabilistic periodic behavior model,  X  X ( T ) is indeed a desired measure of periodicity.
LEMMA 2. If a binary sequence X is generated accord-ing to any periodic distribution vector p T 0 for some T 0
Proof. Define it is easy to see that the value lim n  X  X  X   X  X ( T 0 )isachieved for any T  X  Z and I  X  X  T ,
Observe now that for any ( I,T ), Therefore we have lim where the third equality uses the definition of I  X  .
Note that, similar to the deterministic case, the ambigu-ity of multiple periods still exists as we can easily see that lim n  X  X  X   X  X ( mT 0 ) = lim n  X  X  X   X  X ( T 0 ) for all m  X  Z this paper we are only interested in finding the smallest one. Figure 4: (a) and (c): Ratios of 1 X  X  and 0 X  X  at a single timestamp ( i.e. ,  X  + X (  X  ,T ) and  X   X  X (  X  ,T ) )when T =24 and T =23 , respectively. (b) and (d): Discrepancy scores at a single timestamp ( i.e.  X  X (  X  ,T ) )when T = 24 and T =23 . Figure 5: Periodicity scores of potential periods.
EXAMPLE 3 (Running Example (cont.)). When we overlay the sequence using potential period T =24 ,Fig-ure 4(a) shows that positive observations have high proba-bility to fall into the set of timestamps: { 10 , 11 , 14 , 15 , 16 However, when using the wrong period T =23 , the distribu-tion is almost uniform over time, as shown in Figure 4(c). Similarly, we see large discrepancy scores for T=24 (Fig-ure 4(b)) whereas the discrepancy scores are very small for T=23 (Figure 4(d)). Therefore, we will have  X  X (24) &gt;  X  (23) . Figure 5 shows the periodicity scores for all po-tential periods in [1 : 200] . We can see that the score is maximized at T =24 , which is the true period of the se-quence.
Next, we extend our analysis on the proposed periodicity measure to the case of incomplete observations with a ran-dom observation model. To this end, we introduce a new label  X -1 X  to the binary sequence X which indicates that the observation is unavailable at a specific timestamp. In the random observation model, each observation x ( t ) is associ-ated with a probability d t  X  [0 , 1] and we write d = { d
DEFINITION 4. Asequence X is said to be generated according to ( p T , d ) if
In general, we may assume that each d t is independently drawn from some fixed but unknown distribution f over the interval [0 , 1]. To avoid the trivial case where d t  X  0for all t , we further assume that it has nonzero mean:  X  f &gt; 0. Although this model seems to be very flexible, in the section we prove that our periodicity measure is still valid. In order to do so, we need the following lemma, which states that  X 
X ( I,T )and  X  infinite length observation sequence.

LEMMA 3. Suppose d = { d t } n  X  1 t =0 are i.i.d. random vari-ables in [0 , 1] with nonzero mean, and a sequence X is gener-ated according to ( p T , d ) , write q T i =1  X  p T i .Then lim
Proof. We only prove the first equation. Let y ( t )bea random variable distributed according to Bernoulli( d t )and variables which take value in { 0 , 1 } ,withmean E [ z ( t )] com-puted as follows:
E [ z ( t )] = P ( z ( t )=1)= P ( x ( t )=1 ,y ( t )=1) Define S i = { t : F T ( t )= i } and S + i = { t  X  S + : it is easy to see that | S + i | = t  X  S i z ( t ). Using LLN we get whereweuselim n  X  X  X  | S i | n =1 /T for the last equality. There-fore,
Since our periodicity measure only depends on  X  + X ( I,T ) and  X   X  X ( I,T ), it is now straightforward to prove its validity under the random observation model. We summarize our main result as the following theorem.

THEOREM 1. Suppose d = { d t } n  X  1 t =0 are i.i.d. random variables in [0 , 1] with nonzero mean, and a sequence X is generated according to any ( p T 0 , d ) for some T 0 ,then
The proof is exactly the same as that of Lemma 2 given the result of Lemma 3, hence is omitted here.

Here we make two useful comments on this result. First, the assumption that d t  X  X  are independent of each other plays (a) Discrepancy ( T = 24) Figure 6: Period detection with unknown observa-tions. an important role in the proof. In fact, if this does not hold, the observation sequence could exhibit very different peri-odic behavior from its underlying periodic distribution vec-tor. But a thorough discussion on this issue is beyond the scope of this paper. Second, this result only holds exactly with infinite length sequences. However, it provides a good estimate on the situation with finite length sequences, as-suming that the sequences are long enough. Note that this length requirement is particularly important when a major-ity of samples are missing ( i.e. ,  X  f is close to 0). We will discuss this issue in more detail in Section 4.

EXAMPLE 4 (Running Example (cont.)). To intro-duce random observations, we sample the original sequence with sampling rate 0 . 2 . The generated sequence will have 80% of its entries marked as unknown. Comparing Fig-ure 6(a) with Figure 4(b), we can see very similar discrep-ancy scores over time. Random sampling has little effect on our period detection method. As shown in Figure 6(b), we can still detect the correct period at 24 .
In many real world applications, negative samples may be completely unavailable to us. For example, if we have col-lected data from a local cellphone tower, we will know that a person is in town when he makes phone call through the local tower. However, we are not sure whether this person is in town or not for the rest of time because he could either be out of town or simply not making any call. In this case, the observation sequence X takes value in { 1 ,  X  1 } only, with -1 indicating the missing entries. In this section, we modify our measure of periodicity to handle this case.

Note that due to the lack of negative samples,  X   X  X ( I,T ) can no longer be computed from X . Thus, we need find another quantity to compare  X  + X ( I,T ) with. To this end, an i.i.d. Bermoulli( p ) random variable for some fixed p&gt; 0. It is easy to see that for any T and I  X  X  T ,wehave This corresponds to the case where the positive samples are evenly distributed over all entries after overlay. So we pro-pose the new discrepancy score of I as follows: and define the periodicity measure as: In fact, with some slight modification to the proof of Lemma 2, we can show that it is a desired measure under our probabilistic model, resulting in the following theorem.
THEOREM 2. Suppose d = { d t } n  X  1 t =0 are i.i.d. random variables in [0 , 1] with nonzero mean, and a sequence X is generated according to any ( p T 0 , d ) for some T 0 ,then Proof. Define c + i = p that the value lim n  X  X  X   X  + X ( T 0 )isachievedby I  X  = { [0 ,T 0  X  1] : c + i &gt; 0 } . So it suffices to show that for any T  X  Z and I  X  X  T ,
Observe now that for any ( I,T ), Therefore we have lim where the fourth equality uses the definition of I  X  .
Note that this new measure  X  + X ( T ) can also be applied to the cases where negative samples are available. Given the same validity result, readers may wonder if it can replace  X  ( T ). This is certainly not the case in practice, as our re-sults only hold exactly when the sequence has infinite length. As we will see in experiment results, negative samples indeed provide additional information for period detection in finite length observation sequences.

EXAMPLE 5 (Running Example (cont.)). In this ex-ample we further marked all the negative samples in the se-quence we used in Example 4 as unknown. When there is no negative samples, the portion of positive samples at a single timestamp i is expected to be 1 T , as shown in Figure 7(a). The discrepancy scores when T =24 still have large values at { 10 , 11 , 14 , 15 , 16 } . Thus the correct period can be suc-cessfully detected as shown in Figure 7(b). (a) Distribution ( T = 24) Figure 7: (Running Example) Period detection on sequences without negative samples.
In Section 3, we have introduced our periodicity mea-sure for any potential period T  X  Z . Our period detection method simply computes the periodicity scores for every T and report the one with the highest score.

In this section, we first describe how to compute the peri-odicity score for a potential period and then discuss a prac-tical issue when applying our method to finite length se-quence. We will focus on the case with both positive and negative observations. The case without negative observa-tions can be solved in the same way.

As we have seen in Section 3.1, the set of timestamps I  X  that maximizes  X  X ( T ) can be expressed as where c i = p suffices to compute c i for each i  X  [0 ,T 0  X  1] and select those ones with c i &gt; 0.
 Time Complexity Analysis. For every potential period T ,ittakes O ( n ) time to compute discrepancy score for a single timestamp ( i.e. , c i )andthen O ( T ) time to compute periodicity  X  X ( T ). Since potential period should be in range [1 ,n ], the time complexity of our method is O ( n 2 ). In prac-tice, it is usually unnecessary to try all the potential periods. For example, we may have common sense that the periods will be no larger than certain values. So we only need to try potential periods up to n 0 ,where n 0 n . This will make our method efficient in practice with time complexity as O ( n  X  n 0 ).
Now we want to point out a practical issue when applying our method on finite length sequence. As one may already notice in our running example, we usually see a general in-creasing trend of periodicity scores  X  X ( T )and  X  + X ( T )fora larger potential period T . This trend becomes more domi-nating as the number of observations decreases. For exam-ple, the original running example has observations for 1000 days. If the observations are only for 20 days, our method may result in incorrect period detection result, as the case shown in Figure 8(a). In fact, this phenomenon is expected and can be understood in the following way. Let us take  X  ( T ) as an example. Given a sequence X with finite num-ber of positive observations, it is easy to see that the size of I that maximizes  X  + X ( T ) for any T is bounded above by the number of positive observations. Therefore the value | I always decreases as T increases, no matter whether or not T is a true period of X .

To remedy this issue for finite length sequence, we use periodicity scores on randomized sequence to normalize the original periodicity scores. Specifically, we randomly per-mute the positions of observations along the timeline and compute the periodicity score for each potential period T . This procedure is repeated N times and the average period-icity scores over N trials are output as the base scores. The redline in Figure 8(a) shows the base scores generated from randomized sequences by setting N = 10, which agree well with the trend.

For every potential period T , we subtract the base score from the original periodicity score, resulting in the normal-ized periodicity score. Note that the normalized score also slightly favors shorter period, which helps us to avoid detect-ing duplicated periods ( i.e. , multiples of the prime period).
In this section, we systematically evaluate the techniques presented in this paper on both synthetic and real datasets.
In order to test the effectiveness of our method under var-ious scenarios, we first use synthetic datasets generated ac-cording to a set of parameter. We take the following steps to generate a synthetic test sequence SEQ .
 Step 1. We first fix a period T , for example, T = 24. The periodic segment SEG is a boolean sequence of length T , with values -1 and 1 indicating negative and positive observations, respectively. For simplicity of presentation, we write SEG =[ s 1 : t 1 ,s 2 : t 2 ,... ]where[ s i ,t i i -th interval of SEG whose entries are all set to 1. Step 2. Periodic segment SEG are repeated for TN times to generate the complete observation sequence, denoted as standard sequence SEQ std . SEQ std has length T  X  TN . Step 3 (Random sampling  X  ). We sample the standard sequence with sampling rate  X  . For any element in SEQ std we set its value to 0 ( i.e. , unknown) with probability (1 Step 4 (Missing segments  X  ). For any segment in stan-dard segment SEQ std , we set all the elements in that seg-ment as 0 ( i.e. , unknown) with probability (1  X   X  ). Step 5 (Random noise  X  ). For any remaining observation in SEQ std , we reverse its original values (making  X  1as1 and 1 as  X  1) with probability  X  .

The input sequence SEQ has values  X  1, 0, and 1 indi-cating negative, unknown, and positive observations. In the case when negative samples are unavailable, all the  X  1values will be set to 0. Note that here we set negative observations as  X  1 and unknown ones as 0, which is different from the description in Section 2. The reason is that the unknown entries are set as  X  1, in the presence of many missing en-tries, traditional methods such as Fourier transform will be dominated by missing entries instead of actual observations. The purpose of such adjustment is to facilitate traditional methods and it has no effect on our method.
We will compare our method with the following methods, which are frequently used to detect periods in boolean se-quence [6]. 1. Fourier Transform ( FFT ) : The frequency with the highest spectral power from Fourier transform via FFT is converted into time domain and output as the result. 2. Auto-correlation and Fourier Transform ( Auto ) : We first compute the auto-correlation of the input sequence. Since the output of auto-correlation will have peaks at all the multiples of the true period, we further apply Fourier transform to it and report the period with the highest power. 3. Histogram and Fourier Transform ( Histogram ) :We calculate the distances between any two positive observa-tions and build a histogram of the distances over all the pairs. Then we apply Fourier transform to the histogram and report the period with the highest power.

We will use FFT ( pos )and Auto ( pos )todenotethemeth-ods FFT and Auto-correlation for cases without any nega-tive observations. For Histogram , since it only considers the distances between positive observations, the results for cases with or without negative observations are exactly the same.
In this section, we test all the methods on synthetic data under various settings. The default parameter setting is the following: T = 24, SEG =[9:10 , 14 : 16]. TN = 1000,  X  =0 . 1,  X  =0 . 5, and  X  =0 . 2. For each experiment, we report the performance of all the methods with one of these parameters varying while the others are fixed. For each pa-rameter setting, we repeat the experiment for 100 times and report the accuracy, which is the number of correct period detections over 100 trials. Results are shown in Figure 9. Performance w.r.t sampling rate  X  . To better study the effect of sampling rate, we set  X  = 1 in this experiment. Fig-ure 9(a) shows that our method is significantly better than other methods in terms of handling data with low sampling rate. The accuracy of our method remains 100% even when the sampling rate is as low as 0 . 0075. The accuracies of other methods start to decrease when sampling rate is lower than 0 . 5. Also note that Auto is slightly better than FFT because auto-correlation essentially generates a smoothed version of the categorical data for Fourier transform. In addition, it is interesting to see that FFT and Auto performs better in the case without negative observations.
 Performance w.r.t ratio of observed segments  X  . In this set of experiments, sampling rate  X  is set as 1 to better study the effect of  X  . Figure 9(b) depicts the performance of the methods. Our method again performs much better than other methods. Our method is almost perfect even when  X  =0 . 025. And when all other methods fail at  X  =0 . 005, our method still achieves 80% accuracy.
 Performance w.r.t noise ratio  X  . In Figure 9(c), we show the performance of the methods w.r.t different noise ratios. Histogram is very sensitive to random noises since it considers the distances between any two positive observa-tions. Our method is still the most robust one among all. For example, with  X  =0 . 3, our method achieves accuracy as high as 80%.
 Performance w.r.t number of repetitions TN . Fig-ure 9(d) shows the accuracies as a function of TN .Asex-pected, the accuracies decrease as TN becomes smaller for all the methods, but our method again significantly outper-forms the other ones. Figure 10: Comparison results on randomly gener-ated periodic behaviors.
 Performance w.r.t periodic behavior. We also study the performance of all the methods on randomly generated periodic behaviors. Given a period T and fix the ratio of 1 X  X  in a SEG as r , we generate SEG by setting each ele-ment to 1 with probability r . Sequences generated in this way will have positive observations scattered within a pe-riod, which will cause big problems for all the methods us-ing Fourier transform, as evidenced in Figure 10. This is because Fourier transform is very likely to have high spectral power at short periods if the input values alternate between 1 and 0 frequently. In Figure 10(a) we set r =0 . 4andshow the results w.r.t period length T . In Figure 10(b), we fix T = 24 and show the results with varying r .Aswecan see, all the other methods fail miserably when the periodic behavior is randomly generated. In addition, when the ratio of positive observations is low, i.e. fewer observations, it is more difficult to detect the correct period in general. Comparison with Lomb-Scargle method. Lomb-Scargle periodogram ( Lomb ) [9, 12] was introduced as a variation of Fourier transform to detect periods in unevenly sampled data. The method takes the timestamps with observations and their corresponding values as input. It does not work for the positive-sample-only case, because all the input val-ues will be the same hence no period can be detected. The reason we do not compare with this method systematically is that the method performs poorly on the binary data and it is very slow. Here, we run it on a smaller dataset by set-ting TN = 100. We can see from Table 2 that, when  X  =0 . 5 or  X  =0 . 5, our method and FFT perform well whereas the accuracy of Lomb is already approaching 0. As pointed out in [13], Lomb does not work well in bi-modal periodic signals and sinusoidal signals with non-Gaussian noises, hence not suitable for our purpose.
In this section, we use the real GPS locations of a person who has tracking record for 492 days. We first pick one of his frequently visited locations and generate a boolean ob-servation sequence by treating all the visits to this location as positive observations and visits to other locations as neg-ative observations. We study the performance of the meth-ods on this symbolized movement data at different sampling rates. In Table 1, we compare the methods at two sampling rates, 1 hour and 20 minutes. As one can see in Table 1(a), when overlaying this person X  X  activity onto an period of one day, most of the visits occur in time interval [40, 60] for sampling rate of 20 minutes, or equivalently, in interval [15,
Table 2: Comparison with Lomb-Scargle method. 20] when the time unit is 1 hour. On one hand, when sam-pling rate is 20 minutes, all the methods except FFT ( pos ) and Histogram successfully detect the period of 24 hours, as they all have the strongest peaks at 24 hours (so we take 24 hours as the true period). On the other hand, when the data is sampled at each hour only, all the other methods fail to report 24 hours as the strongest peak whereas our method still succeeds. In fact, the success of our method can be eas-ily inferred from Table 1(a), as one can see that lowering the sampling rate has little effect on the distribution graph of the overlaid sequence. We further show the periods reported by all the methods at various sampling rates in Table 3. Our method obviously outperforms the others in terms of toler-ating low sampling rates.
 Table 3: Periods reported by different methods at various sampling rates.

Next, in Figure 11, we use the symbolized sequence of the same person at a different location and demonstrate the ability of our method in detecting multiple potential periods, especially those long ones. As we can see in Figure 11(a), this person clearly has weekly periodicity w.r.t this location. It is very likely that this location is his office which he only visits during weekdays. Our method correctly detects 7-day with the highest periodicity score and 1-day has second highest score. But all other methods are dominated by the short period of 1-day. Please note that, in the figures of other methods, 1-week point is not even on the peak. This shows the strength of our method at detecting both long and short periods.
Fourier transform and auto-correlation are the two most popular methods to detect periods [11]. However, Fourier transform has known problem in detecting the periods from sparse data [6]. It also performs poorly on data with mul-tiple non-consecutive occurrence in a period, as it tends to prefer short periods [15]. Auto-correlation offers accurate estimation for both short and long periods, but is more dif-ficult to find the unique period due to the fact that the multiples of the true period will have the same score as the true period itself. In addition, both Fourier transform and auto-ccorelation require evenly sampled input data. Lomb-Scargle periodogram [9, 12] is proposed as a variation of Fourier transform to handle unevenly spaced data using least-squares fitting of sinusoidal curves. But it suffers the same problems as Fourier transform. In bioinformatics, several methods have been proposed to address the issue of un-evenly spaced gene data [3, 8]. However, this issue is only one aspect of our problem whereas the low sampling rate and missing data problem have not been studied in these papers. An interesting previous work [6] has studied the problem of periodic pattern detection in sparse boolean se-quences for gene data, where the ratio of the number of 1 X  X  to 0 X  X  is small. However, sparsity in our problem is a result of low sampling rate and missing data, and we do not make any assumption on the sparsity of original periodic patterns.
Studies on period detection in data mining and database area usually assume the input to be a sequence of symbols instead of real value time series, and most of them have been focused on the efficiency of period detection algorithms [5, 1]. The presence of noises in the data has been considered in [10, 16, 2]. Our recent work [7] has studied probabilis-tic periodic behavior mining for moving objects. But it has been focused on dealing with spatiotemporal data, while pe-riod detection is still based on Fourier transform and auto-correlation. In summary, none of previous studies can han-dle all the practical issues we mentioned in this paper, i.e. the observations are incomplete, and the periodic behavior is complicated and noisy.
In this paper, we address the important and challenging problem of period detection from incomplete observations. We first propose a probabilistic model for periodic behaviors. Then, we design a novel measure for periodicity and a prac-tical algorithm to detect periods in real scenarios. We give a rigorous proof of its validity for our probabilistic frame-work. Empirical studies show that our method is robust to imperfectly collected data and complicated periodic behav-iors. A case study on real human movement data further demonstrates the effectiveness of our method.

While our approach is designed for binary sequences, one important extension is to handle observation sequences with real values. For example, sensors may not only detect the us-age of a room but also report the temperature and humidity, and such data could also be sparse, incomplete and unevenly sampled due to the limitations of sensors. We consider this as interesting future work. The work was supported in part by Boeing company, NASA NRA-NNH10ZDA001N, NSF IIS-0905215 and IIS-1017362, the U.S. Army Research Laboratory under Cooperative Agree-ment No. W911NF-09-2-0053 (NS-CTA). The views and con-clusions contained in this paper are those of the authors and should not be interpreted as representing any funding agen-cies. [1] M. G. Elfeky, W. G. Aref, and A. K. Elmagarmid. [2] M. G. Elfeky, W. G. Aref, and A. K. Elmagarmid. [3] E. F. Glynn, J. Chen, and A. R. Mushegian. Detecting [4] M. C. Gonz  X  alez, C. A. Hidalgo, and A.-L. Barab  X as. [5] P. Indyk, N. Koudas, and S. Muthukrishnan.
 [6] I. Junier, J. Herisson, and F. Kepes. Periodic pattern [7] Z. Li, B. Ding, J. Han, R. Kays, and P. Nye. Mining [8] K.-C. Liang, X. Wang, and T.-H. Li. Robust [9] N. R. Lomb. Least-squares frequency analysis of [10] S. Ma and J. L. Hellerstein. Mining partially periodic [11] M. B. Priestley. Spectral Analysis and Time Series . [12] J. D. Scargle. Studies in astronomical time series [13] M. Schimmel. Emphasizing difficulties in the detection [14] T. van Kasteren, A. K. Noulas, G. Englebienne, and [15] M. Vlachos, P. S. Yu, and V. Castelli. On periodicity [16] J. Yang, W. Wang, and P. S. Yu. Mining asynchronous
