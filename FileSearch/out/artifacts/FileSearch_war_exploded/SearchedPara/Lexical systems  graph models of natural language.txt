 Alain Polgue ` re Abstract We introduce a new type of lexical structure called lexical system ,an interoperable model that can feed both monolingual and multilingual language resources. We begin with a formal characterization of lexical systems as simple directed graphs, solely made up of nodes corresponding to lexical entities and links. To illustrate our approach, we present data borrowed from a lexical system that has been generated from the French DiCo database. We later explain how the compi-lation of the original dictionary-like database into a net-like one has been made possible. Finally, we discuss the potential of the proposed lexical structure for designing multilingual lexical resources.
 Keywords Lexical database Graph model Explanatory combinatorial lexicology Lexical function 1 Structure of lexical systems The aim of this paper is to introduce, justify and exemplify a new type of structure for lexical resources called lexical systems . Our presentation is centered around an experiment of lexical system generation that was performed using data tables extracted from the French DiCo database. This experiment has allowed us to produce a lexical system that is a richer structure than the original database it has been derived from.

Lexical systems as formal models of natural language lexicons are very much related to the -Net generation of lexical databases, whose most well-known representative is undoubtedly WordNet (Fellbaum 1998 ). However, lexical systems possess some very specific characteristics that clearly distinguish them from other lexicographic structures. In this section, we first characterize the two main current approaches to the structuring of lexical models, then present lexical systems relative to them. 1.1 Dictionary-vs . net-like lexical databases 1.1.1 Dictionary-like databases as texts The most straightforward way of building lexical databases is to use standard dictionaries (i.e. books) and turn them into electronic entities. It is the approach taken by most publishing companies, with various degrees of sophistication. Resulting products can be termed dictionary-like databases . They are mainly characterized by two features.  X  They are made up of word (word sense) descriptions, called dictionary entries .  X  Dictionary entries can be seen as  X  X  X exts, X  X  in the most general sense.

Consequently, dictionary-like databases are before all huge texts, consisting of a collection of much smaller texts (i.e. entries).
 It seems natural to consider electronic versions of standard dictionaries as texts. However, formal lexical databases such as the multilingual XML-based JMDict (Breen 2004 ) are also textual in nature. They are collections of entries, each entry consisting of a structured text that  X  X  X ells us something X  X  about a word. Even databases encoding relational models of the lexicon can be 100% textual, and therefore dictionary-like. Such is the case of the French DiCo database (Polgue ` re 2000 ), that we have used for compiling our lexical system. As we will see later, the original DiCo database is nothing but a collection of lexicographic records, each record being subdivided into fields that are basically small texts. Although the DiCo is built within the framework of Explanatory Combinatorial Lexicology (Mel X  X   X  uk et al. 1995 ) and concentrates on the description of lexical links, it is clearly not designed as a net-like database X  X ee below. 1.1.2 Net-like databases as graphs Most lexical models, even standard dictionaries, are relational in nature. For instance, all dictionaries define words in terms of other words, use pointers such as  X  X  X ynonym X  X  and  X  X  X ntonym. X  X  However, their structure does not reflect their relational nature. The situation is totally different with true net-like databases. They can be characterized as follows.  X  They are graphs X  X uge sets of connected entities X  X ather than collections of  X  They are not necessarily centered around words, or word senses. Their nodes
Net-like databases are, for many, the most suitable knowledge structures for modeling lexicons. Nevertheless, they pose one major problem: they are generally structured according to a couple of hierarchizing and/or classifying principles. WordNet, for instance, is semantically-oriented and imposes a hierarchical organization of lexical entities based, first of all, on two specific semantic relations: synonymy X  X hrough the grouping of lexical meanings within synsets  X  X nd hypernymy. Additionally, the part of speech classification of lexical units creates a strict partition of the database: WordNet is made up of four separate synset hierarchies (for nouns, verbs, adjectives and adverbs). We do not believe lexical models should be designed following a few rigid principles that impose a hierarchization or classification of data. Such structuring is of course useful, even necessary, but should be projected  X  X  X n demand X  X  onto lexical models. Furthermore, there should not be a predefined, finite set of potential structuring principles; data structures should welcome any of them, and this is precisely one of the main characteristics of lexical systems, that will be presented shortly (Sect. 1.2 ). Notice that the approach to net-like databases we will present here bears striking similarities to the Graph Lexicon model proposed in Trippel ( 2006 ). 1.1.3 Texts vs. graphs: pros and cons Any dictionary-like database can be turned into a net-like database and vice versa. There are two very  X  X  X uperficial X  X  reasons why electronic dictionaries, the richest type of dictionary-like databases, are not available in net-format for natural language processing (NLP) applications: first, a significant amount of manual processing is required in order to extract the often implicit connections between lexical entities that can be found in standard electronic dictionaries; second, these dictionaries are copyrighted and their content cannot be used and distributed freely X  X hich rules out any exploitations for building NLP lexicons (at least, exploitations that people would feel free to let us know about).

Dictionary-like databases that rely on relational models are more compatible with graph encoding. However, there are always relational data in dictionaries, and such data can be extracted and encoded as nodes and connecting links. The important issue is therefore not one of exclusive choice between the two structures; it concerns what each structure is better at. In our opinion, the specialization of each type of structure is as follows.

Dictionary-like structures are tools for editing (writing) and consulting lexical information. Linguistic intuition of lexicographers or users of lexical models performs best on texts. Both lexicographers and users need to be able to see the whole picture about words, and need the entry format at a certain stage X  X lthough other ways of displaying lexical information, such as tables, are extremely useful too. 1
Net-like structures are tools for implementing dynamic aspects of lexicons: wading through lexical knowledge, adding to it, revising it or inferring information from it. Consequently, net-like databases are believed by some to have some form of cognitive validity. Last but not least, net-like databases can more easily integrate other lexical structures or be integrated by them.

In conclusion, although both forms of structures are compatible at a certain level and have their own advantages in specific contexts of use, we are particularly interested by the fact that net-like databases are more prone to live an  X  X  X rganic life X  X  in terms of evolution (addition, subtraction, replacement) and interaction with other data structures (connection with models of other languages, with grammars, etc.). 1.2 Lexical systems: a new type of net-like lexical databases As mentioned above, most net-like lexical databases seem to focus on the description of just a few properties of natural language lexicons (quasi-synonymy, hypernymic organization of word senses, predicative structures and their syntactic expression, etc.). Consequently, developers of these databases often have to gradually  X  X  X tretch X  X  their models in order to add the description of new types of phenomena, that were not of primary concern at the onset. It is legitimate to expect that such graft of new components will leave scars on the initial design of lexical models. The lexical structures we propose, lexical systems (hereafter LS ), do not pose this type of problem for two reasons. First, they are not oriented towards the modeling of just a few specific lexical phenomena, but originate from a global vision of the lexicon as central component of linguistic knowledge. Second, they have a very simple, flat organization, that does not impose any hierarchical or classifying structure on the lexicon. Let us explain how it works.

The design of any given LS has to follow four basic principles, that cannot be tampered with. We will briefly examine each of these principles. 1) Simple directed graph . An LS is a directed graph, and just that. This means that, 2) Non-hierarchical . An LS is a non-hierarchical structure, although it can contain 3) Heterogeneous . An LS is an heterogeneous collection of nodes. Three main 4) With fuzziness . Each component of an LS, whether node or link, carries a trust
Fuzziness encoding is an essential feature of LSs, as structures on which inference can take place or as structures that are, at least partially, inferred from others (in case of generation of LSs from existing lexical databases). Of course, any trust value is not absolute.  X  X  1  X  X  does not mean the information is valid no matter what, and  X  X  0  X  X  that it is necessarily false. Information in LSs, and the rating of this information, is no more absolute than any information that may be stored in someone X  X  mental lexicon. However, if we want to compute on LSs X  content, it is essential to be able to distinguish between data we have all reasons to believe to be true and data we have all reasons to believe to be false.

It is now high time to give concrete examples of LS data. But before we proceed, let us emphasize the fact that no other formal devices than those that have just been introduced are allowed in LSs. Anything else we may want to add must be relevant to other components of the linguistic model, to the grammar for instance. Notice, however, that we do not exclude the need to add a measure of the relative  X  X  X eight X  X  of nodes and links. This measure, different from the trust value, would reflect the degree of activation of each LS element. For instance, the DiCo entry for DE  X  FAITE  X  X efeat X  lists quite a few support verbs that take this noun as complement, among which CONNAI  X  TRE  X  X o know X  and SUBIR  X  X o suffer. X  Weight values could indicate that the former verb is much less commonly used than the second in this context. 2 Examples borrowed from the DiCo LS The DiCo is a French lexical database that focuses on the modeling of paradigmatic and syntagmatic lexical links controlled by lexical units. Paradigmatic links correspond to so-called semantic derivations (synonymy, antonymy, nominaliza-tion, verbalization, names for actants or typical circonstants, etc.). Syntagmatic links correspond to collocations controlled by lexical units (intensifiers, support verbs, etc.). These lexical properties are encoded by means of a system of metalexical entities known as lexical functions . For a presentation of the system of lexical functions, see Mel X  X   X  uk ( 1996 ) and Kahane and Polgue ` re ( 2001 ). Although it does not contain actual definitions, the DiCo partially describes the semantic content of each lexical unit with two formal tools: (i) a semantic label, that corresponds to the genus (core component) of the lexical unit X  X  definition and (ii) a  X  X  X ropositional formula, X  X  which states the predicative nature of the unit (non-predicative meaning or predicate with one, two or more arguments). Each entry also gives the government pattern (roughly, the subcategorization frame) of the unit and lists idioms (phrasal lexical units) that contain the unit under description. Finally, each entry contains a set of examples retrieved from corpora or the Internet. As one can see, the DiCo covers a fairly large range of lexical properties; for more information on the DiCo, one can refer to Polgue ` re ( 2000 ).

Presently, the DiCo is developed as a FileMaker  X  database. Each DiCo entry corresponds to a record in the database, and the core of each record is the field that contains lexical function links controlled by the headword (i.e. the lexical unit described in the entry). Data in (1) below is one item in the lexical function field of the DiCo record for Fr. RANCUNE ( X  X esentment X ):  X  1  X  =  X  X eprouver =
We isolate five different types of LS entities in the above example:  X  Oper12 is the name of a lexical function denoting a type of support verbs. 4  X  f Oper12 g as a whole denotes Oper12 ( RANCUNE ), the application of the Oper12  X  The preceding formula X  X etween the two = ... = symbols X  X s a gloss for:  X  Following the name of the lexical function is the list of values of the lexical  X  The expression between square brackets encodes the syntactic structure
Data in (1) correspond to a very small subgraph in the generated LS, which is visualized in Fig. 1 . Notice that graphical representations we used here have been automatically generated in GraphML format from the LS and then displayed with the yEd graph editor/viewer.

This graph shows how DiCo data given in (1) have been modeled in terms of lexical entities and links. We see that lexical function applications are lexical entities: something to be communicated, that is pointing to actual means of expressing it. The argument ( arg link) of the lexical function application, the lexical unit RANCUNE , is of course also a lexical entity (although of a different nature). The same holds for the values ( value links). None of these values, however, has been diagnosed as possessing a corresponding entry in the DiCo. Consequently, the compilation process has given them the (temporary) status of simple wordforms, with a trust value of 0 : 5 , visualized here by boxes with hashed borders. (Continuous lines for links or boxes indicate a trust value of 1 .) Ultimately, it will be the task of lexicographers to add to the DiCo entries for the corresponding senses of AVOIR ,
One may be surprised to see lexical functions (such as Oper1 ) appear as lexical entities in our LS, because of their very  X  X  X bstract X  X  nature. Two facts justify this approach. First, lexical units too are rather abstract entities. While wordforms horse and horses could be considered as more  X  X  X oncrete, X  X  their grouping under a label HORSE lexical unit is not a trivial abstraction. Second, lexical functions are not only descriptive tools in Explanatory Combinatorial Lexicology. They are also concep-tualized as generalization of lexical units that play an important role in text production, in general rules of paraphrase for instance.

This first illustration demonstrates how the LS version of the DiCo reflects its true relational nature, contrary to its original dictionary-like format as a FileMaker database. It also shows how varied lexical entities can be and how trust values can help keep track of the distinction between what has been explicitly stated by lexicographers and what can be inferred from what they stated.

The next illustration will build on the first one and show how so-called non-standard lexical functions are integrated into the LS. Until now, we have been referring only to standard lexical functions, i.e. lexical functions that belong to the small universal core of lexical relations identified in Explanatory Combinatorial Lexicology (or, more generally, in Meaning-Text theory). However, all paradig-matic and syntagmatic links are not necessarily standard. Here is an illustration, borrowed from the DiCo entry for CHAT  X  X at. X   X  2  X f Ce qu 0 on dit pour appeler g  X  Minet!  X  ;  X  Minou!  X  ;  X  Petit!  X 
Here, a totally non-standard lexical function Ce qu 0 on dit pour appeler  X  X hat one says to call * [= a cat] X  has been used to connect the headword CHAT to expressions such as Minou !  X  X itty kitty! X . As one can see, no gloss has been introduced, because non-standard lexical functions are already explicit, non-formal encoding of lexical relations. The LS interpretation of (2) is therefore a simpler structure than the one used in our previous illustration, as shown in Fig. 2 .
Our last illustration will show how it is possible to project a hierarchical structuring on the DiCo LS when, and only when , it is needed.

The hierarchy of semantic labels used to semantically characterize lexical units in the DiCo has been compiled into the DiCo LS together with the lexical database proper. Each semantic label is connected to its more generic label or labels (as this hierarchy allows for multiple inheritance) with an is a link. Additionally, it is connected to the lexical units it labels by label links. It is thus possible to simply pull the hierarchy of semantic labels out of the LS and it will  X  X  X ish out X  X  all lexical units of the LS, hierarchically organized through hypernymy. Notice that this is different from extracting from the DiCo all lexical units that possess a specific semantic label: we extract all units whose semantic label belongs to a given subhierarchy in the system of semantic labels. Fig. 3 is the graphical result of pulling the accessoire ( X  X ccessory X ) subhierarchy.

To avoid using labels on links, we have programmed the generation of this class of GraphML structures with links encoded as follows: is a links (between semantic labels) appear as thick continuous arrows and label links (between semantic labels and lexical units they label) as thin dotted arrows.

The  X  X  X eauty X  X  of LSs X  structuring does not lie in the fact that it allows us to automatically generate fancy graphical representations. Such representations are just a convenient way to make explicit the internal structure of LSs. What really interests us is what can be done with LSs once we consider them from a functional perspective.

The main functional advantage of LSs lies in the fact that these structures are both cannibal and prone to be cannibalized. Let us explain the two facets of this somehow gruesome metaphor.

First, directed graphs are powerful structures that can encode virtually any kind of information and are particularly suited for lexical knowledge. If one believes that a lexicon is before all a relational entity, we can postulate that all information present in any form of dictionary and database can eventually be compiled into LS structures. The experiment we did in compiling the DiCo (see details in Sect. 3 ) demonstrates well enough this property of LS structures.

Second, because of their extreme simplicity, LS structures can conversely always be  X  X  X igested X  X  by other, more specific types of structures, such as XML versions of dictionary-or net-like databases. For instance, we have regenerated from our LS a DiCo in HTML format, with hyperlinks for entry cross-references and color-coding for trust values of linguistic information. Interestingly, this HTML by-product of the LS contains entries that do not exist in the original DiCo. They are produced for each value of lexical function applications that does not correspond to an entry in the DiCo. The content of these entries is made up of  X  X  X nverse X  X  lexical function relations: pointers to lexical function applications for which the lexical entity is a value. These new entries can be seen as rough drafts, that can be used by lexicographers to write new entries. We will provide more details of this at the end of the next section. 3 Compiling the DiCo (dictionary-like) database into a lexical system The DiCo is presently available both in FileMaker format and as SQL tables, accessible through the DiCoue ` be interface. 5 It is these tables that are used as input for the generation of LSs. 6 They present the advantage of being the result of an extensive processing of the DiCo that splits its content into elementary pieces of lexicographic information (Steinlin et al. 2005 ). It is therefore quite easy to analyze them further in order to perform a restructuring in terms of LS modeling. The task of inferring new information, information that is not explicitly encoded in the DiCo, is the delicate part of the compilation process, due to the richness of the database. We have only implemented a small subset of all inferences that can be made; the computed inferences are of three different types.

First, we performed the reification of many implicit entities in the DiCo. The treatment of lexical function links, as shows in the previous section, is a clear illustration of this extensive reification X  X ee the gap between the DiCo datastructure of (1) and the corresponding LS structure in Fig. 1 . Notice that the reification of entities gives rise to reification of links between these entities. These links, as specific objects in the LS, are new, inferred pieces of information, directly accessible for computation.

Second, there are inferences performed via the injection of one (and, potentially, many) additional datastructure in the LS: the hierarchy of semantic labels. This hierarchy does not exists as such in the DiCo, where only labels themselves appear as semantic characterization for each individual lexical unit. The semantic clustering of lexical units illustrated in Fig. 3 above is a direct, formal consequence of the injection of the hierarchy of semantic labels in the LS; such clustering does not exist as such in the dictionary-like database, as it is stored in a separate datastructure. The injection of the hierarchy of semantic labels is just one example of what we plan to do with LSs in terms of injection of new information.

Third, there is the inference of linguistic objects that are not explicitly handled in the DiCo. For instance, we inferred individual lexemes from idioms that appear inside DiCo records ( COUP DE SOLEIL  X  X unburn X  entails the probable existence of the three lexemes COUP , DE and SOLEIL ). Additionally, the DiCo does not describe as such lexical meanings vs . wordforms vs . signifiers. There is no  X  X  X ntry X  X  in it for, say, the meaning  X  X rand X  [=  X  X ig X  X , the wordform grand # 1 [= masculine singular adjectival form grand associated with its basic meaning  X  X ig X  X  and the signifier grand [= surface form, regardless of any associated meaning]. In contrast, the compilation process systematically introduces entities of all levels (semantemes, wordforms, signifiers, etc.) each time a piece of data in the DiCo allows for such computation.
Clearly, all these can be termed low-level inferences, and they correspond to the minimal processing we wanted to implement when building our first LS. What matters is the fact that this new datastructure is richer mainly because it can itself give rise to higher level inferences. In particular, one can implement on LSs strategies for inferring new properties of lexical units based on extracted generalizations. For instance, it is relatively easy to extract generalizations about combinatorial properties of lexical units based on their semantic label and actantial structure. We can then enrich the LS with proposed combinatorial properties for units that are good candidates but whose description do not yet feature these properties.

It is of course always possible to run scripts on a dictionary-like database and build a separate data structure that will contain all this information. But precisely, this information will not be part of the database itself, whereas it is conceptually an intrinsic component of the LS of the language.

We cannot give here all details of the compilation process. Suffice it to say that, at the present stage, some important information contained in the DiCo is not processed yet. For instance, we have not implemented the compilation of government patterns and lexicographic examples. On the other hand, all lexical function applications and the semantic labeling of lexical units are properly handled. Recall that we import together with the DiCo a hierarchy of semantic labels used by the DiCo lexicographers, which allows us to establish hypernymic links between lexical units, as shown in Fig. 3 above. Notice that the hierarchy of semantic labels is developed with the Prote  X  ge  X  ontology editor. Though it may seem a bit like smashing a fly with a hammer, we get directly from the shelf a tool that satisfies, at the present time, all our needs in terms of semantic information management. We use XML exports from Prote  X  ge  X  to inject this hierarchy into the LS; this is another illustration of the cannibalistic (and not too choosy) nature of LSs.

Codewise, the DiCo LS is just a flat Prolog database with clauses for only two predicates: entity  X  \ Numerical ID [ ; \ Name [ ; \ Type [ ; \ Trust [  X  link  X  \ Numerical ID [ ; \ Source ID [ ; \ Target ID [ ;
Here are some statistics on the content of the DiCo LS produced during our experiment.

Nodes: 37,808 780 semantic labels; 1,301 vocables (= entries in the  X  X  X S wordlist X  X ); 1,690 lexical units (= senses of vocables); 6,464 wordforms; 2,268 non-lexicalized expressions; 7,389 monolexical signifiers; 948 multilexical signifiers; 3,443 lexical functions; 9,417 lexical function applications; 4,108 glosses of lexical function applications
Links: 61,714 871  X  X  X s_a, X  X  between semantic labels; 775  X  X  X em_label, X  X  between semantic labels and lexical units; 1,690  X  X  X ense, X  X  between vocables and lexical units corresponding to specific senses; 2,991  X  X  X asic_form, X  X  between mono-or multilexical signifiers and vocables or lexical units; 6,464  X  X  X ignifier, X  X  between wordforms and monolexical signifiers; 4,135  X  X  X sed_in, X  X  between monolexical signifiers and multiliexical signifiers; 9,417  X  X  X f, X  X  between lexical functions and their application; 6,064  X  X  X loss, X  X  between lexical function applications and their gloss; 9,417  X  X  X rg, X  X  between lexical function applications and their argument; 19,890  X  X  X alue, X  X  between lexical function applications and each of the value elements they return
Let us make a few comments on these numbers in order to illustrate how the generation of the LS from the original DiCo database works.

The FileMaker (or SQL) DiCo database that has been used contained only 775 lexical unit records (word senses). This is reflected in statistics by the number of sem label links between semantic labels and lexical units: only lexical units that were headwords of DiCo records possess a semantic labeling. Statistics above show that the LS contains 1,690 lexical units. So where do the 915 (1,690 -775) extra units come from? They all have been extrapolated from the so-called phraseology ( ph ) field of DiCo records, where lexicographers list idioms that are formally built from the record headword. For instance, the DiCo record for BARBE  X  X eard X  contained (among others) a pointer to the idiom BARBE A ` PAPA  X  X otton candy. X  This idiom did not possess its own record in the original DiCo and has been  X  X  X eified X  X  while generating the LS, among 914 other idioms.

The  X  X  X ordlist X  X  of our LS is therefore much more developed than the DiCo X  X  wordform entities. As explained earlier, it is possible to regenerate from the LS lexical descriptions for any lexical entity that is either a lexical unit or a wordform targeted by a lexical function application, filling wordform descriptions with inverse lexical function links. To test this, we have regenerated an entire DiCo in HTML format from the LS, with a total of 8,154 (1,690 ? 6,464) lexical entries, stored as individual HTML pages. Pages for original DiCo headwords contain the hypertext specification of the original lexical function links, together with all inverse lexical links that have been found in the LS; pages for wordforms contain only inverse links. For instance, the page for METTRE  X  X o put X  (which is not a headword in the original DiCo) contains 71 inverse links, such as: 7
Of course, most of the entries that were not in the original DiCo are fairly poor and will require significant editing to be turned into bona fide DiCo descriptions. They are, however, a useful point of departure for lexicographers; additionally, the richer the DiCo will become, the more productive the LS will be in terms of automatic generation of draft descriptions. 4 Lexical systems and multilinguality The approach to multilingual implementation of lexical resources that LSs allow is compatible with strategies used in known multilingual databases, such as Papillon (Se  X  rasset and Mangeot-Lerebours 2001 ): it sees multilingual resources as connec-tions of basically monolingual models. In this final section, we make proposals for implementing interlingual connections by means of LSs.

A multilingual lexical resource based on the LS architecture should be made up of several fully autonomous LSs , i.e., LSs that are not specially tailored for multilingual connections. They function as independent modules that can be connected while preserving their integrity. Connections between LSs are imple-mented as specialized interlingual links between equivalent lexical entities. There is one exception though: standard lexical functions ( A1 , Magn , AntiMagn , Oper1 , etc.). Because they are universal lexical entities, they have to be stored in a specialized interlingual module; as universals, they play a central role in interlingual connectivity (Fontenelle 1997 ). However, these are only  X  X  X ure X  X  lexical functions. Lexical function applications, such as Oper12 ( RANCUNE ) above, are by no means universals and have to be connected to their counterpart in other languages. Let us examine briefly this aspect of the question.

One has to distinguish at least two main cases of interlingual lexical connections in LSs: direct lexical connections and connections through lexical function applications.

Direct connections, such as Fr. RANCUNE vs .Eng. RESENTMENT should be implemented X  X anually or using existing bilingual resources X  X s simple interlin-gual (i.e. intermodule) links between two lexical entities. Things are not always that simple though, due to the existence of partial or multiple interlingual connections. For instance, what interlingual link should originate from Eng. SIBLING if we want to point to a French counterpart? As there is no lexicalized French equivalent, we may be tempted to include in the French LS entities such as fre ` re ou s X ur ( X  X rother or sister X ). We have two strong objections to this. First, this complex entity will not be a proper translation in most contexts: one cannot translate He killed all his siblings specific context, as well as in many others. Second, and this is more problematic, this approach would force us to enter in the French LS entities for translation purposes, which would transgress the original monolingual integrity of the system. 8 We must admit that we do not have a ready-to-use solution to this problem, translations as lexical entities in target LSs. It may very well be the case that a cluster of interrelated LSs cannot be completely connected for translation purposes without the addition of  X  X  X uffer X  X  LSs that ensure full interlingual connectivity. For instance, the buffer French LS for English to French LS connection could contain phrasal lexical entities such as fre ` res et s X urs ( X  X iblings X ), e  X  tre de me  X  mes parents productive and can lead us to realize that what appeared first as an ad hoc solution may be fully justified from a linguistic perspective. Dealing with the sibling case, for instance, forced us to realized that while fre ` re ( s ) et s X ur ( s ) sounds very normal in French, s X ur ( s ) et fre ` re ( s ) will seem odd or, at least, intentionally built that way. This is a very strong argument for considering that a lexical entity (we do not say lexical unit !) fre ` re ( s ) et s X ur ( s ) does exist in French, independently from the translation problem that sibling poses to us. This phrasal entity should probably be present in any complete French LS.

The case of connections through lexical function applications is even trickier. A simplistic approach would be to consider that it is sufficient to connect interlinguistically lexical function applications to get all resulting lexical connec-tions for value elements. For standard lexical functions, this can be done automatically using the following strategy for two languages A and B.

If the lexical entity L A is connected to L B by means of a  X  X  X ranslation X  X  link, all lexical entities linked to the lexical function application f (L A ) by the  X  X  X alue X  X  link should be connected by a  X  X  X alue_translation X  X  link, with a trust value of  X  X 0.5, X  X  to all lexical entities linked to f (L B ) by a  X  X  X alue X  X  link.

The distinction between  X  X  X ranslation X  X  and  X  X  X alue_translation X  X  links allows for contextual interlingual connections: a lexical entity L X  B could happen to be a proper translation of L X  A only if it occurs as collocate in a specific collocation. But this is not enough. It is also necessary to filter  X  X  X alue_translation X  X  connections that are systematically generated using the above strategy. For instance, each of the specific values given in (1) Sect. 2 should be associated with its closest equivalent among time, we do not see how this can be achieved automatically, unless we can make use of already available multilingual databases of collocations. For English and French, for instance, we plan to experiment in the near future with T. Fontenelle X  X  database of English-French collocation pairs (Fontenelle 1997 ). 5 Conclusions We have achieved the production of a significant LS, which can be considered of broad coverage in terms of the sheer number of entities and links it contains and the richness of linguistic knowledge it encodes. We plan to finish the absorption of all information contained in the DiCo database (including information that can be inferred). We also want to integrate complementary French databases into the LS and start to implement multilingual connections. Another development will be the construction of an editor to access and modify our LS. This tool will also be used to develop DiCo-style LSs for other languages than French.
 References
