 Data grid [1,2,3,4] is a distributed architecture for data management that provides the coordinated and collaborative mechanisms for integrating data distributed across network and forms a single, virtual environment for data access and management. The aim is to facilitate world-wide community with geographically-distributed resources for large-scale data-intensive applications and providing fast, reliable and transparent access to data. Many applications can be deve loped in data grid environment, such as most prominent being global climate simulation, high energy physics and biology computing. 
Data replication [5] is an optimization technique well known in the distributed sys-fault tolerance and increasing the performance and robustness of distributed applica-tions. Various replica management systems [6,7,8] exist, such as the Globus MDS-2 replica catalog, the Grid Data Mirroring Package (GDMP), the Giggle framework and the SDSC X  X  Storage Resource Broker (SRB). These systems differ in several architec-replicas X  lifetime. 
The roles which the database management systems are contributing towards data storage, access, management and transference in distributed environment [9,10,11] is tremendous. Among database operations, Join is a commonly used, but complex, area of attention [12,13]. Existence of autonomous nodes, massive and heterogeneous datasets and the different and unstable bandwidths among nodes brings new chal-lenges to the Join operation in data grid environment. 
In this paper, a join algorithm is proposed that facilitates the queries involving join the users who issue the queries to access the data via grid that involves the join opera-tion. Firstly a reduction algorithm is applied to the data involved. Second grid nodes, For convenience in data transference and data size we suggest new reducing and merging algorithms and sending techniques. The influence of various parameters on the performance of algorithm is studied by experiments, showing the efficiency and usefulness of the work. relation reduction, block transferring and merging. In Section 3 we discuss Edge-weight-minimum-matching algorithms by employing some important concepts from Graph Theory. Section 4 explores the propos ed Join Algorithm in five phases. The Finally we conclude the paper and highlight some future work in Section 6. We start with some preliminaries. These include relation reduction algorithm, row blocking data transfer mode and block merge join algorithm. 2.1 Relation Reduction Algorithm  X  =| R  X  | / | R |,  X  S =| S  X  | / | S | respectively. nodes A and B in data grid and need to be join ed according to some join attribute T. If satisfy the join condition then we need to transfer only these tuples instead of all the tuples in R and S to the execution node where join operation will be performed. The steps of relation reduction algorithm are as follows: are the projection results of R and S according to join attribute T by using commonly known sort-based projection algorithm. assume the order is non-decreasing in this paper. R  X  R &gt;&lt; S = R  X  &gt;&lt; S  X  . R  X  X  X  X  R  X  , S  X  X  X  X  S  X  , and R  X  X  &gt;&lt; S  X  X  = R &gt;&lt; S. R 2.2 Row Blocking Data Transfer Mode For transferring datasets from one grid node to others, we suggest row blocking data transfer technique in which tuples are shipped from one grid node to others in blocks. 
In traditional approach, tuples are shipped one by one through the network. There-fore any short delay in the network would immediately stop the execution of the blocking, the receiving node would have a re servoir of tuples and thus can feed opera-tor even if the tuples of next block is delayed. In this way, the approach compensates for delay in data arrival up to a certain extent. 2.3 Block Merge Join Algorithm Suppose node E is the execution node in which join operation is to be performed over and S  X  respectively. Further we assume two memory spaces MR and MS allocated for R  X  and S  X  respectively to store received tuples from R  X  and S  X  . 
Now, for each block of R  X  and S  X  , there are two phases to complete the join opera-tion at node E: (1) insertion phase , each block is inserted into its corresponding mem-every matched block from MS , secondly each tuple in block R  X  [ h 1 ] is probed with the merged and the result is produced into output buffer. Similarly, for each block S  X  [ h 2 ], the same operation is repeated. 1. Set two variants PR and PS for MR and MS respectively, with initial values 1, 2. When node E receives a block and inserts it into its corresponding memory, it 3. Before merge join operation of two blocks, we can inspect the two value-4. When a new inserted block R  X  [ h 1 ] in MR wants to probe with some block in 
Block merge join algorithm produces join results in an efficient manner. It is sym-case of network delay, the algorithm merges tuples present in memory while waiting for next coming blocks and avoid shipping blocks between memory and disk. Initially, MR and MS are both empty and PS = PR =1. The following figures explain the process of block merge join algorithm. In this section, we discuss Edge-weight-minimum-matching algorithms by employing some important concepts from Graph Theory , which can be used to solve the problem of replica matching and execution node selection in next section described. Definition 2. A maximal matching in a graph is a matching which cannot be enlarged by adding an edge. It is a matching of maximum size among all matchings in the graph. B , such that all vertices in A are saturated by M . Definition 4. Let matching M be a perfect matching from A to B . Let the weights on W ( n )}, then W ( M i ) is called edge-weight-maximum in M . All edge-weight-maximums in these N perfect matchings from A to B compose a set weight-maximums and called edge-weight-minimum in G . The matching M i is called edge-weight-minimum-matching .
 this weighted complete bigraph, we can get six perfect matchings from R to S, ( R shown in Fig 3. 
By enumerating all the weighted complete matchings in the bigraph G and compar-ing all maximum weights of each matching, we can get the edge-weight-minimum in G and edge-weight minimum matching M . But when the number of matchings in-creases, the problem becomes complicated . How to get the edge-weight-minimum matching M and the edge-weight-minimum in G is a problem worth being studied. Now let us introduce the algorithm for seeking an edge-weight-minimum matching M and an edge-weight-minimum in weighted complete bigraph G. 
The main idea of the algorithm of Edge-Weight-Minimum Matching is: use Hun-garian Algorithm or Ford-Fulkerson's Algorithm to find a maximum matching M found, take away the edge E whose weight is maximum and get a subgraph G 1 = G -E, then continue to find a maximum matching in G 1 ... until a maximum matching could not be found in subgraph of G . Now we describe the algorithm as follows: Input: a bipartite graph G =( R , S ) and the weights of G.

Output: an edge-weight-minimum matching M in G.  X  Rank all the edges of the graph G as e  X  Find a maximum matching M  X  Set k := k + 1 , G := G -e Now let X  X  analyze the time complexity of the algorithm. The time complexity of respectively. So if Hungarian Algorithm is used, the time complexity is  X  (( n + m ) 3  X  n  X  m ), and it is O (( n  X  m ) 2 ) if we use Ford-Fulkerson's Algorithm. R { e R
S 3 =7 is the edge-weight-minimum in G . We can describe the problem of join operation using multiple replicas in data grid as ... result at C . management services in data grid such as MDS in Globus. Also the consistency of The main idea of the proposed algorithm is as follows: 
When we join the two relations R and S , first, we select n replicas from m full rep-licas of S so that each replica of S corresponds to a replica of R . Then by using rela-tion reduction algorithm, these 2n replicas of R and S are reduced. Next, when execu-tion nodes are selected by using matching theory, we ship every reduced relation pair tion is executed by using block merge join algorithm at the selected execution node, join results are transferred to (user) node C in pipeline mechanism. 
Now we describe the phases of algorithm in detail. 4.1 Phase I: Matching for Replicas of R and S n replicas from m replicas of S before the join operation executes. Each selected rep-lica of S corresponds to a replica of R. lated as the maximum of all transfer times. To reduce the total response time, the par-allel transfer time should be as minimal as possible. 
We can model this question as seeking an edge-weight-minimum-matching in edge-weight-minimum-matching is found, then the edge-weight-minimum in G time. 4.2 Phase II: Parallel Hashing the Replicas of R and S by using the same hash function H . If necessary, the number of buckets is set to n  X  k , where k is a natural number. For avoiding data skew, the size of each bucket is kept possibly same by selecting a suitable hash function. 
Ultimately what we get: for each node A i , the replica of R in it is partitioned into n into n buckets S (1) , S (2), ... , S ( n ). executing join operation on R and S . 4.3 Phase III: Relation Reduction Phase R  X ... X  T [ S ( n )]. 
In Section 3, we have seen an edge-weight-minimum-matching M in which R i lo-4.4 Phase IV: Execution Nodes Selection Because data grid can provide coordinate resource sharing and cooperating computa-tion, the resources such as database, CPU, disk, memory and instruments can be ac-tremendous processing capability and smaller network transfer rate, we can select n nodes from these k nodes as execution nodes. Reduced results of R and S are shipped in parallel to n execution nodes for the execution of block merge join operation. 
Selecting n nodes from k nodes as execution nodes is the issue of concern. We can model this problem also as seeking an edge-weight-minimum-matching in weighted complete bigraph as mentioned in Section 3. 
The network transfer rate between nodes A i and E j could be regarded as the weight minimum-matching could be found in G , then the matching shows the node to which A (1  X  h  X  n ). B corresponds to E h (1  X  h  X  n ). 4.5 Phase V: Parallel Bl ock Merge Join Operation S  X  ( i ) are parallel shipped from nodes R i and S i to execution node E i . S  X  merge join operations are executing at nodes E 1 , E 2 , ... , E n . 5.1 Experimental Setup We built a simulation environment and conducted an extensive performance study. All the experiments described in this paper are conducted under Windows 2000 envi-ronments with Pentium 2.4G CPU, 256 MB RAM and 40GB disk space. 5.2 Experiment I In this experiment, the influence of network transfer rate to the proposed algorithm is mainly analyzed. Assume d 1 denotes the network transfer rate between node A i having work transfer rate between node E i and node C , and T j denotes the time taken to trans-fer join result from node E i to node C . is represented as | R  X  ( i ) S  X  ( i )|. S  X  ( i ) are equal. So we can get we can get the following inequality: decrease as well. In the proposed algorithm, we first select the nodes with much selecting the locations of R and S , we select the nodes with smaller network transfer much less than the influence of d 4 and d 2 . 5.3 Experiment II We run this experiment using two methods: the first method represents not using influences to total response time between these two methods are compared. In the first method, relations R and S are not reduced and shipped to execution node E where join ferred to node C . experimental result, we can see that when  X  is much smaller, the time of transferring R  X  and S  X  and the total response time in the second method are much smaller. When  X  reaches a fixed value, the time of reducing relations becomes much more. The re-sponse time of the second method may exceed the response time of the first method. first method is the time cost by using relation reduction algorithm. algorithm can solve the problem of replica matching and execution-node selection by making use of matching theory while keeping in view the heterogeneity of network bandwidth. To introduce parallelism in join process, we have developed and used reduction algorithm, row blocking technique and pipelined mechanism. The analytical and experimental results demonstrate the effectiveness of the proposed join algorithm for the management of data in data grid. There are a lot of problems unsolved in query how to join the relations which are partial replicas, that is, they are composed of some parts in the original data, is a problem. (2) how to solve the order problem in multiple from the cache instead of querying data source again. 
