 Emotion classification from social media (such as Tweet, Sina Weibo) is becom-ing more and more important. Many supervised learning methods have been devekioed to solve this problem. However, supervised methods require a large amount of labeled training data. Obtaining labeled data manually can be quite time consuming and noise prone especially for multi-class annotations such as for subject related emotion annotation. Many research studies take advantage of large amount of text available in the social media to investigate automatic methods to obtain labeled data [1, 7, 10]. In these works, naturally annotated text features such as hashtags, emoticons and emoji characters inserted in tweets are automatically extracted from data and these features are then directly used as labels after some simple rule based filtering. However, these automatically ob-tained labels can be quite noisy. Take the following text as an example,  X   X   X   X   X   X  X  X   X   X   X   X   X   X   X   X   X   X   X   X   X   X  X  X  X  #  X   X  # (When you are not busy, playing with microblog retweet may be fun! #boring#) X  . From the text we can infer that the emotion is  X  X appy X , but the author uses a negative hashtag  X  X oring X . As far as we know, there is not much work to handle hashtag noise problem for emotion classification. Figure 1 shows that directly adding data using hashtag as emotion labels (crawled from Sina Weibo) to high quality training data (from NLP&amp;CC2013) will not improve the system and the per-formance degrades continuously as more naturally annotated data are added. This indicates that if there is no appropriate data cleaning method, naturally annotated data may do more harm than good.
 2nd author's affiliation 1st line of address 2nd line of address seed data and a large amount of unlabeled data to achieve much better perfor-mance, such as S3VMs [14]. Data cleaning, as one kind of SSL, has been used to cope with noisy training data, such as co-training [2] and CoTRADE [5]. However, these methods are mainly used in binary classification. In principle, data using automatically obtained hashtags is not unlabeled data. Rather, it is labeled training data with noise.
 for emotion classification. The main objective is to obtain more high quality labeled data to improve the performance of emotion classification . The main issue in this work is the design of data cleaning strategies to obtain high quality data using natural annotation and to use the data to improve classification performance. The basic idea is to train a classifier initially using high quality data provided through manual annotation and make use of this classifier to predict noisy data. Only data with high confidence through the assessment of the predicted label compared to the original label will be used as the additional training data. As noise can accumulate after several iterations, we also make use of a graph based method to estimate accumulated noise and remove noisy data to ensure the overall quality of added training data. Through this study, we want to answer two questions: (1). Can the automatically extracted data effectively remove noise from the naturally annotated data improve the emotion classification performance? in emotion classification and data cleaning. Section 3 introduces our algorithms and strategies. Section 4 reports the evaluation result. Section 5 gives conclusion and future work. Methods for emotion classification can be categorized into rule based methods and machine learning based methods. The former defines a set of rules to infer the emotion contained in text. The latter employs a set of features (such as BoW, N-Gram, emotion lexicon) to train a classifier based on some annotated train-ing data to predict the emotion of a new piece of text. One issue for machine learning based method is how to obtain sufficient high quality training data. Current released corpora includes weblog[12], news headline[13], which are all manually labeled and thus are quite limited in quantity. Recently, more and more researchers explore distant supervision methods which is based on naturally an-notated labels to automatically build training corpus, such as the microblog that uses naturally annotated emoticon, hashtag and emoji characters as annotated emotion labels. Mohammad takes emotion linked hashtags in tweets for emotion classification and proves that when hashtags are consistent to a degree such that they can be used for emotion detection in tweets [6]. Similar methods is used by Wang to obtain a much larger dataset and experiments show that for some minority emotions (i.e., surprise), the prediction performance is not so good [10]. Furthermore, Mohammad makes use of hashtags to construct an emotion corpus, based on which an emotion lexicon was extracted using PMI and the lexicon is used on another domain for emotion classification [7]. Bandhakavi also makes use of microblog containing hashtags to generate emotion lexicon based on EM with class and neutral model [1]. However, none of them addresses the issue of hashtag noise. Experiments in [10] also show that distant supervision is suitable for some emotions (i.e., happiness, sadness and anger) but less able to distinguish minority emotional labels.
 and CoTRADE [5] which include a noise detection method. Wan proposes a co-cleaning and tri-cleaning data cleaning algorithms on sentiment analysis [11]. Gui employs noisy detection on cross-lingual opinion analysis based on label inconsistency with neighbors [3]. However, all the above works are for binary classification. No attempt is made for multi-class emotion analysis. 3.1 Problem Definition Let ( x i ,y i ) denotes a pair of labeled data where x responding dataset size, respectively. Let us assume that n m . Let C denotes the set of class labels ( C = { c 1 ,c 2 ,...,c C N } ) where c C
N is the the number of classes. Our objective is to develop an algorithm M to extend H with L and improve the performance on T. 3.2 Our Proposed Strategy The basic idea of our proposed method is that a classifier initially trained on H is used iteratively to predict L , and the instances with high confidence will be added as training data to retrain the classifier. Because the added training data contains noise and noise can accumulate, we will also devise a method to remove the added training data whose noise exceeds a certain level. To achieve this goal, two problems need to be solved: (1). How to select instances in L to be added as training data; and (2). How to detect the noise instances that is already included in the training data.
 instances from L , we train a classifier based on H and predict on L and obtain a predicted label y 0 i ( i  X  [ m + 1 ,m + n ]) with a confidence, which can be the classifier X  X  prediction probability. We choose those instances such that y with top n ( c the term confidence means the prediction probability of the classifier. In the experiment, we will see the usefulness of the original label constraint y take into consideration of the naturally imbalanced data in emotion corpora, we also control the number of added instances for each class. For the class c the least number of instances in H , we set the added instance number to H in each iteration as n a . Then, for other class c j , we set the added number using the following formula: is to make the data to be more balanced. Because of the imperfection of the classifier, noise in y i can accumulate. To detect the noisy label, we use a k-NN graph based method. Given an added instance x i ,y i G = { V,E,W } is constructed from H + L 0 , where the nodes are instances in H + L 0 and the edge weights are the similarity between instances in the feature space. Based on the manifold assumption that instances with high similarity in the feature space will have similar labels [15], we can measure the inconsistency between two instances based on the similarity in feature space and the difference in the label space. For each pair of ( x i ,y i ) and its neighbor ( x we compute the edge weight  X  ij by: Similarity functions sim ( x i ,x j ) can be constructed in many different ways, in-cluding distance based similarity and cosine similarity between the feature vector representation of two samples. In this work, we simply use cosine similarity as in [3]. For each pair, we define the inconsistency between any two instances to similarity in the label space, which can be calculated as: where D c i c j is the distance between label class c i and c same non-zero label distance, the more similar they are in the feature space, the more inconsistent between the two instances. When the label distance is zero, the inconsistency is zero. D c i c j is defined in the class distance matrix M with each entry d ( p,q ) being the distance between class p and class q because the probability of a mislabeling between different classes is different. For exam-ple, the emotion class  X  X nger X  is more likely to be labeled as  X  X adness X  than  X  X appiness X  , so d ( anger,sadness ) &lt; d ( anger,happiness ). Each emotion can be expressed in the valence-arousal coordinate [4]. Based on the emotion point in the valence-arousal coordinate, we can obtain their corresponding distances. Then we use the following formula to compute the label inconsistency for each vertex i : where i refers to the center vertex and j refers to the neighbor of i and k is the parameter of k-NN, the number of selected most similar neighbors of node i . The more similar they are in the feature space and the more distant in label space between the vertex and its neighbors, the larger the error is for the label. When J i exceeds a certain threshold J thresh , we consider it a noisy label and remove it from the training set L 0 . Here we assume J i follows the Gaussian distribution and use the high quality dataset H to estimate its mean and variance. For each sample ( x i ,y i ) in H we compute its J i using (2) and finally we obtain the mean and variance of J as  X  J and  X  J . Then J thresh can be estimated by: where a is the parameter to control the removal extent. Here we set a = 2 because based on Gaussian distribution, the probability of J 0.023, which is a small probability event and thus we have sufficient confidence to consider it as a noisy label. Since different classes will have different  X   X 
J because of data imbalance, we compute J thresh separately for each class. The algorithm is shown in Figure 2 . The iteration in line 3 is used to control when noise removal will be executed. 4.1 Experiment Setup To evaluate our proposed approach, we take the high quality training data from the benchmark of NLP&amp;CC 2013 Chinese Microblog Emotion classifica-The dataset has eight labels: like , disgust , happiness , sadness , anger , surprise , fear and none . There are 4,000 training instances and 10,000 testing instances in the dataset extracted from Sina Weibo, a popular Chinese version microblog social network like Twitter. All these data are manually labeled. Thus, we treat them as high quality data and assume that the labels in these datasets are ground truth. Since  X  X one X  class data cannot be obtained through hashtag, so we merge testing dataset. Finally we obtain 7,304 high quality labeled data and the data is divided into training and testing data using 1:1 keeping the same proportion of each class.
 using a list of seed words as hashtags (called  X  X uati  X   X  such as  X   X   X  (sad) X  ,  X   X   X  (helpful) X  . The detail of the seed word list is shown in Table 1 . After manually assigning these seed words into the seven emotion categories, we mined 173,951 microblogs and clean the posts in the original data through the following rules: (1). Hashtags not at the beginning of ending of mi-croblog; (2). Text containing more than one hashtags; (3). Duplicated text; (4). Converting traditional Chinese into simplified Chinese; (5). Texts not contain-ing Chinese word; and (6). Text length after removing hashtag less than five. After the above cleaning, there are 48,305 microblogs left as our additional noisy training data. The statistics of the noisy data (L) and high quality labelled data (H) are shown in Table 2 . Note that the data imbalance in the datasets is quite obvious. Take H as an example, the ratio of the largest label set to the smallest label set is over 14.29 (like vs fear).
 toolkit 5 with default parameters. Features used are bag of words and lexicon from a Chinese emotion lexicon DUTIR 6 . For evaluation, we use macro F-score. Parameter k for k-NN is set to 9 empirically and n a is set to 5. 4.2 Result and Analysis The first experiment is to test the performance of our proposed algorithm. We label this algorithm as A + O + R + , which means A dding instances with O riginal noisy label information (with y 0 i = y i constraint) and with noisy instances R emoval based on the algorithm in Table 2 . For comparison, we use the fol-lowing methods that use different addition strategies for comparison: 1. A + O  X  R  X  It adds instances by classifier confidence but without the original 2. A + O + R  X  : It adds instances by classifier confidence with original noisy label 3. A + O  X  R + : It adds instance by classifier confidence with noisy instances re-4. A  X  O + R  X  : As mentioned in introduction part, it directly adds the noisy 5. A  X  O  X  R  X  : This is the reference performance of the original high quality dicates the performance of the original algorithm without using any additional data. It is flat as it does change on the value in the x-axis. This serves as the yardstick to see whether additional training data is any good. Note that the three algorithms, A + O  X  R  X  ,A + O  X  R + ,A  X  O + R  X  are all below A means they are no good. By examining them in more details, we can see they used noisy data either without natural label constraint or without noise removal. This clearly indicate that without noise removal, the additional data should not be used at all. Among the three methods, A + O  X  R  X  achieves the worst result, indicating that using noisy data directly has severe adverse effect. It also indi-cates that emotion classification from microblog is more complex because of its informality. A + O  X  R + also does not use the original label information, but its performance is a little better than A + O  X  R  X  because of noisy instances removal. A  X  O + R  X  uses only the original hashtag label of the noisy data without any inspection. It still performs better than A + O  X  R  X  and A On the other hand, both A + O + R  X  and A + O + R + achieve similar increasing performance, much better than the baseline. The performance of A dicates that hashtags are useful even if noise removal is not conducted. However, A + O + R  X  degrades as iteration number increases because noise can accumulate once the iteration number increases. The performance of A performer as it is more stable. The number of added instances under different iteration number is shown in Figure 4 , which shows that the added instance number of A + O + R  X  continuously increase while A + O + speed because some noisy instances are removed. This further indicates that A + O + R + achieves comparative performance with less additional data com-pared to that of A + O + R  X  .
 data L 0 by different strategies into the original training data H , that is the classi-fier trained on ( H + L 0 ), which is given in Table 3 . Note that we focus on testing the effectiveness of the proposed noise filtering algorithm, so the added number is different for different strategies, as is given in Figure 4 . A improvement than the original training dataset ( H ), similar to A with less data. The other three strategies all have worse performance compared to the baseline because of the added noise.
 ( L 0 ) by different strategies. That is the performance of a classifier trained only on L 0 compared with classifier trained on the original high quality data H, given in Table 4 . Compared to H , A + O + R  X  achieves the best performance in all the noise data selection method, followed by A + O + R + with very close performance. And they achieves 15.8% better performance than directly adding hashtag data ( A  X  O + R  X  ). A  X  O + R  X  is better than A + O  X  R  X  and A classifier.
 Firstly, hashtags cannot be directly used as labels because of noise. Secondly, noisy data can be effectively cleaned by our proposed approach to improve the performance of multi-class classification based on our experiments. In this paper, we present a framework on automatic noise removal for naturally annotated data using hashtags for emotion classification. Experiments show that hashtags are useful but naturally annotated data contains noise so they cannot be used directly without any cleaning. Our proposed algorithm combines the classifier and hashtag to effectively filter out noise to obtain more high quality data. The k-NN graph based noise removal method can further stabilize this pro-cess. Evaluation on NLP&amp;CC2013 Chinese Weibo emotion classification dataset shows that our approach achieves 15.8% better performance than directly using the noisy data without noise filtering. After adding the filtered data with hash-tags into an existing high-quality training data, the performance is increased by 3.7% compared to using the high-quality training data alone. Our method paves the way towards a more scalable training data for emotion classification from microblog. Our future work will focus on how to use the filtered data to further improve the performance of emotion classification. We give our thanks to the anonymous reviewers for the helpful comments. The work presented in this paper is supported by Hong Kong Polytechnic University (PolyU RTVU and CERG PolyU 15211/14E) and the National Nature Science Foundation of China (project number:6127229).
