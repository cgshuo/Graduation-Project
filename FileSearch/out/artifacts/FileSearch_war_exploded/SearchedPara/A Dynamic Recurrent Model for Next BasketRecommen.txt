 Next basket recommendation becomes an increasing con-cern. Most conventional models explore either sequential transaction features or general interests of users. Further, some works treat users X  general interests and sequential be-haviors as two totally divided matters, and then combine them in some way for next basket recommendation. More-over, the state-of-the-art models are based on the assump-tion of Markov Chains (MC), which only capture local se-quential features between two adjacent baskets. In this work, we propose a novel model, Dynamic REcurrent bAs-ket Model (DREAM), based on Recurrent Neural Network (RNN). DREAM not only learns a dynamic representation of a user but also captures global sequential features among baskets. The dynamic representation of a specific user can reveal user X  X  dynamic interests at different time, and the global sequential features reflect interactions of all baskets of the user over time. Experiment results on two public datasets indicate that DREAM is more effective than the state-of-the-art models for next basket recommendation. Next basket recommendation; recurrent neural network
In real-world scenarios, a customer always purchases a series of baskets of items at different time. This recommen-dation task in e-commerce sites is formulated as the next basket recommendation, which has received much attention recently [1, 3].

In general, there are two distinct approaches for next bas-ket recommendation. One perspective is the collaborative filtering (CF) models, which capture users X  general inter-ests but have difficulty in considering sequential features of The first two authors contributed equally to this paper. historical transactions. Matrix factorization (MF) is a suc-cessful CF model [4]. Through factorizing a user-item ma-trix constructed by the whole historical transaction data, users X  general interests can be represented by latent vec-tors. For instance, a sportsman always buy various athletic equipment, the latent vector may tell that he is interested in sport and we can recommend sports items. Moreover, some sequential recommendation models mainly based on MC [2], which extract sequential features from historical transactions and then predict next purchase based on these sequential behaviors.

As a consequence, a more appropriate way to next basket recommendation is to capture above sequential behaviors and user general interests in a hybrid model. Factorizing Personalized Markov Chains (FPMC) can model sequential behaviors between every two adjacent baskets, and user gen-eral interests is shaped by items in baskets [7]. Actually there are multiple interacting factors influencing users X  next purchase in real commercial scenarios. FPMC just utilizes a linear operation on multiple factors, and cannot depict the interactions among multiple factors. Hierarchical Represen-tation Model (HRM) seems to partially solve the problem of how to summarize multiple interacting factors through a nonlinear max pooling operation [9]. Nevertheless, all the MC based methods (including above FPMC and HRM) have the same deficiency that these recommenders can only model local sequential behaviors between every two adjacent bas-kets, and some of which may be irrelevant sometimes. For instance, a user u bought a ultrabook in basket B u t 1 (a basket of user u at time t 1 , similarly hereinafter), some food in B and accessories of the ultrabook in B u t 3 , there does not exist any relevance between every two adjacent baskets. Hence, we need to model global sequential behaviors to make the best of all relations among sequential baskets like the above B 1 and B quential features among all sequential baskets of a user.
In order to mine global sequential features in complex commercial scenarios and reveal dynamic representations of users X  interests, deep neural network is employed in this work. As stated above, local sequential features extracted by HRM is not capable enough to model relations among apart baskets, while a recurrent operation of a deep RNN architecture can capture global sequential features from all baskets of a user. Recently, RNN approaches to word em-bedding for sentence modeling [5], sequential click prediction [10] have achieved much success in respective fields. We pro-pose a dynamic recurrent model, i.e., DREAM, for next bas-all items. ket recommendation. An input instance of DREAM model consists a series of baskets of items, which are sequential transactions of a specific user. Pooling and matrix opera-tions can offer each user a dynamic representation with dif-ferent baskets over time. Moreover, the recurrent structure can obtain some global sequential features for all users from overall historical transaction data. Our experiment results on two real-world datasets reveal that the DREAM model achieves great improvement for next basket recommendation comparing with the state-of-the-art models such as FPMC, HRM.

In this work, we take advantage of the whole historical sequential transaction data to gain comprehensive under-standing of users X  purchase interests and consequently rec-ommend items that each user most probably purchase in the next visit. The main contributions of this work are as follows. We investigate the dynamic representation of each user and the global sequential behaviors of item-purchase history. Experiments on two datasets are conducted to val-idate the effectiveness of DREAM model. To the best of our knowledge, DREAM is the first approach that attempts to incorporate dynamic representation and global sequen-tial behaviors for enhancing the performance of next basket recommendation.
In this section, we formulate the task of next basket rec-ommendation and then introduce the proposed DREAM model in detail.
In the scenario of next basket recommendation, there are a mass of users, and each user purchases a series of baskets of items. Let N be the representations of items, and n v R d indicates the latent representations of item v . For a user u , the historical transactions B u are composed of a collection of baskets { B u t 1 ,B u t 2 ,... } in time order, where B is a basket of items purchased by user u at time t i . For next basket recommendation with historical transaction data, we formalize the problem as predicting a ranking list of items for each user at a specific time t i .
The general framework of DREAM is illustrated in Figure 1. An input instance of the proposed model are a sequence of baskets. For one basket B u t i of the user u , there are a variety of items, B u t i = n u t i ,j  X  R d | j = 1 , 2 ,..., B is the latent representation of the j -th item in basket B
B t i means the number of items in basket B u t i . Now, we can generate the latent vector representation b u t i for a basket B by aggregating representation vectors of these items. In this work, we adopt two kinds of aggregation operation, i.e., max pooling and average pooling .

For the max pooling operation, we aggregate a group of vectors through taking the maximum value of every dimen-sion among all those vectors. Then each dimension of b u formulated as where b u t i ,k is the k -th dimension of a basket-representing vector b u t i , n u t i ,j,k means the value of k -th dimension of the vector representation of the j -th item ( n u t i ,j ) in basket B
The average pooling is a similar operation but replaces maximum with average. In other words, the average pooling is to aggregate a group of vectors through taking the average value of every dimension of all those vectors, which can be formulated in a similar way as These above representations of baskets can form the input layer of a recurrent architecture.

As is shown in Figure 1, the vector representation of a hidden layer h u t i is the dynamic representation of user u at time t i . The recurrent connection weight matrix R helps to propagate sequential signals between every two adjacent hidden state h u t i  X  1 and h u t i [10]. X is a transition matrix between latent vector representations of baskets and a user X  X  interests. Then, the vector representation of the hidden layer can be computed as: where b u t i is a latent vector representation of the user X  X  bas-ket at time t i , and h u t i  X  1 is the dynamic representation of the previous time t i  X  1 . f ( x ) is a activation function, here we choose a sigmoid function f ( x ) = 1 1+ e  X  x . Finally the model can output a user X  X  scores o u,t i towards all items at time t The output o u,t i can be calculated through multiplication of item matrix N and a user X  X  dynamic representation h u t which is formulated as follows: Therefore o u,t i ,v , i.e., an element of o u,t i , represents the score of a transaction between a user u and an item v at time t i . A higher score indicates that the user is more likely to purchase the corresponding item. In the learning process of DREAM, we adopt Bayesian Personalized Ranking (BPR) [6]. BPR is a state-of-the-art pairwise ranking framework for the implicit feedback data. The basic assumption is that a user prefers an item in basket at a specific time than a negative item sample. The negative items can be any other items apart from those in the basket. In this way, we need to maximize the following probability: where v 0 denotes a negative item sample, and  X  ( x ) is a non-linear function which is chosen as  X  ( x ) = 1 1+ e  X  x . Adding up all the log likelihood and the regularization term, the objective function can be written as follows: where  X  = { N , R , X } denotes all the parameters to be learnt,  X  is a parameter to control the power of regulariza-tion. Furthermore, the objective function can be optimized by Back Propagation Through Time (BPTT) [8]. BPTT is to iteratively repeat the calculation of derivations of J with respect to different parameters and obtain these gradients of all the parameters in the end. Then we update parameters utilizing Stochastic Gradient Descent (SGD) until converge.
Notice that the DREAM model utilize an iterative method in learning users X  representation vectors. That is to say, for any new transactions, we can update users X  representation vectors based current ones. Some state-of-the-art models, such as HRM, need to factorize a new built user-item ma-trix to get users X  representation vectors. Therefore this iter-ative learning method may be more practical in real-world applications.
To evaluate the performance of our method on the task of next basket recommendation, we perform experiments on two real-world datasets, i.e., Ta-Feng 1 and T-mall 2 Ta-Feng dataset contains numerous baskets of purchased items from a grocery store, where each basket encapsulates the items purchased by one user in a period of time. This dataset is a public dataset which contains 817,741 transac-tions belonging to 32,266 users and 23,812 items. The T-mall dataset is a public online e-commerce dataset released http://recsyswiki.com/wiki/Grocery shopping datasets http://102.alibaba.com/competition/addDiscovery/index.htm by Alibaba group 3 , which contains 4,298 transactions of 884 users and 9,531 brands. The slight difference between these two datasets is that the T-mall dataset records the transac-tions based on brands and each brand may covers a series of items. The above datasets are preprocessed to obtain k -core subsets [7], i.e. each user u purchased in total at least k items P t chased by at least k users. We set k = 10 for the Ta-Feng dataset, and k = 3 for the relatively smaller T-Mall dataset.
Several baseline and state-of-the-art methods on next-basket recommendation are used for empirical comparison. (1) TOP recommends the top popular items to each user. (2) MC is a Markov chain model based on sequential trans-action information of a user. The prediction function is as follows: (3) NMF is a collaborative filtering method, which applies Nonnegative Matrix Factorization over the user-item matrix. For implementation, we adopt the released codes from NMF: DTU Toolbox 4 . (4) FPMC [7] is a hybrid model combin-ing MC and MF for next basket recommendation, which can capture both sequential effects and general interests of users. (5) HRM [9] is a state-of-the-art hierarchical repre-sentation model, which can capture general users X  interests and sequential effects. Besides, with various nonlinear op-erations, HRM can capture all those factors more properly than previous models. Figure 2: Experiment Results of different methods on two datasets. http://www.alibabagroup.com/cn/global/home http://cogsys.imm.dtu.dk/toolbox/nmf/
For recommendation, we generate a ranking list of K items ( K = 5) for each user u . In order to measure the performance of next basket recommendation, we adopt two evaluation metrics, i.e., F 1-score and Normalized Discounted Cumulative Gain ( NDCG ). F 1-score calculates the har-monic mean of the precision and recall measurements. NDCG is a cumulative measure of ranking quality, which is more sensitive to the relevance of higher ranked items. For both metrics, the larger the value, the better the performance.
On both datasets, we use the last transaction of each user as the testing data and all the rest transactions as the train-ing data. The vector representations of items are randomly initialized. Moreover, performance results of different meth-ods are compared along with varying dimensions d of the representation. We illustrate the results with dimensions { 50, 100, 150 } for the Ta-Feng dataset, and { 10, 15, 20 } for the relatively smaller T-Mall dataset.
First, the performance of DREAM model are compared with the state-of-the-art methods. As illustrated in Figure 2, in general, the performance ranking of next basket recom-mendation methods is as follows, DREAM, HRM, FPMC, NMF, MC and TOP. Since the baseline TOP just list the popular items and does not utilize the features of separate baskets, this method is the weakest one among all meth-ods. Despite the fact that NMF and MC leverage only one kind of feature, either sequential behaviors or users X  general interests, we can observe that the NMF model achieve bet-ter performance than that of the MC model, especially on the sparse T-mall data. It may be because that MC cannot reveal the collaborative information among users. On the sparse user-item matrix of T-mall, collaborative information is more important to generate the accurate interests of users than the sparse sequential behaviors. On both datasets, the HRM model outperforms the FPMC model. Though FPMC and HRM both utilize sequential behaviors, the nonlinear operations among multiple factors of HRM earn it a better performance, while the FPMC model X  X  linear independence assumption of interaction relationship of items in a basket makes it inapplicable in complex commercial scenarios. The proposed DREAM model can consistently outperform all comparing models in terms of both metrics on two datasets. These results show that the dynamic representation of user with a recurrent architecture is effective in capturing se-quential features and dynamic interests of users. Besides, richer nonlinear operations such as pooling and activation functions contribute to a better representations of baskets.
Then, we assess performances of the DREAM model with max pooling and average pooling . As illustrated in Ta-ble 1, DREAM with max pooling can outperform DREAM with average pooling on both datasets with F 1-score @5 and NDCG @5. It demonstrates that max pooling gains advan-tage over average pooling in modeling interactions among multiple factors. Obviously, as a linear operation, average pooling takes an average representation of a basket, indi-cating that each item in a basket measures the basket rep-resentation in an independent way. In real-world scenario, many items we purchase are interactive, that is to say, one item influences whether we purchase another item, then the whole items we purchase can help shape our interests. Con-sequently a better solution is to learn the elaborate interac-tion relationship of a basket of items through a nonlinear op-eration. Max pooling is a nonlinear operation, which takes a key representation of a basket and is more capable to learn those complicated interactions than a linear operation.
In this paper, we have proposed a dynamic recurrent bas-ket model based on RNN for next basket recommendation. Our model can merge users X  current interests and global se-quential features into users X  recurrent and dynamic represen-tation. Moreover, it shows that the nonlinear operation on learning the representation of a basket does well in captur-ing elaborate interactions among multiple factors of items. Extensive experiments on two public datasets demonstrated the effectiveness of the proposed model. This work is jointly supported by National Basic Research Program of China (2012CB316300), and National Natural Science Foundation of China (61403390, U1435221, 61525306).
