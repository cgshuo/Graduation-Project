 Memory-based collaborative filtering (CF) is a popular method to predict user X  X  prefe-rence. The key step of memory-based CF is the calculation of similarity between users or prediction accuracy. Biyun Hu et al. [1,2] introduced the psychometrics model into memory-based CF to alleviate this problem and achieved better results. However, they because user usually has interests in many aspects or fields. On the other hand, they uses Off-the-shelf software package  X  Winsteps [3] to learn the parameters, which limits its algorithm based on multidimensional psychometrics model (CFMPM) is proposed. The parameters are estimated by stochastic gradient descent method. 
The rest of this paper is organized as follows. Section 2 describes the psychome-trics model. In section 3, CFMPM is introduced. Two experiments are designed and analyzed in section 4, followed by conclusions in section 5. In psychometrics, latent trait models also known as item response theory, are a series of mathematical models for measuring examinee X  X  latent trait, such as ability, interest or attitude by his or her response to one question/item or more. Traditional latent trait model was proposed by Rasch [4] in 1960, which can be expressed as Eq. (1). where, B u is the ability value of examinee u , and D i is the difficulty value of question p ( r ui =0) is the probability that examinee u will get a failure on question i . Traditional Rasch model can only deal with binary values (success or failure, usually coded by 1 or 0). Andrich [5] extended Rasch model to handle multivalued scores, which is called rating scale model. It can be expressed as Eq. (2) and (3). parameters need to be estimated. In this section, we will extend psychometrics model from one dimension to multi-dimension. Based on that, a novel CF model and a parameter learning method are proposed. And then, the workflow of the algorithm is described. 3.1 Collaborative Filtering Based on Multidimensional Psychometrics Model In rating scale model expressed by Eq.(2), user X  X  ability B u and item X  X  difficulty D i are scalar quantities, which denote the user X  X  interest and the item X  X  quality in CF [1,2] respectively. However, it is more reasonable to represent user X  X  interest and item X  X  quality by vectors. Based on this idea, the psychometrics model is extended to multi-dimension, which is expressed as Eq. (4) and (5). D dimension l , and it has a smaller probability to get a high rating in dimension l , and F k is the ordered threshold measuring the difficulty for all users to give k points relative to give k -1 points to an item. Each item has K-level ratings. In MovieLens 1 data set, K is set to 5. L is the number of dimensions which denotes the number of latent inter-ests/demands each user has, and it is a meta-parameter, which should be set in ad-vance. If L is set to 1, this model will degenerate into the model represented by Eq. (2). B ul , D il , and F k are parameters need to be estimated. For easy description, a nota-tion  X  k is introduced, and then Eq. (6)-(8) can be deduced from Eq. (4)-(5): In Eq. (8), it can be seen that the rating of user u for item i in dimension l is of multi-by Eq.(9). After that, the rating value of user u for item i can be computed by Eq.(10). where  X   X  X  X   X 0 , which denotes the weight of user u in dimension l , and it represents training set. 3.2 Parameters Learning Method In order to learn the parameters, the loss function is designed as Eq. (11). where Tr denotes the training set. The first term on the right side of the formula is the applied to parameters to avoid over-fitting. The regularization constants  X  1 ,  X  2 ,  X  3 , and  X  can be determined by cross validation. 
We use stochastic gradient descent method [6] to learn the parameters. Each rating r in training set Tr is used to update the parameters according Eq. (14)-(17). Parame-tion, notations e ui and  X  juil are introduced. 3.3 Workflow of the Algorithm The pseudo codes of algorithm CFMPM are shown in figure 1. In the two experiments in the algorithm, the ratings in test set can be predicted by Eq. (10). The MovieLens 100k data set is used to evaluate the algorithm CFMPM. 4.1 Comparison with One-Dimensional Psychometrics Model Based CF To compare CFMPM with the CF algorithms based on one-dimensional psychome-trics model which are proposed in [1, 2] (denoted by Alg1 and Alg2), 5-fold cross validation was done. In this experiment, the interest dimensionality L is set to 25, and when the difference of MAE on the training set between two consecutive iterations is less than 0.00005, the iteration is terminated. Comparison results are shown in table 1. 
Although the MAE of CFMPM is not significant lower than that of Alg2, Alg2 fuses memory-based CF and computes all similarities between every two users and thus its scalability is decreased. So, it means that extending psychometrics model from one dimension to multi-dimension is helpful. 4.2 Comparison with Other Stat e-of-the-Art Algorithms To consistently compare algorithm CFMPM wi th the state-of-the-art CF algorithms reported in [7,8], as they did, we also extract a subset which contains 1000 items and 500 users from MovieLens data set, where each of the users has more than 40 ratings (data density is 10.35%). The first 100, 200 and 300 users in the data set are selected ML_200 and ML_300. But for different training sets, the test set is fixed, i.e., it is set with the last 200 users. In order to evaluate the performance of the algorithm in dif-ferent data sparsity level, we also randomly selected 5, 10 and 20 ratings of the test users into the observed set, and they are named Given5, Given10, and Given20 respectively, while the other ratings of the test users constitute the held out set. 
Dimensionality L in CFMPM is set to 20, and the iteration times is set to 10. As it is done in [7], for every training set on every sparsity level, the observed data set of test users are randomly selected 10 times. The reported results in table 2 are the average results over 10 times. From table 2, it can be seen that CFMPM almost out-performs all the other algorithms on every training set at every data sparsity level. Rating an item for a user is a psychological process. Thus, studying psychology mod-els for the purpose of CF is meaningful. The algorithm CFMPM demonstrates this point. Moreover, CFMPM can be fused in other method to improve the performance further. Meanwhile, when we increase the dimensionality L , usually we can get a decreased MAE, but if the L is increased further and further, the MAE will increase, and the parameters must be tuned more carefully to avoid over-fitting, so, how to choose the dimensionality automatically is a problem we will study in future. Acknowledgement. This work was supported by the National Natural Science Foundation of China [No. 60973105, 90718017, 61170189, and 61202239], the Research Fund for the Doctoral Program of Higher Education [No. 20111102130003] and the Fund of the State Key Laboratory of Software Development Environment [No. KLSDE-2011ZX-03]. 
