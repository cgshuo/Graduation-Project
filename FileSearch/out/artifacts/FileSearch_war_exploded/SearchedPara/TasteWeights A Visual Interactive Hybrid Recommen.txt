 This paper presents an interactive hybrid recommendation system that generates item predictions from multiple social and semantic web resources, such as Wikipedia, Facebook, and Twitter. The system employs hybrid techniques from traditional recommender system literature, in addition to a novel interactive interface which serves to explain the recom-mendation process and elicit preferences from the end user. We present an evaluation that compares different interactive and non-interactive hybrid strategies for computing recom-mendations across diverse social and semantic web APIs. Results of the study indicate that explanation and interac-tion with a visual representation of the hybrid system in-crease user satisfaction and relevance of predicted content. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  relevance feedback ; H.5.2 [ Information Interfaces and Presentation ]: User Interfaces X  graphical user interfaces (GUI), user-centered design User Interfaces, Visual Knowledge Representation, Hybrid Recommender Systems, Data Integration, Social Web Algorithms, Design, Experimentation, Human Factors
The social web has become the dominant modality for dis-tribution of media and collection of user-provided content such as text articles, feedback ratings, and comments for in-stance. Recommendation systems play an increasingly im-portant role in this domain as they serve to filter and refine a user X  X  information space according to their personal tastes and current requirements. However, social web APIs and other data sources are constantly evolving, and traditional recommender system techniques such as automated collab-orative filtering (CF) [9, 16] need to adapt to the changing data environment on the social web. For example, the tra-ditional approach of pre-processing a large, static database of user ratings to produce a correlation matrix (i.e: the Net-flix approach) to finding recommendation partners, can not be applied to user preference data on Facebook because of privacy restrictions in their API. However, we demonstrate that with some adaptation to the CF algorithm, Facebook data can still be effectively harnessed to produce useful per-sonalized recommendation in a collaborative manner.
We make the following contributions addressing the chal-lenges of evolving and emergent data sources for recom-mender systems: We present two enhancements of tradi-tional recommendation processes. First, a novel and syn-ergistic approach to combining predictions from multiple sources on the social web, such as social (Facebook), content-based (Wikipedia) and expert-based (Twitter) recommenda-tions. Second, a novel interactive user interface which serves to both explain the provenance of recommended content in a transparent manner, and to elicit preference data and rel-evance feedback from users at recommendation time.
To evaluate our approaches, we introduce TasteWeights , a hybrid music recommendation system with an interactive interface, allowing users to both understand and control as-pects of the recommendation process that would otherwise go unnoticed. Figure 1 shows a snapshot of the interface, highlighting three social web context sources with a variety of weighting options, along with item recommendations on the right side of the interface. A video demonstration of the system can be watched at 1 . Using this system, a user eval-uation was performed with 32 participants. The evaluation used participants X  own social connections and music prefer-ence data. The study addressed the following core questions:
While the TasteWeights system (Figure 1) is capable of recommending any media content listed in a Facebook pro-file, such as books, TV shows, and movies, recommendations
TasteWeights video demo: http://bit.ly/TasteWeights described in this paper were restricted to music items in or-der to reduce complexity in our evaluations.
Figure 1 shows a screenshot of the TasteWeights music recommender system. The system is organized into three distinct layers and computational steps. 1. Profile Layer : This leftmost layer contains the user X  X  2. Context Layer : The central or  X  X ontext X  layer contains 3. Recommendation Layer : The rightmost layer contains
As the system X  X  name, TasteWeights , implies, users are en-couraged to adjust their tastes via interactive slider-weights and other UI components. While a user drags a slider, weights of the items connected via outgoing links change accordingly in real time. For example, in Figure 1, as the user drags a slider for  X  X ink Floyd X  to the right, the value of  X  X nglish Rock Music Groups X  increases simultaneously and so also do the values of  X  X eatles X ,  X  X olling Stones X ,  X  X adio-head X , and  X  X asis X . Section 4 describes our design decisions and methodologies in detail.
Research related to this work falls into the categories of hybrid recommender systems and the role of interaction and visualization for recommendation systems in general.
Traditional recommender system techniques such as col-laborative filtering (CF) [9, 16], content-based [11, 6], and knowledge-based filtering [17], each have unique strengths and limitations. For example, CF suffers from sparsity and cold start problems [16], while content-based approaches suffer from narrowness and require descriptions. However, a hybrid approach can use one approach to make predic-tions where the other fails, resulting in a more robust rec-ommender system [12]. Burke [4] proposes a taxonomy of hybrid systems. For example, recommendation algorithms can work in parallel before combining their results, may be pipelined such that the output of one algorithm is the in-put of the next, or may be combined into one monolithic algorithm. TasteWeights falls into the parallelized design class, since our approach firstly generates predictions from individual recommender system techniques, then applies a hybridization strategy afterwards.
The focus of this paper is on a visual, interactive inter-face that supports control of a hybrid recommender system. Through visualization we are creating an  X  X xplanation in-terface X  for our recommender system, and, moreover, allow-ing the end user to control aspects of the hybridization and other elements in the recommendation process through a simple informative and interactive interface [19]. A promi-nent work in this area is Herlocker X  X  study of recommen-dation explanations [9]. Herlocker et al. evaluate a  X  X hite box X  conceptual model of recommendation as opposed to the run-of-the-mill black box approach. They present a user study where 21 different recommendation interfaces are pre-sented to users, explaining various types of internal infor-mation from the recommender algorithm. Their general findings agree with Middleton X  X  [13], in that  X  X xplanation interfaces lead to improved acceptance of a predicted rat-ing. X  Herlocker X  X  work highlights justifications for explain-ing recommendations through some form of interface, and those justifications also apply in our design decisions for the TasteWeights recommender system. According to Her-locker, explanatory interfaces:
In addition to these roles of an explanation interface, we posit that interaction can further aid in the recommendation process, namely by:
Previous work focused on interactive visualization of genre information to elicit preference-feedback from users to en-hance the quality of movie recommendations generated from a large scale data set [15, 14]. Gretarsson et al. X  X  Small-Worlds system [7] explored the effect of interactive visual-ization for a movie recommendation system. They found that an interactive interface helped produce more accurate recommendations and increase user acceptance of the pre-dictions. The unique contribution in this work is an analysis of factors across both hybrid recommendation systems and interactive explanatory interfaces.
Following Herlocker X  X  guidelines in [9], TasteWeights was designed to improve the user X  X  understanding of how the hybrid recommender system works under the hood. Burke Figure 2: Additional info shown when an item gets clicked: (a) profile, recommendation, or Wikipedia item (b) Facebook friend (c) Twitter expert [4] suggests that recommender systems have three distinct parts: input, background, and suggestions. TasteWeights follows a similar design structure, as shown by the three columns in Figure 1. Multiple UI controls allow users to fine-tune their preferences and receive real-time feedback on how their actions affect the output. Users are able to tweak the underlying algorithms by changing weights associated with individual items (Figure 1(a)). As the user moves a slider as-sociated with a weight, they can see how that change affects the system as a whole. Individual items are enhanced by additional information when clicked, in a detail-on-demand fashion [18]: profile, recommendation, and Wikipedia items are accompanied by an image and abstract, Facebook friends are shown with their profile photos and music profiles, and Twitter experts are accompanied by their items of expertise (Figure 2). On a larger scale, users are able to express their relative trust in each context source by manipulating a slider for each context source (Figure 1(d)). The system provides dynamic recommendation feedback in real time while these interactions are being performed.

To emphasize the hybridity of the system, distinct colors for each context source are used as visual cues. The opac-ity of each context source box changes proportionally with the weight of the source expressed through its source slider. Any edges connected to a context source item inherit the context source X  X  color. The context column usually cannot fit within the screen. To handle this, we have developed two UI features: a slider allowing to resize the visible portion of the context source (Figure 1(e)), and a scrollbar reveal-ing current position within the column and expressing the relative source size through color coding (Figure 1(f)).
TasteWeights is a general solution that can be applied to a wide range of data sources on the social web. For our eval-uation we have chosen three popular social APIs which re-late to three different core recommender system techniques: Wikipedia (content-based / semantic), Facebook (collabora-tive / social), and Twitter (expert-based).
Wikipedia is the most popular community-driven online encyclopedia, consisting of millions of user-provided articles, some of which are templatized and contain both free text and more structured, tabular data. We query Wikipedia for articles and categories that are most relevant to the user X  X  music profile. The results are presented in the top part of the middle (context) layer in Figure 1. We find rele-vant Wikipedia articles indirectly through DBpedia [1, 2], a semantic web resource that crawls structured data from Wikipedia and organizes it into a database that is queryable through a SPARQL endpoint 2 . The database is an RDF store of subject-predicate-object triples. Subjects and ob-jects correspond to Wikipedia articles and each predicate is a labeled link between two articles. For example, the band  X  X 2 X  is linked to the music genre  X  X lternative Rock X  via a link labeled  X  X enre X . TasteWeights leverages Wikipedia by mapping music items in a user X  X  profile to actual Wikipedia articles. For example,  X  X ink Floyd X  profile item corresponds to http://en.wikipedia.org/wiki/Pink_Floyd ).
Facebook is the world X  X  largest online social network with over 800 million active users in April 2012 3 . Although their API is limited by privacy restrictions, some music preference data is still accessible from direct friends of a user who is authenticated to the API. Facebook music preference data is used to bootstrap the TasteWeights system. The user X  X  music profile items all map to specific pages that represent the artists. In the context layer of Figure 1, Facebook items are a user X  X  friends who have at least one liked item in com-mon with the user, i.e. have similar tastes to the user. This data is mined through the Facebook Graph API 4 . Twitter is a popular Social web microblogging service. Users can upload short text  X  X weets X  through a variety of ap-plications and devices. Twitter is commonly used for propa-gation of news events and for following expertise on various topics. Accordingly, we incorporate this service to produce expert-based recommendations for our TasteWeights sys-tem. Specifically, a user X  X  music profile items can be mapped to hash tags. For example,  X  X ink Floyd X  corresponds to the twitter hash tag #pinkfloyd . In our implementations, an online service from wefollow.com is used to find Twitter ex-perts on the items in the user X  X  music profile. wefollow.com is a user dictionary that curates lists of the most influential Twitter users for a large number of domains.
Now we provide a description of the various models used to gather data and predictions from each source. In the context of Figure 1, computations flow from left-to-right across the three columns. Each data item in the system is associated with a  X  X core X  (analogous to a weight) from 0 to 1 that is visually encoded in the slider bars.
 music preference information is gathered though the Face-book graph API. The list of music preferences in the user X  X  profile are used as input to each of the source-specific com-putational models described in Section 6.1. Preference in-formation for music on Facebook is binary, that is, no scaled http://dbpedia.org/sparql http://facebook.com/press/info.php?statistics https://developers.facebook.com preference rating is available. Accordingly, each profile item is initialized with a score of 0.5.
 (middle column in Figure 1) provide different items that can potentially generate recommended items. Each source requires a different model / strategy to extract these source items (i.e: Facebook friends, Wikipedia articles, Twitter ex-perts). Those are described in 6.1 .
 been collected by each source, the next step is to generate predictions. Individual recommendation scores are calcu-lated as the sum of the weights of all items within the source that are linked to the recommendation. In Section 6.2 we discuss a few different methods for combining the recom-mendation scores from individual sources.
This section describes the specific modelling and predic-tion processes for each context source.
 to Wikipedia articles through dynamic queries over Google X  X  Search API. For each profile item, a search is performed within the English Wikipedia and the top result is selected. Next, (as we discussed in Section 5) a query is issued to DBpedia X  X  SPARQL endpoint for items (articles and cate-gories) that are linked to at least two music items in the ac-tive user X  X  profile. This can be viewed as a content-matching approach to generating recommendations. An overall weight for each Wikipedia item (articles or categories) is calculated as the sum of the individual user-provided weights of the pro-file items it shares links with, as represented by the slider bars in the interface. To generate recommendations from Wikipedia, a further query is sent to DBPedia, this time to retrieve new (recommendation) items that are linked to at least two of the relevant Wikipedia items that were found in the previous step. The recommendation items are fil-tered by type, in the context of music:  X  X usical Artist X  or  X  X and X . For example, as shown in Figure 1, the article for  X  X ink Floyd X  has a semantic link to the category  X  X nglish Rock Music Groups X , which in turn is linked to  X  X he Bea-tles X . In this manner,  X  X he Beatles X  becomes a candidate recommendation from this source.
 book is similar to traditional collaborative filtering, in that the opinions of similar friends are used to generate predic-tions. These friends are ranked according to their similarity with an active user X  X  taste using a Pearson X  X  correlation coef-ficient. We have adapted the correlation formula to account for the fact that Facebook items in users X  music profiles are binary and do not contain scaled ratings. The similarity of each Facebook friend to the active user is given by: where TWCI x,y is the total weight of the items x and y like in common, and TWI x is the total weight of items liked by user x . users that have expertise in the items listed in the active user X  X  profile. We first map profile items to Twitter hash tags (i.e. Michael Jackson gets mapped to # michaeljackson ) and so on. Next, we retrieve the top Twitter experts on those items according to wefollow.com for each hash tag. For example, Pink Floyd experts are found here: http:// wefollow.com/twitter/pinkfloyd . For each expert found, recommendations are produced using the following equation to compute a score for each candidate item.
 where Rank exp,item j is the expert X  X  ranking for the item and | Exp item j | is the total number of experts for the item. For example, if an expert is ranked 20 th out of 100 experts for a specific item the expert gets a score of 0.8 for that item. The overall weight of a Twitter expert is determined by the linear combination:
All hash tags that resolve to bands or musical artists that the relevant Twitter experts have knowledge in are poten-tially recommendable.
As pointed out in Section 3, TasteWeights uses a paral-lelized design, that is, predictions are made by each source-specific model individually and then combined in a final processing step. Parallelized hybrids are further classified by Burke [4] into mixed, weighted, and switching hybrids. We describe and evaluate the following three strategies used in TasteWeights : Weighted, Mixed and Cross-Source. In order to perform the hybrid step we first need to resolve entities across the different context sources. For example, the system needs to know that the Wikipedia article on the band  X  X sian Dub Foundation X  corresponds to a page in the Facebook graph and to the Twitter hash tag # adf . Of the three sources used in this paper, Wikipedia presents the most evolved semantic graph in terms of completeness and non-redundancy [8], and therefore it is the best available resource for entity-resolution. Accordingly, we use Google Search API to map all recommendations to Wikipedia arti-cles to confirm their identities. After this mapping stage we proceed with our different hydrid methods.
 ommended item is simply the weighted sum of the recom-mendation scores for each source. Weights for each context source are user-configurable through interactive sliders in the TasteWeights interface as described earlier.

Automatically optimizing the set of weights for each con-text source is desirable, but not trivial. Empirical boot-strapping can be used to calculate an optimal weighting scheme [20], however, historical data is needed for this ap-proach. The P-Tango system looks into dynamic optimiza-tion of weights of a content-based and a collaborative rec-ommender [5]. In their model, dynamic optimization starts with a uniform distribution of weights and dynamically ad-justs the weights to minimize predictive error as users rate more items. This procedure can be applied on a per item and per user basis and the results can be combined and used for new users of the system. The evaluations presented in this paper do not use dynamic weighting, since the focus is on other interactive aspects of the system. For simplicity, our weights were fixed evenly across the three sources. source are ranked, and then the top-n are picked from each source, one recommendation at a time by alternating the sources. This approach only considers relative position in a ranked list and does not include individual recommenda-tion scores. In cases where a recommendation is produced by multiple context sources (i.e. was previously picked from another source) the algorithm simply selects the next rec-ommendation from the ranked list for that source.
 ommendations that appear in more than one source. We believe that if a recommendation is generated from more than one context source / algorithm, i.e. by both collabora-tive filtering (Facebook) and content-based recommendation (Wikipedia), then it should be considered more important. To compute a final recommendation set, the weighted hybrid approach (Section 6.2) is first applied, then each recommen-dation X  X  weight is multiplied by the number of sources in which it appeared. The following equation describes the the cross-source hybrid approach: where | S rec i | is the number of context sources recommen-dation i was generated by (i.e. 1, 2, or 3).
We evaluated aspects of the TasteWeights system in terms of both recommendation accuracy and user experience. We compared nine methods: recommendations generated by the three individual sources (Wikipedia, Facebook and Twitter; cf. Section 7.2.1), recommendations produced by the three hybrid methods (Weighted, Mixed, and Cross-Source; cf. Section 6.2), and recommendations generated by three inter-action variants that allowed users to fine-tune their prefer-ences. The interaction variants differed based on how much of the recommendation process users could reflect on: items weights in their profile (left column in Figure 1). were able to change the weights on context source items (middle column).
 users could see the effects of their tuning actions on the recommendations (all columns were visible). Note, this is the default interface for the system.

The three different interactive methods could potentially use any of the hybrids as their underlying algorithm. To reduce complexity in our study, the best performing hybrid strategy was chosen for use in the three interactive methods. A pilot study consisting of 7 user trials was performed to find that the cross-source hybrid outperformed the others.
We performed a controlled user study (N=32) with the objective of answering the research questions posed in our earlier discussion (Section 1).

To assess the effects of explanation and interaction with the system on user experience and understanding of the rec-ommendation process a qualitative analysis was performed based on a post-study questionnaire. We asked questions on how useful the explanation of hybridity was and how users perceived refining different aspects of the system.
We also performed a quantitative analysis on the perfor-mance of the nine recommendation methods. We used a within-subjects experimental design. The independent vari-able was recommendation method and the dependent vari-able was accuracy. Each of the nine methods produced a ranked list of recommendations. To compute the overall ac-curacy of a given recommendation list, we first asked the user to rate the top 15 recommendations in the list in ran-dom order and then used Breeze X  X  R-Score  X  X tility X  metric [3] to determine a utility score for the list. The metric as-sumes that the value of recommendations decline exponen-tially based on position in the recommended list. The utility of a given recommendation list for user u is given by: where i j is the item in the j th position, r ui is user u  X  X  rating of item i , (1 to 5 stars), d is Breese X  X   X  X on X  X  care X  thresh-old (experimentally chosen as 2 stars), and  X  is the half-life parameter, which we set to 1.5, controlling the exponential decline of the value of positions in the ranked list.
We considered measuring accuracy via popular approaches including variants of Root Mean Squared Error (RMSE) and Mean Average Error (MAE). However, we opted against us-ing those for two reasons: first, our system X  X  input is music that is not rated by the user but only  X  X iked X , so in a way all Facebook  X  X ikes X  correspond to 5-star ratings; and second, because in the real world people look mostly at the top-n recommendations than the complete recommendation list. 32 users participated in the main study (17 male, 15 fe-male) ranging in age from 19 to 35. Participants were re-cruited through a university-wide experimental program and were paid a nominal amount for their time. Most partici-pants were students and spanned 10 different majors. Pre-and post-study questionnaires were completed by each par-ticipant. Most participants reported that they were regular Facebook users (86% daily), and that they frequently used Wikipedia (36% daily, 45% weekly). There was a notable drop-off in reported use of Twitter in the study group, with 5% daily users, 18% weekly users and 63% who had never used the microblog. Since our system is bootstrapped from a participant X  X  Facebook music profile and associated net-work, probe questions were asked to assess the amount of available data. On average, participants had 416 Facebook friends (notably far larger than the average of 130 for the Figure 3: Plot of means of recommendation meth-ods over utility with 95% confidence intervals. The utility metric is described in 7.1.
 Method 1 Method 2 Diff Lower Upper P Val Cross Hybrid Wikipedia 1.568 0.119 3.017 0.023 Cross Hybrid Facebook (CF) 1.678 0.229 3.127 0.011 Cross Hybrid Twitter 2.477 1.028 3.926 0.000 Full Interaction Cross Hybrid 1.542 0.935 2.991 0.027 Table 1: Results from a Tukey post-hoc analysis of the recommendation methods: multiple compar-isons of means with 95% family-wise confidence level social network 5 ), and Dunbar X  X  optimal number of friend associations (150)[10]. Participants reported that they were familiar with recommender systems such as Pandora and Netflix (3.8 out of 5). When asked about their primary methods for discovering new music, participants X  top choices were  X  X riends X  (45%),  X  X andora X  (36%) and  X  X adio X  (23%).
After completing the pre-study questionnaire, participants were given an explanation of the system controls and approx-imately one minute to familiarize themselves with the vari-ous UI components. Then, participants were asked to tweak the system using each of the three interactive methods, de-scribed in Section 7.1, which were presented in a random order. After that, users were asked to rate a randomized list of output from each of the nine tested methods. The purpose of this task was for participants to rate 15 recommendations produced by each approach on a 5 star scale, 1 being the low-est and 5 being the highest. Ratings were performed in bulk at the end of the study. To rate unknown bands the user was given the chance to look at the band X  X  LastFM 6 page. The page not only contains relevant information about the band but also music samples. After having rated all recommenda-tions, users were asked to answer a post-questionnaire and provide feedback on their perception of the system.
Figure 3 presents a plot of the means of the nine meth-ods over utility with 95% confidence intervals. Overall, the http://facebook.com/press/info.php?statistics http://www.last.fm full interaction method was found to have the highest utility score, while the twitter method produced the lowest utility score. On average, the hybrid methods performed better than the individual ones, and the interactive methods per-formed better than the hybrids.
 Mauchly X  X  test showed a violation of sphericity against Method (W(44) = 0.005, p = 0.01). We ran one-way repeated-measure ANOVA and made Greenhouse-Geisser correction (  X  = 0.49). It revealed a significant effect of the method vari-able on utility (F(3.72, 52.11) = 8.17, p &lt; 0.01). To assess the statistical significance of pair-wise differences within our methods, a Tukey post-hoc analysis was performed and the results are presented in Table 1. Note that not all pair-wise results are shown but only relevant ones.
Here, we examine the accuracy of predictions generated from each individual context source. To recap, we examined Facebook (collaborative / social filtering), Wikipedia (se-mantic / content-based filtering) and Twitter (expert-based recommendations). Based on our 32 users, we found no significant difference in the three methods. Wikipedia had the highest average utility of 4.42 and  X  X xpert recommen-dations X  sourced from Twitter exhibited the lowest average utility of 3.52. Based on our observations, it appeared that recommendations derived from Twitter were more obscure than the other two sources. The authors note that this is likely a result of the particular recommendation technique used, and not necessarily a reflection on the quality of the underlying data in Twitter.
Our second analysis focuses on a comparison of the three hybrid recommendation approaches. The middle portion of Figure 3 shows the utility score for each approach ( weighted , mixed , and cross-source hybrid). Only the cross-source hy-brid approach, in which we favor recommendations coming from more than one source, performed better than all three single-source methods. The Tukey pair-wise test showed sig-nificant differences between the cross-source hybrid method and Wikipedia, Facebook (CF), and Twitter, with p=0.023, p=0.011, and p &lt; 0.001 respectively. This is a strong indi-cation that hybridization across social web APIs can help increase predictive accuracy in recommender systems.
The three methods of interaction described in Section 7 were tested in the study and the results are shown in Figure 3. The full interaction method is the standard use case for the TasteWeights system and it exhibited improved perfor-mance over the best hybrid approach (p=0.027) indicating that interaction with the full system helped the user get better recommendations. As expected, out of all interactive methods the full interaction one achieved the highest accu-racy score of 7.54. However, we note that this is clearly not a fair comparison since in this method, participants could see the recommendations change as they interacted with the system, meaning that recommendation feedback could in-form their interactions. While this is not a fair scientific comparison, we posit that a mechanism which allows such informed, interactive feedback can be beneficial in real world recommender applications.
To assess the effects of interactive visualization on the perceived quality of recommendations, a post-questionnaire was completed by all participants. The study also analyzed the role of the interface as an explanatory mechanism for the underlying algorithms, and as a mechanism to help users learn about the underlying data. Looking at factors affecting explanation and learning, the left side of Figure 4 shows that users generally viewed the system as informative. The highest agreement was for the  X  X elped understand how I got my recommendations X  question, indicating that the system is performing well as an explanation interface.

The graph on the right side of Figure 4 shows results for the perceived usefulness of interaction with the system and the quality of each prediction strategy. Users felt that inter-action helped them get better recommendations. Facebook was reported as the most useful source for generating recom-mendations, followed by Wikipedia, with Twitter reported as by far the least useful. Interestingly, perceived useful-ness shows a relative improvement of 9.7% for Facebook over Wikipedia, while accuracy from Figure 3 indicates the Wikipedia slightly outperforming Facebook. This increase in perceived utility of Facebook may be a result of partici-pants favoring recommendations that come from real people who they trust and have prior information about.
This paper presented TasteWeights , an interactive hybrid recommendation system. The system employs new models for sourcing recommendations from a range of web APIs and presents hybridization strategies for combining those recom-mendations. The TasteWeights explanatory interface edu-cates users about hybrid recommendation systems and en-ables them to tweak the underlying algorithms in real-time. A supervised user study was performed using the system to explore research questions relating to visual interactive recommendation systems. The study results indicate that:
This work was partially supported by the U.S. Army Re-search Laboratory under Cooperative Agreement No. W911NF-09-2-0053; by NSF grant IIS-1058132; and by the U.S. Army Research Laboratory under MURI grant No. W911NF-09-1-0553; The views and conclusions contained in this document are those of the authors and should not be interpreted as rep-resenting the official policies, either expressed or implied, of ARL, NSF, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Gov-ernment purposes notwithstanding any copyright notation here on. The authors would also like to thank Bart Knij-nenburg for his valuable advice. [1] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, [2] S. Bostandjiev, J. O X  X onovan, C. Hall, B. Gretarsson, [3] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [4] R. Burke. Hybrid recommender systems: Survey and [5] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov, [6] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [7] B. Gretarsson, J. O X  X onovan, S. Bostandjiev, C. Hall, [8] A. Halavais and D. Lackaff. An analysis of topical [9] J. L. Herlocker, J. A. Konstan, and J. Riedl. [10] A. Hernando, D. Villuendas, C. Vesperinas, M. Abad, [11] P. Melville, R. Mooney, and R. Nagarajan.
 [12] P. Melville, R. J. Mooney, and R. Nagarajan. [13] S. E. Middleton, H. Alani, and D. D. Roure.
 [14] J. O X  X onovan, B. Gretarsson, S. Bostandjiev, [15] J. O X  X onovan, B. Smyth, B. Gretarsson, [16] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [17] F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, [18] B. Shneiderman. The eyes have it: A task by data [19] N. Tintarev and J. Masthoff. A survey of explanations [20] M. Zanker and M. Jessenitschnig. Case-studies on
