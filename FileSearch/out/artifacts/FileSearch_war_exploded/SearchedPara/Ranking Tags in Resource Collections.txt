 We examine different tag ranking strategies for constructing tag clouds to represent collections of tagged objects. The proposed methods are based on random walk on graphs, di-versification, and rank aggregation, and they are empirically evaluated on a data set of tagged images from Flickr. Categories and Subject Descriptors: H.3 Information Storage And Retrieval: Information Search and Retrieval General Terms: Algorithms Keywords: tag clouds, tag ranking
Assigning tags to Web resources, such as documents, im-ages, videos or bookmarks, has become popular as a simple, easy and effective way to facilitate their retrieval and man-agement. To reduce the cost and improve the effectiveness of tagging, several approaches have focused on (re-)ranking or suggesting tags for an individual resource, based on its content or the tags of other similar resources (e.g. [3]).
In this work, we consider instead the problem of select-ing and ranking tags to describe groups of tagged resources. Typically, tag clouds are employed for this purpose. The goal of a tag cloud is to visualize the most relevant and important tags for the items in a group. In practice, the most frequently occurring tags are selected. We propose and examine alternative methods to select and rank tags in groups of tagged objects, based on tag co-occurance, diver-sification of tags, and rank aggregation. To compare these methods, we have conducted an experimental evaluation on a large real-world dataset containing groups of tagged pho-tos obtained from Flickr. The comparison considers a set of proposed metrics, namely coverage, overlap and selectivity, that characterize the usefulness of a tag cloud for search and navigation. The results show that even though ranking tags based on their frequency performs well in most cases, more effective rankings can be obtained using other methods. Frequency scoring. Let fr ( t,G ) denote the frequency of tag t in the group G , i.e., the number of objects in the group containing t divided by the group size. A simple strategy, typically employed in practice, is to construct the tag cloud using the top-k most frequent tags.
 TF.IDF scoring. An extension is to rank tags based on the same idea as tf . idf scoring for document retrieval. This assigns a lower score to tags that also occur frequently in several other groups. Specifically, the score is modified as: where the idf of a tag is defined analogously to the inverse document frequency of a term in a document collection. Graph-based scoring. Another variation is to take into consideration co-occurrence of tags. For this purpose, we create a graph of the tags, where an edge between two tags t and t j denotes that there is an object in G tagged with both t i and t j . The score of a tag is derived by performing a random walk on this graph. Initially, the score of each tag t is set to its frequency, i.e., f 0 ( t ) = fr ( t,G ). The transition probability from a tag t i to a tag t j is computed as where the similarity sim ( t i ,t j ) between two tags can be computed based on the number of objects where these tags co-occur. After each iteration q , the score of each tag is updated according to: f q ( t i ) = z  X  X with z being a weight parameter. The process is repeated until the score of each tag t converges to a value f ( t ).
This strategy increases the diversity [2] of the tags in the cloud to allow for more objects to be represented. We ex-amine two variations.
 Diversity. The goal is to select tags that are not only as frequent as possible but also as dissimilar as possible from each other, in the sense that they appear in different sets of objects. Therefore, the score of a tag t is defined as where the parameter  X  is used to weight the importance of frequency with respect to the factor of diversity. A greedy approximation algorithm can be used to select the top-k tags, similarly to the method described in [2]. Novelty. Alternatively, we can define the score of tags us-ing the notion of information nuggets . We consider each object to constitute one information nugget. Selecting a tag t , provides a set of information nuggets V ( t ) corresponding to the objects that this tag is assigned to. Let n v,T G number of times a nugget v appears in the tags currently contained in the cloud, and N V the total number of infor-mation nuggets in the group. Given a tag t and the current contents of the tag cloud T G , the score of t is defined as where  X  () is a discount function that reduces the contri-bution of each information nugget based on the number of times it has already been seen. As above, a greedy approxi-mation algorithm can be used to select the top-k tags.
A different direction is to rank the tags of the group by aggregating their rankings in individual objects. The Borda Count method can be used for this purpose [1]. According to it, the score of a tag is computed as assigned to object u and  X  a discount function as above.
We evaluated the different tag ranking methods on a data set comprising groups of tagged photos collected from Flickr. The data set contained in total 451 groups, 488,112 photos, and 112,514 tags, with each group having on average 1270 photos and 2707 distinct tags.
We are interested in characteristics of a tag cloud that make it useful for search and navigation. For this purpose, we consider the three evaluation metrics described below. Coverage. We define the coverage of a tag cloud T G w.r.t. the group of objects G it represents as the portion of objects in G that have at least one tag appearing in T G : Overlap. The overlap of two tags t i and t j is defined as the portion of objects tagged with both t i and t j , i.e., | U ( t defined as the average overlap between each pair of tags: Selectivity. Assume a user is interested in object u and selects all the tags of u appearing in the cloud. The result will contain u and all other objects also having (at least) those tags, i.e., every u i  X  G s.t. T ( u )  X  T G  X  T ( u goal is to maximize the number of filtered out objects. We call this the selectivity of u w.r.t. T G . Thus, we measure the selectivity sel of the tag cloud by computing the average selectivity of the objects in the group: We refer to the above methods using the abbreviations FRQ , TFIDF , RW , DIV , NOV , and RA , respectively. The presented results in Figure 1 are average values over all the 451 groups in the data set, for different tag cloud sizes.
FRQ performs reasonably well, mainly for coverage and selectivity, but less for overlap. RW and RA exhibit a simi-lar performance to FRQ , with the latter outperforming the other two regarding overlap. In contrast, the performance of TFIDF is very low both for coverage and selectivity, but it outperforms all three previous approaches in overlap. Finally, DIV and NOV perform better than all other ap-proaches. Especially for coverage, NOV achieves excellent results, ranging from 93% for top-k = 20 to 99% for top-k = 100. It also has good results for overlap for all values of k , although for k &gt; 60 DIV becomes equally good or even better. As expected, increasing the size of the tag cloud improves the performance of all methods in all metrics. [1] J. A. Aslam and M. H. Montague. Models for [2] S. Gollapudi and A. Sharma. An axiomatic approach [3] D. Liu, X.-S. Hua, L. Yang, M. Wang, and H.-J. Zhang.
