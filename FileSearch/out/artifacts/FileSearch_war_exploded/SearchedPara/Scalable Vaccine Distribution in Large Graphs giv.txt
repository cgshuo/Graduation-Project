 Given an noisy or sampled snapshot of a network, like a contact-network or the blogosphere, in which an infection (or meme/virus) has been spreading for some time, what are the best nodes to immunize (vaccinate)? Manipulating graphs via node removal by itself is an important problem in multiple different domains like epidemiology, public health and social media. Moreover, it is important to account for uncertainty as typically surveillance data on who is infected is limited or the data is sampled. Efficient algorithms for such a problem can help public-health experts take more informed decisions.

In this paper, we study the problem of designing vaccine-distribution algorithms under an uncertain environment, with known information consisting of confirmed cases as well as a probability distribution of unknown cases. We formulate the NP-Hard Uncertain Data-Aware Vaccination problem, and design multiple efficient algorithms for factorizable distri-butions (including a novel sub-quadratic algorithm) which naturally take into account the uncertainty, while provid-ing robust solutions. Finally, we show the effectiveness and scalability of our methods via extensive experiments on real datasets, including large epidemiological and social networks. H.2.8 [ Database Management ]: Database Applications X  Data mining Graph Mining; Uncertainty; Immunization; Diffusion
What is the best way to distribute vaccines to prevent the spread of diseases on a socio-contact network? Most pre-vious works (see Related Work) for controlling propagation have concentrated on developing strategies for vaccination (node/edge removal) pre-emptively before the start of an epidemic. While very useful to provide insights in to which baseline policies can best control an infection, they may not be ideal to help make real-time decisions as the infection is progressing. Consider also social media and cyber secu-rity. Popular phrases or links or rumors are re-posted/re-tweeted on Facebook/Twitter,  X  X nfecting X  followers to do the same. How should Twitter decide which accounts to sus-pend/delete to stop active rumors/spam/malware as much as possible? Which machines should install patches first, in presence of malware attacks? All these problems can be thought of as immunization/vaccination in a network, in presence of already infected nodes [46].

However, in reality contagions usually spread over uncer-tain environments and the sources of such uncertainty are many. For example, in public health, due to the so-called multi-layered surveillance pyramid [39, 16, 30] at each layer the number of detected infections is a fraction of the infec-tions in the layer below it. Hence the total detected infec-tions at the top of the pyramid is a fraction of the actual infections in the population at the bottom. Another exam-ple is the likelihood ratios used in diagnostic testing [13]. For each a person who gets the negative test outcome, she has some probability that her test was a false-negative. In so-cial media, as externals we rarely get access to the complete cascade. Researchers usually have access to only a uniform sample of cases (e.g. the Twitter API). In Facebook, most users keep their activity and profiles private. Moreover, if only because of the extreme velocity of social media data, one has to resort to using only a sample of the data. Hence this implies that we will have to make do with only an un-certain snapshot.

In this paper, we study the problem of how to best dis-tribute vaccines to nodes in large networks, in presence of uncertain prior information. Our goal is not to fill-in the missing information; instead we want to take robust deci-sions in presence of uncertain information. Our contribu-tions include: 1. Problem Formulation : We formulate the Uncertain 2. Efficient Algorithms : As the problem is NP-hard 3. Extensive Experiments : We demonstrate the effec-
The rest of the paper is organized as follows. Section 2 presents some preliminaries while Section 3 sets up the Un-certain Data-Aware Vaccination problem, and discusses the computational complexity of our problem, Section 4 presents our algorithms and Section 5 presents experimental results on several datasets. We give related work in Section 6, and finally conclude in Section 7.
Table 1 lists the main symbols used in this paper. There exists an underlying contact network G on which the conta-gion (disease/virus/meme etc.) can spread. We assume that our network is weighted and undirected, but all our methods can be naturally generalized to directed graphs.
 Symbol Definition and Description UDAV Uncertain Data-Aware Vaccination problem IC Independent Cascade Model
SIR Susceptible-Infected-Recovered Model footprint number of infected nodes at the end benefit number of nodes saved G ( V,E ) graph G with nodes set V and edges set E
U uncertainty model  X  i,j propagation probability from node i to j p i probability that i is infected at the start k the budget (i.e., the number of vaccines avail-S set of nodes to give vaccines to
E S ( F ) the expected footprint after vaccinating S  X  Z ( S ) given graph Z , the expected benefit of vacci-l number of samples  X  percentage of nodes that have p i &gt; 0 in U
We use two widely used propagation models to describe how the virus spreads on the network: the Independent Cascade (IC) model and the Susceptible-Infected-Recovered (SIR) model. SIR is a well-known epidemiological model to model mumps-like infections [17, 2]. A node in this model can be healthy (susceptible), infectious or recovered. When a node u becomes infected at the timestamp t , it will try to infect each of its direct healthy neighbors v with the propa-gation probability  X  u,v . If u succeeds, v will become infec-tious at the timestamp t + 1. At the end of each timestamp t , each infected node u has a curing probability  X  to become  X  X ecovered X  at the next timestamp t + 1. Once recovered, u will never be infected further. The process stops when no additional node becomes infectious. The IC model [21], a special case of SIR, has been extensively studied in the so-cial media to model the viral marketing. Unlike SIR, a node u in IC has only single chance to infect its healthy neighbors (hence the curing probability,  X  = 1 here).
In this paper, we are concerned with the scenario when we know the underlying contact network, but we do not know the exact current infected state of the network. One source of uncertainty is public-health surveillance [39, 16, 34, 30, 12, 5]. Generally there are three types of surveillance: population-based, health provider-based and lab-based. Al-though different types of surveillance may have different probabilities to miss the truly infected person, we can sim-ply use a set of probabilities P (over the nodes) to model such uncertainty. Another example is the likelihood ratios used in diagnostic testing; each a person has a probability p that her test was a false-negative. In Twitter, each relevant  X  X nfected X  tweet can be modeled as having some probability of being missed (because of uniform samples [32]).

Table 2 summarizes common probability distributions mod-els U we use in this paper to model the uncertainty in observed infections. Each gives the probability of a node i not observed as infected being truly infected. We fo-cus on fully factorizable distributions (over nodes) for sim-plicity 1 . Hence, if G j denotes a particular configuration of infections in the network (i.e. a  X  X ossible world X ), then Pr( G  X  G j ) = Q a  X  I p a Q b  X  H (1  X  p b ) where I and H are the set of infected and healthy nodes in G j , and the proba-bilities p i for any node i come from U .
Now we are ready to state our problem formally. We as-sume that a contagion can travel in principle from any node to any other node i.e. the graph is connected (strongly con-nected if directed). We are given a fixed-set I 0 with infected nodes, and an uncertainty model U as above. We are also given a budget k of vaccines. Giving a vaccine to a node ren-ders it immune to the virus and hence it can not get infected further (effectively removing it from the network). Our goal is to find the  X  X est X  set S of nodes to vaccinate to minimize the spread of the contagion, which can be measured by the so-called  X  X ootprint X , the number of infected nodes at the end. A subtle point is that vaccination is meaningful only for healthy nodes . Hence when we select a node-set S , not all the nodes in S can be vaccinated (removed) in all possible sampled graphs: if a node i is infected in a possible world G , then it can not be vaccinated in G j , and it does not give us any benefit there.

More specifically, suppose S is the set of nodes selected initially for vaccination and G i is a particular realization ( X  X orld X ) sampled from U . There only exist infected or healthy nodes in G i . Denote S i  X  S as the subset of nodes
Extending our results to more general forms e.g. distri-butions factorizing over groups of nodes being infected is interesting future work. Name Distribution Description
GENERAL p i Each node has its own infected probability. in S that are healthy in G i  X  X hese are the nodes which will be vaccinated in G i . Denote  X  G i ( S i ) as the expected num-ber of infected nodes after running the epidemiology model e.g. IC, on G i starting from the infected nodes in G i but af-ter removing nodes in set S i . Let F be the random variable denoting the number of infected nodes after choosing set S under U . Then E S ( F ) = P G trying to find the best set S to minimize E S ( F ). Formally: Problem 1: Uncertain Data-Aware Vaccination Problem: UDAV ( G, U ,I 0 ,k ).
 Given: A graph G ( V,E ) with node set V and edge set E , the uncertainty model U , the infected node set I agation probability on each edge { i,j }  X  i,j , and an integer (budget) k .
 Find: A set of nodes S  X  = argmin
Note that as vaccination will be applied only to healthy nodes in a possible world, this formulation also naturally generalizes the corresponding deterministic version of this problem (data-ware vaccination problem studied in DAV [46]). Complexity. UDAV is NP-hard, and cannot be approxi-mated within an absolute error since its deterministic coun-terpart DAV is itself NP-hard, and cannot be approximated within an absolute error [46]. Overview. In this section, we first present a sampling al-gorithm Sample-Cas for UDAV , which is a stochastic al-gorithm under the SAA framework. However, Sample-Cas is not scalable to large networks. Hence, we propose two faster algorithms: Expect-Dom and Expect-Eig , which are based on the expected graph and measuring benefits of vaccinations. After analyzing the performance of Expect-Dom and Expect-Eig , we show that these two algorithms are complementary w.r.t. the support of the uncertainty model, and hence we present a hybrid algorithm called Expect-Max with sub-quadratic running time.

We assume the GENERAL model everywhere in this section (as the rest in Table 2 are just special cases of GENERAL ). Further we describe the algorithms assuming the IC model first(Section 4.1 and 4.2) X  X ater, we will discuss how to ex-tend to the SIR model (Section 4.3). Main Idea. Since UDAV is a stochastic optimization prob-lem, we try to apply the SAA (Sample Average Approxima-tion) [22] framework to solve it. The idea is to reduce the stochastic optimization problem to the deterministic version by sampling the uncertainty distribution to generate a finite number of deterministic cases. Unfortunately, as we men-tioned in the previous section, even the deterministic version of UDAV is NP-hard. Hence we leverage the solution in [46], which utilizes a spanning tree called dominator tree, and then find a suitable sub-modular structure to solve UDAV approximately.
 Details. Let  X  G i ( S i ) be the expected benefit after vacci-nating the healthy node set S i in a graph G i , i.e.: So
Since P G can be rewritten as: S  X  = argmax
So we need to compute  X  G i ( S i ) for each G i , which is es-sentially the deterministic problem on graph G i . Hence we re-purpose the solution from [46]: first merge all the infected nodes in G i into a super node I 0 ( I 0 is infected). If a healthy node has multiple infected neighbors, I 0 will connect to the node with the probability that is the logical-OR of the indi-vidual probabilities (so if a node u has two infected neighbors x and y ,  X  I 0 ,u = 1  X  (1  X   X  x,u )(1  X   X  y,u )). Secondly, build a dominator tree Dom G i on this merged graph, and properly weight it. Briefly, given a source node I 0 , a node v dominates another node u if every path from I 0 to u contains v . Node v is the immediate dominator of u , denoted by v = idom ( u ), if v dominates u and every other dominator of u dominates v . We can build a dominator tree rooted at I 0 by adding an edge between the nodes u and v if v = idom ( u ) (totally in near-linear time [7, 26]). Finally we approximate  X  G i ( S  X 
Dom G i ( S i ) (i.e. the benefit after removing nodes in S In fact, can further prove that the real benefit of removing S from graph G i is lower-bounded by  X  Dom G
Lemma 1. (Lower Bound of  X  G i ( S i ) ) The nodes we can save from G must be greater than nodes we save from its dominator tree, that is,  X  Dom G inequality is saturated when the merged graph is a tree).
Proof. (Sketch) For any node u in S i , the benefit we can get on G i is at least all nodes under the subtree of u in the dominator tree of G i (because there is no path from I 0 to those nodes). Hence,  X  Dom G
Let Q ( S ) = P G we get Q ( S )  X  P G and P G (if the merged-graph is a tree, there is no gap). Hence, Lemma 1 suggests that we can use Q ( S ) to approximate P
G i Pr( G i )  X  G i ( S ). Hence we formulate Problem 2 next, to approximate UDAV (Problem 1).
 Problem 2: Given: G ( V,E ) , U , I 0 , and k .
 Find: A set of nodes S  X  = argmax
Interestingly, Q ( S ) is a submodular function, while  X  G is not submodular [46].

Lemma 2. (Submodularity of Q ( S ) ) Q ( S ) is a submodu-lar function.
 Proof. (Sketch) First of all, we prove that given a set done by a case analysis). Then Q ( S ) is a submodular be-cause the linear combination of submodular functions is still a submodular function.
 We now apply the SAA framework: sample l graphs G 1 ,G 2 ...,G l from U and define Q l ( S ) = 1 l P l i =1  X  Dom G Q ( S ) is a submodular function, we apply the greedy algo-rithm [33] to obtain the (1  X  1 /e )-approximation for Problem 2 (under the l samples). We call this algorithm Sample-Cas (Algorithm 1). Note that we can speed up Algorithm 1 using CELF optimization [27].
 Algorithm 1 The Sample-Cas algorithm Require: Input G , U , I 0 , k and l 1: Sample G 1 ,...,G l from U and G 2: Merge infected nodes into I 0 i for each G i 3: Build dominator trees Dom G 1 ,...,Dom G l rooted at I 4: S =  X  5: for i  X  1 to k do 7: Remove a  X  from each of Dom G 1 ,...,Dom G l . 8: S = S  X  X  a  X  } . 9: end for 10: return S
Lemma 3. (Running Time of Sample-Cas ) The time
Proof. (Sketch) Sample G i needs O ( l | V | ) time, and build Selecting a node a needs l ( | E | + | V | ) time. So in general the time complexity is O ( l ( k | V | + k | E | + | V | log | V | )). How many samples? The next lemma estimates the num-ber of samples l needed so that Q l ( S ) is a good estimate of Q ( S ).

Lemma 4. (Number of samples) For any &gt; 0 , to es-timate Q ( S ) within absolute error with probability  X  = upper bound for  X  Dom G
Proof. (Sketch) It follows from using the well-known Ho-effding X  X  Inequality [31].

As  X  can be O ( | V | ), Lemma 4 shows that we need worst-case O ( | V | 2 ) samples to get accurate estimates. Hence Cas does not scale to large networks.
Since Sample-Cas is not scalable for large networks, we next develop another faster algorithm Expect-Max . We give the main idea, and then describe the details in the sub-sequent subsections.
 Main Idea. We first formulate an equivalent problem which uses the concept of a so-called  X  X xpected graph X  G E . Based on that, we propose two different methods Expect-Dom and Expect-Eig , measuring expected benefits of vaccina-tions. We show that these two methods are in fact comple-mentary, and hence then propose Expect-Max , which is sub-quadratic in running time (in nodes/edges).
Here, we formulate an equivalent formulation of Problem 1 based on the concept of an  X  X xpected graph X .
 Definition 1 (Expected Graph): The expected graph G
E is constructed as follows: start with G ; add a  X  X uper node X  I 0 ; connect I 0 to any node i where p i &gt; 0 with the edge weight  X  I 0 ,i = p i ( p i  X  U , the uncertainty model); and then mark all nodes except I 0 as healthy nodes.

As we show next, this construction transforms the uncer-tainty model from nodes to edges without losing any infor-mation. Hence, we can focus on a single graph G E instead of sampling graphs (the main reason why Sample-Cas was slow).

More specifically, we show in Lemma 5, an equivalent for-mulation of Problem 1 based on expected graph G E , under GENERAL and for budget k = 1. The main idea is that, cru-cially, as GENERAL is factorizable (i.e. for a particular configu-ration G j , Pr( G  X  G j ) = Q a  X  I p a Q b  X  H (1  X  p b model on the expected graph, we will get the same configu-rations like sampling from the uncertainty model in Problem 1. A subtle point is that Lemma 5 also takes into account the fact that nodes can not be vaccinated in all  X  X ossible-worlds X  (wherever they are already infected), by correcting the estimate got from G E by an appropriate factor.
Lemma 5. (Equivalent formulation of UDAV when k = 1 ) When the budget k = 1 , for the UDAV problem, the best node a  X  = arg min a E { a } ( F ) can be equivalently wrriten as a = arg max a (1  X  p a )  X  G
Proof. (Sketch) We first prove  X  G E ( a ) = P G i Pr( G i using Definition 1 and the factorizability of GENERAL . Based on this, we can prove that E { a } ( F ) = P G (1  X  p a )  X  G maximizing (1  X  p a )  X  G
Lemma 5 shows that when the budget k = 1, we can get an equivalent formulation of Problem 1 based on the ex-pected graph. Furthermore, note that UDAV is a stochastic problem, while Lemma 5 is based on calculating  X  X enefits X   X  heuristics to estimate  X  G tary methods based on  X  , the support of the uncertainty model (see Section 4.2.4 for more details).
One of the ways we can estimate the benefits is by using our Lemma 1 on G E . The main idea is that we estimate  X  tree on the expected graph. Motivated by the equivalent formulation of Problem 1 (Lemma 5), we propose that at each step select a node with the maximum value of (1  X  p of G E . We call this algorithm Expect-Dom (Algorithm 2). Algorithm 2 The Expect-Dom algorithm Require: Input G , U , I 0 and k 1: Construct G E 2: S =  X  3: Build a dominator tree Dom G 4: for i  X  1 to k do 5: a  X  = arg max a (1  X  p a )  X  Dom G 6: S = S  X  X  a  X  } 7: Remove a  X  from G E 8: end for 9: return S
Lemma 6. (Running Time of Expect-Dom ) The time Proof. (Sketch) Creating an expected graph G E costs O ( | V | ) time, building a dominator tree and weight it need | V | log | V | time. Updating dominator tree costs O ( | V | + | E | ) time. Hence, the time complexity of Expect-Dom is O ( k ( | V | + | E | ) + | V | log | V | ). Another approach we propose is to estimate  X  G via the change in the largest eigenvalue of G E ,  X   X  1 ( a ), after removing node a . The largest eigenvalue of the adjacency matrix of a graph is related to the so-called  X  X pidemic thresh-old X  of the graph under several epidemic models [37, 36]. If the largest eigenvalue is very small, a virus will get extin-guished quickly. Next we will explain why  X   X  1 ( a ) is crucial to the benefits. In addition to that, we will show how to es-timate  X  G Justification of  X   X  1 ( a ) . Let  X  i / u i be the i -th largest eigenvalue/ eigenvector of G E , and f t be the vector of proba-bility of each node being infected at time t . The next lemma will show that the expected number of newly infected nodes is upper-bounded by a function of  X  1 . Hence, reducing  X  (maximizing  X   X  1 ( a )) by removing node a , can effectively minimize the expected number of newly infected nodes, and eventually minimize E { a } ( F ) (the expected number of in-fected nodes at the end). According to Equation 2 (in Sec-tion 4.1), minimizing E { a } ( F ) is equivalent to maximizing the benefit  X  G  X   X  1 ( a ).

Lemma 7. The expected number of newly infected nodes at timestep t +1 , is upper-bounded by h = e 0 ( P | V | j =1 the nodes, which essentially comes from the uncertainty model).
Proof. (Sketch) First, following steps of Lemma 1 in [36], we can get that the expected number of newly infected nodes at timestep t + 1 is upper-bounded by e 0 ( P | V | j =1  X  Second, since  X  1 is real and positive (using Perron-Frobenius theorem), we get h  X   X  t 1 e 0 ( P | V | j =1 u j u j 0 ) f The Expect-Eig Algorithm. Motivated by Lemma 5 (the equivalent formation of Problem 1) and Lemma 7, we can greedily select a node with the maximum value of (1  X  p ) X   X  1 ( a ) at each step, using  X   X  1 ( a ) as an estimate of the benefit of removing a node. We call this algorithm Expect-Eig (Algorithm 3).
 Comment. [43] gives a fast greedy algorithm for this task, by approximating  X   X  1 ( a )  X  2  X  1 u 2 a (based on the first-order matrix perturbation theory). Here we use it in Algorithm 3 (Line 5).

Lemma 8. (Running Time of Expect-Eig ) The time com-plexity for Algorithm 3 is O ( k ( | V | + | E | )) .
Proof. (Sketch) Calculating u 1 costs O ( | E | ) time using the power method. Hence, Algorithm 3 takes O ( k ( | V | + | E | )) time.
 Algorithm 3 The Expect-Eig algorithm Require: Input G , U , I 0 and k 1: Construct G E 2: Get  X  1 and u 1 = ( u 1 ,...,u n ) 0 from G E . 3: S =  X  4: for i  X  1 to k do 5:  X   X  1 ( a ) = 2  X  1 u 2 a 6: a  X  = arg max a (1  X  p a ) X   X  1 ( a ) 7: S = S  X  X  a  X  } 8: Remove a  X  from G E and update  X  1 and u 1 . 9: end for 10: return S
Although Expect-Dom and Expect-Eig are both fast al-gorithms compared to Sample-Cas , they may not work well all the time. Next we will discuss how uncertainty models affect their performances, and present a hybrid algorithm combining both of them.
 Discussion about Expect-Dom. Denote  X  as the sup-port of the uncertainty model (the percentage of nodes that are possibly infected). When  X  = 0, the UDAV problem becomes exactly the DAV problem [46] (the deterministic case of UDAV ) and Expect-Dom reduces to the algorithm in [46], which was shown to perform well. However con-sider the opposite case  X  = 1. In this case, I 0 connects to the rest of nodes. Hence the dominator tree of G comes a star. For any node a ,  X  Dom G on the propagation probability from I 0 to a (i.e., p a ). We cannot utilize any other information from the original graph, hence we would choose nodes essentially randomly. This also gives us the intuition that as  X  increases, the performance of
Expect-Dom will become worse (a fact we demonstrate in experiments as well).
 Discussion about Expect-Eig. As we discussed in Sec-tion 4.2.3, the expected number of newly infected nodes at timestep t +1 is upperbounded by h = e 0 ( P | V | j =1  X   X  certainty model). We first demonstrate that this inequality ( h  X  h 1 ) saturates when f 1 is parallel to u 1 . Then, we will show how to maximize our chance to achieve this, which will lead us to the discussion about the performance of Expect-Eig in terms of  X  .

Lemma 9. ( h -h 1 Gap) As the inner product of u 1 and f increases, h 1  X  h decreases. When f 1 is parallel to u h 1 = h .
Proof. (Sketch) As u 0 1 f 1 increases, f 1 becomes more par-allel to u 0 1 , and u j 0 f 1 ( j 6 = 1) becomes smaller (because u and u j are orthogonal). Hence h 2  X  h 1 decreases. And when u f 1 = 0 ( j 6 = 1), h 1 = h .

This shows that closer the uncertainty model is to u the better bound h 1 is of h : as a result of which we expect  X   X  1 ( a ) to become a better estimate, and hence Expect-Eig to perform better. How is this related to  X  ? The following analysis shows a preliminary justification. Apriori we do not know the graph, hence we do not know u 1 : so reasonably we can assume it is randomly uniformly picked from a n -dimensional space. Let us denote x as the random variable of the first eigenvector. To make f 1 more parallel to x , we need to maximize the expectation of f 0 1 x (i.e., E x [ f not hard to see that as we increase  X  , E x [ f 0 1 x ] will increase.
Lemma 10. (Expected gap) When  X  increases, E x [ x 0 f 1 increases as well.
 Proof. (Sketch) E x [ x 0 f 1 ] = f 0 1 E x [ x ], and all elements in [ x ] are non-negative. As  X  increases, more elements in f become non-zero, hence E x [ x 0 f 1 ] increases as well.
Lemma 10 suggests that when  X  increases, we expect f 1 and u 1 to become more parallel, and so the gap to decrease, as a result of which  X   X  1 ( a ) becomes a better estimate. Thus even this preliminary analysis immediately suggests that as  X  becomes larger, Expect-Eig should perform better. Again we demonstrate this through experiments as well. The Expect-Max Algorithm. The above discussion sug-gests a complementary picture: when  X  is low, we expect Expect-Dom to be better, and when  X  is high, we expect Expect-Eig to be better. Unfortunately, we don X  X  know ex-actly when which algorithm is better: this likely depends not only on  X  but also the graph, and the distribution. However, we can still leverage this insight to propose a hybrid algo-rithm called Expect-Max , which maintains the scalability and quality of Expect-Dom and Expect-Eig . Expect-Max chooses either Expect-Dom or Expect-Eig based on their performances, that is, Comment. S is the output either of Expect-Dom or Expect-Eig , and E S ( F ) can be obtained by via simulation of the IC model ( not sampling from the uncertainty model). Also note that Expect-Max is not the greedy algorithm that picks one node from either Expect-Dom or Expect-Eig in each step. Instead, it chooses S just once after running Expect-Dom and Expect-Eig . Hence the time complexity is the time to run IC model (which should be sub-quadratic in edges).
Note that in SIR, the footprint is the total number of recovered nodes at the end (in contrast to the IC model). Nevertheless, leveraging the method in [46], we can directly extend our algorithms to SIR model by changing SIR model to IC model with the propagation probability 1  X  (1  X   X  i,j This does not change any of our algorithms/results.
We present a detailed experimental evaluation in this sec-tion.
We briefly describe our set-up next. We implemented the algorithms in Python 2 , and conducted the experiments us-ing a 4 Xeon E7-4850 CPU with 512GB of 1066Mhz main memory.
 Datasets. We ran our experiments on multiple datasets using both IC and SIR. Table 3 summarizes the datasets, which were chosen for their size as well as the applicability to the UDAV problem (from social media to epidemiology). 1. KARATE is a social network of friendships with 34 mem-2. OREGON 3 is the Oregon AS router graph collected from 3. STANFORD 4 is the Stanford CS hyperlink network, in 4. GNUTELLA 5 is a peer-to-peer network showing the snap-5. BRIGHTKITE 5 is a friendship network from a location-6. PORTLAND and MIAMI are social-contact graphs based Uncertainty models. We used three types of uncertainty models: (a) UNIFORM : p = 0 . 6; (b) SURVEILLANCE : p i formly randomly chosen from { 0 . 1 , 0 . 5 } for each node i (fol-lowing different levels of the surveillance pyramid, e.g: 10%
Code can be downloaded from http://people.cs.vt.edu/ ~yaozhang/code/udav http://topology.eecs.umich.edu/data.html . http://www.cise.ufl.edu/research/sparse/matrices/ Gleich/ .
GNUTELLA and BRIGHTKITE are from http://snap. stanford.edu/data/index.html . Expect-Eig when R &gt; 1 , otherwise Expect-Eig is better. of the total population is infected and is in the hospital, and only  X  33% of infected people go to a hospital, which together imply 50% of the total population is infected and does not go to a hospital); (c) PROP-DEG : p i = d i /d max each node i ( d max is the maximum degree of the graph G ). Parameters. For IC model,  X  u,v is uniformly randomly normalized contact time as the propagation probability  X  u,v and set a uniform curing probability  X  = 0 . 6. We uniformly randomly pick 5% of nodes as infected nodes. For Sample-Cas , we set the number of samples l = 200. For robustness, each data point we show is the mean of 1000 runs of the diffusion/epidemiological model.
 Baselines. We compare our algorithms against various in-tuitive and non-trivial competitors to better judge their per-formance. Recall that I 0 is the infected node set ( I { u | u  X  V,p u = 1 } ). Let us denote W = V  X  I 0 (so W is the set of nodes that are not certainly infected at the start). 1. Optimal : a brute-force algorithm that tries all com-2. Random : uniformly randomly select k nodes from W . 3. Degree : choose the top-k nodes from W according to 4. PageRank : pick the top-k healthy nodes from W with 5. Per-PRank : we first merge all infected nodes into 6. Dava -fast: This is a fast immunization algorithm [46], In short, we demonstrate that Sample-Cas and Expect-Max outperform other baselines on all datasets. Sample-Cas provides very accurate results, but does not scale to large networks, while Expect-Max is fast, scalable and ef-fective. We also show the behaviors of Expect-Dom and Expect-Eig as  X  varies. First of all, we compare Sample-Cas with Optimal on KARATE to demonstrate its accuracy (because Optimal is too slow, we chose KARATE so that we can run Optimal completely). As Figure 1(a) shows, for all uncertainty mod-els, Sample-Cas saves at least 90% of nodes compared to Optimal no matter how k changes. We also found as ex-pected, Sample-Cas  X  X  performance gets better as number of samples increases (not shown here).
We compared Expect-Dom with Expect-Eig as  X  changes on multiple datasets under three uncertainty models (see Figure 1(b) and (c)). For all networks, as expected from our discussion in Section 4.2.4, clearly as  X  increases, Expect-Eig becomes better while Expect-Dom becomes worse. In addition to that, there does exist a  X  X ross-over point X  for each network where the algorithms switch in performance ( R = 1 in Figure 1(b) and (c)). However, this cross-over point is dif-ferent for different networks and for different distributions, which is the reason why we propose the Expect-Max algo-rithm (as we do not know exactly when we should use either Expect-Dom or Expect-Eig as  X  changes).
Figure 2(a), (b), (d) and (e) show experimental results under IC model for UNIFORM . In all networks, Sample-Cas and Expect-Max consistently outperform other competi-tors. OREGON contains only 600 nodes, hence we varied k till 50. Due to a jelly-fish-type structure of OREGON , for lower k , most algorithms perform well by targeting the nodes in the core. However, for larger k , Sample-Cas provides the best solution, while Expect-Max outperforms other com-petitors as well, getting solutions almost as good as Sample-Cas . For GNUTELLA , STANFORD and BRIGHTKITE (much larger than OREGON ), the difference of Sample-Cas and Expect-Max from the other algorithms is clearer: they save upto 2 . 5 times the nodes than other algorithms, yet Expect-Max took a fraction of the running time of Sample-Cas (see Ta-outperform other baseline algorithms. ble 4). Note that although Dava -fast contains information of infected nodes, it doesn X  X  perform well (especially on STAN-FORD ) because it fails to take into account the uncertainty model.
 We got similar result under SIR model on PORTLAND and MIAMI for UNIFORM (see Figure 2(c) and (f)). Since PORT-LAND and MIAMI have more than 0 . 5 million nodes, Sample-Cas did not finish even in a day, and we do not show it on the plots. We notice that the larger k becomes, the bet-ter Expect-Max performs than other competitors. When k = 2000, the difference of Expect-Max from other algo-rithms is clearer: it saves more than 10 , 000 nodes than the second best algorithm Dava -fast.
 For SURVEILLANCE and PROP-DEG , the results are the same: Sample-Cas and Expect-Max always outperform other al-gorithms (see Figure 3). We do not show the plots of other datasets and other values of  X  due to lack of space, but the results are similar: Sample-Cas and Expect-Max provide the best solution.
Although both Sample-Cas and Expect-Max are poly-nomial time (in particular Expect-Max is subquadratic in nodes and edges), we show some running time results to evaluate scalability. Table 4 shows the running times of our algorithms under UNIFORM : Expect-Max is much faster than Sample-Cas . Expect-Max takes only 45 sec-onds on STANFORD while Sample-Cas takes about an hour . The larger networks are, the faster Expect-Max is than Sample-Cas . On BRIGHTKITE with 60 K nodes, Expect-Max is more than 50 times faster than Sample-Cas . Fur-thermore, on the largest network MIAMI , Expect-Max takes Table 4: Running times (sec.) when k = 100 and l = 200 (  X  = 0 . 5 ). Runs terminated when running time t &gt; 24 hours. (shown by  X - X ) a bout 2 . 5 hours to select 100 nodes while Sample-Cas did not finish even in one day . Hence, Expect-Max is scalable for large networks. We now review the most closely related work here.
 Stochastic Optimization. Extensive surveys and text-books [40, 20] exist on this topic. Dyer et al. [14] showed that two-stage stochastic programming problems are # P -hard. Sample Average Approximation (SAA) is a well-known frame-work to approach these problems, which yields strong ap-proximation results [22, 41]. We leveraged the SAA frame-work for Sample-Cas in this paper. However, it is not scal-able to large networks because of its computational com-plexity.
 Handling Uncertainty. Many studies in epidemiology try to estimate the total infections using the surveillance pyra-mid [39, 16, 34, 30, 12, 5]. More generally, missing data in baseline algorithms. networks is an important yet relatively poorly understood problem. A line of work in databases studies several query-ing problems on uncertain graphs, including the k-nearest neighbors query [35], discovering reliable subgraphs [19] and efficient subgraph search [44]. Another related line of work studies the effect of sampling on measured structural prop-erties [11, 23, 4] or network construction [25, 29]. Correcting for the effects of missing data in cascades in general has not seen much attention X  X he exceptions are Sadikov et al. [38] (who try to correct metrics like cascade size for sampling), and Adiga et al. [1] (who study the effect of more general noise in the network structure on metrics like expected foot-print in the IC and LT models). Here we study a specific algorithmic task (immunization) under uncertainty in ob-served infections .
 Immunization Algorithms. Most existing studies focus on finding optimal strategies for vaccine allocation under perfect information [10, 6, 28, 8]. Using game theory, Asp-nes et al. [3] developed inoculation strategies for victims of viruses under random starting points. Kuhlman et al. [24] studied two formulations of the problem of blocking a conta-gion through edge removals under the model of discrete dy-namical systems. Tong et al. [43, 42] and Prakash et al. [36] proposed various node-based and edge-based immunization algorithms based on minimizing the largest eigenvalue of the graph. Zhang and Prakash [46] studied the problem of immunizing healthy nodes in presence of already infected nodes.

To summarize, none of the above works studies the prob-lem of distributing vaccines given uncertain surveillance data.
This paper addresses the problem of distributing vaccines given uncertain data over large networks with applications to cascade-like processes on networks in several areas. The main contributions are: (a) Problem Formulation: Motivated by multiple natural (b) Efficient Algorithms: Due to its computational com-(c) Extensive Experiments: Experimental results demon-Future work can include extending our results to other mod-els in epidemiology such as SIS (where nodes can get infected multiple times), and generalizing Expect-Max to any un-certainty distribution (not just factorizable distributions). anonymous reviewers for their comments, and Virginia Bioin-formatics Institute for sharing with us the PORTLAND and MIAMI datasets. This material is based upon work sup-ported by the NSF under Grant No. IIS-1353346 and by the Maryland Procurement Office under contract H98230-14-C-0127. Any opinions, findings and conclusions or recommen-dations express in this material are those of the author(s) and do not necessarily reflect the views of the respective funding agencies.
