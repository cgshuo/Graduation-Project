 The development of non-invasive brain computer interface (BCI) using the electroencephalogram eral years, a large number of signal processing and machine learning methods have been proposed (FLDA) [7], cannot be successfully used. Among the various EEG feature extraction methods, the common spatial patterns (CSPs) method [2] is one of the most popular. Given two classes of EEG EEG feature extraction method, called common spatio-spectral patterns (CSSPs), which extended the CSPs method by concatenating the original EEG data and a time-delayed one to form a longer vector sample, and then performed EEG feature extraction, which is similar to the CSPs method, from these padded samples. The experiments in [3] showed that the CSSPs method outperforms the CSPs method.
 A multi-class extension of the two-class CSPs method (MCSPs) was proposed by Dornhege et al. [4] who adopted a joint approximate diagonalization (JAD) technique to find the optimal spatial filters. Grosse-Wentrup and Buss [5] recently pointed out that the MCSPs method has two major is based on heuristics. To overcome these drawbacks, they proposed a method based on mutual should be noted that both the MCSPs methods are based on the JAD technique, where a closed-form solution is unavailable, making the theoretical analysis difficult.
 MCSSPs method. However, we do not adopt the same JAD technique used in the MCSPs method to derive our MCSSPs method. Instead, we derive our MCSSPs method directly based on the Bayes discriminant vectors. Based on this new theoretic framework, we propose our MCSSPs method for EEG feature extraction and recognition. Let X t ( classify the EEG signal may lead to better classification accuracy than using x t 2.1 The CSPs Method matrix W that simultaneously diagonalizes both class covariance matrices  X  1 and  X  2 [2], i.e., al. [6] proved that the CSPs method can be formulated as the following optimization problem: and this optimization problem boils down to solving the following generalized eigenvalue decom-position problem: (3), then the spatial filters  X  i with the largest and the smallest eigenvalues.
 Then W = [  X  i 2.2 The CSSPs Method The CSSPs method is an extension of CSPs by concatenating the original EEG data and a time-delayed one to form a longer vector sample, and then performing EEG feature extraction, which time-delay operator with the delayed time  X  , i.e., Then, equation (4) can be re-written as the following: tively.
 To express the above equation in a similar form as CSPs, we define replace the original class covariance matrices  X  1 and  X  2 , where novel theory of multi-class Bayes error estimation. Then we present our MCSSPs method based on this Bayes error framework. 3.1 Multi-class Bayes Error Estimation It is well known that the Bayes error regarding classes i and j can be expressed as [7]: respectively. Let  X  ij = where  X   X  ij = 1 we project the samples to 1D by a vector  X  , then the upper bound  X  ij becomes: Define u =  X  T  X   X  ij  X  and v =  X  T  X   X  ij  X  , where  X   X  ij = 1 estimated as  X   X  P c  X  1 Recursively applying the following inequality error bound in equation (14), we have Let  X   X  = P c Combining equations (15) and (16), we have most EEG experiments. Then equation (17) becomes On the other hand, from  X   X  = P c Combining equations (19) and (18), we obtain that 3.2 MCSSPs Based on Multi-class Bayes Error Estimation to minimize the Bayes error, we should minimize its upper bound, which boils down to maximizing the following discriminant criterion filters of MCSSPs as follows: equation (22) is equivalent to solving the following optimization problem the positive or negative sign of  X  T (  X   X   X  i  X  I )  X  . Then So equation (23) can be expressed as Let T ( s ) = P c  X  vector  X  k +1 , we introduce Theorems 1 and 2 below. The similar proofs of both theorems can be found in [9].
 eigenvector corresponding to the largest eigenvalue of the following matrix Theorem 2. Suppose that Q k R k is the QR decomposition of U k . Let U k +1 = ( U k  X  k +1 ) , is the QR decomposition of U k +1 .
 The above two theorems are crucial to design our fast algorithm for solving MCSSPs: Theorem 1 makes it possible to use the power method to solve MCSSPs, while Theorem 2 makes it possible to update Q k +1 from Q k by adding a single column. Moreover, it is notable that Q technique.
 that If pseudo-code of our MCSSPs method using the full search on S in Algorithm 1. However, if c is a 2. Let X t be the j th optimal spatial filter of the MCSSPs method. Construct the new data  X  X t and let Algorithm 1: The MCSSPs Algorithm Based on the Full Search Strategy Input: Initialization: For i = 1 , 2 ,  X  X  X  , k , Do Output:  X  i =  X   X   X   X  1 2  X  i , i = 1 ,  X  X  X  , k .
 Algorithm 2: The MCSSPs Algorithm Based on the Greedy Search Strategy Input: Initialization: For i = 1 , 2 ,  X  X  X  , k , Do Output:  X  i =  X   X   X   X  1 2  X  i , i = 1 ,  X  X  X  , k . elements in the projections  X  p t where  X   X  t For all the k spatio-spectral filters  X  1 ,  X  X  X  ,  X  k , we obtain the k features v t t th trial of EEG data. Now let v t used as the final feature vector of the EEG signal: transformation serves to approximate the normal distribution of the data [2]. For the given unknown EEG data Z , we use the same procedures to extract the corresponding fea-tures, i.e., we first construct the new data  X  Z = extract the corresponding discriminant feature vector f z , where in which  X   X  z denotes the covariance matrix of  X  Z .
 After obtaining the discriminant feature vectors f t neighbor (K-NN) classifier [7]. To test the performance of our MCSSPs method, we use the real world EEG data set to conduct ground. The EEG was sampled at 250 Hz and was filtered between 1 and 50 Hz with the notch filter the EEG signal. Consequently, each trial contains 750 data points. We adopt the two-fold cross also conduct the same experiment using both MCSPs methods proposed by [4] and [5], respectively. the Euclidean distance and 7 nearest neighbors, is used for final classification. choices of the delayed time  X  . From table 1, we can see that the MCSSPs method achieves much better classification performance than the MCSPs methods. Table 1: Comparison of the classification rates (%) versus standard deviations (%) between MCSPs and MCSSPs.
 the multi-class Bayes error estimation theory to generalize the two-class CSSPs method to multi-our MCSSPs method is superior to the MCSPS methods. With more elaborate treatments, e.g., preprocessing the EEG signal and adopting a more advanced classifier, even higher classification rates are possible. These will be reported in our forthcoming papers.
 This work was partly supported by National Natural Science Foundation of China under Grants 60503023 and 60872160.

