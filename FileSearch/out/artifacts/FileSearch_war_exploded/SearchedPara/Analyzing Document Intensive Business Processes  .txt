 Knowledge is manifested in an enterprise in various forms ranging from unstructured operati onal data, to structured information like programs, as well as relational data stored in databases to semi-structured information stored in XML files. This information embodies the co re of an enterprise knowledge base and analyzing the knowledge base can result in intelligent decision making. In order to realize this goal we begin with representing and analyzing unstruc tured knowledge present in an enterprise. In particular, this paper presents a real life example of a document intensive business process (International Trade) and attempts to model and analyze the process in a formal way. Typically, the information cont ained in a document intensive business process is of operationa l nature and requires extensive manual verification, which is both time consuming and error prone. Therefore, this research aims to eliminate such exhaustive manual verification by constructi ng a knowledge base in the form of ontology and apply suitable rule based reasoners to automate the verification process. I.2.4 [ Knowledge Representation Formalisms and Methods ] -Representation languages D.2.2 [ Design Tools and Techniques ] -Decision tables I.2.6 [ Learning ] -Concept learning, Knowledge acquisition I.2.7 [ Natural Language Processing ] -Language models, Language parsing and understanding Algorithms, Management, Do cumentation, Design, Experimentation, Human Factor s, Languages, Verification. Knowledge representation, sema ntic rules, natural language processing, machine learning, international trade, letter of credit. Documents form the core of many business processes in an organization. Typically they contain several pieces of information that may have a structured format but generally having unstructured data as contents. The data contained in these documents are governed by rules as laid out in the operational manual of these business processes or in certain key documents that are themselves part of the business process. In other words, these documents contain information that has a syntactic structure as well as a behavior whose semantics is governed by the underlying operations. Since these documents needs to manually verified, it takes a considerable effort and time to validate the contents of these documents against the presumed rules as determined by the core operations. Moreover human validation and verification is subjected to unavoidable errors. This was precisely one of the prime challenges that were posed to us  X  (the R&amp;D team) in our organization, which runs several business process services for major global enterprises operating in different verticals like financial, healthcare, consumer durables, retail etc. We were given a tour of one of the key business process services for a global financial bank  X  the precise area being International Trade, which generally draws a significant share of GDP for any country. It is a critical business process and rich in documents. It requires intense validation and veri fication by humans and cost of error is enormous. Our objective was to evaluate the document intensive nature of such proce sses and reduce manual intervention wherever possible. Therefore, in this short paper, we lay down our experience in describing the probl em, the challenges and solutions that can be offered so as to enable intelligent document verification-as-a-service (dVaaS). Th e rest of the paper is outlined as follows. Section 2 describes the case and challenges with respect to document verification in general and in particular to International Trade. Section 3 describes our line of attack in the light of the identified challenges before we conclude in Section 4. International trade is a process of buying goods across countries or continents involving buyers and sellers. Although, at first the process seems simple, yet it invol ves considerable risks for both buyer and seller especially with regards to how a payment would be made during purchasing of goods across international borders. For example, the buyers run the risk of paying upfront without receiving the goods whereas the seller runs the risk of shipping the goods without receiving full paymen t. Therefore, to avoid this unusual situation, intermediate banks becomes a mediator between the buyer and seller and a financial instrument called Letter-of-Credit plays a key role in providing assurance to both buyer and seller regarding fulfillm ent of goods and payment. Fig. 1 describes how international trade works. In step 1, after a contract is finalized between a buyer and seller, the buyer X  X  bank supplies a letter of credit to the seller. In step 2, the seller dispatches the goods to a carrier in exchange of a Bill-of-Lading. In step 3, the seller provides the Bill-of-Lading and other key documents like Commercial Invoice, Inspection Certificate, Certificate-of-Origin, Packing List etc., to the seller X  X  bank in exchange of payment from the buyer X  X  bank. This is the key labor intensive step that requires extensive manual verification, which we would like to eliminate. Now we list out some of the key challenges that need to be addressed so as to provide a solution to the problem. Challenge 1  X  There needs to be a way to formally represent the knowledge captured in a set of documents for a given business process. The representation should be such that it is machine processable and computable, i.e., it must be able to represent the syntactic nature of the data cont ained in these documents as well as the behavior in the form of semantic rules that are present in the certain operational documents (like Letter-of-Credit) and other mandatory codes enforced upon by the business process. Challenge 2  X  There needs to be a way to mine or retrieve the information available in natural language text in these documents. Standard techniques for named entity extraction and relationship extraction exists that generally uses supervised learning methods to improve the accuracy of extracted information [1]. The current state-of-the art with respect to entity and relationship extraction is accurate to the extent of 90% -77% respectively. However, the type of information that is extr acted generally tends to answer a different set of questions, which is rather explicit in the unstructured document and syntactic in nature. The kind of information we seek tend to be more semantic in nature, i.e., we would like to extract the behavior in terms of rules from the set of operational documents and then va lidate them against individual instances. Both the challenges are linked, i.e., one needs to know the class of rules and how the knowledge is re presented before any standard information retrieval technique s can be applied. Moreover, because of the difference in abstraction in the nature of information extracted and the rule language required to automate the verification, a third challenge may arise which will require suitable translators to bridge the abstraction gap. Nevertheless, we would first need to address Challe nge 1 before we take a deeper investigation dive towards resolving Challenge 2. Although in this paper, we describe the document verification problem in terms of International trade, the core idea is common to many other document intensive processes that require manual verification like Mortgage Processing, Medical Re porting, Financial Auditing etc. In order to represent the domai n concepts and knowledge with respect to International Trade, we firstly categorize the documents by their type. Classically, the entire document verification process as shown in Fig. 2, is governed by the Letter-of-Credit (LoC) that identifies the key stakeholders involved (e.g., Banks, Buyer, Seller, Carrier, Items or goods), the rules and regulations to follow along with what steps to resort to when an exception occurs. LoC varies from one trans action to another. Additionally there are other fixed guidelines and uniform customs code and practice (UCP 600) [2] that governs any transaction that takes place between the buyer and seller. In order to receive payment in lieu of shipment of goods, the seller produces a set of documents to the receiving bank. These documents are Bill-of-Lading, Commercial Invoice, Certificate of Origin, Packing List and Pre-shipment inspection document among others. The bank needs to verify these documents against th e terms and conditions as laid out in the LoC and UCP 600 (as laid out by the solid lines in Fig. 2). In addition to the above rules, there are internal validation rules that endorse the internal sanctity of these operational documents. These are s hown by dotted arrows. Fig. 3 shows the ontology for the entire set of documents that essentially captures the key concepts of International Trade. Some of the key entities in this ontology are Banks, Buyer, Seller, Transporter, Ordered Item, Cust omer Invoice, Shipping Detail, Customer Order Detail etc. Entities have typed properties that are either object types (e.g., hasBank ) or data types ( hasName ). A subset of the metamodel and sp ecific instances of documents (e.g., commercial invoice) for the International Trade domain is shown in Fig 4. As mentioned earlier, the documen ts contain rules in natural language text that needs to be formally captured for automated reasoning. Table 1 shows a subs et of 57 SWRL (semantic web rule language) rules [3] that we have manually constructed from present in the LoC and UCP 600 documents. Each rule has an antecedent and a consequent and has an abstract syntax similar to Horn-like rules. So far we have been only able to address Challenge 1, which was critical to solve before attempting Challenge 2. To solve Challenge 2, we propose an overall architecture as described in Figs. 5 and 6 that enables the dVaas platform. Fig. 5 shows the more generic architecture than can be used by any document verification process. The architecture shows that there are generally two types of documents  X  a) principal documents that are instance specific and b) general guidelines, standard operating procedures that are instance independent. Both a) and b) contains rules, however, only rules contained in a) needs to be automatically extracted (machine learning techniques) whereas those in b) can be manually encode d as this is a one-time activity. Supporting or instance specific documents are then validated processing engine. Although we do not describe in further details the internal steps, standard tec hniques such as parsing of natural language text to infer the grammatical units and then extracting binary relationship among entities in the text using ontology based scope expansion/restric tion is used. However a major challenge is to extract appropriate class concepts necessary for assembling the rule bodies of SWRL rules. Fig. 6 shows the specific architecture with respect to the given case study (i.e., International Trade). In the architecture, the fixed set of rules (as those present in UCP [2]) are manually encoded (one-time activity) and variable set of rules from LoC require natural language processing and machine learning techniques [1] for automated extraction. We believe that since there will be an abstraction gap between the named entities and relationship so extracted from the natural language text of LoC, a semantic bridge must be built as part of the extraction engine of Fig 6 to translate the named entities and corresponding relationship to a semantic bridge infers informati on in terms of the key actors of a rule, its underlying objective, and wh at events it can raise to meet its desired goal. For example, for rule 1 in Table 1, the key actors are BillOfLading , BookingNumber and InvoiceNumber , its objective (consequent) is to ve rify whether booking and invoice number is equal ( BookingInvoiceEqual ), and it must raise an event called equal to verify this objective . Thus the semantic Table 1. Translating textual rules to formal definition 
Figure 4. Metamodel and its instances for LoC Process bridge helps to bridge the class concepts necessary to assemble the rule bodies. Just like behavior is extracted in the form of rules by the extraction engine, the model instances or individuals X  needs to be extracted from the ope rational documents (see Fig. 6). A contextual parser is used verify the individual instances against the stored knowledge base (ontol ogy) and finally both the rules processing/knowledge engine for formal verification. An associated challenge in providing an automated solution towards dVaaS concerns with semantic equivalence of texts. Typically there are declarative statements present in multiple documents that have different phrasings but same meaning. An example is shown in Fig. 7. In such cases, we propose to apply contextual probabilistic based sema ntic matching techniques so as to establish equivalence relations hip between similar looking texts [4]. A contextual parser along w ith a probabilistic phrase feeder tries to establish relationshi p among subject and similarity analysis (text alignment) is carried out using suffix trees and dynamic programing techniques. Anything that matches below 50% is considered a no matc h and requires further manual intervention whereas anything that matches above 80% is considered a comprehensive match. Automatic semantic role labeling [5] is another useful tec hnique that will be explored in the light of the above challenge. This visionary short paper pres ents our initial line of attack towards analyzing document intensive business processes. The ideas presented are mainly focused on addressing Challenge 1 i.e., to create a suitable knowledge representation using ontology for a real life example from the financial domain -International Trade (LoC). However, the concepts developed are not just restricted to LoC but applicable to any other document intensive business processes. In addition, the opera tional behavior or semantics of the domain is captured using a rule language  X  SWRL. To address Challenge 2, we have proposed an architecture that uses supervised machine learning techniques with a core focus on semantic extraction of relationships to construct rules from natural language text. The idea presented in this paper is only a stepping stone towards realizing our broa der vision of fully automated intelligent document verification ( dVaaS) platform, which is largely unexplored within the scientific community. [1] Aggarwal, C. C., and Zhai, C., 2012. Mining text data , [2] Rodrigo, T. , 2011. UCP 500 to 600: a forward movement . J. [3] Hassanpour, S., O X  X onnor, M. J., and Das, A. K., 2011. A [4] Hassanpour, S., O X  X onnor, M. J., and Das, A. K., 2013. A [5] Gildea, D., and Jurafsky, D., 2000. Automatic Labeling of 
