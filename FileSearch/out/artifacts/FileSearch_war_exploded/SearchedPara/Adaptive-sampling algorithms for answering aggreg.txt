 1. Introduction
Many Web sites such as e-commerce sites and portals publish their data in HTML pages organized as hier-of books, such as Accessories and History . This node corresponds to a Web page that displays the sponding category, such as Warehousing and Encryption . These books are published as different pages.
The main reason for such a hierarchy is to allow easy browsing by Web users, who are able to browse the of Data Mining books by starting from the root page and following the path  X  X  Computers &amp; Internet  X  Databases  X  Storage  X  Data Mining  X  X .
 that competes with Amazon.com. In order to make marketing strategies for its own books, the company needs few sample queries the company would issue about Amazon.com books:  X  Query Q 1 : Find the average price of books on Warehousing . These books correspond to a class of a leaf node. nal node in the hierarchy.
 books to compute their average price. For query Q 2 , we access the pages of Databases books. Although period, and the retrieved data is already out of date.

In this paper, we study how to answer aggregation queries on Web hierarchies by sampling. Given a query, we sample some of the pages of relevant objects to compute an approximate answer to the query. We focus on the following three main challenges related to the problem of how to allocate Web-access resources to the
For instance, the number of books and average price of the Warehousing class could be very different from those of the Encryption and Distributed Computing classes. As of October 2004 in the Amazon.com $336, $78, and $91, respectively (probably some warehousing books had very high prices  X  what we call out-liers). A naive, random sampling approach is not an ideal method since it would require more samples to known a priori. Third, we need to estimate the quality of the answers computed using sampling.
The approach we adopt in dealing with these challenges is to use adaptive sampling, in which we progres-solution. They may, e.g., contain only a few books of moderate prices compared to the other relevant leaf may contain many expensive books on Landscape Architecture distributed over a large price range, whereas nodes about Computer Science books may contain only moderately priced books. Thus if we have a set of queries that ask for average prices of books in Landscape Architecture and only a few single queries on Computer Science , then in order to maintain a good estimation, we choose to oversample the Landscape Architecture books and undersample the Computer Science books.

In this study, we make the following contributions:  X  We formulate a new problem about answering aggregation queries on hierarchical Web sites. We propose adaptive-sampling algorithms for answering a single aggregation query (AVG/MIN/MAX), when the node in the query is a leaf node or an internal node.  X  We propose adaptive-sampling algorithms for answering a set of combined aggregation queries.  X  We conduct extensive experiments to evaluate these algorithms on both real and synthetic data sets. our algorithms for answering single AVG queries for leaf nodes and internal nodes. Section 4 presents our algorithms for answering single MAX/MIN queries on leaf nodes and internal nodes. Section 5 deals with 7 concludes the work. 1.1. Related work
Sampling is a process of selecting subsets of a population to estimate certain parameters about the popu-study how to use sampling techniques to answer aggregation queries online by reporting the progress of answering the aggregation query. Manku et al. [17] use non-uniform random sampling to propose algorithms ples of the document from the databases. Recently, there have been a number of studies on using sampling techniques to answer queries on data streams. See [8,7] for a good survey. 2. Problem formulation In this section, we formulate the problem studied in this paper.
 at the leaf node.

Queries : Each object has a value that interests us, such as the price of a book. We consider aggregation queries for average, maximum and minimum using the aggregate functions AVG, MAX, and MIN, respec-tively. An aggregation query on a node concerns the objects represented by this node and the aggregation then the query node is a leaf node. If we ask for the maximum price of the Databases books, then the query function (AVG, MAX, or MIN) and v is a node in the hierarchy. For instance, the query MAX( Databases ) this query.

Approximate answers with quality guarantees : Given a query c ( v ), we want to compute an approximate measure. The  X  X  X istance X  X  measurement depends on the aggregation function c . For instance, in the case of use quantiles to measure such a distance (Section 4 ).

Our methods for answering queries approximately rely on sampling (see also [1,2] for a preliminary version server side CPU occupation having in mind that at the same time thousands of different Web users probe the same CPU for different queries. We focus on how to make the best use of the available resources to improve threshold on the distance between the estimated answer and the real answer.
 we can obtain a good estimation with few resources. On the other hand, if the standard deviation is large, we need to allocate more resources to this leaf node in order to achieve a good approximation.
We propose a family of adaptive-sampling algorithms for different aggregation functions. Each algorithm isfied with the quality of the approximate answer.

Although in the present paper, we apply our approach to hierarchical structures, our algorithms also work in the more general case where we have to process a workload of aggregation queries whose answers depend on data that are distributed across various Web sites, and any pair of queries from the workload may share some data stored in more than one Web site. 3. Answering AVG queries
In this section, we consider how to answer an AVG aggregation query, denoted as AVG( v ), which asks for we want to get an average interval with a confidence of at least 1 d . 3.1. AVG query on leaf node val. There are two approaches that give us certain quality guarantees. The first one, called the Hoeffding
Limit Theorem, and it assumes that the sample is small compared to the size of the population, but large enough so that approximations based on CLT are accurate. 3.1.1. The Hoeffding approach
Theorem 3.1 (Hoeffding X  X  bound [12] ). Let x 1 ,x 2 , ... ,x X, with values in [a,b]. Denote their average by x  X  1 n have
Based on this theorem, given a set of n random samples x 1 of the real average l , we get from the above theorem:
Therefore, by solving for we get confidence interval :
The formula assumes that a lower bound a and an upper bound b are known. In our application domain, there values. For instance, if we know that all the books about databases at Amazon.com are at least $20 and at We can get exact a and b values by issuing such requests and retrieving the corresponding top record. confidence interval , Eq. (2) tells us how many random samples are needed. 3.1.2. The CLT approach l , and the standard deviation of the X distribution by r X
Based on the Central Limit Theorem (CLT), given n random samples x error parameter where z d is the  X  d  X  1  X  2 quantile of the sample distribution, and where x  X  3.2. AVG query on internal node
Now consider an AVG query for an internal node v . Let v have m descendant leaf nodes c on node v is to distribute the available resources equally to all leaves c be used on another leaf with a larger standard deviation, which may need more samples for a tolerable estimation.

We propose an adaptive-sampling algorithm for answering such a query approximately. Its main idea is to imate answer of high quality. The algorithm is formally described in Fig. 2 .
 c may not be accurate. As a consequence, the algorithm assigns either too many or too few resources to the c allocated in each iteration. The algorithm has two phases.
 leaves c 1 , c 2 , ... , c m , we assign d / m resources to each leaf.

Resource allocation in the ith iteration : It has two stages:  X  For each leaf c k , we compute the average l k and the standard deviation r previous iterations.  X  For each leaf node c k , we assign to it the following number of resources:  X  d r that we do not allow as large a difference in the number of resources allocated in each leaf as would have resulted had the allocation been proportional to the variance. Another reason for our conservative alloca-iterations.
 satisfied with the confidence interval of the estimated answer to the query, computed below.
Estimation of the query in the internal node : The quality D Q of query Q is measured as follows. Suppose leaves c 1 , ... , c m are relevant to the query, and their populations are n query node is n = n 1 + + n m . Then from error analysis (e.g., [20] ) we get are using. 4. MAX/MIN queries
Next we study how to answer MAX/MIN aggregation queries approximately by random sampling. We focus on answering a MAX query, and the results are similarly applicable to the case of answering a MIN a confidence d . 4.1. MAX query on leaf node
Consider the case where the query node in the MAX query is a leaf node. Given n resources, we allocate all of them to the leaf node to draw a set of random samples. We compute the maximum value M of these samples greater than t is 1 / . We can use the quantile of the maximum M of the samples to measure the quality of we consider the Chebyshev inequality.
 then for any P 0
The inequality can be used to give us a bound on the probability that j X l j P M l for the maximum value M in the samples. Thus using in the inequality = M l , we get ability that the value of an object relevant to the query is no less than M is at most 1 r fidence quantile for the value M .

Eq. (4) assumes that the average and the standard deviation of the random variable are known. We can use the samples to estimate these parameters. We estimate the average using the algorithms in Section 3 .As
Using the set of samples, we can estimate the average and standard deviation of X within a distance and dev with probability 1 d , respectively. (For the estimation of the average, see the previous section. greater than the / quantile of X with a probability 1 d , where / = / ( M , l , r )is
Therefore, with a confidence d , the value M is not less than the / quantile of X . 4.2. MAX query on internal node
If the node in the MAX query is an internal node, the answer to the query is similar to that of an AVG we do the following. We compute the average and the standard deviation of the samples drawn from this leaf confidence quantile of all the samples. The algorithm is given in Fig. 3 . 4.3. Queries on internal node
In Sections 3.2 and 4.2 , we saw how we can answer AVG or MAX/MIN queries on internal nodes. We can combine these two algorithms into one. If we have a query F on an internal node and an importance factor f ( f is r k for an AVG query, and 1 / k for a MAX/MIN query), the algorithm can be seen in Fig. 4 . 5. Answering multiple aggregation queries
In this section we study how to answer a set of aggregation queries given limited resources. For example, consider the hierarchy shown in Fig. 5 , on which we are given four AVG queries Q sampling.

One main challenge is taking into consideration the interrelationships among the queries. For example, node g contributes to the answers of three queries ( Q 2 , Q pling strategy we should follow.
 mation are considered to be more important, and deserve more resources in the next iteration. Notice that quality measures of all the queries. 5.1. AVG queries
We first focus on the case where all the queries are AVG queries. Formally, let Q be an AVG query on a node with k leaves, c 1 , ... , c k . Let a 1 , a 2 , ... , a have mation of each leaf by the error propagation formula.

Suppose we have estimated Q to belong in ( Q + D Q , Q D Q ) and we want to see how a small change, ,inthe estimation of one leaf (say, leaf c i ) can affect the previous estimation. We denote by D Q on the Query Q in the case the estimated standard deviation of the leaves are r i.e., D Q a estimation error, we have
A measure of this change is a weight which characterizes leaf c i . For a fixed , we can have k weights w under this setting, if a leaf node u is irrelevant to the query Q , then it has a zero contribution, since and D Q D Q u =0. Fig. 6 describes the -shake algorithm. 5.2. MAX/MIN queries at a certain iteration we have computed the max of query Q and standard deviations l k , r k , respectively, of leaf c node of Q i . Then the quantile /  X  M i ; l k ; r k  X  X  / Q much leaf c k contributes to the answer of query Q i . Fig. 8 visualizes / a very small ratio of the population of leaf c k is greater than the currently found maximum M d and i runs on the MAX queries to which c k contributes. Fig. 7 shows the algorithm. 5.3. Combined queries With combined queries we mean a combination of AVG and MAX/MIN queries posed at the same time. the same leaf for the MAX/MIN queries with the quantiles, and then merge the two needs into one which would be the amount of resources that the leaf would get. To merge we use a multiplicative factor that we tune according to the results of the experiments. The algorithm is found in Fig. 9 . 6. Experiments
We conducted experiments to evaluate the proposed algorithms for both real and synthetic data sets. We collected the real data on book prices from Amazon.com from March 2004 to July 2004. We implemented a gory is books on Database Design , which includes about 800 books. The total number of books collected was approximately 50,000. Fig. 16 shows the distribution characteristics of each category (leaf) after the
For the synthetic data, we used Mathematica to produce leaf nodes which have the same population and standard deviation as the leaf nodes in the real data but following a normal distribution. 6.1. AVG queries
The case of AVG Queries splits into AVG queries on leaf nodes and AVG queries on internal nodes. 6.1.1. AVG on leaf node
We first conducted experiments for AVG queries on leaf nodes of the Amazon.com book hierarchy, using 369 books, one with 2157 books, and one with 11,973 books. We set the confidence of an AVG query to be the algorithm. Fig. 10 and Table 1 show how the Hoeffding approach behaved for the three leaf nodes, when run, the figure shows the estimated average and the corresponding confidence interval. For the node with a the Hoeffding approach gave much better estimations.
 nodes with large populations.

Combining both approaches for the case where the query node is a leaf node, we see that they behave very well in estimating average values for large populations, with CLT being slightly better. The Hoeffding approach is more conservative, giving larger confidence intervals. For small populations, CLT should not be used while the Hoeffding approach may provide some tolerable results. 6.1.2. AVG on internal node
We evaluated the adaptive-sampling algorithm described in Section 3.2 on an internal node with two leaf standard deviation of 33.90. The second leaf node had 2157 books, with an average of 21.00, and a standard selected after many experiments. The best selection was one order of magnitude smaller than the combined population of all the nodes.) We also implemented a naive algorithm that allocates the same number of approach provided more accurate estimations of the average.

We also evaluated both approaches on synthetic data, and a query was posed on an internal node with two approach gave much better estimations of the real average than the naive one and that the behavior of our adaptive approach competes with the naive one. In Table 3 , we can also see the allocated resources with respect to the total sample size in each iteration for both experiments (real and synthetic data). 6.2. MAX queries
We have two cases: (1) MAX queries on leaf nodes; and (2) MAX queries on internal nodes. 6.2.1. MAX on leaf node
We implemented the algorithm described in Section 4.1 for answering a MAX query on a leaf node. For the 52.91. The real maximum value was 735. Fig. 13 and Table 4 show how the adaptive algorithm presented in an estimated maximum value with a high quantile. It found the real maximum value after 1800 resources were same figure, we can also see the computation of the MAX quantiles and how they approached 1 as the number of iterations increased. 6.2.2. MAX on internal node
For answering a MAX query on an internal node we implemented the algorithm presented in Section 4.2 dard deviation of 27.92. The average of the father was 37.59 and the maximum was 1930. For the runs we had tive algorithm already found the real maximum. For the naive approach, even after the fifth iteration, its found maximum was still far from the real maximum.

The synthetic data set followed a normal distribution. The first child had a size of 3396, an average of dard deviation of 28.15. The average of the father was 145.33 and the maximum was 421.71. Similar exper-iments followed.

Fig. 14 shows how our adaptive algorithm competes with the naive one for answering a MAX query on an function of allocated resources with respect to the total sample size.
 data. 6.3. Multiple queries 6.3.1. Multiple AVG queries We applied the -shake algorithm on a real data set drawn from Amazon.com with the hierarchy shown in
Fig. 5 (the characteristics of the tree nodes are shown in Fig. 16 ), and posed the four AVG queries Q behaved for this data set follows: Leaves a , b ,and c contribute only to Q
Q as shown in Fig. 17 . For the first iteration we equally assign eight resources to each leaf.
We compute the weight for each leaf. For leaf a , we have w 2 tribute to queries Q 2 , Q 3 , and Q 4 . For Q 1 we have Summing all the weights we get w a  X 
For leaf g we have w 1 g  X  0, w 2 g  X  0 : 55 10 5 , w 3 g w g  X  w 4 g  X  0 : 17 10 all the leaves in all the queries is W = w a + w b + + w h in this iteration, the number of resources we assign to leaf a is r tions in the first two iterations.
 mation. For instance, nodes a and b are both relevant to query Q others, since each query adds some weight to them. We also use a naive algorithm to compare it to the adaptive algorithm. We feed the naive algorithm with the same presample we drew in the first iteration of algorithm on the same set of queries and compare it to the adaptive algorithm.
We repeated the above experiments with a synthetic data set. The plots of Figs. 18 and 19 show how the two we can see clearly that the adaptive algorithm behaves much better than the naive one, which constantly rithm each leaf gets 2.5% of the total sample size in each iteration. 6.3.2. Multiple MAX/MIN queries
For multiple MAX/MIN queries, we implemented the algorithm described in Fig. 7 and ran it for both the how the algorithm competes in both the adaptive and naive cases. 6.4. Combined queries
We took the tree of Fig. 5 with the same characteristics and posed five queries, Q is zero. For example, in our case w avg 4 g 6  X  0, while w max somehow incomparable ( w max i refers to a quantile calculation,while w tion, and they are also of different magnitude) we need an adjustment to combine these two weights for calculating the total weight of the leaf. Our experiments show that the total weight of a leaf can be given by the formula W = c  X  W avg + W max , where W avg  X  that makes W avg and W max comparable. From our experience c can be given the value W
Running the algorithm and comparing the results with a naive one that assigns the same amount of data accordingly.

From the results we can see that the adaptive algorithms we have developed perform much better than the corresponding naive ones for both real and synthetic data sets. 6.5. Discussion tributed in various leaf Web sites and some queries sharing data and (b) we assume that each element in a probabilities, then we need to combine the two approaches. We are currently working on that. In the same work and in the present paper we use a brute force algorithm to compare our proposed techniques. They call it uniform algorithm while we call it naive algorithm.
 In order to compute confidence intervals we used two of the three approaches that were used in [11] . However, our work is different in that we are not interested in narrowing the time of computation of confidence intervals, but rather we focus on reducing the number of samples used to obtain good confidence intervals.

In order to answer MIN/MAX aggregate queries we approximate quantiles with the use of the Chebyshev inequality while in [17] quantiles are approximated by a variant of Hoeffding inequality with the help of non-uniform random sampling. Also in both works sampling without replacement is employed. However, the previous work focuses on space requirements in main memory when processing large data sets, while we do not have such concerns in the present paper.
 7. Conclusions
In this paper, we studied the problem of answering aggregation queries on data published in hierarchi-cal Web structures. We proposed solutions that approximate the answer to a query by sampling, assuming the query, and such information is not known a priori. We studied various cases of the problem, and developed corresponding algorithms. We have conducted extensive experiments to evaluate these algorithms.

Many open problems need to be studied further. For instance, we could develop more effective algorithms if some information about the distributions of the leaf nodes were known. We need more sophisticated algo-rithms when the data distributions of leaf nodes are skewed, especially if the sizes of the populations on the leaves are very different.
 Acknowledgement We thank Angelika Antonakos for proof reading the manuscript.

References
