 Learning to rank is a popular research area due to its widespread applications. This paper focuses on document retrieval. When learning to rank has been ap-plied to document retrieval, it aims to l earn a real-valued ranking function that induces a ranking order over the documents set of a query.

The existing ranking approaches can be summarized into three categories: pointwise, pairwise and listwise. The pointwise and pairwise methods[1,2] trans-form ranking problem into regression or classification problem. The listwise approaches[3,4,5] minimize the loss functions defined between the ranked list and the ground truth list. Theoretical analysis about the properties of the list-wise loss functions are also conducted. Fe n Xia[3] studied the consistency and soundness of the listwise loss functions, and Yanyan Lan[6] investigated the gen-eralization bound of the listwise loss functions based on Rademacher Averages.
Many listwise algorithms are developed, but no research is conducted to elab-orate the common characteristic of the listwise loss functions. What is more, the listwise losses are inadequate for IR where the high performance of the top documents in the ranked list is preferred, measure by NDCG. In this paper, we propose a framework for cost-sensitive listwise approaches. The cost-sensitive listwise loss functions are constructed based on the documents with weights. The framework reduces the task of setting weights for the documents to the task of setting weights for the document pairs. The weights of the document pairs are computed based on the NDCG. As an example, we develop a cost-sensitive ListMLE algorithm. Experimental results show that the proposed method out-performs ListMLE[3], RankCosine[5], AdaRank[7] and Ranking SVM[2]. NDCG[8] evaluates the performance of the top documents in the ranked list. Suppose n candidate documents are retrieved for a query. Each candidate docu-ment d i is represented as a pair ( x i ,y i ), where x i denotes the query-document pair feature vector and y i is the relevance level. The NDCG@k is defined as: where k denotes the truncation level.  X  is the ranked list generated by a ranking function. g denotes the ground truth list obtained in the document relevance level descending order. g ( j )and  X  ( j ) denote the ground truth ranking position and the ranked position of the document d j respectively. I [ x ] yields one if x is true and zero otherwise. Assume that the ranking function is f , then the ranked position  X  ( j ) is computed from: where f ( x i ) denotes the rank score of the document d i . If there are many doc-uments sharing the same relevance level with the document d j ,itisimpossible to state the definite value of g ( j ). So the approximate value g ( j )isgiven. It is obvious that g ( j )  X  g ( j )foreach j , which implies the inequality. Then the NDCG@k lo ss, abbreviated L ndcg @ k , has a upper bound. 3.1 Existing Listwise Loss Function The listwise approaches take documents lists as an instance, and minimize the loss functions defined between the ranked list and the ground truth list. Typical methods include ListNet[4], RankCosine[5] and ListMLE[3]. We review their loss functions. For the sake of describing simply, the documents have been ranked by the relevance level in descending order, i.e., y 1 y 2 ... y n .

RankCosine L = where  X  is a positive and strictly increasing function. f ( x i ) is the rank score of the document d i computed by the ranking function f .  X  y is a mapping function defined on the relevance level and preserves ground truth list, i.e.,  X  y ( y 1 )  X   X  document with ranked position being at i . 3.2 Analysis of Listwise Loss Function Several listwise approaches are developed, but no analysis is studied to elaborate the common characteristic of the listwise loss functions. In this study, we point out that the listwise loss functions are in essence built upon the probability of ranking a document highest among the documents set, defined as where  X  denotes an increasing function. The existing listwise loss functions can be expressed in terms of the function h .
 To minimize the listwise loss function is equivalent to minimizing the function h . The reason for the goodness of these loss functions is that h is closely re-lated to the pairwise classification error. The conclusion is simply proved in the following. The above inequalities can be verified with I [ z&gt; 0]  X  log 2 (1 + exp( z )) and that the pairwise classification error is inadequate for IR where the ranking order on the top of the ranked list is crucial. Hence, the listwise losses are also inadequate for IR since their key component h is closely related to the pairwise classification error. 4.1 Cost-Sensitive Listwise Loss Function To make the listwise losses focus on the ranking order on the top of the ranked list, a good way is to take account of cost-sensitive in the listwise losses, more precisely, to set different weights for the documents. The function h is redefined by imposing weights for the documents: where  X  i =(  X  i, 1 ,..., X  i,n ) and its components are nonnegative.  X  i,j is the weight of the document d j . The function h canbealsoexpressedasintheform based on the document pairs with weights. h ( x i | x 1 , x 2 ,..., x n ;  X ,  X  i )= where  X  i,j / X  i,i is the weight of the document pair ( d i , d j ). The cost-sensitive listwise approaches focus on the performance of the top documents in the ranked list, measured by NDCG. Therefore, one important issue is to relate the weights of the documents with the NDCG. We formulate the problem of setting weights for the documents into the problem of setting weights for the document pairs. In this study, the weights of the document pairs are theoretically given. 4.2 Bound NDCG Errors by Cost-Sensitive Listwise Loss Function In this section, it is proven that the cost-sensitive listwise losses are the upper bound of NDCG loss. The theorem states definite values of the document pairs X  weights. Theoretical proof is based on the lemma 1. For notational simplicity, let a ( i )=2 y i  X  1, b ( j ) and its gradient  X  b ( j ) are defined as: It is simple to prove that the NDCG@k loss L ndcg @ k has the following upper bound on the basis of equation (5). Due to space limitation, we omit the proof. L Lemma 1. The NDCG@k loss L ndcg @ k is upper bounded by weighted pairwise classification loss.
 L where C 2 denotes a constant. The proof is given in the Appendix A. For each query in the training set, the ranking position g ( j ) of the document d j is easily computed. Therefore, the weights of the document pairs of each query can be calculated at once in training. Based on the lemma, we can justify the correlation between cost-sensitive listwise loss and NDCG@k loss 1 .
 Theorem 1. The cost-sensitive listwise loss is the upper bound of NDCG loss L C 2 denotes a constant that is same to the constant in the lemma 1. Based on z j and w j are nonnegative. The theorem demonstrates that many cost-sensitive listwise approaches can be proposed to directly optimize NDCG. For example, we can transform the existing listwise approac hes to cost-sensitive listwise methods. Meanwhile, the theorem states definite values for all the weights  X  j and  X  j . 4.3 Differences from Cost-Sensitive Ranking SVM The cost-sensitive Ranking SVM[1] and the framework for cost-sensitive listwise approaches both make use of cost-sensitive learning in learning to rank, but there are several differences between them. First, the training instance assigned weights is different. The cost-sensitive Ranking SVM weights on the document pairs. The framework credits the weights for the documents. To solve the problem of setting weights for the documents, the framework reduces it into the task of setting weights for document pairs. Second, the way to calculate the weights of the document pairs is different. The cost-sensitive Ranking SVM sets the weights by the heuristic method. The framework directly computes the weights based on NDCG@k.

Third, the relationship between the loss functions and NDCG loss is also differ-ent. The cost-sensitive Ranking SVM do not solve the problem. The framework proves that the listwise losses are the upper bound of the NDCG loss. 4.4 A Case: Cost-Sensitive ListMLE Ranking Approach To verify the framework, we propose a novel cost-sensitive approach named CS-ListMLE(cost-sensitive ListMLE). The loss function on a query is defined as: The weights are computed according to Theorem 1. The ranking function of CS-w denotes model parameters. We takes gradient descent method to optimize the loss function. Since the loss function is convex, the model parameters converge to a global optimal solution. The algorithm is provided in Figure 1. The experiments are conducted on t hree datasets OHSUMED, TD2003 and TD2004 in Letor2.0 2 . The experiments validate the two points. The one is that whether CS-ListMLE outperforms the ListMLE. The other is that whether CS-ListMLE can obtains higher performance than the other baselines on the top documents of the ranked list. MAP and NDCG@k(N@k) are used as evaluation measures. The truncation level k in NDCG@k is usually 1, 3, 5 and 10. The performances of ListMLE and RankCosine are directly taken from [9], where both approaches do not provide their performance at NDCG@5 and MAP.
To validate the effectiveness of CS-ListMLE, we train the algorithm with dif-ferent parameters. CS-ListMLE@ k claims that cost-sensi tive ListMLE focuses on the top k documents rank order in the ranked list. It means that CS-ListMLE@k directly optimizes NDCG@k. In the experiments, the k takes 1, 3, 5 and 10. 5.1 Ranking Accuracy of ListMLE and Cost-Sensitive ListMLE We report the performance of cost-sen sitive ListMLE and ListMLE on three datasets in Table 1, 2 and 3. The cost-sensitive ListMLE significantly outper-forms ListMLE on the datasets TD2003 and TD2004 in terms of all evaluation measures, while their perform ance is comparable on OHSUMED.
 We explain why CS-ListMLE remarkably outperforms ListMLE on datasets TD2003 and TD2004. On one hand, each query in datasets TD2003 and TD2004 has 1000 documents. The ratio of the queries containing at most 15 relevant doc-uments in all queries is 95% and 89.3% re spectively. Since ListMLE considers all the document pairs, 95% and 89.3% queries loss functions of ListMLE in-duces the losses caused by 484620 irrelevant document pairs. As is well known, the NDCG loss is not sensitive to the losses generated by the irrelevant document pairs. Thus, ListMLE introduces a large deviation from the NDCG loss. How-ever, CS-ListMLE only cares about the document pairs composed of relevant documents and irrelevant documents. On the other hand, ListMLE treats the all documents equally. But CS-ListMLE assigns the weights for the document based on NDCG@k. In summary, the loss of CS-ListMLE is more close to NDCG@k loss than ListMLE on datasets TD2003 and TD2004.

As far as dataset OHSUMED, 81.1% queries have less than 200 documents, while 85.89% queries contain at least 10% relevant documents. Under such situ-ation, the weights of the documents does not affect much in CS-ListMLE. The loss of CS-ListMLE is approximate to the loss of ListMLE. 5.2 Comparison with the Other Baselines We take CS-ListMLE@1 as an example to compare the performance with the other baselines, including RankCosine[5 ], ListNet[4], RSVM[2] and AdaRank[7]. Experimental results are presented in Table 4, 5 and 6. CS-ListMLE almost out-performs RankCosine, AdaRank and Ranking SVM on three datasets at all eval-uation measures. Compared to ListNet, CS-ListMLE obtains higher performance at NDCG@1. We conduct t-test on the improvement of CS-ListMLE over List-Net, Ranking SVM and AdaRank on the three datasets in terms of NDCG@1. The results indicate that the improvement of NDCG@1 over Ranking SVM and AdaRank on dataset OHSUMED is statistically significant(p-value &lt; 0.05). There is no statistically significant difference on dataset TD2003 in spite of rising 6% over AdaRank and Ranking SVM.

Experiments results demonstrate that the CS-ListMLE can achieve high per-formance on NDCG@1, which meets the goal that the CS-ListMLE focuses on the top one documents ranking order of the ranked list. Meanwhile, the cost-sensitive ListMLE obtains comparable performance to the baselines at MAP. In this paper, we point out that the existing listwise losses are inadequate IR where the documents with higher ranks should be emphasized. To address the issue, we propose a framework for cost-sensitive listwise approaches. The frame-work credits weights for the document s. The framework reduces the problem of setting weights for the documents to the problem of setting weights for the document pairs. The weights of the document pairs are computed based on the NDCG. It is proven that the cost-sensitive listwise loss is the upper bound of NDCG loss. As an example, we develop a cost-sensitive ListMLE approach. Ex-perimental results show that the cost-sensitive ListMLE outperforms ListMLE on two benchmark datasets in terms of all evaluation measures. In addition, the cost-sensitive ListMLE almost outperforms the baselines, such as RankCosine, AdaRank and Ranking SVM, on the three datasets at all evaluation measures.
