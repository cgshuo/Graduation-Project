 ORIGINAL PAPER Wonkyo Seo  X  Hyung Il Koo  X  Nam Ik Cho Abstract In this paper, we present a method that locates tables and their cells in camera-captured document images. In order to deal with this problem in the presence of geo-metric and photometric distortions, we develop new junc-tiondetectionandlabelingmethods,wherejunctiondetection means to find candidates for the corners of cells, and junc-tion labeling is to infer their connectivity. We consider junc-tions as the intersections of curves, and so we first develop a multiple curve detection algorithm. After the junction detec-tion, we encode the connectivity information (including false detection) between the junctions into 12 labels, and design a cost function reflecting pairwise relationships as well as local observations. The cost function is minimized via the belief propagation algorithm, and we can locate tables and their cells from the inferred labels. Also, in order to han-dle multiple tables in a single page, we propose a table area detection method. Our method is based on the well-known recursive X-Y cut, however, we modify the method so that we can also deal with curved seams caused by the geometric distortions. For the evaluation of our method, we build a data set that includes a variety of camera-captured table images and make the set publicly available. Experimental results on the set show that our method successfully locates tables and their cells in camera-captured images.
 Keywords Camera-based document analysis and recognition (CBDAR)  X  Table detection  X  Junction detection Table understanding 1 Introduction As mobile devices equipped with high-performance digital cameras are widely available, demands to digitize printed materials with digital cameras have been rapidly increasing. It is because digital cameras have a number of advantages over the flatbed scanners, such as portability, fast response, and non-contact properties [ 14 ]. In order to widen the areas of these camera-based applications, we address the table detec-tion problem in the camera-captured images: This allows us to convert printed tables to computer-readable forms and we can use them in data retrieval, storing, and reproduc-tion. Also, when incorporated with the existing camera-based document analysis methods for the text-abundant images [ 15 , 27 ], this table detection method can improve the over-all layout analysis and optical character recognition (OCR) performances.

Since tables in documents contain valuable information summarizing and/or comparing contents, table recognition have received a lot of attention in document image process-ing community, and a number of methods have been devel-oped to address this problem [ 9 , 29 ]. However, the conven-tional methods were developed for the images from flatbed scanners, where the table boundaries are assumed to be these methods cannot be used for the camera-captured doc-uments where this assumption fails due to the geometric dis-tortions caused by projective transforms and curved docu-ment surfaces. In order to alleviate the limitations of the conventional methods and take the advantages of camera-based approaches, we present an algorithm to localize tables and their cells in camera-captured images. To the best of our knowledge,therehavebeennoalgorithmstolocatetablesand cells in camera-captured images, like the example in Fig. 1 . 1.1 Table detection in scanned documents For decades, a number of methods have been proposed to recognize the tables in scanned document images. Hu et al. [ 9 ] developed a table detection algorithm in single column document images, where they formulated the table detec-tion problem as an optimization task by devising table qual-ity measures. The approach proposed by Mandal et al. [ 16 ] was based on the observation that the gaps between the table columns are larger than the word gaps. Based on this obser-vation, they were able to select the text-lines that possibly belong to table regions. Shafait et al. [ 22 ] presented a table detection algorithm for the multi-column document images. In the paper, they first determined the layout of the page with tab-stops, and then, detected tables using the layout and other clues such as text alignment and gap between text compo-nents. Kieninger et al. presented a table detection and recog-nition system called T-Recs [ 10 , 11 ]. Using the bounding boxes of words, the system detected table cells. Since tables having horizontal and vertical ruling lines are very common, many researchers focused on these cases. Zheng et al. [ 31 ] proposed a line detection algorithm based on the directional single connected chain (DSCC) and identified table bound-aries. In a similar spirit, table regions were detected from the boundary detection and table reconstruction method, where the horizontal and vertical lines were estimated using a set of morphological operations that connect broken lines, and tables were reconstructed using the intersections of detected table lines.

In addition to the ruling lines, the intersections of table boundaries (junctions) are also important features of tables, and some researchers exploited junctions for the table detec-tion. Taylor et al. [ 26 ] classified junctions into 9 cases, and detected and classified these junctions by template matching. However, the complexity of the template matching is very high, and Arias et al. [ 1 ] proposed a more efficient method. Neves et al. [ 19 ] located and identified junctions using mor-phological operations and hierarchical relationships. In their work, they introduced a label to handle non-real junctions, and therefore, they were able to handle the false detection of junctions.

For the table detection in scanned documents, the con-ventional methods exploited a variety of features (e.g., text-lines, gaps between the words/columns, table boundaries, and junctions). However, they were based on the assump-tion that the text-lines and table boundaries are straight and parallel. However, they are neither straight nor parallel in camera-captured images (due to perspective and geometric distortions), and thus the above referenced methods cannot be straightforwardly applied to the camera-captured cases. 1.2 Camera-based document image processing Since mobile devices equipped with high-performance dig-ital cameras are widely available, there have been a lot of research activities to replace flatbed scanners with digital cameras. Since the document images captured by the cam-eras usually suffer from geometric distortion, the reduction of this distortion (also known as document dewarping) is one of the main steps for the document analysis. For the reduction of such distortions, we have to know the 3D struc-tures of surfaces, and the document dewarping algorithms (explicitly/implicitly) estimate the document surfaces from several cues. Some methods were based on the specialized hardwares or stereo-vision systems [ 3 , 28 ] and other methods exploited the specific properties of documents such as text-lines [ 4 , 23 ]. There have been so many researches in docu-ment dewarping, and so we might think that the table detec-tion in camera-captured images can be addressed by apply-ing (i) dewarping techniques and then (ii) conventional table detection algorithms for scanned documents. However, this sequential approach has limitations (these approaches will also be discussed in Sect. 4.1 ). First, the document dewarp-ing algorithms are computationally demanding. Second, the dewarping algorithms were developed to improve OCR per-formance, and they basically work for the text-abundant cases. 1.3 Overview of our algorithm Tables can be detected from the junctions and their labels as shown in Fig. 2 , where the junctions encode the locations of cells, and their labels represent the connectivity infor-mation. Therefore, our table detection algorithm consists of two steps: (a) junction detection and (b) junction labeling. Although there are various table forms, we focus on the cases where tables consist of horizontal and vertical lines. That is, we can locate junctions through the curve fitting and intersection computing. The junction labeling is formulated as an optimization problem, which considers pairwise rela-tionships as well as local observations. The cost function is minimized by the belief propagation algorithm [ 24 , 25 ], and we locate cells from the inferred labels. 1.4 Challenges and our approaches Challenges in our problem are twofold. First, the camera-captured document images suffer from geometric distortions. Whereas the boundaries of tables are straight and parallel in scanned documents, they are neither straight nor parallel in camera-captured images. The second one is that camera-captured images usually suffer from uneven illuminations and thus binarization results may be poor. That is, in conven-tionalcases,wecanfindjunctionsbydetectinghorizontaland vertical straight lines (e.g., by tracing contours) and classify them under thenoise-freeassumptions. Ontheother hand, we have to find complex curves in the presence of noisy objects and the algorithm should be able to handle broken curves (i.e., a single curve is broken into multiple pieces). In order to deal with the first challenge, we develop a robust junction detection method consisted of filtering, table area detection, and curve detection steps. The filtering step is to remove the non-table components in binary images so that we can find the curves more easily. Table area detection step guarantees that there is at most one table in each region, and it simpli-fies the curve detection procedures. In the curve detection step, we find the curves with the random sample consen-sus (RANSAC) algorithm and compute their intersections. In this step, we also (partially) address the second challenge using line-segments as seeds for curve generation. After the junction detection, we have to assign the labels to them. In this process, the label assignment based solely on the local observation is not adequate due to the errors in binarization originated from the second challenge. In order to address this problem, we develop a labeling method considering the pairwise relations as well as local observations. In our frame-work, false junctions (false detection) can be easily handled and we can alleviate the problems in the junctions detection step. 2 Junction detection For locating the junctions, we first binarize an input image as shown in Fig. 3 a, b. Then, we find the curves in the binary image with the RANSAC algorithm and locate the junctions by computing their intersections. 2.1 Binarization Camera-captured document images suffer from uneven illu-minations as shown in Fig. 3 a and this deteriorates the bina-rization performance. In order to alleviate this problem, we adopt a binarization method based on the retinex filtering [ 20 ]. In this approach, the binary image I B is given by I ( x , y ) = 1 I where G  X  I is Gaussian filtered image of I , and  X  1 is a threshold. In order to suppress the noisy responses on dark andhomogeneousregions.Wealsoimposeanadditionalcon-dition in [ 13 ]: |
I ( x , y )  X  ( G  X  I )( x , y ) | &gt; X  for I B ( x , y ) = 1. We used the values in [ 13 ]for  X  1 i.e.,  X  1 = 0 . 99 and  X  2 = 12 . 75. 2.2 Filtering In order to detect the curves in a binary image I B as shown in Fig. 3 b, we adopt the RANSAC algorithm that can estimate parametric models in the presence of outliers. However, since lower outlier ratio improves its efficiency and accuracy, we first filter out the irrelevant components (non-table compo-nents) as shown in Fig. 3 c. For the filtering, we first extract connected components (CCs) in the 8-neighborhood system, where the CCs usually consist of table boundaries, text com-ponents, and noise. When the binarization results are suffi-ciently good, the boundary of a table consists of a single CC. However, the boundaries of tables may also be segmented into multiple parts due to the imperfection in binarization. In order to deal with them, we develop a simple classification method. More specifically, let us denote a set of pixels in a given CC as C ={ ( x where N is the number of pixels in the CC. The covariance matrix of C can be decomposed into: =  X  ing eigenvectors. We are interested in the line-segments (bro-ken table boundaries) satisfying max ( X  1 , X  2 ) min ( X  1 , X  2 ) or large but sparse structures showing  X   X 
N as illustrated in Fig. 4 b, c. The CCs satisfying neither ( 5 ) nor ( 6 ) are considered as irrelevant ones (examples are shown in Fig. 4 d) and we filter them out. We also suppress the CCs whose size is less than a threshold . CCs might be thick (i.e., more than one pixel wide) and this prevents the accurate localization of curves. Hence, we apply thinning operator and denote this image as I cc . 2.3 Table area detection for camera-captured images Given I cc , we partition the page into several regions so that each region has (at most) one table. Among many page Algorithm 1 Table area detection decomposition methods, the recursive X-Y cut is a famous top-down approach for the scanned images [ 7 , 18 ]. The algo-rithm builds projection profiles by accumulating the pixels into X and Y directions and selects the widest gap in these two profiles. Using the selected gap, the page is decomposed into two regions. This algorithm is recursively applied to each region until the widths of all gaps are less than a certain threshold. Although this is a very successful algorithm, it was developed for the scanned images and thus we cannot apply this algorithm to camera-captured document images, because the boundaries are curved and closely placed as shown in Fig. 5 a. Therefore, we develop a new table area detection algorithm as summarized in Algorithm 1. As shown, the flow is similar to the original X-Y cut algorithm; however, we find the optimal paths with the dynamic programming in order to handle the curved boundaries. Similar to the idea in [ 2 , 32 ], where the optimal paths were used for the contents-aware image resizing and text line extraction, respectively, the cumulative energy map d y in the Algorithm 1 is given by d ( i , j ) = min ( d where G  X  is the Gaussian blurred image of I cc .Weuse smoothed images to prevent any seam from passing through a crack of the table, and a small positive constant  X  makes seams less bent. The other cumulative energy map d x is sim-ilarly defined. 2.4 Multiple curve detection After the table area detection, we have one table per each image segment as shown in Fig. 6 a, c. Even though we try to filter out the irrelevant components in Sect. 2.2 , the multiple curve detection is still a challenging problem and we devise an iterative method. Since we assume generalized cylindrical surfaces models [ 14 ], we use the fourth-order polynomials for the horizontal boundaries, and straight lines for the verti-cal boundaries. We also assume that the boundaries have low curvatures so that they are approximated with straight lines locally [ 12 ].

Our method to find the curves consists of three steps: (i) candidate curve detection, (ii) curve refinement with RANSAC, and (iii) redundant curve removal [ 12 ]. To be precise, we detect the line-segments using the probabilistic progressive Hough transform (PPHT) [ 17 ]. Since the table boundaries are locally straight, this transform provides initial line-segments as shown in Fig. 7 a. We consider the detected line-segments as straight lines by extending their end points, and consider the edge points around each line as a putative set for its refinement as shown in Fig. 7 b, and apply the RANSAC algorithm to the set in order to get a refined curve. The curves passing many points are considered better solu-tions and we use the RANSAC result as a refined curve as showninFig. 7 c. As the curves are refined, we update the putative sets according to the refined curves, and repeat this procedure until convergence. After applying our curve refine-ment step to all the line-segments (PPHT results), we remove redundant curves among them. For this goal, we select the closest pair among all pairwise relationships, and remove a curve having a small number of inliers in that pair if their distance is less than threshold. Here, we define the distance between two horizontal curves ( y = f 1 ( x ) and y = f 2 min | f 1 ( x )  X  f 2 ( x ) | (8) and the distance is similarly defined for vertical ones. We also repeat this removal step until there is no curves to remove. As shown in Fig. 6 b, d, this step allows us not only to remove redundant lines but also to deal with double lines. 3 Junction labeling We define junctions as the intersections between horizontal and vertical curves, and two junctions are considered adja-cent when they are neighboring on the curves horizontally or vertically. We represent the detected junctions as a graph G ={ V , E } , where V is a set of junctions and ( p , q )  X  means that p and q are adjacent. 3.1 Labels Since we regard the junctions as the intersections of table boundaries, there are 9 cases as shown in Fig. 2 . However, some of the detected junctions may be false positives (due to the false detection of curves) and we augment 3 labels for them. In summary, we define 12 labels as shown in Table 1 , in N(orth), E(ast), and S(outh) directions and other labels are similarly defined. Label ( 1 , 0 , 1 , 0 ) and ( 0 , 1 , 0 the junctions of tables, but they are the intersection between the true boundary and a falsely detected curve. Similarly ( 0 , 0 , 0 , 0 ) stands for an intersection between two falsely detected curves. Therefore, we can handle false positives in the curve detection using 12 labels in Table 1 . Let us denote the label of a site p as L where u p , r p , d p , and l p  X  X  0 , 1 } . 3.2 Our formulation for labeling Given a graph G , we formulate the junction labeling problem to find L ={ L p } p  X  V as  X  L = arg min E ( L ) (10) where the cost function consists of singleton and pairwise terms. To be precise, it is given by E (
L ) = where V p ( L p ) is a data term reflecting the local observations around p , and W p , q ( L p , L q ) is a pairwise term imposing constraints on the adjacent pairs. 3.3 Cost function and optimization To design a data term in ( 11 ), we use local observations around each junction as shown in Fig. 8 . To be precise, the data term in V p ( L p ) in ( 11 ) is defined as the negative log-likelihood V ( L and we define the likelihood of L p = ( a , b , c , d ) as f ( L where P ( u p = 1 ) is the probability that there exists a valid line in the upper direction at site p , and P ( u p = 0 ) probability that there is no valid edge in that direction. Specif-ically, when we observe n pixels along the curve and k pixels among them are edge points (black pixels in Fig. 3 c), we have P ( u p = 1 )  X  p k e ( 1  X  p e ) n  X  k (14) P ( u p = 0 )  X  p k f ( 1  X  p f ) n  X  k (15) where p e is true positive (of table boundary detection) and p is false positive ratios. Other terms are similarly defined. As an example, let us assume that there are k N , k E , k S , and k edge pixels on four curves, respectively (North, East, South, West directions from the junction), as shown in Fig. 8 . Then, the likelihood of being L p = ( 1 , 1 , 1 , 0 ) is given by f ( L Since the junction labeling based on only local observation may result in inaccurate and inconsistent results, we also exploit constraints between the labels. For example, let us assume that p and q are horizontally adjacent, p is at the left side of q , and L p = 1 . Then, L q can be { 2 , 3 , 4 , 9 , 10 }, however, { 1 , 5 , 7 , 11 , 12 } and { 6 , 8 } are not allowed. In the former case, L p = 1 indicates there is an edge in the right-hand side direction. However, labels in { 1 , 5 , 7 , 11 , 12 } mean that there is no valid edge in that direction. In the latter case, { 5 , 6 , 7 , 8 } can only be located at four corners of tables and L q  X  { 6 , 8 } is not allowed. Based on these observations, we set the pairwise term W p , q ( l p 0 for admissible pairs and a very large value otherwise. The cost function in ( 11 ) is minimized via the belief propagation algorithm and we have the optimal labels for p  X  V . 3.4 Table detection Given a graph { V , E } and the labels of sites as shown in Fig. 10 , we can locate each cell. However, some tables do not have left and right boundaries as shown in Fig. 9 e. In order to deal with such cases, we find illusory lines by connecting the vanishing point (the intersection of vertical straight lines) and the end points of horizontal lines. Finally, in order to reduce the false detection rates of tables, we measure the minimized energy ( 11 ). Since true tables have enough edge pixels for all junctions and their labels are consistent, the cost is usually small. Therefore, our criterion for the rejection is 1 |
V | min E where | V | is the number of sites in V . 4 Experimental results Several parameters are involved in our algorithm:  X  1 , X  2 in the filtering step,  X , V th in the table area detection step, n , p e , p f in the junction labeling step, and E th in the veri-fication step. In all the experiments, we set  X  1 = 10 , X  0 . 2 , = 100 , X  = 0 . 1 , V th = 50 , n = 10 , p e = 0 . 9 , 0 . 1, and E th = 12. Also, in PPHT, we set the minimum line length to 30, and the maximum gap between the line-segments to 5. Some of these parameters should be changed according to the scale of tables and resolution of inputs, which is not feasible in practice. Rather, we assume that the input images roughly contain a single page and resize them to one mega-pixel ones before applying our algorithm. Since images are normalized, our parameter set works for a range of inputs. We used the same parameters for all experiments.

To the best of our knowledge, this is the first approach that addresses the table detection problem in camera-captured document images. Therefore, we could not find public data set for this problem, and we build our own consisted of 38 tables on curved surfaces (1,295 cells) and 47 tables on pla-nar surfaces (1,162 cells), and evaluate the performance of our method. Also, we conducted experiments on synthetic images for the quantitative evaluation of our method for var-ious geometric distortions. Our database and experimental results are publicly available at http://ispl.snu.ac.kr/~cusisi/ TableDetection . 4.1 Experiments on real images Experimental results on real images are shown in Fig. 9 .As shown, our algorithm is able to handle multiple tables in a single page, tables having a small number of cells (Fig. 9 a), double lines (Fig. 9 b, c), and open cells (Fig. 9 e) in the pres-ence of geometric and photometric distortions. For the objec-tive evaluation, we compute the precision ( P ) and recall ( R ): P = tp where tp is the number of correctly located cells (true posi-tives), N is the number of detected cells, and M is the number of cells in the ground truth. We also define F -measure as a harmonic mean of precision and recall: F = 2 The results of our algorithm for curved and planar surface are summarized in Table 2 .

Since we could not find a method that deals with the table detection problem in camera-captured images, we develop a reference method consisting of a dewarping algorithm and a conventional table detection algorithm: We rectify images with the dewarping algorithm [ 30 ] and apply the table detec-tion method [ 6 ]. Here, we adopt the dewarping algorithm in [ 30 ] because the method works without strict assumptions on text and layouts. Some results are shown in Fig. 11 , where red lines represent detected tables by the reference method. The reference method works for many cases, but it has some limitations: (a) the dewarping process requires user interac-tion, (b) it is computationally demanding (it takes several minutes), and (c) the overall performance is sensitive to the dewarping results as shown in Fig. 11 d.

We also conduct experiments on scanned documents, con-sisting of 27 tables (682 cells), and compared the perfor-mance with the conventional method for scanned documents [ 6 ]. Our algorithm achieves P = 0 . 991 , R = 0 . 973, and F = 0 . 981, while the method [ 6 ] yields P = 0 . 976 , R = 0 . 907, and F = 0 . 94. This shows that our algorithm com-pares favorably with the conventional method even for the scanned documents. 4.2 Experiments on synthetic images We also evaluate our method on synthetic images in order to analyze the effects of shot angles and curved surfaces quan-titatively. For the modeling of curved surfaces, we use the fourth-order polynomials similar to the approach in [ 30 ] and increase its complexity by multiplying parameter s  X  X  0 , to its coefficients. For the simulation of perspective pro-jection, we randomly select the rotation matrix of a cam-era [ 8 ], so that its norm is in [ 0 ,  X  3 ] . Finally, we apply 5  X  5 Gaussian filter in order to simulate the image acqui-sition process. Our experimental results are summarized in Fig. 12 . As shown, our method works reliably for a range of shot angles and document surfaces. Especially, our algo-rithm works well for a range of book surfaces when the rotation angle is less than 30  X  , and we believe that tak-ing pictures in this range is not a difficult task even for common users. Some synthetic image results are shown in Fig. 13 .
 4.3 Limitations Poor performance of our method for severe geometric and perspective distortions are mainly caused by: (a) self-occlusions and (b) high curvatures (curves having high curva-tures cannot be approximate with lower order polynomials). However, in practical situations, our algorithm sometimes fails as shown in Fig. 14 . The most common and important case is presented in Fig. 14 a, b: blurred images yield poor binarization results and our method fails to locate all cells due to the small number of detected edge points. Fig. 14 c, d also shows an interesting (even though not very common) case. Two lines (highlighted by arrows) in Fig. 14 c are differ-ent but parallel lines. However, our algorithm considers these two lines as a single one (because they are very close) and fails to assign correct labels to junctions on them as shown in Fig. 14 d. 4.4 Table verification performance Finally, we conduct experiments on document images with-out tables. Since document image dewarping contest data set in CBDAR  X 07 [ 21 ] is publicly available and does not con-tain ruling-based tables, we apply our algorithm to the set in order to test our table verification rule in ( 17 ). There are 102 images in the set, and our algorithm detected 3 tables even with the verification step. However, as shown in Fig. 15 ,false alarms were due to the table-like structures (which may be considered the tables) and there were no false alarms on the text-regions. 4.5 Computational complexity We implemented and tested our method on a computer with a Core i5 3.4-GHz Intel processor. Since the curve detection and junction labeling are performed for each table region, the overall computation time is proportional to the number of tables. However, in general, it takes 0.2 X 1.0s with our unop-timized C++ code and its memory requirements are moderate (about 10MB). The computational bottleneck in our method is the curve detection step presented in Sect. 2.4 . Its com-plexity depends on the number of line-segments provided by PPHT and it usually takes 0.1 X 0.6s (about 80% of the overall procedure). Although the complexity of the belief propaga-tion algorithm is generally high, we have only dozens of sites and its computation time is negligible (2 X 3ms) compared with the overall processing time. 5 Conclusion In this paper, we have proposed a table detection algorithm for the camera-captured document images. We decomposed the problem into two sub-problems and addressed each prob-lem by developing robust techniques. Specifically, we con-sidered junctions as the intersections of curves and devel-oped multiple curve detection algorithm. Also, the junction labeling problem was formulated as an optimization prob-lem considering local observations and pairwise relation-ships. Experimental results show that our algorithm works robustly on a range of geometric and perspective distortions. However, we found that poor binarization results deteriorate the performance of our method, showing that the develop-ment of an efficient and robust binarization method is one of the most important topics in (camera-based) document image processing areas. Our method was developed for the tables having horizontal and vertical ruling lines. However, there are other table types (for example, tables without the lines and the cells differentiated by different colors) and we believe that developing a table detection algorithm for these cases is an interesting research topic.
 References
