 Patents are public and scientific literatures protected by the law, and their abstracts highly contained valuable information. Patent X  X  semantic annotation can effectiv ely protect intellectual property rights and promote corporations X  scientific research innovation. Currently, automatic patent annotation mainly used supervised machine learning algorithms, which required abundant expensive labeled patent data. Due to lack of enough labeled Chinese patent data, this paper adopted a se mi-supervised machine learning method named co-training, which started from a little labeled data. This method cooperated keyword extraction with list extraction, and incrementally annotated functional clauses in patent abstract. Experiment re sults indicated this method can gradually improve the recall wit hout sacrificing the precision. H.3.1 [ Information Storage and Retrieval ]: Content analysis and Indexing; H.4 [ Information Systems Applications ]: Miscellaneous Languages, Algorithms Semantic annotation, patent mining, information extraction, co-training Patent is a form of intellectual property. As an important carrier recording the most novel technology and the crystallization of human wisdom, patents almost include the technology achievements within the field of all applications. It contained valuable research results that ar e important for industry, business, and law. According to a United States Patent &amp; Trademark Office(USPTO) study[1], patents provide a significant amount of valuable technological information th at is not available elsewhere. If the enterprise can make a good use of the patents, 40% research fund and 60% time will be saved. Especially when making an invention, a company or individual may need to evaluate what had already been patented in their industry in order to know where their industry to focus their innovating energy and resources[2]. 
In the domain of patent mining, current research mainly focused on the annotation of pa tent function, technology and composition parts. There were mainly three kinds of methods in patent annotation. One was annota ting patent contents by a pre-defined rules repository. Peter Pa rapaics[8] uses JAPE (Java Annotation Pattern Engine) to de fine the rules of patents X  composition and description parts. The precision of these heuristic rules was fairly high, but they need much manual work and lack of self-adaption. The second method adopted supervised machine learning. It took the annotation as a classification problem and its key point rest on the classifier X  X  creation and feature selection. In a recent NTCIR patent mining competition [6], the average precision of Japanese patent annotation is 0.431 and its average recall is 0.545. Besi des, our team also explored a hybrid method combine rule-based method with the supervised machine learning method to sematic annotation [9]. This method firstly filtered those sentences that can be directly identified by the rules library and then used the Support Vector Machine (SVM) to classify the remaining sentences. The experimental results showed that this method was bette r than the simply rules based method and SVM. Patent annotation is essentially based on information extracting technology. In addition to rule-b ased and supervised machine learning approaches mentioned above, there was another way called semi-supervised machine l earning, which has the advantage of not requiring much tagged cor pus. Its previous works included Brin X  X  DIPRE (Dual Iterative Pattern Relation Expansion) technique for extracting book and author on the web [10]. It started with a sample set of five books and iteratively expanded patterns and instances from the semi-structured web data. Motivated by Brin's method, Agichtein extracted relations from unstructured free text by using named entity tagger [11]. However, those two methods are not suitable for Chinese patent extraction, because the bootstrapping pattern was based on some structured tags, but the patent abstract did not contain any tags. Besides, the Agichtein X  X  method should use some named entity tools, however, there was not such sophisticated tool in Chinese language processing. Co-training [12] was another semi-supervised machine learning method. It firstly used to classify web pages from two distinct views. It is assumed that the description of a web page could be represented by the text on the page, and also by the text of hyperlinks referring to the page. Either view of the example would be sufficient for learning if there is enough labeled data. Two learning algorithm descent from two views were trained separately, and then each algorithm X  X  predictions on new unlabeled examples were used to enlarge the training set of the other. Motivated by the co-training, we took two views to extract patent effect sentence. One is keyword extraction, and the other is list extraction. Those two methods iteratively extract clauses from a few labeled sentences. The difference between our method and traditional co-training methods is our method take coordinated clauses in a list view, which can reduce the number of iteration and maintain accuracy, while traditional method often only consider keywords-based ex traction. Additionally, to the best of our knowledge, our work is the first to study Chinese patent annotation with only a few labeled data. 
Considering the characteristics of Chinese patent effect annotation, this paper proposed two methods extracting patent effect, namely list extraction and keyword extraction. (1)List extraction: Effect clauses in patent abstract are usually close to each other, thus they can be viewed as a list. Extracting some effect clauses arranged in sequence is called list extraction. (2)Keyword extraction: Identifying clauses containing stable collocation and annotating them as effect clauses is called keyword extraction. 
The recall of list extraction is higher because it can extract multiple clauses at one time, but its precision is lower since not every extracted clause is exactly correct. In contract, the precision of keyword extraction is higher, but its recall is lower since one collocation X  X  hit can only annotate one effect clause. Since Chinese patent effect sentences usually contain stable collocation, this collocation can be presented as attribute and value tags. Keyword collocation in patent effect clause is very flexible. For example, in Chinese semantic,  X   X  X  X  X  X  X  X  is equivalent to  X   X  X  X  X  X  X  X  . They are both means  X  cost decreased  X  in English and the attribute  X   X  X  X  X  (cost) can either be in front of the value or behind it. Thus we used an un-ordered pair&lt;attribute, value&gt; to represent keyword collocation pattern. Definition 3.Effect Semantic Class 
Effect semantic class refers to a set of words with the same effect semantics, represented by effectSemnaticClass. The effectSemnaticClass (word). For example, these four words  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  belong to the semantic effect class of  X  X ecrease X . And the collocation pattern is represented as a pair, that is (attribute, effectSematicClass). For example ,  X   X  X  X  X  X  X   X  and  X   X  X  X  X  X  X  X  are both belong to the pattern of (  X  X  X  , decrease). As the patent effect clauses are usually arranged together, we take those clauses as a list to extract . We proposed two list extraction methods. (1) Side-based Extraction The side-based extraction is taken when the left and the right side of effect snippets are both detect ed. It is based on an assumption that the effect clauses are often linked together. As it shown in Fig 3, A, B, C and D represented four clauses, and if the left boundary A and the right boundary D are both be detected as effect clauses, and there is no full stop or semicolon between them, the side-based extraction method would annotate effect tags for each clause between the two sides, which means B and C could also annotated as effect. (2) Coordinated Extraction Figure 4.The average performances of co-training per one iteration 
The result in Figure 4 showed the recall and F-measure was gradually increased without too much decreasing in precision. Actually, in patent retrieval domain, recall is often more important than precision, because if one effect clause is incorrect, the patent examiner can easily detect. But if one effect clause is missed, the patent examiner should go back to review the abstract. Moreover, in the four settings of experiments, we also found that sematic-based selection and the coordinated-based list extraction would get the best performance. The reason is that semantic-based selection can be extended to mo re seed collocations. Besides, coordinated-based list extraction is better because its extraction process just needs one hit clause while side-based extraction requires two boundaries. Effect clauses X  annotation in patent abstract can help the companies to compare the patents they interested in horizontally and provide decision support for the companies. In order to resolve the problem that there is not enough annotated data in Chinese patent, we proposed a co-training method to iteratively extract effect clauses in patent abstract. This method collaborated keyword extraction with list extraction and it can find out the effect clauses in an acceptable rate. In future, we will extend the method in this paper and try to extract other parts in patent abstract, such as component clause , technical clause and so on. This work was supported by the National Natural Science Foundation of China ( 61070011 ) and the Academic Leader Plan of Wuhan City ( 20115053013 ).And I am also grateful to Siyi He and Ruiyuan Li for data collection and proof experiments. [1] United States Patent &amp; Trademark Of fi ce. 1977. Eighth [2] Alberts, D., Yang, C. B., et al . Introduction to patent searching. 
