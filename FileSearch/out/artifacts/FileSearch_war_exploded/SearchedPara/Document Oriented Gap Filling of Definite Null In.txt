 Frame Semantics and concerned with networks of me aning in which words participate . The primary units of lexical analysis in FrameNet are the frame and the lexical unit. Null instantiation is the core frame element which is neither expressed as a dependent null instantiation (INI). Cases of indefinite null instantiation are the missing objects of specific discourse referent , as core frame element FOOD in the following 1 . Definite already understood in the linguistic or discourse context, as the following example in element s, only one of which is filled locally, namely ACTIVITY, which is realized by business. However, another argument, EXPERIENCER , is filled by the I in preceding sentence. 1. [Sue INGESTOR]had eaten already .[INI FOOD] 2. I think that I shall be in a position to m ake the situation rather more clearly to you before long. It has been an [exceedingly DEGREE] difficult and most complicated [business ACTIVITY].[DNI EXPERIENCER] as INIs do not need to be accessible within a context, the task of resolving NIs is r e-stricted to DNIs. As the example 2 , gap filling of DNI aims to find the overt expre s-sion  X  X  X  to fill the omitted frame element  X  X XPERIENCER  X . Because DNI is not which causes the gap filling of DNI becomes a challenging problem in discourse processing.
 Given a DNI, we think that gap filling of DNI can be seen as a classified problem to judge whether a candidate could be taken as filler of a DNI, so we use classification method to solve the problem. In this task, an important step is to determine the scope of candidate words set and features for classification. In this paper, we design a rule to select candidate words set, combine features in a diversified portfolio , and finally use the maximum entropy model to classify candidate words.
 The remainder of this paper is structured as follows. In s ection 2 , we briefly summa r-ize the related work on gap filling of DNI. Section 3 introduces the way to build select cludes this paper. There is a growing interest in developing algorithms for resolving null instantiations. Null instantiations were the focus of the SemEval -10 Task 10, which showed two mission modes , namely full task ( semantic role recognition and labeling + NI linking) and NIs only task, i.e. the identification of null instantiations and their referents given a test set with go ld standard local semantic argument structure 3 . This paper focus on NIs only task to realize gap filling of DNI.
 There are two teams participate in NIs only task. Tonelli and Delmonte 4 developed a knowledge -based system called VENSES++, different resolution strategies are e m-comparable PAS in previous sentences, and then look s for the best head available in that PAS as a referent for the DNI in the current sentence by semant ic matching with corpus to train the feature templates, ultimately they obtained precision and recall rate was 4.62% and 0.86%. The second SemEval system 6 modeled the problem as the same way of semantic role labeling. They consider nouns, pronouns, and noun phra s-es from the previous three sentences as candidate DNI referents. When evaluating larity between filler and role. But, these semantic features have virtually no ef fect on performance possibly due to data sparseness.
 Philip and Josef 7 developed a weakly supervised approach that investigates and co m-bines a number of linguistically motivated strategies. Silberer and Frank 8 view NI resolution as a coreference resolution (CR) task, employing an entity-mention model, combining features of SRL and CR, and achieving F -score is 7.1% at last. Gerber and Chai 9,10 present a study of implicit arguments for a group of nominal predicates. They also use an entity mention approach an d model the problem as a classical super-vised task, implementing a number of syntactic, semantic, and discourse features. Because Gerber and Chai X  X  corpus cover 10 nominal predicates from the commerce noticeably higher than those obtained for the SemEval data. candidate words set (includes search space and POS of words) could reduce the co m-plexity of the system and improve the efficiency of the experiment . In this section, we focus on the selection of candidate words set and features. 3.1 Selection of Candidate words set ment. The accuracy of search space and POS for candidate words would influence the words set which could maximum cover the entire antecedent and has a minimum size . data of NIs only task.
 Table 1 shows the main distribution of DNI referents in training data. We can see that listed in table 1 account for only 65.79 percent of the total number of DNI referents. In training data, there are 58 DNIs have no referent, 6 appear in six sentences before, coverage probability has obvious growth trend from one sentence to three sentences, percent increase than others. Based on the above data, we list several methods in table 2 to choose the best candidate words set. In corpus , some words in search space are impossible to act as frame element fillers, from candidate words set. In the following, we analyze the part -of-speech distribution of DNI referents in training data to choose suitable candidate words.
 As shown in table 3, the words which POS are NPB ( noun phrase) and PRP (pronoun) account for 73.05% in total, as a result we take them as basic POS of candidate words on the data in table 3: 1. Given the current DNI frame element, looking for the same frame elements in the train data. 2. If the same frame elements are found, count ing the POS of their fillers , choosing the largest one as C, and taking NPB, PRP, and C as candidate words for DNI in search space. 3. Otherwise, only taking noun phrases and pronoun as candidate words for DNI in search space. 3.2 Features description Feature selection is important in classification problems and the performance of cla s-sification largely depends on feature selection, which is also a key issue in gap filling of DNI. For definite null instantiations, their conceptually -relevant content is left unexpressed or is not explicitly linked to the frame via linguistic conventions , so it is as features for gap filling of DNI are information of candidate words and DNI frame element. In discourse, head words are frequently used as role filler. The closer head word away information of head word as features for gap filling of DNI. I n a frame, the NI type of would be having different NI type under the same lexical as well. In the case of frame element GOAL and SOURCE, some verbs allow its omission under inde finite null instantiation (1, 4), others allow its omis sion under de finite null instantiation (2, 3). 1. Adam left Paris [INI Goal]. 2. Smithers arrived [DNI Goal]. 3. Sue left [DNI Source]. 4. Sue arrived in Rome [INI Source].
 In conclusion , we also take account of frame information when gap filling of DNI. In table 4, we describe all of the features that may be useful in gap filling for DNI. 3.3 Maximum Entropy Models Maximum entropy model which is based on the maximum entropy principles is set up other. Maximum entropy model , as a kind of statistical method , has been widely used mentation and machine translation) in the late . In the experiment, it will involve a variety of factors when predicting whether a can-dicted as filler of DNI. Maximum entropy model ask for p(y | X) to make the entropy defined below largest under certain rest rict conditions. The restrict conditions refers to all known facts actually , the final output of the proba-bility is: fi (X, y) is features of maximum entropy model, n is the number of features, and the features describe the relationship between X and y.  X i is the weight of each feature. In this paper, we use the maximum entropy toolkit of Dr. Zhang Le for classific a-tion 11. words set with the best feature template in the same corpus. At last we apply them to NIs only task data and c ompar e the result with previous works. 4.1 Corpus In our experiment , we used the corpus distributed for SemEval -2010 Task 10 on  X  X inking Events and Their Participants in Discourse X . The data set consists of the Holmes stories by Arthur Conan Doyle. T he training set has abo ut 7800 words in 438 sen tences; it has 317 frame types, including 1370 annot ated frame instances. The test types and 1703 frames . All data released for the 2010 task include part -of-speech tags, lemmas, and phrase -structure trees from a parser, with head annotations for constit u-ents . Table 5 show s the statistics about this data set.
 4.2 Evaluation measures mance of this system . Assume that Cp is the DNI number predicted by system, Cc is the DNI number which is predicted correct and DNI number in the answer of test set for Co , and then we define precision, recall and F -score as following formulas. We evaluate the performance of experiments based on their average value of chapter 13 and chapter 14. 4.3 Result in gold standard annotated corpus In this section, we use the corpus which has annotated information about null insta n-correctly classified as DNI or INI , we only focus on the DNI. For each DNI, the exp e-rim ent chooses candidate words in context based on the rules defined in 3.1, and then takes their features as input for training and predicting on the maximum entropy mod-el. We think a DNI has no referents, when no word in candidate words set of this DNI is j udged as its antecedent. In order to get the best feature template, we choose H3 in table 1 as search space for DNI candidate set according to Chen et al. The results are listed in table 6.
 Based on the data shown in table 6, we can get that combination of C1, C2 and C3 has better performance than others. This means that combining all features to build fea-ture template could provide more information to the system. In addition, table 6 also shows that the results of chapter 13 were lower than chapter 14, which may be caused which are same with train data, while chapter 14 has 130. So it is obvious that candi-date words set in chapter 14 can cover more DNI referents than chapter 13 based on the first candidate words select rule. Secondly , the experiment consider words in pr e-vious three sentences as candidate DNI referents, but there are 14 percent of antece-dent out of it in chapter 13, and 5 percent in chapter 14. A case in c hapter 13 is given as follows: &lt;fe id="s42_f2b_e1" name="Judge"&gt; &lt;fenode idref="s33_8" /&gt; &lt;flag name="Definite_Interpretation" /&gt; &lt;/fe&gt; Finally, it is exists that DNI referents is composed of multiple phrases rather than one word, which is not taken into account in the system. This situation in chapter 13 has 8, and in chapter 14 has 7. F or example: &lt;fe id="s33_f6_e2" name="Action"&gt; &lt;fenode idref="s33_7" /&gt; &lt;fenode idref="s33_13" /&gt; &lt;fenode idref="s33_12" /&gt; &lt;fenode idref="s33_11" /&gt; &lt;fenode idref="s33_9" /&gt; &lt;fenode idref="s33_8" /&gt; &lt;flag name="Definite_Interpretation" /&gt; &lt;/fe&gt; Because combining all features to build feature template could improve the perfo r-mance of the system, so we choose C1+C2+C3 in table 6 as features to study the i n-fluence of candidate words set in different search space, aiming to choose the best one which could get optimal performance. The results are showed in table 7.
 When choose H2  X  H4  X  H6 or H8 as search space of candidate words set, we can get and correctly predicted more than choose H1  X  H3  X  H5 or H7. As a result, the prec i-conclude that the F -score of system is highest when candidate set is H3 via compar i-son.
 4.4 Result in NIs only task test data task of SemEval -10 X  X  Task -10, as described in Section 4.1 . Besides, in order to focus ments are carried out on gold -standard semantic role labeling. The complete task can be modeled as a pipeline consisting of three sub -tasks: ( a) identifying potential NIs by taking into account information about core arguments, ( b) automatically distinguis h-ing between DNIs and INIs via maximum entropy model , and ( c) resolving NIs cla s-sified as DNI to a suitable referent in the text. We identify NI types based on Fram e-Net and use m aximum entropy model to classify NIs 12. The result of DNI identific a-tion is shown in table 8. The number of our predicted DNI is more than V ENSES++, can also see from the table, our result is far from the gold standard number. Because task (c) is on the basis of task (a) and (b), so it is a limit to the result of DNI gap fil l-ing. As concluded in section 4.3, the system achieved the best performance when the DNIs which are predicted by our system.
 corpus and NIs only corpus. We can see from the table that precision of the former is former two steps. According to our statistics, the number of DNI predicted by the system accounts for 66.76 percent of the answer, and the number that predicted co r-rect ly is only 42.41 percent, which could cause that the input of DNI gap filling in NIs fluence on the result of the classification.
 We compare our results with precious work to illustrate t he effectiveness of our mo d-el. The comparison is showed in figure 1, the horizontal axis display precision, recall figure that our system is better than other ones, t he reason of which may boil down to the following: 1. SEMAFOR and VENSES++ combine classification of NI and DNI resolution, they otherwise, it is labeled as INI. W hile in our system, we decompose the problem i n-to two independent steps. Our system identifies null instantiation at first, and then can take the DNIs which have no referent into account, so the recall of our system is higher than others. 2. SEMAFOR system consider nouns, pronouns, and noun phrases from the previous three sentences as candidate DNI referents, so 26.65 percent of gold DNI referents features they choose received negligible weight and had virtually no effect on pe r-formance because of data sparseness. 3. VENSES++ system requires large corpus to get information of PAS and AHDS, but the corpus of NIs only task is too small to cover all the information. 4. Philip and others only make use of minimal supervision for modeling the role linking task , which make their result lower th an ours.
 Compared with the three models, there are two advantage s of our proposed model. One is t he rule for selecting candidate words in this paper could maximum cover all the DNI referents. And the other one is adding information of head word and frame to traditional features could get the best feature template. processing. By adding new features such as the information of head word and frame choose the best candidate words set and combination of features. Ex periments show that the proposed model can get a better result than existing ones. It is our wish that this study provides new views and thoughts i n natural language processing.
 filling, so it is significant to improve the performance of NI classification for DNI gap tionship of two frames is inheritanc e, their frame element fillers also have some sp e-cial connection. Therefore, we will focus on the research of applying frame relations to gap filling of DNI in the future.
 This work was supported by National Natural Science Fund of China (N o. 60970053), National Language Committee  X 1025 X  planning research (No. YB125 -19), Intern a-tional cooperation in science and technology project of Shanxi Province (No. 2010081044 ), National 863 plans projects ( No. 2006AA01Z142) and Research Project Supported by Shanxi Scholarship Council of China( No. 2013-015) . 
