 et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a di-alogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our motivation is to clarify which TTP are inter-esting to implement given the task at hand. As an illustration, five TTP (which we assume have the best properties to improve the dialogue efficiency) have been implemented and compared in a slot-filling simulated environment.
 Section 2 introduces the TTP taxonomy and Section 3 describes the simulated environment, the experimental setup and the results. We then con-clude in Section 4. In linguistics and philosophy of language, a dis-tinction is made between two different levels of a speech act analysis: locutionary acts and illocu-tionary acts (Austin, 1962; Searle, 1969). Loosely speaking, a locutionary act refers to the act of ut-tering sounds without taking their meaning into account. When the semantic information is the ob-ject of interest, it is an illocutionary act . In (Raux and Eskenazi, 2009), four basic turn-taking transi-tions are presented: the turn transitions with gap , the turn transitions with overlap , the failed inter-ruptions and the time outs where only the mechan-ics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme , which is a modified version of the original classification of interruptions and smooth speaker-switches in-troduced in (Beattie, 1982). This classification is richer than the one in (Raux and Eskenazi, 2009) as the meaning of the turn-taker utterance stood (FAIL INTERP). In addition, even if the meaning of the message has been understood, it can be incoherent with the interaction context (G INCOHERENT, e.g. trying to book a flight from a city with no airport). Again, T can warn G implicitly (INCOHERENCE IMPL) or explicitly, either by explaining the reason of the problem (INCOHERENCE INTERP) or not (INCOHERENCE RAW).

In the case G X  X  utterance is not problematic but yet incomplete (G INCOMPLETE), T can let her understand that she understands what has been said so far by performing a BACKCHAN-NEL ( Yes , uhum etc.), by repeating his words exactly (FEEDBACK RAW) or by commenting them (FEEDBACK INTERP), for example: Yes-terday I went to this new Chinese restaurant in town... / Yeah Fing Shui / ...and it was a pretty good deal ). If G utters enough information to move the dialogue forward (G SUFFICIENT), T can refer to an element in G X  X  utterance im-plicitly ( Aha ) by reacting at the proper timing (REF IMPL), or explicitly in a raw (REF RAW, for example Ok, Sunday ) or interpreted manner (REF INTERP, for example Yeah, Sunday is the only day when I am free ). T can also interrupt G to add some information that is relevant to the course of the dialogue (BARGE IN RESP). Fi-nally, she can wait until G has finished his ut-terance (G COMPLETE) and warn him that he should add more information (REKINDLE, for example: And? ) or start a new dialogue turn (END POINT).

In the rest of this paper, five incremen-tal TTP that are the more used in general, and therefore studied, have been tested in a simulated environment: FAIL RAW (Ghigi et al., 2014), INCOHERENCE INTERP (DeVault et al., 2011), FEEDBACK RAW (Skantze and Schlangen, 2009) and BARGE IN RESP from both sides, user (Selfridge et al., 2013) and system interruptions (DeVault et al., 2011), along with not provide all the slot values or because of ASR noise), the remaining slot values are asked for one by one (system initiative).
 NLG module: The NLG figures out the next sentence to utter given the current Intent Man-ager X  X  output. A straightforward sentence is com-puted, for example, Add the event meeting Mary on July 6 th from 18:00 until 20:00 .
 Verbosity Manager: The Verbosity Manager randomly expands the NLG output with some usual prefixes (like I would like to ...) and suffixes (like please , if possible ...). Also, a few sentences are replaced with off-domain words or repeated twice as it is the case in real dialogues (Ghigi et al., 2014). For questions concerning a specific slot, neither prefixes nor suffixes are added.
 Patience Manager: When the dialogue lasts too long, the US can get impatient and hang up. The US patience corresponds to a threshold on each task duration. It is randomly sampled around a mean of 180 seconds for the experiments. A speech rate of 200 words per minute is assumed for the dialogue duration estimation (Yuan et al., 2006). Moreover, a silence of one second is as-sumed at each regular system/user transition and a two second silence is assumed the other way round. For interruptions and accurate end-point detection, no silence is taken into account. 3.3 ASR Output Simulator The US can run either in a traditional mode in the sense that it provides a complete utterance to the system then it waits for a response, or in an incremental mode where a growing utterance is outputted at each new word. For example: I , I want , I want to , I want to add ...etc. In incremental dialogue systems, the turn increment (called the micro-turn in this case) could be different than the word (a small duration for example).

The ASR output simulator can be used in both modes, but as the traditional mode is a special case of the incremental one, we describe the lat-ter only. This module computes a noisy version of each word (substitution, deletion, or insertion). It also associates a confidence score with each new partial utterance. Moreover, a word in the ASR output can change later as new words pop in (Self-ridge et al., 2011; McGraw and Gruenstein, 2012). In the following, this mechanism is referred to as the ASR instability . At each micro-turn, the sys-3.6 TTP implementation Replicating some turn-taking phenomena like backchannels makes the system seems more real-istic (Meena et al., 2014). In this work, the fo-cus is on dialogue efficiency, therefore, the fol-lowing TTP have been chosen for the implemen-tation: FAIL RAW, INCOHERENCE INTERP, FEEDBACK RAW and BARGE IN RESP from the user X  X  and the system X  X  point of view.

At each micro-turn, the system has to pick an action among three options: to wait (WAIT), to retrieve the last service X  X  response to the client (SPEAK) or to repeat the word at position n  X  2 (if n is the current number of words, because of the ASR instability) in the current partial request (REPEAT). To replicate each selected TTP, a set of rules have been specified to make the proper de-cision. We review the triggering features related to each TTP accommodated to the task at hand (agenda filling).

FAIL RAW: Depending on the last system X  X  di-alogue act, a threshold relative to the number of words without detecting a key concept in the ut-terance has been set. In the case of an open ques-tion (where the system waits for all the informa-tion needed in one request), if no action type has been detected after 6 words, a FAIL RAW event is declared. The system waits for 3 words in the case of a yes/no question, for 4 words in the case of a date and for 6 words in the case of slots (some concepts need more words to be detected and the user may use additional off-domain words).

INCOHERENCE INTERP: This event is useful to promptly react to partial requests that would eventually lead to an error, not because they were not correctly understood, but because they are in conflict with the current dialogue state. If such an inconsistency is detected, the system waits for two words (ASR instability) and if it is main-tained, it takes the floor to warn the user.
FEEDBACK RAW: If at time t, a new word is added to the partial utterance and the ratio be-tween the last partial utterance X  X  score and the one before last (which corresponds to the score of the last increment) is lower than 1/2, then the system waits for two words (because of the ASR instabil-ity), and if the word is still in the partial utterance, a REPEAT action is performed.

BARGE IN RESP (System): This TTP de-pends on the last system dialogue act as it deter-mines which kind of NLU concept the system is pletion), with the corresponding 95% confidence intervals, for the different strategies and for WER varying between 0 and 0.3.

The FEEDBACK RAW strategy performs best whereas INCOHERENCE INTERP does not im-prove over the baseline. This is due to the fact that the system has to deal with an open slot (which set of possible values is not closed and known a pri-ori): the event X  X  description. The system mostly performs ADD actions, so the description slot can take any value and is never compared with exist-ing data. This is the case of many application like message dictation for example. However, in the case of service at hand, an initial concept must be detected (the action), therefore, FAIL RAW im-proves the performance. BARGE IN RESP from user X  X  side is also useful here as dialogues can be long and may contain repetitive system dialogue acts. The users get familiar with the systems and may infer the end of the system X  X  question before it ends. Obviously it is questionable that users may be patient enough (up to several minutes) to achieve such simple tasks in real life. But for the sake of the simulation it was necessary to gener-ate dialogues long enough to have the studied TTP influence them. In a next step, increasing the ser-vice capacities (and complexity) will remedy that as a side effect. Finally, BARGE IN RESP from the system X  X  side does not bring any improvement either which is due to the fact that in this task and because of input noise, in most cases, the response to the initial open question is not enough to fill all the slots. The responses to single-slot questions do not contain suffixes which explains the ineffi-ciency of the last strategy (the US stops speaking as soon as the slot value is given). This paper introduces a new taxonomy of turn-taking phenomena in human dialogue. Then an experiment where five TTP are implemented has been run in a simulated environment. It illustrates the potentiality of the taxonomy and shows that some TTP are worth replicating in some situations but not all. In future work, we plan to perform TTP analysis in the case of real users and to opti-mise the hand-crafted rules introduced here to op-erate the floor management in the system (when to take/give the floor and according to which TTP scheme) by using reinforcement learning (Sutton and Barto, 1998; Lemon and Pietquin, 2012).
