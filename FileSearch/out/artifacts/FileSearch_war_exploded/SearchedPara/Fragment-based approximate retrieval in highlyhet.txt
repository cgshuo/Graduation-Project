 1. Introduction
Interoperability among systems is commonly achieved through the interchange of XML documents that can represent a great variety of information resources: semi-structured data, database schemas, concept taxonomies, ontologies, etc. Most XML document collections are highly heterogeneous from several viewpoints. The first level of heterogeneity is tag heterogeneity : vocabulary discrepancies may occur in the ele-ment tags. Two elements representing the same information can be labelled by tags that are stems (e.g., author and authors ), that are one substring of the other (e.g., authors and co-authors ), or that are similar according to a given thesaurus (e.g., author and writer ). The second level of heterogeneity is structural heterogeneity that results in documents with different hierarchical structures. Structural heterogene-ity can be produced by the different schemas (i.e. DTDs or XML Schemas) behind the XML documents.
Moreover, as schemas can also include optional, alternative, and complex components, structural heterogene-ity can appear even for a single schema collection.

Highly heterogeneous XML collections can be found in a great variety of application domains, most of them related to the discovery and integration of semi-structured information coming from disparate and autonomous sources. Semantic Web Services is one of these application domains, which has been used for experimental evaluation. In this application, services are described according to concepts from one or several ontologies. In this way, service descriptions can be represented as trees expressing the hierarchical relation-ships that can appear in service methods and input/output parameters. Notice that these parameters usually have complex types (e.g., address ) which can be defined in different ways across services. For example, in the
ASSAM Web service collection, address and personal data present several structural relationships. In this con-text, user requests cannot account for all these structural variations as users do not a priori know how data are organized. Instead, the user expresses her request by arranging the elements of interest as she considers it is most likely to find them (pattern). In other words, she expresses an approximation of what she wishes to find, although the final results are not required to exactly comply to the given pattern.

A more complex and specific scenario is that of biomedical information exchange. Sharing clinical data among clinicians is crucial for the development of their researches and daily tasks, see e.g. [6] . Contrary to hospital information systems, where a great effort on data standardization has been produced (e.g. HL7 and IHE), clinical data managed within hospital departments has not been standardized at all because these data are quite irregular and dynamic. Clinical data cover many aspects of a patient: visits, examinations, diag-nosis, symptoms, and a long etcetera. Also clinical procedures use to change over time as new findings over medical evidences are discovered (e.g., new treatments, new lab tests, etc.). Irregularity and dynamicity are two features of semi-structured data that are well supported by XML technology, therefore current biomedical projects like myGRID, 1 PEDRo 2 and caBIG 3 propose different XML-based models for clinical data exchange. Heterogeneity increases dramatically when several departments share their clinical records, since they can consider different detail levels and some clinical variables are more relevant than others. Also the structure of patient records can differ notably from one department to another depending on the particular from all the available data sources (e.g., local patient records, external patient records as well as public dat-abases). For example, given a patient record, a clinician might wish to search not only similar patient records published within her department but also other document portions describing similar cases or reporting inter-esting findings with respect the patient at hand.

To sum up, in this paper we stress the tag and structural heterogeneity of XML document collections. This can lead to search a very large amount of highly heterogeneous documents. In this context, we propose an approach for identifying the portions of documents that are similar to a given pattern . In our context a pattern is a labelled tree whose labels are those that should be retrieved, preferably with the relationship imposed by the hierarchical structure, in the collection of documents (that for simplicity is named the target collection).
We develop a two-phase approach where, in the first phase, tags occurring in the pattern are employed for identifying the portions of the target in which the nodes of the pattern appear. Exploiting the ancestor/descen-dant relationships existing among nodes in the target, subtrees (named fragments ) are extracted having com-mon/similar tags to those in the pattern, but eventually presenting different structures. The structural similarity between the pattern and the fragments is evaluated as a second step, for two purposes. First, for merging fragments in a region when the region exhibits a higher structural similarity with the pattern than the fragments it is originated from. Then, for ranking the identified fragments/regions and producing the result. In this second phase, different similarity measures can be considered, thus accounting for different degrees of document heterogeneity, depending on the application domain and on the heterogeneity degree of the target collection.

The proposed approach is thus highly flexible. The problem is however how to perform the first step effi-those of the pattern, without relying on strict structural constraints. Our approach employs ad-hoc data struc-tures: a similarity-based inverted index (named SII ) of the target and a pattern index extracted from SII on the tified and organized in the levels in which they appear in the target. Fragments are generated by considering the ancestor X  X escendant relationship among such vertices. Then, identified fragments are combined in regions , allowing for the occurrence of nodes with labels not appearing in the pattern, as described above. Finally, some heuristics are employed to avoid considering all the possible ways of merging fragments into regions and for the efficient computation of similarity, thus making our approach more efficient without loosing precision.
In the paper, we formally define the notions of fragments and regions and propose the algorithms allowing their identification, relying on our pattern index structure. The use of different structural similarity functions taking different structural constraints (e.g., ancestor X  X escendant and sibling order) into account is discussed.
The practical applicability of the approach is finally demonstrated, both in terms of quality of the obtained results and in terms of space and time efficiency, through a comprehensive experimental evaluation. The con-tribution of the paper can thus be summarized as follows: (i) specification of an approach for the efficient iden-tification of regions by specifically tailored indexing structures; (ii) characterization of different similarity measures between a pattern and regions in a collection of heterogeneous semi-structured data; (iii) realization of a prototype and experimental validation of the approach. The paper is an extended version of [7] . With respect to [7] , the presentation of the approach has been deeply revised, all the underlying concepts are clearly and formally defined, and the corresponding algorithms, only sketched in [7] , are detailed and their correctness and complexity are discussed. Moreover, the experimental evaluation considerably extends the preliminary results presented in [7] .

The remainder of the paper is organized as follows. Section 2 formally introduces the notions of pattern, target, fragments, and regions the approach relies on. Section 3 is devoted to the discussion of different approaches to measure the similarity between the pattern and a region identified in the target. Section 4 dis-cusses how to efficiently identify fragments and regions. Section 5 presents experimental results while Section 6 compares our approach with related work. Finally, Section 7 concludes the paper. 2. Pattern, target, fragment, and region trees
In our approach, both patterns and targets are represented as trees. Thus, fragments and regions are (sub)-trees as well. In this section, we introduce these notions. First of all, however, we introduce some basic notions and some useful notations on trees together with some functions for element tag similarity. 2.1. Trees
The notation used throughout this paper to represent trees is fairly standard. A tree is a structure T =( V , E ), are reachable via edges from the root, that is, (root( T ), v ) 2 E which a node labeling function label is associated. Given a tree T =( V , E ), Table 1 reports functions and sym-bols used throughout the paper. In the following, when using the notations, the tree T will not be explicitly reported whenever it is clear from the context. Otherwise, it will be marked as subscript of the function.
Node order is determined by a pre-order traversal of the document tree [8] . In a pre-order traversal, a left to right. A post-order traversal is the dual of the pre-order traversal: a node v is visited and assigned its post-order rank post ( v ) after all its children have been traversed from right to left. The level of a node v in the tree is defined, as usual, by stating that the level of the root is 1, and that the level of any other node is the successor of the level of its parent. The position of a node v among its siblings is defined as the left-to-right position at which v appears among the nodes whose father is the father of v . Each node v is coupled the sake of clarity, in the following graphics we omit the quadruples when they are not relevant for the discussion.

Pre-and post-ranking can also be used to efficiently characterize the descendants u of v . A node u is a are trivially computed using these numbers. If, given two nodes, one is neither an ascendant nor a descendant amounts to the number of nodes traversed in moving from the root to the node in the pre-order traversal. The maximal distance d max corresponds to the number of nodes in the tree, i.e. | T |. d post-order rank of the root.

Example 1. Referring to the tree in Fig. 1 a, node (2,2,2,1) is a descendant of node (1,3,1,1), whereas it is a left-relative of node (3,1,2,2). The distance of node (3,1,2,2) from the root is 3, and d 2.2. Label similarity
Labels can be similar or dissimilar depending on the adopted criteria of comparison specified by means of functions. In this paper, the following similarity functions have been considered, even if other ones can be eas-ily integrated: author and Author are similar).  X  Stemming function S t st . Two tags are similar if one is a stem of the other (e.g., author and authors are similar). author and auth are similar). conference-author are similar).  X  Ontology-based function S t o . Two tags are similar if they are synonym relying on a given thesaurus (e.g., author and writer are similar).

Relying on these similarity functions, the notions of similarity between two tags or between a tag and a set of tags are defined as follows:
Definition 1 ( Similarity and Similarly Belonging ). Let S be a set of label similarity functions. Let l labels, l 1 is similar to l 2 according to S (denoted as l to a function in S . Let then l be a label and L be a set of labels, l similarly belongs to L according to S (denoted as l / S L ) if and only if $ n 2 L s.t. l  X  S n .

In the following, when the subscript S is omitted we will implicitly refer to the whole set of similarity func-tions introduced above. 2.3. Pattern and target trees
A pattern is a labeled tree. The pattern is a tree representation of the user interest and can correspond to a collection of navigational expressions on the target tree (e.g., XPath or XQuery expressions in XML docu-ments) or simply to a set of labels for which a  X  X  X reference X  X  is specified on the hierarchical or sibling order in which such labels should occur in the target. Labels in the pattern should be semantically distinct each other in order to avoid that two pattern labels can match the same element in the collection.

Example 2. Consider the pattern in Fig. 1 a. Intuitively, the pattern expresses an interest in document portions related to articles, their titles, and the conferences where they are presented. Possible matches for this pattern are reported in Fig. 1 b X  X . The matching tree in Fig. 1 b contains similar labels but at different positions, misses an element and the two elements appear at different levels.

The target is a set of heterogeneous documents in a source. The target is conveniently represented as a tree with a dummy root labeled db and whose subelements are the documents of the source. This representation relies on the common model adopted by native XML databases (e.g., eXist, Xindice [9] ) and simplifies the adopted notations. An example of target is shown in Fig. 2 . The dummy root has pre-order rank 0 and is at level 0 in the tree.

Definition 2 ( Target ). Let { T 1 , ... , T n } be a collection of trees, where T
T =( V , E ) such that:  X  E  X [ n i  X  1 E i [f X  r ; root  X  T i  X  X  ; 1 6 i 6 n g ,  X  label( r )= db . 2.4. Fragment and region trees
The basic building blocks of our approach are fragments . Given a pattern P and a target T , a fragment is a subtree of T , belonging to a single document of the target, in which only nodes with labels similar to those their nearest common ancestor similarly belong to the labels in the pattern. Edges in the fragment either cor-respond to a direct edge in the target (father X  X hildren relationship) or to a path in the target (ancestor X  descendant relationship). Several edges in the target, indeed, can be collapsed in a single edge in the fragment by  X  X  X kipping X  X  nodes that are not included in the fragment since their labels do not similarly belong to those in the pattern.
 Definition 3 ( Fragment ). A fragment F of a target T =( V which the following properties hold:  X  V F is the maximal subset of V T such that root( T ) 6 2 V label  X  nca  X  u ; v  X  X  / label  X  V  X  P  X  X  ;  X  for each v 2 V F , nca (root( F ), v ) = root( F );  X  E F  X f X  u ; v  X j u ; v 2 V F ^ X  u ; v  X 2 E T ^ X 9 = w 2 V
Example 3. Consider the pattern in Fig. 1 a and the target in Fig. 2 . By considering all the label similarity functions introduced in Section 2.2 , the corresponding four fragments are shown in Fig. 3 a. Labels in the first fragment are exactly the same appearing in the pattern. By contrast, in the others require to exploit the substring and ontology-based functions. For instance, the second tree contains paper as label, and paper  X  S t the substring function S t ss to labels title and conference in the pattern, respectively. The second tree provides an example of fragment in which a node of the original tree (i.e. node (9,8,2,2) labeled by invited ) is not included.

Starting from fragments, regions are introduced as a combination of fragments rooted at the nearest com-mon ancestor in the target. Two fragments can be merged in a region only if they belong to the same docu-ment. In other words, the common root of the two fragments is not the db node of the target.
Example 4. Consider the tree T rooted at node n (13,4,1,3) in Fig. 2 . It has two subtrees (the ones containing elements article -title and article -conference ) that are fragments with respect to the pattern in
Fig. 1 a. Though n is not (part of) a fragment, the subtree consisting of n and its fragment subtrees could have a higher similarity with the pattern tree in Fig. 1 a than its subtrees separately. Therefore, combining fragments into regions may lead to subtrees with higher similarities.
A region can be a single fragment or it can be obtained by merging different fragments in a single subtree whose root is the nearest common ancestor of the fragments. Thus, while all fragment labels similarly belong to those in the pattern, a region can contain labels not similarly belonging to pattern labels.
Definition 4 (Regions). Let F P ( T ) be the set of fragments identified between a pattern P and a target T . The corresponding set of regions R P ( T ) is inductively defined as follows:  X  F P ( T ) R P ( T );  X  For each F =( V T , E T ) 2 F P ( T ) and for each R =( V
S =( V S , E S ) 2 R P ( T ); where:  X  root( S )= nca (root( F ),root( R )),  X  V S = V F [ V R [ {root( S )},  X  E S = E F [ E R [ {(root( S ),root( F )),(root( S ),root( R ))}.

Example 5. The fragments in Fig. 3 a are also regions as well as the region reported in Fig. 3 b obtained by merging the third and fourth fragments in Fig. 3 a. Note that the region root label (i.e. writer ) does not sim-ilarly belong to any label in the pattern.
 Relying on this definition, regions are all possible combinations of fragments in a document of the target.
This number can be exponential in the number of fragments. In Section 4.3 the locality principle will be dis-cussed to reduce the number of regions to consider.

The notions of level of a node and distance between two nodes, when applied to regions, refer to the corresponding notions in the original target tree. More specifically, they refer to the target subtree whose root is the region root and whose leaves are the region leaves. We will refer to this tree as the target subtree covered by the region. This subtree, as already discussed, may contain additional internal nodes that are not included in the region since their labels do not appear in the pattern. Specifically, internal nodes are included in the covered subtree if they are either in the path from the region root to some region node or if they are internal sibling of two nodes in the covered tree (i.e. right-sibling of one of them and left-sibling of the other).

Definition 5 ( Covered Subtree ). Let T be a target and R be a region on it. The subtree of T covered by R , denoted as C ( R ), is the subtree of T such as:  X  V C ( R ) V T is inductively defined as follows:  X  " v 2 V T such that $ u , w 2 V C ( R ) and ( u , v ), ( v , w ) 2 V  X  " v 2 V T such that $ u , w , f 2 V C ( R ) and ( f , u ),( f , v ),( f , w ) 2 V  X  E C ( R ) ={( u , v )|( u , v ) 2 E T s . t . u , v 2 V
Example 6. Consider region R 2 of Fig. 5 . The depth of the region level ( R three nodes. Similarly, the level of the paper labeled node is 3. The distance of the paper labeled node is 4, which is also the maximal distance in the region.

Fig. 4 presents different parts of a target where black nodes identify region nodes and gray nodes together with black nodes form the covered subtree. 3. Similarity of a region w.r.t. a pattern
In this section we present the foundation of our two-phase approach to identify target regions similar to a pattern. We first identify the possible matches between the vertices in the pattern and those in the region hav-ing similar labels, without exploiting the hierarchical structure of the tree. Then, the hierarchical structure is taken into account to select, among the possible matches, those that are structurally more similar. Specifically, after having introduced the definition of mapping, we propose three different similarity measures that combine structure and tag matching. 3.1. Mapping between a pattern and a region
A mapping between a pattern and a region is a relationship among their elements that takes the tags used in the documents into account. Our definition differs from the definition of mapping proposed by other authors [10,11] . Since our focus is on heterogeneous semi-structured data, we do not take the hierarchical organization of the pattern and the region into account in the definition of the mapping. We only require that the element labels are similar.

Definition 6 ( Mapping M ). Let P be a pattern and R be a region. A mapping M is a partial injective function between the vertices of P and those of R such that 8 x p 2 V  X  P  X  ; M  X  x
Example 7. Fig. 5 reports the pattern P of Fig. 2 in the center and three target regions, R represent a mapping among the vertices of the pattern and those of each region.

Several mappings can be established between a pattern and a region. The best one will be selected by means of a similarity measure that evaluates the degree of similarity between the two structures relying on the degree of similarity of their matching vertices.

Example 8. Fig. 6 reports how different mappings can be established between the region R in Fig. 3 b and the pattern P in Fig. 1 a.

Given a similarity measure, like the ones discussed in the next section, assessing the similarity between ver-tices, a mapping can be evaluated as follows.
 Definition 7 ( Evaluation of a Mapping M ). Let M be a mapping between a pattern P and a region R , and let S im be a vertex similarity function. The evaluation of M is:
Similarity between a pattern and a region is then defined as the maximal evaluation among the mappings that can be determined between the pattern and the region.

Definition 8 ( Similarity between a Pattern and a Region ). Let M be the set of mappings between a pattern P and a region R . The similarity between R and P is defined as: 3.2. Similarity between matching vertices
We now present three approaches for computing the similarity between a pair of matching vertices. The first one assesses similarity only on the bases of label matches, whereas the other two take the structure into account. 3.2.1. Match-based similarity
In the first approach, similarity only depends on node labels. Similarity is 1 if labels are identical, whereas a pre-fixed penalty d is applied if labels are similar. If they are not similar, similarity is 0.
Definition 9 ( Match-based Similarity ). Let P be a pattern, R be a region in a target T , x x = M ( x p ). Their similarity is computed as:
Example 9. Let x p be the vertex tagged article in the pattern P in Fig. 5 and x 1 x and the corresponding vertices in the three regions. Table 2b reports, in the first column, the match-based evaluations of the mappings between P and each of the regions (see Fig. 5 ), computed according to Definition 7 . For regions R 1 and R 2 , there is a single mapping ( M also highlights in bold the similarity of P with each of the regions, computed according to Definition 8 . The evaluation details are in Appendix A . 3.2.2. Level-based similarity
In the second approach, the match-based similarity is combined with the evaluation of the level at which x and M ( x p ) appear in the pattern and in the region. Whenever they appear in the same level, their similarity is equal to the similarity computed by the first approach. Otherwise, their similarity linearly decreases as the tree covered by the region.

Definition 10 ( Level-based similarity ). Let P be a pattern, R be a region in a target T , x x = M ( x p ). Their similarity is computed as: The similarity is 0 if the obtained value is below 0.

Example 10. The second columns of Tables 2a and 2b report the level-based similarities. The evaluation details are in Appendix A .
 3.2.3. Distance-based similarity
Since two nodes can be in the same level, but not in the same position, a third approach is introduced. The similarity is computed by taking the distance of nodes x p
Thus, in this case, the similarity is the highest only when the two nodes are in the same position in the pattern and in the region. We recall that distances in the region refer to the distances in the target subtree covered by the region computed through the recursive function d R in Fig. 7 . Given a region R , v
R ordered according to their pre-order rank in the target T . In the figure we report the computation of the distance for the root of R ( v 1 ) and for a generic vertex of R that is not the root. Note that, d two adjacent vertices v i 1 and v i that are not siblings, av remark that the last expression for computing the distance of a generic v in the definition of d R . However, for the sake of clarity we have pointed out these two particular cases.
Definition 11 ( Distance-based Similarity ). Let P be a pattern, R be a region in a target T , x x = M ( x p ). The similarity is computed as: The similarity is 0 if the obtained value is below 0.

Example 11. The third columns of Tables 2a and 2b report the distance-based similarities. The evaluation details are in Appendix A . 4. Construction of fragments and regions
The focus of this section is on the data structures and algorithms for the efficient identification of fragments and regions in the target. As specified in Definition 3 , each fragment is a set of nodes bound by the ancestor X  descendant relationship in the target. A general purpose indexing structure along with an indexing structure depending on the pattern P are employed for improving the performances of our approach. Fragments are merged into regions, as specified in Definition 4 , only when the similarity between P and the generated region is greater than the similarity between P and each single fragment. Target subtrees covered by a region should be evaluated only accessing nodes in the regions and information contained in the auxiliary indexing structures.

In the remainder of the section, we first present the indexing structures. Then, we discuss the algorithms for the construction of a list of fragments and for the creation of regions starting from such a list. 4.1. Similarity-based inverted index and pattern index
Directly evaluating the pattern on the target is inefficient and introduce scalability issues in the approach, due to the tag and structural heterogeneity of the collection. For these reasons, a similarity-based inverted index (SII) is proposed. This index is independent from the retrieval pattern and is composed by a traditional inverted index coupled with a table, name-similarity table , that specifies relationships among tags in the col-lection relying on the semantic functions discussed in Section 2 .
 This index allows us to easily identify in the collection nodes with similar tags according to different criteria.
Since the number of labels that normally occur in a target is sensibly smaller than the number of elements, the size of the name-similarity table is often contained and it can also fit in main memory.

The SII index is built as follows. Starting from the labels of a target T , a traditional inverted index is cre-for each vertex v 2 V  X  T  X  . Then, tags in the collection are grouped according to each of the tag-based similar-ity functions presented in Section 2 and each group is progressively numbered. Each tag is finally associated with the list of the group identifiers it belongs to. Fig. 8 b reports this association by means of a table. For example, author and authors belong to the same class according to function S authors , and writer belong to the same class according to function S l should be retrieved in the target, the rows in the name-similarity table corresponding to l are extracted, and then, according to one or more similarity measures, all the similar tags are easily identified. In the case l does not belong to the name-similarity table, one of the tag-based similarity functions can be applied to iden-tify a similar tag in the table.

Given a pattern P , for every node v in P , all the occurrences of nodes u in the target tree such that level in a pattern index . The pattern index therefore depends on the pattern that should be evaluated on the target. The number of levels in the index depends on the levels in T at which vertices occur with labels similar to those in the pattern. For each level, vertices are ordered according to the pre-order rank.
Depending on the label similarity functions in S , different pattern indexes can be generated. Fig. 9 a shows the pattern index obtained by identifying nodes identical to those of the pattern, Fig. 9 b reports the pattern index obtained by applying the ontology-based function S t the criteria have been exploited. All the pattern indexes are obtained starting from the pattern in Fig. 1 a eval-uated on the SII index in Fig. 8 corresponding to the target in Fig. 2 . The construction of the pattern index requires to identify the entries in SII with similar tags to those of P .
SII . Once the entries are identified, the corresponding nodes are inserted in the pattern index. Since the nodes in each entry are ordered according to the pre-order rank in the target, the construction of the pattern index is performed in linear time. Therefore, the number of operations for each tag in P is in the order of O  X  K M  X  where K is the number of entries and M the maximal number of nodes in each entry. The number of opera-tions for the construction of the entire pattern index for a pattern P is thus O  X j P j K M  X  . We remark that the use of the name-similarity table does not affect the complexity of the approach in the worst case analysis but only in the average case.
 Algorithm 1 : Create Fragments
Require: PI , F , v , l
Ensure: return SF 4.2. Algorithms for the construction of fragments
Once the pattern index is generated, the fragments are generated through the recursive Algorithm 1: Cre-ateFragments and Algorithm 2: CreateListOfFragments . The main advantage of these algorithms is the iden-tification of the fragments through a single visit of the pattern index so that the complexity of fragments con-struction is kept linear.

To simplify the presentation of the algorithm we assume that, once a node in the pattern index is visited and inserted in a fragment, it is removed from the pattern index. In the algorithms, given a pattern index PI , denotes the first node in the list PI ( l ).

Algorithm CreateFragments is invoked relying on the level and the pre-order rank of the roots of the frag-ments to be generated. Given a fragment F , CreateFragments identifies all the nodes of F appearing in the pat-tern index and generates a tree on such nodes according to Definition 3 . Moreover, the recursive calls of this function also return the fragments whose roots appear in a lower level and precede the root of F .
Relying on the assumption that, when a fragment is generated it is removed from PI , the PI on which Cre-ateFragments is invoked for a fragment F does not contain all the nodes belonging to fragments whose roots all the nodes of F along with the nodes of the fragments whose roots precede root( F ) at a level h such that ( h &gt; l ).

Algorithm CreateFragments takes as input the pattern index PI , the current fragment F , a node v in F (ini-where we are looking for descendants of F . Its behavior relies on the following proposition.
Proposition 1. Let CreateFragments be invoked for a fragment F on a level l of a pattern index PI and a leaf node v of F located at a level m in PI(m &lt; l). The following properties hold: (1) If head ( PI ( l )) is a left relative of root( F ), head ( PI ( l )) is the root of a new fragment. (3) If head ( PI ( l )) is a descendant of v in F , head ( PI ( l )) belongs to F and is a descendant of v . (4) If head ( PI ( l )) is a right relative of root( F ), no elements of F can be identified at this level.
The cases described by Proposition 1 can occur in each invocation of Algorithm CreateFragments and han-dled as follows. We refer to Fig. 10 for a better understanding of the behavior of the algorithm. If head (-from PI . Therefore, a new fragment F 0 is created and Algorithm CreateFragments is invoked for this fragment root( F ) and Algorithm CreateFragments is invoked on F and u to identify possible descendants of u in F at
Proposition 1 ), w is associated as a child of v and Algorithm CreateFragments is invoked on F and w to identify possible descendants of w in F at level l+1 (as shown in Fig. 10 node z will be identified). If l can belong to F . Algorithm CreateFragments is thus invoked recursively on F , the same v and level l +1in order to identify further descendants of v that do not stay at level l . Through this call, nodes y and s will be identified if v is their immediate ancestor in F .

Starting from the root of a fragment F , Algorithm CreateFragments is recursively invoked on the levels of tains a node of F , it is detected and inserted in the correct position in the hierarchical structure of F .
Algorithm CreateListOfFragments generates fragments starting from the first level of PI and moving down-ments is invoked on each of the fragments of the first level. Once all the fragments of the first level have been identified, the algorithm proceeds with the nodes of PI still belonging to the remaining levels (if they are not empty). Algorithm CreateListOfFragments ends when it reaches the last level of PI and all the nodes have been removed from PI .
 Algorithm 2 : Create List Of Fragments
Require : PI Ensure return SF identifies all fragments in PI.

All the atomic operations in the algorithm (checking whether a node precedes another one, adding a node to a fragment, removing a node from PI ) require a constant number of operations. The algorithm visits each vertex in the pattern index only once by removing in each level the vertices already included in a fragment. Therefore, its complexity is in O  X  N  X  , where N is the number of nodes in PI .

Fig. 11 contains fragments F 1 , ... , F 4 obtained from the PI of Fig. 9 c. 4.3. Algorithm for the construction of regions
Two fragments should be merged in a single region when, relying on the adopted similarity function, the similarity of the pattern with the region is higher than the similarity with the individual fragments.
Whenever a document in the target is quite big and the number of fragments is high, the regions that should be checked can grow exponentially. To avoid such a situation we exploit the following locality prin-ciple : merging fragments together or merging fragments to regions makes sense only when the fragments/ regions are close. Indeed, as the size of a region tends to be equal to the size of the document, the similarity decreases.

In order to meet such locality principle regions are obtained by merging adjacent fragments. Operatively, two adjacent fragments can be merged when their common ancestor v is not the root of the target. If it is not the root of the target, their common ancestor v becomes the root of the region and the roots of the fragments become the direct children of v . We remark that the common ancestor of two fragments can be easily obtained by traversing the P -arent link included in the nodes of the pattern index.

Combining the locality principle and the approach for merging together two adjacent fragments, Algorithm 3: CreateListOfRegions is obtained. The algorithm works on the list of fragments SF obtained from Algorithm
CreateListOfFragments that is ordered according to the pre-order rank of the roots of the fragments it con-tains. Once a possible region R i is obtained, by merging two adjacent fragments SF ( i 1) and SF ( i ), the sim-
S im  X  P ; R i  X  is the highest, SF ( i 1) is removed from the list and SF ( i ) substituted with R is kept alone and we try to merge SF ( i ) with its right adjacent fragment. The process ends when all the frag-ments in the list have been checked.
 Algorithm 3 : Create List Of Regions
Require SF , P Ensure return SF Example 12. Considering the running example we try to generate regions starting from the fragments in
Fig. 11 . Since the common ancestor between F 1 and F 2 is the root of the target, the two fragments cannot be merged. Same behavior for fragments F 2 and F 3 . Since the common ancestor between F the same document, region R in Fig. 11 is generated. Since the similarity of P with R is higher than its similarity with F 3 and F 4 , R is kept and F 3 , F 4 removed. At the end of the process we have regions { F
A key point of our approach is the efficient computation of the similarity between a pattern P and a frag-ment F or a region R . An array indexed on the labels of P is employed to keep the highest evaluation of sim-added to obtain the similarity between P and F / R . The number of operations is O  X j P j X  . Since the similarity between P and F can be computed during the construction of a fragment, the complexity for evaluating the similarity between P and F in this phase is constant. Things are different for the similarity between P and R , where R is the combination of two fragments. In this case, the evaluations of two arrays should be compared and thus the number of operations is O  X j P j X  .

For the construction of a region a pair of fragments F 1 and F with F 1 and F 2 containing the highest similarity between P and them, must be visited for obtaining the eval-uation of a region. Since the arrays have | P | entries and each fragment is considered only once, the number of Since in the worst case, each fragment contains a single node of the pattern index PI , size ( SF )= size ( PI ).
Therefore, the creation of regions from SF requires O  X  N j P j X  operations, where N is the number of nodes in PI .

We wish to remark that the construction of regions is quite fast because the target should not be explicitly accessed. All the required information are contained in the inverted indexes. Moreover, thanks to our locality principle the number of regions to check is proportional to the number of fragments. Finally, the regions obtained through our process do not present all the vertices occurring in the target but only those necessary for the computation of similarity. Vertices appearing in the region but not in the pattern are evaluated through the pre/post-order rank of each node.

Example 13. Consider the region R 2 in Fig. 5 and the corresponding representation F invited is not explicitly present in R . However, its lack can be taken into account by considering the levels of vertex conference and vertex paper .

The following proposition summarizes the complexity of the algorithm for the creations of regions starting from a pattern.

Proposition 3. Let P be a pattern, K the number of distinct label in the SII index, and M the maximal size of an entry in SII. Moreover, let N be the number of nodes in the pattern index PI. The number of operations for the creation of regions starting from a pattern is O  X  max f X j P j K M  X  ;  X  N j P j X g X  . 5. Prototype and experimental results
We have implemented a prototype using a Oracle Berkeley DB in the back-end, which is being used for the exploration of heterogenous sources in biomedical information integration projects. An example of this func-tionality is shown in two screenshots: Fig. 12 shows the combined results for a query and Fig. 13 shows the top tures. This allows the data engineer to study the available collections as a whole, progressively refining the targets and the measures. Note that the system allows tailoring the similarity measure on-the-fly; this case uses a domain-specific label-matching function (see Section 2.2 ).

We have used this system to experimentally evaluate, both on real and synthetic data, the following aspects of our approach: (1) Reasonable performance with large collections. (2) Handling of severe structural distortions. (3) Retrieval effectiveness in highly heterogeneous collections.

In the remainder of the section we report our results along these aspects. 5.1. Performance
The performance of the system has been tested using two large synthetic datasets, with associated test pat-terns. Dataset 1 is designed to contain just a few matching results, embedded in a large number of don X  X  -care nodes (around 7500 relevant elements out of 10 7 elements). In contrast, dataset 2 has a high proportion of lections have been obtained by sampling each dataset. The characteristics of all datasets are summarized in
Fig. 14 a and b. Results in Fig. 14 c and d show that the retrieval performance is linearly dependent on the size of the result set. 5.2. Effect of structural distortions
The second aspect we have evaluated is the effect of structural variations in fragments. In order to test this, we have generated another synthetic dataset, in which we have embedded potential matches of a test pattern containing 15 elements with the following kinds of controlled distortions: (1) addition of n random nodes; (2) deletion of n random nodes; (3) switching the order of nodes in the same level, with a given probability; (4) switching parent and child nodes, with a given probability.

Results in Fig. 15 show that the system is able to find all relevant fragments despite the introduced distor-tions. Predictably, only the removal of relevant nodes in the target has an effect in the average relevance of results. Adding nodes, switching nodes in the same level, and interchanging parent and child nodes have no effects on the retrieval rate. 5.3. Retrieval in highly heterogeneous collections
In our third set of experiments we analyze the retrieval effectiveness in the context of highly heterogeneous collections. Our goal is to evaluate the effectiveness of our approach according to different parameters, such as the size of the data collection, its degree of vocabulary and structural heterogeneity, and its degree of confor-mance to the query.

We experimented on a set of document collections patterned after the highly heterogeneous ASSAM set. While the information content of the generated collections is the same of that of the real ASSAM, the new collections are bigger and present different levels of heterogeneity and conformance to the queries. The gen-eration is based on empirical estimations of the relative probabilities of ASSAM X  X  main topics and entities.
Since the queries present a tree structure as well, pattern generators have been employed for the automatic construction of synthetic queries. The use of a probabilistic approach for the generation of queries simulates the users X  uncertainty about the structure of the target collection in query formulation.

To obtain quality measures such as precision and recall we need relevance assessments. These are manually evaluated on the original ASSAM collection. In the generated collections, query identifiers are linked to the pattern used for the generation of the collection, thus specifying which generated subtrees constitute a correct answer for the query. This allows us to build collections of arbitrary size while being able to assess the rele-vance of each query answer.

In what follows, we first describe the generation of documents and queries and then present the experimen-tal results on the original collection and on the generated ones.

Generation of documents and queries. To generate suitable test collections and queries we have built a new system whose generation model significantly expands ToXgene [12] facilities, that only provides limited sup-port for  X  X  X andom structures X  X , for the specification of heterogeneous contents.

Our collection generator provides a set of XML pattern constructors , which encapsulate different templates for generating XML structures. A generator pattern is itself an XML document, whose nodes represent both pattern constructors and the tags to be generated. In general, the ancestor/descendant relationships between these tags will be preserved in the generated documents. Each node in a generator pattern may have associated a probability indicating the likelihood of finding the subtree it represents in the generated documents (if omit-model supports a wide variety of possible heterogeneous structures; Table 3 shows the main pattern construc-tors available.

Table 4 shows the summary of the generation patterns used in our experiments. They mainly reflect the features of the ASSAM dataset. As this dataset is mainly a semi-structured representation of a set of web ser-vices, their structures are quite heterogeneous and tag names also present many variations. In this collection, tag names are usually phrases that combine in some way the key concepts of the web service. This feature has been simulated using the a:combi pattern constructor, estimating n -gram probabilities from ASSAM data.
This has been simulated by introducing subpatterns with the constructor a:subPattern .In Table 4 the last column indicates the used subpatterns in each generator pattern. Two sample generators models are shown in
Fig. 16 .
Results on the generated documents and queries. The generated queries were evaluated against a generated collection of 50000 documents, with a total of one million nodes and around five thousand unique labels (around 500 times larger than the original ASSAM). Given the characteristics of the collection, we selected the following parameters for the experiments:  X  We compared the performance of strict label matching with a partial matching function adapted to the characteristics of the collection as described above. The resulting partial matching function combines most of the similarity functions described in Section 2.2 .  X  We used the structural distance similarity measure described in Section 3.2 , with d = 0.1; the results obtained with the level measure were similar for this particular collection.

Fig. 17 shows the precision, recall and F 1 -measure, as well as the precision@10, recall@10 and F the values express the 10 highest-ranked results).

The results under these experimental conditions can be summarized as follows:  X  Setting the cutoff at 10 produces much better results than considering all the results. There is an exception for query 3; a closer analysis of this particular case shows that query 3 contains very ambiguous tags, pro-ducing a large set of irrelevant results despite the use of tag similarity functions.  X  As expected, the results obtained using strict label matching produce a better precision than those obtained using partial label matching, while partial matching produces better recall. Overall, the F erally better for strict matching on all the results, but the combination of 10-highest ranked and partial matching is the best combination.

Results on the original ASSAM collection. Analogous queries were evaluated against the original ASSAM collection, and the relevance of the results checked by hand. A summary of the results is shown in Fig. 18 . The first column indicates the query number, and the second column indicates the similarity threshold used for the answer set (we used an explicit cutoff percentage MinSim instead of selecting the k highest results due to the relatively small size of the collection). The results are closely related to those obtained in our more general experimental setting, including the low F 1 for query Q3. 6. Related work
The need of shifting from exact queries with boolean answers to proximity queries with ranked approxi-mate results is a relevant requirement of XML query languages for searching the Web and several approaches in this direction have been developed. These approaches share the goal of integrating structural conditions typical of database queries with weighted and ranked approximate answers typical of Information Retrieval (IR). Work from the IR area [13] is mainly concerned with the retrieval of XML documents, by representing them with known IR models. These approaches mainly focus on the textual part of XML documents and structure is only used to guide user queries.

A crucial issue in ranked approximate querying is how to score results. A great variation of XML similarity discuss the similarity measures the most meaningful approaches to XML approximate querying rely on to rank results. Further specific structural similarity measures have been proposed in the areas of Schema Match-ing [16] and more recently Ontology Alignment [17] . In the former, tree/graph-matching techniques allow determining which schema portions from the target schema can be mapped to the source ones. In this context, data types and domain constraints are used to decide if two nodes match. However, schemas usually exhibit simple structures that seldom exceed three depth levels (relation-attribute-type). In the latter, the problem con-sists in finding out which concepts of a target ontology can be associated to concepts of the source ontology.
In this section, we focus on approximate query answering for XML documents taking both vocabulary and structural heterogeneity into account. First, we discuss the kind of heterogeneity taken into account and the similarity measures employed to score results. Then, algorithmic approaches to query relaxation and to com-pute the top-k results are reviewed.
 Heterogeneity degree and similarity evaluation. An early approach for XML approximate retrieval is
ELIXIR [18] that allows approximate matching in data content (tree leaves), and ranks the results according to the matching degree, disregarding structure in the evaluation. No structural heterogeneity is considered, and vocabulary heterogeneity is allowed only for data content elements, not for tags.

More sophisticated approaches, like XIRQL [19] and XXL [20] , accept approximate matching at nodes and then discuss how to combine weights depending on the structure. Vocabulary heterogeneity is supported for content and element tags, but no structural heterogeneity is allowed: conditions on document structure are interpreted as filters, thus they need to be exactly satisfied. XXL supports a similarity operator and, to use this operator, the user should be aware of the occurrence of similar keywords or element tags.
In the approach proposed by Damiani and Tanca [21] both XML documents and queries are modeled as graphs labeled with fuzzy weights capturing the information relative relevance. They propose to employ both structure related weighting (weight on an edge) and tag related weighting (weight on a node). Some criteria for weighting are proposed such as the weight decreases as moving far away from the root, the weight depends on the dimension of the subtree. Shortcut edges are considered, thus allowing the insertion of nodes, which weight is function of weights of edges. The match score is a normalized sum of weight of edges.
 In the tree relaxation approach [2] exact and relaxed weights are associated with query nodes and edges.
The score of a match is computed as the sum of the corresponding weights, and the relaxed weight is function of the transformations applied to the tree. The considered transformations are: relax node , replacing the node content with a more general concept; delete node , making a leaf node optional by removing the node and the edge linking it to its parent; relax edge , transforming a parent/child relationship to an ancestor/descendant relationship; promote node , moving up in the tree structure a node (and the corresponding subtree).
The approXQL [5] approach can also handle partial structural matchings. All the paths in the query are however required to occur in the document. The allowed edit operations on the document tree are delete node, insert intermediate node, relabel node. The score of match is function of the number of transformations, each one of which is assigned with a user-specified cost.

Amer-Yahia et al. in [3] account for both vocabulary and structural heterogeneity and propose scoring methods that are inspired by tf * idf and rank query answers on both structure and content. Specifically, twig scoring accounts for all structural and content conditions in the query. Path scoring, by contrast, is an approx-imation of twig scoring that loosens the correlations between query nodes when computing scores. The key idea in path scoring is to decompose the twig query into paths, independently compute the score of each path, and then combine these scores.

The main differences among the considered approaches are summarized in Table 5 . Note how approaches to XML approximate queries have progressively shifted to higher degrees of heterogeneity, and to cope also with structural heterogeneity. Our approach allows for more significant structural variations and can be con-sidered as a step forward in the treatment of structural heterogeneity in the context of XML. All the consid-ered approaches, indeed, enforce at least the ancestor X  X escendant relationship in pattern retrieval, whereas our approach also allows to invert and relax this relationship. Our approach, moreover, is highly flexible because it allows choosing the most appropriate structural similarity measures according to the application semantics.

Tree embedding and top-k processing. A different perspective from which approaches to XML approximate querying started, is that of looking for approximate structural matches, allowing the structure of the docu-problems, ranging from unordered tree inclusion to ordered subtrees, highlighting the inclusion relationships among them. Moreover, he gives a general schema of solution, and instantiates it for each problem, discussing the resulting complexities. His goal, however, is not to measure the distance, nor to rank results. All the instances of the pattern in the data tree are returned.

Another approach aimed at identifying the matches but that does not rank them, is by Kanza and Sagiv [22] . They advocate the need of more flexible query evaluation mechanisms in the context of semi-structured data, where both queries and data are modeled as graphs. They propose mapping query paths to data paths, so long as the data path includes all the labels of the query path; the inclusion needs not to be contiguous or in the same order.

Sub-optimal approaches for ranked tree-matching have been proposed for dealing with the NP complexity of the tree inclusion problems widely discussed and analyzed in [1] . In these approaches, instead of generating all (exponentially many) candidate subtrees, the algorithms return a ranked list of  X  X  X ood enough X  X  matches.
For example, in [23] a dynamic programming algorithm for ranking query results according to a cost function is proposed. In [2] a data pruning algorithm is presented where intermediate query results are filtered dynam-ically during evaluation process. ATreeGrep [24] , instead, uses as basis an exact matching algorithm, but allowing a fixed number of  X  X  X ifferences X  X  in the result. [4] proposes an adaptive query processing algorithm to evaluate approximate matches where approximation is defined by relaxing XPath axes. In adaptive query processing, different plans are permitted for different partial matches, taking the top-k nature of the problem into account.

Starting from the user query, the approaches [2 X 5] , for structural and content scoring of XML documents, generates relaxations of the query structure that preserve the ancestor X  X escendant relationships existing among nodes in the query. These relaxations do not consider the effective presence of such a structure in the collection of documents. The number can also be really high when the number of nodes in the query is high. The novelty of our approach relies on the employment of ad-hoc indexing structures. By exploiting such auxiliary information, only the variations on the pattern that occur in the target are considered. The number discussed in the previous section. Finally, in [2 X 5] constraints in the user queries are relaxed to augment the obtained results, whereas in our approach, we start from a completely relaxed query. We follow this approach because of the high degree of heterogeneity of the collection of documents we work on and we apply indexing structures for improving the performance. 7. Conclusions and future work
In this paper we have developed an approach for the identification of subtrees similar to a given pattern in a collection of highly heterogeneous semi-structured documents. In this context, the hierarchical structure of the pattern cannot be employed for the identification of the target subtrees but only for their ranking. Peculiarities of our approach are the support for tag similarity relying on a thesaurus, the use of indexing structures to improve the performance of the retrieval, and a prototype of the system.

As future work we plan to compare different similarity measures in order to identify those more adequate depending on the application context and the heterogeneity of the considered data. Such measures can be col-lected in a framework of functions that a user can select, compose, and apply depending on her needs. More-over we plan to consider more sophisticated patterns in which further constraints on vertices and edges can be stated. For instance, an element or a portion of the pattern could be requested to mandatorily appear in the target regions, or the difference between the levels in which two elements appear could be constrained by fixing a threshold. The constraints should then be considered in the similarity evaluation. Finally, we wish to con-sider subtree identification in a collection of heterogeneous XML Schemas. In this context, the proposed approach should be tailored to the typical schema constraints (e.g., optionality and repeatability of elements, groups, types).
 Appendix A. Details of similarity evaluation
Detailed match-based similarity (see Example 9 ). Let x p
Fig. 5 and x 1 r ; x 2 r ; x 3 r the corresponding vertices in the regions R same label then the match-based similarity is 1, whereas in the other two regions a similar tag appears, then the match-based similarity is 1 d .

Consider now Table 2b . Since R 1 has two perfect node matches over three nodes in the pattern, the resulting similarity is 2 3 . Region R 2 has two perfect matches and a similarity match, over three nodes in in all cases.

Detailed level-based similarity (see Example 10 ). In Table 2a , the level-based similarity is 1 for region R because the vertex tagged article in that region appears at the same level it appears in the pattern. By contrast, the level-based similarity between x p and x 2 r levels of difference (the level of x 2 r is 3 and the level of x
R is 4. The level-based similarity between x p and x 3 r is 1 level of difference (the level of x 3 r is 2 and the level of x
R is 2.

Consider now Table 2b . Since R 1 has two perfect (both tags and levels coincide) node matches over three region R 3 , the bottom mapping in Fig. 6 results in 1 2 d for node labeled article and 1 d for node labeled the right mapping in Fig. 6 yields to 1 d both for node labeled article for node labeled title , thus in  X  1 d  X  overall similarity, which is the highest one.

Detailed distance-based similarity (see Example 11 ). The distance-based similarity between x because the vertex is in the same position (root). In region R
Node article has distance 3 in R 3 (where the maximal distance is 3) whereas the distance in the pattern
Consider now Table 2b . Since R 1 has two perfect (both tags and positions coincide) node matches over for node labeled article , 1 2 for node labeled title and for node labeled conference , thus resulting in 3 . For region R 3 , the bottom mapping in Fig. 6 results in 1 for node labeled title , thus in 1 2 2 3 d overall similarity. The left mapping in Fig. 6 yields to 1 d for node labeled conference and to 2 3 d for node labeled article , thus in 5 the right mapping in Fig. 6 yields to 1 d both for node labeled article for node labeled title , thus in  X  1 d  X  overall similarity, which is the highest one.
 Appendix B. Proof sketches
Proof Sketch of Proposition 1 . We prove the properties of this proposition through Fig. 10 . In the figure, we nodes are those that can occur at level l in the pattern index for the creation of a fragment F . The following situations can arise.
Proof sketch of Proposition 2 . The proposition directly follows from Proposition 1 and the considerations of how Algorithm 2: CreateListOfFragments works. Indeed, if a node v at a given level of the current PI is not is the root of a fragment and will be removed along with all its descendants when Algorithm 2: CreateListOf-Fragments is invoked on its level. h
Proof Sketch of Proposition 3 . The number of operations for the entire process of region construction is the maximum between the number of operations required for the construction of the pattern index and those required for the extraction of regions from the pattern index. Therefore, exploiting the complexity specified for these operations, the process of region construction is in O  X  max fj P j K M  X  ; N j P jg X  . h
References
