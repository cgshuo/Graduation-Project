 For a given query raised by a specific user, the Query Sug-gestion technique aims to recommend relevant queries which potentially suit the information needs of that user. Due to the complexity of the Web structure and the ambiguity of users X  inputs, most of the suggestion algorithms suffer from the problem of poor recommendation accuracy. In this pa-per, aiming at providing semantically relevant queries for users, we develop a novel, effective and efficient two-level query suggestion model by mining clickthrough data, in the form of two bipartite graphs (user-query and query-URL bi-partite graphs) extracted from the clickthrough data. Based on this, we first propose a joint matrix factorization method which utilizes two bipartite graphs to learn the low-rank query latent feature space, and then build a query simi-larity graph based on the features. After that, we design an online ranking algorithm to propagate similarities on the query similarity graph, and finally recommend latent seman-tically relevant queries to users. Experimental analysis on the clickthrough data of a commercial search engine shows the effectiveness and the efficiency of our method. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query Formulation, Search Process Algorithms, Performance, Experimentation Similarity Propagation, Matrix Factorization, Query Sug-gestion, Clickthrough Data, Web Search With the exponential growth of information on the World Wide Web, Web search engines provide an indispensable in-terface for Web users to obtain any kind of information they may seek. Although current commercial search engines have been proved to be successful for recommending the most relevant Web pages to users, there are several outstanding issues that can potentially degrade the quality of search re-sults, and these merit investigation. The first one is the ambiguity which commonly exists in the natural language. Queries containing ambiguous terms may confuse the search engine into retrieving Web pages which do not satisfy the in-formation needs of users. Another consideration, as reported in [12, 25], is that users tend to submit short queries consist-ing of only one or two terms under most circumstances, and short queries are more likely to be ambiguous. Through the analysis of a commercial search engine X  X  query logs recorded over three months in 2006, we observe that 19.4% of Web queries are single term queries, and a further 30.5% of Web queries contain only two terms. Thirdly, in most cases, the reason why users search is that they have little or even no knowledge about the topic they are searching for. In or-der to find satisfactory answers, users have to rephrase their queries constantly.

To overcome all of these problems, a valuable technique, query suggestion, has been employed by some famous com-mercial search engines, such as Yahoo! 1 , Live Search 2 , Ask and Google 4 , to recommend relevant queries to users. How-ever, due to the commercial reasons, few public papers have been released to unveil the methods they adopt.

Typically, query suggestion is based on local (i.e., search result sets) and global (i.e., thesauri) document analysis [31], or anchor text analysis [19]. However, these traditional methods have difficulty summarizing the latent meaning of a Web document due to the huge noise embedded in each Web page. Moreover, this noise is not easily removed by ma-chine learning methods. In order to avoid these problems, some additional data sources are likely to be very helpful to improve the recommendation quality.

In fact, clickthrough data is an ideal source for mining rel-evant queries. In the typical search scenario, a user initiates a query, and submits it to a search engine. The search engine returns a set of ranked related Web pages or documents to this user. The user then clicks some pages of interest. Some users even refine their queries in order to find the desired information. Therefore, the collection of queries is likely to well reflect the relatedness of the target Web pages [26]. http://www.yahoo.com http://www.live.com http://www.ask.com http://www.google.com
Recently, as a valuable data source, clickthrough data has been employed in some research work in order to op-timize ranking of Web search results [1, 15, 16, 26, 29], im-prove clustering accuracy [4, 30], or conduct other interest-ing work [22, 24]. However, most of these references extract only the query-URL bipartite graph of the clickthrough data for analysis, and ignore the information of users who issued the queries. Actually, users perform as the most important role in the clickthrough data, since all the queries are issued by the users, and which URLs to click are also decided by the users. The connections between queries and URLs are essentially bridged by different kinds of users. Moreover, if two distinct users issued the similar set of queries, we can assume that these two users are very similar since they have similar information needs. From the above analysis, we can-not ignore the users in the clickthrough data.

In this paper, by analyzing the clickthrough data, we de-velop a query suggestion framework using two-level latent semantic analysis. We first extract two bipartite graphs, which are user-query and query-URL bipartite graphs. Then we give solutions to the following two problems: (1) How to learn the query latent feature space from these two bipartite graphs, and (2) How to recommend semantically relevant queries to users?
As to the first problem, we develop a joint matrix fac-torization method which fuse user-query and query-URL bi-partite graphs together to learn the low-dimensional query latent feature space. Then we build a query graph based on the representation of query space. In order to address the second problem, we develop a novel, effective, and efficient similarity propagation model, which not only suggests a list of queries relevant to the queries submitted by users, but also ranks the query list based on the similarity scores.
We evaluate our model for query suggestion using click-through data of a commercial s earch engine. We evaluate our model from different angles: (1) First, it is assessed by a panel of three experts. (2) Then, we evaluate it in terms of the ground truth extracted from the ODP 5 (Open Directory Project) database. (3) Finally, we measure the efficiency of our online query suggestion algorithm by mea-suring how much CPU time that it needs. The results show that our method is both effective and efficient for improving the recommendation quality, as well as generating semanti-cally related queries to users.

The rest of the paper is organized as follows. We review related work in Section 2. Section 3 describes the construc-tion of two bipartite graphs, and proposes a joint matrix factorization method of learning query latent feature space. Section 4 presents the similarity propagation model as well as the method for recommending queries. In Section 5, we demonstrate the empirical analysis of our models and algo-http://www.dmoz.org rithms. Finally, conclusions and future work are given in Section 6.
Our work addresses two important research topics: query suggestion or query recommendation, and clickthrough data analysis.
The intention of query suggestion is similar to that of query expansion [6, 7, 27, 31], query substitution [17] and query refinement [19, 28], which all focus on improving the queries submitted by users. Query suggestion is closely re-lated to query expansion or query substitution which ex-tends the original query with new search terms to narrow the scope of the search. But different from query expansion, query suggestion aims to suggest full queries that have been formulated by previous users so that query integrity and co-herence are preserved in the suggested queries [10]. Query refinement is another closely-related notion, since the objec-tive of query refinement is interactively recommending new queries related to a particular query.

In [31], local and global documents are employed in query expansion by applying the measure of global analysis to the selection of query terms in local feedback. Although experi-ment shows that this method is generally more effective than global analysis, it performs worse than the query expansion method proposed in [7] based on user interactions recorded in user logs. In another approach reported in [19], anchor texts are employed for the purpose of query refinement. This work is based on the observation that Web queries and an-chor texts are highly similar.

In [3] and [8], two query recommendation methods based on clickthrough data are proposed. The main disadvantage of these two algorithms is that they ignore the rich informa-tion embedded in the query-click bipartite graph, and con-sider only queries that appear in the query logs, potentially losing the opportunity to recommend highly semantically related queries to users.

In addition, query suggestion technology has also been developed and applied into several other promising topics, such as pay-for-performance search [11], question-answering service [14], personalized search [6], etc.
In the field of clickthrough data analysis, the most com-mon usage is for optimizing Web search results or rank-ings [1, 15, 16, 26, 29]. In [29], Web search logs are uti-lized to effectively organize the clusters of search results by (1) learning  X  X nteresting aspects X  of a topic and (2) gen-erating more meaningful cluster labels. In [16], a rank-ing function is learned from the implicit feedback extracted from search engine clickthrough data to provide personal-ized search results for users. Besides ranking, clickthrough data is also well studied in the query clustering problem [4, 30]. Query clustering is a process used to discover frequently asked questions or most popular topics on a search engine. This process is crucial for search engines based on question-answering [30]. Recently, clickthrough data has been ana-lyzed and applied to several interesting research topics, such as Web query hierarchy building [24] and extraction of class attributes [22].
Before suggesting queries to users, we first need to pre-process clickthrough data. In this section, we first introduce the structure of clickthrough data and how to construct two bipartite graphs. Then we present a novel joint matrix fac-torization method to learn the low-rank representation for queries.
Clickthrough data records the activities of Web users, which reflects their interests and the latent semantic rela-tionships between users and queries, as well as queries and clicked Web documents. As shown in Table 1, each line of clickthrough data has the following information: a user ID ( u ), a query ( q ) issued by the user, a URL ( l )onwhich the user clicked, the rank ( r )ofthatURL,andthetime( t ) at which the query was submitted for search. Thus the clickthrough data can be represented by a set of quintu-ples u, q, l, r, t . From a statistical point of view, the query word set corresponding with a Web page contains human knowledge on how the pages are related with their issued queries [26]. Thus, in this paper, we utilize the relationships of users and queries, as well as queries and Web pages for the construction of two bipartite graphs containing three types of vertices u, q, l . The information of ranks and times is ignored.

For the user-query bipartite graph, consider an undirected bipartite graph B uq =( V uq ,E uq ), where V uq = U  X  Q , U = { u 1 ,u 2 , ..., u m } ,and Q = { q 1 ,q 2 , ..., q n } . E uq thereisanedgefrom u i to q j } is the set of all edges. The edge ( u i ,q j ) exists in this bipartite graph if and only if a user u i issued a query q j .

For the query-URL bipartite graph, consider another undi-rected bipartite graph B ql =( V ql ,E ql ), where V ql = Q Q = { q 1 ,q 2 , ..., q n } ,and L = { l 1 ,l 2 , ..., l p there is an edge from q i to l j } is the set of all edges. The edge ( q j ,l k ) exists if and only if a user u i clicked a URL l after issuing an query q j .

Figure 1 is an example of the representation of two bi-partite graphs of clickthrough data. The left side rectangle in dashed line contains the user-query bipartite graph B uq while the right side rectangle in dashed includes the query-URL bipartite graph B ql .

In order to perform matrix factorization task on bipartite graph B uq and B ql in the following sections, we transform these two bipartite graphs into two matrices R and S ,re-spectively. For the m  X  n user-query matrix R ,rowsrep-resent users, and columns represent queries. The value of r ij specifies how many times that user u i issued query q j From another aspect, this value indicates how much u i need information about query q j .Forthe n  X  p query-URL ma-trix S , similar to R ,weemploy s jk to quantify how many times that a query q j has been connected to the URL l k by different users. Here,  X  X ifferent X  means that if a user click thesamequery-URLpairseveraltimes,weonlycountit once. This consideration can best discover the relationship between queries and URLs.
The idea of user-query matrix factorization is to derive a high-quality low-dimensional feature representation U and Q of users and queries based on analyzing the user-query matrix R . Here, U is a d  X  m matrix, with each column being the d -dimensional feature vector of a user, while Q is a d  X  n matrix, with each column being the d -dimensional feature vector of a query. Then we define the optimization function as follows: where  X  u and  X  q are small positive numbers,  X  2 F denotes the Frobenius norm, and I R ij is the indicator function that is equal to 1 if user i issued query j and equal to 0 otherwise. The optimization aims to approximate observed value r ij by U i Q j , a product of two low-rank vectors, with regulariza-tion on U and Q . A local minimum of the objective function given by Eq. (1) can be found by performing gradient de-scent in U , Q .

In order to decrease the noise, we normalize the value of r ij by the maximum value of row i in user-query matrix R , denoted as r  X  ij . Now the value of r  X  ij is in the range of [0 , 1]. For the multiplication U T i Q j , we also bound it into range [0 , 1] by employing the logistic function g ( x )= 1 / (1 + exp(  X  x )). Hence, Eq. (1) is enhanced to
Now let us consider the query-URL matrix. Similar to user-query matrix, we also use two d -dimensional matrices Q and L to represent queries and URLs, respectively, where L is a d  X  p matrix, with each column being the d -dimensional feature vector of a URL. Similar to Eq. (2), the idea of query-URL matrix factorization can be represented by where I S jk is the indicator function that is equal to 1 if query j is clicked to URL k and equal to 0 otherwise,  X  q and  X  are small positive numbers. Similar to user-query matrix, s jk is normalized too.
In order to learn the latent query feature space from user-query and query-URL bipartite graphs together, we fuse Eq. (2) and Eq. (3) together by sharing the same query feature space. Hence, we have H ( S, R, U, Q, L )= 1 2 + 2 where  X  r is a small positive number to determine how much information need to be taken from user-query matrix. A local minimum of the objective function given by Eq.(4) can be found by performing simple gradient descent in U i , Q and S k ,  X 
H  X 
H  X 
H  X  X  where g ( x ) is the derivative of logistic function g ( x )= exp( x ) / (1 + exp( x )) 2 . In order to reduce the model com-plexity, in all of the experiments we conduct in Section 5, we set  X  u =  X  q =  X  l . Moreover, in all the experiments we conduct in Section 5, when building the query graph, we use fixed 20 dimensions to represent the query feature space.
Although recently, similar factor analysis methods have been employed in [33, 34] for document retrieval and doc-ument classification, our approach has essential difference compared with these methods. Our method only fits the ob-served data, and treat unobserved data unknown or missing, while their methods fit unobserved data with zero, which will potentially distort the latent feature space. Moreover, since we only fit the observed data, our consideration can accel-erate the computation time of the gradient descent, which will be analyzed in the next section.
Although the feature learning part is the offline computa-tion in our query suggestion framework, we still need to ana-lyze the complexity of it to show that our approach scalable to very large datasets. The main computation of gradient methods is evaluating the object function H and its gradi-ents against variables. Because of the sparsity of matrices R and S , the computational complexity of evaluating the object function H is O (  X  R d +  X  S d ), where  X  R and  X  numbers of nonzero entries in matrices R and S , respectively. The computational complexities for gradients  X  H  X  X  ,  X  H  X  X  in Eq. (5) are O (  X  R d ), O (  X  R d +  X  S d )and O (  X  spectively. Therefore, the total computational complexity in one iteration is O (  X  R d +  X  S d ), which indicates that the computational time of our method is linear with respect to the number of observations in the two sparse matrices. This complexity analysis shows that our proposed approach is very efficient and can scale to very large datasets.
Let us first consider the following problem: given a query q which is issued by a user u , how can we recommend a set of latent semantically relevant queries to this user? A base-line method is to recommend to u the top 5 similar queries of q . This method is simple and seems natural, but since all the queries of clickthrough data are user-generated con-tents, they contain a lot of noise. Some people are good at formulating queries, but some are not. Simply recommend-ing q  X  X  top similar queries has a high probability to intro-duce noise to u . To address this problem, in this section, we propose a novel similarity propagation and query suggestion model, which not only provides semantically relevant queries to users, but also ranks the results.
Our similarity propagation model is modeled on heat dif-fusion. Heat diffusion is a natural physical phenomenon. In a medium, heat always flows from a position with high tem-perature to a position with low temperature. Recently, heat diffusion-based approaches have been successfully applied in various domains such as classification and dimensionality re-duction problems [5, 18, 20]. Reference [20] approximated the heat kernel for a multinomial family in a closed form, from which great improvements were obtained over the use of Gaussian or linear kernels. In [18], Kondor et al. proposed the use of a discrete diffusion kernel for categorical data, and showed that the simple diffusion kernel on the hyper-cube can result in good performance for such data. Belkin et al. employed a heat kernel to construct the weight of a neighborhood graph, and apply it to a nonlinear dimension-ality reduction algorithm in [5]. In [32], Yang et al. proposed a ranking algorithm known as the DiffusionRank using heat diffusion process; simulations showed that it is very robust to Web spamming.

The heat flows throughout a geometric manifold with ini-tial conditions can be described by the following second or-der differential equation: where f ( x, t ) is the temperature at location x at time t , beginning with an initial distribution f 0 ( x ) at time zero, and  X  f is the Laplace-Beltrami operator on a function f [20].
In this paper, we model similarity propagation as a process of heat diffusion. First, we construct the query similarity graph G based on the query feature space learned in Sec-tion 3. Consider a directed weighted graph G =( V, E, W ), where V is the vertex or query set, and V = { q 1 ,q 2 , ..., q E = { ( q i ,q j ) | thereisanedgefrom q i to q j ,and q j set of q i  X  X  k nearest neighbors } .Theedge( q i ,q j )isconsid-ered as a pipe that connects nodes q i and q j . W = { w ij similarity that associated with edge ( q i ,q j ), or it can be in-terpreted as the probability that edge ( q i ,q j )exists value f i ( t ) describes the heat at node q i at time t , beginning from an initial distribution of heat given by f i (0)attime zero. f ( t ) denotes the vector consisting of f i ( t ).
On a directed graph G ( V, E, W ), in the pipe ( q i ,q j flows only from q i to q j . Suppose at time t ,eachnode q receives RH = RH ( i, j, t,  X  t )amountofheatfrom q j during aperiodof X  t . We have four assumptions: (1) RH should be proportional to the time period  X  t ;(2) RH should be proportional to the weight w ji of the directed edge ( q j (3) RH should be proportional to the heat at node q j ;and (4) RH is zero if there is no link from q j to q i .Asaresult, q all its neighbors that points to it.

Atthesametime,node q i diffuses DH ( i, t,  X  t )amountof heat to its subsequent nodes. We assume that: (1) The heat DH ( i, t,  X  t ) should be proportional to the time period  X  t ; (2) The heat DH ( i, t,  X  t ) should be proportional to the heat at node q i ; (3) Each node has the same ability to diffuse heat; (4) The heat DH ( i, t,  X  t ) should be distributed to its sub-sequent nodes proportional to the weight on each edge. As a result, node q i will diffuse (  X f i ( t ) X  t/d i ) k :( q amount of heat to its subsequent nodes, and each of its subsequent nodes q k should receive  X f i ( t ) w ik  X  t/d of heat, where d i is the outdegree of node i . Therefore  X  j =  X /d j . In the case that the outdegree of node i equals zero, we assume that this node will not diffuse heat to oth-ers. To sum up, the heat difference at node q i between time t + X  t and t will be equal to the sum of the heat that it receives, less what it diffuses. This is formulated as f ( t + X  t )  X  f i ( t ) where  X  i is a flag to identify whether node i has any out-links, such that  X  i = 0 if node i does not have any outlinks, otherwise,  X  i = 1. Solving Eq. (7), we obtain where Moreover, e  X t H could be extended as: The matrix e  X t H is called the diffusion kernel in the sense that the heat diffusion process continues infinitely many times from the initial heat diffusion.

Parameter  X  plays an important role in the diffusion pro-cess.  X  is the thermal conductivity, i.e., the heat diffusion co-efficient. If it has a high value, heat will diffuse very quickly. Otherwise, heat will diffuse slowly. In the extreme case, if it is infinitely large, then heat will diffuse from one node to other nodes immediately.

In fact, there are random relations among different queries even if these queries are unrelated in their literal meaning: people of different cultures, genders, ages, and environments, may implicitly link these queries together, but we do not know these latent relations. To capture these relations, we propose to add a uniform random relation among different queries. More specifically, let  X  denote the probability that such phenomena happen, and (1  X   X  ) is the probability of taking a  X  X andom jump X . Without any prior knowledge, we set g = 1 n 1 ,where g is a uniform stochastic distribution vector, 1 is the vector of all ones, and n is the number of queries. Based on the above consideration, we modify our model to Following the setting of  X  in PageRank [9, 21], we set  X  = 0 . 85 in all of our experiments conducted in Section 5.
With the diffusion model proposed in the above section, we can now make query suggestions by the following three steps. (1) First, for a given query q , we select a set of n queries in common with query q , as the heat sources. Then we employ Eq. (12) to calculate the similarities between q and all of the queries in set S as the initial heat values. where W ( q )isthesetofallthewordsthatquery q contains. For an example, if a user submits the query  X  X ony X , and suppose we have three previous queries containing  X  X ony X :  X  X ony X ,  X  X ony Electronics X , and  X  X ony Vaio Laptop X . We treat these three queries as the heat sources, and the initial heat values are 1, 1 / 2, and 1 / 3, respectively. (2) Then, we employ Eq. (11) to start the similarity prop-agation process, and calculate the value of each query in vector f (1). (3) Finally, we sort the results of f (1) in decreasing order, and recommend the Top-N queries to the user who issued the search task.
Since query suggestion is computed online, the computa-tional complexity of suggestion algorithm should be as small as possible. Search engine users also do not have the patience to wait for suggestions for a long time. In this section, we will analyze the complexity of our proposed method, and introduce some very efficient techniques to reduce the com-plexity, and to ensure our algorithm is scalable for very large query similarity graphs.

When the graph of the query similarity graph is very large, a direct computation of e  X  H is very time-consuming. We adopt its discrete approximation to compute the heat diffu-sion equation: where P is a positive integer. In order to reduce the compu-tational complexity, we introduce three techniques: (1) Since f (0) is a vector, we iteratively calculate ( I +  X  P R ) applying the operator ( I +  X  P R )to f (0). (2) For matrix R , we employ a data structure which only stores the informa-tion of non-zero entries, since it is a very sparse matrix. (3) For every heat source, we constrain it by only diffus-ing heat to its neighbors within three steps, which indicates that P = 3 in Eq. (13). This consideration is feasible since a query far from the heat sources would be less similar than the queries near the heat sources. Thus, since every query in query similarity graph G has less than k neighbors (see the definition of G in Section 4.1), the complexity of our query suggestion algorithm is O ( h  X  k 3 ), where h is the number of heat sources. This shows that our algorithm is very efficient since k  X  [20 , 50] can generally suggest queries with very good qualities, as shown in Section 5. We will show the im-pact of parameters k and P in Section 5.4 and Section 5.5, respectively.
We conduct several experiments to measure the effective-ness and efficiency of our proposed query suggestion frame-work. In Section 5.1, we describe the statistics of the dataset we utilize. Section 5.2 shows the recommendation results generated by our online query suggestion algorithm of 20 sample queries. In Section 5.3, we design two measure meth-ods to both manually and automatically evaluate the effec-tiveness of our algorithm. At the same time, we compare our Latent Semantic Query Suggestion (LSQS) method with the query suggestion method using SimRank [13]. Section 5.4 analyzes the impact of parameters k . Finally, Section 5.6 presents the empirical analysis of the efficiency of our online suggestion algorithm.
We construct our dataset based on the clickthrough data of AOL search engine [23]. In total, this dataset spans 3 months from 01 March, 2006 to 31 May, 2006. There are a total of 19,442,629 lines of clickthrough information, 657,426 unique user IDs, 4,802,520 unique queries, and 1,606,326 unique URLs.

This dataset is the raw data recorded by search engine, and contains a lot of noise which will potentially affect the effectiveness of our query suggestion algorithm. Hence, we conduct a similar method employed in [29] to clean the raw data. We clean the data by only keeping those frequent, well-formatted, English queries (queries which only contain characters  X  X  X ,  X  X  X , ...,  X  X  X , and space, and appear more than 3 times). After removing duplicates and cleaning, we get 19,2371 unique users, 224,165 unique queries and 343,302 unique URLs in our data collection in total. After the con-struction of two bipartite graphs using this data collection, we observe that a total of 5,220,660 edges exist in the user-query bipartite graph, which indicates that each user has at least issued 27.14 queries. we also observe that a total of 1,333,798 edges exist in the query-URL bipartite graph, which indicates that each query has 5.95 distinct clicks, and each URL is clicked by 3.89 distinct queries. Moreover, taken as a whole, this data collection has 69,937 unique words which appear in all the queries.
Before presenting the query suggestion results, let us first discuss some interesting characteristics of parameter  X  .As mentioned in Section 4.1,  X  is the thermal conductivity, and it plays an important role in the propagation process.
Following physical intuition, when  X  tends to infinity, the heat diffusion process will become stable, and does not de-pend on the initial temperature distribution, but only on the graph structure, the same as in PageRank. On the other hand, in the extreme case when  X  = 0, then no heat will diffuse, and temperature distribution will remain exactly at the initial values.
In the intermediate case, when  X  is small, the diffusion results will depend more on the initial temperature than the graph structure. In this case, queries suggested by our algorithm will have higher literal similarities with the initial query issued by a user. If  X  is relatively large, the results will depend more on the query graph structure, the the latent sematic relations hidden in the underlying query graph will be uncovered.

Hence, in our experiments, in order to recommend more latently similar queries to users, we combine the results gen-erated from small  X  and large  X  together. Empirically, in our dataset, we set the small  X  to 10 and the relatively large  X  to 1000. For every test query, we conduct the similarity propagation (i.e, heat diffusion) process twice, the first us-ing  X  = 10 and another using  X  = 1000. Then we combine the top 3 queries from the first d iffusion process and the top 2 queries from the second diffusion process together, as the final top 5 suggestion results which will be recommended to users.

In total, we create a set of 50 queries as the testing queries, covering a wide range of topics, such as Computers, Arts, Business, and others. The recommendation results are shown in Table 2. All the results in this table are generated based on the query similarity graph built using parameter k = 50, which indicates that in this directed graph, the outdegree of each query is less than or equal to 50. Due to space limita-tion, we only list the results of 20 testing queries generated by our query suggestion method. All the queries are con-verted to lowercase.

From the results, we observe that our suggestion algo-rithm not only suggests queries which are literally similar to the test queries, but also provides latent semantically rele-vant recommendations. For instance, as to the results using  X  = 1000, if the test query is a company, such as  X  X ntel X , we suggest  X  X entium X  and  X  X entrino X , which are two most suc-cessful sub-brands of semiconductor company Intel .Ifthe test query is a technique, such as  X  X ava X , we recommend  X  X un microsystems inc X  and  X  X irtual machine X . The former sug-gestion is the company who owns the Java Platform ,andthe latter suggestion is a key feature of the Java programming language. They both have high latent semantic relations to query  X  X ava X . If the test query is a human name, such as  X  X  schumacher X , the most successful Formula 1 driver, the latent semantic suggestions are  X  X errari cars X  and  X  X ormula one X . All of the results show that our latent semantic query suggestion algorithm has a promising future. In this section, we first compare our Latent Semantic Query Suggestion (LSQS) method with the approach us-ing SimRank [13]. Then we employ two different metrics to evaluate these two methods.

In the method of SimRank, we use the query-URL bi-partite graph to calculate the similarities between queries. Then based on the similarities, recommend the top-5 simi-lar queries to users. SimRank based on the intuition that two queries are very similar if they link to a lot of similar URLs. On the other hand, two URLs are very similar if they are clicked as a result of several similar queries. Based on this intuition, in SimRank, we first calculate the similarities between URLs, then we compute the similarities for queries based on the similarities of URLs. We iteratively update the similarities until they converge.
 In Table 3, we show the query suggestions of LSQS and SimRank using two ambiguous word  X  X aguar X  and  X  X pple X . We can observe that when using  X  X aguar X  as the keyword, our LSQS algorithm can basically suggest more diverse and relevant queries, while all the suggestions using SimRank are different creatures.  X  X pple X  is another example to show the suggestion results. SimRank only suggest queries that related to the  X  X pple company X , while our LSQS can suggest more kinds of queries related to  X  X pple X .

Evaluating the quality of semantic relations is difficult, in particular for the contents that generated by users, as there are no linguistic resources available. In this paper, we conduct both a manual evaluation by a panel of three human experts, and automatic evaluation based on the ODP database.

In the evaluation by human experts, we ask all the experts to rate the query suggestion results (we use the same 50 testing queries adopted in Section 5.2). We define a 6-point scale (0, 0.2, 0.4, 0.6, 0.8, and 1) to measure the relevance between the testing queries and the suggested queries, in which 0 means  X  X otally irrelevant X  while 1 indicates  X  X ntirely relevant X . The average values of evaluation results are shown in Table 4. We observe that, when measuring the results by human experts, our LSQS algorithm increases the accuracy for about 18.47% than the SimRank algorithm.
 For the automatic evaluation, we utilize the ODP database. ODP, also known as dmoz, is the largest, most compre-hensive human-edited directory of the Web. In this pa-per, we adopt the same method used in [2] to evaluate the quality of suggested queries. When a user types a query in ODP, besides site matches, we can also find categories matches in the form of paths between directories. More-over, these categories are ordered by relevance. For instance, the query  X  X ava X  would provide the hierarchical category  X  X omputers : Programming : Languages : Java X , where  X : X  is used to separate different categories. One of the re-sults for  X  X irtual Machine X  would be  X  X omputers : Pro-gramming : Languages : Java : Implementations X . Hence, tomeasurehowrelatedtwoqueriesare,wecanuseano-tion of similarity between the corresponding categories (as provided by ODP). In particular, we measure the similar-ity between two categories D and D as the length of their longest common prefix F ( D , D ) divided by the length of the longest path between D and D . More precisely, denoting the length of a path with |D| , this similarity is defined as: Sim ( D , D )= |F ( D , D ) | /max {|D| , |D |} . For instance, the similarity between the two queries above is 4 / 5sincethey share the path  X  X omputers : Programming : Languages : Java X  and the longest one is made of five directories. We have evaluated the similarity between two queries by mea-suring the similarity between the most similar categories of the two queries, among the top 5 answers provided by ODP.
As shown in Table 4, we observe that, when evaluating us-ing ODP database, our proposed LSQS algorithm increases the suggestion accuracy for about 17.86% than the SimRank algorithm. This indicates that our proposed query sugges-tion algorithm is very effective.
The parameter k defines the maximal outdegree of each query in the query similarity graph, and it performs as an important role in terms of both effectiveness and efficiency.
Figure 2(a) shows the impact of parameter k on the accu-racy measured by human experts. The X -axis is parameter k , while the Y -axis is the accuracy measured by human ex-perts. As increasing the number of k , the accuracy of LSQS raises, until k = 50. If k&gt; 50, the performance drops a little bit. This is because when k&gt; 50, and especially when k = 100, the possibility that noisy queries are becom-ing added into the query similarity graph is increased, which will potentially affect the quality of query suggestion results. Nevertheless, it still shows very good suggestion quality.
The evaluation results measured using ODP database is shown in Figure 2(b). It generally has the same trend as that observed in Figure 2(a). The main difference is that the accuracy scores using ODP database are generally smaller than the scores rated by the human experts. The reason is straightforward: human experts have a better understanding of the latent semantic similarities between two queries than does the ODP measure method. The parameter P indicates how far the heat diffuses. From Figure 3, we observe that when P = 3, our algorithm achieves the best performance, and then the suggestion quality de-creasesastheincreaseof P . This phenomenon is consistent with the intuition that a query far from the heat sources would be less similar with the original queries.
Efficiency is a very crucial measurement for evaluating online algorithms, especially for online query suggestion al-gorithm. If a query suggestion algorithm is not fast, then no onewoulduseitanymore. Weusethesametestingsetwith previous experiments containing 50 testing queries to evalu-ate the efficiency of our proposed algorithm. The number of diffusion sources for each testing query scales from only a few to several hundreds. We record the average computational time for online suggestions. The computational time in-cludes the similarity propagation time and the ranking time after the propagation. All the experiments are computed by a personal computer consisting of an Intel Pentium D CPU (3.0 GHz , Dual Core )and1 Giga memory. The results are shown in Figure 4. We observe that when k = 10, the av-erage computational time is less than 0.01 second, and this number only increases to 0 . 09 second if k = 50. Since k =50 is the best parameter setting in terms of suggestion quality in our data collection, we can draw the conclusion that our algorithm is efficient.
In this paper, we propose a novel query suggestion frame-work incorporating two parts: an offline computation part and an online computation part. The offline computation part employs a novel joint matrix factorization method us-ing user-query and query-URL bipartite graphs. The on-line part is implemented by a similarity propagation process modeled on the heat diffusion process, and can recommend both literally similar queries and latent semantically rele-vant queries to search engine users. The simulation results show that our proposed query suggestion framework is both effective and efficient.

The user IDs in clickthrough data are only used for the matrix factorization part. Actually, user ID information is very useful for improving the recommendation qualities, since some users can expertly formulate queries, while some are not experts. Hence, in the future, we plan to incorpo-rate the rank information of all the users in the clickthrough data based on link information.

In Section 4.2, Eq. (12) is employed to calculate the initial similarity scores for the diffusion sources. Different calcula-tion methods will definitely generate different query recom-mendation results. This is also a problem that is worth investigating.

Finally, due to the fact that question-answering services are becoming popular, we plan to develop a similar method to that proposed in this paper to match the question issued by a user to the most relevant question previously answered by human experts.
The authors appreciate the anonymous reviewers for their extensive and informative comments for the improvement of this paper. The work described in this paper was fully supported by two grants from the Research Grants Coun-cil of the Hong Kong Special Administrative Region, China (Project No. CUHK4150/07E and GRF #412507). [1] E. Agichtein, E. Brill, and S. Dumais. Improving web [2] R. Baeza-Yates and A. Tiberi. Extracting semantic [3] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza. [4] D. Beeferman and A. Berger . Agglomerative clustering [5] M. Belkin and P. Niyogi. Laplacian eigenmaps for [6] P. A. Chirita, C. S. Firan, and W. Nejdl. Personalized [7] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma. Query [8] G. Dupret and M. Mendoza. Automatic query [9] N. Eiron, K. S. McCurley, and J. A. Tomlin. Ranking [10] W. Gao, C. Niu, J.-Y. Nie, M. Zhou, J. Hu, K.-F. [11] D. Gleich and L. Zhukov. Svd subspace projections for [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic. [13] G. Jeh and J. Widom. SimRank: a measure of [14] J. Jeon, W. B. Croft, and J. H. Lee. Finding similar [15] T. Joachims. Optimizing search engines using [16] T. Joachims and F. Radlinski. Search engines that [17] R. Jones, B. Rey, O. Madani, and W. Greiner. [18] R. I. Kondor and J. D. Lafferty. Diffusion kernels on [19] R. Kraft and J. Zien. Mining anchor text for query [20] J. D. Lafferty and G. Lebanon. Diffusion kernels on [21] L. Page, S. Brin, R. Motwani, and T. Winograd. The [22] M. Pasca and B. V. Durme. What you seek is what [23] G. Pass, A. Chowdhury, and C. Torgeson. A picture of [24] D. Shen, M. Qin, W. Chen, Q. Yang, and Z. Chen. [25] C. Silverstein, M. R. Henzinger, H. Marais, and [26] J.-T. Sun, D. Shen, H.-J. Zeng, Q. Yang, Y. Lu, and [27] M. Theobald, R. Schenkel, and G. Weikum. Efficient [28] B. V  X  elez, R. Weiss, M. A. Sheldon, and D. K. Gifford. [29] X. Wang and C. Zhai. Learn from web search logs to [30] J.-R. Wen, J.-Y. Nie, and H. Zhang. Query clustering [31] J. Xu and W. B. Croft. Query expansion using local [32] H. Yang, I. King, and M. R. Lyu. DiffusionRank: a [33] D.Zhou,S.Zhu,K.Yu,X.Song,B.L.Tseng,H.Zha, [34] S. Zhu, K. Yu, Y. Chi, and Y. Gong. Combining
