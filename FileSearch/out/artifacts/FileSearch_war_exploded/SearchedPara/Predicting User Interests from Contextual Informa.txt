 Search and recommendation systems must include cont extual information to effectively model users X  interests. In this paper, we present a systematic study of the effectiveness of five variant sources of contextual information for user interest modeling. Post-query navigation and general browsing behaviors far outweigh direct search engine interaction as an information-gathering activity. Therefore we conducted this study with a focus on Website recommendations rather than search results. The five contextual information sources used are: social, hi storic, task, collection, and user interaction. We evaluate the u tility of these sources, and overlaps between them, based on how ef fectively they predict users X  future interests. Our findings demonstrate that the sources perform differently depending on the du ration of the time window used for future prediction, and that co ntext overlap outperforms any isolated source. Designers of Websi te suggestion systems can use our findings to provide improved su pport for post-query navigation and general browsing behavior s. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process, information filtering. Algorithms, Experimentation, Human Factors. Context, user interest modeling, Website recommenda tion. Modeling user interests to meet individual user nee ds is an important challenge for personalization and informa tion filtering applications, such as recommender systems [2]. Info rmation behavior is embedded within an external context that motivates the problem situation and influences interaction be havior [12]. Meeting user requirements involves a thorough under standing of their interests expressed explicitly through search engine queries or implicitly through browsing behavior and search context. The information retrieval (IR) community has theori zed about context [12], developed models for context-sensitiv e search ( , [27,30]), and performed user studies investigating the role of context in the information-seeking process ( , [16]). Large-scale IR systems such as Web search engines assume queries are context-independent. This abstraction is necessary given the scale constraints under which these systems operate. User modeling systems have fewer constraints and typically proces s past user consumption data, search-related interactions, or e xplicit ratings to obtain a representation of user interests stored in a model ( , [10,37]). Such models are suitable for predicting future behavior, augmenting search engine queries, or suggesting relevant items during post-query navigation or gene ral browsing. The historical information employed in user interes t modeling is one source of contextual evidence about the current session. Others include time of day, user gender, age, ethni city, locality, etc. The polyrepresentation principle [11] suggests that the overlap between numerous contexts associated with t he current session can be used to locate pertinent items. The querying and result examination behavior of search system users supports the development of rudimentary user interest models tha t are based solely on the interaction context ( , [36]). These interest models can be effective for identifying aspects of user information needs; however, users spend more time engaged in po st-query navigation and general browsing than using search e ngines [34]. Although context information has been used to suppo rt post-query navigation and general browsing ( , attentive systems can offer Website suggestions [4,21]), little is known about the value of different contextual sources for this purpose. In this paper we describe a systematic, log-based s tudy of numerous contextual sources for modeling user inter ests during Web interaction. The core task for any user modelin g system is predicting future behavior, and we evaluate the inf ormativeness of different sources of contextual evidence based on t heir informativeness for predicting users X  future intere sts at different temporal durations. We assume that the user has bro wsed to a Web page and the task is to leverage context to pre dict their future interests. The use of the current page and five dis tinct sources of context are evaluated: (i) interaction : recent interaction behavior preceding the current page; (ii) collection : pages with hyperlinks to the current page; (iii) task : pages related to the current page by sharing the same search engine queries; (iv) historic term interests for the current user, and; (v) social interests of other users that also visit the curren t page. This is the first study to systematically assess contextual var iants for user interest modeling. We also study the use of overlap between sources as a stronger source of contextual signal. As we will show, the performance of contextual variants depend s on the time duration used to represent future interests, and ov erlap between contexts yields more effective interest models than any model itself. Understanding which sources and source comb inations best predict future user interests is critical for the d evelopment of effective Website recommendation systems. The remainder of this paper is structured as follow s. Section 2 presents related work on at least contextual IR, us er modeling, and recommendation systems. Section 3 describes the log data used to perform our study. The user interest models develop ed based on each contextual source are described in Section 4. We describe their evaluation in Section 5, and present the find ings in Section 6. We discuss our findings in Section 7, and conclude in Section 8. This work explores issues at the intersection of co ntextual IR, user studies based on Web browser or search engine inter action logs, data mining, implicit feedback, user modeling, coll aborative filtering, and personalization. Each area has its o wn wealth of published work; this review focuses on relevant asp ects. Traditional IR models regard the retrieval problem as matching a query with a set of documents [28], and are inadequ ate for modeling personalized and contextual search. Previo us work [27, 30] has used statistical modeling for context-sensi tive search, but rely on a single source of contextual evidence. The polyrepresentation [11,12] is based on a cognitive approach to IR and signifies that overlaps between a variety of associated with the interactive IR process can be e xploited to reduce the uncertainty and thereby improve IR perfo rmance. The small number of polyrepresentation studies to date have focused on improving retrieval within small, well-defined t est collections by eliciting multiple information need representati ons from users [16] or mining inter-document references and intra-document structure [19,29]. In contrast, we apply polyrepres entation to tackle the challenge of user interest modeling duri ng Web interaction. Although our study is aimed at providi ng better Web page recommendations for users engaged in browsing activity, the findings could also potentially improve the design of context-sensitive search applications. Supporting information-gathering behavior beyond se arch engine interaction has been actively studied. Recommender systems such as 
Letizia [21] and Watson [4] suggest items to users based on inferences made about user interests gleaned from t heir task environment ( , recently-viewed Web pages or the contents of active desktop applications). StumbleUpon (stumbleupon.com) is a recommender system that uses collaborative filter ing (CF) (an automated process combining human opinions with mac hine learning of personal preference) to create virtual communities of like-minded Web surfers. Rating Web sites updates a personal profile (a blog-style record of rated sites) and ge nerates peer networks of Web surfers linked by common interest. These social networks coordinate the distribution of Web content , so that users  X  X tumble upon X  pages explicitly recommended by frie nds and peers. However, recommendations from CF systems typ ically require explicit action from a large community of u sers [9]. Interaction log analysis has provided researchers w ith insight into user behavior. One element of context that influenc es user behavior is the type of the information-seeking tas k. Various taxonomies of these types have been suggested (for both task nature and task complexity), including [3,5,15]. Th e nature of the information seeking task can lead to differences in user behavior. Kellar and colleagues X  study [15] also examined the differences in dwell time for different tasks. Terai and colleague s investigated these differences in a user study exploring informa tional and transactional tasks on the Web [32]. They found sig nificant differences both in the number of individual pages read and the time taken in reading them between these two task t ypes. Kim and Allen studied both task differences and users X  cogn itive differences [18], Thatcher explored relationships b etween different tasks and the search strategies employed by people of differing degrees of Web experience [33], and White and colleagues [35] studied differences in the search b ehaviors of domain experts and non-experts. These investigation s typically involved examining user behavior through query log analysis and user studies. Without explicit user relevance judgments, user pre ference can only be inferred from their activities ( , clicking on a hyperlink, viewing/saving/bookmarking a page). A ra nge of applications for this concept have been explored, f alling under the category of implicit feedback. Recent studies inclu de those reported in [1,14,27] and have shown to effectively improve retrieval performance across a range of scenarios, especially Web search. Examining the applicability of implicit fee dback for recommender systems has also been studied [7,22]. A pplications of implicit feedback to Web page recommender system s are also available [10,17]. These systems typically establis h historical click trails of a user or a community of users, and assess the accuracy of statistical machine learning models whi ch predict future page visits. A natural application of implicit feedback is in pe rsonalized search engines, which incorporate an individual X  X  h istorical activities as part of a ranking system. There are m any challenges with such personalization. For example, when exploi ting short-term search history one must detect session boundar ies first, so that only those searches with the same information need are used. Unfortunately, most existing studies on long-term s earch context fail to address this problem, although they still g et positive results; studies often use all available context as a whole (or divide it into chunks by time), without distinguishing between rel evant and irrelevant parts. Such work includes [23], which in terpolates the current query with different chunks (time periods) of history (browsed Web pages) for personalized search, and [2 5,31], which construct user profiles from indexed desktop docume nts for search result re-ranking. Modeling user interests is common practice for the construction of recommendation engines at e-commerce sites such as Amazon and Netflix. These can be derived both from explici t actions by users ( , buying a product or requesting a movie) or intera ction log behavior (clicking on certain categories of pro duct or movie). In the Web search arena, user models constructed fr om interaction logs have been used to create automated Web search engine evaluation facilities by Dupret and colleagues [8]. The work most similar to ours is that by Piwowarski and Zaragoza [24] in which they explore three different predictive click model s based on what we term historical and social context, but in a Web search setting trying to predict relationships between queries and clicked documents. In that work, they built a probabilistic user-centric model, a group model, and a global model, and a mod el that combined all three. The best of their models was ab le to achieve either accurate prediction (50% of the clicks) with high recall (75% of the time), or low recall (5% of the time) b ut very high accuracy of 98% prediction correctness. We now describe the primary data source for our log -based study. The primary source of data for this study was the a nonymized logs of URLs visited by users who opted in to provi de data through a widely-distributed browser toolbar. These log entries include a unique identifier for the user, a timesta mp for each page view, a unique browser window identifier (to resolv e ambiguities in determining which browser a page was viewed), an d the URL of the Web page visited. Intranet and secure (https ) URL visits were excluded at the source. In order to remove var iability caused by geographic and linguistic variation in search be havior, we only include entries generated in the English speaking U nited States locale. The results described in this paper are bas ed on a sample of URL visits during a four-month period from Augus t 2008 through November 2008, representing billions of URL visits from 250,000 unique users. The user sample was selected at random from a larger set of five million users after we ha d pre-filtered the data to remove extremely-active outlier users (top 1%), all of whom viewed many thousands of pages per day and wer e likely automated traffic. For each user we required an ade quate number of Web page visits to create their historic context ( , a model of long-term interests). Therefore, in addition to rem oving outliers, we also only chose users who visited at least 100 W eb pages in the time period from August 2008 through September 2008. From these logs we extracted hundreds of millions o f trails , as defined by [34]. Browse trails consist of a te mporally-ordered sequence of URLs comprising all pages visit ed by a user per Web browser instance or browser tab. Trails ter minate with either: (i) a period of user inactivity of 30 or mo re minutes, or (ii) the termination of the browser instance or tab. The 30-minute threshold has already been used to demarcate sessio ns in other Web log analyses ( , [34]). Access to browse trails let us study users X  post-query navigation and general browsing b ehaviors. We extracted millions of context trails from the set of browse trails that allowed us to study real-user interests . Context trails exist within browse trails and comprise a terminal URL, , and the list of five Web pages preceding in the browse trail, session-based interaction context introduced in Section 1. Five pages gave us sufficient information about user int erests for the perceived situation prior to and a low likelihood of being affected by significant shifts in those interests. Around five million terminal URLs were obtained by randomly sam pling by frequency the URLs across the historic browse trail s in August and September 2008 (referred to hereafter as ) ( , each URL had a chance of being selected proportional to its frequency). The set of all terminal URLs, , are the starting points from which we derive contextual information for from the five contextual sources we study.
 In the next section we describe the user interest m odels created based on the context trails and their surrounding c ontexts. We developed user interest models based on and the five sources of contextual information used in our study . The sources were chosen based on elements of a nested model of context stratification proposed by Ingwersen and J X rvelin [ 12]. The dimensions of that model represent the main context ual influences affecting users engaged in information behavior: (i ) structures ::signs ( , discrete units of meaning), page features structures : between-object relations such as hyperlinks or citations; (iii) interaction context : evidence of interaction behavior during the search session; (iv) social, systemic, domain-work task context : peer group ( social context ), retrieval system (systemic), real work or daily-life tasks ( task context ); (v) economic techno-, physical-, and societal context : prevailing infrastructures that influence all elements in the nested model of conte xt, and; (vi) historic context : the experiences of the cognitive actor (user) tha t affect how they perceive and interpret situations. The context stratification is illustrated in Figure 1, with the user at a given Web page, , at the core of the model, and with the dimensions used in our study underlined and shown in boldface. The dimensions not chosen ( , intra-object structures, signs, and emotions) could not accurately be modeled in a log-based study since we lacked access to Web page content (only th eir URLs), the user X  X  cognitive and affective state at session time, or infra-structure details. For each context trail extracted from the logs, we created a user interest model for , the interaction context , and the other contextual variants (collection, historic , task, and social). To define user interests in a manageable way for al l models, we classified the Web pages sourced from each context into the topical hierarchy from a popular Web directory, the Open Directory Project (ODP) (dmoz.org). Given the large number of pages involved, we used automatic classification. O ur classifier assigned labels to pages based on the ODP in a simi lar way to Shen and colleagues [26], by starting with URLs pre sent in the ODP and incrementally pruning non-present URLs unti l a match was found or miss declared. In a similar way to [26 ], we excluded Web pages labeled with the  X   X  and  X   X  top-level ODP categories, since these categories are location -based and are typically uninformative for constructing models of user interests. User interests were represented as a list of ODP ca tegory labels assigned to URLs from each source. The ODP labels in the list were ranked in descending order based on each label  X  X  frequency in the context. For example, the top portion of a u ser interest model for a British golf enthusiast might resemble: ODP Category Labels Freq. The following interest models are created for each contextual variant using this approach: No context ( only): One ODP label is assigned to the terminal URL based on the output of the ODP classifier. This label serves as the interest model for the terminal page in the context trail. Interaction context ( ) : One ODP label is assigned to each of the five pages immediately preceding in the context trail. The labels are aggregated and label frequenc ies (based on the number of pages in the interaction context with each label) are used to create a ranked list of labels. The ranked list is the interest model for the interaction context of . Task context: The interest model for the task context using ODP labels assigned to Web pages visited by o ther users attempting the same or similar tasks. To realize th is goal we used the query and search result page click-through logs from a large commercial Web search engine. One month of logs fro m October 2008 was used to create a graph from each to each query, , with a result-page click on . For each , we traversed the graph to set of related URLs, , via the set of queries, , that led to a click on both and . Figure 2 illustrates this process. Figure 2. Creating task context using queries and result clicks. An ODP label is assigned to each of the related URL s discovered by traversing this graph. The assigned labels are a ggregated and their frequencies used to create a ranked list of l abels. The ranked list represents the interest model for the task context of . Collection context: The interest model for the collection context was created using Web pages containing hyperlinks t hat refer to . We obtained the set of in-links for each from the index of a large commercial Web search engine. An ODP label wa s assigned to each in-link, and in a similar way to other cont exts, we created a ranked list of the labels based on their frequenc y. This list formed the interest model for the collection context of . Historic context: The interest model for the historic context created for each user based on their long-term inte raction history. To create each user X  X  historic context , we classified all Web pages they visited in , and created a ranked list of ODP labels based on label frequency. This list represents the intere st model for the historic context for all visited by that user. Social context: The interest model for social context was created by combining the historic contexts of users that also visit . Note that this differs from the task context in that we focus on other users X  long-term interests rather than only leverag ing common querying behavior to find related URLs. From the br owse trails in we found users who have also visited , and combined their interest models ( historic contexts ) to create a ranked list of ODP labels based on label frequency. This list formed t he interest model for the social context of . Implementing these context variants allowed us to s ystematically evaluate the effectiveness of different sources of context for user interest modeling. We evaluated each source and com binations of sources based on their predictive value. In this section we describe the evaluation of our i nterest models. We describe the preparation of the data for our stu dy, the study methodology, and the measures used to compare the m odels. We divided the set of browse trails described in Se ction 3 into two subsets: historic ( ) and current ( ). was defined earlier as the source of the historic context for each user. From the October 2008 browse trails, , a set of  X  X nseen X  context trails, , was extracted. For each context trail, we constructed i nterest models for and obtained ground truth data about future user i nterests. We used browse trails for the current user taken fr om October 2008 and, if needed, November 2008, that began after the visit to as a source of future user behavior. ODP labels we re assigned to pages in the future, aggregated by label, and a ranked list of ODP labels was created based on label frequency in the same way as with the interest models described in Section 4. The futures were specific to each user and each , and were used to gauge the predictive value of each of contextual source for t he context trail. Interest model effectiveness may vary depending on temporal distance from to some future time point. We made predictions using three temporal durations: (i) short : within one hour of ; (ii) medium : within one day of , or; (iii) long : within one week of . The futures are overlapping: medium contains long contains both short and medium . We could have extended future beyond one week, but felt it would be unreas onable to expect a model to accurately predict longer-term fu ture interests based on a single .
 To help ensure experimental integrity, we did not u se all context trails; we filtered the trails based on the followi ng criteria:  X  The coverage of our ODP classifier with URL back-of f was  X  The ODP category label for search engines, portals, or social  X  Since the ground truth is based on interaction beha vior and  X  Since highly-active users may bias our sample, we s elected at Although the size of dropped to around 15 of the original, filtering the set of all context trails based on th ese criteria was necessary to create a high-quality data set for our study. As stated previously, the evaluation task was to pr edict future user interests following a visit to based solely on or on the available contextual information. We divided into ten equally-sized sets (and discarded the small remainder) to f acilitate more reliable statistical testing. Context trails were r andomly assigned with the constraint that each set contained only on e trail per user. Each set contained 20,550 context trails. The experimental procedure involved performing the following on the 20,550 context trails in each of the 10 experim ental sets: 1. Find the short-, medium-, and long-term futures and build 2. Build user interest models for different context so urces, and; 3. Determine the accuracy of the context-based models in In the next section we describe the measures used t o evaluate the predictive performance of our interest models. The practical use of successful contextual modeling would most likely be in providing a surrogate for user interes ts and in the selection of sites to recommend to users as they br owse the Web. The ODP labels in the six models ( plus five context variants) were stored as ranked lists in descending order of estimated informativeness. The ground truth labels were store d similarly. Therefore, we used standard IR measures to evaluate the predictive accuracy of the context-based models. We gave higher scores to the models for placing actual future inte rests high in the predicted list. For this reason, we focused on meas ures that scored the interest models well for achieving high early p recision. Our evaluation used precision, mean reciprocal rank , normalized cumulative discounted gain, and . We computed these measures separately for short-, medium-, and long-t erm futures. We now describe how we interpreted them for our stu dy. specified future duration. If so, the user interest model would be given a score 1, and 0 otherwise. The scores over a ll context trails were then averaged to provide a final score for each set. a context trail with any of its top 3 actual labels , , in the specified future duration. If there was a match, th e user interest model would be given a score 1, and 0 otherwise. Sc ores were averaged to compute final scores as before. assumes that at most one label prediction would be used in a real system, but correctly predicting any of three dominant inte rest is useful. Mean reciprocal rank: A standard alternative measure used often in Web search evaluation tasks is mean recipr ocal rank ( ); , Chowdhury and Soboroff X  X  investigation reported its use in [6]. To compute this measure the top act ual category label from a context trail was compared progressively dow n the ordered list of predicted category label prediction s for the specified future duration. If matched , the score assigned was the reciprocal of the prediction rank position, , and 0 otherwise. The scores over all context trails were then averaged to compute a final for each set. Normalized discounted cumulative gain: Another measure used was a variant of normalized discounted cumulative g ain ( ) [13]. biases towards the early retrieval of highly-relev ant documents, although it also includes a recall compo nent to the calculation. In our case the documents are ODP labe ls, such that the list of actual labels for a context trail is ge nerated based on the specified future duration and is considered an idea l vector, with each actual label given a relevance score of 1. (An alternative approach would be to assign the label its correspon ding frequency count as its relevance score.) The list of predicte d labels compared to the ideal vector, and a discounted cumu lative gain score is computed using a standard discount factor. Our modification of the standard computation of was to restrict the depth of the comparisons between the two label vectors to the minimum length of the two. The score was then norma lized by dividing it by the maximum possible value that coul d be obtained to this depth. The scores over all context trails w ere averaged to provide a final score for each set. : Evaluation measures in similar settings such as th e KDD Cup 2005 [20] often use the measure (also known as test accuracy) which computes the harmonic mean of precision and r ecall. We include the score to allow comparability to past work. For any context trail, the recall depth is computed based o n the number of predicted labels for that trail. The scores over al l trails were averaged to get the final score for each set. We performed a comparison of the predictive accurac y of user interest models generated based on only and the five sources of contextual evidence. Table 1 shows the results of t his comparison for each of the interest models, at each future tim e duration ( , short, medium, long). Evaluation measures were comp uted over each experimental set and the results averaged. The maximum of the standard errors between the means is also repor ted . The results show that the interaction context predicts user interests most accurately in the time immediately f ollowing the visit to . This is likely because does not represent the beginning or the end of the current task, and the i nteraction that occurs before and after is task-related. The findings show that the interests of the user within one day of are most accurately predicted by the task context , suggesting that the active work task may be lengthy. The findings also show that the lon g-term interests of the user ( , those within one week of ) are most accurately predicted by the historic context of the user, but also the social context comprising the interests of other users who also visit . These other users may share interests with the cu rrent user, making their long-term interests similar (and hence similarly predictive). Given the large sample sizes, the obse rved differences between the models for each measure are statistical ly significant using paired -tests (all 20549 1.96, all .05). The observed variation in model performance for eac h of the three time durations suggests that different sources of c ontextual information may be suited for different tasks. For example, if a Website recommendation system must predict user int erests immediately ( , to recommend Websites that support task completion) it should leverage , interaction context context . However, if the system needs to predict longer te rm interests ( , to recommend Websites of general interest) historic context and social context should be used. The context performed particularly poorly across all time dura tions, perhaps because it was related to rather than the user, their task, or their observed interaction behavior. Since correlated strongly with the other measures we use d it for the additional analysis in the remainder of thi s section. 
Task 0.58 0.60 0.60 0.62 0.61 0.39 0.41 0.42 0.45 0.44 
Historic 0.16 0.24 0.21 0.16 0.18 0.20 0.33 0.29 0. 25 0.31 None 0.71 0.51 0.42 0.64 0.48 0.35 0.54 0.35 0.26 0 .52 0.35 0.21 
Interaction 0.75 0.51 0.43 0.70 0.48 0.31 0.66 0.42 0.28 
Task 0.73 0.55 0.41 0.68 0.50 0.39 0.63 0.46 0.33 0.61 0.44 0.30 Social 0.21 0.26 0.42 0.18 0.23 0.37 0.17 0.20 0.35 0.13 0.19 0.31 
Historic 0.23 0.37 0.47 0.19 0.34 0.44 0.19 0.32 0.43 0.18 0.31 0.40 None n/a n/a n/a 0.58 0.38 0.24 n/a n/a n/a 0.52 0. 35 0.21 
Interaction 0.65 0.44 0.31 0.64 0.42 0.28 0.68 0.43 0.32 
Task 0.63 0.46 0.33 0.64 0.47 0.33 0.64 0.45 0.36 0.61 0.44 0.30 Social 0.16 0.21 0.31 0.14 0.22 0.33 0.18 0.24 0.35 0.13 0.19 0.31 
Historic 0.17 0.32 0.42 0.19 0.34 0.43 0.20 0.33 0.45 0.18 0.31 0.40 0.53 ** 0.45 * * 0.52 ** 0.43 * * 0.49 ** 0.43 * 0.48 * 0.43 * 0.48 * 0.42 * 0.46 * 0.42 0.45 0.42 0.45 0.41 0.44 0.41 0.44 0.40 The findings presented in Table 1 were derived base d on matching the full ODP labels in the interest models with the full label in the ground truth. In that analysis we penalize the inte rest models for any mismatch between the predicted and actual label. H owever, small differences in estimates of user interests ma y be unimportant to a recommendation system. For example , interests represented by the ODP label  X  performed in Section 6.1 this would be regarded as a total miss, whereas it is actually a near miss. We investigate the effect of using label back-off involving the aggregation of O DP category labels under a parent node to mitigate the effect o f near misses. We performed the experiment described in Section 6. 1 an additional time by backing-off on all labels in the ground truth and in the predictions to a specified level. One-le vel back-off means convert all ODP to their top level ( ,  X   X ). Two-and three-level back-off means convert all labels t o their top two and three levels respectively ( ,  X   X  and  X  for the additional analysis performed with back-off to different levels in the ODP hierarchy. As expected, the findi ngs show an increase in the predictive accuracy of all models a nd for all time durations. The trends in the relative ordering of t he interest models observed in Section 6.1 remain unchanged for label back-off (as does the statistical significance of the ob served differences). The relative ordering of the interest models is insensitive to the granularity of the interest repr esentation; any difference in model performance is not due to near misses. The ODP labels used to represent user interests wer e assigned automatically based on page visit information extra cted from our log data. Upon examining the predictions, we observed that du e to constituted our ground truth, the labels periodical ly were of poor quality. Manual inspection of the context trails an d the predicted labels implied the predictions were reasonable. We hypothesized that because a label assigned to the ground truth m ay represent only one visit to a Web page, and have a single use r and one or two clicks, these sparse page visits may be distort ing the evaluation measures. To investigate this, we perfor med the experiment of Section 6.1 an additional time, holdi ng out labels assigned from the ground truth sets based on less t han five visits. We repeated this process by holding out low-frequen cy labels from the prediction, and from the prediction and gr ound truth. In Table 3 we present the findings of this addition al analysis averaged across all experimental sets, for filterin g the predictions, the ground truths, and both. Although the relative ordering of the models remains unchanged (and differences between t hem are still statistically significant), the scores increase and the standard errors drop, giving us more confidence regarding co nclusions drawn about the relative ordering of the context so urces. A key aspect of the principle of polyrepresentation is the use of cognitive overlap between multiple contextual elements to strengthen the relevance signal of certain items [1 1]. We applied this principle directly in our study and in additio n to considering contextual sources independently, we also considere d source combinations. We performed the experiment of Sectio n 6.1 an additional time, but systematically varied the comb inations of contexts used. In total, 57 context combinations w ere tested. For each combination, we obtained the specified ext ernal sources plus if required. We selected the ODP category labels a nd their respective frequencies for labels that appeared in all relevant interest models ; giving us the overlap between context sources. Some sources were more voluminous and may have high er frequency counts even though they had the same labe l ranking. Combining the frequency counts of all used sources would have biased the ranking. To rank items in the overlap, w e adopted a simple strategy using the average rank position of each label across all used contexts, and the sorting based on that average. In Table 4 we present the average scores obtained for the top-10 best-performing combined models. To preserve spa ce, the first letter of each source is used to denote its use in the model ( , =none ( , only), =interaction, etc.). The findings show that using a combination of sources leads to more accura te future predictions in the short-, medium-, and long-term. Those combinations with an score that is significantly different from the best performing model in Table 1 (using a paire d -test) are marked. For each time duration, there exists at lea st one context combination that significantly outperforms all cont exts in isolation; this supports the principle of polyrepre sentation. Data in Table 4 demonstrates that certain contexts are requ ired to obtain high prediction accuracy ( , and interaction context in short-term predictions, task context in medium-term predictions, and social context and historic context in long-term predictions). We studied the effectiveness of different sources o f contextual evidence, and their overlap, for user interest mode ling. The findings of our study suggest that the best-perform ing contextual sources are dependent on the duration between and the end of the prediction window. This has implications for th e systems that use contextual information to support post-query na vigation and general browsing behaviors. For example, these syst ems must not treat all context sources equally. Weights should b e assigned to each source depending on whether the system is reco mmending Web pages that are relevant to the immediate situation, the current work task, or the user X  X  general interests. The con texts as defined could be implemented using server-side lookups ( task , collection and social ) or client-side code ( interaction and historic Our finding that interests within an hour of could be predicted by local context information such as itself and suggests that topical interests, as represented by ODP category labels, are not highly changeable within a short pe riod of time. Search queries and information needs may evolve dur ing this time, but topical interest may be less dynamic. The high effectiveness of task context in predicting activities within one day of may be due to its consideration of the current sit uation as well as similar situations encountered by other users. Since by definition task context is broader than interaction context more likely able to include task variants that cou ld appear within the next full day. The effectiveness of the historic context social context in predicting longer-term user interests is likely related to their ability to predict the general int erests of each user. They are effective at doing so since they have acce ss to large amounts of long-term information for a user and sim ilar users. We demonstrated that polyrepresentation is viable f or user interest modeling. As shown in Table 4, models based on over lap between sources (especially between all sources) performed better than any individual source. More work is necessary to determ ine how best to combine sources beyond linear averaging, includi ng using machine learning to automatically determine source weights. The observed differences in this study may be relat ed to the nature of the sources that were selected. For example, it may have been better to use anchor text rather than in-links as t he context . However, given that this study was log-based, and that we had to transform all contexts to URLs for ODP la beling, the definitions of context we adopted seem reasonable. User studies conducted in tandem with human labeling of user int erests are important next steps to validate our claims. In this paper we have presented a systematic, log-b ased study of the effectiveness of five variant sources of contex tual information for user interest modeling. Given the prevalence of post-query navigation and general browsing, we conducted this study within a framework of Website recommendations rather than search results. We extracted browsing contexts from toolba r logs and built a variety of user interest models based on th e current page, contextual variants, and overlaps between contexts. The interest models were required to predict short-, medium-, an d long-term user interests. Our findings show that the predict ive value of each contextual sources varies according to the time dur ation of the prediction. We showed that the relative ordering of the contexts for each time duration was unaffected by coarser re presentations of user interests and higher-quality predictions or ground truths, and that context overlap was more effective than an y individual context. Website recommendation systems should use context, because doing so outperforms not using it. However, the systems may need to vary the source depending on the modeli ng task. Our findings should enhance Website recommendation syst ems and facilitate improved information-gathering support f or their users. [1] Agichtein, E., Brill, E. &amp; Dumais, S.T. (2006). Improving [2] Bilenko, M. et al. (2008). Talking the talk vs. walking the [3] Broder, A. (2002). A taxonomy of Web search. ACM SIGIR [4] Budzik, J. &amp; Hammond, K. (1999). Watson: antici pating and [5] Bystr X m, K. &amp; J X rvelin, K. (1995). Task complex ity affects [6] Chowdhury, A. &amp; Soboroff, I. (2002). Automatic evaluation [7] Claypool, M. et al. (2001). Inferring user interest. [8] Dupret, G., Murdock, V. &amp; Piwowarski, B. (2007) . Web [9] Goldberg, D. et al . (1992). Using collaborative filtering to [10] Gunduz, S.U. &amp;  X zsu, M.T., (2003). Recommendat ion [11] Ingwersen, P. (1994). Polyrepresentation of in formation [12] Ingwersen, P. &amp; J X rvelin, K. (2005). The Turn: Integration of [13] J X rvelin, K. &amp; Kek X l X inen, J. (2000). IR evalu ation methods [14] Joachims, T. &amp; Radlinski, F. (2007). Search en gines that [15] Kellar, M., Watters, C. &amp; Shepherd, M. (2007). A field study [16] Kelly, D., Dollu, V.D. &amp; Fu, X. (2005). The lo quacious user: [17] Khalil, F., Li, J. &amp; Wang, H. (2008). Integrat ing [18] Kim, K. &amp; Allen, B. (2002). Cognitive and task influences [19] Larsen, B. &amp; Ingwersen, P. (2002). The boomerang [20] Li, Y., Zheng, Z., &amp; Dai, H.K. (2005). KDD CUP -2005 [21] Lieberman, H. (1995). Letizia: an agent that a ssists web [22] Oard, D. &amp; Kim, J. (1998). Implicit feedback f or [23] Pitkow, J. et al. (2002). Personalized search. CACM [24] Piwowarski, B. &amp; Zaragoza, H. (2007). Predicti ve user click [25] Qiu, F. &amp; Cho, J. (2006). Automatic identifica tion of user [26] Shen, X., Dumais, S. &amp; Horvitz, E. (2005). Ana lysis of topic [27] Shen, X., Tan, B. &amp; Zhai, C. (2005). Context-s ensitive [28] Singhal, A. (2001). Modern information retriev al: A brief [29] Skov, M., Larsen, B. &amp; Ingwersen, P. (2006). I nter and intra-[30] Tan, B., Shen, X. &amp; Zhai, C. (2006). Mining lo ng-term [31] Teevan, J., Dumais, S.T. &amp; Horvitz, E. (2005). Personalizing [32] Terai, H. et al. (2008). Differences between informational [33] Thatcher, A. (2008). The influence of web expe rience and [34] White, R.W. &amp; Drucker, S.M. (2007). Investigat ing [35] White, R.W. et al . (2009). Characterizing the influence of [36] White, R.W. et al . (2005). A study of factors affecting the [37] Zhang, Y. &amp; Koren, J. (2007). Efficient bayesi an hierarchical 
