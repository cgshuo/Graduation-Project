 We present an algorithm for mining tree-shaped patterns in a large graph. Novel about our class of patterns is that they can contain constants, and can contain existential nodes which are not counted when determining the number of oc-currences of the pattern in the graph. Our algorithm has a number of provable optimality properties, which are based on the theory of conjunctive database queries. We propose a database-oriented implementation in SQL, and report upon some initial experimental results obtained with our imple-mentation on graph data about food webs, about protein interactions, and about citation analysis.
 H.2.8 [ Database Management ]: Database Applications X  data mining Algorithms, Performance, Experimentation Canonical form, conjunctive query, equivalence checking, graph, levelwise, redundancy checking, SQL, tree query
The problem of mining patterns in graph-structured data has received considerable attention in recent years, as it has many interesting applications in such diverse areas as biol-ogy, the life sciences, the World Wide Web, or social sci-ences. Past work in this area falls in two major categories, not to be confused: 1. In the  X  X ransactional X  category, e.g., [1, 2, 3, 4, 5, 2. In the  X  X ingle graph X  category, e.g., [7, 8, 9, 10, 11],
The present work falls in the single-graph category. Past work in this category has mainly focused on patterns in the form of subgraphs that occur in sufficiently many edge-disjoint isomorphic copies in the graph that is being mined. We propose a rather different notion of pattern, which is still a graph, but with the following features: A simple example of a pattern is shown in Figure 1; when applied to a food web ( X  X ho eats who X ), it describes all organisms x that compete with organism #8 for some or-ganism as food, that itself feeds on organism #0. This pat-tern has one existential node, two selected nodes, and one distinguished node x .

Effectively, what we want to mine are what is known in database research as conjunctive queries [12, 13]; these are the queries we could pose to the graph (stored as a two-column table) in the core fragment of SQL where we do not use aggregates or subqueries, and use only conjunctions of Figure 1: Simple example of a pattern with two se-lected nodes, one existential node, and one distin-guished node x . equality comparisons as where-conditions. For example, the pattern of Figure 1 amounts to the following SQL query on atable G(from,to) : select distinct G3.to as x from G G1, G G2, G G3 where G1.from=0 and G1.to=G2.from and G2.to=8 and G3.from=G2.from
We will present an algorithm for miningconjunctive-query patterns that return sufficiently many answers on a given graph. Our algorithm has the following properties: 1. We restrict to patterns that are trees, such as the ex-2. The algorithm is incremental in the number of nodes 3. For each tree, all conjunctive queries based on that tree 4. A query based on some tree may be equivalent to a 5. Last but not least, our algorithm naturally suggests a
The primary purpose of this paper is to present our al-gorithm; concrete applications to discover new knowledge about real-life scientific datasets is a topic of planned fu-ture work. Yet, using a prototype implementation, we will already demonstrate here that our approach is feasible, by showing some concrete results mined from a food web, a protein interactions graph, and a citation graph. We also give performance figures on random graphs.
In this section, we define the problem formally, and de-scribe our overall approach.
 nodes ; nodes can be any data objects such as numbers or strings. For our purposes, we define a (directed) graph on N as a subset of N 2 , i.e., as a finite set of ordered pairs of nodes. These pairs are called edges . We assume familiarity with the notion of a tree as a special kind of graph, and with standard graph-theoretic concepts such as root of a tree; children , descendants , parent ,and ancestors of a node; and path in a graph. Any good algorithms textbook will supply the necessary background.
 Tree queries. A tree query is a tree Q whose nodes are called variables , where additionally: 1. Some variables may be marked as being existential ; 2. Some other variables may be labeled with a data con-The nodes of Q that are neither existential nor selected are called the distinguished variables of Q .

When we draw a tree query, as in Figure 1, we write each distinguished variable down as x , with different subscripts when there are multiple such variables; we depict existential nodes by the symbol  X  ; and we depict selected nodes by writing down their label.
 Matchings. Recall that a homomorphism from a graph G 1 toagraph G 2 is a mapping h from the nodes of G 1 to the nodes of G 2 that preserves edges, i.e., if ( i,j )  X  G 1 ( h ( i ) ,h ( j ))  X  G 2 . Figure 2: In this example graph, the pattern of Fig-ure 1 has frequency three, as the distinguished node x can be mapped to the three different nodes 4, 5, and 8.

We now define a matching of a query Q in a graph G simply as a homomorphism h from the underlying tree of Q to
G , with the constraint that for any selected node z ,if z is labeled a ,then h ( z )= a .

Furthermore, we define the frequency of Q in G as the number of matchings of Q in G , with the important provi-sion that we identify any two matchings that agree on the distinguished variables . Indeed, two matchings that differ only on the existential nodes need not be distinguished, as this is precisely the intended semantics of existential nodes. Note that we do not need to worry about selected nodes, as all matchings will agree on those by definition. Example. Take again the query Q showninFigure1.Let us name the existential node by y ; let us name the selected node labeled 0 by z 1 ; and the selected node labeled 8 by The distinguished node already has the name x .Nowlet us apply Q to the simple example graph shown in Figure 2. The following table lists all matchings of Q in G : As required by the definition, all matchings match z 1 to 0 and z 2 to 8. Although there are five matchings, we only look at their value on x to distinguish them, as y is existential. So, h 1 and h 3 are identified, as are h 2 and h 4 . In conclusion, the frequency of Q in G is three, as x can be matched to the three different nodes 4, 5, and 8.
 Mining tree queries. We are now in a position to define the mining task: given a graph G and a threshold k , find all tree queries that have frequency at least k in G ; these queries are called frequent .

In theory, however, there are infinitely many frequent queries, and even if we set an upper bound on the size of the queries, there may be exponentially many. As an ex-treme example, if G is the complete graph on the set of nodes { 1 ,...,n } ,and k  X  n ,then any query with constants in { 1 ,...,n } , and at least one distinguished variable, is fre-quent.

Hence, in practice, we want an algorithm that runs incre-mentally, and that can be stopped any time it has run long enough or has produced enough results. Figure 3: Two orderings of the same tree. The left one is canonical. An overall outline of our algorithm is the following: Outer loop: Generate, incrementally, all possible trees of Inner loop: Foreachnewgeneratedtree, generate allqueries The inner loop is organized in a levelwise manner [17], and will be described in the next Section. Different queries can be equivalent, however, and we must take precautions to avoid generating and testing queries that are equivalent to an earlier seen query. This will be discussed in Section 5.
As for the outer loop, it is already well known how to efficiently generate all trees uniquely up to isomorphism, in increasing number of nodes [15, 16, 4, 14]. These procedures typically generate trees that are canonically ordered in the following sense. Given a tree T , we can order the children of every node in some way, and call this an ordering of T For each such possible ordering of T ,wecanwritedownthe level sequence of the resulting tree: if the tree has n nodes then this is a sequence of n numbers, where the i th number is the depth of the i th node in preorder. Here, the depth of the root is 0, the depth of its children is 1, and so on. The canonical ordering of T is then the one that yields the lexicographically maximal level sequence among all possible orderings of T .

For example, Figure 3 shows two orderings of the same tree; the left one is the canonical one.
Let G be the graph being mined, and let U be its set of nodes. In this section, we fix a tree T , and we want to find all queries based on T whose frequency in G is at least k
This tasks lends itself naturally to a levelwise approach [17]. A natural choice for the specialization relation is sug-gested by an alternative notation for the queries under con-sideration. Concretely, since the underlying tree is fixed, any query Q is characterized by three parameters: 1. The set  X  Q of existential nodes; 2. The set  X  Q of selected nodes; 3. The labeling  X  Q : X  Q  X  U of the selected nodes by We now say that Q 1 =( X  1 ,  X  1 , X  1 ) specializes Q 2 =( X  if  X  1  X   X  2 ; X  1  X   X  2 ;and  X  1 agrees with  X  2 on  X  2 .Wealso say that Q 2 generalizes Q 1 .
Clearly, if Q 1 specializes Q 2 , then the frequency of Q at most that of Q 2 , so we can use this relation to guide a levelwise search for the frequent queries. Starting with the most general query T =(  X  ,  X  ,  X  ), we progressively consider more specific queries. The search has the typical property that, in each new iteration, new candidate queries are gener-ated: queries whose frequency has not yet been determined, but all whose generalizations are already known to be fre-quent. Then the frequency of all newly discovered candidate queries is determined, and the process repeats.

There are a great many queries to handle, and in particu-lar, there will be many queries that differ only in  X  .Hence, to generate candidate queries in an efficient manner, we pro-pose the use of candidacy tables and frequency tables .Let X  and  X  be disjoint sets of nodes, as above. Then we define: In practice, the frequency table would also have an addi-tional column to hold the actual frequencies, but for sim-plicity of presentation we will ignore that column.
Note that when  X  =  X  these tables are zero-column ta-bles, which formally still make sense and can be interpreted as boolean values; for example, if FreqTab  X  ,  X  contains the empty tuple, then the query ( X  ,  X  ,  X  ) is frequent; if the table is empty, the query is not frequent.

To populate the tables efficiently, we use the notion of a parent . We say that ( X  ,  X  )isaparentof( X  ,  X ) if either (i)  X  =  X  and  X  has precisely one node more than  X  ;or (ii)  X  =  X  and  X  has precisely one node more than  X  .We then have: Join Lemma. Alabeling  X  is in CanTab  X  ,  X  if and only if the following conditions are satisfied for every parent ( X  of ( X  ,  X ) : (i) If  X = X  ,then  X  |  X   X  FreqTab  X  ,  X  ; (ii) If  X = X  ,then  X   X  FreqTab  X  ,  X  .

The Join Lemma has its name because, viewing the tables as relational database tables, it can be phrased as follows:
The only exception is when  X  =  X  and  X  = { z } is a singleton; this is the initial iteration of the search process, when there are no constants in the parent tables to start from. In that case, we define CanTab  X  , { z } as the table with a single column z , holding all nodes of the graph G being mined.
The search process starts by determining the frequency of the underlying tree T =(  X  ,  X  ,  X  ); indeed, formally this amounts to computing FreqTab  X  ,  X  . Similarly, for each query Q =( X  ,  X  ,  X  )with X  =  X  , all we can do is determine its frequency, except that here, we do this only on condition that its parent queries are frequent.

Wehaveseen abovethat, ifthefrequencytablesare viewed as relational database tables, we can compute each can-didacy table by a single database query, using the Join Lemma. Now suppose the graph G that is being mined is stored in the relational database system as well, in the form of a table G(from,to) .Thenalsoeachfrequencytable can be computed by a single SQL query.

Indeed, in the cases where  X  =  X  this simply amounts to formulating the query in SQL, and determining its count (eliminating duplicates). But also when  X  =  X  ,wecan compute FreqTab  X  ,  X  by a single SQL query. Note that we thus compute the frequency of a large number of patterns in parallel! We proceed as follows. First, we formulate the query ( X  ,  X  ,  X  ) in SQL; call the resulting expression E then take the natural join of E and CanTab  X  ,  X  ,groupby  X , and count each group. The join with the candidacy table ensures that only candidate queries are counted.
It goes without saying that, whenever the frequency ta-ble of a query is found to be empty, the search for more specialized queries is pruned at that point.
 Example. Take again the example pattern (query) of Fig-ure 1. This query is based on the following tree T : Comparing Figure 1, we see that  X  = { x 2 } , X = { x 1 ,x 3 and  X  =( x 1 :0 ,x 3 : 8). The join expression that computes the candidacy table is: The SQL expression E for ( { x 2 } ,  X  ,  X  )is: select distinct G1.from as x1, G2.to as x3, from G G1, G G2, G G3 where G1.to=G2.from and G3.from=G2.from The SQL expression that computes the frequency table then is: select E.x1, E.x3, count(E.x4) where E.x1=CT.x1 and E.x3=CT.x3 group by E.x1, E.x3 having count(E.x4) &gt;= k
Putting everything together so far, the algorithm is given in Figure 4. In outline it is a double Apriori algorithm [21], where the sets  X  form one dimension of itemsets, and the sets  X  another.
In this section, we make a number of modifications to the algorithm described so far, so as to avoid duplicate work on equivalent queries.

Specifically, suppose we are given two queries with the same number of distinguished variables. There is indeed a natural and purely semantical notion of equivalence for such queries, which we define next: }  X  ,  X  | ( X  ,  X  )parentof( X  ,  X ) } s +1 and each s -subset of  X  is in S s }
For example, the two queries shown in Figure 5 are equiv-alent, as are the three queries shown in Figure 6.
Of course, we want to avoid that our algorithm considers some query Q 2 if it is equivalent to an earlier considered query Q 1 . Since our algorithm generates trees in increasing sizes, there are two cases to consider: Case A: Q 1 has fewer nodes than Q 2 .
 Case B: Q 1 and Q 2 have the same number of nodes.
We can analyze the situation using a well-known result from the theory of conjunctive queries [12, 13]. In order to state that result, we need the notion of containment map-ping . A containment mapping from Q 1 to Q 2 is a homomor-phism from Q 1 to Q 2 that maps the distinguished variables of
Q 1 one-to-one to the distinguished variables of Q 2 ,and that maps selected nodes of Q 1 to selected nodes of Q 2 , preserving labels. From the theory of conjunctive database queries [12, 13] we recall the following: Equivalence Theorem. Two queries are equivalent if and only if there are containment mappings between them in both directions.

Armed with this theorem, we now analyze the above two cases.
Using the equivalence theorem, it can be seen that this case can only happenif Q 2 contains redundant subtrees : sub-trees such that removing them yields an equivalent query. (For example, the first two queries in Figure 6 indeed con-tain a redundancy.) In other words, if we can avoid queries with redundancies, then case A will not occur.

The following lemma provides us with an efficient check for redundancies. The proof is given in the Appendix. Redundancy Lemma. Let Q be a tree query without se-lected nodes. Then Q has a redundancy if and only if con-tains a subtree C in the form of a linear chain of existential nodes (possibly just a single node), such that the parent of C has another subtree that is at least as deep as C . This lemma ignores selected nodes, but this is justified. Indeed, from the equivalence theorem and the redundancy lemma it follows that, if all selected nodes in a query Q labeled with distinct constants, then Q has a redundancy if and only if Q has a redundancy, where Q is obtained from Q by turning all selected nodes back into distinguished variables. Since, as explained in Section 4.1, we handle all queries that differ only in the labeling of selected nodes to-gether in asingle table, it is indeedharmless totreat selected nodes as distinguished variables.
As we have seen in Section 4, our algorithm introduces existential nodes levelwise, one by one. This makes the re-dundancy test provided by the redundancy lemma particu-larly easy to perform. Indeed, if Q is a query of which we already know it has no redundancies, and we make one ad-ditional node i existential, then it suffices to test whether i thus becomes part of a subtree C as in the Redundancy Lemma. If so, we will prune the entire search at  X  Q  X  X  i }
We may now assume that Q 1 and Q 2 do not contain re-dundancies, for if they would, they would have been dis-missed already. Again using the isomorphism theorem, it can then be seen that case B can only happen if Q 1 and Q are actually isomorphic , i.e., there is a containment map-ping from Q 1 to Q 2 that is one-to-one, and whose inverse is a containment mapping from Q 2 to Q 1 .(Forexample, the two queries in Figure 5 are indeed isomorphic.) In par-ticular, Q 1 and Q 2 have the same underlying tree. So, in our algorithm, we need an efficient way to avoid isomorphic queries based on the same tree T .

Fortunately, thereis a standard way to dothis, byworking with canonical forms of queries. Consider a pair ( X  ,  X ) over T , as in Section 4. We can view this pair as a labeling of all nodes in  X  get the same generic label  X   X   X ; all nodes in  X  get  X  c  X ; and all remaining nodes get  X  x  X . Wethen say thattwo pairs ( X  1 ,  X  1 )and( X  2 ,  X  2 )are isomorphic if there is a tree isomorphism between the corresponding labeled versions of T that respects the labels.

It is sufficient to work on the level of pairs ( X  ,  X ) to capture all isomorphic queries. Indeed, if ( X  1 ,  X  1 , X  1 ( X  2 ,  X  2 , X  2 ) are isomorphic queries, then certainly the pairs ( X  1 ,  X  1 )and( X  2 ,  X  2 )are equivalentas well. Andconversely, if ( X  1 ,  X  1 )and( X  2 ,  X  2 ) are equivalent, then for each query ( X  1 ,  X  1 , X  1 ) there is an isomorphic query ( X  2 ,  X  2 , X 
In order to represent each pair ( X  ,  X ) uniquely up to iso-morphism, we can rather straightforwardly refine the canon-ical ordering of the underlying unlabeled tree, which we al-ready have (Section 3), to take into account the node labels. Furthermore, the classical linear-time algorithm to canonize a tree [22] generalizes straightforwardly to labeled trees. A nice review of these generalizations has been given by Chi, Yang and Muntz [14].

We will omit the details of the canonical form; in fact, there are several ways to realize it. All that is important is that we can check in linear time whether a pair is canonical; that a pair can be canonized in linear time; and that two pairs are isomorphic if and only if their canonical forms are identical.

Armed by the canonical form, we are now in a position to describe how the algorithm of Section 4 must be modified to avoid equivalent queries. First of all, we only work with pairs ( X  ,  X ) in canonical form; the others are dismissed. The problem then arises, however, that a parent pair ( X  ,  X  ), where we omit a variable from either  X  or  X  as described above, might be non-canonical. In that case the frequency table for ( X  ,  X  ) will not exist. We can solve this by can-onizing ( X  ,  X  ) to its canonical version ( X  ,  X  ), and re-membering the renaming of variables this entails. The table FreqTab  X  ,  X  canthenserveinplaceof FreqTab  X  ,  X  ,after we have applied the inverse renaming to its column head-ings.
When our algorithm is terminated, its final output con-sists of a set of frequency tables for each tree T that was investigated. These tables together form a database that provides an ideal data platform for browsing the mining re-sults. We envisage a browsing tool in which the user draws a tree shape, marks some nodes as existential, and marks some others as selected, annotating some of these by con-stants, but possibly also leaving some of the selected nodes open for instantiation. By consulting the appropriate fre-quency table in our results database, we can immediately report to the user those annotations of the selected nodes that make the pattern frequent.

Our platform also supports a simple form of association rules . While a thorough treatment of association rules over tree queries is beyond the scope of the present paper, we can easily support a simple but useful kind of such rules. Let be a frequent tree query, and let Q 2 be another frequent tree query obtained from Q 1 by making some additional nodes selected. Clearly, the frequency f 2 of Q 2 will be at most the frequency f 1 of Q 1 , and we can define the confidence of the rule Q 1  X  Q 2 as the fraction f 2 /f 1 . With all the frequency tables in place, it is a simple matter to compute confidences. Thus, given a Q 1 and a threshold c ,anApriori-like algorithm can be used to compute all rules Q 1  X  Q 2 the above kind with confidence at least c .The X  X temsets X  are here, of course, the possible sets of extra selected nodes in Q 2 as compared to Q 1 .

We will give a real-life example of an association rule in the next Section.
In this section, we report on some preliminary experi-ments performed using our prototype implementation ap-plied to both real-life and synthetic datasets. The results show that our approach is indeed workable. In the near fu-ture we plan to pay more attention to performance tuning, and to work with domain experts to see if new scientific facts can be discovered.

Theexperimentswere performed onaPentiumIV(2.8GHz) architecture with 1GB of internal memory, running under Linux 2.6. The program was written in C++ with embed-ded SQL, with DB2 UDB v8.2 as the relational database system.
We have worked with a food web, a protein interactions graph, and a citation graph. For each dataset, the table below lists the numberof nodes, number of edges, frequency threshold k , and maximum size of trees considered in the run. As we set rather generous limits on the maximum size of trees, or on the minimum frequency threshold, each run took several hours.
The food web [23] comprises 154 species that are all directly or indirectly dependent on the Scotch Broom (a kind of shrub). One of the patterns that was mined with frequency 176 is the following: This is really a rather arbitrary example, just to give an idea of the kind of complex patterns that can be mined. Note also that, thanks to the constant 20 appearing twice, this is really a non-tree shaped pattern: we could equally well draw both arrows to a single node labeled 20.

Whilewewerethusbrowsingthroughtheresults, wequickly noticed that the constant 20 actually occurs quite predom-inantly, in many different frequent patterns. This constant denotes the species Orthotylus adenocarpi , an omnivorous plant bug. To confirm our hypothesis that this species plays a central role in the food web, we asked for all association rules with the following left-hand side: Indeed, the rule shown above turned up with 89% confi-dence! For 89% of all pairs of species that are linked by a path of length four, Orthotylus adenocarpi is involved in between.

The protein interaction graph [24] comprises molec-ular interactions (symmetric) among 1870 proteins occur-ring in the yeast Saccharomyces cerevisiae .Insuchinterac-tion networks, typically a small number of highly connected nodes occur. Indeed, we discovered the following associa-tion rule with 10% confidence, indicating that protein #224 is highly connected:
The citation graph comes from the KDD cup 2003, and contains around 2500 papers about high-energy physics taken from arXiv.org, with around 350000 cross-references. One of the discovered patterns is the following, with fre-quency 1655, showing two papers that are frequently cited together (by 6% of all papers).
While our current prototype implementation has not yet been tuned for performance, we still conducted some prelim-inary performance measurements, with encouraging results. We have used two types of synthetic datasets.
 Random Web graphs. Naturally occurringgraphs(asfound in biology, sociology, or the WWW) have a number of typ-ical characteristics, such as sparseness and a skewed degree distribution [25]. Various random graph models have been proposed in this respect, of which we have used the  X  X opy model X  for Web graphs [26, 27]. We use degree 5 and prob-ability  X  = 10% to link to a random node (thus 90% to copy a link).

On these graphs, we have measured thetotal runningtime as a function of the size (number of edges) of the graph, where we mine up to tree size 5, with varying minimum frequency thresholds of 4, 10, and 25. The results, depicted in Figure 7, show that the performance of these runs is quite adequate.
 Uniform random graphs. Wehavealso experimentedwith thewell-knownErd  X  os X  X   X  enyirandomgraphs, whereonespec-ifies a number n of nodes and gives each of the possible n 2 edges a uniform probability (we used 10%) of actually be-longing to the graph. In contrast to random Web graphs, these graphs are quite dense and uniform, and they serve well as a worst-case scenario to measure the performance as a function of the number of discovered patterns, which will be huge.

We have run on graphs with 47, 264, and 997 edges, with minimum frequency thresholds of 10 and 25. The results, depicted in Figure 8, show, first, that huge numbers of pat-terns are mined within a reasonable time, and second, that the overhead per discovered pattern is constant (all six lines have the same slope). [1] L. Dehaspe and H. Toivonen. Discovery of frequent [2] A. Inokuchi, T. Washio, and H. Motoda. An [3] M. Kuramochi and G. Karypis. Frequent subgraph [4] M.J. Zaki. Efficiently mining frequent trees in a forest. [5] X. Yan and J. Han. gSpan: Graph-based substructure [6] J. Huan, W. Wang, and J. Prins. Efficient mining of [7] D.J. Cook and L.B. Holder. Substructure discovery [8] N. Vanetik, E. Gudes, and S.E. Shimony. Computing [9] S. Ghazizadeh and S. Chawathe. SEuS: Structure [10] M. Kuramochi and G. Karypis. Finding frequent [11] G. Jeh and J. Widom. Mining the space of graph [12] A. Chandra and P. Merlin. Optimal implementation of [13] S. Abiteboul, R. Hull, and V. Vianu. Foundations of [14] Y. Chi, Y. Yang, and R.R. Muntz. Canonical forms [15] H.I. Scions. Placing trees in lexicographic order. In [16] G. Li and F. Ruskey. The advantages of forward [17] H. Mannila and H. Toivonen. Levelwise search and [18] S. Tsur, J.D. Ullman, et al. Query flocks: A [19] S. Sarawagi, S. Thomas, and R. Agrawal. Integrating [20] S. Chakravarthy, R. Beera, and R. Balachandran. [21] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and [22] A.V. Aho, J.E. Hopcroft, and J.D. Ullman. The [23] J. Memmott, N.D. Martinez, and J.E. Cohen.
 [24] H. Jeong, S.P. Mason, et al. Lethality and centrality [25] M. Newman. The structure and function of complex [26] R. Kumar, P. Raghavan, S. Rajagopalan, [27] K. Bharat, B.-W. Chang, M. Henzinger, and M. Ruhl. [28] Proceedings of the 2002 IEEE International [29] N. Cercone, T.Y. Lin, and X. Wu, editors. Proceedings Proof of the Redundancy Lemma. Let us refer to a subtree C as described in the lemma as an  X  X liminable path X . An elim-inable path is clearly redundant, so we only need to prove the  X  X nly-if X  direction. Let T be a redundant subtree of Q that is maximal, in the sense that it is not the subtree of an-other redundantsubtree. Then there must be a containment mapping h of Q to Q  X  T . All distinguished variables of Q must already be in Q  X  T , since containment mappings are one-to-one on the distinguished variables. Hence, T consists entirely of existential nodes. Also, note that h must fix the root of Q ,sincetheheightof Q is at least that of Q  X  T . Any iteration h n of h is a containment mapping of Q to Q  X  T as well. Moreover, each h n induces a permutation on the set V of distinguished variables. Since V is finite, there are only a finite number of possible permutations of V .A standard argument then shows that there is an iteration h = h m that is the identity on V .
 There are now two possible cases.

First, T itself may be a linear chain. Then the parent p of
T must either be distinguished, or must have at least two children. Indeed, if p would be existential with T as only subtree, then the subtree T rooted at p would be redundant as well, contradicting the maximality of T .If h ( p )= p then T is mapped by h to another subtree of p ;since h is a homomorphism, that subtree must be at least as deep as
T .Hence, T is an eliminable path and we are done. If h ( p ) = p , then the subtree rooted at p consists entirely of existential nodes, since h is the identity on distinguished nodes. This brings us in the second case.

Second, T is not a linear chain. An easy induction on the height shows that any non-linear tree consisting entirely of existential nodes must contain an eliminable path. Hence, T , and thus also Q , contains an eliminable path as desired.
