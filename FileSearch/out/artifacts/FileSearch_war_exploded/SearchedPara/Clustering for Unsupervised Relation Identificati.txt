 Unsupervised Relation Identificati on is the task of automatically discovering interesting relations between entities in a large text corpora. Relations are identified by clustering the frequently co-occurring pairs of entities in such a way that pairs occurring in similar contexts end up belonging to the same clusters. In this paper we compare several cluste ring setups, some of them novel and others already tried. The setups include feature extraction and selection methods and clustering algorithms. In order to do the comparison, we develop a clustering evaluation metric, experiments demonstrate signifi cant superiority of the single-linkage hierarchical clustering w ith the novel threshold selection technique over the other tested clustering algorithms. Also, the experiments indicate that for succe ssful relation identification it is important to use rich complex feat ures of two kinds: features that that test only one slot each ( X  X ntity features X ). We have found that using both kinds of features with the best of the algorithms produces very high-precision results, significantly improving over the previous work. I.2.7 [ Artificial Intelligence ]: Natural Language Processing; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Measurement, Perfo rmance, Experimentation. Unsupervised Relation Identifi cation, Clustering, Relation Learning, Information Extraction. assertions from text. Most IE systems rely on knowledge engineering or on machine learning to generate the  X  X ask model X , which is subsequently used for extracting instances of entities and relations from new text. In the knowledge engineering approach the model (usually in the form of extraction rules) is created manually, and in the machine l earning approach the model is learned automatically from a manually labeled training text. Both approaches require substantial hum an effort, particularly when applied to the broad range of documents, entities, and relations existing in the Web. In order to minimize the manual effort necessary to build IE systems, semi-supervised systems were developed, able to learn the task model using only a large unlabeled corpus and a small set of seeds  X  known true instances of the target entity or relation. Even semi-supervision can be costly for relation extraction at Web scale, because of a large number of different domains and possible relation types. Prevemptive Information Extraction approach was introduced in [10] as a remedy to this problem. Under this approach, there is a preparation stage, during which the IE system automatically discovers all relations, extracts their instances, and puts them into tables, which can be mined later, in response to the user queri es or for other purposes. This preemptive IE approach relies on Unsupervised Relation Identification (URI)  X  an automatic discovery of all interesting relations in a large body of text. Any relation can be identified by a representative subset of its instan ces. Thus, the task of URI is to provide such representative set of instances for each of the relations it discovers. URI systems usually work in the following way: First, the set of candidate relationships is generate d. It may simply consist of all pairs of entities that frequently co-occur in same sentences. Then, the system analyzes the sentences in which the candidates occur, and produces a measure of simila rity between the candidates, based on similarity of the contexts in which they appear. Then, the candidates are clustered using some general-purpose clustering algorithm. Finally, the clusters are pruned, and poor clusters are discarded. In [8] we had shown that the cl usters discovered by URI can be successfully used for seeding a semi-supervised relation extraction system, producing performance comparable to the performance of human-selected seeds. Thus, it makes sense to separate the tasks of relation identification and actual relation extraction. The relation identification stage should find frequent high-precision seeds for the relations, while the extraction stage should extract many more relation instances, gaining recall and balancing it against required precision. In this paper we focus on the URI task. We compare several clustering algorithms, and several feature extraction and selection methods, evaluating them using a novel evaluation metric, which is adapted for evaluating precision-oriented URI clustering results. Our findings demonstrate: In our experiments we consisten tly avoid using supervised named entity recognition (NER) systems. Good NER components only exist for common and very general entity types, such as Person , Organization , and Location . For some relations, the types of attributes are less common, and no ready NER components (or labeled training sets) are availa ble. Also, some Web relation extraction systems (e.g., KnowItA ll [3]) do not use supervised NER components even for known entity types, because such components are usually domain-sp ecific and may perform poorly on cross-domain text collections extracted from the Web. Consequently, the entities in our candidate pairs are simply proper noun phrase heads, extracted by a general-purpose noun phrase chunker (trained on a dataset from the CoNLL-2000 shared task [11]), with the entity boundaries fixed by corpus statistics-based methods ([9]). Nevertheless, we show that the clusterings produced by the best of the strategies approach perfect precision, sufficient for seeding the semi-supervised relation extraction systems. we describe the related work. Then we present the details of the architecture of our URI system, a nd its various components. Then we describe our experiments, di scuss their results, and conclude. The field of URI is very recent, and there is only a small number of works available. Discovering relations by cluste ring pairs of co-occuring entities represented as vectors of context features was introduced by Hasegawa, Sekine et al. [6]. They used a complete-linkage representation of contexts  X  the features were the words that appear in sentences between the entities of the candidate pairs. Consequently, their results had a relatively low precision and were unsuitable for bootstrapping, which usually amplifies any noise in the set of seeds. Chen, Ji et al. [1] used the same context representation, but added an entropy-based feature ranking and selection step. They also used the K -Means algorithm instead of HAC, introducing a stability-based criterion for estim ating the number of clusters. Shinyama and Sekine [10] used simple predicate-argument patterns around the entities of candida te pairs. Their system works on news articles, and improves its accuracy by looking at multiple news sources describing the same event. The authors in [8] first attempted to use the results of URI for seeding a semi-supervised relati on extraction system. Using rich surface patterns for representing the context features we achieved a limited success in discovering and subsequently extracting a small number of relations in the financial news domain. In this paper we build upon our previous work, experimenting with different clustering al gorithms and representations, comparing them to each other using a novel evaluation metric, and producing an URI system that substantially outperforms all of the mentioned systems. In this work we are primarily concerned with the part of a URI system that does clustering, and we do not deal with candidate selection, nor with complex post-processing such as generation of names for the discovered relations. Thus, we can assume that the input to the system is a set of entities E and a set of relation candidates (pairs of entities) C  X  E  X  E . Also, there is a set of contexts S e for each entity e  X  E . Each context of an entity is a sentence in which the entity appears at least once. The set of contexts S c of a candidate c = ( e , e' )  X  C consists of sentences in which both entities of the candidate appear: S c = S e  X  S e' . The output of the system is a partitioning of the candidates into disjoint clusters C = C 1  X  C 2 ...  X  C n  X  G , where the clusters C identify the discovered relations, and the special cluster G (for  X  X arbage X ) gathers all unclassified candidates. The garbage cluster is an essential element of the scheme, since usually many of the candidate pairs do not be long to any well-defined general relation. extraction  X  representing the candidates as vectors in some feature space, (2) clustering of vectors, and (3) pruning of the resulting clusters. These stages and th e various components performing them are described below. the clustering algorithms: a repres entation of the candidates as vectors in some feature space, with a suitable measure of distance between vectors. The representation and the distance (or similarity measure) must be chosen in such a way that under this measure the candidates that often appear in similar contexts would be close to each other, contexts would be far apart. Consequently, we base the representation directly on featur es of the contexts, which can abstractly be defined as follows: mark the candidate pair c = ( e , e' ) inside its context s  X  S substituting the token  X &lt;1&gt; X  for one of the instances of e and the m ) denote the set of all m -slot-marked contexts of the entity e , and MS ( c ) the set of all slot-marked contexts of the candidate c . Finally, for c = ( e , e' ) we let denote the set of all slot-marked contexts related to c , and the set of all slot-marked contexts of all candidates. A context feature is a function f : M  X  {0, 1}. Each such function can be thought of as checking for presence or absence of some feature in the contexts of en tities and pairs. A family of such functions defines some measure of similarity between contexts  X  two contexts are more similar when the values of more functions coincide on them. We extend this similarity to similarity between candidates by defining their representation as follows: Let F be a set of context features. Then, the candidate c is v ( c ) with components so the value of the f -th component of the representation of c equals to the number of times the context feature f appears among the contexts of c . For similarity between two vectors in the feature space we use the common cosine measure which ignores the relative lengths of vectors. Naturally, the utility of such representation depends on the quality similar to the ones we used in [8]. Each such pattern is a sequence of tokens (including the speci al slot-mark tokens), and skips , the context feature f p corresponding to the pattern by A pattern p matches the context s iff all of the tokens of p appear in s in the correct order. The tokens of p must also be adjacent to (by skips in p ), and where arbitrary sequences of tokens may appear between the tokens of p . As an example to the concepts defined above, consider the sentence This sentence would bel ong to the context sets S e =  X  X BM X  ,  X  X rmonk X  ,  X  X ew York X  , and  X  X otus X  , and to the 1-slot-mark the entity  X  X BM X  inside the sentence, we get which would belong to the set MS (  X  X BM X  , 1) and to the sets M ( c ) The context would be matched by the pattern and would not be matched by the pattern If we further 2-slot-mark the entity  X  X ew York X  , we get a slot-marked context pair (  X  X BM X  ,  X  X ew York X  ). Then, the pattern would not match this slot-marked context, whereas the pattern where the asterisk denotes a skip, would. We generate the set of surface patterns by a suitable modification of the Apriori association mining algorithm. First we extract all sequences of tokens (without gaps) that appear in the set M of all contexts with frequency greater than a given minimal support value. Then we mine the contexts (as ordered sets of such sequences) for frequent itemsets. The result is the set of all surface patterns sufficiently supported by the set of contexts. Despite their simplicity, the surface patterns are sufficiently general to capture many recurring properties of contexts, and are sufficient to produce good-quality clusterings, as our experiments demonstrate. They are also more general than all the context features used in the works menti oned in the Related Work section, and this allows us to simulate their performance by suitably bag-of-words feature space of [6] and [1] can be simulated using patterns of the form while the predicate argument patterns of [10] can be simulated by the surface patterns of the form In [8], we used surface patterns of unrestricted form. However, we used a different method of pattern extraction  X  pairwise context generalization. The main dr awback of that method is its computational complexity. Also, we did not use the contexts of individual entities. Thus, the feature space of [8] can be simulated in the current system by using the patterns of the form The number of surface patterns generated at the feature extraction step can be very large. In order to reduce the computation costs of the clustering stage, it is beneficial to remove the useless features. We cannot use the common classification feature ranking since these measures rely on knowledge of the classification of the training set. However, following [1], we can use a feature ranking based on the observation of [2] that good clustering features should improve the separability of the dataset  X  make from each other still farther apart. Using this intuition, we define the score of a feature f by where and where S ij is the similarity between c i and c j and c j after removing the feature f , also normalized to [0..1]. Given a ranking of features, we can select N top-scoring ones and remove the rest. In the experimental section we demonstrate that it is sometimes possible to reduce the number of features by a factor of 100 without losing the quality of clustering. As defined, the merit of the feature selection scheme is questionable, since its computational complexity can be greater than the complexity of actual clustering. However, Dash and Liu argue in [2] that separability-based scores of features can be approximated well by calculating them over small samples of the whole dataset. We do not test this hypothesis in this work, leaving it for further research. We test and compare two common general-purpose clustering algorithms in our experiments: the hierarchical agglomerative clustering (HAC) algorithm, and the partitioning K -Means algorithm. The HAC algorithm starts with all datapoints in separate clusters, and proceeds to iteratively merge the most similar clusters, until all pairwise di stances between the clusters become greater than a prespecified threshold. There are three common ways of calculating the distance (or similarity) between clusters in terms of p airwise distances between their datapoints: single linkage , average linkage and complete linkage . Using these three linkages, the similarity between two clusters is, respectively, the maximum , the average , and the minimum of the similarities between their datapoints. The K -Means algorithm starts with a set of k seed datapoints that define the initial clusters. At each iteration until convergence, the algorithm calculates the centroid of each one of the k clusters, and reassigns every datapoint to the cluster that has the closest centroid. Both the HAC and the K -Means algorithms have parameters that significantly affect the quality of clustering. HAC has the linkage type parameter and the similarity threshold parameter, which specifies when to stop merging the clusters. In all previous works, the HAC was always used with a complete linkage, and with a small fixed threshold. K -Means, on the other hand, depends on the choice of the seeds and on the number k of clusters, which must be known in advance. Usually, the problem of seeds dependence is solved by running the algorithm several times with different random choice of seeds, and then selecting the best clustering among the results, according to some internal consistency measure. As for estimating the number of clusters, Chen, et al [1] advocate using stability-based criterions. In our experiments we surprisi ngly found that the single linkage HAC not only outperforms both th e HAC with other linkage types and the K -Means, but also has a natural stopping criterion:  X  X top merging the clusters when the average similarity between the datapoints of the clusters being merged becomes smaller than  X  times the maximal similarity between them X , where  X  &lt; 1 is a constant, for which we use 1/2. Although this stopping criterion does not always find the best clustering possible for the single linkage HAC, it usually finds a clustering within a small margin of the best. And in almost all produced by the HAC with other linkage types, or by the K -Means, even with the best choice of their parameters. (See the experimental section for the details). In this paper we are primarily concerned with the clustering task. Thus, we utilize a simple and crude method of pruning: we disband all clusters that contain less than a given number of candidates, 4 in our experiments. The released candidates are put into the garbage cluster. This method of pruning makes sense for the URI task, which after all attempts to discover relatively common and open-ended relations. We performed a set of experiments to compare the feature extraction and selection methods and the clustering algorithms described above. We shall first describe our evaluation criterion, and then proceed to the actual experiments. There are various methods for ev aluating clustering results [5]. For the URI task we have to use an external criterion, since we would like the clusters to agree with human intuition as to what constitutes an interesting relation. Consequently, in order to score a given clustering  X  of a set of candidates, we first manually cluster the candidates into a model clustering  X  X  . Then we calculate the square root of the Jackard coefficient JC (  X  ,  X  X  ) = ( SS / ( SS + SD + DS )) 1/2 , where therefore be used as a score for comparing different clusterings. However, the URI task is different from other clustering tasks, because of the existence of a large number of unclassified datapoints, gathered into a single specially designated garbage cluster. The garbage cluster con tains the entity pairs that do not belong to any recognizable relation, which happens either if the co-occurrence of the entities is accidental, or if the relation between them is too idiosyncratic. Since the URI task places much higher value on precision than on recall, the garbage cluster must be evaluated separately from particular, it should be less costly to put a candidate belonging to a relation into the garbage cluster, than to allow a wrong candidate to get in. Thus, the garbage cluster is treated differently in two ways: first, the definition of  X  X o-occurrence X  does not include the garbage cluster  X  the candidates inside the garbage cluster are considered  X  X ot co-occuring X . A nd second, pairs of candidates that co-occur in  X  X  , but at least one one of which is in the constants  X  . We experimentally found that the precise value of  X  does not matter for qualitative ordering of performance of various clustering setups, as long as the value is noticeably smaller than one. In our experiments we use  X  = 0.3. For the experiments we used three different text corpora. One of them is the corpus that was used for evaluating the semi-supervised SRES [4] and KnowItAll [3] systems. The corpus consists of a concatenation of four separate corpora, for the Acquisition , Merger , Mayor_Of , and CEO_Of relations. Each sentence in the corpus contains at least one keyword related to one of the four relations. Although the four corpora were processed separately by the semi-supervised systems, we combined them together for evaluating URI, in order to see how well the system is able to find the relations and to distinguish between them. This corpus is denoted ACMM. The second corpus is a subset of the RCV1 corpus of Reuters news [7], which included news articles on various economics-related topics. The third corpus is a one year (1995) of The New York Times, which was also used in the original work of Hasegawa, Sekine et al. [6]. The corpora were processed by a general-purpose noun phrase chunker, trained on the labeled data for the CoNLL-2000 shared task [11]. All pairs of proper noun phrases that co-occurred sufficiently frequently (30 times or more) were processed by a corpus statistics-based boundary fi xing component (described in [9]) in order to reduce the noise and the amount of garbage, and process produced several thousands of candidate pairs for each of the corpus, which is currently beyond the computing capabilities of our system, due to space problems appearing because of a huge number of features. Therefore, we randomly selected a thousand experiments were performed. Since it is too costly to manu ally cluster even one thousand candidates, we further randomly selected a subset of 200 candidates from each of the working sets, and manually clustered these subsets. During the experiments, the clustering algorithms were run over the full working sets of candidates, but only the selected 200 candidates were used for scoring the results. In the first series of experiments we compared the performance of various clustering algorithms and various feature sets described we list the number of features the system extracted in each of the setups. The K -Means results are the best scores from a large number of seed was selected randomly, and the subsequent k -1 seeds were selected by maximizing the dis tances between them. (Random selection of all seeds produced worse results). All HAC results, except for the  X  X AC single* X , are the best-parameter. The  X  X AC single* X  denotes the HAC with the single linkage and with the  X  X verage/Max similarity &lt; 1/2" stopping criterion. Several conclusions can be drawn from the results. First, we can important. The bag-of-words re presentation is clearly poor and insufficient. Both  X  X rgument-onl y X  (context features related to (context features related to both entities together, as in [8]) perform reasonably well, but still worse than the full-featured setting. Regarding the algorithms, the HAC with single linkage outperforms both K -Means and the other variants of HAC in almost all cases. Also, we can see that the  X  X verage/Max similarity &lt; 1/2" stopping criterion, which is extremely simple and needs no additional computation, performs surprisingly well, always producing results within a very small margin of the best possible. Combination Only All Features 
Top 5000 In this series of experiments we test the separability-based feature selection scheme. The results are summarized in the Table 3. We show only the results for the HAC with single-linkage and AS/MS stopping criterion, as this is the best-performing complete algorithm: As can be seen, the separability-based feature selection is very effective, reducing the dimensionality of the feature space by a factor of 20 with no deterioration in results, and by a factor of 100 with only a very slight deterioration. In the Table 4 we list cluster-by-cluster the relations identified by the system in the New York Times 1995 corpus, together with their sizes and the number of mistakes. As can be seen, the system is very precise, introducing almost no wrong candidates into the relations . The two mistakes, each by 4 wrong candidates, come from incorrect merging of correct clusters. The system also produced several  X  X losed X  clusters, which list the same pair of candidates in different wordings and/or in a different order. For example, the cluster FinMinistry-Japan contains pairs (  X  X inance Ministry X ,  X  X apan X  ), and (  X  X inistry of Finance X ,  X  X apan X  ). The system of course has no knowledge that the entities  X  X inance Ministry X  and  X  X inistry of Finance X  are actually the same. Finally, there are four  X  X arbage X  clusters of various sizes, which include pairs unrelated to each other and pairs that do not belong to any well-defined relation. However, we believe that the closed clusters and the garbage clusters do not significantly harm the intended use of the system, 2 0 Chase-Chemical 2 0 2 0 garbage 2 which is identification of relations for further extraction by semi-supervised systems. If these clusters are excluded, the precision of the system is nearly perfect. In Table 5 we show further details for several top clusters: we list two candidate pairs (alphabetically fi rst) placed into the cluster, and a single context (chronologically first) extracted for each listed candidate. As can be seen from this table, the generated clusters are semantically reasonable. We have presented the results of several experiments, comparing different clustering algorithms and different feature extraction and selection methods for unsupervised relation identification, using an evaluation metric adapted for the task. The experiments demonstrate superior performance of the single linkage HAC clustering algorithm with the average/maximal similarity stopping criterion. We also demonstrated the importance of using complex features, and relying on features that are based both on individual entities and on combination of entities within pairs. Unlike most of the previous works, our system performs without a separate named-entity recognition component, using only a general-purpose noun phrase chunker. Thus, all of the entities initially belong to the same large set. Nevertheless, there are almost no argument type mistakes in the final clusters. Also, although the general-purpose noun phrase chunker makes many mistakes, candidate pairs containing bad entities end up placed into the garbage cluster. In the future research we plan to test the sample-based feature selection, which if successful would allow us to use much bigger initial sets of features, and thus to work with bigger candidate sets. Currently, very big candidate sets are inaccessible to our system, because the number of f eatures that need to be extracted is too large. We also plan to test our clustering scheme in other unsupervised clustering settings, such as clustering of relations between individual words, for the field of unsupervised language acquisition. Some of the data sets were provided by the KnowItAll project at the University of Washington's Turing Center. We thank Oren Etzioni and Stephen Soderland for helpful discussions. [1] Chen, J., D. Ji, C.L. Tan, and Z. Niu. Unsupervised Feature [2] Dash, M. and H. Liu. Feature Selection for Clustering . in [3] Etzioni, O., M. Cafarella, D. Downey, A. Popescu, T. Shaked, [4] Feldman, R. and B. Rosenfeld. Self-Supervised Relation [5] Halkidi, M., Y. Batistakis, and M. Vazirgiannis, On [6] Hasegawa, T., S. Sekine, and R. Grishman. Discovering [7] Lewis, D.D., Y. Yang, T. Rose, and F. Li, RCV1: A New [8] Rosenfeld, B. and R. Feldman. High-Performance [9] Rosenfeld, B. and R. Feldman. Using Corpus Statistics on [10] Shinyama, Y. and S. Sekine. Preemptive Information [11] Tjong, E.F., K. Sang, and S. Buchholz. Introduction to the 
