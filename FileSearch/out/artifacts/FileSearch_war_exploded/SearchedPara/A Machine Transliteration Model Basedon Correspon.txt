 JONG-HOON OH National Institute of Information and Communications Technology KEY-SUN CHOI
Korea Advanced Institute of Science and Technology and HITOSHI ISAHARA National Institute of Information and Communications Technology 1. INTRODUCTION
Machine transliteration is an automatic method for converting words in one language into phonetically equivalent ones in another language. For example, the English word data is commonly transliterated into Korean as  X  X eiteo X  and
Japanese as  X  X   X  eta. X  1 Transliteration is generally used to phonetically trans-late proper names and technical terms, especially from languages using Ro-man alphabets into languages using nonRoman alphabets, such as from En-glish to Korean, Japanese, or Chinese. There has been growing interest in the use of machine transliteration to assist machine translation (MT) [Al-Onaizan and Knight 2002; Knight and Graehl 1997], monolingual information retrieval (MLIR) [Kang and Choi 2000; Lee and Choi 1998], and cross-lingual informa-tion retrieval (CLIR) [Fujii and Tetsuya 2001; Lin and Chen 2002]. In the areas of MLIR and CLIR, machine transliteration bridges the gap between a translit-erated localized form and its original form by generating transliterated forms from each original form (or by generating original forms from each transliter-ation). For CLIR especially, machine transliteration is useful for query trans-lation where proper names and technical terms frequently appear in source language queries as transliterations. In the area of MT, machine translitera-tion prevents translation failure when translations of proper names and tech-nical terms are not registered in a translation dictionary. The use of a machine transliteration model should, therefore, improve the performance of MT, MLIR, and CLIR systems.

Three types of machine transliteration models have been studied: the grapheme 2 -based transliteration model (  X  G ) [Goto et al. 2003; Kang and Choi 2000; Kang and Kim 2000; Lee and Choi 1998; Lee 1999; Li et al. 2004], the phoneme 3 -based transliteration model (  X  P ) [Knight and Graehl 1997; Lee 1999;
Kang 2001], and the hybrid transliteration model (  X  H ) [Al-Onaizan and Knight 2002; Bilac and Tanaka 2004; Lee 1999]. The first two types are classified in terms of the units to be transliterated:  X  G is referred to as the direct model , because it directly transforms source language graphemes into target language graphemes without any phonetic knowledge of source language words, and is called the pivot model because it uses source phonemes as a pivot during the transliteration process. Therefore,  X  P usually needs two steps: duce source language phonemes from the source language graphemes and (2) produce target language graphemes from the source language phonemes. The last type combines  X  G and  X  P through linear interpolation. Hereafter, we re-fer to a source language grapheme as a source grapheme, a source language phoneme as a source phoneme, and a target language grapheme as a target grapheme.

Although transliteration is a phonetic process (  X  P ) rather than an ortho-graphic one (  X  G ) [Knight and Graehl 1997], we should consider both the source graphemes and phonemes to achieve high performance in machine translit-eration, because standard transliterations are not restricted to phoneme-based transliterations. 5 However, many previous studies used only the source graphemes or source phonemes. While this simplifies the machine transliter-ation problem into either  X  G or  X  P , assuming that either all transliteration behaviors, transliteration is a complex process that does not only rely on the source graphemes or phonemes. For example, the standard Ko-rean transliterations of amylase and data are, respectively, a grapheme-based transliteration ( X  X millaaje X ) and a phoneme-based transliteration ( X  X eiteo X ). A machine transliteration model must, therefore, reflect the dynamic transliter-ation behaviors in order to produce correct transliterations.  X  combines  X  G and  X  P through linear interpolation. It does not consider the cor-respondence between the source graphemes and phonemes, even though this correspondence plays an important role in machine transliteration. For exam-ple, source phoneme /AH/ 6 produces significant ambiguities because it can be mapped to almost every vowel in the source and target languages (the follow-
English;  X  X inem a  X ,  X  X ost e l X ,  X  X oll o koseuteu X  in their Korean counterparts; and the correspondence between the source graphemes and phonemes in their orig-inal context, we can more easily infer the correct transliteration of /AH/ since a target grapheme of /AH/ usually depends on the source grapheme correspond-ing to /AH/. 7 Korean transliterations of source grapheme a vary among  X  X  X ,  X  X i X ,  X  X  X ,  X  X o X , and so on. As shown in Table I, the correspondence makes it possible to reduce transliteration ambiguity. In the table, underlined source grapheme a in the example column is pronounced as the source phoneme in the source phoneme column. The correct Korean transliterations of source grapheme a can be more easily found, as shown in the Korean grapheme column, by means of source phonemes in the source phoneme column.
We propose  X  correspondence-based machine transliteration model  X ( dynamically uses both source graphemes and phonemes.  X  C has two significant strengths compared to  X  G ,  X  P , and  X  H . First, it produces transliterations by utilizing the correspondence between the source graphemes and phonemes. As described above, this correspondence is very useful for reducing transliteration ambiguity. Thus,  X  C is better at reducing ambiguity than
Second, it dynamically handles source graphemes and phonemes based on their contexts. Although  X  H also utilizes the source graphemes and phonemes, it uses only a static weight for interpolating between the two probabilities related to the source graphemes and source phonemes. Because  X  C dynamically handles source graphemes and phonemes based on their contexts, it can produce both grapheme-and phoneme-based transliterations based on the context. It can also produce a transliteration in which one part is grapheme-based and the other part is phoneme-based. For example, in the Korean transliteration of neomycin ,  X  X eomaisin, X   X  X eo X  is a grapheme-based transliteration and  X  X aisin X  is a phoneme-based transliteration.

This paper is organized as follows. Section 2 describes related work. Section 3 describes our proposed correspondence-based machine transliteration model, and Section 4 describes the modeling of the component functions. Section 5 describes the experiments we conducted to evaluate our model X  X  performance and presents some of the results. Section 6 discusses the various types of errors in transliteration based on an analysis of actual transliterations. We conclude in Section 7 with a brief summary and a look at future work. 2. PREVIOUS WORK 2.1 Grapheme-Based Transliteration Models
Grapheme-based transliteration models are classified into those based on sta-channels. In this section, we describe the key points of each type.
Lee [1998, 1999] proposed a grapheme-based English-to-Korean translitera-tion model based on statistical translation. He attempted to generate a translit-erated Korean word K for a given source English word E using Eq. (1). He defined a  X  pronunciation unit  X  (PU) as the graphemes that correspond to the source phoneme. He then segmented English into PUs and attempted to find the most relevant Korean graphemes corresponding to the PUs. For example, the English word  X  board (/B AO R D/) X  was segmented into its pronunciation
English word E i is represented as E i = epu i 1 , ... j th PU of E i . A sequence of Korean PUs, kpu i 1 , kpu i 2 for each E i . Lee [1998] generated all possible English PU sequences for each word and their corresponding Korean PU sequences. For example, board can be divided into PU sequences b:oar:d, b:oa:r:d, b:o:a:r:d , and so on. All possible
Korean PUs are then generated from these sequences ( X  X :o:deu, X   X  X :o:reu:deu, X   X  X :o:a:reu:deu, X  and so on). The best PU is then selected using Eq. (1) and taken as the Korean transliteration.
Kim et al. [1999] expanded on Lee X  X  work by considering more information when estimating P ( E | K ), as shown in Eq. (2). He used additional information (Korean PUs kpu i  X  1 and kpu i + 1 ) to approximate P ( E
There are two drawbacks to this approach. First, errors can occur in the PU seg-mentation, leading to incorrect transliterations. Second, generating all possible
PUs for each word in each language is a time-consuming process: if the total number of English PUs is N and the average number of Korean PUs generated for each English PU is M , the total number of generated Korean PU sequences will be about N  X  M .
 Kang and Choi [2000] 9 and Kang [2001] proposed an English grapheme to Korean grapheme conversion model based on decision trees. Seven contextual used to determine the Korean graphemes corresponding to the target English grapheme. For each English grapheme, a corresponding decision tree is con-structed (26 in all). While this approach considers wider contextual informa-tion, it does not consider the phonetic aspect of the transliteration.
Kang and Kim [2000] 10 proposed an English X  X orean transliteration model based on a transliteration network. All possible grapheme sequences are gener-ated to make a transliteration network, as shown in Figure 1. Each node in the network is composed of more than one English grapheme (including graphemes and chunks of graphemes) and the corresponding Korean graphemes. Each arc represents a possible link between nodes. The strength of a link is represented by the weight calculated using Eq. (3), in which  X  X ontext X  refers to historical information regarding English graphemes and  X  X utput X  is the generated Ko-rean grapheme. The optimal path is the one with the highest total weight, as calculated using a Viterbi algorithm [Forney 1973] and a tree-trellis algorithm [Soong and Huang 1991].
Goto et al. [2003] 11 proposed an English-to-Japanese transliteration model, structed with nodes and arcs. A node represents more than one English grapheme (including graphemes and chunks of graphemes) and its corre-sponding katakana characters. An arc represents a possible link between nodes. Consider Eq. (4), where KU represents a katakana string, E rep-resents an English word, ku represents a katakana unit, and z repre-sents the chunk of English graphemes to be transliterated. For example, the transliterated katakana string for actinium is  X  X kuchiniumu X , KU ku  X  X , X  and ku 6 =  X  X u. X  Equation (4) is composed of a translation model, p ( ku i | ku i  X  1 i  X  c , e i + b i  X  c ), and a chunking model, p ( z of each model are estimated using a maximum entropy model. The most prob-able katakana string that maximizes P ( KU | E ) is calculated using a Viterbi algorithm.

The advantages of the Kang and Kim [2000] and Goto et al. [2003] models are that (1) they consider the phonetic aspect called  X  X hunks of graphemes X  and (2) they perform a one-step procedure using a transliteration network as opposed to the two-step pipelined procedure (grapheme chunking and then transliter-ation) of Lee X  X  model [1999]; Lee and Choi [1998]. However, they consider the phonetic aspect only at the grapheme level, which is inadequate. Further infor-mation, such as the source phonemes corresponding to a source grapheme (or a chunk of source graphemes) is necessary to generate a correct target language transliteration.

The joint source-channel based model [Li et al. 2004] simultaneously models both source language and target language contexts (bigram and trigram) for machine transliteration. Its main advantage is its use of bilingual contexts. 2.2 Phoneme-Based Transliteration Models
Knight and Graehl [1997] proposed a Japanese-to-English transliteration ation one in Knight and Graehl X  X  [1997] definition. They modeled Japanese-to-
English transliteration with weighted finite-state transducers (WFSTs). Five parameters are considered: p ( w ), p ( e | w ), p ( j | e ), p ( k sent, respectively, the probabilities for word sequence, word to English sound,
English sound to Japanese sound, Japanese sound to katakana , and katakana to OCR. Given the katakana string o observed by OCR, their model finds the
English word sequence w that maximizes the sum, over e , j , and k ,ofthe five parameters. The main contribution of this work is that it offers a basic framework for  X  P (source language word  X  pronunciation  X  word).

Lee [1999] proposed a phoneme-based English-to-Korean transliteration model that generates Korean transliterations through a two-step procedure.
First, it converts English PUs into English phonemes using the statistical trans-lation model described in Section 2.1. The phonemes are then transformed into Korean PUs using the  X  X nglish-to-Korean Standard Conversion Rules X  (EKSCR S ), which describe the conversion of English phonemes into Korean graphemes using the phonemes as conditions for outputting Korean translit-erations [Korea Ministry of Culture and Tourism 1995]. This approach suffers from two problems: error propagation and limitations in EKSCR
PU-to-English phoneme conversion procedure usually produces errors, which propagate to the next step. The propagated errors make it difficult to gener-ate correct transliterations. The other problem is that EKSCR tain enough rules to generate correct Korean transliterations for all the corre-sponding English words since its main focus is on mapping from one English phoneme to one Korean grapheme without considering the context of the En-glish graphemes and phonemes. For example, the English word board and its pronunciation /B AO R D/ are incorrectly transliterated into  X  X oreudeu X  by
EKSCR S . If the contexts are considered, they are correctly transliterated into  X  X odeu. X  Because of these limitations, Lee X  X  phoneme-based model performs worse than his grapheme-based one (described in Section 2.1).

Kang [2001] 12 proposed a phoneme-based English-to-Korean transliteration model based on decision trees. First, the model produces pronunciation based on a pronunciation dictionary. Then, decision trees for transforming source phonemes into target graphemes are applied. The model used for the decision trees is similar to his grapheme-based transliteration model [Kang and Choi 2000; Kang 2001] described in Section 2.1. Context information for constructing decision trees is seven English phonemes (the left three, the right three, and the target one). However, this model depends on a pronunciation dictionary, making it difficult to produce transliterations when a given English word is not registered in the pronunciation dictionary. 2.3 Hybrid Transliteration Models
Several attempts have been made to use both source graphemes and phonemes in machine transliteration. Several researchers [Lee 1999; Al-Onaizan and
Knight 2002; Bilac and Tanaka 2004] have proposed hybrid transliteration models in which  X  G and  X  P are modeled with WFSTs [Bilac and Tanaka 2004] or a source-channel model [Lee 1999; Al-Onaizan and Knight 2002]. Then, and  X  P are combined through linear interpolation. In  X  P are considered, such as the source grapheme to source phoneme probability, the source phoneme to target grapheme probability, and the target language word probability. The  X  G mainly considers the source grapheme to target grapheme probability. The main disadvantage of the hybrid models is that they do not consider the dependence between the source graphemes and phonemes in the combining process. 2.4 Summary
Much of the previous work has focused on  X  G , rather than mer offers certain advantages compared to the latter. First, unlike not require any knowledge about pronunciation, meaning that while quires only the source grapheme to target grapheme transformation, source grapheme to source phoneme transformation and source phoneme to tar-get grapheme transformation. Second, error propagation occurs in it is composed of two steps. Errors in the first step usually make it difficult to generate correct transliterations in the second step. This is the main rea-son for the performance of  X  P usually being lower than that of many standard transliterations are phoneme-based transliterations. However,  X 
G has limitations. Although it is a relatively simple and effective model, it does not consider phonetic features such as source phonemes. This causes er-rors when a source phoneme rather than a source grapheme provides important clues that can be used to generate the correct transliteration.

Because of the respective natures of  X  G and  X  P , they cannot simultane-ously consider both a source grapheme and a source phoneme. This makes it difficult to generate a correct transliteration, particularly when one model encounters source language words that should be transliterated through ne-gotiation between the source grapheme and the source phoneme or by a dif-ferent transliteration model. The hybrid transliteration model was proposed to solve this problem. However, it still does not consider the dependence be-tween the source grapheme and the source phoneme. Instead, it integrates
Pr (  X  G ) and Pr (  X  P ) by linear interpolation, assigning a static weight for each probability.
Our model,  X  C , overcomes these problems. Although it requires pronunci-ation knowledge, it minimizes errors caused by error propagation by using a source grapheme corresponding to a source phoneme. It is, therefore, more likely to avoid errors caused by error propagation. Because  X  C can dynamically use source graphemes and source phonemes depending on context, it can produce transliterations more effectively. 3. CORRESPONDENCE-BASED MACHINE TRANSLITERATION MODEL
Our correspondence-based transliteration model (  X  C ) is composed of two com-ponent functions:  X  P and  X  ( SP ) T . The  X  SP function produces pronunciation ( S  X  P ), and the  X  ( SP ) T function produces target graphemes ( S
First,  X  SP produces pronunciation and then  X  ( SP ) T produces target graphemes corresponding to the source grapheme and phoneme produced by of  X  ing to the source graphemes. For example,  X  SP produces /B/, /AO/, / /D/ for each source grapheme ( b , o , a , r , and d )in board (see  X  X esults of the right side of Figure 2). In this step, pronunciation is generated in two ways: through a pronunciation dictionary search and by pronunciation estimation. A pronunciation dictionary contains the correct pronunciation corresponding to
English words. Therefore, whether English words are registered in the dictio-nary is checked first; if they are not, pronunciation estimation is used. produces target graphemes corresponding to the source graphemes and source phonemes. For example,  X  ( SP ) T produces  X  X , X   X  X , X   X   X  , X   X  results of  X  SP (b-/B/, o-/AO/, a-/  X  /, r-/R/, and d-/D/) (see  X  X esults of the right side of Figure 2). Finally, the target language transliteration, such as the Korean transliteration  X  X odeu X  for board , is obtained by concatenating the sequence of target graphemes produced by  X  ( SP ) T .

Machine-learning algorithms are used to train  X  SP and  X  ( SP ) T component function, we need features that represent the training instances and data. Table II shows the five feature types, f S , f P our model uses. Depending on the component function, different feature types are applied.  X  SP uses { f S , f Stype , f P } , while  X  ( SP ) T f } . 3.1 Producing Pronunciation
The component function for producing pronunciation (  X  SP phonemes in a set P for each source grapheme, where P is a set of source phonemes defined in ARPABET and S is a set of source graphemes (e.g., En-glish letters). The results of this step can be represented as a sequence of cor-respondences between the source graphemes and source phonemes. We denote the sequence as SP ={ sp 1 , sp 2 , ... , sp n ; sp i = ( s i th source grapheme in the source language word SW ( = s composed of two steps. The first step involves a search in the pronunciation dictionary, which contains English words and their pronunciation. Here we use
The CMU Pronouncing Dictionary , 15 which contains 120,000 English words and their pronunciations. The second step involves pronunciation estimation. If an
English word is not registered in the pronunciation dictionary, we estimate its pronunciation.
 Let SW ( = s 1 , s 2 , ... , s n ) be an English word and P
SW  X  X  pronunciation, where s i represents the i th grapheme, and p
Pronunciation estimation is a task to find the most correct source phoneme grapheme s i . Table III shows an example of pronunciation estimation for b in board . The L1 X  X 3 and R1 X  X 3 represent the left and right source graphemes, respectively, and C 0 represents the current source grapheme (or focus). The  X  SP ( C 0) represents the estimated source phoneme corresponding to f and $ represents the start of words. The results can be interpreted as follows.
The most relevant source phoneme of b , /B/, can be produced by means of the context, f S , f Stype , and f P at L1 X  X 3, C 0, and R1 X  X 3. Other source phonemes for o , a , r , and d in boar d are produced in the same manner ( o r  X  / R / , and d  X  / D / ). Finally, we obtain the pronunciation of board as /B
AO R D/ by concatenating the sequence of source phonemes. 3.2 Producing Target Graphemes
The component function for producing target graphemes (  X  finds the target grapheme in T for each sp i that is a result of this step, SPT , is represented by a sequence of sp i and its corresponding target graphemes generated by  X  ( SP ) T , e.g., SPT = { spt 1 , spt  X  Let SW ( = s 1 , s 2 , ... , s n ) be a source language word, P where s i ,  X  SP ( s i ) = p i , and  X  ( SP)T ( sp i ) = t the source phoneme corresponding to s i , and the target grapheme correspond-of all possible target graphemes that can be derived from sp target graphemes with the source grapheme ( f S ), source phoneme ( f grapheme type ( f Stype ), source phoneme type ( f Ptype ), and put ( f T ) in the context window. Table IV shows an example of board .  X  ( SP)T produces the most probable sequence of target graphemes (e.g., Ko-rean or Japanese), such as  X  (SP)T ( sp 1 ) =  X  X , X   X  (SP)T  X  transliteration of board ,  X  X odeu, X  is acquired by concatenating the sequence of produced target graphemes. 4. MACHINE-LEARNING ALGORITHMS FOR EACH COMPONENT FUNCTION
We can model the component functions using three machine-learning algo-rithms (maximum entropy model, decision tree, and memory-based learning).
Because  X  SP and  X  (SP)T share a similar framework, we limit our focus to in this section. 4.1 Maximum Entropy Model
The maximum entropy model (MEM) is a widely used probability model that can incorporate heterogeneous information effectively [Berger et al. 1996; Miyao and Tsuji 2002]. In MEM, an event, ev , is usually composed of a target event ( te ) and a history event ( he ); say ev = &lt; te , he &gt; bundle of feature functions, fe i ( ev ), which represent the existence of a certain characteristic in event ev . A feature function is a binary-valued function. It is activated ( fe i ( ev ) = 1) when it meets its activating condition; otherwise it is deactivated ( fe i ( ev ) = 0) [Berger et al. 1996; Miyao and Tsuji 2002]. based on the maximum entropy model can be represented as Let source language word SW be composed of n graphemes. SW , P T
SW can then be represented by SW T target language word corresponding to SW , and p i and t i phoneme and target grapheme corresponding to s i . With the assumption that  X  ( SP ) T depends on context information in a window size of k , we simplify Eq. (5):
Because t 1 , ... , t n , s 1 , ... , s n , and p 1 , ... and f P , Ptype , respectively, we can rewrite Eq. (6) where i is the index of the current source grapheme and source phoneme to be transliterated and f X ( l , m ) represents the features of feature type f from position l to position m .

One important thing in designing a model based on the maximum entropy model is to identify feature functions that effectively support certain decisions of the model. Our basic philosophy of feature function design for each component is important. We thus designed the feature function with collocated features in each feature type and in different feature types. The features used in each component function are listed as follows. All of the feature types listed below are used as activating conditions of feature functions for the maximum entropy model to estimate the most relevant output of each component function.  X 
Feature type and features used for  X  ( SP ) T ( k = 3)  X 
All possible features in f S , Stype and f T  X 
All possible feature combinations between features of the same feature type (e.g., { f S  X 
All possible feature combinations between features of different feature types (e.g., { f S
Generally, a conditional maximum entropy model is an exponential log-linear model that gives the conditional probability of event e = &lt; in Eq. (8) [Berger et al. 1996; Miyao and Tsuji 2002]. Note that targets observable with history he .
 the history event ( he ) can be represented as a tuple &lt; f
Table V shows examples of feature functions for  X  ( SP ) T derive the feature functions. For example, fe 1 represents an event where f is b , f P on MEM, Zhang X  X  maximum entropy modeling tool is used [Zhang 2004]. 4.2 Decision Tree
Decision-tree learning is one of the most widely used and best known methods for inductive inference [Quinlan 1986; Mitchell 1997]. ID3 is a greedy algorithm that constructs decision trees in a top-down manner using the information gain, which measures how well a given feature (or attribute) separates training examples based on their target class [Quinlan 1993; Manning and Schutze 1999]. We use C4.5 [Quinlan 1993], a well known tool for decision-tree learning and implementation of Quinlan X  X  ID3 algorithm.
 Training data for  X  ( SP ) T is represented by features located in L3 X  X 1, C 0, and
R1 X  X 3, as described in Tables IV. C4.5 tries to construct a decision tree by look-ing for regularities in the training data [Mitchell 1997]. Figure 3 shows part of a decision tree constructed for  X  ( SP ) T in English-to-Korean transliteration.
To simplify our examples, we use only f S and f P . (Note that all the feature types described in Tables IV are used to construct decision trees.) The set of the tree is represented by decision nodes (circles) and leaf nodes (rectangles), which describe the target classes. Intuitively, the most effective feature for be located in C 0 among L3 X  X 1, C 0, and R1 X  X 3 because the correct outputs for  X  ( SP ) T strongly depend on the source grapheme or phoneme in the C 0 position.
As we expected, the most effective feature in the decision trees was located in the C 0 position, such as C 0( f P ). (Note that the first feature to be tested is the most effective feature in decision trees.) The decision tree for Figure 3 produces the target grapheme (Korean grapheme)  X  X  X  for x ( trieving the decision nodes from C 0( f P ) = / AO / to R 1( f by  X   X  . X  4.3 Memory-Based Learning
Memory-based learning (MBL) is an example-based learning method that is also called instance-based learning and case-based learning. It is based on a k -nearest neighborhood algorithm [Aha et al. 1991; Aha 1997; Cover and Hart 1967; Devijver and Kittler 1982]. In the training phase, MBL places all train-ing data as examples in memory and clusters some examples according to the k -nearest neighborhood principle. It then produces output using similarity-based reasoning between test data and the examples in the memory. Let the test data be x and a set of examples in a memory be Y . The similarity between x and
Y is estimated using a distance function, ( x , Y ). MBL selects an example y a cluster of examples that are most similar to x and then assigns a target class of the example to the x  X  X  target class. We use a memory-based learning tool called TiMBL (Tilburg memory-based learner) version 5.0 [Daelemans et al. 2003].
Training data for MBL is represented in the same form as the training data for a decision tree. Note that the target classes for  X  ( SP ) T are source phonemes and target graphemes. As in Figure 3, we use only f f
P to simplify our examples. Figure 4 shows examples of for English-to-Korean transliteration. All training data are represented with their features in the context of L3 X  X 1, C 0, and R1 X  X 3 and their target classes for  X  ( SP ) T . They are stored in memory during the training phase. The features are weighted during the training phase to differentiate their importance. As shown in Figure 4,  X  ( SP ) T based on MBL outputs the target grapheme  X  X . X  5. EXPERIMENTS
We evaluated our correspondence-based transliteration model ( ducting two types of English-to-Korean and English-to-Japanese translitera-comparison test, we compared the performance of our model with that of
Kang and Choi X  X  English grapheme to Korean grapheme-conversion model based on decision trees (GTN) [Kang and Choi 2000; Kang 2001], Kang and
Kim X  X  English X  X orean transliteration model based on a transliteration net-work (GTN1) [Kang and Kim 2000], Goto et al X  X  English-to-Japanese translit-eration model (GTN2) [Goto et al. 2003], Kang X  X  phoneme-based English-to-
Korean transliteration model based on decision trees (PDT) [Kang 2001], and a hybrid transliteration model in which  X  G and  X  P are modeled with weighted fi-nite state transducers (HWFST) [Bilac and Tanaka 2004]. Note that PDT relies only on a pronunciation dictionary for producing pronunciation. We tested three versions of our model: maximum entropy (CMEM), decision tree (CDT), and memory-based learning (CMBL). To enable us to compare their performance with that of PDT, regardless of the performance of producing pronunciation (  X 
SP ), we applied the same method for producing pronunciation to PDT as used by our model. In the context window size test, we estimated the effect of the context window size on the performance of our model.
 The English-to-Korean test set (EKSet) [Nam 1997] consisted of 7185 English X  X orean pairs X  X here were 6185 training data and 1000 test data. EK-
Set contained no transliteration variations. 16 The English-to-Japanese test set (EJSet) consisted of 10,398 English-katakana pairs from EDICT [Breen 2003] X  1000 for testing and the rest for training. EJSet did contain transliteration variations, like (micro,  X  X aikuro X ) and (micro,  X  X ikuro X ); the average number of Japanese transliterations for an English word was 1.15. Because our EKSet and EJSet contain no or only a few transliteration variations, our evaluation focused on how well our system produced the standard transliterations in the
EKSet and EJSet. Transliteration variations will be discussed in Section 6. Our evaluation measure was word accuracy (WA), as given by Eq. (10), where  X  X Ts X  denotes correct transliterations and  X  X Ts X  denotes the output transliterations.
As shown in Table VI, all three versions of our model had better performance than the other models for both the English-to-Korean and English-to-Japanese transliterations. Table VII shows the information and context size used by each of the models. The key reason for the better performance of our model is that it can use correspondence while the others cannot.

The models that used a wide context window and previous outputs tended to perform better. For example, GTN2 had more accurate results than GDT (Table VI). Because machine transliteration is sensitive to context, the wider the context, the better the performance. Note that the context window size of the other models was limited to three, because a size greater than three either degrades [Kang and Choi 2000; Kang 2001] or does not improve performance [Kang and Kim 2000]. Determining an optimal context window size is thus important for machine transliteration.

For our context window size test, we used CMBL, which showed the best performance among the three versions of our model (Table VI). We varied the window size from 1 to 5. As shown in Table VIII, the best performance was obtained when the size was 3 for both the English-to-Korean and English-to-
Japanese transliterations. When the size was 1, there were many cases in which correct transliterations were not produced because of a lack of information. For example, the right three graphemes are needed to produce the correct target grapheme for t in -tion . When the context window size was over three, it was dif-ficult to generalize the training data because of the increased variety of training data. For both these reasons, our model worked best when the context window size was three. As also shown in Table VIII, the context size should be at least two to avoid significant performance deterioration because of a lack of contex-tual information.

In summary, our model performed significantly better than the other models X  X bout 15 X 41% better for the English-to-Korean transliteration and about 16 X 44% better for the English-to-Japanese transliteration. Our results show that a good transliteration model should simultaneously consider the source grapheme and the source phoneme, along with their correspondence, a reasonable context size, and the previous output. Our transliteration model sat-isfies these three conditions, enabling it to perform better than the other models. 6. DISCUSSION
We have shown experimentally that our correspondence-based transliteration model (  X  C ) effectively produces transliterations. The main reason the best is its ability to effectively handle both grapheme-and phoneme-based transliteration, depending on context. Because most of the other models to which we compared  X  C are grapheme-based, they are better able to produce grapheme-based transliterations than  X  C ;  X  C failed to produce some grapheme-based transliterations correctly that were produced correctly by some of the and ( nickel ,  X  X ikkel X ). The other models sometimes failed to produce correct phoneme-based transliterations; for example, only  X  C model has both strong and weak points. Thus, by using a combination of mod-els that complement each other, we can achieve a high-performance machine transliteration system.

In our evaluation, transliteration variations were not considered to be correct transliterations. In other words, only the standard transliterations in the gold standard (EKSet and EJSet) were considered to be correct. Variations were considered to be an error. In such cases, our transliteration model produced transliteration variations rather than the correct transliterations in the gold standard.

To analyze these errors, we first need to identify the transliteration vari-ations among the transliterations produced by our model. We assume that a transliteration variation should have the support of people, in general, because they are the ones who produce and consume transliteration variations. There-fore, we believe that we can identify the transliteration variations by examin-ing their usage in web data, i.e., the number of web documents in which they appear. To obtain these  X  X eb frequencies, X  we used a phrasal search method in which a phrase composed of a machine-generated transliteration and its source word was used as a query for a web search engine. The retrieved docu-ments contained the query as a phrase. This enabled us to investigate whether a machine-generated transliteration and its source word are generally used as  X  X ransliteration pairs X  17 in target language texts. Example web documents retrieved by a phrasal search are shown in Figure 5. The rectangles drawn in the documents mark machine-generated transliterations, with their source words shown in parentheses. Such patterns indicate that web documents re-trieved by a phrasal search are useful for identifying valid transliteration pairs.
We considered produced transliterations that were not in the gold standard to be transliteration variations if they could be found in web documents. In other words, we accepted transliteration variations if their web frequency was in the English-to-Korean transliteration and about 70 of 278 errors in the English-to-Japanese transliteration were caused by transliteration variations.
Tables IX and X show example standard transliterations and transliteration variations for several English words along with their web frequency (WF). From these results, we identified three characteristics that indicate it is important to accommodate both transliteration variations and the standard transliterations in natural language processing.

The WF (i.e., number of web documents) shows that both transliteration variations and standard transliterations are frequently used in real-world texts.

The WF of transliteration variations was sometimes higher than that of the standard transliteration.

The difference between a standard transliteration and a transliteration vari-ation can usually be found in the target language vowels rather than in the target language consonants. This is because vowels result in more translit-eration ambiguity than consonants.

To evaluate the coverage of our correspondence-based transliteration model (i.e., how well it produces various transliterations including standard transliterations and their variations) and to indirectly evaluate whether the produced transliterations are useful for IR (information retrieval), we con-ducted a  X  X overage test X  on Korean and Japanese IR test collections. Since term frequency ( tf ) and document frequency ( df ) are important factors in IR for determining a term X  X  weight, we used tf and df as two of the three evaluation measures of transliteration coverage (TC). We also used ut , which represents unique transliteration type . These three TC measures ( TC described in Eq. (11), where TR Found represents the set of transliterations found by our method, TR Gold represents the set of transliterations in the gold stan-dard, tr i represents the i th transliteration in TR , tf ( tr of tr i , and df ( tr i ) is the document frequency of tr We constructed the test sets used for the coverage test using Korean and
Japanese IR test collections X  X TCSet (Korean transliteration coverage test set) was constructed using KTSET 2.0 [Park et al. 1996] and JTCSet (Japanese transliteration coverage test set) was constructed using the NTCIR-1 ADHOC test collection [Kando et al. 1999]. Henceforth, we refer to KTSET 2.0 as  X  X T-
SET X  and the NTCIR-1 ADHOC test collection as  X  X TCIR. X  The characteristics of KTSET and NTCIR are summarized in Table XI. There are four types of queries in NTCIR (title, description, narrative, and concept X  X epresenting title of query, short description of query, long description of query, and concept key-word of query, respectively. We used the concept query type for our experiment and  X  X verage length of queries X  (Table XI) because the concept queries usually contain some bilingual information (English concept keywords and correspond-ing Japanese concept keywords).
 As shown in Table XI, NTICR contains much more documents than KTSET. Moreover, the document and query lengths in NTCIR are also longer than in KTSET. Given these difference, we used different strategies in constructing
KTCSet and JTCSet. We constructed KTCSet with Korean transliterations ex-tracted from all documents and queries in KTSET. We then manually added an
English word corresponding to each Korean transliteration. We ignored one-syllable Korean transliterations because they are usually confused with pure Korean words. KTCSet contains 1283 transliterations corresponding to 1149
English words, so one English word corresponds to 1.12 transliterations. Be-cause NTCIR contains many more documents than KTSET, it would be hard to construct JTCSet with all documents. We, therefore, used those documents in NTCIR-containing transliterations originating from the same English words as the transliterations in the queries. First, we manually added English words corresponding to the Japanese transliterations to the NTCIR queries. We then found Japanese transliterations in documents that originated from the same
English word as those in the queries. JTCSet contains 553 transliterations corresponding to 311 English words, so one English word corresponds to 1.78 transliterations. One of the main reasons many more transliteration variations are in JTCSet than KTCSet is the long vowel in Japanese transliterations (or
Japanese katakana ). The long vowel results in various transliteration varia-tions, because it can be inserted after every vowel. For example, NTCIR con-tains several transliterations corresponding to English word data , including  X  X , X  respectively).
 For the coverage test, we produced transliterations for English words in
KTCSet and JTCSet using CDT, CMEM, and CMBL. We then filtered out the produced transliterations for which the WF was zero (only the transliteration appearing in web documents were considered). The results are shown in Ta-ble XII. We calculated the upper bound by applying the WF to the gold standards of KTCSet and JTCSet. It is the TC when TC Found is calculated by removing the transliterations in TC Gold that do not appear in web documents. We use
CMBL as the baseline because it had the best performance (Table VI). We then added transliterations sequentially produced by CMEM and CDT. As shown in
Table XII, combining transliterations produced by the different versions of our model effectively increases TC. Because our approach focuses on producing the most probable transliteration, CMBL alone was less effective than CMBL
CMEM + CMBL. In other words, more than one transliteration should be con-sidered in order to achieve high TC, because KTCSet and JTCSet contain 1.12 and 1.78 transliterations for each English word, respectively. Although some transliterations in the gold standard were not be produced by CMBL +
CMBL, the transliterations had a low term frequency and a low document fre-quency . Therefore, TC tf and TC df were relatively high compared to TC results. For the same reason, the performance gap in terms of TC less than that in terms of TC ut for CMBL + CMEM + CMBL compared to the upper bound. Overall, CMBL + CMEM + CMBL effectively covered translitera-tions about 52 to 69% for TC ut , 78 X 96% for TC tf , and 78 X 96% for TC
TC ut was relatively low, TC sf and TC df were high. Our transliteration model should be useful for IR, because its TC tf and TC df were high, meaning that it produced transliterations that frequently appeared in texts.

While most machine transliteration research has focused on producing stan-dard transliterations, transliteration variations are also important for some applications, especially for information retrieval systems [Kang and Choi 2000;
Lee and Choi 1998; Fujii and Tetsuya 2001]. The ability to recognize terms that are semantically equivalent, but orthographically different, such as transliter-ation equivalent 18 is important for improving the performance of information retrieval systems. As shown in Tables IX and X, we may miss many chances to retrieve relevant documents if we do not consider transliteration equivalents because there are many documents containing only the standard transliteration or a transliteration variation. Consequently, there have been studies on translit-eration pair (or transliteration equivalent) acquisition from corpora [Brill et al. 2001; Tsujii 2002; Collier et al. 1997; Kuo and Yang 2004]. While machine transliteration is aimed at automatically producing transliterations for given source words, transliteration pair acquisition is aimed at finding a phonetic cog-nate in two languages from bilingual corpora. Transliteration acquisition meth-ods usually have three steps: candidate extraction, phonetic conversion, and comparison. In candidate extraction, an algorithm tries to find transliteration pair candidates in bilingual corpora. Source (or target) language words in the candidates are then phonetically converted to target (or source) language ones, as in machine transliteration. For example, Brill et al. [2001], Tsujii [2002], and
Collier et al. [1997] transform Japanese katakana words into English words with their Japanese-to-English back-transliteration systems. Finally, the algo-rithm finds the relevant transliteration pairs by means of phonetic similarity, which is determined by phonetic comparison between the phonetically con-verted source (or target) language word and the target language word in the candidates. Therefore, machine transliteration can serve as one component in transliteration pair acquisition by providing a machine-generated transliter-of source words and their transliterations X  X an be used as training data in machine transliteration. Therefore, these two functions should be used in a complementary fashion to address the problems related to transliteration. 7. CONCLUSION
Unlike previous transliteration models, our correspondence-based machine transliteration model,  X  C , uses the correspondence between source graphemes and source phonemes. This correspondence makes it possible for fectively produce both grapheme-and phoneme-based transliterations. More-over, the correspondence helps it reduce transliteration ambiguity. Experiments showed that  X  C is more effective than other transliteration models; its perfor-mance was better by about 15 X 41% in English-to-Korean transliteration and by about 16 X 44% in English-to-Japanese transliteration.
We plan to apply our transliteration model to an English-to-Chinese translit-eration model. To demonstrate the usefulness of our model in NLP applications, we plan to apply it to such applications as automatic bilingual dictionary con-struction, information retrieval, and machine translation.

