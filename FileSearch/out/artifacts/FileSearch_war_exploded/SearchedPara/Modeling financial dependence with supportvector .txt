 School of Finance, Zhejiang Gongshang University, Hangzhou 310018, Zhejiang, China Tel.: +86 571 2887 7720; Fax: +86 571 2887 7705; E-mail: wangyq@zjgsu.edu.cn 1. Introduction
The problem of modeling asset returns is one of the central important issues in finance. Following the modern portfolio theory [27], multivariate normal distributions have, for a long time, been considered as the main tools for quantifying the dependence between financial assets. This assumption represented a basic pillar on which most of modern finance theory has been built. In the field of asset pricing, this assumption leads to the famous Black-Scholes formula [5,28], which was awarded Nobel Prize in Economics in 1997. In risk management, assuming normality leads to the standard parametric approach measurement. This popularity of multivariate normal distributions in finance mainly stems from their tractable properties for computation. Due to this normality assumption, dependences between the assets in the portfolio only rely on variances and correlation matrices.

Since the 1987 stock crash, this popular assumption was severely challenged. Overwhelming evi-evidence of standard financial products, such as stocks and foreign exchanges, clearly shows that their returns are at odds with this normality assumption [37,42]. Moreover, financial innovation has spurred plain vanilla and exotic nonlinear financial products becomes pervasive phenomenon in balance sheets of many financial institutions. I t is widely recognized that this nor mality assumption can make risk measurement severely incomplete and lead to a very strong underestimation of the real incurred [15].
But abandoning the normality assumption for multi dimensional problems is a much more involved financial assets, except multivariate normal distribution. Due to the fundamental importance of depen-dence modeling in finance, a more systematic modeling for the dependence structure underlying multi-in products and portfolios composed by many assets would be a hopeless task without the use of copula functions.

Copula represents a methodology which has recently become the most significant new tool of financial dependence modeling. It can handle in a flexible way the comovement between markets, risk factors and other relevant variables studied in finance. It has been gathering more and more popularity both among and erratic behavior of financial markets.

By copula, the distribution of the return on a portfolio will depend on the univariate distributions of the individual assets in the portfolio and on the dependence between each of the assets. Consider two joint distribution F , Sklar theorem [36] shows that there is one unique copula function C :[0 , 1] 2  X  [0 , 1] that Necessary and sufficient condition for a bivariate function to be a copula is  X  boundary:  X  u 1 ,u 2  X  [0 , 1]  X  2-increasing:  X  0 u 1 &lt;v 1 1 , 0 u 2 &lt;v 2 1 The above statement can be easily understood by the property of bivariate joint distribution. With cop-management and derivatives pricing.

Usually copula functions are estimated by parametric methods, which assume its copula family and optimize copula parameters by maximizing likelihood functions. But the performance of parametric methods greatly relies on their  X  X uess X  on the copula family. For example, the Gaussian copula assump-key reasons behind the global 2008 X 2009 Subprime Crisis. 1 Financial returns usually show high degree of co-movement in financial crisis, but Gaussian copula fails to capture this lower tail dependence.
Nonparametric methods have been introduced to estimate copula. Empirical copula, introduced by [12, 13], extended the idea of empirical distribution for univariate variable to copula. Because empirical copula is highly discontinuous and wiggly, several methods have been proposed to smooth empirical copula function, such as kernel smoother [8,16], spline [14,22,35] and wavelets [2,18,29]. But all the above methods neglect the shape restrictions Eqs (2) and (3), which makes their estimation unqualified to be copula functions.

This paper proposes a novel shape-restricted least squares support vector regression, brief as SLSSVR regression methods. First suggested by [39,40], least squares support vector regression (LSSVR) is a to a much higher-dimensional space and locate an optimal linear regression in that space. To the best of our knowledge, there is no publication on estimating copula function with support vector regression. But, same as other nonparametric methods, such as kernel smoother, spline and wavelets, the estimated
In statistics terminology, copula estimation can be regarded as a special shape-restricted nonparamet-ric regression problem, which has a long history in the literature. Studies on shape-restricted regres-sion began with [20] which proposed a method for regression under concave shape restriction and [7] which presented maximum likelihood estimators for estimating monotone restrictions on parameters. Regression under unimodal shape restriction was first studied by [44]. More generally, nonparametric regression with monotonicity, concavity and supermodularity, which involve restricting the sign of the regression partial derivatives, can be found in [3]. [30] proposed a regression method which considered both smoothing requirement and shape restrictions and demonstrated their method on a remarkable array of examples.

Incorporating qualitative prior shape knowledge into support vector regression has been explored by [32,38,41]. [32] built monotone least squares support vector machine, which imposed the mono-tonicity constraints on every pair monotone samples. [41] tack led monotone quan tile support vector regression by imposing non-negative derivative constraints on every training sample. [38] also analyzed support vector regression when the derivatives of the regression functions were restricted to be bound-ary, which included monotone, convex and concave shape restrictions. Literature on prior knowledge based support vector regression also includes [17,23,24,26], but none of them tackles shape-restricted regression with 2-increasing shape restriction.

This paper proposes a least squares support vector regression with the boundary and 2-increasing shape restrictions to obtain a nonparametric copula estimation. Following trick of [3], these shape re-First it is nonparametric estimation which doesn X  X  need any assumption on copula families. Second, com-prior knowledge on its shape.

The remainder of the paper is organized as follows. In Section 2, we introduce how to apply LSSVR to fit a smooth copula function. Section 3 details how to supplement the classical LSSVR with shape-related constraints and how to transform it to a convex quadratic program. In Section 4, we demonstrate on financial time series of DJI and FTSE100 indices. The paper is concluded in Section 5. 2. Background
This section introduces the main idea of the application of the classic least squares support vector machine in copula estimation. Consider two financial random variables X 1 and X 2 , with marginal dis-function estimation is a well-established area in statistics, which includes many mature parametric and non-parametric methods, this paper doesn X  X  explore this step. Second, estimate the underlying copula joint distribution F is In modern financial risk management, dependence modeling is synonymous with copula estimation.
The simplest nonparametric copula estimation is empirical copula F ( X 1 ) and F 2 ( X 2 ) with support [0 , 1] 2 highly discontinuous and wiggly, which retards its successful applications in many fields. Some methods have been proposed to smooth empirical copula, such as kernel smoothing, spline and wavelets.
This paper suggests to smooth empirical copula with LSSVR, which is one important kernel meth-ods [33,34] for function approximation. LSSVR maintains all the main features that characterize the maximal margin algorithm: a non-linear function is learned by a linear learning machine in a kernel-on the dimensionality of the space. So, in LSSVR, copula estim ation becomes how to fit a function C :[0 , 1] 2  X  [0 , 1] based on the data set of empirical copula points { ( u i ,C i ) } N i =1 ,where
To achieve nonlinear regression power, the input space [0 , 1] 2 is mapped to a much higher-and possi-in the feature space then the above fitting problem has the following representation: term w w / 2 .

Following the dual program theory, we have where  X  i  X  , i =1 ,...,N , are the Lagrange multipliers corresponding to the constraints. The optimal solution  X   X  i sand b  X  can be obtained by the following equations a kernel function Typical kernels include  X  Gaussian or Radial Basis Function (RBF) kernel  X  Polynomial kernel
The final copula estimation is smooth if Gaussian kernel or polynomial kernel is applied. 3. Shape-restricted LSSVR
When one applies the classical LSSVR to estimate the underlying copula, he can not guarantee that function must be required to be subject to the shape-restrictions Eqs (2) and (3). 3.1. Problem formulation
Same as the classical LSSVR, the shape-restricted LSSVR maps every point in the input space into a higher dimension space with the mapping function  X  (  X  ) and locates a linear function Eq. (8). But, different from the classical LSSVR, the shape-restricted LSSVR determines the function by where F denotes the functional space that satisfies the boundary shape restriction Eq. (2) and the 2-number of functions. The two shape restrictions are continuously constrained, which induces infinite constraints and makes the above estimation problem a challenging infinite-dimensional problem. port vector regression also can been found in [26]. [26] considered support vector regression when the ensures that the regression result strictly fulfills the original constraints.

Let X  X  first consider the boundary shape restriction Eq. (2). A natural first attempt is to append some points from the four boundaries of the support. By intentionally supplementing the training data set with these boundary points in SLSSVR training, we expect that the estimator can fit the four boundaries theory. Assume these 4 M points space evenly on the four boundaries  X  Bottom boundary: (( i/M, 0); 0) ,i =1 ,...,M  X  Left boundary: ((0 ,i/M ); 0) ,i =1 ,...,M  X  Top boundary: (( i/M, 1); i/M ) ,i =1 ,...,M  X  Right boundary: ((1 ,i/M ); i/M ) ,i =1 ,...,M restricted LSSVR, these points shouldn X  X  allow for violation, i.e.
Second we consider the 2-increasing shape restriction Eq. (3). Motivated by [3], we tackle this 2-on the support [0 , 1] 2 Let the corresponding grid points be So the constraints related with the 2-increasing shape restriction are Note the intercept b has disappeared. The above sieve way has one obvious advantage: the constraints
Here we must emphasize that, in the shape-restricted LSSVR, the shape restrictions are only imposed predetermined grid points. Because the continuous constraints are required to be satisfied only on grid But one can make these shape restrictions be satisfied in any degree by imposing the constraints in a finer equidistant grid.

Based on the above analysis, the copula estimation problem becomes Note the first kind N constraints Eq. (21b) are imposed for fitting the copula function with empirical constraints determine its location. 3.2. Dual problem The Lagrangian associated with the above problem is where  X  =(  X  1 ,..., X  N ) ,  X  =(  X  1 ,..., X  M ) and M  X  M -dimension matrix  X  with elements  X  ij are the Lagrange multipliers associated with the constraints Eqs (21b) X (21d) respectively.
According to the Kurush-Kuhn-Tucker conditions, we have So the dual problem becomes a N +4 M + M 2 -dimension convex quadratic program where  X  Others block matrices  X  vec (  X  ) : Vectorization of a matrix which converts the matrix into a column vector, i.e. The intercept b  X  can be obtained by any equality constraints of Eq. (21c) k 4. Experiments 4.1. Artificial data set
This subsection demonstrates the capability of the shape-restricted LSSVR in copula estimation by experiments on one size-100 artificial data set which is randomly generated by Clayton copula [10] with parameter  X  =2 . Clayton copula has the following functional form Clayton copula is widely used in modern financial risk management, because it can characterize lower tail dependence in multi-dimensional return data. Lower tail dependence reflects the dependence struc-samples in the left-lower quadrant obviously show a tendency of co-crash. Of course the Clayton copula satisfies the two shape requirements, as shown in Fig. 1.

Estimation results of the empirical copula algorithm Eq. (5) are shown in Fig. 2. Figure 2(a) shows very much. Its under-performance mainly comes from its simple weights on training sample, thus makes its copula estimation be a stepwise function.

In the classical LSSVR, the trade-off parameter  X  and the RBF kernel parameter  X  2 were 1 and 0.1 respectively. In the shape-restricted LSSVR,  X  and  X  2 were same as that of LSSVR, the grid parameter M was 10. The above parameter settings were arbitrarily determined.

The fitting results of the classi cal LSSVR are shown in Fig. 3. By comparing the four boundaries of the classical LSSVR estimator shown in Fig. 3(a) with that of the true copula shown in Fig. 1(a), we can immediately draw a conclusion that the classical LSSVR estimator badly fits the four boundaries. Figure 3(b) obviously shows that the level curves are very irregular and the estimation violates the 2-increasing shape restriction.

The estimation results of the shape-restricted LSSVR are shown in Fig. 4. As shown in Fig. 4(a), the four boundaries of the shape-restricted LSSVR almost coincide with that of the true copula. So it is clearly that exploiting the prior knowledge on the four boundaries can impr ove copula estimation. Figure 4(b) also clearly demonstrates that the contour of the shape-restricted LSSVR estimation shows nice 2-increasing shape. Compared with the contour of the true copula shown in Fig. 1(b), the shape-restricted LSSVR estimation seems very closely approximated the true copula. Its advantage over the classical LSSVR estimator is obvious. This significant improvement should attribute to the exploitation of the prior knowledge on its shape, which is imposed by the constraints Eqs (21c) and (21d).
To see the relationship between the estimation performance and the grid size M , we also conducted their estimation performance by where  X  C is an estimator and C is the true Clayton copula. Equation (40) can be approximated by mean absolute deviation error (MADE), where T controls the area of each grid. Note MADE is an out-of-sample error measure. In our experi-ment, T is 200. We repeated the above training and test steps 10 times and took their average MADE for model evaluation.
 Figure 5 obviously demonstrates that, for all value of M , the performance of the shape-restricted LSSVR was significantly better than that of the classical LSSVR. This result clearly verified that ex-ploiting prior knowledge in copula e stimation could greatly improve copula estimation performance. We also can conclude from the figure that, as M increases, its marginal performance improvement will converge to zero, which mean that too large M is unnecessary in SLSSVR training. This conclusion can be confirmed by the fact that the matrix  X  will become very sparse as M increases. 4.2. Financial data set This subsection examines the performance of the shape-restricted LSSVR on a real financial data set. We investigated the comovement between two major stock indices, US Dow Jones Index (DJI) and UK Financial Time Stock Exchange 100 Index (FTSE100) from Jan 4, 2000 to Dec 30, 2010. For each day when only one stock market was open for trading, we replaced the closing price of the another market econometrics, volatility of stock markets mainly comes from trading itself, instead of released public information [4]. So the experiment had 2810 daily pair logarithmic returns in 11 years.
Please note the experiment on real world data sets is very different from that on the above artificial was generated and should conduct model performance evaluation by comparing the estimated copula function with the known true copula. While, for the real world data set, the underlying copula function is never recovered. Model comparisons must be based on out-of-sample accuracy. Second, in the exper-the copula function; while in the toy data set we just need to estimate the copula function.
To obtain the conditional marginal distributions of the returns, we modeled both univariate time series by AR(1)-GARCH(1,1)-t [6] individually  X  model specification was mainly based on AIC and BIC criterion. The estimation results of univariate time series are listed in Table 1.

Based on the above estimation, we use the following equation to obtain the probability series  X  F t Kolmogorov-Smirnov test results showed that both probability series  X  F t of DJI and FTSE100 followed the [0,1] uniform distribution at the 5% significance level. We also conducted Ljung-box test on the series to verify whether they are independently distributed. The null hypothesis can not be rejected at the 5% significance level. So the series  X  F t can be regarded i.i.d with [0,1] uniform distribution. copula in real applications can never be recovered. So, in the paper, the underlying true copula was substituted by the empirical c opula for model evaluation.

In this experiment the estimation results of the SLSSVR were compared with that of parametric meth-ods. 5 copula families popular in risk management were chosen for investigation:  X  Gaussian copula  X  Student X  X  copula  X  Gumble copula  X  Frank copula  X  Clayton copula In the above parametric methods, copula parameters were obtained by maximum likelihood estimation One state-of-the-art nonparametric method, kernel smoother [8], was used for model comparison. Two popular kernel functions were applied in kernel smoother: Epanechnikov and Gaussian. In the shape-restricted LSSVR, two kernel functions were selected for evaluation: Gaussian and polynomial. In SLSSVR training, the grid parameter M =10 . All hyper-parameters, bandwidths for kernel smoother,  X  ,  X  2 and p for SLSSVR were selected by the ordinary 10 cross validation.

Model comparison was mainly based on two out-of-sample measures: MADE and root mean square error (RMSE) t -th test sample.

In the experiment, the total data set was partitioned into training data (with size 500) and test data (with size 2310). To decrease the error from the randomness of partition, we repeated this partition 10 times and compared model performance based on their averages. The results are listed in Table 2. In model at the 1% significance level is denoted with italic.

For both error measures MADE and RMSE, the shape-restricted LSSVR with Gaussian kernel achieved the best out-of-sample performance, 0.7600% and 0.9730% respectively. This performance sian kernel for MADE error measure. For both measures, the second and third best methods are SLSSVR with polynomial kernel and kernel smoother with Gaussian kernel. It is also obvious from the table that the parametric methods are uniformly surpassed by the nonparametric methods.
 5. Conclusions and future work This paper proposes a shape-restricted least squares support vector machine for copula estimation. In this nonparametric method, the classical LSSVR is supplemented with constraints related to the two shape restrictions of copula: boundary and 2-increasing. These constraints are imposed on the points of set clearly demonstrated that it had better finite sample property than the classical LSSVR. Empirical tests on comovement between DJI and FTSE100 obviously illustrated that it could achieve significant better performance than parametric methods and kernel smoother, which is one state-of-the-art nonpara-metric method for copula estimation.

Future work of the shape-restricted LSSVR includes the extension of the bivariate case to multivariate cases. Though the method can be extended to multivariate copula with minor modification, it will suffer great computational burden. Because the shape-related constraints are imposed on the equidistant grid, the number of involved knots grows exponentially as the dimension of copula increases. If each dimen-is an N +2 H M + M H quadratic program.
 Acknowledgments
The author thanks the anonymous referees for their valuable comments and suggestions, which im-Science Foundation of China (71101127), Social Sciences Foundation of Chinese Ministry of Education (10YJC790265), Zhejiang Natural Science Foundation (Y7080205) and Zhejiang Province Universities Social Sciences Key Base (Finance Research Center of Zhejiang Gongshang University). References
