 Relational classifiers use relations betw een instances to predict class values ( X  X n-tity classification task X ). An example is classifying papers by categories using relations like CommonAuthor , CommonCitations or SameConference ,wherethe relations indicate the number of co-authors, co-citations or the same confer-ence given two papers. For problems where such relations are present, relational classifier have shown to outperform state-of-the-art non-relational classifiers like Support Vector Machines [1,2,3]. The drawback of relational classifiers is that they can only be applied in scenarios where the relations are explicitly given. In most real-world scenarios this is not the case. If the relations are not directly given, they have to be annotated manually by domain experts. This is a time consuming and expensive task.

In this paper we propose the method LRE ( X  X earning Relation Extraction X ) for automatically extracting relations from a noisy dataset. The method is based on learning a binary regression model for pairs of instances. As the method uses training data, it can adapt itself to different tasks and domains. This makes it superior to handcrafted or heuristic extraction rules.

The overall contributions of our paper are as following: (1) We propose the supervised method LRE for extracting re lations. These relations can be used in relational classifiers for the task of entity classification. (2) Our evaluation indicates that learning the relation with our LRE method is successful and results in a comparable performance to manually labeled relations.
 Our LRE approach has parallels to the field of record linkage [4], where an equivalence relation should be learned. W e share the feature extraction step with work in this field. Here also several heuristic pairwise similarity measures are used to create pairwise features [5,6]. In other components, our approach differs from the work in record linkage as the properties of the relation to predict differs. In record linkage an equivalence relation has to be learned. Thus typically a probabilistic classifier is learned over pairs [5]. Afterwards clustering is performed to create a binary equivalence relation. This approach has been suggested by Preisach et al. [7] to extract relations fo r relational learnin g. In contrast to this we learn a regression model to predict weighted relations. Throughout the paper we use a bibliographic scenario for illustration and evalu-ation. In this scenario a data set of research papers is given and the category of the paper, e.g. Machine Learning or Artificial Intelligence should be predicted. We will denote the set of objects  X  here papers  X  by X = { x 1 ,...,x n } and a relation by R . An example of such a data set is given in table 1. Here each paper is described by the attributes Author , Paper title and Conference .
The field values of each attribute can be seen as a relation over a pair of objects  X  here over two papers. For example the Conference attribute values of p boolean relation SameConference . Similarly, p 1 and p 2 have one author in common and thus CommonAuthors ( p 1 ,p 2 ) = 1. Having such a data set like in figure 1, the relations SameConference and CommonAuthors can easily be constructed. The values of the two binary relations of the given example can be found in table 2. With these two relations any relational classifier can be applied to predict the paper category. 3.1 Relational Classification c  X  C for an object x  X  X given j relations R the range of the relation. We will deal with cases of T  X  R .

There are many approaches for relational classifiers. One example is the prob-abilistic relational classifier (PRN) introduced by Macskassy and Provost [2]. It calculates the class probability as the weighted arithmetic mean of the class-membership probabilities of the related objects given a relation R : Where Z := x  X  X R ( x,x ) is the normalization constant.
 Preisach and Schmidt-Thieme [8] have introduced extensions of this algorithm. One extension is not only to take into account direct neighbors but also indirectly linked objects by longer paths. As R is often very sparse, this can be seen as a densification of the relation graph. The model equation of PRN (see (1)) is for a single relation R . PRN can be extended [8] to a multi-relational classifier EPRN by combining several single -relational PRN classifiers by ensembling techniques, e.g. stacking. 3.2 Noisy Data Sets Relational classifiers are known to result in high quality predictions. However real world data often does not state the relations explicitly. Instead the data set might look like in table 3. Here for example the identity between  X  NIPS 2003  X  and  X  advances in neural information processing systems  X  is not obvious. Thus a relational model cannot be run directly on such noisy data sets.

There are many reasons why relations in data sets are not stated explicitly but are hidden. One obvious reason are errors that occur when humans work with an information system, e.g. typos. Secondly, often several abbreviations can be used, e.g. NIPS stands for N eural I nformation P rocessing S ystems .When writing names the first name can be placed after the family name  X  e.g. John Smith is Smith, John . Other places for noise in textual encoded relations are ambiguities  X  e.g. there are two diff erent people wit h the same name.
This paper deals with the problem of extracting relations from such noisy data sets. We use an adaptive, supervised metho d that learns to extract relations given some training data. 3.3 Type of Relations There are several different types of rela tions that can be extracted. They can be distinguished by the range T of their target. Important ranges are:  X  Boolean relations where T = { 0 , 1 } ,e.g SameConference or SamePub- X  Probabilistic relations where the target is a probability score and thus  X  Weighted relations where a real-valued score is attached to each pair: Our learning method for relations will handle the most general case of weighted relations. In the following we describe our method LRE for L earning R elation E xtraction from a noisy data set like in table 3. Our proposed method extracts pairwise fea-tures given two objects. Based on these features, a regression model for R is learned andappliedtopredict  X  R . The overall algorithm can be found in algorithm 1.
Next we describe the main components of LRE in detail, i.e. extracting pair-wise features, learning the regression model and generating candidates for scaling to large data sets. 4.1 Extracting Pairwise Features The overall goal of our method is to extract relations from noisy attribute values of a data set. Let a 1 ,...,a k : X  X  V be the noisy attributes of our dataset. E.g. a 1 might return the noisy list of the authors of a specific paper, string, etc.

As the target relation is defined over a pair of objects, feature extraction aims to create meaningful pairwise information from the attributes. Thus feature Algorithm 1. LRE: Learning Relation Extraction extraction can be formulated as a function that generates a real valued feature vector for a pair of objects: To create a real-valu ed vector of length l from a pair of objects, several heuristic similarity measures f 1 ,...,f l can be applied. Examples of well-known similarity/ distance functions for strings are TFIDF cosine similarity, Overlap index or Levenshtein distance. Details about these and many more similarity measures can be found in [9]. Table 4 shows an example for feature extraction for the CommonAuthors relation. 4.2 Relation Learning Based on the pairwise features, a regre ssion model is learned to estimate the relation weight between a pair of objects. The model is trained on a labeled subset of objects X tr , where the true relation weight R ( x,y ) between object pairs ( x,y )  X  X 2 tr is known. The features of a pair of objects for training the model and later on to predict the unknown weights consist of the elements of the feature vector f =( f 1 ,...,f l ).

In our implementation we applied a Support Vector Regression (SVR) model using the implementation of libSVM [10]. In general, any other regression method could also be used, e.g. linear r egression or ridge regression.
 4.3 Scaling The method proposed so far has a runtime that is quadratic O ( n 2 )inthenumber of objects X because the binary relation R has | X 2 | possible entries. For large data sets this method is not applicable any more. A solution to the problem relies on the fact that most relations are very sparse, i.e. have many 0 entries. We suggest to use blocking techniques from the field of record linkage to handle such cases. Blocking is a method to reduce the number of pairs, by discarding pairs that are obviously 0. For relations that are equivalence relations any of the proposed blocking techniques from the field of record linkage can be used for GenerateCandidates (see algorithm 1). An overview about blocking for record linkage is given by Baxter et al. [11]. For scaling to the problem of pre-dicting equivalence classes that hav e both big and many classes, the method proposed by Rendle and Schmidt-Thieme [12] can be applied.

In the general case of predicting an arbitrary weighted relation, we suggest to generate candidates by considering only pairs of objects whose similarity based on a cheap measure exceeds a certain threshold. In our evaluation we investigate if our method successfully learns relations for relational classification. We measure the success in two tasks: 1. Relation extraction task : This task measures how good the extracted 2. Entity classification task : Here the quality of a relation R is measured In all, the entity classification task is the more important task and the goal is to achieve a classification quality with a learned relation as high as with a manually labeled one. 5.1 Dataset We perform our evaluation on the relational Cora dataset provided by McCal-lum 1 . This dataset contains papers with their category, author string, citations, conference and journal st ring. We use a subset with the 12 subcategories of  X  X r-tificial Intelligence X , i.e.  X  X achine Learning X ,  X  X nowledge Representation X ,  X  X ata Mining X , etc. We removed papers without authors, citations and neither confer-ence nor journal. In total this subset has 3298 papers.

In the Cora dataset, for the author and citation relation the true relation is already present. For authors the noisy author string is also present. Given this string we try to learn the true author relation. Secondly, we merged the noisy conference and journal attribute. For thi s merged attribute, we manually labeled anewrelation SameConference which states if two papers were published in the same conference proceedings or were published in the same journal. This relation is an equivalence relation. Again in our experiments we try to learn this relation from the noisy string. 5.2 Model Setup We choose a support vector regression as regression model. The hyperparameters are optimized in each repetition via grid search using cross-validation. As simi-larity functions we use TFIDF, relative overlap in tokens and absolute overlap in tokens. We use different variants of tokenizers that extract words, 2-grams and 3-grams. Each similarity function is run with each tokenizer. For speedup we use a canopy blocker for the equivalence relation SameConference ;for Commo-nAuthor we use the blocking method described in section 4.3. For relational classification we use an ensemble of PR N models. The ensemble is created by stacking with an SVM as meta classifier [8]. 5.3 Learning Relations In the first experiment we split the dataset X in two disjoint parts of equal size X elements in X train are known  X  i.e. the relation weights correspond to the manu-ally labeled weights. We then try to predict with LRE all other relation weights, figure 1. We compare the error of LRE to a constant baseline that predicts con-stantly a weight of 0. As the relations are very sparse  X  i.e. the weight of most rela-tion pairs is 0  X  the constant method results in a low RMSE error. Compared to the constant method the relation extract ed by LRE results in an even lower RMSE. Eventhough the relation predicted by the constant method has a low RMSE, this relation is useless for the entity classification task as no objects are linked. With lation contains no information. In contrast to this the relations extracted by LRE are also successful in solving the entity classification task.
For the entity classification task the entity labels on X train are assumed to be known whereas the labels on X test are unknown and quality is measured on X test . Figure 2 shows the classification accuracy using several combinations of relations. For every combination we report the accuracy with manually labeled relations and the relations automatically extracted by LRE. The citation relation is always manually labeled. As you can see, the classification quality using the learned relations is very similar to the results using manually labeled relations. For the case of the SameConference relation, prediction quality is even slightly better with the learned relation. For this relation the errors that the relation extraction makes seem to be informative for solving the entity classification task.
All results were repeated 10 times with d ifferent train/test splits. We report the means; the standard deviation within each experiment is below 0 . 01 accuracy. 5.4 Amount of Training Data In the second experiment we vary the amount of training data for learning the relation. This should show how much pairs of a relation have to be labeled before this relation can be learned successfully and applied to the entity classification task. Our protocol is as following: From the dataset X a test set X test of one third is put aside. Within the remaining 66% we take an increasing proportion X train from 1 to 90 percent. We assume that the relation weights within are known. We than predict the whole relation on X and evaluate it on X test (see figure 3). We repeated the experimen t 8 times with different training data.
Then we use the predicted relation for the task of entity classification. Here we assume that the entity labels on X \ X test are known. We evaluate the quality of the entity classification task on X test . With this evaluation protocol we can measure how many proportions of a relation have to be known (annotated) before it can be successfully learned and applied to the task of entity classification. Please note that with this evaluation protocol the amount of labeled entities is fixed, whereas the amount of labels on r elations is varied. Secondly both tasks are measured on a separate set where no information is given.

Figure 3 shows that both task are successfully solved with about 10% of labeles on relations. This means that the proposed LRE method can easily be applied for classification tasks where only implicit relations are given. In this paper we have described the LRE method for learning to automatically extract relations from noisy datasets. We have shown that only a small amount of training examples is necessary to learn a relation. We also have shown that the learned relations approximate the ma nually annotated rel ations successfully and using them for relational entity classification results in comparable perfor-mance to manually annotated relations. Thus our proposed method can replace a domain expert for the task of relation extraction from noisy data.
In future work we would like to investigat e active learning techniques to select the training dataset for learning a relation.
 This work was funded by the X-Media project (www.x-media-project.org) spon-sored by the European Commission as part of the Information Society Technolo-gies (IST) programme under E C grant number IST-FP6-026978.

