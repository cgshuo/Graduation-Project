 With the rapid growth of World-Wide-Web and new data archiving/analyzing tech-niques, there exists a huge volume of data available in public, which is graph structured in nature including bioinformatics, social science, link analysis, citation analysis, and collaborative network. Graph pattern matching is long investigated in database study. It traditionally stands for subgraph isomorphism problem [25,23], which determines whether a small graph pattern is exactly cont ained in another graph, or graphs in a large graph collection (as the data). Its main application is the so called frequent subgraph mining, which has been extensively studi ed for the last decade [29,28,22,30].
In recent year, there are an increasing num ber of applications which need to deal with large standalone graphs, such as link analysis, social networks and bioinformatics. it is important to know patterns existed in a single large graph [31]. Graph pattern match-ing also is no longer limited to subgraph isomorphism. Usually, the conditions on the matched instances in the data graph generaliz e to the label requirements and the struc-tural requirements, which are succinctly represented by a query graph [3,5,24,26,32]. The graph pattern matching of this type has many applications: It is used in the join processing for managing large XML documents [26]. In life sciences, graph pattern matching can be used for protein interaction networks comparison and protein structure matching [24]. In software engineering, graph pattern matching is used for dependance-related code search over the system dependence graph of the program [27]. Graph pat-tern matching is also central to quering massive RDF repository using SPARQL [33]. Other applications include interactive graph visulization [19], computing service dis-covery [7] and 3D object matching [8].

In this paper, we study top-k graph pattern matching problem which is to find the top-k answers for a graph pattern query over a large data graph. Particularly, to be distinguished from all existing work, our focus is on finding top-k answers of a cyclic graph pattern query. A naive solution is to find all possible answers from the underneath graph using an existing approach [5,26,32], and rank all the answers by the answer weight in order, and report the first k answers with the smallest total weight. However, there can be an enormous number of answers in the underneath graph. The cost of exhaustively enumeration for all of them can be prohibitive. Another solution is to use top-k join [16] to progressively compute the top-k answers rather than the complete set of answers. However, the top-k join solution requires a large amount of memory or have to use costly nested-loop join processing [1]. Other standard top-k processing such as TA [9] can not be directly applied because it needs sorted object lists, where the object to be searched are respectively sorted by each attribute in different sorted object lists. Such conditions can be not easily met in our problem setting.

Finding top-k matches for a cyclic graph query is challenging. However, linear cost algorithms in terms of time and space exist for finding top-k answers for twig queries, as introduced in [12]. It is possible operate on a ranked list of twig answers, in order to find top-k answers of a graph queries. Therefore, the overall processing can be efficient and scalable because those ranked lists of tw ig answers can be obtained very efficiently. Even if a large number of twig answers on the ranked list have to be enumerated before finding the requested top-k answers of the graph query, the cost of such processing increases marginally. Based on this motivation, in this paper, we propose a efficient solution for top-k graph pattern matching.
 Our Contributions: Our contributions are as follows: (1) We propose a new top-k graph pattern matching problem and investigate a baseline solution based on the exist-ing top-k processing technique (Section 2). (2) We propose a new twig query approach which is efficient and scalable in terms of different value scales of k (Section 3); (3) Since not each twig answer in a list corresponds to an answer of the graph query, differ-ent twig lists can result different cost in solving a given cyclic graph query. We propose cost-based optimization to select the best twig query ((Section 3.1); (4) We conducted extensive performance studies using a real dataset, and we confirm the efficiency of our proposed approach (Section 4).

We discuss related work in Section 5 and Section 6 concludes this paper. We discuss top-k graph matching for a given graph query over a large data graph. The data graph is defined as a weighted node-labeled graph G D =( V,E, X , label ,W e ) . Here, V is a set of nodes. E is a set of edges that can be directed or undirected.  X  is a set of node labels, which are usually far less than all nodes in G D . label is a mapping function which assigns each node, v i  X  V ,alabel X  X   X  ,and label ( v i ) is hence the label of node v i . Given a label X  X   X  , the extent of X , denoted as ext ( X ) ,is the set of all nodes in G D that are X -labeled. The weight function W e ( u, v ) assigns a weight to every edge ( u, v )  X  E . The shortest distance from a node u to a node v , denoted W p ( u, v ) , is the minimum total weight along a path from u and v ,in G D .Anda shortest path from u to v is a path from u to v with the minimum total weight W p ( u, v ) . In the following, we use V ( G ) and E ( G ) to denote the set of nodes and the set of edges in a graph G .

Fig. 1 shows a simple data graph, G D , in which all edges are weighted 1. There are 4 labels,  X  = { A, B, C, D } . In Fig. 1, we use the small letter x with a unique number i to signify an X -labeled node x i  X  ext ( X ) .
 A graph query Q =( V ( Q ) ,E ( Q )) is an undirected and connected graph, where V ( Q ) consists of labels in  X  ,and E ( Q ) is a set of edges between two nodes in V ( Q ) . To simplify exposition, we assume unique labels in V ( Q ) in the following discussion, and it is straightforward to extend our appr oach to the case of repeated labels. A graph query Q is a tree query (or twig query ) if it is cycle-free. Otherwise, it is a cyclic query (or graph query ). In the following of this paper, tree query and twig query (cyclic query and graph query) are used interchangeably. Fig. 2(a) shows a graph query with 3 labels. For this query, Fig. 2(b) and Fig. 2(c) illustrate two answers, a 2 ,b 2 ,c 2 and a 3 ,b 3 ,c 3 , that can be found in the data graph G D (Fig. 1).
 To answer a graph query Q is called the graph pattern matching problem ,or GPM for short. An answer of Q , denoted M Q , over G D ,isan n -ary node-tuples, v ping,  X  : Q  X  M Q that satisfies two kinds of conditions specified by Q , namely, label condition and structural condition. (1) The label conditions specified by Q are satisfied, i.e., for every X  X  V ( Q ) , there is a node x  X  M Q labeled by X in G D ; and (2) the structural conditions indicated by Q are satisfied, i.e., for every edge ( X,Y )  X  E ( Q ) , there is a connected path in G D between the two corresponding nodes x, y  X  M Q . 1
GPM asks for all answers for a given query. However, the total number of answers in a large graph can be enormous. To return a large number of answers to a user can be overwhelming for the user to digest, and the computation overhead is also prohibitive. Therefore, in this paper, we focus on efficiently finding top-k answers of a graph query. To p -k Answers: The top-k answers for Q are determined by a score function. Numer-ous score functions are discussed in the literature [21,14,2,15,20,12], which are usually based on node scores and edge scores . The node score is used to reflect the node im-portance of v  X  M Q , while the edge score is used to reflect the connection strengths of ( u, v ) ,where u, v  X  M Q and (  X   X  1 ( u ) , X   X  1 ( v ))  X  E ( Q ) .

For simplicity, we consider the edge score only with the following equation. How-ever, our approach is extendable to include the node score. query edge of Q , there is a corresponding score component of M Q . Eq. 1 is the sum of | E ( Q ) | several edge score components. Intuitively, the smaller distance between two nodes in G D indicates a closer relati onship between them. Therefore, an answer with a smaller score of Eq. 1 is regarded to be better. In other words, an answer M Q tends to be ranked higher if score ( M Q ) is smaller. k -GPM Problem: Consider a graph query Q against a large graph G D .A k -GPM problem finds the top-k answers of Q . Therefore, for k -GPM query Q, its answer is a than that of any other answers of Q . In this paper, we study the problem of k -GPM for a cyclic query Q .

Based on those path lengths in Fig. 2(b) and Fig. 2(c), the top-2 matches are M (1) Q = a 3 ,b 3 ,c 3 and M 2.1 A Direct Solution Based on Top-k Join A storage Scheme. Like the existing work [12,13], we materialize the edge transitive closure of a data graph G D , and store it in tables. The reasons why we proceeds our discussion with such a storage scheme bare (a) it speeds the queries by exempting the burden to search for the large number of required shortest paths at query time; (b) although the transitive closure is very large in size, a compressing scheme such as 2-hop covers [6,4] easily works on it for better space consumption; (c) it supports efficient search of trees [12,13] or even graphs (as will discussed below) for large graphs.
In detail, a table R ( A,D ) stores information for all shortest paths from A -labeled nodes to D -labeled nodes, which can be implemented as a database relations containing three columns essentially: A , D and distance . Here, columns A and D are for A -labeled nodes and D -labeled nodes, respectively. The column distance is for the correspond-ing distance W p ( a, d ) where a and d are A -labeled and D -labeled nodes in the same tuple. Below, we use R ( A,D ) to refer to this table. There can be |  X  | 2 tables, each corre-sponding to a different pair of labels in  X  . Later, we use t to signify a tuple in R ( A,D ) , while t. distance denotes W p ( a, d ) for a, b  X  t . A table supports two ways to access it: the sequential access, which scans the table sequentially, and the random access, which retrieve a tuple using given a and b .Fig.3shows R ( A,B ) , R ( B,C ) and R ( A,C ) for thedatagraph G D in Fig. 1.
 Atop-k Join Solution. The top-k join algorithms [16] can progressively compute top-k joins of several tables without computing all joins of those tables. Particularly, we briefly describe the adaption of a representative [16], called the hash ripple join ,or simply HRJN.
 Suppose there are | E ( Q ) | = l edges in Q and each edge is identified by a number. Let the i -th edge in E ( Q ) be ( X,Y ) , and we use R i to denote R ( X,Y ) . A multi-way join on R 1 , R 2 ,  X  X  X  ,and R l can be used to compute answers of Q . Here, R i and R j are joined together, if a common query node X appears as an end node in both the i -th and the j -th edges of | E ( Q ) | . And the join is based on the equality condition on the corresponding common X columns in table R i and table R j . The top-k join algorithm [16] requires that R 1 , R 2 ,  X  X  X  , R l are sorted in the ascending order of all W p ( a, d ) in their distance columns. HRJN sequentially scans those tables on disk. The tuples already scanned into memory are referred as seen tuples , while those not scanned yet are unseen tuples . For each table R i , a hash index is built for those seen tuples of R i .In detail, during the sequential scan, when an unseen tuple t from R i is accessed, HRJN probes all hash indexes to compute all valid join combinations of t between all seen tuples of R j , i = j . In this way, HRJN progressively joins R 1 , R 2 ,  X  X  X  ,and R l and a buffer is used to maintain temporary top-k anwsers that have been found.The HRJN can stop early when the the upper bound of those top-k answers in the buffer is even smaller than the lower bound of all unseen answers. Finding top-k matches for a cyclic graph query is challenging. However, linear cost algorithms in terms of time and space exist for finding top-k answers for twig queries, as introduced in [12]. It is possible operate on a ranked list of twig answers, in order to find top-k answers of a graph queries. Therefore, the overall processing can be efficient and scalable because those ranked lists of tw ig answers can be obtained very efficiently. Even if a large number of twig answers on the ranked list have to be enumerated before finding the requested top-k answers of the graph query, the cost of such processing increases marginally. We first briefly review the top-k twig query processing, then we discuss our new twig query approach for k -GPM.

Gou et al. shows in [12] that a linear cost algorithm exists in terms of time and space in order to efficiently find the top-k answers of a twig query T over G D ,where G D is stored using the aforementioned storage scheme with edge transitive closure. To process a given twig query T , the bottom-up strategy starts with the smallest subtrees of T and then considers larger subtrees till T is fully considered. The time and space requirement a fixed amount of time  X  , which is independent of the data size, is required to output the second (top-2 ) answer, the third (top-3 ) answer and so on. Interesting readers can refer to [12] for more knowledge. It is important to note that this top-k twig pattern matching does not directly applied for a cyclic query Q , because we cannot decompose the cyclic graph pattern in the same manner as that of the bottom-up strategy. Our Approach. Given a k -GPM query Q , the processing consists of two closely related tasks: Ta s k -1 : select a best twig query based on Q to construct the ranked list of these twig Ta s k -2 : process the ranked list to find the top k answers for the k -GPM as soon as The two tasks are executed simultaneously: In Ta s k -1 , the answers of the twig queries are generated on demand, as long as they are requested by Ta s k -2 . While Ta s k -2 com-putes the answers of Q based on those twig query answers. When all answers of the k -GPM are sucessfully found, it stops all processing.

In Ta s k -1 , those twig queries are obtained by considering the spanning trees of the graph structure of Q . We call such twig queries the t-queries of Q . Thus, any one spanning tree of Q can be a t-query of Q . A t-query returns the answers in the non-descending order of their wei ghts. Therefore, for each t-query, its ordered answers form Similar to a sequential scan over a ranked list, a t-list is constructed and processed pro-gressively: In a t-list, all twig answers seen that far are examined; the last answer is the latest answer returned by the t-query, which is consumed by task-2 immediately when it is generated. New answers of the t-queries are generated on demand and appended to the t-list, as long as they are requested by Ta s k -2 .
 Ta s k -2 tries to extend each twig answer to an answer of Q . Consider a twig answer. If it can be succesfully extended to an answer of Q , the set of nodes in the two answers must be identical. Thus, the twig answer can be a partial answer of Q , where we only need to find the additional edges among those nodes for Q . Those edges represents connections among those nodes in the data graph, which are required to satisfy Q .To this end, we consider all missing query edges , which are those edges appeared in Q , but do not exist in the t-query. For each missing query edge, say ( A, D ) , note that we already have two corresponding nodes a and d in the twig answer. So we only need to look up in R ( A,D ) to see if there is a record for the required shortest path between a and d . If the record can be successfully found, the required shortest path between a and d exists; so we add an edge between a and d to this partial answer, otherwise, this twig answer cannot be extended to an answer of Q and is discarded immediately. Finally, if the records for all missing query edges are found, we successfully obtain an answer of Q with all required shortest paths.
 Algorithm. Algorithm 1 begins with the computation for an optimal t-query T (Line 3). Section 3.1 will address the details of find the best t-query with the minimum estimated cost. At Line 4, the corresponding t-list of T is initialized. Therefore, a call of the function S.next () will return the lastest available answer in S ; this call also tells S to generate the next answer for T (Line 6). All answers in the t-list are discarded immedi-ately when it is examined as follows: we try to extend the latest answer of T (returned by S T .next () ), denoted M  X  T ,toananswerof Q .If M  X  T can be successfully extended to Algorithm 1. KGPM Tw i g a match of Q , a function extendable ( M  X  T ,M Q ) returns true, where the result is passed to M Q by reference. The top-k buffer B is updated with M Q (Line 8).  X  is the largest cost for a match in B and hence is also updated at Line 9. Line 10 derives a lower bound  X  that far for all unseen answers of Q with a bounding function lbound () based on all latest answers of the t-queries. At last, we stop the whole processing once the stop condition of Line 12 is satisfied, which suggest s we all already have that answer for the k -GPM in the buffer.
 Stop Condition. Note that T returns answers ranked by  X  ( A,D )  X  E ( T ) W p ( u, v ) . Partic-ularly, lbound ( M  X  T ) directly returns the score of M  X  T , namely The above equation is based on the fact that the score of any unseen answer of Q should be at least greater than the score of the last answer of T . To understand it, notice that for an answer, M Q ,where score ( M Q )  X  score ( M  X  T ) , it contains an corresponding answer of T , which must be ranked before M  X  T , hence is identified before M  X  T .There-fore, all such M Q should be examined already. To see how the stop condition works, note that lbound ( M  X  T ) (or  X  ) is growing larger and larger as more and more twig an-swers are identified ; in the meanwhile,  X  will not grow as the processing proceeds; it finally equals to the score of the k -th answer of Q . Therefore, the stop condition  X   X   X  can be satisfied. Note that  X  can be futhered tightened by considering the smallest score components corresponding to those missing query edges, which can be easily collected over the base tables offline.
 Example 1. For the example cyclic query in Fig. 2(a), we use a t-query tree T 1 (Fig. 4(a)) of Q to demonstrate the twig query approach. We construct S T 1 showninthetableon the left of Fig. 4(b). When the first twig answer, a 3 ,b 3 ,c 3 , comes, whose score is 2, we look up the weight of ( a 3 ,c 3 ) in R ( a,c ) and it is 1. Thus the first answer of Q is ob-tained and its overall score is 3 . It is buffered and  X  is set to be 3 . And we can obtain the current  X  also as 3 , which is the sum of the twig answer score and the smallest possible score for the query edge ( A, C ) . Since the size of the buffer is below the required num-ber, the stop condition is not satisfied. Then, we move to the second twig answer and it turns out not extendable. Thus, we repeat the precessing and find another Q answer upon the 7 -th twig answer. The stop condition is satisfied upon the 11 -th twig answer. 3.1 Cost-Based Optimizati on for T-Query Selection Given a graph query, there can be many different t-queries for it. Each t-query can give a different cost in solving the k -GPM. Therefore, it is important to select the op-timal t-query given a graph query Q . We discuss a cost-based selection to find the t-query with the smallest cost will be used. We mainly consider the time as the cost to be optimized. Note that [12] already shows the time requirement of a twig query is the second (top-2 ) match, the third (top-3 ) match and so on. Therefore, the cost to solve a k -GPM with the t-query T can be estimated as below, where c is a constant coefficient to tune the weight of two kinds of cost. Now the central issue for optimizing k -GPM is how to estimate the number of twig answers which are consumed before the stop condition is satisfied, namely, N in the above equation.
In order to estimate the value of N , we assume that all answers of a graph query Q are evenly distributed in S T . Moreover, we assume the first k answers of Q obtained by processing S T are the k answers for the k -GPM. In this way, N can be simplified as below: where sel T is the average number of twig answers of T that are needed to obtain each answer of Q .Let N Q and N T denote the total number of answers of Q and T respec-tively. With obove assumption, there is sel T = N T N Q . N Q and N T can be estimated based on existing work on graph pattern matching. Particularly, we use the pattern match estimation in [5]. In this section, we evaluate the performance of our proposed approach experimentally. Specifically, the baseline method is the adaption of the top-k join solution (Section 2.1), represented by join ,for k -GPM. For our twig query approach, we use the cost-based optimization to select the best t-query in order to instantiate Algorithm 1 for the k -GPM. And this method is denoted as twig* . In order to show the effectiveness of the t-query selection, we also compare the performance of Algorithm 1 with a number of randomly selected t-queries, denoted as random1 , random2 and so on. All those algorithms are implemented using C++ .Thevalueof c in Eq. 3 is set as 0 . 2 . We show the elapsed time and required memory for the four cyclic queries Q 1 , Q 2 , Q 3 ,and Q 4 , according to these k values: 10, 50, 100, 150 and 200. The structures of these queries are shown in Fig. 5.

We experimented on the real dataset, DBLP 2 . We construct a  X  X o-authorship graph X  based on the data. This graph contains 840, 688 nodes (authors) and 3,078,263 edges. An edge between two nodes indicates that the two corresponding authors have co-authored one or more papers. As discussed in [18], co-authorship graphs capture many key fea-tures of social networks. We treat this gr aph as a social network, and use the method described in [18] to compute its edge weight. We assign node labels based on text clus-tering algorithms. In detail, we use the paper titles as the text feature for all authors. One author X  X  text feature can come from multiple titles from that author. We group all authors into 100 clusters. For each author , we assign the cluster ID as its node label.
We conducted all experiments on a PC with a 3.4GHz processor, 180G hard disk and 2GB main memory running Windows XP.
 Compare to the Baseline Method. This test is to compare the performance of our twig query approach ( twig* ) with the baseline method, namely the top-k join solution for top-k graph matching ( join ). Fig. 6 shows this test. In general, twig* outperforms join noticeabley. For all queries and most k values, join needs much more time and memory, than twig* . Moreover, the time and memory for join increase significantly as k increases. But both the time and memory of twig* increase quite slower. For example, in Fig. 6 (c) ( Q 3 ), when k increases from 10 to 200 , the elapsed time of join increases from 1 , 005 milliseconds to 180 , 142 milliseconds. In contrast, the time of twig* is from 4 , 013 to 4 , 648 milliseconds. join even cannot finish Q 4 in 2 hours when k equals 100 or a larger value (Fig. 6 (d)). Only when k is as small as 5 and 10 , there are some cases that join can outperform twig* .However, join become quite slow when k takes a relatively larger value. It is because join has to perform a huge number of joins with those seen tuples in memory when k is 10 , 50 or above. Moreover, it has to keep many seen tuples in memory so as k increase, the memory consumption of join also becomes larger and larger as k increases. For example, in Fig. 6 (h), join needs 34 and 56 megabytes of memory for Q 4 when k =10 and k =50 . twig* only needs 16 megabytes of memory for all k values. Performance of our Cost-based Optimization. Fig. 7 shows the elapsed time of twig* as compared to a number of randomly selected t-queries. We can see that twig* is the fastest t-query in solving k -GPM of all graph queries. Take Q 4 as an example, twig* spends 5,920 milliseconds to 6,369 milliseconds, while random1 needs 6,112 millisec-onds to 6,589 m illiseconds and random2 needs 9,481 millisec onds and 35,277 mil-liseconds. The effectiveness of our cost -based optimization can be successfully verified. Graph pattern matching is a long investigated topic for database applications [25,23]. Two lines of work can be identified in terms of the underlying graphs to be searched. One is a large collection of small graphs of hundreds of nodes, where the frequent subgraph mining is studied extensively in recent years, such as [29,28,22,30] to name a few.

Our work belongs the other line, which deals graph searching over a large standalone data graph [2,14,3,5,26,12,32,31]. We can further categorize the work in this line work according to whether there are user-given query graph. [2,14,31] do not have a user-given query graph. [2,14] belong to the so-called keyword search over graphs, which can find the top-k connected trees in the graph such that all user-given keywords are included in the trees. We omit the large number of other studies in this direction for we are searching for cyclic graphs that match user-given graph queries. The recent work [31] even studied frequent subgraphs within a large graph, where the answer structure are also not fixed.

There are many work where the query graph [3,5,24,26,32,11,10] is used. Our prob-lem is the same with them. However, these work does not consider finding top-k an-swers of a graph query. They do not directly work on k -GPM either, becau se computing all answers at first and then sort the results to obtain the k best ones can be very expen-sive. Our solution is closely related to [12]. However, [12] is to find top-k answers for twig queries. A large amount of work has been done for top-k query processing. Refer to [17] for a survey. The top-k join algorithm [17] can be applied to our problem, which we examined in this paper. In this paper, we propose a new top-k graph pattern matching problem, in which the main difference to existing work is that the query is cyclic and can be complex. We investigate a baseline solution using the existing top-k processing technique, which is difficult to successfully solve this problem. We propose a new twig query approach which is economic and scalable for this problem. To find the best twig query in solving a given graph query, we also propose a cost-based optimization for twig query selection. We conducted extensive performance studies using a real dataset, and we confirm the efficiency of our proposed approach.
 Acknowledgments. This work is supported by NSFC (Grant No. 61103049) and Shenzhen Research Fund (Grant No. JC201005270342A). Xianggang Zeng is supported by Shenzhen New Industry Development Fund (Grant No. CXB201005250021A). Shengzhong Feng is supported by Special Funds of The Chinese Academy of Sciences (Grant No. XDA06010500).

