 Quoc Tran Dinh quoc.trandinh@epfl.ch Anastasios Kyrillidis anastasios.kyrillidis@epfl.ch Volkan Cevher volkan.cevher@epfl.ch Sparse inverse covariance matrix estimation is a key step in graph learning. To understand the setup, let us consider learning a Gaussian Markov random field (GMRF) of p nodes/variables from a dataset D := { x 1 , x 2 ,..., x m } , where x j  X  D is a p -dimensional random vector, drawn from the Gaussian distribution N (  X  ,  X  ). Let  X  =  X   X  1 be the inverse covariance (or the precision) matrix for the model. To satisfy the con-ditional independencies with respect to the GMRF,  X  must have zero in  X  ij corresponding to the absence of an edge between nodes i and j (Dempster, 1972). To learn the underlying graph structure from  X   X  1 , one can use the empirical covariance matrix b  X  . Unfortu-nately, this approach is fundamentally ill-posed since the empirical estimates converge to the true covariance at a (1 / the true graph structure accurately requires an over-whelming number of samples. Unsurprisingly, we usu-ally have fewer samples than the ambient dimension, compounding the difficulty of estimation.
 While the possible GMRF structures are exponentially large, the most interesting graphs are rather simple with a sparse set of edges. Provable learning of such graphs can be achieved by ` 1 -norm regularization in the maximum log-likelihood estimation: where  X  &gt; 0 is a parameter to balance the fidelity er-ror and the sparsity of the solution and vec is the vectorization operator. Here, f (  X  ) corresponds to the empirical log-likelihood and g (  X  ) is the sparsity-promoting term. Under this setting, the authors in (Ravikumar et al., 2011) prove that m = O ( d 2 log p ) is sufficient for correctly estimating the GMRF, where d is the graph node-degree. Moreover, the above formu-lation still makes sense for learning other graph mod-els, such as the Ising model, due to the connection of f (  X  ) to the Bregman distance (Banerjee et al., 2008). Numerical solution methods for solving problem (1) have been widely studied in the literature. For in-stance, in (Banerjee et al., 2008; Scheinberg &amp; Rish, 2009; Scheinberg et al., 2010; Hsieh et al., 2011; Rolfs et al., 2012; Olsen et al., 2012) the authors proposed first order primal and dual approaches to (1) and used state-of-the-art structural convex optimization tech-niques such as coordinate descent methods and Lasso-based procedures. Alternatively, the authors in (Hsieh et al., 2011; Olsen et al., 2012) focused on the second order methods and, practically, achieved fast meth-ods with a high accuracy. In (Scheinberg et al., 2010; Yuan, 2012), the authors studied alternating direction methods to solve (1), while the work in (Li &amp; Toh, 2010) is based on interior point-type methods. Algo-rithmic approaches where more structure is known a priori can be found in (Lu, 2010).
 The complexity of the state-of-the-art approaches mentioned above is dominated by the Cholesky decom-position ( O ( p 3 ) in general), which currently creates an important scalability bottleneck. This decomposition appears mandatory since all these approaches employ a guess-and-check step-size selection procedures to en-sure the iterates remain in the positive definite (PD) cone and the inversion of a p  X  p matrix, whose theo-retical cost normally scales with the cost of p  X  p ma-trix multiplications ( O ( p 3 ) direct, O ( p 2 . 807 ) Strassen, and O ( p 2 . 376 ) Coppersmith-Winograd). The inversion operation is seemingly mandatory in the optimization of (1) since the calculation of the descent direction  X  f (  X  i ) :=  X   X   X  1 i + b  X  requires it, and quadratic cost approximations to f (  X  ) also need it. Via Cholesky decompositions, one can first check if the current solu-tion satisfies the PD cone constraint and then recycle the decomposition for inversion for the next iteration. Contributions: We propose a new proximal-Newton framework for solving the general problem of (1) by only assuming that f (  X  ) is self-concordant. Our algo-rithm consists of two phases. In Phase 1, we apply a damped proximal Newton scheme with a new, analytic step-size selection procedure, and prove that our objec-tive function always decreases at least a certain fixed amount. As a result, we avoid globalization strategies such as backtracking line-search or trust-region proce-dures in the existing methods. Moreover, our step-size selection is optimal in the sense that it cannot be im-proved without additional assumptions on the problem structure. In Phase 2, we simply apply the full step proximal-Newton iteration as we get into its provable quadratic convergence region which we can compute explicitly. Moreover, we do not require any additional assumption such as the uniform boundedness of the Hessian as in (Lee et al., 2012).
 In the context of graph learning, we discuss a specific instance of our framework, which avoids Cholesky de-compositions and matrix inversions altogether . Hence, the per iteration complexity of our approach is domi-nated by the cost of p  X  p matrix multiplications. This is because ( i ) our analytic step-size selection procedure ensures the positive definiteness of the iterates doing away with global strategies such as line-search which demands the objective evaluations (via Cholesky), and ( ii ) we avoid calculating the gradient explicitly, and hence matrix inversion by a careful dual formulation. As a result, our approach is attractive for distributed and parallel implementations.
 Paper outline: In Section 2, we first recall some fundamental concepts of convex optimization and self-concordant functions. Then, we describe the basic op-timization set up and show the unique solvability of the problem. In Section 3 we outline our algorithmic framework and describe its analytical complexity. We also deal with the solution of the subproblems by ap-plying the new dual approach in this section. Section 4 presents an application of our theory to graph se-lection problems. Experimental results on real graph learning problems can be found in Section 5. Basic definitions: We reserve lower-case and bold lower-case letters for scalar and vector representation, respectively. Upper-case bold letters denote matri-ces. Let vec : R p  X  p  X  R p 2 be the vectorization op-erator which maps a matrix to a single column, and mat : R p 2  X  R p  X  p is the inverse mapping of vec which transforms a vector to a matrix. For a closed convex function f , we denote its domain by dom( f ), dom( f ) := { x  X  R n | f ( x ) &lt; +  X  X  .
 Definition 2.1 (Self-concordant functions (Definition 2.1.1, pp. 12, (Nesterov &amp; Nemirovski, 1994)) . A con-vex function h : R  X  R is ( standard ) self-concordant tion h : R n  X  R is self-concordant if, for any t  X  R the function  X  ( t ) := h ( x + t v ) is self-concordant for all x  X  dom( f ) and v  X  R n .
 Let h  X  C 3 (dom( f )) be a strictly convex and self-concordant function. For a given vector v  X  R n , the local norm around x  X  dom( f ) with respect to h (  X  ) is defined as k v k x := v T  X  2 h ( x ) v 1 / 2 the corresponding dual norm is given as k v k  X  x := v
T  X  2 h ( x )  X  1 v 1 / 2 . Let  X  : R  X  R + be a function defined as  X  ( t ) := t  X  ln(1 + t ) and  X   X  : [0 , 1]  X  R a function defined as  X   X  ( t ) :=  X  t  X  ln(1  X  t ). The func-tions  X  and  X   X  are both nonnegative, strictly convex and increasing. Based on (Nesterov, 2004)[Theorems 4.1.7 &amp; 4.1.8], we recall the following estimates: where (2) holds for all x , y  X  dom( f ), and (3) holds for all x , y  X  dom( f ) such that k y  X  x k x &lt; 1. Problem statement: In this paper, we consider the following structural convex optimization problem: where f ( x ) is a convex, self-concordant function and g ( x ) is a proper, lower semicontinuous and possibly nonsmooth convex regularization term. It is easy to certify that problem (1) can be transformed into (4) by using the tranformation x := vec (  X  ): f ( x ) :=  X  log det( mat ( x ))+tr( b  X mat ( x )) , mat ( x ) 0 , g ( x ) :=  X  k x k 1 and n := p 2 .
 Proximity operator: A basic tool to handle nons-mooth convex functions is the proximity operator: let g be a proper lower semicontinuous, possibly nons-mooth and convex in R n . We denote by  X  X  ( x ) the subdifferential of g at x . Let f be a self-concordant function and x  X  dom( f ) be fixed. We define P  X  x g ( u ) := nonexpansive mapping, i.e., Unique solvability of the problem: We generalize the result in (Hsieh et al., 2011) to show that problem (4) is uniquely solvable.
 Lemma 2.2. For some x  X  dom( F ) , let  X  ( x ) := x  X  of (4) exists and is unique.
 The proof of this lemma can be done similarly as Theo-rem 4.1.11, pp. 187 in (Nesterov, 2004). For complete-ness, we provide it in the supplementary document. Our algorithmic framework is simply a proximal-Newton method which generates an iterative sequence x x k +1 is computed as x k +1 = x k +  X  k d k , where  X  k  X  (0 , 1] is a step size and d k is the proximal-Newton-type direction as the solution to the subproblem: Here, Q ( d ; x k ) is the following quadratic surrogate of the function f around x k :
Q ( d ; x k ) := f ( x k )+  X  f ( x k ) T d + We denote d k the unique solution of Q ( x k ). The op-timality condition for Q ( x k ) is written as follows: Fixed-point characterization. For given x  X  dom( F ), if we define S ( x ) :=  X  2 f ( x ) x  X  X  X  f ( x ) then the unique solution d k of Q ( x k ) can be computed as lemma shows that the fixed point of R g is the unique solution of (4). The proof is straightforward, and is omitted.
 Lemma 3.1. Let R g be a mapping defined by (8) . Then x  X  is the unique solution of (4) if and only if x  X  is the fixed-point of R g , i.e., x  X  = R g ( x  X  ) . Lemma 3.1 suggests that we can generate an iterative sequence based on the fixed-point principle. Under certain assumptions, one can ensure that R g is con-tractive and the sequence generated by this scheme is convergent. Hence, we characterize this below. 3.1. Full-step proximal-Newton scheme Here, we show that if we start sufficiently close to the solution x  X  , then we can compute the next iteration x k +1 with full-step  X  k +1 = 1, i.e., where d k is the unique solution to Q ( x k ). We call this scheme the full-step proximal Newton (FPN) scheme. For any k  X  0, let us define We refer to this quantity as the proximal Newton decre-ment . The following theorem establishes the local quadratic convergence of the FPN scheme (9).
 Theorem 3.2. For a given x k , let x k +1 be the point generated by the full-step proximal Newton scheme (9) and  X  k be defined by (10) . Then, if  X  k &lt; 1  X  1 0 . 292893 , it holds that Consequently, the sequence x k FPN scheme (9) starting from x 0  X  dom( F ) such that  X  0  X   X   X   X   X  := 5  X  the unique solution of (4) at a quadratic rate. The proof of Theorem 3.2 can be found in the supple-mentary document. 3.2. Damped proximal Newton scheme We now establish that, with an appropriate choice of the step-size  X   X  (0 , 1], the iterative sequence x k generated by the damped proximal Newton scheme is a decreasing sequence, i.e., F ( x k +1 )  X  F ( x k )  X   X  (  X  ) whenever  X  k  X   X  , where  X  &gt; 0 is fixed. First, we show the following property for the new iteration x k +1 . Lemma 3.3. Suppose that x k +1 is a point generated by (12) . Then, we have provided that  X  k  X  k &lt; 1 .
 Proof. Let y k = x k + d k , where d k is the unique solu-tion of Q ( x k ). It follows from the optimality condition of (7) that there exists v k  X   X  X  ( y k ) such that Since f is self-concordant, by (3), for any x k +1 such
F ( x k +1 )  X  F ( x k ) +  X  f ( x k ) T ( x k +1  X  x k ) (15) Since g is convex,  X   X  [0 , 1], by using (14) we have g ( x k +1 )  X  g ( x k ) = g ((1  X   X  k ) x k +  X  k y k )  X  g ( x Now, substituting (16) into (15) and noting that x k +1  X  x k =  X  k d k we obtain the following result F ( x k +1 )  X  F ( x k )+  X   X  (  X  d k which is indeed (13), provided that  X  k  X  k &lt; 1. The following theorem provides an explicit formula for the step size  X  k .
 Theorem 3.4. Let x k +1 be a new point generated by the scheme (12) and  X  k be defined by (10) . Then, if we choose  X  k := (1 +  X  k )  X  1  X  (0 , 1] then Moreover, the step  X  k = (1 +  X  k )  X  1 is optimal. Proof. By the choice of  X  k , we have  X  k  X  k = (1 +  X  )  X  1  X  k &lt; 1. By using the estimate (13) we have F ( x k +1 )  X  F ( x k )  X  (1 +  X  k )  X  1  X  2 k +  X   X  (1 +  X  inequality implies (18). Finally, we note that the func-tion  X  (  X  ) :=  X  X  (1 +  X  ) + ln(1  X   X  X  ) is maximized at  X  k = (1 +  X  k )  X  1 , showing that  X  k is optimal. Theorem 3.4 shows that the damped proximal Newton scheme generates a new point x k +1 that decreases F of (4) at least  X  (  X  ) at each iteration, whenever  X  k  X   X  . Quadratic convergence: Similar to the full-step proximal-Newton scheme (9), we can also show the quadratic convergence of the damped proximal-Newton scheme (12). This statement is summarized in the following theorem.
 Theorem 3.5. For a given x k  X  dom( F ) , let x k +1 be a new point generated by the scheme (12) with  X  k := (1 +  X  k )  X  1 . Then, if  X  k &lt; 1  X  1  X  Hence, the sequence x k  X  k = (1 +  X  k )  X  1 starting from x 0  X  dom( F ) such that  X  0  X   X   X   X   X  := 0 . 221876 locally converges to x  X  , the unique solution of (4) at a quadratic rate.
 The proof of Theorem 3.5 can be found in the supple-mentary document. Note that the value  X   X  in Theorem 3.5 is larger than in Theorem 3.2. However, both val-ues are not tight. 3.3. The algorithm pseudocode As proved by Theorems 3.4 and 3.5, we can use the damped proximal-Newton scheme to build the algo-rithm. Now, we present a two-phase proximal-Newton algorithm. We first select a constant  X   X  (0 ,  X   X  ]. At each iteration, we compute the new point x k +1 by us-ing the damped proximal Newton scheme (12) until we get  X  k  X   X  . Then, we switch to the full-step New-ton scheme and perform it until the convergence is achieved. These steps are described in Algorithm 1. Note that the radius  X  of the quadratic convergence region in Algorithm 1 can be fixed at its upper bound  X   X  . The maximum number of iterations j max and k max can also be specified, if necessary. 3.4. Iteration-complexity analysis We analyze the complexity of Algorithm 1 by separat-ing Phase 1 and Phase 2. This analysis is summarized in the following theorem.
 Theorem 3.6. The maximum number of itera-tions required in Phase 1 does not exceed j max := j (4) . The maximum number of iterations required in Phase 2 to obtain  X  k  X   X  does not exceed k max := O ln ln c  X  , where c := (1  X  4  X  + 2  X  2 )  X  1 &gt; 0 . Proof. Since  X  j  X   X  for all j  X  0 in Phase 1, it follows from Theorem 3.4 that F ( x j +1 )  X  F ( x j )  X   X  (  X  ). By induction we have F ( x  X  )  X  F ( x j max ) Algorithm 1 ( Proximal Newton algorithm ) Initialization:
Require a starting point x 0  X  dom( F ) and a con-stant  X   X  (0 ,  X   X  ], where  X   X  := (5  X 
Phase 1: ( Damped proximal Newton iterations ). for j = 0 to j max do end for Phase 2: ( Full-step proximal Newton iterations ).
Set x 0 := x j from Phase 1 and choose a desired accuracy  X  &gt; 0. for k = 0 to k max do end for F ( x  X  )] / X  (  X  ). Hence, we can fix Let c := (1  X  4  X  + 2  X  2 )  X  1 &gt; 0. By induction, it follows from Theorem 3.2 that we have  X  k  X  ( c ) 2 k  X  1  X  2 ( c ) 2 k  X  1  X  2 k  X   X  , which leads to k  X  O (ln ln( c/ X  )). Hence, we can show that k max := O (ln ln( c/ X  )). We note that we do not use j max as a stopping criterion of Phase 1 of Algorithm 1. In practice, we only need an upper bound of this quantity. If we fix  X  at  X   X  then c  X  4 . 561553 and the complexity of Phase 2 becomes 3.5. Dual solution approach of the subproblem In this subsection we consider a specific instance of tion of the convex subproblem Q ( x k ). For notational convenience, we let q k :=  X  f ( x k ), H k :=  X  2 f ( x Then, the convex subproblem Q ( x k ) can be written equivalently as min By using the min-max principle, we can write (20) as Solving the inner minimization in (21) we obtain: convex. One can apply the fast projected gradient methods with linear convergence rate in (Nesterov, 2007; Beck &amp; Teboulle, 2009) for solving this problem. In order to recover the solution of the primal subprob-lem Q ( x k ), we note that the solution of the paramet-ric minimization problem in (21) is given by y  X  k ( u ) := x of (22). We can recover the primal proximal-Newton search direction d k of the subproblem Q ( x k ) as To compute the quantity  X  k := d k 1, we use (23) such that Note that computing  X  k by (24) requires the inverse of the Hessian matrix  X  2 f ( x k ). In this section, we customize the theory framework of Algorithm 1 by using only Phase 1 to solve the graph selection problem (1).
 Quantification: For clarity, we retain the matrix variable form as presented in (1). We note that f (  X  ) is a self-concordant convex function, while g (  X  ) is a proper, lower semicontinuous and nonsmooth convex function. Thus, our theory presented above can be ap-plied to (1). Given the current estimate  X  i 0, we have  X  f (  X  i ) = b  X   X   X   X  1 i and  X  2 f (  X  i ) =  X   X  1 Under this setting, the dual subproblem (22) becomes:
U  X  i = arg min where e Q i :=  X   X  1 [  X  i b  X  X  i  X  2  X  i ]. Given the dual so-lution U  X  i of (25), the primal proximal-Newton search direction (i.e. the solution of Q ( x k )) is computed as The quantity  X  i defined in (24) can be computed by where W i :=  X  i ( b  X  +  X  U  X  i ).
 The graph learning algorithm: Algorithm 2 sum-marizes the proposed scheme for graph selection. Algorithm 2 ( Dual PN for graph selection (DPNGS) ) Input: Matrix  X  0 and a given tolerance  X  &gt; 0. Output: An approximate solution  X  i of (1).

Initialization: Find a starting point  X  0 0. for i = 0 to i max do end for Overall, Algorithm 2 does not require any matrix in-version operation. It only needs matrix-vector and matrix-matrix calculations, making the parallelization of the code easier. We note that due to the predefined step-size selection  X  i in Algorithm 1 we do not need to do any backtracking line-search step. This advantage can avoid some overhead computation regarding the evaluation of the objective function which is usually expensive in this application.
 Arithmetical complexity analysis: Since the ana-lytical complexity is provided in Theorem 3.6, we only analyze the arithmetical complexity of Algorithm 2 here. As we work through the dual problem, the pri-mal solution is dense even if majority of the entries are rather small (e.g., smaller than 10  X  6 ). 1 Hence, the arithmetical complexity of Algorithm 2 is dominated by the complexity of p  X  p matrix multiplications. For instance, the computation of e Q i and  X  i re-quire basic matrix multiplications. For the compu-tation of  X  i , we require two trace operations: tr( W i in O ( p ) time-complexity and tr( W 2 i ) in O ( p 2 complexity. We note here that, while W i is a dense matrix, the trace operation requires only the compu-tation of the diagonal elements of W 2 i . Given  X  i ,  X  and  X  i ,  X  i +1 requires O ( p 2 ) time-complexity. To compute (25), we can use the fast projected gradient method (FPGM) (Nesterov, 2007; Beck &amp; Teboulle, 2009) with step size 1 /L where L is the Lips-chitz constant of the gradient of the objective function in (25). It is easy to observe that L i :=  X  2 max where  X  max (  X  i ) is the largest eigenvalue of  X  i sparse  X  i , we can approximately compute  X  max (  X  i ) is O ( p 2 ) by using iterative power methods (typically, 10 iterations suffice). The projection onto k vec ( U ) k  X  1 clips the elements by unity in O ( p 2 ) time. Thus, the time overhead due to acceleration is within O ( p 2 ). Given the above, FPGM requires a constant number of iterations k max , which is independent of the dimension p , to achieve an  X  in solution accuracy. Overall, the time-complexity for the solution in (25) is O ( k max M ), where M is the cost of matrix multiplication.
 Remark 4.1 (Parallel and distributed implementa-tion ability) . In Algorithm 2, the outer loop does not require any Cholesky decomposition or matrix inver-sion. Suppose that the fast projected gradient method is applied to solve the dual subproblem (25) . The main operation needed in the whole algorithm is matrix-matrix multiplication of the form  X  i U X  i , where  X  and U are symmetric positive definite. This operation can naturally be computed in a parallel or distributed manner. For more details, we refer the reader to Chap-ter 1 in (Bertsekas &amp; Tsitsiklis, 1989). In this section we test DPNGS (Algorithm 2 in Section 4) and compare it with the state-of-the-art graph selec-tion algorithm QUadratic Inverse Covariance (QUIC) algorithm (Hsieh et al., 2011) on a real world data set. The QUIC algorithm is also a Newton-based method, which in addition exploits the sparsity in solving its primal subproblems. We note that QUIC was imple-mented in C while our codes in this work are imple-mented in MATLAB.
 Implementation details: We test DPNGS on MAT-LAB 2011b running on a PC Intel Xeon X5690 at 3.47GHz per core with 94Gb RAM. To solve (25), we use the FPGM scheme as detailed in the sup-plementary material. We terminate FPGM if either k U k +1  X  U k k F  X   X  in max {k U k k F , 1 } or the number of iterations reaches k max where  X  in &gt; 0 and k max will be specified later. The stopping criterion of the outer loop is  X  i  X  10  X  6 and the maximum number of outer iterations is chosen as i max := 200. We test the follow-ing three variants of DPNGS: DPNGS [  X  in = 10  X  6 and k max = 1000], DPNGS(5) [  X  in = 10  X  4 and k max = 5], and DPNGS(10) [  X  in = 10  X  5 and k max = 10]. The DP-NGS(5) and DPNGS(10) variants can be considered as inexact variants of DPNGS.
 Real-world data: In our experiments, we use the real biology data preprocessed by (Li &amp; Toh, 2010) to compare the performance of the DPNGS variants above and QUIC (Hsieh et al., 2011) for 5 problems: Lymph ( p = 587), Estrogen ( p = 692), Arabidopsis ( p = 834), Leukemia ( p = 1225) and Hereditary ( p = 1869). This dataset can be found at http://ima.umn. edu/ ~ maxxa007/send_SICS/ .
 Convergence behaviour analysis: First, we verify the convergence behaviour of Algorithm 2 by analyzing the quadratic convergence of the quantity  X  i , where  X  i is defined by (27). Our analysis is based on the Lymph problem with p = 587 variables. We note that  X  i reveals the weighted norm of the proximal-gradient mapping of the problem. The convergence behaviour is plotted in Figure 1 for three different values of  X  , namely  X  = 0 . 25,  X  = 0 . 1,  X  = 0 . 05 and  X  = 0 . 01. Figure 1 shows that whenever the values of  X  i gets into the quadratic region, it converges with only a few iterations. As  X  becomes smaller, we need more itera-tions to get into the quadratic convergence region. Next, we illustrate the step-size  X  i of DPNGS. Fig-ure 2 shows the increasing behaviour of the step size on the same dataset. Since  X  i = (1 +  X  i )  X  1 , it con-verges quickly at the last iterations. We also com-pare the objective value decrement of both algorithms in y -log-scale in Figure 3. Using the same tolerance level, we reach the objective value  X  4 . 141662  X  10 after 69 iterations while QUIC needs 159 iterations. Moreover, Figure 3 shows the quadratic convergence of our approach in contrast to QUIC; the latter re-quires many more iterations to slightly improve the objective. Figure 4 is the histogram of the solution in log scale reported by DPNGS and QUIC. Due to the dual solution approach, DPNGS reports an approxi-mate solution with similar sparsity pattern as the one of QUIC. However, our solution has many small num-bers instead of zero as in QUIC as revealed in Figure 4. This seems to be the main weakness of the dual ap-proach : it obviates matrix inversions by avoiding the primal problem, which can return solutions with exact zeros thanks to its soft-thresholding prox-operator. As a result, DPNGS carries around extremely small co-efficients (almost of them smaller than 5  X  10  X  5 ) often preventing it from achieving the same objective level as the numerical experiments on the full data set shows. At the same time, since the approach does not rely on coordinate descent on active sets, it appears much less sensitive to the choice of  X  . This could be an ad-vantage of DPNGS in applications requiring smaller  X  values. If exact sparsity is needed, then a single primal iteration suffices to remove the small coefficients. Numerical experiments on the full dataset: We now report the numerical experiments on the biology dataset and compare the methods. We test both algo-rithms with four different values of  X  , namely  X  = 0 . 25,  X  = 0 . 1,  X  = 0 . 05 and  X  = 0 . 01. The numerical re-sults are reported in Table 1. Since QUIC exceeds the maximum number of iterations i max = 200 and takes a long time, we do not report the results corre-sponding to  X  = 0 . 01. We note again that at the time of this ICML submission, our implementation is done in MATLAB, while QUIC code is (carefully!) imple-mented in C. Hence, our timings may improve.
 We highlight several interesting results from Table 1. First, QUIC obtains the highest accuracy results in most cases, which we attribute to the  X  X ack of soft thresholding X  in our algorithm. As the DPNGS algo-rithm carries around a score of extremely small num-bers (effectively making the solution dense in the nu-merical sense), its solutions are close to QUIC X  X  solu-tions within numerical precision. Moreover, QUIC is extremely efficient when the  X  value is large, since it exploits the sparsity of the putative solutions via co-ordinate descent. Unsurprisingly, QUIC slows down significantly as  X  is decreased.
 DPGNS(5) and DPNGS(10) can obtain near optimal solutions quite rapidly. In particular, DPNGS(10) seems to be the most competitive across the board, of-ten taking a fraction of QUIC X  X  time to provide a very close solution. Hence, one can expect these schemes to be used for initializing other algorithms. For in-stance, QUIC can be a good candidate. We observed in all cases that, in the first few iterations, QUIC per-forms several Cholesky decompositions to stay within the positive definite cone. As the complexity of such operation is large, our step-size selection within QUIC or a DPNGS(10) initialization can be helpful. In this paper, we present the new composite self-concordant optimization framework. As a concrete ap-plication, we demonstrate that graph learning is possi-ble without any Cholesky decompositions via analytic step-size selection as well as without matrix inversions via a careful dual formulation within our framework. By exploiting the self-concordance in the composite graph learning objective, we provide an optimal step-size for this class of composite minimization with prox-imal Newton methods. We show that within the dual formulation of the Newton subproblem, we do not need to explicitly calculate the gradient as it appears in a multiplication form with the Hessian. Thanks to the special structure of this multiplication, we avoid matrix inversions in graph learning. Overall, we ex-pect our optimization framework to have more appli-cations in signal processing/machine learning and be amenable to various parallelization techniques, beyond the ones considered in the graph learning problem. Banerjee, O., El Ghaoui, L., and d X  X spremont, A.
Model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data.
The Journal of Machine Learning Research , 9:485 X  516, 2008.
 Beck, A. and Teboulle, M. A Fast Iterative Shrinkage-
Thresholding Algorithm for Linear Inverse Prob-lems. SIAM J. Imaging Sciences , 2(1):183 X 202, 2009.
 Bertsekas, D.P. and Tsitsiklis, J. N. Parallel and dis-tributed computation: Numerical methods . Prentice Hall, 1989.
 Boyd, S. and Vandenberghe, L. Convex Optimization . University Press, Cambridge, 2004.
 Dempster, A. P. Covariance selection. Biometrics , 28: 157 X 175, 1972.
 Hsieh, C. J., Sustik, M.A., Dhillon, I.S., and Raviku-mar, P. Sparse inverse covariance matrix estimation using quadratic approximation. Advances in Neu-tral Information Processing Systems (NIPS) , 24:1 X  18, 2011.
 Lee, J.D., Sun, Y., and Saunders, M.A. Proxi-mal newton-type methods for convex optimization. Tech. Report. , pp. 1 X 25, 2012.
 Li, L. and Toh, K.C. An inexact interior point method for l 1-regularized sparse covariance selection. Math-ematical Programming Computation , 2(3):291 X 315, 2010.
 Lu, Z. Adaptive first-order methods for general sparse inverse covariance selection. SIAM Journal on
Matrix Analysis and Applications , 31(4):2000 X 2016, 2010.
 Nesterov, Y. Introductory lectures on convex optimiza-tion: a basic course , volume 87 of Applied Optimiza-tion . Kluwer Academic Publishers, 2004.
 Nesterov, Y. Gradient methods for minimizing com-posite objective function. CORE Discussion paper , 76, 2007.
 Nesterov, Y. and Nemirovski, A. Interior-point Poly-nomial Algorithms in Convex Programming . Society for Industrial Mathematics, 1994.
 Olsen, P.A., Oztoprak, F., Nocedal, J., and Rennie,
S.J. Newton-like methods for sparse inverse covari-ance estimation. Optimization Online , 2012.
 Ravikumar, P., Wainwright, M. J., Raskutti, G., and
Yu, B. High-dimensional covariance estimation by minimizing l1-penalized log-determinant divergence. Electron. J. Statist. , 5:935 X 988, 2011.
 Rolfs, B., Rajaratnam, B., Guillot, D., Wong, I., and Maleki, A. Iterative thresholding algorithm for sparse inverse covariance estimation. In Advances in Neural Information Processing Systems 25 , pp. 1583 X 1591, 2012.
 Scheinberg, K. and Rish, I. Sinco-a greedy coordinate ascent method for sparse inverse covariance selection problem. preprint , 2009.
 Scheinberg, K., Ma, S., and Goldfarb, D. Sparse in-verse covariance selection via alternating lineariza-tion methods. arXiv preprint arXiv:1011.0097 , 2010.
 Yuan, X. Alternating direction method for covariance selection models. Journal of Scientific Computing ,
