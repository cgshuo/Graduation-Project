
In this paper, we propose a framework to build predic-tion models from data streams which contain both labeled and unlabeled examples. We argue that due to the increas-ing data collection ability but limited resources for labeling, stream data collected at hand may only have a small num-ber of labeled examples, whereas a large portion of data re-main unlabeled but can be beneficial for learning. Unleash-ing the full potential of the unlabeled instances for stream data mining is, however, a significant challenge, consider that even fully labeled data streams may su ff er from the concept drifting, and inappropriate uses of the unlabeled samples may only make the problem even worse. To build prediction models, we first categorize the stream data into four di ff erent categories, each of which corresponds to the situation where concept drifting may or may not exist in the labeled and unlabeled data. After that, we propose a rela-tional k-means based transfer semi-supervised SVM learn-ing framework (RK-TS 3 VM), which intends to leverage la-beled and unlabeled samples to build prediction models. Experimental results and comparisons on both synthetic and real-world data streams demonstrate that the proposed framework is able to help build prediction models more ac-curate than other simple approaches can o ff er.
Due to the increasing availability of data recording and transmission techniques, applications such as data ware-housing and sensor networking are facing dynamic data streams instead of static data sets. Such dynamic natures of data streams raise two fundamental challenges for data mining research: (1) large and continuous data volumes and (2) evolving or drifting of the concepts (or patterns) under-neath the data. Motivated by the two challenges, a lot of work exists for association rule mining [8], clustering [1], and building prediction models [4, 7, 12, 16, 15].
From classification perspective, two sets of solutions ex-ist for building prediction models from data streams: incre-mental learning [4] and ensemble learning [12, 9, 16, 15]. The former uses new data to update the models trained from historical stream data so the learning process is able to scale up to large data volumes as well as adapt to the changing concepts. Ensemble learning, on the other hand, trains a number of base models from a small portion of stream data (i.e., a data chunk), and combines all base models to form an ensemble classifier for pred iction. For either approach, one presumption is that the underlying stream data must be fully labeled. In practice, labeling training examples is a costly procedure which requires full attention and intensive investigation on the instances. For stream data with con-tinuous data volumes, this becomes a huge burden or even infeasible to realize.

Consider a bank fraud detection center which audits daily credit card transactions to determine high risk or fraudulent transactions. In order to build an automatic fraud prediction model, it is essential to let banking experts pro-vide (label) a number of fraud transactions as training sam-ples. The labeling ability the experts can o ff er is rather lim-ited and probably no bank is willing to pay experts to man-ually label every single transaction, assuming that 10,000 transactions may arrive on a daily basis. A more practical solution is to label a small portion, say 1% or 5%, of trans-actions, but keep the rest of the transactions unlabeled. Due to the missing of the labels, none of the existing stream min-ing algorithms is able to utilize such unlabeled data to help train fraud prediction models.

Indeed, just because stream data have large volumes it does not necessarily mean that mining algorithms are able to utilize them all. Hiding behind the large / continouse data volumes of the stream data is the reality that only a small portion of samples are actually labeled. Unfortunately, al-though many methods exist for mining data streams, very few attempts have been made to address unlabeled sam-ple issue. For static data sets, active learning and semi-supervised learning are two common approaches to solve the problem, where the former intends to reduce the label-ing cost and the latter directly utilizes the unlabeled sam-ples to boost the learning. In [16], Zhu et al. proposed an active learning framework to mi nimize the labeling cost for stream data, and the main goal is to select the most impor-tant sample for labeling such that the classifiers built from the stream data can gain maximum prediction accuracies.
A recent work [10] also addresses the limited training ex-ample problem for stream data by using semi-supervised clustering techniques. But no work currently exists to help understanding the impact of the unlabeled samples on the concept drifting of the data streams.

To build prediction models from stream data, one impor-tant task is to identify and emphasize on historical examples which share identical or similar distributions to the test data (usually the stream data at the next time point). This prob-lem, in practice, is di ffi cult to solve given that we may not have any prior knowledge on the test data and we also do not know when and where the concept drifting may occur [6]. Consequently, most stream mining methods take the assumption that data which are temporally close are also relevant to each other at the concept level. So if we can separate data streams into chunks with the assumption that instances within a chunk share identical distributions (e.g., no concept driting), the most recent data chunk ( up-to-date chunk ) can be used to train classification models to predict instances yet to arrive (i.e, yet-to-come chunk )[12,9,15].
Although this assumption is popularly accepted in data min-ing research, for data stream with both labeled and unla-beled samples (referred to as mixed stream in this paper), samples within one data chunk may not share an identical distribution. Consider that even fully labeled stream data are su ff ering from the concept drifting problem, the exis-tence of unlabeled samples only makes the learning from data stream even more challenging. Answers to the follow-ing three fundamental questions are needed before we can devise e ff ective algorithms for mixed data streams.  X  What are the typical concept drifting scenarios for data  X  How to categorize the mixed stream data in order to re- X  How to devise e ff ective solutions to handle di ff erent
In this paper, we report our research e ff orts in resolving the above three concerns. In short, we revisit the concept drifting scenarios by categorizing instances in mixed data streams into four types: (1) l abeled (Type I) and unlabeled (Type III) examples which have the same distributions as the yet-to-come data chunk; and (2) labeled (Type II) and unlabeled (Type IV) examples which have similar distri-butions to the yet-to-come data chunk. Based on the cat-egorizations, we propose a new Transfer Semi-Supervised SVM (TS 3 VM) model to learn from Types I, II, and III in-stances. A relational k -means (RK) based model is also pro-posed for learning from Type IV examples. By combining TS 3 VM and RK together, we propose a RK-TS 3 VM learn-ing framework which is able to fulfill the learning from the mixed data streams.
 tion 2 discusses data categorization for mixed data streams. We derive a new Transfer Semi-Supervised SVM (TS 3 VM) model and a relational k -means (RK) model in Section 3. Section 4 formulates the complete RK-TS 3 VM learning framework. Experimental results are reported in Section 5, and we conclude this paper in Section 6. chunk containing a number of labeled and unlabeled in-stances. At any specific time, the yet-to-come data chunk is dedicated as the target domain and the mining purpose is to build prediction model to accurately classify instances in the yet-to-come data chunk. For this purpose, the in-stances in the up-to-date chunk can be used to train pre-diction models, under the constraint that only a small por-tion of instances in the up-to-date chunk are labeled. To accurate describe the concept d rifting scenarios for mixed data streams, we can category the examples in the up-to-date chunk into following four types based on the samples X  distributions with respect to the distributions of the target domain (i.e, the yet-to-come chunk): (1) labeled and same distribution examples ( Type I Examples ), labeled and simi-lar distribution examples ( Type II Examples ), unlabeled and same distribution examples ( Type III Examples ), and unla-beled and similar distribution examples ( Type IV Examples ). shown in Fig. 1. Assume the yet-to-come data chunk (test chunk) is dedicated as the target domain, blue solid circles denote the labeled and same distribution examples (Type I), red solid circles denote the labeled and similar distribu-tion examples (Type II), blue hollow circles denote the un-labeled and same distribution examples (Type III), and red hollow circles denote the unlabeled and similar distribution examples (Type IV). Due to the temporal correlations [12] of the concepts, Types I and III data usually locate at the tail of the training chunk, which are close to the yet-to-come chunk. Types II and IV data usually locate at the head of
Figure 1. A conceptual view of the example type catego-the training chunk, which are relatively far away from the yet-to-come chunk.

After defining the four types of examples for mixed data streams, a following question is how to identify their sizes and locations in the up-to-date chunk (training chunk). In-tuitively, the percentage of labeled examples depends on the labeling speed the experts can o ff er and the number of the same distribution examples depends on the concept drifting rate. As shown in Fig. 1, Types I and III examples usu-ally locate at the tail of the up-to-date chunk while Types II and IV examples locate at the head of the up-to-date chunk. Consider a data stream which flows at a speed of n exam-ples per second, and its concept drifts with a possibility of c ,where0  X  c  X  1. At each time stamp, a training chunk D = { x speed of l examples ( l n ) per second. The number of the same distribution examples will have a reverse proportion to the concept drifting rate c with a constant coe ffi cient so we can estimate that about  X   X  c  X  1  X  n examples in chunk D have the same distributions as the test examples while the remaining (1  X   X   X  c  X  1 )  X  n examples will have similar dis-tributions as the test examples. Denote the size of the four types of examples as L 1 , L 2 , L 3 ,and L 4 respectively, we can estimate that their values are given in Eq. (1).

Ideally, we can exactly identify the sizes of the four types of examples by calculating Eq.(1). In practice, we may not have any prior knowledge on the concept drifting rate c ,so the above two equations can X  X  be used directly. In this case, an alternative solution is to a ssign an empirical small value to c . In our experiments in Section 5, the 10% examples at the tail of the training chunk are assigned as the same dis-tribution examples. In following sections we will propose detailed solutions for learning from the four types of data.
In this section, we introduce two learning models to han-dle the four types of examples in the mixed stream. More specifically, because Types I &amp; III examples are assumed to have the same distributions as the target domain, generic semi-supervised learning model [14, 3, 2] (we use SVM in this paper) can be used to directly train classifiers from Types I &amp; III data. For Type II samples, although they are assumed to have di ff erent distributions from the target domain, because they are label ed, we can employ transfer learning principle [5] to build models from Type II sam-ples. Consequently, our first objective is to devise a trans-fer semi-supervised learning based model (TS 3 VM) to train classifiers from Types I, II, &amp; III examples. For type IV ex-amples, because they are unlabeled and have di ff erent distri-butions from the target domain, we will propose a relational k -means based learning model (RK) to handle such data. The final learning framework (RK-TS 3 VM) (discussed in Section 4) will then combine the strength of TS 3 VM and RK to train prediction models from the mixed stream. fication as an examples to articulate our algorithm design. The four types of examples are simplified as follows: Type I data are denoted by T 1 = ( x 1 , y 1 ) ,..., ( x L x are denoted by T 2 = { ( x L L = L denoted by T 3 = { x L + 1 ,..., x L + U } ; and Type IV data ( N un-labeled examples) is denoted by T 4 = { x L + U + 1 ,..., 3.1 TS 3 VM Learning Model quentially incorporating instances in T 1 , T 2 ,and T 3 for learning. More specifically, we first formulate a generic SVM model by taking Type I examples into consideration. After that, we can formulate a transfer SVM model by tak-ing Type II examples into consideration. Finally, we can in-clude Type III examples and formulate the TS 3 VM model. 3.1.1 Learning from Type I Examples To learn from T 1 = { ( x 1 , y 1 ) ,..., ( x L model can be trained by maximizing the margin distance be-tween classes while minimizi ng the error rates as given in Eq. (2), where w is the projection direction, b is the classifi-cation boundary,  X  i is x i  X  X  error distance to b , and parameter C denotes the penalty of the examples inside the margin.
The SVM model given in Eq. (2) is a constrained con-vex optimization problem. To simplify the expression, the Hinge Loss function [3] in Fig. 2 can be used to transform Eq. (2) into an unconstrained convex optimization problem as defined by Eq. (3), where  X  = ( w , b )and f  X  ( x ) = The similar approaches have been commonly used to for-mulate the semi-supervised SVM model [2]. Figure 2. An illustration of the Hinge Loss function (a) 3.1.2 Learning from Types I &amp; II Examples Existing research has shown th at SVM is capable of iden-tifying optimal classification boundaries given su ffi cient number of training samples. In practice, the number of samples in T 1 may be very limited, which may leave clas-sical SVM incapable of learning the optimal classification boundaries. To overcome such deficiency, transfer learn-ing can use labeled samples in T 2 to refine the classification boundary by transferring the knowledge from T 2 to T 1 .An e ff ective way to transfer the knowledge between T 2 and T 1 is to take the problem as a multi-task learning procedure [5]. A common two-task learning SVM model on T 1 and T 2 can be formulated as in Eq. (4), where parameters C 1 and C 2 are the penalties on each task, v 1 and v 2 are the discrepan-cies between the global optimal decision boundary w and the local optimal decision boundary (i.e., w + v 1 for task 1 and w + v 2 for task 2).
In Eq. (4), parameters C 1 and C 2 controls the preference of the two tasks. If C 1 &gt; C 2 , then it prefers task 1 to task 2; otherwise, if C 1 &lt; C 2 , it prefers task 2 to task 1 (Our experimental results in Section 5 will further study the re-lationship between C 1 and C 2 ). By using the Hinge loss function, Eq. (4) can be transformed into an unconstrained form in Eq.(5) where  X  = ( w , v 1 , v 2 , b ), f  X  ( x ) for task 1 while f  X  ( x ) = ( w + v 2 ) x + b for task 2. 3.1.3 Learning from Types I, II, &amp; III Examples In addition to T 1 and T 2 , learning on T 3 may further im-prove the performance in the reas on that (i) labeled samples in T 1 and T 2 are only a small percentage of the whole train-ing examples; and (ii) T 3 contains a relatively large number of examples that come from the same distribution as the test examples, which can greatly help in di ff erentiating the gen-uine classification boundaries. In past several years, learn-ing from a large number of unlabeled examples has been extensively studied from semi-supervised learning perspec-tive. An e ff ective way to train a semi-supervised learning model is to find a classification boundary that achieves a maximum margin not only between labeled examples, but also unlabeled examples, i.e ., semi-supervised SVM [2] adds an extra term C  X  L + U i = L + 1 H ( | f  X  ( x i ) | classification of unlabeled ex amples which locate inside the marginasshowninEq.(6),
Thus, by adding the last term of Eq. (6) (which is used to learn from T 3 )ontoEq.(5)(whichisusedtolearnfrom T 1 and T 2 ), We finally derive the objective function of TS in Eq. (7), where  X  = ( w , v 1 , v 2 , b ),and f  X  ( x i for 1  X  i  X  L 1 , f  X  ( x i ) = ( w + v 2 ) x i + b for L f ( x i ) = wx i + b for L + 1  X  i  X  L + U .
Balance Constrain A possible di ffi culty of the TS 3 VM model is that all unlabeled examples in T 3 may be classified into one class with a very large margin, which may lead to poor performance. To solve the problem, an additional balance constraint should be added to ensure that unlabeled examples in T 3 should be assigned into both classes. In the case that we don X  X  have any prior knowledge about the class ratio in T 3 , a reasonable way [3] is to estimate its class ratio from T 1 and T 2 as in Eq.(8),
Thus by taking account of the balance constrain, we derive the TS 3 VM model in Eq.(9), where  X  = ( w , v 1 , v 2 , b ),and f  X  ( x i ) = ( w + v 1  X  i  X  L f ( x i ) = wx i + b for L + 1  X  i  X  L + U . 3.1.4 Solution to the TS 3 VM Objective Function As shown in Eq. (9), the objective function of TS 3 VM is a non-convex optimization problem, which is di ffi cult to find global minima especially for large scale prob-lems. To overcome this di ffi culty, we propose to solve this non-convex problem by using Concave-Convex Procedure (CCCP) which was developed by the optimization commu-nity in the last few decades [13, 3, 2]. CCCP method de-composes a non-convex function into the sum of a convex function and a concave function, and then approximates the concave part by using a linear function (a tangential approx-imation). By doing so, the whole optimization procedure can be carried out iteratively by solving a sequence of con-vex problem. Algorithm 1 describes the algorithm in detail. Algorithm 1 CCCP Algorithm
From the CCCP perspective, we can observe that the first four terms TS 3 VM are convex functions, whereas the last Symmetric Hinge Loss part C  X  L + U i = L + 1 H ( | f  X  ( x non-convex model. Thus, we will decompose and analysis the last part by using the CCCP met hod. To simplify the no-tation, we denote z i = f  X  ( x i ) , so the last part can be rewrit-ten as C  X  L + U i = L + 1 H ( | z i | ). Considering a specific z loss of generality, we denote it as z here), the Symmetric Hinge Loss on z can be denoted by J ( z ) as in Eq.(10),
Eq.(10) is a non-convex function, which can be spitted into a convex part and a concave part as in Eq.(11),
According to Algorithm 1, the next iterative point can be calculated by the approximation of the concave part J cav shown in Eq.(12), and then minimizing Eq.(13),
If at the current iteration z &lt; 0, then to the next iteration, the e ff ective loss on this point can be denoted as L ( z Eq.(14):
On the contrast, if z  X  0, then to the next iteration, the e ff ective loss on this point can be denoted as L ( z , + 1) in Eq.(15),
By doing so, at each iteration, when taking all the z i = f ( x i ) into considering, solving TS 3 VM model is equivalent to solving Eq.(16) under the balance constrain Eq.(8), where y i ( L + 1  X  i  X  L + U ) is the class label of the corresponding x i which has been assigned at the previous iteration. If y i &lt; 0, then Eq.(14), will be used to calculate the loss function, else Eq.(15), will be used to calculate the loss function. The detailed description of solving TS 3 VM is given in Algorithm 2.
 Algorithm 2 TS 3 VM Learning Model Kernel Trick The TS 3 VM model in Eq.(9) can be only used for linear classification. To identify non-linear classifica-tion boundaries, we can incorporate the kernel function into TS 3 VM by simply replacing the quadratic terms with a form of the sum of the mapped examples L + N i = 1  X  i  X  ( x i denotes a high dimensional feature mapping function [11]. Thus the optimization problem Eq.(9)) shifts to a new opti-mization problem with  X  i as the variables. T , T 2 ,and T 3 because examples in T 4 are unlabeled and have di ff erent distributions from the target domain. In this section, we introduce a relational k -means (RK) [17] based learning model which aims to construct some new features to the labeled examples by usin g information extracted from unlabeled instances in T 4 . An example of the RK learning is shown in Fig. 3, where instances in T 4 are fist clustered into a number of k clusters, G 1 ,  X  X  X  , G k based on a relational matrix built between T 1 and T 4 . After that, k new features f ( x i , G  X  )(  X  = 1  X  X  X  , k ) are added to each instance x construct a new data set T 1 by calculating the relationship between x i and each cluster center. By doing so, the new data set T 1 will contain information transferred from T 4 which can help build a more accurate prediction model.
Given L 1 examples in T 1 ,and N examples in T 4 .The purpose of the relational k -means clustering is to cluster in-stances in T 4 into a number of groups, by taking the rela-tionships between instances in T 1 and T 4 into consideration. Assume W  X  R L 1  X  N denotes the similarity matrix between T 1 and T 4 with each w i , j describing the similarity (which can be calculated according to t he Euclidian distance) be-tween instance x i in T 1 and instance x j in T 4 , for each clus-ter G  X  on W the average pair-wise similarities of all exam-ples in G  X  can be defined as in Eq. (17), where  X  G  X  denotes the average relationship vector of all of instance x j with respect to all examples in T 1 . The ob-jective of the relational k -means is to find k groups, G  X  = 1 ,  X  X  X  , k , such that the sum of the similarities is max-imized while the sum of variances is minimized as defined by Eq. (19), Explicitly solving Eq. (19) is di ffi cult, alternatively, we can employ a recursive hill-climbing search process to find so-lutions. Assume instances in T 4 are clustered into k clusters, G ,  X  X  X  , G G j will only change the cluster objective values J G i and J Therefore, in order to maximize Eq. (19), at each step t ,we can randomly select an instance x from a cluster G i ,and move x to cluster G j . We accept the movement only if the Inequity (20) reaches a larger value at step t + 1.
Based on the search process in Inequity (20), major steps of the relational k -means are listed in the Algorithm 3. Algorithm 3 Relational k -means Clustering Algorithm 4 lists the detailed procedures of the RK-TS 3 VM learning framework which is the combination of the TS 3 VM and RK learning models. Given a training chunk D , the first step is to identify the four types of ex-amples T 1 , T 2 , T 3 , T 4 based on the procedures discussed in Section 2. The second step is to construct a group of k feature vectors, denoted by  X  = {  X  1 ,  X  X  X  , X  k } , by applying RK to T 1 and T 4 . In the third and fourth steps, the k new features will be appended to each instances in T 1 , T 2 , T form three new sets denoted by T 1 , T 2 ,and T 3 respectively (Section 3.2). The fifth step is to build a TS 3 VM model F from T 1 , T 2 ,and T 3 (Section 3.1). At the last step, the fea-ture vectors  X  and the TS 3 VM model are combined as the final prediction model. For any instance x in the test chunk, RK-TS 3 VM first calculate k new features for x ,thenuses TS 3 VM model to predict a label for x .
In this section, we report experimental results and com-parisons of the proposed RK-TS 3 VM framework from the following three aspects: (1)the parameter setting for TS 3 VM; the algorithm performance with respect to the (2) concept drifting rate; and (3) the percentages of labeled ex-amples. Benchmark Methods: We implement RK-TS 3 VM in C ++ by using the VC ++ 6.0 developing environment. Because RK-TS 3 VM is a SVM based learning framework, we use Algorithm 4 RK-TS 3 VM Learning Framework the optimization package in the IMSL Fortran Library 1 to solve the TS 3 VM model in Eq.(9). To assess the algo-rithm performance, we use the conventional SVM model, the Transfer SVM (TrSVM) model (which is formulated following the mutli-task SVM model [5]), and the semi-supervsied SVM (S 3 VM) model on both labeled and unla-beled examples, as the benchmark models for comparisons. We build the SVM and TrSVM models on labeled samples and the S 3 VM model is trained on both labeled and unla-beled samples.
 Data Streams: A synthetic data stream and two real-world data streams are used in our experiments. The employment of the synthetic data stream is to assess the algorithm per-formance under di ff erent concept driftin g scenarios (which we usually don X  X  have control on the real-world streams). The real-world data streams provide the genuine algorithm performance in real-world environments.

In our experiment, the synthetic data stream is gener-ated as an infinite sequence of { ( x i , y i ) +  X  i = 1 is the feature vector and y i  X  X  X  1 , + 1 } is the class label. The feature values of x i are generated by a uniform distri-bution between 0 and 1, and the classification boundary is controlled by Eq.(21), where a i controls the decision boundaries. For each exam-ple x i ,if d i = 1 a i x i  X  a 0 , it is labeled as y i =+ y =  X  1. To simulate the labeling process, we randomly choose p percentage of examples and label them by using Eq.(21). To simulate the concept drifting, a i is given a prob-ability c (0  X  c  X  1) to evolve between a i and a i + 0 . 10% chance to reverse the direction. Besides that, we set a margin between the two classes. For the  X  + 1 X  class, the boundary is set to be d i = 0 a i x i + 0 . 05; while for the  X -1 X  class, the boundary is set to be d i = 0 a i x i  X  0 . 05. To keep class distributions relatively balanced, we enforce the clas-sification boundary around the central point of the feature space by setting a 0 = 1 2 d i = 1 a i . In order to make the deci-sion surface nonlinearly separable, 3% noise is introduced to the stream by randomly flopping the class labels of the selected instances.
 Real-world data streams Two real-world data streams, Sensor and Power Supply, downloaded from the Stream Data Mining Repository [18], are used in our experiments. Sensor stream contains information (temperature, humid-ity, light, and sensor voltage) collected from 56 sensors de-ployed in a lab environment. The data are read every 1-3 minutes from all sensors, and the whole stream contains information recorded over a 2 months period. The learn-ing task is to correctly identify the sensor ID (1 out of 56 sensors) purely based on the sensor data and the recording time. While the data flow over time, so do the concepts un-derlying the stream. For example, the lighting during the working hours is generally stronger than the night, and the temperature of specific sensors (conference room) may sud-denly rise during the meetings. Power Supply stream con-tains three year hourly power supply of an electricity com-pany from two sources: power supply from main grid and power transformed from other grids. The learning task of this stream is to predict which hour (1 out of 24 hours) the current power supply belongs to. The concept drifting in this stream is mainly driven by the issues such as the season, weather, or hour of a day. In our experiments, both streams are transferred into binary-class classification problems. 5.2 Parameter Setting for TS 3 VM
Four important parameters of the TS 3 VM objective func-tion in Eq.(9) are C 1 , C 2 , C ,and C  X  . From multi-task learn-ing perspective, C 1 and C 2 control the discrepancies be-tween the global optimal boundary w and the local optimal boundary w + v 1 ,and w + v 2 . If we assign a relative large value to C 1 (compared to C 2 ), the global optimal solution w will bias towards task 1, and vice versa. If we let C 1 C boundary of Task 1 becomes the global optimal boundary. The parameter C controls the penalty of the misclassified examples in T 1 and T 2 , and the last parameter C  X  controls the penalty of the misclassified examples in T 3 .
In Fig.4, we report the accuracies of TS 3 VM (the y -axis) with respect to di ff erent parameter values (the x -axis). All the results are based on the average over 100 data chunks each containing 500 examples (s ynthetic data stream). The concept drifting probability c is set to be 50%, and the per-centage of labeled examples p = 10%. From Figs.4(a) and (b), we can observe that increasing C 2 will result in a more noticeable performance dete rioration than increasing C . This is consistent our assumption that task 1 is supposed to comply with the same distributions as the target domain. The results in Figs.4(a) and (b) also suggest that a reason-able setting for C 1 and C 2 is to ensure that C 1 C Fig.4(c) we can observe that the performance of the TS 3 VM model has a significant improvement when C  X  increases from 0 (where the accuracy is about 0.93) to 1 (where the accuracy is above 0.96). That is to say, adding T 3 to learn a classifier will significantly improve the performance. Based on the above observations, in following experiments, we set C 1 to be 10 while the remaining to be 1.
In order to investigate RK-TS 3 VM X  X  sensitivity with re-spect to di ff erent probabilities of the concept drifting, we collect a set of results from 100 data chunks with chunk size 500, and the percentage of labeled examples p is set to be 10%. According to our description in Section 2, the sizes of the Types I, II, III, and IV examples are partially determined by the concept drifting probability value c .Al-though we have the power to control the probability value c for synthetic streams, we do not, however, know the proba-bility value c in real-world data streams. To bring the results one step closer to the real-world setting, we pretend that we do not know the probability value c andsimplytakeasmall portion (i.e., 10%) of instances at the tail of each training chunk as the Types I and III examples, and the rest of sam-ples are taken as the Types II and IV examples.

In Table 1, we report the algorithm performance with re-spect to di ff erent concept drifting probability c values (for synthetic stream). For any specific c value, RK-TS 3 VM out-performs its other peers and SVM also performs the worst. On the other hand, when co mparing each algorithm with respect to di ff erent concept drifting probability values, we can observe that all the four algorithms su ff er a loss in ac-curacy when c increases. This asserts that RK-TS 3 VM is relatively stable in handling data streams with high concept drifting probabilities. We believe that the robustness of the RK-TS 3 VM may be attributed to the following two facts. First, due to the di ffi cult of identifying the concept drift-ing points, we cannot determine the proper chunk size to ensure that the concepts within a data chunk remain sta-ble. So the concept drifting may actually happen within a data chunk. RK-TS 3 VM considers that each data chunk is subject to the concept drifting and only a small portion of instances at the tail of each chunk have the same dis-tribution as the target domain. This categorization closely simulates the real-world data stream, especially when the concept drifting probability value c is large. Second, the TS 3 VM and RK learning models can properly utilize the four types of examples by learning from them separately. Consequently, the RK-TS 3 VM is able to receive good per-formance even if it might not be able to accurately estimate the size of the Types I, III and Types II, IV examples. spect to di ff erent percentages of labeled examples. In the experiment, we use 100 da ta chunks each containing 500 examples. A fixed portion of 10% examples at the tail of the training chunk are selected as the same distribution ex-amples (Types I &amp; III). The results in Table 2 indicate that for a specific p value, S 3 VM and RK-TS 3 VM consistently outperforms other two methods which discard the unlabeled for learning. This is consistent with the common observa-tions made from the semi-supervised learning, and further concludes that utilizing unlabeled samples is also an e ff tive way for learning from data streams. When comparing four methods across di ff erent percentages of labeled exam-ples, we can observe that all four methods receive signifi-cant improvements, especially for SVM and TrSVM, when the value p increases. This observation indicates that pro-viding a su ffi cient number of labeled samples is crucial to ensure the accuracy of the prediction models, if learning has no mechanism of utilizing unlabeled samples or no un-labeled samples are available to boost the learning.
In Tables 3 and 4, we report the algorithm performance on two real-world data streams with di ff erent chunk sizes (with p = 10%). The results assert that comparing to its other peers, RK-TS 3 VM can help build the most accurate predic-tion model. When comparing each method across di ff erent chunk sizes, we can see that the prediction models trained from RK-TS 3 VM are the most robust ones with respect to di ff erent chunk sizes. Take the Sensor stream in Table 3 as an example, when the chunk size increases from 100 to 1000, RK-TS 3 VM has the lowest change (only 0.0365) compared to SVM (0.1488), TrSVM (0.0875) and S 3 VM (0.0472)methods. The above results assert that RK-TS 3 VM not only helps build accurate prediction models from data streams, but also relatively less sensitive to di ff erent chunk sizes. In Tables 5 and 6, the four methods are compared with respect to di ff erent percentages of labeled instances (with n = 500). For comparisons purposes, we also list the detailed chunk by chunk results of all four methods in Figs. 5 and 6. The results also validate our conclusion that RK-TS 3 VM is the most robust model with respect to di ff erent chunk sizes, percentages of labeled instances, and concept drifting probabilities.

The above advantages render RK-TS 3 VM a useful tool for practical usages, where real-world users may not have any priori knowledge on the proper chunk sizes, labeling percentages, and concept drif ting rates in the data streams. So a method insensitive to these parameters is able to deliver stable and consistent mining results.

For years, stream data mining research has been primar-ily focused on the data volumes and the concept drifting challenges, under assumption that the stream data are fully labeled. Although the advancement in the hardware and networking technologies has made the data collection eas-ier than ever before, labeling is still a rather expensive pro-cess and instance labels are hardly immediately available for stream data which constantly flow with large volumes. The mining algorithms should therefore consider a three-fold change, labeled / unlabled samples, data volumes, and concept drifting, to build accu rate prediction models. In this paper, we proposed a relational k -means based transfer semi-supervised SVM learning framework (RK-TS 3 VM) for data streams containing bot h labeled and unlabeled sam-ples. Our essential goal is to leverage labeled and unla-beled examples to boost the learning. This goal is achieved through the combination of a transfer semi-supervised SVM learning paradigm and a relational k -means based learning model. Empirical studies on both synthetic and real-world data streams demonstrated that RK-TS 3 VM is superior to other simple approaches such as the classical supervised SVM, Transfer SVM, and Semi-Supervised SVM models.
The contribution of the work reported in the paper is fourfold: (1) we characterize i nstances in data streams con-taining labeled and unlabeled samples into four categories. Such a categorization not onl y provides a clear concept drifting definition, but also may motivate interested read-ers to devise e ffi cient and e ff ective solutions for data stream with labeled and unlabeled samples; (2) we proposed a re-lational k -means based learning model, which is useful for semi-supervised learning when training and test data have di ff erent distributions; (3) we proposed a transfer semi-supervised model to leverage l abeled and unlabeled samples for learning. This model is generally useful when train-ing examples share similar distributions to the test data; and (4) although we used SVM-like model as the learning algorithm, our principle of combining transfer and semi-supervised learning and relational clustering can be fur-ther extended to other learning algorithms for mining data streams contained labeled and unlabeled samples.

