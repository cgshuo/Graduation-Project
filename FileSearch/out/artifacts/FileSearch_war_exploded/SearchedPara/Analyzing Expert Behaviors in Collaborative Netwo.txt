 Collaborative networks are composed of experts who coop-erate with each other to complete specific tasks, such as resolving problems reported by customers. A task is posted and subsequently routed in the network from an expert to another until being resolved. When an expert cannot solve a task, his routing decision ( i.e. , where to transfer a task) is critical since it can significantly affect the completion time of a task. In this work, we attempt to deduce the cognitive process of task routing, and model the decision making of experts as a generative process where a routing decision is made based on mixed routing patterns.

In particular, we observe an interesting phenomenon that an expert tends to transfer a task to someone whose knowl-edge is neither too similar to nor too different from his own. Based on this observation, an expertise difference based rout-ing pattern is developed. We formalize multiple routing patterns by taking into account both rational and random analysis of tasks, and present a generative model to com-bine them. For a held-out set of tasks, our model not only explains their real routing sequences very well, but also accu-rately predicts their completion time. Under three different quality measures, our method significantly outperforms al-l the alternatives with more than 75% accuracy gain. In practice, with the help of our model, hypotheses on how to improve a collaborative network can be tested quickly and reliably, thereby significantly easing performance improve-ment of collaborative networks.
 Source Code http://www.cs.ucsb.edu/~huansun/behavemodel.htm H.1.2 [ Information Systems ]: Models and Principles X  Human information processing;Human factors Collaborative Network; Generative Model; Task Routing; User Modeling
Collaborative networks are abundant in real life, where ex-perts collaborate with each other to complete specific tasks. In service businesses, a service provider often maintains an expert network where service agents collaboratively solve problems reported by customers. Bugzilla[1] is a bug track-ing system where software developers jointly fix the report-ed bugs in projects. In a classic collaborative network, upon receiving a task, an expert first tries to solve it; if he fails, the expert will route the task to another expert. The task is completed until it reaches an expert who can provide a solution.
Figure 1 shows a sample collaborative network with task routing examples. Task t 1 starts at expert A and is resolved by expert D , and task t 2 starts at expert D and is resolved by expert F . The sequences A  X  B  X  C  X  D and D  X  E  X  F are called routing sequences of task t 1 and t 2 respectively. The number of experts on a routing sequence measures the completion time of a task. The average completion time of tasks signifies the efficiency of a collaborative network in problem solving: the shorter, the more efficient.
When the number of experts in a collaborative network becomes large, to whom an expert routes a task significant-ly affects the completion time of the task. For example, in Figure 1, task t 1 can be directly routed to the resolver D from A . In this case the routing decision made by expert A is critical. Therefore, understanding how an expert makes a certain routing decision and detecting his routing behavioral patterns will help us identify the inefficiency of a collabora-tive network.

The task resolution problem in collaborative networks has been studied before. Shao et al. [18] propose a sequence min-ing algorithm to improve the efficiency of task resolution in IT service. Miao et al. [12] develop generative models and recommend better routing by considering both task routing sequences and task contents. In [22], Zhang et al. study the resolution of prediction tasks, which are to obtain probabili-ty assessments for a question of interest. All of these studies aim at developing automated algorithms that can effectively speed up a task X  X  resolution process. However, they largely ignore human factors in real task routing. Take Figure 1 as an example. Why does expert A route task t 1 to B instead of D ? Is it because he does not understand t 1 well, thus randomly distributing it to B , or he believes B has a better chance to solve it, or B has a better chance to find the right expert to solve it? Does expert A make more rational deci-sions than random decisions? While it is very hard to infer A  X  X  decision logic based on an individual task, it is possible to infer it by analyzing many tasks transferred and solved by A , B and D . In this work, we focus on analyzing real expert networks and try to understand experts X  decision logic, i.e. , what kind of routing patterns an expert follows when de-ciding where to route a task. This understanding will help detect the inefficient spots in a collaborative network and give guidance to the management team to provide targeted expert training. Figure 2: Task Transfer Frequency vs. Expertise Difference.

After analyzing thousands of tasks in an IBM service de-partment, we recognize that in many cases, an expert might not route a task to the best candidates (in terms of the pos-sibility to solve the task), especially when the task is far beyond his expertise. Instead, the task is transferred to an expert whose speciality is between the current expert and the best candidates. This routing pattern is clearly indi-cated by Figure 2. Figure 2 plots the histogram of exper-tise difference E A  X  E B E A , which is calculated when expert A transfers a task to B . E A represents the expertise of A and is automatically learnt based on A  X  X  task resolution records. It is observed that an expert tends to transfer a task to some expert whose expertise is neither too similar to nor too dif-ferent from his own. This phenomenon can be explained as follows: An expert is less likely to transfer a task to another expert whose expertise is very similar, given that the current expert already fails to resolve the task. On the other hand, if the expertise of two experts are very different, they might actually specialize in quite different domains; therefore, an expert might not be clear about the other X  X  speciality and few tasks would be transferred between them. We conjec-ture that it is like the situation when a computer science professor gets a quantum physics problem, he might con-sult a CS professor who is working on quantum computing, rather than directly ask a physics professor who is special-ized in quantum physics, though the latter might be a better candidate.

Inspired by the above observation, we introduce a routing pattern describing the general trend of expert A transfer-ring a task to B , based on the expertise difference between A and B . Apart from this routing pattern, another two are also formalized. Specifically, when an expert finds there are five candidates to dispatch a task to  X  all of them can solve the task, who is he going to contact? A straightforward approach is to randomly pick one. An alterative is to look at the capacity of these candidates and route more tasks to an expert who can process more tasks. An expert could follow a certain pattern when deciding where to transfer a task. Different experts might adopt each routing pattern to a different degree and demonstrate different routing behav-ioral characteristics. This study is going to infer the routing patterns as well as experts X  preferences over them, from the historical routing data, and finally give insightful analysis of experts X  performance in a collaborative network.
 The technical contributions of this work are three-fold: First, to the best of our knowledge, we make the first at-tempt to analyze the routing behaviors of experts in a col-laborative network in a large-scale, quantitative manner. We present a general framework to model the decision making and cognitive process of experts, and instantiate the frame-work with multiple routing patterns potentially followed by an expert. A generative model is then presented to model experts X  routing decisions as a result of mixed routing pat-terns. After trained on a historical task set, the model can uncover experts X  underlying decision logic and explain real routing sequences in a held-out testing set very well.
Second, our analytical model can accurately predict the completion time of a task before actually routing it in the network. On the one hand, we verify that our analysis of experts X  routing decision making reflects the real one, in the sense that a task navigated according to our model shall be completed in a similar time as in the real situation. On the other hand, estimating task completion time is important itself, because an accurate estimate of completion time can provide early signals on the  X  X ifficulty X  or  X  X bnormality X  of a task, and managers can allocate more resources and take early actions to deal with such tasks and shorten customer waiting time.

Third, it is usually expensive, if not impossible, to al-ter real-world collaborative networks for hypothesis testing, e.g. , providing more training to a few critical but inefficient experts or changing network structures for better perfor-mance. Since our analytical model has shown similar char-acteristics to the real human routing in collaborative net-works, it can be used to conduct virtual hypothesis testing. Through case studies, we discuss how to utilize our model to optimize collaborative networks.

The rest of the paper is organized as follows. In Sec-tion 2, we briefly describe our problem setting. In Section 3, we discuss multiple routing patterns potentially adopted by an expert, followed by Section 4, where a generative model combining these patterns together is presented. Section 5 details the estimation of task completion time, which serves as both an evaluation metric of our model and an important problem our model can deal with. Section 6 presents our detailed experimental results. Related work is reviewed in Section 7. We conclude this work in Section 8.
We first clarify the notations used in this work. E = { e 1 ,e 2 , ..., e i , ..., e G } is a set of experts in a collaborative network. N i denotes the 1-hop neighborhood of expert e i in the network, i.e. , the expert set e i has ever routed tasks to. W = { w 1 ,w 2 , ..., w n , ..., w N } is a set of words used to describe the tasks. T = { t 1 ,t 2 , .., t m , ..., t M } resolved by the collaborative network, where each t m is an N  X  1 word vector with each dimension recording the word frequency in the task description. Apart from the textual description, each task is also associated with a routing se-quence starting from an initial expert to the resolver of the task.

Table 1 shows one example problem ticket in an IT service department. The ticket with ID 599 is a problem related to operating system , specifically, the low percentage of the available file system space . It was assigned to or initiated by expert IN039, then routed through expert SAV59, and finally resolved by expert SAV4F.

In this paper, we study the following problems: How does an expert in a collaborative network make a routing de-cision? Is there any pattern an expert generally follows when routing a task? Different from previous studies [12, 18, 22], we do not propose algorithms to perform more efficient rout-ing. Instead, we hope to understand the routing decisions actually made by the experts in a collaborative network.
Our intuition is that an expert makes a routing decision by adopting a certain routing strategy either consciously or unconsciously. For example, an expert might decide where to route a task by evaluating the next expert X  X  possibility to solve the task.

We advocate a general and extensible methodology to an-alyze the routing decision making process, which consists of two routing strategies: Task-Neutral Routing (TNR) and Task-Specific Routing (TSR). Under the Task-Neural Rout-ing, an expert does not take into account the specificity of a task when making a routing decision, and treat different tasks equivalently. Under the Task-Specific Routing, how-ever, an expert makes a routing decision by analyzing the specific task being transferred.

We attempt to deduce the cognitive process of an expert during task routing, and model the decision making of an expert as a generative process where a routing decision is generated based on the two routing strategies. Each routing strategy is respectively combined with three basic routing patterns, which overall produces six particular routing pat-terns. Our generative model, with these six routing pattern-s as mixture components, is then proposed to describe the process of an expert X  X  decision making.
Given a task, we assume an expert e i first establishes a pool of candidates, C , to dispatch the task to. The dif-ference between the Task-Neutral Routing (TNR) and the Task-Specific Routing (TSR) lies in the composition of C .In terms of TNR, C contains all of his neighbors N i .Interms of TSR, C is limited to experts who are able to solve the cur-rent task in N i . TNR accommodates the situations when an expert does not understand a task very well, or an expert has a careless work attitude, and thereby making a routing decision irrespective of the specific task and its possible re-solvers; whereas TSR mimics the situation where an expert assesses others X  ability to solve a task before dispatching it.
Once C is established, e i selects one expert from C to route the task to, based on a certain routing pattern. We identified three basic routing patterns:
Uniform Random (UR). This routing pattern implies that an expert makes a decision by randomly selecting one of the candidates in C with an equal probability.

Where e i t  X  X  X  e j denotes the event that expert e i transfers task t to e j . 1 is an indicator function: 1 ( e j  X  C )picks value 1 if e j  X  C holds otherwise 0.

Volume-biased (Load-based) Random (VR). Under this rout-ing pattern, an expert also randomly dispatches tasks, but with a rate proportional to the volume of tasks previously dispatched. VR mimics the situation where the task pro-cessing capacity could vary for different experts. VR can be regarded as an expert X  X  reaction when he finds tasks are processed slowly by some of his collaborators. Let volume v ij denote the number of transferred tasks from e i to e j
Expertise Difference (EX). In addition to the above two routing patterns, this one is derived from the observation shown in Figure 2: An expert is more likely to send a task to another expert whose expertise is neither too close nor too far from his own. Let f ij denote the general trend of expert e i sending a task to e j , given their expertise.
To estimate f ij , we build a model based on the observa-tion in Figure 2. The relative expertise difference between expert e i and e j ,iscalculatedas X ( e i ,e j )= e i  X  e j for simplicity e i is reused to represent the expertise vector of expert e i . The expertise estimation problem will be dis-cussed in Section 3.3. Based on Figure 2, we assume for those tasks transferred, the relative expertise difference be-tween a task sender and a task receiver follows a log-normal distribution with parameters  X  and  X  2 .Wemadethisas-sumption due to the non-negative nature of  X ( e i ,e j )andthe asymmetric shape of the distribution. However, in our ex-periments, we also test a model with a normal distribution to estimate f ij and show that the log-normal distribution works better. Under the log-normal distribution, expert e is more likely to transfer tasks to e j once  X ( e i ,e j ) obtains a higher probability density; therefore, f ij is estimated by:
Note that the histogram in Figure 2 is the accumulation of all possible routing patterns, not only the expertise dif-ference pattern. Later, in the experiments, we will show that the EX pattern with  X  and  X  2 directly estimated from Figure 2 does not perform the best. Instead, parameters  X  and  X  2 shall be estimated with more emphasis on tasks transferred following the EX pattern, which are not known a priori. We will learn them simultaneously through a mixture model with all the routing patterns considered.

To summarize, the three basic patterns { UR, VR, EX } combined with the Task-Neutral Routing and Task-Specific Routing strategy, generate six particular routing patterns:
TNR does not take into account the distinctiveness of a specific task. In contrast, TSR means that an expert makes a routing decision based on the specific task and matches it with potential resolvers. Given expert e i to transfer task t , his routing decision under TSR is influenced by two factors: (1) whether an expert can solve the task or not, and (2) how familiar e i is with that expert. The first factor, only related to the task itself, can be conducted by a classification process without involving e i . The classification identifies a subset of e i  X  X  neighbors who can solve the task, as the candidate pool C . We build the classifier based on the task resolution records of experts in Section 3.3. The second factor is a human factor which can be modeled by the same routing patterns we previously introduced such as UR, VR, and EX. Overall, TSR will check the neighborhood of e i ,run the classifier, and establish a set of candidates C who are capable of solving t . It then selects one particular candidate from C based on one of { UR, VR, EX } .Inaspecialcase where C =  X  , TSR is reduced to TNR where we simply use theentireneighborhood N i as the candidate pool.

The success of our work is related to the recognition of human factors in task routing. A straightforward routing pattern considering the specificity of a task is to transfer the task to an expert with the highest probability to solve it. Our experiments show that such a routing pattern cannot capture the real characteristics of human decision making, such as randomness, uncertainty, and sub-optimality. We observe that similar tasks are often routed to very different experts. Moreover, one usually does not search for people who are most likely to solve a problem due to, e.g. , unfa-miliarity with those people. Instead, he might select a close collaborator who should be able to solve the problem, but not necessarily with the highest probability.
In TSR strategy and the EX routing pattern, we need to estimate an expert X  X  expertise and capability to solve a task. Intuitively, the capability depends on both the expert X  X  expertise and the task description. We resort to a classic l-ogistic regression model [6] that takes an expert X  X  expertise vector and a task X  X  word vector as input, and outputs the expert X  X  capability to solve the task. In the logistic mod-el, the probability for expert e i to solve task t , denoted as P ( e i ,t ), is defined as follows: For simplicity, the expertise vector for expert e i is of the same length as task t , i.e. ,an N  X  1 vector. W 1 and W 2 are the 1  X  N weights respectively associated with the word vector of a task and the expertise vector of an expert. Each component of W 1 and W 2 denotes the contribution of the corresponding dimension in t or e i to the capability predic-tion. b is a bias scalar in the logistic model. The expertise vectors e i  X  X  are not known a priori and they are to be esti-mated together with the model parameters { W 1 ,W 2 ,b } .We use W = { W 1 ,W 2 ,b,e i s } to denote all the parameters.
Given a task t and its routing sequence, e.g. , e i  X  ... e , we observe the groundtruth regarding the resolution ca-pability: The last expert e k solves t and any other expert on the sequence does not solve it. Therefore, we can formulate a training dataset composed of &lt; expert, task &gt; pairs as in-stances and { 0 , 1 } as the observed probability of an expert to solve a task, e.g. ,0for &lt;e i , t&gt; while 1 for &lt;e
The optimal solution of parameters in the model is ob-tained by minimizing the cross-entropy error function [6], basedonthe &lt; expert, task &gt; pairs in the training dataset : where P  X  ( e i ,t ) is the observed probability for expert e solve task t . After the parameters are learnt, given a task and an expert, one can predict the probability for the expert to solve the task using Eqn. 5. Under Task-Specific Rout-ing, when transferring task t , expert e i identifies a subset of his neighbors N i as the candidate pool C = { e j  X  X  i P ( e j ,t )  X   X  } ,where  X  is set at 0.5 in our implementation. Experts in C have a probability to solve t larger than a threshold, and are estimated capable to solve the task.
Essentially, the expert capability estimation is casted as a traditional classification problem. The logistic model we employed is very similar to classification using SVM [9] with a linear kernel [6]. The difference lies in that the expertise vector of an expert is not known a priori. One might con-sider using the average word vector of the tasks resolved by an expert to represent the expert X  X  knowledge. However, in practice, this method can be problematic, because we ob-serve that there might be many experts in a network that serve as  X  X ntermediate transferrers X  and did not resolve any tasks. In our case, we can also utilize those tasks unresolved by an expert to estimate his expertise in Eqn. 6. Besides, by optimizing the cost function over the expertise vectors, we can give lower cost function than fixing them at somewhere non-optimal.
In this section, we present a generative model to put the previously discussed routing patterns together and describe an integrated decision making process.

Figure 3 shows the graphical representation of our gener-ative model. We first clarify the notations in the figure as follows: (1) |E| denotes the number of experts while |T i the number of tasks expert e i  X  X  has ever transferred. A plate means replicating a process for multiple times. (2)  X  is the K  X  1 mixture weights of different routing patterns for expert e i ,where K is the number of routing patterns. In our current setting, we have K = 6 routing patterns, from TNR ur to TSR ex .The k -th component of  X  i reveals the probability that the k -th routing pattern is adopted by e to transfer a task. (3)  X  ,a K  X  1 vector, is parameters in a Dirichlet prior, and serves as a constraint of all the mixture
Figure 3: Graphical Representation of Our Model. weights  X  i  X  X . A Dirichlet prior for the mixture weights tend-s to alleviate over-fitting problems [7]. Besides, with the Dirichlet prior, the mixture weight  X  new for a new expert can be naturally assigned. (4) Z i,t is the label of the routing pattern employed by expert e i when transferring task t .(5)  X  i,t ,a K  X |N i | matrix, defines the probability distribution of expert e i transferring task t to an expert in his neighbor-hood N i , under K routing patterns. Particularly, each row of  X  i,t is filled by a probability distribution under one of the six routing patterns, as defined in Section 3.1. For experts in
N i but not in the candidate pool C , the corresponding elements in  X  i,t are naturally filled with 0. For patterns irrelevant to EX, we pre-compute their probability distribu-tions and fill corresponding rows of  X  i,t , while TNR ex TSR ex are parameterized with  X  and  X  2 . Note that  X  i,t in the inner plate of the graphical model because  X  i,t is as-sociated with expert e i and task t . (6)The shaded variable r i,t indicates the observed receiver of task t transferred from expert e i .

Figure 3 conveys that expert e i decides where to route task t based on multiple routing patterns  X  i,t and his pref-erence  X  i towards adopting different routing patterns. Now we formally describe the generative process as follows: For each task t  X  X  i , the transfer relationship for t is repre-sented by e i t  X  X  X  r i,t . We formulate the likelihood of observing all the task transfer relationships as follows:
Since a routing decision of an expert is independent from that of another expert while the routing decisions of the same expert for different tasks are not independent from each other, we can rewrite L in the following way: Here, where P ( Z i,t |  X  i )=  X  i,k and P ( e i t  X  X  X  r i,t | Z if Z i,t = k , i.e. ,the k -th routing pattern is adopted.  X  the probability for e i routing task t to expert r i,t , under the k -th pattern.  X  i,t k,r shall contain parameters  X  and  X  k -th pattern is TNR ex or TSR ex .

Finally, we resort to the maximum likelihood estimation approach to optimize the parameters in the model:
Now we discuss how to estimate the model parameters in detail. The latent variables {  X  i  X  X , Z i,t  X  X  } are not independent of each other, which makes their true posterior distributions computationally intractable. In this section, we employ a variational approach [6] to solve our model.
We introduce a variational distribution Q in which the la-tent variables are independent of each other to approximate their true posterior distribution, i.e. , Q (  X ,Z )= Q (  X  ) Q ( Z ), where  X  = {  X  i ,  X  e i  X  X } and Z = { Z i,t ,  X  e i  X  X  ,t According to the variational distribution, Q (  X  i )  X  Dir (  X  Q ( Z i,t )  X  Mult (  X  i,t ), , where  X  i and  X  i,t are K al parameters.  X  i and  X  i,t have significant meanings where  X  represents the variational prior for  X  i and reflects which routing pattern e i tends to adopt, while  X  i,t is the varia-tional posterior mixture weights of different routing patterns adopted by e i when transferring task t . Given the observed data, both  X  i and  X  i,t will be derived automatically.
Under the variational distribution and Jensen X  X  inequali-ty, we can maximize the lower bound of the log likelihood, instead of directly maximizing log L which is intractable. where D denotes all the observed task transfer relationships. We expand the lower bound of the log likelihood as follows: Each term on the right-hand side of the above equation, is a function over the model parameters as shown in Eqn. 13 to Eqn. 16.
 Dirichlet distribution Dir (  X  ).
The third term As discussed in Eqn. 9,  X  i,t k,r contains parameters  X  and  X  if the k -th pattern is TNR ex or TSR ex .
 The entropy term
The model parameters are estimated by using the varia-tional expectation-maximization (EM) algorithm. In the E-step, we update the variational parameters {  X   X  X  , X   X  X  } in the M-step, we update the model parameters  X  ,  X  ,and  X  2 so that log L is maximized.

Specifically, the E-step updates the variational parameters accordingtoEqn.17and18. During the M-step, we maximize the lower bound over the parameter  X  ,  X  ,and  X  2 , by utilizing the classic L-BFGS opti-mization algorithm [11]. The derivatives over the parameter  X  are calculated in Eqn. 19. Derivatives over  X  and  X  2 depend on the routing pattern TNR ex and TSR ex , as well as the mixture weights corre-sponding to the two patterns. where we assume TNR ex and TSR ex are the 1 st and 2 nd mixture component respectively. C k is the candidate pool established under TNR or TSR by e i when routing task t . f ir is the general trend of e i sending a task to r i,t ,based
The E-step and M-step are performed iteratively until the algorithm converges, which indicates that the current model parameters fit the observed training data.
In a real collaborative network, a task is routed and com-pleted as long as it reaches an expert who can solve it. The completion time (CT) of a task is defined as the number of experts in its routing sequence. Estimation of the comple-tion time before actually routing a task is critically useful, as it can raise attention for those troublesome tasks and ask the network allocate more resources to handle such tasks. The estimated completion time can also be used to evaluate routing models. A good routing model shall reflect the real decision making process and give the estimation as accurate as possible.

Experts that can resolve a task are not unique and are not known before the task is actually routed. For a new task, one cannot estimate its completion time by targeting a unique  X  X esolver X . Instead, we need to consider multiple potential resolvers and multiple routing sequences.
Given a task and its initial expert, our generative model can generate a routing sequence of experts to process the task. Specifically, given a task t and its current holder, e the receiver r i,t can be sampled according to our generative process described in Section 4. Once r i,t is obtained, it is treated as the current holder of t ; the same procedure is re-peated to produce the next receiver, until we have L experts to process t in sequence. Although the initial expert to deal with a task is important, in our work, we do not particular-ly deal with the assignment of an initial expert to a certain task. We assume that the initial expert to a task is given beforehand: it is either decided by the task requestor ( e.g. , a customer) or by the system.

Task t will stop routing once an expert can solve it. Since each expert in the routing sequence has a probability to solve the task, the completion time can be estimated ( CT t )asthe expected number of experts having accessed the task when it is solved.
 where r m ( r n )isthe m -th ( n -th) expert in a routing se-quence. m  X  1 n =1 [1  X  P ( r n ,t )] P ( r m ,t ) gives the probability for the m -th expert in the sequence to solve the task while the previous m  X  1 experts fail to, where P ( r m ,t ) X  X  are esti-mated using Eqn. 5. Since the probability diminishes quite quickly, we set L = 10 in practice. Indeed, CT t is not going to change much when L is beyond 10. We generate multi-ple routing sequences for each task, estimate the completion time based on each sequence using Eqn. 22, and calculate the average as the final estimated completion time.
In this section, we validate the expertise difference routing pattern and evaluate the accuracy of our method in model-ing expert behaviors on various real-life datasets. We will further demonstrate that with the help of our model, better recommendations on expert training could be automatically obtained and provided to managers for improving the per-formance of collaborative networks.
We use real-world problem ticket data collected from a problem ticketing system in an IBM IT service department throughout 2006. Three datasets in different problem cate-gories are explored: DB2, WebSphere, and AIX. DB2 con-tains problem tickets on database usage and management; WebSphere is a set of problem tickets on the enterprise soft-ware IBM WebSphere[2]; and AIX is the category of problem tickets on operating systems.
 Table 2: Three Datasets on Ticket Resolution.

The details of the three datasets, i.e. , the number of tasks, experts, and the distribution of completion time (CT), are shown in Table 2. The three datasets involve approximately 50 to 400 experts. Understanding how an expert makes a certain routing decision among many candidates is a mean-ingful yet potentially challenging problem. As evident in these datasets, the completion time for different tasks pos-sesses a large diversity, which drives us to analyze expert routing behaviors that possibly lead to such diversity. For each dataset, we randomly partition it into two disjoint sub-sets: 75% of tasks for training, 25% for testing.
To evaluate our generative model in capturing the real decision making process of an expert, we employ two types of measures: (1) Routing Sequence Likelihood . We compute the log likelihood (LL) of the routing relationships in the held-out testing dataset, according to Eqn 8. The higher the log likelihood, the better a model explains the routing decisions of experts. (2) Predicted Completion Time .The routing decision of an expert significantly affects the com-pletion time of a task. Our model is considered valid if a task routed according to our generative process can achieve a similar completion time as it does in real situations. Two measures are employed to calculate the difference between the estimated, CT and the real completion time, CT. 1. Mean Absolute Error (MAE).
 2. Step Loss Measure (SL). Instead of directly comput-
We compare our model with the following algorithms. (1) Regression: For each task, to estimate its completion time, one can resort to a regression algorithm to make the prediction. We use two classic methods: Support Vector Regression (SVR) [9] and Bayesian regression method [14]. Given a task, two types of features are input to each method: (i) word frequency vector in the description of a task; (ii) the initial expert assigned to the task. 10-fold cross validation is conducted for both methods. We evaluate SVR with dif-ferent kernels including a linear kernel, a polynomial kernel, an RBF kernel and a wavelet kernel. For Bayesian regres-sion, we consider Bayesian linear regression and Bayesian logistic regression. Classification using SVM [9] or naive Bayes classifier [14] are also tested, which turns out to be worse than the regression methods. Among all the variants of SVR or Bayesian regression, we always show their best re-sults obtained. The classification/regression approaches are employed as straightforward methods for completion time estimation. They do not attempt to understand the decision making process of experts, and their results on the sequence likelihood measure are not available. (2) Generative models. Miao et al. [12] estimate the prob-ability of an expert to solve a task and the probability of transferring a task from an expert to another. Given a task, [12] recommends a sequence of experts to route the task. Their goal is to shorten the routing as much as possible, while our goal is to characterize human routing patterns in the real network.
Table 3 summarizes the performance of all the methods on step loss measure, MAE, and log likelihood. From the results of SVR and Bayesian regression, we can see that the completion time of a task cannot be accurately predicted based on the straightforward regression methods. In fact, we observe that in the real datasets, similar tasks, even if assigned initially to the same expert, are often routed to dif-ferent experts and resolved with a different completion time. This implies the resolution of a task is a complicated process and involves human factors. The estimated completion time in [12] is usually shorter than the real one as its goal is to shorten routing sequences. It is not surprising that it incurs a large step loss and MAE.
 Now we test multiple variants of our generative model. For each variant, we select combinations of different routing patterns to train a generative model, and test the learned model under the three measures.
 We first examine the performance of TNR-related and TSR-related routing patterns separately. Then they are combined together as TNR+TSR. Table 3 clearly shows both TNR and TSR play a critical role to reduce SL and MAE, indicating both types of strategies are adopted by experts in real cases. Our model does capture the deci-sion making process of experts in a collaborative network. Our method significantly outperforms the content-focused regression methods by 75 %. Moreover, the MAE between our estimated completion time and the real one is between 0.07 and 0.15 , which shows that our method can be used to accurately predict the task completion time.

We then experiment if the expertise difference (EX) rout-ing pattern makes sense. Specifically, we test the model that combines all the routing patterns except TNR ex and TSR ex denoted as TNR+TSR-EX. The results indicates that with the EX routing pattern considered, TNR+TSR will better capture the real decision making process. This result can be attributed to our observation: an expert is more likely to transfer a task to some expert whose expertise is neither too similar nor too different.

One natural hypothesis is that under the task-specific routing, a task will be resolved quickly, since TSR directly takes into account the next expert X  X  ability to solve the task. We now verify this hypothesis. Recall that the variational parameter  X  i,t in our model TNR+TSR reflects the posterior mixture weights used by expert e i when transferring task t . If in  X  i,t , the sum of the components corresponding to TSR-related routing patterns is larger than that corresponding to TNR-related patterns, expert e i is regarded as using T-SR to transfer task t ; otherwise the expert is using TNR. Therefore, we can roughly divide experts into two groups: TNR-kind and TSR-kind. After an expert transfers a task, we count the number of remaining experts needed to resolve the task. We respectively summarize the distribution of the remaining expert number when a TSR-kind expert transfers a task, and that when a TNR-kind expert transfers a task. Figure 4 shows the results on the DB2 tickets. It clearly verifies the hypothesis. On DB2 tickets, a ticket will likely getsolvedwithonemorestepwhenanexpertfavoringT-SR routes it. However, if routed by a TNR-kind expert, a ticket might still need 2 or 3 more experts to get resolved. We obtain an additional implication from Table 3 and Fig-ure 4, that is, TNR+TSR better captures the expert real routing behaviors in a collaborative network while routing based on TSR can lead to more efficient task resolution. Due to space constraints, we omit the results for AIX and WebSphere, which are very similar to that of DB2.
In our EX routing pattern, given the expertise of e i and e we estimate f ij , i.e. , the general trend of e i sending a task to e j , based on a log-normal distribution of  X ( e i ,e j selection of log-normal is due to the non-negative nature of  X ( e i ,e j ) and the asymmetric shape of the distribution shown in Figure 2. However, one might consider estimating f ij based on a normal distribution, since a normal distribu-tion also seems to be quite similar to Figure 2: Table 4 empirically justifies our selection of a log-normal distribution. (TNR+TSR) # is the result corresponding to using a normal distribution to estimate f ij based on Eqn. 23, which is much worse compared with TNR+TSR.

Instead of optimizing  X  and  X  2 during model solution, we could pre-estimate  X  and  X  2 based on the distribution of the relative expertise difference in the training dataset, as shown in Figure 2, and keep them fixed during model training. We denote this setting as (TNR+TSR)*. As discussed in Sec-tion 3.1, the histogram in Figure 2 is due to the integrated effects of all the routing patterns, whereas TNR+TSR op-timizes  X  and  X  2 with more emphasis on tasks transferred following the EX pattern, and can further improve the ac-curacy. Nevertheless, given that the performance does not differ too much between TNR+TSR and (TNR+TSR)*, in practice, one might consider saving the trouble of deriving complicated derivatives over  X  and  X  2 during model solu-tion.
In the management of real collaborative networks, system administrators need to optimize the current network, e.g. ,in terms of expert training, to improve the efficiency of task ex-ecution. However, it is very expensive, if not impossible, to alter the real collaborative network just for hypothesis test-ing. Currently such decisions are manually made by experi-enced managers or consultants, without much quantitative analysis on how the resulting network will perform. Since our model accurately captures the routing behaviors of ex-perts, it can naturally serve as a trustable simulation means for real task routing in the collaborative network. Hypothe-ses on whether a certain change to the network can improve the efficiency or not, can be much more easily examined with the help of our model.

Here we study optimization of the collaborative network, in terms of training experts to have more efficient routing patterns. Particularly, we examine two questions: What kind of routing patterns might bring better resolution effi-ciency? Which expert(s) should be selected for more train-ing, given a limited budget? Section 6.3.2 implies if an ex-pert is more likely to route a task based on TSR, the task will be resolved more quickly. We now formally verify this hypothesis. For each expert, we treat TSR and TNR as t-wo groups of routing patterns, and set the group mixture weights respectively as ( x ,1  X  x ). When an expert trans-fers a task, we first randomly select TSR or TNR based on the group mixture weights, and then select a routing pat-tern inside the selected group according to their mixture weights previously learnt in our model TNR+TSR. Based on Section 5, we estimate the completion time of a task, and evaluate the task resolution efficiency by the average CT of all the tasks. We vary x to test the change of the task resolution efficiency. Only the results in the DB2 tickets are shown in Figure 5 since similar results on WebSphere and AIX are observed. We can see that as the mixture weight for TSR gets closer to 1, the average completion time tends to become shorter, indicating task resolution becomes more ef-ficient. Therefore, experts in the network should be trained to route a task based on TSR.
When the training budget is limited, which experts should be trained first to maximize the performance of the entire network, is an interesting problem. For simplicity, we con-sider the problem of selecting the best candidate. One can extend to top-k candidate selection by adopting a greedy method. Possible methods to recommend an expert include (1) randomly select one expert from the network, denoted as Random ; (2) select the expert that transfers the most tasks, denoted as Frequent Transferrer ; (3) select the ex-pert that is the least efficient: after the expert transfers a task, the average number of remaining steps to solve a task is the highest, denoted as Least Efficient ; (4) use our mod-el to conduct task routing after an expert X  X  routing pattern is changed and select the expert that can lead to the most improvement of efficiency. Efficiency improvement is evalu-ated by the decrease of the average CT of tasks. Methods (2)-(4) are executed on a training task set and evaluated by calculating the efficiency improvement on a testing task set. Table 5 clearly demonstrates that compared with other methods, training the expert recommended with the help of our model, can result in a much more efficiency improve-ment. This result is expected because through routing a training set of tasks with our model, we are able to know which expert X  X  routing pattern plays a critical role in de-creasing the average CT of tasks. This study demonstrates that our model could help conduct hypothesis testing eas-ily and can provide valuable recommendations to decision makers during the optimization of a collaborative network.
Our work is related to previous studies in three cate-gories: (1)Collaborative networks; (2)User behavior mod-eling; (3)Multi-class classification and Markov processes.
Collaborative Networks. Camarinha-Matos et al. [8] propose general modeling perspectives including structural and behavioral to design and manage collaborative network-s. As mentioned in Section 1, Shao et al. [18], Miao et al. [12], and Zhang et al. [22] propose automated routing algorithms to resolve a certain task in collaborative networks as fast as possible. The task resolution problem is also related to the expert finding problem[3, 17]: Given a keyword query, find the most knowledgeable persons regarding that query. All of them aim at proposing algorithms that can speed up the resolution of a task or a query. Our work differs from these studies: We are not aimed at building another recommen-dation algorithm for finding a right resolver. Instead, we try to uncover the patterns underlying human real routing deci-sions. Miao et al. [13] study a network model and a routing model to jointly simulate the structure and the task rout-ing procedure in a collaborative network, while we directly infer the routing models in real collaborative networks. A salient feature of our model is its capability of estimating the completion time of a real task.

User Behavior Modeling. Information propagation, as one type of user behaviors, has been widely studied, such as [10] on influence maximization, [19] on propagation through e-mail forwarding, [20] on information spreading patterns in Twitter, and so on. Unlike information propagation from person to person, the purpose of task routing in a collab-orative network is to find the resolver for a task instead of influencing others. Benevenuto et al. [5] study the click-stream data to reveal key features of user behaviors, such as how often users connect to a social network and the se-quence of activities users conduct on a social network site. Retweeting behaviors of users in Twitter are investigated in [21]. Zhong et al. [23] leverage the knowledge of user rating behaviors in multiple social networks to enhance the pre-dictive performance of user modeling. Different from these previous studies, in this work, we analyze experts X  routing behaviors in collaborative networks: Given a task, how an expert decides where to transfer it and what kind of routing patterns an expert possesses.
 Multi-class Classification and Markov Processes.
 In terms of methodology, our model is related to multi-class classification [16] and Markov processes [4]. When an expert considers where to route a task, the decision process can be regarded as a multi-class classification problem. One can po-tentially build a classifier for each expert, to decide where to route a task ( i.e. , the label). It requires effective features and training algorithms to achieve good performance. Propos-ing such features for classification is not an easy problem. Actually, the routing patterns in our model can be regarded as relevant features for classification. The formalization of a mixture model gives an intuitive explanation of the deci-sion making process of an expert. The task routing problem is also related to a Markov process, particularly, a Markov chain. States in a Markov chain correspond to experts pro-cessing a task at each step in our model. Given the current expert e i , the next expert to access a task is independent from the experts previous to e i , which can be regarded as the Markov property. Different from a classic Markov chain, in our case, the state ( i.e. , expert) transition probability is with respect to a specific task and is obtained through a mixture of multiple routing patterns.
In this paper, we modeled the decision making and cogni-tive process of an expert during task routing in collaborative networks. A routing decision of an expert is formulated as a result of a generative process based on multiple routing patterns. We formalized each routing pattern in a prob-abilistic framework, and modeled experts X  routing decision making through a generative model. Our analytical model has been verified that it not only explains the real routing sequence of a task very well, but also accurately predicts a task X  X  completion time in the current collaborative net-work. In comparison with all the alternatives, our method improves the performance by more than 75% under three different quality measures. We have also demonstrated that our model can provide guidance on optimizing the perfor-mance of collaborative networks.
This research was sponsored in part by the Army Re-search Laboratory under cooperative agreements W911NF-09-2-0053, NSF IIS 0917228, and 0954125. The views and conclusions contained herein are those of the authors and should not be interpreted as representing the official poli-cies, either expressed or implied, of the Army Research Lab-oratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Govern-ment purposes notwithstanding any copyright notice herein. [1] Bugzilla: http://www.bugzilla.org/. [2] http://en.wikipedia.org/wiki/ibmwebsphere. [3] K. Balog, L. Azzopardi, and M. De Rijke. Formal [4] R. Bellman. A markovian decision process. Technical [5] F. Benevenuto, T. Rodrigues, M. Cha, and [6] C. M. Bishop and N. M. Nasrabadi. PRML ,volume1. [7] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [8] L. M. Camarinha-Matos and H. Afsarmanesh. A [9] N. Cristianini and J. Shawe-Taylor. An introduction to [10] D. Kempe, J. Kleinberg, and  X  E. Tardos. Maximizing [11] D. Liu and J. Nocedal. On the limited memory bfgs [12] G. Miao, L. E. Moser, X. Yan, S. Tao, Y. Chen, and [13] G. Miao, S. Tao, W. Cheng, R. Moulic, L. E. Moser, [14] T. M. Mitchell. Machine learning. 1997. Burr Ridge, [15] H. Moskowitz and K. Tang. Bayesian variables [16] J. C. Platt, N. Cristianini, and J. Shawe-taylor. Large [17] P. Serdyukov, H. Rode, and D. Hiemstra. Modeling [18] Q. Shao, Y. Chen, S. Tao, X. Yan, and N. Anerousis. [19] D. Wang, Z. Wen, H. Tong, C.-Y. Lin, C. Song, and [20] S. Wu, J. M. Hofman, W. A. Mason, and D. J. Watts. [21] Z. Yang, J. Guo, K. Cai, J. Tang, J. Li, L. Zhang, and [22] H. Zhang, E. Horvitz, Y. Chen, and D. C. Parkes. [23] E. Zhong, W. Fan, J. Wang, L. Xiao, and Y. Li.
