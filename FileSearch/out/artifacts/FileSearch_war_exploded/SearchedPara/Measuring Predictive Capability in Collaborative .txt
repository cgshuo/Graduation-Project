 This paper presents a new memory-based approach to Col-laborative Filtering where the neighbors of the active user will be selected taking into account their predictive capabil-ity. Our hypothesis is that if a user was good at predicting the past ratings, then his/her predictions will be also helpful to recommend ratings in the future. The predictive capa-bility of a user will be measured using two different criteria: The first one which is based on the likelihood of the active user X  X  rating and the second one tries to minimize the error obtained using his/her predictions. We show our experimen-tal results using standard data sets.
 H.3 [ Information Storage and Retrieval ]: General Algorithms, Theory Probabilistic Reasoning, Collaborative Filtering, Recommender System
The usual formulation of the recommending problem is to predict how an active user might rate an unseen item. Rec-ommender Systems are often based on Collaborative filtering (CF) [6], which relies only on past user behavior. These sys-tems attempt to identify groups of people with similar tastes to those of the user and recommend items that they have liked. In this paper we focus on memory-based approaches that uses the entire rating matrix to make predictions (in contrast to model-based approach that learns an abstrac-tion [4]). The advantage of memory-base approach with re-spect to model-based is that a fewer number of parameters have to be tuned [8], however they have some problems with the sparsity of the data. Nevertheless, memory-based ap-proaches have reached a great popularity because they are simple and intuitive on a conceptual level being also suffi-cient for many real-world problems [3, 7, 5, 8].

Different views of the rating matrix leads to two differ-ent types of memory-based approaches: user-based methods where the predictions are generated based on those ratings given to the target item by similar users [3], and item-based methods where the predictions are generated considering those ratings given by the active user to similar items [7]. Fo-cusing on user-based model, a critical step is to identify users that are similar to some active user, A . The way in which this similarity is computed can have a significant impact on the performance of the system. Studies and real-world implementations so far have relied on traditional vector sim-ilarity measures (say Pearson X  X  correlation in different for-mulations, cosine, Spearman X  X  Rank, etc. [3, 1, 8]) or using a probabilistic framework [8].
 The objective in this paper is to create a memory-based CF model trying to better predict the probability of the al-ternative ratings. This model will be an example of Predic-tive modeling [2]. Our hypothesis is that if a user was good at predicting the past ratings, then his/her predictions shall be also helpful to recommend ratings in the future. Two different alternatives to measure the predictive capability of a user will be considered: The first one that considers how probable is a given user acting as predictor and the second one which tries to minimize the error obtained using his/her predictions.

In order to recommend a rating for the target item, I k , we propose to select the best-N users (those with highest predic-tive capability) among the set of users who previously rated this item. Then, in a second step, the rating for the target item has to be predicted. Usually, this rating is computed by averaging the (weighted) known ratings given by those similar users to I k [8]. Taking into account our predictive purposes in this paper we will also explore a different alter-native to aggregate the information. Briefly, we compute a probability distribution over the candidate ratings, and then this distribution is used to perform the final prediction.
In the process above, the information about the target item only acts as a filter (we focus on those users who rated this item previously). Then, for each user who passes this filter, we measure whether the predictions over all the A  X  X  past ratings are good or not. In this paper we will also explore a different approach. Let us consider the following example. If I wish to obtain a prediction for the movie  X  X onsters vs Aliens X , the quality of a user can be measured by considering his/her predictive capability for those movies which are similar to the target one. In some sense we are giving some opportunities to those users who might do well predicting animation movies but their predictions are not good enough if we consider others genres.

This paper is organized in the following way: Next section presents an overview of the predictive model. The different selecting criteria will be studied in Section 3. How it can be used item X  X  similarities is presented in Section 4. Sec-tion 5 describes the proposed experimentation and Section 6 presents the final conclusions.
Firstly, we shall introduce some notation: Let A be the active user and let U (or U i ) be any other user in the system. We denote by D a (respectively D u ) the set of ratings given by A (respectively U ). We also use r j a to denote the rating given by user A to the j th -item ( r j a = 0 when user A does not rate this item). Given the target item I k , we denote by C k those users who rated this item. Finally, the set of valid ratings is denoted by S .

In order to build a predictive model, we have to look for those elements that are likely to influence the active user X  X  future ratings. In a CF framework these elements are those ratings given by the rest of the users. Briefly (see the algo-rithm in Table 1), our predictive model will select the best-N users (sorted using their predictive capability over the past ratings) among those users who rated the target item, C k In order to measure the predictive capability of a given user, U  X  C k , we shall consider two different alternatives depend-ing on whether U is a predictor for the active user (denoted by H 1 ) or not (denoted by H 2 )
The particular way used to measure the predictive power of an user will be discussed in Section 3.
 Once the set of best-N predictors have been selected from C , their individual predictions (in terms of probability dis-tributions over ratings, P ( r k a |H 1 , D u ) ,  X  r k a aggregated (step 2 in Table 1). Since we know the rating given by each user U j  X  C k to the target item I k , say r we will use the following conditional independence assump-tion: A1 Given r k uj , the predictive probabilities associated to In this paper, the posterior probability distribution over the candidate ratings will be obtained by means of a linear com-bination of the individual predictive probabilities, i.e., Inputs: A active user, I k target item
Output:  X  r k a predicted rating. 1. Neighbors Selection 2. Predictive Process being  X  j,a normalized weights giving more strength to most valuable users. In Section 5 we will discuss how these values might be computed.

Since the objective is the prediction of the rating that the active user should give to I k ,  X  r k a a final decision becomes necessary. There are several methods for computing this prediction from a probability distribution over ratings. For example, we can use the most probable, the average or the median rating. In this paper we will use the median predic-tion since it minimizes the mean absolute error (an standard metric used in CF which will be also used in our experimen-tation). Therefore,
We would like to note that the way in which we compute the predicted rating represents another difference between our approach and the ones in [3, 8]. In these models the prediction is computed based on a weighted aggregation of those ratings given by the selected neighbors whereas our approach uses a weighted aggregation of the individal pre-dictive probabilities.
In this paper we are going to explore two different alter-natives to measure the predictive capability of a given user U : The first one that considers how probable is that U acts as a predictor and the second one, which tries to minimize the error obtained using his/her predictions.
Our objective is to measure how probable is  X  U is a pre-dictor of A  X  given that we know their past ratings, D a and D u , i.e. P ( H 1 | D a , D u ). Considering the Bayes X  theorem we have that with = P ( D a |H 1 , D u ) P ( H 1 | D u ) + P ( D a |H 2 , D
In this equation P ( H i | D u ) represents the subjective prior probability over our hypothesis space, which expresses how plausible we thought H i was before the D a data arrived. In other words, given that we know the set of ratings given by U , what are our beliefs about X  U is a predictor for the active user X . In this paper we shall assume that the two alterna-tives, H 1 and H 2 , are equally probable, although some other approaches might be considered. For example we could con-sider that these values might depend on the number of items rated by U , the rating variability of U (an user who always rates with almost the same value does not help in the pre-dictions) or depending on some social factor controlling how influential a given user is.

The term P ( D a |H 2 , D u ) represents the probability of the ratings D a when it is assumed that U is not a predictor for A , i.e., the ratings of A do not depend on those ratings given by U . Therefore, it is natural to consider that P ( D a |H is equal to P ( D a ).

In order to rank the users according to P ( H 1 | D a , D will use the following proposition, which states that the same ranking will be obtained using the likelihood P ( D a |H 1 (we essentially ignore those terms which do not affect the ranking).
 Proposition: Given any two users U and U 0 , if P ( D a |H 0 1 , D 0 u ) &lt; P ( D a |H 1 , D u ) then P ( H P ( H 1 | D a , D u ) .

So, the problem reduces to compute P ( D a |H 1 , D u ). In by A . In order to compute these values we will consider the following assumption: A2 The active user X  X  ratings are (marginally) independent:
Given that we know how the user U rated each item I i in D a , r i u (if U did not rate the item, it is considered that r u = 0, i.e. we use the null value as the given rating), and considering the conditional independence assumption, A1, we have that P ( r i a |H 1 , D u ) = P ( r i a |H 1 , r i bilities shall be estimated by relative counts over the set of items rated by either A or U , i.e. D a  X  D u , using Laplace smoothing.

Therefore, the likelihood of the active user X  X  ratings shall be computed as (we will work with the natural log)
In this paper we shall study another alternative for mea-suring the predictive power of a user (step 1 in the algorithm in Table 1). The idea will be to measure for each user U who had rated the target item I k , U in C k , the possible loss as-sociated with those predictions obtained when estimating the active user X  X  past ratings. Particularly, and in order to measure the difference between the estimated rating and the true rating, EL , we propose to use the mean absolute error (MAE) over A  X  X  ratings, D a = { r 1 a . . . , r t a } , i.e.
In this equation, the term  X  r i a,u denotes the estimated rat-ing for an item I i in the case of being U a predictor of A . Therefore, in these predictions the predictive probabilities of the user U , P ( r i a |H 1 , D u ) have to be used. Following the ideas of the proposed model and considering the assumption A1, the estimated rating is the median of the individual pre-dictive probabilities, i.e.  X  r a,u = { r | P ( r i a &lt; r |H 1 , r i u ))  X  0 . 5 , P ( r Then, the best N users, i.e. those users achieving the lowest expected loss, EL ( A, U ), will be selected as neighbors of A .
The above metrics try to capture how good is a user U when predicting A  X  X  ratings. In order to compute these met-rics we have considered the influences of the user U over all the past ratings given by A , D a = { r 1 a , . . . , r t cess, the information about the item which is going to be recommended I k only acts as a filter: The required predic-tive measures are computed only for those users who rated I previously, i.e. U  X  C k (step 1.1 in Table 1).

These computations might require a time 1 in the order ( O ( t  X | C k | )) which could be prohibitive in real online ap-plications. In a steady situation, where it is not common to include new ratings, these computations can be performed offline, but this is not the usual case in a recommending framework. This problem is common to all the memory-based approaches for CF. Traditionally these methods select (a priori) more users, although not all of them have given a rating for the items that we wish to predict. As conse-quence, the predictions obtained are not necessary based on N ratings.

In this paper we will study a different approach to reduce the efforts necessary to compute the predictive power of an user U . The idea is to measure the quality based on the pre-dictions obtained for those items which are similar to the target item I k . Thus, if D k a ( D k a  X  D a ) is the set of ratings given by A to the M items most similar to I k , our hypoth-esis is that if a user did well predicting the ratings in D then his/her predictions could be helpful to predict a rating for I k . In order to measure the similarity between items we shall use the adjusted cosine between item X  X  ratings [7]. In some way we are combining both user-based and item-based approaches, combination which has been shown beneficial in other models [8], where the estimated rating is combination of the predicted rating using the two approaches.
In order to evaluate our approach we used MovieLens (ML) and Yahoo! Movies (Yh) [9] data sets: MovieLens contains ratings of 1682 movies rated by 943 users. We have used the original training and test data sets -with 80,000 and 20,000 ratings. On the other hand, Yahoo! Movies contains ratings of 11,915 movies rated by 7,642 users also divided into training and test sets with 211,231 and 10,136 ratings, respectively. As accuracy criterion we have used the MAE metric that measures how close the predictions are to the original ratings. We have used 5-fold cross validation pro-tocol to evaluate the results, also and in order to select the best-N users it has been considered all the users in C k N taking the values 10, 20, 30, 50 and 75. Also, when con-sidering item similarities we have used the M = 10, i.e. the 10 most similar items.
 We have also taken into account two different baselines: B is the model in [3] where the best N neighbors have been selected using Pearson Correlation between users. We wish to note that although this model is simple its performance remains competitive. On the other hand, we have used a model-based CF approach [4] related to the aspect model
We are not considering here the time needed to sort (step 1.2 in Table 1) the predictive probabilities. B 0.7448 0.7344 0.7331 0.7339 0.7355 H X  P 0.7303 0.7244 0.7235 0.7246 0.7246 H X  H 0.7470 0.7427 0.7422 0.7418 0.7412 E X  P 0.7303 0.7279 0.7275 0.7278 0.7281 E X  E 0.7417 0.7427 0.7427 0.7437 0.7432 H X  P 0.7283 0.7215 0.7208 0.7216 0.7233 H X  H 0.7530 0.7471 0.7452 0.7489 0.7466 E X  P 0.7432 0.7350 0.7324 0.7289 0.7283 E X  E 0.7480 0.7430 0.7446 0.7421 0.7434 B 0.7504 0.7390 0.7351 0.7324 0.7319 H X  P 0.7331 0.7317 0.7303 0.7287 0.7293 H X  H 0.7644 0.7561 0.7568 0.7597 0.7588 E X  P 0.6833 0.6771 0.6772 0.6796 0.6817 E X  E 0.7623 0.7551 0.7556 0.7614 0.7650 H X  P 0.7318 0.7313 0.7296 0.7285 0.7291 H X  H 0.8578 0.8442 0.8302 0.8195 0.8092 E X  P 0.7369 0.7175 0.7056 0.7022 0.6997 E X  E 0.7990 0.7833 0.7768 0.7781 0.7806 Table 2: MAE X  X  using MovieLens and Yahoo! Movie for probabilistic semantic analysis 2 . Particularly, the MAE values obtained using 10  X  X ser types X  are 0 . 7425 and 0 . 7458 with MovieLens and Yahoo! movies, respectively.

The two parameters evaluated in the experimentation are, on the one hand, the criterion used to select the neighbor-hood (see Section 3). In this case, we use H to denote that the best users have been selected using their predictive prob-abilities and E to denote that we are trying to minimize the error in the predictions. With respect to the weights  X  j,a used in Equation 1 representing the strength given to the j -user we shall explore three different approaches: Nor-malized Pearson correlation coefficient (  X  P ) over users rat-ings, normalized likelihoods P ( D a | H 1 , D u ) (  X  H ) and nor-malized error loss EL ( A, U ) (  X  E ). Table 2 shows the result obtained in our experimentation. Also, an in order to study the scalability of the approach, we have performed a brief experimentation with 1 Million Movielens data set. Table 3 shows the results obtained after considered 90% training and 10% test. In this case we have fixed to 30 the user X  X  neighborhood.

From these data we can conclude that our proposals are competitive (our best results outperforms those obtained with the baselines). With respect to the criteria used to select the active user neighborhood the minimization of the loss function shows a good performance with all data sets, although the results are remarkable for Yahoo! data and 1M Movielens). Also, the way in which the  X  weights have been computed have an important role in the accuracy of the predictions. Surprisingly, the use of Pearson coefficient,  X  stand out in all the experiments. We believe that this is be-
This model considers a latent variable which can be inter-preted as a  X  X ser type X . Briefly, in this model a user is seen as a distribution over user types and for each user type we can obtain a distribution over the pairs item-rating. NO-IS: 0.7082 0.6901 0.7925 0.6855 0.6972 IS: 0.7159 0.7203 0.7045 0.7246 Table 3: MAE X  X  using 1 Million MovieLens Data Set with and without the use of items-similarity (IS and NO-IS, respectively.) cause our  X  X aive X  approach to normalize the other weights, so a further studies become necessary. Finally, the use of items similarities have been proved beneficial with Movie-Lens data set (we could obtain similar results with less com-putational time). The results obtained with Yahoo! data and 1M Movielens are not conclusive. We guess that the differences in performance between data sets are due to the difficult of finding similarities between items. Nevertheless, we have to say that the predictions can be obtained with less computational time.
In this paper, we show the feasibility of building a memory-based CF system that considers those users having greater impact in the (past) ratings of the active user. The perfor-mance is improved by taking into account how these users influence in the ratings of items similar to the target one. As future work we plan to study the use of content information in order to determine items similarities and also the use of a variable number of neighbors in the recommendation process Acknowledgements: This work has been jointly supported by the Spanish Ministerio de Educaci  X on y Ciencia, and the research program Consolider Ingenio 2010, under projects TIN2005-02516, TIN2008-06566.C04.01 and CSD2007-00018, respectively. [1] H.J. Ahn. A new similarity measure for collaborative [2] S. Geisser (1993) Predictive Inference: An [3] J. L. Herlocker, J. A. Konstan, A. Borchers, J. Riedl. [4] T. Hofmann. Latent semantic models for collaborative [5] G. Linden, B. Smith, J. York. Amazon.com [6] P. Reskick, H.R. Varian. Recommender systems . [7] B. Sarwar, G. Karypis, J. Konstan, J. Reidl. Item [8] J.Wang, A.P. de Vries, M.Reinders Unified Relevance [9] Y ahoo! Webscope dataset
