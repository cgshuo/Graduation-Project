 task in the research area of Topic Detection and Tracking (TDT), compared to the other tasks like known event track-ing and retrospective event detection. Current FSD systems are mostly based on comparing a new document to all the documents in the past, and thresholding on the similarity scores -if all the similarity scores axe below a threshold, the new document is predicted as the first story of a novel event. Such a simple-minded approach yielded limited per-formance in TDT benchmark evaluations. A performance upper-bound analysis by Allan et al.[2] provided a proba-bilistic justification for the observed performance degrada-tion in FSD compared to event tracking, and suggested that new approaches must be explored in order to significantly enhance the current performance level achieved in FSD. 
In this paper, we focus on how to use training data of old events to learn useful statistics for the prediction of new events. More specifically, we investigate a new approach consisting of the following components: 1. classifying documents into broad topics each of which 2. identifying Named Entities (NE's), optimizing their 3. measuring the novelty of a new document conditioned 
The rationale behind our approach is that events belong-ing to the same topic often share a set of keywords. For example, documents talking about different events in air-plane accidents (as a topic) tend to share the words like "airplane", "crash" and "accidents". Those keywords are informative for discriminating on-topic and off-topic docu-ments, but, they also make the first story of a new airplane crash look just like the documents for another airplane crash which has already occurred, and cause FSD systems to miss such reports unless the system has the ability to distinguish the features (words or phrases) discriminative for topic clas-sification and those discriminative for event distinction. To obtain such functionality, we propose the approach of topic-conditioned FSD in which we use supervised learning algo-rithm to classify documents by topic, and topic-conditioned feature weights to measure the novelty of documents at event level. 
Section 2 describes our method; Section 3 introduces the data and performance measures for evaluation, and the sim-ilarity matrices illustrating the confusibility among events within each topic; Section 4 reports experimental results; and Section 5 summarizes the research findings and discusses issues for further research. 
To avoid ambiguities in terminology, let us make a distinc-tion between the words topic and event. By event we mean that some action happened during certain time period and at certain location, e.g., the TWA-800 crash; by topic we mean a recurring and broader class of events, e.g., airplane accidents. An event includes a set of documents, and a topic consists of its children events 1 
Figure 1 shows the two-level scheme for FSD conditioned on topics. The first level is for the classification of docu-ments by topic, using a supervised learning algorithm[10]. The second level consists of several identical copies of an FSD algorithm: each is in charge of FSD for a particular topic. 
The FSD algorithm is extremely simple: when a new doc-ument arrives, it is compared to all the documents in its past ("the history"). If its nearest neighbor in the past has a cosine similarity score (or any reasonable choice of simi-larity measure) below a threshold, then the new document is labeled as "NEW", meaning it is the first story of a novel event; otherwise, it is labeled as "OLD". After this, the doc-ument is added to the history. The threshold is empirically set based on cross validation. This approach has been typ-ical among current FSD systems in the TDT benchmark evaluations, and has been reported in detail in previous pa-pers[9, 13]. When using the FSD algorithm in our two-level FSD scheme, the only modifications we made are that we use one FSD for each topic, and that each FSD keeps its local history (and the derived statistics) instead of the global history in a traditional FSD system. That is, documents are automatically routed to the corresponding topic by the classifier at the first level before they axe sent to the second level for novelty detection. 
The two-level scheme allows us to treat documents and words in different ways at each level. For topic-level clas-sification, we would like to give more weight to the topical discriminative words, like "airplane", "accident", "tornado", "hijacking", etc., while at the novelty detection level, we can also generate a stopword list for each topic based on how common a word is used in that topic, and give more weight to the event-level discriminative terms, like "TWA-800" or "September llth", for example. 
Since topical common words cause events in the same topic to be mutually confusing, and are a potential cause for a FSD system to miss the first story of a new event, a natural choice for us is to remove those words. We ob-tained a stopword list for each topic by thresholding on the training-set document frequency of a word: where n(Ti) is the number of documents on topic Ti; n(t, Ti) is the number of documents containing word t and on topic 1Events, not topics, have been the central foci in TDT; how-ever, for some historical reason, topic and event have been used interchangeably in the TDT literature.  X  N is the total number of documents in the local history  X  Wi,d is the within-document weight for word tl in the current vocabulary V (which is adaptive over time); U~,d is the within-document weight for Named Entity si E S, and S is the set of NEs extracted by far;  X  n(ti,d) is the within-document term frequency (TF) of word ti E V; n(sj, d) is the within-document NE frequency of NE s~ ~ S;  X  n(tl, D) is the within-collection document frequency of term t/and D is the collection of documents processed by far; n(sj, D) is the the within-collection document frequency of NE s~;  X  ak is the weight of the k th type of NEs, empirically tuned through validation. 
For empirical examination, ideally, we would like to have a document collection with a large number of manually la-beled topics and events, and with a reasonable number of documents for each event. In reality, such data sets are diffi-cult to find. The TDT benchmark collections, for example, have over 300 manually defined events but broad topic la-bels are not available, unfortunately. We also found that the TDT events are often sparsely labeled for a given topic, e.g., only three bombing events were labeled among many bomb-ing events actually reported in the TDT corpora. Those sparsely labeled events per topic do not allow us to thor-oughly examine the power of our method in differentiating mutually confusible events. We therefore created our own data collection for the evaluation. 
The source data, named Broadcast News and published by Primary Source Media, consists of 261,209 transcripts for news articles from ABC, CNN, NPR, and MSNBC in the pe-riod from 1992 to 1998. Each transcript comes along with a record that is composed of several fields, such as title, date, source, keywords, abstract and body. We only extracted the body field of each record into a "bag of words", and called it a document. Human-assigned keywords are informative for grouping documents that share a certain topic. For the experiments in this paper, we defined four broad topics -"Airplane Accidents", "Bombings", "Hijackings" and "Tor-nadoes" -and collected the on-topic documents using the corresponding keywords of each topic. 
For each topic, we identified a set of events by randomly sampling some documents within that topic and manually defining the events described in those documents. For each event, we created a brief description indicating what it is about, where and when it happened, who was involved, etc. The event definitions were used by humans to assign event labels to documents, but not used by the system. Further, we used the sampled documents for each event as the queries to retrieve similar documents from the pool of the docu-ments in the same topic. The pooled documents were man-ually labeled with respect to the defined events. 
Using this procedure, we intended to define 10 different events for each topic, but, for topic Hijackings, we only found 6 events in the data collection. Finally, by taking 
Figure 3: Similarity Matrices of Airplane Accidents: baseline and ideal case Several important areas need to be further studied in the future, including: 1. Situated role extraction for NEs: While we have shown 2. Automated hierarchical clustering: Instead of using 3. Adaptive learning at the topic classification level: Sub-stantial developments have been made recently in the We thank Charles Wayne from DoD for his guidance in the 
TDT task definition and evaluation. We also thank Fan Li who helped to create some runs of the topic-level classifica-tion. This research is sponsored in part by National Science 
Foundation (NSF) under the grant number KDI-9873009, and in part by NSF under the grant number IIS-9982226. 
However, any opinions or conclusions in this paper are the authors' and do not necessarily reflect those of the sponsors. [1] The 2001 topic detection and tracking (tdt2001) task definition and evaluation plan. In 2001. [2] J. Allan, V. Lavrenko, and H. Jin. First story detection in tdt is hard. Washiongton DC, 2000. Proceedings of the Ninth International Conference on 
Informaiton and Knowledge Management (CIKM). [3] T. Ault and Y. Yang. knn, rocchio and metrics for information filtering at trec-10. In Proceedings of 
TREC-IO, 2002 (to appear). [4] D. Bikel, S. Miller, R. Schwartz, and R. Weischedel. Nymble: a high-performance learning named-finder. In 
