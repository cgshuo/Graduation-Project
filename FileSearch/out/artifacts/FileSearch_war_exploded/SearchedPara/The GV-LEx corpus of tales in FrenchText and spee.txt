 David Doukhan 1  X  Sophie Rosset 1  X  Albert Rilliard 1  X  Christophe d X  X lessandro 1  X  Martine Adda-Decker 1,2 Abstract A corpus of French tales is presented. Its two parts, a text corpus and a speech corpus, were designed for studying the relationships between the textual struc-tures of tales and speech prosody, with the targeted application of an expressive text-to-speechsynthesis systemembedded in a humanoidrobot.The 89-tale textcorpus, and the 12-tale speech corpus were annotated using a common tale description framework. Lexical level annotations include extended definitions of enumerations, time, place and person named entities, as well as part of speech tags. Supra-lexical level annotations include the segmentation of tales into a sequence of episodes, the localization and attribution of direct quotations, together with tale protagonists co-references. Annota-tion distributions and inter-annotator agreement were analyzed. The largest coverage and strongest agreement were observed for person named entities, characters X  direct quotations, and their associated coreference chains. Speech corpus annotations were extended to allow the analysis of the relations between tale linguistic information and prosodic properties observed in associated speech. Word and phoneme boundaries were inferred through semi-automatic procedures, resulting in linguistic annotations aligned with the speech signal. Intonation stylization models were used to ease the visual and statistical analysis of tale X  X  prosody. Additional meta-information is provided with the speech corpus, allowing describing tale characters according to their gender, age, size, valence and kind. The corpora described in this article are publicly available through the European Language Resources Association catalog.
 Keywords Fairy tale corpus Annotation scheme Inter-annotator agreement Direct quotations Prosody Intonation stylization Text-to-speech Expressivity 1.1 Tales annotation and speech synthesis Tales tend to play a crucial role in children X  X  lives. Tales are used to entertain, educate, transmit moral values, help children to deal with their fears, and stimulate their imagination (Bettelheim 1976 ). Their content is rich, and often polysemous (Golden 1985 ). They may take place in imaginary environments, feature folkloric fantasy characters, as well as speaking animals or objects. They may also contain nested stories, leading to several narrative levels (Gerva  X  s 2010 ). These character-istics may challenge traditional information extraction (IE) systems, mostly conceived to deal with newspaper and medical texts (El Maarouf and Villaneau 2012 ; Goh et al. 2012 ). Automatic procedures extracting information from tales are required for a growing range of applications: story generation (Gerva  X  s et al. 2005 ), interactive storytelling (Grasbon and Braun 2001 ), child-oriented robot (El Maarouf and Villaneau 2012 ; Mutlu et al. 2006 ) and text-to-speech (TTS) (Zhang et al. 2003 ; Mamede and Chaleira 2004 ; Alm et al. 2005 ; Theune et al. 2006 ; Francisco et al. 2012 ). The corpora presented in this article are aimed at providing annotated tale resources in French. While these resources were mainly designed to address TTS issues, they are also valuable for the design of other tale-oriented IE systems.
The resources 1 presented in the present article were built to address a limitation of today X  X  TTS systems, which have difficulties to analyze texts above the level of the sentence. As a result, utterances are synthesized out of context, which may lead to intonational inconsistencies, and monotonous speech streams which are inappropriate for capturing the attention of a children audience. The strategy used to tackle this limitation is borrowed from the programmatic proposal of Hendricks ( 1967 ), i.e. analyzing the linguistic structures  X  X  X eyond the sentence X  X . It requires grouping together several levels of linguistic descriptions, in order to approach the text X  X  structure. Linguistic relations beyond the sentence level are of very different nature and fulfill a large set of functions. Some of the functions described by Hendricks include linguistic devices that may span several sentences, such as chains of coreferences between sentences, deictics, tense sequences, direct quotations and reported speech. The design of automatic procedures able to extract such information is highly ambitious, and requires dedicated corpora. Different existing studies are aimed at the automatic analysis of some of these functions. For example, the automatic detection of tale characters, and of anaphoric chains referring to each character were addressed by El Maarouf and Villaneau ( 2012 ). Higher-level functions may also be retrieved from text that could be relevant for several kinds of automatic analyses. Amongst the functions cited by Hendricks ( 1967 ), the more immediately relevant ones are linked with linguistic devices used to highlight parts of the text, and functions of the text structure. The latter functions are typically addressed in the work of Propp ( 1968 ), for Russian fairy tales. If this work is not strictly linguistic X  X nd may arguably be difficult to adapt to texts of different natures, similar descriptions of fairy tales X  text structure exist (e.g. Greimas and Courte ` s 1976 ), and may be closer to such an approach of beyond sentence functional description (cf. Greimas 1989 , for the description of a tale).

With a view to speech synthesis, several levels of linguistic information may enhance the intonation X  X  contextual relevance. Reliable segmentation schemes for tales may help the prediction of pauses X  length, known to be associated with episode boundaries (van Dijk 1982 ). They may also be used for the synthesis of prosodic instructions related to the position of sentences within paragraphs (Sluijter and Terken 2009 ). The identification of tale characters X  direct quotations are linked with prosodic shifts (Holt 1996 ), that can be used to increase speech synthesis variability and naturalness. Such direct quotations may also be associated to intonational and gestural effects aimed at mimicking the character being quoted. At another level, the anaphoric annotation of tale characters could help the attribution of quotations to the relevant character, the modeling of characters interactions, and the gathering of characters meta-information (age, sex, role ... ). While lexical-level information (time, place, and person named entities) does not address directly the need of  X  X  X bove sentence X  X  information, their detection is useful as an intermediary step for detecting higher level information (Gerva  X  s 2010 ; Lendvai et al. 2010 ).
Existing text and speech tale corpora, and existing approaches to represent tale information are reviewed in the next section. 1.2 Tale text corpora We are aware of few text corpora that have been built to address information extraction from tales. They are listed in Table 1 .

Story generation and interactive storytelling applications are the main motiva-tions for narrative structure annotations. One may refer to the presentation of this field proposed in Mani ( 2014 ) for a detailed view of this field. These applications (Grasbon and Braun 2001 ; Gerva  X  s et al. 2005 ) frequently represent tales on the basis of Propp X  X  narrative functions (Propp 1968 ). This coding scheme was initially defined to help the analysis and the classification of Russian fairy tales. It was used to annotate a corpus of Russian tales, and for the evaluation of narrative structure annotation systems (Malec 2010 ). Bod et al. ( 2012 ) reported a low inter-annotator agreement on the Proppian functions annotation task, highlighting the need for improved annotation guidelines. Other proposals for coding narrative schemes may be found e.g. in Ronfard and Szilas ( 2014 ).

AnnotationsaimedatTTSsynthesisweregenerallydesignedtohelptheselectionofa particular voice. Zhang et al. ( 2003 ) and Mamede and Chaleira ( 2004 ) gathered tales annotated with attributed direct quotations. The attribution of a particular voice to an identified tale character had to be done manually in a second stage. Alm et al. ( 2005 ) andFranciscoet al.( 2012 )annotatedtalecorporawithemotions,allowingtheautomatic selection of emotive voices (angry, sad, ... ).

Among other tale corpora, Goh et al. ( 2012 ) have annotated tales X  main characters. The underlying motivation of their work was to overcome the limitations of traditional named-entity recognition systems, generally restricted to the non-fictional domain. The Fairy Tales Corpus (FTC, El Maarouf and Villaneau 2012 ) contains tales written by adults and children, for child-directed language modeling. Annotations include hand-corrected lemmas and part of speech tags, together with verb semantic roles. Tale characters are tracked with identifiers, and assigned to an ontological category.

To our knowledge, the GV-LEx corpus presented here are, together with the FTC corpus, the only annotated resources of tales in French. Both of them address the annotation of tale character references. They differ in the annotation of episodes, direct quotations, enumerations and named entities in the GV-LEx corpus, versus hand-corrected linguistic information, semantic role labeling and character assign-ment to ontological categories in FTC. Annotations of direct quotations were performed at a larger scale in the GV-LEx corpus than in other reported tale corpora, allowing training statistical models. The proposed episode annotation scheme, a simplified version of Propp X  X  annotation guidelines, aims at the annotation of tales of various cultural origins. Extended named entities annotations may help the training and evaluation of named entity recognition models, suited to fictional texts, and could benefit to a large range of tale-related applications (Gerva  X  s 2010 ; Goh et al. 2012 ). 1.3 Tale speech corpora A list of speech corpora containing tales is given in Table 2 . With the exception of the corpus presented in Levin et al. ( 1982 ), all these resources were designed to improve TTS systems. The annotations used to describe speech corpora can be divided into two main types: annotations describing the speech signal (word and phoneme boundaries, pitch contours, perceived emotions ... ), and annotations describing the lexical content and the interactive structures (text type, lexical structures, discourse mode, co-references ... ).

All transcriptions of the corpora described in Table 2 were time-aligned with the speech signal. The accuracy of this temporal alignment is corpus-dependent. The alignment units considered were breath groups, words or phoneme boundaries. These boundaries can be obtained manually or through automatic and semi-automatic procedures. Levin et al. ( 1982 ) X  X  corpus is, to our knowledge, the earliest attempt to constitute a speech corpus of tales, with word level annotations. This corpus was aimed at describing lexical and prosodic differences between story-reading and story-telling. The other corpora used various annotation strategies to describe and explain prosodic phenomena. Fackrell et al. ( 2000 ) reports on a corpus composed of 3 different languages and 10 different text types (children stories, news, recipes, ... ). Klabbers and van Santen ( 2004 ) and Alm and Sproat ( 2005 ) report experiments carried out on a corpus labeled for studying foot pitch contours and the emotions perceived from the speech signal. Theune et al. ( 2006 ) presents a corpus aimed at modeling prosodic rules reproducing the storytelling X  X  speaking style, suspense and increasing climax. Adell et al. ( 2005 ) report on an emotion corpus with tagging inferred from text and discourse mode (narrative, descriptive, dialog, ... ).

The GV-LEx speech corpus, including 1 h of tales, compare well with the tale corpora reported in Table 2 , and is of suitable size to extract reliable prosodic information to drive TTS synthesis. The novelty of the proposed annotation scheme consists in episode annotations, attributed direct quotations, meta-information on tale characters, co-references, and named entities. The speech recordings were aligned at lexical and phonemic levels, allowing the description of prosody with a good precision for TTS applications. Stylized annotations describing the pitch, power and periodicity contours of the speech signal were added automatically. 1.4 The GV-LEx text and speech tale corpora The corpora more extensively described hereafter were developed in the framework of the GV-LEx project (Gesture and Voice for Expressive Reading, Gelin et al. 2010 ). The main goal of this project was to give a humanoid robot the ability of telling stories to a children audience.

Such resources are a prerequisite for building supra-sentential information extraction systems, and analyzing speech prosody variations or gestural patterns beyond the sentence level. Two corpora were designed: the first one contains written tales, the second one read tales. This paper describes their corresponding content, the labeling process, and annotations. The text corpus X  annotations aim at training and evaluating models for text segmentation (Hearst 1997 ), quotation detection (Weiser and Watrin 2012 ), attribution of quoted speech (Elson and McKeown 2010 ), named-entities extraction (Galibert et al. 2010 ) and co-reference resolution (Uzuner et al. 2012 ). An extension towards enumerative patterns, to be associated with intonational properties, is also given (Bodo et al. 2009 ). The annotations of the speech corpus aim at improved prosodic instructions via appropriate TTS rules. All the data and tools described in this article are gathered together in its ELRA-distributed archive. The archive contains both the text and speech corpora described below. The corpus annotation tool developed to suit the needs of the GV-LEx project is included within the archive, together with the stylized visual represen-tations of the prosodic correlates estimated from the speech corpus.
In the following are described the data representation choices, as well as the annotation protocol of the text corpus, in Sect. 2 . The design of the tales X  annotations is exposed in Sect. 2.3 . The validation of the annotation scheme described in Sects. 2.7 and 4.1 . The description of the speech corpus and of the stylization models simplifying the analysis of prosody are described in Sect. 3 . The paper is concluded by a discussion on the quality of the annotations, proposed in Sect. 4 . 2.1 Data collection Eighty-nine tales in French were collected. 2 The target scenario is a humanoid robot telling about 5 min long tales in front of a 7 X 8 year old audience. Language levels and themes fit for this age group were fixed, and tales were selected to fit both the criteria and the targeted audience. Selected tales also had to contain direct quotations from a minimum of two tale characters. The resulting corpus contains various traditional and contemporary texts featuring animals, fairy, magical, realistic or repetitive tales. 2.2 Text normalization Automated processing requires normalized textual representations. The conversion of HTML-formatted tales to plain text files was performed with Wmatch (Galibert 2009 ; Rosset et al. 2009 ). Some of the document-formatting information was kept in the resulting text files. Grammatical and spelling errors were then hand-corrected in the plain text files.

A tokenizer (Adda et al. 1997 ) was needed for segmentation of plain text files into words, punctuation marks, sentences and paragraphs. Words and punctuation marks were separated by single spaces, sentences by single line breaks, and paragraphs by double line breaks. Ambiguous punctuation marks (e.g. -,  X ) and sentence boundaries were resolved. Compound words including hyphens ( X  X  X hauve-souris X  X ) were considered as a single token. Clitics were split into several tokens (ex: automatically detected proper nouns.

A quantitative description of the 89 tokenized tales is presented in Table 3 . A tale contains an average of 752 words, 61 sentences, and 20 paragraphs. The first paragraph of tales was found to be equivalent to their title. A large variability was observed on the usage of paragraph marks. While some tales (excluding title) were split into two paragraphs only, some others may contain up to forty different paragraphs. Many paragraphs were associated to a possible indentation strategy, consisting in inserting paragraph marks before each direct quotation. Low mean sentence sizes usually correspond to tales containing many direct quotations, associated to simple post-quotation patterns (see example 1). The longest sentence sizes were observed for long descriptions, and tales having repetitive structures (example 2). 2.3 Text annotation methodology The 89 tales were divided between two annotators trained in linguistics, referred to as A1 and A2. A hierarchical XML storing scheme, associated to a document type definition (DTD), was used to encode annotations. Annotators were provided with annotation guidelines (in French) and a fully annotated tale. To perform text annotation on a textual corpus, there are now different tools. For example the Glozz platform (Widlo  X  cher and Mathet 2012 ) and the Brat annotation software (Stenetorp et al. 2012 ) are two different tools widely used for various annotation campaigns. Each of them has very interesting features, and presents some limitations (e.g. keyboard shortcuts, signal alignment, multilevel annotation and visualization, etc.). The GV-LEx consortium choses to develop its own tool in order to fit to the objectives of the project (see Fig. 1 ). It allows multi-level annotations and visualizations and compute statistics about each file or about a set of document. The DTD is used to generate the menus and submenus associated to any hierarchical annotation scheme, allowing dealing with potential changes in the coding scheme. Meanwhile, the other annotations software may easily be applied to the corpus to enrich further the existing annotations. A1 labeled 61 tales, and A2 35 tales, leading to a total of 96 distinct annotations. Seven tales were labeled by A1 and A2, and were used to estimate inter-annotator agreements (Sect. 4.1 ). Resulting annotation file names are formatted as &lt;tale id&gt; . &lt;annotator id&gt; . xml . &lt;tale id&gt; being a 3 digit identifier, &lt;annotator id&gt; being either &lt;A1&gt; or &lt;A2&gt; . Each tale is split into a sequence of episodes , describing the narrative structure. Direct quotations are marked as speech turns . Extensions of enumerations, and of the time, place, and person named entities are used. Speech turns and person entities are enriched with anaphoric annotations, allowing the tracking of characters and the attribution of quotations. A listing of the XML markers related to the annotations is provided in Table 4 . 2.4 Extended enumerations and extended named entities Annotators were asked to mark any pattern that could be associated to an enumeration or a list. These patterns include enumeration of items (example 3), adjectives (example 4), actions, or characters.

Extended named entities were defined to mark mentions to a tale character or group. They were also enriched with anaphoric annotations, enabling the identification of the characters. These mentions include proper names, pronouns, or any relevant nominal groups (example 5). Given the fictional nature of tales, characters can either be humans, animals, plants, or living objects.

Place named entities were defined to include any pattern referring to a given location (examples 6). Similarly, time named entities refer to date, time, or periods (examples 7). Composition operations were allowed, to describe an entity relatively to another (example 8). 2.5 Speech turns Speech turn annotations were defined to mark direct quotations (example 9). They are not necessarily associated to quotation markers (double quotes, quotation dashes). Character speech turns ( &lt;spkr&gt; ) were defined as text segments containing the character X  X  direct quotations. They enclose the contiguous portions of text belonging to a single tale character, ranging from a few words to several sentences, and store the character X  X  anaphoric identifier. In some situations, the narrator may be one of the characters, and thus can quote his own speech (example 10); in this particular case, the anaphoric identifier is set to 0. The different characters X  speech turns are interleaved with narrative text excluding direct quotations, termed as narrator speech turn ( &lt;narr&gt; ). 2.6 Narrative structure Narrative structure annotations were defined as the segmentation of tales into sequences of labeled episodes . This approach is inspired from Propp X  X  structural theory, designed for the representation of Russian fairy tales as linear sequences of tale functions (Propp 1968 ). Fairy tales being a particular kind of children tales, more general structural annotations were necessary to fit the different kinds of tales composing the GV-LEx corpus (animal, repetition, realistic ... ). Propp X  X  representa-tions of tales are sequences of high-level functions, without tracks of the function boundaries within the text. It is well suited to tales classification, and it is used in contemporary research mostly for tales generation (Grasbon and Braun 2001 ; Gerva  X  s et al. 2005 ). For the narrative annotation model presented here aims at extracting text segments for prosodic purposes.  X  X  X cenes X  X  were defined thanks to elements of discourse analysis and computational discourse processing: episodes (van Dijk 1982 ), and subtopic passages (Hearst 1997 ). Resulting episodic annotations were defined as linear and non-overlapping segments, spanning over one or more sentences.
Beyond the title which is considered it X  X  own category, a set of five episodic categories was defined to structure the tale (see Table 5 ). This set is useful for the segmentation of tales from various epochs and cultural origins: exposition contains the setting of the story (place, main characters, etc.), which is equivalent to the Proppian initial situation . The triggering event covers the first eleven tale functions defined by Propp. It lasts from the end of the tale X  X  exposition , until the symbolic departure of the hero. It corresponds to the events altering the tale X  X  initial situation, resulting in a sequence of actions. It may correspond to the death of a character, the violation of an interdiction, etc. The triggering event can be followed by several episodes labeled as scenes and refrains . Refrains are used to mark portions of text having nearly identical surface manifestations within the tale. Scenes are the default episodic category. Their definition is mostly based on episodes (van Dijk 1982 ), and subtopic passages (Hearst 1997 ). Scene boundaries are associated with time, place, character, topic changes, or with the identification of a refrain . The last episode of the tale is generally labeled as epilogue . It may contain a moral, or some of the last five tale functions defined by Propp (recognition, exposure, transfiguration, punishment, wedding). 2.7 Annotations, coverage, and distributions These annotations have been applied to our corpus. Their distribution in the 89 tales of the corpus is analyzed here. One annotation per tale is considered, to avoid overrepresentation of tales annotated twice. Annotator A2 X  X  annotations were kept when two annotations were available, to balance the influence of each annotator in this description. This choice results in the description of 54 tales labeled by A1 and 35 tales labeled by A2. Coverage percentages reported below were obtained considering the number of words covered by a given marker (punctuation signs were excluded). A summary of the markers X  distributions and coverage is provided in Table 5 .
All tales contain a title, and an average of five scenes. Most tales have an exposition and an epilogue, and to a lesser extent a triggering event. Scenes are generally longer than the other episodic categories, and cover the largest amount of the corpus. Epilogues and triggering events are shorter than tales X  initial situations. Refrains were identified in 20 % of the tales: they constitute the episodic category with the lowest coverage, and the smallest length (except the obviously shorter title).
The corpus contains a large amount of direct quotations of characters. Direct quotations of the narrator were found in a single tale. Depending on the tale, the coverage of characters X  direct quotations vary from 4.5 to 72 %, with an average coverage of 30 %. 381 characters are quoted within the corpus, i.e. a median of four speaking characters per tale, and a maximum of 14. Narrator X  X  sentences are generally longer than for other characters, with a median length of 11 words, versus 7. Quoted text was defined as the portions of text enclosed in double quotes, or belonging to a normalized sentence beginning with a quotation dash. Quoted text represents 23.7 % of the tales X  text. 88 % of the quoted text is associated to a character X  X  direct quotations, while the remaining 12 % are associated to non quoted text.
Enumerations cover 20 % of the corpus. 18 % of these structures span over complete sentences. In the case of named entities, the proportion of person named entities is larger than for those of place and time entities leading to an average of respectively 106.7, 15.2 and 10.2 entities per tale. A compositional analysis of named entities shows that 13.6 % of place and 2 % of time named entities are defined relatively to a person named entity. Other compositional schemes (a person defined relatively to another person, or to a place, etc.) are rare (less than 1 %).
Part-of-speech tags obtained through automatic procedures (TreeTagger: Stein and Schmid 1995 ) were used to describe the structure of person entities. The largest amount of these patterns were single personal pronouns (52 %), articles followed by noun (15 %), proper names (7 %), possessive pronouns followed by nouns (3.6 %), article ? adjective ? noun (2.6 %). The remaining 17 % marked references had various structure and complexity. However 99 % of person named entities refer to patterns enclosing five or less words.

The description of co-reference chains for the speech turn blocks and the extended named entities is provided in Table 6 . The size of speech turn co-reference chains refers to the number of contiguous blocks in tale texts related to the direct quotations of a given character. The 9500 extended person entities refer to 922 distinct characters. Thus, about 41 % of the characters identified in tales are at least associated to one speech turn. The largest amount of markers referencing tale characters was used to track these  X  X  X peaking characters X  X  (76.7 %). 27 % of the character markers were used to identify characters mentioned only once in a tale. The median length for a speaking characters co-reference chain was 13, and may be as long as 90. The GV-LEx speech corpus contains annotated recordings of a subset of twelve tales of the GV-LEx text corpus. The text corpus annotation scheme is extended to include signal-dependent information, together with meta-data related to tale speaking characters. Prosodic stylization procedures are also included. This corpus is dedicated (but not limited) to TTS research, with special attention to relationships between text structures and prosodic features. 3.1 Recording procedure Twelve tales of the text corpus were selected for recording by a professional male speaker, well acquainted to studio recording sessions. Normalized tale texts were provided to the speaker before the recording session. The speaker was allowed to modify the text portions he judged unnatural to utter. He was informed of the study X  X  goals, and instructed to produce recordings targeted to a children audience.
Tales were recorded in a professional studio, resulting in a corpus of about 1 h of speech, in audiobook quality. Recordings were digitized using 32 bit floating-point values, with a sample rate of 48 kHz. They contain two channels obtained from two different microphones. A Neumann U87 microphone, suited to speech and musical studio recordings, was used to obtain the first channel. The second channel was recorded using an Earthworks M30 microphone, more suited to acoustic measure-ments. The Earthworks microphone was calibrated with a Bru  X  el and Kj X r sound pressure reference, allowing for true sound intensity analysis. 3.2 Speech transcriptions Lexical transcriptions were checked manually, comparing the GV-LEx text corpus tales and corresponding recordings. Considering the 9664 transcribed words, differences between tale texts and speaker X  X  transcriptions are only marginal: 40 word deletions, 31 word insertions, 41 word modifications (including synonym substitution) and 4 word shifts within sentences. The low amount of differences observed (about 1 %) accounts for a good fidelity to the text. A manual inspection of these differences showed that the modifications occurred only at the sentence level, without affecting neither tale nor sentence structure.

Statistics of the resulting transcriptions are given in Table 7 . Small differences are observed between the subset of recorded tales and the full text corpus (described Sect. 2 ). In particular, recorded tales are on average longer, with a mean size above 800 words. 3.3 Linguistic annotations Linguistic annotations used for the labelling of the text corpus (Sect. 2.3 ) were manually adapted, in order to take into account the small differences occurring between tale texts and their corresponding speech transcriptions. Annotation coverage statistics corresponding to these twelve tale transcriptions are presented in Table 8 . Coverage comparison between the twelve tales of the speech corpus and the 89 tales of the text corpus (Table 5 ) shows few differences. The percentage of words corresponding to character X  X  direct quotations is higher in the speech corpus than in the text corpus: (40 % instead of 30 %). This high amount of direct speech makes the speech corpus highly suited for the analysis of the prosodic correlates of character embodiment. For a more detailed analysis, a set a static features describing a character X  X  age, gender, kind, valence, and height is added in the corpus. 3.4 Speech-specific annotations using word and phonetic alignments Word, phoneme and speech signal alignment are very helpful for prosodic studies. This information, together with extra-phonemic events (audible breaths, hesita-tions, ... ), was obtained through an alignment procedure. Automatic alignment, instead of manual alignment, is required because of the relatively large amount of speech data considered. In addition, automatic alignment methods are often more consistent than manual alignments (Astesano et al. 1995 ).

The alignment procedure was performed by manually annotating breath group boundaries in the speech signal using Praat (Boersma 2002 ), and by associating these segments to the corresponding speech transcriptions. These breath groups were then automatically aligned using a pronunciation dictionary with relevant variants Adda-Decker and Lamel ( 1999 ). The LIMSI French speech recognition system Gauvain et al. ( 2005 ) made use of the manual transcription and the pronunciation variants in forced alignment mode to produce the most plausible phonetic transcription and segmentation of the utterances. Raw statistics related to the phonetic alignment are given in Table 9 . Phonetic transcriptions were then used to infer units used for rhythm analysis: syllables and Inter Perceptual Center Group (IPCG). These units were obtained automatically through Adda-Decker et al. ( 2005 ) syllabification rules for French and Barbosa and Bailly ( 1994 ) procedures.
Word, syllables, IPCG and phone boundaries are stored in Praat TextGrids (Boersma 2002 ). TextGrids are useful and widely used in prosodic research. Punctuation marks in the text are stored as a point tier. This allows the analysis of the relations between punctuation marks in text, and pause realization in spoken utterances. All the linguistic annotation levels (episodes, direct quotations) presented above are associated to an interval tier. An example of transcription alignment is given in Fig. 2 . 3.5 Prosodic representation and stylization In addition to the word and phone segmentations, intonation contours of all the tales were computed. Prosodic stylization is useful for intonation analysis. Raw melodic curves are reduced to syllable-size melodic segments. Stylized and original pitch contours are in principle perceptually indistinguishable, discarding small and poorly relevant pitch information.

Raw intonation contours, stylized intonation, periodicity and loudness contours are stored into spreadsheets. Visual representations and spreadsheets are provided with the corpus.

Estimation of the speech fundamental frequency (a main correlate to pitch), short term power (linked to loudness) and periodicity (corresponding to voiced/unvoiced parts) are obtained with the Yin algorithm (De Cheveigne  X  and Kawahara 2002 ). The following parameter set is used: a minimal f0 of 40 Hz, a maximal f0 of 1000 Hz, a window size = 25 ms and the  X  X op X  parameter set at 2 ms. Pitch estimations are expressed in semitones (st) relative to 1 Hz (110 Hz = 81.38 semitones). Power is expressed in dB, and obtained through Eq. 1 .
 with P and P Ref the period-smoothed instantaneous power estimated by Yin. P being the power of the considered windows, and P Ref the maximal power found in the recordings. This results in power estimates in the range of  X  0 ; 35  X  dB, 35 being a threshold under which pitch and power estimations are not taken into account by the proposed stylization model. Periodicity estimation may be seen as a measure of the reliability of pitch estimation for a given window, following Eq. 2 : Ap Yin being Yin X  X  periodicity measure (ranging  X  0 ;  X  inf  X  ). According to De Cheveigne  X  and Kawahara ( 2002 ), pitch estimations associated to periodicity coefficients below 0.6 are considered uncertain, range ]0.6 X 0.8] is considered as good, values above 0.8 correspond to the best pitch estimations.

Figure 3 shows the superposition of the raw and stylized intonation contours, aligned with word and phoneme annotations.

In the raw intonation contours, pitch curves are plotted with a width proportional to signal power in dB. This display enhances audible portions of the signal, and combine time, pitch, power, and periodicity estimations into 3D meshes. Data associated to power below 35 dB results in a width of 0 and is not plotted. Periodicity estimates are mapped to colors corresponding to MatlabJet color code (dark blue for the lowest periodicity estimates, and dark red for the highest estimates). This provides information on the pitch estimation reliability, as well as on voice quality.

The stylized contours are obtained adapting d X  X lessandro and Mertens ( 1995 ) model of tonal perception. The model maps each syllable X  X  pitch contour to tonal segments representing the perceived pitch.

Pitch estimates with periodicity estimates below 0.2, or power below 32.5 dB were discarded. The retained pitch and power estimates are filtered through a weighted time average model (WTAM) defined by Eq. 3 : With f being either the pitch estimate (in Hz), or the power estimate in dB. The model is used with a differential threshold of pitch change set at 12 st/s, and without glissando threshold. Width of segments is proportional to the weighted time average power estimation at segment boundaries. Segments having slopes above 100 st/s were considered as invalid, and removed from the observations. Tonal segments are plotted over the raw pitch contour with a transparent blue color.

Stylization spreadsheet inputs correspond to vocalic segments. Fields include segmentation boundaries, together with automatically updated boundaries (period-icity above 0.2, power above 32.5 dB, and no pitch segment slope above 100 st/s). Mean, median, maximal, and minimal values of pitch, power, and periodicity are reported within the automatically corrected boundaries. Temporal positions of tonal segment boundaries are reported, together with the associated weighted time average estimates of pitch and power. 4.1 Inter-annotator agreement on episodes An important question is the quality and reliability of annotations in the text corpus. As human annotation is an interpretation process (Leech 1997 ), its evaluation is based on agreement rather than on ground truth. Consistency of annotation for the text corpus was obtained on the seven tales annotated by both A1 and A2, with the help of inter-annotator agreement measures.

Episodic labeling is a particular case of text segmentation into blocks, associated with a block labeling. Table 10 describes the strict agreement for each episodic category. The F-measure is used as an agreement estimator similar to Cohen X  X  Kappa for unit detection (Hripcsak and Rothschild 2005 ). Therefore, it can be interpreted using the scale proposed in Landis and Koch ( 1977 ). Using this scale,  X  X  X air X  X  agreement was reported for exposition, triggering event, and scenes;  X  X  X ubstantial X  X  agreement was reported for epilogue, and  X  X  X erfect X  X  agreement was reported for refrains. However, this is only indicative, because of the relatively small amount of episodes considered, for expositions, refrains, scenes and triggering events.

For more reliable statistics, episodic boundaries are considered in place of episode units. For this sake, tales are converted into binary sequences of sentence boundaries (1 if a sentence boundary is also an episode boundary, and 0 otherwise). Consequently, a tale containing M sentences segmented into N episodes is mapped to a  X  M 1  X  element vector containing  X  N 1  X  episode boundaries.

Sequences associated to the seven tales were then concatenated to build a single vector used in the following agreement estimations.

A F-measure of 0.66 and a coefficient j  X  0 : 59 was observed on the corpus. It can be considered as a substantial agreement, comparable to agreements reported for similar tasks (Artstein and Poesio 2008 ). Note that Cohen X  X  Kappa and F-Measure process on an equal basis both close and distant boundary differences. The resulting agreement estimations on segmentation tasks are often considered pessimistic, given the annotators tendency to agree on most of the segments length, and disagree on segments exact boundaries (Beeferman et al. 1999 ). 4.2 Inter-annotator agreement on structural and lexical elements Structural and lexical units include speech turns, enumerations, as well as time, place, and person extended named entities. Characters speech turns were analyzed without considering the narrator speech turns. Then, speech turn agreement analysis is rather a unit identification task than a text segmentation task. Following Grouin et al. ( 2011 ) and Fort et al. ( 2012 ), F-Measure ( F ) and slot error rate ( SER ) were used to describe agreements.
 where | A 1| and | A 2| are the number of same class units annotated by A1 and A2. sm is the number of strict matches between A1 and A2. pm is the amount of partial matches: units of the same category covering common portions of text but having different boundaries. e is the number of units that do not match at all, defined as e  X j A 1 j X j A 2 j 2 sm 2 pm .
 Agreement estimates for the lexical and structural units are given in Table 11 . Whatever the metric, speech turns show a near-perfect agreement. Despite the difficulty of determining to what extent a plant, object or animal may be considered as a tale character, the agreements reported for the extended person named entities was high. The use of extended definitions of time and place named entity led to a substantial agreement. Note that relatively large amounts of partial matches were found for enumeration place named entities. 4.3 Inter-annotator agreement on tale character references Reference characters are encoded within the extended person named entities, and at the speech turn level (this aspect has been discussed in the preceding section). Following Artstein and Poesio ( 2008 ) and Passonneau ( 2004 ) recommendations, agreement was measured for co-reference chains using Krippendorff X  X  alpha with d , Jaccard ( d j ), and MASI ( d m ) metrics (Krippendorff 1980 ) . Krippendorff X  X  alpha considers units that are labeled by a minimum of two coders. Consequently, units identified as person named entity or character speech turn by a single annotator were not taken into account by this measure.

Following Uzuner et al. ( 2012 ), adaptations of the F-Measure were also used for anaphoric agreement estimation. This adaptation consists in considering co-reference pairs rather than co-reference chains, and is defined in Eq. 6 . Two variants of this measure were implemented: F  X  being the optimistic variant, inferring the reference pairs considering only the units identified by annotator A1 and A2. F being the pessimistic variant, considering each annotated unit, and penalizing both unit identification and reference annotation.
 The agreement estimates for co-reference annotations are provided in Table 12 . For Alpha coefficients greater than 0.8, person entities and speech turns anaphoric annotations can be considered as reliable (Krippendorff 1980 ). Agreement on speech turn anaphoric chains annotation is almost complete. This observation may be explained by the ease of this task, together with lower amount of speech turn units, and smaller co-reference chains length. F-Measure estimations showed good agreement, in comparison with the results reported in the 2011 i2b2/VA Challenge corpora (Uzuner et al. 2012 ). The lower agreement estimation obtained for person entity pairs using the pessimistic F-Measure is mostly due to a poor agreement on the corresponding unit identification. 4.4 Conclusion We presented a corpus including both written and spoken tales in French. Both text and speech have been annotated using a shared framework. Specific annotation tools were developed for this purpose.

The 89 tales X  text corpus was designed for tale information extraction, particularly for improving the natural language processing modules of TTS systems. The 12 tales X  speech corpus was designed to describe the relations between information annotated in written tales and prosodic properties observed in speech. These relations may then be modeled by rules, or using machine learning techniques. The GV-LEx corpus is distributed through the ELRA catalog, 3 together with the annotation tool used for corpus tagging, and which can be easily adapted to any other hierarchical annotation scheme described with a DTD.

Tales were segmented into sequences of labeled episodes inspired by Propp X  X  structural formalism (Propp 1968 ). They were annotated in terms of direct quotations, named entities, co-references and enumerations. As mentioned in (Declerck and Scheidel 2010 ; Gerva  X  s 2010 ; Lendvai et al. 2010 ), such corpora are of great value for fictional-text oriented information processing. Inter-annotator agreement and coverage analyses showed a high annotation reliability of direct quotations, extended person named entities, and their respective coreference chains.
The segmentation of the tales had to use a generalized scheme, as tales were of very different natures. The proposed scheme allows a common description for all of them, on the basis of a restricted set of 5 scenes X  types (plus the title). Not all these types were found in each tale. The results validate the linguistic structures chosen to describe tales, with respect to the speech synthesis issues. While episodic categories were not necessarily associated to the strongest inter-annotator agreements, they exhibit statistically significant prosodic properties that could be used to improve TTS systems (e.g. varying pause durations influencing the rhythm of tales X  delivery: cf. Doukhan et al. 2012a ). Meta-information describing a tale character X  X  age, gender, kind, valence, height, Proppian character type (Propp 1968 ) and Greimas actant category (Greimas 1966 ) were also used to extend speech corpus annotations. This allowed us to describe the prosodic correlates associated with character embodiment (Doukhan et al. 2011 ), and we plan to extend the whole text corpus with character meta-information.
The text corpus was used to train and evaluate models of episode segmentation, and speech turn detection. These models were included into the natural language processing module of a TTS and gesture synthesis system embed in a robot.
The speech corpus provides recordings of read tales in French. It includes word and phoneme boundaries aligned with the signal, together with the corresponding linguistic annotations. It is useful for the description and analysis of tale prosody, in relation with the linguistic structure. For instance, read tale speaking style was described, and compared to other speaking styles (political address, radio news, dialogue) in Doukhan et al. ( 2011 , 2012a ).

The results of the acoustic-prosodic analyses demonstrated the richness and the complexity of prosodic patterns occurring in read tales. It also showed larger prosodic variations in read tales than in the other reported speaking styles, which highlights the need for domain-specific resources to describe tales X  prosody. The outcome of this analysis allowed us to define prosodic rules for reading tales in TTS. With the help of the GV-LEx corpus, a storyteller robot prototype was successfully presented (Doukhan et al. 2011 , 2012a ; Doukhan 2013 ).
 References
 David Doukhan 1  X  Sophie Rosset 1  X  Albert Rilliard 1  X  Christophe d X  X lessandro 1  X  Martine Adda-Decker 1,2 Abstract A corpus of French tales is presented. Its two parts, a text corpus and a speech corpus, were designed for studying the relationships between the textual struc-tures of tales and speech prosody, with the targeted application of an expressive text-to-speechsynthesis systemembedded in a humanoidrobot.The 89-tale textcorpus, and the 12-tale speech corpus were annotated using a common tale description framework. Lexical level annotations include extended definitions of enumerations, time, place and person named entities, as well as part of speech tags. Supra-lexical level annotations include the segmentation of tales into a sequence of episodes, the localization and attribution of direct quotations, together with tale protagonists co-references. Annota-tion distributions and inter-annotator agreement were analyzed. The largest coverage and strongest agreement were observed for person named entities, characters X  direct quotations, and their associated coreference chains. Speech corpus annotations were extended to allow the analysis of the relations between tale linguistic information and prosodic properties observed in associated speech. Word and phoneme boundaries were inferred through semi-automatic procedures, resulting in linguistic annotations aligned with the speech signal. Intonation stylization models were used to ease the visual and statistical analysis of tale X  X  prosody. Additional meta-information is provided with the speech corpus, allowing describing tale characters according to their gender, age, size, valence and kind. The corpora described in this article are publicly available through the European Language Resources Association catalog.
 Keywords Fairy tale corpus Annotation scheme Inter-annotator agreement Direct quotations Prosody Intonation stylization Text-to-speech Expressivity 1.1 Tales annotation and speech synthesis Tales tend to play a crucial role in children X  X  lives. Tales are used to entertain, educate, transmit moral values, help children to deal with their fears, and stimulate their imagination (Bettelheim 1976 ). Their content is rich, and often polysemous (Golden 1985 ). They may take place in imaginary environments, feature folkloric fantasy characters, as well as speaking animals or objects. They may also contain nested stories, leading to several narrative levels (Gerva  X  s 2010 ). These character-istics may challenge traditional information extraction (IE) systems, mostly conceived to deal with newspaper and medical texts (El Maarouf and Villaneau 2012 ; Goh et al. 2012 ). Automatic procedures extracting information from tales are required for a growing range of applications: story generation (Gerva  X  s et al. 2005 ), interactive storytelling (Grasbon and Braun 2001 ), child-oriented robot (El Maarouf and Villaneau 2012 ; Mutlu et al. 2006 ) and text-to-speech (TTS) (Zhang et al. 2003 ; Mamede and Chaleira 2004 ; Alm et al. 2005 ; Theune et al. 2006 ; Francisco et al. 2012 ). The corpora presented in this article are aimed at providing annotated tale resources in French. While these resources were mainly designed to address TTS issues, they are also valuable for the design of other tale-oriented IE systems.
The resources 1 presented in the present article were built to address a limitation of today X  X  TTS systems, which have difficulties to analyze texts above the level of the sentence. As a result, utterances are synthesized out of context, which may lead to intonational inconsistencies, and monotonous speech streams which are inappropriate for capturing the attention of a children audience. The strategy used to tackle this limitation is borrowed from the programmatic proposal of Hendricks ( 1967 ), i.e. analyzing the linguistic structures  X  X  X eyond the sentence X  X . It requires grouping together several levels of linguistic descriptions, in order to approach the text X  X  structure. Linguistic relations beyond the sentence level are of very different nature and fulfill a large set of functions. Some of the functions described by Hendricks include linguistic devices that may span several sentences, such as chains of coreferences between sentences, deictics, tense sequences, direct quotations and reported speech. The design of automatic procedures able to extract such information is highly ambitious, and requires dedicated corpora. Different existing studies are aimed at the automatic analysis of some of these functions. For example, the automatic detection of tale characters, and of anaphoric chains referring to each character were addressed by El Maarouf and Villaneau ( 2012 ). Higher-level functions may also be retrieved from text that could be relevant for several kinds of automatic analyses. Amongst the functions cited by Hendricks ( 1967 ), the more immediately relevant ones are linked with linguistic devices used to highlight parts of the text, and functions of the text structure. The latter functions are typically addressed in the work of Propp ( 1968 ), for Russian fairy tales. If this work is not strictly linguistic X  X nd may arguably be difficult to adapt to texts of different natures, similar descriptions of fairy tales X  text structure exist (e.g. Greimas and Courte ` s 1976 ), and may be closer to such an approach of beyond sentence functional description (cf. Greimas 1989 , for the description of a tale).

With a view to speech synthesis, several levels of linguistic information may enhance the intonation X  X  contextual relevance. Reliable segmentation schemes for tales may help the prediction of pauses X  length, known to be associated with episode boundaries (van Dijk 1982 ). They may also be used for the synthesis of prosodic instructions related to the position of sentences within paragraphs (Sluijter and Terken 2009 ). The identification of tale characters X  direct quotations are linked with prosodic shifts (Holt 1996 ), that can be used to increase speech synthesis variability and naturalness. Such direct quotations may also be associated to intonational and gestural effects aimed at mimicking the character being quoted. At another level, the anaphoric annotation of tale characters could help the attribution of quotations to the relevant character, the modeling of characters interactions, and the gathering of characters meta-information (age, sex, role ... ). While lexical-level information (time, place, and person named entities) does not address directly the need of  X  X  X bove sentence X  X  information, their detection is useful as an intermediary step for detecting higher level information (Gerva  X  s 2010 ; Lendvai et al. 2010 ).
Existing text and speech tale corpora, and existing approaches to represent tale information are reviewed in the next section. 1.2 Tale text corpora We are aware of few text corpora that have been built to address information extraction from tales. They are listed in Table 1 .

Story generation and interactive storytelling applications are the main motiva-tions for narrative structure annotations. One may refer to the presentation of this field proposed in Mani ( 2014 ) for a detailed view of this field. These applications (Grasbon and Braun 2001 ; Gerva  X  s et al. 2005 ) frequently represent tales on the basis of Propp X  X  narrative functions (Propp 1968 ). This coding scheme was initially defined to help the analysis and the classification of Russian fairy tales. It was used to annotate a corpus of Russian tales, and for the evaluation of narrative structure annotation systems (Malec 2010 ). Bod et al. ( 2012 ) reported a low inter-annotator agreement on the Proppian functions annotation task, highlighting the need for improved annotation guidelines. Other proposals for coding narrative schemes may be found e.g. in Ronfard and Szilas ( 2014 ).

AnnotationsaimedatTTSsynthesisweregenerallydesignedtohelptheselectionofa particular voice. Zhang et al. ( 2003 ) and Mamede and Chaleira ( 2004 ) gathered tales annotated with attributed direct quotations. The attribution of a particular voice to an identified tale character had to be done manually in a second stage. Alm et al. ( 2005 ) andFranciscoet al.( 2012 )annotatedtalecorporawithemotions,allowingtheautomatic selection of emotive voices (angry, sad, ... ).

Among other tale corpora, Goh et al. ( 2012 ) have annotated tales X  main characters. The underlying motivation of their work was to overcome the limitations of traditional named-entity recognition systems, generally restricted to the non-fictional domain. The Fairy Tales Corpus (FTC, El Maarouf and Villaneau 2012 ) contains tales written by adults and children, for child-directed language modeling. Annotations include hand-corrected lemmas and part of speech tags, together with verb semantic roles. Tale characters are tracked with identifiers, and assigned to an ontological category.

To our knowledge, the GV-LEx corpus presented here are, together with the FTC corpus, the only annotated resources of tales in French. Both of them address the annotation of tale character references. They differ in the annotation of episodes, direct quotations, enumerations and named entities in the GV-LEx corpus, versus hand-corrected linguistic information, semantic role labeling and character assign-ment to ontological categories in FTC. Annotations of direct quotations were performed at a larger scale in the GV-LEx corpus than in other reported tale corpora, allowing training statistical models. The proposed episode annotation scheme, a simplified version of Propp X  X  annotation guidelines, aims at the annotation of tales of various cultural origins. Extended named entities annotations may help the training and evaluation of named entity recognition models, suited to fictional texts, and could benefit to a large range of tale-related applications (Gerva  X  s 2010 ; Goh et al. 2012 ). 1.3 Tale speech corpora A list of speech corpora containing tales is given in Table 2 . With the exception of the corpus presented in Levin et al. ( 1982 ), all these resources were designed to improve TTS systems. The annotations used to describe speech corpora can be divided into two main types: annotations describing the speech signal (word and phoneme boundaries, pitch contours, perceived emotions ... ), and annotations describing the lexical content and the interactive structures (text type, lexical structures, discourse mode, co-references ... ).

All transcriptions of the corpora described in Table 2 were time-aligned with the speech signal. The accuracy of this temporal alignment is corpus-dependent. The alignment units considered were breath groups, words or phoneme boundaries. These boundaries can be obtained manually or through automatic and semi-automatic procedures. Levin et al. ( 1982 ) X  X  corpus is, to our knowledge, the earliest attempt to constitute a speech corpus of tales, with word level annotations. This corpus was aimed at describing lexical and prosodic differences between story-reading and story-telling. The other corpora used various annotation strategies to describe and explain prosodic phenomena. Fackrell et al. ( 2000 ) reports on a corpus composed of 3 different languages and 10 different text types (children stories, news, recipes, ... ). Klabbers and van Santen ( 2004 ) and Alm and Sproat ( 2005 ) report experiments carried out on a corpus labeled for studying foot pitch contours and the emotions perceived from the speech signal. Theune et al. ( 2006 ) presents a corpus aimed at modeling prosodic rules reproducing the storytelling X  X  speaking style, suspense and increasing climax. Adell et al. ( 2005 ) report on an emotion corpus with tagging inferred from text and discourse mode (narrative, descriptive, dialog, ... ).

The GV-LEx speech corpus, including 1 h of tales, compare well with the tale corpora reported in Table 2 , and is of suitable size to extract reliable prosodic information to drive TTS synthesis. The novelty of the proposed annotation scheme consists in episode annotations, attributed direct quotations, meta-information on tale characters, co-references, and named entities. The speech recordings were aligned at lexical and phonemic levels, allowing the description of prosody with a good precision for TTS applications. Stylized annotations describing the pitch, power and periodicity contours of the speech signal were added automatically. 1.4 The GV-LEx text and speech tale corpora The corpora more extensively described hereafter were developed in the framework of the GV-LEx project (Gesture and Voice for Expressive Reading, Gelin et al. 2010 ). The main goal of this project was to give a humanoid robot the ability of telling stories to a children audience.

Such resources are a prerequisite for building supra-sentential information extraction systems, and analyzing speech prosody variations or gestural patterns beyond the sentence level. Two corpora were designed: the first one contains written tales, the second one read tales. This paper describes their corresponding content, the labeling process, and annotations. The text corpus X  annotations aim at training and evaluating models for text segmentation (Hearst 1997 ), quotation detection (Weiser and Watrin 2012 ), attribution of quoted speech (Elson and McKeown 2010 ), named-entities extraction (Galibert et al. 2010 ) and co-reference resolution (Uzuner et al. 2012 ). An extension towards enumerative patterns, to be associated with intonational properties, is also given (Bodo et al. 2009 ). The annotations of the speech corpus aim at improved prosodic instructions via appropriate TTS rules. All the data and tools described in this article are gathered together in its ELRA-distributed archive. The archive contains both the text and speech corpora described below. The corpus annotation tool developed to suit the needs of the GV-LEx project is included within the archive, together with the stylized visual represen-tations of the prosodic correlates estimated from the speech corpus.
In the following are described the data representation choices, as well as the annotation protocol of the text corpus, in Sect. 2 . The design of the tales X  annotations is exposed in Sect. 2.3 . The validation of the annotation scheme described in Sects. 2.7 and 4.1 . The description of the speech corpus and of the stylization models simplifying the analysis of prosody are described in Sect. 3 . The paper is concluded by a discussion on the quality of the annotations, proposed in Sect. 4 . 2.1 Data collection Eighty-nine tales in French were collected. 2 The target scenario is a humanoid robot telling about 5 min long tales in front of a 7 X 8 year old audience. Language levels and themes fit for this age group were fixed, and tales were selected to fit both the criteria and the targeted audience. Selected tales also had to contain direct quotations from a minimum of two tale characters. The resulting corpus contains various traditional and contemporary texts featuring animals, fairy, magical, realistic or repetitive tales. 2.2 Text normalization Automated processing requires normalized textual representations. The conversion of HTML-formatted tales to plain text files was performed with Wmatch (Galibert 2009 ; Rosset et al. 2009 ). Some of the document-formatting information was kept in the resulting text files. Grammatical and spelling errors were then hand-corrected in the plain text files.

A tokenizer (Adda et al. 1997 ) was needed for segmentation of plain text files into words, punctuation marks, sentences and paragraphs. Words and punctuation marks were separated by single spaces, sentences by single line breaks, and paragraphs by double line breaks. Ambiguous punctuation marks (e.g. -,  X ) and sentence boundaries were resolved. Compound words including hyphens ( X  X  X hauve-souris X  X ) were considered as a single token. Clitics were split into several tokens (ex: automatically detected proper nouns.

A quantitative description of the 89 tokenized tales is presented in Table 3 . A tale contains an average of 752 words, 61 sentences, and 20 paragraphs. The first paragraph of tales was found to be equivalent to their title. A large variability was observed on the usage of paragraph marks. While some tales (excluding title) were split into two paragraphs only, some others may contain up to forty different paragraphs. Many paragraphs were associated to a possible indentation strategy, consisting in inserting paragraph marks before each direct quotation. Low mean sentence sizes usually correspond to tales containing many direct quotations, associated to simple post-quotation patterns (see example 1). The longest sentence sizes were observed for long descriptions, and tales having repetitive structures (example 2). 2.3 Text annotation methodology The 89 tales were divided between two annotators trained in linguistics, referred to as A1 and A2. A hierarchical XML storing scheme, associated to a document type definition (DTD), was used to encode annotations. Annotators were provided with annotation guidelines (in French) and a fully annotated tale. To perform text annotation on a textual corpus, there are now different tools. For example the Glozz platform (Widlo  X  cher and Mathet 2012 ) and the Brat annotation software (Stenetorp et al. 2012 ) are two different tools widely used for various annotation campaigns. Each of them has very interesting features, and presents some limitations (e.g. keyboard shortcuts, signal alignment, multilevel annotation and visualization, etc.). The GV-LEx consortium choses to develop its own tool in order to fit to the objectives of the project (see Fig. 1 ). It allows multi-level annotations and visualizations and compute statistics about each file or about a set of document. The DTD is used to generate the menus and submenus associated to any hierarchical annotation scheme, allowing dealing with potential changes in the coding scheme. Meanwhile, the other annotations software may easily be applied to the corpus to enrich further the existing annotations. A1 labeled 61 tales, and A2 35 tales, leading to a total of 96 distinct annotations. Seven tales were labeled by A1 and A2, and were used to estimate inter-annotator agreements (Sect. 4.1 ). Resulting annotation file names are formatted as &lt;tale id&gt; . &lt;annotator id&gt; . xml . &lt;tale id&gt; being a 3 digit identifier, &lt;annotator id&gt; being either &lt;A1&gt; or &lt;A2&gt; . Each tale is split into a sequence of episodes , describing the narrative structure. Direct quotations are marked as speech turns . Extensions of enumerations, and of the time, place, and person named entities are used. Speech turns and person entities are enriched with anaphoric annotations, allowing the tracking of characters and the attribution of quotations. A listing of the XML markers related to the annotations is provided in Table 4 . 2.4 Extended enumerations and extended named entities Annotators were asked to mark any pattern that could be associated to an enumeration or a list. These patterns include enumeration of items (example 3), adjectives (example 4), actions, or characters.

Extended named entities were defined to mark mentions to a tale character or group. They were also enriched with anaphoric annotations, enabling the identification of the characters. These mentions include proper names, pronouns, or any relevant nominal groups (example 5). Given the fictional nature of tales, characters can either be humans, animals, plants, or living objects.

Place named entities were defined to include any pattern referring to a given location (examples 6). Similarly, time named entities refer to date, time, or periods (examples 7). Composition operations were allowed, to describe an entity relatively to another (example 8). 2.5 Speech turns Speech turn annotations were defined to mark direct quotations (example 9). They are not necessarily associated to quotation markers (double quotes, quotation dashes). Character speech turns ( &lt;spkr&gt; ) were defined as text segments containing the character X  X  direct quotations. They enclose the contiguous portions of text belonging to a single tale character, ranging from a few words to several sentences, and store the character X  X  anaphoric identifier. In some situations, the narrator may be one of the characters, and thus can quote his own speech (example 10); in this particular case, the anaphoric identifier is set to 0. The different characters X  speech turns are interleaved with narrative text excluding direct quotations, termed as narrator speech turn ( &lt;narr&gt; ). 2.6 Narrative structure Narrative structure annotations were defined as the segmentation of tales into sequences of labeled episodes . This approach is inspired from Propp X  X  structural theory, designed for the representation of Russian fairy tales as linear sequences of tale functions (Propp 1968 ). Fairy tales being a particular kind of children tales, more general structural annotations were necessary to fit the different kinds of tales composing the GV-LEx corpus (animal, repetition, realistic ... ). Propp X  X  representa-tions of tales are sequences of high-level functions, without tracks of the function boundaries within the text. It is well suited to tales classification, and it is used in contemporary research mostly for tales generation (Grasbon and Braun 2001 ; Gerva  X  s et al. 2005 ). For the narrative annotation model presented here aims at extracting text segments for prosodic purposes.  X  X  X cenes X  X  were defined thanks to elements of discourse analysis and computational discourse processing: episodes (van Dijk 1982 ), and subtopic passages (Hearst 1997 ). Resulting episodic annotations were defined as linear and non-overlapping segments, spanning over one or more sentences.
Beyond the title which is considered it X  X  own category, a set of five episodic categories was defined to structure the tale (see Table 5 ). This set is useful for the segmentation of tales from various epochs and cultural origins: exposition contains the setting of the story (place, main characters, etc.), which is equivalent to the Proppian initial situation . The triggering event covers the first eleven tale functions defined by Propp. It lasts from the end of the tale X  X  exposition , until the symbolic departure of the hero. It corresponds to the events altering the tale X  X  initial situation, resulting in a sequence of actions. It may correspond to the death of a character, the violation of an interdiction, etc. The triggering event can be followed by several episodes labeled as scenes and refrains . Refrains are used to mark portions of text having nearly identical surface manifestations within the tale. Scenes are the default episodic category. Their definition is mostly based on episodes (van Dijk 1982 ), and subtopic passages (Hearst 1997 ). Scene boundaries are associated with time, place, character, topic changes, or with the identification of a refrain . The last episode of the tale is generally labeled as epilogue . It may contain a moral, or some of the last five tale functions defined by Propp (recognition, exposure, transfiguration, punishment, wedding). 2.7 Annotations, coverage, and distributions These annotations have been applied to our corpus. Their distribution in the 89 tales of the corpus is analyzed here. One annotation per tale is considered, to avoid overrepresentation of tales annotated twice. Annotator A2 X  X  annotations were kept when two annotations were available, to balance the influence of each annotator in this description. This choice results in the description of 54 tales labeled by A1 and 35 tales labeled by A2. Coverage percentages reported below were obtained considering the number of words covered by a given marker (punctuation signs were excluded). A summary of the markers X  distributions and coverage is provided in Table 5 .
All tales contain a title, and an average of five scenes. Most tales have an exposition and an epilogue, and to a lesser extent a triggering event. Scenes are generally longer than the other episodic categories, and cover the largest amount of the corpus. Epilogues and triggering events are shorter than tales X  initial situations. Refrains were identified in 20 % of the tales: they constitute the episodic category with the lowest coverage, and the smallest length (except the obviously shorter title).
The corpus contains a large amount of direct quotations of characters. Direct quotations of the narrator were found in a single tale. Depending on the tale, the coverage of characters X  direct quotations vary from 4.5 to 72 %, with an average coverage of 30 %. 381 characters are quoted within the corpus, i.e. a median of four speaking characters per tale, and a maximum of 14. Narrator X  X  sentences are generally longer than for other characters, with a median length of 11 words, versus 7. Quoted text was defined as the portions of text enclosed in double quotes, or belonging to a normalized sentence beginning with a quotation dash. Quoted text represents 23.7 % of the tales X  text. 88 % of the quoted text is associated to a character X  X  direct quotations, while the remaining 12 % are associated to non quoted text.
Enumerations cover 20 % of the corpus. 18 % of these structures span over complete sentences. In the case of named entities, the proportion of person named entities is larger than for those of place and time entities leading to an average of respectively 106.7, 15.2 and 10.2 entities per tale. A compositional analysis of named entities shows that 13.6 % of place and 2 % of time named entities are defined relatively to a person named entity. Other compositional schemes (a person defined relatively to another person, or to a place, etc.) are rare (less than 1 %).
Part-of-speech tags obtained through automatic procedures (TreeTagger: Stein and Schmid 1995 ) were used to describe the structure of person entities. The largest amount of these patterns were single personal pronouns (52 %), articles followed by noun (15 %), proper names (7 %), possessive pronouns followed by nouns (3.6 %), article ? adjective ? noun (2.6 %). The remaining 17 % marked references had various structure and complexity. However 99 % of person named entities refer to patterns enclosing five or less words.

The description of co-reference chains for the speech turn blocks and the extended named entities is provided in Table 6 . The size of speech turn co-reference chains refers to the number of contiguous blocks in tale texts related to the direct quotations of a given character. The 9500 extended person entities refer to 922 distinct characters. Thus, about 41 % of the characters identified in tales are at least associated to one speech turn. The largest amount of markers referencing tale characters was used to track these  X  X  X peaking characters X  X  (76.7 %). 27 % of the character markers were used to identify characters mentioned only once in a tale. The median length for a speaking characters co-reference chain was 13, and may be as long as 90. The GV-LEx speech corpus contains annotated recordings of a subset of twelve tales of the GV-LEx text corpus. The text corpus annotation scheme is extended to include signal-dependent information, together with meta-data related to tale speaking characters. Prosodic stylization procedures are also included. This corpus is dedicated (but not limited) to TTS research, with special attention to relationships between text structures and prosodic features. 3.1 Recording procedure Twelve tales of the text corpus were selected for recording by a professional male speaker, well acquainted to studio recording sessions. Normalized tale texts were provided to the speaker before the recording session. The speaker was allowed to modify the text portions he judged unnatural to utter. He was informed of the study X  X  goals, and instructed to produce recordings targeted to a children audience.
Tales were recorded in a professional studio, resulting in a corpus of about 1 h of speech, in audiobook quality. Recordings were digitized using 32 bit floating-point values, with a sample rate of 48 kHz. They contain two channels obtained from two different microphones. A Neumann U87 microphone, suited to speech and musical studio recordings, was used to obtain the first channel. The second channel was recorded using an Earthworks M30 microphone, more suited to acoustic measure-ments. The Earthworks microphone was calibrated with a Bru  X  el and Kj X r sound pressure reference, allowing for true sound intensity analysis. 3.2 Speech transcriptions Lexical transcriptions were checked manually, comparing the GV-LEx text corpus tales and corresponding recordings. Considering the 9664 transcribed words, differences between tale texts and speaker X  X  transcriptions are only marginal: 40 word deletions, 31 word insertions, 41 word modifications (including synonym substitution) and 4 word shifts within sentences. The low amount of differences observed (about 1 %) accounts for a good fidelity to the text. A manual inspection of these differences showed that the modifications occurred only at the sentence level, without affecting neither tale nor sentence structure.

Statistics of the resulting transcriptions are given in Table 7 . Small differences are observed between the subset of recorded tales and the full text corpus (described Sect. 2 ). In particular, recorded tales are on average longer, with a mean size above 800 words. 3.3 Linguistic annotations Linguistic annotations used for the labelling of the text corpus (Sect. 2.3 ) were manually adapted, in order to take into account the small differences occurring between tale texts and their corresponding speech transcriptions. Annotation coverage statistics corresponding to these twelve tale transcriptions are presented in Table 8 . Coverage comparison between the twelve tales of the speech corpus and the 89 tales of the text corpus (Table 5 ) shows few differences. The percentage of words corresponding to character X  X  direct quotations is higher in the speech corpus than in the text corpus: (40 % instead of 30 %). This high amount of direct speech makes the speech corpus highly suited for the analysis of the prosodic correlates of character embodiment. For a more detailed analysis, a set a static features describing a character X  X  age, gender, kind, valence, and height is added in the corpus. 3.4 Speech-specific annotations using word and phonetic alignments Word, phoneme and speech signal alignment are very helpful for prosodic studies. This information, together with extra-phonemic events (audible breaths, hesita-tions, ... ), was obtained through an alignment procedure. Automatic alignment, instead of manual alignment, is required because of the relatively large amount of speech data considered. In addition, automatic alignment methods are often more consistent than manual alignments (Astesano et al. 1995 ).

The alignment procedure was performed by manually annotating breath group boundaries in the speech signal using Praat (Boersma 2002 ), and by associating these segments to the corresponding speech transcriptions. These breath groups were then automatically aligned using a pronunciation dictionary with relevant variants Adda-Decker and Lamel ( 1999 ). The LIMSI French speech recognition system Gauvain et al. ( 2005 ) made use of the manual transcription and the pronunciation variants in forced alignment mode to produce the most plausible phonetic transcription and segmentation of the utterances. Raw statistics related to the phonetic alignment are given in Table 9 . Phonetic transcriptions were then used to infer units used for rhythm analysis: syllables and Inter Perceptual Center Group (IPCG). These units were obtained automatically through Adda-Decker et al. ( 2005 ) syllabification rules for French and Barbosa and Bailly ( 1994 ) procedures.
Word, syllables, IPCG and phone boundaries are stored in Praat TextGrids (Boersma 2002 ). TextGrids are useful and widely used in prosodic research. Punctuation marks in the text are stored as a point tier. This allows the analysis of the relations between punctuation marks in text, and pause realization in spoken utterances. All the linguistic annotation levels (episodes, direct quotations) presented above are associated to an interval tier. An example of transcription alignment is given in Fig. 2 . 3.5 Prosodic representation and stylization In addition to the word and phone segmentations, intonation contours of all the tales were computed. Prosodic stylization is useful for intonation analysis. Raw melodic curves are reduced to syllable-size melodic segments. Stylized and original pitch contours are in principle perceptually indistinguishable, discarding small and poorly relevant pitch information.

Raw intonation contours, stylized intonation, periodicity and loudness contours are stored into spreadsheets. Visual representations and spreadsheets are provided with the corpus.

Estimation of the speech fundamental frequency (a main correlate to pitch), short term power (linked to loudness) and periodicity (corresponding to voiced/unvoiced parts) are obtained with the Yin algorithm (De Cheveigne  X  and Kawahara 2002 ). The following parameter set is used: a minimal f0 of 40 Hz, a maximal f0 of 1000 Hz, a window size = 25 ms and the  X  X op X  parameter set at 2 ms. Pitch estimations are expressed in semitones (st) relative to 1 Hz (110 Hz = 81.38 semitones). Power is expressed in dB, and obtained through Eq. 1 .
 with P and P Ref the period-smoothed instantaneous power estimated by Yin. P being the power of the considered windows, and P Ref the maximal power found in the recordings. This results in power estimates in the range of  X  0 ; 35  X  dB, 35 being a threshold under which pitch and power estimations are not taken into account by the proposed stylization model. Periodicity estimation may be seen as a measure of the reliability of pitch estimation for a given window, following Eq. 2 : Ap Yin being Yin X  X  periodicity measure (ranging  X  0 ;  X  inf  X  ). According to De Cheveigne  X  and Kawahara ( 2002 ), pitch estimations associated to periodicity coefficients below 0.6 are considered uncertain, range ]0.6 X 0.8] is considered as good, values above 0.8 correspond to the best pitch estimations.

Figure 3 shows the superposition of the raw and stylized intonation contours, aligned with word and phoneme annotations.

In the raw intonation contours, pitch curves are plotted with a width proportional to signal power in dB. This display enhances audible portions of the signal, and combine time, pitch, power, and periodicity estimations into 3D meshes. Data associated to power below 35 dB results in a width of 0 and is not plotted. Periodicity estimates are mapped to colors corresponding to MatlabJet color code (dark blue for the lowest periodicity estimates, and dark red for the highest estimates). This provides information on the pitch estimation reliability, as well as on voice quality.

The stylized contours are obtained adapting d X  X lessandro and Mertens ( 1995 ) model of tonal perception. The model maps each syllable X  X  pitch contour to tonal segments representing the perceived pitch.

Pitch estimates with periodicity estimates below 0.2, or power below 32.5 dB were discarded. The retained pitch and power estimates are filtered through a weighted time average model (WTAM) defined by Eq. 3 : With f being either the pitch estimate (in Hz), or the power estimate in dB. The model is used with a differential threshold of pitch change set at 12 st/s, and without glissando threshold. Width of segments is proportional to the weighted time average power estimation at segment boundaries. Segments having slopes above 100 st/s were considered as invalid, and removed from the observations. Tonal segments are plotted over the raw pitch contour with a transparent blue color.

Stylization spreadsheet inputs correspond to vocalic segments. Fields include segmentation boundaries, together with automatically updated boundaries (period-icity above 0.2, power above 32.5 dB, and no pitch segment slope above 100 st/s). Mean, median, maximal, and minimal values of pitch, power, and periodicity are reported within the automatically corrected boundaries. Temporal positions of tonal segment boundaries are reported, together with the associated weighted time average estimates of pitch and power. 4.1 Inter-annotator agreement on episodes An important question is the quality and reliability of annotations in the text corpus. As human annotation is an interpretation process (Leech 1997 ), its evaluation is based on agreement rather than on ground truth. Consistency of annotation for the text corpus was obtained on the seven tales annotated by both A1 and A2, with the help of inter-annotator agreement measures.

Episodic labeling is a particular case of text segmentation into blocks, associated with a block labeling. Table 10 describes the strict agreement for each episodic category. The F-measure is used as an agreement estimator similar to Cohen X  X  Kappa for unit detection (Hripcsak and Rothschild 2005 ). Therefore, it can be interpreted using the scale proposed in Landis and Koch ( 1977 ). Using this scale,  X  X  X air X  X  agreement was reported for exposition, triggering event, and scenes;  X  X  X ubstantial X  X  agreement was reported for epilogue, and  X  X  X erfect X  X  agreement was reported for refrains. However, this is only indicative, because of the relatively small amount of episodes considered, for expositions, refrains, scenes and triggering events.

For more reliable statistics, episodic boundaries are considered in place of episode units. For this sake, tales are converted into binary sequences of sentence boundaries (1 if a sentence boundary is also an episode boundary, and 0 otherwise). Consequently, a tale containing M sentences segmented into N episodes is mapped to a  X  M 1  X  element vector containing  X  N 1  X  episode boundaries.

Sequences associated to the seven tales were then concatenated to build a single vector used in the following agreement estimations.

A F-measure of 0.66 and a coefficient j  X  0 : 59 was observed on the corpus. It can be considered as a substantial agreement, comparable to agreements reported for similar tasks (Artstein and Poesio 2008 ). Note that Cohen X  X  Kappa and F-Measure process on an equal basis both close and distant boundary differences. The resulting agreement estimations on segmentation tasks are often considered pessimistic, given the annotators tendency to agree on most of the segments length, and disagree on segments exact boundaries (Beeferman et al. 1999 ). 4.2 Inter-annotator agreement on structural and lexical elements Structural and lexical units include speech turns, enumerations, as well as time, place, and person extended named entities. Characters speech turns were analyzed without considering the narrator speech turns. Then, speech turn agreement analysis is rather a unit identification task than a text segmentation task. Following Grouin et al. ( 2011 ) and Fort et al. ( 2012 ), F-Measure ( F ) and slot error rate ( SER ) were used to describe agreements.
 where | A 1| and | A 2| are the number of same class units annotated by A1 and A2. sm is the number of strict matches between A1 and A2. pm is the amount of partial matches: units of the same category covering common portions of text but having different boundaries. e is the number of units that do not match at all, defined as e  X j A 1 j X j A 2 j 2 sm 2 pm .
 Agreement estimates for the lexical and structural units are given in Table 11 . Whatever the metric, speech turns show a near-perfect agreement. Despite the difficulty of determining to what extent a plant, object or animal may be considered as a tale character, the agreements reported for the extended person named entities was high. The use of extended definitions of time and place named entity led to a substantial agreement. Note that relatively large amounts of partial matches were found for enumeration place named entities. 4.3 Inter-annotator agreement on tale character references Reference characters are encoded within the extended person named entities, and at the speech turn level (this aspect has been discussed in the preceding section). Following Artstein and Poesio ( 2008 ) and Passonneau ( 2004 ) recommendations, agreement was measured for co-reference chains using Krippendorff X  X  alpha with d , Jaccard ( d j ), and MASI ( d m ) metrics (Krippendorff 1980 ) . Krippendorff X  X  alpha considers units that are labeled by a minimum of two coders. Consequently, units identified as person named entity or character speech turn by a single annotator were not taken into account by this measure.

Following Uzuner et al. ( 2012 ), adaptations of the F-Measure were also used for anaphoric agreement estimation. This adaptation consists in considering co-reference pairs rather than co-reference chains, and is defined in Eq. 6 . Two variants of this measure were implemented: F  X  being the optimistic variant, inferring the reference pairs considering only the units identified by annotator A1 and A2. F being the pessimistic variant, considering each annotated unit, and penalizing both unit identification and reference annotation.
 The agreement estimates for co-reference annotations are provided in Table 12 . For Alpha coefficients greater than 0.8, person entities and speech turns anaphoric annotations can be considered as reliable (Krippendorff 1980 ). Agreement on speech turn anaphoric chains annotation is almost complete. This observation may be explained by the ease of this task, together with lower amount of speech turn units, and smaller co-reference chains length. F-Measure estimations showed good agreement, in comparison with the results reported in the 2011 i2b2/VA Challenge corpora (Uzuner et al. 2012 ). The lower agreement estimation obtained for person entity pairs using the pessimistic F-Measure is mostly due to a poor agreement on the corresponding unit identification. 4.4 Conclusion We presented a corpus including both written and spoken tales in French. Both text and speech have been annotated using a shared framework. Specific annotation tools were developed for this purpose.

The 89 tales X  text corpus was designed for tale information extraction, particularly for improving the natural language processing modules of TTS systems. The 12 tales X  speech corpus was designed to describe the relations between information annotated in written tales and prosodic properties observed in speech. These relations may then be modeled by rules, or using machine learning techniques. The GV-LEx corpus is distributed through the ELRA catalog, 3 together with the annotation tool used for corpus tagging, and which can be easily adapted to any other hierarchical annotation scheme described with a DTD.

Tales were segmented into sequences of labeled episodes inspired by Propp X  X  structural formalism (Propp 1968 ). They were annotated in terms of direct quotations, named entities, co-references and enumerations. As mentioned in (Declerck and Scheidel 2010 ; Gerva  X  s 2010 ; Lendvai et al. 2010 ), such corpora are of great value for fictional-text oriented information processing. Inter-annotator agreement and coverage analyses showed a high annotation reliability of direct quotations, extended person named entities, and their respective coreference chains.
The segmentation of the tales had to use a generalized scheme, as tales were of very different natures. The proposed scheme allows a common description for all of them, on the basis of a restricted set of 5 scenes X  types (plus the title). Not all these types were found in each tale. The results validate the linguistic structures chosen to describe tales, with respect to the speech synthesis issues. While episodic categories were not necessarily associated to the strongest inter-annotator agreements, they exhibit statistically significant prosodic properties that could be used to improve TTS systems (e.g. varying pause durations influencing the rhythm of tales X  delivery: cf. Doukhan et al. 2012a ). Meta-information describing a tale character X  X  age, gender, kind, valence, height, Proppian character type (Propp 1968 ) and Greimas actant category (Greimas 1966 ) were also used to extend speech corpus annotations. This allowed us to describe the prosodic correlates associated with character embodiment (Doukhan et al. 2011 ), and we plan to extend the whole text corpus with character meta-information.
The text corpus was used to train and evaluate models of episode segmentation, and speech turn detection. These models were included into the natural language processing module of a TTS and gesture synthesis system embed in a robot.
The speech corpus provides recordings of read tales in French. It includes word and phoneme boundaries aligned with the signal, together with the corresponding linguistic annotations. It is useful for the description and analysis of tale prosody, in relation with the linguistic structure. For instance, read tale speaking style was described, and compared to other speaking styles (political address, radio news, dialogue) in Doukhan et al. ( 2011 , 2012a ).

The results of the acoustic-prosodic analyses demonstrated the richness and the complexity of prosodic patterns occurring in read tales. It also showed larger prosodic variations in read tales than in the other reported speaking styles, which highlights the need for domain-specific resources to describe tales X  prosody. The outcome of this analysis allowed us to define prosodic rules for reading tales in TTS. With the help of the GV-LEx corpus, a storyteller robot prototype was successfully presented (Doukhan et al. 2011 , 2012a ; Doukhan 2013 ).
 References
