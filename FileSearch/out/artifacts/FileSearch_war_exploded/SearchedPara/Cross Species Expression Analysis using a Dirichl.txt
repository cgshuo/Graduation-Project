 pathogens are resistant to drugs while others are not [3].
 species (known as ortholog) is not known. A number of methods have been suggested to solve the relying on top sequence matches. Such an assignment can be us ed to concatenate the expression have a similar expression pattern.
 assignment may lead to wrong conclusions about the conserva tion of genes. Methods that have prior on matches between homologous genes in these species ( derived from sequence data). The the number of clusters.
 We have tested our method on simulated and immune response da ta. In both cases the algorithm address other problems including matchings of captions to i mages (see Section 5). matches are not known in advance.
 are not known for most genes, we have a prior for gene pairs (on e from each species) which is expressed in the other species and if so, who.
 [ x settings, where x probability between x where N in
Y . We use  X  i to denote the vector (  X  i, 0 ,..., X  i,n latent matching variable. If m has no match in y . Our goal is to infer both, the latent variables m pairs of samples ( x represent random variables and E[ X ] represents the expectation of a random variable X . Model selection is an important problem when analyzing real world data. Many clustering algo-approach to develop a nonparametric model for clustering an d matching cross species expression data. Our model, termed Dirichlet Process Mixture Model wit h Latent Matchings (DPMMLM) ex-between vectors to be clustered. 3.1 Dirichlet Process Let G can be seen from the explicit stick-breaking construction d ue to Sethuraman [11] as follows. Let ( V  X   X  G 0 . Then a random measure G defined as where  X  according to DP (  X ,G 3.2 Dirichlet Process Mixture Model (DPMM) mixture model is given by where F (  X  3.3 Dirichlet Process Mixture Model with Latent Matchings (DPMML M) matching between x and y . We use F Y respectively; and F  X  is a random variable of the prior distribution G the mixture membership of the sample pair ( x The major difference between our model and a regular DPMM is t he dependence of x m i &gt; 0 then we resort to the marginal distribution F 3.4 Mean-field variational methods inequality: chosen parametric family. 3.5 Variational Inference for DPMMLM V
K = 1 p ( x , y |  X , X  0 ) = where p ( z first part of (6) p (  X  |  X  the likelihood of the assignments to clusters and matchings .
 choose the distribution that factorizes over { m follows: where q distributions are conjugate distributions for the likelih ood of the parameters in (6). q These issues are discussed in details in section 3.5.2.
 Using this variational distribution we obtain a lower bound for the log likelihood: log p ( x , y |  X , X  0 )  X  E[log p (  X  |  X  0 )] + E[log p ( V |  X  )] where all expectations are with respect to the distribution q ( m , z , v ,  X  ) and To compute the terms in (8), we note that where q ( z 3.5.1 Coordinate ascent inference algorithm The lower bound above can be optimized by a coordinate ascent algorithm. The update rules for all terms except for the q inference for conjugate-exponential graphical models [15 ]. We discuss the update rule for q section 3.5.2. 3.5.2 Application of the model to multivariate Gaussians unknown mean and covariance matrix. The prior distribution G Gaussian-Wishart distribution. In a classical DP Gaussian Mixture Model with Gaussian-Wishart with  X  = (  X  and conditional distributions as follows: where W is a p The priors for  X  proper prior is given to W and b , p to decoupling of the marginal and conditional distribution s. Therefore, the distribution q symbols, we omit the subscript k of the specific cluster k . Posterior distribution of  X  Gaussian-Wishart conjugate priors.
 Posterior distribution of  X  W ,b is a singleton discrete distribution g such that g ( W  X  ) = 1 ,g ( b  X  ) = 1 . 4.1 Simulated data samples, we use the first 3 dimensions to create 120 datapoint s x = [ x dimensions of the first 100 datapoints are used to create y = [ y matches for 20 points in x ). Hence, the ground truth M matrix is a diagonal 120  X  100 matrix. mean and standard deviation shown in Figure 1(a) and Figure 1 (b). We compare the performance of our model(DPMMLM) with a standard Dirichlet Process Mixt ure Model where each component in percentage of correct matchings inferred by DPMMLM and the h ighest prior matching. For DP-MMLM, a datapoint x matching leads to only 25% accuracy. Figure 1(b) and 1(c) sho w the Normalized Mutual Informa-noise, DPMMLM still achieves high NMI of 0.8 and Adjusted Ran d index of 0.92. In conclusion, identify correct clusters even with the high noise levels. 4.2 Immune response dataset We compared human and mouse immune response datasets to iden tify similar and divergent genes. with and without treatment by IFN- X  [19]. We used BLASTN to compute the sequence similarity our model. The M matrix is the bit scores between human and mouse genes thresh olded at 75 . Human genes which are not matched to any mouse gene in the clus ter have a blank line on the change much. We used the Gene Ontology (GO, www.geneontology.org) to cal culate the enrichment of functional not activated following Yarsinia infection in mouse.
 We have also analyzed the matchings obtained using sequence data alone (prior) and by combining sequence and expression data (posterior) using our method. The top posterior gene is the same these clusters looked homogenous across species. We have developed a new model for simultaneously clustering and matching genes across species. also demonstrated the power of our method on simulated data a nd immune response dataset. While that are extracted and improve the matching outcome.
 Acknowledgments We thank the anonymous reviewers for constructive and insig htful comments. This work is sup-ported in part by NIH grant 1RO1 GM085022 and NSF grants DBI-0 965316 and CAREER-0448453 to Z.B.J. [4] G. Quon, Y. W. Teh, E. Chan, M. Brudno, T. Hughes, and Q. D. M orris. A mixture model [6] Sven Bergmann, Jan Ihmels, and Naama Barkai. Similariti es and differences in genome-wide [7] Y. Lu, R. Rosenfeld, and Z. Bar-Joseph. Identifying cycl ing genes by combining sequence [10] Thomas S. Ferguson. A bayesian analysis of some nonpara metric problems. The Annals of [12] Michael I. Jordan, Zoubin Ghahramani, Tommi S. Jaakkol a, and Lawrence K. Saul. An in-[14] H. Ishwaran and James. Gibbs sampling methods for stick breaking priors. Journal of the [15] Zoubin Ghahramani and Matthew J. Beal. Propagation alg orithms for variational bayesian
