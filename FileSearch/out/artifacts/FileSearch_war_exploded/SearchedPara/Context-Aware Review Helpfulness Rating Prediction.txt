 Online reviews play a vital role in the decision-making pro-cess for online users. Helpful reviews are usually buried in a large number of unhelpful reviews, and with the consis-tently increasing number of reviews, it becomes more and more difficult for online users to find helpful reviews. There-fore most online review websites allow online users to rate the helpfulness of a review and a global helpfulness score is computed for the review based on its available ratings. However, in reality, user-specified helpfulness ratings for re-views are very sparse -a few reviews attract large numbers of helpfulness ratings while most reviews obtain few or even no helpfulness ratings. The available helpfulness ratings are too sparse for online users to assess the helpfulness of reviews. Also the helpfulness of a review is not necessarily equally useful for all users and users with different background may treat the helpfulness of a review very differently. The user idiosyncracy of review helpfulness motivates us to study the problem of review helpfulness rating prediction in this paper. We first identify various types of context information, model them mathematically, and propose a context-aware review helpfulness rating prediction framework CAP. Experimental results demonstrate the effectiveness of the proposed frame-work and the importance of context awareness in solving the review helpfulness rating prediction problem.
 H.3.3 [ Information Search and Retrieval ]: Information filtering; J.4 [ Computer Application ]: Social and Behav-ioral Sciences Review Rating Prediction, Social Context, Review Recom-mendation, Content Context
Reviews, providing experiences with and opinions about products or services from other users, play a crucial role in online communities such as e-commerce and product review sites, where users rely on reviews in their decision-making process. For example, users will select restaurants with good reviews in Yelp, and reviews about products in eBay are im-portant sources of information for users to make purchases. However, helpful reviews are usually buried in large numbers of useless reviews [15], and with the availability of massive reviews, it becomes increasingly difficult for online users to find helpful reviews.

In an attempt to help online users identify helpful reviews, most online review websites implement a mechanism to allow users to rate the helpfulness of a review and then a global helpfulness score is computed for the review such as  X 20 out of 30 people found the following review helpful X  in eBay and a score from 0 to 5 in Ciao. In reality, a large proportion of reviews obtain few or no helpfulness ratings, particularly the more recent ones and the available helpfulness ratings are too sparse for online users to assess the helpfulness of reviews [15]. For example, it is difficult for users to assess the helpfulness of a review in eBay with a score of X 1 out of 1 people found review helpful X . There is recent work automat-ically predicting a global helpfulness score for a review [9, 13, 15]. However, a review is not necessarily equally useful for all users. For example, in eBay, a review X  X  helpfulness can have a score of  X 500 out of 1000 people found the fol-lowing review helpful X , which indicates that the other half do not think the review helpful or are indifferent. This user idiosyncracy of review helpfulness motivates us to study if we can predict review helpfulness rating for each user.
We choose a product review site, a classical type of online review websites, to investigate if review helpfulness rating prediction can help mitigate the problem caused by user id-iosyncracy. Figure 1(a) gives an overview of product review sites where users have four different behaviors -connecting to other users, writing reviews, rating the helpfulness of re-views, and rating items. Figure 1(b) depicts the user help-fulness rating behavior and there are two types of ratings including item ratings and review helpfulness ratings. The review helpfulness rating is fundamentally different from the item rating. The former indicates  X  X ow does a user X rate a review from another user Y ? X  while the latter denotes  X  X ow does a user X rate an item? X . These differences not only are useful to differ our studied problem from item rating predic-tion problem, but also present unique opportunities for us to investigate the review helpfulness rating prediction problem. First, the texts of reviews can affect how users rate the help-fulness of reviews [13], thus provide content context about reviews. Second, users play two roles in review helpfulness rating: authors -users who write reviews, and raters -users who rate reviews. Both raters and authors can rate items, Figure 1: An Overview of Product Review Sites and the User Helpfulness Rating Behavior. and raters may be related to authors such as raters may con-nect to authors. Raters, authors and their relations provide rich social context about reviews. For example, authors with high reputations are likely to write helpful reviews [4], and raters might think of reviews from their connected authors more helpful. Therefore the dual roles of users expand the horizon of social context in helpfulness rating, providing a new perspective to exploit social context.

The availability of content context and social context pro-vides unique opportunities but also brings about new chal-lenges: (1) what types of social context can be extracted from the dual roles of users in helpfulness rating, and (2) how to model content context and various types of social context mathematically for prediction. Addressing these two chal-lenges, we propose a framework for the helpfulness rating prediction problem by exploiting context information. Our contributions are summarized next.
The rest of this paper is organized as follows. Section 2 defines our problem formally. Section 3 describes the dataset and analyzes various types of social context. Section 4 introduces how to formulate context information mathe-matically and a context-aware helpfulness rating prediction framework. Section 5 presents experimental results and our observations. Section 6 briefly reviews related work. Section 7 concludes this study with future work.
Typically there are three types of objects on product re-view sites. Let U = { u 1 ,u 2 ,...,u n } be the set of users, { p 1 ,p 2 ,...,p m } be the set of items, and R = { r 1 ,r 2 be the set of reviews where n , m and N are the numbers of users, items and reviews, respectively. Users in product re-view websites have four behaviors. First, users can connect to each other and we use T  X  R n  X  n to represent their social relations where T ij =1if u j creates a connection to u i zero otherwise. Second, users can rate items and R  X  R n  X  m is introduced to denote item rating where R ij is the item rating if u i gives p j a rating. Third, users can rate the help-fulness of reviews and H  X  R n  X  N is employed to represent helpfulness rating where H ij is the helpfulness rating if u gives r j a rating. For both R and H , we adopt a symbol  X ? X  to represent unknown ratings. Finally, users can write reviews and we use A  X  R n  X  N to denote the author-review relations where A ij = 1 indicates that r j is written by u zero otherwise. For the j -th review r j ,weuse x j to represent its textual feature vector. We use O = { u i ,r j ,u k | H and Q = { u i ,r j ,u k | H ij =? } to denote the set of known and unknown helpfulness ratings respectively, where u k is the author of r j . Although we choose product view sites to study the problem, the framework proposed in this paper can be applied to other online review websites.

With the notations above, our problem can be stated as: given the known helpfulness rating set O and its contex-tual awareness including the social network T ,theitemrat-ings R , the author-review relations A , and the review con-tent { x j } N j =1 , we aim to predict unknown helpful ratings for triples u i ,r j ,u k in Q by exploiting the known helpfulness rating set O and context information { T , R , A , { x j } N
The dual roles of users in the studied problem bring about unique challenges and opportunities to exploit social con-text. In this section, we conduct preliminary social context analysis to seek a solution to the first challenge -what types of social context can be extracted. For the purpose of this study, we crawled a data set from Ciao, a popular product review site. We started with a set of the most active users and then did breadth-first search until no new users could be found. For each user, we collect his/her profile, social networks and item rating entities. For each item rating entity, we collected the time point when this entity was created, item name, the category of the item, the rating score and the associated review. For each review, we collected its textual content, raters, their helpfulness ratings to the review and the time points when helpfulness ratings were created. We filter users giving no helpfulness ratings and reviews receiving no helpfulness ratings. Some statistics about the dataset are shown in Table 1 where the number of item ratings is the same as that of reviews since they are one-to-one correspondences.

In Ciao, users give scores from 0 to 5 to indicate the help-fulness of reviews, and we find that the majority (80 . 74%) of helpfulness ratings are 3 and 4. We compute the number of helpfulness ratings given by each user and the distribu-tion suggests a power-law-like distribution: a few users con-tribute a large number of helpfulness ratings, and most users give few helpfulness ratings. We also compute the number of helpfulness ratings received by each review, and the dis-tribution also suggests a power-law-like distribution.
Authors, raters and their relations provide rich social con-text about reviews. From Figure 1(b), we extract two types of individual context , i.e., author context in Figure 2(a) and rater context in Figure 2(b), and two types of relation con-text , i.e., connection context in Figure 2(c) and preference context in Figure 2(d)).
Most existing tasks exploiting social context only consider users as either authors [15, 12] or raters [10, 16]. For ex-ample, author context is exploited as the social features in review quality prediction problem [12], while rater context is widely exploited in the item rating prediction problem [10, 1]. Author context and rater context are seldom both inves-tigated in one problem, while our problem naturally involves both of them. There are recent studies exploiting relations between users [11, 17]. Only considering one role of users, they utilize relations between two raters [11, 17] or two au-thors [15]. However, we consider relations between raters and authors in our problem, which is rarely studied before. In the following two subsections, we focus our attention on the analysis of connection context and preference context.
Given that raters connect to the author of a review, we investigate how the raters will rate the helpfulness of the re-view. For each review, we divide its raters into two groups: connection group G t -containing raters who have connec-tions with its author, and non-connection group G r -con-taining raters without relations with its author. To analyze connection context, we select reviews with both G t and G not null, including 74 . 45% of all reviews. This observation suggests that most reviews involve connection context. On average, 33 . 17% of helpfulness ratings for a review are from the connection group G t .

For the j -th review r j , we use connection rating T j and non-connection rating R j to represent the average helpful-ness ratings from raters in G t and G r , respectively. Assume that t and r are the vectors of all connection ratings ( T and non-connection ratings ( R i s), respectively. We check the means of t and r and find that the mean of t 3.9627 is larger than that of r 3.7734 . To study the significance, we also conduct a two-sample t-test on the vectors t and r .The null hypothesis is H 0 : t  X  r , and the alternative hypothesis is H 1 : t &gt; r . The result show that there is strong evidence to reject the null hypothesis with significance level  X  =0 . 01, indicating t is significantly larger than r . With the evidence from the means and t-test result, we conclude Observation 1 -raters are likely to think of reviews from their connected authors more helpful.

Users may have heterogeneous connection strengths with their social networks [22]. For each review, we further di-vide the connection group G t equally into strong connection group and weak connection group based on the metric intro-duced in [22]. We do similar analysis on these two groups to that on G t and G r . To save space, we ignore the detailed results and directly give Observation 2 -the more strongly raters connect to an author, the more helpful raters consider the reviews from the author.
Given that raters have similar preferences to the author of a review, we investigate how the raters will think of the helpfulness of the review. To answer this question, we first need to define the measure of preference similarity between raters and authors. In the context of product review sites, user preferences can be extracted from the item rating be-havior [23]. For example, if two users rate the same items similarly, they have similar preferences or opinions. There-fore we use item rating similarity to measure preference sim-ilarity between the raters and authors. For the i -th user u we first calculate his/her cosine item rating similarities with other users s ik ,  X  k = i , and then we choose j -th user u as u i  X  X  preference similar user if s ij &gt; 1 n  X  1 k s n  X  1 k s ik is the average item similarity between u i and other users. Let P  X  R n  X  n denote the preference relation matrix where P ( i, j )=1if u j is a preference similar user of u and zero otherwise.

Similar to connection context analysis, for each review, we split its raters into two groups: preference group G o the group of raters who are the preference similar users of the author, and non-preference group G s -the group of users who are not the preference similar users of the author. To conduct preference context analysis, we choose reviews with both G o and G s not null, including 89 . 08% of all reviews. On average, 48 . 93% of helpfulness ratings for a review are from the preference group G t . These observations reveal that most reviews have preference context. For each review, we check the rater overlap between preference group G o and connec-tion group G t in connection context analysis and find that the average overlap is 9 . 23%. This observation suggests that preference context is very different from connection context and it is necessary to study them separately.

For the i -th review, we use preference rating O i and non-preference rating S i to denote the average helpfulness rat-ings from G o and G s , respectively. Let o and s be the set of preference ratings ( O i s) and non-preference ratings ( S respectively, and the mean of o 3.8440 is larger than that of s 3.7468 . We also conduct a two-sample t-test on the vectors o and s . The null hypothesis is H 0 : o  X  s ,and the alternative hypothesis is H 1 : o &gt; s . The result show that there is strong evidence to reject the null hypothesis with significance level  X  =0 . 01. With the evidence from the means and t-test result, we conclude Observation 3 -raters are likely to consider the reviews from their preference similar authors more helpful.

For each review, based on the item similarities between raters and its author, we further divide G o equally into high preference similar group and low preference similar group. By analyzing these two groups as similar to G o and G s ,we find Observation 4 -the more similar the preferences of raters and an author are, the more helpful raters consider the reviews from the author.
With social context analysis in the last section, we are ready to introduce our context-aware helpfulness rating pre-diction framework CAP to address the second challenge -how to model content context and various types of social context for the prediction problem.
We use  X  H ij to denote the estimated helpfulness rating from u i to r j . Before modeling contextual information, we first introduce our basic model based on probabilistic ma-trix factorization, and the helpfulness rating H ij can be es-timated as, where u i  X  R K and v j  X  R K are latent factors of u i and r to capture the preference of u i and the characteristics of r where K is the number of latent factors.

Modeling Content Context : Different from the item rating prediction problem, in the review helpfulness rating prediction problem, the texts of reviews provide content con-text about reviews. We introduce a latent factor  X  j to ex-ploit the review content of r j as, where the latent factor  X  j has a linear relation with the textual features from review content [14] with coefficients g and we use similar textual features to these in [15]. Following the common assumption on the loss or error function, we further assume Gaussian error between  X  j and g x j [1, 4].
Modeling Individual Context : Individual context contains author context and rater context. For the help-fulness rating of u i to r j from the author u k , we introduce two latent factors  X  k and  X  i to capture author context and rater context, respectively. According to the observations from [15], author context is usually related to the charac-teristics of authors such as their reputations and statuses. Assume that there is an author feature vector z k for u k Similar to modeling review content, we consider a linear re-lation between author context  X  k and the characteristics of the author z k with Gaussian error, and then author context can be formulated as, A similar strategy can be applied to rater context. Assume that for the rater u i , there is a rater feature vector y then rater context is formally defined as,
Modeling Relation Context : Relation context in-cludes connection context and preference context. Different from individual context, relation context only exists when raters and authors have connections or preference relations. Therefore for the helpfulness rating of u i to r j from the au-thor u k , we define two indicator functions: (1)  X  1 is defined for preference context where  X  1 ( i, k )=1if u i is the pref-erence similar user of u k ( P ik = 1) and zero otherwise; (2)  X  2 is defined for connection context where  X  2 ( i, k )=1if u i trusts u k ( T ik = 1) and zero otherwise. To model con-nection context and preference context, we introduce two latent factors  X  k i and  X  k i to model them, respectively. Based on Observation 2 , connection context is related to the con-nection strengths between raters and authors. Therefore for the pair of users u i ,u k , we define a connection strength feature vector q k i , and then the latent factor  X  k i for connec-tion context is formulated as, where we use an active function f on h q k i to ensure that the effect from connection context is positive according to Observation 1 and we find that a sigmoid function works well in this paper. Similarly, based on Observation 3 and Observation 4 ,thelatentfactor  X  k i is formally defined as, where p k i is a preference similar feature vector for the pair of users u i ,u k .

We use similar author feature vector z k as in [15], and the definitions of the rater features for y i , the preference simi-lar features for p k i and the connection strength features for q i can be found in Appendix . Exploiting content context and various types of social context, our context-aware help-fulness rating prediction framework CAP will estimate the helpfulness rating H ij as H  X  H  X  j  X  X  ( g x j , X  2  X  ) , X  i  X  X  ( d y i , X  2  X  ) , X  k  X  X  ( b z  X  i  X  X  ( f ( r p k i ) , X  2  X  ) , X  k i  X  X  ( f ( h q k i ) , X  u i  X  X VN ( Wy i , A u ) , v j  X  X VN ( Vx j , A v ) , (2) where we also relate the latent factors of u i and v j to ob-served features of u i and r j with coefficients W and V re-spectively, and MVN denotes multivariate normal distribu-tion.

Predicting Helpfulness Rating : After learning the la-tent factors  X  and prior parameters  X  from known ratings O , an unknown rating of u i to r j from u k can be predicted as,  X  H product review sites are highly dynamic systems where new users and new reviews are continuously added [23]. For new users and reviews, we do not have any historical helpfulness ratings (cold-start problem) and we cannot get their latent factors directly. However, the parameters  X  are independent of any specific users or reviews, and their latent factors can be estimated via  X  with their observed features as,  X  i = d y i , X  j = g x j , X  k = b z k , X  j i = f ( r p k i )  X  i = f ( V q k i ) , u i = Wy i , v j = Vx j .

The proposed framework CAP has several nice proper-ties. First, CAP allows us to incorporate the observed fea-tures of review content, authors, raters and their relations by modeling the effects of content context and various types of social context information on the helpfulness rating pre-diction problem. Usually the more we observe the data, a better model we can learn from the data [1, 4]. Second, the parameters  X  in CAP are independent of any specific users or reviews and can be applied to new users or new re-views. Therefore, it provides a unique framework to address both cold and warm start problems in the review helpfulness rating prediction problem. In reality, this property is very important as online review systems are highly dynamic with new users and reviews consistently added.
In this paper, we adopt Monte Carlo EM algorithm [3] to learn latent factors and prior parameters for CAP from the data automatically. The Monte Carlo EM algorithm maximizes the marginal log-likelihood by iterating through expectation (E) and maximization (M) steps until conver-gence. Let  X   X  t denote the t -th estimate of the set of prior parameters  X  at the t -th iteration.

E-step : We take the expectation of the complete data log likelihood with respect to the posterior of latent factors  X  conditional on the observation data O as, where L ( X  ,  X ) is the data log-likelihood and the expectation is taken over the posterior distribution P ( X  |O ,  X   X  t ). The E-step in our model is not in close form due to the multiplica-tive terms u i v j , thus approximated by Monte Carlo mean. We use a Gibbs sampler to draw samples of the latent fac-tors and compute the Monte Carlo means and variances of latent factors.

Computing Monte Carlo mean and variance of  X  i :Now considering that all the other factors are given, we use Rest to denote all other factors except  X  i . Assume that L (  X  the function including terms involving  X  i in L ( X  ,  X ). Let L (  X  i )and L (  X  i ) denote the first-order and second-order derivatives of L (  X  i ), respectively. Suppose that  X   X  minimizer of L (  X  i ) satisfying the equation L (  X  i )=0.Then approximations of the mean and variance of  X  i are  X   X  i and L (  X  i )( X   X  i )  X  1 , respectively [3]. We first take the derivation of L ( X  ,  X ) w.r.t.  X  i as, where a ij = H ij  X   X  j  X   X  1 ( i, k )  X  k i  X   X  2 ( i, k )  X  and I ( i ) is the set of helpfulness ratings from u i .Thengiven Rest , the Monte Carlo mean and variance of  X  i are,
Similar to  X  i , we can compute the Monte Carlo means details to save space.

M-step : We maximize the expected complete log likeli-hood from the E-step to update  X  as, where we consider A u =  X  2 u I and A v =  X  2 v I . Estimating (  X  2  X  , d ) : Setting zeros to the derivations of E tain, where E [  X  i ]and V [  X  i ] are the Monte Carlo mean and vari-ance of  X  i obtained in the E-step, respectively.
Similarly, we can obtain other prior parameters {  X  2 H , X   X  , X  2  X  , W , p , V } .For r and h , we use the Newton-Raphson method to update them as, where  X  X   X  r and  X  2 E  X  r  X  r are the first-order and second-order respectively.
In this section, we conduct experiments to answer the following questions (1) Does context awareness help to im-prove the performance of helpfulness rating prediction as expected? (2) If it does, is it necessary to exploit every type of contextual information? To answer the first question, we compare our proposed framework CAP with representative baseline methods. To answer the second question, we in-vestigate the effects of content context and various types of social context on CAP.
We first rank all helpfulness ratings according to the time points when they are published in chronological order, and then equally split the whole data set into two parts -50% of them as the training set and 50% of them as the test-ing set. For the testing set, we further divide it into two parts: (1) cold-start -including helpfulness ratings where the raters or authors are newly added users or the reviews are newly written reviews; and (2) warm-start -containing rat-ings where the raters and the reviews exist in the training set. We examine the data and find that cold-start includes 44 . 72% of the testing set. A large proportion of review help-fulness ratings are cold-start ratings, further demonstrating the significance of finding a unique framework for the prob-lem of review helpfulness rating prediction with both cold-start and warm-start settings. A common metric Root Mean Squared Error is used to evaluate performance.
We compare the proposed framework CAP to various base-line methods, which can be grouped into three categories.
Methods in the first category are totally based on simple statistics from the training set and they are: ST:Mean -predicting the helpfulness of a review as the mean of the helpfulness ratings in the training set; ST:Review -pre-dicting the helpfulness of a review as the average helpfulness rating the review received in the training set; ST:Author -predicting the helpfulness of a review from an author as the average helpfulness rating of the reviews from the author in the training set and ST:Rater -predicting the helpfulness rating from a specific rater as the average rating given by the rater in the training set.

The second category covers the state-of-the-art predic-tors in the item rating prediction problem and they are: IRP:MF -performing a low-rank matrix factorization on helpfulness rating matrix H [10, 26]; IRP:Neighbor -pre-dicting the helpfulness rating of a review from a rater as the average weighted rating of the review from the rater X  X  trust network or similar users; and IRP:MF+Neighbor -this predictor exploits both rating and social information [17]. Note that we do not compare our framework CAP with methods based on tensor factorization [8, 18]: (1) the focus of this paper is to investigate whether exploiting context-aware information can improve the prediction performance and we can choose tensor factorization based methods in-stead of matrix factorization based methods as our basic models; and (2) the high time and space complexities of ten-sor factorization limit their applications to large-scale data sets. We also do not compare CAP with feature-based fac-torization methods [25] in this subsection since they are spe-cial cases of CAP, which is discussed in later subsection.
The methods in the third category are review quality pre-dictors and they are: RQP:Text -performing linear regres-sion on textual features from the review content; RQP:Author -performing linear regression on author features, referred as the social features of reviews in [15]; and RQP:Text+Author -performing linear regression on the features with both tex-tual features and author features. The predictors in this category will compute a global helpfulness score for a review Table 2: Performance of Different Predictors in terms of RMSE.
 over all users, while ignore the user idiosyncracy of review helpfulness .

The parameters in baseline methods are pruned via cross validation and the comparison results are shown in Table 2. We have the following observations from the warm-start data set,
In cold-start , we have similar observations. However, con-tent context plays a more important role in the cold-start problem. The methods considering the review content al-ways outperform those ignoring it. CAP also obtains the best performance, indicating the ability of the proposed frame-work CAP to solve the cold-start problem.
With these observations, we can draw an answer to the first question -Exploiting context awareness, our proposed framework gains significant performance improvement in the problem of review helpfulness rating prediction with both warm-start and cold-start settings.
Empirical study shows that CAP significantly helps im-prove the helpfulness rating prediction performance by ex-ploiting context awareness. In this subsection, we investi-gate the effect of content context and various types of so-cial context on CAP. Except the basic model from the item rating prediction problem ( u i v j ), our proposed framework CAP exploits content context (  X  j ) and four types of so-cial context (  X  i ,  X  k ,  X  k i and  X  k i ). To answer the second question, we eliminate the effects of content context and four types of social context systematically from the pro-posed framework CAP by defining the following variants of CAP: (1) CAP \ Author -eliminating the effect of au-thor context from CAP; (2) CAP \ Rater -eliminating the effect of rater context from CAP; (3) CAP \ Connection -eliminating the effect of connection context from CAP; (4) CAP \ Preference -eliminating the effect of preference con-text from CAP; (5) CAP \ ARCP -eliminating the effects of four types of social context from CAP; (6) CAP \ Text -eliminating the effect of content context of reviews from CAP; and (7) CAP \ Text \ ARCP -eliminating the effects from content context and four types of context information from CAP. This variant is a feature-based matrix factoriza-tion method [25].

The results are demonstrated in Figures 3(a) and 3(b) in warm-start and cold-start , respectively. When we elim-inate each type of social context from CAP, the perfor-mance degrades. Compared to CAP, on average, the perfor-mance of CAP \ Author , CAP \ Rater , CAP \ Connection and CAP \ Preference relatively reduces 14 . 86% and 7 . 22% in terms of RMSE in warm-start and cold-start respectively, indicat-ing that social context information can help improve the performance. When eliminating four types of social context simultaneously, the performance of CAP \ ARCP is worse than that of variants which eliminate one type of social con-text, indicating that the four types of social context con-tain complementary information to each other. When we eliminate the effect of content context, the performance re-duces more than 20% in both warm-start and cold-start data sets and the content of reviews plays an important role in the prediction process, especially for the cold-start problem. CAP \ Text \ ARCP performs worst, suggesting the importance of content context and various types of social context information for CAP. However, CAP \ Text \ ARCP obtains performance improvement over IRP:MF .Bothof them consider the interactions between the latent factors of raters and reviews, while CAP \ Text \ ARCP also incor-porates observed features of raters and reviews, suggest-ing that observed features are very important and can help improve prediction performance. Besides the performance improvement, another advantage of CAP \ Text \ ARCP over IRP:MF is that it enables to solve the cold-start problem in the review helpfulness rating prediction problem.
With these observations, we can answer the second ques-tion that the contributors to the performance improvement in CAP include: (1) considering content context, (2) exploit-ing various types of social context, and (3) incorporating observed features of raters and reviews. Figure 3: The Performance of Variants of Our Framework in terms of RMSE.
Helpful reviews are usually buried among large amounts of useless reviews and automatically assessing the quality of a review attracts increasing attention in recent years. Most previous work considers the quality prediction problem as a classification or regression problem [24, 9, 13, 14, 19, 15, 12]. [24, 9, 13, 14] utilize textual features such as the length of the review, percentages of nouns and adjectives, the subjectivity of the review and so on, while methods like [19, 15, 12] ex-pand textual features with social features (the characteristic features of authors) such as the reputations of authors, the number of past reviews by the author, past average ratings etc. The results show that incorporating the characteristics of authors with textual features can significantly improve prediction performance [15, 12]. There are also other studies indicating that the helpfulness of reviews is not necessarily strongly correlated with certain measures about the quality of reviews [13, 5].
Collaborative filter is one of the most popular techniques for item rating prediction, roughly categorized into neigh-borhood approaches and latent factor models [10, 21]. The neighborhood-based approaches can be further divided into user-oriented methods [6] and item-oriented methods [20]. User-oriented methods infer an unknown rating from a user to an item as the weighted average of all the ratings from his correlated users to the item, while item-oriented approaches product the rating from a user to an item based on the aver-age ratings of similar or correlated items by the same user. Latent factor models consider the interactions between la-tent features of users and items by projecting them to the same latent factor space. Matrix factorization methods are very competitive methods in this category [10, 7, 17]. They assume that a few latent patterns influence user rating be-haviors and perform a low-rank matrix factorization on the user-item rating matrix. Recently, high-dimensional tensor factorization based methods were proposed to allow adding additional dimensions to the user-item matrix [8, 18]. How-ever, the limitations of the high-dimensional tensor factor-ization based methods are their high time and space com-plexities.
In this paper we study the problem of review helpfulness rating prediction by exploiting context awareness to infer unknown helpfulness ratings automatically. We extract four types of social context, i.e., author context, rater context, connection context and preference context, formulate them mathematically, and propose a context-aware helpfulness prediction framework CAP which exploits content context and various types of social context. Experimental results demonstrate that our proposed framework outperforms the state-of-the-art baseline methods with both cold-start and warm-start settings, and further experiments are conducted to understand the importance of context awareness in the proposed framework.
 There are several directions needing further investigation. First, we will study how to model context awareness in the tensor factorization based models. Second, user preferences are likely to change over time and it is interesting to exploit temporal effects in CAP. Finally, users may need helpful re-views associating with the recommended items to help them make decisions. Recommending items and the helpful re-views simultaneously will be a promising direction. We thank the useful comments from Atish Das Sarma and anonymous reviewers. This work is, in part, supported by ARO (#025071) and NSF (#IIS-1217466). [1] D. Agarwal and B. Chen. Regression-based latent [2] C. Yeung and T. Iwata. Strength of social influence in [3] J. Booth and J. Hobert. Maximizing generalized linear [4] B. Chen, J. Guo, B. Tseng, and J. Yang. User reput [5] C. Danescu-Niculescu-Mizil, G. Kossinets, [6] J. Herlocker, J. Konstan, A. Borchers, and J. Riedl. [7] M. Jamali and M. Ester. A matrix factorization [8] A. Karatzoglou, X. Amatriain, L. Baltrunas, and [9] S. Kim, P. Pantel, T. Chklovski, and [10] Y. Koren. Factorization meets the neighborhood: a [11] Y. Koren. Collaborative filtering with temporal [12] E. Lim, V. Nguyen, N. Jindal, B. Liu, and H. Lauw. [13] J. Liu, Y. Cao, C. Lin, Y. Huang, and M. Zhou. [14] Y.Liu, X.Huang, A.An, and X.Yu. Modeling and pred [15] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. [16] H. Ma, I. King, and M. Lyu. Learning to recommend [17] H.Ma, D.Zhou, C.Liu, M.Lyu, and I.King. Recommen [18] S. Moghaddam, M. Jamali, and M. Ester. etf: [19] M. O X  X ahony and B. Smyth. Learning to recommend [20] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [21] X. Su and T. Khoshgoftaar. A survey of collaborative [22] J. Tang, H. Gao, and H. Liu. mTrust: Discerning [23] J.Tang, H.Gao, H.Liu, A. Sarma. eTrust: Understa [24] Z. Zhang and B. Varadarajan. Utility scoring of [25] K. Zhou, S. Yang, and H. Zha. Functional matrix [26] M. Andriy, and S. Ruslan. Probabilistic matrix Rater Features : # of trustors, # of trustees, pagerank score, average item rating, average item rating from the so-cial network, average item rating from similar users, average helpfulness rating, average helpfulness rating from the trust network, average helpfulness rating from similar users
Preference Similar Features : #ofcommonlyrated items, Jaccard X  X  coefficient on rated items, Cosine similarity of item ratings, Pearson similarity of item ratings, difference of average item rating scores, difference of maximal item rating scores, difference of minimal item rating scores
Connection Strength Features : Jaccard X  X  coefficient on common out-degrees, Jaccard X  X  coefficient on common in-degrees, Adamic/Adar score on common out-degrees, Adamic /Adar score on in-degrees, Katz score.
