
Department of Computer Engineering and IT, Amirkabir University of Technology, Tehran, Iran Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran 1. Introduction
A new paradigm in the video coding literature is Distributed Video Coding (DVC). The principal objective in DVC is to provide a flexible way to distribute the computational complexity between the encoder and the decoder, unlike the conventional video coding methods that impose considerable com-plexity on the encoder [1]. This flexibility is desir able in applications such as mobile camera phones, video surveillance systems, and disposable video cameras. DVC is based on the Slepian-Wolf [2] and Wyner-Ziv [3] theorems that explain the lossless and lossy coding of distributed sources, respectively.
Inspired by these theorems, the Stanford codec is proposed [4,5] as one of the early DVC solutions and has later been adopted in many DVC researches [6 X 14]. In this architecture, the video frames are divided into two groups; namely, Key and Wyner-Ziv (WZ) frames. Key frames are encoded separately using an intra-coding scheme (e.g. JPEG coding, H.264 Intra coding [15]) and sent to the decoder. On the other hand, WZ frames are quantized, transformed, and turbo-coded. The parity bits generated in the last step are stored in a buffer at the encoder and subsequently sent in chunks upon decoder request. The decoder simply decodes the key frames and by interpolating/extrapolating the decoded key frames and/or the previously received WZ frames produces an estimation of the incoming WZ frame. Next, the decoder tries to remove the potential errors in this estimation by requesting for the parity bits generated at the encoder in an iterative turbo decoding procedure. A failure in turbo decoding causes the decoder to request for more parity bits from the encoder through the feedback channel to correct the estimation. This procedure is repeated until the probability of error in the decoded WZ frame becomes arbitrarily small.

While this architecture is simple and flexible in incorporating various channel coding methods (e.g. turbo codes [16], LDPC codes [17], and raptor codes [18]), the presence of a feedback channel is not admissible or plausible in some applications (e.g. one-way communication scenarios, offline video en-coding and decoding, mobile communications). In addition, the iterative approach of requesting for more parity bits through the feedback channel in the decoding phase causes additional delays in the coding procedure. Iterative decoding also imposes high computational complexity on the decoder.

As the only role of the feedback channel is to request for more parity bits from the encoder, it can be eliminated if the efficient bitrate can be estimated at the encoder. With this end in view, we introduce an encoder bitrate estimation method by obtaining a subset of features from the residue of the WZ and its previous Key frame and using  X  -SVM (Support Vector Machine) regression. We also propose a Hybrid coding mode to further reduce the complexity at the decoder in the feedback-based architecture. This method provides an initial estimate of the bitrate and compensates for the underestimations caused by using the feedback channel.

The remainder of the paper is organized as follows. In Section 2, we will review the previous works on bitrate estimation at the encoder. The proposed method for bitrate estimation is introduced in Section 3. The method and its robustness toward different values for parameters of the  X  -SVM model is evaluated in Section 4. The paper is concluded in Section 5. 2. Related work
One of the early solutions for bitrate estimation in DVC is the work by Artigas et al. [19], wherein they implement a simple rate estimation algorithm which averages the previous and the next frames, and estimates the error probability by comparing this average to the original frame. The bitrate is then allocated using the empirical results obtained in an off-line process from three different sequences. The authors do not specify the details of this algorithm and how the empirical results are used. As reported by the authors, compared to the feedback-based approach, the overall bitrate is 10 Kbps to 100 Kbps, which is noticeable.

Another solution is introduced by Adikari et al. [20] in which encoding of a WZ frame is carried out by two interleaved encoders. The output of each encoder is sent to its corresponding decoder and each decoder uses the output of the other decoder as side information. Decoding is performed iteratively for a given number of iterations. A drawback of this method is that the user has to manually set the bitrate for parity bits, which is undesirable in many applications. In addition, using two Wyner-Ziv encoders increases the encoding complexity by a factor of two. The proposed solution outperforms the conventional Wyner-Ziv codec for a low-motion video sequence. The performance for more complex video sequences is not reported.

In [21], Morbee et al. propose a pixel-domain solution for bitrate estimation. They model the correla-tion noise between the side information and the original WZ frame at the decoder. Next, for every frame, they calculate the error probability at the bitplane level to estimate the bitrate of each bitplane.
A machine learning technique is proposed by Martinez et al. for bitrate estimation [22]. In this tech-nique, they train a decision tree which classifies blocks of the WZ frame into several predefined classes based on their similarity to the previous Key frame. High performance is reported for rate prediction of the two most significant bits of each block. This high performance is mostly due to the introduced skip mode for low residual blocks and the quality of the decoded video is not investigated.

By computing the conditional entropy for each bit-plane of the DCT bands of a WZ frame given its previous and next Key frames, Brites et al. proposed an analytical method for bitrate estimation at the encoder. In this method, a Laplacian distribution models the residual difference between each DCT band of each WZ frame and the DCT bands of Y, where Y is an estimation of the side information generated by applying fast motion compensated interpolation technique on the Key frames. Using this probability model, the conditional probability for the bits of each bitplane of the DCT bands is calculated. These the bitplane is estimated using this conditional entropy together with another factor called the bit-plane relative error probability in a heuristic formulation [23,24].
 Sheng et al. have proposed a rate prediction method [25] in which the frame blocks are Intra coded, WZ coded or skipped, based on their correlation with the estimated side information. The rate for WZ blocks is then estimated using a linear model, based on the conditional entropy of the original WZ block given the estimated side information. While the experiments show an RD (Rate-Distortion) performance close to the feedback-based scenario for low-motion video sequences, the performance for high-motion videos is not investigated.

Recently, Nickaein et al. [26] proposed a neural network-based method in which a trained neural net-work estimates the efficient bitrate for each WZ frame, using a set of features extracted from the residue of the WZ frame and the previous key frame. In this paper, we generalize this method by introducing more robust features and a more robust estimator. The experiment results show that the proposed esti-mator is more accurate and robust to outliers than the one in [26] and less sensitive to the choice of its parameters. 3. Proposed method
Figure 1 shows the proposed architecture, which is an adoption of the feedback-based Stanford codec introduced in [27]. In the proposed architecture, we suppress the feedback channel and introduce an encoder rate control (ERC) module. Each WZ frame is partitioned into four quadrants and each quad-rant is separately coded. The ERC module has two components: the feature extraction component that generates a set of features for each frame and the SVM regression module which estimates the efficient bitrate for that frame. These two modules are explained in the following section. 3.1. Feature extraction
For each WZ frame quadrant X q ,where q =0 , 1 ,... 3 , the residual quadrant X q R is defined as the difference between X q and its corresponding quadrant in the previous frame X q B , zero where the two quadrants are equal and increases as more variation (e.g. motions, intensity changes) appears in X q B with respect to X q . Non-zero values of X q R ( x, y ) indicate that X q B cannot predict X q perfectly. Since the decoder uses X q B as the side information for the original WZ frame, X q R shows the quality of this side information at the decoder for the current quadrant. Therefore, the efficient bitrate can be estimated based on X q R .
 To reduce the dimension of X R , it is mapped to the feature space spanned by the following features: Entropy, Energy, Variance, and estimated  X  parameters for the correlation noise of the DCT coefficients. The entropy is given by where Pr X q R ( x, y )= l represents the fraction of pixels with the intensity value l in quadrant X q R . The normalized energy and variance are also computed by where  X  X q R is the empirical mean of X q R ( x, y ) .

The  X  i feature (for i =0 ,..., 63) is the parameter of the Laplacian distribution estimated for the subband i of the quantized DCT coefficients at the encoder. After applying an 8  X  8DCTtransform, the DCT coefficients are quantized and the coefficients corresponding to the same frequency (e.g. all DC coefficients) are grouped together, making a total of 8  X  8 = 64 groups of coefficients. Finally, the distribution of the i th group is modeled by estimating the parameter of a Laplacian distribution as [28]
We obtain 64 features for each frame quadrant in this procedure. The total number of features extracted for each frame is then 67 features. 3.2. Dimension reduction
In the previous subsection, we introduced our method for feature extraction and obtained 67 features for each frame. To further reduce the dimension of our model and avoid curse of dimensionality ,we investigate the methods to extract a smaller number of features from the raw features.

To evaluate the relevance of all 64  X  i parameters in the bitrate estimation, we first measured their correlation with the optimal bitrate value for 100 frames. Figure 2 illustrates the result of this experiment. A high correlation value for  X  i indicates that it can be employed as an effective feature in estimating the optimal bitrate. To reduce the number of features, only a subset of  X  i  X  X  with absolute correlation values of 0.7 or higher is chosen. This decision is made in the training stage using three video sequences:  X  X all Monitor X ,  X  X oreman X , and  X  X occer X .

The choice of features solely based on their correlation with the target function value is generally a na X ve feature selection approach as redundant features might be selected and relevant features might be discarded since the correlation only measures the linear dependency between two random variables. Two well-known methods for dimension reduction are Sequential Forward Feature Selection (SFFS) [29] and Principal Component Analysis (PCA) [30]. The first is a feature selection method that starts from the feature subsets consisting a single feature and iteratively add more features to these sets in a greedy approach. PCA, on the other hand, is a feature extraction method that finds a linear transformation to map the feature set into a new set of orthogonal features which capture the maximum amount of variation in the input data. We use these two methods to realize if a more compact and accurate set of features can be derived from the initial features. For this purpose, the  X  i features defined in Subsection 3. 1 are extracted for all frames of  X  X oreman X  video sequence and the optimal bitrate for decoding these frames in the feedback-based WZ codec [27] is measured. The 100 data samples obtained from first 100 frames are used as training data and the remaining 40 samples are used as test data. More details about the video sequence and experiments are presented in Section 3.

The SFFS method needs a criteria function to evaluate the hypothesis feature sets. We use the mean-squared error of a prediction model in a cross-validation as our evaluation function. The prediction models employed are feed-forward neural network and SVM. After SFFS determined the optimal fea-ture set, we use this feature set to train a prediction model and measure its performance over the test data. For PCA, we apply PCA on the training data to obtain the linear transformation. We then use this transformation to map data to the new set of features. A subset of new features that captures highest variance of data is selected for training a prediction model and its performance on test data is measured. Again, feed-forward neural network and SVM are employed as prediction models. The number of fea-tures for both PCA and SFFS feature selection methods are varied from 1 to 52 out of 64 features. Each experiment is performed 50 times and the average prediction error in terms of mean-squared error are plotted in Fig. 3.

Figure 3 shows the average error rate for neural network and SVM models, trained using a set of fea-tures selected by either SFFS or PCA, given a certain number of features. The results show that SVM model generally outperform feed-forward neural network model. In addition, the accuracy in SVM mod-els are more stable compared to feed-forward neural network models and they maintain this accuracy when the number of features are relatively high (e.g. 50 features). By comparing the results for SFFS and PCA methods for feature selection, it is observed that SFFS generally outperforms PCA. This shows that the extracted features,  X  i , can properly predict the bitrate and there is no gain in using PCA i.e. mapping these features to a space where maximize the variance. Moreover, the performance of thresh-olding method is close to PCA-SVM and SFFS-SVM cases. This shows that while SFFS and PCA are well-known and more advanced feature selection/extraction methods, the presented method for feature selection is effective hence we will employ it for dimension reduction. 3.3. Support vector regression for bitrate estimation
The origin of SVM have been developed by Vapnik [31] and are employed in various research ar-eas. SVM was developed to solve classification problems and have then been extended to solve regres-sion [32]. The formulation of SVM is inspired by the principles of Structural Risk Minimization (SRM) in the pattern recognition case, and Regularization Theory in the regression case. The advantage of SVM is its ability to map the input into a higher dimensional feature space in an efficient and computationally practical way by an appropriate choice of kernel functions.

The  X  -SVM [33] is a variant of SVM proposed for solving regression problems. The formulation of the where x i  X  R d L , y i  X  R and d L is the dimension of the input feature. The set is assumed to has been generated based on some unknown but well-defined map g : R d L  X  R .Using d H basis functions  X  where  X  ( x )=[  X  1 ( x ) ,..., X  d H ( x )] T and w and b are the parameters of the model that should be optimized based on some criteria.

In  X  -SVM, the method of selecting w and b is to minimize the regularized risk function:
Subject to:
Here, w T w describes the model complexity, 1 N  X  + 1 N  X   X  is the empirical risk (i.e. the slack variables that allow model to have errors on training data), and C is a constant that controls the trade-off between the model complexity and the empirical risk.

The  X  parameter is an upper bound for the fraction of training errors and a lower bound for the fraction of support vectors. Unlike -SVM, the user does not have to set parameter which characterizes the degree of noise insensitivity of the model. This is desirable since the optimal value of is usually unknown.

The function K ( x i ,x j )=  X  ( x i ) T  X  ( x j ) is called the kernel function. It can be shown that the ap-proximation function g ( x ) may be written in terms of the kernel function as
To estimate the required bitrate for each quadrant, we employ  X  -SVM as the regression method at the encoder. As the training data, seventy first frames of the  X  X oreman X ,  X  X all Monitor X , and  X  X oast Guard X  video sequences are encoded with a feedback-based WZ codec [27] and their corresponding bitrates are recorded as optimal bitrates. For each quadrant in these frames, the features introduced in Section 3.1 are also extracted and together with the observed bitrate form the training data. Therefore, the extracted features form the input pattern x i and their corresponding bitrate is the desirable output of the model, i.e. y i .The g function we aim to approximate models the relationship between the extracted features and optimal bitrate. The  X  -SVM is then trained in an off-line training phase and the generated model (the set of support vectors and their corresponding weights) is kept as the ERC model. As seen in the following,  X  -SVM can model this function with a small error margin. This also suggests that the selected features are effective in representing the original residual frame.

We have employed the LIBSVM [34] implementation of  X  -SVM with the RBF kernel in our simu-lations. We set C = 1000 ,  X  =0 . 5 ,and  X  =1 /n where n is the number of features. The impact of different choices of these parameters on the performance is investigated in Section 4.2. 4. Experiments
In this section we will evaluate four coding modes: 1. Feedback mode where the feedback channel is available. The decoder can ask the encoder for 2. SVR-based mode where we use the trained SVM to estimate the efficient bitrate for each quadrant 3. Hybrid mode is a mixture of the two previous modes where the SVM initially predicts the required 4. NN-based mode which represents the neural network-based solution we have introduced in our 4.1. Experimental setup
We use three video sequences to evaluate the coding modes. The video sequences are  X  X oreman X ,  X  X all Monitor X , and  X  X occer X , at QCIF resolution and frame rate 15 Hz. We divide the first 140 frames of each video sequence into two equal parts. The first half is used for training the SVM and the other half (the remaining seventy frames) is used in the testing phase with a GOP size of two. The motion oracle mode [27] of the Stanford codec is used to generate the side information.

The coding is performed four times with Q =0 . 5 , 1 , 2 , 4 as the scaling factor of the quantization matrix, yielding four RD points for each sequence.
 4.2. Experimental results
The RD performance of the coding modes is shown in Figs 4 to 6. The Feedback-based mode has the highest RD performance in all video sequences as expected. On the other hand, the NN-based mode generally has the lowest performance.

The Hybrid mode has both higher bitrate and higher quality than the SVR-based mode. The higher bitrate is caused by requesting for more bits as compensation for bitrate underestimation, while the higher quality (identical to the DRC mode quality) is in fact due to the failure of the SVR-based mode in some cases. The Hybrid mode has a slightly higher bitrate than the DRC mode (9 Kbit/s in average) owing to overestimation of the actual bitrate for some quadrants.

The SVR-based method generally outperforms the NN-based method, especially in high motion videos where its performance is noticeably higher (Fig. 6). This shows that SVR estimation is more robust than feed-forward neural network for diverse values of bitrate. This can be verified by comparing the average mean squared error of  X  -SVM presented in Table 2 to that of the neural network method [26] and comparing average mean-squared error of SVM and feed-forward neural network (Fig. 3). Both SVR-based and NN-based modes exhibit good and almost identical RD performance for  X  X all Monitor X  which is a low-motion video sequence. However, in videos with higher motions their perfor-mances drop, namely in  X  X oreman X  and  X  X occer X  video sequences. This is mainly due to the technique we have adopted for recovering from decoding failures caused by bitrate underestimation. The technique is to use the quadrant from the previous frame as an estimation of the current lost quadrant. This method can compensate for the loss in the low-motion videos, while the previous quadrant is not necessarily an accurate estimation of the current missing quadrant in the high motion video sequences and a drop in PSNR is likely to occur.
 Figure 7 shows the bitrate for transferred WZ frames using different coding methods in addition to the PSNR of the decoded WZ frames. One notable observation is that for some frames, an underestimation in the bitrate causes a significant drop in the PSNR of the SVR-based method; even if the underestima-tion seems to be negligible. This is due to the failure in decoding the WZ frame since the transferred bits were not sufficient for correcting the errors. While we can improve the RD performance by favor-ing overestimation over underestimation by giving a higher error cost to the latter, this underestimation could still happen in some cases. In fact, we are already overestimating the bitrate since we have simply used the difference between WZ and Key frames to see how well the previous frame can predict the cur-rent frame. In a nutshell, bitrate underestimation is a n inherent limitation in the Stanford feedback-free architectures and its undesirable impact should be reduced by the use of advanced recovery techniques at the decoder [35 X 37].

Table 1 shows the average decoding time in seconds for  X  X oreman X  frames. While the Hybrid method has the feedback channel and has a slightly higher bitrate compared to the DRC mode, it imposes signif-icantly lower computational complexity at the decoder. This is a result of estimating the required bitrate initially, which prevents c onsecutive decoding failures until su ccessful decoding, which is inherent in Feedback-based mode. The mean squared error of bitrate estimator for the test frames of each video sequence is presented in Table 2 to study the accuracy of the bit rate estimation in diff erent conditions. Accordi ng to these results, the performance of the estimator is invariant of different video sequences and qualities. What causes the varying RD performance in different video sequences and qualities is the variation of side information quality in different conditions. Specifically, as the th ree video sequences have different motion levels, the accuracy of the side information is not steady and high-motion videos are more sensitive to bitrate underestimation. Therefore, while the bitrate estimation error, reported in Table 2, is independent of videos with different motions, the quality of side information is not and it is the cause of more failures in high motion videos (Table 3). 4.3. Robustness of the estimator
A key superiority of SVM regression over neural network regression is that the complexity of the model is automatically handled in the former while there is no straightforward method to determine the optimal model (e.g. number of layers, number of nodes, and activation functions) in the latter.
To study the effect of  X  -SVM parameters on the estimation performance, we have trained the  X  -SVM using different values for  X  and C in 50 iterations and averaged the mean squared error of the trained  X  -SVM on the test samples. The resu lts are illustrated in Fig . 8. As it can be seen, t he estimation accuracy is not sensitive to the value of  X  and  X  = 0.5 is a proper choice in the rest of the experiments. The performance of  X  -SVM is also invariant to the value of C as long as it is chosen large enough ( C&gt; 100). 5. Conclusion
A major limitation of distributed video coding in Stanford architecture is the presence of a feedback channel. The only role of this feedback channel is to allow the decoder to request for more bits from the encoder. In this paper, we presented a bit rate estimation method which employs a trained SVR model to estimate the bitrate for each WZ frame.

This method allows a feed-back free DVC scheme wherein there is no need for a feedback channel from the decoder to the encoder. To estimate the bitrate, we employed an SVR-based module which extracts a set of features from the residual between the encoding WZ frame and the previous key frame. The SVR model estimates the efficient bitrate for the current WZ frame and then the estimated number of bits is sent to the decoder. The SVM model is trained in an offline training phase. The experimental results show high estimation accuracy in terms of mean squared error. The RD performance is close to the ideal for low-motion videos (Hall Monitor video sequence) and drops down to 2dB for high-motion videos (Soccer video sequence). This reduction is mainly due to the simple technique used in the generation of side information and using more advanced methods in side information generation could avoid this decline.

In addition, a hybrid method is proposed that hires the feedback channel and bitrate estimation. Similar to the feedback-free method, in this method the encode r estimates the efficient bitrate for a WZ frame using the SVM model. In the case of bitrate underestimation, however, the decoder can request for more bits from the decoder. The experimental results demonstrate that this method maintains an RD performance close to the ideal while considerably reducing the complexity of the decoder. References
