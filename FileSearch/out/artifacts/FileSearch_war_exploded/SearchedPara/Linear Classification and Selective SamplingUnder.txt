 instances generated by an unknown source. Each time a new ins tance is received the learner predicts observed. This protocol is natural in many applications, fo r instance weather forecasting or stock market prediction, because Nature (or the market) is sponta neously disclosing the true label after each learner X  X  guess. On the other hand, in many other applic ations obtaining labels may be an measured with respect to both the number of mistakes (made on the entire sequence of instances) likely to be useful to the algorithm, and then queries those o nes only. This strategy somehow needs to combine a measure of utility of examples with a measure of c onfidence. In the case of learning the margin. In [10] this approach was employed to define a sele ctive sampling rule that queries a a linear learning algorithm based on an incremental version of Regularized linear Least-Squares (RLS) for classification. Although this selective sampling algorithm is efficient, and has simple of this algorithm.
 We improve on those results in several ways making three main contributions: (i) By coupling the Tsybakov low noise condition, used to parametrize the insta nce distribution, with the linear model exponent in the low noise condition. (ii) Under the same low n oise condition, we prove that the on a real-world medium-size dataset showing that variants o f our mistake-driven sampler compare favorably with other selective samplers proposed in the lit erature, like the ones in [11, 16, 20]. Related work. Selective sampling, originally introduced by Cohn, Atlas a nd Ladner in [13, 14], survey), the goal is to identify an unknown boolean function f from a given class, and the learner framework in which the learner also queries arbitrary domai n points. However, in their case labels are stochastically related to instances (which are real vec tors). They prove risk bounds in terms of nonparametric characterizations of both the regularity of the Bayes decision boundary and the and sequential hypothesis testing exists (see for instance the detailed description in [9]) which is concerned with problems that share similarities with activ e learning. The idea of querying small based model of active learning, where the algorithm is allow ed to interactively choose which labels to obtain from an i.i.d. pool of unlabeled instances. A landm ark result in the selective sampling protocol is the query-by-committee algorithm of Freund, Se ung, Shamir and Tishby [17]. In the a more practical implementation). An exponential advantag e in the realizable case is also obtained with a simple variant of the Perceptron algorithm by Dasgupt a, Kalai and Monteleoni [16], under labels are needed, where  X  is the risk of f  X  . A much more general nonparametric lower bound for active learning is obtained by Castro and Nowak [9]. General selective sampling strategies for the nonrealizable case have been proposed in [3, 4, 15]. However , none of these learning algorithms We consider the following online selective sampling protoc ol. At each step t = 1 , 2 ,... the sam-pling algorithm (or selective sampler ) receives an instance x for the associated label y pling X  (issuing a query) in order to receive the label y seeing the label y information encoded by ( x We assume instances x distribution on the surface of the unit Euclidean sphere in R d , so that k X Following [10], we assume that labels y noise model: there exists a fixed and unknown vector u  X  R d , with Euclidean norm k u k = 1 , such that E Y for this noise model. In the following, all probabilities P and expectations E are understood with respect to the joint distribution of the i.i.d. data process { ( X to denote conditioning on ( X where each f When ( X X R the learner X  X  predictions can only depend on the queried exa mples, the regret is computed over all time steps, including the ones when the selective sampler di d not issue a query. In order to model the distribution of the instances around the hyperplane u  X  x = 0 , we use Mammen-Tsybakov low noise condition [24]: tion, one can show that  X   X  X  X  implies the hard margin condition | f  X  ( X We consider linear classifiers predicting the value of Y a dynamically updated weight vector which might be intended as the current estimate for u . Our w be the number of queried examples during the first t time steps, S matrix of the queried instances up to time t  X  1 , and y corresponding labels. Then the RLS estimator is defined by where I is the d  X  d identity matrix. Note that w estimator in this particular form has been first considered b y Vovk [25] and by Azoury and War-muth [2]. Compared to standard RLS, here x use b  X  the current approximation to  X  S matrices, we can compute updates and predictions in time  X ( d 2 ) . The algorithm in (2) can also be expressed in dual variable form. This is needed, for insta nce, when we want to use the feature represented in O ( N 2 is the baseline against which we measure the performance of o ur selective sampling algorithm. The regret bound is expressed i.t.o. the whole spectrum of the pr ocess covariance matrix E [ X Theorem 1 Assume the low noise condition (1) holds with exponent  X   X  0 and constant c &gt; 0 . Then the expected cumulative regret after n steps of the fully supervised algorithm based on (2) is bounded by E 4 c (1 + ln | I + S 4 c 1 + nant of a matrix, S When  X  = 0 (corresponding to a vacuous noise condition) the bound of Th eorem 1 reduces to O logarithmic behavior O d ln n . Notice that P d whenever the spectrum of E [ X meaningful even when d =  X  , while the third one only applies to the finite dimensional ca se. Parameters:  X  &gt; 0 ,  X  Initialization: weight vector w = (0 ,..., 0)  X  ; storage counter N = 0 .
 At each time t = 1 , 2 ,... do the following: Fast rates of convergence have typically been proven for bat ch-style algorithms, such as empirical to our paper is Ying and Zhou [26], where the authors prove bou nds for online linear classification using the low noise condition (1), though under different di stributional assumptions. eigenvalue of the process covariance matrix E [ X sampler issues a query at time t based on both the query counter N ically, if evidence is collected that the number N estimate of 1 /  X  2 instance x tion about the data-generating process. This additional in formation is needed because, unlike the prevents us from bounding the sum of conditional variances o f the involved RLS estimator through ln I + S n S  X  n , as we can do when proving Theorem 1 (see below). Instead, we h ave to individu-ally bound each conditional variance term via the smallest e mpirical eigenvalue of the correlation matrix. The transient regime in Figure 1 is exactly needed to ensure that this smallest empirical capture the two main aspects of the selective sampling proto col: First, we control the probability of making a mistake when we do not query labels; second, the al gorithm is able to adaptively op-timize the sampling rate by exploiting the additional infor mation provided by the examples having small margin. The appropriate sampling rate clearly depend s on the (unknown) amount of noise  X  that, when a small margin is detected, a query be issued (and t he next example be stored) only if geous from a computational standpoint, because of the spars ity of the computed solution. It is easy in Theorem 2. However, in this case we can only give guarantee s on the expected number of stored examples (which can indeed be much smaller than the actual nu mber of queried labels). Theorem 2 Assume the low noise condition (1) holds with unknown expone nt  X   X  0 and assume the selective sampler of Figure 1 is run with  X  cumulative regret is bounded by O d + ln n of queried labels (including the stored ones) is bounded by O d + ln n The proof, sketched below, hinges on showing that b  X  margin  X  that our selective sampler is able to adaptively estimate th e number of queries needed to ensure a 1 /t increase of the regret when a query is not issued at time t .
 grets are expressed in terms of the number N of issued queries. To see this consider first the case  X   X   X  (the hard margin case, essentially analyzed in [10]). Then b oth algorithms have a per-step regret of order (ln n ) /n . However, since the semi-supervised algorithm makes only N = O (ln n ) order N/e N where the fully supervised has only (ln N ) /N . We have thus recovered the exponen-tial advantage observed in previous works [16, 17]. When  X  = 0 (vacuous noise conditions), the per-step regret rates in terms of N become (excluding logarithmic factors) of order N  X  1 / 3 in the of  X  where the semi-supervised bound becomes better. In order to find this critical value we write the N indicates that selective sampling is advantageous when the noise level (as modeled by the Mammen-Tsybakov condition) is not too high. Finally, observe that t he way it is stated now, the bound of Remark 3 below.
 Proof of Theorem 1. The proof proceeds by relating the classification regret to t he square loss re-gret via a comparison theorem. The square loss regret is then controlled by applying a known point-wise bound. For all measurable f : R d  X  R , let R be the square loss regret, and R rem from [5] with the  X  -transform function  X  ( z ) = z 2 associated with the square loss. Under the low noise condition (1) this yields R ( f )  X  4 cR have E P n P Theorem 11.8]) by 1 + ln I + S argument, and then to the concave function ln || of a (positive definite) matrix argument. Observing that E S from the second one just by using  X  Proof sketch of Theorem 2. We aim at bounding from above the cumulative regret P to be at most cn X  1+  X  + P n label (because b  X  2 queries at all.
 Note that (III) bounds the regret over non-sampled examples . In what follows, we sketch the way we bound each of the three terms separately. A bound on (I) is e asily obtained as (I)  X   X  the subsequence of stored instances and labels is a sequence of i.i.d. random variables distributed as showing that for any fixed number N of |  X  t |  X   X  by known results (the one we used is [21, Theorem 4.2]) on the c oncentration of eigenvalues of these concentration results we can bound term (II) by O ( d +ln n Putting together and choosing  X  of the order of ln n on the number of queried labels is obtained in a similar way.
 Remark 3 The linear dependence on d in Theorem 2 derives from a direct application of the con-the way the process spectrum decreases (e.g., [6, 7]), there by extending the above analysis to the to Theorem 2, since the resulting bounds would be harder to re ad, and would somehow obscure understanding of regret and sampling rate behavior as a func tion of n . In evaluating the empirical performance of our selective sa mpling algorithm, we consider two addi-we want to leverage the more informative content of small mar gin instances. The second variant is a mistake-driven version (referred to as SSMD , Selective Sampling Mistake Driven) that queries the the algorithm in Figure 1 will then be called SSNL (Selective Sampling Next Label) since it queries the next label whenever a small margin is observed. For all th ree algorithms we dropped the intial transient regime (Step 3 in Figure 1).
 Reuters Corpus Volume 1 dataset (RCV1). Every example in thi s dataset is encoded as a vector of real attributes computed through a standard TF -IDF bag-of-words processing of the original news of excerpts from a newswire feed is a realistic learning prob lem for selective sampling algorithms classification performance is measured using a macroaverag ed F -measure 2 RP/ ( R + P ) , where P dual variable implementations and linear kernels.
 The results are summarized in Figures 2 and 3. The former only refers to (an average over) the 50 most frequent categories, while the latter includes them al l. In Figure 2 (left) we show how SSMD compares to SSNL , and to its most immediate counterpart, SS . In Figure 2 (right) we compare SSMD to other algorithms that are known to have good empirical per formance, including the second-order version of the label efficient classifier ( SOLE ), as described in [11], and the DKMPERC variant of the DKM algorithm (see, e.g., [16, 20]). DKMPERC differs from DKM since it adopts a standard perceptron update rule. The perceptron algorithm ( PERC ) and its second-order counterpart ( SOP ) a mistake-driven variant of the algorithm analyzed in Theor em 1. It is reasonable to assume that in a selective sampling setup we are interested in the perfor mance achieved when the fraction of queried labels stays below some threshold, say 10% . In this range of sampling rate, SSMD has the steepest increase in the achieved F -measure, and surpasses any other algorithm. Unsurprising ly, as the number of queried labels gets larger, SSMD , SOLE and SOP exhibit similar behaviors. Moreover, Figure 2: Average F -measure obtained by different algorithms after 40 , 000 examples, as a function of the number of queried labels. The average only refers to th e 50 most frequent categories. Points are obtained by repeatedly running each algorithm with diff erent values of parameters (in Figure 1, the relevant parameter is  X  ). Trend lines are computed as approximate cubic splines con necting consecutive points. task, as measured by the separation margin. Right: F -measure achieved on the different binary of positive examples. The two plots are produced by SSMD with a specific value of the  X  parameter. Varying  X  does not significantly alter the reported trend. provides a significant advantage. Under our test conditions DKMPERC proved ineffective, probably because most tasks in the RCV1 dataset are not linearly separ able. A similar behavior was observed other algorithms considered here are based on the more compu tationally intensive ridge regression-like procedure.
 In our selective sampling framework it is important to inves tigate how harder problems influence the sampling rate of an algorithm and, for each binary proble m, to assess the impact of the number of positive examples on F-measure performance. Coarsely sp eaking, we would expect that the hard topics are the infrequent ones. Here we focus on SSMD since it is reasonably the best candidate, among our selective samplers, as applied to real-world prob lems. In Figure 3 (left) we report the (right). Note that in both plots topics are sorted by frequen cy with the most frequent categories obtained by running the C -SVM algorithm on that task 1 . Figure 3 (left) clearly shows that SSMD different numbers of positive examples, the storage rate ac hieved by SSMD on those tasks may be similar when the norm of the weight vectors computed by C -SVM is nearly the same. On the other number of positive examples, but this independence is obtai ned at the cost of querying more and in order to achieve a good F-measure performance, it compens ates by querying many more labels.
