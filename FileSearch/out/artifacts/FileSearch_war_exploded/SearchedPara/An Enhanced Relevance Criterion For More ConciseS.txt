 Supervised local pattern discovery aims to find subsets of a database with a high statistical unusualness in the distribu-tion of a target attribute. Local pattern discovery is often used to generate a human-understandable representation of the most interesting dependencies in a data set. Hence, the more crisp and concise the output is, the better. Unfor-tunately, standard algorithm often produce very large and redundant outputs.

In this paper, we introduce  X -relevance, a definition of a more strict criterion of relevance. It will allow us to signifi-cantly reduce the output space, while being able to guaran-tee that every local pattern has a  X -relevant representative which is almost as good in a clearly defined sense. We show empirically that  X -relevance leads to a considerable reduc-tion of the amount of returned patterns. We also demon-strate that in a top-k setting, the removal of not  X -relevant patterns improves the quality of the result set.
 H.2.8 [ H.2.8 Database Applications ]: Data mining Theory,Algorithms Local Patterns, Subgroup Discovery, Theory of Relevance
Supervised local pattern discovery is the task of finding patterns that describe subsets of a database with a high sta-tistical unusualness in the distribution of a target attribute. Different approaches for supervised local pattern discovery have been proposed, which differ in the way in which the statistical unusualness is defined. Among these approaches are subgroup discovery [10] contrast set mining [2] and cor-related itemset mining [20], all of which are also sometimes subsumed under the name supervised descriptive rule dis-covery [12]. Hence, in this paper we use the words pattern and subgroup interchangeably. Moreover, we will focus one the special case of a binary class label.

In many (if not most) applications of supervised pattern discovery, the practical usefulness of the approach depends on the ability to produce a concise, non-redundant output. Unfortunately, in particular in situations with some amount of noise, standard local pattern algorithms are often found to return a high number of very similar, correlated patterns. Figure 1: Highly correlated set of subgroups. If a s mall loss of precision is tolerable, each single sub-group already describes the target concept well.

The basic problem is depicted in Figure 1. Here, we have aligned (or projected) the instances in a two-dimensional space, and the green area highlights a subset with a high share of target-class instances ( X + X ). The figure also shows three subgroups, visualized by rectangular boxes. While it is clear that all subgroups are correct, non-identical descrip-tions of parts of the target concept, they are highly corre-lated. Hence, when one is willing to sacrifice a small amount of precision in favor of simplicity, one single subgroup suf-fices to describe the target concept reasonably well.
Different techniques have been used to reduce the output space of supervised pattern discovery. One particularly in-teresting approach is the theory of relevance [7]. The idea is to check whether a subgroup s d is better suited as a predictor of the label than another subgroup sd irr , which holds true if all correct prediction from sd irr can be made by sd as well, and all errors from sd are made by sd irr as well. If so, then sd irr is irrelevant and can be ignored. A pattern is then defined to be relevant if it is not dominated by another pattern in the above sense.

While the theory of relevance provides a nice theoreti-cal approach to the suppression of useless patterns, and has shown to be of great use in practical applications [14], it is based on a stringent definition of dominance. Even if a pattern misclassifies hundreds or thousands of positives cor-rectly matched by another pattern, but is better on a single negative, then the former pattern will not be considered as dominated by the latter pattern.

In this paper, we aim at an extended definition of rele-vance that allows for a controlled amount of lenience. To this end, we propose a relaxed criterion of dominance, which al-lows a dominating subgroup to predict a small number of ex-amples worse than its dominated counterpart. Thereupon, we define a more strict criterion of relevance : Due to the relaxed criterion of dominance, more patterns may dom-inate a given pattern, such that it is harder for a pattern not to be dominated, i.e. to be relevant.

The resulting definition of  X -relevance will allow us to significantly reduce the output space. At the same time, it will provide the guarantee that every local pattern sd  X  X  has a  X -relevant representative which is almost as good, in the sense that if the dominated pattern has precision p (i.e. a share of positives p ), then the  X -relevant representative will (i) support all of sd  X  X  positives and (ii) will have at least precision (1  X   X )  X  p . That is, the loss in precision is limited by the factor  X .

As the main contribution of our paper we see
To demonstrate the usefulness of  X -relevance we show experimentally that it results in a significant reduction of the number of resulting patterns. Moreover, to show that  X -relevance keeps the X  X mportant X  X attern and only removes patterns of little use, we will also apply it to top-k subgroup discovery [10]. The basic idea, depicted in Figure 2, is that removing subgroups which are not  X -relevant from the top-k patterns allows other patterns, which cover different and thus more interesting aspects of pattern space, to make into the output.

Every  X -relevant pattern is closed on the positives, mean-ing that the  X -relevant patterns is a subset of the well-known closed patterns [6, 3]. Compared to heuristic approaches for redundancy avoidance, like weighted covering [13] or beam selection strategies [22],  X -relevance is a principled approach that provides formal guarantees on the quality of the result. Figure 2: Top subfigure shows the classical top-3 s ubgroups, which are highly correlated; The bottom subfigure shows that choosing a representative for the sets of highly correlated subgroups allows other, non-redundant subgroup descriptions to enter the top-3 result list Moreover, although (like the other approaches) it introduces a new parameter, this parameter has a clear interpretation (the loss in precision tolerated for the representatives). Fi-nally, compared to  X -closed itemsets [4], in spite of the sim-ilar name it has different characteristics: in our approach there is a guarantee that for every dominated pattern has a  X -dominant representative, which is not guaranteed for  X -closed itemsets.

The remainder of this paper is structured as follows: the next section formally introduces the notions of closure op-erators, domination and relevance. Section 3 describes our theoretical contribution, the definition of  X -relevance, which is a more strict criterion of relevance. This is applied to the problem of subgroup discovery in Section 4. Experiments in Section 5 demonstrate that  X -relevance leads to a consider-able reduction of the size of the set of subgroups and that the combination with top-k approaches improves the quality of the outcome. Section 6 concludes.
We will now briefly review the (classical) definition of rele-vance and summarize some important results from that area.
A database DB is a collection of data records , i.e. DB = d , . . . , d m . We assume every record d i to be described by a set of n binary features ( f 1 ( d i ) , . . . , f n ( d Moreover, we assume that all records have a binary label . Formally, the label is a special feature class ( d ) with range { + ,  X  X  . A subgroup description sd is a subset of the feature set, i.e. sd  X  { f 1 , . . . , f n } . In the following, we will sometimes simply write subgroup to refer to a subgroup description. A data record d satisfies sd if f ( d ) = 1 for all f  X  s d . Finally, DB [ sd ] to denote the set of records d  X  DB of a database DB satisfying a subgroup description sd .
The theory of relevance [15, 14] is aimed at eliminating irrelevant patterns. A subgroup sd irr is considered as irrele-vant if it is dominated (or covered ) by another subgroup sd in the following sense:
Definition 1. The subgroup sd irr is dominated by the subgroup sd in database DB iff. Here, TP denotes the true positives , which are defined as TP ( DB , sd ) = { c  X  DB [ sd ] | class ( c ) = + } . Similarly, FP denotes the false positives , i.e. FP ( DB , sd ) = { c  X  DB [ sd ] | class ( c ) =  X  X  . Note that it is possible that two subgroups dominate each other, however only in the case that they have identical support. In this case, their closure can be used as their common unique representative.
The above notion allows to distinguish between irrele-vant and relevant subgroups, the former being those dom-inated by a different subgroup. The idea of the theory of relevance is to restrict consideration to the relevant sub-groups, because for each of the other subgroups there is a dominating relevant subgroup which is more valuable.
As shown by Garriga et al. [7], the notion of relevance can be restated in terms of the following mapping between subgroup descriptions:  X  + is a closure operator , i.e. a function defined on the P ( { f 1 , . . . , f n } ), (i) X  X   X ( X ) (extensivity), (ii) X  X  Y  X   X ( X )  X   X ( Y ) (monotonicity), and (iii)  X ( X ) =  X ( X ( X )) (idempotence) holds.

The fixpoints of  X  + , i.e. the subgroup descriptions sd such that sd =  X  + ( sd ), are called the closed-on-the-positives . The main result in [7] is that
Proposition 1. The space of relevant patterns consists of all patterns sd rel satisfying the following:
The connection between relevancy and closure operators is particularly interesting because closure operators have ex-tensively been studied in the area of closed pattern mining (cf. [21]). However, unlike here in closed pattern mining the closure operator is defined solely on the support , with-out accounting for labels (i.e.,  X  sup ( X ) = { f |  X  d  X  DB [ X ] : f [ d ] = 1 } ). The fixpoints of this closure operator are simply called closed patterns.
We will now present our relaxed dominance criterion which leads to a stricter definition of relevance. But before we do so, let us give a short example why such a criterion is neces-sary. Let sd 1 be a pattern which covers 1000 positive exam-ples and 1 negative example. Let sd 2 be specialization of sd that covers exactly the same examples, with the exception of one positive and the negative one. Obviously, neither of the subgroups dominates each other, because although the true positives of sd 2 are contained in the true positives of sd one false positive of sd 1 is missing in sd 2 (intuitively speak-ing, sd 1 is better than sd 2 on the positives, but worse on the negatives). However, in practice it is questionable whether such a small difference will have any significant impact.
Motivated by this example, we will introduce a definition of dominance that allows a percentage  X  of missing false pos-itives in the dominated pattern. I.e. the dominated pattern may be better than the dominating one on the negatives, but only slightly so. Thus, in the above example sd 2 would be dominated by sd 1 (for an appropriate  X ).

It is obvious that larger datasets can be constructed ac-cording to the scheme of our example. In larger datasets the effect can be that the top-k subgroups all characterize very similar subgroups, while other, different and thus more interesting subgroups are pushed out of the result. To over-come this problem, we will now propose a relaxed definition of relevance.
The first step in defining a relaxed notion of relevance is to modify the definition of dominance. To this end, we intro-duce the notion of  X -domination, where  X  is a real-valued parameter between 0 and 1. The larger the value of  X , the lower the requirements for a subgroup to be dominated, and thus the more subgroups are (potentially) dominated.
Definition 2. (  X  -dominance ) Let  X  be some value, 0  X   X  &lt; 1 . The subgroup sd irr is  X  -dominated by the subgroup sd in database DB iff.
Intuitively, this definition says that sd irr is  X -dominated if it supports less positives than the dominating pattern, and although it may support less negatives than the dominating pattern, the number of negatives in this difference set is rel-atively small compared with the overall size of the subgroup sd
Note that also alternative definitions of the second con-straint would be possible, e.g. using a constant bound on the number of additional false positives. The main advan-tage of the relative definition is that it allows us to quantify the relation between the share of positives in the dominated subgroup and in the dominating subgroups:
Proposition 2. If a subgroup sd irr is  X  -dominated by a subgroup sd rel , then the share of positives in sd rel is no lower than (1  X   X ) times the share of positives in sd irr . Formally,
Proof. W e have that | TP ( DB , sd rel ) | / | DB [ sd rel ] | = | TP ( DB , sd rel ) | / ( | TP ( DB , sd rel ) | + | FP ( DB , sd | TP ( DB , sd rel ) | / ( | TP ( DB , sd rel ) | + From the first condition of relevance, we can conclude that the above must be Moreover, from the second condition we have which together from the earlier inequality implies the propo-sition.

With this proposition,  X  becomes a parameter with a c learly defined semantic, namely the control of the trade-off of compression versus allowed loss of precision p ( sd ) = value of  X  that is consistent with his practical application requirements. Note that the question of how much loss of precision is still considered as tolerable is an external de-cision, hence it is necessary to include a user-controllable parameter for this step.
In this part, we will prove some important properties of the generalized definition of dominance that will be of im-portance later. As already mention, a higher value of  X  has the effect that potentially more subgroups are dominated. In fact, the following implication holds:
Lemma 3. If a subgroup sd  X  -dominates another sub-group sd irr , then the subgroup sd  X   X  -dominates sd irr  X   X  &gt;  X  .

Proof. This follows from the fact that the function f ( X ) = 1  X   X  i s monotonically increasing for  X  &lt; 1.

In particular, every subgroup dominated according to the c lassical definition of dominance is  X -dominated for arbi-trary  X , as 0-dominance is equivalent to classical dominance. The definition of  X -dominance implies additional properties, which are similar to those of the classical definition:
Lemma 4. The following holds: 1. Every subgroup sd notCl not closed on the positives is 2. Let sd 1 , sd 2 be different subgroups closed on the pos-3. Every subgroup that is closed on the positives and that
Proof. Item 1: Let sd notCl be some subgroup not closed on the positives. Then sd notCl is dominated by sd closed  X  ( sd notCl ). This can be verified by checking the conditions of the definition of domination: 1. both subgroups support the same set of positives (by definition), hence the first con-dition is satisfied. 2. sd closed supports a subset of the ex-amples supported by sd notCl , hence the second condition is satisfied.
 Item 2: By condition 1 of the definition of relevance, the TP supported by sd 1 are all supported by sd 2 . Hence, the closure on the positives of sd 1 contains the subgroup de-scription of sd 2 . As sd 1 is closed on the positives, sd be a specialization of sd 2 .

Item 3: Assume that sd irr is dominated by some pat-tern sd notCl not closed on the positives. Then, it must also be dominated by sd closed =  X  + ( sd notCl ): first, sd and sd notCl support the same positives. Second, by Defini-tion 2 we have | FP ( DB , sd notCl ) \ FP ( DB , sd irr ) |  X   X  / (1  X   X ) | DB [ sd irr ] | . Moreover, the false positives of sd subset of the false positives of sd closed , which implies | FP ( DB , sd rel ) \ FP ( DB , sd irr ) |  X   X  / (1  X   X ) | DB [ sd completes the proof.

Finally, we will present an example to illustrate the defi-n ition and to show that dominance does not have one par-ticular property, namely transitivity. Please consider the example dataset is given in Table 1. It includes three fea-tures, A , B and C , and the support of each of these features is a subset of the support of the previous features.
The space of subgroup descriptions of this example is vi-sualized in Figure 3, together with the records that support the different subgroups (positive records are rendered with a gray filling). The subgroup C (which is equivalent to ABC ) supports only one record, which is positive; the subgroup B (resp. AB ) supports three records, two of which are pos-itive; and finally A supports 5 records, three of which are positive.
 Figure 3: The dominance relation is not transitive
F or  X  = 0,  X -domination does not differ from the classi-cal definition of domination, so none of the above subgroup descriptions is dominated. For  X  = 0 . 5, A  X -dominates AB : the true positives of AB (examples 1 and 3) are also true positives of A , there exists 1 false positive of A that is no false positive of AB (example 4), AB covers a total of 3 examples (1,2, and 3), and 1  X  0 . 5  X  3 . Similarly, it is easy to verify that AB 0 . 5-dominates ABC . However, A does not 0 . 5-dominate ABC , because 1 &gt; 0 . 5  X  1: the  X -dominance relation is not transitive !
Now that we have defined  X -dominance, we turn to the definition of  X -relevance. It might seem at first that  X -relevance can be defined in complete analogy to classical relevance (where a subgroup is relevant if it is not dominated by any other subgroup). This, however, is problematic due to the different characteristics of  X -dominance, namely to the missing transitivity.

If we would define patterns to be  X -relevant if they are not being dominated by any other pattern, then there would be irrelevant patterns (wrt. such a definition) that are not dominated by relevant pattern. The effect would be that (unlike it classical relevance) patterns could be suppressed although the result does not contain a dominating pattern.
To avoid such undesirable situations, we base our def-inition of  X -relevance on the notion of a covering of  X -dominating subgroups:
Definition 3. Given a dataset DB, a set of subgroups S is called a covering of  X  -relevant subgroups for DB iff.
The first condition ensures that S is a covering, that is, every subgroup has a  X  -relevant representative . The second requires it to be minimal . The third condition says that we want the covering to consist only of subgroups closed on the positives , because as usual we want to use these as representatives.

The practical significance of this definition is that in com-bination with Proposition 2 we can now guarantee that if one is willing to tolerate a loss of precision of at most  X , it suffices to look only at the subgroups in such a cover-ing. Part 1 of the definition guarantees that for all other subgroups we can find a subgroup in the covering which is almost as good.

While this definition seems to leave a high degree of free-dom, in fact it defines precisely one single set of patterns. These can be constructed iteratively, based on the specializa-tion graph defined on the patterns closed-on-the-positives. This graph G = ( V, E ) has, as vertex set V , the set of closed-on-the-positives, and its edge set consists of all ( p, p that p  X  is a specialization of p (not necessarily a direct spe-cialization). Based on this graph, the covering of  X -relevant subgroups can be constructed as described in Algorithm 1.
We will now prove that these construction rules are cor-rect, and yield a uniquely determine set of patterns:
Proposition 5. The algorithm calculates a set Cov such that (i) Cov is a covering; and (ii) any covering must include all patterns in Cov.

Proof. We first show inductively that all nodes in Cov must be part of the covering.
 Algorithm 1 C overing of  X -relevant Subgroups 1: l et G = the specialization graph for the patterns 2: let Cov := { c  X  G | c has no predecessor in G } 3: while the vertex set of G is not empty do 4: G := the graph obtained from G by removing all  X -5: let Cov := Cov  X  X  c  X  G | c has no predecessor in G } 6: return Cov (Base case:) The set of vertexes selected in Line 2 have t o be part of the covering, because (i) they are closed on the positives, and (ii) there isn X  X  any closed-on-the-positive generalization of them. Thus, according to Lemma 4 they are not  X -dominated by any other pattern and hence they must be part of the covering. (Inductive step:) All nodes removed in 4 cannot be part of any covering. This follows directly from the second part of Definition 3 together with the fact that the covering already includes a pattern that  X -dominates them.

Moreover, all nodes added to the covering in Line 5 must be part of the covering. This follows from Lemma 4 and the facts that (i) the covering does not yet include a pat-tern which  X -dominates them, and (ii) there isn X  X  any  X -dominating pattern which could alternatively be added to the covering, because for all generalizations we already know that they either cannot be part of the covering or are not  X -dominating.

This completes the first part of the proof. It remains to show that the algorithms terminates, and that when it ends Cov contains a covering.

The fact that the algorithm ends follows from the facts that the (initial) vertex set is finite, and that in every loop the graph is replaced by a graph with strictly less vertexes (because G has no cycles).

Finally, Cov must be a covering because for every ver-tex resp. pattern, either it is in the covering or there is a dominating pattern in Cov . This directly follows from the construction of the algorithm for patterns that are closed on the positives. For all other patterns sd notCl , either their closure in the positives, sd closed =  X  + ( sd notCl ) is a member of Cov ; then, they are obviously dominated. Else, their clo-sure sd closed is dominated by some member sd rel of Cov . By statement 2 of Lemma 4, sd rel is a generalization of sd closed Hence, the true positives of sd rel are a superset of the true positives of sd closed , resp. sd notCl and the first condition of Definition 2 is satisfied. It remains to show that the second condition also holds. sd rel dominates sd closed , hence by Definition 2 we have | FP ( DB , sd rel ) \ FP ( DB , sd closed ) |  X   X  / (1  X   X ) | DB [ sd
Moreover, the false positives of sd notCl are a superset of the false positives of sd closed , and the support set of sd is a superset of the support set of sd closed . This implies | FP ( DB , sd rel ) \ FP ( DB , sd notCl ) |  X   X  / (1  X   X ) | DB [ sd
Corollary 6 . Definition 3 defines a unique set of pat-terns.

Proof. This follows from the above proposition and the fact that a covering has to be minimal  X  i.e. from the second item in the definition.
Based on Corollary 6, we finally define  X -relevance as fol-l ows:
Definition 4. A subgroup is called a  X  -relevant for a dataset DB iff. it is a member of DB  X  X  unique covering of  X  -relevant patterns.
It is interesting to notice that a property like Lemma 3 (dealing with  X -dominance) does not hold for  X -relevance: it is possible that a subgroup becomes  X -irrelevant for one value of  X , but that for another  X   X  &gt;  X , becomes  X   X  -relevant again. This can lead to the situation that a covering for one value of  X  is actually smaller than that for a higher value  X   X  . For example, consider the data set in Table 2. For  X  = 0 . 5, the subgroup AB dominates the subgroups ABC and ABD , but is not dominated by A . Hence, the relevant subgroups for  X  = 0 . 5 are A and AB . For  X  = 0 . 56, A dom-inates AB , but does dominate neither ABC nor ABD , so there exists three relevant subgroups, A , ABC , and ABD . Again, this has to do with the missing transitivity of domi-nance: AB does still dominate ABC and ABD , but as AB is suppressed from the result set, this does not exclude its two specializations. Figure 4 show the graph with the dom-inance dependencies between these subgroups together with the minimal  X  for which the dominance holds.
 T able 2: The size of the  X  -relevant pattern set is not monotonous in  X 
In the experiments, however, we will demonstrate that this problem usually does not occur in practice.
Figure 4: The dominance graph of Example 2.
Our algorithm from Section 3.3 computes the unique cov-ering of  X -relevant patterns for a database. While the cov-ering of  X -relevant patterns can be much smaller than the whole set of (relevant) patterns, depending on the database this set can still be unacceptably large. As already men-tioned in the introduction, one standard approach to deal with this issue is to rank the pattern according to some quality function and keep only the top  X  k patterns. In this section, we will describe how our new concept of  X -relevance can be combined with top  X  k approaches  X  more precisely, how it can be used to devise an improved subgroup discovery algorithm.
The interestingness of a subgroup description sd in the context of a database DB is measured by a quality func-tion q that assigns a real-valued quality q ( sd , DB ) to sd . In this paper, we only consider the following family of quality functions: Here, a is a constant such that 0  X  a  X  1. The family of quality functions characterized by Equation 2 includes some of the most popular quality functions: for a = 1, it is order equivalent to the Piatetsky-Shapiro quality function [10] and the weighted relative accuracy WRACC [16], while for a = 0 . 5 it corresponds to the binomial test quality function [10]. Based on the definition of a quality function, classical top-k subgroup discovery [10] is then concerned with finding the k highest-quality subgroups.
Using our generalization notion of relevance, we extend the task of subgroup discovery as follows:
Task 1. Top-k  X  -Relevant Subgroup Discovery Given a database DB, a quality function q , an integer k &gt; 0 and a real value  X  , 0  X   X  &lt; 1 , find a set of subgroup descriptions G of size k , such that  X -relevant Subgroup Discovery can be performed follow-ing the algorithm from Section 3.3, where for every discov-ered pattern its quality is calculated. In a subsequent step, all but the top-k subgroups are then discarded.

However, it is not necessary to compute the graph G be-forehand, as this can be done dynamically during the execu-tion of the algorithm. The basic trick is that Property 2 of Lemma 4 allows to search through the space of closed pat-terns in a general-to-specific order. If one is only interested in the top-k patterns, then large parts of the specialization graph (used in the construction in Sec. 3.3 ) can be pruned using so-called optimistic estimators [24, 19, 9]. Essentially, all vertexes corresponding to subgroups with optimistic es-timate below a minimum threshold can be ignored. Even if such a threshold is not specified beforehand, the thres-hold can dynamically be determined using the quality of the best k relevant subgroups so far considered. The overall algorithm is quite similar to the one in [8], and the com-putation is thus roughly as expensive as classical relevant pattern mining. The details are omitted for space reasons, c omputational aspects not being the focus of our investiga-tion. We remark, however, that each experiment presented in Section 5 could be computed within less than 5 minutes on a Core-2 Duo PC, with most experiments completing in a few seconds.
In this section, we consider the effect of our new definition of relevance on several benchmark datasets. More precisely, we will analyze the following two questions: 1. To what extent does the new definition reduce the 2. Does the use of our stronger relevance criterion im-
To answer these questions, we applied our algorithm on 8 datasets from the UCI repository [1], listed in Table 3 along with some of their properties.

In this section, we aim to show that  X -relevance signifi-cantly reduces the number of patterns that are found in a database. In [3] it has already been shown that closed sub-groups very much reduce the number of patterns in compar-ison to all possible patterns, while in [7] it has been shown that going from closed pattern to relevant patterns again very much reduces the amount of patterns found. Hence, it suffices to show that going from relevant patterns, i.e.  X -relevant patterns for  X  = 0, to  X -relevant patterns for  X  &gt; 0 reduces the number of patterns.

Figure 5 shows how the number of  X -relevant patterns reduces depending on  X . It can be seen that for all datasets, the number of patterns reduces with increasing  X .
Despite the reduction of the output space, the number of  X -relevant patterns found can still be too large to handle. Therefore, a combination with a top-k approach is advisable. The benefit that comes with the usage of  X -relevant patterns is that the top-k  X -relevant patterns are less redundant and more  X  X nteresting X  than classical top  X  k patterns.
In the following, we will first illustrate the impact of our approach on the redundancy of the top subgroups using the visualization introduced in [22]. Thereafter, we will describe the effect of our approach using a set of performance figures. While optimizing accuracy is not the primary goal of sub-group discovery [16], it is a common approach to evaluate reduction Figure 5: Number of  X  -relevant rules found (per-centage, y-axis) depending on  X  (x-axis). predictive accuracy in the absence of a better option to cap-ture the  X  X nterestingness X  of the patterns.
To illustrate how our approach affects redundancy, we use the visualization proposed by [22]. Here, the coverage of a set of subgroups, i.e. the set of records satisfied by the individual subgroups, is visualized as a rectangular plot of black and white pixels. The plot has one row of pixels for every subgroup. Similarly, there is one column for every record. The pixel at location ( x, y ) is plotted in black if the x -th subgroup includes record y ; else, the pixel is plotted in white. If a set of subgroups is highly redundant, then the plot will reveal noticeable vertical patterns: the reason is that the coverage of the subgroups, and hence the rows visualizing them, will be very similar.

Figure 6 shows an individual plot for the top-k subgroups found using different approaches. On top, we show the plot for the top  X  20 classic subgroups; next, we show the plot for the top-20 closed subgroups; thereafter, we show the plot for the top-20 relevant subgroups; and finally, we show the plot for the top  X  20  X -relevant subgroups ( X  = 0 . 1). It is obvi-ous that the first three plots exhibit vertical patterns, mean-ing that there is a high degree of redundancy. In the last plot  X  visualizing the  X -relevant subgroups  X  no such pat-tern is appearant, meaning that the  X -relevant subgroups are much more diverse.
We use the following experimental setup: we convert a set of patterns in a predictive model in the following way: for any pattern sd we compute the class probability p ( sd ) = | D B [ sd ] | . To any example x that is covered by sd , we assign p ( sd ) as the predicted class probability. In case x is covered by more than one pattern, we assign to it the maximum p of all covering patterns. If x is not covered by any pattern, we assign to it the default probability. This allows to compute the Area under the Curve (AUC) of a set of patterns, which is a measure of how good the set of patterns reproduces the underlying class distribution.
Figure 7 shows the AUC of the Top 10  X -relevant patterns for different values of  X  and the Piatetsky-Shapiro quality function. It can be seen that the AUC tends to increase for  X  &gt; 0 (for 5 datasets, there is a clear improvement; one is apparent, meaning that they are much less redundant. dataset ( X  X ursery X ) is completely unaffected; and finally, for two datasets ( X  X ymph X  and  X  X ote X ), the plot shows that the AUC decreases after reaching a maximum for a value of  X  around 0.05). The results are similar for the binomial qual-ity function in Figure 8: again, the AUC tends to increase when  X -relevant patterns are considered instead of classical relevant patterns.
In this paper, we have presented  X -relevance as an en-hancement of the theory of relevance. It was shown that  X -relevance can be defined in terms of a unique covering of a database.  X -relevance allows to significantly reduce the output of local pattern detection tasks, while being able to guarantee that for every pattern that is excluded from the result, there is a pattern included in the result which is al-most as good in a clearly defined sense.

In addition, algorithmic solutions for finding all and the top-k  X -relevant patterns have been introduced. As  X -relevance is built upon a weaker criterion of domination than classical relevance, there exists fewer  X -relevant pat-terns than strictly relevant ones. We have shown empirically that this can very much reduce the amount of pattern that are found, while there is no negative effect on the useful-ness of the patterns (in terms of the AUC when using the patterns as a predictive model).

Compared to other approaches targeting redundancy avoid-ance (e.g. [11, 5, 18, 23]), our approach considers labeled data and provides particular guarantees about the resulting set of patterns, as precised by Proposition 2. The paper [17] introduces an extension of classical relevance to subgroups similar to ours. However, it only defines what is called delta-dominance in this paper; it does not uniquely define delta-relevance of a single subgroup in the sense of Definition 4. Furthermore, the algorithm is not based on patterns that are closed on the positive. It is this asymmetric treatment of the positive labelled data that allows us to drastically reduce the size of the search space for our algorithm. This publication has been produced in the context of the EU Collaborative Project  X  X ICODE -Mastering Data-Intensive Collaboration and Decision Making X  which is co-funded by the European Commission under the contract FP7-ICT--257184.
 Part of this work was supported by the German Science Foundation (DFG) under  X  X A 1615/1-1 X  and by the Euro-pean Commission under  X  X CT-FP7-LIFT-255951 X . [1] Arthur Asuncion and David J. Newman. UCI machine [2] Stephen D. Bay and Michael J. Pazzani. Detecting [3] Mario Boley and Henrik Grosskreutz. Non-redundant [4] Mario Boley, Tam  X as Horv  X ath, and Stefan Wrobel. [5] Bj  X  orn Bringmann and Albrecht Zimmermann. The [6] Toon Calders, Christophe Rigotti, and Jean-Francois [7] Gemma C. Garriga, Petra Kralj, and Nada Lavra X c. [8] Henrik Grosskreutz and Daniel Paurat. Fast and [9] Henrik Grosskreutz, Stefan R  X  uping, and Stefan [10] Willi Kl  X  osgen. Explora: A multipattern and [11] Arno J. Knobbe and Eric K. Y. Ho. Pattern teams. In [12] Petra Kralj Novak, Nada Lavra X c, and Geoffrey I. [13] Nada Lavrac, Peter A. Flach, Branko Kavsek, and [14] Nada Lavrac and Dragan Gamberger. Relevancy in [15] Nada Lavrac, Dragan Gamberger, and Viktor [16] Nada Lavrac, Branko Kavsek, Peter Flach, and Ljupco [17] Florian Lemmerich and Martin Atzmueller.
 [18] Michael Mampaey, Nikolaj Tatti, and Jilles Vreeken. [19] Shinichi Morishita and Jun Sese. Traversing itemset [20] Siegfried Nijssen, Tias Guns, and Luc De Raedt. [21] Nicolas Pasquier, Yves Bastide, Rafik Taouil, and [22] Matthijs van Leeuwen and Arno J. Knobbe.
 [23] Geoffrey I. Webb. Self-sufficient itemsets: An [24] Stefan Wrobel. An algorithm for multi-relational
