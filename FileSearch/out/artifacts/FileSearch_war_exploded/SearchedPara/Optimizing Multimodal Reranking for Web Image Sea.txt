 In this poster, we introduce a web image search reranking approach with exploring multiple modalities. Different from the conventional methods that build graph with one feature set for reranking, our approach integrates multiple feature sets that describe visual content from different aspects. We simultaneously integrate the learning of relevance scores, the weighting of different feature sets, the distance metric and the scaling for each feature set into a unified scheme. Ex-perimental results on a large data set that contains more than 1,100 queries and 1 million images demonstrate the effectiveness of our approach.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models Algorithms, Experimentation, Performance Image Search; Reranking; Graph-based Learning
Commercial image search engines, such as Google, Ya-hoo and Bing, usually index web images using textual in-formation, such as images X  titles and ALT text and the sur-rounding texts on web pages. However, frequently the text information does not describe the content of images, and it can severely degrade the web image search performance. Reranking is an approach to boosting image search perfor-mance by adjusting search results based on images X  visual information [1][2][4][5][6]. Typically, image search reranking is based on two assumptions: (1) the results after reranking should not change too much from the initial ranking list; and (2) visually similar images should be close in ranking lists. These two assumption usually can be formulated as a graph-based learning scheme, where vertices are images and edges indicate the pairwise similarities [1][2][5].
Although many different reranking algorithms have been proposed, existing results show that reranking is not guaran-teed to improve performance. In fact, in several cases search performance may even degrade after reranking. One reason is that the second assumption does not hold for the em-ployed feature space. Actually the effective features should vary across queries.

In this work, we propose a web image search reranking approach with multiple modalities. Here a modality is re-garded as a description of images, i.e., a feature set. Our proposed scheme integrates multiple modalities in a graph-based learning framework. It simultaneously learns the rel-evance scores, the weighting of different modalities, the dis-tance metric and the scaling for each modality. The effects of different modalities can be adaptively modulated for each query. Although multiple modalities are involved, there are only two parameters in our algorithm.
Generally, graph-based reranking can be formulated as a regularization framework as follows where r = [ r 1 ,r 2 ,...,r N ] T is the ranking scores correspond-ing to a sample set X = [ x 1 , x 2 ,..., x N ] T . Here the term R ( . ) is the regularization term that models the assumption that visually similar images should be close, and the term L ( . ) is a loss term that estimates the difference between r and  X  r . For the first term, it is usually formulated as where W is a similarity matrix in which w ij indicates the visually similarity of x i and x j , and d ii indicates the sum of the i -th row of W .

Now we extend the scheme to obtain our algorithm. First, considering using one modality, we use Mahalanobis distance metric instead of the Euclidean distance metric w ij = exp(  X  ( x i  X  x j ) T M ( x i  X  x j )) = exp(  X  X | A ( x Then we consider there are K modalities. Here we linearly combine the regularizer terms, i.e., R ( r , A 1 ,..., A K , X  ) = k -th modality that satisfies 0  X   X  k  X  1 and P K k =1  X  k As previously mentioned, we integrate the learning of the weights into our regularization framework in order to adap-tively modulate the impacts of different modalities. There-fore, the regularizer term turns to R ( r , A 1 ,..., A K , X  )=
For the loss term, usually it estimates the difference be-tween two ranking lists. Here we directly use the square loss. Therefore, our algorithm can be formulated as the following optimization problem s.t. 0  X   X  k  X  1 ,
We can see that this optimization framework involves the following variables: (1) r , the ranking scores to be estimat-ed; (2)  X  , the weights for combining K modalities; and (3) A k , (1  X  k  X  K ), the transform matrices for K modalities. We adopt alternating optimization to solve the problem.
First, we consider  X  and A k ( k = 1 , 2 ,...,K ) are fixed, then r can be solved with a closed-form solution.

Second, we consider r ,  X  , and A 1 ,..., A k  X  1 , A k +1 are fixed, then we derive the derivative of Q with respect to A k . It can be derived that  X  A k =  X  k X optimized with gradient descent method.

Finally, considering r and A k ( k = 1 , 2 ,...,K ) are fixed, then Eq.6 becomes: We can employ coordinate descent method to solve Eq.7.
We can iterate the optimization of r , A 1 , A 2 ,..., A K  X  . Since each step decreases the objective in Eq.6 and the value of the objective function is lower bounded by 0, the whole process is guaranteed to converge.
We evaluate our approach with several existing methods on the large-scale image search dataset, MSRA-MM Version 2.0[3], that contains the search results (1,011,738 images in total) of 1,165 queries from Microsoft Bing image search Table 1: Average NDCG@100 comparison for each cat-engine. In [3], the queries are manually classified into 10 categories, and each image is labeled with 3 relevance levels (0, 1, and 2). There are 7 feature sets are extracted. We compare the following methods: (1) Bayesian rerankingBayesianReranking[5]. We concate-nate all features into a long vector and then perform the preference strength based method in [5]. (2) Graph-based reranking with concatenated features. That is, we concatenate all the features into a long vector and then perform graph-based reranking. (3) Proposed multimodal reranking algorithm. For the initial relevance score of i -th ranking position, we estimate it by averaging the ground truth scores at the i -th position of all 1,165 queries.

The methods are denoted as  X  X ayesian X ,  X  X oncatenation X  and  X  X ultimodal X , respectively. For all the involved param-eters, we tune them to their optimal values on the 68 queries in of Ver1 with the performance evaluation metric of aver-age NDCG@100, and then these parameters are fixed in the processing of all queries.

Table 1 illustrates the average NDCG@100 measurements of the queries in each category after reranking. We al-so demonstrate the performance of original search results without reranking. From the table we can see that, in av-erage, all the reranking methods can improve the original search results. Our method performs the best for all cat-egories. Its superiority over the  X  X oncatenation X  method demonstrates the effectiveness of our approach of integrat-ing multiple modalities. All the experimental results clearly demonstrate the effectiveness of our approach.
