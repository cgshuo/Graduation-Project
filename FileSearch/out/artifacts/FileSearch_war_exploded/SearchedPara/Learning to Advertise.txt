 Content-targeted advertising, the task of automatically as-sociating ads to a Web page, constitutes a key Web moneti-zation strategy nowadays. Further, it introduces new chal-lenging technical problems and raises interesting questions. For instance, how to design ranking functions able to satisfy conflicting goals such as selecting advertisements (ads) that are relevant to the users and suitable and profitable to the publishers and advertisers? In this paper we propose a new framework for associating ads with web pages based on Ge-netic Programming (GP). Our GP method aims at learning functions that select the most appropriate ads, given the contents of a Web page. These ranking functions are de-signed to optimize overall precision and minimize the num-ber of misplacements. By using a real ad collection and web pages from a newspaper, we obtained a gain over a state-of-the-art baseline method of 61 . 7% in average precision. Further, by evolving individuals to provide good ranking es-timations, GP was able to discover ranking functions that are very effective in placing ads in web pages while avoiding irrelevant ones.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; I.5.3 [ Pattern Recognition ]: Applications X  Text processing Algorithms, Experimentation Web Advertising, Genetic Programming Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00.
The Internet has become one of the most important me-dia for advertising nowadays. It represents the possibility of global exposure to large audiences at very low cost, which attracts great sums in investments in advertising. This sit-uation was different just few years ago, when the failure of many Web companies led to a dropping in supply of cheap venture capital and considerable reduction in on-line ad-vertising investments [29, 30]. According to the Interactive Advertising Bureau (IAB) [18], such reduction caused con-secutive declines in quarterly revenues of companies in the US market, beginning with the first quarter of 2001. How-ever, this loss trend has been reversed by the end of 2002. This recovery has coincided with the increasing adoption of a particular Web advertising format, the search advertising. Nowadays, this is the leading format and, by 2010, it will represent a market of more than US$11 billion [23], accord-ing to Forrester Research projections.

In search advertising, an advertiser company is given prom-inent positioning in ad lists in return for a placement fee. Be-cause of this, such methods are called paid placement strate-gies . The most popular paid placement strategy is a non-intrusive technique called Keyword-targeted advertising [30]. In this technique, keywords extracted from the user X  X  search query are matched against keywords associated with ads provided by advertisers. A ranking of the ads, which also takes into consideration the amount that each advertiser is willing to pay, is computed. The top ranked ads are dis-played in the search result page together with the answers for the user X  X  query.

The success of keyword-targeted advertising has moti-vated information gatekeepers to offer their ad services in different contexts. For example, relevant ads could be shown to users directly in the pages of information portals. The motivation is to take advantage of the users immediate infor-mation interests at browsing time. The problem of match-ing ads to a Web page that is browsed, which we refer to as Content-targeted advertising [21], is different from that of keyword-targeted advertising. In this case, instead of deal-ing with users X  keywords, we have to use the contents of a Web page to decide which ads to display.

A previous work in literature [28] has shown that the use of different pieces of evidence, such as structural informa-tion and the contents of the advertiser X  X  page, can impact on the relevance of the ads selected to be displayed. This work, however, did not answer important questions such as how to combine the available pieces of evidence or how much importance should be given to each evidence. This led us to a question: how can we design a ranking strategy for dis-playing ads according to their relevance by effectively lever-aging all the evidence available? Further, given the negative impact of irrelevant ads on credibility and brand of publish-ers and advertisers, how to design functions that minimize the placement of irrelevant ads, especially when the relevant ones are not available?
To give proper answers for these questions, we propose a new approach to content-targeted advertising based on Genetic Programming (GP). GP is a machine learning tech-nique inspired by biological evolution to find solutions opti-mized for certain problem characteristics. Our assumption is that GP is able to learn the intrinsic characteristics of the content-targeted advertising problem and use them to provide solutions able to improve the ranking effectiveness.
To validate our GP method we performed experiments using a real ad collection and web pages extracted from a Brazilian newspaper. The results obtained indicate that GP is able to learn ranking functions that are very effective in placing ads in web pages. In particular, our best function provided a gain over state-of-the-art strategies of approxi-mately 61 . 7% in average precision. Further, GP was able to learn functions that successfully avoid the placement of irrelevant ads by calculating thresholds based on the page where the ads should be placed.

This paper is organized as follows. In Section 2, we pro-vide background information on content-targeted advertis-ing and GP. In Section 3, we describe how we modeled the content-targeted advertising problem using GP. In Section 4, we describe our experiments and report our results. In Section 5, we describe the related work. In Section 6, we present the conclusions.
In this section we present background information on con-tent-target advertising and review the main concepts in Ge-netic Programming.
Content-targeted advertising consists in showing a list of adsinawebpage,referredtoasthe triggering page. The ads are expected to be relevant to the users and suitable and profitable to the publishers and advertisers. Therefore, factors that contribute to the order in which the ads are displayed in the lists are: (i) the relatedness and adequacy of ads to the content of the page and (ii) the amount the advertiser is willing to pay for clicks in their ads.
In this work we consider that an ad is composed of three structural parts: a title, a textual description and a hyper-link. In fact, these are the usual components of an ad in search advertising systems. The hyperlink points to a page, called landing page , where a transaction can be started. In this page, the user can also find more information related to the ad or to the company, its products and services. Fig-ure 1 illustrates an ad list with two ad slots on the right side of a web page. For the ad in the first ad slot, the ti-tle is  X  X FID Alternative X , the description is  X  X ingle contact 1-Wire memory with 64-bit unique serial number X , and the hyperlink points to the site  X  X ww.maxim-ic.com X .
 Figure 1: Example of content-based advertising in the page of a company that offers health care jobs. The content of the page is about the usage of an identification technology called RFID. On the right side, we can see ads picked for this page by Google X  X  content-targeted advertising system.

Besides the visible parts, a set of keywords K = { k 1 ,k k } is associated with each ad. The keywords comprise one or more words and are used by the advertisers to describe which topics should appear in a web page to display the ads on it. For instance, for the first ad shown in Figure 1, the ad keyword could be  X  X FID X  or  X  X FID alternative X . To asso-ciate a certain keyword k with one of its ads, the advertiser has to bid on k inanauctiontypesystem. Themorethe advertiser bids on k , greater are the chances that its ads will be shown in the ad list of pages in which topic k is present. Notice that the advertisers will only pay for their bids when the users click on their ads. Further, an advertiser can asso-ciate several ads with the same product or service. We refer to such group of ads as a campaign . Notice that only an ad percampaignshouldbeplacedinawebpageinorderto ensure a fair use of the page advertising space and increase the likelihood that the user will find an interesting ad.
In this work we are particularly interested in the relevance aspect of the content-targeted advertising problem. Given a web collection D andasetofads A , our task is to select ads a i  X  X  related to the contents of a Web page p  X  X  and rank them according to how relevant they are. The ad list is then built in such way that more relevant ads are placed in top positions and, as far as possible, only one ad per campaign is selected. In the following, we formally define this restriction.

Let C = { C 1 ,C 2 ,...,C n } be a partition of A that repre-sents the set of campaigns C 1 ,C 2 ,...,C n .Let r ( a i D X  R be a function that indicates how relevant is the ad a to the triggering page p .Let  X  ijp : N  X C X D X  R be a function that represents the relevance score of the i -th top-ranked ad of campaign C j according to the function r .For instance, if a s is the second top-ranked ad of campaign C  X  p =0 . 5 indicates that r ( a s ,p )=0 . 5. We are interested in finding the function rank ( a i ,p ): A X D X  R that can be used to build rank lists that satisfy the constraint:
As previously mentioned, ad placement systems should minimize the possibility of exhibiting irrelevant ads. Mis-placements are particularly common in two situations. First, in spite of the ad and the page being related to the same subject, their mapping is not appropriate. For example, this is the case of placing ads in pages about catastrophes or un-ethical and illegal advertising. Second, the triggering page is about a topic for which it is hard to find relevant ads. In order to minimize misplacements in such situations, spe-cially the second, a good ranking function should provide reliable relevance estimations such that it would be possible to distinguish the acceptable relevance levels from the not acceptable.

Notice that, in this work, we intend to learn the ranking functions rank ( a i ,p ), through GP. These ranking functions are designed to optimize overall precision and minimize the number of misplacements.
Genetic programming (GP) [19] is a set of artificial intelli-gence search algorithms that follows the principles of biolog-ical inheritance and evolution. GP is typically used to ap-proximate complex, non-linear functional relationships [19]. Because of the intrinsic parallel search mechanism and pow-erful global exploration capability in a high-dimensional space, GP has been used to solve a wide range of hard optimization problems that oftentimes have no best known solutions. The overall GP framework for a setting comprising a training and a validation collection is described in Listing 1.

In GP, the solution to a problem is represented as an in-dividual (i.e., a chromosome) in a population pool. These individuals are represented by means of complex data struc-tures such as trees, linked lists, or stacks [20]. The length or size of these data structures is not fixed, although it may be constrained by implementation to be within a certain size limit. Initially, the population starts with individuals cre-ated randomly as we can see in Listing 1 (line 6). Then they evolve generation by generation through genetic operations (lines 7-13). A fitness function is used to assign the fitness value for each individual (line 9). The fitness value indicates how well they perform in the training examples and it can be used as a means of selecting the best ones (line 10). To evolve the best individuals, genetic operators are applied to them with the aim of creating more diverse and better per-forming individuals (line 12). Examples of such operators are reproduction, mutation, and crossover. The reproduc-tion operator is used to breed new individuals identical to their parents, the crossover operator takes two individuals (parents) to breed a new one that shares some attributes with each parent, and the mutation operator simulates the deviations that occur in the reproduction process.
The last step in the GP framework presented in Listing 1 consists in determining the best individual to be applied to the test set. The natural choice is the individual with best performance in the training set. However, it might not gen-eralize well due to overfitting 1 during the learning. In order to alleviate this problem the best individuals evolved over N g generations are applied to a second document collection, which we call a validation collection (line 15). Then it is possible to select the individual that presents good perfor-mance in both sets, the training and validation (line 17). It is likely to generalize well since it proved to be a good choice in two different document sets.

Therefore, an initial strategy to select the best individual should be to get the one that presents the best average per-formance in the training and validation sets. However, since the average does not ensure that the selected individual has a balanced performance in the both sets, it would be inter-esting to consider the standard deviation to correct such a bias.

More formally, we apply the following method to deter-mine our best individual. Let  X  f i be the average performance of individual i in the training and validation collections, and  X  ( f i ) be the corresponding standard deviation. The best in-dividual is given by:
In order to apply GP to the problem of content-targeted advertising we need to define three key components of the GP framework described in Listing 1: the individuals, the genetic operators and the fitness function.
Since we are interested in finding a good ranking function to match ads and pages, as described in Section 2.1, we decided to represent our individual using a tree structure. As observed by [9], a tree based representation allows for easy parsing, implementation, and interpretation. Figure 2 illustrates an individual.

As we can see in Figure 2, the non-leaf nodes in the tree structure ( X * X ,  X  X og X , and  X / X ) represent functions applied to the terminals in the leaf nodes. The functions addition
Situation in which the learner may adjust to very specific random features of the training data such that the perfor-mance on the training examples still increases while the per-formance on unseen data becomes worse. Figure 2: A sample tree representation for a func-tion. Hereweshowthecommon TF-IDF weighting scheme. (+), multiplication (  X  ), division ( / ) and logarithm ( log )are used in our individual representation. They were selected because they provide meaningful operations on relations. For example, matching functions used in Information Re-trieval (IR) commonly employ addition and multiplication to reinforce relations in different degrees, division to accom-modate inverse relationships, and logarithm to smooth val-ues.

These functions are applied to terminals that are the leaf nodes in the tree structure ( X  X f X ,  X  X  X , and  X  X f X ), as shown in Figure 2. Since in this work we intend, through GP, to discover a single ranking function to find a set of relevant ads with regard to a Web page by combining all or several of the available evidence, the terminals to be used in our repre-sentation comprise the information related to this evidence. In other words, the terminals represent statistics about the structural parts of the ads and the information provided by the advertisers such as the keywords associated with the ads and the content of the landing page. Additionally, we use real numbers as terminals to allow fixed weighted factors.
Table 1 describes all the terminals to be used. Notice in this table that P stands for different structural parts of the ads and the information provided by advertisers (key-word, title, description, and landing page), and G indicates whether the ads are grouped. For instance, the feature tf ad , title stands for the number of times a term appears in the title of an ad whereas the feature tf camp , title represents the number of times a term appears in the titles of all the ads of a campaign.
The genetic operators used in our model are those com-monly used in GP, that is, mutation, crossover, and repro-duction. Notice that, given the representation of our indi-viduals by means of trees, the crossover operator consists in taking two trees and exchanging randomly selected subn-odes of these trees forming two new children. Accordingly, the mutation operator was implemented in such a way that a randomly selected subtree is replaced by a new subtree also created randomly.
We now define the fitness function that is the objective function GP aims to optimize. The algorithm described in Listing 2 details our fitness evaluation function.
We start by noticing that the ranked lists produced by our random individuals do not satisfy the campaign constraint given by Eq. 1. Thus, in order that function fitness (which corresponds to function rank in Section 2.1) can satisfy that constraint, we apply the individual i (which corresponds to function r inSection2.1)toeachcampaignincollection T according to a round robin strategy, as follows. For each campaign, a ranking is built according to the similarity func-tion i (lines 3-4). The top ranked ad of each ranking is then selected till that all the campaigns have been considered (lines 6-9). These ads are sorted according to the relevance scores provided by i and inserted into the final ranked list (lines 10-11). The process is repeated until that no ads re-main to be selected (line 5). By doing this, we guarantee that the j -th top-ranked ad of a campaign will always be placed into a page above the ( j + 1)-th top-ranked ad of any other campaign, satisfying the campaign constraint. The fitness value corresponding to individual i is then obtained through the evaluation of the final ranked list (line 12). Note that depending on the evaluation function to be used we can propose different fitness functions. The evaluation functions and corresponding fiteness functions to be used in this work are discussed in the following paragraphs.

A good ranked list should maximize the placement of rel-evant ads near to top positions since these are the positions more likely to be clicked by the users [11]. Thus, the eval-uation function should take into consideration the number of relevant ads and the order in which they appear, that is, it should be a combination of precision and recall [2], two well-known retrieval measures in IR. An example of such evaluation function is given by: where  X  = 1 k is a normalizing constant used to ensure that pavg @ k fits between 0 and 1, k is the number of ads to bedisplayedinapage, a i is the i -th top ranked ad, and r ( d )  X  X  0 , 1 } is the relevance score assigned to an ad, being 1 if the document is relevant and 0 otherwise. The relevance information is obtained from users.

This metric is based on the non-interpolated average pre-cision (PAVG), a measure commonly used in TREC eval-uations [15]. The difference between metrics PAVG and pavg @ k is the value of the constant  X  ,whichinPAVGis given by the inverse of the total of relevant documents in the collection. By using  X  = 1 k , we ensure that a ranking function that places relevant ads in all the top positions will receive the maximum pavg @ k value equal to 1. In this way, we are able to correctly evaluate functions that suggest a number of ads less than the total of ad slots available. In this work, we refer to the fitness function that uses pavg @ k to evaluate its individuals as f pavg @ k .
Other goal that we want to accomplish with our fitness functions is to reward ranking functions that minimize the placement of irrelevant ads. As mentioned before, these ads should be avoided since they contribute to a negative percep-tion by the users on the credibility and brand of publishers and advertisers. A possible solution to this problem is to consider the ranking values provided by the GP individuals as estimations of how relevant the ads are to the triggering page. By doing so, we can set threshold values to distinguish acceptable relevance levels from non-acceptable ones.
Thus, our problem is now finding a matching function that provides reliable estimations in a spectrum in which a threshold value can be set to separate relevant ads from non relevant ones. Our assumption is that GP is able to find such functions. Thus, given a certain threshold level t ,we modify our evaluation function such that it rewards individ-uals that tends to place relevant ads above t and nonrelevant ads below t . Accordingly, it punishes individuals that tends to place irrelevant ads above t and relevant ads below t .Our second evaluation metric is given by: where k 1 , k 3 , k 2 ,and k 4 are the weights associated with the number of relevant ads above ( r at )andbelow( r bt )the threshold and non relevant ads below ( n bt )andabove( n at the threshold, respectively.

Notice that in our experiments we give more weight to n at since we want specially to avoid the placement of irrelevant ads in the top positions. In particular, we use k 1 = k 3 k =1and k 4 =2.

An important remaining issue is how to define the thresh-old value t . In this work we define t = v min + k t ( v max where v min and v max are the minimum and maximum val-ues given by the ranking function. The constant k t is the relative position in the spectrum the GP individual should consider a point of low confidence. In our experiments we use k t =0 . 3. In other words, our new fitness functions will reward ranking functions in which the minimum score as-signed to a relevant ad corresponds to 30% of ( v max  X  v
Notice that, in fact, it is not possible to know the val-ues of v min and v max because we deal with randomly gen-erated functions. As a consequence we define these limits by inspecting the rank values provided by our random in-dividuals. In this study we adopt two different strategies to estimate the limit values. In the first, we use the maxi-mum value given to a certain page as v max and the minimum value as v min . Thus, we have different thresholds for differ-ent pages. We refer to the fitness function that uses pavg @ k to evaluate its individuals and calculate thresholds for each page as f local . A possible disadvantage of f local is that it tends to suggests, at least, one ad per page. In the second strategy we use the maximum value given to an individual as v max and the minimum value as v min . In this case we have only one threshold value for a function. In this work we refer to the fitness function that uses pavg @ k t to evaluate its individuals and calculate thresholds for each individual as f global . Contrary to f local , f global is more likely to suggest no ads to a certain page.
In this section we describe the experiments and present the results.
To evaluate our ad placement framework, we used a test collection built from a set of 100 pages extracted from a Brazilian newspaper. These are our triggering pages. They were crawled in such a way that only the contents of their articles were preserved. As we have no preference for par-ticular topics, these pages cover subjects as diverse as cul-ture, local news, international news, economy, sports, poli-tics, agriculture, cars, children, real estate, computers and internet, TV, travels, and economy.

To obtain a set of relevant ads for our test collections, weadoptedthesamepoolingmethodusedtoevaluatethe TREC Web-based collection [16]. In other words, for each of our 100 triggering pages, we selected the top three ranked ads provided by each of the ten ad placement methods pro-posed in [28]. These ads were obtained from a real case ad collection composed of 93,972 ads grouped in 2,029 cam-paigns provided by 1,744 advertisers. With these ads, ad-vertisers associated a total of 68,238 keywords 2 . In this col-lection, only one keyword is associated with each ad. This makes campaigns very important since they are used by the advertisers to associate several keywords with a product or service. As a result of the pooling method, a total of 1,860 distinct ads were selected. They were then inserted into pools corresponding to each triggering pages. Each pool contained an average of 15.81 ads. All the ads were submit-ted to a manual evaluation by a group of 15 subjects. Each
Data in the portuguese language provided by an on-line ad company that operates in Brazil. subject was asked to evaluate the ads selected to each page according to its relevance to the pages. The average number of relevant ads per page pool was 5.15.

Since our experiment can be qualified as a supervised learning task, we follow the three data-sets design [7, 24]. In other words, the 2,337 evaluated pairs of ads and doc-uments resulting of the pooling process were used to built training, test, and validation sets. For this, we randomly split the data into three parts. We used 50 pages (and its corresponding ads) for training, 30 pages for validation, and 20 pages for test. As previously mentioned, the introduc-tion of the validation dataset is to help alleviate the prob-lem of overfitting of GP on the training data and select the best generalizable individual. All the results reported in this work are based on the test data set.
We learned on the training sample using different param-eters. We noticed that a small population size and different rates for the genetic operations produce better results. The size of the populations used in our experiment was fixed at 750 individuals. The maximum depth of the tree used to represent an individual was set as 17. In all experiments re-lated here, the populations were created using four different random seeds and were allowed to evolve for 30 generations. This number was determined empirically. The random seeds used were 245, 37383, 322443, and 6758. As in [19], we used crossover, mutation, and reproduction rates of 85%, 10%, and 5%, respectively. We tested our GP framework using the three fitness functions described in Section 3.3. Ex-periments for each function were run four times using the different random seeds. The best result among the four runs is reported and used for comparison.
We present the results of our experiments considering that a triggering page offers three ad slots. We report figures using pavg @3 (Eq. 3, with k = 3), for the case in which the methods assign exactly three ads per page. For the cases in which they are allowed to assign less than three ads, we use pavg @ k (Eq. 3) and pavg @ k t (Eq. 4). In all the cases, as in [28], we also report the number of hits and ads suggested per ad slot. We call hit the placement of a relevant ad.
We compare the results of our GP ranking functions with those obtained by the AAK H method described in [28]. This method consists in using a cosine similarity function to match the triggering page to the ad. Besides its title and descrip-tion, the content of the ad, as used by AAK H , includes the content of the keyword and the landing page associated with it. Further, this method requires that all the terms in the ad keyword be present in the triggering page to the ad to be considered a good matching. Amongst the methods pre-sented in [28], which take into account only the ad title, description, keywords, and landing page, AAK H is the best. Given these pieces of evidence, note that, as far as we know, this is the best method found in the literature. This makes AAK H an ideal baseline since our GP individuals make use ofthesamebodyofevidence.
In this section we present the results of experiments with exactly three ads per page and with possibly less than three ads per page.
 Table 2: Performance comparison between the best individual evolved from the optimization of f pavg @ k (
GP1 ) and baseline method ( AAK H ). Columns labelled #1, #2, and #3 indicate the total of hits and sug-gestions for the first, second, and third ad slots, re-spectively.
As we can see in Table 2, our best GP individual ( GP1 ), reached a performance of 50.8% in pavg @3. This corre-sponds to a gain of 61.7% when compared with our baseline. An interesting characteristic of GP1 is its successful perfor-mance in the first ad slot which is the one more likely to be clicked by the users [11].

Figure 3 displays the evolution along 30 generations of the population from which GP1 was selected. For each genera-tion we can see the ten best individuals sorted according to the performance of their fitness function ( f pavg @ k ). The fig-ure shows a remarkable difference in the performance of the individuals when we compare training and test sets. This is due to overfitting. The individuals applied to the training set tend to learn very specific characteristics not found in the test set. As a consequence, the best individuals of the training set are not so good in the test set. However, by selecting the best individual using Eq. 2, we were able to get a ranking function that generalizes well. Figure 3: Evolution Process for 300 individuals in 30 generations. Notice that each ten individuals corre-spond to one generation.
Table 3 compares the performance of the best individuals obtained by GP that have evolved to avoid placing irrelevant ads according to threshold values. In this table, GP2 is the individual evolved from the optimization of f local . The line corresponding to this individual shows performance figures for the case in which the threshold value is not taken into consideration. That is, all the top ads selected by GP2 are evaluated independently of their ranking scores. The line started with GP2+thr corresponds to the same individual for the opposite case, that is, the threshold value is taken into consideration. Similarly, GP3 evolved from the optimiza-tion of f global and its corresponding performance figures are shown for the cases where the threshold was used ( GP3+thr and was not used ( GP3 ).

Notice in Table 3 that GP2 and GP3 present better per-formance than the baseline with gains of 37 . 2% and 9 . 6%, respectively, for the pavg @ k metric. These results, however, are worse than those obtained with our best individual, GP1 This is due in part to the fact that more precise individuals tend to misplace ads less frequently and, consequently, they have less opportunities to be rewarded by correctly placing irrelevant ads below a certain threshold.

When we analyze the performance of the individuals af-ter applying the thresholds, we notice an improvement for GP2+thr and no difference for GP3+thr . For instance, method GP2+thr was able to avoid placing twelve irrelevant ads in the third slot with the loss of only five ads. When consid-ering the metric pavg @ k t , the gain of GP2+thr over GP2 approximately of 16%. This allows us to conclude that GP was able to learn functions that avoid the placement of ir-relevant ads and present good overall performance for the case in which different thresholds are obtained for each page. Conversely, for the case in which a unique global threshold has to be used, GP was not able to learn good ranking func-tions.
The success of search advertising has motivated research in many topics related to targeted advertising. Examples of these studies include the comparison of ranking strate-gies [11], the characterization of fake traffic in order to detect frauds [5], the proposal of tools for keyword suggestion [3], and the design and implementation of a large-scale targeted advertising system [1].

In particular, the relevance aspect of the ranking strate-gies has attracted attention. This is not surprising since many works in advertising research have emphasized the im-portance of relevant associations for consumers [26] and how irrelevant ads can turn off users and relevant ads are more likely to be clicked on [11]. As a result, some works have tried to determine how to take advantage of the available evidence to improve the relevance of the selected ads. For instance, studies on keyword matching showed that the na-ture and size of the keywords have impact on the likelihood of an ad to be clicked [25]. Relevance is also the focus of the authors in [28] which proposed several strategies for ranking ads in content-targeted advertising. These strategies took into consideration the contents of structural parts of the ad and additional information obtained from web pages other than the triggering page. Examples of these pages are the landing pages or web pages obtained by means of a proba-bilistic model. They showed that considering the contents of the ad structural parts and external pages can improve the relevance of the selected ads. In contrast to that work, we propose to learn the best ranking strategies in order to ef-fectively leverage all the evidence available while minimizing the placement of irrelevant ads. For this, we use GP.
GP has been applied to several IR topics in recent years, such as query induction, representation, and optimization [4, 17, 22], document clustering and classification [14, 31], and document ranking [13,27]. From these, many works [6 X 8,10] have applied GP to discover ranking functions. For example, success has been reported in applying GP to find ranking functions optimized to specific queries in the information routing task [7]. Similarly, GP has also been successfully used in the ad-hoc retrieval task [10]. In fact, this work is inspired on this prior research in ranking function dis-covery. But it differs significantly in several important as-pects. Since we intend to find ranking functions for content-targeted advertising, we deal with specific characteristics of this problem not found in classical IR tasks previously studied. For instance, content-targeted advertising presents different kinds of evidence, the possibility of taking advan-tage of campaign clustering statistics, and specific ranking related issues such as campaign placement restrictions and impact of irrelevant ads.
In this paper we proposed and tested a new framework for associating ads with web pages based on GP. In partic-ular, given the importance of relevance for content-target advertising systems, our GP method aimed to learn func-tions able to select the more relevant ads given the available evidence. By using a real ad collection and web pages from a Brazilian newspaper, we obtained a gain over our base-line method of 61 . 7%. Further, by evolving individuals to provide good ranking estimations, GP was able to discover ranking functions that are very effective in placing ads in web pages while avoiding the irrelevant ones.

In the future we intend to provide more extensive and comprehensive analysis of our models and expand them in order to contemplate additional evidence and consider other important aspects of the content-targeted advertising prob-lem. Regarding model analysis, we intend to study how different threshold tuning strategies impact on the learn-ing and effectiveness of our GP framework. We also plan to perform more extensive comparison of our method with other machine learning techniques, such as the SVM-based approach [8]. Future plans also include a detailed study of why GP ranking functions outperform other techniques in this task. Regarding new models, we intend to evolve func-tions that take into consideration the category information associated with ads and pages. More important, we plan to expand our models to yield ranking functions that combine the relevance and monetary aspects of the problem by con-sidering the amount the advertiser is willing to pay for the placement of their ads.
This work was supported in part by the GERINDO Project grant MCT/CNPq/CT-INFO 552.087/02-5, by the CNPq grant 30.5237/02-0 (Nivio Ziviani), by the 5S-QV project grant MCT/CNPq/CT-INFO 551013/2005-2, by the CNPq grant 300188/95-1 (Berthier Ribeiro-Neto), by grant 10023-UFMG/RTR/PRPQ/RECEM-DOUTORES/04 (sub-grant 32-PROGRAMACAO GENETICA). Marco Cristo is sup-ported by Fucapi, Manaus, AM, Brazil. left columns.
