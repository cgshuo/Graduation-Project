 Comparisons between file signatures and inverted files for text retrieval have shown the shortcomings of traditional file signatures. It has been widely accepted that traditional file signatures are inferior alternatives to inverted files. This paper describes TopSig, a new approach to the construction of file signatures that extends recent advances in semantic hashing and dimensionality reduction. These were not so far linked to general purpose, signature file based, search engines. We demonstrate significant improvements in the performance of signature file based indexing and retrieval. Performance is comparable to the state of the art inverted file based systems, including language models and BM25. These findings suggest that file signatures offer a viable al-ternative to inverted files in suitable settings and positions the file signatures model in the class of Vector Space retrieval models.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval Models, Relevance Feedback, Search Process, Clustering Algorithms, Experimentation, Performance, Theory Signature Files, Random Indexing, Topology, Quantisation, Vector Space IR, Search Engines, Document Clustering, Doc-ument Signatures
Document signatures have been largely absent from main-stream IR publications about general purpose search engines and ranking models for several years. The decline in the at-tention paid to this approach started with the publication of the paper  X  X nverted Files Versus Signature Files for Text Indexing X  by Zobel et al [19]. This paper offers an exten-sive comparison between signature files and inverted files for text indexing. The authors concluded that inverted files are distinctly superior to signature files. Signature files are found to be slower, offer less functionality and require larger indexes. They conclude that the bit sliced signature files under-perform on almost all counts and offer very little if any advantages over inverted files. A similar picture emerges during the discussion of signature files by Witten et al [15]. The presumed advantages of efficient bit-wise processing and the potential for index compression are not generally achiev-able in practice. For a detailed explanation of signature files consult the work of Faloutsos and Christodoulakis [4].
Recent approaches to similarity search [17] have explored similar ideas to TopSig for mapping documents to N bit strings for comparison using Hamming distance. The ap-proach taken by Zhang et al [17] and prior publications focus on similarity comparisons between documents. Their models have not been applied to general purpose ad-hoc retrieval. More importantly, Zhang et al [17] use a complicated ap-proach to the static, off-line derivation of signatures, which involves supervised and unsupervised learning to generate document signatures. This in effect prevents the application of the approach to ad-hoc retrieval where a query signature has to be derived at run-time. It is not practical in a very large collection due to the excessive computational load of supervised and unsupervised learning.

Unlike earlier attempts, we approach the design of TopSig document signatures from basic principles. TopSig is rad-ically different in the construction of file signatures and in the manner in which the search is performed. We present results of extensive experiments, performed with large stan-dard IR collections, where we compare TopSig with stan-dard retrieval models such as BM25 and various language models. We also describe document clustering experiments that demonstrate the effectiveness of the approach relative to standard document representation for clustering.
The remainder of this paper is organised as follows. Sec-tion 2 introduces the TopSig approach in detail. Sections 3, 4 and 5 define and evaluate the use of this approach for ad-hoc retrieval and clustering. The paper is concluded with a discussion in Section 6.
TopSig represents a radically different approach to the construction of signature files. Unlike the traditional ad-hoc approach [4], TopSig is principled and signature files emerge naturally from a highly effective compression of the well un-derstood and commonly used Vector Space representation of documents.
We approach the design of document signatures from the perspective of dimensionality reduction. TopSig starts from a straight forward application of a vector space representa-tion of the collection -the term-document weight matrix. We then derive the signatures through extreme and lossy compression, in two steps, to produce topology preserving binary document signatures. While the actual mechanism that is proposed is highly efficient in signature construction and in searching, we first focus the discussion on the con-ceptual approach, its justification and theoretical grounding, while leaving the implementation and performance analysis details for later in the paper.
 In this section we describe the concepts that underpin TopSig. These concepts are not new -Random Indexing and Numeric Quantisation -but when put together to form file signatures, the results are remarkable.
Latent Semantic Analysis [3] is a popular technique that is used with word space models. LSA creates context vectors from a document term occurrence matrix by performing Sin-gular Value Decomposition (SVD). SVD is computationally expensive and this limits its application in large collections.
Random Indexing (RI) [11] is an efficient, scalable and incremental approach to dimensionality reduction. At the foundation of RI is the Johnson-Lindenstrauss lemma [5]. It states that if points in a high-dimensional space are pro-jected into a randomly chosen subspace, of sufficiently high-dimensionality, then the distances between the points are approximately preserved.
 Word space models often use RI as an alternative to LSA. Both LSA and RI start from the term-document frequency matrix. RI has linear complexity in the number of terms in a document and also in the collection size. This is a significant advantage over LSA whose time complexity is prohibitive in large collections. As stated by Manning et al [9] in 2008, in relation to LSA - X  X he computational cost of the SVD is significant; at the time of this writing, we know of no suc-cessful experiment with over one million documents X . RI can be performed incrementally and online as data arrives. Any document can be indexed independently from all other doc-uments in the collection. This eliminates the need to build and store the entire document-by-term matrix. Addition-ally, newly encountered terms are naturally accommodated without having to recalculate any of the projections of pre-viously encoded documents.
Document signatures are fixed length bit patterns. In or-der to transform the real-valued projected term-document matrix into a signatures matrix, we proceeded to reduce numerical precision. TopSig takes the reduction in numeri-cal precision to its ultimate conclusion by and reducing the precision all the way to a single bit. Binary signatures are obtained by taking only the sign-bits of the projected doc-ument vectors (!!). This is a key step in TopSig signature calculation; it may appear to be highly excessive precision reduction, but it is in fact surprisingly effective, as we shall demonstrate with search and clustering experiments in the following sections. Both clustering and ranking applica-tions are concerned not with the actual similarity values, but rather with their rank order. As long as rank order is preserved the distortion due to reduced numerical precision is not problematic.

To complete the generation of a document signature we need to pack the  X  1 representation of signatures, onto bi-nary strings. This is done by representing positive signs as 1s, and negative signs as 0s. The final result is thus a bi-nary digital signature, but it still conceptually represents signatures.

To measure the impact of aggressive dimensionality reduc-tion we measure the root mean squared differences (RMSE) between the normalised mutual distance matrices of 1000 document vectors and their compressed counterparts. Fig-ure 1 depicts the results of our experiment. On the y-axis is the topological distortion, measured by RMSE. On the x-axis is the number of dimensions in the projection. Each of the curves on the plot corresponds to a different numerical precision. The bottom curve corresponds to double preci-sion, and then the plots above correspond to 8-bit quantisa-tion, through 7-bit quantisation, and so on all the way down to 1-bit quantisation.

As the dimensional-ity of the projected subspace is increased the distortion becomes smaller and is true re-gardless of numerical precision. Most of the gain is achieved quite early with rela-tively small dimension-ality and is the expected behaviour of both RI and LSA. Unexpect-edly, as we reduce the numerical precision the deterioration is very small. The low-est curve in Figure 1 corresponds to double precision. It is only when precision is dropped to 3-bits and below that the difference in RMSE becomes noticeable. Even with 1-bit precision we are still able to significantly preserve topology quite early with very small dimensionality.
We provide a concrete description of TopSig components used for ad-hoc retrieval and describe the evaluation of doc-ument retrieval using the INEX Wikipedia collection and the TREC Wall Street Journal (WSJ) collection.
We have not addressed the weighting of terms. The most effective weighting function we have found is described by P ( t | D )= tdf | D | , P ( t | C )= tcf | C | and W ( t,D )= log W ( t,D )istheweightforterm t in document D , tdf is the term frequency for term t in document D , | D | is the total number of term occurrences in document D , tcf is the col-lection frequency for term t ,and | C | is the total number of term occurrences in the collection. P ( t | D )isanestimateof the probability o f finding the term t given a document D , and P ( t | C ) is an estimate of the probability of finding term t given the collection C .

The weighting function W ( t,D ) produces a larger value if the frequency of a term in a document is higher than ex-pected, and smaller if the frequency is lower than expected. The logarithm of the ratio of these expected values is taken, so as to dampen the effect of an inordinately large frequency of a term in a document. Negative weight values are set to zero.
In order to search the collection with a given query, we need to generate a query signature. Query document vectors are generated using standard TF-IDF weighting. This real valued query vector is then converted to a signature using exactly the same process as used with document signatures. It is necessary to use exactly the same process and param-eters in generating the query signature as when generating document signatures.

Document signatures are represented in binary form, where 1-bits correspond to +1, and 0-bits correspond to -1. Query signatures, before taking the sign bits, may contain a mix of 3 classes of values: positive, negative, or zero. This de-pends on the signs of term signatures, and a value of zero is obtained when none of the query terms occupy some bit positions. As a matter of fact, with short queries and sparse term signatures this is almost invariably the case. These zero valued bit positions are those for which the query does not specify any preference. To account for this, a query mask is also generated to accompany the query signature. This mask has 1-bits in all positions other than those that are not covered by any term in the query. The 1-bits in the mask identify the subspace in signature space which the query terms cover. When comparing the query signature against document signatures, the similarity measure must not take account of differences in those bit positions. Con-ceptually, those are neither +1 nor  X  1.
Ranking with TopSig is performed with the Hamming dis-tance, calculating the similarity score for each document. The Hamming distance is rank equivalent to the Euclidean distance since all signatures have the same vector length -we note that the signatures correspond to +1 and  X  1values, not 1 and 0 values, and hence the length of each signature of N bits is ent for each query, the Hamming distance for each query will generally be calculated in a different subspace. The distance metric is therefore a masked Hamming distance.

If the document and query are identical in the query sub-space then the Hamming distance will be zero. The Ham-ming distance between two signatures of N bits is restricted to the range [0 , 1 , 2 ,..N ]. For a signature file with 1024 bits per document there are at most 1025 possible distances between the query and a document, and many less if the query is short. This means that in a collection such as the Wikipedia, with millions of documents, if we rank all the documents by the Hamming distance from the query, we are bound to get numerous ties.

Although document signatures are not completely ran-dom -they are biased by the document contents, and sim-ilar documents have similar signatures -we still expect the vast majority of the documents to be centred at about a Hamming distance of N/ 2 from the query signature. Indeed this is always observed. The distribution of distances al-ways resembles a binomial distribution, which we expect if the distribution of signatures was indeed random. It is not quite that, but we still observe strong resemblance to truly random distribution.

We are interested in early precision and so TopSig can still achieve granularity in ranking of documents. This is so because a large number of documents falls much closer than N/ 2 to the query signature, and the number of ties di-minishes rapidly as the distance becomes smaller. Some ties still remain nevertheless and these may be broken arbitrar-ily or by using simple heuristics or document features. For instance, page-rank can be used, or any one of hundreds of document features that are reportedly used in commercial search engines.
Psuedo relevance feedback is known to improve the perfor-mance of a retrieval system. TopSig can implement pseudo relevance in the usual manner, through query expansion. This however is a generic approach and can be be used with any search engine. There is however an additional oppor-tunity to apply pseudo relevance feedback, an opportunity that is unique and specific to TopSig.

An initial TopSig search is performed in the subspace of the query signature by using the masked Hamming distance to rank all the documents in the collection. TopSig can ex-pand the query signature by completing information from the top-k ranked documents and populating bits not in the original query subspace. The mean of the top-k ranked doc-uments populates query bits not in the original query. This signature is now spans the full signature space and takes into account information from highly ranked results, including in bit positions that were not informed directly by the query terms. The new query is constructed by inserting only the missing bits into the original signature.

The ranking of documents in relation to the new query is then repeated by re-ranking a very small fraction of the nearest signatures -usually those that were retained in a shortened result list following the initial search. The feed-back leads to statistically significant improvement in perfor-mance.
We have evaluated TopSig using the INEX Wikipedia 2009 collection, and the TREC Wall Street Journal (WSJ) Col-lection. INEX Wikipedia collection contains 2,666,192 doc-uments with a vocabulary of 2,132,352 terms. The mean document length in the Wikipedia has 360 terms, the short-est has 1 term and the longest has 38,740 terms. We used all 68 queries from INEX 2009 for which there are relevance judgements. The Wall Street Journal Collection consists of 173,252 documents and a vocabulary of 113,288 terms. The mean WSJ document length is 475 terms, the shortest has 3 terms, and the longest has 12,811 terms. We used TREC WSJ queries 51-100.

To compare TopSig with state-of-the-art approaches, we have used the ATIRE search engine (formerly k [12]. ATIRE is a highly efficient state-of-the-art system which implements several ranking functions, over an inverted file system. The ATIRE search engine has been thoroughly tested at INEX against other search engines, including several well known systems such as Zettair, Lucene, and Indri, and has been shown to produce accurate and reliable results.

The references given herein to the ranking functions that were compared with TopSig, are to the actual papers that were followed in implementin g the methods, as documented in the ATIRE search engine manual. These are Jelineck-Mercer (LMJM) [16], DLH13 [8], Divergence from Random-ness [1], and Bose-Einstein [1]. The ranking functions were evaluated with relevance judgements from TREC and INEX, and the trec eval program.
Figure 2 depicts the precision-recall curves for INEX 2009 topics, against a tuned BM25 system, using k =1 . 1and b = 3, and with Rocchio pseudo relevance feedback. This BM25 baseline curve is optimistic -it is tuned with the ac-tual queries, and performs better than any official run at INEX 2009. This provides a very conservative yardstick by which to measure the performance. The figure shows sev-eral TopSig indexes, encoding the signature with 64, 128, 256, 512, 768, 1024, 2048, 3072, and 4096 bits per signa-ture. We have tested signatures of no more than 4096 bits because that signature file size is just below the size of the most efficient Inverted File index that we have been able to produce with ATIRE. ATIRE produces a significantly smaller index than Lucene, Indri and Zettair without sacri-ficing performance. Only one in 12 vector elements were set in the random term signatures, to either +1 or to  X  1, with the rest of the elements set to 0. As the number of bits in the signature increases, so does the recall. The performance of the file signatures is quite respectable once we allow for about 512 bits per signature -particularly at early preci-sion. All the other language model based ranking functions produce a recall-precision curve that falls below BM25, and just above the best TopSig curve, but are not shown on the plot so as to reduce the clutter.
While Figure 2 may at first suggest that file signatures produce inferior performance, we must focus our attention on the early precision, and this requires some justification before we do that.

Moffat and Zobel [10] found that P@N correlates with user satisfaction. A user who is given 7 relevant documents in the top 10 is better off than one who is only given 2. They argue that recall does not have a similar use case that reflects user satisfaction. Even for a recall oriented task, a user is unlikely to look past the top 30 results. For most tasks, the first page or top 10 results are most useful to the user. Users achieve recall not through searching the entire ranked list but by reformulating queries. Recent work by Zobel and Moffat [18] suggests recall is not important except for a few recall oriented tasks such as retrieval in medical and legal domains. If a system provides 100% recall, it implies that the user can create a perfect query. Even in recall based tasks, users tend to re-probe the collection with multiple queries to minimise the risk they have missed important documents.

The same argument is applied to discount the importance that is attributed the commonly used measure of Mean Av-erage Precision (MAP) as it too depends on higher recall and a long tail of relevant results. Again, it is not clear what user satisfaction is correlated with MAP. Turpin and Scholer [13] performed retrieval experiments where users completed search tasks using search results with MAP scores between 55% and 95%. They were unable to find a correlation be-tween MAP scores and a precision based task requiring the first relevant document to be found. For recall based tasks, they only found a weak link between MAP and the num-ber of relevant documents found in a given time period. Figure 2: INEX 2009 Pre-cision vs Recall Figure 4: Wall Street Journal P@n They conclude that MAP does not correlate with user per-formance on simple information finding web search tasks.
Recall is not likely to be important to users except in some specific domains. Therefore, we focus our attention on comparison of P@N results between TopSig and state of the art inverted file approaches. The results immediately make it obvious that TopSig is a viable option for common information finding tasks
To assess TopSig at early precision we look at early preci-sion in the P@N plots on Figures 3 and 4, for the 68 INEX 2009 ad-hoc queries and the TREC Wall Street Journal queries 51-100. It is immediately clear that TopSig performs similarly.

In order to look more carefully at the differences, we fo-cused on the P@10 performance differences on the Wikipedia collection, between the best performing ranking function -BM25, and TopSig with 4096 bit signatures. The average P@10 for BM25 is 0 . 54, and for TopSig it is 0 . 51. We look at all 68 queries and performed two-tailed paired t-test. There is no statistically significant difference with p =0 . 41. Fig-ure 5 depicts the P@10 values for all 68 queries. The topics on the X axis are ordered by increasing P@10 values for BM25. The TopSig P@10 values are plotted in the same order. It is obvious that the two approaches produce very different results on a per-topic comparison. The two sys-tems do not agree on which topics are difficult and which are not, and both sometime fail (on different topics) to pro-duce any relevant result in the top-10. It is a common and well understood phenomena that this should occur and it is true for all the ranking functions that we tested. However, there is a much stronger correlation between all the language models, and BM25, as to which topics are hard and which are easy. No such correlation is observed for TopSig which seems to behave quite differently despite producing similar overall precision. This leads us to conjecture that combin-ing TopSig with BM25 (or any of the other models tested) may lead to better results than emerge from combining any other pair of more correlated ranking functions. Testing this conjecture is outside the scope of this paper.
TopSig is efficient and compares well with the inverted file approach. On a standard PC, a 1024 bit signature index can be searched by brute force in about 175 milliseconds, with a collection of 2.7 million signatures of the English Wikipedia documents. The signatures file size for this collection is only 325 MB, less than 0.65% of the collection size, and so it easily fits in memory. By contrast, the highly compressed inverted file of ATIRE (formerly known as ANT) that un-derlies all the other models, occupies 1.5GB, or about 3% of the uncompressed text collection size. ATIRE itself is highly efficient and for comparison, the Indri index for the same collection occupies about 11% of the space.

Searching with TopSig is also efficient. We have not im-plemented a parallel multicore search which offers linear speedup in the number of cores. Even so, all 68 queries for INEX collection were completed in 12 seconds for the Wikipedia collection and all 50 WSJ topics were completed in 4 seconds, on a basic Laptop. This is comparable to the performance that is obtained with the inverted file system.
The goal of clustering is to place documents into topical groups. The space and time efficiency of the TopSig repre-sentation allows it to outperform current approaches. It is also competitive in terms of document cluster quality. We have modified the k-means algorithm to work with signa-tures. This approach is compared to the implementation of k-means in the CLUTO clustering toolkit [6] that is popu-lar in the IR community. CLUTO uses full precision sparse vectors to represent documents.

The k-means [7] algorithm was modified to work with the bit string representation of TopSig. Cluster centroids and documents are N bit strings. Each bit in a centroid is the median for all documents it rep resents. If more than half the documents contain a bit set to 1 then the centroid contains this value in the corresponding position. As the 1 and 0 val-ues represent +1 and -1 this is equivalent to adding all the vectors and taking the sign of each position. The standard Hamming distance measure is used to compare all vectors. The algorithm is initialized by selecting k random docu-ments as centroids. This modified version of k-means always converged when the maximum number of iterations was not limited. Whether this modified version has the same con-vergence guarantees as the original algorithm is unknown. We have evaluated document clustering using a 144,265 Wikpedia document subset -the INEX 2010 XML Mining collection [2]. The standard approach of comparing clus-ters to a  X  X round truth X  set of categories is measured via Micro Purity. On this collection, Purity produces approx-imately the same relationships between different clustering approaches as F1, Normalized Mutual Information and En-tropy. There are 36 categories for documents that are ex-tracted from the Wikipedia category graph.

An alternative evaluation is performed that has a specific application in information retrieval. Ad-hoc retrieval rele-vance judgements are used to measure the spread of relevant documents over clusters. This is motivated by the cluster hypothesis [14], stating that documents relevant to the same information need tend to cluster together. If this hypothesis holds then most of the results will be in a small number of Figure 6: INEX 2010 Mi-cro Purity clusters. The Normalized Cumulative Cluster Gain measure represents how relevant documents are spread over clusters. It falls in the range [0 , 1] where a score of 1 indicates all rel-evant documents were contained in 1 cluster and a score of 0 indicates all relevant documents were evenly spread across all clusters. Complete details of the evaluation are available in a track overview paper from INEX 2010 [2].

The sparse document vectors used to create the TopSig document signatures are used as input to the k-means im-plementation in CLUTO. Therefore, we are comparing the same algorithm on the same data except for the fact the Top-Sig representation is extremely compressed and has a differ-ent centroid representation and distance measure. Both im-plementations of k-means are initialized randomly and are allowed to run for a maximum of 10 iterations. 36, 100, 200, 500 and 1000 clusters were produced by each approach where 36 was chosen to match the number of categories. This allows the trend of the measures to be visualised as the number of clusters are varied.
Figures 6 and 7 represent the quality of the clustering approaches using the Micro Purity and NCCG measures re-spectively. The TopSig representation nears the quality of CLUTO at 1024 bits and matches it at 4096 bits according to both measures. The best NCCG scores are all greater than 0.84 for all numbers of clusters, strongly supporting the cluster hypothesis, even when splitting the collection into 1,000 clusters.

Figure 8 shows how many times faster the TopSig cluster-ing is than the traditional sparse vector approach in CLUTO. For example, using 4096 bit signatures to create 500 clus-ters is completed 20 times faster than CLUTO and 80 times faster at 1024 bits. This is one to two orders of magnitude increase in efficiency while still achieving the same quality as traditional approaches.

Figures 6, 7 and 8 can not be significance tested as they are a single run of the algorithms. However, the graphs al-low the general trends to be visualised. CLUTO k-means takes approximately 5 hours to produce 1,000 clusters on this relatively small collection. Therefore, the CLUTO and TopSig k-means algorithms were repeatedly run to produce 36 clusters given different starting conditions. Given each random initialisation, k-means converges to a different local minima. The k-means impleme ntations were run 20 times to measure this variability. Table 9 contains the results of this experiment where TopSig approaches that are equivalent to the CLUTO approach are highlighted in boldface. Equiva-lence was tested using the t -test with p&gt; 0.05 indicating no statistically significant difference. Figure 8: INEX 2010 Clustering Speed Up
We have described TopSig, an approach to the construc-tion of file signatures that emerges from aggressive compres-sion of the conventional term-document weight matrix that underlies the most common and most successful inverted file approaches. When focusing on early precision, TopSig is shown to be as effective as even the best models available, while requiring equal or less amounts of space for storing sig-natures. Significant reductions in signature index size can be achieved with TopSig as a trade-off. Testing with stan-dard clustering benchmark tasks demonstrates TopSig to be equally effective and as accurate as a state-of-the-art clus-tering solution such as CLUTO, with processing speedup of one to two orders of magnitude.

TopSig had been applied to documents of greatly varying lengths. Both the WSJ and the Wikipedia collections have very short to very long documents, varying in size by up to five orders of magnitude. It had been suggested that file signatures are susceptible to this situation because of the increased probability of collisions on terms, but TopSig still performs well on these collections. In particular, we have tested TopSig with WSJ -the same collection that was used by Zobel et al to demonstrate the superiority of conventional inverted files. TopSig clearly outperforms conventional file signatures that were previously discredited. In this paper we compare TopSig directly with inverted file approaches to demonstrate similar performance levels.

There are certain differences between TopSig and inverted file based retrieval which may offer advantages in some ap-plication settings. TopSig performs the search in constant time and independently of query length. Comparing full documents to the collection (filtering task), or processing long queries, take exactly the same time as comparing a sin-gle term query. This may be useful in applications where predictability and quality of service guarantees are critical. The index size can be reduced by shortening the signature length, with smooth degradation in retrieval performance. Signatures may offer significant advantages where storage space is at a premium and a robust trade off is sought.
Distributed search is an attractive setting for TopSig -dis-tributed indexing and retrieval have to resolve the problems of collection splitting and result fusion. With TopSig these operations are trivial to implement since the Hamming dis-tance between signatures can be used as a universal metric across the system. If each text object in an enterprise carries its own signature then crawling and indexing the enterprise collection is a simple as collecting the signatures. Alterna-tively, TopSig can support the implementation of massively parallel search simply by distributing the query signature to every participating sub-system that maintains its own set of signatures. It is also trivial to implement distributed filter-ing with TopSig by maintaining a  X  X atch list X  of signatures that can be compared with incoming text objects at run time.

TopSig represents a principled approach to the construc-tion of file signatures, placing it in the same conceptual framework as other models. It offers a view of file signa-tures as a highly compressed vector space representation of the collection, or alternatively, it offers a geometric represen-tation of documents as points on the vertices of a collection hypercube. This is very different from the bitwise-efficiency motivated conventional ad-hoc formulation of file signatures.
