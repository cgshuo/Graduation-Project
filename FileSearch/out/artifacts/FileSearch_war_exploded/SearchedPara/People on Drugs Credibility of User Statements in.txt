 Online health communities are a valuable source of infor-mation for patients and physicians. However, such user-generated resources are often plagued by inaccuracies and misinformation. In this work we propose a method for auto-matically establishing the credibility of user-generated med-ical statements and the trustworthiness of their authors by exploiting linguistic cues and distant supervision from ex-pert sources. To this end we introduce a probabilistic graphi-cal model that jointly learns user trustworthiness, statement credibility, and language objectivity.

We apply this methodology to the task of extracting rare or unknown side-effects of medical drugs X  X his being one of the problems where large scale non-expert data has the po-tential to complement expert medical knowledge. We show that our method can reliably extract side-effects and fil-ter out false statements, while identifying trustworthy users that are likely to contribute valuable medical information. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Filtering ; I.2.7 [ Compu-ting Methodologies ]: Artificial Intelligence -Natural Lan-guage Processing Design, Algorithms, Measurement, Experimentation Credibility; Trustworthiness; Objectivity; Veracity; Proba-bilistic Graphical Models
Online social media includes a wealth of topic-specific communities and discussion forums about politics, music, health, and many other domains. User-generated content in such communities offer a great potential for distilling and an-alyzing facts and opinions. In particular, online health com-munities constitute an important source of information for patients and doctors alike, with 59% of the adult U. S. pop-ulation consulting online health resources [13], and nearly half of U. S. physicians relying on online resources for pro-fessional use [17].

One of the major hurdles preventing the full exploita-tion of information from online health communities is the widespread concern regarding the quality and credibility of user-generated content [37, 48]. To address this issue, this work proposes a model that can automatically assess the credibility of medical statements made by users of online health communities. In particular, we focus on extracting rare or unknown side-effects of drugs X  X his being one of the problems where large scale non-expert data has the poten-tial to complement expert medical knowledge [47], but where misinformation can have hazardous consequences [7].
The main intuition behind the proposed model is that there is an important interaction between the credibility of a statement, the trustworthiness of the user making that statement and the language used in the post containing that statement. Therefore, we consider the mutual interaction between the following factors:  X  Users: the overall trustworthiness (or authority) of a  X  Language: the objectivity , rationality (as opposed to emo- X  Statements: the credibility (or truthfulness) of medical
These factors have a strong influence on each other. In-tuitively, a statement is more credible if it is posted by a trustworthy user and expressed using confident and objec-tive language. As an example, consider the following review about the drug Depo-Provera by a senior member of health-boards.com , one of the largest online health communities:  X  . . . Depo is very dangerous as a birth control and has too many long term side-effects like reducing bone density . . .  X  This post contains a credible statement that a side-effect of Depo-Provera is to reduce bone density. Conversely, highly subjective and emotional language suggests lower credibil-ity of the user X  X  statements. A negative example along these lines is: time it fels somewhat demonic.  X  Although this post suggests that taking Xanax can lead to hallucination, the style in which it is written renders the credibility of this statement doubtful. These examples sup-port the intuition that to identify credible medical state-ments, we also need to assess the trustworthiness of users and the objectivity of their language. In this work we lever-age this intuition through a joint analysis of statements, users, and language in online health communities.

Although information extraction methods using proba-bilistic graphical models [39, 21] have been previously em-ployed to extract statements from user generated content, they do not account for the inherent bias, subjectivity and misinformation prevalent in health forums. Unlike standard information extraction techniques [23, 5, 41], our method considers the role language can have in assessing the cred-ibility of the extracted statements. Stylistic features X  X uch as the use of modals and inferential conjunctions X  X elp iden-tify accurate statements, while affective features help deter-mine the emotional state of the user making those state-ments (e.g., anxiety, confidence).

The main technical contribution of this paper is a proba-bilistic graphical model which is tailored to the problem set-ting as to facilitate joint inference over users, language, and statements. We devise a Markov Random Field (MRF) with individual users, posts, and statements as nodes, as summa-rized in Figure 1. The quality of these nodes X  X rustworthiness, objectivity, and credibility X  X s modeled as binary random variables. The model is semi-supervised with a subset of training side-effect statements derived from expert medical databases, labeled as true or false. In addition, the model relies on linguistic and user features that can be directly observed in online communities. Inference and parameter estimation is done via an EM (Expectation-Maximization) framework, where MCMC sampling is used in the E-step for estimating the label of unknown statements and the Trust Region Newton method [27] is used in the M-step to com-pute feature weights.

We apply our method to 2 . 8 million posts contributed by 15 , 000 users of one of the largest online health community healthboards.com . Our model achieves an overall accuracy of 82% in identifying drug side-effects, bringing an improve-ment of 13% over an SVM baseline using the same features and an improvement of 4% over a stronger SVM classifier which uses distant supervision to account for feature spar-sity. We further evaluate how the proposed model performs in two realistic use cases: discovering rare side-effects of drugs and identifying trustworthy users in a community.
To summarize, this paper brings the following main con-tributions:  X  Model: It proposes a model that captures the interactions  X  Method: It introduces a method for joint inference over  X  Application: It applies this methodology to the problem  X  Use-cases: It evaluates the performance of the model in
Our approach leverages the intuition that there is an im-portant interaction between statement credibility, linguistic objectivity, and user trustworthiness. We therefore model these factors jointly through a probabilistic graphical model, more specifically a Markov Random Field (MRF), where each statement, post and user is associated with a binary random variable. Figure 1 provides an overview of our model. For a given statement, the corresponding variable should have value 1 if the statement is credible, and 0 otherwise. Likewise, the values of post and user variables reflect the objectivity and trustworthiness of posts and users. Nodes, Features and Labels Nodes associated with users and posts have observable features, which can be extracted from the online community. For users, we derive engage-ment features (number of questions and answers posted), interaction features (e.g., replies, giving thanks), and de-mographic information (e.g., age, gender). For posts, we extract linguistic features in the form of discourse markers and affective phrases. Our features are presented in details in Section 3. While for statements there are no observable features, we can derive distant training labels for a subset of statements from expert databases, like the Mayo Clinic, which list typical as well as rare side-effects of widely used drugs.
 Edges The primary goal of the proposed system is to re-trieve the credibility label of unobserved statements given some expert labeled statements and the observed features by leveraging the mutual influence between the model X  X  vari-ables. To this end, the MRF X  X  nodes are connected by the following (undirected) edges:  X  each user is connected to all her posts;  X  each statement is connected to all posts from which it can  X  each user is connected to statements that appear in at Configured this way, the model has the capacity to cap-ture important interactions between statements, posts, and users  X  for example, credible statements can boost a user X  X  trustworthiness, whereas some false statements may bring it down. Furthermore, since the inference (detailed in Section 4) is centered around the cliques in the graph (factors) and multiple cliques can share nodes, more complex  X  X ross-talk X  is also captured. For instance, when several highly trustwor-thy users agree on a statement and one user disagrees, this reduces the trustworthiness of the disagreeing user.
In addition to establishing the credibility of statements, the proposed system also computes individual likelihoods as a by-product of the inference process, and therefore can out-put rankings for all statements, users, and posts, in descend-ing order of credibility, trustworthiness, and objectivity. Figure 1: Overview of the proposed model, which captures the interactions between statement credibility, post objec-tivity, and user trustworthiness.
The linguistic characteristics of a post can convey the au-thor X  X  attitude towards her statements as well as her emo-tional state [8]. In our model we use stylistic and affective features to assess a post X  X  objectivity and quality. Stylistic Features Consider the following user post: This post evokes a lot of uncertainty, and does not specifi-cally point to the occurrence of any side effect from a first-hand experience. Note the usage of strong modals (depicting a high degree of uncertainty)  X  X an X ,  X  X ay X ,  X  X ould X , the in-definite determiner  X  X ome X , the conditional  X  X f X , the adverb of possibility  X  X robably X  and the question particle  X  X hich X . Even the usage of too many named entities for drug and dis-ease names can impact the credibility of a statement (refer the introductory example).

Contrast the above post with the following one : This post uses the inferential conjunction  X  X ence X  to draw conclusions from a previous argument, the definite deter-miners  X  X his X ,  X  X hose X ,  X  X he X  and  X  X ost X  to pinpoint entities and the highly certain weak modal  X  X ill X .

Table 1 shows a set of linguistic features which we deem suitable for discriminating between these two kinds of posts. Many of the features related to epistemic modality have been discussed in prior linguistic literature [8, 46] and features related to discourse coherence have also been employed in earlier computational work (e.g., [31, 51]).

For each stylistic feature type f i shown in Table 1 and each post p j , we compute the relative frequency of words of type f i occurring in p j , thus constructing a feature vector F
L ( p j ) =  X  freq ij = #( words in f i ) / length ( p j further aggregate these vectors over all posts p j by a user u k into
F L ( u k ) =  X  X Affective Features Each user has an affective state that depicts her attitude and emotions that are reflected in her posts. Note that a user X  X  affective state may change over time; so it is a property of posts, not of users per se. As an example, consider the following post: The high level of depression and negativity in the post makes one wonder if the statements on drug side-effects are really credible. Contrast this post to the following one: where the user objectivity and positivity in the post make it much more credible.

We use the WordNet-Affect lexicon [40], where each word sense (WordNet synset) is mapped to one of 285 attributes of the affective feature space, like confusion, ambiguity, hope, anticipation, hate . We do not perform word sense disam-biguation (WSD), and instead simply take the most com-mon sense of a word (which is generally a good heuristics for WSD). For each post, we create an affective feature vec-tor  X  F E ( p j )  X  using these features, analogous to the stylistic vectors  X  F L ( p j )  X  . Table 2 shows a sample of the affective features used in this work.
 Preliminary Feature Exploration To test whether the linguistic features introduced so far are sufficiently infor-mative of how helpful a user is in the context of health forums, we conduct a preliminary experimental study. In the healthboards.com forum, community members have the option of expressing their gratitude to a user if they find one of her posts helpful by giving  X  X hanks X  votes. Solely for the purpose of this preliminary experiment, we use the total number of  X  X hanks X  votes that a user received from all her posts as a weak proxy measure for user helpfulness.
We train a regression model on the per-user stylistic fea-ture vectors F L ( u k ) with #thanks normalized by #posts for each user u k as response variable. We repeat the same experiment using only the per-user affective feature vectors F E ( u k ) to identify the most important affective features.
Figure 2 shows the relative weight of various stylistic and affective linguistic features in determining user helpfulness , with positive weights being indicative of features contribut-ing to a user being considered helpful by the community. Figure 2a shows that user confidence, pride, affection and positivity in statements are correlated with user helpfulness, in contrast to misery, depression and negativity in attitude. Figure 2b shows that inferential statements about definite entities have a positive impact, as opposed to the use of hypothetical statements, contrasting sentences, doubts and queries.

This experiment confirms that linguistic features can be informative in the context of online health communities. Al-though we use  X  X hanks X  votes as a proxy for user helpfulness, there is no guarantee that the information provided by help-ful users is actually correct. A user can receive  X  X hanks X  for a multitude of reasons (e.g. being compassionate or support-ive), and yet provide incorrect information. Hence, while the features described here are part of our final model, the feature weights learned in this preliminary experiment are not going to be used; instead, partially provided expert in-formation is used to train our probabilistic model (refer to Section 4).
User demographics like age, gender and location, as well as engagement in the community reflected by the number of posts, questions, replies, or thanks received, are expected to correlate with user authority in social networks. Also, users who write long posts tend to deviate from the topic, often with highly emotional digression. On the other hand, short posts can be regarded as being crisp, objective and on topic. We attempt to capture these intuitive aspects as additional per-user features &lt; F U ( u k ) &gt; . 2
As outlined in Section 2, we model our learning task as a Markov Random Field (MRF), where the random vari-
For verbosity, we compute the first three moments of each user X  X  post-length distribution (#sentences and #words). ables are the users U = { u 1 ,u 2 ,...u | U | } , their posts P = { p 1 ,p 2 ...p | P | } , and the distinct statements S = { s about drug side-effects extracted from all posts. Our model is semi-supervised in that we harness ground-truth labels for a subset of statements, derived from the expert databases. Let S L be the set of statements labeled by an expert as true or false, and let S U be the set of unlabeled statements. Our goal is to infer labels for the statements in S U .
The cliques in our MRF are triangles consisting of a state-ment s i , a post p j that contains that statement, and a user u k who wrote this post. As the same statement can be made in different posts by the same or other users, there are more cliques than statements. For convenient notation, let S  X  note the set of statement instances that correspond to the set of cliques, with statements  X  X epeated X  when necessary.
Let  X  i ( S  X  i ,p j ,u k ) be a potential function for clique i . Each clique has a set of associated feature functions F weight vector W . We denote the individual features and their weights as f il and w l . The features are constituted by the stylistic, affective, and user features explained in Sec-tion 3: F i = F L ( p j )  X  F E ( p j )  X  F U ( u k ) . Instead of computing the joint probability distribution Pr ( S,P,U ; W ) like in a standard MRF, we adopt the paradigm of Conditional Random Fields (CRF X  X ) and settle for the simpler task of estimating the conditional distribution: with normalization constant Z ( P,U ); or with features and weights made explicit: Pr ( S | P,U ; W ) = 1
CRF parameter learning usually works on fully observed training data. However, in our setting, only a subset of the S variables have labels and we need to consider the parti-tioning of S into S L and S U : Pr ( S U ,S L | P,U ; W ) = 1
For parameter estimation, we need to maximize the marginal log-likelihood: LL ( W ) = log Pr ( S L | P,U ; W ) = log X
We can clamp the values of S L to their observed values in the training data [42, 54] and compute the distribution over S U as:
There are different ways of addressing the optimization problem for finding the argmax of LL ( W ). In this work, we choose the Expectation-Maximization (EM) approach [29]. We first estimate the labels of the variables S U from the pos-terior distribution using Gibbs sampling, and then maximize the log-likelihood to estimate the feature weights: The update step to sample the labels of S U variables by Gibbs sampling is given by: where C denotes the set of cliques containing statement S For the M-step in Equation 7b, we use an L 2 -regularized Trust Region Newton Method [27], suited for large-scale un-constrained optimization, where many feature values may be zero. For this we use an implementation of LibLinear [12].
The above approach captures user trustworthiness implic-itly via the weights of the feature vectors. However, we may want to model user trustworthiness in a way that explic-itly aggregates over all the statements made by a user. Let t denote the trustworthiness of user u k , measured as the fraction of her statements that were considered true in the previous EM iteration: where S i,k is the label assigned to u k  X  X  statement S i previous EM iteration. Equation 8 can then be modified into:
Therefore, the random variable for trustworthiness de-pends on the proportion of true statements made by the user. The label of a statement, in turn, is determined by the language objectivity of the posts and trustworthiness of all the users in the community that make the statement.
The inference is an iterative process consisting of the fol-lowing 3 main steps: 1. Estimate user trustworthiness t k using Equation 9. 2. Apply the E -Step to estimate q ( S U ; W (  X  ) ) 3. Apply the M -Step to estimate W (  X  +1) using Equa-
In this section, we study the predictive power of our prob-abilistic model and compare it to three baselines.
We use data from the healthboards.com , one of the largest online health communities, with 850 , 000 registered mem-bers and over 4 . 5 million posted messages. We extracted 15 , 000 users and all of their posts, 2 . 8 million posts in total. Users are sampled based on their post frequency; Table 3 shows the user categorization in terms of their community engagement. 3 We employ an IE tool [11] to extract side-effect statements from the posts. Details of the experimental setting are available on our website. 4
As ground truth for drug side-effects, we rely on data from the Mayo Clinic portal, 5 which contains curated expert in-formation about drugs, with side-effects being listed as more common, less common and rare for each drug. We extracted 2 , 172 drugs which are categorized into 837 drug families. For our experiments, we select 6 widely used drug families (based on webmd.com ). Table 4 provides information on this sample and its coverage on healthboards.com . Table 5 shows the number of common, less common, and rare side-effects for the six drug families as given by the Mayo Clinic portal.
Overall, 77 . 7% of the active contributors are female. Table 4: Information on sample drug families: number of posts and number of users reporting at least one side effect.
We compare our probabilistic model against the following baseline methods, using the same features as our model and classifying the same set of side-effect candidates. Frequency Baseline For each statement on a drug side-effect, we consider how frequently the statement has been made in community. This gives us a ranking of side-effects. SVM Baseline For each drug and possible side-effect we determine all posts where it is mentioned and aggregate the features F L , F E , F U , described in Section 3 over all these posts, thus creating a single feature vector for each side-effect.

We use the ground-truth labels from the Mayo Clinic por-tal to train a Support Vector Machine (SVM) classifier with a linear kernel, L 2 loss, and L 1 or L 2 regularization, for classifying unlabeled statements.
 Table 5: Number of common, less common, and rare side-effects listed by experts on Mayo Clinic.
 SVM Baseline with Distant Supervision As the num-ber of common side-effects for any drug is typically small, the above approach to create a single feature vector for each side-effect results in a very small training set. Hence, we use the notion of distant supervision to create a rich, expanded training set.

A feature vector is created for every mention or instance of a side-effect in different user posts. The feature vector &lt; S i ,p j ,u k &gt; has the label of the side-effect, and represents the set of cliques in Equation 2. The semi-supervised CRF formulation in our approach further allows for information sharing between the cliques to estimate the labels of the unobserved statements from the expert-provided ones.
This process creates a noisy training set, as a post may contain multiple side-effects, positive and negative. This re-sults in multiple similar feature vectors with different labels. During testing, the same side-effect may get different labels from its different instances. We take a majority voting of the labels obtained by a side-effect, across predictions over its different instances, and assign a unique label to it.
We conduct two lines of experiments, with different set-tings on what is considered ground-truth.
 Experimental Setting I We consider only most common side-effects listed by the Mayo Clinic portal as positive ground-truth, whereas all other side-effects (less common, rare and unobserved) are considered to be negative instances (i.e., so unlikely that they should be considered as false statements, if reported by a user). The training set is constructed in the same way. This setting aims to study the predictive power of our model in determining the common side-effects of a drug, in comparison to the baselines.
 Experimental Setting II Here we address our original motivation: discovering less common and rare side-effects. During training, as positive ground-truth we consider com-mon and less common side-effects (as stated by the experts on the Mayo Clinic site), whereas all rare and unobserved side-effects are considered negative instances. Our goal here is to test how well the model can identify less known and rare side-effects as true statements.

We purposely do not consider rare side-effects as posi-tive training examples, as users frequently talk about expe-riencing all possible side-effects. Instead we aim to evaluate the model X  X  ability to retrieve such statements starting only from very reliable positive instances. We measure perfor-mance on rare side-effects as the recall for such statements being labeled as true statements, in spite of considering only common and less common side-effects as positive instances during training.
 Train-Test Data Split For each drug family, we create multiple random splits of 80% training data and 20% test data. All results reported below are averaged over 200 such splits. All baselines and our CRF model use same test sets. Evaluation Metrics The standard measure for the qual-report the specificity ( tn tn + fp ) and sensitivity ( tp tivity measures the true positive rate or the model X  X  ability to identify positive side-effects, whereas specificity measures true negative rate.
Table 6 shows the accuracy comparison of our system (CRF) with the baselines for different drug families in the first setting. The first naive baseline, which simply considers the frequency of posts containing the side-effect by different users, has an average accuracy of 57 . 6% across different drug families.

Incorporating supervision in the classifier as the first SVM baseline (SVM w/o DS), along with a rich set of features for users, posts and language, achieves an average accuracy im-provement of 11 . 4%. In the second SVM baseline (SVM DS), we represent each post reporting a side-effect as a sep-arate feature vector. This not only expands the training set leading to better parameter estimation, but also represents the set of cliques in Equation 2 (we therefore consider this to be a strong baseline). This brings an average accuracy im-provement of 7% when using L 1 regularization and 9% when using L 2 regularization. Our model (CRF), by further con-sidering the coupling between users, posts and statements, allows information to flow between the cliques in a feedback loop bringing a further accuracy improvement of 4% over the strong SVM DS L 2 baseline.

Figure 3 shows the sensitivity and specificity comparison of the baselines with the CRF model. Our approach has an overall 5% increase in sensitivity and 3% increase in speci-ficity over the SVM L 2 baseline.

The specificity increase over the SVM L 2 baseline is max-imum for the Alprazolam drug family at 8 . 3%. Users tak-ing such anti-depressants often suffer from anxiety disorder, panic attacks or depression and report a large number of side-effects; also there are a large number of expert-reported side-effects for this drug family (refer Table 5). Hence, the task of discarding certain side-effects is harder for this par-ticular drug, but our linguistic features help our model over-come this and perform well.

The drugs Metronidazole, Metformin and Omeprazole treat some serious physical conditions, have less number of expert and user-reported side-effects. Consequently, our model cap-tures user statement corroboration well to attain a sensitiv-ity improvement of 7 . 8% , 6 . 5% and 6 . 3% respectively. Over-Figure 3: Specificity and sensitivity comparison of models. all, our classifier performs best for these drug categories.
Table 7 shows the overall model performance, as well as the recall for identifying rare side-effects of each drug in the second setting. The drugs Metformin, Levothyroxine and Omeprazole have much fewer side-effects, and the classifier does an almost perfect job in identifying all of them. Feature Informativeness In order to find the predictive power of individual feature classes, tests are performed us-ing L 2 -loss and L 2 -regularized SVM over a split of the test data. Affective features are found to be the most informa-tive, followed by document length statistics, which are more informative than user and stylistic features. The importance of the document length features support our intuition that objective posts tend to be crisp, whereas longer ones often indulge in emotional digressions.

Among user features, the most informative is the ratio of number of replies to number of questions, followed by gender, number of posts and, finally, the number of thanks received from fellow users.

When considered independently, user, affective and stylis-tic features achieve F 1 scores between 51% and 55% for Al-prazolam; whereas the combination of all features yield 70% F 1 score.
The previous section has focused on evaluating the pre-dictive power of our model and inference method. Now we shift the focus to two application-oriented use-cases: discov-ering side-effects that are not covered by expert databases, and identifying the most trustworthy users that are worth following.
Members of an online community may report side-effects that are either flagged as very rare in an expert knowledge base (KB) or not listed at all. We call the latter out-of-KB statements. As before, we use the data from the Mayo Clinic portal as our KB, and focus on the following two drugs rep-resenting different kinds of medical conditions and patient-reporting styles: Alprazolam and Levothyroxine. For each of these drugs, we perform an experiment as follows.
For each drug X , we identify all side-effects S that are reported for X by members of the health community; here we consider all side-effects listed for any drug in the KB as a potential result. For example, if  X  X allucination X  is listed for some drug but not for the drug Xanax, we capture mentions of hallucination in posts about Xanax. We use our prob-abilistic model to compute credibility scores for these out-of-KB side-effects, and compile a ranked list of 10 highest-scoring side-effects for each drug. This ranked list is further extended by 10 randomly chosen out-of-KB side-effects (if reported at least once for the given drug).

The ranked list of out-of-KB side-effects is shown to two annotators 6 who manually assess their credibility, by read-ing the complete discussion thread (including expert replies to patient posts) and other threads that involve the users who reported the side-effect. The assessment is binary: the side-effect is considered either true (1) or false (0); we choose the final label via majority voting, breaking ties using other expert databases ( patient.co.uk and webmd.com ). This way, we can compute the quality of the ranked list in terms of the NDCG (Normalized Discounted Cumulative Gain) mea-
Here, rel i is the graded relevance of a result (0 or 1 in our case) at position i . DCG penalizes relevant items ap-pearing lower in the rank list, where the graded relevance score is reduced logarithmically proportional to the position of the result. As the length of lists may vary for different queries, DCG scores are normalized using the ideal score, IDCG where the results of a rank list are sorted by rele-vance giving the maximum possible DCG score. We also report the Cohen X  X  Kappa inter-annotator agreement mea-sure.

Table 8 shows the Kappa and NDCG score comparison be-tween the baseline and our CRF model. The baseline here is to rank side-effects by frequency, i.e., how often are they re-ported in the posts of different users on the given drug. The strength of Kappa is considered  X  X oderate X  (but significant), which depicts the difficulty in identifying the side-effects of a drug just by looking at user posts in a community. The baseline performs very poorly for the anti-depressant Al-prazolam, as users suffering from anxiety disorders report a large number of side-effects most of which are not credible. On the other hand, for Levothyroxine (a drug for hypothy-roidism) the baseline model performs quite well, as users re-port more serious symptoms and conditions associated with the drug (which also has much less expert-stated side-effects compared to Alprazolam, as shown in Table 4). The CRF model performs perfectly for both drugs. None of authors were among the annotators.
 Table 8: Use-case experiment on discovering rare side-effects.
Table 9: Use-case experiment on identifying trustworthy users.
In the second use-case experiment, we evaluate how well our model can identify trustworthy users in a community. We find the top-ranked users in the community given by their trustworthiness scores ( t k , as defined in Section 4), for each of the drugs Alprazolam and Levothyroxine. The base-line model selects the most-thanked contributors in the com-munity. The moderators and facilitators of the community, listed by both models as top users, are removed from the ranked lists, in order to focus on the interesting, non-obvious cases. Two annotators are asked to annotate the top-ranked users listed by each model as trustworthy or not, based on the users X  posts on the target drug. The judges are asked to mark a user as trustworthy if they would consider following the respective user in the community. Judgements were ag-gregated via majority voting, with ties being considered as not trustworthy. Although this task may seem highly sub-jective, the Cohen X  X  Kappa scores show high inter-annotator agreement (Table 9). The strength of agreement is consid-ered to be  X  X ery good X  for the user posts on Levothyroxine, and  X  X ood X  for the Alprazolam users. Also in this use-case, our model performs well and outperforms the baseline for both drug families.
Subject-Predicate-Object statement extraction There is ample work on extracting Subject-Predicate-Object (SPO) statements from natural-language text [39, 23, 5, 41]. State-of-the-art methods combine pattern matching with extrac-tion rules and consistency reasoning. This can be done ei-ther in a shallow manner, over sequences of text tokens, or in combination with deep parsing and other linguistic analyses. The resulting SPO triples often have highly varying confi-dence, as to whether they are really expressed in the text or picked up spuriously. Judging the credibility of statements is out of the scope of classic SPO extraction methods. Biomedical Information Extraction Customized IE tech-niques have been developed to tap biomedical publications like PubMed articles for extracting facts about diseases, symptoms, and drugs. Emphasis has been on the molecular level, i.e. proteins, genes, and regulatory pathways (e.g., [6, 22, 4]), and to a lesser extent on biological or medi-cal events from scientific articles and from clinical narra-tives [19, 52]. LDA-style models have been used for sum-marizing drug-experience reports [36] and for building large knowledge bases for life science and health [11]. More re-cently, search engine query logs were shown to be a valuable source for identifying unknown drug side-effects [47]. Our work is complementing these approaches, by emphasizing the role of user generated content on social media. Truth Finding Our work relates to a research direction that aims to assess the truth of a given statement that is frequently observed on the Web X  X  typical example being  X  X bama is a Muslim X  [53, 33, 35]. Information-retrieval techniques are used to systematically generate alternative hypotheses for a given statement X  X  X bama is a Christian X  X  and assess the evidence for each alternative [25]. Similar approaches have been developed for structured data such as flight times or stock quotes, where different Web sources of-ten yield contradictory values [24]. Recently, an LDA-style latent-topic model was used for discriminating true from false claims, with various ways of generating incorrect state-ments (guesses, mistakes, lies) [34]. None of this prior work considered online discussion forums. Truth assessment for medical claims about diseases and their treatments (includ-ing drugs and general phrases such as  X  X urgery X ) was casted as an information retrieval style evidence-aggregation and ranking method over curated health portals [45]. Although these are elaborate models, they are not geared for our set-ting where the credibility of statements is intertwined with user trustworthiness and the linguistic properties of user posts.
 Language Analysis for Social Media Social media is an important setting for linguistic tasks that relate to our work, such as sentiment analysis (e.g., [43, 32, 28, 31, 30]), identifying bias [14, 38] and, more broadly, characterizing subjective language [49, 26]. Particularly relevant to our research direction is the link between subjectivity analysis and information extraction [50].
 Trust and Reputation Management A lot of work has been dedicated to building trust and reputation manage-ment systems in social media, mostly motivated by the need to filter and organize customer product reviews, but also in the context of social networks. One type of approach has been to model the propagation of trust within a network of users [20, 15]. TrustRank [20] has become a popular measure of trustworthiness, based on random walks on (or spectral decomposition of) the user graph. Reputation management has been studied in multiple contexts, such as peer-to-peer systems, blogs, and online interactions [1, 2, 9, 3, 16]. Most of this work focused on explicit relationships between users to infer authority and trust levels, and make little or no use of the content. An exception is a model for trust propagation which devises a HITS-style algorithm for propagating trust scores in a heterogeneous network of claims, news sources, and news articles [44], building on an intuition similar to that behind our proposed approach. Evidence for a claim is collected from related news articles using generic IR-style word-level measures. In contrast, our work considers user-generated content which is represented by rich linguistic fea-tures and employs a CRF to model the complex interaction characteristic of online communities.
Discussions in online communities are often plagued by inaccuracies and misinformation. This hinders the exploita-tion of these rich and valuable resources as information sources. In this work we focus on establishing the credibility of side-effect statements in health communities. To this end, we propose a probabilistic graphical model to jointly learn the interactions between user trustworthiness, statement credi-bility and language use. We apply the model to extract side-effects of drugs from health communities, where we leverage the user interactions, stylistic and affective features of lan-guage use, and user properties to learn the credibility of user statements. We show that our approach is effective in re-liably extracting side-effects of drugs and filtering out false information prevalent in online health communities.
In addition to validating our system X  X  performance against expert knowledge, we show it can be successfully used in two application oriented use-cases: identifying unknown side-effects of drugs, a scenario where large-scale non-expert data has the potential to complement expert knowledge, and se-lecting trustworthy users that are deemed worth following.
Although our model achieves high accuracy in most of the test cases, it relies on a relatively simple information extrac-tion machinery to identify candidate side-effect statements, which is prone to errors. The tool misses out on certain kinds of paraphrases (e.g.  X  X ightmares X  and  X  X nusual dream X  for Xanax) resulting in a drop in recall. We believe that a more sophisticated information extraction approach can further improve our approach.
 Acknowledgements We thank the anonymous reviewers for their helpful (and credible) comments. We also thank Patrick Ernst for helping setting up the statement extraction tool and Amy Siu for helping in the annotation task. [1] B.T. Adler, L. Alfaro. A content-driven reputation [2] N. Agarwal, H. Liu. Trust in Blogosphere.
 [3] L. Alfaro, A. Kulshreshtha, I. Pye, B.T. Adler. [4] J. Bj  X  orne, F. Ginter, S. Pyysalo, J. Tsujii, T. [5] P. Bohannon, N. Dalvi, Y. Filmus, N. Jacoby, S. [6] M. Bundschus, M. Dejori, M. Stetter, V. Tresp, H.P. [7] R.J.W. Cline, K.M. Haynes. Consumer health [8] J. Coates. Epistemic Modality and Spoken Discourse. [9] Z. Despotovic. Trust and Reputation in Peer-to-Peer [10] X. Dong, L. Berti-Equille, Y. Hu, D. Srivastava. [11] P. Ernst, C. Meng, A. Siu, G. Weikum. KnowLife: a [12] R.E. Fan, K.W. Chang, C.J. Hsieh, X.R. Wang, C.J. [13] S. Fox, M. Duggan. Health online 2013. Pew Internet [14] S. Greene, P. Resnik. More than Words: Syntactic [15] R.V. Guha, R. Kumar, P. Raghavan, A. Tomkins. [16] C. Hang, Z. Zhang, M.P. Singh. Shin: Generalized [17] IMS Institute for Healthcare Informatics. Engaging [18] K. J  X  arvelin. J. Kek  X  al  X  ainen. Cumulated gain-based [19] P. Jindal, D. Roth. End-to-End Coreference [20] S.D. Kamvar, M.T. Schlosser, H. Garcia-Molina. The [21] D. Koller, N. Friedman. Probabilistic Graphical [22] M. Krallinger, A. Valencia, L. Hirschman. Linking [23] R. Krishnamurthy, Y. Li, S. Raghavan, F. Reiss, S. [24] X. Li, X.L. Dong, K. Lyons, W. Meng, D. Srivastava. [25] X. Li, W. Meng, C.T. Yu. T-verifier: Verifying [26] C. Lin, Y. He, R. Everson. Sentence Subjectivity [27] C. Lin, R.C. Weng, S.S Keerthi. Trust Region Newton [28] B. Liu. Sentiment Analysis and Opinion Mining. [29] A. McCallum, K. Bellare, F. Pereira. A conditional [30] S. Mukherjee, G. Basu, S. Joshi. Joint Author [31] S. Mukherjee, P. Bhattacharyya. Sentiment Analysis [32] B. Pang, L. Lee. Opinion Mining and Sentiment [33] J. Pasternack, D. Roth. Knowing What to Believe [34] J. Pasternack, D. Roth. Latent credibility analysis. [35] J. Pasternack, D. Roth. Making Better Informed Trust [36] M.J. Paul, M. Dredze. Drug Extraction from the Web: [37] G. Peterson, P Aslani, K.A. Williams. How do [38] M. Recasens, C. Danescu-Niculescu-Mizil, D. Jurafsky. [39] S. Sarawagi. Information Extraction. Foundations and [40] C. Strapparava, A. Valitutti. Wordnet-affect: an [41] F.M. Suchanek, G. Weikum. Knowledge harvesting [42] C.A. Sutton, A. McCallum. An Introduction to [43] P.D. Turney. Thumbs Up or Thumbs Down? Semantic [44] V.G.V. Vydiswaran, C. Zhai, D. Roth. Content-driven [45] V.G.V. Vydiswaran, C. Zhai, D. Roth. Gauging the [46] P. Westney. How to Be More-or-Less Certain in [47] R.W. White, R. Harpaz, N.H. Shah, W. DuMouchel, [48] R.W. White, E. Horvitz. From health search to [49] J. Wiebe, E. Riloff. Creating Subjective and Objective [50] J. Wiebe, E. Riloff. Finding Mutual Benefit between [51] F. Wolf, E. Gibson, T. Desmet. Discourse coherence [52] Y. Xu, K. Hong, J. Tsujii, E.C. Chang. Feature [53] X. Yin, J. Han, P.S. Yu. Truth discovery with multiple [54] X. Zhu, Z. Ghahramani, J. Lafferty. Semi-supervised
