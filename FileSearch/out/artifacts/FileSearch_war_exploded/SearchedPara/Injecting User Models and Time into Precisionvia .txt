 We propose a family of new evaluation measures, called Markov Precision (MP) , which exploits continuous-time and discrete-time Markov chains in order to inject user mod-els into precision. Continuous-time MP behaves like time-calibrated measures, bringing the time spent by the user into the evaluation of a system; discrete-time MP behaves like traditional evaluation measures. Being part of the same Markovian framework, the time-based and rank-based ver-sions of MP produce values that are directly comparable.
We show that it is possible to re-create average precision using specific user models and this helps in providing an ex-planation of Average Precision (AP) in terms of user mod-els more realistic than the ones currently used to justify it. We also propose several alternative models that take into account different possible behaviors in scanning a ranked result list.
 Finally, we conduct a thorough experimental evaluation of MP on standard TREC collections in order to show that MP is as reliable as other measures and we provide an example of calibration of its time parameters based on click logs from Yandex.
 H.3.4 [ Information Search and Retrieval ]: Systems and Software X  Performance evaluation (efficiency and effective-ness) Experimentation, Measurement, Performance Evaluation; Markov Precision; User Model; Time Experimental evaluation has been central to Information Retrieval (IR) since its beginning [15] and Cranfield is the predominant paradigm for carrying out system-oriented ex-perimentation [11]. Over the decades, several measures have been proposed to evaluate retrieval effectiveness.
AP [5] represents the  X  X old standard X  measure in IR [35], known to be stable [3] and informative [1], with a natural top-heavy bias and an underlying theoretical basis as ap-proximation of the area under the precision/recall curve. Nevertheless, due to its dependence on the recall base, it as-sumes a perfect knowledge of the relevance of each document in the collection, which is an approximation when pooling is adopted and not assessed documents are assumed to be not relevant [14], and is even more exacerbated in the case of large scale or dynamic collections [4, 35].

However, the strongest criticism to AP comes from the absence of a convincing user model for it, a feature which is deemed extremely important in order to make the inter-pretation of a measure meaningful and to bridge the gap between system-oriented and user-oriented studies [7, 21, 31]. In this respect, [22] argued that the model behind AP is abstract, complex, and far from the real behavior of users interacting with an IR system, especially when it comes to its dependence on the recall base which is something actu-ally unknown to real users. As a consequence, [25] proposed a simple but moderately plausibile user model for AP, which allows for a mix of different behaviors in the population of users.

In this paper, we take up from the final considerations of [25], at page 690:  X  X his argument could provide the ba-sis for a more elaborate model, by for example basing the set of p s ( n ) on some more sophisticated view of stopping behaviour X , where p s ( n ) is the probability that the user sat-isfaction point is the document at rank n .

We propose a family of measures of retrieval effectiveness, called Markov Precision (MP) , where we exploit Markov chains [23] to inject different user models into precision and which does not depend on the recall base. We represent each position in a ranked result list with a state in a Markov chain and the different topologies and transition probabili-ties among the states of the Markov chain allow us to model the different and perhaps complex user behaviors and paths in scanning a ranked result list. The invariant distribution of the Markov chain provides us with the probability of the user being in a given state/rank position in stationary con-ditions and we use these probabilities to compute a weighted average of precision at those rank positions.

The framework we propose is actually more general and it is based on continuous-time Markov chains in order to take into account also the time a user spends in visiting a sin-gle document. It is then possible to extract a discrete-time Markov chain, when considering only the transitions among rank positions and not the time spent in each document. This gives us a two-fold opportunity: when we consider the discrete-time Markov chain, we are basically reasoning as traditional evaluation measures which assess the utility for the user in scanning the ranked result list; when we consider the continuous-time Markov chain,we also embed the infor-mation about the time spent by the user in visiting a docu-ment and we have a single measure including both aspects. This represents a valuable contribution of the paper since, up to now, rank and time have been two separate variables according to which retrieval effectiveness is evaluated [31].
The Markov chain approach relies on some assumptions  X  e.g. no long-term memory and exponentially distributed holding times  X  which may seem oversimplifications of the reality, e.g. a user who considers the whole history of visited documents to decide whether to stop or not. However, other measures, such as Rank-Biased Precision (RBP) [22] where transitioning to the next document or stopping is a step-by-step decision based just on the persistence parameter, are memory-less in this sense. Moreover, a Markovian model is simple enough to be easily dealt with while still being quite powerful and this work intends to be a first step towards a richer world of models that we will explore in the future.
We then propose some basic models for the transition ma-trix of the Markov chain. Clearly, this is not intended to be an exhaustive list of all the possible models but more of an exemplification of how it is possible to plug different user models into the framework. Still, these basic models pro-vide a second valuable contribution of the paper. Indeed, we will show how some of these models, when provided with the same level of information about the recall base as AP, actually are AP, thus giving an explanation of it in terms of a slightly richer user model than the one of [25]. We will also show how some of them are extremely highly correlated to AP, thus suggesting how AP can be considered a very good approximation of more complex user strategies. This helps in shedding some light on why AP is the de-facto X  X old standard X  in IR, even though it has been so often criticized.
Finally, we conduct a thorough experimental evaluation of the MP measure both using standard Text REtrieval Conference (TREC) 1 collections and click-logs with assessed queries made available by Yandex [29]. The results show that MP is comparable to other measures for some desir-able properties like robustness to pool downsampling while the Yandex click-logs allow us to estimate the time spent by the users on the documents and apply the continous-time Markov chain.

The paper is organized as follows: Section 2 presents the related works; Section 3 discusses other pertinent measures to which MP will be compared; Section 4 fully introduces MP; Section 5 reports the conducted experimental evalua-tion of MP; and Section 6 draws some conclusion and pro-vides an outlook for future work.
Markov-based approaches have been previously exploited in IR, for example: Markov chains have been used to gener-ate query models [19], for query expansion [12, 20], and for document ranking [13]. However, to the best of our knowl-http://trec.nist.gov/ edge, Markov chains have not been applied to the definition of a fully-fledged measure for retrieval effectiveness. [8] uses Markov chains to address the placement problem in the case of two-dimensional results presentation: they have to allocate images on a grid to maximize the expected total utility of the user, according to some evaluation mea-sure, and the Markov chain models how the user moves in the grid. Their approach differs from ours since they are not defining a measure of effectiveness which embeds a Markov chain but they rather solve an optimization problem via a Markov chain; moreover, they only use discrete-time Markov chains and limit transitions only to adjacent states. What we share is the idea that a Markov chain can be used to model how a user scans a result list, mono dimensional in our case, two-dimensional in their case.

When it comes to other evaluation measures, the focus of the paper is on lab-style evaluation, search tasks with infor-mational intents [2], and binary relevance. So, for example, measures for novelty and diversity are out of the scope of the present paper [10] as are measures for graded relevance like Discounted Cumulated Gain (DCG) [16], Expected Re-ciprocal Rank (ERR) [6], or Q-measure [26].

With regard to the time dimension brought in by the continuous-time Markov chain, the most relevant work is Time-Biased Gain (TBG) [30, 31]. We share the idea of getting time into evaluation measures but we adopted a dif-ferent approach. While TBG substitutes traditional evalua-tion measures, MP provides a single framework for keeping both aspects depending on which Markov chain you use. With respect to the user model adopted in TBG, there are some relevant differences: first, we use full Markov models while [30] at page 2014 points out that  X  X ur model can be viewed as a semi-Markov model X ; then, TBG assumes a se-quential scanning of the result lists where MP allows the user to move and jump backward and forward in the results list. What TBG addressed and is not in the scope of the present work is how to calibrate the measure with respect to time: [31] proposed a procedure to calibrate time with re-spect to document length and [30] extended it to stochastic simulation. In the present work, we provide a basic exam-ple of calibration based on the estimation of average time spent per document from click logs, just to show how the parameters of the framework could be tuned. However, in the future, nothing prevents us (or others) from investigat-ing more advanced calibration strategies or applying those proposed by [30, 31].

Previous work on click logs [17] has reported that, on av-erage, users scan ranked list in a forward linear fashion while MP allow users to move forward and backward in a ranked list. As reported in Section 5.5, from Yandex logs, we found that 21% of the users move backward in the ranked list, thus supporting our assumption, even if more exploration on this is left for future work. Moreover, U-measure [28] is a recent proposal which shares with MP the idea of removing the constraint of the linear scan but it does not adopt Markov models and has also somewhat different goals, such as evalu-ating complex tasks like multi-query sessions and diversified IR.

When it comes to other ways of modelling user behaviour into evaluation measures, [7] proposes relying on three com-ponents: a browsing model, a model of document utility, and a utility accumulation model. Even if we took up from [25], MP can also be framed in the light of the work of [7]. Indeed, the Markovian model provides us with the browsing model, precision account for the model of document utility, and the weighted average of precision by the invariant distribution of the Markov chain supplies the utility accumulation model.
Thus, evaluation measures of direct comparison, which will be detailed in Section 3, are those built around the con-cept of precision, namely AP, P@10, and Rprec [5]. RBP [22] comes into play as a binary evaluation measure not depen-dent on the recall base, even though it is not built around the concept of precision despite its name. Finally, we are also interested in Binary Preference (bpref) [4], just to have a comparison point when testing MP with respect to reduced-size pools. In this last respect, we are not interested in infAP [35], since we are neither looking for an estimator of AP nor investigating alternative strategies for pool down-sampling. For the same reason, we are not interested here in experimenting with respect to condensed-list measures [27].
Let us consider a ranked list of T documents in response to a given topic, let d n be the document retrieved at posi-tion n  X  T whose relevance is denoted by a n , equal to 1 if the document is considered relevant and 0 otherwise. The ranked list of documents is denoted with D = { d i ,i  X  T and R = { i j : j =1 ,...,T and a i j =1 } is the set of the ranks of the relevant documents, whose cardinality is r = |R| and which indicate the total number of relevant re-trieved documents by the system for the given topic. Let RB be the recall base of the topic, i.e. the total number of judged relevant documents for a given topic, and NRB the total number of judged not relevant documents for a given topic.
 The precision at rank n is thus defined as which corresponds to the percentage or  X  X ensity X  of relevant documents present among the first n , n included, in the list. Note that Rprec is Prec( RB ), which makes clear its dependence on the recall base.
 The recall at rank T is defined as which corresponds to the fraction of relevant documents of the specific run with respect to the total number of judged relevant documents.
The original definition of Average Precision (AP) [5] is the average over all RB judged relevant documents of the precision at their ranks, considering zero the precision at the not retrieved relevant documents: where, in the last equation, the first operand is the recall and the second one is the arithmetic mean of the precisions at each relevant retrieved document. This formulation fur-ther highlights the dependence of AP on the recall base and the recall itself.

As previously discussed, [25] proposed a simple, proba-bilistic user model measure of effectiveness called Normal-ized Cumulative Precision (NCP) , which includes AP as a particular case. The author assumes that any given user will stop his search at a given document in the ranked list, that we call its satisfaction point, according to a common probability law.

Furthermore, he considers that a user will stop his search only at relevant documents and that the probability that he stops at any given relevant documents is fixed and indepen-dent from the specific run he is considering, while it is 0 at any non relevant document. So, he defines a probability distribution p s on the set of all the documents available for agiventopic.
 Given a specific run and the set of its retrieved documents D , the definition of the NCP is then the expectation (aver-age) of the precision at the ranks of the retrieved, relevant documents, accordingly to a distribution p s (  X  ), i.e. It is easy to see that the above definition of AP is in this con-text equal to the NCP measure when we choose the uniform law p U over all the relevant documents for the topic
The previous user model is simple and it can be consid-ered as a starting point for more sophisticated models, as also suggested by [25] itself. As in the case of AP, the assumption that the user knows the recall base of a given topic is a weakness of this model. Furthermore, the proba-bility that a user stops their search at a given document on a specific run depends on a probability distribution defined on the whole set of relevant documents available for a given topic.

The choice of the uniform distribution to determine the stopping point in a given search is itself of difficult inter-pretation, since this means that any relevant document in a ranked list of retrieved documents has the same probability.
We will see in the next section how, stepping from the in-tuition behind NCP, we can define, thanks to simple Markov chains, a more realistic user model, how AP can be still con-sidered as a good approximation in many cases and how to generalize AP to a whole new class of Markovian models.
Rank-Biased Precision (RBP) [22] assumes a user model where the user starts from the top ranked document and with probability p , called persistence, goes to the next doc-ument or with probability 1  X  p stops. RBP is defined as follows:
It can be noted that, despite its name, RBP does not de-pend on the notion of precision. Nevertheless, it represents a measure for binary relevance which does not depend on the recall base and thus gives a comparison point in this last respect for MP.
Binary Preference (bpref) [4, 32] is a measure based on binary preferences and it evaluates systems using only the judged documents. It can be thought of as the inverse of the fraction of judged irrelevant documents that are retrieved before relevant ones: where j is a member of the first RB not relevant retrieved documents. bpref has proved to be quite robust in the case of incomplete and imperfect relevance judgements. Here, for us, it represents a comparison point when evaluating MP with respect to reduced-size pools.

It can be noted how heavily bpref depends on the recall base RB . This is not only a scale factor as in the case of AP but it also determines the cardinality of the set from which the not relevant documents j are taken. Moreover, it makes use also of NRB , the total number of judged not relevant documents, a kind of information which is hard to imagine available to any real user. So, in a sense, it seems much more a  X  X ool-oriented X  than a system-oriented measure since, for determining its score, it uses much more information about the pool than about the system under examination and this could be an explanation of its robustness to the pool reduc-tion.
We will assume that each user starts from a chosen doc-ument in the ranked list and considers this document for a random time, that is distributed according to a known pos-itive random variable. Then they decides, according to a probability law that we will specify in the sequel and inde-pendent from the random time spent in the first document, to move to another document in the list. Then, they con-siders this new document for a random time and moves, independently, to a third relevant document and so on.
After a random number of forward and backward move-ments along the ranked list, the user will end their search and we will evaluate the total utility provided by the sys-tem to them by taking the average of the precision of the judged relevant documents they has considered during their search. According to this construction when we compute this average, the precision of a document visited k times will contribute to the mean with a k/n weight.

We mathematically model the user behavior in the frame-work of the Markovian processes [23]. To fix the notation, we will denote by X 0 ,X 1 ,X 2 ,... the (random) sequence of document ranks visited by the user and by T 0 , T 1 , T 2 random times spent, respectively, visiting the first document considered, the second one and so on. Therefore, X 0 = i means that the user starts from the first document at rank i and T 0 = t 0 means that they spends t 0 units of time visiting this first document, then X 1 = j means that they visits the document at rank j as the second one, and so on.
 First of all, we will assume that X 0 is a random variable on T = { 1 , 2 ,...,T } with a given distribution  X  =(  X  1 ,..., X  so for any i  X  X  , P [ X 0 = i ]=  X  i . Then, we will assume that the probability to pass from the document at rank i to the document at rank j will only depend on the starting rank i and not on the whole list of documents visited before. This can be formalized as follows: for any n  X  N and i, j, i 0 ,...,i n  X  1  X  X  . Figure 1: Structure of the Markov chain ( X n ) n  X  N .
Thanks to the condition (6) and fixing a starting distribu-tion  X  , the random variables ( X n ) n  X  N define a time homoge-nous discrete time Markov Chain, shown in Figure 1, with state space T , initial distribution  X  and transition matrix P =( p i,j ) i,j  X  X  (Markov(  X  ,P) in the sequel).
To obtain a continuous-time Markov Chain, we have to assume that the holding times T n have all exponential dis-tribution, i.e.
 Furthermore, conditioned on the fact that X n = i ,thelaw of T n will be exponential with parameter  X  i ,where  X  i is a positive real number that may depend on the specific state i of the chain the user is visiting at that time.
When our interest is only on the jump chain ( X n ) n  X  N i.e. when we are interested in extracting the corresponding discrete-time Markov chain to act as a traditional evaluation measure, we simply assume that all these variables are expo-nential with parameter  X  = 1. When we are also interested in the time dimension, we have to provide a calibration for these exponential variables. We report a very simple exam-ple in Section 5 using click logs from Yandex.

The reason for choosing such a model will be immediately clear. Let us assume hereafter that the matrix P will be irreducible. This means that we can move in a finite number of steps from any document to any other document with positive probability. Thanks to (6) and the multiplication rule, the probability to pass in n steps from the document i to the document j is equal to p ( n ) i,j ,the( i, j ) entry of the matrix P n and the irreducibility means that given any pair probability distribution of any random variable X n ,which denotes the rank of the document visited after n movements, is completely determined by  X  and P ,since Given such a model, we assume that a user will visit a num-ber n of documents in the list and then they will stop their search. In order to measure their satisfaction, we will eval-uate the average of the precision of the ranks of the judged relevant documents visited by the user during their search as where ( Y n ) n  X  N denotes the sub-chain of ( X n ) n  X  N siders just the visits to the judged relevant documents at ranks R , and shown in Figure 2. Figure 2: Structure of the sub-Markov chain ( Y n ) n  X  N (relevant documents are shown in grey; not relevant ones in white).

Note that this sub-chain has in general a transition ma-trix different form P . The new transition matrix P can be computed easily from P by solving a linear system as de-tailed in [23] and discussed in Section 4.3.1. Note that P computed in this way somehow  X  X bsorbs X  and takes into ac-count also the probabilities of passing through not relevant documents (which are basically redistributed over the rele-vant ones) and makes it different from the transition matrix that you would have obtained by using only the relevant documents since the beginning.

Clearly the previous quantity is of little use if evaluated at an unknown finite step n . However, the Ergodic The-orem of the theory of the Markov processes is perfect for approximating this quantity:
Theorem 1. Let P be irreducible,  X  be any distribution and R finite. If ( Y n ) n  X  0 is Markov(  X  , P ), then for any func-tion f : R X  R we have where f = i  X  X   X  i f ( i ) and  X  is the invariant distribution of P .
 The importance of this class of theorems is clear: almost surely and independently of the initial distribution  X  ,we can approximate, for n large, the average over the time by the (much simpler) average over the states of the Markov chain. Indeed, under the previous assumptions it is possible to prove that the matrix P admits a unique invariant distri-bution, i.e a probability distribution  X  such that if ( Y is Markov(  X  , P ), then for any n Moreover, the invariant distribution in this case is the unique left eigenvector of the eigenvalue 1 of the matrix P , i.e. the unique solution of the linear equation
Remark 1. Under additional hypotheses, it can be pro-ved that the invariant distribution itself is the limit of any row of the matrix P n ,as n  X  X  X  , useful result in order to evaluate in practice the invariant distribution. The conver-gence is generally very fast and for n =10 we already have a reasonable approximation of the true value of  X  .Thisjus-tifies the use of MP to approximate the mean precision of the usually few documents visited by a user.

We can now define a new family of user oriented retrieval effectiveness measures, called Markov Precision (MP) ,which depends on the specific user model and the invariant distri-bution derived.

Definition 1. Given a ranked list of retrieved documents, defined by R the ranks of its judged relevant documents and defined a Markov (  X  ,P) user model, the Markov Precision metric will be defined as where Prec ( n ) represent the Precision at n and  X  the (unique) invariant distribution of the Markov chain ( Y n ) n  X  N .
MP is defined without knowing the recall base RB of a given topic, but just the ranks of the judged relevant doc-uments in a given run for this topic. As pointed out, for example in [22], the need to know the value of RB repre-sents a weakness in AP that is overcome here.
 In order to include the time dimension and thanks to the Ergodic Theorem for the continuous time Markov chains, we can replicate the previous computations and define a new measure distribution of the Markov chain ( Y n ) n  X  N and  X  i is the pa-rameter of the holding time in state i . To use this alternative measure, we have to provide a calibration for the coefficients  X  i and we will compare MP with MPcont in a very simple example in Section 5 using click logs from Yandex. In order to define a simple Markovian user model, whose MP value will be AP, let us consider the following transition probabilities among the documents in a given ranked list: for any i, j  X  X  , i = j , and where, again, T denotes the cardinality of the set T .

In this model we assume that a user moves from a docu-ment to another document with a fixed, constant probability, the value of which depends on the total number of relevant documents present in the specific run.

Since the invariant distribution is 1 T , 1 T ,..., 1 T we obtain that which is equal to AP once multiplied by T RB . Note that if we create the Markov chain starting directly from the rele-vant documents R we have to multiply MP by Rec ( T )asin equation 3. In this way, we explain AP with a slightly richer user model, where the user can move forward and backward among any document and is not forced to visit only the rel-evant ones. It is also clear from the equation above that MP is not AP unless you provide it with the same amount of in-formation AP knows about the recall base, namely rescaling MP by the recall base.

Looking at this the other way around, this instantiation of MP (without the rescaling) can be considered a kind of AP where the artificial knowledge of the recall base has been removed and so, it tells us how AP might look like if you remove the dependency on the recall base and insert an ex-plicit user model. This consideration will turn out to be useful in the experimental part when we will find other user models, highly correlated to AP, which may give a richer explanation of it.

Moreover, the previous constant invariant distribution is common to many others user models. For example, if the transition matrix is irreducible and symmetric or even just bistochastic, meaning that the sum of the entries on each column is equal to 1, the invariant distribution is again the above constant vector. In this sense, if the validity of the present Markovian user model is accepted, it shows once more why AP has become a reference point, since it repre-sents a good approximation for a wide class of models that we can define.
We will analyze three possible choices:
We will obtain eight models that we will call after the possible three choices. So, for example, MP GL AD ID is an effectiveness measure with transition probabilities among all the retrieved documents, based on a model on the whole set T , and with transition probabilities proportional to the inverse of the distance of the documents in the ranked list and so on for the other combinations of the parameters.
In the AD case, we consider the whole Markov chain ( X n ) on the whole set T with a given initial distribution  X  and a transition matrix P =( p i,j ) i,j  X  X  and then we derive the subchain ( Y n ) n  X  N on the set R . In order to obtain the in-variant distribution of the subchain, we will have to derive its transition matrix P . It can be proved (see [23]) that this matrix can be defined as follows Table 1: Main features of the adopted data sets.
 where the vector ( h j i ,i  X  X  ) is the minimal non-negative solution to the linear system So, once this linear system is solved, we obtain the transition matrix P needed to compute the Markov Precision for the given model.

In the OR model, we create the Markov Chain ( X n ) n  X  N directly on the set R .
In the GL model, we assume that the transition proba-bilities p i,j &gt; 0 for any choice of i = j .Inthiscasewe will assume that there will be a positive, even if very small, probability to pass from any document in the ranked list to any other. For example, the previous model for Average precision is a GL model
By contrast, in LO we will assume that there exist tran-sition probabilities only among adjacent nodes. This is the same kind of logic behind RBP, even though RBP allows only for forward transitions, and is similar to the strategy of [8] for the two-dimensional placement problem.
In the ID model, we assume that the probability to pass from one document to another one in the ranked list is pro-portional to the inverse of the relative distance of these two documents: Denoting by ( s 1 ,...,s m ) the states of the Markov chain, we thus have the following transition probabilities: It is immediately clear that the probabilities (10) define an irreducible transition matrix P of a discrete time Markov Chain on the state space and therefore we can define Markov precision for this model.

In the LID model, we smooth the distance by using the base 10 logarithm so that that transition probabilities do not decrease not too fast. The choice of the base 10 for the logarithm is due to a typical Web scenario focused on the page of the first 10 results.
In order to assess MP and compare it to the other per-tinent evaluation measures (AP, P@10, Rprec, RBP, and Table 2: Kendall  X  correlation between AP and the other comparison measures using complete judg-ments (high correlations marked with *).
 bpref), we conducted a correlation analysis and we studied its robustness to pool downsampling. As far as RBP is con-cerned, we set p =0 . 8, which indicates a medium persistence of the user.

We used the following data sets: TREC 7 Ad Hoc, TREC 8 Ad Hoc, TREC 10 Web, and TREC 14 Robust, whose fea-tures are summarized in Table 1. We used all the topics and all the runs that retrieved at least one document per topic. In the case of collections with graded relevance assessment (TREC 10 and 14), we mapped them to binary relevance with a lenient strategy, i.e. both relevant and highly rele-vant documents have been mapped to relevant ones.
As far as pool downsampling is concerned, we used the same strategy of [4]: it basically creates separate random lists of relevant/not relevant documents and select a given fraction R % of them, ensuring that at least 1 relevant and 10 not relevant documents are in the pool. We used R %= [90, 70, 50, 30, 10].

As far as the calibration of time is concerned, we used click logs made available by Yandex [29] in the context of the Relevance Prediction Challenge 2 . The logs consist of 340,796,067 records with 30,717,251 unique queries, retriev-ing 10 URLs each. We used the training set where there are 5,191 assessed queries which correspond to 30,741,907 records and we selected those queries which appear at least in 100 sessions each to calibrate the time.

The full source code of the software used to conduct the experiments is available for download 3 in order to ease com-parison and verification of the results.
Table 2 reports the Kendall  X  correlation [18] between AP and the other comparison measures, using complete judge-ments, for all the collections. Previous work [33, 34] con-sidered correlations greater than 0.9 as equivalent rankings and correlations less than 0.8 as rankings containing notice-able differences. Table 2 is consistent with previous findings, with a high correlation between AP, Rprec, and bpref and lower correlation values for P@10 and RBP.

Table 3 reports the Kendall  X  correlation between the dif-ferent models for MP, discussed in Section 4.3 and whose notation (GL/LO, AD/OR, ID/LID) is used here as well, and the performance measures of direct comparison, for all the considered collections 4 . For each variant of MP, the ta-ble reports its actual value and also a second row labelled with the suffix @ Rec ( T ) to indicate a rescaled version of http://imat-relpred.yandex.ru/en/ http://matters.dei.unipd.it/ The fact that the values for the LO AD ID and LO AD LID models are the same is not due to a copy&amp;paste error but to the fact that the two chains, in the local model, are the same apart from a constant and so they produce equal rankings.
 MP by recall. Indeed, this is the same operation needed to make MP equal to AP in the case of the model with con-stant transition probabilities discussed in Section 4.2 and corresponds to providing MP with the same level of infor-mation about the recall base that also AP uses. This has a twofold purpose: (i) to determine if there are other models beyond the ones of Section 4.2 which can give us an addi-tional interpretation of AP; (ii) to get a general feeling of what is the impact of injecting information about the recall into an evaluation measure. In the table, we have marked high correlations, those above 0.90, with a star and we have marked extremely high correlations, those above 0.97, with two stars.

As a general trend MP tends not to have high correlations with the other evaluation measures, indicating that it takes a different angle from them. This can be accounted for by the effect of the user model explicitly embedded in MP which, for example, allows the user to move forward and backward in the result list while other measures allow only for sequen-tial scans. On the other hand, the proposed models keep it not too far away from the other measures, especially those around precision (AP, P@10, Rprec), since the correlation never drops below 0.70. This is coherent with the fact that both MP and the other measures (AP, P@10, Rprec) are all around the concept of precision and so they have a common denominator.

Moreover, it can be noted that MP tends to be more cor-related with P@10 and then with Rprec and AP. This is consistent with the fact that MP does not depend on the recall base, as P@10 does, while Rprec implicitly and AP explicitly depend on it.

Finally, the results show a moderate correlation with bpref and a slightly lower one with RBP, whose only common denominator is to not depend on the recall base.

Whit regard to @ Rec ( T ), we can note how they greatly boost the correlation with AP in almost all cases, often mov-ing MP from low to high correlations, and, in turn, increase the correlation with Rprec and bpref (more correlated by themselves to AP) with respect to the one with RBP which tends to decrease.

In particular, there are some cases, like MP GL AD LID or MP LO AD ID, where it jumps between 0.97 and 1.00. We consider this a case in which MP is providing us with an alternative interpretation of AP, in the sense discussed in Section 4.2. For example, MP GL AD LID provided with information about recall tells us that we can look at AP as a measure that also models a user who can move backward and forward among all the documents in the list and who prefers smaller jumps to bigger ones. The fact that we have found a few models so highly correlated with AP suggests that AP has become a gold standard also because it represents some articulated user models.
Figure 3 shows the effect of reducing the pool size on the absolute average performances, over all the topics and runs. For space reasons, we do not report figures for all the possible combinations reported in Table 3 but just some to give the reader an idea of the behavior of MP; the considerations made here are however valid also for the not reported figures.
It can be noted how MP shows consistent behavior over all the collections and for various models: its absolute aver-age values decrease as the pool reduction rate increases in a manner similare to AP and Rprec. Consistently with previ-ous results, P@10 and RBP exhibit a more marked decrease while bpref tends to stay constant. This positive property of bpref is an indicator that it is not very sensible or it does not fully exploit the additional information which is provided when the pool increases. Figure 4 shows the effect of reducing the pool size on the Kendall  X  correlation between each measure on the full pool and the pool at a given reduction rate. The results shown are consistent with previous findings as far as the measures of direct comparison are concerned, showing that bpref is almost always the more robust measure to pool reduction. It is indeed plausible that, keeping bpref the absolute aver-age performances almost constant, also the ranking of the systems does not change much.

As far as MP is concerned, we can note that global models [ GL ], shown in the case of TREC 7, 8 and 10, tend to per-form comparably to AP and, when provided with the same information about the recall base, which both AP and bpref exploit, they consistently improve their performances and, in the case of TREC 8, they outperform AP and perform closely to bpref. This is an interesting result since, unlike bpref, the absolute average performances of MP vary at dif-ferent pool reduction rates, indicating that MP is able to exploit the variable amount of information available at dif-ferent pool reduction rates, still not affecting too much the overall ranking of the systems.

The global models [ GL ] on only relevant documents [ OR ] behave consistently with the global ones on all documents [ AD ], shown in the case of TREC 7 and TREC 10, even if they are a little bit more resilient to the pool reduction. This is consistent with the fact that they use less information than the AD ones and so they are less sensitive to the pool size. The TREC 7 also shows the effect of using the inverse of the distance [ ID ] or the log of the inverse of the distance [ LID ], which provides more robustness to pool reduction.
When it comes to local models [ LO ], these tend to behave comparably to the global ones in the case of all documents [ AD ], as can be noted in the case of TREC 8, while they aremoreaffectedbythepoolreductioninthecaseofonly relevant documents [ OR ], as can be noted in the case of TREC 14.
On the basis of the click logs, 21% of the observed tran-sitions are backward, a fact that validates our assumption that a user moves forward and backward along the ranked list.
To compare the discrete-time version of MP with the con-tinuous-time one, we have considered 3 runs with 5 relevant documents and estimated the parameters of the exponen-tial holding times by the inverse of the sample mean of the time spent by the users visiting these states, multiplied by ( n  X  1) /n .WeusedtheGL AD ID model and the values of discrete-time MP and continuous-time MP are reported in Table 4.

Note that the precisions at each fixed rank n of the first, second and third runs are decreasing and as one expects MP of the three runs is decreasing. However, since the (es-timated) holding times of the first documents in the first run are very low, continuos-time MP is smaller for the first run. This clearly shows that the use of continuous-time MP depends heavily on the calibration of the holding times.
We introduced a new family of measures, called MP, which exploit Markov chains in order to inject different user mod-els and time into precision and which is not dependent on the recall base. This permitted us to overcome some of the traditional criticisms of AP (lack of a clear user model, de-pendence on the recall base) while still offering a measure which is AP when provided with the same amount of infor-mation about the recall base that AP exploits. Moreover, MP goes beyond almost all the evaluation measures allowing for non sequential scanning of the result lists.

We have proposed some basic user interaction models and validated their properties, in terms of correlation to other measures and robustness to pool reduction, thus showing it is as reliable as them. We have also found that some of these models have an extremely high correlation with AP and this can help in providing alternative interpretations of AP in the light of more complex user models and in explaining why AP is a  X  X old standard X  in IR.

MP also bridges the gap between X  X ank-oriented X  X nd X  X ime-oriented X  measures, providing a single unified framework where both viewpoints can co-exist and allowing for direct comparison among the values of the X  X ank-oriented X (discrete-time Markov chain) and  X  X ime-oriented X  (continuous-time Markov chain) versions. We have also provided an example of how time can be calibrated using click logs from Yandex.
Future works concern the investigation of alternative user models able to account also for the number of relevant/not relevant documents visited so far  X  a kind of information which is actually available to a real user  X  by employing a multidimensional Markov chains to not violate the memory-less assumption. A further interesting option would also be to investigate whether click model-based IR measures [9] can be represented via the Markov chain and thus embedded in MP, i.e. whether the transition probabilities of the Markov chain can be learned directly from click-logs, thus leveraging models fully induced by user behaviour.

Another area of interest concerns how to calibrate time into MP: work on click model-based measures can shed some light in this respect and the techniques proposed by [30, 31] for calibrating time with respect to document length can link MP not only to click logs but also to document collections.
An interesting question for the future is whether MP could fit search tasks other than informational ones, such as fact, entity, or attributes focused searches or whether it could also work with other kinds of test collections, such as nugget-based ones [24].

Finally, the robustness of MP could be further investi-gated, for example evaluating how it performs on condensed-lists [27].
 We wish to thank the anonymous reviewers and meta-revie-wers whose comments and discussions helped us in improv-ing the paper and better clarifying some angles of it.
The PREFORMA project 5 (contract no. 619568), as part of the 7th Framework Program of the European Commis-sion, has partially supported the reported work. http://www.preforma-project.eu/ and continuous-time MP.
 [1] J. A. Aslam, E. Yilmaz, and V. Pavlu. The Maximum [2] A. Broder. A Taxonomy of Web Search. SIGIR [3] C. Buckley and E. M. Voorhees. Evaluating Evaluation [4] C. Buckley and E. M. Voorhees. Retrieval Evaluation [5] C. Buckley and E. M. Voorhees. Retrieval System [6] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. [7] B. Carterette. System Effectiveness, User Models, and [8] F. Chierichetti, R. Kumar, and P. Raghavan.
 [9] A. Chuklin, P. Serdyukov, and M. de Rijke. Click [10] C. L. A. Clarke, N. Craswell, I. Soboroff, and [11] C. W. Cleverdon. The Cranfield Tests on Index [12] K. Collins-Thompson and J. Callan. Query Expansion [13] C. Danilowicz and J. Bali  X  nski. Document ranking [14] D. K. Harman. Overview of the Third Text REtrieval [15] D. K. Harman. Information Retrieval Evaluation . [16] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated Gain-Based [17] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and [18] M. G. Kendall. The Treatment of Ties in Ranking [19] J. Lafferty and C. Zhai. Document Language Models, [20] K. T. Maxwell and W. B. Croft. Compact Query [21] A. Moffat, P. Thomas, and F. Scholer. Users Versus [22] A. Moffat and J. Zobel. Rank-biased Precision for [23] J. R. Norris. Markov chains . Cambridge University [24] V. Pavlu, S. Rajput, P. B. Golbus, and J. A. Aslam. [25] S. Robertson. A New Interpretation of Average [26] T. Sakai. Ranking the NTCIR Systems Based on [27] T. Sakai. Alternatives to Bpref. In SIGIR, pages [28] T. Sakai and Z. Dou. Summaries, Ranked Retrieval [29] P . Serdyukov, N. Craswell, and G. Dupret.
 [30] M. D. Smucker and C. L. A. Clarke. Stochastic [31] M. D. Smucker and C. L. A. Clarke. Time-Based [32] I. Soboroff. Dynamic Test Collections: Measuring [33] E. Voorhees. Evaluation by Highly Relevant [34] E. M. Voorhees. Variations in relevance judgments and [35] E. Yilmaz and J. A. Aslam. Estimating Average
