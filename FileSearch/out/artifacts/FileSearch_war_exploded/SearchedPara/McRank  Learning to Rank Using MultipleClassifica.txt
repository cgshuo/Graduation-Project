 Dept. of Statistical Science pingli@cornell.edu or to guide the generation of a list of URLs fed to the dynamic r anker. { 1 , 2 , 3 , ..., n } . We denote the inverse mapping by  X  i =  X  ( i ) =  X   X  1 ( i ) . The DCG score is computed from the relevance levels of the n URLs as where [ i ] is the rank order, and y original (pre-ranked) order. y number of queries and URLs. In this study, we assume these lab els are  X  X old-standard. X  In the definition of DCG, c Suppose a dataset contains N words, the NDCG for the j th query (NDCG where DCG 3.1 Bounding DCG Errors by Classification Errors For a permutation mapping  X  , the error is DCG DCG URLs with the same relevance levels are arbitrarily ranked w ithout affecting DCG corresponding permutation mapping also by g .
 vance level  X  y URLs according to  X  y  X  y Proof: Thus, we can minimize the classification error P n should use other (well-known) surrogate loss functions suc h as (7). 3.2 Input Data for Classification A training dataset contains N  X  X raining data matrix X  of size N  X  P , where N = P N Q learning notation { y in 3.3 From Classification to Ranking convert (imperfect) classification results into ranking sc ores. Recall we assume a training dataset { y We learn the class probabilities p puted the scores S descending order of S When T ( k ) = k , the scoring function S transformation on S 3.4 The Boosting Tree Algorithm for Learning Class Probabil ities
Algorithm 1 implements a boosting tree algorithm for learni ng class probabilities p although the presentation is slightly different. 0:  X  y i,k = 1 , if y i = k , and  X  y i,k = 0 otherwise. 1:
F i,k = 0 , k = 0 to K  X  1 , i = 1 to N 2: For m = 1 to M Do 3: For k = 0 to K  X  1 Do 4: p 5: { R 6:  X  7: F 8: End 9: End We first partition the training data points into two groups: { y multiple classification. Thus we can learn Pr ( y learn Pr ( y data are { y the response values 2 y i  X  1 .
 Algorithm 3] by replacing the ( l considerably worse than the least-square tree boost.
 we use them directly as the ranking scores to order the data po ints within each query. 0: 1: 2: For m = 1 to M Do 5: { R 6:  X  7: S 9: End and Web-1 are the same datasets used in [5]. Web-2 is the main d ataset used in [13]. Our experiment showed that LambdaRank improved FRank by about 0.9 ( % ) NDCG on Web-2. 6.1 The Datasets URLs per query, and 10,000/5,000/10,000 queries for train/ validation/test. train/validation/test, with in total 652,500 URLs.
 These unlabeled URLs were assigned the level 0 [13].
 cross-validations and report the average NDCG scores. 6.2 The Parameters: M , J ,  X  J artificial dataset and Web-1, J = 40 for Web-2, and J = 20 for Web-3. M = 2000 for Web-2, and M = 1500 for Web-3. 6.3 The Test NDCG Results at Truncation Level L = 10 datasets and all 4 ranking algorithms, evaluated at the trun cation level L = 10 . high capacity) rankers using boosting tree algorithms tend to fit the data very well. 6.4 The NDCG Results at Various Truncation Levels ( L = 1 to 10 ) L = 10 but also (essentially) true for smaller truncation levels. average NDCG scores. Bottom Panels: the corresponding stan dard deviations. ordinal classification over classification.
 ing quality ranking results.
 Appendix I An Efficient Implementation for Building Boosting Trees and the sorted orders in all other features for the next split . s Appendix II Some More Experiments on Web-1 two different scoring functions.
 ing scores, including the Expected Relevance S P
