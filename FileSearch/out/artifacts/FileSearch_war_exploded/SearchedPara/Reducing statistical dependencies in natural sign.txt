 Signals may be manipulated, transmitted or stored more e ffi ciently if they are transformed to a rep-resentation in which there is no statistical redundancy bet ween the individual components. In the context of biological sensory systems, the e ffi cient coding hypothesis [1, 2] proposes that the princi-ple of reducing redundancies in natural signals can be used t o explain various properties of biological perceptual systems. Given a source model, the problem of der iving an appropriate transformation to remove statistical dependencies, based on the statistic s of observed samples, has been studied for more than a century. The most well-known example is principa l components analysis (PCA), a lin-ear transformation derived from the second-order signal st atistics (i.e., the covariance structure), that can fully eliminate dependencies for Gaussian sources. Ove r the past two decades, a more general method, known as independent component analysis (ICA), has been developed to handle the case when the signal is sampled from a linearly transformed facto rial source. ICA and related methods have shown success in many applications, especially in deri ving optimal representations for natural signals [3, 4, 5, 6].
 Although PCA and ICA bases may be computed for nearly any sour ce, they are only guaranteed to eliminate dependencies when the assumed source model is cor rect. And even in cases where these methodologies seems to produce an interesting solution, th e components of the resulting represen-tation may be far from independent. A case in point is that of n atural images, for which derived ICA transformations consist of localized oriented basis funct ions that appear similar to the receptive field descriptions of neurons in mammalian visual cortex [3, 5, 4] . Although dependency between the responses of such linear basis functions is reduced compare d to that of the original pixels, this reduc-tion is only slightly more than that achieved with PCA or othe r bandpass filters [7, 8]. Furthermore, the responses of ICA and related filters still exhibit striki ng higher-order dependencies [9, 10, 11]. Here, we consider the dependency elimination problem for th e class of source models known as elliptically symmetric densities (ESDs) [12]. For ESDs, li near transforms have no e ff ect on the dependencies beyond second-order, and thus ICA decomposit ions o ff er no advantage over PCA. We introduce an alternative nonlinear procedure, which we cal l radial Gaussianization (RG). In RG, the norms of whitened signal vectors are nonlinearly adjust ed to ensure that the resulting output density is a spherical Gaussian, whose components are stati stically independent. We first show that the joint statistics of proximal bandpass filter responses f or natural signals (sounds and images) are better described as an ESD than linearly transformed factor ial sources. Consistent with this, we demonstrate that the reduction in dependency achieved by ap plying RG to such data is significantly greater than that achieved by PCA or ICA. A preliminary versi on of portions of this work was described in [13]. where  X  is a positive definite matrix, f ( ) is the generating function satisfying f ( )  X  0 and R to one [12]. The definitive characteristic of an ESD is that th e level sets of constant probability are ellipsoids determined by  X  . In the special case when  X  is a multiple of the identity matrix, the level sets of p ( x ) are hyper-spheres and the density is known as a spherically symmetric density (SSD). Assuming x has finite second-order statistics,  X  is a multiple of the covariance matrix, which implies that any ESD can be transformed into an SSD by a PCA / whitening operation.
 When the generating function is an exponential, the resulti ng ESD is a zero-mean multivariate Gaus-sian with covariance matrix  X  . In this case, x can also be regarded as a linear transformation of a vector s containing independent unit-variance Gaussian component s, as: x =  X   X  1 / 2 s . In fact, the Gaussian is the only density that is both elliptically symme tric and linearly decomposable into inde-pendent components [14]. In other words, the Gaussian densi ties correspond to the intersection of the class of ESDs and the class assumed by the ICA methods. As a special case, a spherical Gaussian is the only spherically symmetric density that is also factorial (i.e. , has independent components). These relationships are illustrated in a Venn diagram in Fig . 1.
 Apart from the special case of Gaussian densities, a linear t ransformation such as PCA or ICA cannot completely eliminate dependencies in the ESDs. In particul ar, PCA and whitening can transform an ESD variable to a spherically symmetric variable, x wht , but the resulting density will not be factorial unless it is Gaussian. And ICA would apply an addit ional rotation (i.e., an orthogonal matrix) to transform x wht to a new set of coordinates maximizing a higher-order contra st function (e.g., kurtosis). However, for spherically symmetric x wht , p ( x wht ) is invariant to rotation, and thus una ff ected by orthogonal transformations. Given that linear transforms are ine ff ective in removing dependencies from a spherically symmetr ic variable x wht (and hence the original ESD variable x ), we need to consider non-linear mappings. As described previously, a spherical Gaussian is the only SSD w ith independent components. Thus, a natural solution for eliminating the dependencies in a non-Gaussian spherically symmetric x wht is to transform it to a spherical Gaussian.
 Selecting such a non-linear mapping without any further con straint is a highly ill-posed problem. It is natural to restrict to nonlinear mappings that act radially , preserving the spherical symme-try. Specifically, one can show that the generating function of p ( x wht ) is completely determined by its radial marginal distribution: p r ( r ) = r d  X  1 Gamma function, and  X  is the normalizing constant that ensures that the density in tegrates to one. In the special case of a spherical Gaussian of unit variance, the radial marginal is a chi -density with d degrees of freedom: p (RG) transformation as x rg = g ( k x wht k ) x wht radial marginal density of x wht to the chi -density. Solving for a monotonic g ( ) is a standard one-dimensional density-mapping problem, and the unique solut ion is the composition of the inverse cumulative density function (CDF) of p the procedure is provided in Fig. 2. In practice, we can estim ate F r ( r ) from a histogram computed from training data, and use this to construct a numerical app roximation (i.e., a look-up table) of the continuous function  X  g ( r ). Note that the accuracy of the estimated RG transformation will depend on the number of data samples, but is independent of the dimensi onality of the data vectors. In summary, a non-Gaussian ESD signal can be radially Gaussi anized by first applying PCA and whitening operations to remove second-order dependency (y ielding an SSD), followed by a nonlin-ear transformation that maps the radial marginal to a chi -density. An understanding of the statistical behaviors of source sig nals is beneficial for many problems in signal processing, and can also provide insights into the de sign and functionality of biological sen-sory systems. Gaussian signal models are widely used, becau se they are easily characterized and often lead to clean and e ffi cient solutions. But many naturally occurring signals exhi bit striking non-Gaussian statistics, and much recent literature focus es on the problem of characterizing and exploiting these behaviors. Specifically, ICA methodologi es have been used to derive linear repre-sentations for natural sound and image signals whose coe ffi cients are maximally sparse or indepen-dent [3, 5, 6]. These analyses generally produced basis sets containing bandpass filters resembling those used to model the early transformations of biological auditory and visual systems.
 Despite the success of ICA methods in providing a fundamenta l motivation for sensory receptive fields, there are a number of simple observations that indica te inconsistencies in this interpreta-tion. First, the responses of ICA or other bandpass filters ex hibit striking dependencies, in which the variance of one filter response can be predicted from the a mplitude of another nearby filter re-sponse [10, 15]. This suggests that although the marginal de nsity of the bandpass filter responses are heavy-tailed, their joint density is not consistent with th e linearly transformed factorial source model assumed by ICA. Furthermore, the marginal distributions of a wide variety of bandpass filters (even a  X  X ilter X  with randomly selected zero-mean weights) are all highly kurtotic [7]. This would not be expected for the ICA source model: projecting the local data onto a random direction should result in a density that becomes more Gaussian as the neighborhood s ize increases, in accordance with a generalized version of the central limit theorem [16]. A rec ent quantitative study [8] further showed that the oriented bandpass filters obtained through ICA opti mization on images lead to a surprisingly small improvement in reducing dependency relative to decor relation methods such as PCA. Taken together, all of these observations suggest that the filters obtained through ICA optimization repre-sent a  X  X hallow X  optimum, and are perhaps not as uniquely sui ted for image or sound representation as initially believed. Consistent with this, recently deve loped models for local image statistics model local groups of image bandpass filter responses with non-Gau ssian ESDs [e.g., 17, 18, 11, 19, 20]. These all suggest that RG might provide an appropriate means of eliminating dependencies in natu-ral signals. Below, we test this empirically. 4.1 Dependency Reduction in Natural Sounds We first apply RG to natural sounds. We used sound clips from co mmercial CDs, which have a sampling frequency of 44100 Hz and typical length of 15  X  20 seconds, and contents including animal vocalization and recordings in natural environment s. These sound clips were filtered with a bandpass gammatone filter, which are commonly used to model t he peripheral auditory system [21]. In our experiments, analysis was based on a filter with center frequency of 3078 Hz.
 Shown in the top row of column (a) in Fig.3 are contour plots of the joint histograms obtained from pairs of coe ffi cients of a bandpass-filtered natural sound, separated with di ff erent time inter-vals. Similar to the empirical observations for natural ima ges [17, 11], the joint densities are non-Gaussian, and have roughly elliptically symmetric contour s for temporally proximal pairs. Shown in the top row of column (b) in Fig.3 are the conditional histo grams corresponding to the same pair of signals. The  X  X ow-tie X  shaped conditional distribution , which has been also observed in natural images [10, 11, 15], indicates that the conditional varianc e of one signal depends on the value of the other. This is a highly non-Gaussian behavior, since the con ditional variances of a jointly Gaussian density are always constant, independent of the value of the conditioning variable. For pairs that are distant, both the second-order correlation and the high er-order dependency become weaker. As a result, the corresponding joint histograms show more rese mblance to the factorial product of two one-dimensional super-Gaussian densities (bottom row of c olumn (a) in Fig.3), and the shape of the corresponding conditional histograms (column (b)) is more constant, all as would be expected for two independent random variables .
 As described in previous sections, the statistical depende ncies in an elliptically symmetric random variable can be e ff ectively removed by a linear whitening operation followed b y a nonlinear radial Gaussianization, the latter being implemented as histogra m transform of the radial marginal den-sity of the whitened signal. Shown in columns (c) and (d) in Fi g.3 are the joint and conditional histograms of the transformed data. First, note that when th e two signals are nearby, RG is highly e ff ective, as suggested by the roughly Gaussian joint density ( equally spaced circular contours), and by the consistent vertical cross-sections of the condition al histogram. However, as the temporal sep-aration between the two signals increases, the e ff ects of RG become weaker (middle row, Fig. 3). When the two signals are distant (bottom row, Fig.3), they ar e nearly independent, and applying RG can actually increase dependency, as suggested by the irregular shape of the condi tional densities (bottom row, column (d)). To quantify more precisely the dependency reduction achiev ed by RG, we measure the statistical dependency of our multivariate sources using the multi-information (MI) [22], which is defined as the Kulback-Leibler divergence [23] between the joint dist ribution and the product of its marginals: I ( x ) = D KL p ( x ) k Q k p ( x k ) = P d k ferential entropy of x , and H ( x k ) denotes the di ff erential entropy of the k th component of x . As a measure of statistical dependency among the elements of x , MI is non-negative, and is zero if and only if the components of x are mutually independent. Furthermore, MI is invariant to a ny transformation on individual components of x (e.g., element-wise rescaling).
 To compare the e ff ect of di ff erent dependency reduction methods, we estimated the MI of p airs of bandpass filter responses with di ff erent temporal separations. This is achieved with a non-par ametric  X  X in-less X  method based on the order statistics [24], which alleviates the strong bias and variance intrinsic to the more traditional binning (i.e.,  X  X lug-in X  ) estimators. It is especially e ff ective in this case, where the data dimensionality is two. We computed the M I for each pair of raw signals, as well as pairs of the PCA, ICA and RG transformed signals. The ICA tr ansformation was obtained using RADICAL [25], an algorithm that directly optimizes the MI us ing a smoothed grid search over a non-parametric estimate of entropy.
 The results, averaged over all 10 sounds, are plotted in Fig. 4. First, we note that PCA produces a relatively modest reduction in MI: roughly 20% for small sep arations, decreasing gradually as the separation increase. We also see that ICA o ff ers very little additional reduction over PCA for small separations. In contrast, the nonlinear RG transformation achieves an impressive reduction (nearly 100%) in MI for pairs separated by less than 0 . 5 msec. This can be understood by considering the joint and conditional histograms in Fig. 3. Since the joint d ensity of nearby pairs is approximately elliptically symmetric, ICA cannot provide much improveme nt beyond what is obtained with PCA, while RG is expected to perform well. On the other hand, the jo int densities of more distant pairs (beyond 2 . 5 msec) are roughly factorial, as seen in the bottom row of Fig . 3. In this case, neither PCA nor ICA is e ff ective in further reducing dependency, as is seen in the plot s of Fig. 4, but RG makes the pairs more dependent, as indicated by an increase in MI above that of the original pairs for separation over 2 . 5 msec. This is a direct result of the fact that the data do not a dhere to the elliptically symmetric source model assumptions underlyi ng the RG procedure. For intermediate separations (0 . 2 to 2 msec), there is a transition of the joint densities from elliptically symmetric to factorial (second row in Fig. 3), and ICA is seen to o ff er a modest improvement over PCA. We found qualitatively similar behaviors (right column in Fig . 4) when analyzing pairs of bandpass filter responses of natural images using the data sets described in the next section. 4.2 Dependency Reduction in Natural Images We have also examined the ability of RG to reduce dependencie s of image pixel blocks with lo-cal mean removed. We examined eight images of natural woodla nd scenes from the van Hateren database [26]. We extracted the central 1024  X  1024 region from each, computed the log of the in-tensity values, and then subtracted the local mean [8] by con volving with an isotropic bandpass filter that captures an annulus of frequencies in the Fourier domai n ranging from  X / 4 to  X  radians / pixel. We denote blocks taken from these bandpass filtered images as x raw . These blocks were then trans-formed with PCA (denoted x pca ), ICA (denoted x ica ) and RG (denoted x rg ). These block data are of significantly higher dimension than the filter response pa irs examined in the previous section. For this reason, we switched our ICA computations from RADIC AL to the more e ffi cient FastICA algorithm [27], with a contrast function g ( u ) = 1  X  exp(  X  u 2 ) and using the symmetric approach for optimization.
 We would like to compare the dependency reduction performan ce of each of these methods using multi-information. However, direct estimation of MI becom es di ffi cult and less accurate with higher data dimensionality. Instead, as in [8], we can avoid direct estimation of MI by evaluating and comparing the di ff erences in MI of the various transformed blocks relative to x raw . Specifically, we  X 
I rg = I ( x raw )  X  I ( x rg ). Full details of this computation are described in [13]. Shown in Fig.5 are scatter plots of  X  I pca versus  X  I ica (red circles) and  X  I rg (blue pluses) for various block sizes. Each point corresponds to MI computation over b locks from one of eight bandpass-filtered test images. As the figure shows, RG achieves signific ant reduction in MI for most images, and this holds over a range of block sizes, whereas ICA shows o nly a very small improvement relative to PCA 1 . We again conclude that ICA does not o ff er much advantage over second-order decorrelation algorithms such as PCA, while RG o ff ers significant improvements. These results may be attributed to the fact that the joint density for local pix el blocks tend to be close to be elliptically symmetric [17, 11]. We have introduced a new signal transformation known as radi al Gaussianization (RG), which can eliminate dependencies of sources with elliptically symme tric densities. Empirically, we have shown that RG transform is highly e ff ective at removing dependencies between pairs of samples in band-pass filtered sounds and images, and within local blocks of ba ndpass filtered images.
 One important issue underlying our development of this meth odology is the intimate relation be-tween source models and dependency reduction methods. The c lass of elliptically symmetric densi-ties represents a generalization of the Gaussian family tha t is complementary to the class of linearly transformed factorial densities (see Fig. 1). The three dep endency reduction methods we have dis-cussed (PCA, ICA and RG) are each associated with one of these classes, and are each guaranteed to produce independent responses when applied to signals dr awn from a density belonging to the corresponding class. But applying one of these methods to a s ignal with an incompatible source model may not achieve the expected reduction in dependency ( e.g., applying ICA to an ESD), and in some cases can even increase dependencies (e.g., applyin g RG to a factorial density). Several recently published methods are related to RG. An ite rative Gaussianization scheme trans-forms any source model to a spherical Gaussian by alternatin g between linear ICA transformations and nonlinear histogram matching to map marginal densities to Gaussians [28]. However, in gen-eral, the overall transformation of iterative Gaussianiza tion is an alternating concatenation of many linear / nonlinear transformations, and results in a substantial di stortion of the original source space. For the special case of ESDs, RG provides a simple one-step pr ocedure with minimal distortion. Another nonlinear transform that has also been shown to be ab le to reduce higher-order dependen-cies in natural signals is divisive normalization [15]. In t he extended version of this paper [13], we show that there is no ESD source model for whose dependencies can be completely eliminated by divisive normalization. On the other hand, divisive normal ization provides a rough approximation to RG, which suggests that RG might provide a more principled justification for normalization-like nonlinear behaviors seen in biological sensory systems.
 There are a number of extensions of RG that are worth consider ing in the context of signal repre-sentation. First, we are interested in specific sub-familie s of ESD for which the nonlinear mapping of signal amplitudes in RG may be expressed in closed form. Se cond, the RG methodology pro-vides a solution to the e ffi cient coding problem for ESD signals in the noise-free case, and it is worthwhile to consider how the solution would be a ff ected by the presence of sensor and / or chan-nel noise. Third, we have shown that RG substantially reduce s dependency for nearby samples of bandpass filtered image / sound, but that performance worsens as the coe ffi cients become more sep-arated, where their joint densities are closer to factorial . Recent models of natural images [29, 30] have used Markov random fields based on local elliptically sy mmetric models, and these are seen to provide a natural transition of pairwise joint densities fr om elliptically symmetric to factorial. We are currently exploring extensions of the RG methodology to such global models. And finally, we are currently examining the statistics of signals after loc al RG transformations, with the expectation that remaining statistical regularities (e.g., orientati on and phase dependencies in images) can be studied, modeled and removed with additional transformati ons.

