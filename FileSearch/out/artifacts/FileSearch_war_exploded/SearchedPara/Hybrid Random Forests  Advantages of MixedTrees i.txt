
Baoxun Xu 1 , Joshua Zhexue Huang 2 , Graham Williams 2 , Mark Junjie Li 2 , Random forests [1,2] are a popular classification method which builds an ensem-C4.5 [3] or CART [4], but only one type was exploited within a single random forest. In recent years, random forests ha ve attracted increasing attention due to (1) its competitive perfo rmance compared with other classification methods, especially for high-dimensional data, (2) algorithmic intuitiveness and simplic-ity, and (3) its most important capability - X  X nsemble X  using bagging [5] and stochastic discrimination [2].

The most popular forest construction procedure was proposed by Breiman [1], novelly using bagging to generate training data subsets for building individual trees. A subspace of features is then randomly selected at each node to grow branches of a decision tree. The trees are then combined as an ensemble into a random forest [1].

In the literature, different types of d ecision trees algorithms have been pro-posed, including C4.5, CART and CHAID [6]. Each type of decision tree algo-rithms employs a different tree building process and captures different discriminative information.

Random forests gain some of their performance advantage through the diver-sity of the trees in the resulting ensemble. We can add another kind of diversity to the random forest framework by removing any potential bias from using a single type of decision tree. We propose t o use several different types of decision trees for each training data subset, and select the best tree as the individual tree classifier in the random forest model.

Our method is motivated by the experie nces of foresters in dealing with the development and care of hybrid forest s. An important concept in Forestry is that of a  X  X ybrid forest. X  Such a forest uses multiple tree species as a mixed planting in accordance with soil structur e (moisture, nutrients, acidity). This method has demonstrated highly econo mic, ecological and practical value in forestry research. Mimicing this idea, we have developed a hybrid random forest method to explore whether we can further enhance the classification performance of a random forest ensemble classifier. Specifically, we build three different types of tree classifiers (C4.5, CART and CHAID) for each training data subset. We then evaluate the performance of the thr ee classifiers and select the best tree. In this way, we build a hybrid random forest which may include different types of decision trees in the ensemble. The a dded diversity of the decision trees can effectively improve the accuracy of each tr ee in the forest, and hence the accuracy of the ensemble.

To demonstrate the effectiveness of our proposed method, we apply it to the popular application of text classification. With the ever-increasing volume of text data from the Internet, databases, and archives, text categorization has become a key technique for handling and organizing text data. It has received growing attention in recent years. A set o f popular and mature machine learn-ing approaches have been deployed for categorizing text documents, including random forests [8], support vector machines (SVM) [9], naive Bayes (NB) [10], k-nearest neighbors (KNN) [11], and decision trees. Due to algorithmic simplic-ity and prominent classification performance for high dimensional data, random forests have become a preferred method.

In this paper, we compare the performance of our random forest with that of other three random forest methods, i.e., C4.5 random forest, CART random for-est and CHAID random forest, and other three mainstream text categorization methods, i.e., support vector machines, naive Bayes and k-nearest neighbors, on six datasets. The experimental results show that our hybrid random forest achieves improved classification perfo rmance over these six compared methods.
The rest of this paper is organized as fo llows. Section 2 introduces the frame-work for building a hybrid Random Forest, and gives a brief analysis of the method. The evaluation methods are presented in Section 3, we present exper-imental results in Section 4. Our conclu sions and future work are presented in Section 5.
 In this section, we introduce a general framework for building hybrid random forests. We then briefly review three types of decision tree algorithms, i.e., C4.5, CART and CHAID. We also present our hybrid random forest algorithm that integrates the best trees from the differ ent types of decision tree algorithms. 2.1 Framework for Building Hybrid Random Forest As an ensemble learner, the performance of a random forest is highly dependent on two factors: the diversity among th e trees and the accuracy of each tree [12]. Diversity is commonly obtained by using bagging and random subspace sampling. We introduce a further element of diversity by using different types of trees.

Continuing our analogy with forestry, the different data subsets from bagging represents the  X  X oil structures. X  Different decision tree algorithms represent  X  X if-ferent tree species X . Our approach has tw o key aspects: one is to use three types of decision tree algorithms to generate t hree different tree classifiers for each training data subset; the other is to evaluate the accuracy of each tree as the measure of tree importance. In this paper, we use the out-of-bag accuracy to assess the importance of a tree.

Following Breiman, we use bagging to generate a series of training data subsets from which we build trees. For each tree, the data subset used to grow the tree is called the  X  X n-of-bag X  (IOB) data and the remaining data subset is called the  X  X ut-of-bag X  (OOB) data. Since OOB data is not used for building trees we can use this data to objectively evaluate eac h tree X  X  accuracy and importance. The OOB accuracy gives an unbiased estim ate of the true accuracy of a model.
Given n instances in a training dataset D and a tree classifier h k ( IOB k ) built from the k X  X h training data subset IOB k , we define the OOB accuracy of the tree h k ( IOB k )foreach di  X  D as: where I(.) is an indicator function. The larger the OOBAcc k , the better classi-fication quality a tree has.

We use the out-of-bag data subset OOB i to calculate the out-of-bag accuracies of the three types of trees (C4.5, CART and CHAID) with evaluation values A 1 , A 2 and A 3 respectively.
 Fig. 1 illustrates the procedure for building a hybrid random forest model. Firstly, a series of IOB/OOB datasets are generated from the entire train-ing dataset by bagging. Then, three types of tree classifiers (C4.5, CART and CHAID) are built using each IOB dataset. The corresponding OOB dataset is used to calculate the OOB accuracies of th e three tree classifiers. Finally, we select the tree with the highest OOB accu racy as the final tree classifier, which is included in the hybrid random forest.
Building a hybrid random forest model in this way will increase the diversity among the trees. The classification performance of each individual tree classifier is also maximized. 2.2 Decision Tree Algorithms The core of our approach is the diversity of decision tree algorithms in our random forest. Different decision tree algorithms grow structurally different trees from the same training data. Selecting a good decision tree algorithm to grow trees for a random forest is critical for th e performance of the random forest. Few studies have considered how different d ecision tree algorithms affect a random forest.Wedosointhispaper.
 The common decision tree algorithms are as follows: Classification Trees 4.5. (C4.5) is a supervised learning classification algo-rithm used to construct deci sion trees. Given a set of pre-classified objects, each described by a vector of attribute values, we construct a mapping from attribute values to classes. C4.5 uses a divide-and-conquer approach, which is similar to re-cursive partitioning, to grow decision trees. C4.5 selects the test that maximizes the information gain ratio (IGR) [3].
 Classification and Regression Tree. (CART) is a recursive partitioning method that can be used for both regression and classification. Beginning with the entire dataset, a tree is constructed by splitting subsets of the dataset by considering all predictor variables for splitting. The best predictor is chosen at each node using a variety of impurity or diversity measures. The goal is to produce subsets of the data which are homogeneous with respect to the target variable [4]. The main difference between C4.5 and CART is the test selection and evaluation process.
 Chi-squared Automatic Interaction Detector. (CHAID) method is based on the chi-square test of association. A CHAID decision tree is constructed by repeatedly splitting subsets of the space into two or more nodes. To determine the best split at any node, any allowable pair of categories of the predictor variables is merged until there is no statistically significant difference within the pair with respect to the target variable [6,7].

From these decision tree algorithms, we can see that the difference lies in the way to split a node, such as the split functions and binary branches or multi-branches. In this work we use these differ ent decision tree algorithms to build a hybrid random forest. 2.3 Algorithm In this subsection, we present our hybrid random forest algorithm which inte-grates the three types of tree classifiers. The detailed steps are introduced in Algorithm 1.

In Algorithm 1, lines 10-17 loop to build K decision trees. In the loop, Line 11 samples the training data D by sampling with replacement to generate an in-of-bag data subset IOB i for building a decision tree. Lines 12-15 build three types of tree classifiers (C4.5, CART and CHAID). In this procedure, Line 13 out-of-bag accuracy of the tree classifie r. After this procedure, Line 16 selects the tree classifier with the maximum out-of-bag accuracy. K decision trees are thus generated to form a hybrid random forest model M .

Generically, function createT ree j () first creates a new node. Then, it tests the stopping criteria to decide whether to return to the upper node or to split this node. If we chose to split this node, then we randomly select m features as a subspace for node splitting. These features are used as candidates to generate the best split to partition the node. For each subset of the partition, createT ree j () is called again to create a new node under the current node. If a leaf node is created, it returns to the parent node. This recursive process continues until a full tree is generated. We use two measures to evaluate the classification performance of the hybrid random forest, the test accuracy and the F1 metric. The test accuracy measures the performance of a random forest on a separate test dataset. The F1 metric is a commonly used measure of cl assification performance. Algorithm 1. Hybrid Random Forest Algorithm 1: Input: 2: -D : the training dataset, 3: -A : the features space { A 1 ,A 2 , ..., A M } , 4: -Y : the class features space { y 1 ,y 2 , ..., y q } , 5: -K : the number of trees, 6: -m : the size of subspaces. 8: Output: A random forest M ; 9: Method: 10: for i =1 to K do 11: draw a bootstrap sample in-of-bag data subset IOB i and out-of-bag data 12: for j =1 to 3 do 13: h i,j ( IOB i )= createT ree j (); 14: use out-of-bag data subset OOB i to calculate the out-of-bag accuracy 15: end for 16: select h i ( IOB i ) with the highest out-of-bag accuracy OOBAcc i as best 17: end for 20: Function createTree() 21: create a new node N ; 22: if stopping criteria is met then 23: return N as a leaf node; 24: else 25: randomly select m features as a subspace; 26: use these m features as candidates to generate the best split for the node 27: call createTree() for each split; 28: end if 29: return N ; Test Accuracy. Let D t be a test dataset and Y t be the class labels. Given d  X  D The test accuracy is calculated as where n is the number of objects in D t and y i indicates the true class of d i . F1 Metric. To evaluate the performance of cl assification methods in dealing with an unbalanced class distribution, we use the F1 metric introduced by Yang and Liu [13]. This measure is equal to the harmonic mean of recall (  X  )and precision (  X  ). The overall F1 score of the enti re classification problem can be computed by a micro-average and a macro-average.
 Micro-averaged F1. This is computed globally over all classes, and emphasizes the performance of a classifier on common classes. Define  X  and  X  as follows: where q is the number of classes. TP i (True Positives) is the number of objects correctly predicted as class i , FP i (False Positives) is the number of objects that are predicted to belong to class i but do not. The micro-averaged F1 is computed as: Macro-averaged F1. This is first computed locally over each class, and then the average over all classes is taken. It e mphasizes the performance of a classifier on rare categories. Define  X  and  X  as follows: F 1 for each category i and the macro-averaged F1 are computed as:
The larger the MicroF1 and MacroF1 values are, the better the classification performance of the classifier. In this section, we conduct experiments to demonstrate the effectiveness of the hybrid random forest algorithm for classifying text data. Text datasets with var-ious sizes and characteris tics are used in the experiments. The experimental results show that the hybrid random forest algorithm not only outper-forms single-tree type random forest algorithms, i.e., C4.5 RF, CART RF and CHAID RF, in classification accuracy, but also outperforms other three mainstream text categorization methods, i.e., SVM, NB and KNN. 4.1 Datasets In the experiments, we used six real-world text datasets. These text datasets are selected due to their diversities in the n umber of terms or features, the number of documents, and the number of classes. Their dimensionalities vary from 2000 to 11,465, numbers of instances vary from 918 to 11,162 and the minority class rate varies from 0.32% to 6.43%. In each text dataset, we randomly select 70% of documents as the training dataset, and the remaining data as the test dataset. Detailed information of the six text datasets is listed in Table 1.

These datasets are frequently used as text document classification bench-mark data [14]. Dataset Fbis was compiled from Foreign Broadcast Information Service TREC-5 [15]. The datasets Re0 and Re1 were selected from Reuters-21578 text categorization test collection Distribution 1.0 [16]. Datasets Oh5 and Ohscal are from the OHSUMED subset of the MEDLINE database [17]. Wap is from the WebACE project (WAP) [18]. 4.2 Test Accuracy Improvement The purpose of this experiment is to evaluate the effect of the hybrid random forest method on accuracy. The six tex t datasets were analyzed and results were compared with other three random forest methods (C4.5 RF, CART RF and CHAID RF). For each text dataset, we ran each random forest algorithm against different sizes of feature subspaces. Since the number of features in these datasets was very large, we started with a subspace of 15 features and increased the subspace with 5 more features each time. For a given subspace size, we built 100 trees for each random forest model. I n order to obtain a stable result, we built 80 random forest models for each subspace size, each dataset and each algorithm, and computed the averages of the test accuracy as the final result for comparison.

Fig. 2 shows the plots of the average test accuracy of the four random for-est models in different sizes generated with the four methods from the six text datasets. For the same number of features, the higher the accuracy, the better the result. From these figures, we can observe that the hybrid random forest algorithm consistently performs better than the other three random forest algo-rithms. The advantages are more obvious in the smaller subspaces. The hybrid random forest algorithm quickly achie ves high accuracy as the subspace size increases. The other thre e random forest algorithms require larger subspaces to achieve a similar accuracy. These results illustrate that the hybrid random forest algorithm outperforms the other three random forest algorithms in the classification accuracy results on all the six text datasets.

To further investigate the performance of the hybrid random forest, we com-puted the average accuracy of the trees in each single-type random forest. This is compared to the average accuracy of thetreesofthesametypewithinthe one hybrid random forest. In all comparisons, the subspace size of was used, where M is the total number of features in the dataset. The results are shown in Table 2. For example, for tree type C4.5 and dataset Fbis, the average accuracy of all trees from the random forest built using C4.5 (named as C4.5 RF) is 0.6379. The average accuracy of all C4.5 trees from the hybrid random forest (named as Hybrid RF) is 0.6489. It is clearly seen in Table 2 that tree classifiers of any given type in our hybrid random forest always have higher average classification accuracy than those using only trees of the same one type. 4.3 Performance Comparisons of other Text Classification Method We conduct a further experimental compa rison against other three widely used text categorization methods, i.e., support vector machines (SVM), Naive Bayes (NB), and k-nearest neighbor (KNN). The SVM uses a linear Kernel with a regularization parameter of 0.03125, which is often used in text categorization. For Naive Bayes, we adopted the multi-variate Bernoulli event model that is fre-quently used in text classification [19]. For k-nearest neighbor (KNN), we set the number of neighbors as 13. In the experiments, we use WEKA X  X  implementation for these three text classification methods [20]. We use a single subspace size of 90 features in all the six datasets to run the random forest algorithms, which provides a consistent result as shown in Fig. 2. In order to obtain stable results, we built 20 random forest models for each random forest algorithm and each dataset, and present the average results, we can see that the range of values are less than  X  0 . 005 and the hybrid trees are always more accurate.

The comparison results are listed in Fig. 3, 4 and 5. While the improvement is often quite small, there is always an improvement demonstrated. We observe that our proposed method always outperforms the compared mainstream text categorization methods. We have presented a new hybrid random forest algorithm which increases di-versity amongst the ensemble of trees by choosing different tree algorithms. We demonstrate the advantage of our method in categorization. Our algorithm con-sistently improves classification perform ance. In the future work, we will consider alternative options for combining the three types of trees, rather than using the simple approach of keeping just one tree. For example, the results from the three trees might be combined into a single decisi on. Finally, alternative decision tree algorithms, or even other types of model builders, will be considered within this hybrid framework.
 Acknowledgements. This research is supported in part by Shenzhen New Industry Development F und under grant No.CXB201005250021A.
