 The aim of document clustering is to organize a collection of documents into sep-arate clusters, so that documents within one cluster are as similar to each other as possible, while documents in a cluster are as dissimilar as possible from those in the other clusters. Document clustering has many important applications in in-formation retrieval; for example, search result clustering to improve information presentation to user, or clu ster-based retrieval for mo re efficient search. Over the years, there have been countless number of c lustering algorithms being proposed. They come from different scientific backgrounds, and employ various techniques and approaches. Some examples of up-to-date development are von Mises-Fisher model-based clustering [1], bipartite graph-based [3], non-negative matrix fac-torization [16] or co-clustering on manifolds [8]. However, after more than half a century since its introduction, the elementary k -means is still regarded as one of the top 10 algorithms in dat a mining today [15]. One recent scientific discussion suggests that practitioners in the field prefer to use k -means as their favourite clustering algorithm [9]. Perhaps, despite many of its drawbacks, the reasons for its immense popularity are its simplicity, understandability and scalability.
In general, a formal approach to clustering is to consider it as an optimiza-tion problem. An optimal partition is one that optimizes a particular criterion function of similarity or distance among data. Essentially, clustering solutions de-pend greatly on how this similarity measure is defined, and whether the specified measure suits the intrinsic structure of data. In the original k -means, for exam-ple, it is the sum-of-squared-error criterion, which uses Euclidean distance. For very sparse and high-dimensional domains such as document clustering, spher-ical k -means, which replaces Euclidean distance by cosine similarity, is more suitable than the standard k -means [4]. Banerjee et al. [2] introduced a class of distance measures, called Bregman divergences, which have attracted a lot of at-tentions. Particularly, KL-divergence, a special case of Bregman divergence, was reported to provide good results on large text datasets. These research findings reveal to us that the nature of similarity measure plays a very important role in the success or failure of a clu stering method. More intere stingly, non-Euclidean and non-metric measures can be informative for statistical learning of data [12]. There has also been argument that the symmetry and non-negative assumption of similarity measures is a limitation of current approaches to clustering [13]. The above observations are the motivation for our work reported in this paper. Firstly, our main objective is to derive a novel method for measuring similarity between data objects. Our application domain is sparse and high-dimensional data, particularly text doc uments. Secondly, we formulate clustering criterion functions which lead to high-quality, fast and scalable algorithms. In [18], Zhao and Karypis presented their work on hierarchical clustering algo-rithms for document datasets. Their conclusion was that partitional methods were more effective and efficient than agglomerative ones. These methods were basically developed based on optimizing a set of criterion functions. This set included graph-based edge-cutting functions, intra-cluster similarity measures, inter-cluster dissimilarity measures and combinations of both types of measure. They also compared the performance of these criterion functions in partitional clustering of large document datasets [17]. All of these methods were imple-mented into a complete software package called CLUTO [10]. CLUTO is well-known because while providing high quality document clustering solutions, it is very efficient computationally. One of it s recent applications is, for example, in job information retrieval based on document similarity [14].

In this paper, we review CLUTO X  X  partitional clustering functionality with four of its best criterion functions. These four criteria, summarized in Table 1, were reported in the literature that they produced good clustering results [17], with H 2 being the best overall. In Table 1, d represents a document vector. In document clustering, documents are often represented in vector space model. When a collection S of n documents has a total of m terms, each document is considered as an m -dimensional vector. The vect ors are weighted by standard Term Frequency-Inverse Document Frequency (TF-IDF) scheme, and normalized to have unit length, i.e. d = 1. When partitioned into k clusters, the subset of documents in cluster r is denoted by S r . D = d of all the documents, and D r = d C = D/n is the centroid vector of all the documents, while C r = D r /n r is the centroid vector of cluster r , n r = | S r | .

Among the four criterion functions, I 2 had been popular in text clustering domain, whereas the other three were proposed by Zhao and Karypis. I 2 is actually equivalent to the objective function of Spherical k -means algorithm [4]. Its goal is to maximize the sum of similarities between document vectors and centroid vector of the cluster that they are assigned to. While I 2 is an internal criterion, E 1 is an external one, due to the fact that it aims to minimize the similarity between each cluster X  X  centroid and the centroid of the entire collection. Before summed up, the similarities are weighted by corresponding cluster sizes. H 1 and H 2 are categorized as hybrid criterion functions, since they are formulated by dividing I 1 and I 2 by E 1 respectively. I 1 = k r =1 D r 2 /n r is another internal criterion similar to I 2 , but because its clustering performance was shown to be pretty poor [17], we choose not to include it in our comparison.
In all the above criterion functions, similarity of two documents, Sim ( d i ,d j ), is defined as the cosine of the angle between the corresponding vectors. Since the vectors are of unit length, this is equal to their dot-product: In the next section, we propose a novel way to evaluate similarity of documents, and consequently formulate new criterion functions for document clustering. 3.1 Our Novel Similarity Measure The similarity measure in Eq. (1) can be rewritten as follows without affecting its meaning: where 0 is vector 0 representing the origin point. According to Eq. (2), we deter-mine the similarity of documents d i and d j by the angle between the two points when looking from the origin. Thus, this is based on just one reference point.
To construct a new concept of similarity, our idea is simple: if we look at the two points from a set of different positions, we may have a better judgment of how close or distant they are. This is applicable to everything in real life, too. For example, before giving a decision to any problem, it is always necessary to approach the problem from different per spectives to have a more comprehensive understanding of the problem itself. When looking at an object, for instance a building, we will have a clearer picture of it if we stand to view it from different angles. In the vector-space model, if we stand at not the origin but a third point d , the directions and distances from this viewpoint to d i and d j will be presented by the difference vectors ( d i  X  d h )and( d j  X  d h ). By applying this idea, we define a new similarity measure for two documents in a cluster as follows: According to this equation, similarity of two documents in the same cluster is defined as the average of similarities measured with respect to all other docu-ments that do not belong to that cluster. Hence, similarity here is defined in close relation to the clustering problem. On the one hand, the two objects of the measure must be in the same cluster. On the other hand, the points from where to establish this measure must be outside the cluster. There is a presumption of cluster memberships prior to the measure. If we further define each relative similarity simply as the dot-product of the difference vectors, we have: From a viewpoint d h outside cluster S r , the similarity between two points d i and d j inside this cluster equals to the product of the cosine of the angle looking from d h and the Euclidean distances from d h to each of these two points. Hence, through these distances, Eq. (4) also contains a measure of inter-cluster dissim-ilarity, given that points d i and d j belong to cluster S r ,whereas d h belongs to another cluster. 3.2 The Clustering Criterion Functions Our first criterion function, called I R , aims to maximize the cluster size-weighted sum of average pairwise similarities between documents that have the same cluster label. Let us consider function F , which represents this sum: By applying Eq. (4) for Sim ( d i ,d j ) and expanding the sum of vector products, after some derivation steps, we will be able to obtain: Substituting back into Eq. (5) to give: As n is constant, maximizing F above is equivalent to maximizing: Comparing  X  F to min-max cut graph-based clustering function [5], which is also includedinCLUTOas G 1 [17], it is seen that both of them involve the two terms ||
D r || 2 and D t r D . The former is a measure of intra-cluster similarity, whereas the latter is a form of external measure (sim ilarity between a cluster and the entire document collection). However, while G 1  X  X  objective is to minimize the inverse ratio between these two terms,  X  F aims to maximize their weighted difference. In  X  F , this value for each cluster is weighted again by the inverse of cluster X  X  size, before summed up across the clusters . Such a criterion, similarly to some of CLUTO X  X  functions, is expected to be sensitive to cluster size. Following the formulation of COSA, a well-known subspace clustering algorithm [7], it would be better to have a set of weight factors {  X  r } k 1 , which are simple functions of respective cluster sizes { n r } k 1 , to regulate the distribution of these cluster sizes in clustering solutions. Consequently, we have  X  F become: And if by letting  X  r = n  X  r ,where  X  is some constant called regulating factor,  X   X  [0 , 1], we arrive at the final criterion function I In our experiments, it has been observed that the criterion function yields rela-tively good clustering results when  X   X  (0 , 1).

The principle for formulation of I R is related to that of CLUTO X  X  criterion function I 1 , in the sense that a cluster quality is measured by the average pairwise similarity between documents within that cluster. An alternative approach is to use similarity between each document vect or and its cluster X  X  centroid instead. Based on this ground, our second criterion function, called I V ,isformulatedas follows. Considering objective function G : By expanding the vector product, after some derivation, we will be able to obtain: Substituting back into Eq. (9), we get: Since n is constant and does not affect the optimization problem, maximizing the above function is equivalent to maximizing I V : Comparing I V with CLUTO X  X  criterion function H 2 ,wenoticethatbothofthem take in two terms D r and D t r D/ D r . Though, while H 2 is simply the ratio of two other criterion functions I 2 and E 1 , I V calculates the weighted difference between these two terms for each of the c lusters before summing them up. This variation brings about the distincti ons in clustering performance between I V and H 2 , since it affects how documents are moved from one cluster to another during the optimization process. 3.3 Optimization Algorithm Our goal is to perform document clustering by optimizing criterion functions I R and I V in Eq. (8) and (10). To achieve this, we utilize the sequential and incre-mental version of k -means, which is guaranteed to converge to a local optimum [6,17]. This algorithm consists of a number of iterations: initially, k seeds are selected randomly and each document is assigned to cluster of its closest seed based on cosine similarity; in each of the subsequent iterations, the documents are picked in random order and, for each document, a move to a new cluster takes place if such move leads to an increase in the objective function. Particu-larly, considering that the expression of I V in Eq. (10) depends only on n r and D r , r =1 ,...,k , let us represent I V in a general form: Assume that, at beginning of some iteration, a document d i belongs to a cluster S p that has objective value I p ( n p ,D p ). d i will be moved to another cluster S q that has objective value I q ( n q ,D q ) if the following condition is satisfied: Hence, document d i is moved to a new cluster that gives the largest increase in the objective function, if such an increase exists. The composite vectors of corresponding old and new clusters are updated instantly after each move. If a maximum number of iterations is re ached or no more move is detected, the procedure is stopped.

A major advantage of our clustering functions under this optimization scheme is that they are very efficient computationally. During the optimization process, the main computational demand is from searching for optimum clusters to move individual documents to, and updating composite vectors as a result of such moves. If  X  denotes the number of iterations the algorithm takes, nz the total number of non-zero entries in all documen t vectors, the computational complex-ity required for clustering with I R and I V is approximately O ( nz  X  k  X   X  ). 4.1 Document Datasets There are twenty benchmark document co llections employed in our experiments. Apart from the fifteen datasets used in [17] to demonstrate CLUTO X  X  perfor-mance, we used five m ore collections ( la2 , tr11 , tr12 , tr23 , tr45 )tohaveaneven more thorough examination of the clustering methods. All datasets are available with the CLUTO toolkit. These datasets possess diverse characteristics in terms of number of classes, number of documents and number of words. They were already preprocessed by standard procedures, including stop-word removal and stemming. We further removed words that appear in less than two documents or more than 99.5% of the documents. The documents were then weighted by TF-IDF and normalized to unit vectors. Table 2 summarizes these datasets. 4.2 Experimental Setup and Evaluation Metrics We compare I R and I V with the criteria in Table 1 for their performance in document partitional clustering. For I R , the regulating factor  X  was set at 0.3 throughout the experiments, after we had observed that this was one of the best values. For CLUTO, there is a C library interface freely available [10]. We used this library to run the tests for I 2 , E 1 , H 1 and H 2 with direct k -way incremental algorithm. Zhao and Karypis [17] evaluated these four criterion functions based on entropy and purity for k = 5, 10, 15 and 20. Hence, we repeated their experiments with those numbers of clusters on each datasets. The same numbers of clusters were also used for I R and I V .Asaresult,therewas a total of 480 cases (6 criterion functions, 20 datasets, 4 values of k ). Besides, since both entropy and purity are biased towards larger number of clusters, we resorted to an additional evaluation metric: the normalized mutual information (NMI). It was suggested to be a superior measure to entropy and purity [19]. All three metrics have value within [0,1]. For entropy, the smaller value the better; for purity and NMI, greater value indicates better clustering result.
For each of the 480 cases, 10 runs were carried out and the average entropy, purity and NMI were calculated. Besides, to eliminate the effect of random ini-tialization, each run was set to have 10 trials with different initializations, from which the best result (based on objective function) was selected as the final out-put for that run. This procedure was applied to all the methods in comparison. Due to space limitation, we could not report all individual evaluation values here. We employed the technique used in [17] to present the summarized results over all datasets through relative entropy , relative purity and relative NMI .If I,J  X  X  I R ,I V ,I 2 ,E 1 ,H 1 ,H 2 } , for each pair of dataset S and cluster number k , the relative evaluation measures corresponding to any criterion function I are: where Entropy I,S,k and Purity I,S,k are the entropy and purity resulted from clustering S by I with k . Relative NMI is calculated in similar way to relative purity. Then, according to e ach relative measure, I is the best performer among all criterion functions if it has a value of 1. Otherwise its value is greater than 1; the larger this value is, the worse it has performed. Since the original evaluation measures on different datasets with different cluster numbers can be very diverse, using the relative metrics enables us to average the results over all the examined datasets. Eventually, the final average measures are calculated over all 4 cluster numbers to yield the overall performance. 4.3 Results Table 3 summarizes performance of all the clustering criterion functions based on the three evaluation metrics. The average results over all 20 datasets with the different values of cluster number k , as well as the overall average performances, are shown. For each row of the table, the number in bold and underlined is the best value (closest to 1); the one in bold only is the second best. We observe that I
R and I V consistently outperform the other criterion function s across varied selections of k , under different types of evaluation. In Fig. 1 and Fig. 2, we show the relative NMI performance of the criterion functions, averaged over the numbers of clusters used, on each of the twenty datasets. In the figures, left-to-right in legend corresponds to left-to-right in the plot. It can be noticed that the first and second bars in each subgroup, which represent I R and I V respectively, are frequently the shortest and closest to 1. There are only 2 cases, re0 and tr12 , where both I R and I V are not in the top 2 NMIs. Otherwise, on the rest of the datasets, it appears from the figures X  patterns that our two proposed functions consistently provide better clustering results than the others.
To have a statistical justification for our comparisons above, paired t-tests [11] with 5% significance level were conducted. The outcomes in Table 4 show in most cases, performance improvement by I R and I V over the others is statistically significant. Additionally, we also examined I R  X  X  performance with different  X  values from 0 to 1, over all given datasets with k = 10. In Fig. 3, top-to-bottom in legend corresponds to left-to-right in the plot. As the figure shows, there is little variation regarding purity and NMI when 0 &lt; X &lt; 1. In general, relatively good selections of  X  , applied to all three evaluation metrics, are from 0.2 to 0.8.
Finally, to inspect the appropriateness of the new similarity measure and its clustering algorithms more carefully, another experiment was carried out. Cluster assignment output from Spherical k -means (i.e. I 2 ), which uses cosine similarity, was further optimized by I R and I V . If such refinement made by I R and I V leads to improved result, the proposed measure and methods are potentially more suitable for the clustering proble m. We denote these refinement schemes as rI R and rI V . For comparison, besides Spherical k -means (sp k means), we also included the original methods I R and I V (with random initializations), CLUTO X  X  graph method with cosine similarity (graphCS) and with extended Jaccard similarity (graphEJ), and the Min-Max Cut algorithm (MMC) [5]. Table 5 presents the NMI clustering results of the clustering approaches on a group of typical datasets, where each k is set to be the actual number of classes. It shows that using I R or I V to refine output of sp k means does give rise to clustering quality. Such improvement is meaningful, since it demonstrates the suitability and effectiveness of our proposal. Besides, the results also show again the better performance of the original I R and I V compared with the other methods. In this paper, we propose a multi-viewpoint based similarity measuring method and two novel criterion functions for document clustering. The main principle is that similarity between two objects in the same cluster is assessed from many different viewpoints which are objects outside that cluster. The final estimate is based on a combination, e.g. the average, of all these relative assessments. We deem that this method offers more informative assessment than single ori-gin point based similarity measures. From the proposed similarity measure, we introduce two clustering criterion functions I R and I V . They are applied for clus-tering large document collections. Comparisons with related methods, especially the ones from the well-known software package CLUTO, show that our criterion functions produce significantly better clustering solutions. Based on the twenty datasets examined, I V yields the best performance, followed by I R .
This work focuses on partitional clustering of documents. In the future, we could apply the proposed criterion functions for hierarchical clustering algo-rithms. Future methods could also rely on the same principle of measuring sim-ilarity from multiple viewpoints, but explore alternative means instead of dot product of vectors or average of assessments.

