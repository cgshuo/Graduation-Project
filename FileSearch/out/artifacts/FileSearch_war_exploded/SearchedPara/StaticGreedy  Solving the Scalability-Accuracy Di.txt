 Influence maximization, defined as a problem of finding a set of seed nodes to trigger a maximized spread of influ-ence, is crucial to viral marketing on social networks. For practical viral marketing on large scale social networks, it is required that influence maximization algorithms should have both guaranteed accuracy and high scalability. How-ever, existing algorithms suffer a scalability-accuracy dilem-ma: conventional greedy algorithms guarantee the accuracy with expensive computation, while the scalable heuristic al-gorithms suffer from unstable accuracy.

In this paper, we focus on solving this scalability-accuracy dilemma. We point out that the essential reason of the dilemma is the surprising fact that the submodularity, a key requirement of the objective function for a greedy algo-rithm to approximate the optimum, is not guaranteed in all conventional greedy algorithms in the literature of influence maximization. Therefore a greedy algorithm has to afford a huge number of Monte Carlo simulations to reduce the pain caused by unguaranteed submodularity. Motivated by this critical finding, we propose a static greedy algorithm, named StaticGreedy , to strictly guarantee the submodularity of influence spread function during the seed selection process. The proposed algorithm makes the computational expense dramatically reduced by two orders of magnitude without loss of accuracy. Moreover, we propose a dynamical update strategy which can speed up the StaticGreedy algorithm by 2-7 times on large scale social networks.
 F.2.2 [ Analysis of Algorithms and Problem Complex-ity ]: Non-numerical Algorithms and Problems; D.2.8 [ Software Engineering ]: Metrics X  complexity measures, performance measures Algorithms, Experiments, Performance influence maximization; greedy a lgorithm; scalability; social networks; viral marketing
We are witnessing the increasing prosperity of online so-cial network sites and social media sites, where people are connected by heterogeneous social relationships. These on-line social networks provide convenient platforms for in-formation dissemination and marketing campaign, allowing ideas and behaviors to flow along the social relationships in the effective word-of-mouth manner. Many companies have made efforts to popularize or promote their brands or prod-ucts on online social networks by launching campaigns akin to viral marketing. The success of viral marketing is rooted in the interpersonal influence, which has been empirically studied in various contexts [8, 24, 15, 11, 12, 18, 29, 1].
Influence maximization, formulated as a discrete optimiza-tion problem by Kempe et al. [14], is a fundamental problem for viral marketing. It aims to find a fixed-size set of seed nodes, which can influence the maximum number of nodes, generally referred to as influence spread . The solution of the influence maximization problem is closely related to infor-mation spread models, which are used to model the process of influence spread. Two commonly-used models are the in-dependent cascade model and the linear threshold model. Kempe et al. [14] proved the influence maximization prob-lem is NP-hard with either model, and proposed a greedy algorithm to approximate the optimal solution within a fac-tor of (1  X  1 / e  X  ), where depends on the accuracy of influence spread estimation. Since no algorithm can effi-ciently estimate the exact influence spread of a given seed set on typically sized networks [5, 7], Monte Carlo approach is usually used to provide an approximation, resulting a s-mall positive error .

Unfortunately, the greedy algorithm proposed by Kempe et al. (referred to as GeneralGreedy in this paper) suffers severe scalability problem, i.e., it relies on a huge number of Monte Carlo simulations to achieve a fair solution, which results in an unaffordable computation on large-scale social networks. To overcome this problem, many efforts have been made to explore a more scalable greedy algorithm along two directions [17, 6, 16, 28, 22, 13, 9]. On one direction, re-searchers insisted on Monte Carlo simulations and reduced the number of trials that need Monte Carlo simulations to estimate the influence spreads of node sets. For example, a  X  X azy-forward X  strategy was proposed to effectively reduce the number of candidate nodes [17]. However, the reduction in computational expense was limited since a large number of Monte Carlo simulations were still needed in every single estimation to guarantee the final accuracy. On the other direction, various heuristics were proposed to efficiently es-timate influence spreads instead of Monte Carlo simulations. In a representative work, the maximum influence paths be-tween every pair of nodes are used to approximately compute the influence pro pagation [5]. However , the gain in scalabil-ity is obtained with the pain of unguaranteed accuracy. In a word, existing influence maximization algorithms suffer the scalability-accuracy dilemma.

This paper focuses on resolving the scalability-accuracy dilemma of influence maximization with respect to the in-dependent cascade model. We analyze the essential cause of the scalability-accuracy dilemma, and then propose a static greedy algorithm to combat it. Moreover, we further im-prove the scalability of the proposed algorithm by a dynamic update strategy. The contributions of this paper are sum-marized as follows: Influence maximization was first studied by Domingos and Richardson from the algorithmic perspective [8, 24], and was then formulated as a discrete optimization problem by Kempe et al. [14]. They also proposed a greedy algorithm, with the accuracy guaranteed by the monotonicity and sub-modularity properties of the objective function of influence maximization problem. However, this greedy algorithm is inefficient and not scalable to large scale social networks.
Thus, several studies were devoted to optimize Kepme X  X  greedy algorithm without affecting its guaranteed accuracy. Leskovec et al. [17] proposed the X  X ost-effective lazy forward X  strategy, namely CELF, for selecting new seed nodes by further exploiting the submodularity property of influence maximization. The CELF strategy can greatly reduce the number of evaluations on the influence spread of nodes. This strategy was further improved to a CELF++ strategy [9], which simultaneously calculates the influence spread for two successive iterations of greedy algorithm. NewGreedy algo-rithm [6] reuses the results of Monte Carlo simulations to estimate the influence spread for all candidate nodes in the same iteration. It has been further developed into Mixed-Greedy algorithm to integrate the advantages of both the CELF strategy and the NewGreedy algorithm.

Unfortunately, those improved greedy algorithms are still inefficient for involving too many Monte Carlo simulation-s for influence spread estimation. Hence, several heuristics for the independent cascade model were proposed to improve the scalability of greedy algor ithm by simplifying influence spread estimation. Chen et al. [6] suggested a degree dis-count heuristics to significantly decrease the running time by only considering the direct influence of a node to its one-hop neighbors, however, this method is tailored to influence maximization on uniform independent cascade model. Wang et al. [28] divided a network into communities and conducted Monte Carlo simulations within each community instead of the whole network. Luo et al. [19] conducted the greedy al-gorithm on a small set of nodes, consisting of the top nodes ranked by PageRank algorithm on social network. Kimu-ra and Saito [16] proposed the shortest-path based influence cascade models and provided efficient algorithms to compute the influence spread under these models. Instead of using the simple shortest path, PMIA algorithm [5, 27] employed maximum influence paths for influence spread estimation, and this algorithm is believed to be the best heuristic al-gorithm so far. However, these heuristics may violate the guaranteed accuracy of greedy algorithm and thus one may concern about the reliability of these heuristics.
In addition, several influence maximization algorithms are beyond the framework of greedy algorithm. Jiang et al. [13] suggested a simulated annealing approach with several heuris-tics to speed up influence spread estimation. Narayanam et al. [22] gave a way to improve the scalability of influence maximization using the concept of Shapley value borrowed from the cooperative game theory. Mathioudakis et al. [20] suggested removing some unimportant edges to accelerate influence computation algorithms.

Moreover, recently several works studied influence maxi-mization problem in competitive environment [2, 4, 25]. B-harathi et al. modified the independent cascade model to the case of multiple competing innovations [2]. Carnes et al. [4] extended the independent cascade model to a distance-based model and a wave propagation model. The two models are further studied by Shirazipourazad et al [25], and they tried to minimize the cost (the number of seed nodes selected) un-der a given competition goal. Since the object functions of those above extended independent cascade model still main-tain the submodularity and monotonicity properties, greedy algorithms are used to achieve a guaranteed accuracy. In addition, some researchers studied influence spread limiting problem [3, 10, 26] under variants of the independent cascade model, but the submodularity and monotonicity properties of the object functions become difficult to be ensured.
We consider the influence maximization problem with re-spect to the independent cascade model. For a directed graph G =( V,E ), each edge u, v  X  E is associated with a probability p ( u, v ). When u is activated, it has one chance to activate v with the successful rate p ( u, v ), if v has not been activated yet. The activation is fully determined by p ( u, v ). Given a seed set S , its influence spread I ( S )isde-fined as the expected number of nodes eventually activated. The influence maximization problem aims at finding a set S that maximizes I ( S ), under the constraint that the size of S is no larger than a predefined positive integer k .
To resolve the influence maximization problem, one needs to estimate I ( S ) for any given S . However, it is intractable to exactly compute I ( S ) on a typically sized graph. In prac-tice, Monte Carlo methods are employed to estimate I ( S ), and can be implemented in two different ways as follows:
Those two methods are essentially equivalent and either has its own advantage and disadvantage. For estimating the influence spread of a given seed set, the simulation method is faster, because it only needs to examine a small por-tion of edges while the snapshot method has to examine all the edges. For estimating the influence spreads of different seed sets, the snapshot method outperforms the simulation method in terms of time complexity, since each snapshot serves all seed sets.
For any greedy algorithm of influence maximization, it is required that the influence spread function I (  X  ) is monotone and submodular to achieve a (1  X  1 / e)-approximation [23]. We say that a function f (  X  ) is monotone if f ( S  X  X  v } for any set S and any element v/  X  S ,and f (  X  ) is submodular if f ( S  X  X  v } )  X  f ( S )  X  f ( T  X  X  v } )  X  f ( T )when S The submodularity property is also explained as a natural  X  X iminishing return X  property. It has been proven that I ( is monotone and submodular when its value can be exactly estimated [14, 21]. Unfortunately, things become different when Monte Carlo simulation is employed to approximately estimate I (  X  ).

Let us take a closer look. In existing greedy algorithms, different Monte Carlo simulations are conducted indepen-dently across different iterations. The spread along an edge (a) Original graph (b) Snapshot1 (c) Snapshot2 Figure 1: Illustrations of unguaranteed submodular-ity property. u, v may fail in one Monte Carlo simulation and succeed in another Monte Carlo simulation. As a result, the marginal gain from adding v to the seed set in the i -th iteration might be lower than the marginal gain from adding v in the ( i +1)-th iteration, i.e., I ( S i  X  X  v } )  X  I ( S i ) &lt;I ( S with S i  X  S i +1 , which violates the submodularity property. For example, we produce Monte Carlo snapshots for a graph where each edge u, v associated with a uniform propaga-tion probability p ( u, v )=0 . 5 as shown in Figure 1(a). In the first iteration we produce one snapshot shown in Fig-ure 1(b), and in the second iteration we produce another snapshot shown in Figure 1(c). We start from an empty seed set S 0 =  X  . Obviously S 1 = { v 2 } ,since v 2 has the largest influence spread in Figure 1(b). Now we check the marginal gains from adding v 4 in the two iterations, which are estimated on the two snapshots respectively.
The marginal gain from adding v 4 increases from 1 to 3, dissatisfying the submodularity requirement. The reason is that the estimation of influence spread of v 4 ,aswellasthat of v 2 , differs between the two iterations with different snap-shots being used. To summarize, producing different Monte Carlo simulations across different iterations brings the risk of unguaranteed submodularity. Similarly, the monotonicity property is also unguaranteed.

To reduce the pain from unguaranteed submodularity and monotonicity, one has to estimate the influence spread func-tion I (  X  ) exactly. For this purpose, existing greedy algo-rithms conduct an extremely large number (typically 10 , 000 or 20 , 000) of Monte Carlo simulations in every iteration. However, the submodularity and monotonicity properties can only be guaranteed with a certain probability in this way because of the finite number of Monte Carlo simulations. As a result, to achieve the guaranteed (1  X  1 / e)-approximation, existing greedy algorithms have to bear the expensive com-putational cost for conducting huge number of Monte Carlo simulations. This poses the scalability-accuracy dilemma suffered by existing greedy algorithms.
We have pointed out that the key for combating the scalability-accuracy dilemma is ensuring that the estimated influence spreads of any seed set are the same in different iterations, so as to overcome the unguaranteed submodularity and mono-tonicity rooted in different Monte Carlo simulations con-ducted in different iterations of greedy algorithms. We pro-Algorithm 1 StaticGreedy( G , k , R ) 1: initialize S =  X  2: for i =1to R do 3: generate snapshot G i by removing each edge u, v 4: end for 5: for i =1to k do 6: set s v =0forall v  X  V \ S // s v stores the influence 7: for j =1to R do 8: for all v  X  V \ S do 9: s v += | R ( G j ,S  X  X  v } ) | // R ( G j ,S  X  X  v } )isthe 10: end for 11: end for 12: S = S  X  X  arg max 13: end for 14: output S pose a solution to guarantee submodularity and monotoncity in a simpler but more effective way. Instead of producing a huge number of Monte Carlo simulations in every itera-tions, we produce a (not very large) number of Monte Carlo snapshots at the very beginning, and use the same set of snapshots in all iterations. Those snapshots are called  X  X tat-ic X , results in the StaticGreedy algorithm. That algorithm ensures that the estimated influence spreads of any seed set are exactly the same in different iterations, and thus guaran-tees submodularity and monotonicity properties. Avoiding a huge number of Monte Carlo simulations needed in every it-erations, our algorithm brings the possibility to significantly reduce the computational expense without loss of accuracy.
Given an underlying social network G and a positive inte-ger k , the StaticGreedy algorithm runs in the following two stages to seek for a seed set S that maximizes the influence spread I ( S ): 1. Static snapshots: Select a value of R ,thenumberof 2. Greedy selection: Start from an empty seed set S ,iter-
The StaticGreedy algorithm is formally described in Algo-rithm 1. Two main differences between this algorithm and existing greedy algorithms include: (1) Monte Carlo simu-lations are conducted in static snapshot manner, which are sampled before the greedy process of selecting seed nodes, as is shown in line 2 to 4; (2) The same set of snapshots are reused in every iteration to estimate the influence spread I ( S ), where explains the meaning of  X  X tatic X .
Both our StaticGreedy algorithm and conventional greedy algorithms provide a (1  X  1 / e  X  )-approximation to the op-timal solution of influence maximization. The main differ-ence lies in the origin of . For conventional greedy algo-rithms, depends on the extent to which the submodu-larity is guaranteed and it generally requires a huge num-ber of Monte Carlo simulations, typically in the magnitude of 10,000. For StaticGreedy algorithm, is caused by the variance of the unbiased estimation to the optimal influence spread using finite static snapshots. In practice, a small is usually achieved using a small number of static snapshot-s, e.g., 100. In this way, StaticGreedy algorithm efficiently solves the scalability-accuracy dilemma suffered by conven-tional greedy algorithms for influence maximization.
To clarify the effectiveness of the StaticGreedy algorith-m compared with traditional greedy algorithms, we illus-trate the accuracy of these algorithms with respect to the number R of Monte Carlo simulations on a benchmark net-work NetHEPT. This network consists of tens of thousand-s of physics researchers and their co-authorship relations. The baseline greedy algorithm is the CELFGreedy, which is the general greedy algorithm with CELF optimization, and the NewGreedy, which is a snapshot-based greedy al-gorithm reusing snapshots for influence spread estimation within the same iteration. We employ the NewGreedy al-gorithm as a comparison to show that our StaticGreedy is fundamentally different from existing snapshot-based greedy algorithm. The comparisons are conducted with respect to two commonly-used IC models: the uniform independent cascade (UIC) model with p =0 . 01 and the weighted in-dependent cascade (WIC) model [14] with p ( u, v )=1 /d v where d v is the indegree of node v .

Since the optimal influence spread is unknown to us, the ground truth we use here is the influence spread of the so-lution S  X  k with the set size k , obtained by the CELFGreedy algorithm with typical setting, i.e., R = 20,000. To evaluate the relative difference between the influence spread I ( S and the ground truth, we use a measure d R,k defined as where S R,k is the set of seed nodes obtained by a greedy algorithm with a given R ,and k is the size of seed set. For agiven R , we run each of the three greedy algorithms for 100 times to calculate the average relative difference. Here, we only report the results with k = 50 since the results for other k are similar.
 As shown in Figure 2, for both the UIC model and the WIC model, the StaticGreedy algorithm quickly approach-es to the ground truth while the CELFGreedy algorithm converges slowly. This confirms that the StaticGreedy algo-rithm can achieve good accuracy even when the number R of Monte Carlo simulations is small, e.g., R = 100. More-over, the accuracy of StaticGreedy algorithm consistently outperforms the accuracy of CELFGreedy algorithm. The NewGreedy algorithm performs very differently for the UIC model and the WIC model. It needs a large R for the WIC model although it works well for the UIC model. Further-more, the smaller value of R does not indicate that the New-Greedy algorithm is more effective than the StaticGreedy algorithm, because the NewGreedy algorithm needs k  X  R Monte Carlo simulations with each iteration using R simu-lations. We will give more discussions about this point later. As a conclusion, only the StaticGreedy algorithm exhibits Figure 2: The relationship between d R,k and R on NetHEPT network.
 Figure 3: Minimal number of snapshots needed to accurately find a solution. consistently good performance for the two models.
We further evaluate the accuracy of the StaticGreedy algo-rithm with respect to the size k of seed set. For this purpose, we define R min as the minimal R satisfying d R,k  X  0 . 005. As shown in Figure 3, the values of R min for the StaticGreedy algorithm are consistently smaller than the values of R min for the CELFGreedy algorithm. The NewGreedy algorithm again performs differently on the two models.

To further understand the finding that the StaticGreedy algorithm can achieve a rapid convergence with respect to R , we introduce a measure H R,k ( S ) to analyze the solution space of greedy algorithm, which is defined as where p ( S ) is the fraction of a certain solution S relative to the size of solution space according to the setting of a given R and k for a greedy algorithm. H R,k ( S )isakindofen-tropy, which characterizes the heterogeneity of a probability distribution. A large value of H R,k ( S ) means much uncer-tainty of the solution. When the value of H R,k ( S )=0,the algorithm converges to a unique solution. Actually, there are always many solutions with very close influence, and the number of different solutions is always larger when the net-work is larger or k becomes larger. Here, we choose k =5to illustrate the advantage of StaticGreedy algorithm over the other two greedy algorithms. For each R , we run the algo-rithm for 100 times and calculate the H R,k =5 ( S ) according to the obtained 100 solutions. As shown in Figure 4, the solution space of StaticGreedy algorithm narrows quickly, while the CELFGreedy shows a slow convergence. For the Figure 4: The entropy of the solution space with respect to R .
 UIC model, the trend of H ( S ) for the StaticGreedy algorith-m and the NewGreedy algorithm is similar, explaining why the two algorithms need a similar R min under this model. For the WIC model, the H ( S ) for the NewGreedy algorith-m and the CELFGreedy algorithm are similar and narrow slowly, while H ( S ) converges quickly for the StaticGreedy algorithm. In sum, with the strictly guaranteed submodular-ity property, the StaticGreedy algorithm can always achieve a rapid convergence of the solution space.

According to the above analysis, we can see that the Stat-icGreedy algorithm is essentially different from the New-Greedy algorithm. The NewGreedy algorithm aims to re-duce the computational cost by simultaneously estimating the influence spread of many seed sets in the same iteration, while the submodularity property is not maintained since different iterations do not share the results of Monte Carlo simulations as done by the StaticGreedy algorithm.
Now we analyze the time complexity of the StaticGreedy algorithm. Since the number of Monte Carlo simulations for influence spread estimation, R , is significant different for our StaticGreedy algorithm and other greedy algorithms, for clarity, we use R to denote the number of Monte Carlo sim-ulations required by existing greedy algorithms and use R to denote the number of Monte Carlo simulations required by our StaticGreedy algorithm. In addition, n is the num-ber of nodes in the underlying influence network, m is the number of edges in the network, m is the average number of active edges in the snapshots obtained by sampling the influence network, and k is the number of seed nodes. For the StaticGreedy algorithm, the time complexity includes two parts: firstly, the time complexity of generating R s-napshots is O ( R m ); secondly, it takes O ( knR m )timeto select seed nodes in greedy manner on those static snapshot-s. Thus, the total time complexity is O ( R m + knR m ). For the space complexity of StaticGreedy algorithm is O ( R m ), which is used to store the R snapshots. The comparison with the general greedy algorithm [14] and the NewGreedy algorithm [6] is given in Table 1.

Figure 5 shows the running time of each greedy algorithm with their respective R min for different k . The StaticGreedy algorithm outperforms the other two greedy algorithms, and runs much faster than the CELFGreedy algorithm. Al-though the NewGreedy algorithm has a similar small R min to the StaticGreedy algorithm, its time-consuming is still Figure 5: The running time of each greedy algorithm with their respective R min Table 1: Time and space complexity of algorithms Algorithms Time complexity Space complexity StaticGreedy O ( R m + knR m ) O ( R m ) GeneralGreedy O ( knRm ) O ( m )
NewGreedy O ( kRTm ) O ( m ) larger than the StaticGreedy algorithm, which is mainly be-cause that the NewGreedy algorithm needs to do R Monte Carlo simulations in every iteration, while StaticGreedy al-gorithm only need to do R times at the very beginning. Moreover, we later propose an improved version of the Stat-icGreedy algorithm, which can further effectively decrease the running time of the current StaticGreedy algorithm.
The time complexity of the StaticGreedy algorithm can be further reduced by employing the CELF optimization and other optimization strategies. In the next section, we give a dynamic update strategy to improve the efficiency of the StaticGreedy algorithm.
One may ask the question: why the StaticGreedy algorith-m can achieve the high accuracy with a small R ? Indeed, a small R may result in the inaccurate estimation of the influ-ence spread of a given seed set. However, as we show here, the inaccurate estimation matters little at finding the solu-tion of influence maximization. Basically, the reason lies in that the influence maximization aims to find a set of nodes rather than a ranked set of nodes. The inaccurate estima-tion of influence spread may alter the order of nodes in the seed set while has little influence on the set of nodes.
The idea behind the StaticGreedy method for indepen-dent cascade model can be easily generalized to the linear threshold model. In this paper, the details are omitted with the limitation of space.
 In addition, it is unclear on how to determine a suitable R at present. How do we determine the minimum R for a specific network and a given spread model? What are the factors affecting R in StaticGreedy or previous greedy algorithms? We leave these interesting questions as open problems in the future.
In this section, we propose a dynamic update strategy to speed up the proposed static greedy algorithm. This strate-gy exploits the advantage of static snapshots and calculates the marginal gain in an efficient incremental manner. Specif-ically, when a node v  X  is selected as a seed node, we directly discount the marginal gain of other nodes by the marginal gain shared by these nodes and v  X  .

For a snapshot G i ,weuse R ( G i ,v )todenotethesetof nodes which are reachable from v and use U ( G i ,v )todenote the set of nodes from which v can be reached. In the first it-eration, the marginal gain of v is | R ( G i ,v ) | . In our dynamic update strategy, when v  X  is selected as a seed node, we find the set U ( G i ,w ) for each node w  X  R ( G i ,v  X  ). Then, for every u  X  U ( G i ,w ), we delete w from R ( G i ,u ). The size of the remained R ( G i ,u ) reflects the marginal gain of u in the next iteration. In this way, we can maintain a dynamically updated marginal gain for each node to avoid calculating the marginal gain from scratch. The detailed implementation of the improved static algorithm, namely StaticGreedyDU , is given in Algorithm 2.
 Nowweanalyzethetimeandspacecomplexityofthe StaticGreedyDU algorithm. For undirected graphs, R ( G i ,v ) is the same to U ( G i ,v ). We only need to store the infor-mation of connected components for each snapshot. Thus, the space complexity is O ( R n ). Thetimecomplexityis O ( R m ) for generating R snapshots and calculating the ini-tial marginal gain. The time complexity is O ( kn ) for up-dating the marginal gain of all the related nodes. Thus, the total time complexity is O ( R m + kn ). For directed graphs, needs to store R ( G i ,v )and U ( G i ,v ) for each node, the space complexity is O ( R nn T + R nn U ). Assume the maximum running time to compute R ( G i ,v )and U ( G i ,v )is t T respectively. The time complexity is O ( R m ) for generat-ing snapshots, O ( R nt T + R nt U ) for computing the initial incremental influence spread, and O ( kR n T n U ) for updat-ing the marginal gains. Thus, the total time complexity is O ( R m + R nt T + R nt U + kR n T n U ) for directed graphs. Note that n T , n U , t T and t U are usually very small in real world networks since these networks are usually sparse.
In this section, we conduct experiments on several real-world networks to compare our StaticGreedy algorithm with a number of existing algorithms. The experiments aim at il-lustrating the performance of our algorithm comparing to other algorithms from the following two aspects: (a) ac-curacy at finding the seed nodes maximizing the influence spread, (b) scalability. Datasets. Six real world networks are employed to demon-strate the performance of our algorithms by comparing with other existing algorithms. These networks include three undirected scientific collaboration networks and three di-rected online social networks. In the three scientific col-laboration networks, namely NetHEPT, NetPHY, and D-BLP 1 , nodes represent authors and edges represent coau-thor relationships among authors. All of those 6 networks
The three scientific collaboration networks are downloaded from http://research. microsoft.com/en-us/people/weic/. Those networks are actually multigraphs, where parallel edges between two nodes denoting the number of paper-s coauthored by the two authors. We view parallel edges between two nodes as a single edge to simplify. Algorithm 2 StaticGreedyDU( G , k , R ) 1: initialize S =  X  2: set the marginal gain s v =0forall v  X  V 3: for i =1to R do 4: generate G i 5: compute and record R ( G i ,v )and U ( G i ,v ) for all v 6: for each node v  X  V do 7: s v += | R ( G i ,v ) | 8: end for 9: end for 10: for r =1to k do 11: v  X  =arg max 12: S = S  X  X  v  X  } 13: for i =1to R do 14: for each node w  X  R ( G i ,v  X  ) do 15: for each node u  X  U ( G i ,w ) do 16: delete w from R ( G i ,u ) 17: s u = s u -1 18: end for 19: end for 20: end for 21: end for 22: output S.
 Table 2: Statistics of six test real world networks. are undirected. NetHEPT is extracted from the  X  X igh En-ergy Physics -Theory X  section of the e-print arXiv website between 1991 and 2003. NetPHY is constructed from the full paper list of the  X  X hysics X  section of the arXiv website. DBLP, much larger than the former two scientific collab-oration networks, is extracted from the DBLP Computer Science Bibliography 3 . The three online social network-s Epinions, Slashdot, and Douban 4 are collected from the websites Epinions.com, Slashdot.com, and Douban.com. In the Epinions network, an edge u, v means that a user u trusts another user v . Slashdot is a friend network extract-ed from a technology-related news website Slashdot.com. In the Douban network [12] an edge u, v means that a user u follows another user v . All the three online social networks are directed. Those 6 networks are representative networks, covering a variety of networks with different kinds of rela-tions and different sizes ranging from tens of thousands of edges to millions. Basic statistics of those networks are given in Table 2.
 Influence spread models. The algorithms are evaluated http://www.arXiv.org http://www.informatik.uni-trier.de/ ley/db/
Epinions and Slashdot can be downloaded from http://snap.stanford.edu/data/. The last one can be obtained on demand via email to the authors. with two commonly used implementations of independen-t cascade model: the uniform independent cascade model (UIC) and the weighted independent cascade model (WIC). With UIC, the propagation probability on every edge is as-signed with a uniform value. We assign p (  X  ,  X  )=0 . 001 for Douban and p (  X  ,  X  )=0 . 01 for other networks, because the average degree of Douban is roughly ten times than that of any other network. With WIC, the propagation probability on every edge could be assigned with different values. We follow a typical configuration to assign p ( u, v )=1 /d v d v is the indegree of node v .
 Algorithms. A total of six algorithms are tested, including our algorithm, a greedy algorithm CELFGreedy, as well as four heuristic algorithms PMIA, SP1M, DegreeDiscount and Degree. We also test the NewGreedy algorithm and the Mixed-Greedy algorithm on these datasets, and the results are sim-ilar to the CELFGreedy algorithm, hence we omit the two greedy algorithms. Since the PMIA heuristic is the state-of-the-art heuristic [5], we do not implement more heuris-tics such as distance centrality, betweenness centrality, or PageRank-based heuristics. All experiments are conducted on a server with 2.0GHz Quad-Core Intel Xeon X7550 and 64G memory.
We run tests on the six datasets and two IC models. The tested seed size k are 1, 5, 10, ... , up to 50. For the compar-ison of running time, we only consider the seed size k = 50.
We first compare the accuracy of the StaticGreedy algo-rithm with other algorithms by showing the influence spread of the obtained seed set. For every obtained seed set, 20 , 000 Monte Carlo simulations are used to evaluate its influence spread. Figure 6 shows the experimental results on influence spread for the six datasets under the UIC model. As shown in Figure 6(a) and Figure 6(b), the CELFGreedy algorith-m provides the best influence spread on the moderate sized networks NetHEPT and NetPHY where the CELFGreedy algorithm is feasible to run. On the dataset NetHEPT, all the algorithms except the Degree heuristic algorithm have the influence spread similar to the CELFGreedy algorith-m. However, on the dataset NetPHY, the differences among these algorithms become visible. StaticGreedy algorithm is still very close to the CELFGreedy algorithm and out-performs all the other algorithms. The difference between StaticGreedy algorithm and the CELFGreedy algorithm is less than 2%. Note that the accuracy of the StaticGreedy algorithm is obtained with a very small R = 100 and can be further improved with larger R . For the rest networks with large scale where the CELFGreedy algorithm is infea-sible, we compare the StaticGreedy algorithm with the other three baseline algorithms. We can see that the StaticGreedy algorithm always has the best accuracy. In particular, for the DBLP dataset, the StaticGreedy algorithm significant-ly outperforms the competing algorithms. We further test StaticGreedy algorithm on the six test datasets with re-spect to the WIC model. For the moderate sized networks NetHEPT and NetPHY where CELFGreedy is feasible, as shown in Figure 7(a) and Figure 7(b), the StaticGreedy al-gorithm has almost the same influence spread to the CELF-Greedy algorithm, which is the most accurate greedy algo-rithm. Moreover, StaticGreedy algorithm outperforms the other algorithms with a visible gap. For the DBLP, Epin-ions, Slashdot and Douban networks with large scale, the CELFGreedy algorithm is not scalable to these network-s while StaticGreedy algorithm performs well. Moreover, for DBLP, Epinions networks, the StaticGreedy algorithm has slight higher accuracy than the other three baseline al-gorithms, and for Slashdot and Douban, it has consistent accuracy with the other algorithms. For these networks, due to their structural characteristics, a simple degree algo-rithm is good enough for influence maximization under the WIC model. However, for a given network, it is hard to determine a priori whether a simple heuristic is enough for influence maximization.

As demonstrated by the results on the test networks with both the UIC and WIC models, StaticGreedy algorithm has guaranteed accuracy as the original greedy algorithm and outperforms the state-of-the-art heuristics. Moreover, com-pared with the original greedy algorithm, the guaranteed accuracy of the StaticGreedy algorithm is obtained with the number of Monte Carlo simulations dramatically reduced by two orders of magnitude, i.e., from 20 , 000 to 100.
We now test the running time of StaticGreedy algorith-m and the competing algorithms. For StaticGreedy, we test the running time of both the StaticGreedyDU algorithm and the StaticGreedy algorithm with CELF optimization, denot-ed as StaticGreedyCELF. For heuristic algorithms, we test the running time of the PMIA and SP1M. We neglect the Degree and Degree discount algorithms since their accuracy are always lower than the PMIA and SP1M algorithms.
Figure 8 shows the experimental results. For the six test networks, the StaticGreedyDU algorithm always runs 2-7 times faster than the StaticGreedyCELF algorithm, and the improvement is more significant for DBLP. The CELFGreedy algorithm is quite slow even for the moderate sized dataset-s, i.e., NetHEPT and NetPHY. The CELFGreedy algorith-m requires several hours while our static greedy algorithms only take several seconds. The two static greedy algorithms reduce the running time by three orders of magnitude, com-pared with the CELFGreedy algorithm. More importantly, our static greedy algorithms obtain the reduction of run-ning time without affecting the guaranteed accuracy. The time cost of our static greedy algorithms also significantly outperform the SP1M algorithm, which is not scalable and becomes infeasible to run for some large scale networks, such as DBLP and Douban networks. Furthermore, the running time of our static greedy algorithms is comparable to the PMIA algorithm, which is the most scalable heuristic algo-rithm. Note that the accuracy of the PMIA algorithm is unguaranteed. In addition, the StaticGreedyDU algorithm even outperforms the PMIA algorithm on three large scale networks, Epinions, Slashdot and Douban. It seems that our algorithm has the potential advantage on large scale networks compared with the PMIA algorithm.
In this paper, we have analyzed the scalability-accuracy dilemma of greedy algorithms for influence maximization, which has roots in the unguaranteed submodularity and monotonicity in existing implementations. We propose a static greedy algorithm to combat this problem by sharing Monte Carlo simulations in different iterations. Since both submodularity and monotonicity are strictly guaranteed, the static greedy algorithm always converges much more quickly than existing greedy algorithms. Hence, the proposed algo-rithm achieves the same accuracy with the state-of-the-art greedy algorithms while the number of Monte Carlo sim-ulations needed is dramatically reduced by two orders of magnitude. We further give a dynamic update strategy tak-ing advantage of the static snapshots to improve the static greedy algorithm, by applying which our algorithm becomes comparable to the most scalable heuristic algorithm. In ad-dition, the idea behind the static greedy algorithm can be easily generalized to linear threshold model.

For the future work, we will study how to determine the minimum number R of Monte Carlo simulations given net-work structure and diffusion model. Furthermore, we will implement the proposed static algorithm towards the frame of parallel computing to further improve the computational efficiency. We also look forward to seeing more applications of our algorithm on real world networks and practical sce-narios. This work was funded by the National Natural Science Foundati on of China with Nos 61202215, 61232010, 61202213, 61174152, and the National Basic Research Program of Chi-na (973 program) under grant numb er 2013CB329602. The authors thank Wei Chen for providing the codes of the P-MIA algorithm and the datasets: NetHEPT, NetPHY and DBLP. The authors also thank to Jure Leskovec for provid-ing the download for the social network datasets, Epinions and Slashdot. The authors thank to the member of the group NASC(www.gro upnasc.org). [1] P. Bao, H.-W. Shen, J. Huang, and X.-Q. Cheng. [2] S. Bharathi, D. Kempe, and M. Salek. Competitive [3] C. Budak, D. Agrawal, and A. El Abbadi. Limiting [4] T. Carnes, C. Nagarajan, S. M. Wild, and A. van [5] W. Chen, C. Wang, and Y. Wang. Scalable influence Figure 8: Running times of different algorithms on test datasets under the UIC model and the WIC model. [6] W. Chen, Y. Wang, and S. Yang. Efficient influence [7] W. Chen, Y. Yuan, and L. Zhang. Scalable influence [8] P. Domingos and M. Richardson. Mining the network [9] A.Goyal,W.Lu,andL.V.Lakshmanan.Celf++: [10] X. He, G. Song, W. Chen, and Q. Jiang. Influence [11] J. Huang, X.-Q. Cheng, J. Guo, H.-W. Shen, and [12] J. Huang, X.-Q. Cheng, H.-W. Shen, T. Zhou, and [13] Q. Jiang, G. Song, C. Gao, Y. Wang, W. Si, and [14] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [15] M. Kimura and K. Saito. Tractable models for [16] M. Kimura, K. Saito, R. Nakano, and H. Motoda. [17] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [18] D. Li, X. Shuai, G. Sun, J. Tang, Y. Ding, and Z. Luo. [19] Z.-L. Luo, W.-D. Cai, Y.-J. Li, and D. Peng. A [20] M. Mathioudakis, F. Bonchi, C. Castillo, A. Gionis, [21] E. Mossel and S. Roch. On the submodularity of [22] R. Narayanam and Y. Narahari. A shapley [23] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An [24] M. Richardson and P. Domingos. Mining [25] S. Shirazipourazad, B. Bogard, H. Vachhani, A. Sen, [26] R. M. Tripathy, A. Bagchi, and S. Mehta. A study of [27] C. Wang, W. Chen, and Y. Wang. Scalable influence [28] Y. Wang, G. Cong, G. Song, and K. Xie.
 [29] M.Ye,X.Liu,andW.-C.Lee.Exploringsocial
