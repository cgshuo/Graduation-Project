 In this work, we study similarity measures for text-centric XML documents based on an extended vector space model, which considers both document content and structure. Experimental results based on a benchmark showed superior performance of the proposed measure over the baseline which ignores structural knowledge of XML documents. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval models  X  retrieval models . Models, Experimentation XML Search and Retrieval In traditional IR, both documents and queries are expressed in free text which provides no clue about the logical structure of the documents. In contrast, a XML document has a hierarchical structure, where the different tags of nodes indicate different semantic properties of the text underneath such as it being the semantic relationships among different element types. The richer representation of XML allows a user to formulate their information need more precisely by imposing constraints on both the content and structure. In recent years, there has been an increasing interest on XML search and retrieval in the IR community such as the INEX evaluation initiative [3]. However, the focus of most existing research is on finding the most relevant component in an XML document to return as answer to a short query. The problem of document to document comparison is not well studied yet, while it is important for many applications such as similarity search, clustering and classification. The vector space is a standard model for text retrieval, in which queries and documents are both represented by vectors in a high dimensional space whose axes corres pond to the set of terms in the document corpus. The coordinate of each document vector is determined by w d (t) which stands for the weight of t in document d and is commonly computed by a score of the tf * idf family. The relevance of a document to a query is usually evaluated by the similarity of their corresponding vectors such as the cosine measure: Several recent works [1,3,4] pr oposed extensions of the regular vector space model for XML documents so that both content and structure are taken into account. The basic idea underlying these approaches is to use pairs of the form (t, c) instead of single terms differentiated by the context c of its appearance which is typically identified by the path leading to the term from the root of the hierarchical structure of the XML document. Thus the weight of individual terms w x (t) should be repl aced by weight of terms in context denoted by w x (c,t) . Moreover, when computing vector similarity, it is proposed that terms occurring in different but similar contexts should also be accounted for by utilizing a context resemblance measure: Thus the cosine similarity between two XML documents become To instantiate this similarity measure, we need to specify the computation of the weight w x (c,t) . In [1], w x tf (c,t)  X  idf(c,t) where  X  idf(c,t) = log( | N |/| N (c,t) | )with | N | = total number of documents  X  tf x (c,t) is the number of occurrences of (t,c) in x . To further exploit the structural information, [4] introduced the concept of  X  X eighted term frequency X  to reflect that different locations carries different importance when comparing two documents. For example, in an article, a word occurring in the  X  X itle X  is more important than in a  X  X aragraph X , which in turn is more important than in the  X  X eference X . In [2], the importance of different tags are manually assigned a weights  X  (x i ) and the weight w(c) for a particular context c with a tree path x w(c) X tf x (c,t)  X  idf(c,t) . Instead of manually assigning the importance weights to different element tags and computing the importance for a context by the product of the weights of the elements on the path, we propose to apply genetic algorithm to search for the optimal context weights w(c)  X  X  based on a set of training documents for which the relevant documents have been manually selected. Genetic algorithms(GAs) provide a optimization procedure motivated by biological evolution. Given the current population of hypotheses, GAs generates successor hypotheses by mutating and recombining the best currently known hypotheses so that the members of the population will approach the optimal hypothesis in the long run. Given the collection of XML documents, we may find the set of all possible contexts in which a term may occur, denoted by C . Each hypothesis thus represents a set of | C | numbers in the range [0, 1], each of which corres ponds to the importance weight of a particular context and is encoded by a 5-bit binary string. So a hypothesis is encoded by a 5  X  |C| bit binary string. To evaluate a hypothesis, we instantiate the similarity measure with the set of context weights and use it to rank the collection for the set of training documents and compute the mean average precision (MAP) as the fitness of the hypothesis. Mutation is simulated by randomly inverting some bits in the representation and crossover is implemented by swap bits randomly sampled from two input hypotheses. The detailed algorithm is presented in Table 1. The dataset used for evaluation consists of 1894 XML documents describing items in the Museum of Qin Terracotta Warriors and Horses with a total size of 7.8 MB. Each document contains the following types of elements: title, description, record type, resource type, object condition, location, repository, reference and source. We chose 40 documents for evaluation and manually selected their relevant documents from the collection. To study the effectiveness of the structure based similarity measure for XML documents, we compare it with a baseline, which ignores the structure and compare two documents using the regular vector based similarity measure, we compare two schemes for computing w (c,t) both based on w(c)  X  tf x (c,t)  X  idf(c,t) . The first scheme, denoted by structure I, uses the same weight 1.0 for any context c . The second scheme, denoted by structure II, uses the w(c) X  X  tuned by GAs. For structure II, we evaluate its performance through 8-fold cross validation, where in each run, 32 documents are used for training and the remaining 8 for testing and the final performance is computed by averaging the performance on the testing data in the 8 different runs. The experimental results are summarized in Figure 1, based on which we can make the following interesting observations:  X  Utilizing structure has shown clearly superior performance  X  The context weight is useful for improving the structure [1] D. Carmel, Y.S. Maarek, M. Mandelbrod, Y. Mass and A. [2] V. Kakade and P. Raghavan.  X  X ncoding XML in Vector [3] Initiative for the evaluation of XML retrieval [4] S. Liu, Q. Zhu and W.W. Chu.  X  X onfigurable Indexing and 
Figure 1: Performance of different similarity measures 
