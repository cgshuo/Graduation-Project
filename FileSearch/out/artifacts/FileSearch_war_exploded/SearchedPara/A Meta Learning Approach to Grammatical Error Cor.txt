 As language learning has drawn significant attention in the community , grammatical error correction (GEC), consequently, has attracted a fair amount of attention. Several organization s have built diverse resources including grammatical error (GE) tagged corpora.

Although there are some publicly released GE tagged corpora, it is still challenging to train a good GEC model due to the lack of large GE tagged learner corpus. The available GE tagged corpora are mostly small datasets having different characteristics depending on the development methods , e.g. spoken corpus vs. written corpus . This situation forced rese archers to utilize native corpora rather than GE tagged learner corpora for the GEC task.

The native corpus approach consists of learn ing a model that predicts the correct form of an article given the surrounding context . Some researchers focused on mining better features from the linguistic and pedagogic knowledge , whereas others focused on test ing different classification methods ( Knight and Chandler, 1994; Minnen et al., 2000; Lee, 2004; Nagata et al., 2006; Han et al., 2006; De Felice, 2008 ) .

Recent ly, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results ( Han et al., 2010; Rozovskaya and Roth, 2010 ). S ince the two approaches are closely related to each other, they can be informative to each other. For example, Dahlmeier and Ng ( 2011 ) proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a na tive or GE tagged learner corpus alone . However, methods which train a GEC model from various GE tagged corpora have received less focus .
 In this paper, we present a novel approach to the GEC task using meta -learning . We focus mainly on article error s for two reasons. First, article s are one of the most significant sources of GE for the learners with various L1 backgrounds . Second, the effec tive features for article error correction are already well engineered allowing for quick analysis of the method . Our approach is distinguished from others by integrat ing the predictive models trained on several GE tagged learner corpora, rather than just one GE tagged corpus . Moreover, the framework is compatible to any classification technique. In this study, we also us e a native corpus employing Dahlmeier and Ng  X  s approach. We demonstrate the effectiveness of the proposed method against base line models in article error correction task s .
The remainder of thi s paper is organized as follows : Section 2 explains our proposed method. The experi ments are presented in Section 3 . Finally, Section 4 concludes the paper. O ur method predicts the type of article for a noun phrase within three classes: null , definite , and indefinite . A correction arises when the predict ion disagree s with the observed article. The meta -learning technique is applied to this task to deal with multiple corpora obtained from different sources.

A meta -classifier decides the final output based on the intermediate results obtained from several base classifiers. Each base classifier is trained on a different corpus than are the other classifiers . In this work, t he feature extraction processes used f or the base classifiers are identical to each other for simplicity , although they need not necessarily be identical. The meta -classifier takes the output scores of the base classifiers as its input and is trained on the held -out dev elopment data (Figure 1a ) . During run time , the trained classifiers are organized in the same manner. For the given features, the base classifiers independently calculate the score, then the meta -classifier makes the final decision based on the scores (Figure 1b). 2.1. Meta -learning
Meta -learning is a sequential learning process following the output of other base learners (classifiers). N ormally, different classifiers successfully predict results on different parts of the input space, so researchers have often tried to combine differe nt classifiers together (Breiman, 1996; Cohen et al., 2007; Zhang, 2007; Ayd X n , 2009; Menahem et al., 2009) . To capitalize on the strengths and compensate for the weaknesses of each classifier, we build a meta -learner that takes an input vector consisting of the outputs of the base classifiers. The performance of meta -learning can be improved using output probabilities for every class label from the base classifiers.

The meta -classifier for the proposed method consists of multiple linear classifier s . E ach classifier take s an input vector consisting of the output scores of each base classifier and calculates a score for each type of article . The meta -classifier finally takes the class having the maximum score.
A common design of an ensemble is to train d ifferent base classifiers with the same dataset, but in this work o ne classification technique wa s used with different datasets each having different characteristics . Although only one classification method wa s used in this work, different methods each wel l -tuned to the individual corpora may be used to improve the performance.

We employed the meta -learning method to generate synergy among corpora with diverse character istics . More specifically, it is shown by cross validation that meta -learning performs at a level that is comparable to the best base classifier (Dzeroski and Zenko, 2004) . 2.2. Base Classifiers In the meta -learning framework, the performance of the base classifiers is important because the improvement in base classificatio n generally enha -Figure 1 : Overview of the proposed method nces the overall performance. T he base classifier s can be expected to become more infor mative as more data are provided . W e followed the structural learning approach (Ando and Zhang, 2005) , which trains a model from both a native corpus and a GE tagged corpus (Dahlmeire and Ng, 2011) , to improve the base classifiers by the additional information extracted from a native corpus .

Structural learning is a technique which trains multiple classifiers with common structure. T he common structure chooses the hypothesis space of each individual classifier and the individual classifiers are trained separately once the hypothesis space is determined . T he common structure can be obtained from auxiliary problems which are closely related to the main pro blems.
A w ord selecti on problem is a task to predict the appropriate wor d given the surrounding context in a native corpus and is a closely related auxiliary problem of the GEC task. We can obtain the common structure from the article selection problem and use it for the correction problem.
In this work, a ll the base classifiers use d the same least squares loss function for structural learning. We adopted the feature set investigated in De Felice ( 2008) for article error correction. We use the Stanford coreNLP toolkit 1 (Toutanova and Manning, 2000; Klein and Manning, 2003a; Klein and Manning, 2003b; Finkel et al, 2005) to extract the features. 2.3. E valuation Metric
T he effectiveness of the proposed method is evaluated in terms of accuracy, precision, recall, and F 1 -score (Dahlmeire and Ng, 2011). Accuracy is the number of correct predictions divided by the total number of instances. Precision is the ratio of the suggested corrections that agree with the tagge d answer to the total number of the suggested correction s whereas recall is the ratio of the suggested correction s that agree with the tagged answer to the total number of correction s in the corpus. 3.1. Datasets In this work we use d a native corpu s and two GE tagged corpora. For the native corpus, we used news data 2 which is a large English text extracted from news articles. The First Certificate in English exams in the Cambridge Learner Corpus 3 (hereafter, CLC -FCE ; Yannakoudakis et al. , 2011 ) and the J apanese L earner E nglish corpus (Izumi et . a l . , 2005) were used for the GE tagged corpora .
We extracted noun phrases from each corpus by parsing the text of the respective corpora . (1) We parsed the native corpus from the beginning until approximately a million noun phrases are extracted. (2) About 90k noun phrases containing ~3,300 mistakes in article usage were extracted from the entire CLC -FCE corpus, and (3) about 30k noun phrases containing ~2,500 mistakes were extracted from the JLE corpus. 
The e xtracted noun phrases were used for our training and test data. We hold out 10% of the data for the test. We applied 20% under -sampling to the training instances that do not have an y error s to alleviate data imbalance in the training set.

We emphasize the fact that the two learner corpora differ from each other in three aspects. The first aspect is the styles of the texts : the CLC is literary whereas the JLE is colloquial. The second is the error rate: about 3.5% for CLC -FCE and 8.5% for JLE . Finally, the third is the distribution of L1 languages of the learners : the learners of the CLC corpus h ave various L1 background s whereas the learners of the JLE consist of only Japanese. The se experiments demonstrate the effectiveness of the proposed method relying on the diversity of the corpora.

T he native corpus was used to find the common structure using structural learning and two GE tagged learner corpora are used to train the base classifiers by structural learning with the common structure obtained from the n ews corpus.

We trained three classifiers for comparison ; (1) the classifier (INTEG) trained with the integrated training set of the two GE tagged corpora , and two base classifier s used for the ensemble : (2) the base classifier (CB) trained only with the CLC -FCE and (3) the other base classifier (JB) trained with the JLE . 3.2. Results The accuracy obtained from the word selection task with the news corpus was 76.10%. Upon obtaining the parameters of the word selection task, the structural parameter  X  was calculated by s ingular v alue d ecomposition and was used for the structural learning of the main GEC task.
 We used three different test data sets: the CLC -FCE , the JLE and an integrated test set of the two . The accuracy (Acc . ) and the precision (Prec.) of the INTEG was poorer than CB on the CLC -FCE test set (Table 1) , whereas INTEG outperformed JB on the JLE test (Table 2) . 
S ome instances extracted from the CLC -FCE corpus have similar characteristics to the instances from the JLE corpus. This overlap of instances affect ed the performance in both positive and negative ways. Prediction of instances similar to those in the JLE was enhanced . C onsequently, INTEG model demonstrated better accuracy and precision for the JLE test set . Unfortunately , for the CLC test set, the instances resulted in lower accuracy and precision .

The proposed model is able to alleviate this model bias due to similar instances observed in the INTEG model. T he accuracy of the proposed model consistently increased by over 10% for all three data sets. The relative performance gain in terms of F1 -score (F 1 ) was 15% on the integrated set. This performance gain stems from the over 25% relative impr ovement of the precision (Table 1, 2 and 3 ) .

We believe the improvement comes from the contribution of reconfirming procedure s performed by the meta -classifier. When the prediction of the two base classifiers conflicts with each other, t he meta -classifier tend s to choose the one with a higher confidence score; this choice improve s the accuracy and precision b ecause known features generate a higher confidence whereas unseen or less -weighted features generate a lower score .
Although t he proposed model introduced a tradeoff between precision and recall (Rec.) , this tradeoff was tolerable in order to improve the overall F1 -score. Since GEC is a task where false alarm is critical, obtaining high precisi on is very important. The low precision on the whole experiments is due to the data im balance . I nstances in the dataset are mostly not erroneous, e.g., only 3.5% of erroneous instances for the CLC corpus. T he standard for correct prediction is also very strict and does not allow multiple answer s. P erformance can be evaluated in a more realistic way by a pplying a soft er standard , e.g., by evaluating manually. We have presented a novel approach to grammatical error correction by building a meta -classifier using multiple GE tagged corpora with different characteristics in various aspects . T he experiments showed that building a meta -classifier overcomes the interference that occurs when training with a set of heterogeneous corpora. T he proposed method also outperforms the base classifier themselves tested on the same class of test set as the train ing set with which the base classifiers are trained. A better automatic evaluation metric would be needed as further research.
 Industrial Strategic technology devel opment program, 10035252, development of dialog -based spontaneous speech interface technology on mobile platform, funded by the Ministry of Knowledge Economy (MKE, Korea) .
 Model Acc . Prec . Rec . F 1 INTEG 73.37 4.69 72.39 8.82 CB 77.20 5.39 71.17 10.03 Proposed 86.99 6.17 45.77 10.88 Table 1 : Best results for GEC task on CLC -FCE test set. Model Acc . Prec . Rec . F 1 INTEG 78.87 14.88 85.47 25.35 JB 78.02 14.49 86.32 24.82 Proposed 89.61 19.28 46.60 27.27 Table 2 : Best results for GEC task on JLE test set. Model Acc . Prec . Rec . F 1 INTEG 74.64 6.84 77.86 12.58 Proposed 87.50 8.61 46.12 14.52 Table 3 : Best results for GEC task on the integrated set of CLC -FCE and JLE test sets.
