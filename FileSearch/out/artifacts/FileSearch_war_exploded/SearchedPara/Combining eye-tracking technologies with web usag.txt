 1. Introduction
Mining, which studies different ways of extracting information from data generated on the Web. With this knowledge, it is possible to develop techniques and algorithms to attract and retain users on a website. Specifically, this area applies data mining techniques to data originated on the Web with the aim of obtaining valuable information to continuously improve a website in terms of design and content, among other aspects. the Website Keywords ( Vela  X  squez et al., 2005 ), defined as a word or set of words used by users in their information search process, and which characterizes the content of a website or page. After finding them, the sites can be redesigned according to the needs and requirements of its users and, thus, be in the vanguard.
Although identifying the Website Keywords of a site helps to know the preferences of users, the methodology that discovers them only focuses on the textual content, leaving out the analysis of the multimedia content of websites. For this reason, in Dujovne and Vela  X  squez (2009) the methodology was extended and inte-grated with both the textual content and the multimedia content in their analysis.

In Dujovne and Vela  X  squez (2009) web objects are defined as  X  X  X ny structured group of words or a multimedia resource that is present on a web page that has metadata which describe its content X  X . Also, they characterized a Website Keyobject as a web object that captures the attention of the users and that charac-terizes the contents of a website ( Vela  X  squez et al., 2011 ). From the above definitions it is possible to deduce that every website consists of a set of web objects and that the set of Website Keyobjects it has is a subset of the former.

Also in Vela  X  squez et al. (2011) the designed methodology allowed the identification of the Website Keyobjects of a site.
These, like the Website Keywords Vela  X  squez (2011) , give guide-lines for the websites to be redesigned according to user require-ments. This methodology requires knowledge of the time spent by users on the web objects, i.e., how long a user spends looking at each web object. To determine the permanence time they propose two steps, sessionization and the application of a survey.
A. Sessionization : It is the process that reconstructs user sessions. A session is the sequence of web pages visited by a user while browsing a site. The necessary data for a session reconstruction is registered in the web log files. Through this process it is possible to determine, for example, the permanence time of a user on each page, among other things.

B. Application of a survey : It refers to the implementation of a survey on a control group, wherein web objects were sorted according to their importance within each page of the website.
By mixing the two processes, the time spent by users on the web object is estimated. However, thanks to the eye-tracking technology it is possible to dispense with this survey. Eye-tracking technology allows knowing what a person looks at as a function of time ( Ali-Hasan et al., 2008 ). By applying this technology to users browsing a site it is possible to measure the time spent on each web object. In this sense, if it was possible to quantify the permanence time of a control group of users on web objects, an improvement to the methodology developed in Vela  X  squez et al. (2011) could be made, i.e., determining the Website Keyobjects more accurately.

Section 2 describes the related work with the paper proposal, explaining concepts like web mining, the nature of the data originated on the Web and how eye-tracking techniques have facilitated the application of its usability for analyzing computer-based systems. Section 3 describes the elemental issues for understanding how the eye-tracking techniques work. Section 4 shows a methodology for identifying Website Keyobjects, the main problem to be tackled in this paper. In Section 5 , the whole set of experiments performed for demonstrating the practical utility of eye-tracking tools in the scope of web mining is shown. Finally, Section 6 presents the paper X  X  conclusions and future work. 2. Related work
In this section a conceptual framework about the traditional web mining process, which uses data originated on the Web, and the possibility of using other kinds of data, for instance those generated by the application of eye-tracking tools, will be introduced. 2.1. Data originated on the web
The data that are originated on the Web are classified into three types ( Vela  X  squez and Jain, 2010 ): content, structure and usage. 1. Content : It refers to the objects on Web pages, including text, images, sounds and videos, in other words, all that can be seen on a page. Thus, the text can be presented in a semi-struc-tured, highly structured or unstructured way. On the other hand, the multimedia content requires metadata that describe it; however, it is uncommon to find these descriptions. 2. Structure : They are the links between pages. Usually when there is a link between two pages, these are related by their content. If a set of pages are linked together, a common information community is created. 3. Usage : It is the data generated by users in their navigation process, as Web servers store each request made by users in a file called a web log. 2.2. Web mining
Web mining is the application of data mining to data origi-nated on the Web ( Chang et al., 2001 ; Vela  X  squez and Jain, 2010 ). It is conceived as a product of the intersection of several research areas such as databases, information retrieval, artificial intelli-gence, especially the sub-areas of machine learning and language processing ( Etzioni, 1996 ). Research in this field is experiencing significant growth because of the large amount of data available for analysis ( Kosala and Blockeel, 2000 ). This is no small task, considering that the Web is a large collection of heterogeneous, declassified, distributed, time-varying, semi-structured high-dimensional data ( Pal et al., 2002 ).

Since the data originating from the Web can be classified into three categories, it is natural that Web mining also branches into these categories. Their nature differs in the way that they are set up as different problems. The sub-areas are ( Vela  X  squez and Palade, 2008 ; Kosala and Blockeel, 2000 ; Vela  X  squez and Jain, 2010 ): 1. Web content mining (WCM): It is targeted to discover useful information from Web documents. WCM is not only limited to analyzing the text of Web pages, but also includes other types of documents such as images and videos. However, the analysis of this data type, called multimedia data mining, does not receive as much attention as text analysis. 2. Web structure mining (WSM): It is the sub-area which studies the links on Web pages. The pages and links are modeled as the nodes and arcs of a directed graph, respectively. The arc starts on the node that represents the page that has the link and ends at the node representing the page being targeted. 3. Web usage mining (WUM): It is focused on the application of data mining techniques to discover useful patterns that can predict user behavior while interacting on the Web. To dis-cover these patterns, the browsing sessions, understood as the sequence of pages that a user visits while surfing the web, are analyzed. 2.3. Web user perception
One important question when a web page is designed is about what the web user will perceive and understand concerning the content and structure shown ( Lee et al., 2004 ). Perception is a function of thinking, i.e., how we recognize and interpret an object by using our senses for encoding, storing and integrating information related to some previous knowledge.

Understanding web user perception is important for creating a better website design, which will finally attract and retain the users. However, it is not a simple task, because this perception is related to the web user X  X  knowledge background, i.e., his/her personal experience ( Novak et al., 2000 ).
 According to the conceptual model of flow proposed by
Hoffman and Novak (1997) during the web user X  X  navigation, the website structure is perceived as a cognitive experienced state, which is determined by  X  X  high levels of skill and control ; high levels of challenge and arousal ; focused attention ; and is enhanced by interactivity and telepresence  X  X . Perhaps the unique factor that can be influenced directly by construction of the website is the web user X  X  focused attention. However, it could be a double-edged sword, i.e, attention can be captured because the website content is attractive or because the content is unpleasant, in which case the web user will never again visit the site.

In any case, to understand what the web user is looking for, or at least to know what elements in the website capture his/her attention it is useful to improve the site structure and content.
In that regard, many approaches have been addressed, usually from the information and knowledge extracted from web data ( Kosala and Blockeel, 2000 ; Pal et al., 2002 ) and also from the usability theory for creating web-based systems ( Nielsen and Pernice, 2009 ).
 2.4. Usability approaches that assesses how easy user interfaces are to use  X  X  and it has five quality components to be analyzed: the above components, it is necessary to implement qualitative and quantitative measures about the user experience. In that sense, a number of evaluation methods have been created ( Jay et al., 2008 ): for researching purposes, a combination of two or more of them are necessary, mainly because its application always has a subjective component. For instance, the first six methods need to apply some kind of survey for getting the user point of view. In the case of eye-tracking tools, more precise quantitative measure can be obtained because an independent computerized system is used for tracking the user X  X  eye position on the computer X  X  screen, and to use these data a certain indicator about what the user seeing is extracted, which can be used as a measure of the user interest in a web page. However, the eye position also can be influenced by external situations that could modify the user X  X  mood, altering the fixation of their eyes. In conclusion, the eye-tracking method is arising as one of the most objective in terms of the usability measure ( Nielsen and Pernice, 2009 ). 2.5. Eye tracking ments are measured. Thus, a res earcher can know what a person is looking at in each moment and the sequence in which their eyes move from one place to another. Following the eye movements of people can help researchers of the human X  X omputer interaction to understand the processing of visual information and the factors that may impact upon the usability of the interface. Thus, recordings of eye movements can provide a source of objective data for the evaluation of interfaces, which in turn may provide information to improve their design ( Poole and Ball, 2005 ). 2.6. Eye movements
When looking at any scene, the eyes of a person move between points that capture their attention, which are able to recreate a brain image of the scene. While there are models of complex eye move-ments consisting of five steps ( Duchowski, 2003 ), the typical model (which is enough for studies of eye tracking) consists of two concepts, fixation and saccades. Fixation is defined as the moment in which the eyes are fixed on an object and it is possible to appreciate it in detail, while the saccades correspond to rapid eye movements between two fixations ( Nielsen and Pernice, 2009 ). It is important to note that while pr oducing a saccade we are blind (we are not aware of what is between the two objects that caught our attention). However, our brain can interpret this  X  X  image sequence  X  X  as a continuum, and therefore, our perception seems more like a video than a sequence of images. 2.6.1. Visual attention
Visual attention is a phenomenon that has been studied for about a 100 years and still cannot be understood. Early studies were limited by technology, and corresponded only to observa-tion and introspection. At present, this field is studied by different disciplines such as psychophysics, cognitive neuroscience and computer science, to name a few ( Duchowski, 2003 ). Overall, human vision consists of two parts, a small central area with a very high resolution, called foveal vision, and the large majority of the visual field with a low resolution, called peripheral vision.
Usually, the fact of paying attention to regions of interest is related to eye movements (overt attention). However, we can also pay attention to peripheral objects without making such move-ments (covert attention) ( Ali-Hasan et al., 2008 ).

On the other hand, there are two known ways in which attention is guided, bottom-up and top-down. The first, derived only from the visual scene, posits that regions of interest attract our attention strongly enough to not look at the rest of the scene (foveal vision). In turn, top-down is driven by cognitive factors such as knowledge, expectation and current goals. Under this model, people are more inclined to look around (peripheral vision); as an example, an individual who drives regularly is more likely to notice the gas stations while doing other activities than someone who does not drive ( Frintrop et al., 2010 ).
Nowadays, it is not yet clear what it is that really captures our attention, nor how we respond to different stimuli. There is an evidence that we pay attention to spatial locations, features and objects. Most researchers believe that these theories are not mutually exclusive and moreover, that visual attention can be developed in each of these sub-areas. It is worth noting that humans can pay attention simultaneously to multiple regions of interest (a maximum of five) ( Poole and Ball, 2005 ). 2.6.2. The Eye-mind hypothesis Considering the theories described in the previous section, in
Duchowski (2003) posited the following model: 1. Given a stimulus such as an image, the scene is seen largely in parallel through peripheral vision and therefore, at low resolution. At this stage, the interesting features of the image can  X  X  X ppear X  X . 2. In this moment, attention is disconnected from the foveal vision (high resolution), but the eyes quickly move toward the first region of attraction. 3. Once the eyes are positioned, the fovea is aligned to the region of interest and attention is linked to perception, i.e., the user X  X  attention has been captured and, therefore, it is possible to observe in high resolution.

In Nielsen and Pernice (2009) a simple model is proposed, which in its essence is the same. Their hypothesis states that  X  X  People are usually thinking about what they are looking at. Although they do not always understand what they see or are not fully focused on it ; if they are observing something, then they are paying attention , especially when they are concentrated on a particular task  X  X . 2.7. Eye tracking and perception on the web
How human beings allocate attention within different parts of a web page is an interesting issue to investigate. In fact, knowing which visual objects assist in or distract web user navigation from finding what is being looked for, could be the key to modifying website structure, content and web object characteristics, such as position, shape, etc. within a web page ( Michailidou et al., 2008 ).
Eye-tracking systems have been used to investigate how sighted persons use and perceive the web object features on a website. This new knowledge is very important for web page designers, web masters, advertisers, etc., because many innova-tions can be improved for web page design, creation and visual representation ( Buscher et al., 2009 ).

The correct free text distribution and other web object pre-sentation on a web page can significantly improve the web user comprehension regarding what she/he reads and understands. In fact, web user behavior is not the same when faced by a text-only page versus an illustrated one. The correct content and distribu-tion on a web page can facilitate both web user comprehension and the information searching task, by making the page more attractive ( Buscher et al., 2010 ).

An open question is which regions within a web page the user recognizes from previously visited ones. Indeed, if that knowledge can be extracted, compact versions of the page could be created, assisting the web user during an exploration or search task.
To combine the knowledge extracted by analyzing web user perception by using an eye-tracking tool with the knowledge extracted from web user behavior by applying web mining algorithms in data originated on the website, is the objective of this paper. Both techniques are complementary and useful for the final goal: to understand what the web user is looking for on a website ( Vela  X  squez, 2012 ). 3. Eye-tracking techniques
To understand how the eye-tracking technology can be used in a web mining process, in this section we will review the basis concepts about its operation ( Holmqvist et al., 2011 ). 3.1. Electrooculography
In the 1950s, electrooculography ( Kaufman et al., 1993 ) was the most-used eye-tracking technique. It was based on measuring the difference of electrical potential of the skin through the use of electrodes located around the eyes. This is possible since the cornea is kept some 10ths of mV more positive than the retina, which produces the difference of potential that is measured, and which varies according to the movement of the eyes. This technique measures the relative position of the eyes with respect to the head; therefore, it is not appropriate for calculating the point of attention ( Bulling et al., 2011 ). 3.2. Scleral contact lenses
This technique consists of attaching a mechanical or optical reference to a contact lens to be used directly on the eyes. It is necessary that the contact lens be particularly large, so that it extends over the cornea and sclera, since this reduces the possibility of it moving across the eye ( Duchowski, 2003 ).
Different types of references on contact lenses have been used, the most common being a small coil, which can be located externally by applying an electromagnetic field ( Roberts et al., 2008 ; Van der Geest and Frens, 2002 ). While it is one of the most precise techniques for measuring eye movements, it is also the most invasive, and causes discomfort when being used. 3.3. Reflection of the cornea and pupil center based on video
This is the eye-tracking technique which is most commonly used nowadays. It consists of a standard desktop computer with an infrared camera mounted under a monitor, with image-processing software to locate and identify the reflection of the cornea and the center of the pupil. With these characteristics, it is possible to dissociate eye movements from the position of the head, which makes it possible to calculate the attention focus of users ( Poole and Ball, 2005 ).

In operation, an infrared light from an LED is directed toward the user to create noticeable reflections of the features of the eyes, thus making tracking easier (infrared light is used to avoid dazzling the user). Light enters the retina and a lot of it is reflected, so that the pupil appears as a bright, well-defined disc (the effect known as bright pupil). The corneal reflection is also generated by infrared light, appearing as a small but strong shine ( Poole and Ball, 2005 ). Fig. 1 shows the bright pupil effect and the corneal reflection.

A digital camera captures and records the reflection light and the collected data are analyzed to extract the eye rotation through variations in the corneal reflection, also called  X  X  X lint X  X  or the first Purkinje reflection ( Morimoto et al., 2000 ).
 In Fig. 2 I 1 is the reflection from the cornea X  X  external surface;
I is the reflection from the cornea X  X  internal surface; I 3 the reflection from the anterior surface of the crystalline lens and finally I 4 is the reflection from the other surface of the crystalline lens.

Once the image processing software has analyzed the I 1 , ... , I corneal reflex, the vector that results from them is measured, and by using some trigonometric calculations, the point of attention can be found.
 4. Methodology to find Website Keyobjects  X  X  a structured group of words or multimedia content that is present on a Web page, and which has metadata describing its content . X  X  In the previous definition, the metadata are fundamental as they are the basis of the information to construct the vector representing the content of the page. In addition, two multimedia files can be compared by their metadata, a problem which can be dealt with more easily than comparing files directly, because it only com-pares text. Along with this, they defined the Website Keyobject as  X  X  one or a group of web objects that attract user attention and which characterize the contents of a web page or site  X  X . They provide knowledge about the content and format of most interest to users of a website, therefore finding them may be useful to improve the site both in presentation and content.

Website Keyobject are ( Vela  X  squez et al., 2011 ): 4. Web object similarity : To compare two web objects a similar-5. Permanence time on objects : after defining the objects, it is 6. Vector of user behavior : finally, for each session identified, the 7. Clustering algorithms : once all the cleaning and transforma-8. Similarity measures for sessions : The similarity defined for 5. Experiment and results
On a site, the methodology designed by Vela  X  squez et al. (2011) hereinafter the original methodology will be executed, and also the modified methodology will be executed, to which the perma-nence times calculated with an eye tracker will be incorporated. 5.1. Experiment
To capture the interest of users in the different objects of the pages, two procedures will be used, using an eye tracker and the application of a survey. In this sense, experiments were con-ducted on the site www.mbauchile.cl belonging to the Master in Business Administration and Management program of the Depart-ment of Industrial Engineering of the University of Chile. Fig. 3 shows the site, which consists of 124 pages and 163 different objects that appear on the site 2047 times. Thus, the average number of objects per page is 12.55. With regard to visits, each month 4158 different people access the site, 6111 sessions are recorded and 26,589 pages are seen.

On the other hand, before selecting the controlled users who would participate in the experiment, the business expert was asked for information on the target of the site under study with the objective of choosing a representative sample of individuals who visit the site. Considering this information, 33 people were selected. Of these, 16 were male and 17 female, and their average age was 24.3 years. Regarding the knowledge and use of the Web, 15 of them defined themselves as expert web users, 12 considered that their knowledge is average and only six of them defined themselves as basic users.

Finally, for the development of the experiments eye tracking software and hardware tools were used. Regarding the hardware, the Tobii T120 Eye Tracker 1 was used, which consists of a 17-in. monitor to which two infrared emitters and a light sensor are incorporated. This hardware has a time resolution of 120 Hz and has a margin of error of 0.5. With respect to software, the Tobii
Studio Enterprise Edition was used, a solution which easily allows mapping what is displayed on the monitor with the same location that users observe. 5.1.1. Capturing of data
To discover the composition of the site http://www.mbauchile. cl , a crawler that generated the list of pages that make up the site was implemented. This crawler was developed using the Beautiful
Soup Python library. Once the list of pages to be analyzed was captured, the following procedure was used in identifying the objects of the site. To separate each page into the objects that compose it, two criteria were considered, differences in the content (concepts) and the spatial separation between objects of each page. In order to know the coordinates of the objects within the pages, the Python Imaging Library (PIL) was used, which allows working with images on the Python interpreter. A script was used, which from the images of the pages of the site generated the coordinates of the various objects belonging to each page. After defining the objects, by using the methodology explained in Section 4 , the pixels that compound the web objects are identified as shown in Fig. 4 and the concept that described them were generated.

Regarding the visits to the site, it was possible to recover the web log from the server that hosts the site together with the system administrator. It was not possible to recover all of the requests as the historic records were not stored. However, the requests corresponding to the month of August 2011 were obtained. During this month, 3031 different people visited the site, in 5480 sessions. In total 28,832 pages were viewed, there were 156,259 requests and a traffic of 3.20 GB was reached. In order to measure the interest of users in the web objects, their permanence time on each was measured and estimated. This was done in two ways, by using an eye tracker and by applying the following survey used by Vela  X  squez et al. (2011) .
First a list of web objects is identified and three questions were asked to the controlled users. The first one was  X  X  Which object was the most appealing to you within the whole Website ? X  X , the second question was to make a top 20 list with all the objects of the site being the first the most appealing for them. Finally for each page which had two or more objects, 10 points must be awarded between all of them having the most points the object which was the most appealing to the user within a certain page. An example about how the survey works is shown in Table 1 which contain the answers given by one user. The survey was applied on web pages containing two or more objects.

The data contained in Table 1 were interpreted as follows: one page can contain two or more objects (until four), the column
Favorite shows the favorite object and the regarding four columns the points given by the user to each object. For instance, the page
ID 9 has the objects IDs 11 and 12. From these two objects, the favorite one for the user is the ID 11 because 7 points were given, where only 3 points were given to object ID 12.

Next step was to propose to 15 of the controlled users the following situation:  X  X  You have an intention to apply for an MBA program , but have not yet made a final decision , therefore your first step will be to get informed. In the search for information you have arrived at the website http://www.mbauchile.cl , which provides relevant data about the MBA program offered by the University of
Chile. Starting from the home site , navigate freely until you can make a decision or decide to take a new step  X  X . In this way, it was attempted to emulate the typical navigation of users at home.
The remaining 18 individuals did not navigate freely, but were
Each of them was presented semi-random pages of the site. Users could move to the next page when deemed convenient, but if they spent more than a minute on a page, they were automatically redirected to the following page. The number of pages displayed to users was not higher than 30.
 their eye movements were captured, subjects were asked to answer a survey in which they had to indicate the objects that most captured their attention. To measure the interest of the users, they had to distribute 10 points, as they chose, over the objects on each page, considering that the more points an object had, the more interest he or she had. 5.1.2. Selection, data cleaning and transformation
Once the 163 objects on the site were identified, the business expert validated this separation, but also brought together, broke up and removed some pre-selected objects. Following this valida-tion, as some objects changed, it was necessary to re-calculate their positions on the pages. To do this, the script that generated the location (in pixels) of objects on the page was modified and re-executed. Then the coordinates of the pixels of the objects were normalized according to the size of the stimulus, so that the coordinates of the objects came from being stored as integers between 0 and the length of the object, to a double-precision value between 0 and 1. Regarding the concepts (which describe objects), the way in which they were generated was validated by the business expert, so it was not necessary to make any changes, except for grouping or breaking up the concepts of objects that were modified by the expert. Then, the script that calculates the conceptual similarity between objects was implemented. To implement this script, the algorithm defined previously by Vela  X  squez et al. (2011) was followed. Data transformation was separated from user interest according to the way in which the data were captured.

The first step in transforming this data was grouping them according to the point observed (in a small neighborhood), increas-ing the duration of fixation according to the number of records grouped. A known statistical result is the range of duration of fixations, which are between 150 and 600 milliseconds (ms) ( Duchowski, 2003 ), where the lowest threshold at which the brain can understand what is being observed is 150 ms. As noted above, the eye tracker used has a resolution of 120 Hz, therefore it captures information every 8 ms. With this in formation, the records (already grouped) with the fixation-durat ion field lower than 150 ms were considered invalid, as in this cas e, the user interviewed never noticed whether he or she was looking at a point at that moment. With the invalid records, whether because of a fixation-duration lower than 150 ms or because it was indicated by the validity-left and validity-right attributes, an indicator was constructed, called acceptance-percentage, which showed the percentage of time in which the eye movements of the controlled user upon each stimulus (website) were correctly measured. If this indicator was small, it would be a mistake to consider the records corresponding to the stimuli for further analysis, because results would simply be extrapolated which could be valid or not. For this reason, the records corresponding to stimuli with low acceptance-percentage were eliminated. Stimuli with acceptance-percentage higher than the average of all values plus two standard deviations were considered valid, resulting at a minimum 86%. From this result it is possible to consider the data capture with the eye tracker as successful. Finally, the permanence times were averaged.
On the other hand, the results of the survey corresponded to files where the page, the object, and points of interest assigned by the user were registered. These data were transformed so that the 10 points assigned by each user, corresponded to 100% of user interest in the stimulus. For example, if a person assigned 5 points to object X on page Y , it was assumed that the interest of the user in object X was 50% on page Y . Similar to the previous case, 0 was assigned to the interest of the user in objects that did not get points. Afterwards these results were averaged and stored. Starting from web requests recovered, the next step was to run the process of sessionization. The result was a set of sessions, in which each of these contained a list of pages associated with the amount of time spent on these. Then, for each register, the page was replaced by the objects that made it up, and the time spent on the page was weighed by the percentage of permanence on the object. Additionally the objects that appeared on more than one page were considered with special attention, because for a session the same object could have been seen twice. In this case, the times for both pages were added up, because they were paid attention twice. Then the most important n objects in each session were selected. The criterion for selecting the most important objects was the time spent on them. 5.1.3. Application of data mining algorithms The methodology to find Website Keyobjects designed in Vela  X  squez et al. (2011) grouped the Important Objects Vectors (IOV see Eq. (5) ) by using three techniques: Self-Organizing Feature Maps, k -means and Association Rules. The results of these techniques were sets of vectors where the elements were similar to each other, but different when taking elements from different sets. The criteria used to determine if an object was a Website Keyobject was to select the objects that appeared more times in the clusters shown by the three algorithms. 5.1.4. Experiments
As a first experiment, the same strategy used in Vela  X  squez et al. (2011) was developed, in which the results of the survey about the importance of the web objects, from the user point of view, was used for estimating the time spent by a user seeing an object in a visited page during his/her session. In that sense, the average of points assigned in Table 1 per web object were calculated.

Because the sessionization process gives us the total time spent by the web user in a visited page, an estimation for the time spent seeing each web object in the page is necessary. This estimation is obtained by weighing the time spent in each page with the average of points from the above survey.

In the second experiment, the above described survey is eliminated and the time spent for the web user seeing the web objects in a visited page is calculated by using the data generated with the application of the eye tracking tool. 5.2. Results
The SOFM network was implemented in Python using {12 12, 14 14, 18 18, 24 24} neurons in the chart with a toroidal topology. However, after several tests regarding the number of neurons of the SOFM network, it was found that one constituted by 12 12 neurons gave the best results.

This network gave 8 clusters for each experiment. The output of this algorithm was modified to deliver lists of session identi-fiers belonging to each cluster, in order to count the number of occurrences of objects in different clusters.

Regarding the k -means technique, it was implemented in Java 1.42, using k as the number obtained by the previous technique, i.e., 8. On the other hand, for the implementation of Association
Rules, the Weka platform 2 was used. Only objects in the IOVs that were processed according to the platform were considered. The
Apriori algorithm was used and it was asked to generate only 30 rules with a maximum confidence of 0.9. Both the algorithm and the platform to be used were the ones used by Vela  X  squez et al. (2011) when he implemented this methodology. 5.2.1. Precision, recall and F-measure
To compare the results of both experiments, three ranges were selected, taking 10, 20 and 30 Website Keyobjects. Table 2 shows the precision achieved by experiments in the three ranges selected. Table 3 shows recall, and Table 4 shows the F-measure indicator.

An improvement of 15 X 20% can be noticed by comparing both experiments, which validates the fact that this technology is useful for measuring the interest of users. On the other hand, one can note that when choosing 30 Website Keyobjects the accuracy obtained decreases. This is because for this number a selection of objects that are not relevant begins. At this point, if we consider n  X  24 as threshold it is concluded that the accuracy of the second experiment is 93%. Regarding recall, when taking 10 or 20 Website Keyobjects, this indicator is considerably smaller.
This is expected since some Keyobjects are no longer being considered. However, in the second experiment, better results for all ranges observed are obtained. Finally, F -measure is a measure that combines both accuracy and recall indicators, therefore it was expected to achieve better results in the second experiment. 6. Conclusion and future work
In the present paper it was proved that using an eye tracker to measure the amount of time users spend looking at the different objects on a web page instead of conducting a survey to estimate these values improve the accuracy of finding the Website Key-objects of a site. To achieve this result, a comprehensive study on data originating from the Web, on the mathematical models used to describe the behavior of web users and on existing eye-tracking tools was carried out.
 determines what a person looks at. This is insufficient when what is sought is to qualify what a person looks at. In other words, these tools cannot determine if what is observed is liked or disliked. Therefore, the results provided by the eye tracker must be considered as the measure (always positive) of the interest of a person.
 the following step to improve the methodology to find Website
Keyobjects, the need to consider what users feel or think while looking at a web object naturally arises. This could be achieved by using elements of neurotechnology, such as electrodes that measure what brain area is more excited when a person is navigating a website. Emotiv.com is a company that manufac-tures this type of equipment (for this type of research) at a low cost.
 consists of further exploring the data generated by the eye tracker. During the course of this research only these data were used to determine what objects the controlled users looked at.
However, there is a wide range of studies that can use these data, such as determining from the trajectory of the eye movements if a person understands what he or she sees or not. Furthermore, no data on pupil dilation were considered, it being known that the more dilated they are, the greater the interest of a person in what they see. However, it is still not possible to classify this interest as good or bad.
 herein, for example, to establish an ontology to standardize metadata. This could establish more expressive relationships between objects. In this same area, it could be possible to automate the process generating the metadata, because so far it is a slow and tedious process that, being manual, allows the introduction of unintentional errors. Finally, it could be possible to analyze the way in which this methodology operates, to investigate whether changing the structure of it can achieve better results than using three different data mining algorithms.
Thus, creating a new way of ranking the objects may help in this goal.
 Acknowledgment This work was supported partially by the FONDEF project D10I-1198 entitled, WHALE: Web Hypermedia Analysis Latent
Environment and the Millennium Institute on Complex Engineer-ing Systems (ICM: P-05-004-F, CONICYT: FBO16).
 References
