 We address the problem of marker-less articulated pose and s hape estimation of the human body from images using a detailed parametric body model [3]. Most prior work on marker-less pose exploit crude models of body shape ( e.g. cylinders [8, 15], superquadrics, voxels [7]). We argue that a richer representation of shape is needed to make futur e strides in building better generative models. Discriminative methods [1, 2, 10, 13, 16, 17], more r ecently introduced specifically for designed to be invariant to body shape variations. Any real-world system must be able to estimate both body shape and pose simultaneously.
 Discriminative approaches to pose estimation attempt to le arn a direct mapping from image fea-tures to 3D pose from either a single image [1, 14, 17] or multi ple approximately calibrated views [9]. These approaches tend to use silhouettes [1, 9, 14] and s ometimes edges [16, 17] as image features and learn a probabilistic mapping in the form of Nea rest Neighbor (NN) search, regression [1], mixture of regressors [2], mixture of Baysian experts [ 17], or specialized mappings [14]. While effective and fast, they are inherently limited by the amoun t and the quality of the training data. More importantly they currently do not address estimation o f the body shape itself. Body shape es-timation (independent of the pose) has many applications in biometric authentication and consumer application domains. Simplified models of body shape have a long history in compute r vision and provide a relatively low dimensional description of the human form. More detailed tr iangulated mesh models obtained from laser range scans have been viewed as too high dimensional fo r vision applications. Moreover, mesh models of individuals lack a convenient, low-dimensional, parameterization to allow fitting to new subjects. In this paper we use the SCAPE model (Shape Complet ion and Animation of PEople) [3] which provides a low-dimensional parameterized mesh that i s learned from a database of 3D range scans of different people. The SCAPE model captures correla ted body shape deformations of the body due to the identity of the person and their non-rigid mus cle deformation due to articulation. This model has been shown to allow tractable estimation of pa rameters from multi-view silhouette image features [5, 11] and from monocular images in scenes wi th point lights and cast shadows [4]. In [5] the SCAPE model is projected into multiple calibrated images and an iterative importance sampling method is used for inference of the pose and shape th at best explain the observed sil-houettes. Alternatively, in [11] visual hulls are construc ted from many silhouette images and the tures with SCAPE. Both [5] and [11], however, require manual initialization to bootstrap estimation. In this paper we substitute discriminative articulated pos e and shape estimation in place of manual with the estimation of shape, and couple the discriminative and generative methods for more robust combined estimation. Few combined discriminative and gene rative pose estimation methods that exist [16], typically require temporal image data and do not address shape estimation problem. For discriminative pose and shape estimation we use a Mixtur e of Experts model, with kernel linear regression as experts, to learn a direct probabilistic mapp ing between monocular silhouette contour features and the SCAPE parameters. To our knowledge this is t he first work that has attempted to recover the 3D shape of the human body from monocular image di rectly. While the results are typi-For generative optimization we make use of the method propos ed in [5] where the silhouettes are predicted in multiple views given the pose and shape paramet ers of the SCAPE model and are com-pared to the observed silhouettes using a Chamfer distance m easure. For training data we use the SCAPE model to generate pairs of 3D body shapes and projected image silhouettes. Evaluation is performed on sequences of two subjects performing free-sty le motion. We are able to predict pose, shape, and simple biometric measurements for the subjects f rom images captured by 4 synchronized cameras. We also show results for 3D shape estimation from mo nocular images.
 The contributions of this paper are two fold: (1) we formulat e a discriminative model for estimating the pose and shape directly from monocular image features, a nd (2) we couple this discriminative method with a generative stochastic optimization for detai led estimation of pose and the shape. In this section we briefly introduce the SCAPE body model; for details the reader is referred to [3]. A low-dimensional mesh model is learned using principal com ponent analysis applied to a registered database of range scans. The SCAPE model is defined by a set of p arameterized deformations that are applied to a reference mesh that consists of T triangles {  X  x Each of the triangles in the reference mesh is defined by three vertices in 3D space, ( v and has a corresponding associated body part index p has P = 15 body parts corresponding to torso, pelvis, head, and 3 segments for each of the upper and lower extremities). For convenience, the triangles of t he mesh are parameterized by the edges, articulated pose of the body amounts to estimating paramete rs, Y , of the deformations required to produce the mesh {  X  y state-space of the model can be expressed by a vector Y = {  X ,  X ,  X  } , where  X   X  R 3 is the global to the skeleton (encoded using Euler angles), and  X   X  R 9 is the shape parameters encoding the identity-specific shape of the person. Given a set of estimat ed parameters Y a new mesh {  X  y be produced using: Figure 1: Silhouette contour descriptors. Radial Distance Function (RDF) encoding of the silhou-ette contour is illustrated in ( a ); Shape Context (SC) encoding of a contour sample point in ( b ). where R of the shape-space parameters  X  ; Q ( R non-rigid articulation-induced deformations ( e.g. bulging of muscles). Notice, that Q () is simply a learned linear function of the rigid rotation and has no ind ependent parameters. To learn Q () we minimize the residual in the least-squared sense between the set of 70 registered scans of one person under different (but known) articulations. It is als o worth mentioning that body shape linear deformation sub-space, S (  X  ) = U corresponding to eigen-directions of the shape-space that characterize a given body shape. In this work we make use of silhouette features for both discr iminative and generative estimation of pose and shape. Silhouettes are commonly used for human pose estimation [1, 2, 13, 15, 17]; while from a mesh model. The framework introduced here, however, i s general and can easily be extended to incorporate richer features ( e.g. edges [15], dense region descriptors [16] such as SIFT or HOG , or hierarchical descriptors [10] like HMAX, Hyperfeatures , Spatial Pyramid). The use of such richer feature representations will likely improve both discrimi native and generative estimation. shape-based histograms of the contour points sampled from t he external boundary of the silhouette. At every sampled boundary point the shape context descripto r is parameterized by the number of orientation bins,  X  , number of radial-distance bins, r , and the minimum and maximum radial dis-tances denoted by r a function of the overall silhouette height and normalizing the individual shape context histogram by the sum over all histogram bins. Assuming that N contour points are chosen, at random, to en-code the silhouette, the full feature vector can be represen ted using  X rN bin histogram. Even for moderate values of N this produces high dimensional feature vectors that are har d to deal with. To reduce the silhouette representation to a more manageabl e size, a secondary histogramming was introduced by Agarwal and Triggs in [1]. In this, bag-of-words style model, the shape context space is vector quantized into a set of K clusters ( a.k.a. codewords). The K = 100 center codebook is learned by running k-means clustering on the combined set of shape context vectors obtained from the large set of training silhouettes. Once the codebook is l earned, the quantized K -dimensional histograms are obtained by voting into the histogram bins co rresponding to codebook entries. Soft voting has been shown [1] to reduce effects of spatial quanti zation. The final descriptor X can be compared.
 Following the prior work [1, 13] we let  X  = 12 , r = 5 , r of the silhouette and  X  is typically 1 similar to the limb size [1]. For shape estimation, we found t hat combining features across multiple spatial scales ( e.g.  X  = { 1 Radial distance function. The Radial Distance Function (RDF) features are defined by a f eature vector X silhouette, and p we use N = 100 points, resulting in the X of the RDF descriptor is comparable to that of shape context i ntroduced above. Unlike the shape context descriptor, the RDF feature vector is neither scale nor translation invariant. Hence, RDF features are only suited for applications where camera cali bration is known and fixed. To produce initial estimates for the body pose and/or shape i n 3D from image features, we need to and, as with many inverse problems, is highly ambiguous. To m odel this non-linear relationship we use a Mixtures of Experts (MoE) model to represent the condit ionals [2, 17].
 The parameters of the MoE model are learned by maximizing the log-likelihood of the training data iterative Expectation Maximization (EM) algorithm, based on type-II maximum likelihood, to learn parameters of the MoE. Our model for the conditional can be wr itten as: where p p constant offset, Y =  X  X +  X  , as our expert model, which allows us to solve for the paramet ers  X  Pose estimation is a high dimensional and ill-conditioned p roblem, so simple least squares estima-alization. To reduce this, we add smoothness constraints on the learned mapping. We use a damped a regularization parameter. Larger values of  X  will result in overdamping, where the solution will be solution of the ridge regressors is not symmetric under the s caling of the inputs, we normalize the Weighted ridge regression solution for the parameters  X  as follows, where Z and diag ( Z [ y (1) , y (2) , ..., y ( N ) ] are vectors of inputs and outputs from the training data D . p  X  P estimated ownership weight of the example n by the expert k estimated by expectation The above outlines the full EM procedure for the MoE model. We learn three separate models for EM learning by clustering the output 3D poses using the K-mea ns procedure.
 Implementation details. For articulated pose and shape we experimented with using bo th RDF and SC features (global position requires RDF features sinc e SC is location and scale invariant). SC features tend to work better for pose estimation where as R DF features perform better for shape estimation. Hence, we learn p (  X  | X unavailable, we estimate the shape using p (  X  | X cannot estimate the overall height. We estimate the number o f mixture components, M , and regular-ization parameter,  X  , by learning a number of models and cross validating on the wi thheld dataset. both pose and shape), p ( Y | I )  X  p ( I | Y ) p ( Y ) , using a set of N weighted samples { y where y is an associated normalized weight. As in [5] we make no rigor ous probabilistic claims about the generative model, but rather use it as effective means of per forming stochastic search. As required by the annealing framework, we define a set of importance func tions q samples at each respective iteration k . We define importance functions recursively using a smoothe d version of posterior from the previous iteration q local optima, the likelihood is annealed as follows: p T convergence. Here we make use of the discriminative pose and shape estimate from Section 4 to abuse of notation) y (0) that measures how well our model under a given state Y matches the image evidence, I , obtained from one or multiple synchronized cameras. We adopt the like lihood function introduced in [5] that measures the similarity between observed and hypothes ized silhouettes. For a given camera view, a foreground silhouette is computed using a shadow-su ppressing background subtraction pro-cedure and is compared to the silhouette obtained by project ing the SCAPE model subject to the hypothesized state into the image plane (given calibration parameters of the camera). Pixels in the This is made efficient by the use of Chamfer distance map preco mputed for both silhouettes. Datasets. In this paper we make use of 3 different datasets. The training dataset , used to learn discriminative MoE models and codeword dictionary for SC, w as generated by synthesizing 3000 silhouette images obtained by projecting corresponding SC APE body models into an image plane using calibration parameters of the camera. SCAPE body mode ls, in turn, were generated by ran-domly sampling the pose from a database of motion capture dat a (consisting of generally non-cyclic random motions) and the body shape coefficient from a uniform distribution centered at the mean shape. Similar synthetic test dataset was constructed consisting of 597 silhouette-SCAPE body ( a ) ( b ) ( c ) Figure 2: Discriminative estimation of weight loss. Two images of a subject before and after weight loss are shown in ( a ) on the left and right respectively. The images were downloa ded from discriminative estimation procedure is shown in ( c ). In bottom row, we manually rotated the model use p (  X  | X estimated that the person illustrated in the top row lost 22 lb and the one illustrated in the bottom row  X  32 lb ; web-reported weight loss for the two subjects was 24 lb and 64 lb respectively. Notice that the neutral posture assumed in images was not present in our training data set, causing visible artifacts with estimation of the arm pose. Also, the bottom e xample pushes the limits of our current shape model which was trained using only 10 scans of people, none close to the desired body shape. model pairs. In addition, we collected a real dataset consisting of hardware-synchronized motion capture and video collected using 4 cameras. Two subjects were captured performing roughly the same class of motions as in the training dataset.
 Discriminative estimation of shape. Results of using the MoE model, similar to the one introduced here, for pose estimation have previously been reported in [ 2] and [17]. Our experience with the articulated pose estimation was similar and we omit support ing experiments due to lack of space. For discriminative estimation of shape we quantitatively c ompared SC and RDF features, by training two MoE models p (  X  | X calibration is available (on the average we achieve a 19 . 3 % performance increase over simply using the mean shape). We attribute the superior performance of RD F features to their sensitivity to the silhouette position and scale, that allows for better estim ation of overall height of the body. Given the shape we can also estimate the volume of the body and assuming constant density of water, compute the weight of the person. To illustrate this w e estimate approximate weight loss of a person from monocular uncalibrated images (see Figure 2). Please note that this application is a weight calculations, since non-rigid deformations caused by articulations of the body will result in (unnatural) variations in weight. In practice, however, we found such variations produce relatively minor artifacts. The weight calculations are, on the other h and, very sensitive to the body shape. Combining discriminative and generative estimation. Lastly we tested the performance of the combined discriminative and generative framework by estim ating articulated pose, shape and bio-metric measurements for people in our real dataset . Results of biometric measurement estimates can be seen in Figure 3; corresponding visual illustration o f results is shown in Figure 4. Analysis of errors. Rarely our system does produce poor pose and/or shape estima tes. Typically degree view ambiguity and/or pose configuration ambiguitie s, due to symmetry, in the silhouettes. A (34) B (30) Figure 3: Estimating basic biometric measurements. Figure illustrates basic biometric measure-ments (height, arm span 3 and weight) recovered for two subjects A and B. Mean and stand ard devi-ation reported over 34 and 30 frames for subject A and B respec tively. Every 25 -th frame from two sequence obtained using 4 synchronized cameras was chosen for estimation. The actual measured values for the two subjects are shown in the left column. Esti mates obtained using discriminative only and discriminative followed by generative shape estim ation methods are reported in the next two columns. Discriminative method used only one view for es timation, where as generative method proach, that unlike [5] does not require manual initializat ion, performs comparably (and sometimes marginally better than [5]) in terms of mean performance (bu t has roughly twice the variance). We have presented a method for automatic estimation of artic ulated pose and shape of people from images. Our approach goes beyond prior work in that it is able to estimate a detailed parametric model (SCAPE) directly from images without requiring manua l intervention or initialization. We found that the discriminative model produced an effective i nitialization for generative optimization procedure and that biometric measurements from the recover ed shape were comparable to those pro-duced by prior approaches that required manual initializat ion [5]. We also introduced and addressed the problem of discriminative estimation of shape from mono cular calibrated and un-calibrated im-ages. More accurate shape estimates from monocular data wil l require richer image descriptors. A number of straightforward extensions to our model will lik ely yeld immediate improvement in performance. Among such, is the use of temporal consistency in the discriminative pose (and per-haps shape) estimation [17] and dense image descriptors [10 ]. In addition, in this work we estimated the shape space of the SCAPE model from only 10 body scans, as a result the learned shape space Figure 2 where the weight of the heavier woman is underestima ted.
 Acknowledgments. This work was supported by NSF grants IIS-0534858 and IIS-05 35075 and a gift from Intel Corp. We also thank James Davis and Dragomir A nguelov for discussions and data. Subject A Subject B Figure 4: Visualizing pose and shape estimation. Examples of simultaneous pose and shape estimation for subjects A and B are shown on top and bottom res pectively. Results are obtained by all 4 views. Middle column shows the projection of the model onto i mage silhouettes, where light blue denotes image silhouette, dark red projection of the mo del and orange non-silhouette regions that overlap with the projection. On the right are the two vie ws of the estimated 3D model.
 by Leonid Sigal, Alexandru B alan, Michael J. Black Spotlight ID: W43
