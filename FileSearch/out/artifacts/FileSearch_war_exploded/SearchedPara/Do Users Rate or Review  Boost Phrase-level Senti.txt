 Current approaches for contextual sentiment lexicon con-struction in phrase-level sentiment analysis assume that the numerical star rating of a review represents the overall senti-ment orientation of the review text. Although widely adopted, we find through user rating analysis that this is not neces-sarily true. In this paper, we attempt to bridge the gap between phrase-level and review/document-level sentiment analysis by leveraging the results given by review-level sen-timent classification to boost phrase-level sentiment polarity labeling in contextual sentiment lexicon construction tasks, using a novel constrained convex optimization framework. Experimental results on both English and Chinese reviews show that our framework improves the precision of senti-ment polarity labeling by up to 5 . 6%, which is a significant improvement from current approaches.
 I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing; H.3.3 [ Information Storage and Retrieval ]: Infor-mation Search and Retrieval -Classification Sentiment Analysis; Sentiment Classification; Sentiment Lex-icon Construction; Optimization
The construction of a sentiment lexicon is of key impor-tance in phrase-level sentiment analysis [7] and many other tasks such as recommender systems [10], where each entry in the lexicon is a Feature-Opinion (F-O) word pair together with the corresponding Sentiment polarity (S), represented by (F,O,S) [5]. For example, the entries ( service, excellent, positive ) and ( phone quality, perfect, positive ) could be ex-tracted from the textual review of Figure 1.

However, current phrase-level sentiment lexicon construc-tion approaches may only give sentiment polarity labeling (assigning the S for an F-O pair) precisions of around 70%  X  80% [4]. We find through large-scale user behavior analy-sis that one of the basic assumptions in current approaches, i.e., the overall numerical rating of a review represents the overall sentiment of the review text, is not necessarily true.
To avoid the biased assumption, we propose to boost the performance of phrase-level sentiment polarity labeling in a reverse way, which is to use unsupervised review-level sen-timent classification results instead of the numerical ratings as a heuristic for phrase-level polarity labeling. State-of-the-art review-level sentiment classification techniques, even the unsupervised approaches, can give pretty good precisions of above 90% [9, 6], which could be reliable to boost the per-formance of phrase-level sentiment polarity labeling.
In general the framework is two-stage. In the first stage, the overall sentiment orientations of the product reviews are labeled using a review-level sentiment classifier. In the sec-ond stage, we extract feature-opinion pairs from the corpus [5, 8], then use the overall sentiment orientations of the re-views as constraints to learn the sentiment polarities of these pairs automatically, using a novel optimization framework.
Experimental results on both English and Chinese review datasets show that our framework improves the precision of phrase-level sentiment polarity labeling significantly, which means that the original assumption might be infeasible, and that it might be promising to leverage sentence-or review-level sentiment analysis techniques to boost the performance of phrase-level sentiment analysis tasks.
The first stage of the framework determines the overall sentiment of each piece of review by conducting review-level sentiment classification, and the second stage lever-ages the results for sentiment lexicon construction. We use x = [ x 1 ,x 2 ] T ( x i  X  0) to represent a sentiment vector, where x and x 2 are the positive and negative degrees, respectively, and use X = [ x 1 x 2  X  X  X  x m ] T as the sentiment matrix for a set of m reviews or feature-opinion pairs.
Two possible sentiment vector candidates are used in this stage. If a review is classified as positive by a sentiment classification algorithm, then its sentient vector is assigned
Figure 1: A sample user review from Amazon.com as x = [1 , 0] T , otherwise, the corresponding sentiment vector is x = [0 , 1] T . Based on the classification results, a sentiment matrix  X  X = [ x 1 x 2  X  X  X  x m ] T is constructed, which will be used as a constraint in the next stage.

We use the sentence orientation prediction approach in [1] for English reviews, and the automatic seed word selection scheme in [9] for Chinese reviews. Both of them are state-of-the-art approaches on the corresponding language.
We consider four kinds of constraints to learn the senti-ment lexicon X : 1) Review-level sentiment orientation, 2) General sentiment lexicon, 3) Linguistic heuristics, and 4) Sentential sentiment consistency. 1) Review-level Sentiment Orientation captures the overall sentiment of a review given by the review-level sen-timent classification algorithm in the previous stage. We construct a matrix A to indicate the frequency of each F-O is the frequency of F-O pair j in review i . The matrix I is an indication matrix that allows us to take the  X  X egation rules X  into consideration. I neg ij =  X  1 if the F-O pair j is modified by a negation word, e.g.  X  X o X ,  X  X ot X ,  X  X ardly X , etc. Otherwise, I neg ij = 1.

The sentiments of all the F-O pairs are aggregated to ap-proximate the review-level sentiment polarity, which gives the following objective function: R 1 = k AX  X   X  X k 2 F 2) General Sentiment Lexicon captures the sentiment of some context-irrelevant opinion words, like excellent, good and bad . We construct the general sentiment lexicon X 0 labeling the polarities of the F-O pairs in X according to the public sentiment corpora MPQA 1 on English, and HowNet 2 on Chinese. An F-O pair is labeled as [1 , 0] T or [0 , 1] opinion word is included in the positive or negative word set, correspondingly. Otherwise, we use [0 , 0] T .
We expect the sentiment polarities of the context-irrelevant words in X to be close to those in the general sentiment lex-icon X 0 , which corresponds to the objective function R 2 k G ( X  X  X 0 ) k 2 F , where G is a diagonal matrix indicating which F-O pairs in X are  X  X ixed X  by the general sentiment lexicon X 0 . Namely, G ii = 1 if the i -th F-O pair has a fixed sentiment, and G ii = 0 otherwise. 3) Linguistic Heuristic captures the linguistic  X  X nd X  and  X  X ut X  relationship. It is intuitional that those F-O pairs frequently concatenated with  X  X nd X  might have similar sen-timents, while those frequently connected by  X  X ut X  tend to have opposite sentiments. To formalize the intuition, we de-fine two n  X  n matrices W a and W b for the  X  X nd X  and  X  X ut X  linguistic heuristics, respectively. We set W a ij = W a or W b ij = W b ji = 1 if pair i and j are concatenated by  X  X nd X  or  X  X ut X  for a minimal number of times, correspondingly, otherwise, we set W a ij = W a ji = 0. The objective function regarding both  X  X nd X  and  X  X ut X  linguistic heuristic is: R 3 = tr( X T D a X  X  X T W a X ) + tr( X T D b X  X  X T W b where tr(  X  ) is the trace of a matrix, D a , D b  X  R n  X  n onal matrices where D a ii = P n j =1 W a ij , and D b ii http://mpqa.cs.pitt.edu/corpora/ http://www.keenage.com/ umn permutation function to reverse the columns of X , and D = D a + D b . The underlying intuition is that the sentiment vectors of two pairs should be similar if they are frequently linked by  X  X nd X  and opposite if by  X  X ut X , or a penalty would be introduced to the loss function. 4) Sentential Sentiment Consistency captures the sentiment consistency in sentences [3], i.e., similar opinion orientations are usually expressed in consecutive sentences. To formalize the heuristic, a sentential similarity matrix W s  X  R n  X  n is introduced, which leverages the sentential distance between F-O pairs in corpus to estimate their sen-tential similarities. For example, consider two pairs i and j , if they co-occur in the same piece of review in the corpus, then we calculate their sentential similarity in this review, and the final similarity between i and j is the average of all their intra-review similarities. More formally, suppose pair i and pair j co-occur in the same review for N ij times, and the k -th co-occurrence happens in review t i k , then W s W ji are defined as: where the length of a review length ( r i k ) is the number of words (punctuations excluded) in the review, and the dis-tance dist ( i,j ) of pair i and j in the review is the number of words between the two feature words of the pair. The corre-sponding objective function is R 4 = tr( X T D s X  X  X T W where D s is also a diagonal matrix, and D s ii = P n j =1
With the above constraints from different information sources and aspects, we adopt the following objective function to learn the contextual sentiment lexicon X : where  X  1 , X  2 , X  3 and  X  4 are positive weighing parameters that control the contributions of each information source in the learning process. An important property of the objec-tive function (1) is its convexity, which makes it possible to search for the global optimal solution X  X  . We give the up-dating rule for learning X  X  directly here, as shown in (2). The proof of the updating rule as well as its convergence is similar to the KKT condition approach in [2].

In this work, we choose the function s ( x i ) = x i 1  X  x calculate the final sentiment polarity. Pair i is labeled as positive if s ( x i )  X  0, and negative if s ( x i ) &lt; 0.
We use the MP3 player reviews crawled from Amazon for the experiment on English, which is publicly available 3 . For the Chinese language, we use the restaurant reviews crawled from Dianping 4 , which is a famous restaurant rating website http://sifaka.cs.uiuc.edu/~wang296/Data/ http://www.dianping.com/ in China. Each of the reviews of the two datasets consists of a piece of review text and an overall numerical rating raging from 1 to 5 stars. Some statistical information about these two datasets is shown in Table 1.

An important property of our restaurant review dataset is that, each review is accompanied with three sub-aspect ratings except for the overall rating. They are users X  ratings made on the flavour , environment and service of restaurants, respectively, which makes it possible for us to conduct much detailed user rating analysis on this dataset. The range of the sub-aspect ratings are also from 1 to 5.
The ratings on three sub-aspects allow us to investigate a user X  X   X  X rue X  feelings on more specific aspects of a restaurant beyond the overall rating. For the overall rating and each sub-aspect rating, we calculate the percentage that each of the 5 star ratings takes in the total number of ratings, shown in Figure 2. The x-axis represents 1 star through 5 stars, and the y-axis is the percentage of each star rating. Figure 2: Percentage of each star of overall rating, flavour, environment and service.

We see that user ratings tend to center around 4 stars on overall rating, while they tend to center around 2  X  3 stars on the sub-aspect ratings. This implies that the overall rating might not serve as a real reflection of the users X  feelings, and users tend to  X  X ell the truth X  in much detailed sub-aspects. In order to examine the statistical significance, we calculate the average rating  X  and coefficient of variation c v =  X / X  for the overall rating and the three sub-aspect ratings, where  X  is the standard deviation. Table 2 shows the results. We see that users tend to give higher scores on overall rating, and the scores on overall rating are more concentrated.
More intuitionally, we conduct per user analysis. For each user and each kind of rating (overall, flavour, environment and service), we calculate the percentage of 4 or 5 stars that the user made. Then we sort these percentages of the users in descending order, which is shown in Figure 3.

It is clear that user rating behaviours on overall and sub-aspect ratings are different. More than a half of the users Table 2: Average ratings and coefficient of variation Figure 3: Percentage of  X  4 stars made by each user on each kind of rating, sorted in descending order of percentages. made 50% or more 4+ ratings in terms of overall rating, while less than 5% users did so on sub-aspect ratings.
This analysis partly shows that it might not be appropri-ate to use overall ratings as groundtruth to label the senti-ment orientations of review texts, as users tend to act differ-ently when making overall ratings and expressing their true feelings on detailed product features/aspects.
We choose the frequently used measures precision, recall and F-measure to evaluate the performance of polarity la-beling, and experiment with the following methods:
We use  X  1 =  X  2 =  X  3 =  X  4 = 1 in this experiment, and the results on the two datasets are shown in Table 3. We did not perform the  X  X ubaspect X  method on mp3 player reviews as the sub-aspect ratings are absent.

We see that labeling the polarities by querying the general opinion word sets gives the best precision on both of the two datasets. However, the recall of this method is rather low. This implies that there are many  X  X ontextual dependent X  opinion words which are absent from these word sets.
The  X  X ptimize X  method and our  X  X verall X  method are similar in that both of them leverage overall numerical rat-ings as the groundtruth of review-level sentiment orienta-tions. Though the Optimize method achieves slightly better recall, their overall performance are comparable. Further more, by taking advantage of the sub-aspect ratings in the  X  X ubaspect X  method, both precision and recall are improved from  X  X ptimize X  and  X  X verall X  methods, which implies that the detailed sub-aspect ratings could be more reliable.
Finally, our  X  X oost X  method achieves the best performance in terms of recall and F-measure, on both of the two datasets. MP3 Player Data General 0.9238 0.4201 0.5776 Optimize 0.8269 0.7626 0.7934 Overall 0.8288 0.7525 0.7888 Boost 0 . 8504 0.7683 0.8073 Restaurant Review General 0.9017 0.3571 0.5115 Optimize 0.8405 0.7760 0.8069 Overall 0.8473 0.7468 0.7938 Subaspect 0.8675 0.7561 0.8079 Boost 0 . 8879 0.7818 0.8315 Besides, it also achieves the best precision without regard to the  X  X eneral X  method. This further verifies the effect of leveraging review-level sentiment classification in boosting the process of phrase-level polarity labeling.
In this subsection, we attempt to study the effect of dif-ferent constraints in our framework by analyzing the four main parameters  X  1  X   X  4 in objective function (1).
We first conduct  X  X nock Out One Term X  experiment on these parameters, to see whether all these constraints con-tribute to the performance of phrase-level polarity labeling. We set one of the four parameters to 0 at a time, and eval-uate the F-measure. The results are shown in Table 4.
The experimental result shows that knocking out any of the four parameters decreases the performance of polarity labeling. Besides, removing the constraint on review-level sentiment orientation (  X  1 ) or general sentiment lexicon (  X  decreases the performance to a great extent, which implies that these two information sources are of great importance in constructing the sentiment lexicon.

We further investigate the effect of different constraints by fixing three parameters to 1 and weighing the remaining parameter. The results on restaurant are shown in Figure 4, and the observations on mp3 player dataset are similar.
The experimental result shows that giving more weights to the constraints of review-level sentiment orientation and general sentiment lexicon could further improve the per-formance, which means that these two information sources might be more reliable. However, weighting the constraint on sentential sentiment consistency too much would decrease the performance, this implies that noise could be introduced by this heuristic and it is not as reliable as the linguistic heuristic of  X  X nd X  and  X  X ut X .
 Table 4: F-measure by knocking out one constraint Default 1 1 1 1 0.8073 0.8315
Knock 0 1 1 1 0.6783 0.6476 out 1 0 1 1 0.6332 0.6728 one 1 1 0 1 0.7461 0.7352 term 1 1 1 0 0.7756 0.7504
We tuned the parameters carefully to get the optimal per-formance. Finally, the optimal result on mp3 player dataset was achieved when using the parameters (4, 2, 1, 0.25), with an F-measure of 0.8237, and on restaurant review dataset (3, 2, 2, 0.5) is used, which gives the F-measure of 0.8584.
In this paper, we investigated the inconsistency between overall numerical ratings and the sentiment orientations of textual user reviews in real-world datasets, which is an un-validated assumption but frequently used in previous work. We propose to leverage review-level sentiment classification techniques to boost the performance of phase-level senti-ment polarity labeling. Besides, we formalize the phrase-level sentiment polarity labeling problem in a simple convex optimization framework, and designed iterative updating al-gorithms for model learning. Experimental results on both English and Chinese datasets show that our framework helps to improve the performance in contextual sentiment lexicon construction tasks.

This work is a first step towards bridging the gap between phrase-level and sentence/review-level sentiment analysis. Except for the four kinds of heuristics investigated in this paper, the framework can also integrate various other in-formation sources. Besides, review-level analysis could also be promising to help extract feature or opinion words in phrase-level analysis, except for the polarity labeling task in this work. Additional insights about the bidirectional rela-tionship of phrase-and review-level analysis may also yield more effective heuristics and algorithms for both tasks.
