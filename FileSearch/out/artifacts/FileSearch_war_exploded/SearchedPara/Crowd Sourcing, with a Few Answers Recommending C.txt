 Real-time traffic awareness applications are playing an ever in-creasing role understanding and tackling traffic congestion in cities. First-hand accounts from drivers witnessing an incident is an in-valuable source of information for traffic managers. Nowadays, drivers increasingly contact control rooms through social media to report on journey times, accidents or road weather conditions. These new interactions allow traffic controllers to engage users, and in particular to query them for information rather than pas-sively collecting it. Querying participants presents the challenge of which users to probe for updates about a specific situation. In order to maximise the probability of a user responding and the accuracy of the information, we propose a strategy which takes into account the engagement levels of the user, the mobility profile and the rep-utation of the user. We provide an analysis of a real-world user corpus of Twitter users contributing updates to LiveDrive, a Dublin based traffic radio station.
 Keywords: Recommender Systems; Crowd-sourcing; Traffic.
Crowd sourcing of urban information is becoming increasingly important in the context of smarter cities. For example, Waze vides crowd sourced traffic monitoring. FixMyStreet supports re-porting information such as noise pollution, potholes and general repairs for the attention of city councils 2 . Social media analysis has already been used for incident or emergency detection or mon-itoring, such as earthquakes [9] or floods [5, 12]. It has been used also for traffic monitoring in the city of Dublin [4]. In order to move from passive crowd sourcing to active crowd sourcing, such systems need to actively identify and engage users to provide the right information at the right time, thus encouraging contributions.
Specific solutions have also been developed to estimate user re-liability in the context of spatial crowd sourcing, and in particular traffic monitoring. Crowd sourcing can be used to resolve conflict-ing reports from physical sensors, and these reports can be used as an initial estimate of the true answer [2]. Spatial models have been https://www.waze.com/ https://www.fixmystreet.ie/ c  X  developed to detect unreliable crowd sourced sensors to measure radioactivity in Japan [11]. When monitoring social media, a re-lated challenge is to detect individuals that are located in the area affected by a problem and these merely talking about it [10].
Sensor or user selection based on space and time constraints have also been considered. In order to maximise the usefulness of the answers received, one can construct probability distributions over sensor locations and optimise the queries based on this distribution [8]. Generic location aware crowd sourcing platforms have also been developed. These platforms distribute tasks to users based on their location [1, 6, 7]. These platforms are different from our setting. Indeed, they either use a pull-based system, where users request tasks based on their current location, continuously moni-tor the location of users or expect users to move to complete tasks. We, on the other hand, expect our queries to be generated mostly during peak hours, and for users commuting. In our opinion, such users are unlikely to take a detour in a traffic jam to answer a ques-tion. However, they can report on a location they X  X e been through recently. We expect a user to provide information only if they have a history of reporting on this particular location of interest.
Our contribution is an algorithm to recommend, based on pre-dicted user engagement, which users to follow or to query to obtain traffic updates around the city. Our algorithm takes into account:
We evaluate this proposed strategy using a real-world collection of user contributed tweets and traffic related updates of LiveDrive, a Dublin based traffic radio station.
LiveDrive 3 CityFM is a radio station run by Dublin County Coun-cil. The radio station broadcasts during the morning and evening peak traffic times. Listeners are incentivised to provide real-time updates to the station by the possibility to receive free parking vouchers, request a song of their choice and the general understand-ing that if they contribute useful information that benefits others, they too may benefit from the contributions of others. The team consists primarily of three members, the radio presenter who com-municates the updates to the listeners, the producer who monitors incoming alerts and a camera controller who has access to a num-ber of the traffic cameras in the city when trying to clarify reported issues. Incoming alerts are sent to the team via email, phone calls, text messages and Twitter. http://dublincityfm.ie/livedrive
We collected the tweets both originating from and directed to the LiveDrive Twitter account using the public API 4 from October 2012 until February 2014 resulting in 38637 tweets from 2240 ac-counts. As most of the tweets are not geo-located, we generate for each tweet an approximate location based on specific words used, mostly street names, abbreviations of these names or specific area in the city. To do so, we follow the methodology of [4].
 Example LiveDrive tweet: Source: LiveDrive Message: There has been an incident on Nassau St at the junction of Dawson St. Nassau St is blocked and the left turn from Dawson St is also blocked Date: Fri Feb 14 07:06:29 Location Keywords: nassau junction dawson Approx. Location: 53.341297, -6.2582927 Example tweet from user: Source: @BeastyBoy_ Message: Pedestrian knocked down on Nassau st at house of frasier -no traffic getting past. @LiveDrive @aaroadwatch @gardainfo @GardaTraffic Date: Fri Feb 14 07:04:03 Location Keywords: nassau Approx. Location: 53.342697,-6.256634
For a broader analysis, we also collected another 943703 tweets geo-located in Dublin, not related to the LiveDrive account.
To build the reputation of a user, we must decide whether a tweet sent to LiveDrive is related to a valid incident or not. There are two typical crowd sourcing methods to assess the quality of a tweet: compare to other tweets, or to a gold standard. Since the majority of incidents were reported by a single user or a very small number of users, majority voting strategies are of limited use. Therefore, we rely on a gold standard: the warnings about incidents on the LiveDrive Twitter account.

We first assign an approximate location to both the user tweets and the LiveDrive tweets. We then try to match each single user tweet with a LiveDrive one, based on a spatio-temporal distance. For the spatial dimension, we tried increasing distances from 0km to 5km, and we saw a sharp increase of matches up to 1km, while little difference was noted after that. We therefore selected 1km as spatial threshold. For time, we noticed that there is a linear corre-lation between temporal distance and number of matched tweets. We arbitrarily chose 2 hours as temporal threshold, based on our personal estimates of how long a traffic problem may last.
In order to take into account the reputation of a user, we wish to reward users who provide actionable information. If a user con-sistently provides content that is rebroadcast and shared by the LiveDrive team and therefore of benefit to other users, then this user can be considered a reputable contributor. The reputation of a user is initialised to an input parameter R init  X  [0 , 1] . For every additional informative tweet sent by the user, the value is updated with a reward constant R reward
In order to capture the time dynamics and take into account that the last time a user has contributed information also plays a role in the probability as to whether the user will tweet, or respond, about an incident, the reputation value is decayed over time. As a result, users who are continuously providing valuable updates are http://www.twitter.com rewarded, and inactive users are degraded by: where  X  is the decay coefficient and k is the number of elapsed time units since the user last contributed an update. The selection of the decay coefficient,  X  , and time unit, k , should be based on the importance of recency. For the purposes of this paper we use the following values: R init =0.5, R reward =0.1,  X  =0,98 and k = number of weeks.
We seek information updates that can be provided in an oppor-tunistic manner, so we need to take into account the time of day we believe the user may be travelling, based on the previous updates provided by the user. Figure 1 shows the probability distribution of when messages are received by the LiveDrive team (crossed red line). The peak hours for the LiveDrive related tweets are in the morning between 7 and 10 followed by an afternoon peak between the hours of 4 and 7. We also report the probability distribution of all other tweets not related to LiveDrive (circled green line) to give a perspective of the relative effects and volume of the LiveDrive service compared to generic Twitter accounts and topics.

In order to compute the time profile of the users we discretise the time of day the users were observed into hourly intervals t  X  [1 , 2 ,  X  , 24] . We then bin the frequencies a user has been observed in the respective hourly intervals c u ( t ) and compute the correspond-ing maximum likelihood estimate as:
We also need to take into account the locations each user may be travelling through based on his previous tweets. Figure 2 shows the locations associated to all tweets we use. We construct individual users X  location profiles by looking at the location keywords used for the geo-coding of tweets rather than at the coordinates. We believe that these words provide more information about the trajectory of a user than point-wise coordinates. For example, a user reporting a problem on the N4 on the way to the M50 motorway (big road circling Dublin) may be able to report on a problem on the N4 or the M50 far from the crossroad, but not be able to do so for a problem on a road parallel to these even if the incident is closer to the N4-M50 junction.
 We compute the location profile in a similar manner as before. We bin the frequencies of a user X  X  observations across all location keywords assuming location keywords are not necessarily depen-dent on each other. Given an input location query l = { l gives potentially multiple location keywords is now used to com-pute the probability that the user has information about those input location keywords:
The criteria we consider include the number of tweets contributed by the user, the time profile of the user, the location profile of the user and the reputation. Each of these criteria has a different scale and therefore mapping these objectives to a single utility scale can be problematic, since it may be difficult to provide precise trade-offs between objectives [3]. As a result, it is natural to consider multi-attribute or multi-criteria utility functions to cope with mul-tiple and non-commensurate utility scales on which the decision maker X  X  preferences are expressed. Therefore we propose using Pareto optimisation to determine the non-dominant solution set.
Given p attributes, a multi-attribute utility value is characterised by a vector ~u = ( u 1 ,...,u p )  X  R p , where u i represents the utility with respect to attribute i  X  { 1 ,...,p } . Given ~u,~v  X  R , we say that ~u Pareto dominates ~v (denoted ~u &lt; ~v ) iff  X  i  X  { 1 ,...,p } u i  X  v i . As usual, the symbol refers to the asym-metric part of &lt; , namely ~u ~v iif ~u &lt; ~v and it is not the case that ~v &lt; ~u . Given a finite set of utility vectors U  X  the maximal set , denoted by max &lt; ( U ) , to be the set consisting of the undominated elements in U , i.e., max &lt; ( U ) = { ~v  X  U | U ,~v ~u } . Computing max &lt; ( U ) is quadratic in the size of U .
Our goal here is to study how the main strategy described above performs in an hypothetical application for recommending users to follow, or to query about a specific incident. We imagine to have to query a number of users under budget constraints to maximize the likelihood of their reply, while ensuring load balance across users. Further validation of this methodology involving actual queries is part of our future work in this direction.

We utilise the LiveDrive messages to simulate the workload for the users. This results in 2124 queries about  X  X ncidents X  (LiveDrive messages) where we try to predict users that contributed tweets about the incident, that is, tweets that were a) geo-coded and con-tained usable location keywords and b) validated as described in the previous section. User contributions up until the query time (i.e. time of the LiveDrive  X  X ncident X  tweet) are used to build user profiles. Note that this includes tweets that were not validated by a LiveDrive event and did not necessarily contain location keywords. Users sometimes signal there is no problem (anymore) at a partic-ular location, and while these tweets are usually not validated by LiveDrive, they still provide information about the typical location and time a user is active. User contributed tweets that have been validated are withheld until after the given LiveDrive message has been processed in order to not unfairly advantage the algorithm.
We first include four metrics as selection criteria: number of tweets, time probability, location probability and the reputation of the user. Our goal is to accurately recommend which users to query based on the time of day and the location keywords of interest. A recommendation is a success if a user who actually did contribute a validated tweet is included in the Pareto optimal solution set.
We achieved an accuracy of 77.16% with an infinite budget. We only consider contributing users who have a history of at least 4 tweets, as with fewer tweets the system may not know enough about a user. Indeed, the accuracy for any particular user increases with the number of tweets from that user that the system as seen be-fore, as shown by Figure 3 (dashed green line). The accuracy starts at 40% and increases to above 60% after the first 20 tweets. This indicates our approach is able to capture the behaviour of users. Depending on the accuracy required from the system, it may be beneficial to increase the minimum number of tweets that must be observed from a user before considering it for a query.

Figure 3 also shows the number of users that have received a query with a given number of previously observed tweets. That curve is not monotonically decreasing because no query is emitted for non-validated tweets. Because users emit tweets at different rates, the overall accuracy does not increase much over time.
We now investigate the performance of our approach under a budget constraint. The initial candidates are selected using the Pareto optimisation approach and users are then ranked based on three possible strategies. Figure 4 shows the performance with a decreasing budget ranking the candidates based on time probabil-ity, location probability and reputation. As can be seen the budget does not have an impact until it drops below 50 queries. The repu-tation ranked strategy however, only drops 2% when the budget is reduced to 25 and still maintains a success rate of 65.34% with a budget of 10. The success rate drops to only 21.56% with a budget of one, however it should be noted that this measure of success is whether we accurately predicted which user contributed a relevant tweet. Our end goal is to identify users who are good candidates to poll for updates taking into account the time of day and location, meaning those recommended with a budget of 1 may still be valid candidates who could respond if probed with a high probability. Ranking based on location and time on the other hand suffer a large drop in performance as the budget available decreases, demonstrat-ing that once users with a reasonable probability based on time and location profiles are identified, taking into account the reputation of the user becomes the more successful strategy.
Figure 6 shows a violin plot 5 demonstrating the distribution of queries across the user population with varying budget constraints. As can be seen, when no load balancing strategy is in place, a single user could potentially be queried 2124 times when considering a budget of 25 over the course of the 15 month experiment. This is clearly too much load to place on a single user in the system and has the potential to cause this user to opt out of the system. As a result we introduce an additional decay factor in the user reputation as proposed in equation 2, however the value of k is determined by the number of times the user was queried in the given time unit. Figure 6 shows the impact on load distribution when considering the number of queries the user has received that day, or that week. Depending on the budget constraints the additional decay factor helps to distribute the load more evenly across the available users.
Figure 5 shows the impact on accuracy when predicting the ex-act user who contributed the tweet when employing the load bal-ancing schemes. As can be seen, there is only a small reduction in accuracy due to the decision to distribute the load across users. When considering a budget of 5 the accuracy drops from 52.11% to 47.55% and 45.66% when considering the number of queries a user has already been given that day and that week respectively.
We present a strategy to recommend users who may be probed in order to provide crowd-sourced traffic updates. We evaluate our strategy using a novel dataset consisting of real user-service inter-actions over the course of 15 months. We demonstrate the ability to accurately predict which user is appropriate to provide information depending on the time of day and location of interest. We study the behaviour of our algorithm with a budget of maximum users that can be queried. We also consider different load balancing ap-http://www.itl.nist.gov/div898/software/ dataplot/refman1/auxillar/violplot.htm proaches to better spread queries between users. While this can lead to a decrease in accuracy, it can both keep medium users en-gaged in the system and avoid sending too many queries to good users, which may make them leave our crowd sourcing scheme. Using real tweets addressed to a Dublin traffic radio, our empiri-cal evaluation shows our approach can accurately predict who will contribute tweets about an incident at a particular place and time. While these first results are promising, we believe there is room for improvement. From an algorithmic point of view, more advanced method from reinforcement learning could increase accuracy or the learning rate. From a practical point of view, we hope to test our ap-proach by actively querying users. Human traffic controllers could trigger the queries. However, automatically sending queries based on sensor measurements may be a more promising approach.
 This work is partly funded by the EU FP7 INSIGHT project (project number 318225).
