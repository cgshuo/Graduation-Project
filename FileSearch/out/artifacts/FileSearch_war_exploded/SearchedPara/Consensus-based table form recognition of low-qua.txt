 ORIGINAL PAPER H. Nielson  X  W. Barrett Abstract Given a set of low-quality line-delimited tabular documents of the same layout, we present a robust zoning algorithm which exploits both intra-and inter-document consensus to extract the structure of the table. The structure is captured in the form of a document template, that can then be snapped to a new document to perform automated  X  X ookie cutter X  data extraction. We also report a companion consensus-based algorithm for the classification of zone content as either machine print, handwriting or empty. Using scanned Census records from 1841 to 1881, the template is recovered with an efficiency of.076 [0, 1). Using consensus over about 10 documents from each data set, this error was reduced to.0076, or by 90%, which amounts to two missing line segments and one false positive. Similarly, the error for coverage was reduced from 0.098 to 0.016, or by 83%. Use of consensus also resulted in machine print classification accuracy of 100% for two of the three data sets. The classifi-cation error for handwriting averaged 0.1225 per document. By exploiting consensus within and between documents, au-tomated zoning and labeling is greatly improved, providing field-level indexing of document content.
 Keywords Zoning  X  Table recognition 1 Introduction With improvements in scanning technology, increasing stor-age capacity, and the expanding connectivity and availability of the Internet, millions of tabular documents, including ge-nealogical birth, death and census records, have been made available on line. However, in order to exploit the content of these documents, the granularity of the indexing must move from the image level to individual fields within the docu-ment. Field-level indexing provides a means of partition-ing the document into meaningful and relevant components with the attendant benefits of increased speed and economy of data transfer and storage. Rather than transferring and searching through the entire document, selected fields can be transmitted instead. This allows the user to focus on the information important to them.
 also allows each field X  X  contents to be contextually ana-lyzed. For example, a field that contains printed text could be sent to an OCR engine and database for recognition and indexing. Fields containing handwriting could be stored for subsequent, semi-automated, user-assisted interpretation or pattern-matched indexing. To perform automated field-level indexing and addressability, automated zoning techniques are needed to partition the document and identify the loca-tion and content of regions and fields.
 accomplish this task, and are quite successful on reasonably good quality documents. Most approaches, however, revolve around the idea of completely and accurately segmenting an image from the features found exclusively in that im-age. Historical documents are often less than ideal due to age, exposure, and handling. Large collections of these doc-uments have been preserved on microfilm which can serve to compound image quality. High film fog levels, variable film density, and incorrect exposure settings can be a few con-tributing factors. Geometric distortions are not uncommon as many original documents were bound into books creat-ing an uneven surface when the image was captured either digitally or photographically. All of these factors contribute to make current automated document processing techniques error-prone and labor-intensive to correct. To deal with im-ages of potentially low quality, most zoning systems provide some rules, or a priori knowledge, about the expected im-ages to be zoned. However, such rule-based systems are of-ten limited in their ability to generalize to documents of dif-ferent types. Furthermore, existing techniques for table form recognition are not designed for older, historical documents of low quality and are applied to one document at a time, failing to take advantage of the improvement that can be ob-tained through inter-document consensus.
 ture from a sequence of deskewed, low-quality, line-delimited historical documents with a consistent format. We will show that through consensus we are able to increase zoning accuracy collectively, compared to zoning each doc-ument individually. We will also classify each field X  X  content into machine print or handwriting (or empty) by taking ad-vantage of the consistency of static machine print content from document to document. Finally, we show how a tem-plate can be used as a robust  X  X ookie cutter X  to automatically zone subsequent documents that have the same layout. tion 2 discusses previous approaches along with strengths and weaknesses. Section 3 describes our consensus-based approach. Section 4 introduces the metrics used to evaluate the zoning and classification accuracy and presents results with and without consensus. Section 5 summarizes our re-sults and concludes with a discussion of possible areas for improvement. 2 Previous work Extracting a document X  X  geometric layout requires identify-ing features that define its structure. This can be performed using top-down, model-driven approaches or bottom-up, data-driven techniques. In top-down processing, a document is split into its component parts by recursively subdividing larger areas into smaller ones. Splitting up a document re-quires identifying delimiters in the image, such as lines or whitespace. 2.1 Recognition of line-delineated tables and forms Nagy and Seth [ 11 ] introduce the X  X  Y tree for partitioning a scanned document. Each node in the tree represents a rect-angular region, with each new level representing alternating horizontal and vertical subdivisions or  X  X uts X . The cuts are made contextually depending on the rectangle being subdi-vided. While many techniques use profiles to identify delim-iters in the document, these features are often susceptible to noise which increases the possibility of error. In this paper, we increase the utility of the profile by employing a matched filter to amplify the signal of interest and dampen everything else.
 ble using both lines and implied lines as delimiters. Lines are represented as vectors and are organized into an X  X  Y tree. This approach depends on images with a simple background for proper binarization, as well as well-defined bounding boxes of machine-print or handwritten characters to estimate certain typographical parameters.
 Chen and Lee [ 4 ] split the document into uniform horizon-tal and vertical strips. The size of the strips is required to be no larger than twice the size of the smallest line to be identified. Line segments are found by identifying peaks in the local profile of each strip. Line segments in adjacent strips are merged together to create the lines found in the form.
 tion is that of Hori and Doermann [ 8 ], where form structure is extracted with good accuracy, in the presence of touching characters and broken lines, by dealing with regions directly rather than through line analysis and grouping. Good re-sults on low-quality images are also obtained by Shinjo et al. [ 15 ], by analyzing line intersections and terminal points re-cursively until an internally consistent representation is ob-tained. A variety of model-based approaches have also been applied successfully [ 13 ] where domain-specific models ap-pear to yield the best results. 2.2 Related work in table recognition Ittner and Baird [ 9 ] present a zoning method that looks for whitespace instead of lines. Chandran and Kasturi [ 3 ] iden-tify all lines and implied lines (white streams) in the ta-ble. The process requires a minimum number of lines to be present to determine table boundaries. Line identification re-quires the a priori settings of minimum line length and the maximum thickness of lines in the image.
 ety of techniques such as run length smoothing algorithm (RLSA) to identify text lines, resolution reduction [ 14 ]and connected components at the word level [ 10 ] and character level [ 12 ].
 into its text lines which are initially used for deskewing us-ing the Hough transform. Text line components are created by smearing adjacent characters and words together using RLSA. Interline spacing is determined by finding the peak of the 1D Fourier transform of the horizontal project profile. This same technique is used in the research presented in this paper.
 For example, Xi and Lee [ 17 ] present a wavelet based ap-proach to extract a tabular structure.
 process of zoning by looking at documents independent from one another. Casey and Ferguson [ 2 ] present a forms editing tool allowing the user to predefine a document X  X  lay-out by scanning in a blank form to serve as a master for the specified form. Taylor, Fritzson, and Pastor [ 16 ] introduce the idea of combining information from multiple images. Both approaches allow the user to edit the template infor-mation.
 tified regions do so according to their predefined or spatial relationship to adjacent regions and their global position in the document. We intend to classify cells by examining their content and exploiting inter-document consistency.
 these authors and produces very good results where the signal-to-noise ratio (SNR) is good and individual fields in a form are well delimited by conspicuous lines or spaces. However, many existing techniques become quite brittle and fail when applied to older, low-quality, historical documents where the SNR is low and lines are faded or non-existent in many instances. In such cases, more robust approaches are needed. We exploit intra-and inter-document consensus to improve SNR and automatically extract the document template. The template is then used to perform automated  X  X ookie cutter X  data extraction on other forms with the same format. 3 Consensus-based zoning In our consensus-based zoning algorithm, partitioning a tabular document is based on the assumption that different regions within the document are delimited by lines (Fig. 1 ). By identifying these lines, an editable mesh representing the geometric layout of the document is created. Individual meshes are combined to form a single mesh (template) through consensus. Each region of interest (ROI) in the template is classified according to its content: printed text, handwriting, or empty. The template is then used to zone new documents of that layout. 3.1 Candidate line identification Peaks in horizontal and vertical profiles are used to identify lines in a document, even where the line may be broken or intersects with other lines or writing. Because profiles are sensitive to skew, all documents must be deskewed prior to generating their profiles.
 peaks by increasing the signal-to-noise ratio between line peaks and the remainder of the profile. The filter f ( x )is created by sampling N peaks from the profile.
 c ( x ) = p ( x )  X  f ( x ) (1) p where c max is the largest value in c ( x )and S defines the scaled range of p f ( x ) .
 as a horizontal candidate line (Fig. 2 ). The pixel position in each candidate line is recorded, along with the line X  X  width corresponding to the width of the peak. Vertical line candidates are found after splitting the document into its component regions. 3.1.1 Line thinning The list of candidate lines may include lines spaced closer than  X   X  , which is defined to be  X  = w where w 1 and w 2 are the widths of two candidate lines. noise that was unsuccessfully filtered out of the profile. In both cases, these closely paired lines do not contribute to the document X  X  geometric layout and are thinned by removing the weaker of the two lines from the list of candidate lines. 3.2 Region splitting Profiles of an entire image can only be used to find global lines within the document. Local lines would not produce a large enough peak in the profile to correctly segment it against the surrounding noise. In order to find these local lines within a profile, the profile must be constrained to specific areas of the image.
 sponding to regions of similar geometric layout and analyz-ing their profiles, we are able to identify local lines that oth-erwise might not have been identified in the global profile. sections: the header, the body, and the footer (Fig. 1 ). This method is not limited to these three sections and could be generalized to documents of a different layout.
 present in a document while the header and footer regions are optional. The body of the tabular documents under consideration represents the largest of the three sections and demonstrates the greatest intra-document consistency: rows are uniformly spaced and the columns remain the same throughout the body.
 analysis of the horizontal profile. The Fourier transform of p ( y ) is computed and the magnitude | P h ( s ) | determined producing a series of peaks (Fig. 3 ). The first peak ( P in the frequency magnitude spectrum identifies the lowest regularly occurring frequency in the profile and corresponds to the body X  X  line spacing. Each subsequent peak is a harmonic frequency, an integral multiple of the line spacing frequency P 1 .
 the mean of the magnitude. The first value which differs from the mean by more than x standard deviations (where x = 7) is identified as the body line spacing frequency. If no peak was identified, x is decremented until a peak is identified. The body inter-line spacing ( b s ) is obtained in pixel units directly from the the peak frequency: b = T where T is the length of the filtered horizontal profile. body, or footer. Successive pairings of candidate lines spaced by b s are grouped together. The list with the most pairings is determined to contain the list of body lines (body, in Fig. 1 ). Any lines located above this group are labeled as belonging to the header, while lines below are labeled as footer. Any line found within the body which is not spaced by b s from its neighbors is labeled as a false positive and removed. Intra-body consensus is enforced by the constraints of grouped, uniformly spaced lines, while lending robustness to detection of individual lines. lines using the same process discussed in Sect. 3.1. Columns in the body closer than  X   X  (Eq. (3)) are thinned. Columns in the header and footer which are located  X   X  pixels apart from columns within the body are merged together, matching those columns which may extend through more than one section of the document. Finally, columns in the header and footer sections are also thinned.
 is created by combining the horizontal and vertical lines (Fig. 1 ). As each line is added to the mesh, it is subdivided into multiple line segments as it intersects with other lines. The mesh, while not yet completely accurate to the document X  X  actual layout, represents the best guess up to this point. Detection of false line segments is postponed until additional features can be considered to increase the accuracy of identification. 3.3 Local snapping To compensate for geometric distortion which may exist in the image, each line segment X  X  position is adjusted, or  X  X napped X , to the location in the image presenting the strongest line support (Fig. 4 ).
 segment maximizing p ( x ) over the interval defined by the segment. It is labeled the  X  X eed edge X , with its two vertices labeled pivot vertices ( v p ). Beginning with one pivot vertex and moving away from the seed edge, the next adjacent vertex becomes the snap vertex ( v s ) which is snapped to the location maximizing: s ( x ) = e The first term is a Gaussian weighting where p g represents the global line position. Sigma defines the width of the Gaussian and is ( 1 / 2 s r ) l where l is the snap neighborhood height for rows or width for columns and s r represents the snap resistance. lp f ( x ) is the filtered local profile over the line segment (v p , 1 2 (v s + v s + i )) where v s + 1 is the next adjacent vertex.
 to adjust its position to locations close to the line X  X  global position, but becomes increasingly restrictive the farther away it gets. By adjusting s r  X  X  value we can restrict how far we allow snapping to occur from the global position. neighborhood to prevent overlapping with adjacent rows or columns and v s is moved to that position. The variable v now becomes v s and v s advances to the next adjacent vertex in the line. This process continues until there are no more vertices to snap in that direction. The algorithm repeats with the remaining pivot vertex, moving in the opposite direction. 3.4 False positive detection Peaks found in a profile often correspond to items other than actual lines in the image, primarily rows or columns of printed text. In addition, candidate lines initially extend through the length of the document which may not be the case (footer, in Fig. 1 ). These false positives need to be identified and removed from consideration as lines. pendicular profile of each line segment in the header and footer (Fig. 5 ). For a line of text, alternating characters and whitespace create a high amount of variability in the profile compared with an actual line.
 scan-converted line segment, scaled by a neighborhood min and max, is generated. If mean( l ) &lt; T m or variance ( l ) then the line is labeled a false positive and removed. a closed ROI is removed. 3.5 Document template creation To exploit the inter-document consensus, we combine zoning information gained from each document to create a template describing the geometric layout of the document set. Each document is zoned (Fig. 6 a) and the created mesh is stored (Fig. 6 b). The mesh may be incomplete due to low image quality, resulting in missed lines or not removing some false lines. A subsequent image with the same layout is zoned and its mesh saved (Fig. 6 c). This mesh may be slightly different, missing and finding some different lines than the first mesh, even though the document layout is the same. By combining these two meshes (through registration and addition), any missed lines in one mesh but found in the other, are filled in (Fig. 6 d). Combining meshes from the remaining images in the data set creates a mesh containing the accumulated zoning information from all the documents in the data set (Fig. 6 e). The frequency of occurrence for each line segment is kept. Lines which were not found consistently having a lower frequency of occurrence are assumed to be spurious zoning errors. Thresholding out the less frequent lines produces the completed template describing the geometric layout of the document (Fig. 6 f). choose to merge m 2 into m 1 .Since m 2 was created from a different document than m 1 , the position of each mesh may be different. In addition, the scale from one image to the next might also be slightly different, especially among large, high-resolution images. To merge line information from m 2 into m 1 , m 2 must first be registered to m 1 . dy ) to register m 2 to m 1 is determined by correlating the horizontal and vertical profiles of m 2 to m 1 . The correlation operation is used to measure the amount of overlap between m 1 and m 2 . As overlap increases, the correlation output increases.
 horizontal and vertical profiles of m 2 independently. The vertical profile of m 1 is first correlated with the vertical profile of m 2 at several different scales. The scaled profiles are created using the same process as described above, except the position and width of the row are scaled by the scaling factor.
 to the same position as m 1 . The meshes should completely overlap after scaling and shifting, but because of image distortion, this may not be the case. To identify which rows and columns in m 2 correspond to rows and columns in m , an equivalency mapping is created. The equivalencies are created by identifying the rows and columns in the same, or about the same, position between the two meshes. Establishing equivalencies is similar in principal to the local snap discussed previously.
 column equivalencies are determined similar to the rows. tions, columns may exist in either one or more sections. Therefore, correspondences are established only between columns that belong to the same section(s).
 then columns from m 2 are merged into their corresponding rows and columns in m 1 . Each row is merged segment by segment into the corresponding segments of the row in m . If the segments from m 2 do not completely overlap the segments in m 1 , the segments in either m 2 or m 1 are split so that only completely overlapping segments are merged together.
 segment maintains a count of the number of times it was accumulated and keeps a running average of its width and position. If no correspondence for a row in m 2 was found, the line is simply inserted into m 1 with an initial vote of one.
 same process described above. 3.5.1 Template thresholding When all the meshes have been combined into one, the number of votes for each line segment represents the segment X  X  frequency of occurrence. The histogram of votes for all line segments in the merged mesh forms a bimodal distribution. Because of the distribution X  X  well-defined bimodality, a simple Otsu threshold [ 7 ] is used to effectively threshold those segments with a high vote count from those with a low vote count.
 those line segments found consistently within the collection of documents. The resultant binarized mesh becomes a tem-plate representing the geometric layout of the table (Fig. 6 f). 3.6 Global snapping With a robust template of the document X  X  geometric layout, subsequent images can be zoned by snapping the template to the documents in subsequent images. Identify-ing the document X  X  position is accomplished by correlating the horizontal and vertical profiles of the image with the profile of the template. The point of the highest correlation identifies the location of the document. generated using the approach discussed in Sect. 3.1. The template X  X  profile is created by establishing a peak at every line location. The peak X  X  intensity for line x is determined by I ( x ) = where v is the number of votes received for each segment in the line, N is the number of segments in the line, V is the total number of votes, and l ( x ) is the length of the line. zero corresponding to the estimated width of the line. size that might exist from image to image, the template X  X  signatures are generated at several different scales. Begin-ning with the scale range [0.96, 1.04] at increments of 0.01, the scale with the maximum peak ( s ) is identified. The scale is further refined over the range [ s  X  0 . 005, s + 0 . 005] at increments of 0.001.
 dx = P v  X  s v (7) dy = P h  X  s h (8) where P is the peak location in the correlated profile and s is the size of the profile for vertical and horizontal profiles. snapped into position (Fig. 7 ) following which the mesh undergoes a local snap as well. To be less susceptible to noise, local snapping at this stage is more restrictive with an increased s r value. This is to prevent snapping to neighboring signals, such as a text line, which might prove stronger than the actual line. 3.7 ROI content classification With the creation of the document template, the content in each field or ROI is classified into one of three classes: empty, printed text, or handwriting.
 ROI X  X  dominant axis for each ROI from multiple documents. Empty ROIs are identified by their relatively linear profile measured by calculating the standard error of estimate from the least squares regression line of the profile. If the ROI is empty, it is removed from consideration as a candidate printed text ROI.
 each other resulting in ( N /2) comparisons. Each comparison is made by calculating the correlation difference d ( x ) = For those ROIs which contain printed text, p 1 and p 2 will be very similar (Fig. 8 )and d ( x ) will have a minimum around N /2. Those ROIs identified with high correlation are classified as printed text ROIs while the remainder are classified as handwriting. ric layout of the table with each region X  X  content classified and awaiting further processing (Fig. 9 ). 4Results There are two basic results to consider: the geometric accuracy and the ROI content classification accuracy. First, a brief description of the data and the metrics used to cal-culate performance will be given, followed by the measured results. Finally, a brief discussion on speed performance is included to evaluate the feasibility of applying this approach to document zoning of large collections of images. 4.1 Data sets Four different data sets were used to evaluate the perfor-mance of the zoning algorithm: the British 1841 (Fig. 19 ) and 1881 (Fig. 20 ) census and the U.S. 1870 (Fig. 21 )and 1930 census (Fig. 22 ). Each document group represents a line-delimited table, each with their own deficiencies in image quality.
 sets were scanned from microfilm in full 8-bit grayscale at the highest possible resolution on a Wicks and Wilson 4100 scanstation. The 1930 census images 1 were also scanned from microfilm, but at a much lower resolution. The number of documents used to create a template and their average image size for each data set is listed in Table 1 . bleed thru, and poor focus. The British 1881 census suffered from some faint writing but overall had good contrast and provided the best quality images out of the four data sets. The U.S. 1870 census suffered from uneven density, faint writing, high base fog, and spots. The U.S. 1930 census suffered from geometric distortion, faint lines, and was acquired at a much lower (marginal) resolution, compared with the other three document sets. 4.2 Performance metric There is a lack of standard performance metrics in the field of document recognition systems. The results of many approaches are either presented in a non-quantitative way or by using a metric specific to the type of document being zoned. With such a variation in performance metrics, it becomes difficult to provide a valuable comparison between any two zoning methods or to even provide a system-agnostic method of measuring zoned results compared with the ground truth of the document.
 proposed by Garris [ 6 ] to measure our results. Given a reference mesh representing the ground truth of the docu-ment X  X  geometric structure, it is compared with the result generated by the document recognition system called the hypothesis mesh. The hypothesis mesh is measured by two criteria: efficiency and coverage. These two metrics mirror to some degree the metrics of accuracy and precision used in information research. Efficiency measures the number of ROIs found compared with the number of zones in the reference mesh. Coverage measures the similarity between the hypothesis and reference zones.
 pothesis mesh, a one-to-one mapping is created between the zones in the hypothesis and reference meshes. Garris does not present a mapping algorithm. The mapping algorithm we used snaps the hypothesis mesh to the reference mesh using the approach discussed previously. Each reference ROI is matched to the hypothesis ROI that has the greatest area of overlap with the hypothesis ROI X  X  area. If the area of overlap is less than 20% of the reference ROI X  X  area, it is not counted as a match. If no reference ROI overlaps with the hypothesis ROI, that ROI is counted as an  X  X nsertion X , meaning an extra ROI was inserted into the hypothesis mesh where none existed. Any reference ROIs which are not matched to an hypothesis ROI are counted as  X  X eletions X , meaning the reference ROI was not found in, or was deleted from, the hypothesis mesh.
 e = d where d is the number of  X  X eletions X , i is the number of  X  X nsertions X , and N is the total number of ROIs in the reference template.
 each ROI in the hypothesis template has been paired to an ROI in the reference template. This results in an efficiency error of zero. ROI a is paired with ROI 1 because it overlaps 1 more than 3 .ROIbispairedwith2andcispairedwith3.
 If the area of overlap between c and 3 had been smaller than 20%, they would not be paired together.
 greater area of overlap with ROI 1 than 2. ROI d is paired with ROI 3 because of a greater overlap than the overlap be-tween c and 3. ROI 2 is not paired and is labeled as a deletion while ROIs b and c are labeled as insertions. The efficiency error for this hypothesis template is ( 1 + 2 )/( 3 + 1 + c = u where u is the amount of underage , o is the overage ,and A is the total reference area. Underage is defined as the combined area of reference ROIs which do not overlap with the hypothesis ROIs and includes the area of  X  X eleted X  ROIs. Overage is the combined area of the hypothesis ROIs which do not overlap with the reference ROIs and includes the area of  X  X nserted X  ROIs.
 hypothesis template introduced in Figs. 10 and 13 shows the coverage error ( c = 0 . 46) for Fig. 11 .
 of accuracy can be determined. It can be seen that the two measures can be complimentary. A mesh with a low efficiency error (Fig. 10 ) can have a high coverage error (Fig. 12 ). The reverse, however, is not true because a mesh with a low coverage error would imply a low efficiency error. 4.3 Geometric evaluation Figure 14 a and b show two meshes created from the collec-tion of zoned 1841 census images. Each image, depending on its quality, may produce a mesh identifying lines where there are not any or missing lines where they exist. These two meshes along with 44 other meshes created from the remaining images in the data set are combined to form themeshinFig. 15 a. The histogram of line segments X  votes shows the bimodal distribution between line segments that occur with low and high frequency (Fig. 15 b). The vote threshold as determined by the Otsu threshold algorithm is 23, meaning that if a line segment does not receive votes from more than 22 documents (in this case one-half), it is removed. The final thresholded mesh is shown in Fig. 15 c. The error for the final template is calculated by comparison to the reference template, which is a user-modified version of the final template representing the ground truth of the document X  X  geometric layout. In Fig. 15 c, the final template has one deletion and one insertion for an overall efficiency error of 0.008. Both the deletion and insertion are found in the header of the document.
 meshes can be seen for the 1870, 1881, and 1930 data sets in Figs. 16  X  18 , respectively.
 four thresholded templates are listed in Tables 2 and 3 , respectively. For the 1841, 1870, and 1881 data sets, each deletion and insertion occurred in the header and footer. The deletions were the result of a local line that was too small to generate a profile peak strong enough to be identified, or the line strength was consistently weak from image to image. The insertions were the result of text lines that were not distinguishable from an actual line, generally because of the blurring together of adjacent characters within the text line. than the other three data sets with 479 deletions and 1 insertion. Of those deletions, 468 came from nine columns that were missed. The missed columns were a result of little to no line support present in most of the documents because of the marginal resolution with which those documents were scanned.
 mean efficiency and coverage error for each image in its cor-responding data set is listed in Tables 4 and 5 . In every case the error rate was lower for the template than for the average image. This clearly demonstrates that zoning an image using consensus by combining information produces a more accurate result than by individually zoning each document. 4.4 Global snapping With an accurate template describing the geometric layout of a document, subsequent images of the same layout can be zoned simply by applying the template. However, since the template and document may not lie at the same position, the template must first be registered to the document through the process of global  X  X napping X .
 the granularity of indexing from the image level to the in-dividual fields defined by the template. Field-level indexing allows for automatic content extraction where, in the case of census records, surname fields or other vital data can be extracted automatically from each table by applying the template as a  X  X ookie cutter X . Since the template is already defined, zoning accuracy remains constant, providing robustness with images of varying quality. It also takes less time to snap a template to an image rather than having to try and recreate it with each image. template for each data set was snapped to each image in the set. In every case, the template was snapped correctly to the document X  X  location in the image! 4.5 Classification evaluation Classification of ROI content is broken down into two sep-arate steps. First, identifying the ROIs containing machine print and second, finding the empty ROIs. 4.5.1 Machine print Using a template that accurately represents the ground truth of the table X  X  geometric layout, the template is snapped to each image in the data set. Every ROI in the template is sampled by computing the profile from the ROI X  X  dominant axis. These profiles are compared for similarity to their counterparts from document to document. Those ROIs whose profiles exhibit high degrees of correlation, exceed-ing the threshold T m (Sect. 3.7), are labeled as containing machine print. The template with the labeled machine print ROIs is compared with a reference template whose manual labeling of machine-print ROIs represents the ground truth of the document. The results are calculated in the same manner as efficiency according to the following: m = n where n is the number of false negatives (ROIs that should have been classified as machine print but were not), p is the number of false positives (ROIs that should not have been classified as machine print but were), and N is the number of machine print ROIs in the template. The accuracy of machine print ROI classification for each of the four data sets is listed in Table 6 .
 because the leftmost and rightmost columns in the table numbered the rows from 1 to 50 on the odd pages and 51 X 100 on the even. This dissimilar ROI content from odd to even pages helped contribute to the high classification error. By comparing just the even pages and the odd pages separately, we can see a lower error rate.
 sus), 11 (1881 census), 12 (1870 census), and Fig. 13 aand b (1930 even and odd pages, respectively). The first thing to note is that  X  X ixed content X  ROIs, those ROIs which contain both machine print and handwriting, are labeled as machine print. This shows that although the handwriting provides variable content, the machine print in this case dominates the profile. While it could be argued that a third class is required for mixed content ROIs, the current classification method is unable to distinguish between a mixed content ROI and either a machine print or handwriting ROI.
 amining the results. In the 1841 census there were four ROIs which are machine print ROIs but were not classified correctly. The reason for the incorrect classification is due to the variable quality of the ROI from image to image. This disparity between profiles results in a low correlation and misclassification (Fig. 23 ) but could perhaps be addressed through prior image enhancement.
 Because the images were scanned with such a marginal resolution, the ROI profiles were scaled up during normal-ization to identify their content, however, this causes a noisy but empty ROI to be falsely classified as nonempty. 4.5.2 Handwriting With the machine-print ROIs identified, the remaining ROIs are classified as either empty or non-empty. It is assumed that the non-empty ROIs contain handwriting conveying some sort of information, but the ROI could also contain imaging artifacts such as noise, uneven background, bleed thru, ascenders, and descenders, which contribute to misclassification. The current method does not distinguish between the two. In this case, it is desirable to label anything which could contain handwriting or other content, allowing for a subsequent higher-level contextual analysis to separate handwriting from noise. With this goal in mind we would expect to see a higher rate of false positives than false negatives.
 reference template for each image in each data set was created manually. The template identifies all the ROIs containing handwriting with the remainder labeled as empty. These collections of reference templates provide the ground truth by which our results are evaluated. It should be emphasized that these reference templates identify those cells which are thought to contain handwriting. Empty cells and non-empty cells thought to contain noise are labeled as empty. The purpose for this is to establish a true and accurate baseline by which we can compare the results of our empty/non-empty decision to future approaches which might attempt to separate noise from handwriting. The false positives identify the number of ROIs not con-taining handwriting that were classified as containing handwriting. The false negatives identify the number of ROIs which do contain handwriting but were classified as empty. The error rate is calculated using the same equation as efficiency (Eq. (10)), where false positives are counted as insertions and false negatives as deletions.
 As expected, the error for false positives was found to be generally higher than the error for false negatives. False negatives were almost always the result of faint writing. A second cause for false negatives occurred when the amount of handwriting was significantly smaller than the area of its bounding ROI. The signal belonging to the handwriting was dominated by the background signal in the profile.
 descenders and those ROIs that contained a non-uniform background resulting in a non-linear profile. If the ROI X  X  profile deviated enough from its first order approximation, the ROI was labeled non-empty. 4.6 Speed performance While the focus of this research was not on speed, the methods presented in this paper are able to work quickly with high resolution images. Table 8 shows measurements for three steps in the template creation process: zoning (mesh creation), mesh accumulation, and machine print classification. The timing averages of three separate runs were made and are compared with a timed estimate to manually zone an image. These tests were performed on a dual Athlon 1800 + with1GBRAM.
 an image, zone it, and write out to file the corresponding mesh. The mesh accumulation ( Acc .) column measures the average time to read in a mesh and merge it into the template. The label column measures the average time taken per image to classify machine print ROIs by reading the image, snapping the template to the image, sampling profiles from each ROI, and comparing the ROI profiles from each  X  X ampled X  image. The total time is the sum of the average time taken per image to perform those three steps. estimated from the following formula: C ( l ) = s + al (13) where s is the startup cost to load the image and setup the tool used to create the template, a is the time needed to cre-ate a line segment, and I is the number of contiguous lines that would have to be added to create a template of the im-age. It was assumed an experienced operator would require 10 s to set up ( s = 10) and that they could create a line seg-ment every 3 s ( a = 3). Labeling machine print ROIs could be done with a simple mouse-click on the ROI. Clicking on each machine print ROI was assumed to take 1 s per ROI. the manual estimates, creating an accurate template will probably require that multiple images be zoned. Even after a template has been automatically created, it may still not be completely accurate, requiring manual correction. Table 9 shows the combined time required to automatically zone, accumulate, and label each data set using all the images in the set. This time includes the time required to manually correct any error found in the resultant template. The time required to manually correct a template is computed the same as with the manual estimate, with a setup time often seconds, 3 s to create and/or delete a line, and one second to correctly classify each ROI missed or falsely added. is less than the automatic zoning approach, it should be noted that there are several inefficiencies in the current zoning process. First, all the images in the data set were used for template creation. If, during the zoning process, it was determined that no new information was being added to the mesh, the process could stop without having to zone the remaining images in the set. This would decrease the time to automatically create the template. In addition, accumulation of meshes could occur as a collection of images are being zoned. Labeling of machine print ROIs could also occur in parallel so that each image only has to be read once, instead of twice, as is currently the case.
 the semi-automated process was still quicker than manual creation. In spite of the manual corrections required, the semi-automated method proved quicker because of the small image size and table complexity.
 a template to an image. These timings also include the classification of all non-machine print ROIs as either empty or containing handwriting. The manual estimate would, at best, require the template to be dragged in place over the document. Manual classification of ROIs into empty and handwriting would depend on their ratio of occurrence. If there are more handwriting ROIs versus empty, it would be more efficient for the operator to identify those empty ROIs. The reverse would be true if there were more empty ROIs to handwriting ROIs. The worst case would occur as the ratio between the two classes approached 1:1. We assume a 1:4 ratio, that is one empty ROI to four handwriting ROIs or vice versa. The manual estimate is figured using the same formula defined in Eq. (13) where s is the time to drag the template into place, assumed to require 5 s ( s The time to label an ROI as either empty or handwriting is assumedtobe1s( a = 1) and the number of ROIs to be labeled ( R ) per image is assumed to be one-fourth of the number of non-machine print ROIs in the image ( l = R / 4 the time required to automatically snap a template to an im-age and classify ROIs into empty/handwriting is markedly less than having to do the same thing manually. Labeling requires the bulk of the time, which is one reason the manual estimates are so high. If labeling didnot occur, the time between automated snapping and manual snapping would be roughly equal. However, while the time may be equal, there is an unmeasured benefit of not requiring an operator to have to attend to each and every document, allowing the computer to automatically perform the snapping. 5Conclusion We have shown that exploitation of intra-and inter-document consensus leads to a significant improvement in accuracy. Measured results show that templates created from multiple documents are more accurate than the average template created from a single image from 1.5 times better for the 1930 census to 24 times improvement in the 1870 census. Furthermore, we believe that the use of consensus in this way would also improve the results obtained from other techniques that are designed for, and applied to individual document images.
 ROIs containing static machine print, by measuring their similarity from document to document, produces good results provided the difference in image quality between images is not too extreme. Identifying whether the cell is empty or not also produces good results, but is much more dependent and sensitive to image quality.
 generated, it can be globally (and locally) snapped to a new image of the same layout. This is done completely automatically, correctly handling slight variations in scale and geometric distortion. In fact, it has never failed in the 132 documents tested against. Thus, the template can now be used as a robust  X  X ookie cutter X  to index and extract the content of hundreds of subsequent images of the same layout automatically without any operator intervention. this approach can be practically applied to high-resolution images requiring only a few seconds to perform the zoning process.
 References
