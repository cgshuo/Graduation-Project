 In this paper we propose a term clustering approach to im-prove the performance of sentence retrieval in Question An-swering (QA) systems. As the search in question answer-ing is conducted over smaller segments of data than in a document retrieval task, the problems of data sparsity and exact matching become more critical. In this paper we pro-pose Language Modeling (LM) techniques to overcome such problems and improve the sentence retrieval performance. Our proposed methods include building class-based mod-els by term clustering, and then employing higher order n-grams with the new class-based model. We report our exper-iments on the TREC 2007 questions from QA track. The re-sults show that the methods investigated here enhanced the mean average precision of sentence retrieval from 23.62% to 29.91%.
 Categories and Subject Descriptors: H.3.3 Informa-tion Storage and Retrieval:Information Search and Retriev al [clustering, retrieval models] General Terms: Theory, Algorithms Keywords: information retrieval, sentence retrieval, ques-tion answering, language modeling, term clustering
In the recent past, open domain QA has become one of the most actively investigated topics in natural language pro-cessing. Its popularity stems from the fact that a user re-ceives an exact answer to his questions rather than being overwhelmed with a large number of retrieved documents, which he must then sort through to find the desired answer.
In complete a QA system, document retrieval is an im-portant component which should provide a list of candidate documents to be analyzed by the rest of the system. Docu-ment retrieval, however, is insufficient, as the retrieved do c-uments are much larger than the required answer, and topic changes typically occur within a single document. In the QA context, the relevant information is most often found in one sentence or two. Hence, it is essential to split the text into smaller segments, such as sentences, and rank them in a sentence retrieval step which is our research focus. Re-trieved sentences are then further processed using a variet y of techniques to extract the final answers. Shen [12] showed that improvement in sentence retrieval performance has a significant positive effect on the accuracy of the QA system.
For retrieving relevant sentences, we adopt here the LM-based information retrieval proposed by Ponte and Croft [10 ]. This technique has also been used for sentence retrieval and found to outperform other methods like tfidf and Okapi [9].
In the majority of the information retrieval literature, a simple word-based unigram is used. The major fault of this model is that all terms are treated independently and no re-lationships between words are considered. When estimating word-based unigrams, a search is performed for only the ex-act literal words present in the query. In consequence, such algorithms will fail to retrieve other relevant informatio n. For example, having the question  X  X ho invented the car? X  as an input for a QA system, the sentence retrieval compo-nent might retrieve  X  X etween 1832 and 1839, Robert An-derson of Scotland invented the first crude electric car car-riage. X  . But using the exact match model, the retrieval al-gorithm misses sentences like  X  X icolas-Joseph Cugnot built the first self propelled mechanical vehicle. X  or  X  X n automo-bile powered by his own engine was built by Karl Benz in 1885 and granted a patent. X  , although these sentences con-tain the words  X  X uilt X  ,  X  X ehicle X  , and  X  X utomobile X  which are very likely to be relevant to the question.

For this reason, it is desirable to have a more sophisti-cated model to capture the semantics of sentences rather than just the term distributions. This issue has motivated a great deal of research on term relationships over the last decades. Improvements in system performance from such schemes have proven chalenging, however, for two primary reasons: the difficulty of estimating term relationships and the difficulty of integrating both exact match and term rela-tionships in a single weighting scheme [6]. In this paper, we introduce a class-based model by applying term clustering t o estimate term relationships. Then, use a linear interpolat ion to integrate both word-and class-based models.

The paper is organized as follows. In Section 2, we de-scribe our class-based model. Section 3 introduces the idea of using higher order n -grams in the new class-based model. In Section 4, experimental results are presented. Finally, Section 5 summarizes the paper and suggests future work.
In this research, we use a class-based LM by applying term clustering to capture term relationships. Term clustering has been widely used in different natural language process-ing applications, including speech recognition [11], mach ine translation [15], query expansion [1], text categorizatio n [4], automatic thesaurus generation [7], and word sense disam-biguation [8]. However, to the best of our knowledge, it has not been applied to LM-based information retrieval.
One of the advantages of term clustering is its flexibility to capture different features. Semantic, syntactic, and sta -tistical properties of terms can be utilized in various term clustering algorithms. Another advantage of term clusteri ng is its inherent reduction in data sparsity. As there are vast ly fewer clusters than words, the variation in possible patter ns is reduced and the probability of seeing a given pattern is thereby enhanced. Hence, in addition to relaxing the exact match requirement the proposed approach solves a portion of the data sparsity problem.
In LM-based sentence retrieval, the probability P ( Q | S ) of generating query Q conditioned on the observation of sentence S is first calculated, and thereafter sentences are ranked in descending order of this probability. For word-based unigrams, the probability of the query Q given the sentence S is estimated based on query terms.
 where M is the number of query terms, q i denotes the i th query term in Q , and S is the sentence model.

For class-based unigrams, P ( Q | S ) is computed based on the cluster to which each query term belongs, where C q i is the cluster that contains q i and P ( q i | C the emission probability of the i th query term given its clus-ter and the sentence. To calculate P ( C q i | S ), the sentence model is created based on clusters instead of terms. As a result, each cluster is considered as a single entity and the se new entities are used to create the model.

To be more specific, for each sentence in the word-based model, the sentence terms are extracted. Then the sentence unigram is created from the terms. While in the class-based model, using a term clustering technique, a map between terms and clusters is created. In this case, instead of ex-tracting the terms, the clusters which the terms belong to are extracted. Then the sentence unigram is created from the clusters. Finally, P ( Q | S ) is computed based on the new model of S , and the sentences are ranked according to this probability.
In order to cluster lexical items, we used the word clus-tering algorithm proposed by Brown [2] which is one of the most well-known and effective clustering algorithms in LM.
The Brown algorithm uses mutual information between cluster pairs in a bottom-up approach to maximize Average Mutual Information (AMI) between adjacent clusters.
As shown in Algorithm 1, the clusters are initialized with a single term. Then, in each iteration, all pairs of clusters are Algorithm 1 The Brown Word Clustering Algorithm Initial Mapping: Put a single word in each cluster
Compute the initial AMI of the collection repeat until reach the predefined number of clusters repeat until no more increment in AMI temporarily combined and the AMI between adjacent clus-ters is computed. Thereafter, the best cluster pair, which offers a minimum decrement in AMI, is permanently com-bined together. This continues for V  X  K iterations, where V is the number of terms and K is the predefined number of clusters. To increase the AMI, a final step is performed, whereby each term is moved to that cluster for which the resulting partition has the greatest AMI. The algorithm ter -minates when AMI ceases to increase.

Upon examining the results of the clustering, it is evident that there is a clear relationship between the terms belongi ng to the same cluster. The following lines show some examples of clusters created by the Brown algorithm:  X  significantly, highly, strongly, fairly  X  shipping, carrying  X  Jazz, symphony, theater which indicate having only a single term of a cluster is suf-ficient to search for other terms of the same cluster. For example, seeing the term  X  X ighly X  in a query, the class-based model is able to retrieve sentences that do not have this term but are nonetheless relevant to the query in that the cluster also contains other terms like  X  X trongly X  . The word-based model, on the other hand, would not rank such sentences highly.
The class-based model can reasonably be expected to in-crease system recall, in that it is able to find more rele-vant sentences. This method may decrease the system pre-cision, however, by retrieving more irrelevant sentences. To avoid this problem, we use the linear interpolation of our new class-based model and the word-based model, thereby benefitting from the advantages of both models and avoiding their disadvantages.

To use the interpolation model, the probability q i given both word-and class-based models is computed from (1) and (2) and interpolated by a weighting parameter  X  .
As mentioned before, one of the difficulties of relaxing the exact matching assumption is the problem of integrating both exact matching of single words and term relationship in a weighting scheme. By using the interpolation model we can test our model with different weights of  X  .
In practice, the statistical LM is often approximated by the recent sequence of words, namely n -grams. The simplest of n -gram models, namely the unigram, is most often used in information retrieval applications. In this model, howeve r, the word dependencies are not considered. To overcome this problem, it is necessary to consider longer word contexts, such as those used in the bigram and trigram. As these models include local context, they are able to condition the probability of the next word on those previous.

Much of the research into traditional information retrieva l methods failed to result in performance improvements by applying either bigram or trigram models [3]. Song and Croft [14] used bigram for the first time in LM-based infor-mation retrieval and obtained a better result in document retrieval.

It is very difficult to apply these models in the context of sentence retrieval, however, as data sparsity at the senten ce level is much more pronounced than that at the document level. At the sentence level, the probability of seeing larg e patterns is very low and hence it is very difficult to use higher order n -grams for sentence retrieval. To overcome this prob-lem, we applied the class-based bigram and trigram instead of the word-based bigram in order to test the hypothesis that by using the class-based model, the data sparsity prob-lem could be sufficiently ameliorated so that higher order n -grams would become effective for this task.

Having class-based sentence retrieval, we use class bigram and class trigram models formulated as follows:
Although the class-based model helps to have less sparse data, this problem is not fixed completely. Hence, for using the trigram model, the bigram model is used as background model. The bigram probabilities have also been combined with the unigram as a background model. questions from the QA track. The TREC 2007 QA task con-tains 70 question series, which focused on a target, consist ed of several factoid questions, one to two list questions, and exactly one other question [5]. For our experiments, the fac-toid questions have been used, while the sentence retrieval model described in this paper are suitable for different type s of questions. The total number of factoid question for all 70 series used in our experiments is 218 questions.

The relevance judgments available in NIST data are an-notated at the document level. To evaluate our sentence retrieval, we need to perform our own annotation to find rel-evant sentences as  X  X round truth X  in evaluating our model. A relevant sentence in the QA task, is a sentence which is http://trec.nist.gov related to the question and contains the answer. To ex-tract the set of relevant sentences, we used an automatic step followed by a manual step. In the automatic step, for each answer of each question, the relevant document to that particular answer released by NIST was processed and all sentences that contain the answer string were extracted. In the second step, the extracted sentences were checked man-ually and the sentences which are not related to the context of the question were filtered out.

To do our sentence retrieval experiments, a set of 1,960 sentences were used as input to our system. For each ques-tion, the sentence set contains the relevant sentences to th e question which is almost 10 sentences on average with the rest of the sentences in the set being irrelevant. This in-put set was selected in the same way as described by Shen et. al [13]. Since the answers of TREC 2007 questions are extracted from the BLOG06 and AQUAINT corpora, we also used the same corpora for document retrieval and con-sequently the sentence retrieval task. The lexicon contain ed nearly 10,000 terms, which included all words present in the questions and the sentences to be processed.

To create the proposed model, in the first step, word-based unigram and bigram models were created. Then, by clustering lexical items, class-based unigram, bigram, an d trigram models were created, wherein lower order n -grams were used as back-off models. Finally, the new class-based model was interpolated with the word-based model. For each question, the system ranked the sentences according to the probability of generating the query from the sentences models.

For all models three different smoothing methods pro-posed by Zhai and Lafferty [16] for the document level were applied. The smoothing methods include Jelinek-Mercer lin -ear interpolation, Bayesian smoothing with Dirichlet prio rs, and absolute discounting.

Finally, we need to specify the number of classes to cluster the words. Tests were conducted with several numbers of clusters. Figure 1 shows the mean average precision (MAP) of the class-based unigram for varying numbers of clusters. Setting the number of clusters to 0, the model works like the uniform model. Equating the number of clusters with the number of words is equivalent to using a word-based model. According to the results, the best mean average precision is achieved by clustering all 10,000 lexical items into 3,00 0 clusters. We have the same result in bigram and trigram. Hence, this value was used in all further experiments.
Table 1 reports the upper bound results of our experi-ments while using different smoothing parameters, in which we use the word-based unigram as our baseline. The columns titled X % change X  X llustrate the relative change of each mod el compared to word-based unigram model. As shown, we achieved a significant improvement on class-based unigram compared to the word-based unigram model. This improve-ment indicates that the term clustering approach proposed here could successfully capture relationships between ter ms and retrieve more relevant sentences.

As discussed in Section 4, using word-based bigram model did not improve the mean average precision due to the data sparsity problem at sentence level. The class-based bigram , however, does improve the sentence retrieval performance which shows that our proposed class-based model solved a part of data sparsity. The performance of the class-based trigram is still inferior to that of its bigram counterpart, however, due to data sparsity that our procedure has not entirely eliminated.
 Figure 2: MAP over different interpolation weights
As mentioned previously, to achieve the best performance, we interpolated word-and class-based models. Towards this end, the best class-based model which is bigram and the best word-based model which is unigram were selected. Figure 2 shows the mean average precision for various values of  X  . We see the interpolation model with any mid-range weight outperforms both word-and class-based models, while at  X  = 0 . 5, mean average precision increases to 0.2991.
In this paper we introduced a class-based LM approach using term clustering for sentence retrieval in QA systems to solve the data sparsity, the exact matching, and the term independence problems. We found out that the class-based model using term clustering is an effective approach to this end. In addition, we also evaluated class-based bigram and trigram. Moreover, linear interpolation of a class-based b i-gram and a word-based unigram was investigated. Our results indicated a significant improvement of sentence re-trieval mean average precision from 23.62% to 29.91%.
In this research we only applied the Brown clustering method, as this is the best-known algorithm for term clus-tering in LM. In future work, we plan to apply other term clustering algorithms and compare their effectiveness on se n-tence retrieval performance.
