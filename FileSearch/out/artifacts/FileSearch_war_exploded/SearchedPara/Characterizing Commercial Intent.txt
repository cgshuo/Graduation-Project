 Understanding the intent underlying user X  X  queries may help personalize search results and therefore improve user satis-faction. We develop a methodology for using the content of search engine result pages (SERPs) along with the infor-mation obtained from query strings to study characteristics of query intent, with a particular focus on sponsored search. This work represents an initial step towards the development and evaluation of an ontology for commercial search, con-sidering queries that reference specific products, brands and retailers. The characteristics of query categories are studied with respect to aggregated user X  X  clickthrough behavior on advertising links. We present a model for clickthrough be-havior that considers the influence of such factors as the lo-cation of ads and the rank of ads, along with query category. We evaluate our work using a large corpus of clickthrough data obtained from a major commercial search engine. Our findings suggest that query based features, along with the content of SERPs, are effective in detecting query intent. The clickthrough behavior is found to be consistent with the classification for the general categories of query intent, while for product, brand and retailer categories, all is true to a lesser extent.
 H.3.5 [ Information Storage and Retrieval ]: On-line Information Services Algorithms, Experimentation, Measurement query intent, sponsored search, clickthrough, evaluation Intent detection is one of the crucial long-standing goals of information access. Understanding the intent underlying user queries may help personalize search results and there-fore improve user satisfaction. Traditionally, user intent may correspond to any of the standard categories of Web query [7]: navigational , informational , and transactional . On the other hand, in the context of sponsored search, informa-tion providers may wish to know whether a user has the in-tention to purchase or utilize a commercial service, or what is called online commercial intent [12]. Sponsored search has evolved to satisfy the needs of users for relevant search results and the desires of advertisers for increased traffic to their Websites. It operates by matching ads to queries as they are received by a search engine. These ads are dis-played to the user, along with organic search results. Ad-vertisers are usually charged according to the cost-per-click model [6], where the charge is calculated based on the user clicks (if any) on the displayed ads. Ideally, advertisers wish to bid on multiple low-cost, highly targeted keywords that will generate high clickthrough rates (CTR) for their ads, where ad clickthrough rates are known to decrease as ads are displayed in lower ranks on result page due to reduced visual attention [25]. This is also addressed by Joachims et al. [17] in terms of search engine organic clickthrough, and it is referred as the  X  X rust bias X  effect of displayed results based on their ranks.

As pointed out by Broder et al. [8], when there is no ad relevant to the user X  X  interest, showing irrelevant ads should be avoided as they could annoy the user and produce no economic benefit. Moreover, bringing query intent detection into the context of sponsored search can help advertisers to automatically create more appropriate and relevant ad con-tent, develop better ranking ads by matching the content of ads with the user X  X  query intent, as well as contribute to the general understanding of user intent inference and Web search behavior modeling. This paper approaches query in-tent detection using the information obtained from the query itself (e.g. the number of characters and words in the query string). In addition, result pages returned for queries are considered as representatives of the nature of the queries, and therefore their content is used as a means to identify the intent underlying queries.

There is a relatively easy, cheap, and reliable approach presented to label a set of queries through Amazon Mechan-ical Turk 1 in order to be used for training purposes. The queries are consistently labeled by assessors in different di-mensions, and such labels are fed to classifiers in order to identify different categories of query intents for a larger set of queries. The classification accuracies confirm that distinc-tions among these categories are reasonably distinguishable, and also query based features, along with the content of www.mturk.com/mturk Category Feature Description search engine result pages (SERPs), are effective in detecting such categories. In this regard, the paper presents an initial step towards a long-term goal of extending the traditional categories of Web queries [7] by developing and evaluating the seeds of an ontology for commercial search. In addition to the commercial/ noncommercial and navigational/ infor-mational dimensions of query intent, we consider queries that reference specific products, brands and retailers, avoid-ing the more traditional topical categories, such as sport and news.

Several methods in sponsored clickthrough analysis have been proposed in the literature [13, 15, 25]. The problem is mostly addressed using the content of ads [18], while the influence of factors such as rank of ads and queries for which the ads appear on the search result page are often not con-sidered. In this regard, the purpose of our work, in part, is to build a clickthrough model in order to study whether there is a relation between user X  X  behavior in ad clickthrough and characteristics of queries and their corresponding spon-sored results shown on a search result page. Hence, ad click-through behavior is studied with respect to such factors as the number of displayed ads, location of ads, and rank of ads and further with respect to the categories of query intent, with the emphasis on the commercial intent. It is shown that clickthrough behavior is consistent with the query in-tent identified through classification. Information obtained from implicit feedback resources, such as user query logs [24] have been widely used to interpret and predict user Web search behavior and preferences [1, 17, 23, 29], which may be extended to study query intent. Queries are often short, and therefore a query by itself may not reveal much about the user [9]. Implicit feedback can en-hance the information obtained from queries. Lee et al. [20] predict user query goals in terms of navigational and in-formational intent, based on past user-click behavior and anchor-link distribution. Rose and Levinson [26] conducted a study, developing a hierarchy of query goals with three top-level categories: informational, navigational and resource. Under their taxonomy, a transactional query as defined by Broder [7] might fall under either of their three categories, depending on details of the desired transaction. In [4], Baeza-Yates et al. establish three categories from the content of the queries for goals which motivate a user to make a search: in-formational, non-informational, and ambiguous. They de-velop models applying supervised and unsupervised learning techniques for query identification purpose. Semi-supervised and supervised learning techniques [5, 21, 22, 28] have been applied over different data resources in order to address query intent classification.

Most of the above work focuses on query intent with re-spect to the traditional navigational, informational, and trans-actional categories of Broder [7]. More recently, there has been growing interest in commercial intent classification. In this regard, Dai et al. [12] propose a commercial query detec-tor. They train machine learning models from search result pages and the contents of the top ranking pages. In Ashkan et al. [2], machine learning classifiers are trained based on two settings: i) the ad clickthrough features are combined with the query and SERP features (obtained from the con-tent of search engine result pages), and ii) the combination of query and SERP features are used while no ad click-through features are involved. The classifiers are used to automatically identify the intention underlying user entered queries in two dimensions: commercial/ noncommercial and navigational/ informational. In this work, the latter set-ting of the features is used in order to avoid any possible distortion the ad clickthrough features could create in ad clickthrough analysis. The commercial category of intent is further studied in terms of the specificity of products, re-tailers, and brands. Jansen [16] points out the nature of commercial queries by considering five categories: intent to buy, product specific, location specific, company specific, and general. It has been shown that most of the queries fall into the product specific category, while a very small per-centage focuses on companies and location. Finally, Ghose et al. [15] study sponsored search at a keyword level. Their results indicate that while retailer specific ads (based on navigational queries) increase clickthrough rates, brand spe-cific ads (based on transactional queries) decrease the click-through rate. With respect to the context of sponsored search in this pa-per, we consider inferring commercial intent as an obvious candidate. A commercial query is defined as a query with an underlying intention to make an immediate or future pur-chase of a specific product or service, while anything else falls into the noncommercial category. The ontology is also expanded by considering subcategories of commercial intent which are defined to be product , retailer , and brand . The main idea is to study whether a specific  X  X roduct X ,  X  X etailer X , or  X  X rand X  is included in a commercial query or implied by the query. It is noted that we avoid the more traditional topical categories, such as  X  X port X  and  X  X ews X .

Furthermore, the standard categories of Web queries iden-tified by Broder [7] are studied in this paper, however we subsume transactional queries under one of the two cate-gories of either navigational or informational , as appropri-ate. A navigational query is defined as a query with the underlying intention to locate a specific Website, while an informational query is everything else.

Our assumption is that the result pages returned for a query can be considered as representatives of the nature of a query. For instance, if a query like  X  X heap shoes X  is en-tered by the user, the appearance of keywords like  X  X uy X ,  X  X ree X , and  X  X hipping X  may be good representatives of the commercial nature of such a query. Furthermore, features extracted from the query itself (e.g. the number of char-acters and words in the query string) are considered to be helpful in understanding the intention underlying the query. Therefore the two types of features used in this work are as follows: i) the content of search engine result pages (SERPs), and ii) query based features. In this regard, we build auto-matic classifiers in order to determine the intention under-lying user entered queries in different dimensions. Descrip-tions of the feature sets are presented in Table 1. The experimental study conducted in this paper is based on a data set obtained from Microsoft adCenter consisting of search and click logs sampled over three months. Personally identifying information was removed from this set. The data includes a sample of roughly 100 million search impressions, where an impression is defined as a single search result page. There is also a set of ad clicks associated with the impression data. Queries are assumed to be in the English language. We removed any extra space at the beginning and the end of the queries, and between words of the queries for both impression and clickthrough files. We then case-normalized the queries. Impressions with a duplicate combination of impression id and user session id were removed in order to filter out repeated queries from the same user.

In order to prevent train-test contamination, we randomly split the impression and clickthrough data into three equal-sized sets (i.e. set A, set B, and set C) at the query level. We use set A to train classifiers for query intent detection; we use set B to study the characteristics of different categories of query intent; we use set C to estimate the distributions of ads on different locations of the result pages. All three sets contain approximately the same number of queries (about 800K) along with their impression and clickthrough infor-mation. There are many queries with very small number of ad clicks. Similar to Richardson et al. [25], since our analysis deals with empirical ad clickthrough of queries, it may be wildly different from the true clickthrough rate for queries with few number of ads, leading to noise in the analysis. Hence, we filtered the sets to include only the queries that have at least four ad clicks. After filtering, we ended up with 45032, 44941 and 44909 queries in sets A, B, and C respectively (134882 queries in total). In this section, we build query intent classifiers on our data set in different dimensions and with respect to the feature sets explained before. First, the process of annotating a set of queries, selected from the training data ( set A ), is ad-dressed so the set would be used to train the classifiers. As discussed in previous work [2], we manually labeled a set of 1700 Web queries with respect to their two major dimensions of intent. Those queries were labeled by three researchers from our group. A Web application was developed for an-notation purposes so that each annotator was able to login to the system and view one query at a time along with the result page returned for that query. The annotators were responsible for judging the presumed intent of the queries from the perspective of a general user, requiring consider-able time and effort. For this work we aimed to increase our set of labeled queries relatively easily, cheaply, and reliably. For this purpose, we employed Amazon Mechanical Turk.
According to Amazon,  X  X echanical Turk is based on the idea that there are still tasks that human beings can do much more effectively than computers, such as identifying objects in a photo or video, transcribing audio recordings X , or in our case manually labeling queries. Amazon calls these tasks HITs (human intelligence tasks). A HIT represents a single, self-contained task that a so-called worker can work on, submit an answer, and collect a reward for completing. In order to train and evaluate our classifiers, 3000 extra queries among the 45K queries in set A were selected in order to be manually labeled along the two major dimen-sions of query intent. The original impression file was sorted based on the time of the impression. Starting from an ar-bitrary point in the file (approximately 1 / 5 of the length of the file from the beginning), 3000 queries were selected for which the query was contained in the set A and it was not among the previously labeled 1700 queries. This selection approach was used in order to pick 3000 queries from a con-tinuous period of time in set A. We refer to this set as the MT set (Mechanical Turk set). We also randomly selected 1000 queries of the previously manually labeled queries as a seed set in order to be used to validate the results obtained from the experiment with Mechanical Turk. Consequently, we ended up with 4000 queries for labeling and eventually for training the classifier. The entire set of selected queries (i.e. 4000 queries) were then divided into 40 batches of 100 queries, with each batch containing 25 seed queries and 75 MT queries. These batches were submitted to Mechanical Turk, each as a single HIT, in order to be labeled according to instructions that we provided for the workers. They were asked to judge the presumed intent of the search queries from the perspective of a general user as follows: For each batch labeled and submitted by a worker, we com-pared the labels assigned to the seed queries of the batch with the actual labels of those queries (previously deter-mined by our three local annotators). If the agreement of the worker with our annotators was found to be above 60% (a threshold above the random case), the labels assigned by this worker were accepted. Otherwise, the labels were re-jected and the same batch of queries were submitted for an extra round of labeling by a different worker. If the agree-ment was found to be above 75%, we awarded a bonus to the worker. We continued this process until we had all batches successfully labeled by five different workers. The final la-bel of each query has been assigned based on the majority of the labels obtained for the query. At the end, 42% of queries were labeled as commercial and 58% were labeled as noncommercial , while 55% of queries were labeled as navi-gational and 45% were labeled as informational .

The same process was repeated in order to obtain labeled queries for the specific subcategories of the commercial in-tent. A set of 510 manually labeled commercial queries were labeled by the same three annotators separately in each sub-margins of Kappa and the mean Fleiss X  Kappa for each dimension Table 2: Percentage of HITs falling in different agreement levels for different dimensions of intent Commercial/ Noncommercial 59.1% 25.8% 15.1% Navigational/ Informational 57.4% 28.9% 13.7% Product Specific/ Generic 32.3% 33.7% 34% Retailer Specific/ Generic 35.4% 38% 26.6%
Brand Specific/ Generic 42.3% 34.3% 23.4% category. This set was considered as the seed set , while a set of 1500 queries, which all came up as commercial queries from the previous process, was considered as MT set . 15 batches of 134 queries were created with each batch con-taining 34 seed queries and 100 MT queries. These batches were submitted to Mechanical Turk, each as a single HIT, in three rounds (each round corresponding to one of the three subcategories of commercial intent: product, retailer, and brand). The workers were asked to judge the presumed in-tent of the search queries from the perspective of a general user as follows: The same strategy for accepting (with/without bonus) or rejecting the HITs were used, and the final label of each query has been assigned based on the majority of the labels obtained for the query in each category. For each dimension of query intent, the queries of a HIT have to be labeled by five different workers and into two categories. Hence, there are three possible states of agree-ment level for each query in a HIT: i) all five workers agree (i.e. 5-0), ii) four agree on one category and one on the other (i.e. 4-1), and iii) three agree on one of the categories and the other two agree on the other category (i.e. 3-2). The result of labeling through Mechanical Turk is reported in Table 2 in terms of percentages corresponding to each of these agreement levels for each dimension of query intent. As it can be seen, workers have high agreement on the cat-egories of queries in the two general dimensions (i.e. com-mercial/ noncommercial and navigational/ informational). There are 59% and 57% reported for the two general dimen-sions where there is full agreement among the workers. Only 15.1% and 13.7% of the queries ended up with low agreement (3-2) among the workers.
 In addition to considering a number of queries from the seed set in order to qualify the result of a HIT for acceptance, we have also selected Cohen X  X  Kappa [10] as measure of agree-ment among the workers who labeled the submitted queries. Kappa is considered as the proportion of agreement cor-rected for chance, and is scaled to vary from -1 to +1 so that a negative value indicates a poorer than chance agree-ment, zero indicates exactly chance agreement, and a posi-tive value indicates better than chance agreement. A value of unity indicates perfect agreement. The use of kappa im-plicitly assumes that all disagreements are equally serious. Cohen X  X  kappa measures the agreement between two anno-tators while each classifies a number of items into a number of mutually exclusive categories.

In our case, where multiple annotators (i.e. workers) label the queries, Fleiss X  kappa [14] is used. Fleiss X  kappa works for a number of annotators, each giving categorical labels to the entire set of a fixed number of items. However, in our case the entire set of queries are broken into smaller batches in order to be submitted as reasonable-size HITs to the sys-tem. Hence, in each dimension of query intent, we measured Fleiss X  Kappa for every submitted HIT which were labeled in that dimension and by five independent workers. The final Kappa value for the entire set and in regards to a par-ticular query intent dimension is calculated as the mean of Fleiss X  Kappa for the batches in that dimension. The mean Kappa for each dimension is reported in Table 3. Moreover, the number of batches falling in different margins of Kappa as defined by Landis and Koch [19] is also presented in Ta-ble 3. Landis and Koch [19] give six levels of interpretation for Kappa value as poor agreement , slight agreement , fair agreement , moderate agreement , substantial agreement , and perfect agreement . We put each batch of queries (HIT) into one of these agreement levels according to the value of Fleiss X  Kappa calculated for the HIT. The results for 40 HITs of the two general dimensions and 15 HITs of the specific subcate-gories are shown in Table 3. As it can be seen in the Table, in the two general dimensions most of the HITs ended up with substantial agreement while for the three specific sub-categories most have moderate or fair agreement. As a result of this observation, while it will be pointed out later in the paper, we will use the queries, that have the agreement level of either 5-0 or 4-1 among their annotators, as our training queries for the classifiers in the specific subcategories. At the point that a set of 4000 queries were labeled in com-mercial/ noncommercial and navigational/ informational di-mensions, the query and SERP features are extracted for the entire set in order to be fed to SVM classifiers for the train-ing purpose in each dimension. The query specific features have been extracted from the query strings and also from queries based on different agreement levels among the annotators Table 4: Prediction accuracy for Commercial/ Non-commercial classifier and Navigational/ Informa-tional classifier the content of search engine result pages returned for them. We submitted each query to the Live search engine downloaded the first search engine result page (SERP) for that query. Each SERP is then represented as an unordered multi-set of term frequency ratios. (a  X  X ag of words X ). Note that the terms were extracted from the organic results only. Ads were removed, to avoid any possible bias that ad key-words might produce in the classification. Two SVM binary classifiers are then trained with respect to the extracted fea-tures, one of which is trained based on the commercial/ non-commercial labels and the other one is trained based on the navigational/ informational labels. The SVM-light pack-age [27] is used, where 10-fold cross validation is used to measure the accuracy of each classifier. A report of the pre-diction accuracy for the classifiers is presented in Table 4. Finally, the trained classifiers have been used to predict the intention underlying the 45,032 queries in set B in both di-mensions: i) whether each query is either mostly commer-cial or mostly noncommercial, and ii) whether each query is either mostly navigational or mostly informational. The queries of set B and the intents underlying them is the target of further analysis in the remainder of paper. A total of 2010 queries from the entire set of queries (1700 previously labeled and the 3000 new queries) were labeled as commercial. Hence, it is assumed that the general intent of each query among the set of 2010 is likely to be com-mercial. That is, the presumed purpose of the query is to make an immediate or future purchase of a product or ser-vice. As mentioned previously, these queries were further labeled in three dimensions: product, retailer, and brand. For instance,  X  X almart X  is considered as broad category of products, unknown brand, and retailer specific, while  X  X ar X  is considered as product specific, unknown brand and un-known retailer. As another example, X  X nited Airlines ticket X  is assumed to be product specific and brand specific, how-ever it has an unknown retailer since a United Airlines ticket can be purchased from different travel services. www.live.com (now www.bing.com)
The set of 2010 labeled queries along with the features extracted for them (similar to the previous case) were used as our training set in order to train three SVM binary classi-fiers, each of them corresponding to one of the three subcat-egories of commercial intent. After training the classifiers based on the combined feature sets, the prediction accuracy was calculated for each classifier using the 10-fold cross val-idation. The performance measures for the three classifiers are presented in the first part of Table 5.

As pointed out previously, the levels of agreement for the queries labeled into the three specific subcategories were not found to be as strong as the ones in the two major cat-egories (commercial/ noncommercial and navigational/ in-formational). Hence, we trained each of the three binary classifiers in specific category with respect to three different subsets of the 2010 labeled queries: i) the entire set in which the queries had the agreement of 5-0, 4-1, or 3-2 on the labels assigned to them, ii) a subset of queries in which there was an agreement of 5-0 or 4-1 on the labels assigned to them, and iii) a subset of queries in which all annotator agreed on the assigned labels (an agreement of 5-0 only). The perfor-mance measures for each setting along the three classifiers are presented in Table 5. In order to have a balance be-tween the accuracy and size of the training set we picked the second setting (labeled queries with the agreement level of either 5-0 or 4-1) as our main training set in order to train the three binary classifiers in the three specific subcat-egories of commercial intent. Finally, all the queries of set B , that were labeled as commercial by the aforementioned commercial classifier (about 19K queries), have been fed to these three trained classifiers separately in order to catego-rize each query into the three dimensions of the commercial intent. It is assumed the number of displayed ads and their place-ment on a result page and the intents behind the correspond-ing query can influence the clickthrough rate (CTR) for the result page. We start by examining the average number of clicks per impression for queries with a particular number of ads from set B. First, impressions are sorted according to the number of ads displayed for each. The number of ads in the impression file varies from one to eight. Thus, impres-sions are divided into eight groups, each denoted as set A where i is the number of displayed ads for the impressions in that set. The value | A i | indicates the number of impressions with i ads displayed. We use the unique id number for each impression (impression id) to determine whether it resulted in an ad click. Repeating this process for all impressions in the eight groups, we can calculate the total number of ad clicks for each. Figure 1: Average CTR for impressions with partic-ular number of ads Let a j i  X  A i denote the unique impression id for the j impression in A i . We define c j i to represent whether there was an ad click resulting from such an impression. In other words, c j i = 1, if there is an ad click associated with a clickthrough data, and c j i = 0 otherwise. Hence, the average number of ad clicks per impression CT R i , for queries with a particular number of ads i , is obtained as follows: We calculated the average clickthrough rate (CTR) for the eight ad-based groups of set B, resulting in the plot depicted in Figure 1. For clarity of presentation, the points for each particular number of ads are connected. The lines do not imply interpolation. Generally speaking, the more ads dis-played, the more clicks they receive. This observation could indicate that the number of ads (in part) determines the number of ad clicks. The dip at rank 5 will be explained shortly. Figure 2 shows the same CTR trend when the rank of the clicked ads is also considered. Note that ad clicks mostly occur at the first and the second ranks, and most especially at the first rank. This observation confirms that clickthrough rate of ads significantly decreases as they are displayed in lower ranks on the page, as a result of reduced visual attention [25]. In addition to the rank of ads, their location (top or side of a result page) could also affect clickthrough rates. Our logs do not record the locations of ads, while only the ranks of clicked ads along with the total number of displayed ads are available. However, a single ad at rank 1 for instance, may appear either on the top or at the side. According to Jansen [16], top-listed ads are assumed to be more relevant than organic results and side-listed ads. This could affect the frequency of clicks for ads at different locations. In this regard, we hypothesize that peaks and valleys in the two plots (Figures 1 and 2) could result from the location of different ads for which the clicks are recorded.

Previously we proposed a probabilistic model in order to derive the locations of ads and study their impact on click-through [3]. In that model, the analysis was simplified using an assumption indicating that clicking on a top ad is in-dependent of the number of ads displayed at the side of a result page. Therefore, the analysis resulted in a few click-through rate values (corresponding to different ranks and locations) to be estimated as negative numbers that were Figure 2: Average CTR at specific ranks for impres-sions with particular number of ads Table 6: Percentage of SERPs with particular num-ber of ads on the top and at the side from the results obtained through an experiment on 43K queries treated as zero. However, in this work, a probabilistic model is presented for the placements of ads on different locations (top/ side) of a result page where no such assumption is re-quired in order to simplify the analysis. As explained later, the clickthrough values for different locations are estimated by solving an optimization problem.

As mentioned before, the total number of displayed ads varies from 1 to 8. A batch of approximately 43,000 queries, randomly selected from sets A, B, and C, was submitted to the Live search engine in order to study different possibili-ties in terms of the number of ads and their locations on the search engine result pages (SERPs, and also known as im-pressions). The results are shown in Table 6 in percentage form. According to this experiment, the maximum number of ads displayed at the right side of a search result page is 5, and the maximum number of ads displayed on top of a result page is 3. It is also assumed the rank of ads are assigned in a way that the ads displayed on top (if any) are ranked higher than the ones displayed at the side. As an example, if a and a t 2 are two ads displayed on top of the page as the first ad and the second ad respectively, while a s 1 is displayed at the side, the rank order of these three ads with respect to the page is considered as follows: a t 1 , a t 2 , and a s
Let R be a random variable characterizing the distribution of possible ranks of the ads at which clicks occur, and N represents the total number of ads displayed on a result page. The average clickthrough rate for result pages, in which a total of N = n ads are displayed and the ad at rank R = r is clicked, can be denoted as P ( R = r | N = n ). Let T and S be the number of displayed ads on the top and at the side of a result page respectively, hence N = T + S . For a result page with T = t ads displayed on the top and S = s ads displayed at the side, summation of the likelihood of no click (i.e. P ( R = 0 | T = t, S = s ) = 0) and the likelihood of click on any ad at rank r (i.e. P ( R = r | T = t, S = s )) where n = t + s and 1  X  r  X  n is obviously 1. In other words, the following equation holds: where P ( T = t, S = s ) refers to each cell in Table 6 and represents the likelihood of SERPs with T = t ads on the top and S = s ads at the side. P ( R, S, T ) is defined over R  X  { 0 , ..., n } , n = t + s , 0  X  t  X  3, 0  X  s  X  5, and it is described as the likelihood of a SERP resulting in click at rank r while t and s ads are displayed on the top and at the side of SERP respectively. Note r = 0 means no ad click.
Our main objective is to estimate the average clickthrough rate at rank r for varying number of ads at different locations on a SERP. This can be seen as the conditional probability P ( R = r | T = t, S = s ) which can be written based on P ( R, S, T ) as follows: Hence, in order to calculate P ( R = r | T = t, S = s ) in Equa-tion 3 for all values of s and t , P ( R, S, T ) has to be first solved for all possible values of s and t . This probability distribution is produced from user interaction (i.e. click at r  X  1 or no click) with various states of a result page. In or-der to cope with various possibilities caused by the dynamic nature of human interaction, a solution with maximum ran-domness looks promising. Therefore, entropy [11], as a mea-sure of randomness and uncertainty, can be maximized in order to obtain a stable state of the system as an answer for P ( R, S, T ). Hence the following optimization problem is defined in order to maximize the entropy, H ( P ( R, S, T )): maximize H(P(R, S, T)) subject to: where r  X  X  0 , ..., n } , n = t + s , 0  X  t  X  3, and 0  X  s  X  5. In the first line of the constraints, P ( N = n ) can be calculated by the summation of the corresponding probabilities from Table 6 (e.g. P ( N = 1) = P ( T = 0 , S = 1) + P ( T = 1 , S = 0)). Moreover, P ( R = r | N = n ) for all possible values of n (i.e. 1  X  n  X  8) can be estimated through Figure 2, which represents the average clickthrough rate at different ranks for varying number of ads.

All in all, by solving the optimization problem, P ( R = r | T = t, S = s ) can be obtained for different values of r , t , and s , and therefore P ( R = r | S = s, T = 0) can be cal-culated by substituting t = 0 in Equation 3. Consequently P ( R = r | T = t ) can be estimated as follows:
P ( R = r | T = t ) = Figure 3: Adjusted plots for average CTR for impressions with a particular number of ads on top/ side of the page where P ( S = s | T = t ) is the probability of appearance of S = s ads at the side of a result page conditioned on the number of top ads, t , displayed on the result page. It is noted that each cell in Table 6 represents the likelihood of SERPs with T = t ads on the top and S = s ads at the side (i.e. P ( T = t, S = s )). Also the summation of the cells in a column represents the likelihood of SERPs with T = t ads on the top (i.e. P ( T = t ). Thus, the aforementioned conditional probability can be calculated from Table 6 as follows: We refer to the estimated values obtained for P ( R = r | S = s, T = 0) and P ( R = r | T = t ) as the adjusted values at rank r . We calculated these values for the queries in set B. The ones corresponding to the clickthrough rate at rank 1, 2, 3, and 4 at different locations are plotted in Figure 3 in percentage form. The rates for other ranks (5 to 8) are not presented in the figure, as they are close to zero.
The trend of changes in the adjusted values can be used to explain the dips in Figures 1 and 2. According to Figure 3, the lowest estimated value at each rank is for the case where there are 5 ads displayed at the side while no ad appears on the top. This can be viewed as a reason for the dip at 5 in Figures 1 and 2. As can be observed in the figure, the more ads displayed on the top, the more clicks they would receive ( T = 1, T = 2, T = 3). At each rank, comparing the values for top ads (the first three on the corresponding plot) and the ones with no top ads (the last five on the corresponding plot), it is observed that ads on the top of a result page are more often the targets of clicks than the ads at the side. This observation will be further investigated when the intent underlying the query displayed on a result page is taken into consideration as well. Having the apparent intention underlying each query deter-mined, we follow a similar approach to that of Equation 1, calculating the average clickthrough rate for all the impres-sions with a particular number of ads. However, this time, we consider only the impressions for which the associated queries fall into a given class. The average clickthrough rate Figure 4: CTR for impressions with particular num-ber of ads and associated with various query types for the four possible combinations of major query classes in pairs (i.e. commercial-navigational, commercial-informa-tional, noncommercial-navigational, and noncommercial-informational) against the number of ads are plotted in Fig-ure 4. The plot from Figure 1 is also placed in Figure 4 in order to provide a baseline for comparison. Note that the plots indicate the average clickthrough rate for impres-sions with a particular number of ads and associated with particular classes of query intent.

It can be seen in Figure 4 that ad clickthrough behavior is distinct for different categories of query intent, and this can indicate that the clickthrough behavior is consistent with the classification results of the general categories of query intent. Generally speaking, categories that involve commer-cial intent are the leaders among the others (plots related to commercial-navigational and commercial-informational cat-egories). This will confirm that commercial category of queries receive more ad clicks comparing to the others. It can also be seen that commercial-navigational queries re-ceive more ad clicks than commercial-informational queries, on average. In other words, the ads that reflect the intent of commercial-navigational queries seem to be more of a target of clicks than the ones that reflect the intent of commercial-informational queries. An example for illustrating the dif-ference is  X  X merican airlines X  as a commercial-navigational query against  X  X irline tickets X  as a commercial-informational query. The chance that user would find a related ad for the former query is greater than the latter, because the former query is restricted by the airline name.

In order to study the impact of ad location on clickthrough for commercial intent, the adjusted plots for commercial, commercial-navigational, and commercial-informational cat-egories along with the case with no query intent are depicted in Figure 5. Note that the summation of estimated click at different ranks (from 1 to 8) is plotted for each category of intents in order to represent the total clickthrough at each point. For all the plots, the dip at the point where no ads are displayed on the top and five ads are displayed at the side ( S = 5, T = 0) represents that for this place-ment of the ads, there is not that much clickthrough from the users, which can explain the dip at five in the corre-sponding plots of Figure 4. The placement of ads appears to have a substantial impact on the number of clicks they receive along different intents. Similar to Figure 4, consid-ering the navigational aspect of a commercial query versus the informational aspect of a commercial query appears to Figure 5: Adjusted plots for average CTR for im-pressions corresponding to different query intents and with a particular number of ads on top/ side of the page have substantial value in clickthrough rate. It can be seen that commercial-navigational queries tend to result in rela-tively significant clickthrough on the ads placed at different locations of the result pages comparing to the commercial-informational queries. It may be easier to place ads for navigational queries than informational queries. This can be further studied so that analyzing the commercial intent from the navigational/informational point of view would be used towards inferring the placement of ads on result pages.
It is also noted that for all categories the more ads dis-played on the top, the more clicks they would receive ( T = 1, T = 2, T = 3), however the difference between the click-through of top ads and side ads becomes lower when it comes to the leader query categories (i.e. commercial-navigational and commercial). One could say when the intent underlying the user X  X  query is commercial, the effect of location of ads becomes less significant, however the ads on the top are still the main targets of the click.

The average clickthrough rate for each subcategory of commercial intent is also depicted in Figure 6. Among the three subcategories, only for the retailer category, when a specific retailer is implied by the query intent, the number of clicks for varying number of ads is always higher compar-ing to the case where the retailer in unknown. For the other two, at some points, the ratio of clicks for generic product and unknown brand is higher than for specific product and specific brand respectively. One could say ads are placed in a way that the ones that reflect retailer intent are more of a target of clicks than the others. On the other hand, for the brand category, where the brand name is specified, the ratio of ad clicks is insignificant comparing to the case that the brand name is unknown in the query. We would explain this observation according to the findings of Ghose et al. in [15]. Searches on specific brand names could in-dicate that the user needs a commercial product or service, but doesn X  X  yet know where to buy it from. This makes such queries to provide competitive situations in search. If an ad wins the click and the order, that implies such an ad has taken market share away from a competitor, resulting in an increase in the conversion rate not in the click rate. cial intent and with a particular number of ads on top/ side of the page Finally the adjusted plots for the impact of location of ads on the specific commercial subcategories are depicted in Fig-ure 7. Apart from the brand category, the clickthrough be-havior on the ads at different locations for the other two cat-egories could indicate that ads might have not been placed appropriately with respect to the specific subcategories of commercial intent. Generally speaking, the specific com-mercial subcategories show less distinct behavior in terms of their ad clickthrough (Figures 7 and 6) comparing to the other two general dimensions (commercial/ noncommercial and navigational/ informational from Figures 4 and 5). The consistency of clickthrough analysis with the classification results is found to be significantly true for the general com-mercial split of the queries, while all is true for the specific subcategories to a lesser extent. This work presents an initial step towards a long-term goal of extending the traditional categories of Web queries by devel-oping and evaluating the seeds of an ontology for commercial search. This first step considers queries that reference spe-cific products, brands and retailers, avoiding the more tra-ditional topical categories, such as sport and news. These categories are derived from a manual examination of query logs and are validated through a consistent labeling obtained through Mechanical Turk, where reasonable agreements are obtained among the annotators along the different dimen-sions of query categories. Moreover, the accuracies obtained from the trained query classifiers confirm that distinctions among these categories are reasonably distinguishable. In this regard, query based features along with the content of SERPs, are found to be effective in detecting query intent.
The characteristics of different query categories are then studied with respect to clickthrough behavior on advertis-ing links. In this regard, a model for clickthrough behavior is presented that considers the influence of such factors as the location of ads and the rank of ads, along with query category. In general, the placement of ads appears to have a substantial impact on the number of clicks they receive. This impact is more obvious when the intent underlying the queries, for which those ads are displayed, is also taken into account. In other words, analyzing query intent is helpful in inferring the placement of ads on result pages. This obser-vation is particularly true for the general commercial split of the queries, and it also holds for the specific subcate-gories of commercial intent to a lesser extent. In particular, considering the navigational aspect of a commercial query versus the informational aspect of a commercial query ap-pears to have substantial value. It has been shown that commercial-navigational queries tend to result in relatively significant clickthrough on the ads placed at different lo-cations of the result pages comparing to the commercial-informational queries.

Our findings in a sense have implications on issues re-lated to advertising and search engine optimization. The in-tent based analysis of queries may help advertisers to adjust and improve the quality of their ads by picking appropriate keywords. Moreover, our intent-based clickthrough analysis suggests that the placement of ads (i.e. rank, location, etc) on a result page impacts the clickthrough behavior of the users for which such ads are displayed. Therefore, such a placement can be adjusted with respect to the intents un-derlying user X  X  queries and to the expected number of clicks that different ads would receive in different locations in or-der to maximize the revenue. Investigating this issue is a direction for future work. We would like to thank Microsoft Research and Microsoft adCenter for providing the Beyond Search data and for sup-porting this work through the Beyond Search RFP. [1] E. Agichtein, E. Brill, S. Dumais, and R. Ragno. [2] A. Ashkan, C. Clarke, E. Agichtein, and Q. Guo. [3] A. Ashkan, C. Clarke, E. Agichtein, and Q. Guo. [4] R. Baeza-Yates, L. Calder  X an-Benavides, and [5] S. Beitzel, E. Jensen, O. Frieder, D. Grossman, [6] R. Briggs and N. Hollis. Advertising on the Web: Is [7] A. Broder. A taxonomy of Web search. ACM SIGIR [8] A. Broder, M. Ciaramita, M. Fontoura, [9] A. Broder, M. Fontoura, E. Gabrilovich, A. Joshi, [10] J. Cohen. A coefficient of agreement for nominal [11] T. Cover and J. Thomas. Elements of information [12] H. Dai, L. Zhao, Z. Nie, J. Wen, L. Wang, and Y. Li. [13] K. Debmbsczynski, W. Kotlowski, and D. Weiss. [14] J. Fleiss and J. Cohen. The equivalence of weighted [15] A. Ghose and S. Yang. An empirical analysis of [16] B. Jansen. The comparative effectiveness of sponsored [17] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and [18] A. Lacerda, M. Cristo, M. Gon  X calves, W. Fan, [19] J. Landis and G. Koch. The measurement of observer [20] U. Lee, Z. Liu, and J. Cho. Automatic identification of [21] X. Li, Y. Wang, and A. Acero. Learning query intent [22] D. Nettleton, L. Calder  X an-Benavides, and [23] B. Poblete and R. Baeza-Yates. Query-sets: using [24] M. Richardson. Learning about the world through [25] M. Richardson, E. Dominowska, and R. Ragno.
 [26] D. Rose and D. Levinson. Understanding user goals in [27] T. Joachims, SVMlight support vector machine, 2008. [28] B. Tan and F. Peng. Unsupervised query segmentation [29] J. Teevan, S. Dumais, and D. Liebling. To personalize
