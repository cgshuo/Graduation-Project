 In recent years, document composition as well as text-based communication have rapidly increased. According to Internet World Stats , 1 30.4% of the world population has used the Internet in the year 2011. The number of world-wide email accounts is ex-pected to increase from 3.1 billion in 2011 to nearly 4.1 billion by year-end 2015 [Group 2011]. This represents an average annual growth rate of 7% over the next four years. In 2011, each corporate email user (representing 25% of world-wide mailboxes) sends and receives about 105 email messages per day [Group 2011]. These statistics reveal that text composition is becoming popular. So far as text entry is concerned, the text compo-sition rate in English with personal electronic gadgets is very low (12 X 22 wpm with a soft keyboard [Go and Endo 2008; MacKenzie et al. 1999; Oulasvirta et al. 2013; Trnka et al. 2009], and 35 X 40 wpm with a hardware QWERTY keyboard [Isokoski 2004]).
In the context of Indian languages, the text entry rate on average is 25 wpm [Joshi et al. 2004] with a QWERTY-mapped hardware keyboard. The composition of text in Indian languages has several issues. It contains a large number of alphabets,  X  matra  X ,  X  halant  X , and complex characters ( X  X uktakshar X ) etc. [Koul 2008; Mohanan 1994]. So, typing in an Indian language with a conventional QWERTY keyboard is not an easy task, as significant training is required to compose the text [Joshi et al. 2004]. As an alternative to a hardware QWERTY keyboard, researchers introduced a virtual keyboard. A virtual keyboard is an onscreen graphical display where keys are spa-tially arranged and can be tapped with finger tip or mouse pointer. Typically, virtual keyboard-based text entry systems result in a lower text entry rate than a hardware keyboard [Trnka et al. 2009]. In particular, it becomes a major issue in the context of Indian languages, where the text entry rate through a virtual keyboard is typically 3 X 5 wpm [Samanta et al. 2013; Sarcar et al. 2010]. As a way out, the virtual the key-board needs to be supported with a text entry rate enhancement strategy such as word prediction.

Word prediction enables a user to enter text without completely typing the required word and thus saves a number of keystrokes. In other words, a word prediction system predicts an intended word that a user is in the process of entering or going to type. While a user types text, the prediction system monitors the input letter-by-letter and produces a list of texts beginning with context. Each time a letter is added or deleted, the list of predicted words gets updated. When the target word appears in the list (prediction window), it can be chosen and inserted into the text under composition.
Performance of a text prediction system depends on many factors such as dictio-nary size, language characteristic, size and position of prediction window, block of text to be predicted, search strategy, prediction method, etc. [Garay-Vitoria and Abascal 2006; Herold 2004; Sharma et al. 2010]. Apart from this, it is also observed that word prediction systems provide spelling assistance to a user. Herold [2004] has reported that with spelling support offered by word prediction, writing text character by char-acter is replaced by selecting the word instead of forming it. The system facilitates a user to identify and select a word of his interest from the prediction window so that he can avoid a spelling error in advance [Klund and Novak 1995]. In other words, word prediction helps users to correct errors as they occur by realizing that the pre-dicted words do not look like the word they require. Then the user will experiment with other possibilities (like manipulating the character entered so far until the en-tered word looks right. Study also reveals that the system recognizes the word and eliminates the need to spell it completely when the user can correctly enter the first few characters of the word [Zordell 1990]. People with physical disabilities and users with severe spelling problems whose errors cannot be corrected by a spell checker can also get assistance from the word prediction system [MacArthur et al. 1996]. So far as the existing word prediction technique is concerned it has a limitation: the user must correctly spell the beginning of the word without any phonetic substitution [MacArthur 1998; Herold et al. 2008; Zordell 1990]. Please note that, while composing text, spelling errors can occur due to several reasons such as a motor-coordination slip, similarity between character(s), spelling knowledge, dyslexia, and organization of keys in layout.

The Hindi language, which follows Devanagari script, 2 contains a large set of char-acters (13 vowels, 33 consonants, 12 matras, and special symbols like anusvara, vis-arga, chandra bindu, and nukta, etc.) [Consortium 2009; Gupta and Jamal 2006] along with complex characters called  X  X onjuncts X  (character composed with two or more characters and  X  X alant X ) [MacKenzie and Tanaka-Ishii 2007]. Further, there are some graphically and phonetically similar characters, which increases the finite chance of confusion when selecting the proper character and occasionally leads toward tapping wrong characters. Also, Hindi is an inflected language (which requires a large lexi-con for prediction) with an average word length of 4.69 compared to 5.1 in English [Bharati et al. 2002]. A large number of entries in a lexicon with the lower average word length affects the performance of a word prediction system [Wandmacher 2009]. These complexities make the text composition task error-prone as a consequence yielding a poor text entry rate. Therefore, there is a need to develop a user friendly word prediction system that detects and corrects spelling errors while composing text and achieves a better text entry rate with acceptable accuracy.
In this article, we propose a word prediction system with error detection and correc-tion mechanism augmented with virtual keyboard to enhance the text composition rate in Hindi. We consider Hindi, national language of India, in our proposed word predic-tion system (295 million users speak in this language 4 ) also, it is the fourth language in the ranking of the languages in the world.

The rest of the paper is organized as follows. In Section 2, we review the principles of existing word prediction mechanisms. The issues and challenges for developing a pre-dictive virtual keyboard in Indian languages are discussed in Section 3. In Section 4, we describe our proposed approach to develop the word prediction system for text entry in Hindi. We have done several experiments to judge the performance of our proposed approach. Our experimental results are presented in Section 5. A comparison of the existing Hindi word prediction systems with our work is done in Section 6. Finally, Section 7 contains discussion and Section 8 concludes the article. In recent literature, a number of text prediction methodologies [Fazly 2002; Garay-Vitoria and Abascal 2006] have been reported. All of these text prediction methodolo-gies can be broadly classified into two categories: statistical and syntactical predictions [Fazly 2002]. In this section, we briefly discuss the principles of these methods. We also discuss the scope of applicability of these methods in the context of Indian languages.
Statistical predictor. Language information is the supportive source for the most of the existing word prediction systems. The language information used in statistical pre-diction systems are mostly n-gram language models [Boissiere 2003; Levinson 1985; NCIP 1994]. In these prediction methods, a list of predicted words can be generated based on the frequency of a word and/or the recency-of-use (last recently used) [Trnka et al. 2009; Vanderheiden and Kelso 1987]. Most of the word prediction systems in the early 1980s used word frequency information [Fazly 2002], that is, a word unigram model for predicting words. These prediction methods ignore all previous contexts en-tered by the user and use only word frequency information for prediction. Another strategy is based on the observation that if a word has been used recently, then that word would be needed soon. Hence, the last recently used technique has been found to improve the result [Fazly 2002; Garay-Vitoria and Abascal 2006; Higginbotham 1992].
In order to improve the accuracy of a prediction method, a larger context entered by a user, and word sequence information such as word bigram or trigram models [Fazly 2002], are considered. The word pair X  X  bigram and trigram are computed from a corpus in order to predict the most probable word, knowing the previous context. The bigram prediction method predicts the current word based on the last word; it is repre-sented as P ( w i | w i  X  1 ) , where w i is the current word and w in the trigram prediction method, the last two words are taken as a context for pre-dicting the next word; it is given by P ( w i | w i  X  1 , w and w i  X  1 and w i  X  2 are the last two words. Trigram models are generally established as a standard baseline model in natural language processing [Jurafsky and Martin 2000; Manning and Sch  X  utze 1999]. One issue with the trigram model is that training generally requires more massive texts than basic word frequency methods to provide useful prediction [Trnka et al. 2009]. As many of the trigram sequences may never occur, even the training corpus is huge, so the problem of data sparseness is always an issue, and it must be addressed with careful processing techniques such as smoothing [Katz 1987]. In addition to this, the trigram model needs to store all forms of a word containing different inflections to be present in the lexicon [Garay-Vitoria and Abascal 2006], which in turn increases the lexicon size and hence demands huge memory. Some of the systems developed using statistical methods are Reactive Keyboard [Darragh and Witten 1991], WordQ, Predictive Adaptive Lexicon (PAL) [Alm et al. 1992] and Profet [Carlberger et al. 1997b; Carlberger 1997].

Syntactic predictor. The goal of syntactic prediction is to suggest grammatically ap-propriate words. It uses the probability of occurrence of a word for given part-of-speech (POS) tag information for prediction. Probability of having the word w most likely tags for the two previous words t i  X  1 and t P w i | t i  X  1 , t i  X  2 [Fazly 2002; Pedler 2007]. This approach takes the syntactic informa-tion from natural languages into account for predicting words. It uses the probability of appearance of each word P w i | t i  X  1 , t i  X  2 and the relative probability of appearance of a POS tag P t i  X  1 | t i  X  2 (n-gram model for parts-of-speech tags). Systems developed using such a method are SyntaxPal [Alm et al. 1992], New Profet [Carlberger et al. 1997a] and FASTY [Matiasek et al. 2002].

Another syntactic prediction method using grammar considers subject-object ar-rangement in the sentence. Sentences entered by a user are analyzed by grammar rules using Natural Language Processing (NLP) techniques in order to obtain the suitable parts-of-speech tag information for a given sentence [Wood 1996]. Methods for analyzing sentences may be top-down [Dyke 1991] or bottom-up [Garay-Vitoria and Gonz  X  alez 1997; Jurafsky and Martin 2000]. These methods expect that a user enters words that are already present in the vocabulary and that their grammatical information is already known. Words that are not present in the grammar file are to be entered manually in the system with its proper tag information by the user [Juraf-sky and Martin 2000; Manning and Sch  X  utze 1999]. Windmill [Wood 1996] is one such system based on the concept of syntactic prediction using English grammar.
The syntactic method assumes that a tagger tags the sentence from the beginning and has to look at the context several times to decide the final tag assignment for the word [Fazly 2002; Jurafsky and Martin 2000; Manning and Sch  X  utze 1999]. Whereas, a system that uses a tagger for tagging a word without having to tag the whole sentence from the beginning will be better, as it has to look at only a few surrounding words instead of a complete sentence. A detailed description on this can be found in Fazly [2002], Fazly and Hirst [2003], Garay-Vitoria and Abascal [2006], Jurafsky and Martin [2000], Manning and Sch  X  utze [1999], NCIP [1994], and Swiffin et al. [1987]. It is also found that by including syntactic information in prediction, appropriate words are removed from the prediction list almost as often inappropriate words are prohibited from appearing on the list [Garay-Vitoria and Abascal 2006]. Another issue of the syntactic prediction method is adoption of words. As all words in the lexicon need to be tagged with their syntactic category, out-of-vocabulary words become issues and need the user X  X  intervention.

A comparison between performance of statistical and syntactical methods is reported by Fazly et al. [Fazly 2002; Fazly and Hirst 2003]. A small amount of improvement is found with the syntactic predictor compared to the statistical system, which comes at the cost of huge computation time [Fazly 2002]. They have found that the keystroke savings of the linear combination of word-bigram and tag-trigram (parts-of-speech tag trigram) give better results than the baseline algorithm, which uses only word n-grams [Fazly 2002]. It has been also found that the word bigram algorithm is about 6.5 times faster than the linear combination algorithm [Fazly and Hirst 2003].

On the other hand, there are some commercially used disambiguation-based predic-tive text entry methods on mobile devices like T9, Letterwise [MacKenzie et al. 2001], etc. The methods are based on 12-key input from mobile device keypads.

Applicability in the context of Indian languages. Both statistical and syntactical pre-diction methods are applicable in the context of Indian languages. However, Indian languages are morphologically rich and have a more flexible word order than English [Begum et al. 2008; Ramanathan et al. 2009]. In the syntactical prediction method, information such as subject and object positions is not always able to explain the var-ious linguistic phenomena and needs to take a semantic relation into consideration [Bhatia 1987]. As Indian languages are more inflected, 5 so the statistical prediction method needs to store different inflections of a word in the lexicon. If the words con-taining inflection are not part of the lexicon, they behave like out-of-vocabulary words and composing them requires more keystrokes. Keeping all inflected words not only demands huge memory but also processing time. Moreover, to develop a word pre-diction system in an Indian language some issues have to be considered. The issues for the development of a prediction system for Indian languages are discussed in the next section. There are many scripts such as Mandarin, South-Asian languages, etc., where text en-try becomes a complex and error-prone task. Also, there are some issues in developing a word prediction system for those languages. In the following, we mention a few such issues in the context of an Indian language, namely Hindi.
 Large character set. The Hindi language uses a large number of base characters. The possible character combinations can be consonant and diacritic, consonant and consonant with the help of halant and so on. Combining characters in these ways forms a new syllable, so representing all of them in the standard keyboard is not feasible. Researchers propose mapping more than one character in a single key and to use special keys, namely Shift , Ctrl ,and Alt , for selection of suitable characters [MacKenzie and Tanaka-Ishii 2007]. But, this increases the number of key presses re-quired to enter a character. Presence of a large character set and use of multiple key presses affect the word prediction performance by decreasing the keystroke savings and imposing cognitive load on users. Normalization. Indian language data require normalization [Consortium 2011; CDAC 2010b], as there exist characters having equivalent unicode representations (shown in Table I(a)). In addition to this, the use of Zero-Width Joiner U200D) and the Zero-Width Non Joiner 7 (unicode value U200C) represent conjuncts in different ways. For example, say  X   X  [k X @] (unicode sequence U 0915 can be represented in different forms such as  X   X  (unicode sequence U 0915 U 200 D + U 0937) or  X   X  (unicode sequence U 0915 + U 094 D [Constable 2004]. If normalization is not done properly, then searching the word writ-ten in one form will omit the words in another form [CDAC 2010b]. This increases the miss rate in word prediction although alternate words are present in the vocabulary. According to the unicode consortium [Consortium 2011], various characters are ana-lyzed visually as consisting of multiple parts to represent them as units, as shown in Table I(b). These compositions, in fact, are not valid for composing text although they appear as correct [Consortium 2011].

Input sequence. The diacritics in the Indian language are not necessarily written or read in a linear sequence. In other words, the writing order and the phonological order may not match in Devanagari [Ishida 2010; MacKenzie and Tanaka-Ishii 2007]. Fur-ther, the position of a character in a word may not be fixed. For example, to compose the word [nirmit  X  X ] , the user has to select the characters in the order: + + + + + + . Note that this type of correct ordering demands cognitive load on the users.
Typographical variants. In the Hindi language, several words have multiple cor-rect spellings and alternate representation forms [CDAC 2010a, 2010b]. The charac-ter  X  anuswar  X  can be used as half-na (e.g. [Hi n d  X  X :] and (e.g. [mu n b@i:] and [mumb@i:] ). In addition to this, it contains dual forms that are grammatically correct, while only one form is acceptable (as in [lije:] ) [Balasubramaniam 2006] in standard Hindi.

Presence of phonetic/graphical similar characters. There exist characters that are phonetically similar [Ahmed et al. 2011; Joshi et al. 2003], such as ( [C@] , [ X @] , [s@] ), ( [ X  X ] ,and [ri:] ), ( [i:] and [ ji:] ), and ( remains ample chance of confusion, for example, between [b and [d  X  h @] ;and [k h @] and [rv@] [Ghosh and Knuth 1983]. These issues make the task of text entry more error-prone.

Text entry interface. A text entry mechanism should facilitate higher text entry rate, minimum keystrokes, lower cognitive load on users, and minimum eye and hand move-ments for composing text accurately [Garay-Vitoria and Abascal 2006; MacKenzie and Tanaka-Ishii 2007]. Also, the system should be easy to use and provide an effective way of correcting mistakes. An effective text entry system must include localization, error correction, editor support, feedback, and context of use [Kristensson 2009]. The same is also relevant in the context of Indian languages. Indeed, it is a challenge to deal with the preceding relevant issues to develop an effective text entry system in Hindi. In this section, we discuss the proposed approach of predicting words while typing text using a Hindi virtual keyboard. Our approach consists of three tasks: (a) development of a language model, (b) defining score metrics, and (c) prediction methodology. The language model has been developed using the Hindi Wikipedia corpus to support our word prediction system. We use a few metrics in our prediction method. The metrics are defined followed by our proposed approach to word prediction. We consider the Hindi Wikipedia corpus (written in Devanagari unicode) to build our language model. A Web crawler is developed to download the Wikipedia Web pages from the Internet. The downloaded pages contain texts, images, and HTML tags. Since, only the text part is relevant to our work, we filter the Wikipedia corpus to remove all nonrelevant elements and convert the text into unicode normalized form [Consortium 2010; Strassel et al. 2003]. The n-gram language model is developed using this pro-cessed data. The model contains unigram, bigram, and trigram probabilities of the words. The approach to building this model is elaborated in the following.
As many of the n-gram sequences may never occur even if the training corpus is huge, the problem of data sparseness is always an issue [Katz 1987], and it must be addressed with careful processing techniques, called smoothing. Backoff n-gram mod-eling is such a nonlinear smoothing technique introduced by Katz [1987] and Seymore and Rosenfeld [1996]. According to the Backoff n-gram modeling approach, if we see no counts (unseen event) for a trigram sequence, say w i  X  2 to determine P w i | w i  X  1 w i  X  2 , then we can estimate its likelihood by using the bigram probability P w i | w i  X  1 ; if we do not see counts to calculate P w use unigram probability P ( w i ) . However, if we have a non-zero count for trigram (seen event), we depend on trigram counts and do not interpolate the bigram and unigram counts. We only  X  X ack off X  to a lower order n-gram if we have zero evidence for a higher order n-gram. Backoff n-gram modeling is formally expressed in Equation 1.
Here, P w i | w i  X  1 w i  X  2 represents trigram backoff probability and P is discounting probability (computed using Equation 2). C is the number of a counts for a seen word sequence, C  X  represents the discounted count, and N signifies the order of n-gram.  X  (used in Equation 1) is a function of the preceding word string ( w the probability mass distribution from an ( N )gram to an ( N mated by Equation 3 according to the Good-Turing discounting method [Jurafsky and Martin 2000; Manning and Sch  X  utze 1999; Wandmacher 2009]. We have used the CMU-SLM toolkit [SLM 1999] to calculate backoff probabilities for the Hindi Wikipedia resource.

After processing the Hindi Wikipedia corpus, the language model contains 65001 unigram (that is, 65000 vocabulary words and one symbol for out-of-vocabulary word), 1.01 million bigrams and 2.2 million trigrams. The developed language model contains the backoff probability for n-gram and also includes its probability mass distribution (used in cases when one of the higher order n-gram sequences does not exist). We consider four metrics in our proposed word prediction system. The metrics and their calculations are discussed in the following. (1) ED Equal . Given a target word (  X  ) and typed word (  X  ), the score ED as the minimum number of edit operations needed to transform  X  into a part of  X  , with the allowed edit-operations being insertion, deletion, or substitution of a single character. The steps involved in calculation of ED Equal are shown in Algorithm 1. It may be noted that the calculation of ED Equal follows Levenshtein edit distance [Cormen et al. 2001; Kukich 1992].

The working of Algorithm 1 is illustrated with an example. Suppose, the desired word  X  is a! [viCe: X @t  X  X :a:u n ] and user has typed  X  ( [vi:Ce:s@] ). The array d [ i , j ] is used to store the minimum number of operations needed to transform  X  into  X  , where  X  is a part of  X  . In this case,  X  is [viCe: X @] . Here, ED calculated as 2 (see Table II). Note that the Levenshtein edit distance between  X  and  X  is 6 (shown in Table II). Also note that when the length of a target word (  X  )is smaller than a typed word (  X  ), the value of ED Equal is same as the Levenshtein edit distance.
 (2) E Score . Given the typed word (  X  ) and desired word (  X  ), E the error between the typed word (  X  ) and the desired word (  X  ) on a scale of [0 is calculated using Equation 4.

In Equation 4, Length(  X  ) denotes the length of the typed word  X  . A smaller value of E Score implies that  X  is more similar to  X  . In our work, normalization is performed with Length ( X ) because E Score uses the concept of ED Equal imum number of edit operations needed to transform  X  into a part of  X  (let it be  X  ). Here, the lengths of  X  and  X  are the same, that is, Length ( X  ) Maximum ( Length ( X ) , Length ( X  )) = Length ( X ) . (3) B Score . Given a backoff probability P w n | w n  X  1
In other words, the B Score of a backoff probability is defined as the absolute value of its logarithmic (base 10) value (see Equation 5). A smaller value of the B implies the word is highly probable. (4) P Score . It is defined as a phonetic similarity between typed word (  X  ) and desired word (  X  ) on a scale of [0  X  1] and can be computed using Algorithm 2.

Algorithm 2 uses the concept of sets of phonetically similar characters. We have built the sets based on the similarity in pronunciation of characters. The discussions available in the literature 8 are also being considered while the sets are prepared. All sets of phonetically similar characters in Hindi are shown in Table III. In Table III, C denotes a character and IPA denotes the representation of a character in the international phonetic alphabet. For example, [C@] , [ X @] ,and [s@] is such a set of characters. The first entry in a row in Table III represents the Character Set ID
CSID of a phonetically similar set of characters. Thus, [C@] is the CSID of [C@] , [ X @] ,and [s@] (see Table III). CSID Seq (in Algorithm 2) is a sequence of characters after converting each character in a word, say  X  , to its corresponding CSID . As an example, for the words a! [viCe: X @t  X  X :a:u n ] and [vi:Ce:s@] CSID [b@iC@e:C@t  X  X @:u n ] and ie [b@iC@e:C@] , respectively.

We illustrate Algorithm 2 with an example. Suppose, a desired word  X  is  X  [ut  X  X   X  X m@] and user types  X  as  X  u  X  [ut  X  X m@] . The CSID CSID Seq for  X  is u [ut  X  X m@] . From these sequences, removing  X  halant  X  and consecu-tive occurrences of duplicate CSID , we find  X  1 as u [ut  X  X m@] and  X  Therefore, the P Score between  X  and  X  is calculated as E case. We may note that the P Score value indicates how much two words are phonetically similar. At any instance of text composition, user wants to compose a word w of composition w i  X  2 w i  X  1 w i , where w i  X  1 and w i words. Here, w i  X  2 and w i  X  1 may be empty (when user is at the beginning of composing the first word). Further, consider that toward the composition of w tered  X  , which is a part of the desired word w i (see Figure 1). Our proposed approach predicts the word w i ,if  X  , the part of w i , is entered correctly or there is any error in it. To predict the target word, we first generate a list of candidate words from the lan-guage model. Then we calculate the different scores between  X  and each candidate in the list of candidates. Finally, we rank the candidates based on their scores and gener-ate a list of predicted words. The framework of the proposed prediction methodology is shown in Figure 2. There are three main modules in our prediction approach: (a) gen-eration of candidate list, (b) accumulation of score, and (c) ranking of predicted words. These three modules are discussed in detail in the following.

Generation of candidate list. Generation of a list of candidate words prior to the prediction can be thought of in two stages: (1) completion of the current word and (2) prediction of the next word. The steps involved in each stage are described in the following. (1) Completion of current word . Let the candidate words to be stored in a list say Algorithm 3 Candidate words generation (2) Prediction of next word . When the target word appears in the prediction list and the
The detailed steps for generating the candidate list for completion of current word and predicting next word are precisely stated in Algorithm 3.
 Merging of scores. In Section 4.2, we have proposed four score metrics, namely P E
Score ,and B Score , based on phonetic similarity, typing error, and backoff probability, respectively, and ED Equal , which is used for calculating P illustrate the accumulation method of these scores with an example.

Let us consider a part of CandidateList, as shown in Table IV(a). We calculate the values of these scores for each item in CandidateList. Calculation of different scores on these words is described in the following. Let  X  CandidateList (see Table IV(a)). The ScoreList represents the list of different scores of the candidate words. This list stores the calculated scores and is used by the ranking module (see Table IV(b)). In this example, suppose, at any instant,  X  is for which candidate words are:  X  i is [b@Hut  X  X ] ,  X  i +
We calculate E Score between  X  i and  X  (using Equation 4). To do this, we need to compute ED Equal between  X  i and  X  (Algorithm 1). The value of E (see Table IV(b)). Similarly, E Score values with  X  and  X  as shown in Table IV(b). Next, we calculate P score between  X  which uses the CSID Seq . The P score between  X  i and  X  is 0.25. Likewise, P between  X  and  X  i + 1 ,  X  i + 2 ...  X  i + 5 are calculated and shown in Table IV(b). The B calculated taking the absolute value of the logarithmic value of the backoff probability of  X  i (using Eqn 5). The B Score values of  X  i + 1 ,  X  i
We store the values of the different scores for each  X  i separated by tab symbol ( to form a string  X  . We call this process merging of scores. This string  X  is then added to ScoreList . When the user selects a word from the prediction list, our proposed pre-diction methodology predicts the next word (prediction system is in the stage of next word prediction). In this case, we store only B Score and  X  of different scores is precisely stated in Algorithm 4.

Ranking of predicted words. We sort the ScoreList using Lexicographical sort in as-cending order (considering collating sequence in a string of score values) to rank the Algorithm 4 Score calculation most probable words. The next step is to select the top N words (  X  only) from this list and display them in the prediction window. Here, N denotes the size of the predic-tion window. The ranking of the ScoreList and analysis of various scores are shown in Table V. Let any two tuples (entries) in this list be denoted by T corresponding values P 1 , E 1 , B 1 ,and W 1 for tuple T T . Here, P 1 means P Score for T 1 , E 1 means E Score , B word present in T 1 . The same mapping is also true for tuple T
If the two tuples in the list have the same E Score value, equal to zero, that is, E E (  X  ) without any error in it. On the other hand, if E 1 = are the same but they contain some typing variations from  X  .When P CSID sequence of  X  matches the prefix of the CSID sequences present in T The condition P 1 = P 2 = 0 indicates that there is a match between the CSID sequences of T 1 and T 2 but there is no match with the CSID sequence of  X  .

The conditions P 1 = P 2 = 0and E 1 = E 2 = 0 implies that both T same CSID sequence as entered by  X  but the key required to be pressed by the user in  X  does not match exactly with words W 1 and W 2 . The desired and typed characters are different in  X  and T 1 and  X  and T 2 groups but they are similar with T the other hand, if P 1 = P 2 = 0and E 1 = E 2 = 0, then both T with typing variations as well as not being exactly similar to  X  . However, the value of P Score indicates the amount of phonetic similarity. This situation may occur where P without any variation. Suppose, both P 1 = P 2 and E 1 = E becomes the deciding factor and is used to break the tie between the candidate words. A candidate word having a smaller B Score indicates its higher priority. Even when the B
Score in T 1 matches the B Score in T 2 , then the words W the deciding factors for the ranking of the words as they are lexicographically sorted. Finally, the proposed prediction system displays all the words with the same prefix as typed by the user, followed by words having similar CSID, and the words having typographic variations. To judge the efficacy of our approach, we have conducted a number of experiments. In this section, we describe (a) metric for performance measure, (b) experimental setup, (c) evaluation procedure, and d) experimental result. Text entry rate measure varies from person to person and also depends on human factors such as fatigue, error making, etc. Also, the speed with which someone can move the cursor around, the speed with which someone sees a word vary from person to person. Taking all these into consideration, it is necessary to decide the right metrics to be used to judge a system meant for user interaction. The description of the metrics used to evaluate our proposed word prediction system is stated below.

Text entry rate (wpm). The text entry rate is measured by the number of words a user can enter and it is expressed in terms of words per minute or wpm .Let T be the final transcribed string entered by the user and | T | be the length of this string, that is, the number of characters entered. Let S denote the time taken by a user in sec-onds, measured from the entry of the first character to the entry of the last, including backspaces. We calculate text entry rate in wpm using Equation 6 [MacKenzie and Tanaka-Ishii 2007].

In Equation 6, w denotes the average length of words for a language. It has been observed that the average word length in Hindi is 4.695 [Bharati et al. 2002]. The  X  1 in the numerator signifies that the time S is measured from the entry of the first character to the entry of the last character (the total text length is
Keystroke savings (KS). Keystroke savings refers to the percentage of the keystrokes that a user can save while using a word prediction system [Fazly 2002; Wolf et al. 2006]. According to this measure, the keystroke savings can be expressed as shown in Equation 7.

Here, T total is the total composed texts, K w is the number of keystrokes required to type given texts, and K s indicates number of times words are selected from the prediction window. We may note that this measure includes the additional keystrokes required for selecting intended words from the prediction list.

Potential keystroke savings (PKS). PKS is defined as the keystroke savings obtained by users if they fully utilize the word prediction system [Fazly 2002]. That is, for ev-ery word present in a trial text, the user selects the word as soon as it appears in the prediction list. It may be noted that KS returns the keystroke savings actually accom-plished by the user, and it varies from user to user. Further, the KS is less than or equal to PKS , because a user may or may not check the prediction window after every character is pressed and sometimes may miss the desired word.

Prediction utilization (PU). This metric defines how much a user depends on the word prediction system at the time of the text composition [Fazly 2002]. It is calculated as the ratio of KS to PKS (Eqn 8).

Hit rate (HR). It refers to the percentage of times target words appear in the predic-tion list while composing text.

Keystrokes until prediction (KuP). Keystrokes until prediction is defined as the aver-age number of keystrokes that a user must enter before the appearance of the desired word in the prediction list [Wolf et al. 2006]. Calculation of KuP is shown in Equation 9. where N denotes the number of words in the text (C) and K keystrokes required to type a word w C . All experiments in this work have been carried out on a Windows 7 operating sys-tem, Intel Core 2 Duo processor with 2 GB primary memory. The proposed algorithms and Hindi predictive virtual keyboard have been developed using C #3.5intheVisual Studio 2008 environment. A Web version of the developed system is hosted at Human Computer Interaction Lab, Indian Institute of Technology, Kharagpur, India. to the developed word prediction system as *hIndiA (as shown in Figure 3). Two different approaches are considered for evaluating the word prediction method: (a) empirical evaluation and (b) simulated evaluation [Wandmacher 2009]. In the empirical evaluation, users compose texts, whereas in the simulated evaluation, the prediction system is tested with several trial texts emulating human behavior. With empirical evaluation, many significant observations are obtained, which include mes-sage composition speed, human factors such as error rate, fatigue, learning time, user satisfaction, etc. Simulation always generates the best result, as the text can be en-tered and selected at the highest possible speed, but it does not consider human factors such as fatigue or error-making. Several authors [Garay-Vitoria and Abascal 2004; Koester and Levine 1998] use this approach for evaluation. In our experiments, we have considered both evaluations. These two evaluation procedures are discussed in the following. 5.3.1. Empirical Evaluation. In the empirical evaluation method, all experiments have been carried out with users of different educational backgrounds and having famil-iarity with the Hindi language. In our experiments, users have been asked to type benchmark texts with and without the help of the predictive keyboard. The time taken to compose texts and the keys that were pressed by users to compose texts are recorded in a log file. This log file is then analyzed with respect to the metrics defined in Section 5.1.

We have followed two procedures for user evaluation, namely Read and Type (RT) and Listen and Type (LT). In RT -based evaluation method, composition of text requires the extra effort of shifting focus from reading to typing and vice versa, in addition to increased eye and hand movement times. In LT -based evaluation, users first need to listen to the text word by word uttered by an instructor and then type those words. The LT method produces comparatively faster text entry but also increases the chance of committing typing errors.

We have considered five benchmark texts from different domains to evaluate the proposed system. These benchmark texts are classified as In-domain and Out-of-domain data. As we have taken the Wikipedia corpus to train our system (discussed in Section 4.1); benchmark texts that are parts of Wikipedia are treated as In-domain texts. All other benchmark texts are treated as Out-of-domain texts. A summary of texts used in our experiments is shown in Table VI.

Participants. To evaluate the proposed word prediction system with users, we include 38 users in our experiments. Depending on their educational backgrounds, reading and writing efficiency in Hindi, and computer knowledge, all users were clas-sified into two categories: experienced and inexperienced . The users in the experienced category were skilled and regular computer users such as students at higher schools, graduate, and office staff members. In the inexperienced category, we included people who were novice computer users, such as shopkeepers, housekeepers, and primary-level school children. For conducting the experiments in the Hindi language, we se-lected five office staff members, seven graduate, and eight high school, students for the experienced category. We choose five shopkeepers, five housekeepers, and eight primary-level school students for the inexperienced category. Classification of users is summarized in Table VII.

During the experiments, we maintained approximately 65 centimeters between com-puter screen and participant. The benchmark texts and the keyboard for typing were chosen in a random order in each session to minimize the memorization effect of users. The order was counterbalanced across the participants. For both Read and Type and Listen and Type procedures, a time gap between two consecutive procedures was fol-lowed, which was between one to three days. Before each session, the users practiced a text entry task to familiarize themselves with the Hindi virtual keyboard. After com-pletion of all sessions for a user, we collected feedback to study his opinions about the text entry method.

The objectives of our experiments were to evaluate the text entry performance with the proposed word prediction system by comparing text entry rate and error reduction rate with and without prediction support. In our prediction system, we consider the placement of the prediction window as shown in Figure 3 and the size of the prediction window as seven. The user results of Read and Type and Listen and Type based evalu-ation were averaged for further computation. To analyze text entry rate, we conducted Paired t test using the Statistical Package for the Social Sciences (also called SPSS) tool [IBM 2011].

The average text entry performance of *hIndiA with and without prediction for dif-ferent benchmark texts is shown in Figure 4(a). Here, WoP and WP represent with-out and with prediction, respectively. Analysis of the Paired t test reveals that there is a significant difference of mean text entry rate between WoP and WP . That is, t = X  21.34, mean difference  X ( WoP  X  WP ) is  X  8.1, d.f (37), and p &lt; 0.05 for the 2-tail test. User achieves on average, 144.76% improvement with keyboard augmented with the proposed prediction mechanism compared to the keyboard without predic-tion support. We observe that the benchmark texts from In-domain perform better than Out-of-domain . We can conclude that the performance of WP is better compared to WoP .

The text composed using *hIndiA contains fewer errors than the text composed using a normal virtual keyboard without prediction (see Figure 4(b)). With analysis of paired t test, we find that t = 30.99,  X ( WoP  X  WP ) = 14.67, d.f (37), and p &lt; 0.05 for the 2-tail test. In other words, there is a significant difference in the mean of typing errors without using prediction and using proposed prediction ( p &lt; 0.05). The result of user evaluation shows that *hIndiA corrects on average, 89.75% of typing errors compared to text entry without prediction on the same benchmark texts.
 Further, we have observed Keystroke savings as 43.77%, Hit rate as 92.49%, and Prediction utilization as 95.82% with the proposed system.

We conducted a small survey with the participants after completion of their exper-imental sessions. A set of six questionaries were given to each participant to rate the system in a 1 X 5 Likert-scale . Responses from the participants were then consolidated, and are presented in Table VIII. In this table, a comparison is made between systems with and without augmenting of word prediction (WP and WoP, respectively). When asked about the ease of use, user felt that WP is much easier to use than the WoP. Similarly, user felt that WP is less tiring than WoP. WP is also found to be much faster compared to WoP. It is more accurate and useful over WoP. In addition to this, user also found that WP is less distracting than WoP.

We used Multirater Generalized Kappa [Stolberg et al. 2004] to evaluate the interrater agreement using Equation 10. where  X  K G is generalized kappa score,  X  p is mean proportion agreement, and agreement. We observed overall interrater agreement among 38 participants for six questions as 0.459. However, for experienced and inexperienced category users, values are 0.518 and 0.332, respectively. 5.3.2. Simulated Evaluation. In this method, a simulation component has been devel-oped which reads words from the different benchmark texts (see Table VI) and passes them character by character to the proposed word prediction system. It processes and populates the word in the prediction list. Whenever the prediction list contains the tar-get word, it accepts the word and processes the next word until the text is complete. If the word is presented in the prediction list and selected by the simulated component, it automatically increments the hit count and appends space in the composed text.
Simulation is done on different modes with the proposed word prediction system as described in Table IX. In Mode 1 , the simulation program reads a word from the benchmark texts and composes the text without any error. In Mode 2 , the simulation program also takes the location number where an error can be incorporated (let it be the i th position). The program reads the word from the benchmark texts and randomly chooses a character and alters it with a character at the i th position in the word. Here, i &gt; 1, that is, the error can be at the second position or onward. In Mode 3 , the program selects the character at the i th position in a word and replaces it with any similar character (character having same CSID ). In this mode, i similar character can occur at the first position. Whereas, in Mode 4 , a random number is generated between 0 and 1. If it is 0, a random character error will be placed at any position within the word, otherwise, the system puts a phonetically equivalent character at a random position. Further, when an error occurs at the first position in Mode 4 , it is replaced with an equivalent CSID character.

The performance of *hIndiA for different modes of simulation and benchmark texts (with prediction window size seven) is further discussed. Potential keystroke savings (PKS) , Keystrokes until prediction (KuP) ,and Hit rate (HR) with different benchmark texts and different modes such as Mode 1 , Mode 2 , Mode 3 ,and Mode 4 are presented in Figure 5. The performance achieved in Mode 1 is represented by Ef . Mode 2 con-tains four different positions of errors, which are represented as E2 to E5 . Mode 3 , which contains five different positions of errors in a word is represented by P1 to P5 . R represents the performance achieved in Mode 4 .

We achieve Potential keystroke savings of 45.64% when there is no error (in Mode 1 ), whereas we achieve 43.50% of potential keystroke savings in the presence of typing errors (see Figure 5(a) and 5(b)). We have presented the typing error by taking the average of Mode 2 , Mode 3 ,and Mode 4 . We observe that Potential keystroke savings increases as simulated errors occur toward the ending location of any word (e.g. Po-tential keystroke savings for error occurrence at location 3, is greater than the error at location 2 (see Figure 5(a)). We have also observed that more Potential keystroke savings are achieved when an error in character belongs to a similar group (in Mode 3 ) than the error belonging to a random character (in Mode 2 ). We also observe that Po-tential keystroke savings for In-domain data ( H5 ) is higher compared to Out-of-domain data. The Keystrokes until prediction for In-domain requires fewer key presses in both Mode 3 and Mode 2 (see Figure 5(c)). We also observe that Keystrokes until prediction is large in the presence of typing errors. The Keystrokes until prediction of 1.662 char-acters is observed when there are typing errors, as opposed to 1.542 characters when there is no error (also see Figure 5(d)). The benchmark texts H2 are observed to have higher Keystrokes until prediction in all modes. However, the performance of H3 and H4 is similar. The HR of In-domain is also higher compared to Out-of-domain text. We observe that HR achieved when error occurs at the first position (repented as P 1) is smaller compared to other cases but greater than the E 2 condition. HR achieved with and without errors are summarized in Figure 5(f). In addition to this, we achieve the average text entry performance considering all modes of simulation as 62.52% of Potential keystroke savings , 96.5% of Hit rate ,and Keystrokes until prediction as 0.83 with text from In-domain (see H5 in Figure 5(a), 5(c), and 5(f)).

We introduce approximately 11,260 simulated errors while composing texts with a prediction window of size seven. It is observed that 8461 words were predicted accu-rately before any error occurred (error is avoided, in Mode 2 , Mode 3 ,and Mode 4 ). Thus in 2799 words ( = 11, 260  X  8,461) error occurred in simulation before the target words came into the prediction window. After applying avoidance, detection and cor-rection (the proposed approach) only 492 errors were left untreated (see Figure 5(g)). In the traditional word prediction approach, errors are generally avoided instead of detected and corrected [Herold et al. 2008; MacArthur 1998; Zordell 1990]. Using the traditional approach, 75.15% of errors are avoided whereas in our proposed approach, 95.63% of errors are either avoided or detected and corrected accurately (also see Figure 5(h)). We compare the efficiency of our approach with the existing approaches like Lipik [Lipik 2012] and Google [Google 2010]. These two systems resemble our sys-tem so far as the input and output are concerned. We also compare our system with Quillpad [Tachyon Technologies 2012] and Google Transliterate [Google 2014], al-though they are meant for transliteration but can be used for document composition in Hindi. We start with the description of each interface and then summarize the result.
Google. Google provides a word prediction mechanism to predict search keywords (in many Indian languages including Hindi). It is augmented with virtual keyboard in a QWERTY layout and displays results in the prediction window, which is vertical in orientation (see Figure 6(a)). When a user enters a prefix of a word, it returns the top ten possible suggestions in the prediction window. It also provides multiple words to be predicted and displayed in the prediction window. When the predicted word is selected from the prediction window, it searches the Internet and returns the results.
Lipik. Lipik is the predictive software which supports text composition in Hindi lan-guage. It has an inbuilt virtual keyboard to enter texts. The keyboard is based on the QWERTY layout. It is useful for composing documents or email in Hindi. Prediction (word-level) provides ten suggestions in the prediction window. The prediction window is horizontally organized and placed between the text area and the keyboard area (see Figure 6(b)). Once the word is completed, user needs to press a space bar to populate the next possible word. The scenario necessitates one additional key press on each suc-cessful completion of a word, apart from the selection of it from the prediction window.
Lipik and Google work with those words that are entered correctly. For example, when a user wants to compose the word &amp; ' [vist  X  X  X  X   X  X ] , if a typographic error occurs, like deletion of halant , selection of a phonetically similar character (between [s@] and [C@] ) or a selection error in matra (between [i] and [i:] ), etc., the systems fail to suggest corrected words. Indeed, none of them provides support for error correction to the user and it is the user X  X  responsibility to type the prefix of the word correctly.
Quillpad [Tachyon Technologies 2012] and Google Transliterate [Google 2014] are transliteration tools, which take character by character (in English as input) and guess an equivalent Hindi unicode sequence of characters. It should be noted that Quillpad and Google Transliterate do not predict next character(s) or perform word completion based on user X  X  partial input character(s). For example, when a user tries to compose the word  X  X harat X  and enters the sequence of characters  X  X har X  the prediction list shows words: [b h @r@] , [b h A:r@] ,and [b@r@] , but not the word To get the word [b h A:r@t  X  X ] , the user should give the input as  X  X harat X . Further, note that the number of characters to type the word [b h less compared to its English counterpart  X  X harat X  (6 keystrokes). Thus, in general, the typing in English often produces less or no keystroke savings compared to the situation when user gives input directly in unicode.

Our proposed prediction system can be used for composing any document, email, texts and so on. It has phonetic support and can handle human typing errors. It also has the support of auditory clues integrated within the interface. In addition to pre-dicting the word correctly when there is no error, our system also suggests the intended words more precisely in the presence of typing errors. Table X compares our proposed prediction system with Lipik, Google, and a trigram-based approach, we term as the Trigram approach.

We have also performed a study of users X  text entry performance on our proposed system, *hIndiA , along with Lipik, Google and Trigram. We have included seven users who are different than the participants involved in the previous experiments (Section 5.3.1). We have taken the same benchmark texts as discussed in the previous experiments. In this experiment, we have followed Listen and Type (LT)-based evalua-tion only. For a session, keyboard and the benchmark texts have been chosen randomly. The random order is counterbalanced across the users. The text entry performances have been averaged over users and presented in Table XI.
 Most of the users who participated in our experiments were not necessarily typists; they needed a huge amount of time to search the Hindi characters in the virtual key-board. As many of them never used any kind of virtual keyboard, a significant amount of training was required to compose texts in Hindi.

We critically checked the performance of the prediction system with different texts and users. We have conducted several experiments on texts taken from various do-mains, such as novels, story books, journalism, autobiography, and others. Needless to say the results are valid for the five different texts (total of 75 sentences) and to 38 users with varying proficiency of computer skill and education level. We observed that the proposed system performs better with In-domain data ( H5 )than Out-of-domain data ( H3 , H4 , H1 ,and H2 in respective order). User needs fewer key presses in text composition from H1 , H3 and H4 than texts from H1 and H2 . The proposed system accurately suggests the mistyped words, and at the same time it saves keystrokes needed to compose texts. Also, it has been found that Potential keystroke savings is directly proportional to the position in which the error occurred in a word.
It is observed that our proposed system corrects 95.63% of simulated errors. It achieves 95.01% of Hit rate and Keystrokes until prediction of 1.54 in the error-free con-dition whereas in the presence of error, Hit rate is 92.25 and Keystrokes until prediction is 1.66. With benchmark text H5 , it achieves on average, 62.52% of Potential keystroke savings , 96.5% of Hit rate ,and Keystrokes until prediction of 0.83. The proposed word prediction system is simple to use for both categories of users (see Table VII). It is also observed that text composition speed is significantly increased with the use of our word prediction system and is able to correct spelling mistakes.

It may be noted from the observation that user faces many problems in character by character text composition in Hindi. This is due to many factors: changing of visual representation of a character after combination (such as [nirmit  X  X ] can be written as + + + + + + and () (British) can be written as + + + + increases the cognitive load on users, as many of them have the difficulty of composing those glyphs. Instead, in English text composition, characters are visually separated from each other (such as school(s+c+h+o+o+l)). It is also observed that selection of a word from the list of words is easier compared to composing them character by char-acter. Further, we note that correction of errors requires pressing the backspace key, which in turns decreases the keystroke savings. In contrast, in *hIndia , in the case of errors, system predicts the correct words, thus avoiding use of the backspace key, and hence the improvement in keystroke savings and text entry rate. Related to our experiments and experimental results, we would like to point out their validity and limitations.
 Language resource creation. In our experiments we used the Wikipedia corpus in Hindi to build our language resource model. The corpus includes 65001 unigrams, 1.01 million bigrams and 2.2 million trigrams. The observed results, therefore, are subject to the use of that corpus. Instead of the Wikipedia corpus, we could use other corpora, such as a newspaper corpus.

Participants. In our experiments, we used the help of 38 participants with varying levels of computer knowledge, reading/writing in Hindi, occupation, and educational background. We would claim the results subject to the testing with respect to these participants.

Benchmark text and participant X  X  time. We have used benchmark texts of total size 1126 words per participant. The benchmark texts were chosen from different popular sources of Hindi literature. Participants were involved in the experiments ranging from 2 X 4 months with several sessions. Each session lasted 2 X 3 hours.

Keyboard layout. We have followed a virtual keyboard where characters on the keys are laid in alphabetical order. Results may vary with different keyboard layouts.
First character error. If a phonetic error occurs at the first character, our system can detect and correct it. However, if there is a random character error at the first character, our system cannot handle that error. Of late, various virtual keyboards have been developed that are mostly for composition of texts in English. This work proposes to develop a text entry system in the context of the Indian scenario and aims at designing a predictive virtual keyboard in Hindi (national language of India and the 4th language 10 in the ranking of the languages in the world).

The proposed Hindi text entry system called *hIndiA (Hindi virtual keyboard with word prediction) is comparable to the existing systems namely Lipik, Google, Quillpad, Google Transliterate and so on. The word prediction mechanism proposed in this work is an ingenious approach particularly for dealing with the complexities in Hindi text composition. With the proposed word prediction, text entry becomes 89.75% less error prone and the text entry rate improvement is 144.765% with respect to text entry without prediction. Apart from this, potential keystroke savings ( PKS ) and keystroke savings ( KS ) are achieved as 45.67% and 43.77%, respectively. More significantly, the proposed word prediction works even if a part of word is misspelled, unlike the existing approaches.

The simulation studies reveal that our prediction system is able to detect and correct 95.63% of the typing errors. This is indeed a significant observation. The proposed approach to text composition is not necessarily limited to Hindi. In fact, our approach can easily be extended to many other Indian, as well as other languages, incorporating their corresponding language features into account.

There is further room for improvements, which are highlighted as follows. User adaptation and personalization can be incorporated to enhance the text entry per-formance. We can investigate context-based syntactical prediction with an error-correction mechanism. There is a lack of calculating errors during text composition through our word prediction system. A new metric can be developed to judge the error behavior during text composition using word prediction.
