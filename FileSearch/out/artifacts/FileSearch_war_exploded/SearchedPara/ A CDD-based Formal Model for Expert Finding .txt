 Searching an organization X  X  documen t repositories for experts is a frequently faced problem in intranet information management. This paper proposes a candidate-centered model which is referred as Candidate Description Document (CDD)-based retrieval model. The expertise evidence about an expert candidate scattered over repositories is mined and aggregated automatically to form a profile called the candidate's CDD, which represents his knowledge. We present the model from its foundations through its logical development and argue in favor of this model for expert finding. We devise and compare the different strategies for exploring a variety of expertis e evidence. The experiments on TREC enterprise corpora demons trate that the CDD-based model achieves significant and consiste nt improvement on performance through comparative studies with non-CDD methods. H.3.3 Information Search and Retrieval; Algorithms, Performance, Experimentation Expert finding, knowledge mana gement, expertise modeling, Finding experts in a particular area is a frequently encountered problem within any commercial, educational or government organization. There are a numbe r of situations where knowing "who know what" within an organization is necessary, including knowledge sharing, team formati on, project launching, etc. Different from traditional document retrieval tasks, expert finding aims at finding a higher semantic and abstract concept  X  X erson X , other than the real and concrete documents in the collection. Simply using search engine to shift the target from document to expert is not an effective approach. The reason lies in that for documents retrieval, the words in a document are explicit and known thus can be indexed for retr ieval. However, the experts X  information may be scattered ove r repositories and thus not be accurately and explicitly documented, so it needs to discover the implicit expertise to estim ate who is the expert. Generally speaking, there are two alternative expert search models: the document-centered m odel and the candidate-centered model. The document-centered m odel is a traditional prevailing model. Source corporate docum ents are retrieved using information retrieval systems, a nd the matching sources are then mined for experts. In candida te-centered models, expert candidates are represented by a pre-constructed or dynamically generated document aggregated from the corporate documents. A typical system built by Nick Craswell and David Hawking is P@NOPTIC Expert [1]. We propose a candidate-centered model which builds a direct relationship between query and e xpert by retrieving Candidate Description Document (CDD)s for each candidate. The CDD of a certain candidate is a profile to represent his knowledge, which is aggregated from his automatically identified expertise evidence that scattered over document repos itories. Three natural heuristics is considered to interpret th e model and develop formulae for CDD weighting. We argue that there are several reasons which account for preference of the candidate-centered model. Information relevant to an e xpert is distributed across the organization in heterogeneous sour ces. In most cases the expertise data is not fully documented and usually only parts of a document are related to the expert whom it mentions. In order to better describe the knowledge of a particular candidate, the expertise representation should be estab lished on a more precise level instead of the document. Here we adopt the concept  X  X xpert evidence X  as the fundamental element in representing the expertise. We make the following definition: Definition 1 : Let x be a text sequence obtained from document d , and let c be a candidate. If x can represent the knowledge of c through a logical or natural association, then x is the evidence of candidate c , denoted (,) Evi x c . The text x can be professional and desc riptive terms or phases like  X  Information retrieval  X . All pieces of expert evidence associated with a particular expert candidate can be aggregated as a knowledge description to represen t him. We give this another definition: Definition 2 : There are potential pieces of expertise evidence distributed in heterogeneous sources, which can be identified and extracted automatically to form a document that describes the particular candidate c . This refined document is called Candidate Description Document (CDD) . In an organization, each candidate may correspond to a particular CDD. The approach is motivated by the assumption that each expert X  X  knowledge can be represented by a list of terms which are related to him. And in a limited document collection, this ideal description is approximated by th e aggregation of expert evidence which is extracted automatically in enterprise repositories. Therefore the probability of a candidate to be the expert under the given query can be defined as the probability that the ideal description of candidate X  X  know ledge matched to the query. Formally, this can be expressed as: where C denotes the ideal description of candidate c , and CDD is used to estimate the ideal knowledge representation. CDD is a knowledge representation formed by pieces of expert evidence. Each piece of evidence (,, ) Evi x c a conveys a particular knowledge of candidate c through the association a . Therefore, contrast to exploiting information by examining the term incidence in document retrieval, the CDD-based model needs some natural interpretation on knowledge representation through expert evidence. We find three intuitive and desirable heuristics that determine the relevance of a specific CDD to a given query. These heuristics are motivated by the observations on some common characteristics of the judgment when people make to find experts. The first heuristic is the expertise intensity (EI) on the required topic. The amount of the required information that a candidate X  X  knowledge contains contributes to present how much the required knowledge the candidate has. We assume that if a candidate possesses more knowledge, he is more likely to be the expert. The next intuitive heuristic is expertise discrimination (ED). If some knowledge that a candidate possesses can distinguish him from other candidates, we denot e such knowledge with a high degree of expertise discrimination. It ensures that given a fixed number of candidates, we should favor the candidates who have more discriminative knowledge and penalize those with the common knowledge. The third heuristic is referred as effective expertise proportion (EEP). People usually possess knowle dge in more than one field. In expert finding problem, the in formation on the required topic may be only part of the candida tes X  knowledge. And people prefer the expert who focuses his atte ntion more on the topic. For example, under the query  X  Information retrieval  X , an expert on IR is more likely to be selected than another one who labels his interest as  X  Computer Science  X . We make an assumption that among those candidates with the sa me expertise intensity on the topic, the candidate with larger effective expertise proportion is more likely to be the expert sin ce he concentrates more on it. We now present how to embody th e three basic heuristics in our CDD framework and detail the ranking formula. The expertise intensity of a candidate X  X  CDD is the sum over all intensities of its composing evidence. For each piece of salient factor to represent expertis e intensity. The weight of expert intensity in evidence is calculated under the formula given by Robertson and Walker who model the term frequencies within documents as two Poisson distri butions. The Poisson model is well satisfied by expert evidence that each evidence is associated with one topic and the distribution of term in text x is Poisson. Formally, the weight of each CDD is expressed as: CDD, the constant k controls how much the weight reacts to normalization heuristic for each piece of evidence since we assume that each piece of evidence relates to one topic and the nature of evidence ensures that th ey will be succinct rather than wordy. The expertise discrimination heur istic depends on the number of the CDDs where the query term occurs and the total amount of CDD collection. The weighting function we adopt is like the inverse document frequency (IDF) weight in document retrieval model. Actually, the expertise discrimination exerts the same effort like IDF in estimating which query term is more professional to differentiate ca ndidates. A plau sible weighting function is where N is the size of CDD collection and n is the number of CDDs containing the term t . The effective expertise proportion is considered as the ratio between the relevant knowledge to query and the whole knowledge that the candidate posse sses. Specifically, in CDD this heuristic is weighted by the proportion between the relevant evidence and all the evidence in CDD. We adopt those pieces of evidence whose expertis e intensity are above zero as relevant knowledge and count their text le ngth. Formally, the weight of effective expertise proportion of a CDD is defined as: where r L is the length of all relevant pieces of evidence in CDD and L is the length of CDD. The tuning constant b is used to control the concentration effect. Finally, we get the last weighting function that encapsulates the three heuristics. WEIEDEEP b b = X   X  =  X  X  X  X + Note that though our function is very similar with BM25 function [3], our model conceptually and formally differs from it because CDD model is based on the he uristics for finding people. Particularly, in our model TF is weighted under 2-Possion model on each piece of expertise evidence and the EI is the sum of the weight over all pieces of evidence in CDD. Moreover, we do not normalize the EI using evidence length. Instead, we propose an EEP factor which involves the to tal length of CDD and the length of relevant evidence in CDD. Th erefore, the CDD-based model is not simply an adaptation of BM25. Although the document-centered model has been widely employed in the past to tackle the problem, we believe the candidate-centered model is the more suitable solution to expert finding. One of the reasons for using candidate-centered model rather than document-centered mode l is that  X  X ne should solve the problem directly and never solve a more general problem as an intermediate step X  [4]. For fi nding experts, representing the candidates X  knowledge directly is a more intuitive solution contrast to the more general issu e that finding the distribution of the documents which are relevant to both the query and candidate. Beyond the theoretical considera tion, there are other reasons specific to the expert finding ta sk make the candidate-centered model more suitable. The discriminating power of query term is important in retrieval task to penalize popular terms in the documents. The expertise discrimination heuristic of candida te-centered model ensures that those more professional and discriminative query terms will be favored. However, in document-centered model, the discriminating power of query te rm is using document frequencies from the original collection. Imagin e the cases that there are some query terms with relatively high IDF in original document collection but those query terms ar e uniformly scattered in most CDDs, which means such query te rms do not have high expertise discrimination to CDDs. For example, the term  X  mentor  X  may differentiate documents well in original collection but it is quite popular in CDD collection. In su ch cases, the discrminability of query term in two models is different and the IDF factor in document-centered model cannot exer t its effort in discriminating experts. Therefore we believe that employing expertise discrimination is more rational. In document-centered model, all the exploitation processes are operated at search time since its first step is to retrieve relevant documents to given query. However, in candidate-centered model, the generation of CDDs is an o ffline job. Moreover, the CDDs merely consist of the extracted ev idence which is a small part of original collection in amount. Generally speaking, users are affected more by query response time than indexing time and we only generate the CDDs once to handle any queries. As the fundamental component of CDD, the expert evidence plays an essential role in represen ting candidates X  knowledge in our model. We identify three kinds of association for expertise evidence as following: Context evidence for an expert is the words around the expert name which is identified in the document. Co-occurrence between text and candidate can be used as evidence and we extract the terms that appear in the same wi ndow of text with the candidate. Block-based evidence is generated using markup terms in HTML documents, such as the Title, Heading , Bold , etc, which contribute to describing and summarizing we b pages, contain good summary words, and have expressive force. Semantic-group-based evidence extraction is based on the phenomena that persons often co-o ccur in the context as a group. We examine a mixture of patterns that group information expressed. For example, a list of person names may represent members of a group; in some tabl es, the left column lists person names and in the right column gives the corresponding description information like the professional title. Correct recognition of such group patterns brings on highly credible associations. Due to the page limits, in this paper we concentrate on the CDD model presentation and in another paper [1] we have described the strategies of name identificati on and expertise evidence extraction in details. Our CDD-based search model is evaluated on the dataset adopted in TREC enterprise track 2005 and 2006 [5]. The collection is a crawl of the public W3C (*.w3c.o rg) sites. We took the topics adopted by the expert finding task of TREC. The main evaluation measures used for the expert finding task is mean average precision (MAP). We examine the three two heuristics in our CDD-based model presented in Section 2.2: exper tise intensity (EI) and expertise discrimination (ED). Table 1 shows the retrieval performances. In weighting EI, according to our e xperiments, changing constant k affect the MAP slightly and it takes 1 empirically. The reason lies in that each piece of evidence is extracted as a fragment of the original document and the times of the query term that appears in the evidence is not much, theref ore varying the constant k does not affect much. The experimental results confir m our assumptions proposed in Section 2.2. And note that using EI alone is already more effective than the average performance of TREC systems, which had a MAP of 0.1969 in 2005 and 0.3863 in 2006. Heuristics 
EI 0.2274 0.3636 0.4667 0.5851 Varying the value of b in formula (4) allow us to evaluate the effect of using EEP on the test sets. Smaller values reduce the EEP effect. In TREC 2005 query set, the curve shows that generally the average precision in creases as b rises, which is consistent with the effect on the training set. However, in the 2006 query set, MAP increases slightly when b is less than 0.3, and then falls rapidly when EEP becomes larg er than 0.55. The inconsistent observation in two years X  query sets can be explained by the facts that in TREC 2005, the search t opics were the names of the so-called  X  X orking groups X , and the e xperts were members of these groups, which means that the relevant assessment are based on the ground truth of W3C people. In TREC 2006, both the topics creation and relevance assessments are accomplished by participants. 
Figure 1: The impact of varying the value of b in tuning the effect of effective expertise proportion (EEP) on query sets of These differences indicate that: firstly, finding working group member is a fundamentally differe nt task with finding people who are experts in an ad-hoc info rmational subject. Secondly, the pooling method implies that to some extent, the experts are judged by those non-expert assessors. The judgers cannot capture a comprehensive familiarity with all those candidates and their judgments are inevitably merely relied on those documents gathered in the pools. Besides the inaccuracy problem, it also brings another problem which may reduce the effect of EEP. Assessors may choose those candi dates who are very active like directors and supervisors of a department or an institute, where their names just appear in almost each document from that department. This situation cont radicts our assumption that to prefer those candidates who focus on the topic more. To demonstrate our statement that the CDD-based model is more effective than the document-centered model, we perform experiments to compare expert finding performances using the two models. The implementation of the contrastive document-centered experiment employs the traditional approach adopted by many document-centered systems mentioned in Section 1 with the following steps: (i) retrieve documen ts relevant to the query using traditional IR model, (ii) calculate the candidates X  expert degree using voting method among the returned documents. Several voting ways are attempted, we find the most effective scheme is to calculate the candidate X  X  score according to the ranking of the documents where he or she appears in step (i). 
Table 2. Comparative best results between CDD-based search Model 
Document-centered model 0.2201 0.3776 0.3903 0.5896 CDD-based model 0.2716 0.4091 0.5077 0.6128 Improve 23.4% 8.3% 30.1% 3.9% Table 2 shows the improvement of the CDD-based model upon the comparative document-centered model. The results illustrate a consistent and significant gap betw een the best results of the two models. We achieve the best pe rformance in TREC enterprise track 2005 and top 5 in TREC 2006. Among the participants during the two years, most approaches employ document-centered models. But we should note that in order to make a fair comparison it is important to take into account how others approached the task. First, unlik e most participants, we only use the Web pages part of the corpus and do not utilize other documents (such as mail lists), which is about half of the collection in amount. Further more, our models are unsupervised which means no manual efforts were made to increase the performance. In particular, we do not resort to some special treatment to the documents like some participants who adopt extraction according to the template of the W3C website. In this paper, we propose a candi date-centered formal model to solve the expert finding problem. The model is based on the view of representing knowledge of candidate by the evidence which is automatically extracted from an organization X  X  document repositories. Then we presented th ree basic heuristics determining the knowledge representation to de tail the model description and explore the strategies to extr act the expertise evidence. There is a lot of space for further improvement through more sophisticated strategies of expe rt evidence identification and extraction. Another issue is th at we could investigate the relationships between the knowledge presentations of candidates to build up a social network. And as another part of future work, our model can be extended to other object-centered vertical search fields such as software s earch, MP3 search and so on. This work was supported by the Chinese National Key Foundation Research &amp;Development Plan (2004CB318108), the Chinese Natural Science Foundation (60621062, 60503064) and the National 863 High Technology Project (2006AA01Z141). We would like to thank Ian Soboroff, Le Zhao, and the anonymous reviewers for th eir helpful suggestions. [1] N. Craswell, D. Hawking, Anne-Marie Vercoustre,Peter [2] Y. Fu, W. Yu, Y. Li, Y. Liu, M. Zhang, and S. Ma. THUIR at [3] K. S. Jones, S. Walker, and S. E. Robertson. A probabilistic [4] V. N. Vapnik, Statistical Learning Theory, John Wiley &amp; [5] TREC. Enterprise track, 2005 and 2006. URL: 
