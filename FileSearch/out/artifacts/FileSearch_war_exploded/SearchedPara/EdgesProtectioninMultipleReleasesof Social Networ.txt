 Nowadays, online social network sites, such as facebook, twitter and weibo, have received dramatic interest, more and more people join in various social networks. People use online social networks to share data, which produce lots of social network data. Using data mining methods to analyze social network data, you can get lots of meaningful results: to op timize the search engine in the social networks, to improve the existing social networks, to study the characteristics of social networks. If this data is directly exposed to researchers, it will cause the privacy disclosure, which leads us to study how to effectively anonymize so as to protect sensitive information in social networks while maximizing the social network X  X  utility analysis.

A social network can be modeled as a graph in which each node represents an individual, and the connections between individuals are summarized by the edges. Most of prior privacy protection techniques in social network data pub-lishing focus primarily on static social networks. However, one single snapshot is not useful for analyzing the evolution of social networks, such as how the pop-ularity of individuals changes or how a disease spreads over time. To support such analysis, privacy issues in multiple releases of social network data urgently need to be addressed.

In this paper, we consider how to protect edges between individuals in multiple releases of social network data. For example, figure 1 shows two snapshots of a dynamic social network at time t =0and t = 1. The graph G 0 evolves into G 1 after adding an edge and deleting an edge. Our focus is on the privacy of edges between individuals in dynamic social networks, so we do not study the privacy of nodes X  attributes.

Bhagat et al.[1] proposes edges protectio n for anonymizing a single graph. It masks the mapping via grouping the nodes of the graph. This technique retains the entire graph structure but perturbs the mapping from labels to nodes. Bhagat et al.[2] further use link prediction algorithms to model the evolution, however, the prediction graph could partly predict the newly added edges. Based on [1], Wang et al.[3] design a constraint in the grouping procedure, taking into account the effect of time to avoid revealing privacy with multiple releases. Both Bhagat et al.[2] and Wang et al.[3] assume edges and nodes are only added to the graph, not deleted. In this paper, graph model is extended to allow edges deletion, which is close to the evolution of social networks. In this work, we make the following contributions: 1. We solve the problem of edges deletion in dynamic edges protection. 2. We propose the Dynamic Safety Condition , which effectively constrains 3. We devise the heuristic algorithm DEP, which anonymizes a sequential graphs 4. We evaluate our approach on two real datasets.
 This paper is organized as follows. Section 2 gives the problem definition. Section 3 introduces the anonymized me thod. Section 4 reports experimental results. Section 5 presents the relat ed work. Section 6 concludes the paper. In this paper, a time-stamped social network is modeled as an undirected simple graph G t ( V t ,E t ,L t , L ), where V t is the set of nodes corresponding to the indi-viduals at time t , E t is the set of edges that represent the relationships between individuals at time t , L t is the set of labels at time t and a function L : V t  X  L t assigns each node a label. A label has an identity(such as user id or name), and a set of properties(such as age, gender and country). Let G = &lt;G 0 ,G 1 , ..., G T &gt; be the sequence of graphs representing the network observed at timestamps t =0 , 1 , ..., T respectively. We mainly solve the problem of edges deletion in the evolution of social networks. The operation of node deletion could also be treated as retaining the node and deleting all edges related to the node in our paper, so the quantity of nodes is always increased. Thus, we have V t  X  1  X  V t and L t  X  1  X  L t where t =1to T .Let G  X  i denotes the anonymized graph of G i at time t = i .

Given G and a constant k , the protection objectives guaranteed by this paper are: 1. For any edge e  X  E t , without background knowledge the probability that an 2. For any two nodes v x ,v y  X  V t , without background knowledge the probability To protect edges, [1] focuses on masking the mapping via grouping the nodes of the graph. They propose a Safety Condition that each node must interact with at most one node in any group and no edges exist in a group. [2] defines the Edge Identification which measures the likelihood of identifying an interaction. Both Safety Condition and Edge Identification ensure sparsity of interactions between nodes of any two groups, but Safety Condition is more restrictive than Edge Identification . Definition 1 (Safety Condition). A grouping of nodes in graph G ,satisfies the Safety Condition if Definition 2 (Edge Identification). Given a pair of groups of nodes, g x  X  V and g y  X  V , their Edge Identification EI ( g x ,g y ) is the ratio of the number of edges between the two groups to the maximum number of such edges In figure 2, G  X  0 and G  X  1 are the released graphs of original graphs in figure 1. They are respectively generat ed using the method in [1] with k = 2. Intersecting identified in the released graphs. Then, the adversary could conclude that there is a relationship between node 4 and node 7 in both G  X  0 and G  X  1 , which obviously violates privacy purposes. [3] applies the algorithm DMRA(Decreasing Multiple Releases Anonymization) in anonymizing dynamic social network data. This approach first anonymizes G
T , and then gradually produces G T  X  1 ,G T  X  2 , ..., G 0 . The same anonymized procedure is used in our paper. To protect deleted edges, we introduce the sup-plementary graph G T ,where V T = V T and E T =  X  T t =1 ( E t  X  1 \ E t )  X  E T .So the supplementary graph G T contains all the deleted edges in the evolution of social networks. For example, figure 3( a ) shows the following original graph G 2 at time t = 2, and figure 3( b ) shows the corresponding supplementary graph G 2 . Therefore, G 2 includes two deleted edges which are represented by dash lines in figure3( b ).
 3.1 Dynamic Safety Condition Definition 3 (Dynamic Safety Condition). Agroupingofnodes V t for the graph G t , satisfies the dynamic Safety Condition if  X   X  group g x ,g y , m is the number of edges between g x and g y ,m
Based on [3], we give the definition of Dynamic Safety Condition . The first condition requires that the nodes in one group are created at the same time,. The second condition constrains edges not exist in one group. The third condition limits the number of edges between any two groups.
 Theorem 1. If nodes partition satisfies Dynamic Safety Condition, the anonymized graphs can dynamically protect edges against attacks without back-ground knowledge.
 Proof. The first condition in Dynamic Safety Condition requires that the nodes in one group are created at the same time. Using this condition in our anonymized method, we constrain the size of groups in anonymized graphs is no less than k . Thus, without background knowledge the probability that an attacker can identify a node is at most 1 k . The second condition constrains edges not exist in one group. For each edge in our anonymized graphs, there are at least k candidate labels for the two endpoints of it. Thus, without back-ground knowledge the probability that an attacker can identify a node involved in an edge is at most 1 k . The third condition constrains the number of edges m between any two groups is no more than | g x || g y | k . Edge Identification is the probability an attacker can attach to a particular pair of users between any two groups. With respect to nodes partition, Edge Identification equals to knowledge the probability that an attacker can identify that there is an edge between two nodes is at most 1 k . Therefore, Dynamic Safety Condition can make our anonymized graphs sa tisfy privacy objectives. 3.2 The DEP Alogrithm The algorithm DEP has a similar structure as the algorithm in [3]. The input of DEP are a sequential original graphs G = &lt;G 0 ,G 1 , ..., G T &gt; , a supplementary graph G T and a parameter k . The output of DEP are a set of groups with size at puts all the nodes of G T into a NodeList and sorts the NodeList basedonthe properties of nodes X  label to enable nodes in a group have the similar values of the properties. Each time, we select a SeedNode from the NodeList and remove it from the list, and insert the SeedNode into the first group that has fewer than k nodes, if performing this insertion would not violate the Dynamic Safety Condition (line 4-11). If no group can be found which satisfies this condition, or all groups existed have at least k nodes, then a new group containing only SeedNode is created(line 12-14). For any group g which cannot reach size k ,we first delete this group from the group set. Then we take each node in g in turn, and insert it into the first group which size is no less than k under Dynamic Safety Condition (line 15-21). In some cases, there are no suitable groups for the insertion operation. We add ( k  X  X  g | ) noise nodes into g and randomly assign Algorithm 1. Dynamical Edges Prot ection (DEP) Algorithm labels to noise nodes following the label distribution in G T , then return g back to group set(line 23-26). After grouping, we assign the corresponding label list to each node according to its group in G T . Finally, we delete all edges in E T \ E T from G T to generate G  X  T , then we delete all nodes in V t \ V t  X  1 , all edges in E t = T to 1. 3.3 The Running Example Figure 4 shows the running example of anonymizing a sequential original graphs G = &lt;G 0 ,G 1 ,G 2 &gt; with k =2. Firstly, we establish the supplementary graph G 2 based on groups partition. Observing the Dynamic Safety Condition , V 2 is partitioned ing label list to each node according to its group in G 2 . Thirdly, we delete all edges in E 2 \ E 2 from G 2 to generate G  X  2 . Last, we delete all nodes in V 2 \ V 1 , all edges in E 2 \ E 1 and add edges in E 1 \ E 2 from G  X  2 to generate G  X  1 ,andalso generate G  X  0 in the same way .
 In this section, we conduct aggregate net work queries on two datasets. For each query, its relative error is | n  X  n | n .Where n and n are the results of the query on the original and anonymized graphs, respectively. In this paper, we test two kinds of queries based on [1, 3, 4]: 1. One hop query: The number of nod es pairs represented by a 4-tuple ( v 1 ,c 1 , 2. Two hops query: The number of nodes tuples represented by a 6-tuple ca-CondMat: This dataset shows a Condense Matter collaboration net-work which is built from the scientific co llaborations between authors X  papers from January 1993 to April 2003(available at http://snap.stanford.edu/data/ca-CondMat.htm). It contains 23,133 nodes and 186,936 edges. An undirected edge is created in the graph if two authors co-authored a paper. We use the Adult dataset from the UC Irvine Machine Learning Repository(available at http://archive.ics.uci.edu/ml/machine-learning-databases/adult/)to assign a la-bel to each node in the graph, and only consider a set of 3 properties: age, gender and country.

Speed Dating: This dataset is from a publicly available Speed Dating study conducted by Fisman et al.[5](availa ble at http://andr ewgelman .com/2008/01 /the speeddating 1/). After sanitizing the data, it contains 552 nodes and 4,184 edges. Each node is associated with 3 properties, such as age, gender and country, chosen from 21 properties in the original data. Each edge represents a dating between two participants.

To simulate the evolution of social networks, we respectively start with two datasets as G 0 , Next, we generate each subsequent graph G t from G t  X  1 for t =1 to 2. This simulation uses four evolution parameters a, b, c, d .Weset a as 5%, b as 10%, c as 20% and d as 10%. At each iteration, G t is evolved in four steps: 1. We randomly delete a | E t  X  1 | edges in G t  X  1 . 2. We create b | V t  X  1 | new nodes. For each new node, we assign a label from 3. We randomly create c | V t  X  1 | new edges between new nodes and nodes in G t  X  1 4. We randomly create d | E t  X  1 | new edges between nodes in G t  X  1 if there is no
We conduct 100 queries, and use the average relative query error to measure the utility of the anonymized graphs. We also consider a efficient sort order in [1] over the properties of nodes X  label : Country, Gender, and Age(CGA). In order to perform queries on the anonymized graphs with the label list, we use Sampling Consistent Graphs in [1] which are consistent with the anonymized graphs, and analyze the sampled graphs. As the anonymized methods in [2, 3] do not consider the situation of edges deletion, we couldn X  X  compare our results with them. Figure 5 and figure 6 show the average relative error of one hop queries and two hops queries respectively. It is easy to observ e that average relative error increases as k rises. This is because the increasing of k leads to more alternative labels for the nodes in the group. The result on one hop queries is better than that of two hops queries, as two hops queries use 2 conjunctions. Last, sorting the properties of nodes X  label is necessarily needed in our anonymized method. The problem of privacy protection in social networks is first proposed in [6], where the authors demonstrate that the naive anonymization strategy which replaces all identifiers of individuals with randomized integers is not sufficient by both active and passive attacks. In active attacks, an adversary maliciously plants a subgraph in the network before it is published and uses the knowledge of the planted subgraph to re-identify nodes and edges in the published network. In passive attacks, an adversary simply uses a small uniquely identifiable subgraph to infer the identity of vertices in the published network. However, they do not provide a solution to protect against these attacks.

In anonymizing social network data, there are two categories: clustering-based approaches and graph modification approaches. The clustering-based methods [1, 7 X 10] cluster nodes and edges into groups and anonymize a subgraph into a super-node. In this way, the details about individuals can be hidden properly. [7, 9] propose anonymizing a graph by partitioning the nodes and summarizing the graph at partition level. The critical difference is that the method in [9] takes into account both the generalization information loss and the structural infor-mation loss during the clustering procedure. Zheleva and Getoor[8] focuses on the case where there are multiple types of edges but only one type of nodes, and applies clustering-based method in protecting relationships disclosure. Cormode et al.[10] focuses on the problem of anonymizing bipartite graphs. Based on [10], Bhagat et al.[1] further constructs a mod el of the rich interaction graph, and proposes three approaches in protecting users X  rich interaction.

The graph modification methods[11 X 19] anonymize a graph by modifying(such as, adding and/or deleting) edges and nodes in a graph. Hay et al.[15] proposes an approach that obeys a rule of random edge additions and deletions in anonymiz-ing the graph, this method can effectively resist some kinds of attacks but suffers a significant cost in utility. Edge randomization techniques are further explored in [16], whose goal is to preserve the spectral properties of the graph. While the network utility is much improved, the effect on anonymity is not quantified. Liu et al.[17] perturbs the weights of some edges to retain the shortest path and the approximate cost of the path between some pairs of nodes in the original network. Liu and Terzi[14] first introduces the k -anonymity model from the relational data to the social network data, and proposes k -degree anonymity to protect each in-dividual in a group consisting of at least k nodes of the same degree. Zhou and Pei[13] proposes the stronger model that each individual in a group consisting of at least k nodes of the same degree and sharing 1-neighbourhood isomorphism. Zou et al.[18] proposes a k -automorphism model that each individual in a group consisting of at least k nodes without any structural difference. Cheng et al.[19] designs a k -isomorphism model that the anonymous graph consists of k disjoint isomorphic subgraphs to protect nodes and relationships. [11, 12] based on dif-ferent models apply l -diversity in protecting nodes re-identification and nodes X  sensitive attribute. In this paper, we protect edges in anonymizing multiple releases of social network data. We present the Dynamic Safety Condition and the heuristic algorithms DEP. The Dynamic Safety Condition constrains nodes partition to ensure sparsity of edges between any two group in the evolution of social networks. The DEP algorithm anonymizes a sequential graphs to satisfy the privacy objective. We prove the effectiveness of the proposed anonymized method through extensive experiments.
 Acknowledgment. This work is partially supported by the HGJ National Significant Science and Technology Projects under Grant No. 2012ZX01039-004-009, Key Lab of Information Network Security, Ministry of Public Security un-der Grant No.C11606, the National Natural Science Foundation of China under Grant No. 61170263.

