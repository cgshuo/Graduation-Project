 If we know that 5 out of 6 of Smith X  X  friends love to play tennis, what would you say about Smith X  X  main hobby? Same question, when we know that Johnson X  X  50 out of 60 friends love to play tennis -are we more confident about Smith, or about Johnson? Most people would be more confident in the latter case, despite the fact that the ratio of tennis-to-non-tennis friends, is the same in both cases. In this paper, we address the node classification problem on networks. Networks appear in numerous real-world applications, like social networks, citation net-works, and biological networks. Often, the nodes of these networks have labels : E.g., users in social networks have demographic attributes (gender, age bracket, applications, labels of a majority of nodes are often unavailable, which makes the node classification problem more important.
 labeled graph with labeled and unlabeled nodes, find correct labels of unlabeled nodes based on labeled nodes. Real-world applications of this setting are numer-and anomaly detection [ 9 ]. Here we propose SocNL, a semi-supervised learning (SSL) algorithm for the node classification problem. The SSL algorithm is one of the most promising algo-Similar to the other SSL algorithms, SocNL is also based on the smoothness hypothesis where a connected nodes tend to share a label. The main advan-tage of our algorithm is to provide the reliable confidence for each result Bayesian inference perspective, the more evidence we observe, the more confident the estimate is, which is the principle we adopt in this paper.
 The Main Idea and the Main Results. Figures 1(a) and 1(b) show our main idea. Suppose we have an example graph where nodes A and B are classified into conservative or liberal. As the intermediate result, SocNL can output the posterior distribution of the probability of being conservative for A and B shown in Figure 1(b) , which have different shapes. The important point is that the posterior of A has more focused peak than B because A gets more evidence from its neighbors. By taking the posterior into account, the final result of the probability of being conservative is 0.76 for A while 0.59 for B, which agrees with our intuition that A is more confidently conservative. This result is quite differ from the result by label propagation [ 15 ] that does not consider the amount of evidence, where both nodes are assigned the identical probability 0.86. Figure 1(c) shows our main result illustrating SocNL wins or ties in the first place against other methods on POKEC network (see details in Section 6 ). Contributions. Our contributions are summarized as follows: 1. Novel Algorithm : We propose a semi-supervised algorithm that is (a) simple ; it only requires solving a linear system, (b) fast ; each iteration of its recursive inference is linear on the input size and is proved to converge, and (c) provides reliable confidence ; it takes into account the amount of the evidence to provide the reliable confidence. 2. Theoretical Analysis : We show the solid theoretical foundation of our 3. Empirical Analysis : We perform extensive experiments on three different Outline. The rest of the paper is organized as standard: problem definition, algorithm description, theoretical analysis, empirical analysis, and conclusion. In this section, we overview the semi-supervised learning, which makes use of unlabeled data in addition to labeled data to improve the performance. Most of SSL algorithms are classified into the generative models, the low-density sep-aration, and the graph-based methods [ 5 ]. Here, we focus on the graph-based methods which our algorithm belongs to.
 Although these methods have achieved successful improvements, they do not consider the amount of evidence. This may cause some problems when we deal with the node classification. Because most of real-world networks have power law distributions [ 6 ] where a majority of nodes have a small number of neighbors, which means we cannot obtain sufficient evidence from neighbors.
 been proposed [ 7 , 8 , 11 ]. Fang et al. [ 7 ] proposed DGR (Dirichlet-based Graph Regularization) that assumes every node has a Dirichlet prior and propagates it along edges. Although DGR provides the posterior like our algorithm, it has to solve a optimization problem numerically for each iteration, indicating it does not scale so much. Orbach et al. [ 11 ] devised an algorithm called TACO (Transduction Algorithm with Confidence). TACO infers the label probability and the uncertainty of it simultaneously. Chen et al. [ 8 ] also proposed an SSL algorithm called ReLISH (Reliable Label Inference via Smoothness Hypothesis). ReLISH is also formulated as a convex optimization problem and has a clear closed-form solution. However, it requires O ( n 3 ) complexity, meaning it does not fit large scale networks.
 algorithms. Note that LP can also incorporate the prior knowledge, but it does not consider the amount of evidence, meaning that LP does not provide the reliable confidence (evaluated in Section 6 ). This section defines the terminologies and formulates the node classification problem. Table 2 gives the list of symbols. Let G =( V, E ) be a partially labeled graph where V is set of N nodes and E is set of M edges. The set of nodes is composed of two types of nodes. V L  X  V is a set of L labeled nodes whose labels are known, while V U = V \ V L is a set of U unlabeled nodes whose labels are unavailable. Let Y be the set of K possible labels, and Y the label assignments for the corresponding nodes in V L . Using these terminolo-gies, the node classification problem is formulated as follows: Problem 1 (Node Classification)  X  Given : a partially labeled graph G =( V, E )  X  Find : label probability f ij that node i has label j .
 value max k f ik for each node indicates how confident the result is, which is used in the experiments.
 In this section, we propose SocNL, a novel semi-supervised node classification algorithm. Similar to the other SSL algorithms, SocNL is also based on the smoothness hypothesis : connected nodes are likely to share a label. Also, we adopt Bayesian principle that the estimate is inherently uncertain and becomes the more confident if we observe the mode evidence. This principle is suitable to our problem because if a node has many neighbors, we can obtain much evidence to infer the label probability of that node. On the other hand, if we cannot obtain sufficient evidence (i.e., a small number of neighbors), the inference result is unreliable. To formulate these ideas, SocNL adopts the followings:  X  Label propagation : SocNL propagates labels from labeled nodes to unlabeled  X  Bayesian inference : SocNL assigns each node with the prior label probability 4.1 The Model In this section, we formulate the model. For now, let X  X  ignore the unlabeled neighbors of target node i for simplicity. What we want to do here is to infer neighbors  X  N i , where  X  y i is the predicted label of i .
 k |  X  )=  X  k where  X  is the parameter of the categorical distribution. According to the smoothness hypothesis, we believe that a neighbor of node i shares the same parameter  X  as i . Then we get the multinomial likelihood function of labels of neighbors of i as follows: where  X  ( y j ,k ) takes 1 if y j = k otherwise 0, and n ik number of i  X  X  neighbors whose label is k . Here we assume that labels of neigh-bors are i.i.d. As the conjugate prior of the multinomial distribution is Dirichlet distribution, let X  X  think that the prior of parameter  X  is Dirichlet distribution: these together, we get the posterior distribution as follows: tive distribution for node i  X  X  label as follows: where  X  0 = K k =1  X  k . By integrating out parameter  X  of the posterior distribu-tion, SocNL takes into account all the possible value of  X  rior. We name this solution Myopic baseline , which only uses labeled neighbors  X  N i of target node i . Algorithm 1. Iterative Algorithm 4.2 Iterative Algorithm In this section we develop our full algorithm, SocNL, which utilizes both labeled and unlabeled neighbors N i . In this case, we do not know  X  ( y nodes. Hence, instead of simply counting  X  ( y j ,k ), we calculate n where we use the adjacency matrix A . We can think that n expectation value of the number of i  X  X  neighbors with label k . For labeled nodes, we set P ( X  y j = k | N j )=  X  ( y j ,k ). Plugging Eqn 5 into Eqn 4 and using f P ( X  y = k | N i ), we get: Since this equation is in the recursive fashion, we devise an iterative algorithm to solve it.
 Hereafter, we formulate the matrix form of the iterative algorithm. Let row normalized N  X  K matrix. We write F L and F U as the upper L lower U  X  K sub-matrices of F , respectively. Also, we write same way. The subscript L and U mean that the sub-matrices correspond to the labeled nodes in V L and unlabeled nodes in V U , respectively. Recall that each labeled node has f ik =  X  ( y i ,k ), which corresponds to the components of Using the matrices defined thus far, we write the following assignment for-mula: where 1 is U dimensional column vector where each component is 1.
 U  X 
U diagonal matrix with diagonal component [ D U ] ii = j A prove in Section 5 , the iterative algorithm repeating this assignment formula always converges to the solution if  X  k &gt; 0 for all k , which corresponds to valid Dirichlet prior. The iterative algorithm of SocNL is shown in Algorithm 1 .All f of unlabeled nodes are initialized as arbitrary values. Note that SocNL is applicable to directed graphs without any modification of Algorithm 1 , where the adjacency matrix A is asymmetric.
 In this section, we show that SocNL has the solid theoretical foundation and connections to label propagation and Bayesian inference. All omitted proofs are shown in the appendix.
 Convergence and Complexity. Here we show the convergence guarantee, the convergence speed, and the complexity of SocNL.
 Theorem 1 . The iterative algorithm of SocNL always converges on arbitrary graphs if  X  k &gt; 0 for all k .
 Corollary 1 . The fixed point solution of SocNL is written as: where Proof . It follows directly from the proof of Theorem 1 (Appendix A). Theorem 2 . SocNL with prior strength  X  0 converges faster than SocNL with another prior strength  X  0 if  X  0 &gt; X  0 .
 Theorem 3 . The time complexity of SocNL is O ( hK ( N + M )) where h is the number of iterations.
 Connection to label propagation. Next, we show that LP is a special case of SocNL.
 Theorem 4 . The special case of SocNL with parameter  X  k =0 for all k is equivalent to LP.
 This means SocNL still works even if parameter  X  k = 0 for all k although it corresponds to invalid Dirichlet prior.
 Corollary 2 . SocNL converges faster than LP.
 Proof. It follows directly from Theorems 2 and 4 .
 Connection to Bayesian inference. As mentioned in Section 4 ,SocNLisa natural extension of Bayesian inference.
 Theorem 5 . SocNL is equivalent to Bayesian inference over Dirichlet com-pound multinomial if we ignore all the unlabeled neighbors of target node i . According to Theorems 4 and 5 , SocNL behaves as the bridge between label propagation and Bayesian inference. In this section, we report the empirical analysis of our algorithm to answer the following questions:  X  Q1 -Prior : How does the prior strength affect the performance of SocNL?  X  Q2 -Accuracy : How accurate SocNL is compared to LP and Myopic?  X  Q3 -Convergence : How fast does SocNL converge? Datasets. Three network datasets described in Table 3 are used in our experi-ments. Smoothness is the probability that a connected pair has the same label. Values in parentheses are the smoothness after performing randomization of labels. POLBLOGS is a blog-citation network where the labels are political leanings of blogs. COAUTHOR is a co-authorship network where node i and j are connected if they co-write a paper. Labels on this network are the research field of authors (DB, DM, ML, and AI). POKEC is a social network in Slovakia where node i has an out-going edge to node j if i follows j . Labels are home locations of users.
 Evaluation. We divide a set of labeled nodes into training nodes (30%), vali-dation nodes (35%), and test nodes (35%), where labels of validation nodes and test nodes are hidden. Validation nodes are used in Section 6.1 to validate the prior strength, and test nodes are used in Section 6.2 to compare the perfor-mance. We perform node classification to infer hidden labels. Then we report the precision@ p that is the precision of top p % of test (or validation) nodes ordered by the confidence value max k f ik .
 Reproducibility. The datasets we use in this paper are all available on the web as shown in Table 3 . Also, our code is available on our website 6.1 Q1 -Prior In this section we study how the prior strength affects the performance of SocNL. Throughout the experiments in this paper, we use the class mass ratio as the prior  X  k =  X L k /L where L k denotes the number of labeled nodes with label k and  X  is the prior strength parameter which equals to  X  0 results where we vary the prior strength  X  from 0 . 001 to 10.
 We can see that larger  X  results in well-calibrated confidence (i.e., higher precision at lower recall) but lower overall precision (right-most). For this reason we need to choose the correct value for  X  to get a good trade-off between them. We can see that larger  X  is needed to get well-calibrated confidence on POKEC network that has the relatively small smoothness. This is intuitive because if the smoothness is small, the data is not reliable and then we need more data to correctly update the prior, meaning that the large prior strength is needed. Observation 1 . Strong prior is needed for graphs with weak smoothness. This agrees with intuition: the higher the value of  X  0 , the more emphasis it implies on the priors and the less emphasis on the evidence from the graph. Thus, if we know there is weak smoothness, then we should use the large prior. From the results, we choose 0 . 1 for POLBLOGS and COAUTHOR, and 10 for POKEC as the best prior strength for the experiments in the next section. 6.2 Q2 -Accuracy Figure 3 shows the results, where we compare the accuracy of three algorithms. Myopic uses the same prior as SocNL. We can see that SocNL wins or ties in the first place on all networks. Specifically, LP shows low precision for  X  X onfident X  results (left) because LP does not consider the amount of evidence. According to the results in this section and the last section, we can say that SocNL performs better than LP on graphs with less smoothness (e.g., POKEC) because the larger prior strength is needed.
 not have enough labeled neighbors. On the other hand, our algorithm achieves higher precision than Myopic because SocNL can propagate the evidence from more than 1-step away. This result means that s imilar to other SSL algorithms, SocNL tolerates low label density (i.e., small fraction of labeled nodes). Observation 2 . SocNL outperforms LP and Myopic baseline on graphs with less smoothness and low label density. 6.3 Q3 -Convergence In this section, we compare the convergence speed of LP and SocNL with different  X  . Figure 4 shows the results where x-axis indicates the number of iterations and the y-axis indicates the error between F k U and F k  X  1 U SocNL converges faster if it uses the larger prior strength. Observation 3 . SocNL converges faster if it uses the larger prior strength. In this paper, we proposed SocNL, which addresses the node classification prob-lem on networks. Specifically, we studied how to provide the reliable confidence of the classification result. Our contributions in this paper are:  X  Novel Algorithm : we proposed a novel semi-supervised learning algorithm, called SocNL (Section 4 ).  X  Theoretical Analysis : SocNL provably converges, and has connections to label propagation and Bayesian inference (Section 5 ).  X  Empirical Analysis : experiments on three different real networks show that SocNL wins or ties in the first place (Section 6 ).
 Our future work includes investigating how to address the ordinal or numer-ical labels such as movie ratings and user locations as coordinates. We plan to study the other distributions for the model.
 A. Proof of Theorem 1 Proof . By rearranging Eqn 7 , we get: It directly leads to Since  X  0 &gt; 0 , the  X  -norm || P UU ||  X  = max i j | [ series n i =0 ( P UU ) i converges to ( I  X  P UU )  X  1 ,andalso lim which means SocNL converges.
 B. Proof of Theorem 2 Proof . Here, let  X  (  X  0 ) be the spectral radius of matrix strength  X  0 . According to Eqn 9 , larger  X  0 makes all the components of smaller, which means that all the eigenvalues of P UU become smaller. Hence, the in the faster convergence of the infinite series lim n  X  X  X  SocNL with  X  0 converges faster than SocNL with  X  0 .
 C. Proof of Theorem 3 Proof . In line 4 of Algorithm 1, the matrix multiplication needs O ( KM ) and the matrix addition requires O ( KN ) time. Putting together these operations, the time complexity of the iterative algorithm of SocNL is O ( hK ( N + M )) . D. Proof of Theorem 4 Proof . By setting the prior  X  k =0 for all k , we get: which is exactly the same fixed point solution of LP. E. Proof of Theorem 5 Proof . Ignoring all the unlabeled neighbors means that we discard all edges among unlabeled nodes, leading to A UU = O . Hence, the fixed point solution of SocNL becomes: The element-wise form is as follows: where we use f ik =  X  ( y i ,k ) for labeled nodes. This equation is the same as Eqn 4 , which is the solution for Bayesian inference.

