 Una Benlic, Jin-Kao Hao n 1. Introduction
The maximum cut problem (Max-Cut) is one of Karp X  X  21 NP-complete problems with numerous practical applications ( Karp, 1972 ). Let G  X  X  V , E  X  be an undirected graph with the set of vertices V and the set of edges E , each edge  X  i , j  X  A associated with a weight w ij . Max-Cut consists in partitioning the vertices of V into two disjoint subsets V 1 and V 2 such that the total weight of the edges whose endpoints belong to different subsets is maximized, i.e., f  X  V , V 2  X  X  max Given its theoretical and practical importance, Max-Cut has received considerable attention over the last decades. Well-known exact methods for Max-Cut, such as the Branch and Price procedure ( Krishnan and Mitchell, 2006 ), are capable of solving to optimality heuristic methods have been proposed including global equilibrium search ( Shylo and Shylo, 2010 ), projected gradient approach ( Burer and Monteiro, 2001 ), rank-2 relaxation heuristic ( Burer et al., 2002 ), and greedy heuristics ( Kahruman et al., 2007 ). Other well-known algorithms are based on popular metaheuristics such as variable neighborhood search ( Festa et al., 2002 ), tabu search ( Arra  X  iz and Olivo, 2009 ; Kochenberger et al., in press ), scatter search ( Mart X   X  et al., 2009 ), grasp ( Wang et al., in press ), and different hybrid approaches ( Festa et al., 2002 ; Wang et al., in press ).
In this work, we propose a new heuristic algorithm for Max-Cut, using the Breakout Local Search (BLS) ( Benlic and Hao, 2012, 2013 ).
Based on the framework of Iterated Local Search (ILS) ( Lourenco et al., 2003 ), BLS combines local search (i.e., the steepest descent) with a dedicated and adaptive diversification mechanism. Its basic idea is to use local search to discover local optima and employ adaptive perturbations to continually move from one attractor to another in the search space. The continual exploration of new search areas is achieved by alternating between random and directed, and weak and strong perturbations depending on the current search state. Despite its simplicity, BLS shows excellent performance on the set of well-known Max-Cut instances in terms of both solution quality and computational time. Out of 71 bench-mark instances, the proposed approach is capable of improving the previous best-known solutions in 34 cases and reaching the previous best-known results for 35 instances, within a computa-tional time ranging from less than 1 s to 5.6 h for the largest instance with 20,000 vertices.
 In the next section, we present in details the Breakout Local
Search approach for the Max-Cut problem. Section 3 shows extensive computational results and comparisons with the state-of-art Max-Cut algorithms. In Section 4 ,weprovideaparameter sensitivity analysis and justify the parameter settings used to obtain the reported results. Moreover, we investigate the efficiency of the proposed diversification mechanism of BLS, and highlight the importance of excluding diversification schemes during the local search phase. Conclusions are given in the last section. 2. Breakout Local Search (BLS)
Our Breakout Local Search (BLS) approach is conceptually rather simple and transits from one basin of attraction to another basin by a combined use of local search (to reach local optima) and dedicated perturbations (to discover new promising regions). Algorithm 1. The Breakout Local Search for the Max-Cut problem. Require : Graph G  X  X  V , E  X  , initial jump magnitude L 0 number T of non-improving attractors visited before strong perturb.
 Ensure : A partition of V . 1: C  X  generate _ initial _ solution  X  V  X  / n C is a partition of V into two subsets V 1 and V 2 n / 2: f c  X  f  X  C  X  / n f c Records the objective value of the solution n / 4: f best  X  f c / n f best Records the best objective value reached so 5: C p  X  C / n C p Records the solution obtained after the last 8: while stopping condition not reached do 9: Let m be the best move m eligible for C 10: while f  X  C m  X  4 f  X  C  X  do 11: f c  X  f  X  C m  X  / n Records the objective value of the 12: C  X  C m / n Perform the best-improving move n / 14: H  X  Iter  X  g / n Update tabu list , g is the tabu tenure n / 15: Iter  X  Iter  X  1 16: end while 17: if f c 4 f best then 20: else 21: o  X  o  X  1 22: end if 24: if o 4 T then 25: / n Search seems to be stagnating, random perturbation 26: o  X  0 27: end if 28: if C  X  C p then 29: / n Search returned to previous local optimum , increase 30: L  X  L  X  1 31: else 32: / n Search escaped from the previous local optimum, 33: L  X  L 0 34: end if 36: C p  X  C 37: C  X  Perturbation  X  C , L , H , Iter , o  X  / n Section 2.3.1 n / 38: end while
Recall that given a search space S and an objective function f ,a neighborhood N is a function N : S -P  X  S  X  that associates to each solution C of S a subset N ( C )of S . A local optimum C n with respect to the given neighborhood N is a solution such that 8 C 0 f  X  C n  X  Z f  X  C 0  X  , where f is the maximization function. A basin of attraction of a local optimum C n can be defined as the set B solutions that lead the local search to the given local optimum C n , local optimum C n acts as an attractor with respect to the solutions B , the terms attractor and local optimum will be used inter-changeably throughout this paper. Notice that in practice, for a given solution C , a neighboring solution C 0 is typically generated by applying a move operator to C . Let m be the move applied to C , we use C 0  X  C m to denote the transition from the current solution C to the new neighboring solution C 0 .

BLS follows the general scheme of iterated local search ( Lourenco et al., 2003 ) and alternates between a local search phase, which uses the steepest descent ( Papadimitriou and Steiglitz, 1998 ) to discover an attractor, and a perturbation phase, which guides the search to escape from the current basin of attraction. The general BLS algorithm is shown in Algorithm 1 .
After generation of an initial solution (line 1) and an initializa-tion step (lines 2 X 7), BLS applies the steepest descent to reach a local optimum (lines 9 X 16). Each iteration of this local search procedure identifies the best move m among those that are applicable to the current solution C , and applies m to C to obtain a new solution which replaces the current solution (lines 9 X 12). Updates are performed to reflect the current state of the search (lines 13 X 22). In particular, if the last discovered local optimum is better than the best solution found so far (recorded in C is updated with the last local optimum (lines 17 X 18). If no improving neighbor exists, local optimality is reached. At this point, BLS tries to escape from the basin of attraction of the current local optimum and to go into another basin of attraction. For this purpose, BLS applies a number L of dedicated moves to the current optimum C (we say that C is perturbed, see Section 2.3 for details). Each time an attractor is perturbed (line 37), the perturbed solution becomes the new starting point for the next round of the local search procedure (a new round of the outer while structure, line 8). The algorithm stops when a prefixed condition is satisfied. This can be, for example, a cutoff time, an allowed maximum of iterations or a target objective value to be attained. In this paper, an allowed maximum of iterations is used (see Section 3 ).

To determine the most appropriate perturbation (its type and magnitude), we distinguish two situations. First, if the search returns to the immediate previous attractor (recorded in C perturbs C more strongly by increasing the number of perturba-tion moves L to be applied (lines 28 X 30). Otherwise (i.e., the search succeeded in escaping from the current attractor), the number of perturbation moves L is reduced to its initial value L ( L 0 is a parameter). Second, if the search cannot improve the best solution found so far after visiting a certain number T ( T is a parameter) of local optima, BLS applies a significantly stronger perturbation in order to drive definitively the search towards a new and more distant region in the search space (lines 24 X 27).
The success of the described method depends basically on two key factors. First, it is important to determine the number L of perturbation moves (also called  X  X  X erturbation strength X  X  or  X  X  X ump magnitude X  X ) to be applied to change or perturb the solution. Second, it is equally important to consider the type of perturba-tion moves to be applied. While conventional perturbations are often based on random moves, more focused perturbations using dedicated information could be more effective. The degree of diversification introduced by a perturbation mechanism depends both on the jump magnitude and the type of moves used for perturbation. If the diversification is too weak, the local search has greater chances to end up cycling between two or more locally optimal solutions, leading to search stagnation. On the other hand, a too strong diversification will have the same effect as a random restart, which usually results in a low probability of finding better solutions in the following local search phase. For its perturbation mechanism, the proposed BLS takes advantage of the information related to the search status and history. We explain the perturbation mechanism is Section 2.3 . 2.1. The neighborhood relations and its exploration
For solution transformations, BLS employs three distinct move operators (moves for short) M 1 M 3 whose basic idea is to generate a new cut C by moving vertices to the opposite partition subset. To define these move operators, we first introduce the notion of move gain which indicates how much a partition is improved, according to the optimization objective, if a vertex is moved to another subset. For each vertex v A V , we determine the gain g v of moving v to the opposite partition subset. As we show in Section 2.2 , the vertex with the (best) highest gain can be easily determined using a special bucket data structure that has been extensively used to the related (and different) graph partitioning problem.

Given a partition (cut) C  X f V 1 , V 2 g , the three move operators are defined as follows: M : Select a vertex v m with the highest gain. Move the selected vertex v m from its current subset to the opposite partition subset.
 M : Select a highest gain vertex v 1 from V 1 and a highest gain vertex v 2 from V 2 . Move v 1 to V 2 , and v 2 to V 1 . M : Randomly select a vertex v . Move the selected vertex v from its current subset to the opposite partition subset.

Each iteration of the local search consists in identifying the best move m from M 1 and applying it to C to obtain a new solution. This process is repeated until a local optimum is reached (see lines 9 X 16 of Algorithm 1). The two directed perturbations of BLS apply a move m from M 1 and M 2 respectively, while the strong perturbation, which acts as a restart, performs a move from M 3 (see Section 2.3.1 for the three perturbation strategies). 2.2. Bucket sorting
To ensure a fast evaluation of the neighboring moves, our implementation uses the bucket sorting data structure which keeps vertices ordered by their gains. This structure is used to avoid unnecessary search for the highest gain vertex and to minimize the time needed for updating the gains of vertices affected by each move.

The bucket sorting structure was first proposed by Fiduccia and Mattheyses ( Fiduccia and Mattheyses, 1982 ) to improve the
Kerninghan X  X in algorithm ( Kernighan and Lin, 1970 ) for the minimum graph bisection problem. We adopt this technique for our Max-Cut problem. The idea is to put all the vertices with the same gain g in a bucket that is ranked g . Then, to determine a vertex with the maximum gain, it suffices to go to the non-empty bucket with the highest rank, and select a vertex from the bucket.
After each move, the bucket structure is updated by recomputing gains of the selected vertex and its neighbors, and transferring these vertices to appropriate buckets.

The bucket data structure consists of two arrays of buckets, one for each partition subset, where each bucket of an array is represented by a doubly linked list. An example of the bucket data structure is illustrated in Fig. 1 . The arrays are indexed by the possible gain values for a move, ranging from g max to g min
A special pointer maxgain points to the highest index in the array whose bucket is not empty, and thus enables to select the best improving move in constant time. The structure also keeps an additional array of vertices where each element (vertex) points to its corresponding vertex in the doubly linked lists. This enables a direct access to the vertices in buckets and their transfer from one bucket to another in constant time.

Each time a move involving a vertex v is performed, only the gains of the vertices adjacent to v are recalculated (in O  X  1  X  ) and updated in the bucket structure in constant time (delete and insert operations in the bucket are both of O  X  1  X  complexity).
Therefore, the complexity of moving vertex v from its current subset to the opposite subset is upper-bounded by the number of vertices adjacent to v . 2.3. Adaptive perturbation mechanism
The perturbation mechanism plays a crucial role within BLS since the local search alone cannot escape from a local optimum.
BLS thus tries to move to the next basin of attraction by applying a weak or strong, directed or random perturbation depending on the state of the search (lines 23 X 37 of Algorithm 1). The pseudo-code of this adaptive perturbation-based diversification proce-dure is given in Algorithms 2 and 3 .

The perturbation procedure ( Algorithm 2 ) takes as its input the following parameters: the current solution C which will be perturbed, the jump magnitude L determined in the main BLS algorithm (Algorithm 1, lines 30 and 33), the tabu list H , the global iteration counter Iter and the number of consecutive non-improving local optima visited o . Based on these information, the perturbation procedure determines the type of moves to be applied. The perturbation moves can either be random or direc-ted. First, if the search fails to update the best solution after consecutively visiting a certain number T of local optima (indi-cated by o  X  0, Algorithm 2 ), the search is considered to be trapped in a non-promising search-space region and a strong perturbation is applied ( Algorithm 2 , line 3) which basically displaces randomly a certain number (fixed by the jump magni-tude L ) of vertices from one side of the two-way partition to the other side. Here no constrained is imposed on the choice of the displaced vertices and any vertex can take part in this perturbation process. We will explain this random perturbation in Section 2.3.1 .

Second, if the number of consecutively visited local optima does not exceed the threshold T , we will allow the search to explore the current search region more thoroughly by adaptively choosing between weaker (directed) and random (stronger) perturbation moves (the adaptive mechanism is described in
Section 2.3.1 ). Basically, the directed perturbation is more oriented towards search intensification than a random perturba-tion, since perturbation moves are chosen by also considering the quality criterion so as not to deteriorate too much the current solution. Two different types of directed perturbation moves are distinguished with BLS and are explained in the next section.
Once the type of perturbation is determined, BLS modifies the current solution C by applying to it L perturbation moves which are chosen from the corresponding set of moves defined in the next section ( Algorithm 3 ). Notice that as in the case of moves performed during the local search phase, perturbation moves are added into the tabu list to avoid reconsidering them for the next g iterations ( Algorithm 3 , line 4, see also Section 2.3.1 ). The perturbed solution is then used as the new starting point for the next round of the local search.
 Require : Local optimum C , jump magnitude L , tabu list H , global iteration counter Iter , number of consecutive non-improving local optima visited o .
 Ensure : A perturbed solution C . 1: if o  X  0 then 3: C  X  Perturb  X  C , L , B  X  / n Random perturb. with moves from 4: else 5: Determine probability P according to Formula (2) / n 6: With probability P n Q , C  X  Perburb  X  C , L , A 1  X  7: With probability P  X  1 Q  X  , C  X  Perturb  X  C , L , A 8: With probability  X  1 P  X  , C  X  Perturb  X  C , L , B  X  9: end if 10: Return C Algorithm 3. Perturbation operator Perburb  X  C , L , M  X  . Require : Local optimum C , perturbation strength L , tabu list
H , global iteration counter Iter , the set of perturbation moves M .

Ensure : A perturbed solution p . 1: for i :  X  1to L do 2: Take move m A M 3: C  X  C m 4: H  X  Iter  X  g / n Update tabu list , g is the tabu tenure n / 6: Iter  X  Iter  X  1 7: end for 8: Return C 2.3.1. The perturbation strategies
As mentioned above, BLS employs two types of directed perturbations and a random perturbation to guide the search towards new regions of the search space.

Directed perturbations are based on the idea of tabu list from tabu search ( Glover and Laguna, 1997 ). These perturbations use a selection rule that favors the moves that minimize the degrada-tion of the objective, under the constraint that the moves are not prohibited by the tabu list. Move prohibition is determined in the following way. Each time a vertex v is moved from its current subset V c , it is forbidden to place it back to V c for g iterations (called tabu tenure), where g takes a random value from a given range.

The information for move prohibition is maintained in the tabu list H where the i th element is the iteration number when vertex i was last moved plus g . The tabu status of a move is neglected only if the move leads to a new solution better than the best solution found so far (this is called aspiration in the terminology of tabu search). The directed perturbations rely thus both on (1) history information which keeps track, for each move, the last time (iteration) when it was performed and (2) the quality of the moves to be applied for perturbation in order not to deteriorate too much the perturbed solution.

The eligible moves for the first type of directed perturbation (applied in Algorithm 2 line 6) are identified by the set A that A  X f m 9 m A M 1 , max f g m g ,  X  H m  X  g  X  o Iter or  X  g m where g m is the gain for performing move m (see Sections 2.1 and 2.2 ), f c the objective value of the current solution, and f objective value of the best found solution. Note that the first directed perturbation considers a subset of eligible moves obtained by applying the move operator M 1 (see Section 2.1 ).
The second type of directed perturbation (applied in Algorithm 2, line 7) is almost the same as the first type. The only difference is that the second directed perturbation considers eligible moves obtained with the move operator M 2 (see Section 2.1 ). These moves are identified by the set A 2 such that A  X f m 9 m A M 2 , max f g m g ,  X  H m  X  g  X  o Iter or  X  g m
Finally, the random perturbation , consists in performing ran-domly selected moves (i.e., M 3 from Section 2.1 ). More formally, moves performed during random perturbation are identified by the set B such that B  X f m 9 m A M 3 g :
Since random perturbations can displace any vertex of the partition without constraint, the quality of the resulting solution could be severely affected. In this sense, this perturbation is significantly stronger than the directed perturbations.
As soon as a search stagnation is detected, i.e., the best found solution has not been improved after consecutively visiting T local optima, BLS applies moves of random perturbation in order to drive the search towards distant regions of the search space (lines 1 X 3 of Algorithm 2). Otherwise, BLS applies probabilistically these three types of perturbations. The probability of applying a particular perturbation is determined dynamically depending on the current number of consecutive non-improving attractors visited (indicated by o in Algorithm 1). The idea is to apply more often directed perturbations (with a higher probability) at the beginning of the search, i.e., as the search progresses towards improved new local optima (the non-improving consecutive counter o is small). With the increase of o , the probability of using directed perturbations progressively decreases while the probability of applying random moves increases for the purpose of a stronger diversification.

Additionally, it has been observed from an experimental analysis that it is often useful to guarantee a minimum of applications of a directed perturbation. Therefore, we constraint the probability P of applying directed perturbations to take values no smaller than a threshold P 0 P  X 
P 0 otherwise ( where T is the maximum number of non-improving local optima visited before carrying out a stronger perturbation.

Given probability P of applying directed perturbation, the probability of applying the first and the second type of directed perturbation is determined respectively by P Q and P  X  1 Q  X  where Q is a constant from  X  0 , 1 (see Algorithm 2). BLS then generates a perturbed solution by applying accordingly the perturbation operator to make the dedicated moves from the sets A , A or B (see Algorithm 3).

In Section 4.2 , we provide an experimental study showing the influence of this perturbation strategy on the performance of our search algorithm. 2.4. Discussion
The general BLS procedure combines some features from several well-established metaheuristics: iterated local search ( Lourenco et al., 2003 ), tabu search ( Glover and Laguna, 1997 ) and simulated annealing ( Kirkpatrick et al., 1983 ). We briefly discuss the similarities and differences between our BLS approach and these methods.

Following the general framework of ILS, BLS uses local search to discover local optima and perturbation to diversify the search. However, BLS distinguishes itself from most ILS algorithms by the combination of multiple perturbation strategies triggered accord-ing to the search status, leading to variable levels of diversifica-tion. Moreover, with BLS each locally optimal solution returned by the local search procedure is always accepted as the new starting solution no matter its quality, which completely elim-inates the acceptance criterion component of ILS.

A further distinction of BLS is the way an appropriate pertur-bation strategy is selected at a certain stage of the search. As explained in Section 2.3.1 , BLS applies a weak perturbation with a higher probability P as long as the search progresses towards improved solutions. As the number of consecutively visited non-improving local optima o increases, indicating a possible search stagnation, we progressively decrease the probability for a weak perturbation and increase the probability for a strong perturba-tion. The idea of this adaptive change of probability finds its inspiration from simulated annealing and enables a better bal-ance between an intensified and diversified search.

To direct the search towards more promising regions of the search space, BLS employs perturbation strategies based on the notion of tabu list that is borrowed from tabu search. Tabu list enables BLS to perform perturbation moves that do not deterio-rate too much the solution quality in a way that the search does not return to the previous local optimum. However, BLS does not consider the tabu list during its local search (descent) phases while each iteration of tabu search is constrained by the tabu list.
As such, BLS and tabu search may explore different trajectories during their respective search, leading to different local optima. In fact, one of the keys to the effectiveness of BLS is that it completely excludes diversification during local search, unlike tabu search and simulated annealing for which the intensification and diversification are always intertwined. We argue that during local search, diversification schemes may not be relevant and the compromise between search exploration and exploitation is critical only once a local optimum is reached. Other studies supporting this idea can be found in Battiti and Protasi (1996) and Kelly et al. (1994) . We show computational evidences to support this assumption in Section 4.2.2 .

As we will see in the next section, BLS is able to attain highly competitive results on the set of well-known benchmarks for the Max-Cut problem in comparison with the state of the art algorithms. 3. Experimental results
In this section, we report extensive computational results of our BLS approach and show comparisons with some state of the art methods of the literature. We conduct our experiments on a set of 71 benchmark instances that has been widely used to evaluate Max-Cut algorithms. These instances can be downloaded from http://www.stanford.edu/ yyye/yyye/Gset/ and include toroidal, planar and random graphs, with the number of vertices ranging from 9 V 9  X  800 to 20,000, and edge weights of values 1, 0, or 1. 3.1. Parameter settings and comparison criteria
The parameter settings of BLS used in our experiments are given in Table 1 . These parameter values were determined by performing a preliminary experiment on a selection of 15 pro-blem instances from the set of the first 54 graphs (G1 X  X 54).
In this experiment, we tested different values for each of the five parameters ( L 0 , T , f , P 0 and Q ), while fixing the rest of the parameters to their default values given in Table 1 .In Section 4.1 , we provide a parameter sensitivity analysis and justify the setting of parameters that is used to obtain the reported results.
Given its stochastic nature, we run our BLS approach 20 times on each of the 71 benchmark instances, each run being limited to 200 , 000 9 V 9 iterations where 9 V 9 is the number of vertices in the given graph instance. The assessment of BLS performance is based on two comparisons: one is against the best-known results ever reported in the literature and the other is against four state of the art methods. In addition to information related to the quality criteria (best objective values, average objective values and standard deviation), we also show computing times for indicative purposes. Our computing times are based on a C  X  X  implementa-tion of our BLS algorithm which is compiled with GNU gcc under
GNU/Linux running on an Intel Xeon E5440 with 2.83 GHz and 2 GB. Following the DIMACS machine benchmark, 1 our machine requires 0.23 CPU seconds for r300.5, 1.42 CPU seconds for r400.5, and 5.42 CPU seconds for r500.5.

It should be noted that a fully fair comparative analysis with the existing Max-Cut algorithms from the literature is not a straight-forward task because of the differences in computing hardware, programming language, termination criterion, etc. For this reason, the evaluation is mainly based on the best-known results obtained with different state of art Max-Cut algorithms ( Table 2 ). The comparison with individual algorithms is presented only for indicative purposes and should be interpreted with caution ( Table 3 ). Nevertheless, our experimental study provides interesting indications about the performance of the proposed
BLS algorithm relative to these state of the art approaches. 3.2. Comparisons with the current best-known solutions
Table 2 summarizes the computational results of BLS on the set of 71 Max-Cut instances (G1 X  X 81) in comparison with the current best-known results (column f prev ) which are from refer-2009 ; Shylo and Shylo, 2010 ; Wang et al., in press ). For BLS, we report the best objective value f best , the average objective value f , the standard deviation s , and the average CPU time in seconds required for reaching f best over 20 executions. The results from Table 2 show that BLS is able to improve the previous best-known results for 34 instances, 2 and reach the best-known solution in 35 cases. As far as we know, solutions for the two largest Max-Cut instances (G77 and G81) have not been reported in the literature. However, for future comparisons, we include in
Table 2 the result obtained by BLS for these two instances. As for the computing time required to reach its best solution from column f best , BLS takes on average a time ranging from less than 1 s to 10 min for instances with up to 3000 vertices. For the large and very large instances with 5000 X 20,000 vertices, the comput-ing time needed goes from 0.2 to 5.6 h. 3.3. Comparisons with the current best performing approaches
To further evaluate the performance of BLS, we compare it with the following algorithms that achieve state-of-art performance: 1. Two very recent GRASP-Tabu search algorithms ( Wang et al., in press )  X  a GRASP-Tabu Search algorithm working with a single solution (GRASP-TS) and its reinforcement (GRASP-TS/
PM) by a population management strategy. The reported results were obtained on a PC running Windows XP with
Pentium 2.83 GHz CPU and 2 GB RAM (the same computing platform as the one we used). 2. Scatter search (SS) ( Mart X   X  et al., 2009 )  X  an advanced scatter search incorporating several inovative features. The evaluation of SS was performed on a machine with a 3.2 GHz Intel Xenon processor and 2 GB of RAM (a comparable computer as that we used). 3. Rank-2 relaxation heuristic (CirCut) ( Burer et al., 2002 )  X  a method based on a relaxation of the problem. The results reported in this paper for CirCut were obtained under the same conditions as that of SS and are taken from Mart X   X  et al. (2009) . Since large Max-Cut instances (G55 X  X 81) are very rarely used in the literature for algorithm evaluation, we limit this comparison to the first 54 Max-Cut instances which are also the most commonly used in the past.

Table 3 provides the results of this comparison with the four reference approaches. For each approach, we report the percen-tage deviation r from the best-known solution (column f prev objective value attained by a given approach. Moreover, we show for each algorithm the required average time in seconds, taken from the corresponding papers.

GRASP-TS/PM is one of the current most effective algorithm for the Max-Cut problem, which attains the previous best-known result for 41 out of 54 instances, with an average percentage deviation of 0.048. GRASP-TS also provides excellent performance on these instances, compared to the current state-of-art Max-Cut heuristics. It is able to reach the previous best-known solution for 22 instances with an average percentage deviation of 0.199. The other two popular Max-Cut approaches, SS and CirCut, can obtain the previous best-known result in 11 and 12 cases respectively, with an average percentage deviation of 0.289 and 0.339.
The results from Table 3 show that BLS outperforms the four reference algorithms in terms of solution quality. Indeed, the average percentage deviation of the best results obtained with BLS is 0.066, meaning that BLS improves on average the best-known result by 0.066%. Moreover, BLS also seems to be highly competitive with other approaches in terms of computing time. The average run-time required by BLS for the 54 instances is 176 s, which is significantly less than the average time required by the four reference approaches, considering that the reported results were obtained on comparable computers.

To see whether there exists significant performance difference in terms of solution quality among BLS and the reference algo-rithms, we apply the Friedman non-parametric statistical test followed by the Post-hoc test on the results from Table 3 . From the Friedman test, we observe that there is a significant perfor-mance difference among the compared algorithms (with a p -value less than 2.2e 16). Moreover, the Post-hoc analysis shows that BLS statistically outperforms GRASP-TS, SS and CirCut with p -values of 7.081000e 09, 9.992007e 16 and 0.000000e  X  00 respectively. However, the performance between BLS and GRASP-TS/PM is statistically less significant with a p -value of 9.547157e 02. 4. Experimental analyses 4.1. Parameter sensitivity analysis
The performed parameter sensitivity analysis is based on a subset of 15 selected Max-Cut instances from the set of the first 54 graphs (G1 X  X 54). For each BLS parameter (i.e., L 0 , T , f , P Q ), we test a number of possible values while fixing the other parameters to their default values from Table 1 . We test values for L P in the range [0.5, 0.9] and Q in the range [0.2, 0.8]. Similarly, for the tabu tenure f we tried several ranges which induce increas-ingly larger degrees of diversification into the search. For each instance and each parameter setting, we perform 20 independent runs with the time limit per run set to 30 min.
We use the Friedman statistical test to see whether there is any difference in BLS performance, in terms of its average result, when varying the value of a single parameter as mentioned above. The Friedman test shows that there is no statistical difference in the performance (with p -value 4 0 : 8) when varying respectively the values of T , f ,and Q . This implies that these three parameters exhibit no particular sensitivity. On the other hand, when varying values of parameters L 0 and P 0 respectively, the Friedman test revealed a statistical difference in performance with p -value  X  0.006906 and p -value  X  0.005237. We thus perform the Post-hoc test on these solution sets obtained respectively with different settings of para-meters L 0 and P 0 . The results of these analyses are provided in Tables 4 and 5 for L 0 and P 0 respectively, where each table entry shows the p -value for two sets of average results obtained with two different values of the corresponding parameter.

From the results in Table 4 for L 0 , we observe that for any two tested values of L 0 the p -value is generally significant (often p -value 4 0 : 5), except in 4 cases when the p -value o 0 : 05. This implies that L 0 is not highly sensitive to different settings. However, the analytical results from Table 5 show that P 0 even less sensitive than L 0 . Indeed, the p -value for two solution sets obtained with different values of P 0 is often very close to 1.
Only in 2 cases, the difference is statistically significant (with p -value o 0 : 01).

To further investigate the performance of BLS with different values for L 0 and P 0 , we show in Figs. 2 and 3 the box and whisker plots which indicate, for each tested parameter value, the dis-tribution and range of the obtained results for the 15 used instances. For the sake of clarity, these results are expressed as the percentage deviation of the average result from the best-known solution f best reported in the literature.

From the box and whisker plot in Fig. 2 , we observe a visible difference in the distribution of results among the data sets obtained with different settings of parameter L 0 . For the set of results generated with small values of L 0 r 0 : 01 9 V 9 indicates a significantly smaller variation compared to the results obtained with larger values of L 0 . For instance, the comparison between the two sets of results, obtained with L 0  X  0 : 01 deviations of the results from S 1 and S 2 range from 0.25% to 0.07% and from 0.45% to 0.5% respectively. More precisely, around 25% of the results from S 2 have a lower percentage deviation from f best than any of the result from S 1 , while another 37% of the results from S 2 have a higher percentage deviation from f best than any of the result from S 1 . We can thus conclude the deviations from the best-known result does not vary much from one instance to another.

From the box and whisker plot in Fig. 3 , we observe that the difference in the distribution and variation of results among the solution sets generated with different settings of parameter P less evident than in Fig. 2 . This confirms our previous observa-tions from the Post-hoc analysis that P 0 is slightly less sensitive than L 0 . 4.2. Influence of diversification strategies: comparisons and discussions
The objective of this section is twofold. First, we wish to highlight the contribution of the proposed diversification mechanism to the overall performance of the BLS method. In Section 4.2.1 , we thus provide a statistical comparison between several variants of BLS integrating different perturbation mechan-isms. Second, we try to justify our statement made in Section 2.4 that diversification schemes are crucial only once a local optimum is reached and should be excluded during local search. For this purpose, we provide in Section 4.2.2 a comparison with tabu search and iterated tabu search (ITS) methods which, because of the tabu list, induce a certain degree of diversification at each iteration. These two methods are obtained with minimal changes of our BLS algorithm.

We perform the comparisons using the set of the 54 Max-Cut instances (G1 X  X 54). In every experiment and for each instance, the reported results are obtained under the same conditions, i.e., after 20 independent executions with the maximum time limit per run set to 30 min. 4.2.1. Comparison with different variants of the perturbation mechanism
In this section, we perform a comparison between several versions of our algorithm, which employ different diversification strategies to escape local optima. The first version of the diversi-fication mechanism (call it V 1 ) is based solely on random moves of type M 3 (from the set of moves B , see Section 2.3.1 ). The second version (call it V 2 ) adaptively switches between the directed perturbation, which performs moves of type M 1 from the set A (see Section 2.3.1 ), and the random perturbation. The third version (call it V 3 ) integrates a diversification strategy that combines the two types of directed perturbations, which effec-tuate respectively moves from the set A 1 (moves of type M the set A 2 (moves of type M 2 ). The last version is our default BLS algorithm detailed in Section 2 . Note that the strongest diversi-fication is induced by V 1 since only random moves are considered for perturbation. On the other hand, the weakest diversification is introduced with V 3 since all the perturbation moves consider the quality criterion so as not to degrade too much the resulting solution.

The results of this experiment are shown in Table 6 . Columns f and f avg provide respectively the best and average results obtained by each algorithm. The results indicate that the three algorithms, i.e., V 2 , V 3 and default BLS, clearly outperform algo-rithm V 1 which combines the descent local search with the most basic perturbation mechanism based on random moves. More precisely, the best results reported in columns f best indicate that our default BLS algorithm reports a better solution than V out of the 54 instances and attains the same result as V 1 other 18 instances. However, the difference between V 2 , V the default BLS is much less obvious. Indeed, we observe from columns f best that the default BLS outperforms V 2 and V 5 and 6 cases respectively (out of 54), and is outperformed on 4 and 5 instances respectively. To see whether there is a statistically significant difference in average results (from column f ) obtained by the four algorithms, we perform the Friedman test followed by the Post-hoc test. The Friedman test revealed a significant difference with the p -value o 2 : 2 e 16. As expected, the Post-hoc test showed a significant difference between the sets of average solutions obtained with V 1 and the default BLS algorithm with the p -value of 0.000000e  X  00. Moreover, the Post-hoc test showed that the default BLS algorithm statistically outperforms V 2 in terms of average performance with the p -value of 1.701825e 03. However, there is no statistical difference in average performance between V 3 and the default BLS algorithm with the p -value of 7.734857e 01. From Table 6 , we observe that V outperforms the three other algorithms, in terms of average results, for a number of small instances (i.e., G1 X  X 10). This implies that the weakest diversification insures the best perfor-mance for these instances. On the other hand, the default BLS algorithm provides better average results than V 3 for a number of more difficult instances (e.g., G36 X  X 42, G51 X  X 54).

To conclude, the directed perturbation, which uses dedicated information, is more beneficial than the random perturbation for the tested Max-Cut instances. Nevertheless, for some difficult instances, an even better average performance with BLS is obtained when combining perturbation strategies that introduce varying degrees of diversification into the search process. 4.2.2. Comparison with tabu search (TS) and iterated tabu search (ITS)
As previously mentioned, one of the keys to the effectiveness of BLS is that it completely excludes diversification during its local search phase. Indeed, the descent phases of BLS are carried out by moves that are selected by considering only the quality criterion.
To provide some justifications to this idea, we perform a compar-ison with a tabu search algorithm (TS) and an iterated tabu search algorithm (ITS) which are obtained by making minor modifica-tions to our BLS algorithm.

The TS algorithm used for this comparison consists in per-forming moves identified by the two sets A 1 and A 2 (see Section 2.3.1 for the definition of sets A 1 and A 2 ). With equal probability,
TS performs a move either from A 1 or from A 2 . Note that this procedure is simply the directed perturbation of BLS. For ITS, we modify our BLS algorithm by excluding the adaptive perturbation strategy. The local search phase of ITS is the above-mentioned TS procedure, while the perturbation mechanism corresponds to the random perturbation performed by BLS. The perturbation phase of ITS is triggered if the best found solution is not improved after 10,000 iterations of the TS procedure. It is important to note that the tabu list of TS and ITS insures a certain degree of diversifica-tion at each iteration.

For each approach, we report in Table 7 the best and average result in columns f best and f avg respectively. From column f observe that for 19 instances, BLS finds better results than both TS and ITS. In other 35 cases, the best solution attained by BLS is at least as good as that reached by both TS and ILS.

To see whether BLS statistically outperforms TS and ITS in terms of solution quality, we apply the Friedman non-parametric statis-tical test followed by the Post-hoc test on the average results from
Table 7 . The Friedman test discloses that there is a significant difference among the compared algorithms with a p -value of 4.724e 05. Moreover, the Post-hoc analysis shows that BLS is statistically better than TS and ITS with a p -value of 6.554058e 04 and 4.615015e 05 respectively. Although we did not include the average time required by each approach to reach the best result from f best , BLS remains highly competitive with TS and ILS also in terms of computational time. While TS and ILS need on average 236 and 330 s respectively to reach their best results reported in f , BLS requires on average around 180 s for the 54 instances. 5. Conclusion
In this paper, we presented the Breakout Local Search approach for the Max-Cut problem. The BLS alternates between a local search phase (to find local optima) and a perturbation-based diversification phase (to jump from a local optimum to another local optimum). In addition to the descent-based local search procedure, the diversification phase is of an extreme importance for the performance of BLS since the local search alone is unable to escape a local optimum. The diversification mechanism of the proposed approach adaptively controls the jumps towards new local optima according to the state of the search. This is achieved by varying the magnitude of a jump and selecting the most suitable perturbation for each diversification phase.

Experimental evaluations on a popular set of benchmark instances showed that despite its simplicity, our approach out-performs all the current Max-Cut algorithms in terms of solution quality. Out of the 71 benchmark instances, BLS improves the current best results in 34 cases and attains the previous best-known result for 35 instances. Moreover, the computing time required by BLS to reach the reported results competes very favorably compared to other state-of-the-art approaches. To attain its best results reported in the paper, BLS needs less than one second to 10 min for the graphs with up to 3000 vertices, and 0.2 X 5.6 h for the large and very large instances with 5000 X 20,000 vertices.

We also provided experimental evidences to highlight the importance of the adaptive perturbation strategy employed by the proposed BLS approach, and the benefit of separating com-pletely diversification from intensification during the local search phases.
 Acknowledgment
We are grateful to the anonymous referees for valuable suggestions and comments which helped us improve the paper. The work is partially supported by the RaDaPop (2009 X 2013) and LigeRO projects (2009 X 2013) from the Region of Pays de la Loire, France.
 References
