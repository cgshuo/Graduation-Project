 Undirected graphical models such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) have shown great success for problems involving struc-tured output variables (e.g. Wellner et al. (2004), Finkel et al. (2005)). For many real-world NLP ap-plications, however, the required graph structure can be very complex, and computing the global normal-ization factor even approximately can be extremely hard. Previous approaches for training CRFs have either (1) opted for a training method that no longer maximizes the likelihood, (e.g. McCallum and Well-simplified graph structure to avoid intractable global normalization (e.g. Roth and Yih (2005), Wellner et al. (2004)).

Solutions of the first type replace the computation of the global normalization factor y p ( y | x ) with argmax y p ( y | x ) during training, since finding an argmax of a probability distribution is often an eas-ier problem than finding the entire probability distri-bution. Training via the voted perceptron algorithm (Collins, 2002) or using a max-margin criterion also correspond to the first option (e.g. McCallum and Wellner (2004), Finley and Joachims (2005)). But without the global normalization, the maximum-likelihood criterion motivated by the maximum en-tropy principle (Berger et al., 1996) is no longer a feasible option as an optimization criterion.
The second solution simplifies the graph struc-ture for training, and applies complex global infer-ence only for testing. In spite of the discrepancy between the training model and the testing model, it has been empirically shown that (1) performing global inference only during testing can improve performance (e.g. Finkel et al. (2005), Roth and Yih (2005)), and (2) full-blown global training can of-ten perform worse due to insufficient training data (e.g. Punyakanok et al. (2005)). Importantly, how-ever, attempts to reduce the discrepancy between the training and test models  X  by judiciously adding the effect of global inference to the training  X  have pro-duced substantial performance improvements over locally trained models (e.g. Cohen and Carvalho (2005), Sutton and McCallum (2005a)).

In this paper, we present structured local training , a novel training procedure for maximum-likelihood training of undirected graphical models, such as CRFs. The procedure maximizes likelihood while exploiting the benefits of global inference during training by capturing the interactions between local inference and global inference via hidden variables.
Furthermore, we introduce biased potential func-tions that redefine the likelihood for CRFs so that the performance of CRFs trained under the max-imum likelihood criterion correlates better empiri-cally with the preferred evaluation measures such as F-score and MUC-score.

We focus on the problem of coreference resolu-tion; however, our approaches are general and can be extended to other NLP applications with struc-tured output. Our approaches also extend to non-conditional graphical models such as Markov Ran-dom Fields. In experiments on two coreference data sets, structured local training reduces the error rate significantly (3.5%) for one coreference data set and minimally (  X  1%) for the other. Experiments using biased potential functions increase recall uniformly and significantly for both data sets and both task-specific evaluation measures. Results for the com-bination of the two techniques are promising, but mixed: pairwise F1 increases by 0.8-5.5% for both data sets; MUC F1 increases by 3.5% for one data set, but slightly hurts performance for the second data set.

In  X  2, we describe structured local training , and follow with experimental results in  X  3. In  X  4, we describe biased potential functions and follow with experimental results in  X  5. We discuss related work in  X  6. 2.1 Definitions For clarity, we define the following terms that we will use throughout the paper.  X  local inference: 2 Inference factored into smaller  X  global inference: Inference applied on the entire  X  local training: Training that does not invoke  X  global training: Training that does invoke global 2.2 A Motivating Example for Coreference In this section, we present an example of the coref-erence resolution problem to motivate our approach. It has been shown that global inference-based train-ing for coreference resolution outperforms training with local inference only (e.g. Finley and Joachims (2005), McCallum and Wellner (2004)). In particu-lar, the output of coreference resolution must obey equivalence relations, and exploiting such structural constraints on the output space during training can improve performance. Consider the coreference res-olution task for the following text.
 In the above text, the  X  she  X  in the last sen-tence is coreferent with both mentions of  X  Elizabeth  X . However, when we consider  X  she  X  and  X  Elizabeth (1)  X  in isolation from the remaining coreference chain, it can be difficult for a machine learning method to determine whether the pair is coreferent or not. Indeed, such a pair may not look very different from the pair  X  she  X  and  X  Mary (1)  X  in terms of feature vectors. It is much easier, however, to determine that  X  she  X  and  X  Elizabeth (2)  X  are coreferent, or that  X  Elizabeth (1)  X  and  X  Elizabeth (2)  X  are coreferent. Only by taking the transitive closure of these pair-wise coreference relations does it become clear that  X  she  X  and  X  Elizabeth (1)  X  are coreferent. In other words, global training might handle potentially confusing coreference cases better because it allows parameter learning (for each pairwise coreference decision) to be informed by global inference.
We argue that, with appropriate modification to the learning instances, local training is adequate for the coreference resolution task. Specifically, we pro-pose that confusing pairs in the training data  X  such as  X  she  X  and  X  Elizabeth (1)  X   X  be learned as not-coreferent , so long as the global inference step can fix this error by exploiting the structure of the out-put space, i.e. by exploiting the equivalence rela-tions. This is the key idea of structured local train-ing , which we elaborate formally in the following section. 2.3 A Hidden-Variable Model In this section, we present a general description of structured local training . Let y be a vector of out-put variables for structured output, and let x be a vector of input variables. In order to capture the in-teractions between global inference and local infer-ence, we introduce hidden variables h , | h | = | y | , so that the global inference for p ( y, h | x ) can be fac-tored into two components using the product rule, as follows: The second component p ( h | x ) on the right hand side corresponds to the local model, for which the infer-ence factorizes into smaller independent pieces, e.g. argmax h p ( h | x )= { argmax h first component p ( y | h, x ) on the right hand side cor-responds to the global model, whose inference may not factorize nicely. Further, we assume that y is in-dependent of x given h , so that p ( y | h, x )= p ( y | h ) . That is to say, h captures sufficient information from x , so that given h , global inference of y only de-pends on h . The quantity of p ( y | x ) then is given by marginalizing out h as follows: Intuitively, the hidden variables h represent the lo-cal decisions that can lead to a good y after global inference is applied. In the case of coreference reso-lution, one natural factorization would be that global inference is a clustering algorithm, and local infer-ence is a classification decision on each pair of noun that we only parameterize the local model p ( h | x ) , although it would be possible to extend the parame-terization to the global model as well, depending on the particular application under consideration. The similarity between a pair of mentions is parameter-ized via log-linear models. However, once we have the similarity scores extracted via local inference, the clustering algorithm does not require further pa-rameterization.
 For training, we apply the standard Expectation-Maximization (EM) algorithm (Dempster et al., 1977) as follows:  X  E Step: Compute a distribution By repeatedly applying the above two steps for t =1 , 2 , ... , the value of  X  converges to the local maxima of the conditional log likelihood L (  X  )= log P ( y | x , X  ) . 2.4 Application to Coreference Resolution For y i  X  y (and h i  X  h ) in the coreference resolution task, y i =1 (and h i =1 ) corresponds to i th pair of mentions being coreferent, and y i =0 (and h i =0 ) corresponds to i th pair being not coreferent. [Local Model P ( h | x ) ] For the local model, we de-each clique potential as Let  X ( h | x )  X  i  X  ( h i ,x i ) . Then, Notice that in this model, finding argmax h P ( h | x ) corresponds to simply finding argmax h dependently for each h i  X  h . [Global Model P ( y | h ) ] For the global model, we assume a deterministic clustering algorithm is given. In particular, we focus on single-link clustering, as it has been shown to be effective for coreference reso-lution (e.g. Ng and Cardie (2002)). With single-link clustering, P ( y | h )=1 if h can be clustered to y , and P ( y | h )=0 if h cannot be clustered to y . 5 [Computation of the E-step] The E-step requires computation of the distribution of P ( h | y , x , X  ( t  X  1) ) , which we will simply denote as P ( h | y , x ) , since all our distributions are implicitly conditioned on the model parameters  X  .
 Notice that when computing P ( h | y , x ) , the denomi-nator P ( y | x ) stays as a constant for different values of h . The E-step requires enumeration of all possible values of h , but it is intractable with our formulation, because inference for the global model P ( y | h ) does not factor out nicely. Therefore, we must resort to an approximation method. Neal and Hinton (1998) an-alyze and motivate various approximate EM training methods. One popular choice in practice is called  X  X iterbi training X , a variant of the EM algorithm, which has been shown effective in many NLP ap-plications. Viterbi training approximates the distri-bution by assigning all probability mass to a single best assignment. The algorithm for this is shown in Figure 1.
 We propose another approximation option for the E-step that is given by Figure 2. Intuitively, when the current local model misses positive coreference decisions, the first algorithm constructs a y that is closest to h for single-link clustering to recover the true labeling y  X  , while the second algorithm con-structs a y that is closer to y  X  by preserving all of [Computation of M-step] Because P ( y | h ) is not parameterized, finding argmax  X  P ( y , h | x ) reduces to finding argmax  X  P ( h | x ) , which is standard CRF training. In order to speed up the training, we start convex optimization for CRFs using the parame-the very first iteration of EM, we start by setting P ( y  X  | x )=1 for E-step, so that the first M-step will finds argmax  X  P ( y  X  | x ) . [Inference on the test data] It is intractable to marginalize out h from P ( y , h | x ) . Therefore, sim-ilar to the Viterbi-training in the E-step, we approx-imate the distribution of h by argmax h P ( h | X ) . Data set: We evaluate our approach with two coreference data sets: MUC6 (MUC-6, 1995) and we extract noun phrases (mentions) automatically, but for MPQA, we assume mentions for corefer-ence resolution are given as in Stoyanov and Cardie (2006). For MUC6, we use the standard training/test data split. For MPQA, we use 150 documents for training, and 50 documents for testing.
 Configuration: We follow Ng and Cardie (2002) for feature vector construction for each pair of men-structing a training/testing instance for each docu-ment: a training/testing instance consists of all pairs of mentions in a document. Then, a single pair of mentions is a sub-instance . We use the Mallet 9 im-plementation of CRFs, and set a Gaussian prior of 1 . 0 for all experiments. At each M-step, we train CRFs starting from the parameters from the previous M-step. We train CRFs up to 200 iterations, but be-cause we start training CRFs from the previous pa-rameters, the convergence from the second M-step becomes much faster. We apply up to 5 EM itera-tions, and choose best performing  X  ( t ) , 2  X  t  X  5 Hypothesis: For the baseline (BASE) we employ the locally trained model for pairwise decisions without global inference. Clustering is applied only at test time, in order to make the assignment on the output variables coherent. We hypothesize that for the baseline, maximizing the likelihood for training will correlate more with the pairwise accuracy of the incoherent decisions before clustering than the pair-wise accuracy of the coherent decisions after cluster-ing. We also hypothesize that by performing struc-tured local training (SLT), maximizing the likeli-hood will correlate more with the pairwise accuracy after clustering.
 Results: Experimental results are shown in Ta-ble 1. We report error rate ( error rate = 100  X  accuracy ) on the pairwise decisions (e %), and F1-ison, we show numbers from both after and before single-link clustering is applied. As hypothesized, the error rate of BASE increases after clustering, while the error rate of SLT decreases after cluster-ing. Moreover, the error rate of SLT is considerably lower than that of BASE after clustering. However, the F1-score does not correlate with the error rate. That is, a lower error rate does not always lead to a higher F1-score, which motivates the Biased Poten-tial Functions that we introduce in the next section. Notice that when we compare the precision/recall breakdown after clustering, SLT has higher precision and lower recall than BASE . We introduce biased potential functions for train-ing CRFs to empirically favor preferred evaluation measures for the learning task, such as F-score and MUC-score that have been considered hard for tradi-tional likelihood-based methods to optimize for. In-tuitively, biased potential functions emphasize those sub-components of an instance that can be of greater importance than the rest of an instance. 4.1 Definitions The conditional probability of P ( y | x ) 12 for CRFs is given by (Lafferty et al., 2001) where  X  ( C i , x ) is a potential function defined over each clique C i . Potential functions are typically pa-rameterized in an exponential form as follows. where  X  k are the parameters and f k (  X  ) are fea-ture indicator functions. Because the Hammersley-Clifford theorem (1971) for undirected graphical models holds for any non-negative potential func-tions, we propose alternative potential functions as follows.  X  ( C i , x )= where  X  is a non-negative bias factor, and  X  ( C i , x ) is a predicate (or an indicator function) to check cer-tain properties on ( C i , x ) . 13 Examples of possible  X  (  X  ) would be whether the true assignment for C i in the training data contains certain class values, or whether the current observation indexed by C i has particular characteristics. More specific details will be given in  X  4.2.

Training and testing with biased potential func-tions is mostly identical to the traditional log-linear formulations by  X  (  X  ) as defined above, except for small and straightforward modifications to the com-putation of the likelihood and the derivative of the likelihood.
The key idea for biased potential functions is nothing new, as it is conceptually similar to in-stance weighting for problems with non-structured output (e.g. Aha and Goldstone (1992), Cardie et al. (1997)). However, biased potential functions differ technically in that they emphasize desired subcom-ponents without altering the i.i.d. assumption, and still weight each instance alike. Despite the con-ceptual simplicity, we are not aware of any previ-ous work that explored biased potential functions for problems with structured output. 4.2 Applications to Coreference Resolution [Bias on Coreferent Pairs] For coreference res-olution, pairs that are coreferent are in a minority this skewed data problem, by amplifying the clique potentials that correspond to coreferent pairs. We define  X  ( y i ,x i ) to be true if and only if the true as-signment for y i in the training data is  X  X oreferent X  . Notice that  X  (  X  ) does not depend on what particu-lar value y i might take, but only depends on the true value of y i in the training data. For testing,  X  ( y i ,x [Bias on Closer Coreferent Pairs] For corefer-ence resolution, we hypothesize that coreferent pairs for closer mentions have more significance, because they tend to have clearer linguistic clues to deter-mine coreference. We further hypothesize that by emphasizing only close coreferent pairs, we can have our model favor the MUC score. For this, we define  X  ( y i ,x i ) to be true if and only if x i is for a pair of mentions that are the closest coreferent pair. Data sets and configurations for experiments are identical to those used in  X  3.
 Hypothesis: We hypothesize that using biased po-tential functions, maximizing the likelihood for training can correlate better with F1-score or MUC-score than the pairwise accuracy. In particular, we hypothesize that biasing on every coreferent pair will correlate more with F1-score, and bias-ing on close coreferent pairs will correlate more with MUC-score. In general, we expect that bias-ing on coreferent pairs will boost recall, potentially decreasing precision.
 Results [BPF]: Experimental results for biased potential functions, without structured local train-ing, are shown in Table 2. BASIC -P 1  X  denotes local training with biased potential on the closest corefer-ent pairs with bias factor  X  , and BASIC -P a  X  denotes local training with biased potential on the all coref-erent pairs with bias factor  X  , where  X  =1 . 5 or 3 . 0 . For brevity, we only show pairwise numbers before biased potential functions in general boost recall at the cost of precision. Also, for a fixed value of Results [SLT+BPF]: Experimental results that combine SLT and BPF are shown in Table 3. Sim-ilarly as before, SLT -P x  X  denotes SLT with biased potential scheme P x , with bias factor  X  . For brevity, we only show numbers after applying single-link-clustering. Unlike the results shown in Table 2, for a fixed value of  X  , SLT -P 1  X  correlates better with pairwise-F1, and SLT -P a  X  correlates better with MUC-F1. This indicates that when biased poten-tial functions are used in conjunction with SLT, the effect of biased potential functions can be different from the case without SLT. Comparing F1-scores in Table 2 and Table 3, we see that the combination of biased potential functions with SLT improves per-formance in general. In particular, SLT -P 1 3 . 0 and BASE on both data sets, for both pairwise-F1 and MUC-F1. We present performance scores for all variations of configurations for reference, but we also mark the particular configuration SLT -P x  X  (by  X * X  on F1-scores) that is chosen when selecting the configuration based on the performance on the train-ing data for each performance measure. To con-clude, structured local training with biased poten-tial functions bring a substantial improvement for MUC-F1 score, from 66.4% to 69.9% for MUC6 data set. For pairwise-F1, the performance increase from 57.7% to 58.5% for MUC6, and from 65.1% to Structured local training is motivated by recent re-search that has shown that reducing the discrep-ancy between the training model and testing model can improve the performance without incurring the heavy computational overhead of full-blown global valho (2005), Sutton and McCallum (2005a), Sutton and McCallum (2005b)). Our work differs in that (1) we use hidden variables to capture the interac-tions between local inference and global inference, (2) we present an application to coreference resolu-tion, while previous work has shown applications for variants of sequence tagging. McCallum and Well-ner (2004) showed a global training approach with CRFs for coreference resolution, but they used the voted perceptron algorithm for training, which no longer maximizes the likelihood. In addition, they assume that all and only those noun phrases involved in coreference resolution are given.

The performance of our system on MUC6 data set is comparable to previously reported systems. Using the same feature set, Ng and Cardie (2002) reports 64.5% of MUC-score, while our system achieved 69.9%. Ng and Cardie (2002) reports 70.4% of MUC-score using hand-selected features. With an additional feature selection or feature induc-tion step, the performance of our system might fur-ther improve. McCallum and Wellner (2004) reports 73.42% of MUC-score on MUC6 data set, but their experiments assumed perfect identification of all and only those noun phrases involved in a coreference relation, thus substantially simplifying the task. We present a novel training procedure, structured local training , that maximizes likelihood while exploiting the benefits of global inference during training. This is achieved by incorporating hidden variables to capture the interactions between local inference and global inference. In addition, we introduce biased potential functions that allow CRFs to empirically favor performance measures such as F1-score or MUC-score. We focused on the application of coreference resolution in this paper, but the key ideas of our approaches can be extended to other applications, and other machine learning techniques motivated by Markov networks.

