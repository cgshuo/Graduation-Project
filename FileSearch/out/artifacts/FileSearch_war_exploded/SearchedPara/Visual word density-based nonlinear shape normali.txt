 ORIGINAL PAPER Yunxue Shao  X  Chunheng Wang  X  Baihua Xiao Abstract In handwritten Chinese character recognition, character normalization method. In this paper, a visual word density-based nonlinear normalization method is proposed for handwritten Chinese character recognition. The underly-be determined by the visual word around this pixel. Visual vocabulary is used for mapping from a visual word to a den-sity value. The mapping vocabulary is learned to maximize the ratio of the between-class variation and the within-class variation. Feature extraction is involved in the optimization stage, hence the proposed normalization method is beneficial for the following feature extraction. Furthermore, the pro-posed method can be applied to some other image classifica-this paper. Experimental results on one constrained handwrit-ing database (CASIA) and one unconstrained handwriting database (CASIA-HWDB1.1) demonstrate that the proposed method outperforms the start-of-the-art methods. Experi-ments on scene character databases chars74k and ICDAR03-CH show that the proposed method is promising for some image classification problems.
 Keywords Visual word density  X  Handwritten Chinese character recognition  X  Character shape normalization  X  Scene character recognition 1 Introduction The problem of handwritten Chinese character recogni-system includes character image normalization, feature extraction, and classification. Among which, character nor-malization largely affects the performance of a system. Many character normalization methods have been proposed includ-moment normalization [ 14 ], bi-moment normalization [ 5 ], cient and has been used in most HCCR systems with suc-cess. Compared with linear normalization, the DDNLN or LDNLN largely reduces the within-class shape variation. of the 1D methods, Horiuchi et al. [ 3 ] proposed a pseudo 2D nonlinear normalization (P2DNLN) method by equaliz-ing the line density functions of each row/column instead more effective than LDNLN, it is computationally expensive. A more efficient pseudo 2D normalization method which proposed. This method achieves a comparable performance with P2DNLN while the computational complexity is much smaller.
 density-based methods (LDNLN, P2DNLN, and LDPI) are the most successful on most of the databases especially on the unconstrained handwriting databases. However, on the On the other hand, there is no relationship between the char-acter normalization and the following feature extraction. In this paper, a visual word density (VWD)-based normalization compute the visual word density of each pixel, a visual word is used for mapping from this visual word to a density value. the proposed normalization method is beneficial for the fol-lowing feature extraction. Furthermore, the proposed method is promising for some image classification problems. Some virtues of the proposed VWD-based normalization method method to maximize the ratio of the between-class variation extraction method is involved, hence the learning result is beneficial for the predetermined feature extraction method. (b) Traditional nonlinear normalization methods can only be designed only for handwritten character recognition. In con-trast, the proposed method is not restricted on binary image, tal results in this paper show that traditional methods have unstable performance on the constrained and unconstrained handwriting databases. The proposed method achieves better performance on both the constrained and the unconstrained handwriting databases.
 The proposed method is evaluated on two handwritten Chinese character databases (the constrained handwriting databases CASIA and the unconstrained handwriting data-bases CASIA-HWDB1.1 [ 18 ] ) and two scene character data-bases (chars74k [ 19 ] and ICDAR03-CH [ 20 ]). Experimental results on the two handwriting databases show that the pro-posed method outperforms the start-of-the-art methods. The scene character recognition experiments demonstrate that the proposed method is promising for some image classification the related works are reviewed in Sect. 2 . Then, the visual word density-based shape normalization method is proposed a conclusion is given in Sect. 5 . 2 Related works position, and shape of character images so as to reduce the within-class shape variation. Denote the input image and the malization is implemented by coordinate mapping r = r ( x , y ), c = c ( x , y ), The mapped coordinates ( r , c ) are discretized and interpo-lated to generate the normalized image g ( r , c ) = f ( x 2.1 1D normalization methods Under 1D normalization, the pixels at the same row or column are mapped to the same row or column in the normalized image. r = r ( x ), c = c ( y ), and W 2 and H 2 as the width and height of the normalized image. The mapping function of the linear normalization is
The 1D moment normalization method [ 14 ] aligns the cen-second-order 1D moments  X  x and  X  y . The width and height of the input image are reset to  X  x =  X  respectively. The coordinate mapping function is given by  X   X   X 
The bi-moment normalization method [ 5 ] aligns the cen-troid of the input image as 1D moment normalization does, but the width and height are treated asymmetric with respect to the centroid. The second-order moments are split into two the input image are reset to [ x c  X   X   X   X  x , x c +  X   X  + [ y by r = W 2 u ( x ) = W 2 a 1 x 2 + b 1 x + c 1 , c = H 2 v( y ) = H 2 a 2 y 2 + b 2 y + c 2 , where a 1 , b 1 , c 1 are parameters subject to  X   X   X   X   X   X   X  u x c  X   X   X   X  x = 0 , u ( x c ) = 0 . 5 , u x c +  X   X  + x = 1 , a , b
To the best of our knowledge, only two types of density-based nonlinear normalization method, dot density [ 13 ] and based nonlinear methods need to compute the density  X  of the input image first. And then, the mapping function is obtained by density equalization r = W 2 u ( x ) = W 2  X  x i = 0 h u ( i ), c = H 2 v( y ) = H 2  X  y j = 0 h v ( j ), where  X   X   X   X   X   X   X   X   X 
Yamashita et al. [ 13 ] define the density image as the pixel value of the input image.  X ( i , j ) = f ( i , j ) +  X , (9) where  X  is a constant. This method is called as dot density-based nonlinear normalization method (DDNLN). The dot density-based method tries to make stroke pixels uniform.
Yamada et al. [ 2 ] define the line density as an inscribed to be L 1 and L 2 , a left edge to be L 3 and L 4, where L L 3 exist on the left of ( i , j ) .  X   X   X   X   X   X   X   X   X   X   X 
L 1 = max { i | i &lt; i , f ( i , j )&gt; 0&amp; f ( i +
L 2 = min { i | i  X  i , f ( i , j )&gt; 0&amp; f ( i + 1 ,
L 3 = max { i | i &lt; i , f ( i  X  1 , j ) = 0&amp; f ( i
L 4 = min { i | i  X  i , f ( i  X  1 , j ) = 0&amp; f ( i , j Here, note that there is a case i is undefined. A line inter-L , L L roughly approximated diameter of the inscribed circle at each point. The line density  X  is calculated as the maximum of the inverse values of L x and L y .  X ( i , j ) =
Another way of defining the line density is proposed in [ 1 ] by Tsukumo and Tanaka. The line density along x-direction and y-direction is computed and used for coordinate mapping separately. Denote the line densities as  X  x ( i , j ) and  X   X  distances between neighboring strokes, respectively. Com-pared to the Yamada X  X  method, previous work [ 15 ] shows that same time, Yamada X  X  method has some two-dimensionality and locality. In this paper, we compare the proposed method with Yamada X  X  method. 2.2 Pseudo 2D methods Horiuchi et al. [ 3 ] proposed a pseudo 2D nonlinear normal-ization (P2DNLN) method. The basic idea of P2DNLN is to equalize the line density functions of each row or column of shape deformation, they blurred the line density functions such that the equalization of each row or column depends on its neighboring rows or columns. The blurred horizontal density function is given by  X  ( i , j where  X  2 is the variance of a Gaussian function. The blurred column independently to generate 1D coordinate mapping functions r ( x , y 0 ) or c ( x 0 , y ) .

Although this method is very effective, it is very compu-tationally expensive because of row-and column-wise line pseudo 2D normalization method which is called line density ring and row/column-wise equalization, LDPI partitions the 2D line density map into soft strips. 1D coordinate functions are computed from the density projection of each strip and combined into a 2D function.
 izontal strips: ( i , j ) = w k ( j ) X  where w k ( j ) are  X   X   X   X   X   X   X   X   X  w 1 ( j ) = w w 2 ( j ) = 1  X  w 1 ( j ), j &lt; y w 2 ( j ) = 1  X  w 3 ( j ), j  X  y w 3 ( j ) = w where w 0 controls the weight of the upper and lower part of the line density map. The weight functions with w 0 = 1are depicted in Fig. 1 .
The three strips are used to compute three 1D coordinate coordinate mapping functions: r ( x , y ) = Similarly, the vertical 2D coordinate mapping function c ( x , y ) can be computed.
 the dot density and the proposed VWD-based method. The extension is implemented by replacing the line density with dot density or visual word density in the LDPI method and will be called as dot density projection interpolation (DDPI) and visual word density projection interpolation (VWDPI), normalization (MN), bi-moment normalization (BMN), and Marukawa [ 4 ]. 3 Visual word density-based nonlinear normalization Figure 2 shows an example of nonlinear normalization based character image. The others are the corresponding normal-ized image based on different densities. Images (d) and (e), which are the normalization results of line density-and dot density-based methods, are just the special cases of them. We know that different normalization results correspond to different performances. How to find a better density compu-tation method is considered in this paper.

Dot density equalization method uses only the pixel value at method uses the pixels along row y and column x to com-pute the density. This two methods are proposed according the within-class scatter smaller. To determine the density at (VWD) treats each pixel as a visual word and gives this pixel a density value according to this visual word. Figure 3 gives methods.

To compute the VWD, firstly, the method for extracting a visual word at each pixel should be determined. Then, the mapping method from a visual word to a density value should be learned. Finally, the word extracting and word mapping methods are used to compute the density for each input char-acter image. While the VWD been computed, the 1D or 2D density-based normalization method can be used to normal-ize the input image.

In this section, the visual word extraction method is first the learning method is given in Sect. 3.3 . 3.1 Visual word extraction Given an input image, the visual word at ( x , y ) is defined as the feature vector extracted from the image patch around ( x different performances. In this paper, just for showing the effectiveness of the proposed method, the descriptor used for recognition is the list of pixel values on the gradient image experiments. The visual word for other applications should be designed specifically. 3.2 Mapping method Bag of visual words (BOVW) model [ 21  X  23 ] is successfully used in many image classification problems. In the BOVW model, visual vocabulary is used to quantize a visual word. The training character images are divided into patches using K-means clustering.
 Suppose a visual vocabulary contains N w codewords Q { q words are S { s 1 ,..., s N w } , where s i is a real number. S ( q i ) = s i , (18) Denote p x , y as the visual word of f ( x , y ) at ( x , the density value at ( x , y ) can be computed by finding the nearest codeword in the vocabulary and set this codeword X  X  density as this visual word X  X  density. Formally,  X ( x , y ) = S q i | Figure 4 illustrates the mapping from a visual word to a den-sity value. After the visual word density been computed, the 1D nonlinear normalization or 2D nonlinear normalization method can be used to normalize the input image.

Specially, when the patch X  X  width is set to 1 and the num-ber of codeword in the vocabulary is set to 2, the proposed VWD-based method can be seen as the dot density-based method. The codeword is the background value and the fore-ground value, and the corresponding density values are  X  and foreground value plus  X  . 3.3 Density learning The mapping from a visual word to a density value is based on a visual vocabulary. Each codeword in the vocabulary should be mapped to an appropriate density value.
  X  f and v i , j as the feature vector extracted from g i , j ( the predetermined feature extraction method.

Let the nonlinear transformation from f i , j ( x g g Substituting Eq. ( 19 )inEq.( 20 )gives g Let function E as the nonlinear feature extraction process, then v
The density learning method finds a density for each code-word in the visual vocabulary so as to minimize the criterion function F . min F = min where S w =
S N c is the number of the classes. N s is the number of samples in each class.  X  i is the mean vector of the i th class and the mean vector of all samples. The gradient of the objective function with respect to s i is  X 
F  X  s E and T in Eq. ( 22 ) are unknown nonlinear functions, hence (PS) is a family of numerical optimization methods that do Hence, PS can be used on functions that are not continuous or search algorithms is referred to [ 25 ].

Pattern search algorithm is an iterative method that gener-ates a sequence of feasible iterates whose objective function densities are initiated with a constant value. The normalized PS algorithm proceeds by conducting a series of exploratory moves about the current iterate. If there do not exist a suc-cessful move, then decrease the move step and try again. The learning rules used in this paper are as follows: 3. If there is no s i moved, then  X  =  X / 2.
 Repeat step 2 X 3 until F converges to a stable point. image is normalized by Eq. ( 7 ). Finally, the normalization-feature vectors. From Eqs. ( 7 ) and ( 8 ), we can see that on image normalization. Therefore, constant a in step 1 can be set arbitrarily. In our experiment, we set a = 1. In PS algorithm automatically decreases the step if needed. In our experiments,  X  is set to 0.2 initially.

In the learning method, feature extraction method is involved, hence the optimization result is beneficial for the predetermined feature extraction method. Figure 5 shows the convergence characteristics of the learning process for the CASIA-HWDB1.1 database. We can see that the pattern search method of the objective function quickly converges regardless of patch width W p . Figure 6 shows some example of normalized images after iterating several times. 4 Experimental results 4.1 Handwritten Chinese character recognition We evaluate the proposed method on the CASIA database and the CASIA-HWDB1.1 [ 18 ]. The CASIA database, which is collected by the Institute of Automation, Chinese Academy of Sciences, contains 3,755 Chinese characters, 300 samples per class. Two hundred and fifty samples per class are used for training and the remaining 50 samples for testing. The CASIA-HWDB1.1 database is built by the National Lab-oratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences. It contains 3,755 Chinese characters, almost 300 samples per class. As suggested by the remaining 60 are used for testing. The preprocessing of the samples in CASIA-HWDB1.1 is referred to [ 26 ]. Some samples in the two databases are given in Fig. 7 . The first three rows are taken from CASIA, and the remaining rows are taken from CASIA-HWDB1.1.

In this experiment, the modified quadratic discriminant functions (MQDF2) [ 10 ] which have been widely applied to HCCR with great success are used as the classifier. The normalization-cooperated gradient feature (NCGF) [ 12 ]is decomposed into eight chain-code directions. Each direction is extracted 8  X  8 values by Gaussian blurring and down-sampling. The feature dimensionality is 512. Before classi-fication, the feature vector is reduced to 256 dimensional by Fisher discriminant analysis (FDA).

There are a number of conventional techniques that have been developed for handwritten Chinese character nor-malization. In our experiments, the proposed VWD-based method is compared with dot density (DD)-and line density (LD)-based methods. The pseudo 2D extension VWDPI is compared with the DDPI and LDPI methods. These methods often achieve the best performance.

Firstly, for evaluating the performance of different para-classes are used in this experiment. Parameters evaluated in this experiment are width of the visual word W p and size of the visual vocabulary N w . The number of principal eigen-vectors k used in MQDF2 is set to 50. Tables 1 and 2 present there exists a minimal but best vocabulary for a fixed W p This is identical to the characteristic of vocabulary used in the BOW framework. For example, when W p = 9, the perfor-mance of 100 codewords is better than 50 or 200 codewords. In this paper, these parameters and the feature types used for extracting visual word are not optimized. We just want to show the effectiveness of the proposed framework. In the following experiments, parameters N w = 100 , W p = 9, and its corresponding learned mapping vocabulary are used. We will see that good performance can be achieved even by these not optimized parameters.

Then, the performances on the whole databases using the selected parameters and its corresponding learned mapping vocabulary are evaluated. Figure 8 shows some examples of normalization using DD, DDPI, LD, LDPI, VWD, and VWDPI. The first column is the original character image. The other columns from (b) to (g) correspond to the normal-ized images by DD, LD, VWD, DDPI, LDPI, and VWDPI, respectively.
 The number of principal eigenvectors k used in the MQDF2 classifier affects the recognition rates. Therefore, Tables 3 and 4 present the results of different density equalization-based normalization methods with varying number of k on the two databases, respectively. On the CASIA database, the DD and DDPI perform a little better than LD and LDPI while on the CASIA-HWDB1.1 data-DDPI. The proposed method achieves the best result on both the two databases. These results demonstrate that the DD method and LD method are unstable compared to the proposed VWD method. A recognition rate of 98.48 % on CASIA and 88.79 % on CASIA-HWDB1.1 is achieved by the VWD method and 98.74 % on CASIA and 90.19 % on CASIA-HWDB1.1 is achieved by the VWDPI. Although these parameters of the proposed method are not optimized on the whole database, the proposed method performs better than the state-of-the-art methods.

Most of the misclassified characters have shapes similar to the assigned class. Some of them are inherently similar, and some of them are similar due to cursive writing. However, some of them are due to the shape normalization. Figure 9 shows some examples of the misclassified samples because denotes the ground truth. The blue ellipse denotes the crit-ical region human used to discriminate the character. From Fig. 9 , we can see that the line density (LD)-based method VWD-based method performs better. About 1,594 charac-ters in CASIA database which is misclassified by LD-based method are corrected by the VWD method. Most of them are like Fig. 9 a, b. However, as shown in Fig. 9 c, about 1,086 characters in CASIA database which is misclassified by the VWD method are corrected by the LD method. These results tell us that different normalization method can give comple-mentary features, and we can combine them together to give a malization method or a set of VWD method based on differ-ent mapping vocabulary will be concerned in our future work. 4.2 Scene character recognition Unlike other shape normalization methods for handwritten Chinese character recognition, the proposed method can be applied to some image classification problems. In this exper-iment, we evaluate the proposed method on the problem an object recognition than an optical character recognition unsuitable to this problem. Methods showed success in objec-normalization method can improve the performance.
The chars74k and ICDAR03-CH databases are used in this experiment. The chars74k database [ 19 ] contains 62 classes consisting of digits, and upper-and lower-case letters. Just for showing the effectiveness of the proposed method, the other half is used for testing. Figure 10 shows some exam-ple images from the chars74k database. The ICDAR03-CH images in the training set of ICDAR03-CH are used for train-ing. In this experiment, the color images are converted to gray images. Each image is normalized into 64  X  64. Feature extraction method used in this experiment is the same as used fier is KNN. The parameters W p and N w are the same as used in the HCCR experiment. Figure 11 shows some normaliza-variation is reduced by the normalization method.
Tables 5 and 6 present the results with varying number of W p , N w , and the N k nearest neighbors in KNN method. We can see that different parameters X  performance differs a ent normalization methods on the two databases. Parameters used in the proposed VWD method are W p = 7 , N w = 200 on the chars74k database and W p = 7 , N w = 100 on the ICDAR03-CH database, respectively. From these tables, we promising for some image classification problems. 5 Conclusion In this paper, a visual word density-based nonlinear normal-of the vocabulary learning is to maximize the ratio of the between-class variation and the within-class variation. Pat-Feature extraction method is involved in the learning stage, hence the learning result is beneficial for the predetermined feature extraction method.
 The proposed method is evaluated on two handwritten Chinese character databases and two scene character data-bases. In handwritten Chinese character recognition exper-proposed method. Experimental results show that the pro-posed method performs better than the state-of-the-art meth-ods. The recognition rate 90.19 and 98.74 % is achieved on CASIA-HWDB1.1 and CASIA database, respectively. Gen-as an object recognition problem. Traditional character nor-malization methods cannot be applied to these problems. The proposed method is compared with the linear normalization and the moment-based normalization method. Experimental results demonstrate that the proposed method performs well and is promising for some objection recognition problems. Applying the proposed method to some other object recogni-tion problems and combining a set of VWD-based methods will be concerned in our future work.
 References
