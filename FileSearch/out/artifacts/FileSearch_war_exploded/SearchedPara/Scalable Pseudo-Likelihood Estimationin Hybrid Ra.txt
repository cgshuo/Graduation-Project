 I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database Applications X  data mining Algorithms, Experimentation, Performance Bayesian networks, Hybrid random fields, Markov random fields, Modularity, Scalability
Bayesian networks (BNs) and Markov random fields (MRFs) are useful formalisms for representing joint proba-bility distributions [23, 14]. Important research efforts have focused on the problem of learning such models from data [5, 12, 8, 21]. One major limitation of both BNs and MRFs is that, in the absence of prior knowledge, learning these models can be computationally very expensive. The hybrid random field (HRF) model investigated in this paper is a generalization of BNs. The aim of defining HRFs is to al-low for efficient model selection in arbitrarily large domains, while retaining the flexibility of BNs and MRFs in modeling complex probability distributions. Although HRFs exploit a BN-like factorization of joint distributions into a set of local conditional distributions, they factorize joint distribu-tions into spatially (rather than ancestrally) related local distributions, thereby obtaining a MRF-like statistical rep-resentation.

In order to reduce the computational cost of learning with respect to BNs and MRFs, the idea is to develop a structure learning algorithm which takes advantage of the modular nature of HRFs. At the same time, in order to preserve the expressive power of BNs, HRFs are designed in such a waythatBNsturnouttobeaspecialcaseofHRFs. This will be shown by proving that the class of distributions that can be represented by BNs is strictly included in the class of pseudo-likelihood measures that can be represented by HRFs.

The paper is structured as follows. In Sec. 2, after re-viewing some concepts related to BNs, we describe the HRF formalism, and we show that BNs can be seen as a special case of HRFs. Parameter learning is addressed in Sec. 3, while Sec. 4 focuses on structure learning. In Sec. 5 we dis-cuss some related work on graphical models. Sec. 6 contains an experimental investigation of HRFs. The main contribu-tions of the paper are summarized in Sec. 7.
HRFs can be used to represent pseudo-likelihood distribu-tions underlying sets of random variables. A HRF is defined as follows: Definition 1. Let X be a set of random variables X ,...,X n . A hybrid random field for X 1 ,...,X n is a set of Bayesian networks BN 1 ,...,BN n (with graphs G 1 ,..., G such that: ii. For each X i , P ( X i | X \{ X i } )= P ( X i |MB i Clearly, MB i ( X i ) is a Markov blanket (MB) of X i within BN i [23]. The elements of R ( X i ) are called  X  X elatives of X That is, the relatives of a node X i in a HRF are the nodes appearing in graph G i (except X i itself). We refer to condi-tion ii in Definition 1 as the  X  X odularity property X . Based on the modularity property, the set MB i ( X i )isaMBof X i in X . Both BNs and MRFs assume some kind of condi-tional independence property. While the representation of joint probabilities in BNs is allowed by the directed Markov assumption [23, 20], MRFs need to assume one of the statis-tical conditions detailed in the Hammersley-Clifford theorem [1, 19]. Similarly, the conditional independence property en-tailed by HRFs is the modularity condition.

The pseudo-likelihood of a given state x of the variables in X , denoted by P  X  ( X = x ), is defined as follows [2]: Given the modularity property of HRFs, Eq. 1 can be rewrit-ten as follows: where mb i ( X i ) denotes the state of MB i ( X i ). Therefore, in order to represent a pseudo-likelihood in a HRF, we only need to be able to compute the conditional distribution of each node X i given the state of MB i ( X i ). This can be done very efficiently [22]. When needed, standard Gibbs sampling techniques can be used to extract a strict joint probability from a HRF [9].
 One detail to note concerns the presence of loops in HRFs. Loops cannot arise at the local level (i.e. within the BNs), since this is prevented from the very use of BNs as models for the local distributions. On the other hand, loops can arise at the global level, since it may happen that two nodes point to one another if considered simultaneously in different BNs. This is not a problem at all, because of the modular nature of HRFs. Global loops do not affect the way that a pseudo-likelihood is computed, since that function is factorized as a product of local distributions such that each one of them is computed independently of the remaining ones.

We now prove two theorems, which illustrate some rela-tionships between HRFs and BNs.

Theorem 1. For each Bayesian network BN ,thereex-ists a hybrid random field HRF representing the same joint distribution represented by BN .
 Proof. Suppose X 1 ,...,X n are the nodes contained in BN .ConstructaHRF HRF for X 1 ,...,X n such that, if PA ( X i )isthesetofparentsof X i in BN and PA i ( X i )isthe set of parents of X i in BN i ,then MB i ( X i )= PA i ( X PA ( X i ). Denoting by P  X  HRF and by P BN the distribu-tions represented by HRF and BN respectively, it follows that P HRF ( X 1 ,...,X n )= P BN ( X 1 ,...,X n ).

In order to prove the second theorem, we need the follow-ing definition [23]:
Definition 2. An undirected graph G is said to be  X  X hordal X  if for every cycle in G containing at least four edges there is at least one chord, i.e. an edge connecting two non-consecutive nodes along that cycle.
 It is known that any Markov network MRF obtained from a non-chordal graph entails two conditional independence relationships such that no BN can entail both relationships at the same time [23]. The following theorem shows that the conditional independencies entailed by non-chordal graphs can instead be modeled by means of HRFs:
Theorem 2. For any non-chordal graph G ,thereexist two conditional independence statements such that no BN can entail both statements at the same time, while a HRF can always be constructed so as to entail both statements.
Proof. Suppose that C = { X 1 ,...,X n } is a subset of the nodes in G such that n  X  4and C is a cycle that does not contain any chord. For any way of directing the edges in C so as to obtain a BN BN containing X 1 ,...,X n there will be a pair of non-adjacent nodes X i and X j in BN sharing a common child X k ,where1  X  i, j, k  X  n . Now, the Markov network MRF resulting from G entails that X i and X j are independent given { X k ,X l } (where X is any node in C\{ X i ,X j ,X k } ), because the paths con-necting X i and X j are blocked by { X k ,X l } . For an analo-gous reason, MRF entails that X k and X l are independent given { X i ,X j } . Although BN can entail the latter con-ditional independence by having its edges so directed that the meetings at X i and X j are not head-to-head, X i and X j are not d-separated by { X k ,X l } , which means that BN does not entail the conditional independence of X i and X given { X k ,X l } .ConsidernowaHRF HRF containing all nodes in C .Set MB i ( X i )= MB j ( X j )= { X k ,X l } and MB k ( X k )= MB l ( X l )= { X i ,X j } . Then, HRF entails both that X i and X j are independent given { X k ,X l } and that X k and X l are independent given { X i ,X j } . The fact that HRFs generalize BNs does not mean that HRFs are a better probabilistic model than BNs. The proper conclusion we can draw from Theorems 1 and 2 is that by using HRFs instead of BNs we do not lose any representa-tional power. On the contrary, by using HRFs we acquire the capability of representing (if needed) some conditional independencies that are not representable by BNs. An em-pirical argument to the effect that HRFs (coupled with a particular structure learning technique) are a reliable prob-abilistic tool for link-prediction applications is provided by the promising results of the ex periments reported in Sec. 6.
In HRFs, parameter learning consists of learning the con-ditional probability tables (CPTs) of the BNs modeling the local conditional distributions, given that each G i has been specified. We use the technique described below [20]. Since the technique applies in general to any BN, in order to de-note the parents of node X i we use the notation PA ( X i rather than PA i ( X i ).

Consider a dataset D , where each data point d j is a vec-tor ( x 1 j ,...,x n j ). For a node X i having no parents in the graph, we only need to estimate the absolute distribution P ( X i ). For each value x i k of X i , our estimate is the follow-ing: where N is the equivalent sample size [17]. In particular, we assume to have observed any particular value x i k for a num-ber of times equal to p  X  N ,where p is the prior probability that X i = x i k . In our implementation of BNs (and HRFs) in this work, we assign uniform prior probabilities to the dif-ferent values of each variable. Therefore, we set p i k = where D i is the domain of variable X i . The value we assign
For a node X i having parents PA ( X i ), we need to esti-mate a distribution P ( X i |PA ( X i )= pa ( X i )) for each pos-sible state pa ( X i )of PA ( X i ). For each value x i k estimate is the following:
P ( X i = x i k |PA ( X i )= pa ( X i )) = all possible states of PA ( X i ). As a result, each value x of a non-root node X i turns out to have been observed ex-actly N |D i | times within the equivalent sample, where N p
Structure learning in HRFs con sists of learning, for each variable X i , what other variables appear in BN i ,andwhat edges are contained in G i . We now present a heuristic struc-ture learning algorithm for HRFs, which we call  X  X arkov Blanket Merging X  (MBM). The aim of MBM is to find an assignment of MBs MB 1 ( X 1 ) ,..., MB n ( X n )to X 1 ,...,X that (locally) maximizes the model pseudo-likelihood given a dataset D . The basic idea is to start from a certain as-signment of relatives to the model variables, to learn the local BNs of the model, and then to iteratively refine the assignment so as to come up with MBs that increase the model pseudo-likelihood with respect to the previous assign-ment. The algorithm stops when no further refinement of the MBs increases the model pseudo-likelihood. MBM is a local search algorithm exploring a space of possible MB assignments to the model variables.

In order to develop the algorithm, we specify three com-ponents: ( i ) a way to produce the initial assignment, i.e. a model initialization strategy; ( ii ) a way to refine a given as-signment so as to produce an alternative assignment, i.e. a search operator; ( iii ) a way to evaluate a given assignment, i.e. an evaluation function. These three components are de-scribed in Sec. 4.2. Before addressing them, we specify (in Sec. 4.1) a general technique for learning the structure of BNs, since this technique will be used within MBM. While parameter learning requires that the graph of the BN has been previously specified, structure learning aims at inferring from a dataset the graph itself (together with the CPTs). A general way of formalizing this task consists in viewing it as a search problem. Given the random variables X ,...,X n , the problem space is the set of all possible di-rected acyclic graphs (DAGs) with nodes X 1 ,...,X n ,and the task is to find the DAG such that the corresponding BN maximizes a given evaluation function. Therefore, given the search space, what we have to specify is first a suitable eval-uation function, and second a search strategy allowing us to effectively explore that space.
 Given a BN h and a set D of patterns x 1 ,..., x m ,wewrite Algorithm 1 Learning the structure of a BN Input: BN h ; dataset D . 1. do 2. s = mdl ( h ) 3. N = { n : n is a neighbor of h } 4. h = the highest-scoring element of N 5. s = mdl ( h ) 6. if( s &gt; s ) 7. h = h 8. while( s &gt; s ) 9. return h down the joint probability of D given h in the following way: where pa j ( X i ) stands for the state of the parents of X is determined by pattern x j . Our choice for the evaluation function is based on the minimum description length (MDL) principle [24]. The version of the MDL principle that we use for structure learning takes the form of the function mdl ( h ), defined as follows: where par ( h ) is the number of parameters specified in h . mdl ( h ) penalizes the likelihood of h to an extent that is proportional to the network complexity, where complexity is measured by par ( h ). It can be shown that mdl ( h )is asymptotically correct [26, 20].

Given the evaluation function, we specify a strategy for searching the model space. In order to find the model with the highest MDL score, we use a hill-climbing algorithm. The algorithm starts from a BN h with an empty DAG, and it generates a set of neighbors of h ,whereaneighborisa BN whose DAG is obtained from h in one of three ways: ( i ) adding one arc; ( ii )removingonearc;( iii ) reversing one arc. Once a new DAG has been constructed, a correspond-ing BN is obtained by learning the CPTs for that DAG. While generating new DAGs, we need to discard the ones containing cycles. The neighbors of h are scored, and the highest-scoring neighbor h is compared to h .If h scores better than h , the whole cycle is iterated for h ,andthe process continues until no neighbor of the currently accepted network improves on the score of that network. In order to speed up the search, a useful trick is to maintain a tabu list, keeping track of the states explored at each cycle, so as to prevent the algorithm from scoring several times models already encountered during the search. The pseudocode of Algorithm 1 implements the strategy just described.
MBM produces an initial assignment by choosing an ini-tial size k of the set of relatives, and then by selecting as relatives of each X i the k variables that display the highest dependence (as measured by the  X  2 test) with respect to X . Given the sets of relatives, an assignment of MBs to the respective variables is obtained by learning (both the struc-ture and the parameters of) BN i for each variable X i ,where BN i contains X i together with its relatives R ( X i ). In order to learn the structure of the local BNs, we use Algorithm 1. In each application, a suitable value for k can be assessed by preliminary cross-validation.

Given a current assignment of MBs to the model variables, where the assignment is given by MB 1 ( X 1 ) ,..., MB n ( X (as determined by BN 1 ,...,BN n ), a new assignment is ob-tained as follows. For each variable X i ,weconstructtheset U as the union of MB i with the MBs of X i in all graphs G j such that X i appears in G j . Given the sets U 1 ,..., U first check whether the cardinality of each U i does not ex-ceed a certain threshold k  X  , and then we construct a new set of BNs BN 1 ,...,BN n such that, if |U i | X  k  X  ,then BN i the BN learned (from the dataset at hand) for the variables in { X i } X  X  i ,whereas,if |U i | &gt;k  X  ,then BN i = BN i .Given the networks BN 1 ,...,BN n , a new assignment of MBs to X ,...,X n is obtained in the following manner. For each X , we compare the value value tively, the conditional log-likelihoods of X i given its MB, as determined on the one hand by BN i , and on the other hand by BN i . If the latter value is higher than the former, i.e. if the conditional log-likelihood of X i given its MB increases after replacing MB i ( X i )with MB i ( X i ), then MB i ( X chosen as the MB of X i in the new assignment, otherwise X i is assigned again MB i ( X i ). As for the parameter k in the model initialization step, a suitable value for k  X  can also be determined by means of cross-validation.

An assignment of MBs to the variables is evaluated by measuring the model pseudo-log-likelihood, i.e. the loga-rithm of the formula given in Eq. 2. Therefore, the evalua-tion function for model h given dataset D is the following: In fact, by defining an alternative assignment based on the current one, MBM implicitly evaluates the new assignment, because the new assignment will differ from the old one only if there is at least one variable X i such that the new MB of X i increases the conditional log-likelihood of X i given the MB. Clearly, an increase in any one of the n local log-likelihoods ensures an increase in the global (pseudo-)log-likelihood. The reason is that our search operator works in a modular fashion, that is the way each MB i ( X i )ismodified during MBM is such that the change does not affect any other MB within the model. Therefore, after MBM builds a new assignment, it is sufficient to compare it to the old one in order to know whether it increases the model pseudo-likelihood: if the two assignments are different, then MBM endorses the new assignment (as a better one), otherwise the old assignment is retained and MBM stops searching. Pseudocode for MBM is provided by Algorithm 2.

By using bounds on the size of the sets of relatives, MBM restricts significantly the size of the search space with respect to Algorithm 1. To understand why, consider that the total number of DAGs containing n nodes is given by a function f ( n ) which grows exponentially with n [5]. On the other hand, given the upper bound k  X  on the size of the set of relatives, the worst-case size of the search space for MBM is given by f  X  ( n )= i  X  n  X  f ( k  X  ), where i is the number of iterations run by MBM until convergence. This result is particularly encouraging, since f  X  ( n ) grows only linearly with n .
 Algorithm 2 Learning the structure of a HRF Input: Set X of variables X 1 ,...,X n ; dataset D ; integers k , k  X  .
 External routines:  X  2 ( i, j ) , returning the value of the  X  test on X i and X j ; learnBN( X i , R i ) , using Algorithm 1 to learn a BN for { X i } X  X  i from D ; getMB( X i ,BN j ) , return-ing the MB of X i in BN j if X i is in BN j ,or  X  otherwise; getL( X i , MB i ) , returning 1. for(i = 1 to n) 2. R i = { X j in X \{ X i } with k -top  X  2 ( i, j ) } 3. do 4. assignmentW asRef ined = false 5. for(i = 1 to n) 6. BN i = learnBN( X i , R i ) 7. for(i = 1 to n) 8. U i = 9. for(i = 1 to n) 10. if( |U i | &lt;= k  X  ) 11. BN i = learnBN( X i , U i ) 13. MB i = getMB( X i ,BN i ) 14. if(getL( X i , MB i ) &gt; getL( X i , MB i )) 15. R i = MB i 16. assignmentW asRef ined = true 17. while( assignmentW asRef ined ) 18. h = { BN 1 ,...,BN n } 19. return h
Dependency networks (DNs) significantly reduce the com-putational cost of learning with respect to BNs and MRFs [11]. While the structure of DNs is fixed by using a feature selection algorithm to assign each node a set of neighbors (i.e. a MB), in MBM feature selection only initializes the model structure, and the HRF can then be refined to better fit the data distribution. HRFs can be viewed as a particu-lar class of DNs, designed with the primary aim of allowing for iterative stru cture learning.

Chain graphs (CGs) define a mathematical framework for studying the properties of probabilistic graphical models at a high level of abstraction [15]. BNs and MRFs are special cases of CGs. While the basic idea of developing a formalism capable of subsuming some known classes of probabilistic graphical models is common to CGs and HRFs, our work on the latter models is more strictly focused on learning and its algorithmic aspects, such as scalability. In practical applications, CGs have been learned in the form of particular graphical models (such as BNs and MRFs) or combinations thereof [4]. Since our experimental study compares HRFs to BNs and MRFs, our model is thereby compared to the most representative kinds of CGs for which effective learning algorithms exist.

The  X  X ocal to global search X  algorithm [13] for MB dis-covery achieves computational efficiency whithout making the faithfulness assumption. However, this algorithm is not generally warranted to optimize the chosen evaluation func-tion, since the score of the learned network can happen to decrease during the learning process.

A computationally efficient method for learning MBs is the Max-Min Markov Blanket (MMMB) algorithm [28]. A crucial difference between MMMB and MBM is that the former method is committed to the faithfulness assumption [27, 20] with respect to the learned BNs, which is dispensed with in MBM.
We now offer an experimental investigation of the behav-ior of HRFs in a number of respects, comparing them to BNs, MRFs, DNs, and also to the naive Bayes (NB) estima-tor [6]. In Sec. 6.1 HRFs are applied to some link-prediction tasks, while Sec. 6.2 explicitly focuses on the computational burden of learning HRFs as opposed to related graphical models. All models and algorithms have been implemented in the JProGraM software library, which is released at http://www.dii.unisi.it/~freno/ under an open-source license. The same website also hosts those datasets used in this work that are not otherwise available on the web.
Before describing the experiments, we briefly explain how we use MRFs and DNs. Concerning MRFs, joint distri-butions are estimated using the pseudo-likelihood approx-imation (for the sake of computational efficiency). The model weights are learned by means of a maximum (pseudo-)likelihood strategy. In particular, the model pseudo-likelihood is optimized using the L-BFGS algorithm [16]. In order to construct the graph in MRFs, we adopt the fol-lowing strategy. First, for each variable X i in the domain, we run a  X  2 test between X i and each other variable X j in order to measure the strength of the correlation existing between X i and X j . Then, for each X i , we select the k variables that achieve the highest scores on the  X  2 test, and we add these k variablesasrelativesto X i . Ineachappli-cation, a suitable value for k is determined by preliminary cross-validation. Clearly, the way we construct the graph in MRFs is very similar to the model initialization step in HRFs.

Concerning DNs, a set of k neighborsisassignedtoeach node based on the results of the  X  2 test, where k is tuned by preliminary validation tests. The local distributions are then learned using the techniques suggested in the relevant literature [11, 7]. In all the experiments described below, the parameter k will refer to the number of neighbors (or relatives) initially assigned to each node based on the results of the  X  2 test, both in the case of MRFs, DNs, and HRFs. On the other hand, the parameter k  X  will denote the upper bound on the size of the set of relatives considered when learning HRFs by MBM.
Sec. 6.1.1 explains how probabilistic graphical models are applied to link prediction tasks. Two applications to the task of predicting references in scientific papers are described in Sec. 6.1.2, while Sec. 6.1.3 deals with the collaborative recommendation of movies. HRFs are compared not only to BNs, DNs, and MRFs, but also to the naive Bayes (NB) algorithm [6].
In general terms, our link-prediction system has to deal with a set of users of a database and a set of items contained in the database, where the items can be papers, movies, or virtually anything else. For each user, information is avail-able concerning which items in the database have already been chosen by that user. Formally, the aim of the system is to compute, for each user, a scoring function measuring the expected interest of the user for each item in the database. The goal is to measure the interest in items that the user has not yet considered, so that they can be ranked according to their relevance for the next choice the user will make.
We denote the set of database users as U = { u 1 ,...,u m and the set of database items as O = { o 1 ,...,o n } .For each user u i ,wehaveaset O i  X  X  of items such that O i contains the items already chosen by u i .Theaimof the link-prediction system is to provide, for each user u scoring function score i ( o j ), defined for each item o database, such that, if score i ( o j ) &gt;score i ( o k then the predicted interest of u i in o j is higher than the predicted interest of u i in o k . Therefore, the scoring function score i ( o j ) allows to rank objects in the database according to their expected interest to u i .

In order to predict the interest a user u i will have in object o , the kind of information we try to exploit is the condi-tional probability of choosing (i.e linking to ) o j given the set O i of objects that u i is known to have already chosen. If we define a way to estimate that conditional probability using each model, then we can simply use the value of that probability as the score assigned by each model to the object being ranked. In other words, if o j is the object we want to rank for u i once we know the elements of O i ,thenforeach model we need to specify a way to compute the value of the function score i ( o j ), defined as follows: where L i ( o j ) is a boolean function such that That is, L i ( o j ) is simply the truth function of the sentence  X  u i will link to o j  X .

The NB classifier can be applied to link prediction and collaborative recommendation in the following way [18, 25]. If o j is the object we want to rank for user u i ,thenwe compute the following scoring function: score i ( o j )= =log P ( L i ( o j )=1)+ In order to estimate the probabilities referred to in Eq. 10, our relational dataset is formalized as a set of patterns { d 1 ,..., d m } , such that each d i is a boolean vector ( L i ( o 1 ) ,...,L i ( o n )) specifying which objects were chosen by u . In other words, for each user we construct a correspond-ing pattern whose dimension is the total number of objects contained in the database. Therefore, the resulting dataset will contain a number of patterns which is equal to the num-ber of database users. Given such a dataset, absolute and conditional probabilities are estimated by computing rela-tive frequencies and exploiting them in the way described in Sec. 3. This formalization of the data is also exploited for applying the other probabilistic models.

The way that BNs, DNs, MRFs, and HRFs are applied to ranking is the following. Given the formalization of the dataset described above, we first learn a model containing n (boolean) random variables X 1 ,...,X n ,where n is the number of objects contained in the database and each X j corresponds to object o j . Once the model has been learned, the notion of MB provides a conceptually straightforward (and computationally very efficient) way of computing the value specified in Eq. 8: score i ( o j )= P ( L i ( o j )=1 | where each x k i is the value of L i ( o k ), and mb i ( X state of the MB of X j in the graphical model, as that state is determined by pattern d i .
The task we deal with in this section is the prediction of citations in research papers. In particular, given a paper containing a specific set of references, the task is to rank all remaining papers in a certain database, based on their relevance as additional references to be included in the paper at hand.

We test the ranking algorithms on the CiteSeer and Cora datasets. We exploit a preprocessing of the data which is publicly available at http://www.cs.umd.edu/projects/ linqs/projects/lbc/index.html . From each dataset we extract the citation graph of the paper corpus. We then check the number of references contained in each paper, and we remove papers that do not contain at least 3 references. After this preprocessing, each dataset is formalized as a list containg m vectors of n boolean features, where each vec-tor is a paper and each feature stands for the presence or absence of a certain reference within the paper. For the Cite-Seer dataset we have that m = 547 and n = 1067, while for Cora we have that m = 956 and n = 1229. In other words, m corresponds to the number of database users, while n corresponds to the number of database objects.

Each dataset is partitioned into training and test sets ac-cording to a 5-fold cross-validation procedure. The test con-sists in the following task. For each example (i.e. a paper) in the test set, we remove one reference from the paper, and we require the tested model to rank that reference given the remaining references contained in the paper at hand. The idea behind this query is that the removed reference should receive the highest possible rank from a good ranking algo-rithm.

The result of ranking is evaluated using the mean recip-rocal rank (MRR) metric. If j is the index of a certain example (hence query) within the test set, o j is the object (that is the reference) that should receive the highest rank for that query, and rank ( o j ) is the rank assigned to o the algorithm at hand, then MRR is defined as follows: where m is the size of the test set. The results of the exper-iments are shown in Tables 1 X 2.

Concerning the standard BN model, the dimensionality of these tasks prevents us from applying Algorithm 1 because of computational limitations. Therefore, BNs are trained us-ing the K2 structure learning algorithm [5], where the model likelihood is used as evaluation function and the maximum number of parents allowed for each node is set to 2. Al-though the K2 algorithm is much faster than Algorithm 1 Table 1: MRR values (5-fold cross-validation) mea-sured on the CiteSeer dataset for BN, DN ( k =8 ), HRF ( k =8 , k  X  =10 ), MRF ( k =3 ), and NB. (at the cost of being less accurate), it is still very expensive to run for high-dimensional problems. In fact, its worst-case computational complexity is O ( n 4 )[5]. OntheCite-Seer dataset, K2 requires about 20 hours computation on a 1.83 GHz PC architecture, while for Cora it requires about 40 hours. On the other hand, the difference between run-ning MBM on the CiteSeer dataset and running it on Cora is relatively small (in the order of a few minutes), and in both cases training time does not exceed 1 hour. Learning DNs is even less expensive. Training time for NB is also not significant (about half an hour on Cora), whereas MRFs require about 6 hours training for CiteSeer and 8 hours for Cora.
 Table 2: MRR values (5-fold cross-validation) mea-suredontheCoradatasetforBN,DN( k =8 ), HRF ( k =8 , k  X  =10 ), MRF ( k =3 ), and NB.
 The results of the experiments are quite encouraging for HRFs. Both HRFs and BNs significantly outperform NB and MRFs. In general, the behavior of HRFs and BNs is much more reliable across the two tasks than the behav-ior of NB and MRFs, for the following reason. While MRFs outperform NB on the CiteSeer dataset, NB outperforms in-stead MRFs the Cora dataset. Given this result, the kind of probability distribut ion underlying the former domain must be significantly different from the distribution revealed by the second one. Since both HRFs and BNs behave stably well across the two tasks, the experiments show these two models to be more robust than the competing ones. Finally, the advantage of HRFs over DNs is pretty strong. For this reason, we believe that the kind of structure learning im-plemented by MBM makes pseudo-likelihood estimation in HRFs much more robust than it is in standard DNs. The task we deal with in this section involves the Movie-Lens database. The dataset used in the experiment contains data concerning 1,682 movies. The number of database users is 943. The MovieLens da taset is publicly available at http://www.grouplens.org/ . We formalize the Movie-Lens link-prediction task according to an implicit-voting-with-binary-preferences strategy [3].  X  X mplicit voting X  means that we only exploit information concerning whether a user rated a certain item or not, without taking into account the specific rating. Therefore, user choices are modeled as  X  X i-nary preferences X . Given such a formalization, applying the ranking strategy described in Sec. 6.1.1 is straightforward.
For the MovieLens database, we also consider the results achieved by the ItemRank (IR) recommender system [10]. The reason is that, to the best of our knowledge, the results achieved by IR on this particular dataset are the best ones achieved thus far with respect to the evaluation metric we also adopt in the experiments, and therefore they provide an authoritative term of comparison for evaluating the behavior of HRFs.

Results on the MovieLens link-prediction task are evalu-ated using two versions of the degree of agreement (DOA) metric, which we describe next. The DOA metric is aimed at measuring how accurate a ranking of database items is for a user u i . Let us denote by L a given training set and by T the corresponding test set. Moreover, let L i denote the set of movies such that each one of these movies is rated by u in L ,and T i the set of movies rated by u i in T . Finally, let N i denote the set of movies that are never rated by u that N i = O\ ( L i  X  X  i ). The first step in specifying the DOA for a ranking algorithm R is to define, for each user u i for any pair of movies o j and o k , a function order i ( o such that where R i ( o j ) is the rank assigned by R to movie o j for user u . Given this function, we define the DOA for each user u i in the following way: For each user u i ,DOA i measures the percentage of movie pairs in T i  X N i ranked in the correct order by the algorithm at hand.

Once defined the DOA with respect to each user u i ,we specify macro-averaged and micro-averaged DOA. The macro-averaged DOA is defined as In other words, the macro-DOA is the average of all DOA i such that T i is not empty. On the other hand, the micro-averaged DOA is given by micro-DOA = Clearly, the micro-DOA assigns a higher weight to users with a larger number of ratings in the test set, whereas the macro-DOA assigns the same weight to all users, no matter how many ratings are present in the test set for each one of them.
Macro-averaged and micro-averaged DOA values are mea-sured by 5-fold cross-validation. The test employs a publicly available partitioning of the dataset into five pairs of train-ing and test sets, which allows to easily compare different results to be found in the literature. Training the MRF model requires about 12 hours on average for each fold (on the same PC architecture used for the previous measure-ments). The number of feature functions contained in each model (averaged over the five MRFs learned for the different folds) is equal to 16,396. This means that, in order to learn the weights of each MRF, we need to optimize a function of 16,396 parameters (on average). On the other hand, learn-ing HRFs by MBM takes about one hour and a half for each fold, while training DNs requires less than one hour. Table 3 collects the results. BNs are not included in this compari-son because the K2 algorithm does not finish running in 72 hours.
 Table 3: Average DOA (  X  standard deviation) mea-sured on the MovieLens dataset for DN ( k =8 ), HRF ( k =8 , k  X  =10 ), IR, MRF ( k =3 ), and NB.

The HRF model achieves the highest accuracy with re-spect to the macro-averaged DOA, while its performance is nearly equivalent to the best one (achieved by MRFs) with respect to the micro-averaged DOA. Both MRFs and HRFs are more accurate than NB and IR, according to both evalu-ation metrics. On the other hand, the accuracy displayed by DNs is significantly lower with respect to all other models. In order to compare the computational cost of learning HRFs to the cost of learning BNs, MRFs, and DNs, we measure the time needed to learn the respective models from a number of artificial datasets of growing dimensionality. Each dataset contains 1000 patterns, drawn from a single distribution (that is from only one class). All features are binary. Given each dataset, we measure the time needed for learning ( i ) BNs using Algorithm 1, ( ii ) BNs using the K2 structure learning algorithm, ( iii )DNs,( iv )HRFs,and ( v ) MRFs using the algorithms described above. Clearly, while we are going to learn the structure (and not only the parameters) of BNs and HRFs, for DNs and MRFs we only learn the parameters, since for the latter models structure learning is limited to the initialization of the MBs. This means that the task is more demanding in the case of BNs and HRFs. For MRFs the value of k is set to 6, for DNs it is set to 8, while for HRFs the values of k and k  X  are set to 8 and 10 respectively. In the K2 algorithm, likelihood is used as evaluation function and the maximum number of parents allowed for each node is set to 3. We choose these specific parameter values because they are the largest ones we ever considered in our applications, while tuning the parameters in preliminary cross-validation runs of the experiments. Time was measured on a PC equipped with a 2.34 GHz processor. The results are illustrated in Figs. 1 X 4, where learning time (in seconds) is plotted for the different models against the increasing dimensionality of the data. Figure 1: Learning time for BNs (Algorithm 1) and HRFs ( k =8 , k  X  =10 ) as the problem size increases. Figure 2: Learning time for BNs (K2 algorithm) and HRFs ( k =8 , k  X  =10 ) as the problem size increases. The comparison displays a clear advantage of HRFs over BNs and MRFs. The improvement of HRFs over BNs (trained with Algorithm 1) is dramatic, while the difference between HRFs and MRFs is less consistent. Concerning the K2 al-gorithm for BNs, training time grows much more quickly than the corresponding time for HRFs. Although K2 is very fast for low-dimensional datasets, the time measurements reported in the figures show that as the number of variables increases, learning HRFs (or even MRFs) becomes more and more convenient with respect to learning BNs. The signifi-cance of the gap between MBM and K2 becomes even more apparent if we consider the time measurements reported (in Sec. 6.1) for the link-prediction experiments, where we deal with datasets involving more than a thousand variables. On the other hand, learning DNs is more efficient than learning HRFs, but in this respect we should note once again that MBM is a full-fledged structure learning algorithm, while for DNs (as for MRFs) only the parameters are learned. More-over, the increase in the amount of time needed to learn HRFs with respect to learning DNs is quite small if com-pared to the amount of time needed to learn BNs or MRFs. Figure 3: Learning time for DNs ( k =8 )andHRFs ( k =8 , k  X  =10 ) as the problem size increases. Figure 4: Learning time for MRFs ( k =6 )andHRFs ( k =8 , k  X  =10 ) as the problem size increases.
The investigation on HRFs presented in this paper allows us to draw two conclusions. On the one hand, MBM is able to learn networks of probabilistic relationships to a degree of accuracy that is higher than (or comparable to) the ac-curacy displayed by standard learning algorithms for BNs, DNs, and MRFs. On the other hand, the accuracy of MBM is coupled with a dramatic improvement, in terms of com-putational efficiency, over standard learning techniques for BNs and MRFs.
 Two limitations of HRFs need to be considered too. First, HRFs are more suitable for pseudo-likelihood estimation than they are for learning joint probability distributions. The reason is that computing a strict joint probability in HRFs requires to perform Gibbs sampling, which can take considerable time before converging to a stationary point. Second, learning HRFs by MBM is computationally more expensive than learning DNs. However, the heavier burden of learning HRFs as compared to DNs is largely compen-sated for by the higher prediction accuracy of the learned models.
The authors are grateful to Manfred Jaeger for providing suggestions and comments concerning a preliminary version of this work. [1] J. Besag. Spatial Interaction and the Statistical [2] J. Besag. Statistical Analysis of Non-Lattice Data. [3] J. S. Breese, D. Heckerman, and C. M. Kadie.
 [4] S. Carroll and V. Pavlovic. Protein Classification [5] G.F.CooperandE.Herskovits.ABayesianMethod [6] P. Domingos and M. Pazzani. On the Optimality of [7] N. Friedman and M. Goldszmidt. Learning Bayesian [8] N. Friedman and D. Koller. Being Bayesian about [9] W. R. Gilks, S. Richardson, and D. Spiegelhalter. [10] M. Gori and A. Pucci. ItemRank: A Random-Walk [11] D. Heckerman, D. M. Chickering, C. Meek, [12] D. Heckerman, D. Geiger, and D. M. Chickering. [13] K.-B. Hwang, J. W. Lee, S.-W. Chung, and B.-T. [14] R. Kindermann and J. L. Snell. Markov Random [15] S. L. Lauritzen and N. Wermuth. Graphical Models [16] D. C. Liu and J. Nocedal. On the Limited Memory [17] T. M. Mitchell. Machine Learning . McGraw-Hill, 1997. [18] K. Miyahara and M. J. Pazzani. Collaborative [19] J. Moussouris. Gibbs and Markov Random Systems [20] R. E. Neapolitan. Learning Bayesian Networks . [21] S. Parise and M. Welling. Bayesian Model Scoring in [22] J. Pearl. Evidential Reasoning Using Stochastic [23] J. Pearl. Probabilistic Reasoning in Intelligent [24] J. Rissanen. Stochastic Complexity. Journal of the [25] V.Robles,P.Larra  X  naga, E. Menasalvas, M. S. P  X  erez, [26] G. Schwarz. Estimating the Dimension of a Model. [27] P. Spirtes, C. Glymour, and R. Scheines. Causation, [28] I. Tsamardinos, C. F. Aliferis, and A. R. Statnikov.
