 When s u rfin g the Web, especially browsin g news reports, we are ea g er for q u ick access to the most important information with least time. L u ckily, researchers have paid m u ch effort to the extraction of a brief and to-the-point s u mmary. News s u mmarization has u nder g one development from monolin gu al to m u ltilin gu al, from text s u mmarization to cross-media s u mmarization, from sin g le-point s u mmarization to timeline.
Meanwhile, topic-foc u sin g or even personalization is a g rowin g trend of all kinds of Internet applications, s u ch as recommendation systems, searchin g res u lts, apps, and so on. As we know, a news event u s u ally involves several topics of information, for instance, economy, politics, m ilitary and history. Users from a specific field may show interests in only some specific topics. Therefore, a s u mmary which is foc u sed on a predefined topic can help to satisfy u sers  X  interests in this topic. L u hn [10] proposes that we can take a partic u lar sphere of interest into consideration for personalization. P aice and Jones [12] also find that u sers wo u ld consider an abstract a  X  g ood X  one as it incl u des the detail they are interested in.

Altho ug hprevio u sst u dies have addressed the problem how to extract the topic-biased contents for a topic-foc u sed s u mmary, they seldom disc u ss covera g e, topic bias and content coherence at the same time. In this paper, we propose a framework to pro-d u ce topic-foc u sed s u mmarization for a g iven news event, based on topic-biased snippet extraction and selection. O u r method exhibits excellent performance in all of these three aspects.

The contrib u tions of o u r work can be s u mmarized as follows: 1. We present a framework to prod u ce topic-foc u sed s u mmarization by retainin g in-2. We employ snippets, each of which is composed of several consec u tive sentences, 3. We select snippets based on topic-relevancy as well as content-relevancy, and hence 2.1 Keyphrase Extraction Keyphrase extraction is the basis for f u rther knowled g e discovery and data minin g . Sakai and Mas u yama [14] assi g nlar g ewei g hts to no u ns appearin g locationally and chronolo g ically front. Frank et a l. [6] and T u rney [15] determine whether a g iven n-g ram is a keyphrase or not u sin g a model trained with annotated data beforehand. Bo u din et a l. [2], Mihalcea and Tara u [11], Wan and Xiao [16] foc u son g raph-based likelihood ratio test based on their relative freq u encies in relevant and irrelevant doc u -ment sets. 2.2 Snippet Extraction In o u rprevio u sst u dy [17], we propose snippet, which is composed of several consec u -tive sentences, to describe an entity. Startin g from a head sentence, a snippet g rows u p by addin g relevant nei g hborin g sentences into itself. Most st u dies on s u mmarization so far are based on sentences or para g raphs, while the proposition of snippets can provide a new idea for more coherent and informative s u mmarization. 2.3 Personalized Summarization P ersonalization is a g rowin g trend of all kinds of Internet applications, s u ch as recom-mendation systems and searchin g res u lts. Sakai and Mas u yama [14] let a u ser choose keywords which he/she is interested in and increase the wei g ht of the chosen words. D  X   X az and Gerv  X  as [5] ask a u ser for words to describe his interest and model it. Yan et a l. [18] s u pport u ser interaction of clickin g into the s u mmary sentences and examinin g so u rce contexts, which implicitly indicates what readers are interested in. Q u and Chen [13] combine collaborative filterin g and s u mmarization, makin gu se of the information that u sers with similar interests ta gg ed. H u et a l. [7] make u se of social websites and bookmarkin g sites to personalize s u mmarization. To make a topic-foc u sed s u mmary for a g iven event, we first constr u ct correspondin g topic si g nat u re u sin g the method in [9], and then we extract biased snippets based on the topic si g nat u re. In o u r method, snippets rather than sentences and para g raphs are u sed as text u al components of the s u mmary for both content coherence and covera g e. After extractin g snippets, we cl u ster them for the consideration of red u ndancy elim-ination, decidin g the n u mber of cl u sters thro ug h an optimization problem involvin g inner-cl u ster coherence and inter-cl u ster diversity. We select one representative snippet from each cl u ster accordin g to content-relevancy as well as topic-relevancy. After that, we order the selected snippets chronolo g ically and hence we g et the final res u lt.
Fi g . 1 shows the whole process of o u r method. We will explain each step as follows, and u se s to denote a sentence and S to denote a snippet.
 3.1 Topic-Biased Snippet Extraction In o u rprevio u sst u dy [17], we propose the concept snippet and a snippet g rowth model. Startin g from a head-sentence, a snippet g rows u p by addin g relevant nei g hborin g sen-tences into itself, while the relevancy is decided by text similarity, distance f u nction and infl u ence f u nction. In this paper, we expand o u r model to emphasize information related to a g iven topic, as shown in Al g orithm 1. Let u s describe the f u nctions u sed in Al g orithm 1 one by one.

Given some topics and preclassified doc u ment sets foc u sed on different topics re-spectively, we can constr u ct different topic si g nat u re from the correspondin g preclassi-fied doc u ment set u sin g  X  2 log X  , which is comp u ted by Lin and Hovy  X  s method [9].  X  is likelihood ratio and more appropriate than  X  2 test for sparse data, and the q u antity  X  2 log X  is asymptotically  X  2 distrib u ted.

To choose appropriate topic-biased head sentences, we comp u te  X  2 log X  for each word w in each sentence, and then we g et hs val u efor s ,asshowninEq u ation 1.
Text similarity is comp u ted by Eq u ation 2, where s expanded is the expanded word set of sentence s . With the help of WordNet, we expand sentence s with the synonyms, hypernyms and hyponyms of each no u nandverbin s . Algorithm 1. Topic-biased snippet g rowth model
In distance f u nction (see Eq u ation 3), d ij is the n u mber of sentences between s i and s and  X  is a coefficient.
In infl u ence f u nction (see Eq u ation 4), x 0 is the coordinate of head-sentence, d 0 i is the distance between head-sentence and s i ,  X  is a coefficient decidin g the len g th of a snippet to some extent.  X  and  X  are the mean and standard deviation of the variables nat u ral lo g arithm. 3.2 Snippet Clustering Snippets we g et in Section 3.1 may share similar information with each other. To red u ce information red u ndancy, we u se LDA method to cl u ster the extracted snippets, and then select one representative snippet from each cl u ster.

To decide the n u mber of cl u sters for each topic (denoted as K ), we desi g nanal-g orithm (Al g orithm 2) which can achieve both hi g h inner-cl u ster coherence and inter-cl u ster diversity.

We first define coherence and diversity for the cl u sterin g res u lt u nder K as Eq u ation 5 and 6. C denotes the set of K cl u sters { c 1 , c 2 ,..., c K } . Coherence is comp u ted as the reciprocal of avera g e inner-cl u ster semantic distances of all cl u sters, and diversity is the avera g einter-cl u ster semantic distances of every two cl u sters. Semantic distance between two snippets KL ( S i ,S j ) is comp u ted as K u llback-Leibler Diver g ence.
K u llback-Leibler Diver g ence is g iven as Eq u ation 7, based on semantic probability distrib u tion of words in a snippet p ( w l | S ) .

Semantic probability distrib u tion is g iven as Eq u ation 8, estimated by word fre-q u ency.
In Eq u ation 9, tf ( w l ,S ) is the freq u ency of word w l in snippet S ,and w expanded is the expanded word set of w . It assi g ns lower freq u ency to a word that is expanded o u t with more words.

Act u ally the problem of snippet cl u sterin g can be transformed into the followin g optimization problem: An approximate sol u tion is g iven in Al g orithm 2.
 Algorithm 2. Decision of K based on coherence and diversity 3.3 Snippet Selection After cl u sterin g , we select one snippet with hi g hest score from each cl u ster as can-didates to form the final s u mmary. Score is made u p of both content-relevancy and topic-relevancy, which are respectively eval u ated by news event keywords and topic si g nat u re.

We extract event keywords accordin g to Eq u ation 11, where d denotes news event doc u ment set and D denotes Goo g le N g ram corp u s. The final score of a snippet is comp u ted accordin g to Eq u ation 12. Content-relevancy is comp u ted accordin g to the part before pl u ssi g n ( X + X ), and topic-relevancy is after the pl u ssi g n.  X  denotes the wei g ht of content-relevancy and | S | is the n u mber of sentences in S . score ( S )= s
Accordin g to [1], chronolo g ical orderin g ,incl u din g p u blication date of a doc u ment and sentence position in the doc u ment, plays a major role in arran g in g sentences. Th u s we arran g e selected snippets in a chronolo g ical order to achieve the final s u mmary. 4.1 Datasets To extract the topic si g nat u res, we constr u ct fo u r doc u ment sets, which emphasize on economy, politics, military and history respectively. These doc u ments are collected from seven selected so u rces, as shown in Table 1. # Sents denotes the total n u mber of sentences in a doc u ment set.

In order to g et news doc u ments that contain information abo u t all of the fo u r topics, we collect a doc u ment set rather than u sin g an existin g one. As shown in Table 2 and Ta-ble 3, we u se  X  X iaoy u Islands X ,  X  X dward Snowden X ,  X 2013 US Government Sh u tdown X  and  X  X yria Crisis X  as q u eries and collect doc u ments from five infl u ential international news websites. # RS denotes the n u mber of reference s u mmaries, and # AvgLen ( RS ) is the avera g en u mber of sentences of reference s u mmaries.
 We perform anaphora resol u tionofpersonprono u ns and no u ns of time with Stanford CoreNL P , word stemmin g with P orter Stemmer, as well as stop-word removin g on these news event doc u ment sets. 4.2 Evaluation Metrics The covera g e of important information in a s u mmary is of si g nificance to the overall q u ality of the s u mmary. Most recent researches foc u sonthe ROUGE eval u ation [4], [8]. In o u r experiments, we comp u te ROUGE -1 for each method accordin g to Eq u ation 13, where Count match ( gram n ) is the maxim u mn u mber of n-g rams co-occ u rrin g in a candidate s u mmary and a set of reference s u mmaries.

Since there is not m u ch previo u s work, we employ a novel man u al approach to eval-u ate o u r contrib u tions, topic-biased information and content coherence.

Firstly, we eval u ate topic bias. We split the 4 s u mmaries of different topics into sen-tences, disor g anize them, and then present them to eval u ators. They are req u ested to classify these sentences into fo u r g ro u ps, foc u sin g on economy, politics, military and history respectively. We comp u te the F 1 -Measure accordin g to Eq u ation14toeval u -ate the o u tcome of topic bias. P is the precision while R is the recall of classification.
Next, we foc u s on content coherence. We consider a s u mmary to be coherent and lo g ical if its order of sentences corresponds to man u al orderin g . On the promise of a certain covera g e of important information, we disorder sentences in a s u mmary and req u est eval u ators to reorder them. We employ nDCG index ( g iven in Eq u ation 15) u sed in Information Retrieval to eval u ate the consistence of orderin g between reordered s u mmary and candidate s u mmary. IDCG is DCG val u e of the correspondin g s u mmary reordered by eval u ators. score i is the score of the ith sentence, and a hi g her score is assi g ned to a sentence with an earlier position in reordered s u mmary.

We compare o u r method with several baselines, listed as follows. 1. Random: It selects sentences and orders them randomly. 2. REF: Man u al s u mmary. 3. SUI: Sakai and Mas u yama  X  s method [14]. Its relevant keywords (selected by u sers) 4. S P :O u r proposed method, extractin g topic-biased snippets to form a topic-foc u sed 5. SL: O u r method witho u t topic-foc u sin g . It selects head-sentences randomly and 6. P L: O u r method witho u t snippet extraction. It extracts topic-biased sentences to 4.3 Overall Performance Comparison We s e t thres head as 4.2, thres expanding as 100,  X  as 10,  X  as 0,  X  as 0.25,  X  as 0.17,
Table 4 shows the top 8 si g nat u re terms for 4 topics. We can see that these terms describe each topic p roperly and distin gu ish from others. Table 5 shows the avera g e ROUGE  X  1 val u e of 4 news events of each method. We can find that o u r proposed method performs well. The reason why SL g ets poor scores may be that a reference s u mmary incl u des information of a specific topic which the res u lt of SL does not in-cl u de.

Table 6 shows the avera g e F 1 -score of 4 news events of each method. We find that both P LandS P achieve g ood F 1 -scores , that is, topic-biased information is well retained. All scores of historical topic are less than other topics. The reason may be that the si g nat u re terms we extract for this topic are relatively imprecise. Besides, news doc u ments themselves contain little historical information.

Table 7 shows the avera g e nDCG val u e of 4 news events of each method. We are aware that methods based on snippets (SL and S P ) perform m u ch better than others.
Table 8 shows the s u mmaries of  X  X iaoy u Islands X  prod u ced by o u r method. We do not show the history-foc u sed s u mmary since it incl u des some sensitive information. We can find that different topic-foc u sed s u mmaries have distinct information from others altho ug h they share some common information.

In order to show the topic bias between s u mmaries prod u ced by different methods, we provide Word Storm u sin g Castella and S u tton  X  s method [3]. From Fi g . 2, we can see that s u mmaries g enerated by REF, S P , P L and SUI contain some topic-biased words, s u ch as  X  X conomy X ,  X  X ank X ,  X  X ales X , and so on. The sizes of these words demonstrate their different importance in different s u mmaries. In this paper, we propose a framework to prod u ce topic-foc u sed s u mmarization for a g iven news event, based on topic-biased snippet extraction and selection. Experiments cond u cted on real data demonstrate a g ood covera g e, topic-relevancy, and content co-herence of the s u mmaries g enerated by o u r approach. As o u rf u t u re work, more rob u st eval u ations will be cond u cted. F u rthermore, we will try to prod u ce personalized s u m-marization by replacin g  X  X opic si g nat u re X  with  X  X erson si g nat u re X . Acknowledgments. We sincerely thank all the anonymo u s reviewers for their val u able comments, which have helped a lot to improve this paper. This work is s u pported by NSFC with Grant No. 61370054 and 973 P ro g ram with Grant No. 2014CB340405.

