
With t he rapid development of Internet and digital technology , a variety of new media which supports desired information automatically, quickly and intelligently from massive amounts of news. prominent . The traditional manually method of news abridgement is time -consuming when faced with requests.

Based on these problems and challenges, this paper pres ents a novel algorithm based on word given news with high density .

The contributions of our paper are as follows: 1) A novel word alignment method is applied into news title abridgement , which integrates application rules and statistical methods to achieve intelligent abridgement . 2) A framework that combines sentence abridgement and sentence selection is proposed to generate abridgement results of news content . 3) An automatic summarization evaluation method specific to sentence abridgement is proposed.
Most current methods abridge sentences by removing unimportant words or phrases with supervised due to computational efficiency and other reasons . Unsupervised methods are mainly based on integer dependencies well .
 summary, or summarizing with the formulated optimization framework, including integer linear programming (ILP) and sub -module functions . Gillick et. al. [ 9 ] put forward an ILP method based on natural language processing. abridgement algorithm based on word alignment , word weighting based on features comb ination, sentence weighting based on features comb ination, heuristic sentence abridgement algorithm based on key words. These algorithms build up a news abridgement system. Each algorithm will be described in detail below. 3.1 S entence Abridgement Algorithm Based on Word Alignment vocabulary from many synonyms, w e use the edit distance algorithm to align the words with different word usage when news titles are written can be acquired using maximum probability principle. meaning .

In this paper, transition probability matrix is obtained by monolingual word alignment [12] [13] and showed in table 1.

In the table above , the alignment words which can replace the original word s and their corresponding probability are bracketed . For example, @a X  NULL  X  0.33  X  @a  X  0.67  X  , employ (NULL, 0.33; replaced by NULL with pr obability 0.33, is replaced by " @a  X  employ  X  " with probability 0.67 . W e news . 3.2 Word W eigh t ing Based on Features Comb ination
W e put forward a n algorithm based on multi -feature of sentence and prolixity processing combined with the heuristic sentence abridgement algorithm based on keywords to abridge news text.
Many factors are to be considered in news text abridgement , including word frequency, part of speech, combination to calculate the weight of word s in news text. 1 ) Position of word news usually introduces its five elements: when, where, who, why, and what is going on.
We identify the five elements of news from the first sentence by named entity recognition [14] , and give weights by the following principles. 2) Key word and obtain 2105 key words, which are given higher weights .
T he key word list is obtained through machine learning and adding new words . Some results are shown in t able 2.
 3 ) P art of speech Nouns and compound nouns play important roles in expressing the meaning of articles . the weight of words .
 parameters  X   X  and  X  are determined according to the repeated adjustment of the experiment. Meanwhile, the value of  X  is related to the length of article, and the empirical value is 15.
The weight of word w Z calculated with formula (4) is as follows, Where d is document, x is the other words in the document. 3.3 Sentence Weighting Based on Features Comb ination a series of features to weigh the importance of each sentence. 1) Content of sentence information is , and the more important the sentence is. Where N is the number of words in sentence s Z , word w k  X  s Z 0 &lt; Cont s Z  X  1 . 2 ) P osition of sentence (7). features is the final weight of the sentence. The formula for calculating the weight of a sentence is as follow s : Where  X  and  X  are adjustable parameter s,  X  +  X  =1. 3.4 Heuristic Sentence Abridgement Algorithm Based on Key w ords sentence [16] , and determines whether the sentence is to be removed or retained by the composition of each node in the syntax tree and the keyword feature. In this approach, we combine multiple constraints to improve the linguistic quality of abri dged sentences [17] .

We obtain a set of rules and the w eights of rules through machine learning. For example, "remove the " remove the preposition phrases as attributive or adverbial in a sentence " and so on . method based on integer linear programming.

To restore the grammar and semantic of abridged sentence, we use the vector space model to c alculate finally use sentence selection based on IL P to generate the abridgement of news. abridgement . 4.1 News T itle Abridgement Experiment components.
 grammar normalization, and compression ratio. By analyzing the criteria above, a comprehensive evaluation of sentence abridgement f unction is given in equation (9) : means the com pression ratio, so that Score denotes sentence abridgement overall score. Through normalization are evaluated manually. E valuation results are shown in t able 4. Several typical examples of abridgement results are shown in t able 3, and are elaborated as follows. automatic compression ratio is 76.47%. Comparing with manual result, automatic result not only in the the original meaning, by matching synonym "  X b X   X  Korean nursing home  X  " as "  X  X   X  Korean hospital  X  ", however the main meaning remain s the same, also the result is within the acceptable range.
By observing the results present ed in table 4, the overall system output results are inferior to manual in terms of grammar and semantics, system output basically conforms to the specification of Chinese. This also illustrates that the system has advantages in maintaining the syntactic structure and semantic is close to manual result, therefore the system preliminarily achieves the goal of abridging titles . 4.2 Experime nt of News T ext Abridgement which guarantees the generalization of the model , so as to better evaluate its performance . 1) Keywords extraction experiment results
Due to space limitations, part of results is give n in Table 2. 2 ) News content abstract pre -extraction 
According to the results of repeated testing procedures, the parameters  X   X  and  X  in th e formulas sentences are sorted based on their relative locations in the original document. 3 ) Pre -extraction Abstract sentence abridgement of evaluation are given in T able 5. of the sentence, so that obtain a relatively high er semantic score. 4 ) News abridgement system evaluation sentences in the generated summary , and K sentences that appear in both the standard summary and the extraction task of this paper involves sentence abridgement , which may cause k equals to 0, we propose a novel definition for pr ecision and recall .
 W here k denote s the number of similar sentences. And the results of precision, recall and F j  X  score are shown in t able 6.

The experimental results suggest that the news abridgement algorithm is feasible an d the extraction density.
 ( http://www.chinanews.com/gj/2014/05 -27/6214377.shtml ) . The original news has in total 1303 words, requirements but also significantly reduces the time of consideration in manual abridgement . 
Abridged news title am3 9Z 15 ?V (Modi became the fifteenth Prime Minister of India)
Abridged news text *. 27 KDo 9Rtam3A 9%&amp;Z 15 ?VCg:Y ; ,%0&gt; X 9 ^: I2=+X\[s 4000 #1/cfamX3` F 9X5)J(?Vhq-BnjTXNO ...... eBQ@:Y ;,!l %0&gt;X 9 9"GW%8 !4 9R7EP]U  X  kiHp r ambdL6' $ 9_SWLM&lt; (As foreign media reported on 27th, the leader of the Bharatiya Janata Party (BJP) Modi has become the 15th Prime Minister of the Republic of India economic community have expectations.)
The experimental results show that the automatic news text abridgement s ystem proposed in this paper achieve s good results.

As the experiment result s suggest , the proposed news abridgement algorithm is feasible. The algorithm could automatically generate coherent and representative s ummaries of the given news with high density , which could significantly reduce the workload of news editing and abridgement .
