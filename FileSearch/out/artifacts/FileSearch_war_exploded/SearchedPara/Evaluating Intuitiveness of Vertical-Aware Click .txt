  X  Modeling user behavior on a search engine result page is important for understanding the users and supporting simulation experiments. As result pages become more complex, click models evolve as well in order to capture additional aspects of user behavior in response to new forms of result presentation.

We propose a method for evaluating the intuitiveness of vertical-aware click models, namely the ability of a click model to capture key aspects of aggregated result pages, such as vertical selection, item selection, result presentation and vertical diversity. This method allows us to isolate model components and therefore gives a multi-faceted view on a model X  X  performance. We argue that our method can be used in conjunction with traditional click model evaluation metrics such as log-likelihood or perplexity. In order to demonstrate the power of our method in situations where result pages can contain more than one type of vertical (e.g., Image and News ) we extend the previously studied Federated Click Model such that it models user clicks on such pages. Our evaluation method yields non-trivial yet interpretable conclusions about the intuitiveness of click models, highlighting their strengths and weaknesses.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Aggregated search; federated search; click models; evaluation
The problem of predicting user clicks has recently gained con-siderable interest. A click model is a probabilistic model of user behavior on a search engine result page. It is used to facilitate simulated experiments when real click data is limited or simply un-available (see, e.g., [ 4 ]). In addition, the parameters of click models  X 
Now at Google Switzerland.  X  Part of this work was conducted while at University of Glasgow. inferred from real clicks help us understand user behavior [ 6 ] and estimate the relevance of documents shown to the user [1].
Several vertical-aware click models have recently been devel-oped (e.g., [ 3 , 5 ]). These models aim to capture different aspects of user interaction with a so-called aggregated or vertical search system. The result page of an aggregated search (AS) system usually contains, in addition to regular Web results, heterogeneous results federated from different sub-collections or verticals (e.g., Image , Video or News ), which are then presented in a grouped fashion. These vertical results influence user behavior in new ways [3].
Traditionally, click models have been evaluated on their ability to predict future clicks from past observations [ 3 , 6 ]. More is required for the evaluation of vertical-aware click models, as we need to assess their ability to capture the peculiarities of the user behavior on the AS result page such as attention bias . We adapt the intuitiveness test proposed by Sakai [9] to evaluate vertical-aware click models. While Sakai X  X  idea has been adopted before, namely for the setting of aggregated search metrics [ 14 ], our contribution is new in that we apply it to evaluate click models instead of metrics.
The main research question that we aim to answer is: How can we evaluate the ability of a click model to capture key aspects of a vertical (aggregated) search system? In the process of answering this question we learn that none of the existing click models are designed to deal with a result page containing multiple verticals (e.g., both News and Video ). We introduce such a model and evaluate it using our evaluation method.
Sakai [9] proposes a way of quantifying  X  X hich metric is more in-tuitive. X  This method has been applied to understanding aggregated search metrics in [ 14 ], where four key factors of aggregated search systems are listed: vertical selection (VS), item selection (IS), result presentation (RP) and vertical diversity (VD). The authors measure the preference agreement of a given aggregated search metric with a  X  X asic X  single-component metric for each factor; they also assess the ability of a metric to capture the combination of these factors.
The main contribution of our work is that we adapt the intuitive-ness test to evaluate vertical-aware click models instead of aggre-gated search metrics. In order to apply the intuitiveness test to click models, we use a simulation setup and proceed as follows. We run a click model CM to simulate user clicks 1 and report the total number of clicks (CTR) produced by the simulated user as a metric score for a given ranking. We then compare AS systems by the number The code we use to simulate clicks is available as a part of Lerot [10] at https://bitbucket.org/ilps/lerot .
Disagree = 0 ; Correct 1 = 0 ; Correct 2 = 0 ; foreach pair of runs ( r 1 ,r 2 ) do Intuitiveness ( CM 1 | CM 2 ,M GS ) = Correct 1 / Disagree ; Intuitiveness ( CM 2 | CM 1 ,M GS ) = Correct 2 / Disagree ;
Algorithm 1: Computing the intuitiveness scores of click mod-els CM 1 and CM 2 based on preference agreement with a gold standard metric M GS . of clicks they receive according to a click model CM , like in A/B-testing experiments. 2 The outcome of this AS system comparison determines the intuitiveness of the underlying click model.
Algorithm 1 shows our intuitiveness test algorithm. The algo-rithm computes relative intuitiveness scores for a pair of click mod-els CM 1 and CM 2 and a gold standard metric M GS . The latter represents a basic property that a candidate metric should satisfy. We consider not one but four metrics as our gold standards, one for each aggregated search factor; the same metrics were used by [ 14 ]. These gold standards are intentionally kept simple. They should be agnostic to differences across metrics (e.g., different position-based discounts); their purpose is to separate out and test single factor properties of more complex click models. The four gold standard metrics are: (a) VS: vertical precision; (b) VD: vertical recall; (c) IS: mean precision of vertical result items; and (d) RP: Spearman X  X  rank correlation with a  X  X erfect X  AS reference page.

We first obtain all pairs of AS result pages for which CM CM 2 disagree about which result page should get more clicks. Out of these disagreements, we count how often each click model X  X  CTR scores agree with the gold standard metric(s). The click model that concords more with the gold standard metric(s) is considered to be more  X  X ntuitive. X  An ideal click model should be consistent with all four gold standards; we therefore add an additional step to Algorithm 1 by counting how often the model agrees with a subset or all the four gold standards at the same time.

When compared to traditional perplexity-based click model eval-uation [ 3 , 6 ], our method has the following advantages: (1) it allows for assessments of individual model components, separating their contribution to the model X  X  performance; (2) it assigns explanatory scores that allow us to assess the ideas underlying a click model; and (3) it allows us to make use of public test collections and obtain re-usable scores without need to access a user click log.
In this section we present the click models (both traditional and vertical-aware) that we use to demonstrate our intuitiveness evalua-tion method. We first introduce the models and then specify their parameters as well as the aggregated search dataset that we use. Traditional Click Models. We start with the simple traditional click models and then move to the more complex vertical-aware
Alternatively, one can perform an interleaving comparison [ 2 ], but this is beyond the scope of the paper. models. In order to model the user X  X  behavior on a search engine result page (SERP), a click model usually employs two sets of bi-nary random variables: E i (examination), which equals 1 if the user examines the i -th document snippet, C i (click), which equals 1 if the user clicks the i -th document link. The Random Click Model ( RCM ) assumes that a document is clicked with proba-bility p = 0 . 5 regardless of document position and its perceived relevance: P ( C i = 1) = p . If we take into account the fact that the documents lower in the SERP have a lower chance of be-ing examined [ 12 ], we obtain a Position-Based Model ( PBM ): P ( C i = 1) = P ( C i = 1 | E i = 1)  X  P ( E i = 1) , where the exam-ination probability P ( E i = 1) = p i  X  1 and the probability of a click given examination is approximated using relevance labels: P ( C i = 1 | E i = 1) = r i ; a similar model was used as a baseline model in [1]. Following Zhang et al. [12], we set p = 0 . 73 . 15% of the search result pages contain more than one type of vertical. Since this is a significant fraction of the search traffic, we want to adequately evaluate click models that capture user behavior in such multi-vertical settings. In order to demonstrate how our method rates such models, we introduce a multi-vertical Federated Click Model ( mFCM ), a generalization of the Federated Click Model ( FCM ) by Chen et al. [ 3 , 4 ] in which we allow different vertical types, each with its own influence on examination probabilities.
As in [ 3 ], P ( E i = 1) is influenced by the distance to different verticals on the page and the attention bias caused by these verticals. If there is no attention bias present, the examination probability  X  depends only on the rank of the document i : Here, A is the vector of independent binary random variables A attention bias values for each vertical vert j . The influence of ver-tical documents on the examination probability of a document i is represented by a function  X  i ( A ) . We set it to 1 if document i is the vertical document itself and decrease it as document i is further away from the vertical documents [ 3 ]. According to Chen et al. [3] , the decrease should depend on the vertical type j , so we introduce parameters  X  j that depends solely on the vertical type j : where dist j ( i ) is the distance from document i to the nearest docu-ment that belongs to vert j [3, 4].

If we do not distinguish between different verticals in (4) , i.e. set  X  j =  X  for all j , and also assume that for a vertical j , its attention bias A j is determined only by its position on the page, i.e., P ( A j = 1) = hpos vert was used in [ 4 ]. If we do assume that  X  j takes different values for different j , we get the model that we call here mFCM -NO .
In order to further distinguish different verticals we use the verti-cal orientation of the user, the probability that users prefer a certain vertical to general web results [ 13 , 14 ]. We write orient ( vert to denote the orientation of the user towards the type of vert query q . Having orientation values, we can further improve our click model by refining the estimation of attention bias:
For simplicity we use binary relevance labels, following [4]. The model defined by equations (1)  X  (5) is called mFCM . The sim-pler mFCM -NO model that does not use vertical orientation ( X  X O X  for  X  X o orientation X ), is also of interest, since vertical orientation values are not always available and it is important to understand their contribution.
For the mFCM model we instantiate the  X  ,  X  and hpos param-eters similar to [ 4 ]. We set  X  to 0 . 1 for multimedia verticals such as News or Blogs and 0 . 2 for text-based verticals such as Image or Video to resemble click heatmaps reported by [ 3 ] for the corre-sponding vertical types. We also set hpos = [ . 95 , . 9 , . 85 , . 8 , . 75 , user cannot see documents below rank 6 without scrolling), and for since Chen et al. [3] suggest that a text vertical, unlike multimedia verticals, does not substantially influence user clicks if it is not at the top of the page; this is also supported by [ 11 ]. As in [ 4 ],  X  equals probabilities reported by Joachims et al. [7].

To complete the experimental setup we need to specify the ag-gregated search systems and document dataset that we use. We use simulated aggregated systems from [ 14 ], which are built by systematically varying the quality of key aggregated search compo-nents. Specifically, we use 4 state-of-the-art VS systems, 3 ranking functions for selecting vertical items for IS and 3 ways to embed vertical result blocks on the final AS pages (RP). In total, we have simulated 36 AS systems ( 4  X  3  X  3 ). As a document collection we use a public aggregated search dataset [ 8 ] for which relevance judgements of documents and vertical orientation preference judg-ments are available for each topic. There are 50 test topics in our collection, so with 36 simulated AS systems runs we have a total of C 36 = 630 run pairs and 50  X  630 = 31 , 500 pairs of result pages.
We report on the intuitiveness scores computed for a variety of click models, using Algorithm 1. For each click model we test intuitiveness with respect to the four AS factors individually, as well as the ability to capture a combination of multiple AS factors. The models that we test are: mFCM , mFCM -NO , FCM , PBM , RCM , all of which are described in Section 3.1. Table 1 lists our results. For every gold standard metric and every pair of click models, we give the intuitiveness scores of both models and the percentage of result page pairs for which the models disagree.
For example, Table 1 (a) shows that if we compare mFCM and mFCM -NO in terms of the component VS (the ability to select relevant verticals), there are 14 . 7% ( 4 , 620 out of 31 , 500 pairs) disagreements. The intuitiveness score for mFCM is 0 . 870 , which is the fraction of these disagreements for which mFCM agrees with the gold standard metric. The score for mFCM -NO is only 0 . 833 , so mFCM is more likely to agree with VS metric than mFCM -NO . Note that the scores of two competing models do not add up to 1; when the gold standard judges two result pages to be equally good, both click models agree with the gold standard. That is also why the scores for a very simple RCM are relatively high in Table 1 (a). We can also observe that as two click models differ more, the percentage of disagreements increases. For instance, the more complex click models tend to have a substantial disagreement with the random click model RCM .

Let  X  CM 1 &gt; CM 2  X  denote the relationship  X  X lick model CM statistically significantly outperforms click model CM 2 in terms of concordance with a given gold-standard metric. X  Our findings can be summarized as follows:  X  VS: mFCM &gt; mFCM -NO , FCM ;  X  VD: mFCM , mFCM -NO &gt; PBM &gt; FCM &gt; RCM ;  X  IS: mFCM &gt; mFCM -NO &gt; FCM &gt; PBM &gt; RCM ;  X  RP: FCM &gt; PBM &gt; mFCM , mFCM -NO &gt; RCM ;  X  VS and IS: mFCM &gt; mFCM -NO &gt; FCM &gt; PBM &gt; RCM ;  X  VS, IS, VD: mFCM &gt; mFCM -NO &gt; FCM &gt; PBM &gt; RCM ;  X  VS, IS, RP, VD (all four metrics): mFCM &gt; PBM &gt; RCM , For single-component evaluation, mFCM outperforms the other models on VS, VD and IS, with mFCM -NO as a second-best alter-native. The same holds for the combinations VS + IS and VS + IS + VD. For RP, FCM performs best, with PBM ranking second. The RP factor is measured as correlation with a  X  X erfect X  result page in which highly oriented verticals are put on top. However, this order does not necessarily emit the maximum number of clicks in FCM -like click models. For example, if there is a vertical lower on the page that attracts a lot of attention, it may be better to place the relevant document just above or below this vertical. The ta-ble suggests that the intrinsic  X  X ptimal X  result orders for mFCM and mFCM -NO are further from the  X  X erfect X  order than PBM  X  X . When we look at all gold standard metrics combined, FCM and mFCM are almost equally good, with mFCM -NO again as a second-best alternative.

Our evaluation method implies that mFCM captures the VS, IS and VD factors very well, better than any other model we tested. Even without orientation values, mFCM -NO is able to capture these factors. mFCM performs worse at capturing result presen-tation as measured by our RP metric, which is unsurprising as the multiple vertical click model focuses less on putting relevant results on top and better accounts for attention bias caused by multiple vertical blocks. This shows that our intuitiveness evaluation method is able to draw non-trivial detailed conclusions about model X  X  per-formance. These conclusions do not contradict our prior knowledge about the click models and can always be explained.
We introduced an evaluation method that can be used to assess a vertical-aware click model X  X  ability to capture key components of an aggregated search system and demonstrated it using different vertical-aware as well as traditional click models. We also showed that click models that account for multiple vertical blocks within a single result page typically get higher intuitiveness scores, which indicates that our evaluation method measures the right thing.
One limitation of the work presented here is that we do not use raw click data to infer the parameters of the click models we experiment with. However, we set these parameters using previous work that does use real click and eye gaze data [3, 7, 11].

As a direction for future work we want to compare the findings of the intuitiveness test with conventional model performance tests (e.g., perplexity of click prediction) and see whether good intuitive-ness scores also imply good click prediction results and vice-versa.
