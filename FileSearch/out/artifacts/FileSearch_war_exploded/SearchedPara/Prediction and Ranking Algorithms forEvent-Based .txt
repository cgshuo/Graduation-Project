 Event-based network data consists of sets of events over time, each of which may involve multiple entities. Exam-ples include email traffic, telephone calls, and research pub-lications (interpreted as co-authorship events). Traditional network analysis techniques, such as social network models, often aggregate the relational information from each event into a single static network. In contrast, in this paper we focus on the temporal nature of such data. In particular, we look at the problems of temporal link prediction and node ranking, and describe new methods that illustrate opportu-nities for data mining and machine learning techniques in this context. Experimental results are discussed for a large set of co-authorship events measured over multiple years, and a large corporate email data set spanning 21 months. Large data sets describing events over time and involving multiple participants are increasingly of interest from a data analysis perspective. Examples include: Social network analysis has, generally speaking, been ap-plied to two types of data: persistent relationships (friend-ships, affiliations, web links, etc.) and discrete events (meet-ings, publications, communications, transactions, etc.). How-ever, prior research on quantitative analysis methods for data of either type has largely focused on a static view of the data in which all links are considered simultaneously, even if the underlying data is known to change over time. Event data is inherently temporal, with a time-stamp or fixed time interval associated with each event. As an exam-ple, consider Figures 1 and 2 ; each of these shows a method of visualizing the connections created between individuals by participating in events. Figure 1 shows a sequence of email messages between individuals A, B, C, D , and E ; each vertical  X  X imeslice X  represents emails that were sent at the same time. Figure 2 shows a sequence of events (papers) and their participants (authors) as a hypergraph, where hyper-edges represent papers (tagged by year) and vertices repre-sent authors. These visualizations illustrate that there can be multiple different representations for event data: as a single aggregate network, a series of networks, and so on. From a data analysis and data mining perspective there are a number of different questions that can be asked in this context, including questions about how the networks evolve over time, emergence of communities, and so forth. In this paper we review our recent work on two specific problems related to event network data: In Section 2 we describe some general notation for event networks and participants. In Section 3 we provide a brief review of relevant prior work in areas such as social network analysis, statistical network models, and machine learning. Figure 2: A co-authorship hypergraph tagged by year. We then illustrate how machine learning techniques can be applied to the prediction problem described above and de-scribe results from a set of experiments with a multi-year co-author data set consisting of 150,000 authors and 300,000 papers. In Section 4 we describe our work on algorithms for time-dependent ranking based on event data, and its appli-cation to a large corporate email data set. Section 5 provides concluding comments. We define an event-based data set as consisting of a set of events E = { e 1 , . . . , e m } and a set of participating entities V = { v 1 , . . . , v n } . The set of entities that participate in event e i are denoted P i , e.g., P 1 = { v 1 , v 4 , v 10 and each entity can have a set of attributes or covariates. We denote covariates for e i as y i and covariates for v j and the sets of all event and entity covariates as Y and X respectively. For convenience, we denote the event covari-ate representing the time at which an event e i occurred as t , where i indicates that it is the i th event in order of oc-currence. Note that some events (such as emails) may have an  X  X nstantaneous X  time-stamp t i , while other events such as co-authorship events for technical papers would have a coarser time-stamp, e.g., at the level of year of publication, t  X  X  1985 , 1986 , . . . , 2005 } . Extensions of this representa-tion could allow events to have a duration with a start and end time (such as meeting durations or tenure on a com-mittee); however, we do not investigate the notion of events with duration in this paper.
 Extending the notation above, we can express the proposi-tion  X  v j and v k are co-participants in event e i  X  by v P , and the proposition  X  v j and v k are co-participants in one or more events in the interval [ t, t + X  t ] X  as v j , v k We denote the subset of events taking place in this interval We denote the rank of v j as R ( v j ), and (where appropriate) the rank of v j at time t i as R i ( v j ). The notion of rank as an indicator of the significance of an entity is a key concept in algorithms such as PageRank, which we discuss further in Section 4.
 Given this representation of the data, we can represent some of its structural properties as a network in various ways, depending on the precise nature of the events and of the desired analysis. Generally speaking, a network extracted from such a data set usually contains a vertex corresponding to each entity v j , and edges link vertices that participate in the same events. However, as we will see, it is not always appropriate to aggregate all events together into a single graph for analysis. Within the field of social networks there is a rich tradition of defining statistical models for network data. Various forms of Markov random fields (MRFs) [ 8 ] and exponential ran-dom graph models (sometimes referred to as p  X  models in the social networks literature [ 27 ]) have been used to con-struct distributions P ( E ) over the edge set E of a graph, or conditional distributions P ( E | X ) given node covariates X . Much of this work builds on the earlier classic work of Besag in spatial statistics [ 2 ].
 The general goal is to infer a parsimonious model for P ( E ) or P ( E | X ) that requires a relatively small number of pa-rameters to explain the pattern of observed relations (and non-relations), as a function of both local network properties (such as the indegree and outdegree of individual nodes) as well as the covariates X . These generative modeling frame-works inherit the usual advantages of statistical modeling, including the ability to fit such models to data using statisti-cal inference techniques, modeling techniques for incorporat-ing covariates X (e.g., via suitably-defined logistic regression models [ 10 ]), inference methods for handling systematic er-rors in the measurements of links [ 5 ], hierarchical Bayes and random effect frameworks that allow individual-level varia-tion to be modeled [ 9 ], and methodologies for incorporating specific prior information such as desired functional forms on degree distributions [ 23 ].
 A major limitation of many of these models is lack of scala-bility as a function of the number of vertices. For example, in the latent variable model of Hoff, Raftery, and Handcock [ 10 ] the likelihood is by definition a product over all pairs of nodes, whether an edge was observed or not, leading to an inherently O ( n 2 ) algorithm. While this may be practical for relatively small social networks, such algorithms are not directly scalable to many of the large networks (in which n  X  10 5 ) that are often of interest in data mining. Work in statistical relational learning has also addressed the problem of building general-purpose statistical models of re-lational information. For example, Taskar et al. [ 26 ] use a relational Markov network (RMN) to define a probabilistic model over the entire network, including entity attributes and links. The primary goal of this work is to classify links by type, but the approach can also be applied to predicting link presence. Scalability to large networks is again an issue with such approaches.
 In contrast to the approaches above, in Section 3.3 we de-scribe how we construct local conditional probability mod-els for link prediction in a manner that does not require the construction of a full joint distribution P ( E ) over all edges. We do this by embedding the local graph structure and covariates in a fixed-dimensional feature space, allowing us to use standard predictive modeling techniques for learn-ing conditional distributions, and to avoid the complexity of specifying joint distributions over sets of edges. While this loses some of the power of the full joint modeling approach, we will nonetheless argue that this can be an effective (and scalable) approach when prediction (in the form of queries regarding specified entity pairs) is the primary goal. The work described in the previous subsection describes tra-ditional modeling efforts that are largely focused on static networks. As we stated in the introduction, for event-based networks it is of interest to directly take the temporal and sequential aspect of the data into account. Below we sum-marize some recent work along these lines.
 Perhaps the most widely-publicized work on modeling of temporal aspects of network data focuses on finding general-purpose stochastic laws or rules for link generation over time. Typically these laws or rules are governed by a small number of free parameters that control (for example) the probability of new link generation when a new node is in-troduced to the network. Examples of this approach include the preferential attachment model [ 16 ] and the  X  X orest fire X  model [ 14 ]. When used to simulate network data, these models yield networks with aggregate properties that are often quite similar to those seen in real-world network data, such as degree distributions, community characteristics, and network diameters. While these models have had consider-able success in reflecting global aggregate network proper-ties, they do not explicitly allow one to make predictions at the individual node or link level. For example, these models do not allow one to predict whether a new event will occur (over some future time span) involving two specific entities v and v k , as a function of existing graph and covariate data pertaining to v j and v k .
 Snijders [ 24 ] describes several interesting statistical mod-els for understanding the dynamics of evolving networks of persistent relationships. These take as input sequential in-stantaneous observations of a network, and attempt to fit a specific parametric model for continuous evolution of the network such that its outputs (in the form of network  X  X nap-shots X ) accurately predict the observations. These meth-ods are not directly applicable to event data, and as with the static modeling counterparts discussed earlier, parame-ter estimation for these models typically does not scale well to large networks.
 Popescul and Ungar [ 19 ] present a method which involves performing a constrained search, in the space of database queries, to generate candidate features which are then used in a logistic regression to predict the presence or absence of a link between a specified pair of entities. Features are included or not based on a Bayes Information Criterion [ 21 ] evaluation. While this method was applied only to static graphs, it could in theory be extended to predict links in future time periods. However, the representation of the fea-tures as SQL database queries limits their expressiveness, and thus this method of feature generation cannot discover features which have been demonstrated to be highly infor-mative. For example, SQL cannot readily represent features that relate to complex properties of the network topology, such as shortest-path distance in a network, or properties of an entity X  X  neighborhood whose components are weighted according to their own topological properties ([ 1 ], [ 18 ], etc.). Likewise, features such as similarity metrics of entity or event attributes cannot be expressed in SQL.
 Liben-Nowell and Kleinberg [ 15 ] rank all pairs of entities according to their value for a specified single network-based feature based on known event data, and declare that the k pairs with the highest feature value are those that will par-ticipate in an event in the following time period (where k is the number of pairs which are assumed to co-participate). This method does not scale well to large networks, involves some potentially problematic assumptions (such as prior knowledge of k ), and may have low predictive accuracy since only a single feature is being used for event prediction. We consider below the specific problem of answering the question  X  X iven the existing event data, will entities v j v k co-participate in at least one event in a future specified interval? X . Our approach is to treat it as a data-driven clas-sification problem (in which  X  X o-participating X  is one class, and  X  X ot co-participating X  is the other). The methods used are primarily probabilistic classifiers, which assign a prob-ability to each class conditioned on the values of a set of specified features, whose nature may vary depending on the data set. We formally define this conditional probability as follows: where v j , v k  X  P t,t + X  t is a binary proposition defining whether entities v j and v k co-participate in any event in the time period [ t, t +  X  t ], f is a function returning a vector w of feature values, E 1 ,t is the historical event data up to time t , and X , Y are the relevant entity and event covariate data. This formulation frames the problem as one of learning a mapping from feature vectors to class probabilities; this problem is well understood by the machine learning com-munity, and can be solved using standard  X  X ff-the-shelf X  prediction algorithms.
 There exist two variants of this problem: one in which v j and v k may or may not have co-participated in any previous interval, and one in which it is guaranteed that they have never previously co-participated (i.e., predicting new collab-orations). The latter problem is generally considered more difficult, and is the one which we discuss below. The primary components of a classification model are the choices of features, training and test sets, classification method, and evaluation metric; we will briefly discuss each of these below. Figure 3: The intervals used for defining the training and test data In large-scale network analysis, it is also important to con-sider the ramifications of different representations of the un-derlying data. In particular, while graphs are by far the most common representations of this type of data, they are not always the most appropriate. For example, if events involve Figure 4: Precision of the top k instances, for three ranking methods multiple entities (such as coauthorship of a paper, or at-tendance at a meeting), then a graph-based representation will represent each entity as a vertex, and each event with k participants as a set of O ( k 2 ) edges (specifically, a clique of size k on the participants X  vertices). This representation may require a great deal of space (for one data set, 150,000 events were represented by 2.2 million edges), tends to blur or erase the correspondence between the original data and the network topology (since each event in the folded graph is represented by a set of edges, each of which may be as-sociated with &gt; 1 event), and generally makes dealing with event metadata more difficult.
 A more natural representation of such data is a hypergraph in which each entity is represented by a vertex, and each event is represented by a single hyperedge which connects the k entities that participated in the event (in contrast with the O ( k 2 ) edges required by the graph representation). This representation is much more efficient and accurate than the graph representation, but due to a lack of available pro-gramming tools that can directly manipulate hypergraphs, researchers in network analysis have generally chosen to ac-cept the limitations of the graph representation. In the experiments described below we used the JUNG network software library [ 11 ], which can represent and manipulate hypergraphs as well as graphs; this allowed us to use the generally more advantageous hypergraph representation. We have experimented with the approach of using classifi-cation methods to perform link ( i.e. , event co-participation) prediction over time on a data set that consists of 128,000 scientific abstracts and the 310,000 authors of these publica-tions, which spans the 6-year time period 1998-2003. Each paper constitutes an event, and all of the authors of the paper are co-participants in this event.
 An example of a prediction problem for this type of data is to select the 1% most prolific authors (3100 of them) and try to predict new collaborations among these authors in the final year of the data. In the test set of 50,000 pairs of authors, approximately 6% of these pairs had new collaborations in the final year.
 Figure 4 shows the precision for various values of k , defined as the fraction of the top-ranked k instances (from differ-ent models) that represent (true) positive instances (that is, pairs of individuals that were correctly predicted to co-participate in the specified time period). This fraction is an indicator of the utility of the probability returned by the classifiers in terms of ranking positive instances high and negative instances low; for example, we can see that of the 50 highest-ranked pairs according to the logistic regression method, 42 were positive instances. These results suggest that relatively standard machine learning methods can ex-tract predictive power from this type of event data; in par-ticular, this approach appears to be particularly useful as a ranking mechanism for detecting candidate pairs that are highly likely to co-participate in future events. We now switch attention to the second problem mentioned in the introduction, namely entity ranking from event-based data. There exist a variety of algorithms that rank enti-ties in a network according to criteria that reflect struc-tural properties of the network (such as the extent to which paths in the network pass through each individual); these rankings are interpreted as such qualities as  X  X entrality X ,  X  X uthority X ,  X  X nfluence X , and so forth. Examples of these algorithms include betweenness centrality [ 3 ], eigenvector centrality [ 22 ], PageRank [ 4 ], and HITS [ 12 ]. Each of these algorithms makes the implicit assumption that the network data is static, and generates a single rank value for the data set; their underlying models do not incorporate any notion of sequence or timing, and all data are incorporated into a single picture of the network. While this assumption may be reasonable for networks based on persistent relation-ships (such as web page hyperlinks), it is less appropriate for event-based networks. For example, researchers gain pres-tige as their papers are cited, and lose it if they are no longer actively cited.
 One can use such algorithms to generate ranks that change over time by applying them to subsets of the data restricted to successive intervals. However, this presents a few difficul-ties: even the subsets will be static pictures, and any infor-mation about the sequence of events during each interval is lost. More fundamentally, these algorithms necessarily op-erate on networks which represent aggregations of past and current events; it is neither useful nor especially meaningful for PageRank to operate on a network which contains many vertices but only a few edges corresponding to the current event(s). As such, the presence of links representing past events can cause the ranks to evolve in nonintuitive ways when small perturbations, corresponding to new events, oc-cur. Furthermore, it is not clear what the semantics of the links induced by events should be for purposes of calculating an evolving ranking. For example, how should email events be represented by edges? Options include edges directed to-wards the sender, edges directed towards the receiver, and hyperedges connecting all participants. However, it is not clear how each of these choices would affect the ranks which emerge from PageRank and other algorithms which operate on this sort of data.
 We illustrate one of these problems with the following exam-ple. Figure 5 is a network representation of email traffic, in which &lt; X, Y &gt; exists if X has emailed Y , and has weight equal to the number of such emails. Any ranking al-gorithm which operates on static networks would assign the same rank to A and C . However, if we consider individual Figure 5: A network representing a sequence of messages Figure 6: A message sequence that could have resulted in the network in Figure 5 emails in sequence, we observe that patterns of communica-tion may change over time, and thus the ranks may change as well: Figure 6 represents a possible sequence of messages that correspond to the static network in Figure 5 . In this representation C at first is more important than A , and later this reverses. Furthermore, participation in an event at time t can affect one X  X  participation in events at time t j ( j &gt; i ) (for example, based on Figure 6 we can guess that D  X  X  email to B at time t 4 may have resulted in B  X  X  email to A at time t , but the reverse is clearly impossible). These observations underline the desirability for an event-based ranking algo-rithm to be able to generate ranks which evolve over time, and whose ranks respect the events X  temporal sequence. We have identified several properties which we believe ought to be satisfied by algorithms which generate a sequence of values which model the evolution of ranks over time based on event participation: 1. comparability across time: rank values should be nor-2. participation increases rank in proportion to other par-3. participating can always increase rank (even if partic-4. participants X  ranks don X  X  decrease 5. non-participants X  ranks don X  X  increase 6. rank value evolution reflects event sequence As already noted above, PageRank and similar algorithms do not satisfy (4), (5), and (6) in general, and may not satisfy (3) in some cases.
 The functioning of PageRank and related algorithms can be modeled in terms of iterated  X  X otential X  flow, according to the following specifications: EventRank [ 17 ] is a framework for ranking algorithms which operate on event data and incorporate temporal informa-tion. Algorithms from this framework can also be concep-tualized in terms of iterated potential flow. However, while the initialization is identical to that of PageRank, the others differ as follows: We define the basic model as follows: we denote the poten-tial of participant v  X  V at time t i by R i ( v ), which takes on values in the interval (0 , 1). R 0 ( v )  X  1 n (uniform initial distribution), and in general R i ( v ) is recursively defined as where  X  i is the total amount of potential that the event e contributes to the participant set,  X  R ( d, t i ) is the additive inverse of d  X  X  potential, i.e., 1  X  R i ( d ), and T N i  X  1 the total amount of potential held by the non-participants of m i , that is, P Further details of the model may be found in [ 17 ], in which we argue that this model satisfies all of the requirements stated above.
 As a test of this framework, we performed experiments on approximately 1 million emails spanning 21 months of an organization X  X  email server log, for 628 individuals (Figure 7 ). The data for each message included the identities of the sender and recipients, and the time at which it was sent, but not the content of the message itself. We also had access to a single snapshot of the organizational hierarchy for 378 members of the organization.
 The definition of rank in a social network is generally some-what subjective; ranking algorithms generally do not have a  X  X round truth X  to which their output can be compared to determine accuracy of the ranking model, although for smaller social networks one can measure the consistency of algorithmically determined ranks with those derived from in-dividual surveys. While we have observed that EventRank satisfies the properties listed above, a more objective mea-sure of relevance is desirable.
 Figure 7: A static view of an organization X  X  email network We hypothesized that, in general, the rank of an individual is related to her position in the organizational hierarchy (see Figure 8 for an illustration), in the following senses: first, that an individual A  X  X  rank is correlated with the number of her subordinates, and second, that A  X  X  rank should be greater than that of those below her in the hierarchy (sub-ordinates: B, C ), and less than that of those above her in the hierarchy (superordinates: J, H ).
 Since the organizational hierarchy is itself a static network, for purposes of these comparisons we needed to define a sin-gle  X  X umulative X  rank value for each individual. One of the measures that we chose was the sum of  X  X ncoming X  poten-tial (that is, changes to c  X  X  potential caused by c receiving a message), which we denoted as S i ; this is analogous to the HITS  X  X uthority X  score, and to network indegree.
 Generally, we observed that S i had a weak linear correlation (0.47) with log(number of subordinates). We also measured the extent to which the rank ordering derived from S i agreed with the hierarchy (in the sense defined above), and found that this ordering was highly consistent: the average num-ber of inversions (situations in which a subordinate X  X  rank was higher than that of a superordinate) was lower, and the overall accuracy higher, than that for any other rank order-ing we tested. Additional details on these results may be found in [ 17 ].
 While we did not have a direct way of validating Event-Rank X  X  time-varying ranks for each individual, we did ex-amine the data for that of a few individuals about which some additional information was known. Figure 9 shows a plot of rank vs. time for five individuals. Individual A was working on projects of increasing visibility during this time period; B went on leave around week 60 or so; C worked primarily on their own rather than with other members of their group; E did not start working in this organization until approximately week 30; and D was the leader of the group which included the other four individuals. Intuitively, this time series seems to agree with this limited information. We have presented methods for network analysis that explic-itly incorporate time and sequence, and are thus well-suited to addressing event data sets. We argued that an emphasis on predictive modeling, using techniques from data mining and machine learning, can yield scalable and robust algo-rithms in this context. Experimental results demonstrated that these approaches can be used to accurately predict or-ganizational structure from event data and to rank likely future co-participations between entities.
 There are many other open research problems relating to event-based data sets and the evolution of their associated networks; we believe that such problems present opportuni-ties for new practical applications and for a better under-standing of the dynamics of the underlying phenomena. This material is based upon work supported by the National Science Foundation under award number NSF IIS-0083489. [1] L. A. Adamic and E. Adar. Friends and neighbors on [2] J. Besag. Spatial interaction and the statistic analysis of [3] U. Brandes. A faster algorithm for betweenness central-[4] S. Brin and L. Page. The anatomy of a large-scale hy-[5] C. Butts. Network inference, error, and informant [6] W. W. Cohen. Enron email dataset. [7] C. Cortes and D. Pregibon. Giga-mining. In Knowledge [8] O. Frank and D. Strauss. Markov graphs. Journal of the [9] P. D. Hoff. Random effects models for network data. [10] P. D. Hoff, A. E. Raftery, and M. S. Handcock. Latent [11] JUNG Framework Development Team. JUNG: [12] J. M. Kleinberg. Authoritative sources in a hyperlinked [13] S. Lawrence, C. L. Giles, and K. Bollacker. Digital li-[14] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs [15] D. Liben-Nowell and J. Kleinberg. The link prediction [16] M. Newman. Clustering and preferential attachment [17] J. O X  X adadhain and P. Smyth. EventRank: A frame-[18] J. O X  X adadhain, P. Smyth, and L. Adamic. Learning [19] A. Popescul and L. H. Ungar. Statistical relational [20] G. Salton and M. J. McGill. Introduction to Modern [21] G. Schwarz. Estimating the dimension of a model. The [22] J. R. Seeley. The net of reciprocal influence: A prob-[23] T. A. Snijders. Accounting for degree distributions in [24] T. A. Snijders. Models and Methods in Social Network [25] M. Steyvers, P. Smyth, M. Rosen-Zvi, and T. Griffiths. [26] B. Taskar, M.-F. Wong, P. Abbeel, and D. Koller. Link [27] S. Wasserman and P. Pattison. Logit models and logis-
