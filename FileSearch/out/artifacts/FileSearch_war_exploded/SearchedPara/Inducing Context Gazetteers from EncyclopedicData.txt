 Named entity recognition (NER) is a task that recognizes the mentions of entities of interest. Entity types vary depending on the target domains. In the general domain, for example, the names of people, locations and organizations are most common entity types [5,25], whereas the names of genes and gene products are in the biomedical domain [12,22]. In fact, NER has been regarded as a funda-mental sub-task in many natural language processing (NLP) applications such as information extraction, question and answering, and machine translation.
NER has been tackled in various ways from rule-based to statistical ap-proaches. However, most state-of-the-art NER models formalize it as a sequence labeling task and employ supervised machine learning approaches such as Condi-tional Random Fields (CRF) and Support Vector Machines (SVMs). To achieve high-performance, a supervised machine learning approach requires a set of fea-tures that are well designed to distinguish mentions of entities from others. Com-monly used features are local features obtained from a small and linear window (local context hereinafter ). For example, presuming that we shall determine the label of the underlined word  X  X ssociated X  in Fig. 1, then the neighboring and current words such as  X  X ajor X ,  X  X lastid-lipid X ,  X  X ssociated X ,  X  X rotein X  and  X  X s X  within the local context [-2,2] are useful as word uni-gram features (the relative position of each word is shown under the word). These local features contribute to production of strong baseline models [ 2,8,20]. However, recent studies [4,13] have demonstrated that incorporating features from non-local context can help further improve the recognition perform ance. In Fig. 1, for instance, direct and indirect head-words of the word  X  X ssociated X  such as  X  X rotein X ,  X  X ncoding X ,  X  X ene X , and  X  X xpressed X  can be useful non-local features.

As described in this paper, we propose to use a context gazetteer, which is a list of contexts that co-occur with entity names, for incorporating new sen-tence level non-local features into NER model. A context gazetteer consists of dependency paths of variable lengths to capture more syntactically meaningful contexts than traditional local contexts. Confidence values are assigned to these contexts to reflect how they are likely to appear with entity names. We build a context gazetteer from a huge amount of hig hly precise and automatically labeled data using an encyclopedic database because manually annotated data are often too few to extract rich and sophisticated context patterns. Therefore, a con-text gazetteer is expected to help rec ognize unknown entity names that do not appear in training data, in addition to out-of-vocabulary (OOV) entity names that are not registered in entity gazett eers. In experiment, we build a context gazetteer of gene names and apply it for a biomedical named entity recogni-tion task. It is particularly interesting that top-ranked entries in the created context gazetteer have various forms. A s expected, there are many predicate X  argument structure style contexts using domain specific verbal (and nominal) predicates such as  X  X xpress X ,  X  X nhibit X  and  X  X romote. X  Moreover, abbreviation, apposition, and conjunction dependencies are frequently included as a part of high confidence context patterns. These contexts can be interpreted as fragments of domain knowledge that appear in stereotypical syntactic structures in texts. The context gazetteer boosted both the precision from 89.06 to 89.32 and the recall from 82.78 to 83.46. As a consequence, the overall F1-score is improved from 85.81 to 86.29.

The remainder of this paper is organized as follows. In Sec. 2, we explain work related to our research. Section 3 describes the proposed method for creating a context gazetteer. In the next section, we build a context gazetteer of gene names from the EntrezGene database [16], and apply it to the BioCreative 2 gene name recognition task [22]. The usefulnes s of a context gazetteer is demonstrated experimentally. Representative output results are analyzed. We show what kinds of context patterns are mined and how they affect a proposed model using the context gazetteer. Sectio n 5 summarizes the contributions of this work, and explains the future work for generalizing learned contexts. This section presents a summary of thre e types of related studies of sentence level non-local features, gazetteer induction and weakly supervised learning. Sentence level non-local features usually depend on a deep parsing technique. For example, a previous work [7] used the Stanford dependency parser [17] to exploit features such as the head and governor of the noun phrases in a biomed-ical NER task. A more recent work [23] evaluated the effect of seven different parsers in feature generation for finding base noun phrases including gene names. However, they extract contexts only from training data, whereas we use a large amount of automatically annotated data. As a result, our approach is likely to provide richer and more sophisticated context patterns than their methods.
Gazetteers are invaluable resources for N ER tasks, especially for dealing with unknown words that do not appear in training data. They might have the same semantic categories to target entity classes [9], or related classes that are often more fine-grained sub-classes of the target entity classes [20,26]. Word clusters are also useful resources for NER similar t o gazetteers. In a related study [18], the Brown clustering algorit hm [3] were applied to NER successfully. A more recent work [11] used the dependency relations between verbs and multiword nouns for clustering multiword expressions. However, to the best of our knowledge, all of the related work that we have surveyed produce entity gazetteers (clusters).
The most similar concept to the contexts in this research can be found in the studies related to weakly supervised learning approach. For instance, a boot-strapping method [21] extracts context patterns from unlabeled data using a small set of seed words (entity mentio ns in case of NER) for a target class. In turn, it extracts new entity mentions using the extracted context patterns, and repeats this process. However, the quality of context patterns (and also entity mentions) degrades as iteration goes on because it inevitably suffers from se-mantic drift. In contrast, our method induces a large number of highly precise contexts without a repetitive process b y exploiting an encyclopedic database. This approach have become more realistic lately because of many publicly avail-able resources such as Wikipedia 1 and domain-specific databases. A context gazetteer is a confidence assigned list of dependency paths (hereinafter, contexts) of variable length that can co -occur with target entity names. Figure 2 portrays an exemplary context of length 3. It is a high confidence context in the context gazetteer of gene name s that will be used in the experiment section. It means that a word X surrounded by the context consisting of the head word expression , a dependent cells and a grand-dependent cancer with the corresponding dependency relations prep of , prep in and nn is likely to be an entity word, which is a part of a target entity name. This context can help to recognize the headword of an underlined gene name in a sentence,  X  X he expression of FasL in gastric cancer cells and of Fas in apoptotic TIL was also detected in vivo. X 
A useful context gazetteer should have rich and sophisticated contexts that are specific to target semantic classes. For the first requirement, we extract contexts from a large amount of automatically labeled data rather than a few manually annotated data. To satisfy the second requirement, confidence values are assigned to the extracted contexts. Figure 3 is the flowchart for the context gazetteer generation. Each step is explained in detail in the following. Step 1. An encyclopedic databa se consists of domain specific entity names and their descriptions. For each entity name, we label every mention of it in the de-scription using exact string matching. The primary reason for using an encyclo-pedic database rather than the list of target entity names and some free texts is to remove the ambiguity of the semantic categories of target entity names appearing in free texts [29]. For example, presuming that we are going to generate labeled data with the names of people using some free text (e.g. newspapers) and a list of the names of people automatically, the process would invariably create very noisy data because human names are often used as the names of companies (e.g., Hewlett-Packard and Ford Motor Company), diseases (e.g. Alzheimer disease), places (e.g., Washington, D.C and St. Paul, Minnesota), and so on.
 Step 2. The labeled texts are then parsed. The dependency paths (contexts) involving entity words are extracted. B ecause of the excessive number of possible contexts, we applied two constraints to c ontext generation. First, the contexts that have no content words (nouns, verbs and adjectives) except an entity word are removed because these contexts are o ften too general to be effective contexts. Second, we limit the maximum length of contexts depending on the data size. Step 3. For each context, an entity word is anonymized. Then, contexts can be normalized to increase the coverage of a context gazetteer. For example, stems (or lemmas) are useful instead of words. After normalization, we remove duplicated contexts and keep them unique.
 Step 4. Contexts are often ambiguous even if they frequently appear with tar-get entity names. We solve this problem by assigning confidence to each context. Presuming that data D is annotated automatically with the mentions of T dif-ferent entity types 2 , then, the confidence (conditional probability) of an entity type t given a context c is defined as in where e t is an entity word of the semantic type t  X  T in the data D .Theestimated confidence is pessimistic, meaning that they are usually lower than they should be because automatically annotated data have high precision but low recall. In this section, we create a context gaze tteer of gene names from the EntrezGene database [16], and apply it to the BioCreative 2 gene name recognition task [22]. We analyze the effect of the context gazetteer by comparing the NER models with and without the context gazetteer. 4.1 Data Context Gazetteer. For gazetteer generation, we use the gene names (includ-ing synonyms) and the human curated reference information in the EntrezGene. At the first step in Fig. 3, 358,049 abstracts are extracted from the MEDLINE database 3 using reference information. Each abstract is labeled using the gene names referenced in the abstract. The l abeled gene names are highly precise because explicit references exist bet ween the gene names and the abstracts.
Second, the labeled texts are parsed using the Stanford POS tagger [27] and dependency parser [17] included in the CoreNLP tool 4 . Then, we extracted the dependency paths (contexts) that involve entity words. Contexts that have no content words aside from entity words are filtered out. The maximum length is set to 5 experimentally.

Third, the entity words of the contexts are anonymized. In the biomedical domain, many entity names include symbols and numbers. For domain-specific normalization, continuous numbers and symbols of the words in the contexts are converted into a representative number (0) and symbol (under-bar), respectively. Lastly, confidence values are assigned to each context using Eq. 1. Contexts appearing less than 10 times are removed in this process beca use the estimated confidence might be unreliable.

Several extracted contexts having high confidence are presented in Table 1. At the beginning of this study, we expected to obtain contexts sim ilar to predicate-argument structure (PAS) and domain specific relations. For example, the second context in this table indicates that X is likely to be a gene if it appears in a relation with C-jun as in  X ... interaction between X and C-Jun  X . The fourth and seventh contexts are in the form of PAS using nominal and verbal predicates respectively. However, we also found unexpected but interesting contexts too. First, many contexts capt ure factual knowledge. The first and fifth contexts are the simplest ones meaning that X is likely to be a gene if it is a globin or a repressor . The sixth context means X is likely to be a gene if it acts as a mediator . Second, some contexts re present procedural information. The third context, for instance, indi cates that there is a screening process for analyzing mutations of a gene. Lastly, the eighth context, seemingly uninformative at first glance, means that discovering the function of a gene is a common task as in  X  X he exact function of IP-30 is not yet known, but it may play a role ... X  Entity Gazetteer. We use four entity gazetteers compiled from the Entrez-Gene, Universal Protein Resource (UniProt) [6], Unified Medical Language Sys-tem (UMLS) [1] and the Open Biological and Biomedical Ontologies (OBO) 5 . For improving the coverage of these gaze tteers, continuous numbers and symbols of the entity names are normalized into a representative number and symbol (0 for numbers and under-bar for symbols), and all alphabet characters are lower-cased. This process also applies to the input texts.

For the entity gazetteers compiled f rom the EntrezGene and the UniProt, we use the single semantic categories: gene and protein. However, the UMLS and the OBO gazetteers have multiple categories, some of which are related to gene names such as peptides and amino acids, but many of which are differ-ent biomedical entity categories. Du ring NER system development, we found that not only gene-related categories but also other categories are beneficial for increasing performance.
 GENETAG corpus. The BioCreative 2 gene menti on recognition task uses the GENETAG corpus [24] comprising 20,000 sentences, of which 15,000 sentences were used for training and 5,000 sentences were used for testing.

We processed raw texts to obtain additional syntactic information for use in feature generation. Raw tex ts consisting of sentences are split into tokens using a fine-grained tokenization scheme that uses whitespace and non-alphanumeric characters as token boundary markers. When a string is tokenized at non-alphanumeric character, this character also becomes a single character token (e.g.,  X  X 53-activated X  to  X  X 53 X ,  X - X  and  X  X ctivated X ). Next, the tokenized text is fed to the GENIA tagger [28] for lemmatization, POS-tagging, and chunking. For each entity gazetteer, the sequences of to kens that appear in the gazetteer are tagged using the BIO labels (e.g.,  X  X ntityGaz B-EntrezGene X ,  X  X ntityGaz B-UniProt X , etc.). Lastly, for the EntrezGene context gazetteer, the tokens surrounded by the contexts of the gazetteer are tagged with context gazetteer class label. The confidence of a context is quantized at every 0.1 step. For ex-ample, if a token is surrounded by two contexts with the confidence 0.31 and 0.56, then we assign two labels to the token,  X  X ontextGaz EntrezGene 3 X  and  X  X ontextGaz EntrezGene 6 X , where the confidence is rounded up. 4.2 Machine Learning and Features For machine learning, we use the CRFsuite [19], which implements first-order linear-chain Conditional Random Fields [14]. The regularization parameter (C) is optimized using the first 90% of the original training data as training data and the rest, 10% as the development data. Fifteen C values (0.03125, 0.0625, 0.125, 0.25, 0.5, 0.75, 1, 2, 3, 4, 5, 6, 8, 10, and 16) are tested. The best performing one is chosen.

A set of features used in the experiment is presented in Table 2, and the symbols are explained in Table 3. 4.3 Experiment Results Table 4 shows an experiment result obtained using various combinations of the four entity gazetteers and the context ga zetteer. The numbers in a pair of paren-theses show improvement from the model 0 (baseline model) using no gazetteers.
When the context gazetteer is used in comb ination with the entity gazetteer(s), both precision and recall increase, as shown in models 3 and 5. Considering that precision and recall are tradeoff measures, the experiment result demonstrates the usefulness of the context gazetteer . In addition, the context gazetteer im-proves recall notably. This is an important merit because NER models usually exhibit high precision but low recall [10] because of the asymmetric data where one class label, O , dominates all other classes.

Surprisingly, when only the context gaze tteer is used, the overall performance drops slightly. We suspect that some rela tion exists between entity gazetteers and context gazetteers but further investigation is necessary to reveal it. 4.4 Result Analysis We manually compared about 20% of the output of models 4 and 5 to see how the context gazetteer features affect the tagging results.

There are 32 gene names correctly r ecognized by model 5 but not by model 4. In all of these cases, one or more context gazetteer features are triggered. The following list shows several examples in which model 5 recognized the under-barred gene names and model 4 recognized the italicized gene names.  X  One major transcript encodes MEQ ,a 339-amino-acid bZIP protein which  X  The association of I-92 with p92 , p84 , p75 , p73 , p69 ,and p57 was com- X  The exact function of IP-30 is not yet known, but it may play a role in Two context gazetteer features are triggered for the gene name  X  X EQ X ,  X  X obj(encode, X) X , and  X  X ppos(X, protein). X  The second feature is a strong evidence of X being a gene name becaus e a word X is in apposition with the word protein. In the second example,  X  X -92 X  has a feature  X  X rep of(association, X), prep with(X, p0) X  meaning that X is likely to be a part of gene name if it is associated with the gene name  X  X 0 X  whe re 0 is a normalized number. Contexts of these kinds are the fragments of domain specific knowledge and usually have high confidence (0.5 for this context). In the last example, the gene name  X  X P-30 X  has a context gaze tteer feature  X  X rep of(function, X) X  and a more specific one  X  X subjpass(known, function), prep of(function, X) X  with confidence 0.44 and 0.54. These contexts can be interpreted as domain-specific expressions where figuring out the function of a gene is a much more important task than others (54% vs. the rest).
 However, 15 gene names are recognized by model 4, but not by model 5. Context gazetteer features are not triggered for 3 cases. Because we use the words (not stems or lemmas) in the contexts, the coverage might be not sufficiently high. For the other 12 cases, context ga zetteer features are fired, but these gene names are not recognized. We are current ly investigating the causes of these cases. As described in this paper, we proposed the use of a context gazetteer as a new non-local feature for NER. We also described how to induce a rich and sophisticated context gazetteer from au tomatically annotated data using an en-cyclopedic database. Compared to the feature aggregation methods [4,13,20], the proposed method can be easily applied to streaming data such as tweets and pre-processed data with sentence select ion where recognizing document (or dis-course) boundaries is difficult. The proposed method is applied to a biomedical NERtask.Itsusefulnessisdemonstra ted in addition to entity gazetteers.
However, we also uncovered difficulties. First, for this research, we used words and their dependencies as contexts. However, these contexts sometimes include uninformative words in the middle of contexts. If it is possible to generalize the contexts by replacing these unimportant words with POS-tags or wildcards, then the coverage of the context gazetteer can be enhanced. Second, gene names (or parts of them) often appear as a part of contexts. Although these contexts often have very high confidence, they may not be general patterns. They can be more useful if they were replaced by some general gene name wildcards.
 Acknowledgments. This research was partly supported by JST, PRESTO. This research was partly supported by JSPS KAKENHI Grant Numbers 23240018 and 23700159.
