 Piecewise Linear Representation (PLR) has been a widely used method for approximating data streams in the form of compact line segments. The buffer-based approach to PLR enables a semi-global approximation which relies on the aggregated processing of batches of streamed data so that to adjust and improve the approximation results. However, one challenge towards applying the buffer-based approach is allocating the necessary memory resources for stream buffering. This challenge is further complicated in a multi-stream environment where multiple data streams are competing for the available memory resources, especia lly in resource-constrained sys-tems such as sensors and mobile devices.

In this paper, we address precisely those challenges mentioned above and propose efficient buffer management techniques for the PLR of multiple data streams. In particular, we propose a new dynamic approach called Dynamic Buffer Management with Error Monitoring (DBMEM) , which leverages the relationship between the buffer demands of each data stream and its exhibited pattern of data values towards estimating a sufficient buffer size. This en-ables DBMEM to provide a global buffer allocation strategy that maximizes the overall PLR approximation quality for multiple data streams as shown by our experimental results.
 H.2.4 [ Database Management ]: Systems X  Query Processing Algorithms, Design, Experimentation, Performance PLR, data streams, dynamic buffer allocation  X 
This work is supported in part by the Australian Research Council award DP110102777
Figure 1: Incremental vs. buffer-based approach to PLR.
In order to effectively represent streaming data for efficient stor-age and sequence trend analysis, Piecewise Linear Representation (PLR) has been widely used for approximating such data in the form of compact line segments [1]. To guarantee the approximation quality, an error bound is typically specified to restrict the maxi-mum error allowed for each segment. With its practical advantages, error-bound PLR technique has been widely used in many domains including ECG analysis [2] and financial market [3].

Intuitively, an error-bound PLR on streaming data can be gener-ated using an incremental approach, which greedily updates a line to approximate as many points as possible until the error bound is reached [1]. However, such simple incremental approach might lead to inappropriate segmentation that falls short in reflecting the inherent data trends, as shown in Figure 1.

In order to better represent data trends and reduce the approxi-mation error, Keogh et al. [1] proposed the SWAB buffer-based ap-proach for online error-bound PLR. In SWAB, a buffer is allocated, in which stream data points are stored as they arrive and processed as a  X  X atch X  all together. Compared to the incremental approach, SWAB adopts a semi-global view of streaming data which results in more faithful approximations (as shown in Figure 1).

In this paper, we argue that allocating the appropriate amount of buffer space is central to the success of all buffer-based PLR algorithms including SWAB. One challenge towards applying the buffer-based approach is the allocation of enough memory resources for stream buffering. On the one hand, underestimating the al-located buffer might lead to a poor approximation that resembles that of the incremental approach. On the other hand, overesti-mating that allocated buffer might lead to wasting scarce mem-ory resources. The drawbacks of such overestimation are partic-ularly emphasized in a multi-stream environment where multiple data streams are competing for the available memory resources. This is especially the case in resource-constrained systems such as sensors and mobile devices. Moreover, for each stream, the buffer demand is typically dynamic as the data behavior varies over time and that variation is often uncorrelated across the different data streams which makes allocating the right buffer space further chal-lenging.

In this paper, we address precisely those challenges mentioned above and propose efficient buffer management techniques for the piecewise linear representations of multiple data streams. In par-ticular, we extend the basic SWAB algorithm and propose a new dynamic approach called Dynamic Buffer Management with Er-ror Monitoring (DBMEM) . DBMEM leverages the relationship be-tween the buffer demands of each data stream and its exhibited pat-tern of data values towards estimating its sufficient buffer size. This enables DBMEM to provide a global buffer allocation strategy that maximizes the overall PLR approximation quality for multiple data streams.

The rest of this paper is organized as follows. We formally de-fine some preliminaries in Section 2. The main approaches of this work are introduced in Section 3. Section 4 shows our experimental results, and we conclude in Section 5.
In the model considered in this paper, a data stream S is an infi-nite series of numerical data points such that S = p 1 ,p efficient storage and communication, a data stream is continuously approximated into a sequence of consecutive line segments using the Piecewise Linear Representation (PLR) approach. Hence, a data stream S is perceived as a series of line segments SG such that SG = sg 1 ,sg 2 ,... . Each segment sg i is easily identified by a linear function, which is characterized by a 4-tuple { b i representing sg i  X  X  beginning and end positions, line slope and off-set respectively. Hence, for any b i  X  j  X  e i , the approximate value of p j can be simply derived by p j = g i  X  j + h i .

In order to measure the approximation error, in this paper we adopt the widely used Sum Squared Error (SSE) metric. SSE is defined as the sum of the squared error between all the point val-ues and their corresponding approximate values. For instance, the approximation error of the points on segment sg i is computed as j = b i ( p j  X  p j ) 2 . In order to provide guarantees for the quality of approximation, a maximum error is typically defined for all the line segments. Specifically, for a sequence of m line segments:  X  error bound.

In the presence of multiple data streams, the overall buffer re-source should be distributed among the different streams. In par-ticular, suppose there are k data streams to process in parallel, de-noted as S = S 1 ,S 2 ,...,S k , with defined error bounds  X  1 , X  2 ,..., X  k . In that case, each of the k streamsistobeas-signed a portion of the total available buffer L .

In order to evaluate the quality of approximation under the multi-stream and limited buffer model, we utilize the error-to-buffer curve shown in Figure 2. The figure illustrates the typical overall ap-proximation error achieved by the SWAB algorithm as the provided buffer size changes. In particular, as the buffer size increases, there is a growing semi-global view of the buffered data, which helps to adjust the segmentation and reduce the overall error. However, if the buffer size is large enough, the optimized segmentation will be determined and the result of the approximation error will level off and converge to a minimum value, which we call E O . Hence, increasing the buffer size beyond the point will result in wasting buffer space while achieving no further reductions in the achieved approximation error.

The value E O serves as a benchmark for assessing the approxi-mation error exhbited under any buffer setting. Specifically, if the overall error of the segments generated under a certain buffer set-ting is E B , then the approximation error achieved under that setting can be evaluated as: | E B  X  E O | /E O . Accordingly, for k streams, the overall approximation error can be evaluated as: In this section, we will first introduce a simple extension of the SWAB algorithm [1] to the case of multiple data streams considered in this paper (Section 3.1). While that extended version adopts a static solution to the buffer allocation problem, it forms the basis for our novel dynamic approach presented in Section 3.2.
Recall from the previous section that the relationship between the approximation error and the available buffer size is easily cap-tured using the error-to-buffer curve as shown in Figure 2. In partic-ular, when the buffer size increases, the overall error first increases to a peak value, and then falls down to a convergence value with some fluctuations. We denote that buffer size at which the approx-imation error converges as B 0 .

Intuitively, in the presence of multiple data streams and enough memory resources, allocating each data stream S i a buffer space of size B i 0 should minimize the approximation error per stream, and in turn the overall error across streams. In reality, however, mem-ory resources are limited, especia lly in resource-constrained envi-ronments, which makes efficient buffer allocation across those data streams a necessity. In such case, assume that stream S cated a buffer space of size l i such that l i  X  B i 0 . To determine the expected error incurred by approximating S i using l i ,wesimply employ a quadratic fitting model, as shown in Figure 3, where the parabola captures the downward trend of the error-to-buffer curve.
Since we evaluate the approximation quality by the relative value of overall error, for simplification, we can normalize the error-to-buffer curve by the convergence error. Hence, the relationship be-tween the overall error E B ( l i ) and the corresponding buffer size l is estimated using the following equation: where a i represents the curvature of the parabola and indicates the rate of reduction in approximation error.

Thus, our objective is to determine the value of each l i to minimize a i ( B i 0  X  l i ) 2 under the constraint that l where L is the total available buffer space. By substituting B l = l i , then we can derive the following compact objective: given l i = B i 0  X  L , minimize a i l i 2 . To solve this optimiza-tion problem, we appy the classical Lagrange Multiplier Method in which we introduce the multiplier  X  and derive the objective func-tion as:
To solve the objective function and get the minimum value, de-rive the partial derivative for each variable, and let it be zero:
Finally, we can obtain the solution for each l i : Hence, the actual buffer assigned to stream S i is:
Putting it together, in our optimized static solution for buffer al-location across multiple data streams, we follow the following two steps: 1) create an error-to-buffer curve per data stream S some training data, and 2) calculate the optimal buffer l to a data stream S i using Equation 4.

In the first step above, the training data per stream S i a subsequence of S i  X  X  history that is collected during a training phase. That training data is leveraged to create the error-to-buffer curve and in turn, to determine the optimal buffer size l ond step. Once a buffer of size l i has been assigned to each data stream S i , the buffer-based SWAB algorithm is applied to approx-imate the newly arriving data points and the buffer size remains constant (= l i ) throughout the stream X  X  lifetime.
The static solution described above is expected to provide an optimized buffer allocation when the characteristics of each data stream exhibited through the training phase are sustained through-out its lifetime. For many practical applications, however, such assumption is not guaranteed since the characteristics of the under-lying data streams are expected to vary over time. This represents a challenge to our static solution, which we address in this sec-tion via a novel dynamic approach to the buffer allocation problem. Specifically, in the following we first focus on the problem of dy-namic buffer allocation for a single data stream then we extend our solution to the general case of multiple data streams.
Clearly the convergence buffer size B 0 (in Figure 2) is different for different data streams, which is an intrinsic feature of the SWAB algorithm. In particular, under SWAB, the streamed data points are accumulated in the assigned buffer until it is full at which point the PLR processing takes place. Specifically, a global algorithm (i.e., bottom-up algorithm) is carried out on the buffer points to gener-ate a PLR representation of segments. Out of those segments, only the first one is generated and its corresponding points are removed from the buffer, whereas the data points corresponding to the re-maining segments are retained in buffer and are processed in the next iteration of SWAB (i.e., when the buffer is full again).
Clearly, the convergence buffer size B 0 highly depends on the fluctuation in data as well as the error bound. For instance, if the streamed data points easily fit onto one segment that adheres to the specified error bound, then a larger B 0 is beneficial since it allows accumulating more data points, process them once, and re-lease them all together. However, if the streamed data points are highly fluctuating then each iteration of SWAB will process a full buffer but release only very few points. Hence, it is beneficial to maintain a small buffer in the first place so that to save on the pro-cessing time as well as save the extra buffer space and allocate it to a less-fluctuating data stream.

Hence, the pattern of data values and the fluctuations in these values directly affect the amount of buffer required during approxi-mation. Meanwhile, if a buffer of size B 0 is provided and it is full, then there is enough data points in that buffer to determine a high-quality segmentation, which cannot be further improved even when given a buffer bigger than B 0 . This indicates that there must be some characteristic that captures the behavior of the subsequence of points within the buffer and determines if the currently provided buffer is enough.

Based on the observations above, we are motivated to find an in-dicator that captures such characteristic and reflects the status of the buffered data points. That indicator should fulfill the following cri-teria: (1) it should be incrementally updated with the arrival of new data; (2) it should reflect the fluctuations in the stream data values; (3) it should make use of the SSE value, since the error-bound is de-fined based on that value. Accordingly, once that indicator reaches a certain threshold, we can assert that the current buffer size is suf-ficient and that there is no need to accumulate more points.
In this paper, we propose to use a single line to fit all the data points that are currently buffered, and derive the corresponding SSE value of that single line, namely single-SSE. Intuitively, that single-SSE value will keep increasing as more points arrive on the data stream. The intuition is that if the single-SSE increases to a certain threshold, the data points in the buffer will contain enough informa-tion to determine the optimized segmentation since the SSE value can reflect the fluctuation of the sequence. Accordingly, we define the single-SSE value as follows:
D EFINITION 1. Given a sequence of data points such that there is a line segment that approximates those points using least square fitting, single-SSE is defined as the SSE between the original points and the approximate points on that line segment.

The proposed single-SSE indicator has the desirable property that it is incrementally calculated in constant time. Hence, the single-SSE value is continuously updated and monitored as new data points are streamed in. Once that values reaches a pre-specified threshold, the amount of buffered points is asserted to be sufficient and the bottom-up algorithm is applied on those points to generate aPLR.

In order to define a proper threshold value for the single-SSE indicator, we leverage the training data sequence for that purpose. However, differently from the optimized static solution, we decide the threshold value according to a statistical analysis of the approx-imation quality provided by a range of feasible buffer sizes instead of just B 0 . In particular, for a given training sequence we conduct the SWAB algorithm on a buffer of size B 0 and at each point where the buffer is filled up with data, we calculate the corresponding single-SSE. Since a buffer of size B 0 is large enough to converge the segmentation result, it implies that the single-SSE value is also large enough to converge the segmentation. Finally after SWAB processes all the training points, we can generate a histogram of all the single-SSE values.
As shown in Figure 4, the proposed histogram represents the count number (i.e., frequency) of the different single-SSE values perceived throughout the training phase. In the figure, each bin in-dicates the count number of all the s ingle-SSE values falling in the corresponding bin range. Hence, a proper choice of the single-SSE threshold is a one with sufficient coverage. For instance, if we set the coverage to a certain percentage (e.g. 60% coverage), then the corresponding single-SSE threshold will be the one that is large enough to cover 60% of the recorded single-SSE values. Our ex-perimental results show that choosing a standard coverage around the 80% mark results in a reasonable threshold that successfully estimates and allocated the buffer requirements of each stream as discussed in the next section.
In this section, we propose our Dynamic Buffer Management with Error Monitoring (DBMEM) algorithm, which is a new ap-proach that adaptively allocates the buffer resources required for the approximation of multiple data streams. Towards this, DB-MEM leverages the single-SSE histogram information described in the previous section. In particular, DBMEM learns the single-SSE threshold value for each data stream in the system and utilizes that value to assign each stream a corresponding priority value that rep-resents its buffer demands. The details of the DBMEM algorithm are listed as follows: Initialization: Initially, we first divide and assign the available buffer space across the data streams using the optimized static ap-proach. For each stream, the single-SSE value is calculated and updated as new data arrives.
 Buffer Release: Once the buffer space of a certain data stream is filled up with data points, the bottom-up algorithm is applied on those points and one line segment is generated. After storing that segment, the corresponding portion of the buffer space is released as a free resource.
 Buffer Reallocation: To reallocate any available free buffer space, DBMEM divides that available space into several buffer units, which are assigned to the data stream with the highest priority one unit at a time. Such priority is calculated based on the single-SSE of the residual points in the buffer together with the correspond-ing single-SSE threshold. In particular, assume that for stream S the single-SSE threshold is  X  i , and the current single-SSE of the buffered data points is E R i , then the priority of S i is defined as the distance between E R i and  X  i , which is calculated as:
The intuition underlying DBMEM i s that the priority of a data stream should be increasing as its single-SSE value decreases. This is equivalent to the case in which it is easy to fit all the arriving points to a single segment with minimum error. In that case, it is beneficial to increase the buffer size and accumulate more points before running the bottom-up algorithm for approximation. To the contrary, if the single-SSE value is observed to be increasing, it indicates that it is beneficial to cap its buffer size since very few of the buffered points will actually fit to a line segment and there is no need to accumulate more.
In this section, we show experimental results that compare the performance achieved by our proposed approaches over synthetic data streams.

In order to simulate the streaming data, we generate random data values that follow a random-walk model. That is, each data point is smaller or greater than the previous data point according to the relationship p i +1 = p i +  X  ,where  X  follows a normal distribution N (  X ,  X  2 ) such that in the default setting  X  =0 and  X  2 =1
To evaluate the approximation quality, we use Equation 1 where we calculate the percentage of the overall error relative to the con-vergence benchmark (i.e., E O ) of each stream as described in Sec-tion 2.

The results reported in each experiment are obtained by applying the proposed algorithms on 5 data streams, each of which contains 10000 data points. We repeat the processing for 5 times and report the average results.
In this experiment, we analyze the effect of data fluctuations on the approximation quality achieved by our proposed algorithms.
To introduce data fluctuations in to our default settings, we inject some short data sequences that are generated according to a random model with  X  =0 and  X  2 =10 , which has higher deviation than the original model used to generate the default data streams. We embed those high-fluctuation sequences into the original sequences according to some percentage which is a simulation parameter. By tuning that embedding percentage and the available buffer size, we are able to compare the approximation results provided by the op-timized static algorithm and DB MEM under different settings.
Figure 5 shows the overall error (relative to convergence error) as the percentage of embedding fluctuating data increases from 10% to 100% when the total buffer size is set to 40% of the total con-vergence buffer size of all streams (i.e., B i 0 ). From the figure, it is obvious that DBMEM shows a significant improvement over the static approach. This improvement is further emphasized as the the embedding percentage increases. In particular, when the percentage of embedded sequences is low, the two approaches pro-vide similar results, but when the embedding percentage increases to higher levels, DBMEM will gradually outperform the static ap-proach as it automatically adapts to the data stream characteristics (i.e., fluctuations). In this experiment, we study the sensitivity of our proposed DB-MEM algorithm to the coverage parameter which determines the single-SEE threshold value as discussed in Section 3.2.
Figure 6 shows the relative overall approximation error achieved by DBMEM as the coverage parameter is increased from 10% to 100%. From the curve trend, we can observe that, when the cov-erage value increases, the approximation quality will initially im-prove. However, if the coverage is excessively high, the quality of approximation will decrease. This is because the histogram of single-SSE distribution usually contains some high values occur-ring at low frequency (i.e., long tail distribution). Hence, if the coverage is too high, then in turn the single-SSE threshold value will be set to a high value leading to a case where some data streams will signal a higher demand for buffer space than what they actually need. Assigning more buffer space to such streams results in an un-fair situation where other streams that actually need that buffer are under-allocated, which eventually causes the increase in approx-imation error as observed in Figure 6. Hence we recommend to set the coverage parameter within the range of 60% to 80% provides an appropriate value to estimate the actual buffer demands per stream.
In this section, in addition to the quality of approximation, we also study the quality of compression which is an equally important factor in data stream approximation via PLR.
Figure 7 shows the results from applying the original SWAB al-gorithm as the buffer size increases. The y-axis shows both the approximation error as well as the number of generated segments. The figure shows that when the buffer size is small, the approxima-tion error can also be small due to the fine segmentation, but the number of segments generated will be large (i.e., low compression ratio). On the other hand, increasing the buffer size allows for ac-cumulating more data points and in turn, the generated segments can approximate more data. Hence the number of PLR segments will decrease while the approximation error grows to a peak value. Only if the buffer size is sufficient, both the compression ratio and the approximation error can be improved to a satisfactory level. This shows the need for setting such sufficient bound on the buffer size allocated to each stream, which is achieved by the approaches proposed in this paper.
In this paper, we argue that allocating the appropriate amount of buffer space is central to the success of all buffer-based PLR algo-rithms including the popular SWAB algorithm [1]. Towards this, we propose new algorithms with the objective of providing a fair and balanced buffer allocation across multiple data streams. Our proposed algorithms have the desirable feature of avoiding both the underestimation or overestimation of the necessary buffer re-quirements per approximated data stream. This is achieved through a statical analysis of the data streams under consideration, which form the basis for both our static and dynamic approaches. Our ex-perimental evaluation shows th e ability of our proposed approaches to provide a global buffer allocation strategy that maximizes the overall PLR approximation quality for multiple data streams. [1] E. Keogh, S. Chu, D. Hart, and M. Pazzani. An online [2] P. Trahanias and E. Skordalakis. Syntactic pattern recognition [3] H. Wu, B. Salzberg, and D. Zhang. Online event-driven
