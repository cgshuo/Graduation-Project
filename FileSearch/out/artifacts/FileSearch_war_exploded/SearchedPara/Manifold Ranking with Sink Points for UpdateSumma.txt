 Update summarization aims to create a summary over a topic-related multi-document dataset based on the assump-tion that the user has already read a set of earlier documents of the same topic. Beyond the problems (i.e., topic rele-vance, salience, and diversity in extracted information) t ack-led by topic-focused multi-document summarization, the up -date summarization must address the novelty problem as well. In this paper, we propose a novel extractive approach based on manifold ranking with sink points for update sum-marization. Specifically, our approach leverages a manifol d ranking process over the sentence manifold to find topic rele -vant and salient sentences. More important, by introducing the sink points into sentence manifold, the ranking process can further capture the novelty and diversity based on the intrinsic sentence manifold. Therefore, we are able to ad-dress the four challenging problems above for update sum-marization in a unified way. Experiments on benchmarks of TAC are performed and the evaluation results show that our approach can achieve comparative performance to the existing best performing systems in TAC tasks.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  abstracting methods ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  text analysis Algorithms, Performance, Experimentation Update Summarization, Multi-document Summarization, Man -ifold Ranking with Sink Points
There has been increasing interests in text summariza-tion with the massive explosion in the amount of data on the Web. As the real time data becomes the trends, it is important that the summarization can take the temporal di-mension into account so that the obsolete information which has been presented to users in the past can be removed in the summary. Update summarization aims to write a short summary over a set of topic-related multi-document dataset , under the assumption that the user has already read a given set of earlier documents of the same topic. Give this defi-nition, we can find that there are four major problems that update summarization need to address: 1) Topic Relevance : The summary is based on a topic-related multi-document dataset, where a topic here represents user X  X  information need. Therefore, the summary must stick to the topic users are interested in. 2) Salience : Not all the sentences in doc-uments deliver information of equal importance about the topic. The summary has to neglect those trivial content because of the length limitation, and keep the salient infor -mation as much as possible. 3) Diversity : There should be less redundant information in the summary. In this way, we can fully leverage the limited summary space to cover as much information as possible about the topic. 4) Nov-elty : Given a specified topic and two chronologically ordered document datasets, the summary need to focus on the new information conveyed by the later dataset as compared with the earlier one under that topic.

Update summarization has attracted a lot of research in-terests recently. Most previous work can be categorized as extractive approach, which composes a summary by extract-ing sentences from target document dataset. Different ways were introduced in these approaches to address the novelty problem, including time decay factor [1, 5], sentence filter -ing [7], topic analysis [4] and negative influence diffusion [3]. However, most of these approaches [7, 3, 4, 5] did not address the four problems for update summarization simul-taneously. In contrary, they need some additional steps to address diversity or novelty with some heuristics.
In this paper, we propose a novel extractive approach based on manifold ranking with sink points for update sum-marization. This approach can iteratively extract sentenc es to form an update summary by simultaneously addressing the four problems above in a unified way. Specifically, our approach leverages a manifold ranking process [8] over sen-tence manifold, which can help find topic relevant and salien t sentences. More important, we introduce the sink points into the sentence manifold, which denote the sentences whos e ranking scores are fixed to the minimum ranking score dur-ing the manifold ranking process. Therefore, the ranking scores of other sentences close to the sink points will be nat -urally penalized during the ranking process based on the intrinsic sentence manifold. By turning both the sentences from the earlier document dataset and that already selected for summary into sink points, we can capture both novelty and diversity during the ranking process. In this way, we are able to address the four problems for update summariza-tion simultaneously in a unified way. We conduct empirical experiments based on the benchmark datasets of TAC2008 and TAC2009. The ROUGE evaluation results show that our approach can achieve comparative performance to the existing best performing systems in TAC tasks and signifi-cantly outperform other baseline methods.
Neither novelty nor diversity required by updated summa-rization can be addressed by the traditional manifold rank-ing process. Work [6] leveraged an additional step with a greedy algorithm to address the diversity problem. Unlike their approach, here we introduce the sink points into the sentence manifold to help capture both novelty and diversit y during the ranking process. The sink points are sentences whose ranking scores are fixed to the minimum ranking score (i.e. zero in our case) on the manifold during the ranking process. Intuitively, we can imagine the sink points as the  X  X lack holes X  on the manifold, where ranking scores spread-ing to them will be  X  X bsorbed X  and no ranking scores would be able to  X  X scape X  from them. In this way, the ranking scores of other sentences close to the sink points (i.e. sen-tences sharing similar information with the sink points) wi ll be naturally penalized during the ranking process based on the intrinsic sentence manifold.

As we know, novelty focuses on the new information con-veyed by the later dataset as compared with the earlier one under the given topic. Thus, we need to penalize the sen-tences in the later dataset which convey similar informa-tion as the earlier dataset. While diversity focuses on the redundant information among the selected sentences in a summary. Thus we need to penalize the sentences convey-ing similar information as the sentences already in a sum-mary. Therefore, by turning both the sentences from the earlier dataset and that already selected for summary into sink points, we can capture both novelty and diversity sim-ilarly based on the intrinsic sentence manifold during the ranking process. In this way, we address the four problems for update summarization in a unified way.

Formally, let  X  = { x 0 , x 1 , . . . , x s , x s +1 , . . . , x note a set of data points over the sentence manifold (each point represents one sentence), where point x 0 denotes the pseudo sentence of topic description, x 1 , . . . , x s denote sen-tences set as sink points, and x s +1 , . . . , x n denote the rest free sentences to be ranked, named free points . Hereafter, sentence and point will not be discriminated unless otherwi se specified. Let f :  X   X  R denote a ranking function which assigns a ranking value f i to each point x i . We can view f as a vector f = [ f 0 , f 1 , . . . , f s , f s +1 , . . . , f a vector y = [ y 0 , y 1 , . . . , y s , y s +1 , . . . , y since x 0 is the topic sentence, and y i = 0 (1  X  i  X  n ) for all the other sentences. The algorithm of update summa-rization based on manifold ranking with sink points is as follows: 1. Form the affinity matrix W for the sentence manifold, 2. Construct the Matrix S = D  X  1 / 2 W D  X  1 / 2 in which D 3. Iterate f ( t +1) =  X SI f f ( t )+(1  X   X  ) y until convergence, 4. Let f  X  i denote the limit of the sequence { f i ( t ) } . Each 5. Select the sentence x m with maximum score f  X  m as a 6. It the summary length is not reached, go to step 3.
As we can see, the major difference between our algorithm (i.e. manifold ranking with sink points) and traditional ma n-ifold ranking algorithm is that we introduce the indicator matrix I f into the iteration function in step 3. This indica-tor matrix I f is used to fix the ranking scores of sink points at the minimum (i.e., zero in our case) during the iteration. As a result, the sink points will not spread any ranking score to their neighbors during the ranking process. It is impor-tant to know that, with the indicator matrix introduced, the new iteration algorithm can still achieve a global stabl e state.

Theorem 1. The sequence { f ( t ) } converges to
Proof. According to iteration equation used in the algorithm, we have Let  X  P = D  X  1 W I f ,  X  P is the similarity transformation of SI as follows: hence  X  P and SI f have the same eigenvalues  X  .
Note that |  X  P ii | = 0, according to Gershgorin circle theo-rem, we have where |  X  | represents the norm of any eigenvalue of  X  P .
Since 0  X   X  &lt; 1, and |  X  | X  1, Hence, We can use this closed form to compute the ranking scores of sentences directly. In large-scale real-world problems, h ow-ever, an iteration algorithm is preferred. Update summarization has been one of the main tasks in a lot of manual labor to create the benchmark data for up-date summarization tasks. TAC2008 provided 48 topics and TAC2009 provided 44 topics. Each topic was composed of 20 relevant documents from the AQUAINT-2 collection of news articles, and the documents were divided into 2 Datasets: Document Set A and Document Set B. Each document set had 10 documents, and all the documents in set A chrono-logically preceded the documents in set B. In TAC task, a 100-word summary was required to be generated for each set of documents. The summary of Set B should be written under the assumption that the user has already read the con-tent of set A and should inform the user of new information about the given topic. for automatic summarization evaluation, as it produces the most reliable scores in correspondence with human evalua-tions. It measures summary quality by counting the number of overlapping units such as n-gram, word sequences, and word pairs between the computer-generated summary and the ideal summaries created by humans. The n-gram recall measure, ROUGE-N, is computed as follows: where n stands for the length of the n-gram, Cnt match ( gram is the maximum number of n-grams co-occurring in a candi-date summary and a set of reference summaries Refs , and Cnt ( gram n ) is the number of n-gram in the reference sum-maries. In evaluation, we use the ROUGE-2 (bigram-based) and ROUGE-SU4 (an extended version of ROUGE-2) au-tomatic metrics. The results were obtained with ROUGE version 1.5.5 with the settings used for TAC2008.
For evaluation, we compared our approach with several baseline methods. One category of baseline methods con-sists of the top performing systems on update summariza-tion tasks according to the ROUGE-2 metric on TAC2008 and TAC2009. Besides, we also leverage three other baseline systems, named Baseline-L, Baseline-U, and Baseline-MR, for comparison.
Baseline-L and Baseline-U are two standard baseline meth-ods provided by NIST on TAC. Baseline-L takes all the lead-ing sentences (up to 100 words) in the most recent docu-ment. It provides a lower bound on what can be achieved with those extractive summarizer [2]. Baseline-U generate s a summary consisting of sentences that have been manually selected from the dataset by a team of five human  X  X entence-extractors X  from the University of Montreal. It provides an approximate upper bound on what can be achieved with a purely extractive summarizer. This baseline method is only available on TAC2009.

The Baseline-MR method could be considered as an ex-tension of the method proposed in [6] on update summariza-tion. It involves two major steps: (1) a traditional manifol d ranking strategy is applied on sentence manifold construct ed from document set B; (2) an additional greedy algorithm is then employed to penalize sentences based on the document set A and sentences already selected for summary. The ma-jor difference lies between Baseline-MR and our approach is that Baseline-MR employs an additional greedy algorithm to address the novelty and diversity, while our approach intro -duce sink points into manifold ranking for the same purpose.
Besides, we denote our approach based on manifold rank-ing with sink points as MRSP . For experiments, we set the only parameter  X  of MRSP to 0 . 85, and the parameters of Baseline-MR are set as follows:  X  = 0 . 9,  X  = 1. Note here  X  acts as a balance factor between the influence of the in-trinsic manifold structure and the prior knowledge on each sentence in both methods, and  X  is the same penalty factor as used by Wan et al. [6]. We set the parameters to the spe-cific values as the corresponding summarization approach can achieve its best performance. To represent document set A on our sentence manifold, we form a pseudo sentence for A by aggregating all the sentences. Note that there are other ways to represent the information in document set A on the sentence manifold, e.g., one may make a summary on A first and then turn the summary into a data point on the sentence manifold.
The performance comparison based on update summa-rization tasks of TAC2008 and TAC2009 is shown in Table 1 and Table 2 respectively. Note that in Table 1, S14 repre-sents the best performing system by ROUGE-2 on TAC2008. It is also an extractive summarization approach. In Table 2, S34 represents the best performing system by ROUGE-2 on TAC2009. However, since S34 is not a purely extrac-tive summarization approach (with massive abstractive tec h-niques), we also shown the best performing extractive sum-marization approach on TAC2009, dented as system S24, for better comparison.

From the results on TAC2008 shown in Table 1, we can see that our approach can achieve comparative performance to the best performing extractive approach S14 in terms of both ROUGE-2 and ROUGE-SU4, and significantly outperform the other two baseline methods (p-value &lt; 0 . 01). Similarly, from the results on TAC2009 shown in Table 2, we can ob-serve that our approach can also obtain comparative perfor-mance to the best performing system S34, even though S34 uses massive abstractive techniques. Besides, our approac h can significantly outperform the best performing extractiv e Table 1: Performance Comparison on TAC2008 Table 2: Performance Comparison on TAC2009 approach S24 on TAC2009 and all the other three baseline methods (p-value &lt; 0 . 01). It is interesting to notice that the Baseline-U method, the supposed upper bound baseline sys-tem of TAC2009 provided by NIST, was also beaten by our approach.
There is only one parameter  X  in our proposed model, which is in fact a balance factor between the influence of the intrinsic manifold structure and the prior knowledge on each sentence. Figure 1 shows the influence of parameter  X  on the summarization performance. ROUGE X 2 Figure 1: ROUGE-2 vs. Parameter  X  on MRSP
As we can see, the summarization approach performs not so well when  X  is small, which may be due to the over em-phasis of the prior knowledge. However, we can also notice the degradation of performance when  X  approaches 1, which shows putting too much weight on the influence of struc-ture may not work well either. As a result, our Algorithm achieves the best performance when  X  = 0 . 85 approximately on both benchmarks of TAC2008 and TAC2009.
In this paper, we propose a novel approach based on mani-fold ranking with sink points for update summarization. By introducing the sink points into manifold ranking process, the multiple problems of update summarization including topic relevance, salience, novelty, and diversity, can be s i-multaneously addressed in a unified way. Experiments on benchmark of TAC2008 and TAC2009 show that the pro-posed approach can achieve comparative performance to the existing best performing systems in TAC tasks and signifi-cantly outperform other baseline methods.

For the future work, it is interesting to apply our pro-posed algorithm in Information Retrieval and Recommen-dation scenarios where a ranking that can simultaneously considers relevance, representative, novelty and diversi ty is also expected.
 This research work was supported by the State Key Program of National Natural Science Foundation of China (Grant No. 60933005) and the Program of National Natural Sci-ence Foundation of China (Grant No.60903139). [1] F. Boudin, M. El-B`eze, and J.-M. Torres-Moreno. A [2] H. T. Dang and K. Owczarzak. Overview of the tac [3] W. Li, F. Wei, Q. Lu, and Y. He. PNR2: Ranking [4] J. Steinberger and K. Je X zek. Update summarization [5] X. Wan. Timedtextrank: adding the temporal [6] X. Wan, J. Yang, and J. Xiao. Manifold-ranking based [7] J. Zhang, X. Cheng, H. Xu, X. Wang, and Y. Zeng. [8] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and
