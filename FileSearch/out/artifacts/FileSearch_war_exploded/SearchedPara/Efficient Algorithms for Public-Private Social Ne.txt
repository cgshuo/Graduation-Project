 We introduce the public-private model of graphs. In this model, we have a public graph and each node in the public graph has an associated private graph. The motivation for studying this model stems from social networks, where the nodes are the users, the public graph is visible to everyone, and the private graph at each node is visible only to the user at the node. From each node X  X  viewpoint, the graph is just a union of its private graph and the public graph.
We consider the problem of e ciently computing various properties of the graphs from each node X  X  point of view, with minimal amount of recomputation on the public graph. To illustrate the richness of our model, we explore two powerful computational paradigms for studying large graphs, namely, sketching and sampling, and focus on some key problems in social networks and show e cient algorithms in the public-private graph model. In the sketching model, we show how to e ciently approximate the neighborhood function, which in turn can be used to approximate various notions of cen-trality. In the sampling model, we focus on all-pair shortest path distances, node similarities, and correlation clustering. H.2.8 [ Database Management ]: Database Applications X  Data mining ;G.2.2[ Discrete Mathematics ]: Graph The-ory X  Graph algorithms ;K.4.1[ Computers and Society ]: Public Policy Issues X  Privacy Privacy; Social Networks; Graph Algorithms
Supported in part by a Google Focused Research Award, and by the MIUR-PRIN National Project  X  X RS TechnoMe-dia X  (Algorithmics for Social Technological Networks).
Work partially supported by a Google Europe Ph.D. Fel-lowship in Algorithms, 2011 and a Google Focused Award; part of the work done while at the Sapienza U. of Rome.
A social network is a perfect poster child for a massive graph. It embodies all the complexities and subtleties one might encounter in a typical large graph: degree distribu-tions that are heavy-tailed, the abundance of local struc-tures, the existence of global sparsity, the presence of noisy edges to the constant evolving nature, and so on. The study of social networks has blossomed into a fertile area of re-search in the last few years. There are several natural ques-tions that are key and unique to social networks. Owing to the scale of the network and its associated idiosyncrasies, many of these questions cannot be answered well by tradi-tional algorithmic tools and techniques. A large e  X  ort in the computational social sciences is devoted to the development of new algorithms and algorithmic paradigms for studying social networks  X  this field, though, still is in its infancy.
Privacy issues are a major factor in the algorithmic anal-ysis of social networks. In fact, privacy controls the way information is shared among the members of the social net-work, and also influences the way in which the network itself can be viewed and processed by algorithms. Privacy guar-antees are implemented in di  X  erent ways by di  X  erent social networks. In the simplest case, a user can mark some of her friends as private; this would make the edges between this user and these friends visible only to the user herself. In a di  X  erent instantiation of privacy, a user can be member of a private group; in this case, all the edges among the group members (in the extreme case, a clique) are to be considered private. Thus, each user in the social network has her own view of the link structure of the network.

In a recent study [16], Dey et al. crawled a snapshot of 1.4 million New York City Facebook users and reported that 52 . 6% of them hid their friends list. To illustrate the sce-nario further, consider a social recommendation algorithm. The social network provider could use only the public por-tion of the network to run the algorithm and build recom-mendations; this will easily ensure privacy for all the users. But, this will not benefit nodes whose edges are overwhelm-ingly private; as noted in the NYC example, there can be several such nodes. Alternatively, social network providers can, naively speaking, run the algorithm once for each user, on the union of the public portion of the network and the user X  X  private network. This also clearly respects the overall privacy requirements, however, it is grossly ine cient.
In this paper, we initiate the problem of designing e cient algorithms in the public-private network model. We seek al-gorithms that improve upon a naive implementation (e.g., running the vanilla algorithm on each of the di  X  erent net-works seen by the various users; the network seen by a user is the union of her private network and the public network). As a first step, we formalize the notion of the public-private graph model. We show our formalization is simple enough to be algorithmically useful, while is rich and realistic enough to be practically relevant.
 Our contributions. In the public-private graph model, there is a public graph G whose nodes are the users and that is visible to all users in the network. Each node u in the public graph has a private graph G u associated with itself; the nodes of G u are users from the public graph, and G u only known to u . We stipulate that the private graph cannot be arbitrary. Each node v in the private graph G u is at most distance two from u . While this might seem restrictive at first, it is su cient to capture many interesting privacy settings. For example, if G u is a star centered at u , then it captures the setting where u can mark certain of her friends as private. Likewise, if G u is a clique containing u , then it captures the setting where u is part of a private group. Our models allows G u to be a bit more general, supporting the following example. Consider the case of sharing a private circle in Google+. When a node u builds a private circle, it can choose that the members of the circle are visible to the rest of the circle. Consider two members v and w of this circle that are not in each others X  public or private circles. Then the edge ( u, v ) is private to w and the edge ( u, w )is private to node v . In other words, ( u, w ) 2 G v and ( u, v ) 2 G w , but neither of v nor w is connected to the other in the public graph, or in either or their private graphs.
We call an algorithm to be e cient in this model if it can compute a function on G [ G u in time proportional to the size of G u , i.e., just the number of edges in the private graph. The algorithm is allowed to preprocess the public graph G to store a (succinct) synopsis of G .

In this model, we consider two powerful computational paradigms for massive graphs, namely, sketching and sam-pling. Sketching algorithms have been developed for some basic graph problems including connectivity and cut sizes and more social-network specific problems such as neigh-borhood estimation and reachability. Some of the sketching algorithms produce composable sketches, i.e., the sketches of two graphs can be combined to get a sketch of their union. Adapting such algorithms to the public-private model is im-mediate (and thus less interesting). Our neighborhood esti-mation problems, though, have a quite non-trivial composi-tion. We obtain an e cient algorithm for estimating reach-ability counts in the public-private model; as it is known from earlier work, this quantity can be an e  X  ective heuristic for estimating various network centrality measures.
In the sampling setting, we illustrate our model with non-trivial algorithms for three key social network problems: es-timating all-pair distances, estimating node (pairwise) sim-ilarities, and correlation clustering. For the first two prob-lems, we obtain sampling-based algorithms that are e cient in the public-private model. For correlation clustering, we show how to e ciently update a clustering solution on the public graph using the edges in the private graph.
We illustrate the e  X  ectiveness of our model and the com-putational e ciency of our algorithms by performing exper-iments on real-world social networks. Figure 1: An example of an undirected public-private graph. Here, the blue edges out of node a are private to a and the red edges out of g and the edge ( d, e ) are private to g . The public graph consists of all the black edges.
We define the public-private model of graphs. In this model, we have a directed graph G =( V, E ), where V is the set of nodes and E is the set of edges; this graph is called the public graph. Let n = | V | and m = | E | . For each node u 2 V , we have an associated private graph where V u = { v 1 ,...,v k }  X  V and
E u  X  ( { u }  X  V u ) [ ( V u  X  { u } ) [ ( V u  X  V ) [ ( V  X  V Sometimes, we will consider the special case when G u is a star centered at u ; in this case, E u = { u }  X  V u .For simplicity, we use G [ G u to denote the graph with V as the set of nodes and E [ E u as the set of edges. In the above definitions, it is without loss of generality to assume u 2 V and E \ E u = ; . Furthermore, these notions can be extended to the weighted case in an obvious manner.
Let Out ( u ) denote the out-neighborhood of u and let Out denote the two-level out-neighborhood of u in G [ G u . While these definitions are for directed graphs, it is easy to extend them to undirected graphs.

In this paper we study e cient algorithms for various ba-sic graph problems in this model. In particular, we focus on the following computational question: how best we can preprocess the public graph G so that we can answer queries about or compute properties of G [ G u , for an arbitrary u ,as e ciently as possible? Ideally, the preprocessing of G should use space quasilinear in n and time poly( m ); the computation on G [ G u should use time/space near-linear in | E u | and poly(log n ). Note that the central parameters of interest are the preprocessing time and space of G and the query time to compute a property of G [ G u .

We consider two flavors of algorithms in this model. In the first we focus on sketching algorithms. In the second we focus on sampling algorithms.
 Warm-up: Number of connected components. To gain familiarity with the model before presenting other re-sults, we first show how to e ciently solve a simple problem in this setting: computing the number of connected compo-nents in undirected graphs when G u is a star. In this setting we have access to G and all the G u in advance and we want to be able to compute e ciently the number of connected component in G [ G u for each node u .

In the preprocessing step, we compute the connected com-ponents of the public graph. We then assign a component identifier to each node and store this information; this takes O ( m ) time and O ( n log n ) space since all we need is to store the label ` ( u ) of the component to which each node u 2 V belongs. Furthermore, we also store the total number of connected components.
 Now, to compute the number of connected components of G [ G u , we count the number of di  X  erent connected compo-nents that G u connects. This takes time | E u | since we only need to scan all the edges in G u .

Proposition 1. We can count the number of connected components in the public-private model using preprocessing time O ( m ) and space O ( n log n ) and query time | E u
In this section we show how to use graph sketches to ef-ficiently compute some interesting and non-trivial functions in the public-private graph model. We will deal with di-rected graphs in this section though the results easily apply to the undirected case as well.
 We first make an easy observation about graph sketches. Informally, a graph sketch is composable if the sketch of the graph G [ H can be easily obtained from the sketch of G and the sketch of H . Graph problems that are solvable by composable sketches naturally fit in the public-private model: compute the sketch of G and store it. To compute the function on G [ G u , first compute the sketch of G u use the composability property to compute the sketch of G [ G u using the stored sketch for G . Such sketches (which use linear projections, and are hence composable) exist for some basic graph problems such as connectivity and cut-size estimation [1, 2, 28]. Since the answer is easy for these problems, we will not consider them further.

For other problems such as neighborhood estimation, even though sketches exist [7,10,11,29] and even though they are composable, one has to be careful how to compose them ef-ficiently in the public-private model. This is precisely what we do in this section. We show how to e ciently compute the number of nodes reachable from a node u in G [ G u and hence e ciently estimate the number of nodes within distance 1 , 2 ,..., and so on from u . We then use these quan-tities to get an estimate of some centrality measures as in [8]. Given a directed graph G =( V, E ), the reachability tree T ( v ) at a node v is defined as any directed tree with v as the root that contains all the nodes reachable from v using the edges in E . Here, for each edge ( x, y ) in the tree, x is the parent, y is the child, and ( x, y ) 2 E . This is a useful structure in general, for example, in a social network setting where the directed edges denote the  X  X ollow X  relation, the size of the reachability tree represents the number of people who follow a specific user (at the root of the tree) directly or indirectly.

The main tool that we use to e ciently estimate the size of the reachability tree for a specific node is the bottom-k sketch [12]. Before describing our algorithm we briefly review the bottom-k sketch and show how it can be used to estimate the size of the reachability tree at a node. Suppose we are interested in estimating the size of an arbitrary subset V 0  X  V . First, we assign to each node v in the graph a number r ( v ) uniformly at random in [0 , 1]. Let r ( V 0 the set { r ( v ) } v 2 V 0 . Assuming | r ( V 0 ) | k ,let Bot r ( V 0 ) be the subset of the k smallest elements in r ( V let b k ( V 0 )=max { Bot k ( V 0 ) } , i.e., the k th smallest element in r ( V 0 ). Now we can estimate the size of V 0 just looking at Bot k ( V 0 ) and b k ( V 0 ); it constitutes the sketch of V estimate of the size of V 0 is given by As shown in [11, 12] the estimate is accurate; indeed, for any c&gt; 0, it is enough to set k =(2+ c )  X  2 log n to have a probability of having relative error larger than  X  bounded by n c . A nice property of this sketch is that it is composable; this is crucial in estimating the size of the reachability tree.
Using such sketches it is possible to estimate the size of the reachability tree in a graph e ciently using the follow-ing algorithm. As before, each node v 2 V has a random number r ( v ) 2 [0 , 1]. Initially each node v has a sketch S ( v, 0) = Bot k ( Out ( v )), i.e., the set of k th smallest numbers assigned to nodes in Out ( v ). Then at iteration i , each node v in the graph receives S ( w, i 1) for all the out-neighbors w 2 Out ( v ), and computes S ( v, i ) as the set of k th small-est numbers in its sketch and that of its neighbors, i.e., S ( v, i )= Bot k D iterations, where D is diameter of the graph, S ( u, D ) is equal to Bot k ( T ( u )), i.e., the sketch of T ( u ), where T ( u ) is the set of nodes in the reachability tree of u . Thus we can sketch the size of all the reachability tree in G in time O ( mD  X  2 log n ) and using memory O (  X  2 n log n ). Now we will show how to use those sketches to estimate the reacha-bility tree for each node u in G [ G u .

Theorem 2. The size of the reachability tree can be ap-proximated to within (1+  X  ) -factor in the public-private model using preprocessing time O ( mD  X  2 log n ) ,space O (  X  2 and query time O ( | E u |  X  2 log n ) .
 Proof. The main idea of our algorithm is to estimate T (  X  ), i.e., re-compute S (  X  ), only for nodes in { u } [ Out ( u ). In order to prove that this is su cient we first show the following lemma. Intuitively, it says that in-neighbors of u and the in-neighbors of the out-neighbors of u play no role in computing the reachability tree rooted at u .
 Lemma 3. Let G =( V, E ) be a directed graph and let T ( u )= T G ( u ) be the reachability tree rooted at u 2 V in G . Let G 0 =( V, E 0 ) be the graph on the same set of nodes with
E 0 = E \{ ( w, v ) 2 E | v = u or ( v 2 Out ( u )and w 6 = u ) } , and let T 0 ( u )= T G 0 ( u ) be the reachability tree rooted at u in G .Then T ( u )= T 0 ( u ) .
 Proof. Suppose that the statement is false. Since E 0  X  E , this implies that T ( u ) \ T 0 ( u ) 6 = ; .Let z 2 T ( u ) \ T Now if z is reachable from a path in G but not in G 0 , then this implies that every directed path connecting u to z must have an edge in { ( w, v ) | v = u or ( v 2 Out ( u )and w 6 = u ) } . Let  X  be one such path and let ( y, v ) 2 { ( w, v ) | v = u or ( v 2 Out ( u )and w 6 = u ) } .Nowif v = u , we can re-move all edges after ( y, v ) and the edge ( y, v ) and we still get a directed path connecting u to z , which contradicts the hypothesis. So we can assume that ( y, v ) 2 { ( w, v ) | v 2 Out ( u )and w 6 = u } be the first edge in { ( w, v ) | v 2 Out ( u )and w 6 = u } that we encounter in  X  . Now from  X  we can obtain a directed path from u to z that does not use any edge in { ( w, v ) | v 2 Out ( u )and w 6 = u } by removing from  X  all edges after ( y, v ) and the edge ( y, v ) and by adding the edge ( u, v ) that exist because v 2 Out ( u ). So z 2 T which once again contradicts the hypothesis. This concludes the proof of Lemma 3.
 We continue with the proof of Theorem 2. We will focus on having an estimate of the size reachability tree for u in G [ G u . Consider T G ( u ) and T G 0 ( u ), where G 0 =( V, E where E 0 = E \{ ( w, v ) | v = u or ( v 2 Out ( u )and w 6 = u ) } . From Lemma 3, we have T G ( u )= T G 0 ( u ).
 For simplicity, we first assume we have access to all of T
G 0 ( v ), 8 v 2 V . (Note this is not true in practice since we only have access to T G ( v ), 8 v 2 V and we cannot precom-pute T G 0 ( v ) since they could be potentially di  X  erent for each node.) We will later show how to eliminate this assumption.
With this assumption, our goal is to estimate | T G [ G u Note that instead of focusing on T G [ G u ( u ) we can work v = u or ( v 2 Out ( u )and w 6 = u ) } ; indeed, using Lemma 3 T
Note that in G 0 the nodes in { u } [ Out ( u ) do not have any incoming edges. So adding incoming edges to { u } [ Out ( u ) does not change the reachability tree of any node w/ 2 { u } [ Out ( u ). Hence 8 w/ 2 { u } [ Out ( u ) we have T T
Thus, the only sketches that we need to recompute are the ones for the nodes in { u } [ Out ( u ). We focus first on the nodes in Out ( u ); let z 2 Out ( u ). Note that all nodes in Out ( z ) are at least at distance two from u in G 0 and so for them, we already have (a sketch of) the correct reacha-bility tree. Using this fact we can recompute the sketch for T where r ( w ) is the random number associated with w . The correctness of this step follows since the reachability tree of z is equal to the union of the reachability tree of its out-neighbors plus its neighbors. So when we add a few outgoing edges to a node we just need to add the reachability tree of the new neighbors and the new neighbors to obtain the new reachability tree.

Using this observation we can compute S ( z ) for all nodes z 2 Out ( u ). So now we can use similar arguments to recom-pute S ( u ). In particular we have that S ( u )= Bot k T
Unfortunately so far we assumed to have access to T G 0 ( z ) but this is not true because we only have access to T G ( z ). Now we argue that even if we use T G ( z ) instead of T G 0 we will still obtain the correct sketch. Note in particular that we can restrict our attention only to nodes in Out 2 Suppose for y 2 Out 2 ( u ) we have s 2 T G ( y ) \ T G 0 that T G 0 ( y )  X  T G ( y ).)
Now if s 2 T G ( y ), then s 2 T G [ G u ( u ) since y 2 Out when computing a sketch for T G ( y ) will not cause a prob-lem when computing a sketch for T G 0 [ G 0 T
G 0 [ G 0 u ( u ). So the random number r ( s )associatedwith s would have been considered (in computing the sketch) in any case when computing T G 0 [ G 0
Hence, we can use T G ( z ) instead of T G 0 ( z ) without chang-ing the value of Bot k . In this way we obtain an algorithm to compute the reachability tree of a node u , by using precom-puting time O ( mD  X  2 log n ), using memory O (  X  2 n log n ) and processing time O ( | E u |  X  2 log n ).
Based on the results in the previous section, we now show how to compute a few interesting centrality measures, namely, Closeness centrality, Lin X  X  centrality, and Harmonic central-ity. The idea is to use the same approach used in the pre-vious section to compute the volume of the ball of di  X  erent diameters centered at each node. Then we can use those numbers to obtain approximations to the three centrality measures as in [8].

Before describing our algorithm, we recall the definition of these measures. Let d ( v, w ) be the shortest path distance between v and w in G and let B u ( d )= { v | d ( v, u )  X  d } . Let D be the diameter of G . (i) Closeness centrality is defined as (ii) Lin X  X  centrality is defined as C ( u )= (iii) Harmonic centrality is defined as
Now note that |{ y | d ( y, u ) &lt; 1 }| is the size of the reach-ability tree rooted at u , which we already saw how to esti-mate. So we need only to estimate | B u ( d ) | | B u ( d 1) | to obtain a formal estimator for the centrality measures. Unfor-tunately this is hard even for simple graphs. Our approach will be to compute a good approximation of | B u ( d ) | for all d&gt; 0 using bottom-k sketch as in [11]. We then use it to estimate | B u ( d ) | | B u ( d 1) | ; by subtracting two estimates we eschew any theoretical guarantees but as in [8], this is an e  X  ective method to estimate these centralities in practice.
For the remainder, we focus on getting a good approxi-mation for | B u ( d ) | in the public-private graph setting. This can be done using a technique similar to the one used to estimate the reachability tree. We start by showing how to compute this estimate in G , then we explain how to compute it in G [ G u .

The core idea of the algorithm is once again to use the bottom-k sketch. Initially each node u has a sketch S ( u, 0) and after updating the sketch as before, at the end of the d th iteration, S G ( u, d ) contains a sketch of B u ( d )in G . Fur-thermore, we have the following analog of Lemma 3: Lemma 4. Let G =( V, E ) be a directed graph and let B ( d ) be the bal l of diameter d rooted at u in G .Let G 0 ( V, E 0 ) be the graph on the same set of nodes but where E E \{ ( z, v ) | v = u or ( v 2 Out ( u )and z 6 = u ) } ;let B the ball of diameter d rooted at u in G 0 .Then B u ( d )= B The proof follows as that of Lemma 3 and by the fact that every time we change a path, we only shorten it.

Now using Lemma 4 and using a similar reasoning as be-fore, we can compute a sketch of B u ( d )in G [ G u . In fact, for each v 2 Out ( u ) we can compute an intermediate bottom-k sketch as Bot k Finally we can compute S The correctness of the estimator can be proved using the same technique showed before; we omit the details in this version. Note that in this case to compute an estimate for the ball of diameter d we need to keep a good estimate for balls of diameter d 1 and d 2.

Theorem 5. For any d ,wecanestimate | B u ( d ) | to within (1 +  X  ) -factor in the public-private model using preprocess-ing time O ( mD  X  2 log n ) ,space O (  X  2 Dn log n ) ,andquery time O ( | E u |  X  2 log n ) .
In this section we show how a few well-known sampling algorithms can be e ciently realized in the public-private graph model. The examples that we exhibit will be of in-creasing interest and hardness.
The distance between two nodes in a social network is a useful feature for many applications. For example, it can be a feature to predict which celebrity a particular user will follow. In this section we study how to approximate e -ciently the distance between any two nodes in the graph in the public-private model. Note that this problem is particu-larly interesting in our model because the distances between two nodes can change dramatically even if we add a single edge. In this section we assume that the graph is undirected.
Theorem 6. We can approximate the distance between two nodes to within O (log n ) in the public-private model us-ing preprocessing time O ( m log 2 n ) ,space O ( n log 2 query time O ( | E u | log 2 n ) .

Proof. Consider the all-pair shortest path approxima-tion of Das Sarma et al. [32]. The basic idea behind the algorithm is to estimate the distances between two nodes v and w in a graph G =( V, E ) by precomputing the distances to a random subset of nodes S  X  V and then to estimate the distance d ( v, w )between v and w by looking at a subset of the shortest paths that go through S .

More formally, the algorithm computes an O (log 2 n )-sized sample by computing for log n times, a sample of size 2 log n + 2 in the following way. It first generates b log n c + 1 random sets of nodes of sizes 1 , 2 ,..., 2 r called S 0 ,S 1 ,...,S r = b log n c . Then it computes for each node v and for all i , the closest node v i 2 S i to v and the corresponding dis-tance. Finally for each node v , the algorithm stores as a sample the pairs h v i ,d ( v, v i ) i for all i . Note that the pre-vious computation can be executed in time O ( m log 2 n )by doing a breadth-first search (BFS) from each set S i .
Now we can estimate the distance between two nodes v and w simply by looking at their respective samples. Let W v be the sample for each node v . Then, the approximate Essentially, the above estimator sums the distance from a common element in the sample. Note that if the graph is connected, then this distance is always well defined, other-wise if there is no common node in the samples, the distance is set to 1 . Using such an estimator, it is possible to approx-imate the distances between any two nodes in undirected graphs 1 by multiplicative factor of O (log n ) w.h.p. Thus, it is possible to compute in time O ( m log 2 n ) samples of total size O ( n log 2 n ) that allow to approximate the distances be-tween any two pairs of nodes within a multiplicative factor O (log n )intime O (log 2 n )in G .

Now we discuss how to use those samples to compute an approximation of the shortest path in G [ G u . In the follow-ing let d G (  X  ,  X  ) denote the shortest path between two nodes in G and d G [ G u (  X  ,  X  ) denote the shortest path between two nodes in G [ G u . The key observation is to note that the shortest path between two nodes u and v in G [ G u is: d Using the samples described earlier, we can obtain an O (log n ) multiplicative approximation for all the distances in d G Given that in expression (1) we consider at most O ( | E u such distances and that we can estimate each of them in O (log 2 n ) time, the proof is complete.
The shortest path is a classic way to estimate the closeness between nodes in a social network but unfortunately it takes into account only the length of a path between two nodes and not the number of paths between them. For this reason several di  X  erent distances have been introduced to capture the a nity between two nodes in a social network, including the work of Katz [21] and personalized PageRank [18]. Personalized PageRank. One of the popular algorithms for node similarity is personalized PageRank (PPR). Here we propose an heuristic to e ciently estimate the PPR of a node u in the public-private model. (For more background on PPR, see [18].) For the public graph G we precompute for each node v 2 G , the vector PPR v ( G )in G . In this phase we use the algorithm of Andersen et al. [4] with the given parameter  X  to approximate the vectors e ciently.

For each private graph G u we obtain the PPR vector of u based on the decomposition result of Jeh and Widom [20]: PPR u ( G u )=(1  X  )deg G In our heuristic we substitute the results for the precompute graph G instead of the private graph.
 PPR u ( G u )  X  (1  X  )deg G Note that even if this computation may look rough at first sight, we can show experimentally that this simple heuris-tic is very e  X  ective in practice (Section 5.3). Unfortunately we cannot show any theoretical guarantees on the approx-imation of PPR and therefore we study another similarity metric for which we can show formal guarantees.
Unfortunately it is not possible to get a similar theoretical guarantees for directed graphs. Nevertheless the authors in [32] show that similar samples give good results in practice also for some structured directed graphs as the Web graph. Social a nity. We now focus on the similarity measure introduced in Panigrahy et al. [30]; we chose this measure for its elegance and for its conducive properties. This metric captures both the number of paths between the two nodes and the length of the paths between two nodes. Formally, the similarity A  X  ( v, w ) between two nodes v and w is defined as the maximum fraction of edges that can be deleted ran-domly from the graph without disconnecting v and w with probability at least  X  . The authors also show how to com-pute this sampling-based similarity measure e ciently and show empirically that this measure nicely captures the se-mantic similarity between users in Twitter. For the remain-der of this section we assume that the graph is undirected.
Theorem 7. The social a nity between two nodes can be estimated in the public-private model using preprocess-ing time O ( m log 2 m ) ,space O ( n log 2 n ) ,andquerytime O ( | E u | +log 2 m ) .

Proof. Let  X  &gt; 0 be a constant. The main idea in [30] is to construct log m distinct telescoping sequences of log m probability that an edge is not deleted in G i,j is (1  X  ) for 1  X  j  X  (log m ) /  X  . We then compute the connected components in all the (log 2 m ) /  X  subgraphs. Using these, we estimate A  X  ( v, w )as: where we used the Iverson bracket notation: [  X  ] equals 1 if the predicate  X  is true and is 0 otherwise. They show that this estimate is within an additive  X   X  factor from the correct A ( v, w ), with high probability. Note that this estimation can be computed in time O ( m log 2 m ) for constant  X  , and all the samples can be stored in space O ( n log 2 m ). In fact we need to store only the component ids for each node.
We now show how to e ciently compute this measure on the G [ G u graph. The basic intuition is to use an e cient algorithm to compute the new connected components. Un-fortunately using a union-find algorithm on the entire graph would be impractical because it would take too long to up-date the connected components ids of all the nodes in the graphs. For this reason we need to keep the component ids of all nodes in the graphs in a slightly di  X  erent way to allow for quick updates.

More precisely, each node in the public graph does the fol-lowing: instead of storing O (log 2 m ) components ids for the to its components ids. When the edges in G u are added to the public graph, we first establish via sampling to which of considering their e  X  ect on the entire graph, we analyze their e  X  ect on the compressed graph where nodes with the same component ids are collapsed together.

Note that for a single subgraph this can be done in time linear in | E u | . For example, consider the subgraph G i,j E ( i, j ) be the edges in E u that exist in the graph G i,j the random deletions. To compute the new connected com-ponents in G i,j , using the pointers to the connected compo-nents id for all the nodes incident in E u ( i, j ), it is possible to see which components are connected by edges in E u ( i, j ). Then by starting a few BFS visits in the collapsed version
It is easy to construct such a sequence by constructing graph G i from G i 1 by keeping the edges in G i 1 with prob-ability (1  X  ). (nodes in the same connected components are contracted together) of G i,j from connected components incident to E ( i, j ), it is possible to update the component ids (we keep an arbitrary id for all the component in the same BFS tree) in time linear in | E u | . Using this idea, it is possible to up-date the component ids for all the nodes in the graph in time O ( | E u | ) and hence the proof is complete.
In this section we consider the problem of clustering in the public-private graph model. Correlation clustering is a fundamental problem in social network analysis that has received a lot of attention over the past decade.

We start with some definitions. A partition of V is a collection C of subsets of V such that 8 { C i ,C j } 2 C C \ C j = ? and to denote the sets C i 2 C . For this section we assume that there are two types of edges in the public graph: positive edges, denoted E + and negative edges denoted E .Recall the correlation clustering problem [5].

Definition 8. The triple ( V, E + ,E ) is a correlation clus-tering instance if let E + \ E = ? and E + [ E = V 2 .A solution of the correlation clustering problem is a partition C of V .Thecostof C is equal to: The goal of the correlation clustering problem is to find a partition C of V that minimizes the cost of the clustering. A partition is an  X  -approximation if its cost is no larger than  X  times the cost of the optimal partition.
 Similar to the edges in the public graph, the edges in G u also of two types: E + u and E u . In the following we will show that given an (approximate) correlation clustering solution to the public graph G , we can quickly find an approximate correlation clustering to G [ G u . The solution to G would be through a sampling algorithm. For the rest of the subsection we assume that G u is a star; extending our results to more general G u as in the other sections is an open problem.
Given a correlation clustering instance I =( V, E + ,E ), and some u 62 V , let the instance I u =( V [ { u } ,E + [ E u ,E [ E u ) be obtained from I by adding u and the edges incident on u to I (so that E + u \ E u = ? and E + u [ E {{ u, v }| v 2 V } ). Note that we assumed u/ 2 V ; this is for simplicity of exposition. After the proof we will show how to handle this.

Given a partition C of V and a v 2 V , we consider parti-tions of V [ { u } that can be obtained by adding u to one of the clusters of C , or by placing u in a new singleton cluster. These |C| + 1 partitions are called the u -neighbors of C .We now bound the quality of a solution to G [ G u .

Lemma 9. Let C be an  X  -approximation of I .Consider an instance I u .Then,atleastoneofthe u -neighbors of C is an O (  X  ) -approximation of the instance I u .
Proof. Let C = { C 1 ,...,C t } for some integer t .Let k i (resp., k i ) be the number of positive (resp., negative) neighbors of u in the cluster C i . Then
Let c be the cost of C on the instance I ,let c ? be the min-imum cost on the instance I .Also,let c ? u be the minimum cost on the instance I u . Observe that c ? u c ? . Let us also use c u ( C i ) to denote the cost of the edges incident on u ,if we assign u to the cluster C i , and c u ( ? ) be the cost of those edges if we let u be in a singleton cluster.

Let us define the cost of a cluster C to be equal to: c ( C )= | E \ C | + 1 2  X | E + \ {{ v, v 0 }| v 2 C and v Observe that the cost of a clustering C can be decomposed in the sum of the cost of its clusters: c ( C )=
Suppose that C is an  X  -approximate solution of the in-stance I . Suppose we add u to I to obtain I u . Then, let us produce a solution C u by adding u to one of the clus-ters of C , or to a singleton cluster, to minimize the total cost of C u . If u is placed in a new singleton cluster, then c ( C u ) c ( C )= C , then we have c ( C u ) c ( C )= k i + Now, suppose that C u places u into a new cluster by itself. By the minimality of the cost of C u , we have that, for each i , k + i  X  k i .

Let us split the total cost c u ( C u ) of the clustering C follows. For each cluster C i 2 C , let us define c u ( C the total number of negative edges inside C i , plus half the number of the positive edges split between C i and another cluster in C , plus k i ,i.e., c u ( C i )= c ( C i )+ k i c ( C u )= c ( C )+
Before continuing our proof, we now recall that a bad triangle is a set of three elements of an instance that are connected by exactly one negative edge (and two positive edges). A fractional packing of triangles is an assignment of positive weights to the triangles of the instance such that, for each edge { v 0 ,v 00 } , the sum of the weights of the trian-gles that contain that edge does not exceed 1 ( 8 { v 0 ,v P tional packing is equal to the sum of the weights of its bad triangles. It is known [3] that the total weight of a fractional packing is a lower bound on the cost of the optimal solution of a correlation clustering instance.

Let us consider the generic cluster C i 2 C . If it induces at least k + i negative edges, then k + i  X  c ( C i )  X  c Otherwise, we have that C i induces fewer than k + i nega-tive edges. Now, since C i induces fewer than k + i negative edges, and since k + i  X  k i , we have that there must exist a positive matching, of cardinality (1 ) k + i ,composedof edges { v, v 0 } 2 C i 2 such that { v, u } is positive and { v is negative. For each { v, v 0 } in the matching, we give weight 1 to the triangle { v, v 0 ,u } . This (integral) packing then proves that the total cost of the edges between the nodes in C i [ { u } , regardless of how the nodes are partitioned, has to be at least (1 ) k + i . If we choose = 1 2 , we have that  X  regardless of whether the number of negative edges in C i is lower or upper bounded by k + i  X  the total cost of C [ { u } has to be at least 1 2 most c u ( C u )  X  c ( C )+ its own cluster we obtain an O (  X  ) approximation.
Suppose instead that the optimal C u positions u in some cluster C i 2 C . Then k i  X  k + i and, moreover, k + i k k j k j , for each j =1 ,...,t . Then, again, either c ( C i was larger than k j , or we can create a matching between a fraction of (1 ) of the k i nodes of C i that are connected to u through negative edges and the k i nodes of C i that are connected to u through positive edges. This gives a packing of total weight (1 )  X  k i , so (by choosing = 1 2 )if k Finally, we consider the case k i  X  is placed in C i by the solution). Now, either the cost of c ( C ) was larger than 1 2
We now define a new fractional packing of bad trian-gles. We will give positive weight to a triangle i  X  it con-tains u , intersects two di  X  erent C j ,C j 0 2 C , and the two triangle X  X  nodes in C j and C j 0 are connected by a nega-tive edge. Each triangle with positive weight will have the same weight 1 P t ber of positive edges in the cut, the number of such tri-angles is at least  X   X  P
No edge will have weight more than 1, and the total weight of the triangles will equal: Since the cost of the solution is at most c ( C )+ O the approximation ratio is at most O (  X  ).
 The above result tell us that a simple algorithm can start from a clustering and place a (new) node greedily with-out losing much in the approximation ratio. In the public-private graph model, note that the node u is not new. To handle this, given an instance I =( V, E + ,E ), and some u 2 V , let the instance I u =( V \{ u } ,E + u ,E u ) be ob-tained from I by removing u and the edges incident on u from I .

Suppose that we precompute an approximate solution to the public graph G . Then, for an arbitrary node u we can apply Lemma 9 to G u , with the new edges of u , to obtain an O (  X  )-approximation algorithm. If we use the sampling-based algorithm of Ailon et al. [3], we get  X  =3.

Theorem 10. We can approximate the correlation clus-tering within a factor O (1) in the public-private model (when G u is a star) using preprocessing time O ( m ) ,space O ( m ) , and query time O ( | E u | log n ) .
In this section we demonstrate the e ciency of our algo-rithms in the public-private graph model. For purposes of showcasing the public-private graph model, we will choose the following algorithms: reachability tree size estimation by sketching, shortest path by sampling, and correlation clus-tering by sampling.

For experimentation purposes, we use some of the social networks publicly available as part of the Stanford X  X  SNAP dataset ( http://snap.stanford.edu/data ). In Table 1 we give some basic statistics of the graphs that we used in the experiments.

To obtain examples in the public-private model, we do the following: given a graph ( V, E ), we pick a node u 2 V uniformly at random and designate the graph induced on the V \{ u } to be the public graph G . To define the private graph G u at u , we do one of the two modifications: in the star-case, we let the private edges E u be the subset { ( v, w ) 2 E } where either v = u or w = u , i.e., the nodes connected to or from u . In the clique-case, we let the private edges of E be all the edges in { u } [ Out ( u ). As we mentioned earlier, these two cases represent two di  X  erent types of privacy.
Since our main emphasis is to show the gains in running time, we will present the ratio A/B of the following two run-ning times: A is the running time of our update algorithm that works on the private graph G u and a sketch or sample of the public graph G and B is the running time of the usual algorithm on G [ G u , i.e., a naive implementation. This ratio will reflect the average running time savings factor we can obtain by using our algorithm instead of running the usual algorithm on G [ G u . Since our algorithms are randomized, each running time is averaged over 10 independent trials and we report the ratio A/B averaged over 100 independent pri-vate graphs. Unless otherwise specified, the quality of the solutions produced by these two separate methods, namely, the update-based algorithm and the usual algorithm, are near-identical (modulo randomness).
In this section we demonstrate our algorithm for comput-ing the size of the reachability tree. We construct the public and private graphs as described before, for both star-case and the clique-case. We implement the naive sketching al-gorithm on G [ G u . We then compare its running time against our update algorithm, which uses the sketch for G , generates E 0 u from E u using the definition in Lemma 3, and updates the sketch of u and nodes in Out ( u ) according to the algorithm in Section 3.1.

Table 2 shows the average running time gains over the naive algorithm for both the star-case and clique-case of private graphs. Unsurprisingly, the e ciency gains made by our algorithm are several orders of magnitude, uniformly across di  X  erent datasets. Figure 2 shows the e  X  ect of  X  Table 2: E ciency gains for reachability in the star-case and the clique-case;  X  =0 . 3. (which controls the accuracy of the estimate) on the e -ciency gain. Recall that a smaller value of  X  means a higher accuracy. Interestingly, the gains increase as  X  decreases: note that a smaller  X  leads to a larger k (see the algorithm in Section 3.1) and hence might result in more book-keeping for maintaining the bottom-k data structure Bot k (  X  ).
Figure 2: Role of  X  in e ciency gains for Wiki-Vote .
We next focus on analyzing the performance of our algo-rithm to compute the shortest path from a node u to another arbitrary node in the private graph G [ G u . We run our ex-periments on YouTube data [34] and we only analyze the star-case since the clique-case a  X  ects the shortest path in the same way as in the star-case.

More specifically, we compare the running time and the accuracy of our algorithm with the naive algorithm that exe-cutes a single-source shortest path algorithm (i.e., Dijkstra X  X  algorithm) to compute the distance between two nodes. Af-ter showing that our algorithm vastly outperforms the naive solution, we turn our attention on the trade-o  X  between the size of the sketches that we use and the accuracy of the so-lution. In our experiments, we observe A/B  X  1 / 827, where the comparison is with the classic Dijkstra algorithm. We also observe that our algorithm obtain a good approxima-tion of the shortest path (in fact our estimation is almost never more than a factor 1 . 5 away from the real value.)
In this section we evaluate our heuristic for PPR. For each graph in our dataset with ground truth communities (Orkut, YouTube, DBLP, LiveJournal) we sampled a set of 20 nodes whose neighbors belong to at least two di  X  erent communi-ties. Let u be such a node and let C u be the set of the communities to which the neighbors of u belong. For each node u , we declare a random half of the communities in C as private and mark as private all the edges to and within these communities; the remaining edges are marked public.
For each private subgraph G u we run the following exper-iment. We determine the ground truth PPR ranking of u using the algorithm of Andersen et al. [4], with a given  X  . We also compute the ranking obtained by our heuristic using the result of preprocessing the public graph, which is again obtained using the same algorithm. We evaluate the accu-racy of the rankings and the performance of our heuristic. In all the experiments, we set  X  =0 . 15 and vary  X  .
Table 3 (Column A/B) and Figure 3 shows the ratio of the running time of our heuristic and the algorithm of Andersen et al. on G [ G u . In all datasets, it is clear that the heuristic is faster by several orders of magnitude. It is interesting to notice that as  X  gets smaller, the performance of the heuristic degrades. This is because if  X  is very small, then the rankings become very long ( n in the limit) and hence the heuristic takes significantly more time to evaluate them. Figure 3: Role of  X  in e ciency gains for our social networks. Table 3: E ciency and accuracy of our heuristic for the PPR,  X  =0 . 001. Column A/B, RMSE, Cosine, and  X  @50 represent the ratio between ground truth time and our heuristics, the Root Mean Square Error, the Cosine Simi-larity and the Kendall- X  index for the first 50 positions of the ranking.

Table 3 shows the accuracy measure for the rankings com-puted. It is clear that the heuristic produces rankings whose RMSE with the ground truth is remarkably close to 0 and the cosine similarity is close to 1; this suggests that the dis-tributions are approximated well. Also the Kendall- X  corre-lation of the first 50 positions of the rankings (which is more useful from a practical viewpoint) is quite high.
In this section we demonstrate our algorithm for correla-tion clustering in the public-private graph model. As dis-cussed before, we construct the public graph G and the private graph G u for many u  X  X . Since our algorithm for correlation clustering works only for the star-case, we do not consider the clique-case here. We compute a correlation clustering of the public graph G using the sampling Pivot algorithm of Ailon et al. [3]. We use the output of this algo-rithm, the edges in G u , and guarantee of Lemma 9 in order to compute the correlation clustering on G [ G u .
Since correlation clustering is on signed networks, we use two signed networks from SNAP. The network Epinions consists of who-trusts-whom network of epinions.com . The network Slashdot consists of the social network in slashdot. com from February 2009. We treat every non-edge of the two networks as a negative edge. Table 4 shows the e -ciency gains for two sample graphs. We see that our update Table 4: E ciency gains for correlation clustering (in the star-case). algorithm obtains highly significant savings over the naive implementation.
The related work falls into several categories including dynamic graph algorithms, graph sketching, and graph sam-pling algorithms.

On the face of it, the public-private model seems related to the dynamic (aka incremental) graph algorithms. In this model, at each time step, a new edge or a node is inserted or deleted, and the goal is to maintain an appropriate data structure of the changing graph so that one can e ciently compute certain functions of the graph at any point in time. There are several natural functions for which e cient (and in many cases, optimal) dynamic algorithms are known, e.g., connectivity [23], minimum spanning trees [19], transitive closure [24], all-pair shortest paths [15], etc. See the survey by Demetrescu et al. [14] for an overview of the area. There are basic di  X  erences between dynamic graphs and public-private graphs. First of all, while many dynamic graph algo-rithms deal with both insertions and deletions and they are optimized for single insert/delete operations, public-private graph computation mainly deals with batch additions. Also the central parameters of interest for dynamic algorithms are the data structure update time and the (incremental) func-tion computation time; the space of the data structure plays a lesser role. In addition, existing algorithms for dynamic graphs are tailored for computing the function exactly, for obtaining asymptotic bounds, and for classical graph algo-rithms; they have not been applied broadly to the social network settings. Finally, recent attempts [6,33] to present more general results for social networks are mainly tailored toward community detection, and their techniques do not apply to our problem setting.

Our model is also related to the problem of sketching graphs to answer queries about them. In the graph sketching model, a succinct representation of a graph, called a sketch, is constructed from the graph. This sketch can be used to compute some functions on the whole graph. The sketch depends on the actual function to be computed and e cient graph sketches are known for a variety of problems includ-ing connectivity [1], cut size and distance between nodes [2]. However, graph sketching is still in its infancy and sketches have been developed only for some very basic graph prob-lems; discouragingly, some of the more interesting problems are faced with strong lower bounds. On a topic more rele-vant to social networks, the so-called All Distance Sketches were developed to approximate the neighborhood function of graphs; see the original work of Cohen [10,11], ANF [29], and hyperANF [7]. Some of the graph sketches have the property that they are composable: the sketch of the union of two graphs can be computed from their respective indi-vidual sketches. This is ideal for our setting, where we can compute a sketch of the public graph and sketches for pri-vate graphs, and consequently, can compute the sketch of the union of the public graph with any private graph. Even though this looks directly applicable, in some cases it is not clear if such a composition can be e ciently implemented in the public-private graph model. In fact, one of our con-tributions is to show that the neighborhood approximation sketch can be implemented e ciently in our model.

Sampling algorithms have been used for several graph and social network problems. Typically, sampling algorithms pick nodes (or edges) in the graph according to some dis-tribution, e.g., uniform on the nodes, or proportional to the degrees (e.g., by a uniform random walk), etc. Sampling al-gorithms have been used to estimate basic graph properties including the size of the network [22], average degree [13], clustering coe cient [17]. In the public-private model, these problems are less interesting since they can be solved triv-ially and with ease. More sophisticated sampling algorithms exist for other social network problems including all-pair dis-tance estimation [32], similarity estimation [30], correlation clustering [3], densest subgraphs [9], etc. It is not a priori clear if it is possible at all to adapt these algorithms to the public-private model. We show how to extend the all-pair distance estimation, similarity estimation, and correlation clustering to public-private graphs; showing a similar result for the densest subgraph problem is an open problem.
In this paper we introduced the public-private model of computation for online social networks. This model is mo-tivated by a new classes of features introduced by online social networks, where users can define public and private friends, or public and private lists or circles. Our model ab-stracts the privacy aspects in the link structure of the social network and establishes a formal framework to study e -cient social network algorithms that respect the privacy of the links; such algorithms operate, for a given user, on this user X  X  private graph and on the common public graph. As a demonstration of the simplicity and the potential of our model, we study two classes of popular social network algo-rithms using our framework: sketching and sampling. We show e cient algorithms for many important social network problems and illustrate the computational benefits of the framework by experimental analysis.

We believe that the public-private model is an abstrac-tion that can be used to develop e cient social network al-gorithms. Our work leaves a number of open interesting research directions such as: obtaining e cient algorithms for the densest subgraph/community detection problems, in-fluence maximization, computing other pairwise similarity scores, and most importantly, recommendation systems.
