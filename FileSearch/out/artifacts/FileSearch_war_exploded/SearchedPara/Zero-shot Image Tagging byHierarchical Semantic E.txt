 Given the difficulty of acquiring labeled examples for many fine-grained visual classes, there is an increasing interest in zero-shot image tagging, aiming to tag images with novel labels that have no training examples present. Using a se-mantic space trained by a neural language model, the cur-rent state-of-the-art embeds both images and labels into the space, wherein cross-media similarity is computed. How-ever, for labels of relatively low occurrence, its similarity to images and other labels can be unreliable. This paper pro-poses Hier archical S emantic E mbedding (HierSE), a simple model that exploits the WordNet hierarchy to improve label embedding and consequently image embedding. Moreover, we identify two good tricks, namely training the neural lan-guage model using Flickr tags instead of web documents, and using partial match instead of full match for vectorizing a WordNet node. All this lets us outperform the state-of-the-art. On a test set of over 1,500 visual object classes and 1.3 million images, the proposed model beats the current best results (18.3% versus 9.4% in hit@1).
 I.4.8 [ Image Processing and Computer Vision ]: Scene Analysis X  Object recognition Image tagging, zero shot learning, semantic embedding
People use tags to find specific images in social media. As user-contributed tags tend to be overly personalized and in-complete, automated image tagging that can predict labels relevant with respect to the visual content is crucial for im-age search. The state-of-the-art approach to image tagging employs a deep convolutional neural network [6], trained on  X  C orresponding author.
 image and other randomly chosen words. More recently, Norouzi et al. propose a simpler yet more effective solution for image embedding [9]. Given an unlabeled image, they use an existing m -way image classification system (whose labels have no overlap with target labels) to predict a few most relevant labels, and build the embedding vector of the given image by convex combination of the label embedding vectors. With this solution, they achieve the state-of-the-art results on the ImageNet zero-shot learning task.

We argue that several issues are overlooked in the seman-tic embedding method [9]. First, since the neural language model essentially exploits word co-occurrence in a text cor-pus, for a label of relatively low occurrence, its embedding vector could be unreliable for computing its similarity to im-ages and other labels. On the other hand, it is this kind of label that we want to tackle via zero shot learning (other-wise we could choose to harvest training examples from the Internet). Second, how to deal with labels that are out of the language model vocabulary is unclear. Moreover, while Wikipedia articles have been the default source for deduc-ing the semantic space [3,9], Flickr might be a better source, as its tag co-occurrence statistics better reflect a label X  X  vi-sual context. By addressing the above issues, this paper improves on the semantic embedding method, and eventu-ally contributes a new model, as illustrated in Fig. 1, that outperforms the state-the-art for zero-shot image tagging.
Given an unlabeled image, the goal of zero-shot image tag-ging is to automatically tag the image with labels that have no training examples available. This is approached by em-bedding both the image and the novel labels into a common semantic space such that their relevance can be estimated in terms of the distance between the corresponding vectors in the space. More formally, let x be an image, y be a la-bel, and p ( y | x ) be a classifier which estimates the relevance of the label y with respect to the image x . Given a set of m 0 training labels Y 0 , we have access to n training examples D be a m 0 -way classifier learned from D 0 . We use Y 1 to denote a set of m 1 test labels, which have no training examples in the zero-shot learning setting, i.e., Y 0  X  Y 1 =  X  . With the help of D 0 and some semantic knowledge, we aim to build a classifier p 1 ( y | x ) that can perform reasonably well for Y 1 .
Our work improves on the semantic embedding model [9], so we first describe it in Section 2.2, and subsequently in-troduce our model in Section 2.3. As shown in Eq. (3), the use of super ( y ) always allows y to be mapped into S , while the convex combination makes the similar measure more reliable for rare labels. Moreover, for a label of multiple senses, e.g.,  X  X ouse X , it will have distinct embedding vectors depending on its given sense. In con-trast, in previous embedding models the label will always be represented by the same vector regardless of its senses.
For some WordNet nodes, they consist of multiple phrases, e.g.,  X  X ook jacket X  and  X  X ust cover X . To represent a specific node in S , previous work tries to find matches in the skip-gram model for every phrase, and average the corresponding vectors [9]. Since we are interested in learning the skip-gram model from Flickr tags, which are however mostly single words instead of phrases, we consider a less strict rule that makes matches in terms of single words. As opposed to the previous full match, we term this rule as partial match.
Putting s hi ( y ) into Eq. (1), we obtain f hi ( x ) as the hi-erarchically embedded semantic vector of an image. Ac-hyper-parameter T is set to be 10, according to [9]. An overview of the proposed model is visualized in Fig. 1.
This section presents an evaluation to verify our proposal, compared with the baseline model [9]. For reproducibility, the evaluation is based on public data.
Training Label Set Y 0 . Following [9], we use the Im-ageNet 1K label set as Y 0 , including 1,000 visual object classes defined in the Large Scale Visual Recognition Chal-lenge 2012 [10]. A pre-trained DeepNet model provided by Caffe [4] is used as p 0 ( y | x ). It is a stacked convolutional neural network [6], consisting of five convolutional layers fol-lowed by two fully connected layers and a softmax output layer. The model is learned from over 1m labeled examples.
Test Label Set Y 1 . Following [9], the test label set consist of labels within 2 tree hops of Y 0 , namely their direct parent and child nodes, resulting in 1,548 novel labels in total. The ground-truthed test images are from ImageNet [2], with the number of relevant images per label ranges from 1 to 2,330, with an average number of 846. The total number of test images is 1.3m.

Semantic Space S . Similar to [9], S in this work is also trained by a skip-gram model, using the word2vec software [8]. We train a 500-D model with 2.2m words using the latest Wikipedia dump. Another 500-D model with 382k words is learned from user tags of 4 million Flickr images. Additionally, we experiment with a pre-trained model with 3m words [8], trained on a Google News dataset.

Performance Metric . We report hit@ k , which is the per-centage of test images for which the true label is among the top-k predicted tags.
In order to study 1) which resources to use for construct-ing the semantic space, 2) how to convert a WordNet node to a semantic embedding vector, and 3) if adding the hier-archy in the embedding process is helpful, we conduct the following three experiments. For the ease of comparison, we abbreviate the proposed model as HierSE, and name the baseline model [9] as FlatSE.
 partial match, our implementation of FlatSE outperforms i ts original implementation (13.5% versus 9.4% in hit@1).
Experiment 3. HierSE or FlatSE? As Table 1 shows, Hi-erSE beats FlatSE. In particular, when used in combina-tion with the Flickr based semantic space, HierSE almost achieves a doubled accuracy when compared to the number reported in [9] (18.3% versus 9.4% in hit@1). Notice that our implementation of FlatSE scores lower than the original paper. One possible reason is that we use an off-the-shelf DeepNet, which might be less effective than its counterpart in [9]. Some tagging results are provided in Table 3.
This paper contributes to zero-shot image tagging by in-troducing the WordNet hierarchy into a deep learning based semantic embedding framework. The proposed hierarchi-cal semantic embedding model is found to be effective. In addition, we identify two good practices which further im-prove the tagging accuracy. That is, using Flickr tags to train the semantic space, and using partial match to em-bed a WordNet node into the space. Code is available at https://github.com/li-xirong/hierse
Acknowledgements . This work was supported by NSFC (No. 61303184), the Fundamental Research Funds for the Central Universities and the Research Funds of Renmin Uni-versity of China (No. 14XNLQ01). [1] Z. Akata, F. Perronnin, Z. Harchaoui, and C. Schmid. [2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and
