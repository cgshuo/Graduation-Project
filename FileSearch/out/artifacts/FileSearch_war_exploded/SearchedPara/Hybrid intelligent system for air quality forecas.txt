 1. Introduction
The study of the air conditions, as well as its prediction, is an important topic due to the relationship between high concentra-tions of pollutants, such as particulate matter (PM), and adverse effects on human health, that is an issue of increasing public concern. Pollutants concentration forecasting ( Niska et al., 2004;
Pisoni et al., 2009; Siwek et al., 2011 ) is a relevant task, since it enables governments to warn the population regarding high levels of pollution. Several epidemiological studies have associated the concentration of those pollutants with cardiovascular and respira-tory diseases ( Ebelt et al., 2005; Nel, 2005; Peng et al., 2008 ). The
Global Monitoring Report ( Bank, 2008 )af fi rms that the major urban air pollutant that affects the human health is PM. applied for forecasting of the PM concentration. Some works have compared the performance of different ANNs in the prediction of one step ahead. Sharma et al. (2003) used the concentration data of seven pollutants, among them PM 2.5 and PM 10 , of the California area to evaluate the performance of four ANN models: Recurrent Network Model (RNM), Change Point Detection Model with RNM, Sequential Network Construction Model and Self Organizing
Feature Model. Ordieres et al. (2005) addressed the PM 2.5 centration in the cities of El Paso (Texas) and Ciudad Ju X rez (Chihuahua) to compare the performance of the Multilayer Perceptron (MLP) model, Radial Basis Function (RBF) and Square
Multilayer Perceptron (SMLP). Other works proposed ANN based on MLP model. Perez and Reyes (2006) developed an integrated
ANN to forecast the maximum average concentration for PM 10 day for city of Santiago, Chile. Kukkonen et al. (2003) combined the MLP model with homoscedastic and heteroscedastic Gaussian noise (ANN-HeG) to forecast the PM 10 concentration in Helsinki.
Although most of the works have evaluated the prediction of one step ahead, Kurt and Oktay (2010) used a MLP model of three layers to forecast sulfur dioxide (SO 2 ), carbon monoxide (CO) and
PM 10 concentration levels for 3 days ahead for a Besiktas district.
Intelligent models based on arti fi cial neural network (ANN) also have been widely used to predict the PM concentration aiming best results. Some works combined Principal Component
Analysis (PCA) with ANN models, as Slini et al. (2006) , that proposed a hybrid system (PCA-MLP) to forecast PM 10 concentra-tion in Thessaloniki. Voukantsis et al. (2011) proposed a metho-dology that selects the input variables using PCA and the prediction is performed by combining the outputs of two meth-ods: MLP and linear regression (LR). In that work, the time series concentration of PM 2.5 and PM 10 in Thessaloniki and Helsinki were used. Other hybrid systems were also proposed. Niska et al. (2005) integrated a MLP model with a numerical weather prediction model HIRLAM (High Resolution Limited Area Model) to predict sequential hourly time series of concentrations of PM 2.5
Helsinki. In that work, an input selection method based on the use of a multi-objective genetic algorithm (MOGA) was applied to reduce the number of potential meteorological input variables. For
PM 10 concentration management in Santiago, Chile, Perez (2012) combined a MLP model with a nearest neighbor method. Siwek and Osowski (2012) combined ANNs to forecast daily average concentration of PM 10 in Warsaw, Poland.

Despite many intelligent models have been applied for fore-casting of the PM concentration, to the authors  X  knowledge, no one considered the fact that these time series consist of a random walk process ( Sitte and Sitte, 2002 ), typical of a Brownian motion process ( Grau-Bov X  and Strlic, 2013; Sahu and Nicolis, 2008;
Cheng et al., in press ). A random walk ( Sitte and Sitte, 2002 )isa stochastic process that consists of successive and connected steps in which each step is chosen by a random mechanism unin-fl uenced by any previous step. This phenomenon also is widely seen in the fi nancial time series representation.
 In this paper, we present an evolutionary hybrid system, called
TAEF method ( Ferreira et al., 2008 ), for time series prediction of particulate matter concentrations. The system was particularly developed to forecast time series from of the phenomenon guided by random walk ( Sitte and Sitte, 2002 ). The approach is composed of two main parts: parameters optimization and phase adjustment.
The parameters optimization uses a genetic algorithm to search for the best parameters to train the predictor. A Multilayer Perceptron neural networks is used as predictor and the following parameters are adjusted: number of time lags to represent the series, number of hidden units and the algorithm to perform the training of the predictor. After, a phase adjustment procedure is performed to improve the accuracy of the predictor by automatically correcting time phase distortions. These distortions in the forecasting are common when the phenomena guided by a random walk process ( Ferreira et al., 2008 ) are addressed, such as the PM concentration ( Grau-Bov X  and Strlic, 2013; Sahu and Nicolis, 2008; Cheng et al., in press ). Thus, in the case of PM concentration levels, the phase adjustment procedure could signi fi cantly improve the accuracy of the intelligent methods? This is a relevant aspect addressed in this paper.

This paper is organized as follows. Section 2 describes the method and the phase adjustment procedure. Section 3 presents a set of six evaluation measures used to analyze the prediction results of the architecture. Simulation results and concluding remarks are presented in Sections 4 and 5 , respectively. 2. The architecture for PM concentration forecasting
Given an univariate time series database (  X  ), the output of the architecture is a trained Arti fi cial Neural Network (ANN) that is ready to predict the next day value of the time series. The of the architecture is the Normalization, where each time series is normalized to lie within the interval [0,1]. After normalization, the database (  X  ) is divided into three disjoint parts: training ( validation (  X  ), and test (  X  ).

Fig. 1 shows that the architecture is composed of two main modules: (i) Parameters Optimization ( Section 2.1 ) and (ii) Phase Adjustment ( Section 2.2 ). 2.1. Parameters optimization The parameters optimization module is based on a modi fi ed Genetic Algorithm (GA) proposed by Leung et al. (2003) , used also in other works ( Moris et al., 2003; Xu et al., 2007 ), and is the basis for the GA used in the TAEF method. The GA searches for the best parameters of an ANN in order to improve its performance. In the search process, the GA combines exploration (global search) and exploitation (local search) strategies ( Yannibelli and Amandi, 2013 ). The exploration process uses the genetic operators to search for new promising regions in the search space. The exploitation process is performed by the neural network training algorithm to fi ne-tune the solutions reached by the evolutionary search.
The output of this module is the best ANN chosen from a set of candidates after the optimization procedure.

Inspired by Takens  X  (1980) theorem, the approach aims to search for the minimum dimensionality of time lags required to reproduce the generative phenomenon of the time series. In other words, the GA searches for the best and more optimized combina-tion of time lags of the predictive model. On the design of a predictive model, the number of time lags is an important aspect because the larger the number of lags the higher the cost associated to represent the time series.

The initial population of the GA is a set of possible solutions randomly generated and each individual of the population is encoded by one chromosome. The chromosome is composed of the following parameters that de fi nes an ANN (in our case, a multilayer perceptron  X  MLP): number of input nodes, number of units in the hidden layer, weights, training algorithm and an unit step function to each weight. This unit step acts like a switch to each weight of the ANN, since it enables that connections which are not important be eliminated in the evolution process.
After the initial population generation, each individual is trained using one of the four candidate algorithms: Levenberg Marquardt ( Mor, 1977 ), Scaled Conjugated Gradient ( Moller, 1993 ),
RPROP ( Reidmiller and Braun, 1993 ) and One Step Secant Con-jugate Gradient ( Battiti, 1992 ). The stopping criteria of this training are the number of epochs, the increase in the validation error and the decrease in the training error.

After the training using a gradient descent algorithm, the GA is used to evolve the population towards a good fi tness solution. So, each chromosome in the population is evaluated by a fi tness function for the PM concentration forecasting proposed here. The fi tness function is de fi ned in Eq. (1) and it is composed of well-known performance measures: Prediction Of Change In Direction (POCID), Mean Squared Error (MSE), Mean Absolute Percentage Error (MAPE), U of Theil Statistics (Theil) and Average
Relative Variance (ARV). These measures are de fi ned in Section 3 . fitness  X  POCID 1  X  MSE  X  MAPE  X  Theil  X  ARV :  X  1  X 
This fi tness function creates a global indicator of the forecasting performance (in the range 0  X  100). The higher the fi tness value, the better is the quality of the prediction model.

After the evaluation phase, two chromosomes are selected as parents by the method of spinning the roulette wheel. The higher the fi tness value of the chromosome, the higher is the chance of it being selected. So, it is expected that high potential parents will produce better offspring. The parents generate the offspring using the genetic operators proposed by Leung et al. (2003) . For each new offspring created, the individuals are trained using a neural network training algorithm among four candidates and this algo-rithm is selected by the evolutionary process.
 number of epochs; (ii) an increase in the validation error; or (iii) a decrease in the training error.
 fi tness of the best individual ( fBest ) with the minimum acceptable fi tness ( MinFit )de fi ned by the user. The best ANN (with the value of fbest ) of the population is the one with the higher that de fi nes the maximum number of lags ( MaxLags )inthesearch search for a better solution. This update aims to increase the chance of greater than MinFit ,thevariable MaxLags is updated to the number of lags of this individual. After, the MinFit is set as the fi reached by the best individual and the GA is started again to search for a better solution. In this case, we expect to fi nd a solution that has a higher fi tness than MinFit . This is possible because the vicinity of the best individual found, so far, can be a promising region for better individuals. This process is rep eated until the maximum number of iterations of the approach be reached. 2.2. Phase adjustment ( Section 2.1 ) is evaluated by a statistical test (hypothesis test, predictive performance better than a random walk like model (null hypothesis) or not (alternative hypothesis). A random walk model ( Sitte and Sitte, 2002 ) is the simplest forecast model, where the best prediction of one step ahead is given by the current value of the time out of two operation modes: is not rejected), this means that the trained ANN is ready for practical use. In contrast, when the operation Out-of-phase mode is selected, a phase adjustment procedure is performed to mini-mize the effects of the time delay mismatch. The phase adjust-ment procedure ( Ferreira et al., 2008 ) is composed of two steps ( Fig. 2 ): (1) given an input vector  X  t 1 ; t 2 ; ... ; ( y 1 ) of the ANN model is calculated; (2) the input vector is rearranged to include y 1 :  X  y 1 ; t 1 ; t 2 ; ... ; t given as input to the same ANN model used in Step 1 and its output is the fi nal forecasting.
 3. Evaluation measures The evaluation of the method is performed by six measures:
Mean Squared Error (MSE), Mean Absolute Percentage Error (MAPE), U of Theil Statistics, Average Relative Variance (ARV),
Prediction of Change in Direction (POCID) and Index of Agreement (IA). These measures are described below.

The MSE measure ( Rodrigues et al., 2010; de Mattos Neto et al., 2010 ) is commonly used in the literature of time series forecasting and it is de fi ned by the following equation:
MSE  X  1 output j is the predicted value at period j . It is worth mentioning that
MSE cannot be considered a conclusive measure for comparison of different forecasting models ( Clements and Hendry, 1993 ). Thus, other evaluation measures should be considered.

The MAPE measure ( Rodrigues et al., 2010; de Mattos Neto et al., 2010 ) is given by the equation:
MAPE  X  100 N  X  N
The U of Theil Statistics ( Rodrigues et al., 2010; de Mattos Neto et al., 2010 ) can be de fi ned as
Theil  X 
The ARV measure ( Rodrigues et al., 2010; de Mattos Neto et al., 2010 )isde fi ned as
ARV  X  where target is the mean of the series.

The POCID measure ( Rodrigues et al., 2010; de Mattos Neto et al., 2010 ) is given by
POCID  X  100 where
D  X  1 ( The IA measure ( Voukantsis et al., 2011 ) is given by
IA  X  1
For MSE, MAPE, Theil and ARV, the lower the value of those measures, the better is the forecasting of the model. Theil is a measure used to compare the model performance with a random walk model performance. If the value of the measure is equal to 1, the model is equivalent to the random walk model. However, if its value is smaller or greater than 1, the model performance is better or worse than the performance of the random walk model, respectively. ARV is a measure that is used to compare the model forecasting with the forecasting of the mean of the series. If the
ARV value is equal to 1, the forecasting of the predictor is equal to the mean of the series. However, if its value is less or greater than 1, the prediction of the model is better or worse than the mean, respectively. In case of POCID and IA, the higher the value the better is the performance of the model. The POCID can have values in the range  X  0 ; 100 and IA in the range [0,1]. 4. Simulation and results
The method is evaluated using four time series that correspond to daily mean concentrations of PM 2.5 and PM 10 from Helsinki. The data were measured in the time period of 2001  X  2003 from stations of Kallio and Vallila ( Voukantsis et al., 2011 ). These stations are in locals with different characteristics of Helsinki. Vallila is more in fl uenced by traf fi c in the center of the city, while the station of Kallio is an urban background. Generally, the population on urban background locals is less exposed to pollu-tion, whereas the traf fi c locals represent urban environments more severely polluted. For each region, PM 2.5 and PM 10 tration time series are used in this work, composing a data set of four series. All series are normalized to lie within the interval [0,1] and divided in three sets: 80% for training, 10% for validation and 10% for test. For each time series, ten simulations were performed by the architecture and the best model based on the validation dataset (  X  ) is selected as the predictive model. All the results shown refer to one step ahead predictions generated using the test set (  X  ). The parameters of the method are set up to (i) Initial acceptable fi tness value (1% of error); (ii) Initial maximum number of time lags (10); (iii) Maximum number of hidden units (20); and (iv) Maximum number of iterations (10).

The parameters of the genetic algorithm used by the architec-ture are set up to (i) Mutation probability (10%); (ii) Population size (10); (iii) Maximum number of generations (1000); and (iv) Minimum fi tness progress (10 4 ). Three stopping conditions for the method are used: (i) Maximum number of iterations (1000); (ii) Generation loss (5%); and (iii) Progress training (10 4.1. Kallio station time series forecasting
Table 1 shows the forecasting of the PM 2.5 and PM 10 concen-tration time series from the Kallio station using the architecture under consideration. Comparing the results before (In-phase) and after (Out-of-phase) the phase adjustment, we observe that the forecasting is consistently better when the phase of the time series is adjusted by the approach, independently of the time series analyzed and the measure used.

Figs. 3 and 4 show the real concentration series for the Kallio station (solid lines) and the forecasting generated by the method (dashed lines) for PM 2.5 and PM 10 , respectively. Figs. 3 (a) and 4 (a) show the results without phase adjustment and Figs. 3 (b) and 4 (b) show the results with phase adjustment. Observing these fi gures, we note that the best fi t happens when the phases are adjusted.

After the optimization procedures, the method selected the following parameters for the best ANN when the PM 2.5 concentra-tion time series was used: (i) six lags: 1, 2, 4, 8, 9 and 10; (ii) eight neurons in hidden layer; and (iii) Levenberg  X  Marquardt training algorithm. For the PM 10 concentration time series, the parameters were (i) fi ve lags: 2, 3, 4, 5 and 9; (ii) four neurons in hidden layer; and (iii) Levenberg  X  Marquardt training algorithm. For both cases, the method indicated the out-of-phase con fi guration for the predictive models. 4.2. Vallila station time series forecasting
Table 2 shows the forecasting of the PM 2.5 and PM 10 concen-tration time series from the Vallila station using the architecture under consideration. Comparing the results before (In-phase) and after (Out-of-phase) the phase adjustment, we observe again that the forecasting is consistently better when the phase of the time series is adjusted by the approach, independently of the time series analyzed and the measure used.

Figs. 5 and 6 show the real concentration series for the Vallila station (solid lines) and the forecasting generated by the method (dashed lines) for PM 2.5 and PM 10 , respectively. Figs. 5 (a) and 6 (a) show the results without phase adjustment and Figs. 5 (b) and 6 (b) show the results with phase adjustment. We can note that again the best fi t happens when the phases are adjusted.
After the optimization procedures, the architecture selected the following parameters for the best ANN when the PM 2.5 concentra-tion time series was used: (i) six lags: 1, 2, 3, 6, 7 and 8; (ii) six neurons in hidden layer; and (iii) Levenberg  X  Marquardt training algorithm. For the PM 10 concentration time series, the parameters were (i) four lags: 1, 4, 6 and 10; (ii) eight neurons in hidden layer; and (iii) Levenberg  X  Marquardt training algorithm. The method classi fi ed the predictive ANN with an out-of-phase con fi for the both time series PM 2.5 and PM 10 . 4.3. Discussion the method generated predictive models (ANNs) for PM concen-tration with a prediction performance better than the random walk model (based on the statistics U of Theil) and better than the forecasting using only the mean of series (ARV). The POCID measure shows that the prediction obtained by the predictive models follows the direction of the series in all cases. From the results shown in Tables 1 and 2 , it is observed that the phase adjustment procedure improved signi fi catively the performance of the hybrid system for all used measures and the fi tness function.
This result shows that this procedure can enhance the perfor-mance of the prediction when PM concentration time series are addressed.
Table 3 shows the results, in terms of IA, obtained by the approach and by several techniques for different periods. The IA was considered because it is a performance measure widely used in the literature of the pollutant forecasting. The values used in the comparison are shown only as a reference. However, for all cases, the approach overcomes the results found in the literature by a large margin. Another alternative to measure the performance of the proposed method is to evaluate the mean IA using the k -fold cross-validation procedure. So, each time series was divided into three folds ( k  X  3), where each fold corresponds to 1 year (2001, 2002 and 2003). The proposed approach obtained the following mean and standard deviation results in terms of the IA measure: (i) for the Kallio Station: 0.95 7 0.03 for PM 2.5 and 0.94
PM ; and, (ii) for the Vallila Station: 0.96 7 0.01 and 0.95 for PM 2.5 and PM 10 . These average results are similar to the ones shown in Table 3 .
 In contrast with previous models ( Kukkonen et al., 2003;
Voukantsis et al., 2011; Niska et al., 2005; Siwek and Osowski, 2012; Vlachogianni et al., 2011 ) that use several variables of meteorological data, the presented architecture does not require any exogenous information to perform the prediction. 5. Conclusions
In this paper, an architecture to forecast particulate matter concentration levels was presented. The architecture is composed of two main parts: parameters optimization and phase adjust-ment. In the parameters adjustment part, an optimization process is performed to fi nd the best parameters of the predictor. After, a phase adjustment procedure is performed to minimize the effects of the time delay mismatch. This phase adjustment aims to improve the accuracy of the predictor by automatically correcting time phase distortions that can occur in the forecasting of time series, that has its generation process driven by Brownian motion process (also called  X  random walk  X  )( Grau-Bov X  and Strlic, 2013 ).
The performance of the method was assessed using six well-known performance measures and four time series. The time series consist of concentration levels of PM 2.5 and PM 10 stations of Kallio and Vallila. The stations are located in urban background and urban traf fi c, each one containing different characteristics. The experimental results showed a consistent better performance of the approach when compared with other techniques (e.g. Voukantsis et al., 2011; Vlachogianni et al., 2011 ) for all investigated series. In contrast to other methods in the literature that use several exogenous time series to predict a time series of interest, the approach uses only the time series under study to perform the prediction.

The performance of the method was reached mainly due to the use of the phase correction procedure. Thus, these results show that the phase adjustment procedure can be an interesting alternative to enhance the forecasting of the intelligent methods that are proposed to solve the forecasting problem of the PM concentration.
 References
