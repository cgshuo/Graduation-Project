 In many practical situations, a classification task can often be divided into related sub-tasks. Since the related sub-tasks tend to share common factors, solving them together is expected to be more advantageous than solving them independently. This approach is called multi-task learning (MTL, a.k.a. inductive transfer or learning to learn ) and has theoretically and experimentally proven to be useful [4, 5, 8].
 Typically, the  X  X elatedness X  among tasks is implemented as imposing the solutions of related tasks to be similar (e.g. [5]). However, the MTL methods developed so far have several limitations. First, it is often assumed that all sub-tasks are related to each other [5]. However, this may not be always true in practice X  X ome are related but others may not be. The second problem is that the related tasks are often imposed to be close in the sense that the sum of the distances between solutions over all pairs of related tasks is upper-bounded [8] (which is often referred to as the global constraint [10]). This implies that all the solutions of related tasks are not necessarily close, but some can be quite different.
 In this paper, we propose a new MTL method which overcomes the above limitations. We settle the first issue by making use of a task network that describes the relation structure among tasks. This enables us to deal with intricate relation structures in a systematic way. We solve the second problem by directly upper-bounding each distance between the solutions of related task pairs (which we call local constraints).
 We apply this ideas in the framework of support vector machines (SVMs) and show that linear SVMs can be trained via a second order cone program (SOCP) [3] in the primal. An SOCP is a convex problem and the global solution can be computed efficiently. We further show that the kernelized version of the proposed method can be formulated as a matrix-fractional program (MFP) [3] in the dual, which can be again cast as an SOCP; thus the optimization problem of the kernelized variant is still convex and the global solution can be computed efficiently. Through experiments with artificial and real-world protein super-family classification data sets, we show that the proposed MTL method compares favorably with existing MTL methods.
 We further test the performance of the proposed approach in ordinal regression scenarios [9], where the goal is to predict ordinal class labels such as users X  preferences ( X  X ike X / X  X eutral X / X  X islike X ) or students X  grades (from  X  X  X  to  X  X  X ). The ordinal regression problems can be formulated as a set of regression, the relatedness among tasks is highly structured. That is, the solutions (decision bound-and  X  X  X  vs.  X  X  X  would be related, but  X  X  X  vs.  X  X  X  and  X  X  X  vs.  X  X  X  may not be. Our experiments demonstrate that the proposed method is also useful in the ordinal regression scenarios and tends to outperform existing approaches [9, 8] In this section, we formulate the MTL problem.
 Let us consider M binary classification tasks, which all share the common input-output space X X  { X  1 } . For the time being, we assume X X  R d for simplicity; later in Section 4, we extend it to for t =1 ,..., . Each data sample ( x t ,y t ) has its target task; we denote the set of sample indices are exclusive: M i =1 |I i | = and I i  X  X  j = null ,  X  i = j .
 i =1 ,...,M, where w i  X  R d and b i  X  R are the model parameters of the i -th task. We assume that a task network is available. The task network describes the relationships among tasks, where each node represents a task and two nodes are connected by an edge if they are related to each other 1 .We denote the edge set by E X { ( i k ,j k ) } K k =1 . In this section, we propose a new MTL method. 3.1 Basic Idea When the relation among tasks is not available, we may just solve M penalized fitting problems individually: where C  X   X  R + is a regularization constant and Hinge(  X  ,  X  ) is the hinge loss function: Hinge( f, y )  X  max(1  X  fy, 0) . This individual approach tends to perform poorly if the number of training samples in each task is limited X  X he performance is expected to be improved if more training samples are available. Here, we can exploit the information of the task network. A naive idea would be to use the training samples of neighboring tasks in the task network for solving the target fitting problem. However, this does not fully make use of the network structure since there are many other indirectly connected tasks via some paths on the network.
 To cope with this problem, we take another approach here, which is based on the expectation that the solutions of related tasks are close to each other. More specifically, we impose the following constraint on the optimization problem (1): Namely, we upper-bound each difference between the solutions of related task pairs by a positive scalar  X   X  R + . We refer to this constraint as local constraint following [10]. Note that we do not impose a constraint on the bias parameter b i since the bias could be significantly different even among related tasks. The constraint (2) allows us to implicitly increase the number of training samples over the task network in a systematic way through the solutions of related tasks. Following the convention [8], we blend Eqs.(1) and (2) as where C  X  is a positive trade-off parameter. Then our optimization problem is summarized as follows: Problem 1. subj. to where w  X  w 1 ,..., w M , and  X   X   X  [  X   X  1 ,..., X   X  ] . (4) 3.2 Primal MTL Learning by SOCP The second order cone program (SOCP) is a class of convex programs of minimizing a linear func-tion over an intersection of second-order cones [3]: 2 Problem 2. min f z wrt z  X  R n subj. to A i z + b i  X  c i z + d i , for i =1 ,...,N, (5) Linear programs, quadratic programs, and quadratically-constrainedquadratic programs are actually special cases of SOCPs. SOCPs are a sub-class of semidefinite programs (SDPs) [3], but SOCPs can be solved more efficiently than SDPs. Successful optimization algorithms for both SDP and SOCP are interior-point algorithms. The SDP solvers (e.g. [2]) consume O ( n 2 i n 2 i ) time complexity for solving Problem 2, but the SOCP-specialized solvers that directly solve Problem 2 take only O ( n 2 i n i ) computation [7]. Thus, SOCPs can be solved more efficiently than SDPs. We can show that Problem 1 is cast as an SOCP using hyperbolic constraints [3].
 Theorem 1. Problem 1 can be reduced to an SOCP and it can be solved with O (( Md + ) 2 ( Kd + )) computation. The previous section showed that a linear version of the proposed MTL method can be cast as an SOCP. In this section, we show how the kernel trick could be employed for obtaining a non-linear variant. 4.1 Dual Formulation Let K fea be a positive semidefinite matrix with the ( s, t ) -th element being the inner-product of introduce a kernel among tasks. Using a new K -dimensional non-negative parameter vector  X   X  R + , we define the kernel matrix of tasks by Laplacian kernel [11], where the k -th edge is weighted according to  X  k . Let Z  X  N M  X  be the indicator of a task and a sample such that Z i,t =1 if t  X  X  i and Z i,t =0 otherwise. Then the information about the tasks are expressed by the  X  kernel matrix Z K net (  X  ) Z . We integrate the two kernel matrices K fea and Z K net (  X  ) Z by where  X  denotes the Hadamard product (a.k.a element-wise product ). This parameterized ma-trix K int (  X  ) is guaranteed to be positive semidefinite [6].
 Based on the above notations, the dual formulation of Problem 1 can be expressed using the param-eterized integrated kernel matrix K int (  X  ) as follows: Problem 3. We note that the solutions  X  and  X  tend to be sparse due to the 1 norm.
 Changing the definition of K fea from the linear kernel to an arbitrary kernel, we can extend the proposed linear MTL method to non-linear domains. Furthermore, we can also deal with non-vectorial structured data by employing a suitable kernel such as the string kernel and the Fisher kernel.
 In the test stage, a new sample x in the j -th task is classified by 4.2 Dual MTL Learning by SOCP Here, we show that the above dual problem can also be reduced to an SOCP. To this end, we first introduce a matrix-fractional program (MFP) [7]: Problem 4. min ( Fz + g ) P ( z )  X  1 ( Fz + g ) wrt. z  X  R p + subj. to P ( z )  X  P 0 + and strictly positive definite cone of n  X  n matrices, respectively.
 Let us re-define d as the rank of the feature kernel matrix K fea . We introduce a matrix V fea  X  R  X  d which decomposes the feature kernel matrix as K fea = V fea V fea . Define the -dimensional vectors f y ) , for h =1 ,...,d. Using those variables, the objective function in Problem 3 can be rewritten as This implies that Problem 3 can be transformed into the combination of a linear program and d MFPs.
 Then we can re-express the graph Lagrangian matrix of tasks as U  X  = V lap diag(  X  ) V lap . Given the fact that an MFP can be reduced to an SOCP [7], we can reduce Problem 3 to the following SOCP: Problem 5. Consequently, we obtain the following result: Theorem 2. The dual problem of CoNs learning (Problem 3) can be reduced to the SOCP in Prob-lem 5 and it can be solved with O (( Kd + ) 2 (( M + K ) d + )) computation. In this section, we discuss the properties of the proposed MTL method and the relation to existing methods.
 MTL with Common Bias A possible variant of the proposed MTL method would be to share the common bias parameter with all tasks (i.e. b 1 = b 2 =  X  X  X  = b M ). The idea is expected to be useful particularly when the number of samples in each task is very small. We can also apply the common bias idea in the kernelized version just by replacing the constraint Z diag( y )  X  = 0 M in Problem 3 by y  X  =0 .
 Global vs. Local Constraints Micchelli and Pontil [8] have proposed a related MTL method which upper-bounds the sum of the differences of K related task pairs, i.e., However, the global constraint can allow some of the distances to be large since only the sum is upper-bounded. This actually causes a significant performance degradation in practice, which will be experimentally demonstrated in Section 6. We note that the idea of local constraints is also used in the kernel learning problem [10].
 Relation to Standard SVMs By construction, the proposed MTL method includes the standard SVM learning algorithm a special case. Indeed, when the number of tasks is one, Problem 3 is reduced to the standard SVM optimization problem. Thus, the proposed method may be regarded as a natural extension of SVMs.
 Ordinal Regression As we mentioned in Section 1, MTL approaches are useful in ordinal regres-sion problems. Ordinal regression is a task of learning multiple quantiles, which can be formulated as a set of one-versus-one classification problems. A naive approach to ordinal regression is to individually train M SVMs with score functions f i ( x )= w i , x + b i , i =1 ,...,M . Shashua and Levin [9] proposed an ordinal regression method called the support vector ordinal regres-sion (SVOR), where the weight vectors are shared by all SVMs (i.e. w 1 = w 2 =  X  X  X  = w M ) and only the bias parameter is learned individually.
 The proposed MTL method can be naturally employed in ordinal regression by constraining the weight vectors as w i  X  w i +1 2  X   X  , i =1 ,...,M  X  1 , i.e., the task network only has a weight be-tween consecutive tasks. This method actually includes the above two ordinal regression approaches as special cases X  C  X  =0 (i.e., ignoring the task network) yields the independent training of SVMs and C  X  =  X  (i.e., the weight vectors of all SVMs agree) is reduced to SVOR. Thus, in the context of ordinal regression, the proposed method smoothly bridges two extremes and allows us to control the belief of task constraints. In this section, we show the usefulness of the proposed method through experiments. 6.1 Toy Multiple Classification Tasks First, we illustrate how the proposed method behaves using a 2 -dimensional toy data set, which includes 200 tasks (see Figure 1(a)). Each task possesses a circular-shaped classification boundary 0 . 02( i  X  1) , 0) for 1  X  i  X  100 and (0 ,  X  1+0 . 02( i  X  101)) for 101  X  i  X  200 . For each task, only two positive and two negative samples are generated following the uniform distribution. We construct a task network where consecutive tasks are connected in a circular manner, i.e., (1 , 2) , 100 and the last 100 nodes.
 We compare the following methods: a naive method where 200 SVMs are trained indivisually (in-dividually learned SVM,  X  IL-SVM  X ), the MTL-SVM algorithm where the global constraint and the fully connected task network are used [5] ( X  MTL-SVM(global/full)  X ),and the proposed method which uses local constraints and the properly defined task network ( X  MTL-SVM(local/network)  X ). The results are exhibited in Figure 1, showing that IL-SVM can not capture the circular shape due to the small sample size in each task. MTL-SVM(global/full) can successfully capture closed-loop boundaries by making use of the information from other tasks. However, the result is still not so reliable since non-consecutive unrelated tasks heavily damage the solutions. On the other hand, MTL-SVM(local/network) nicely captures the circular boundaries and the results are highly reliable. Thus, given an appropriate task network, the proposed MTL-SVM(local/network) can effectively exploit information of the related tasks.
Dataset IL-SVM One-SVM MTL-SVM (global/full) MTL-SVM (global/network) MTL-SVM (local/network) 6.2 Protein Super-Family Classification Next, we test the performance of the proposed method with real-world protein super-family classifi-cation problems.
 The input data are amino acid sequences from the SCOP database [1] (not SOCP). We counted 2 -mers for extraction of feature vectors. There are 20 kinds of amino acids. Hence, the number of features is 20 2 = 400 . We use RBF kernels, where the kernel width  X  2 rbf is set to the average of the squared distances to the fifth nearest neighbors. Each data set consists of two folds. Each fold is divided into several super-families. We here consider the classification problem into the super-families. A positive class is chosen from one fold, and a negative class is chosen from the other fold. We perform multi-task learning from all the possible combinations. For example, three super-families are in DNA/RNA binding, and two in SH3. The number of combinations is 3  X  2=6 . So the data set d-s has the six binary classification tasks. We used four folds: DNA/RNA binding, Flavodoxin, OB-fold and SH3. From these folds, we generate six data sets: d-f, d-f, d-o, f-o, f-s, and o-s, where the fold names are abbreviated to d, f, o, and s, respectively.
 The task networks are constructed as follows: if the positive super-family or the negative super-family is common to two tasks, the two tasks are regarded as a related task pair and connected by an edge. We compare the proposed MTL-SVM(local/network) with IL-SVM,  X  One-SVM  X , MTL-SVM(global/full), and MTL-SVM(global/network). One-SVM regards the multiple tasks as one big task and learns the big task once by a standard SVM. We set C  X  =1 for all the approaches. The value of the parameter C  X  for three MTL-SVM approaches is determined by cross-validation over the training set. We randomly pick ten training sequences from each super-family, and use them for training. We compute the classification accuracies of the remaining test sequences. We repeat this procedure 10 times and take the average of the accuracies.
 The results are described in Table 1, showing that the proposed MTL-SVM(local/network) com-pares favorably with the other methods. In this simulation, the task network is constructed rather heuristically. Even so, the proposed MTL-SVM(local/network) is shown to significantly outperform MTL-SVM(global/full), which does not use the network structure. This implies that the proposed method still works well even when the task network contains small errors. It is interesting to note that MTL-SVM(global/network) actually does not work well in this simulation, implying that the task relatedness are not properly controlled by the global constraint. Thus the use of the local con-straints would be effective in MTL scenarios. 6.3 Ordinal Regression As discussed in Section 5, MTL methods are useful in ordinal regression. Here we create five ordinal classification tasks, each of which estimates a quantile. We compare MTL-SVM(local/network)with IL-SVM, SVOR [9] (see Section 5), MTL-SVM(full/network) and MTL-SVM(global/network). The value of the parameter C  X  for three MTL-SVM approaches is determined by cross-validation over the training set. We set C  X  =1 for all the approaches. We use RBF kernels, where the parame-ter  X  2 rbf is set to the average of the squared distances to the fifth nearest neighbors. We randomly picked 200 samples for training. The remaining samples are used for evaluating the classification accuracies.
Data set IL-SVM SVOR MTL-SVM (global/full) MTL-SVM (global/network) MTL-SVM (local/network) pumadyn 0.643 (0.007) 0.661 (0.006) 0.629 (0.025) 0.645 (0.018) 0.661 (0.007) bank-8fh 0.781 (0.003) 0.777 (0.006) 0.772 (0.006) 0.773 (0.006) 0.779 (0.002) bank-8fm 0.854 (0.004) 0.845 (0.010) 0.832 (0.013) 0.847 (0.009) 0.854 (0.009) calihouse 0.648 (0.003) 0.642 (0.008) 0.640 (0.005) 0.646 (0.007) 0.650 (0.004) The averaged performance over five runs is described in Table 2, showing that the proposed MTL-SVM(local/network) is also promising in ordinal regression scenarios. In this paper, we proposed a new multi-task learning method, which overcomes the limitation of existing approaches by making use of a task network and local constraints. We demonstrated through simulations that the proposed method is useful in multi-task learning scenario; moreover, it also works excellently in ordinal regression scenarios.
 The standard SVMs have a variety of extensions and have been combined with various techniques, e.g., one-class SVMs, SV regression, and the  X  -trick. We expect that such extensions and techniques can also be applied similarly to the proposed method. Other possible future works include the elucidation of the entire regularization path and the application to learning from multiple networks; developing algorithms for learning probabilistic models with a task network is also a promising direction to be explored.
 Acknowledgments This work was partially supported by a Grant-in-Aid for Young Scientists (B), number 18700287, from the Ministry of Education, Culture, Sports, Science and Technology, Japan.

