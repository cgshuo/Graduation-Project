 In recent years, machine learning (ML) has been more and more used to solve complex tasks in different disciplines, ranging from Data Mining to Information Retrieval (IR) or Natural Language Processing (NLP). These tasks often require the processing of structured input. For example, NLP applications critically deal with syntactic and seman-tic structures. Modeling the latter in terms of feature vec-tors for ML algorithms requires large expertise, intuition and deep knowledge about the target linguistic phenomenon. Kernel Methods (KMs) are powerful ML techniques (see e.g., [5]), which can alleviate the data representation problem as they substitute scalar product between feature vectors with similarity functions (kernels) directly defined between training/test instances, e.g., syntactic trees, (thus features are not needed anymore). Additionally, kernel engineering, i.e., the composition or adaptation of several prototype ker-nels, facilitates the design of the similarity functions required for new tasks, e.g., [1, 2]. KMs can be very valuable for IR research, e.g., KMs allow us to easily exploit syntac-tic/semantic structures, e.g., dependency, constituency or shallow semantic structures, in learning to rank algorithms [3, 4]. In general, KMs can make easier the use of NLP techniques in IR tasks.

This tutorial aims at introducing essential and simpli-fied theory of Support Vector Machines (SVMs) and KMs for the design of practical applications. It describes ef-fective kernels for easily engineering automatic classifiers and learning to rank algorithms, also using structured data and semantic processing. Some examples are drawn from well-known tasks, i.e., Question Answering and Passage Re-ranking, Short and Long Text Categorization, Relation Ex-traction, Named Entity Recognition, Co-Reference Resolu-tion. Moreover, some practical demonstrations are given with SVM-Light-TK (tree kernel) toolkit. More in detail, best practices for successfully using KMs for IR and NLP are presented according to the following outline: (i) a very brief introduction to SVMs (explained from an application viewpoint) and KM theory (the essential content for understanding practical procedures). (ii) Presentation of kernel engineering building blocks, such as linear, polynomial, lexical, sequence and tree kernels, by focusing on their function, accuracy and efficiency rather than their mathematical characterization, so that they can be easily understood. (iii) Illustration of important applications for which ker-nels achieve the state of the art, i.e., Question Classifica-tion, Question and Answer (passage) Reranking, Relation Extraction, coreference resolution and hierarchical text cat-egorization. In this perspective kernels for reranking will be presented as an efficient and effective approach to learning dependencies between structured input and output. (iv) Practical exercise on quick design of ML systems us-ing SVM-Light-TK toolkit, which encodes several kernels in SVMs. (v) Summary of the key points to engineer innovative and effective kernels starting from basic kernels and using sys-tematic data transformations. (vi) Presentation of the latest KM findings: kernel-based learning on large-scale with fast SVMs, generalized struc-tural and semantic kernels and reverse kernel engineering. I.2.7 [ Natural Language Processing ]: [Language parsing and understanding, Text analysis] Algorithms, Experimentation Question Answering, Kernel Methods, Large-Scale Learn-ing, Support Vector Machines, Structural Kernels [1] A. Moschitti. Efficient convolution kernels for [2] A. Moschitti. Kernel methods, syntax and semantics for [3] A. Moschitti and S. Quarteroni. Linguistic kernels for [4] A. Severyn and A. Moschitti. Structural relationships [5] J. Shawe-Taylor and N. Cristianini. Kernel Methods for
