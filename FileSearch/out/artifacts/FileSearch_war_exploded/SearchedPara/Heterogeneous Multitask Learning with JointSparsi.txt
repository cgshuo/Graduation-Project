 Carnegie Mellon University xyang@stat.cmu.edu In multitask learning, one is interested in learning a set of related models for predicting multiple (possibly) related outputs (i.e., tasks) given a set of input variables [4]. In many applications, the multiple tasks share a common input space, but have different functional mappings to different output variables corresponding to different tasks. When the tasks and their corresponding models are believed to be related, it is desirable to learn all of the models jointly rather than treating each task as independent of each other and fitting each model separately. Such a learning strategy that allows us to borrow information across tasks can potentially increase the predictive power of the learned models.
 Depending on the type of information shared among the tasks, a number of different algorithms have been proposed. For example, hierarchical Bayesian models have been applied when the parameter values themselves are thought to be similar across tasks [2, 14]. A probabilistic method for modeling the latent structure shared across multiple tasks has been proposed [16]. For problems of which the input lies in a high-dimensional space and the goal is to recover the shared sparsity structure across tasks, a regularized regression method has been proposed [10].
 In this paper, we consider an interesting and not uncommon scenario of multitask learning, where the tasks are heterogeneous and bear a union support . That is, each task can be either a regression or classification problem, with the inputs lying in a very high-dimensional feature space, but only a small number of the input variables (i.e., predictors) are relevant to each of the output variables (i.e., responses). Furthermore, we assume that all of the related tasks possibly share common relevant predictors, but with varying amount of influence on each task.
 Previous approaches for multitask learning usually consider a set of homogeneous tasks, such as re-gressions only, or classifications only. When each of these discrete or continuous prediction tasks is treated separately, given a high-dimensional design, the lasso method that penalizes the loss function with an L 1 norm of the parameters has been a popular approach for variable selection [13, 11], since the L 1 regularization has the property of shrinking parameters corresponding to irrelevant predictors exactly to zero. One of the successful extensions of the standard lasso is the group lasso that uses an L /L 2 penalty defined over predictor groups [15], instead of just the L 1 penalty ubiquitously over all predictors. Recently, a more general L 1 /L q -regularized regression scheme with q &gt; 0 has been thoroughly investigated [17]. When the L 1 /L q penalty is used in estimating the regression function for a single predictive task, it makes use of information about the grouping of input variables, and applies the L 1 penalty over the L q norm of the regression coefficients for each group of inputs. As a result, variable selection can be effectively achieved on each group rather than on each individual input variable. This type of regularization scheme can be also used against the output variables in a single classification task with multi-way (rather than binary) prediction, where the output is ex-panded from univariate to multivariate with dummy variables for each prediction category. In this situation the group lasso can promote selecting the same set of relevant predictors across all of the dummy variables (which is desirable since these dummy variables indeed correspond to only a sin-gle multi-way output). In our multitask learning problem, when the L 1 /L 2 penalty of group lasso is used for multitask regression [9, 10, 1], the L 2 norm is applied to the regression coefficients for each input across all tasks, and the L 1 norm is applied to these L 2 norms, playing the role of selecting common input variables relevant to one or more tasks via a sparse union support recovery. Since the parameter estimation problem formulated with such penalty terms has a convex objective function, many of the algorithms developed for a general convex optimization problem can be used for solving the learning problem. For example, an interior point method and a preconditioned conjugate gra-dient algorithm have been used to solve a large-scale L 1 -regularized linear regression and logistic regression [8]. In [6, 13], a coordinate-descent method was used in solving an L 1 -regularized linear regression and generalized linear models, where the soft thresholding operator gives a closed-form solution for each coordinate in each iteration.
 In this paper, we consider the more challenging, but realistic scenario of having heterogenous out-puts, i.e., both continuous and discrete responses, in multitask learning. This means that the tasks in question consist of both regression and classification problems. Assuming a linear regression for continuous-valued output and a logistic regression for discrete-valued output with dummy variables for multiple categories, an L 1 /L q penalty can be used to learn both types of tasks jointly for a sparse union support recovery. Since the L 1 /L q penalty selects the same relevant inputs for all dummy out-puts for each classification task, the desired consistency in chosen relevant inputs across the dummy variables corresponding to the same multi-way response is automatically maintained. We consider particular cases of L 1 /L q regularizations with q = 2 and q =  X  .
 Our work is primarily motivated by the problem of genetic association mapping based on genome-wide genotype data of single nucleotide polymorphisms (SNPs), and phenotype data such as disease status, clinical traits, and microarray data collected over a large number of individuals. The goal in this study is to identify the SNPs (or inputs) that explain the variation in the phenotypes (or outputs), while reducing false positives in the presence of a large number of irrelevant SNPs from the genome-scale data. Since many clinical traits for a given disease are highly correlated, it is greatly beneficial to combine information across multiple such related phenotypes because the inputs often involve millions of SNPs and the association signals of causal (or relevant) SNPs tend to be very weak when computed individually. However, statistically significant patterns can emerge when the joint started recognizing the importance of the joint analysis of multiple correlated phenotypes [5, 18], but there has been a lack of statistical tools to systematically perform such analysis. In our previous work [7], we developed a regularized regression method, called a graph-guided fused lasso, for multitask regression problem that takes advantage of the graph structure over tasks to encourage a selection of common inputs across highly correlated traits in the graph. However, this method can only be applied to the restricted case of correlated continuous-valued outputs. In reality, the set of clinical traits related to a disease often contains both continuous-and discrete-valued traits. As we demonstrate in our experiments, the L 1 /L q regularization for the joint regression and classification can successfully handle this situation.
 The paper is organized as follows. In Section 2, we introduce the notation and the basic formulation for joint regression-classification problem, and describe the L 1 /L  X  and L 1 /L 2 regularized regres-sions for heterogeneous multitask learning in this setting. In Section 3, we formulate the parameter estimation as a convex optimization problem, and present an interior-point method for solving it. Section 4 presents experimental results on simulated and asthma datasets. In Section 5, we conclude with a brief discussion of future work. Suppose that we have K tasks of learning a predictive model for the output variable, given a common set of P input variables. In our joint regression-classification setting, we assume that the K tasks consist of K r tasks with continuous-valued outputs and K c tasks with discrete-valued outputs of an arbitrary number of categories.
 For each of the K r regression problems, we assume a linear relationship between the input vector X of size P and the k th output Y k as follows: intercept; and  X  denotes the residual.
 Let y k = ( y k 1 , . . . , y kN ) 0 represent the vector of observations for the k th output over N samples; and X represent an N  X  P matrix X = ( x 1 , . . . , x N ) 0 of the input shared across all of the K tasks, minimizing the sum of squared error: where 1 is an N -vector of 1 X  X .
 For the tasks with discrete-valued output, we set up a multinomial (i.e., softmax) logistic regression for each of the K c tasks, assuming that the k th task has M k categories: category of the k th classification task, and  X  ( c ) k 0 is the intercept.
 Assuming that the measurements for the K c output variables are collected for the same set of N samples as in the regression tasks, we expand each output data y ki for the k th task of the i th sample into a set of M k binary variables y 0 ki = ( y k 1 i , . . . , y kM value 1 if the i th sample for the k th classification task belongs to the m th category and value 0 oth-erwise, and thus and the shared input data X , one can estimate the parameters  X  ( c ) km  X  X  by minimizing the negative log-likelihood given as below: L c =  X  In this joint regression-classification problem, we form a global objective function by combining the two empirical loss functions in Equations (1) and (3): ing that there are no shared patterns in the way that each of the K output variables is dependent on the input variables. Our goal is to increase the performance of variable selection and prediction power by allowing the sharing of information among the heterogeneous tasks. In real-world applications, often the covariates lie in a very high-dimensional space with only a sparse structure in the predictive model by selecting the true relevant covariates. For example, in a genetic association mapping, often millions of genetic markers over a population of individuals are examined to find associations with the given phenotype such as clinical traits, disease status, or molecular phenotypes. The challenge in this type of study is to locate the true causal SNPs that influence the phenotype. We consider the case where the related tasks share the same sparsity pattern such that they have a common set of relevant input variables for both the regression and classification tasks and the amount of influence of the relevant input variables on the output may vary across the tasks. We introduce an L 1 /L q regularization to the problem of the heterogeneous multitask learning in Equation (4) as below: regularization parameter which determines the sparsity level and could be chosen by cross validation. We consider two extreme cases of the L 1 /L q penalty for group variable selection in our problem which are L  X  norm and L 2 norm across different tasks in one dimension.
 for the j th dimension. Here, the L  X  and L 2 norms over the parameters across different tasks can regulate the joint sparsity among tasks. The L 1 /L  X  and L 1 /L 2 norms encourage group sparsity dimension j if the L  X  or L 2 norm for that dimension is set to be 0. Similarly, if the L 1 operator have any non-zero values smaller than the maximum or satisfying the L 2 -norm constraints. The L /L  X  penalty tends to encourage the parameter values to be the same across all tasks for a given input [17], whereas under L 1 /L 2 penalty the values of the parameters across tasks tend to be more different for a given input than in the L 1 /L  X  penalty. Different methods such as gradient descent, steepest descent, Newton X  X  method and Quasi-Newton method can be used to solve the problem in Equation (5). Although second-order methods have a fast convergence near the global minimum of the convex objective functions, they involve comput-ing a Hessian matrix and inverting it, which can be infeasible in a high-dimensional setting. The coordinate-descent method iteratively updates each element of the parameter vector one at a time, using a closed-form update equation given all of the other elements. However, since it is a first-order method, the speed of convergence becomes slow as the number of tasks and dimension increase. In [8], the truncated Newton X  X  method that uses a preconditionor and solves the linear system instead of inverting the Hessian matrix has been proposed as a fast optimization method for a very large-scale problem. The linear regression loss and logistic regression loss have different forms. The interior method optimizes their original loss function without any transformation so that it is more intuitive to see how the two heterogeneous tasks affect each other.
 In this section, we discuss the case of the L 1 /L  X  penalty since the same optimization method can be easily extended to handle the L 1 /L 2 penalty. First, we re-write the problem of minimizing Equation (5) with the nondifferentiable L 1 /L  X  penalty as Further re-writing the constraints in the above problem, we obtain 2  X  P  X  ( K r + inequality constraints as follows: Using the barrier method [3], we re-formulate the objective function in Equation (7) into an uncon-strained problem given as where Then, we apply the log barrier function I  X  ( f ( x )) =  X  (1 /t ) log(  X  f ( x )) , where t is an additional parameter that determines the accuracy of the approximation.
  X  &gt; 1 , and tolerance  X  &gt; 0 , we iterate the following steps until convergence.
 Step 1 Compute  X   X  ( t ) by minimizing L Barrier , starting at  X  .
 Step 2 Update:  X  :=  X   X  ( t ) Step 3 Stopping criterion: quit if m/t &lt;  X  where m is the number of constraint functions. Step 4 Increase t : t := t X  In Step 1 , we use the Newton X  X  method to minimize L Barrier at t . In each iteration, we in-crease t in Step 4 , so that we have a more accurate approximation of I  X  ( u ) through I  X  ( f ( x )) =  X  (1 /t ) log(  X  f ( x )) .
 In Step 1 , we find the direction towards the optimal solution using Newton X  X  method: where  X   X  and  X  u are the searching directions of the model parameters and bounding parameters. K r components for regression tasks, g ( c ) has K c  X  ( M k  X  1) components for classification tasks, and H is the Hessian matrix given as: Figure 1: The regularization path for L 1 /L  X  -regularized methods. (a) Regression parameters esti-mated from the heterogeneous task learning method, (b) regression parameters estimated from re-gression tasks only, (c) logistic-regression parameters estimated from the heterogeneous task learn-ing method, and (d) logistic-regression parameters estimated from classification tasks only. Blue curves: irrelevant inputs; Red curves: relevant inputs. where R and L are second derivatives of the parameters  X  for regression tasks in the form of R = In the overall interior-point method, the process of constructing and inverting Hessian matrix is the most time-consuming part. In order to make the algorithm scalable to a large problem, we use a preconditionor diag ( H ) of the Hessian matrix H , and apply the preconditioned conjugate-gradient algorithm to compute the searching direction. We demonstrate our methods for heterogeneous multitask learning with L 1 /L  X  and L 1 /L 2 regular-izations on simulated and asthma datasets, and compare their performances with those from solving two types of multitask-learning problems for regressions and classifications separately. 5.1 Simulation Study In the context of genetic association analysis, we simulate the input and output data with known model parameters as follows. We start from the 120 haplotypes of chromosome 7 from the popu-lation of European ancestry in HapMap data [12], and randomly mate the haplotypes to generate genotype data for 500 individuals. We randomly select 50 SNPs across the chromosome as inputs. classification task with five categories, and choose five common SNPs from the total of 50 SNPs as relevant covariates across all of the tasks. We fill the non-zero entries in the regression coefficients  X  k  X  X  with values uniformly distributed in the interval [ a , b ] with 5  X  a, b  X  10 , and the non-zero output space. Given these inputs and the model parameters, we generate the output values, using the noise for regression tasks distributed as N (0 ,  X  2 sim ) . In the classification task, we expand the single output into five dummy variables representing different categories that take values of 0 or 1 depending on which category each sample belongs to. We repeat this whole process of simulating inputs and outputs to obtain 50 datasets, and report the results averaged over these datasets. The regularization paths of the different multitask-learning methods with an L 1 /L  X  regularization obtained from a single simulated dataset are shown in Figure 1. The results from learning all of the tasks jointly are shown in Figures 1(a) and 1(c) for regression and classification tasks, respectively, whereas the results from learning the two sets of regression and classification tasks separately are shown in Figures 1(b) and 1(d). The red curves indicate the parameters for true relevant inputs, and the blue curves for true irrelevant inputs. We find that when learning both types of tasks jointly, the parameters of the irrelevant inputs are more reliably set to zero along the regularization path than learning the two types of tasks separately.
 In order to evaluate the performance of the methods, we use two criteria of sensitivity/specificity plotted as receiver operating characteristic (ROC) curves and prediction errors on test data. To obtain ROC curves, we estimate the parameters, sort the input-output pairs according to the magnitude of Figure 2: ROC curves for detecting true relevant input variables when the sample size N varies. (a) Regression tasks with N = 100 , (b) classification tasks with N = 100 , (c) regression tasks with N = 200 , and (d) classification tasks with N = 200 . Noise level N (0,1) was used. The joint regression-classification methods achieve nearly perfect accuracy, and their ROC curves are com-pletely aligned with the axes. X  X  X  indicates homogeneous multitask learning, and  X  X M X  heterogenous multitask learning (This notation is the same for the following other figures).
 Figure 3: Prediction errors when the sample size N varies. (a) Regression tasks with N =100, (b) classification tasks with N = 100 , (c) regression tasks with N = 200 , and (d) classification tasks with N = 200 . Noise level N (0,1) was used.
 We vary the sample size to N = 100 and 200, and show the ROC curves for detecting true relevant inputs using different methods in Figure 2. We use  X  sim = 1 to generate noise in the regression tasks. Results for the regression and classification tasks with N = 100 are shown in Figure 2(a) and (b) respectively, and similarly, the results with N = 200 in Figure 2(c) and (d). The results with L /L  X  penalty are shown with color blue and green to compare the homogeneous and heteroge-neous methods. Red and yellow are results using the L 1 /L 2 penalty. Although the performance of learning the two types of tasks separately improves with a larger sample size, the joint estimation performs significantly better for both sample sizes. A similar trend can be seen in the prediction errors for the same simulated datasets in Figure 3.
 In order to see how different signal-to-noise ratios affect the performance, we vary the noise level to  X  2 sim = 5 and  X  2 sim = 8 , and plot the ROC curves averaged over 50 datasets with a sample size N = 300 in Figure 4. Our results show that for both of the signal-to-noise ratios, learning regression and classification tasks jointly improves the performance significantly. The same observation can be made from the prediction errors in Figure 5. We can see that the L 1 /L 2 method tends to improve the variable selection, but the tradeoff is that the prediction error will be high when the noise level is low. While L 1 /L  X  has a good balance between the variable selection accuracy and prediction error at a lower noise level, as the noise increases, the L 1 /L 2 outperforms L 1 /L  X  in both variable selection and prediction accuracy. Figure 4: ROC curves for detecting true relevant input variables when the noise level varies. (a) Regression tasks with noise level N (0 , 5) , (b) classification tasks with noise level N (0 , 5) , (c) re-gression tasks with noise level N (0 , 8) , and (d) classification tasks with noise level N (0 , 8) . Sample size N =300 was used. N (0 , 8 2 ) , and (d) classification tasks with noise level N (0 , 8 2 ) . Sample size N =300 was used. Figure 6: Parameters estimated from the asthma dataset for discovery of causal SNPs for the cor-related phenotypes. (a) Heterogeneous task learning method, and (b) separate analysis of multitask regressions and multitask classifications. The rows represent tasks, and the columns represent SNPs. 5.2 Analysis of Asthma Dataset We apply our method to the asthma dataset with 34 SNPs in the IL4R gene of chromosome 11 and five asthma-related clinical traits collected over 613 patients. The set of traits includes four continuous-valued traits related to lung physiology such as baseline predrug FEV1, maximum FEV1, baseline predrug FVC, and maximum FVC as well as a single discrete-valued trait with five categories. The goal of this analysis is to discover whether any of the SNPs (inputs) are influenc-ing each of the asthma-related traits (outputs). We fit the joint regression-classification method with L /L  X  and L 1 /L 2 regularizations, and compare the results from fitting L 1 /L  X  and L 1 /L 2 regular-ized methods only for the regression tasks or only for the classification task. We show the estimated parameters for the joint learning with L 1 /L  X  penalty in Figure 6(a) and the separate learning with L /L  X  penalty in Figure 6(b), where the first four rows correspond to the four regression tasks, the next four rows are parameters for the four dummy variables of the classification task, and the columns represent SNPs. We can see that the heterogeneous multitask-learning method encourages to find common causal SNPs for the multiclass classification task and the regression tasks. In this paper, we proposed a method for a recovery of union support in heterogeneous multitask learning, where the set of tasks consists of both regressions and classifications. In our experiments with simulated and asthma datasets, we demonstrated that using L 1 /L 2 or L 1 /L  X  regularizations in the joint regression-classification problem improves the performance for identifying the input variables that are commonly relevant to multiple tasks.
 The sparse union support recovery as was presented in this paper is concerned with finding inputs that influence at least one task. In the real-world problem of association mapping, there is a cluster-ing structure such as co-regulated genes, and it would be interesting to discover SNPs that are causal to at least one of the outputs within the subgroup rather than all of the outputs. In addition, SNPs in a region of chromosome are often correlated with each other because of the non-random recombi-nation process during inheritance, and this correlation structure, called linkage disequilibrium, has been actively investigated. A promising future direction would be to model this complex correlation pattern in both the input and output spaces within our framework.
 Acknowledgments EPX is supported by grant NSF DBI-0640543, NSF DBI-0546594, NSF IIS-0713379,
