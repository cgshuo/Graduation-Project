 We propose a dynamic faceted search system for discovery-driven analysis on data with both textual content and struc-tured attributes. From a keyword query, we want to dynami-cally select a small set of  X  X nteresting X  attributes and present aggregates on them to a user. Similar to work in OLAP ex-ploration, we define  X  X nterestingness X  as how surprising an aggregated value is, based on a given expectation. We make two new contributions by proposing a novel X  X avigational X  X x-pectation that X  X  particularly useful in the context of faceted search, and a novel interestingness measure through judicious application of p -values. Through a user survey, we find the new expectation and interestingness metric quite effective. We develop an efficient dynamic faceted search system by improving a popular open source engine, Solr . Our system exploits compressed bitmaps for caching the posting lists in an inverted index, and a novel directory structure called a bitset tree for fast bitset intersection. We conduct a compre-hensive experimental study on large real data sets and show that our engine performs 2 to 3 times faster than Solr. H.3.3 [ Information Search and Retrieval ]: Miscellaneous Algorithms, Experimentation
An increasing amount of information consists of a combina-tion of both structured and unstructured data. For example, patent documents contain structured properties such as in-ventors, assignees, class codes, and filing date, as well as a body of unstructured text. Helpdesk tickets store not only structured data such as the ticket X  X  originator, responsible party, and status, but also text describing the problem and its origin. Increasingly, enterprises want to run analytics [5, 25] on text to extract additional valuable structured infor-mation such as chemical compounds used in a patent and products mentioned in a helpdesk ticket. As a result, the to-tal number of structured properties in those data sets can be fairly large (mid to high tens or even hundreds). Performing discovery-driven analysis on such data sets becomes challeng-ing since a user may not know which properties to focus on. Ideally, a user would like to just type in some keywords into a system which would then guide him to areas of interest.
A promising query interface for such mixed data is Faceted search [26], which is widely used by e-commerce sites such as amazon.com and shopping.com for querying their cata-logs. For example, a user might enter  X  X igital camera X  in the keyword window of shopping.com. There are potentially thousands of matches, but only a few popular ones can be dis-played on the screen. To assist navigation, the system also shows in a separate panel summaries of search results, such as a count of digital cameras in each range of price and reso-lution (we refer to properties such as price and resolution as facets ). When the user selects a particular price range such as  X $200 X $300 X , the system adds a structured constraint on price to the original query, and refreshes the top matches and the summaries with results from the new query. The naviga-tion process continues until the user finds the desired camera. Faceted search offers several advantages. First, it smoothly integrates free text search with structured querying. Second, the counts on selected facets serve as context for further nav-igation. For example, a user might choose to focus his search in the price range that has the most cameras.

Today X  X  faceted search systems are designed for browsing catalog data and are not directly suitable for discovery-driven exploration because of the following reasons. First, to pre-serve browsing consistency, facets selected for navigation tend to be  X  X tatic X , i.e., they often don X  X  change with different key-words. A typical heuristic rule to select facets is to favor those with more counts [23]. For example, consider a key-word search for  X  X ML X  on a repository of software patents. A traditional faceted search system is likely to present for navigation an assignee facet with values such as IBM and Microsoft, since they have more patents on  X  X ML X  in terms of the absolute counts. While such a result may be useful for certain people, others may find a startup with only five patents, but all on  X  X ML X , to be more interesting. Second, when browsing online catalogs, the navigational facets are single-dimensional only. An important aspect of discovery is to identify interesting correlations, and thus the ability to present facets in pairs, triples, etc. is critical.
We propose a dynamic faceted search system for the kind of discovery-driven analysis that is often performed in On-Line Analytical Processing ( OLAP ) systems. From a potentially large search result, we want to automatically and dynamically discover a small set of facets and values that are deemed 3 most  X  X nteresting X  to a user. This enables the user to quickly understand important patterns in the query result and to refine his search based on these patterns.

Following earlier work in structured OLAP [19, 20], we de-fine  X  X nterestingness X  as how surprising or unexpected a sum-mary is, according to an expectation. We make the following new contributions. First, since interestingness is subjectiv e, we allow users to set expectations of their own. In partic-ular, we propose a novel  X  X avigational X  method of setting a user X  X  expectation that naturally fits how he navigates in a faceted search system. Second, we propose a novel method of measuring the degree of surprise through judicious use of p -values. Our method is unbiased to domain size and also makes intuitive sense. Finally, we validate the relevance of our dynamically selected facets by conducting a user survey based on a real data set. The survey result is positive.
For better performance, many traditional OLAP systems pre-compute a data cube [11], and then perform subsequent analysis on the cube itself rather than on the base data. This is impossible when structured data is mixed with text, since maintaining a cube including all possible keywords in the text is prohibitive. Similar to existing faceted search systems, we build a runtime engine on top of an inverted index and dy-namically compute aggregations over results returned by the index. Our dynamic faceted search engine is computation-ally intensive because it not only considers single-dimensional facets, but also facet combinations. We improve the perfor-mance of existing systems by exploiting two new ideas. First, we cache facet data in a compressed bitmap for better space utilization as well as faster set intersections. Second, we de-velop a novel directory structure called a bitset tree on top of the inverted index to reduce the overhead of unnecessary bitset intersections.

The rest of the paper is organized as follows. We define the terminology and formally state our problem in Section 2. We describe different expectations that a user can set and our X  X n-terestingness X  measure in Section 3. Section 4 revisits exist-ing faceted search implementations and describes the design of our improved implementation. In Section 5, we present results from the user survey and the performance evaluation using two real data sets. We summarize the related work in Section 6 and conclude in Section 7.
In this section, we introduce the terminology used in the rest of the paper, and define the problem to solve.
Defn 1 . A repository D is a collection of documents, each of which is composed of some free text and one or more &lt; facet : value &gt; pairs. For simplicity, we assume that both the facet and the value are strings, although in general the values can be typed. Given a value f in facet F , we call &lt;F : f &gt; an instance of facet F . All unique values associated with a facet F form the domain of F . We allow each document to have any number of instances of a particular facet. For example, a publication can have two facet instances, &lt; author : X &gt; and &lt; author : Y &gt; .

Defn 2 . Often, multiple facets represent the same concept at different granularities. We organize the domain of these facets into a facet hierarchy . Each node in the hierarchy stores a &lt; facet : value &gt; pair. A node &lt;F 1 : f 1 &gt; is the parent of another node &lt;F 2 : f 2 &gt; if for each document, F implies F 1 = f 1 . For example, in the facet hierarchy shown in Figure 1, node &lt; state : Texas &gt; is the parent of node &lt; city : Houston &gt; . We also add to the hierarchy a unique dummy root node of the form &lt;All i : all i &gt; and assume that the equality All i = all i is always true. A facet may be present in more than one hierarchy.
Defn 3. For simplicity, we assume that a query q on the repository has the form  X  keywords &amp;&amp; F 1 = f 1 &amp;&amp; F . . .  X . The result of q is denoted by D q and includes the set of documents having the specified keywords and satisfying all constraints on selected facets. A typical user session starts with a query with just the keywords, followed by the addition or the removal of constraints on facets to the original query.
Defn 4. Given a query q , we define a facet summary for a facet set F 1 , . . . , F m as a list of tuples &lt;f and A ( f 1 , . . . , f m ) is an aggregate of documents in D contain all these facet instances. In this paper, we focus only on aggregates that count the number of documents.

Problem Definition : Given a repository of documents with n facets, a query q , and two integers K 1 and K 2 , we want to select K 1 facet sets and a facet summary for each with up to K 2 tuples that are the most  X  X nteresting X  to a user, i.e., they are the most unexpected or surprising to a user based on his expectation. For easy reference, we include important symbols in the following table.

The concept of  X  X nterestingness X  has been studied in the context of analyzing OLAP cubes [19, 20, 26]. In all that work,  X  X nterestingness X  is defined by how surprising it is that a cell value in the cube is different from an expected one. There are different ways of setting the expectation. For ex-ample, in [20, 26], the expected value of a cell is derived from other sibling cells at the same level or from cells that are one or more levels higher in the dimensional hierarchy. The ex-pectation is often set by the system, although [19] allows a user to specify a list of cells as  X  X nown X  and uses them to set the expectation for other cells.

Following this work, we also measure  X  X nterestingness X  as how surprising an actual aggregated value is, given a certain expectation. Different users may have different expectations and we try to make the process of setting the expectation easy for the users. In Section 3.1, we describe three useful methods of setting the expectation. The  X  X avigational X  X ethod is par-ticularly suitable in the context of faceted search and is the best method found in our survey. Previous work didn X  X  pay too much attention to make sure that the computed degree of interestingness is comparable within and across domains. For example, the KL-divergence [4] used in [19] is very sen-sitive to domain sizes. In Section 3.2, we describe a novel 4 interestingness measure that addresses this problem and also makes intuitive sense. For a given set of facet values f 1 , f 2 , . . . , f m from facets F , F 2 , . . . , F m , we define C D ( f 1 , . . . , f m ) and C as the count of the number of documents with all those facet values in D and D q , respectively. We use E [ C q ( f 1 , . . . , f to denote an X  X xpected X  X alue for C q ( f 1 , . . . , f m ). We identify three different methods of setting a user X  X  expectation.
Natural: Suppose that a user knows very little about the data in the repository. Absent any specific knowledge, the user very likely assumes some natural distribution in the data set. For example, the user may think that documents in the repository are uniformly distributed along each facet, and facets are independent of each other. Based on this, we define a natural method of setting the expectation. Given a query q , the expected counts are set as follows. For an individual values in F in D q ). For an instance f 1 , . . . , f m of a facet set, we estimate the expected count as As we can see, the former is based on the uniformity assump-tion while the latter is based on the independence assump-tion. In this case, interesting facets tend to be those that are skewed or correlated in the query result. For example, in the patent repository, assignee IBM is likely to be interest-ing since IBM owns many more patents than others. Such information could be useful for people who don X  X  know much about the patent literature.

Navigational: If a user is already familiar with the repos-itory, natural expectation may no longer be appropriate. For instance, most researchers won X  X  be surprised by the fact that IBM owns a lot of patents. This motivates the second method, navigational , which sets the expectation based on how the user navigates the results. When a user types the first keyword query q 1 , we set the counts proportionally based on the data distribution in the complete repository. Specifically, we have E [ C q 1 ( f 1 , . . . , f m )] = | D q 1 | X  ( C If a user issues a second query q 2 by drilling into a facet instance, we reset the expectation using the result from q i.e., E [ C q 2 ( f 1 , . . . , f m )] = | D q 2 | X  ( C q ing such an expectation, IBM may no longer be an interest-ing assignee just because of the large absolute patent count. Instead, the startup that we mentioned in the introduction could be more interesting. Although it only owns 5 patents on  X  X ML X , that number is significant given the low expectation based on its overall patent record.

Ad hoc: If a user is not satisfied with the previous two methods, the user can use an ad hoc one by telling the system to set expectation based on an arbitrary query q of the user X  X  choice. Similar to the navigational method, we set the count for each facet value proportionally based on the distribution of the result of q . A good example is for analyzing facets with an ordered domain. If a user is looking at a subset of patents in the current year, then it makes sense to set the expectation using a similar query, but constrained to the previous year instead of the current one.
In this section, we first discuss the interestingness of a single facet instance, followed by that of the whole facet.
Single facet instance: We need to quantify the degree of interestingness based on an actual and an expected count. Let us assume for now that the expectation is set from the distribution of all data in the repository. We must be able to decide, for example, which of the following hypothetical find-ings is more interesting given a query q on a patent reposi-tory: (i) 45 patents out of 500 in D q were issued in year 2000, whereas out of the repository of 100,000 patents, 5% of them were issued in that year; or (ii) 10 of the patents in D q filed by IBM, whereas IBM owns 2% of all patents. It seems that there are many distance metrics that we could use here. However, the fact that the facets year and assignee have dif-ferent domain size makes the selection challenging, since it X  X  not clear how one should normalize the distance values cross domains to ensure that they are comparable.

As a guiding principle, we calculate a level of interesting-ness of a facet instance by evaluating it with respect to a sce-nario in which its associated count is generated by random sampling. The presumption is that the smaller the probabil-ity of observing the count under random sampling, the more interesting the facet instance. Of course such a measure of in-terestingness ignores any knowledge about the facet instance except the frequency.

Specifically, suppose that a certain facet value occurs in r out of R documents in the repository and in q out of Q documents in the output of a certain query. Also suppose a-vis the query could be evaluated by the probability that in a random sample of size Q there will be at least q docu-ments with that facet value. Such a probability is often called in statistical hypothesis testing the p -value, which gives the probability of obtaining a result at least as extreme as a given data point, under the null hypothesis. That probability is de-rived from the hypergeometric distribution and is equal to A similar hypothesis can be derived when q Q &lt; r R . The hy-pergeometric distribution is suitable for sampling without re-placement. In our implementation, we approximate p -values using the normal distribution or the Poisson distribution for easier calculation. This approximation is based on sampling with replacement. However, such a difference is often negli-gible since we expect the number of matching documents in a query to be a small fraction of the whole repository (typi-cally 5% or less). Note that these p -values serve only as an intuitive measure of interestingness; the precise accuracy is not crucial.

Suppose that in the above example, we calculate p -values of about 0.000032 and 0.005 for year 2000 and assignee IBM, respectively. We can decide that the facet instance year 2000 is more interesting, because statistically, it is more unlikely that the associated actual count is produced by chance. We may also conclude that the entire facet year is more interest-ing because at least one of its instances appears to be more correlated with the query.

The use of p -values is one way to introduce a  X  X ommon denominator X  for comparing interestingness across different facets of varying domain size. We choose p -values for the following reasons. First, it makes intuitive sense. This is be-cause p -values essentially measure how extreme an event is, which agrees with the definition of a surprise. Second, inde-pendent of facet type, p -values always produce a normalized 5 degree of interestingness between 0 and 1. The interesting-ness of a facet can be easily computed by aggregating the p -values on its instances. Finally, when experimenting differ-ent distance metrics, we find the results produced by p -values to be more relevant.

For a facet with a large number of instances, the above-mentioned probability measure may not be appropriate be-cause, even under random sampling, it is to be expected that some values will have small p -values 1 . For example, suppose that the facet of inventor in a repository of 100,000 patents has 2,000 distinct values (for simplicity, assume that each patent has only a single inventor). Thus, on average there are 50 patents per inventor. For the sake of simplicity, let X  X  assume that each inventor has precisely 50 patents. Suppose that the output of a certain query contains 1,000 documents, and a certain inventor appears in four patents in the query output. In a random sample, the expected number of patents with the same inventor is only 0.5. This particular inventor may seem interesting because in a random sample of 1,000 the probability that this inventor will appear in at least four patents is approximately 0.0017. However, there are 2,000 inventors in the repository, and the probability that at least one of them will have at least four patents in the query out-put is approximately 0.973. Therefore, it is not interesting at all to see that there exists some inventor like this in the query output. On the other hand, if there exists an inventor that appears in 10 out of 1,000 patents in the query output, then it is interesting because the probability of such an event in a random sample of size 1000 is less than 10  X  6 . In our implementation, for a facet with a large domain, we ensure that we only use a p -value if its product with the domain size is still small enough.

The whole facet: Presenting individual facet instances from many different facets to the user could be confusing. Instead, we want to organize the instances by their facets and select only a small number of interesting facets. Given the interestingness scores of the individual facet instance, we wish to associate an aggregate score of interestingness with the whole facet. One way of computing the interestingness of an entire facet is to evaluate the probability that in a random sample of the same size as the query output, the distribution of all facet instances will be as far from the distribution in the entire repository as is the distribution observed in the query output. One possibility is to use the Chi 2 distribution to eval-and r i are the count of the ith facet instance in the query and the repository, respectively. However, there are a couple of problems with the above approach. First, a human user often is presented with and capable of digesting a small number of values. Using all values in a facet to compute an aggregated degree of interestingness for the facet may not reflect what a user actually observes. Second, an interesting value in a facet may easily be X  X iluted X  X hen aggregated with a large number of less interesting ones. We employ a simpler, but more prac-tical way of ranking the interestingness at the facet level. For each facet F , we consider the p -values of only the k most inter-esting values in F . Suppose that the p -values of those values are p 1  X  X  X  X  X  X  p k . We first replace them by s i =  X  log p ( i = 1 , . . . , k ). Thus, s 1  X  X  X  X  X  X  s k . The final measure of
In fact, the p -values observed in random sampling are dis-tributed uniformly, so the expected value of the least p -value in a sample with replacement of size Q is 1 Q +1 . interestingness of facet F is computed as P k i =1 w i  X  s w i is a weight. The larger the aggregated value, the more interesting the facet is. We experiment with three different schemes of setting the weights, MaxWeight , AvgWeight and HybridWeight . MaxWeight assigns 1 to w 1 and 0 to the rest of weights. It favors a facet with at least one very interesting value. AvgWeight assigns each w i an equal weight. The last one, HybridWeight , averages the interestingness computed by MaxWeight and AvgWeight . In Section 5.2, we evaluate the effectiveness of those three schemes in our user survey.
To summarize, through judicious application of p -values, we quantitatively compute the interestingness of individual facet instances as well as the whole facet. We then present to the user the top K 1 most interesting facet sets and within each, the top K 2 most interesting facet instances. For each facet instance, in addition to the actual count, we also show an expected count and an associated degree of interestingness from our calculation.

The discussion in this section assumes that the expectation is set using all data in the repository. The same analysis can be applied to other kinds of expectation. The only differ-ence is that the repository is no longer the original one, but a contrived one that gives those expected values. We can use p -values to rate the interestingness based on other aggregate functions, provided there exists a well-defined probability di s-tribution of what the user expects to see. For example, if the assumption is that the user expects to see prices from a cer-tain cumulative distribution F ( t ) = Pr { X  X  t } , then it is easy to derive the distribution of the maximum observation in a sample of size n , i.e., F max( t ) = Pr(max 1  X  i  X  n ( F ( t )) n . Therefore, the probability that the maximum would be greater than or equal to an actually observed maximum can be calculated accordingly. The same argument applies to other typical aggregates such as minimum and median.
In this section, we first review existing faceted search im-plementations based on inverted indexes in Section 4.1. Sec-tion 4.2 describes techniques that significantly improve the computation of facet summaries. We cover other implemen-tation details in Section 4.3.
All of today X  X  faceted search engines are built on top of inverted (or text) indexes. In addition to supporting text search well, such an implementation offers several flexibili-ties: (1) no schema is needed a priori since every document is self-describing; (2) missing values are not indexed, ideal for sparse data sets; (3) indexing documents with multiple values in the same facet is easy. A typical inverted index maintains an ordered list of terms . Each term points to a posting list that includes an ordered list of the ID s of documents contain-ing that term. A directory structure built on top of the term list is used for quick term lookups. To perform a search, the text index first locates the terms matching the list of key-words, and then merges the posting lists of those terms to compute the matching document set. Modern text indexes are extremely efficient in merging posting lists (for any com-bination of union and intersection), through zigzag-style joins [14]. An inverted index can optionally save certain terms of each document in a store , indexed by document ID . Given a document, one can fetch any stored term quickly. 6
To support faceted search over an inverted index, one sim-ply needs to map every token in the free text and every &lt;f acet, value&gt; pair in the input documents to an index term. Given a faceted query q , the system (1) identifies all matching documents D q ; (2) computes the count on each facet value (singletons only) over D q ; and (3) selects a subset of facet values and the corresponding counts to present to the user. The first step is simply traditional IR. A significant fraction of time is spent in the second step. We are aware of two possible implementations of that step.

A simple implementation is to keep &lt; facet,value &gt; pairs for each document in the store. At runtime, for each matching document d , fetch all facet instances of d by probing the store, and then construct a hash table to compute the count on all facet values. A second implementation is used in Solr [21], an open source engine built on top of Lucene [15]. It is currently used by cnet.com for faceted search. Solr has a unique design that indexes facets without storing them. To compute facet counts for a query q , Solr enumerates every facet instance &lt;F, f &gt; from the index and intersects its posting list with D . From the intersected set, it derives the count on facet value f . To speed up performance, Solr caches each posting list to a bitset and represent the bitset in one of two ways. If the bitset is dense, it is represented as a bitmap. Otherwise, it is represented as a hash map of document IDs .

Compared with the simple implementation, Solr has several advantages. First, the bitset representation of facets is more compact since facet values are not duplicated. Second, be-cause facets are stored separately in different bitsets, it avoids fetching facets that are not needed for counting. There are several reasons why some facets don X  X  have to be counted: (1) Facets are often organized in hierarchies, and users usually only care about higher level of facets when issuing the initial keyword queries; (2) When a user drills into a specific value of facet F , for the new query, it is not necessary to compute counts for F or any of its ancestors since they are all bound to a single value in the new result set. Last but not least, Solr does not need to construct a hash table for computing the counts since they are calculated one group at a time.
We adopt the general Solr approach in our implementation, but make some important improvements. One limitation in Solr is that it has to choose a threshold that decides the rep-resentation of the bitset. The bitmap representation is faster when performing document intersections, but sometimes con-sumes more space. It is not obvious how to choose a threshold that optimally balances space and time. Such a tradeoff has been extensively studied in relational databases. Our first improvement is to always represent a bitset as a compressed bitmap using Word-Aligned Hybrid (WAH) code [27]. WAH code is a run-length encoding of a bitmap. In WAH, there are two types of words: literal words and fill words. The former is a verbatim representation of 31 bits and the latter encodes the length of a list of all 0 X  X  or 1 X  X  in 30 bits. A bitmap is broken into groups of 31 bits first and then converted into a sequence of literal and fill words. Operations on bitmaps such as intersection can be performed on WAH code directly with-out decoding. As shown in [27], compared to other bitmap compression methods, WAH offers a good balance between space and performance.

A second limitation in Solr is that it has to intersect the matching document set D q with the bitset of every facet in-stance. For facets with a large domain, such computation can be quite expensive. Our second improvement is to reduce the number of intersections by building a directory structure called bitset tree on top of the bitsets of a facet. The bitset tree structure is an extension of GiST proposed in [29].
Building and Using a Bitset Tree : We create one bitset tree per facet F . A bitset tree is a balanced multi-way tree, in which each node has up to s &lt; bitset, node pointer &gt; entries ( s is a fanout parameter). We build a bitset tree bottom-up, level by level. Starting with the leaf nodes, for each bitset b corresponding to facet instance &lt;F : f &gt; , we create an entry &lt;b, null&gt; . We then divide all entries into groups of size s (the last group may be smaller than s ). Precisely how entries are divided will be explained later in this section. For each group, we generate a leaf node holding all entries in that group. We then build the next level of nodes. For each node e in the previous level, we create a new entry &lt;b  X  , e&gt; , where b is computed by bitwise  X  X ring X  the bitsets in e . After that, we again divide the newly created entries into groups of size s , and generate a new node to hold all the entries in each group. We continue building the next higher level of nodes until there is only a single new node created. We refer to the last node created as the root .
 Given D q as a bitset, we can use the bitset tree on a facet F to guide us to the bitsets on which an intersection with D q is indeed needed. We begin at the root of the tree and intersect D q with each bitset at the root node. If the result of an intersection returns an empty bitset (all bits are zero), we can prune the corresponding branch since no document in D q has any facet values in that branch. Otherwise, we follow the corresponding node pointer to check bitsets in the new node. Note that, in general, we may have to follow multiple pointers (resembling the traditional R-Tree). We continue this process until we reach the leaf nodes. We intersect D with each bitset there, and return the intersected result if it is not empty. From each returned bitset, we can count the number of documents on a certain facet value.

To illustrate how a bitset tree works, consider a small repos-itory with five documents. Assume a facet F has only six values. An example bitset tree on F of fanout 3 is shown in Figure 2. Each node is designated by a dashed box. The six bitsets in F are grouped into two leaf nodes. The root node has two entries, each pointing to a leaf node. Suppose D q a bitset of 10000. We start at the root node and intersect D q with the two bitsets there. Both intersected results are empty. We can stop right here and return. We save four bitset intersections in this case (Solr intersects D q with all 6 bitsets in the leaf nodes). If D q is a bitset of 01000, we again intersect it with both bitsets in the root node. Since only the result from the left bitset is non-empty, we just need to visit the left leaf node and intersect D q with the three bitsets there. We perform a total of five bitset intersections, instead of six. Note that our saving is much more significant with more facet values. Occasionally, it costs more when using a bitset tree. For instance, if D q is a bitset of 00100, we have to intersect D q with all eight bitsets in three nodes and pay 7 two extra bitset operations. However, we try to avoid those cases through an analysis explained later in the section.
Notice that we only have to perform the full bitset inter-section at the leaf nodes. At any internal node, as soon as we know that the result of an intersection is not empty, we can stop the current intersection and continue to visit nodes in the next level. We can exploit bitset trees for computing ag-gregates on combinations of facet values as well. To compute counts on a pair of facets { F 1 , F 2 } , we first use D the bitset tree on facet F 1 . We obtain an intermediate bitset I 1 for each value f 1 in F 1 (we exclude empty I f 1 ). Next, we use each I f 1 to probe the bitset tree on facet F 2 . From the returned bitsets, we can compute the actual count C q ( f for every f 2 in F 2 .

Analysis of a Bitset Tree : In general, given b bitsets, a bitset tree with fanout s has log s ( b ) levels. When using a bitset tree is beneficial, only a small number of branches is actually followed. Thus, we expect to perform h  X  s  X  log bitset intersections, where h is a small constant. This num-ber is minimized when s/ln ( s ) is minimized over the natural numbers, i.e., for s = 3.

The saving from using a bitset tree depends on how bitsets are grouped into nodes. Ideally, we want to group bitsets in such a way that shared bits are common within groups, but rare across groups. Similarly to R-Trees [22], constructing a bitset tree with optimal performance is NP-hard. We solve the problem heuristically by picking the first bitset for a node e at random and then continuing to add the next available bitset that shares the most bits with all bitsets in e . Although such a process is quadratic to the number of bitsets, it is not a big concern since bitset trees are built only once.
Given a facet tree T with n leaf nodes, and m documents in D q , what is the expected fraction (call it V T ) of nodes in T that we have to visit to perform bitset intersection with D If we assume that documents in D q are selected at random, we expect that fraction at the leaf level to be: Applying the same analysis on every tree level, we obtain V
Since most of the nodes are in the leaves, we can use for-mula (1) to approximate V T . For n =100,000, the estimate is about 0.5% for m =500, and 5% for m = 5 , 000. For n = 1 , 000, the estimates are 40% and 99% for m = 500 and m = 5 , 000, respectively. Obviously, bitset trees are benefi-cial when the facet domain is relatively large. Less obviously, they are also very useful when we compute counts on facet combinations. Remember that to compute counts on a pair of facets { F 1 , F 2 } , we first intersect D q with bitsets in facet F . Each intermediate bitset I f 1 tends to be sparse because bits in D q are spread over all facet instances in F 1 . As a result, when intersecting I f 1 with bitsets in facet F 2 set tree on F 2 is extremely helpful in reducing the number of intersections. Based on the above estimates, our system dynamically decides at runtime whether to use the bitset tree or to visit all leaf nodes for bitset intersection.
Aggregates on Facet Combinations: When consider-ing facet combinations, we avoid choosing facets within the same facet hierarchy. Those facets are defined to have func-tional dependencies and are less likely to be useful when pre-sented together. However, the total number of facet combi-nations can still be large. From the analysis in Section 3, we observe that the larger the number of unique value combi-nations in a facet set, the less interesting the facet set tends to be. Therefore, we heuristically prune a facet set if the number of accumulated facet values exceeds a threshold, set proportional to | D q | . We enumerate facet sets in increasing set size, i.e., single facets first, then pairs, then triples, and so on. This way, if a facet set is pruned, it is easy to remove all its supersets from further enumeration.

Supporting Hierarchies: Solr does not directly support facet hierarchies. In our implementation, for a given facet F in hierarchy h , each value f in F is encoded as a term by a full path from root to &lt;F, f &gt; in h . This is very similar to techniques used for indexing XML documents [10]. If a query includes a constraint F = f , we can easily identify terms corresponding to descendants of &lt;F, f &gt; in a hierarchy by checking a prefix in each term.

Incremental Support : One potential problem with any bitmap implementation is that it is expensive to update. For-tunately, this is not a big concern for us. An inverted index typically maintains multiple index segments, each responsible for a non-overlapping set of documents. New documents are first buffered in memory and are not immediately searchable. Over time, a new index segment is created using the new documents. Periodically, smaller segments are merged into bigger ones to reduce search overhead and to remove deleted documents. The compressed bitmaps and the bitset trees used in our implementation are maintained per segment, and are constructed each time that a new segment is created.
In this section, we conduct a comprehensive evaluation of the dynamic faceted search system that we built, on both relevance and performance using two real data sets. We in-troduce the experimental setup in Section 5.1. In Section 5.2, we summarize the findings of a user survey on relevance. We describe the performance results in Section 5.3.
We select two types of data with a mixture of structured and unstructured information for our tests, DBLP [6] and Patent [17]. The DBLP data contains about 13,000 papers published in 26 venues (e.g., SIGMOD, VLDB, TODS, etc) in the past 30 years. It has 14 facets organized in 6 hierarchies, including author, venue, time (e.g., decade, year), location (e.g., country, city), number of authors per paper, and num-ber of citations per paper. We use the title of each paper as text for keyword searches. The Patent data has about 1.8 million U.S. patents from the past 30 years. We use the full description of a patent as text. There are 16 facets organized into 10 hierarchies. The facet names and the hierarchy levels are given in Table 1. The DBLP data has been manually cleaned and we use it to conduct the user survey. The Patent data is much larger in size and we use it for performance evaluation.

We index all facets in both datasets using Lucene [15], an open source inverted index. Lucene organizes the index struc-ture in segments, each containing a subset of documents. Since the DBLP dataset is relatively small, all documents are indexed into one Lucene index segment. We create four Patent datasets, each including a varying number of patents. 8 Each Patent dataset is indexed by Lucene in segments of ap-proximately 4GB each. In all datasets, if the domain of a facet is larger than 1000, we create extra levels of facets in a hierarchy by grouping domain values alphabetically. Ta-ble 2 summarizes the sizing parameters of all the datasets. Our dynamic faceted search engine currently only considers facet sets up to size 2, since most important correlations are between a pair of facet values.
To understand the usefulness of the dynamic faceted search proposal in general, and the effectiveness of our proposed ex-pectations and p -value based measure, we conducted an ex-ploratory, qualitative, and task-oriented user study. Through our web interface, a user can choose one of the two types of expectations that we currently support, natural and naviga-tional , and one of the three weighting methods of aggregat-ing interestingness (as described in Section 3.2). When a user types a keyword, we display a page with three sections. The middle section contains a list of the top matching docu-ments returned by the inverted index. The left section shows the facet summaries selected dynamically by our approach. An example output is shown in Figure 3(a). For each facet instance, in addition to the actual count, we also show the expected count, and a bar indicating the degree of interest-ingness. The bar is colored green if the expected count is less than the actual one, and red otherwise. Although not shown in the figure, we also provide a one-line explanation to help the user better understand how we set the expectation. For example, for the navigational expectation, we show the query used for computing the expectation. For comparison, we mimic how today X  X  faceted search systems select facets and present in the right section facet summaries selected using a heuristic rule that orders facets just by decreasing counts. We interviewed a total of 15 computer science graduate students, 9 from CMU and 6 from EPFL. Although our study consists of small number of users, their feedback helped us identify the strengths and weaknesses of our proposed mechanisms.
We conducted the survey in two parts.In the first part, we fixed the weighting method to HybridWeight and focused on the effectiveness of different expectations and the measure. For each user, we performed tests on three keyword queries. Two of the keywords were provided by us:  X  distributed  X  and  X  mining  X , each having about 400 matches. We let the user pick the third keyword, with the only requirement that the number of matching documents has to be sufficiently large. For each query, the user saw three outputs selected by our dynamic approach, one based on the natural expectation, and the other two based on the navigational expectation. For the latter two, one used the complete repository to set the expec-tation, and the other was a drill-in query and used the pre-vious query to set the expectation. For each of the three dy-namic outputs and the output selected heuristically, we asked the user for a score between 1 and 10 indicating the perceived relevance of the facet summaries. A score of 1 means not use-ful at all, and a score of 10 means very relevant. We compare the score of each dynamic output with the heuristic one for each query. There were a total of 15  X  3  X  3 = 135 compar-isons. We categorize each comparison as positive, neutral, or negative, depending on whether the dynamic score was higher, equal, or lower than the heuristic one. The break-down of the results is shown in Figure 3(b).

Overall, about 60% of the answers were positive while only 20% were negative. In particular, users overwhelmingly pre-ferred the outputs from navigational . We first summarize why the users liked the navigational approach. The top table in Figure 3(c) shows dynamically selected facet summaries for the keyword X  X ining X . Our users found it useful to know that 2004 and 2001 are important years for KDD since they had more shares of the mining papers than expected. They also found it interesting that two famous authors were more pro-ductive in the mining area in 2000s and 1990s, respectively, and had moved on to other topics since then. All users except one liked the fact that our system can show facets in pairs, since they exposed interesting correlations. In comparison, users found the heuristic output given in the bottom table in Figure 3(c) less informative. Similarly, for the keyword  X  X is-tributed X  (the navigational output is given by Figure 3(a)), users liked the fact that facet  X  X ecade X  was selected as the top one. The ordering of the facet instances in  X  X ecade X , although not according to decreasing counts, clearly demon-strates trend changes in the area of distributed systems. For one of the user selected keywords X  X  X elational X  X  X he most inter-esting facet instance is dynamically selected to be author  X  X . F. Codd X , since most of his publications are on  X  X elational X  with very few in other areas. However,  X  X . F. Codd X  was not selected by the heuristic approach, since many other authors have published more  X  X elational X  papers than Codd. When the user drilled into  X  X . F. Codd X , our system used the pre-vious query to set the expectation and dynamically selected  X  X itations Range X  as the top facet. It becomes immediately clear that papers by Codd are more frequently cited than other papers containing the keyword  X  X elational X . All these results convinced our users that the navigational way of set-ting the expectation and our p -value based measure are use-ful in discovering interesting or unexpected patterns. Finall y, most users expressed interest in the  X  X d Hoc X  method of set-ting the expectation (not yet supported by our system).
Our dynamic approach also received some negative feed-back. Certain facets such as city and type were seldom wanted by certain users no matter how statistically interesting they were. Similarly, other facets such as author were always pre-ferred by some users, independent of the keywords. In the future, we plan to improve our interface by allowing a user to 9 (a) Top facet summaries for keyword  X  X is-tributed X , using navigational expectation. prune uninteresting facets and to  X  X in X  interesting ones inter-actively. Our system will then dynamically select the remain-ing facets. Overall, the feedback for the natural expectation is neutral. An important reason is that when our users picked the third keyword, they mostly selected keywords from their own areas of research. Therefore, the facet summaries se-lected using the natural expectation were not very surprising or informative to them. Our conjecture is that, had they se-lected keywords from an unfamiliar area, their reaction might have been different.

In the second part of the survey, we evaluated the trade-offs among different ways of aggregating the degree of interesting-ness. Each user was asked to score the facet summaries se-lected dynamically for keyword  X  X ml X  using each of the three weighting methods. The number of people who preferred Hy-bridWeight , MinWeight and AverageWeight were 7, 6 and 2, respectively. This shows that the interestingness of a facet is strongly influenced by a few of its most interesting instances.
In this section, we study the performance aspect of the dynamic faceted search, using the Patent dataset. We im-plemented five different versions of the proposed dynamic faceted search, in Java. A simple version is based on the simple approach described in Section 4.1. We favor the sim-ple version by keeping only facets, not text, in the store. A Solr version implements the approach used in Solr as de-scribed in Section 4.1, but with extension to support hierar-chies as described in Section 4.3. The third implementation, called compressed , improves Solr by representing all bitsets in WAH code. The fourth implementation, called tree , im-proves Solr by using bitset trees (as described in Section 4.2) to reduce the number of bitset intersections, but keeping the bitset representation used in Solr. The last implementation, called compressed-tree , applies both WAH code and bitset-trees on Solr . We used Apache Commons-Maths Library [28] to compute the degree of interestingness based on the descrip-tion in Section 3. We performed all experiments on a 3GHz P4 desktop machine with 1GB of memory and a single disk drive, running Linux.

In all tests, we set the expectation to be navigational (time taken for other kinds of expectations is comparable), and we consider the top level facets in all hierarchies. We break the total elapsed time of a query into pure search time and sum-mary computation time. The former is the time that Lucene takes to compute the matching documents and rank them. Ideally, we want the two times to be of comparable length. In order to have better control of the query size, we some-times simulate queries by selecting a subset of documents at random. Unless specified otherwise, all queries used in this section are simulated.

To understand where the time goes in our system, we first run a query that matches about 25,000 documents using the tree implementation, and break the total time into search time and summary computation time. The result is shown in Figure 4. When the data size is small, the two times are comparable. As the data size gets larger, the summary com-putation time starts to dominate. In the remaining section, we will be focusing on the time to compute facet summaries. Figure 4: Time breakdown of Tree on different index sizes, for a query matching 25,000 documents.

In this section, we compare the performance of the five dif-ferent implementations of dynamic faceted search. In the first experiment, we study the pure CPU overhead of each of the implementations. To achieve this, we consider the smallest dataset, PAT-4G, and cache in memory the index terms of top level facets. For the simple implementation, we further keep the index store in memory. We also keep the bitset trees in memory for implementations that require them. We present the total amount of memory consumption for each implementation in Figure 5(a). The memory consumption of simple is about 65MB, while all other implementations re-quire less than 3MB memory footprint. WAH encoding helps reduce the memory consumption by almost 50%. Bitset-trees consume some extra space because of the directory structure.
Figure 5(b) shows, for each implementation, the summary computation time using randomly selected document sets of varying sizes. As we can see, even when the entire dataset fits in memory, the simple implementation is still much slower compared to others. This simple implementation operates on one document at a time and has the overhead of maintaining 10 (a) Memory consumption of different implementations. a hash table for computing the counts for all facet instances. All other implementations avoid such overhead since they ag-gregate counts one group at a time.

Although WAH encoding saves space, it does not improve performance. When performing intersection on WAH-encoded bitsets, we need to maintain an extra Java object to store the run-length information in the current position. Such over-head offsets the benefit from a smaller footprint in memory. Another reason is because the number of documents in PAT-4G is relatively small, about 110,000. When encoding bitsets on such a dataset, many 31-bit chunks have at least a 1-bit and have to be represented as a literal word. Therefore, the compression that WAH can achieve is limited. We X  X  like to investigate in the future whether using byte-aligned encoding performs better for small datasets.
 Exploiting bitset-trees improves performance significantly. Although there is no facet with a very large domain in this dataset, bitset-trees are very useful when computing counts on facet pairs. After intersecting the query bitset with the bitsets on the first facet, the intermediate bitsets become sparse. When using such intermediate bitsets to probe the second facet, the bitset tree on the second facet can prune many unnecessary bitset intersections. In Figure 5(c), we show the fraction of total bitset intersections that are saved because of the bitset-trees. On average, the bitset-trees give us about a 40% saving. We note that these savings may not translate proportionally to savings in time since the cost of bitset intersections also depends on the density of the bitsets.
To summarize the in-memory test, the tree implementation gives the best performance for most of the time, and scales well as query sizes approach the number of documents in the index. WAH compression is mainly useful when the query is much smaller than the number of documents in the index.
Next we study the performance of each method on the large data set PAT-52G. For a fair comparison, we allocate a 50MB buffer pool to each method. Data that can X  X  be cached in memory has to be paged out and read back when accessed again. The simple implementation uses the buffer pool to cache documents fetched from the store. The rest of the im-plementation caches bitsets and/or bitset-trees in the buffer pool. We measure the total elapsed time on summary com-putation for each implementation, with varying query sizes.
Figure 6 shows the results in seconds. As expected, simple performs the worst across the board. Most of its overhead comes from the additional random I/Os when fetching facets from the document store. The document buffer pool is not very effective since temporal locality is low. On this much larger data set, compression becomes very effective. With WAH encoding, the compressed implementation runs about twice as fast as Solr , while consuming slightly less memory. Also, the benefit from using bitset-trees is almost as large as compression. Because we use formula (1) in Section 4.2 to dynamically decide whether to use a bitset-tree for probing or not, the tree implementation always performs better than Solr . Combining compression and bitset-trees together gives the best performance. However, the benefits are not additive. Using WAH code, the bitset intersection on internal nodes in a bitset-tree becomes more expensive since they tend to be denser than the leaves. Nevertheless, the combined imple-mentation in general runs at least two to three times as fast as Solr and orders of magnitude faster than simple . Figure 6: Time to compute summaries on PAT-52G dataset, with different query sizes
From the results of the experiments we conclude that the simple method does not give acceptable performance in any scenario. We found that our techniques, including WAH en-coding and bitset-trees, provide significant performance im-provement over existing solutions. On a single computer, our best implementation of the dynamic faceted search can keep a user session interactive for queries matching 5000 documents or less. In the future we intend to make the process interac-tive for even larger queries by computing the interestingness on multiple servers in parallel.
There exist several commercial implementations of faceted search. Both Endeca [8] and IBM X  X  Websphere content dis-covery server (formally iPhrase) [23] are mainly intended for managing product catalogs in e-commerce sites and thus of-ten do not have a large repository to deal with. Google Base [2] provides a faceted search interface. After a user types in a keyword, certain facets are presented to the user for fur-11 ther navigation. However, based on our knowledge, the facet selection in those systems is primitive, and none of them au-tomatically and dynamically selects interesting facets on a per query basis as we do. The Flamenco system [9] also im-plements a faceted search interface, but mostly addresses the user interface issues. Instead of returning a long list of match-ing documents, search sites such as Clusty [3] group similar documents in the result together and create a faceted-like dis-play on the fly. Groups are dynamically generated through a taxonomy on the text of the result set. In comparison, our work discovers useful information from pre-identified facets. Also, Clusty does not consider a user X  X  prior knowledge when generating the groups.

There exists work [1, 12] on extending relational databases to support IR-style queries. The focus is on retrieving the top K matching tuples. More recently, [26] studies how to in-tegrate faceted search into OLAP analysis. A keyword query is first converted to joins of dimensional and fact tables. The most interesting dimensional attributes and their values are discovered from the join results, by comparing aggregates of a measure at different levels. In comparison, our work provides discovery-driven analysis in the context of faceted search.
Text analytics [5][25] tries to automatically extract struc-tured information from text by using a variety of technologies including statistical and rule-based natural language process-ing, information retrieval, machine learning, ontologies, and automated reasoning. It can derive not only basic entities such as persons, locations, and organizations, but also rela-tionships between those entities. Such extracted information allows more precise queries. If we model each type of ex-tracted information as a new facet, the number of facets asso-ciated with a repository becomes significantly larger. There-fore, automatically selecting interesting facets for a given query becomes much more important.

There exists work in the data mining area on discovering interesting information. A survey on various interestingness measures can be found in [30]. Exploratory data analysis methods used in [31, 32] focus on finding linear combinations of variables to identify clusters in the dataset. Those meth-ods, however, are not directly applicable to categorical data that is common in faceted search. There has been research on identifying interesting patterns through time series anal-ysis and a good survey can be found at [18]. Finally, [13] discovers correlated attribute pairs in a relational database. It applies chi-squared analysis for identifying correlations and employs random sampling for efficiency. However, those anal-yses are not driven by user queries.
We develop a novel dynamic faceted search system to sup-port OLAP-style discovery-driven analysis on a large set of structured and unstructured data. We propose an intuitive and effective way of measuring  X  X nterestingness X  and a novel navigational method of setting a user X  X  expectation. The feedback from a user survey validates that our approach is promising. By exploiting WAH codes and bitset trees, we built an efficient runtime engine on top of an inverted index. We want to pursue several directions in the future. First, as mentioned in Section 5.2, we X  X  like to incorporate user feed-back in facet selection. Second, we X  X  like to explore how to extend the aggregates to functions other than count, such as sum or average on some numerical measures. Finally, for even larger data sets, we want to investigate how to support dynamic faceted search in a distributed environment. [1] Sanjay Agrawal, et al: DBXplorer: A System for [2] http://base.google.com/ [3] http://clusty.com/ [4] Thomas M. Cover and Joy a. Thomas. Elements of [5] W. Dakka, et al: Automatic discovery of useful facet [6] DBLP dataset: http://dblp.uni-trier.de/xml/ [7] Bradley Efron and Robert J. Tibshirani: An [8] http://endeca.com/ [9] The Flamenco Search Interface Project. [10] Roy Goldman and Jennifer Widom, DataGuides: [11] Jim Gray, et al: Data Cube: A Relational Aggregation [12] Vagelis Hristidis, et al: DISCOVER: Keyword Search [13] Ihab F. Ilyas, et al: CORDS: Automatic Discovery of [14] Xiaohui Long et al: Optimized Query Execution in [15] http://lucene.apache.org/ [16] Tom M. Mitchell: Machine learning. McGraw-Hill,1997 [17] Patent dataset: http://www.nber.org/patents [18] John Roddick, et al: A Survey of Temporal Knowledge [19] Sunita Sarawagi: User-Adaptive Exploration of [20] Sunita Sarawagi, et al: Discovery-Driven Exploration of [21] http://incubator.apache.org/solr/ [22] Jayme Luiz Szwarcfiter: Optimal multiway search trees [23] http://www.ibm.com/software/data/discovery/content [24] Witten, I.H., et al: Managing Gigabytes: Compressing [25] http://www.research.ibm.com/UIMA/ [26] Ping Wu, et al: From Keyword-based Retrieval to [27] Kesheng Wu, et al: Optimizing bitmap indices with [28] http://commons.apache.org/math/ [29] Hellerstein, et al: Generalized search trees for database [30] Liqiang Geng, et al. Interestingness measures for data [31] Friedman, et al: Exploratory Projection Pursuit. In [32] Swayne, et al: XGobi: Interactive Dynamic Data
