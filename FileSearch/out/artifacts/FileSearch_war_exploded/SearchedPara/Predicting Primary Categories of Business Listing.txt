 We consider the problem of identifying primary categories of a business listing among the categories provided by the owner of the business. The category information submit-ted by business owners cannot be trusted with absolute certainty since they may purposefully add some secondary or irrelevant categories to increase recall in local search re-sults, which makes category search very challenging for lo-cal search engines. Thus, identifying primary categories of a business is a crucial problem in local search. This problem can be cast as a multi-label classification problem with a large number of categories. However, the large scale of the problem makes it infeasible to use conventional supervised-learning-based text categorization approaches.

We propose a large-scale classification framework that lever-ages multiple types of classification labels to produce a highly accurate classifier with fast training time. We effectively combine the complementary label sources to refine predic-tion. The experimental results indicate that our framework achieves very high precision and recall and outperforms a Centroid-based method.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval models Algorithms, Design, Experimentation Vertical search, Text categorization, Primary category
Local search is growing faster than Web search with more people using mobile devices. Studies show that at least 20% of Web queries have some local intent [9]. In local search, category queries such as  X  X estaurants X  are known to be harder than business name queries such as  X  X est Buy X  in the sense that the ranking quality for these queries by search engines is inferior [6].

One of the challenges in category queries in local search is that the category descriptions submitted by business owners are often incorrect. They often add some secondary or irrele-vant categories to increase recall. For example, the owner of a Japanese restaurant may add  X  X orean Restaurants X  to the category description of the business, hoping that the busi-ness may appear in the search results for the query  X  X orean Restaurants X  as well as for the query  X  X apanese restaurants X . This motivates the problem of identifying primary (or true) categories of a business. This can be considered as an multi-label classification problem [7] in which we can assign mul-tiple primary categories to a business. There has been a lot of research in text categorization [4, 3, 1]. See [5, 8] for com-prehensive surveys of the topic. However, the large number of categories in local search (2K categories in total) makes it impossible to use conventional supervised-learning-based text categorization methods.

In this paper, we present a solution to the large-scale pri-mary category prediction (multi-label classification) prob-lem by combining three complementary label sources:
In our proposed solution, a set of highly predictive fea-tures are derived from labels from business owners and click signals and then a classifier is trained from these features using labels by human judges as targets. The experimental results demonstrate that integrating these multiple sources of labels is highly beneficial for a large-scale classification problem.
In this section, we propose a machine learning approach to identify primary categories of a business listing page.
Let D = { d 1 ,d 2 ,... } be the set of all business listing pages stored in a local search index and C = { c 1 ,c 2 ,... } be the set of all categories for local businesses defined by human editors. Let T = { t 1 ,t 2 ,... } be the set of all terms appearing in D . We assume that each business page d is represented by a vector space model. The set of categories assigned to a business listing d is denoted by C d . We use D c = { d | c  X  C ,d  X  D } to denote the set of all listings that have c as Figure 1: An example of a business listing page. Categories are highlighted in a red box. one of the categories. A category c is a primary category of a business listing d if c represents one of the main categories of d . The primary category classification problem is posed as follows: Given a business listing d and a category c  X  C determine whether c is a primary category of d .
 Figure 1 shows an example of a business listing page. Based on the above definitions, C d of this listing is the set {  X  X teak Houses X ,  X  X estaurants X ,  X  X arry Out &amp; Take Out X ,  X  X merican Restaurants X ,  X  X eafood Restaurants X  } . These cat-egories are either provided by the owner of the business or a third-party information provider. In this example, only  X  X eafood Restaurants X  is a primary category of the business and the other categories are either secondary or irrelevant.
Note that our problem can be seen as a multi-label text categorization problem since it is reasonable to assume that a business may have multiple primary categories. Also, we assume that there is at least one primary category for one business listing. This assumption leads to a useful feature normalization, which is discussed in Section 2.3.3.
The main challenge for our problem is the large number of categories (2K categories in total), which makes it very dif-ficult to apply conventional supervised-learning-based text categorization approaches. Obtaining enough labels to train a classifier for each category is not feasible. Thus, we need to leverage some other types of pseudo labels to train a clas-sifier. There are two such pseudo labels available for our problem. One is the category description C d assigned to listings. Although C d contains some incorrect categories, a collection of listings with the same category carry important information about the category. The other is the user clicks gathered from local search click logs. Category names (e.g.,  X  X hinese restaurants X ) are common queries in local search. User clicks on business listings in the search results provide important signals about the relationship between categories and business listings.

Our proposed solution is as follows. We first derive a set of features x to be used in our classifier from the above two pseudo-label sources (discussed in detail in Section 2.3). Note that a feature vector x is defined for a business listing-category pair ( d , c ). For example, the click-through rate of d for c (from the search results when c is used as a query) is such a feature. Then, we train a classifier f ( d,c ) using train-ing data { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,... } where y i is a label provided by human judges.

Table 1 compares the three different types of label sources leveraged in our solution. It is clear that the three sources complement one another in terms of accuracy and cover-age. Since categories by owners and user clicks have large coverage, they are appropriate for being used as targets to generate features (discussed in Section 2.3 in detail). On the other hand, the editorial labels by human judges are very ac-curate although they are not enough to train a classifier for each class. Thus, we use it as the final learning targets to combine the features (in Section 2.4).
In this section, we discuss how features are derived. Note that each feature is defined for a business listing-category pair ( d , c ) to be used as a signal for our classifier f ( d,c ). For each category c  X  C , we define where d is a business listing represented as a tf-idf weight vector. In other words, Centroid c is the cumulated weight vector for all the listings that share the category c in their assigned categories. Then, we can compute the cosine simi-larity measure between a business listing d and the centroid vector Centroid c for a category c :
We use cosine sim ( d,c ) as a feature for our classifier. The motivation for this features is as follows. Each centroid vec-tor Centroid c is a mixture of the true distribution of terms for the category c and the noise due to errors in C d . How-ever, the true distribution dominates the centroid since the error rate of categories assigned by owners is low (around 10%). Also, it should be noted that even when the owner of a business may assign secondary or irrelevant categories to the category description part of the content ( C d ) to in-crease recall for local search, it is less likely for the owner to corrupt the overall content of the business data ( d ). For example,  X  X orean Restaurants X  can be easily added to the category description of a Japanese restaurant by the owner hoping that the business may appear in the search results for the query  X  X orean Restaurants X  as well as for the query  X  X apanese restaurants X . However, the owner would not add many Korean menu items to the content. Hence, we ex-pect that cosine sim ( d,c ) will be high when c is a primary category of d and low otherwise. Indeed, this hypothesis is verified in the experimental results which show that the centroid-based features are very effective for our classifica-tion problem.

To reduce the dimension of the document vectors and min-imize the noise in the centroids, we propose another simi-larity feature based on new centroids generated by the  X  2 method [10]. The  X  2 statistic score  X  2 ( t,c ) for a term t and a category c is where N r + is the number of times t and c co-occur, N n + the number of times t occurs without c , N r  X  is the number of times c occurs without t , N n  X  is the number of times neither Categories assigned by owners ( C d ) medium high features in Section 2.3.1 c nor t occurs, and N is the total number of documents. If the  X  2 statistic score for t is high, it belongs to characteristic vocabulary of c .

Using  X  2 statistic scores, we generate a reduced set of terms T 0 c = { t  X  T |  X  2 ( t,c ) &gt;  X  } for each category c . Then, we generate a new centroid filtered by the reduced terms: where M c is a diagonal matrix with M c ii = 1 if t i  X  T 0 otherwise. Finally, a new similarity feature is
In local search, category queries such as  X  X estaurants X  are very common. User clicks on business listings in the search results page provide crucial information about the relation-ship between the query and the clicked listings: The more clicks on a listing, the more likely the listing is to be about the query. The key observation is: When a query q matches a category name c , clicks on a listing d in the search results page for q can be translated into a positive relationship be-tween d and c . In this section, the features for a category c are obtained from click statistics for c as a query in click logs.

The simplest form of a click-based feature is the click-through rate where clicks and views are for d in the query sessions for c . It is well known that CTR suffers from the position bias: The results at higher positions get more clicks regardless of their relevance. To address the position bias problem, we use the following two click measures in addition to CTR. where clicks i  X  { 0 , 1 } denotes if d was clicked in the i -th session out of N sessions in which d appeared for c , p i position of d in the i -th session and aCTR p is the aggregated CTR (over all queries and sessions) for position p . where skips is the number of sessions in which d was not clicked but some other results below d were clicked. Note that SKIP CTR is a good approximation of so-called at-tractiveness , defined to be the probability of a click on a document given that the document is examined by the user.
The hypothesis that there is at least one primary category for each d suggests that we need to consider the relationships among the categories in C d . To this end, we propose to add a normalized feature normalized ( feature ( d,c )) for each feature feature ( d,c ): normalized ( feature ( d,c )) = feature ( d,c ) For example, let C d = { c 1 ,c 2 } be the category set for d and CTR ( d,c 1 ) = 0.4, CTR ( d,c 2 ) = 0.2 . Then, normalized ( CTR ( d,c 1 )) = 1, normalized ( CTR ( d,c 2 )) = 0.5. The in-tuition behind this normalization is: The category c max arg max c 0  X  C d feature ( d,c 0 ) is likely to be a primary category regardless of its feature value according to the above hypoth-esis. The relative information provided by the normalized features combined with the original features increases the predictive power of our classifier.
Given training data { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,... } , we use the gra-dient boosting method (GBDT) [2] to train a classifier f ( d,c ). Each feature vector x consists of the features defined in the previous section: x = { cosine sim ( d,c ), normalized ( cosine sim ( d,c )), CTR ( d,c ), normalized ( CTR ( d,c )), ... } .
The major difference between our framework and typical text categorization frameworks is that there are much fewer features in our framework but each feature is much stronger. Most classifiers for text categorization use a set of terms as features. On the other hand, we use a small number of very strong features for the classifier. Each feature used in our classifier can be even considered as a stand-alone model . In Section 3, we show that each feature performs reasonably well as a classifier. In this sense, the training step in our framework can be viewed as combining multiple models to improve prediction.
In this section, we present experimental results to validate our approach. We use data sets from a commercial local search engine. There are 20M business listings, 2K categories and 53M terms in total. That is, || D || = 20M, || C || = 2K and || T || = 53M. We obtain labels from human judges for 42K (listing, category) pairs. We generate 12 features for the 42K (listing, category) pairs in the editorial judgment data. To generate click-based features in Section 2.3.2, we use 6-month click logs in the local search engine. In addition to the features defined in the previous section, one simple category term frequency feature and its normalized version are included. We use 50% of the data as training data and the rest as test data. Figure 2: Precision vs. recall of different models. Each point corresponds to a threshold value for the output of a model.
We evaluate the classifier trained as described in Section 2.4 using precision-recall as the evaluation metric. To see the effectiveness of our proposed method, we compare it with each of the features as a baseline:
Figure 2 shows the comparion of different models based on precision-recall. Our proposed classifier gbdt significantly outperforms all baselines. The results show some interest-ing characteristics of each feature. In general, click-based features ( ctr , coec and skip ctr ) show higher precision than centroid-based features given the same recall. How-ever, click-based features suffer from a sudden drop in pre-cision as recall decreases. This happens since a very high CTR, for example, is likely to be due to a very small num-ber of views (with a similar number of clicks). Also, we can see that click-based features have limited recall compared to centroid-based features: They can never achieve recall higher than 70%. On the other hand, centroid-based fea-tures can achieve much better recall (over 70%). Also, they do not suffer from a sudden drop in precision as recall de-creases. We also observe that the  X  2 -based term filtering improves prediction. It is clear that our classifier combines the benefits of different features to predict primary cate-gories.
 Table 2 shows the ordered categories by gbdt for  X  X ed Lobster X  in Figure 1. The primary category of the business  X  X eafood Restaurants X  is on top while a irrelevant category  X  X arry Out &amp; Take Out X  is on bottom.
We presented a solution to a large-scale multi-label classi-fication problem in the context of finding primary categories Table 2: Categories sorted by the gbdt outputs for  X  X ed Lobster X  in Figure 1 of local businesses. We showed that we can combine multi-ple label sources effectively to train a highly accurate classi-fier. Also, we demonstrated that our classifier outperforms a Centroid-based method.

One promising future direction is to investigate a method that updates centroids iteratively using a classifier. We can filter out bad categories in each listing based on the first classifier, which leads to improved centroids. We can then train a new classifier based on the improved centroids. Also, we will investigate the usefulness of adding variants of sim-ilarity features to the feature set. [1] W. W. Cohen and Y. Singer. Context-sensitive [2] J. Friedman. Greedy function approximation: a [3] T. Joachims. A probabilistic analysis of the rocchio [4] T. Joachims. Text categorization with suport vector [5] T. Joachims, Y. Yang. Text categorization.
 [6] C. Kang, X. Wang, Y. Chang, and B. Tseng. Learning [7] F. Sebastiani. Machine learning in automated text [8] F. Sebastiani. Text categorization. In Text Mining and [9] P. Venetis, H. Gonzalez, C. S. Jensen, and A. Y. [10] Y. Yang and J. O. Pedersen. A comparative study on
