 Successful software systems are always able to evolve as stakeholder requirements and environments where the deployed systems operate [1]. In today X  X  competitive market, meeting changing user demands 1 is a critical driving factor of software evo-lution. The software system should adapt to the social environment where users form opinions based on their experience with it [3]. Therefore, systematically and effective-ly eliciting evolutionary requirements is critical for the software to adapt and improve. 
User feedback provides useful information that can help to improve software quali-ty and identify missing features [4]. However, with software delivered via the Inter-net, the scopes and types of users are uncertain before delivering software systems, since there are differences of space and time between users and developers. Fortunate-ly, user generated content is becoming mainstream in web platforms, and consumers are willing to publish online reviews to express their opinions about software systems. These reviews that manifest user demands in real contexts of use have become an available feedback resource for eliciting requirements to design future software re-leases. Moreover, the reviews that come from large quantities of disparate users con-tain abundant data and its expressions [5]. For example, the Apple App Store has more than five hundred million active registered users and billions of online reviews. 
Current software engineering research and practice favor requirements elicitation derived from online reviews. Several approaches have been developed, regarding the techniques and processes to consolidate, analyze and determine requirements in ac-cordance with online feedback [6-7]. However, these approaches mostly rely on ma-online reviews in order to shorten time-to-market. Obviously, automated techniques, such as text mining, information retrieval, and machine learning can be effective tools for identifying software features and associated opinions mentioned in user comments [8-9]. However, due to complex and diverse opinion expressions, it is challenging to utilize automated analysis for accurately deriving constructive feedback from the reviews of software systems. What X  X  more, assisting developers with determining evolutionary requirements based on user feedback is also challenging. 
In this paper, we present a systematic approach for the transformation of online re-views to evolutionary requirements. For the first problem of automated text analysis we analyze the characteristics of online software reviews and then adapt the syntactic relation-based propagation approach (SRPA) to automatically identify opinion ex-pressions about common software features. In order to provide meaningful feedback, we present a method S-GN for clustering opinion expressions from a network pers-pective, which uses the Girvan-Newman algorithm with the Explicit Semantic Analy-sis similarity. To address the second problem of assisting developers, we consider an economic impact to analyze user satisfaction based on this feedback and then deter-mine important changes for requirements. 
The contributions of our research are as follows:  X 
SRPA+, an expanded version of SRPA, is more suitable for mining complete opi-nion expressions from software reviews.  X 
The proposed method S-GN optimizes the clusters of opinion expressions by con-sidering a macro network topology.  X 
We combine user satisfaction analysis with the inherent economic attributes asso-ciated with the software revenue to determine the evolutionary requirements.  X 
We show experimentally that our approach achieves good performance for deriv-ing constructive feedback even with large amounts of review data, and furthermore discovers the evolutionary requirements that tend to be ignored by developers. 
The remainder of this paper is organized as follows. Section 2 elaborates our approach. Section 3 describes the experiment and analyzes the results. Section 4 introduces related work and Section 5 discusses conclusions and future work. In our approach, we first extract opinions about software features from large amounts of online reviews and determine whether opinions are positive or negative. Then, we categorize opinions and select corresponding review sentences to represent the feed-back on software features. Finally, we generate a document of evolutionary require-ments from an economic perspective. 2.1 Extracting Targets and Sentiment Words A user opinion mentioned in a review is defined as a target-sentiment pair. The target is a topic on the software feature that is a prominent or distinctive user-visible aspect, quality, or characteristic of the system [10]. The sentiment is the user evaluation of its can be modeled using the dependency grammar [11]. There have been many methods used to model sentiment words, targets and their dependency relationships [21-23]. We adapt the syntactic relation-based propagation approach (SRPA) due to its model-ing naturally for the opinion mining task. SRPA extracts targets and sentiment words iteratively using known and extracted words through the identification of syntactic relations [12]. The bootstrapping process starts with a seed sentiment lexicon. 
The key of SRPA is the propagation rules based on syntactic relations. As targets and sentiment words are usually nouns/noun phrases and adjectives respectively [13], SRPA only defines the relations between nouns and adjectives, between adjectives, and between nouns. However, software systems have the dynamic features of compu-ting and processing. Users may comment on the software X  X  behavior and impact on the application environment using opinion expressions that depend on the relations between verbs and adverbs. In addition, sentiment verbs such as love can also express opinions. Accordingly, we define new propagation rules based on Stanford POS tag-ger 2 and syntactic parser 3 , as shown in Table 1. 2.2 Identifying Complete Expressions of Opinions Since the targets extracted in the previous st ep are individual words, we need to iden-tify the complete target expressions. Generally, a sentence clause contains only one target-sentiment pair unless there are conjunctions [12]. However, in the sentence Kaspersky didn X  X  update to a correct version quickly , there are two target-sentiment expressions, namely Kaspersky update quickly and a correct version . Therefore, we further merge the opinion expressions on the same software feature, and remove the noisy ones caused by unconstrained propagation rules. 
The target words consist of nouns and verbs. For noun target expressions, we ex-verbs with direct objects or prepositional objects, the verb phrases in the phrase-structure trees serve as the target expressions. Note that the parser doesn X  X  distinguish prepositional objects and adverb prepositional phrases. We check the compound are verbs without objects, the verbs and their subjects compose the target expressions. 
Based on the identified target expressions, we employ the following two rules to share some words, they must describe the same software feature. Rule 2 : if the words in opinion expressions have direct dependency relations, they are likely to represent the same software feature. 
We prune noisy opinion expressions according to word frequency. The sentiment words, negations, and stop words are removed from the merged opinion expressions and then the scores of processed expressions are calculated as follows: opinion expession with the highest score unless there are conjunctions. 2.3 Assigning Sentiment Polarities to Opinion Expressions We propose a two-stage method for assigning polarities to opinions. In the first stage, the polarities for the newly extracted sentiment words are inferred through the rules in [12]. The extracted words are assigned with the same polarities as the known words in the current review. The polarity changes when there are an odd number of negations or contrary words between the extracted word and the known word. The polarity val-sum of polarity values of known sentiment words in the current review. 
In the second stage, the polarity score of a complete opinion expression is estimated by the following ordered weighted averaging (OWA) aggregation [14] of the contained sentiment words. where s i is the polarity of a sentiment word in the opinion expression; N si is the num-The types of sentiment words consis of verbs ( v ), adjectives ( adj ), and adverbs ( adv ). As verbs are the core of sentences whereas adjectives and adverbs are modifiers, the their importance. The value of w si is concerned with the position of the type of s i . The OWA operators aggregate both the polarities of sentiment words and the importance of their types. If the polarity score of an opinion expression is greater than 0, its polar-ity is positive, and otherwise negative. The polarity changes if there are an odd num-ber of negations associated with sentiment words in the opinion expression. 2.4 Organizing Opinions into Structured Feedback In order to provide meaningful feedback, we first group similar opinion expressions about software features. Each category represents a unique overall, functional or qual-ity requirement. Then we produced the structured feedback classified by software features, including several corresponding sentences. 
The opinion expressions and the semantic associations between them construct an undirected graph G = ( V , E ), where V is the set of vertices for the opinion expressions and E is the set of edges for the semantic links between any two vertices. There is a semantic link between two opinion expressions if their semantic similarity is greater than a certain threshold  X  . We rely on the Explicit Semantic Analysis (ESA) algo-rithm to compute the semantic similarity between opinion expressions. ESA first builds an inverted index for all Wikipedia concepts, then represents any text as a weighted vector of Wikipedia concepts by retrieving its terms from the inverted index and finally assesses the relatedness in concept space using conventional metrics [15]. 
Based on the graph G , we adopt the Girvan-Newman (GN) algorithm to cluster the opinion expressions. The GN algorithm is a typical method for detecting network communities. Without the prior information for determining the centers of communi-ties, the GN algorithm constructs communities by progressively removing edges from the original graph [16]. Each community represents a feature category. 
For describing the feedback of each feature category, we select 3-5 sentences in which the opinion expressions are nearest to the center of the category. Finally, we manually label the names of feature categories in accordance with the corresponding sentences and then merge the feature categories with the same name. 2.5 Generating Document of Evolutionary Requirements The feedback for each feature category implies an overall, function or quality re-quirement of the software system. However, it is critical to assess the priority and importance of feedback for software evolution. Because user satisfaction is the best indicator of a company X  X  future profits [17], it is the direct driving factor of software evolution. From an economic perspective, our decision to determine evolutionary requirements depends on the user satisfaction indexes evaluated by the feedback for software features. The satisfaction score of a software feature is defined as follows: which is a measure used in economics to show the responsiveness, or elasticity, of the quantity demanded of a good or service to a change in its price 5 . Formulated as [18], E indicates the substitutability and importance of the software in customer purchases. Introducing E d to user satisfaction evaluation emph asizes user acceptance of the tech-nions may result in so massive loss of users to reduce the software revenue. 
According to Equation (3), if the user sa tisfaction score of a software feature is greater than 0, the corresponding requirement is reusable or added, and changed oth-erwise. We compute the user satisfaction score for high frequent features mentioned in the reviews and then manually generate the document of evolutionary requirements in the light of those review sentences for each software features. Those evolutionary requirements that drive more economic gain are prioritized systematically. To demonstrate the practicality of our approach in eliciting evolutionary requirements even with large amounts of online reviews, we first introduce the data sets and set-tings. Then, we evaluate the opinion mining techniques including the identification and classification of opinions. Finally, we analyze the usefulness of the evolutionary requirements document for developers. 3.1 Data Sets and Settings As can be seen in Table 2, we used two data sets of online reviews: the packaged software of Kaspersky Internet Security 2011 3-Users (KIS 2011) from Amazon.com and the mobile application of TuneIn Radio Pro V3.6 (TuneIn 3.6) from the Apple App Store. For each testing data set, we manually labeled the potential software fea-review sentences according to the semantics of related opinions. 
The Stanford POS Tagger and parser are respectively used to tag and parse the data  X  =0.3,  X  =0.2, and  X  =0.4 are experimentally set for our approach. 
As the exact quantity demanded for determining E d is not available, we modified the evaluation model of user satisfaction in Section 2.5 by replacing E d with the price elasticity of sales rank E r . The sales rank implies the demand for a software product/ application relative to other competitors. Si nce it is observed that the association be-tween sales rank and demand approximately conforms to a Pareto distribution, the formula of E r is similar with -E d . 3.2 Evaluation of Opinion Identification As shown in Table 3, our method for opinion identification, SRPA+, outperforms SRPA in all conditions. Significantly higher recall, especially for KIS 2011 indicates that the new propagation rules work well. The improvement in precision implies that merging opinion expressions avoids one-sided identification. Note that the results of TuneIn 3.6 produced by SRPA+ are basically lower than those of KIS 2011. This is because the decreased performance of natu ral language processing techniques for dealing with more phrases and incomplete sentences in the reviews of TuneIn 3.6. 
Table 4 illustrates the results of polarity assignment using SRPA+. Clearly, the good recall reveals that the propagation performs well in discovering new sentiment words. We can observe that the precision of opinion expressions is significantly high-er than that of new sentiment words. There are two main reasons for relatively worse performance of new sentiment words in precision. First, the review data sets often have errors of spelling and grammatical structure or non-standard sentences so that automatic tagging and parsing don X  X  always work correctly. Second, the propagation rules have only the constraints of POS tags so that more ordinary words are intro-duced with the increase of the review data sets. In spite of this, our methods of merg-ing and pruning opinion expressions reduce the effect of noisy sentiment words. 3.3 Evaluation of Opinion Classification The proposed method for opinion classification is called S-GN. The baseline methods include J-Kmeans and S-Kmeans. Both are k-means clustering algorithms based on the Jaccard coefficient and the ESA similarity respectively. S-GN produces k clusters automatically. The inputs of J-Kmeans and S-Kmeans are set as the same number of clusters produced by S-GN. Table 5 shows the results of opinion classification in recall, precision and F-score. S-GN and S-Kmeans significantly outperform J-Kmeans in all conditions. S-GN has better results than S-Kmeans especially in precision. Such results imply that the ESA similarity based similarity measurement. As ESA enhances the semantic representations of texts using expanded Wikipedia concepts, it alleviates the clusters of duplicated categories. In addition, the k-means algorithm requires a priori number of clusters. It is difficult to op-timize k seeds for avoiding poor clusters. The GN algorithm produces the optimized number of clusters considering the global network topology so that it reduces the clusters containing mixed categories. 3.4 Evaluation of Generated Evolutionary Requirements Document We organized a human subjective study to evaluate the usefulness of the generated evolutionary requirements document. 50 partic ipants that have over three years expe-rience in software development were required to report the evolutionary requirements for TuneIn 3.6. We compared the generated document with participants X  reports to validate that our approach can discover requirements that were ignored by developers. 
In the first stage, the participants make decisions about requirements evolution based developers, with which more than 30% of the participants agreed. Table 7 shows the results generated by our approach. For functional requirements, developers paid more attention to key, special and value-added feat ures while users were more concerned with features should be improved or changed only when there are significant issues and bugs, for example  X  pause  X . However, developers have difficulty predicting user preferences for these features in the real world, such as  X  favorites  X ,  X  schedule  X  and  X  streaming  X . In terms of quality requirements, developers assessed the objective features for Internet Radio jective features like  X  operability  X . Consequently, user feedback can assist in determining evolutionary requirements that developers sometimes overlook. 
In the second stage, we provided the structured feedback derived from mining the reviews of TuneIn 3.6 for the participants to revise their presented evolutionary re-quirements. The most common strategy used by 76% participants is to decide the priority of feedback on each software feature by the frequency of its occurrence and its user satisfaction. The features re vised by the participants contains  X  user interface  X  in addition to those in Table 7. The ordinary satisfaction score and economic satisfac-tion score of the feature are -0.0714 and 0.0489. Intuitively, it is difficult to determine However, the economic satisfaction indicates the acceptance of a feature compared with the overall technical level in the market. Although the negative ordinary satisfac-tion score implies that  X  user interface  X  implemented in TuneIn 3.6 is lower than common user expectation with it, the positive economic satisfaction score suggests that the same is true for other competitors in the market. Even if users are not satisfied with TuneIn 3.6, they have no other better alternatives. In other words, improving  X  user interface  X  cannot significantly have positive impact on the revenue of TuneIn 3.6. Thereby, our approach argues even though a feature of the software product or application has poor ordinary satisfaction, it does not have to be changed until its economic satisfaction is negative. Determining evolutionary requirements based on economic satisfaction manifests that software evolution does not blindly pursue user interests, but rather balances the interests of users and developers. 
In addition,  X  user interface  X  is a feature relative to specific contexts of use. As Tu-diverse in terms of specific user habits. To reduce the potential risk, this type of fea-tures should only be improved when it has significantly low user satisfaction. In other research, there are techniques de veloped for eliciting requirements from on-functional and non-functional requirements of mobile devices through finding the customer requirements using their opinions ga thered from social network services [7]. Such works capture changing requirements without limited range of users and insuffi-cient expressions. However, thes e approaches mostly rely on manual content analysis. 
Cleland-Huang et al. adopt a classification algorithm to detect non-functional re-quirements (NFRs) from freeform documents including stakeholder comments [19]. One problem is that limited documents hinder identifying changing NFRs in a timely manner. Hao et al. utilize machine learning t echniques to extract the aspects of service quality from Web reviews for conducting automatic service quality evaluation [8]. Carre X o et al. adapt information retrieval techniques including topic modeling for exploring the rich user comments of mobile applications to extract new/changed re-before and after software evolution to provide instructive information for designing future systems [20]. Although these approaches initially access the validity of using automated techniques to discover software requirements, they lack the deep analysis about how user feedback influences changes in requirements. 
Our research is inspired by opinion mining techniques that make it possible to au-tomatically elicit requirements from huge volumes of user feedback data. The main-stream approaches are divided into two categories. One is to identify opinions based on word co-occurrence and grammatical structures [21-23]. Such approaches have good performance for extracting fine-grained features as well as opinions. However, the integrity of extraction rules/templates and domain knowledge have an obvious topic modeling [24-26]. While it is not hard for topic models to find those very gener-al and frequent features from a large document collection, it is not easy to find those locally frequent but globally not so frequent features [2]. This paper presented a novel approach for eliciting evolutionary requirements through analysis of online review data by integrating various techniques of SRPA+, S-GN and user satisfaction analysis including economi c factors. To conduct our research, we first accessed a broad spectrum of review da ta with complex and diverse opinion ex-pressions and then evaluated the performance of automated techniques for consolidat-ing, analyzing and structuring feedback information. Furthermore, the proposed me-thod of user satisfaction analysis assisted developers with finding a set of evolutio-nary requirements associated with the software revenue. We reported a human subjec-tive study with fifty developers, evaluating the usefulness of the evolutionary re-quirements document generated by our approach. As a result, the generated document could help developers understand why and what to evolve for future software releas-es. In particular, they were led to focus on the improvements in specific functions and quality in use that they had previously ignored. 
Future work will refine our opinion mining method to improve the performance of evaluate our approach using a broader data set from different domains. Acknowledgments. The work in this paper was partially fund by National Natural Science Foundation of China under Grant No. 61170087 and State Key Laboratory of Software Development Environment of China under Grant No. SKLSDE-2012ZX-13. 
