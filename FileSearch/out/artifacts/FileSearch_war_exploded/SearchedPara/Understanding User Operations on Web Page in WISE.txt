 Web Information System [1] (WIS) often contains hundreds or thousands of linked Web pages with structured data and operations defined on them. WIS fetches resources by Web technologies, manipulates information to accomplish business process, and provide more openness and flexibility to various end users. Let X  X  take a Web-based hospital information system used by Shanghai Renji Hospital in China for example. It contains 335 pages in its inpatient management subsystem. Each contains one to over ten operations. It X  X  easy to see that data operation similarity as well as structure similarity or presentation similarity exist among pages. Constructing Web pages manually is a repeatable work, and the maintenance is ever more troublesome. WIS requires an auto-generating of those data-driven pages. But the gap between information processing on pages and underlying data sources made that a difficult job. How to construct WIS automatically become s a challenging research field. Many methodologies contribute to that work [2] . For instance, Relationship Management Methodology [3] , Object Oriented Hypermedia Design Methodology [4] and UML based Web Engineering have been developed to support a hypermedia design process. They succeed in identifying different steps to be taken in development of Web applications, but still need users to write code for data operation processing on Web pages. Most of other methodologies like UIDE [5] , Mecano [6] , Hera [7] and template methods [9] only concentrate on data structure or presentation similarity. None of them devote in the process and semantics of user operations ev en a few did process Search implicatedly. 
There are two ways for auto-building of WIS: a top-down approach and a bottom-up one. The former generates Web pages according to user requirements and organizes persistent data according to page structures. [8] gives such an example. This method is easy to satisfy users, but cannot be applied in complex systems due to hard maintenance of persistent data caused by inevitable redundancy. It also fails to meet the situation when WIS must be built on a legacy source. The latter, mostly those hypermedia presentation methods, starts from persistent data design usually with the help of a DBMS, and then generates Web presentation of data. But it can hardly support auto-process of arbitrary user operations on Web pages since business data is organized by a database designer and often not for the convenient use of end users. 
WISE tries a trade-off method: Web pages are generated by template model which includes definitions of structured data and operations. If a data source is present, no matter it is a legacy system or not, a mapping strategy is adopted to bridge the gap between Web applications and persistent data. After all template items map to a data source, the general user operations can map to concrete operations on that data source. The operation mapping method forms a part of our WIS auto-construction framework and is used to generate operation processing code. This paper will discuss the built-in operations in WISE: Link, Search, Clear, Modify and Add. Link is defined on a sub template attribute or a component of a template instance. It X  X  used for navigation among templates. Let T be a template and Attrs(T) be the set of attributes of T, Search, Clear and Modify could be defined on two disjoint subsets of Attrs(T). One is used for receive user input and generates operation constraints and denoted by CA S/C/M . The other is used for receive output from underlying persistent data source and denoted by TA S/C/M . TA C also generates Clear candidates and TA M receives new value input by users. Add could be defined on only one subsets of Attrs(T), which is used for receive input from users and generates new instances and denoted by TA A . Because of the structure similarity between template and nested table, one could regard template as a logic view. That viewpoint makes mapping template attributes and operations to data source possible. On the other hand, data source often use DBMS to manage business data. Those data is organized according to database storage strategy, not to template scheme. So mapping template attributes and operations to data source is necessary. 
Given a template T and an attributes A of T, if A has a source D in data source M, we say D is the origin of A in M. Otherwise, A has no origin in M. If A has an origin D in M, and D can be presented as such a SQL statement: SELECT S FROM T 1 , ... ,T n (n  X  1)[WHERE W], we say A has a basic origin in M. Let OS expression in Select clause, OF M (A) be the set of tables(or views) in From clause, and OW M (A) be possible conditions in Where clause. OS M (A), OF M (A) and OW M (A) is called the original target, original range and original condition of A in M respectively. 
An attribute may have an origin but not a basic one in a data source. To find basic origins of all template attributes is a preliminary work for the operation process. Constraint 1. Given a template T,  X  o  X  {Search,Add,Modify,Clear} and  X  A  X  CA o  X 
TA o , if o could be converted to an operation on data source M, A has a basic origin in M.

The process of Link is much simpler than the rest four built-in operations. The process of Search is similar to the query conversion method describe in [11]. So the rest of this paper only presents the disposal of Add, Clear, and Modify. table in a data source. So |OF M (A i )|=1 is met. Since not all data manipulations defined on views could be executed successfully in DBMS, the following constraint is made. Constraint 2. Given a template T,  X  o  X  {Add,Modify,Clear}, and  X  A  X  CA o  X  TA o , if o could be converted to an operation on data source M, OF M (A) is a certain table.
In traditional DBMS, Insert, Update and Delete could process only a single table each time. But in WIS, users need to define operations mapping to a process on multiple tables at a same time. So the original ranges of different Add target may be different. The following steps explain in detail how to process Add operation. Step1. Arrange all attributes in TA A into m groups: the original range of each group is the same, while the original ranges of different groups are different. Step2. Let T i (1  X  i  X  m) be the original range of i-th group. Collect all Key-Foreign Key Constraints(K-FKC) among tables T 1 , ... ,T m from data source M. Generate the constraint dependency graph G M (Add): (1) For  X  T i (1  X  i  X  m), there X  X  a certain vertex V Ti in G M (Add) mapping to it. (2) If T j  X  X  foreign key references T i  X  X  key, add directed edge from T i to T j . add vertex V Tp into G M (Add) if V Tp is not in G M (Add). Add directed edge from V Ti to V Step3. If there X  X  no loop in G M (Add), insert into those tables mapping to zero in-SQL statement: INSERT INTO T i (OS M (A i1 ), ... ,OS M (A ik )) VALUES (V Ai1 , ... ,V Aik ). Repeat this step till all tables mapping to zero in-degree vertexes could be inserted. Step4. Check a p(p  X  1) in-degree vertex V T in G M (Add). T could be inserted if all tables mapping to V T  X  X  preceding vertexes have be inserted correctly. Let V Ti (1  X  i&lt;p) be such a preceding vertex. According to Step2, we know T has a foreign key FK i referencing T i  X  X  key K i . If T is the original range of j-th group {A j1 , ... ,A jk }(k  X  n), T X  X  V instance. If T X  X  not a original range of any group, V T must be a vertex added in Step2 (3). T X  X  insert scheme is [FK 1 , ... ,FK p ] and insert instance is (V FK1 , ... ,V FKp ). Repeat this step till all tables mapping to all vertexes in G M (Add) could be inserted. 
If there X  X  a loop in G M (Add), all tables mapping to vertexes in that loop couldn X  X  be inserted until at least one K-FKC on those tables is disabled. Then one could follow Step3 and Step4 to fulfill Add operation. Step1. Clear condition is generated according to input value received by CA C , while TA C will be used for receive outputs from data source. This sub process is similar to Search process except that Constraint2 sh ould be abided. We call it the preceding search of Clear operation and produce a select statement S for it. 
When a Clear map to a table X  X  deleting, the process is very simple. Is it possible to define Clear involves multiple tables? Let X  X  take Fig.1 for example. Suppose the OS M (t 2 )=B.b 2 , and OF M (t 2 )=B. The tuples of table A and B are shown in Fig.1(a) and (b). If there X  X  a join path A  X  B and the corresponding join condition is A.a 2 =B.b 1 , executing the preceding search, we X  X l get Clear candidates as shown in (c). It X  X  easy to see that not every candidate could map to a unique tuple of A or B, and vice versa. 
When one candidate is mapping to multiple tuples of a single table, template instance clear brings on the uncertainty in tuple delete. For example, (3,8) of T shown in (c) may be generated from the join of (3,4) in A and (4,8,1) in B or (4,8,2) in B. If (3,8) is cleared, shall we delete only (4,8,1) or (4,8,2), or delete them both? That problem is caused by the filtering of duplicate tuples in query result in DBMS. The next Step will make some addition into the process of preceding search to avoid it. contains T i  X  X  key. If not, add one key into TS compulsively. Or add the rest attributes of T i which haven X  X  belonged to TS in case there X  X  no key defined on T i .
 Step3. Execute statement S or the evolved statement generated by Step2. Project query result on all attributes in TA C without filtering of duplicate tuples. Now we get clear candidates on T. As shown in Fig.5(d), one could regard a (3,8) is generated from the join of (3,4) in A and (4,8,1) in B, another from the join of (3,4) and (4,8,2). (1  X  i  X  k), v But when multiple candidates map to a single tuple, instance clear also brings uncertainty on tuple delete. Consider (1,6) and (1,5) of T, they all map to (1,2) in A. If users only clear (1,6) or (1,5), shall we delete (1,2) from A? If we do so, another instance will never be seen in T. If we don X  X , the clear instance exists still. Constraint 3. Given a template T, its Clear operation could be converted to delete operation on data source M if there X  X  only one table in original range of its preceding query, or, let the set of clear instances be V C and the set of clear candidates be VC C , for  X  v 1  X  V C and  X  v 2  X  (VC C -V C ), v 1 and v 2 are generated from different tuples. Step4. Check if Constraint3 is met. If so, the clear instances in V C could be converted DELETE FROM T i WHERE K i IN= {v 1i (K i ), ... ,v ni (K i )}. 
Some tables may be added into original range because of the involvement in certain join paths. For example, the join path between table A and B in Fig.1 would be A  X  C  X  B instead of A  X  B and the corresponding join condition be A.a C.c 2 =B.b 1 . Therefore, C is added into the original range of preceding query. But no there X  X  K-FKC between A and C and ON DELETE CASCADE option is used in the constraint definition, referenced tuple delete from A would trigger referencing tuple delete from B. That process will be auto-executed by DBMS. Modify is also taken on the result of a preceding search. In order to support Modify mapping to updates on multiple tables, tuple update uncertainty is eliminated by the same method described in Clear when one candidate mapping to multiple tuples. But when multiple candidates map to a single tuple, Constraint3 is inadequate to eliminate the uncertainty. Let X  X  consider (1,6) and (1,5) in Fig.1(d). They all map to (1,2) in A. Constraint3 ensures (1,6) and (1,5) will either be updated simultaneously or not be updated at all. But even if they are updated simultaneously, one may change (1,6) to (3,6) and (1,5) to (5,5). The update sema ntics on (1,2) wouldn X  X  be consistent. Constraint 4. Given a template T, Modify could be converted to update operation on data source M if there X  X  only one table in original range of its preceding query, or, let VC M , v 1 and v 2 are generated from different tuples. 
In the conversion of Modify to update on data source M, the first three steps are similar to that of Clear. The last step is presented as the following: Step4. Let the set of Modify instances be V M ={v 1 , ... ,v n }(n  X  1). Let all attributes for v j T key. Let user input value on A jo (1  X  o  X  m) in v j be New(v j (A jo )). Now check if Constraint4 is met. If so, the instance Modify in V M could be converted to tuple updates on all tables in {T 1 , ... ,T k }. As for  X  T i (1  X  i  X  k), the SQL statement is: UPDATE T i SET OS M (A 11 )=New(v 1 (A 11 )), ... ,OS M (A 1m )=New(v 1 (A 1m )), ... , 
WHERE K i IN={v 1i (K i ), ... ,v ni (K i )}; In WISE, those built-in operations are converted successfully to data source managed by DBMS. WISE also provides a set of visual tools [10] to define data structure, mapping, user operation, etc. WISE can transform those definitions to executable code under the restriction of operation semantics and fulfill database access. 
There are many works to be done in the future, such as the expression of complex conditions for operations on Web pages, the support of user defined operations, dynamic operation modification, etc. 
