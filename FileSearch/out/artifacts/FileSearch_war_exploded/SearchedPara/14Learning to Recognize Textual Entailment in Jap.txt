 MINH QUANG NHAT PHAM, MINH LE NGUYEN, and AKIRA SHIMAZU, Recognizing Textual Entailment (RTE) is a fundamental task in Natural Language Understanding. It has been proposed with the aim of building a common applied se-mantic framework for modeling language variability [Dagan et al. 2006]. Given two text portions T (text) and H (hypothesis), the task is to determine whether the meaning of H can be inferred from the meaning of T.

RTE can potentially be applied in many NLP tasks, such as question answering or text summarization. Applications of RTE have been reported in several studies: question answering [Harabagiu and Hickl 2006] and information extraction [Romano et al. 2006]. In these studies, RTE has been integrated as an important component. For instance, in question answering [Harabagiu and Hickl 2006], an RTE component was used to determine if a candidate answer is the right answer for a question or not. Recently, RTE tasks have received much attention in NLP research community. There have been several RTE shared tasks held by the TAC conference [Bentivogli et al. 2009] and many dedicated RTE workshops. However, to our knowledge, most published articles on RTE are for English, and only a very few are for other languages. It may be due to the fact that performance of state-of-the-art RTE systems signifi-cantly depends on RTE resources such as evaluation data, WordNet, or database of inference rules, which have been mainly developed for English. Studies of RTE for other languages rather than English are useful, because for a specific language, there are language-specific linguistic phenomena which we need to take into account.
In this article, we conduct an investigation of a machine learning approach to RTE task for Japanese. We build a lightweight RTE system that is based on machine learn-ing. We formalize RTE task as a binary classification problem and apply machine learning algorithms to combine entailment features extracted from each pair of text T and hypothesis H. We evaluate our system using benchmark data sets from NTCIR9 RITE workshop [Shima et al. 2011] X  X he first attempt of constructing a common bench-mark for evaluating systems which automatically detect entailment, paraphrase, and contradiction in texts written in Japanese. This work is an extension of previous work in Pham et al. [2011, 2012].

The use of bilingual corpora and machine translation for RTE tasks has been ex-plored in the cross-lingual textual entailment recognition task [Mehdad et al. 2010, 2011] which is the task of recognizing textual entailment relationships between two text portions in different languages. Different from Mehdad et al. [2010, 2011], in this study, machine translation is used for monolingual RTE. In our system, a machine translation component is used to produce English translations of original Japanese texts, and both original Japanese texts and their translations are used to learn an entailment classifier. Our method is based on a reasonable assumption that if T en-tails H, then the translation of T should also entail the translation of H. Although to the best of our knowledge, state-of-the-art machine translation systems perform much worse than human translators, our method of using machine translation for Japanese RTE has some advantages. First, we can utilize RTE resources and tools for English languages, which are not available for Japanese. Second, some semantic relations of Japanese words which cannot be recognized due to the limitation of semantic resources in Japanese, may be recognized in English translations. We expect that English trans-lations of a text and a hypothesis can provide more useful features for the RTE system to determine the entailment relationship in the pair more correctly. Pham et al. [2011, 2012] did not investigate how the performance of the RTE system changes if different MT engines are used. In this article, we present experimental results with two popular MT engines: Google Translator and Bing Translator.

Generally, in a machine-learning-based framework, there are two main elements which need to be considered: features and machine learning algorithms. These two aspects are extensively analyzed in this article. Especially, in order to improve the accuracy of the system, we apply several ensemble learning algorithms which train multiple classifiers and combine their outputs. In experiments, we adopt two ensem-ble learning approaches: bagging [Breiman 1996] and boosting [Freund and Schapire 1996]. Experimental results showed the performance improvement although the im-provement is moderate because of the nature of training data and extracted features.
In short, the main contributions of our article are as follows.  X  The article investigates a machine learning approach to recognizing textual en-tailment in Japanese. The effects of entailment features and machine learning algorithms on the performance of our Japanese RTE system are extensively ana-lyzed. Experimental results showed that our proposed method significantly outper-forms baseline methods using lexical matching and syntactic matching.  X  We analyze the impact of various resources on the performance of our RTE system by conducting ablation tests.  X  In our study, we propose using machine translation to improve the performance of our Japanese RTE system. Experimental results indicated the effectiveness of using machine translation for RTE on Japanese data sets.

The remainder of the article is organized as follows. Section 2 presents some re-lated work to our research. Section 3 briefly presents background on two approaches to RTE and ensemble learning methods in machine learning. In Section 4, we describe our machine learning-based RTE system. Section 5 gives experimental settings and Section 6 presents experimental results achieved on two Japanese RTE data sets. In Section 7, we discuss hard phenomena observed in Japanese RTE data sets. Section 8 discusses approaches to Japanese RTE presented at NTCIR9-RITE. Finally, Section 9 gives conclusions and some remarks. Mehdad et al. [2010] proposed the cross-lingual textual entailment (CLTE) task where text T and hypothesis H are written in different languages. A basic solution for CLTE task was proposed, in which a machine translation (MT) system is added to the front-end of an existing RTE engine. For instance, for a pair of English text and Spanish hypothesis, the hypothesis will be translated into English and then, the RTE engine will be run on the pair of the text and the translation of the hypothesis. This approach has advantages in terms of modularity but suffers from the error propagation caused by the MT component [Mehdad et al. 2011]. Another limitation of the basic solution is that it reduces the possibility to control the behavior of the RTE engine because of unpredictable errors propagated from the MT system.

Mehdad et al. [2011] proposed a new method for the CLTE task, which takes advan-tages of bilingual parallel corpora by extracting information from the phrase-table to enrich inference and entailment rules, and using extracted rules for a distance-based entailment system. The use of bilingual parallel corpora for monolingual textual en-tailment was also explored. The main idea of that work is to increase the coverage of monolingual paraphrase tables by extracting paraphrases from bilingual parallel corpora and use extracted paraphrases for monolingual RTE. The proposed method in Mehdad et al. [2011] allows a tighter integration of MT and RTE algorithms and avoids any dependency of external MT components.

Different from previous work mentioned above, our approach makes use of machine translation for monolingual RTE in a machine learning-based framework. In our ma-chine learning-based RTE system, we combine both features extracted from data in original language and features extracted from translation data which were produced by an MT component to learn an entailment classifier. The main advantage of our pro-posed method is that it can make use of variability of words/phrases via translation. Several methods compute semantic similarity between the text T and the hypothesis H and decide if entailment relationship exists in the pair T/H by comparing the similarity score with a manually chosen threshold. For example, the pair T/H is decided to be an entailment pair if the similarity of T and H is equal or greater than a threshold. Text similarity between the text and the hypothesis can be computed based on surface or syntactic representations. For instance, one can use word overlap or count the number of common edges of dependency parses derived from T and H. For a more complete survey of text similarity measures used in RTE task, see Androutsopoulos and Malakasiotis [2010].

Similar to text similarity, distance between the text T and the hypothesis H can be used to decide the entailment relation of the pair T/H. Edit distance of the pair T/H is defined as the cost of the edit sequence (string or tree edits) needed to transform T into H. The intuition is that the smaller the edit distance between T and H is, the more likely that T entails H. Several methods that apply string edit distance [Levenshtein 1966] or tree edit distance [Zhang and Shasha 1989] have been reported [Kouylekov and Magnini 2005]. In these methods, the RTE task has been formulated as a classification problem. Mul-tiple entailment features extracted from each pair T/H are combined using machine learning methods [Malakasiotis and Androutsopoulos 2007]. Features may be similar-ity measures applied on the pair or other features such as polarity difference between TandH. Ensemble learning involves the procedures employed to train multiple learning ma-chines and appropriately combine their outputs in order to obtain better prediction performance [Brown 2009; Dietterich 2000]. The principle of ensemble learning is that on average, committee decision should have better overall accuracy than individ-ual predictions.

In our case, we applied ensemble learning methods for the binary classification prob-lem. Specifically, we adopted three common ensemble learning algorithms: bagging [Breiman 1996], random forest [Breiman 2001], and AdaBoost [Freund and Schapire 1996]. 3.3.1. Bagging. In the bagging (Boosting Aggregating) algorithm [Breiman 1996], each member classifier of the ensemble is constructed from a different training dataset, and the predictions are combined either by uniform averaging or voting over class la-bels. Each training dataset is created by uniformly sampling the total N data examples in the original training data set.

Similar to many ensemble methods, the base models in bagging methods should be unstable models which produce different behaviors with small changes to training data. In experiments, we choose Ripper rule learners [Cohen 1995] as base models. We also tried the random forest method [Breiman 2001] which combines the bagging algorithm with random subspace method [Ho 1998]. 3.3.2. AdaBoost. The AdaBoost algorithm, short for adaptive boosting, introduced by Freund and Schapire [1996] has been seen as an effective boosting algorithm. In this section, we briefly describe the AdaBoost algorithm.

The input of the algorithm is a training set ( x 1 , y 1 ) , ..., ( x m , y m ) where each x i be-Y = { X  1 , +1 } . AdaBoost calls a given weak (base) learning algorithm repeatedly in a number of rounds t =1 , ..., T . There are weights associated with data examples x i in the training set. At the beginning, all weights are set equally. The main idea of AdaBoost is to add one classifier on each round. Each new classifier is constructed by a learning algorithm so that the classification error on the weighted training data set is minimized. In order to achieve that, weights of data examples are updated on each round. Specifically, on each round, weights of incorrectly classified data examples are increased so that the base learner focuses on hard examples which are misclassified by previous classifiers.

Although, the actual performance of AdaBoost on a particular problem is dependent on data and the chosen weak learner, the algorithm has shown its advantages in sev-eral studies [Bauer and Kohavi 1999; Freund and Schapire 1996]. In experiments, we used  X  X ecision stumps X  [Dietterich 2000] as weak learners. In our article, we adopt the machine learning approach to building an RTE system. The RTE task is formulated as a binary classification problem in which each instance consists of a pair of a text T and a hypothesis H.

In this section, we describe our RTE system. The RTE system is divided into five main modules as shown in Figure 1: bilingual enrichment, preprocessing, feature ex-traction, training, and classification.

First, each Japanese pair T/H is automatically translated into English using an MT engine. Then, in preprocessing, both the Japanese pair and its associated translation pair are analyzed. After that, extracted features from the pair and its translation pair are input to an entailment classifier to determine if the entailment relationship exists in the pair or not. The entailment classifier is trained on the training set consisting of pairs T/H with their gold labels.

In experiments, we investigate several machine learning algorithms for the RTE task: support vector machines (SVMs) [Vapnik 1998]; maximum entropy model [Berger et al. 1996]; and three ensemble learning algorithms: bagging [Breiman 1996], random forest [Breiman 2001], and AdaBoost [Freund and Schapire 1996]. In order to make use of the bilingual constraint for RTE, the original RTE corpus in Japanese is automatically translated into English using Google Translator Toolkit 1 .In experiments, we try Microsoft Bing Translator 2 and compare the overall accuracy with the accuracy when we use Google Translator in the Bilingual Enrichment module. 4.2.1. Japanese Pairs. We use Cabocha tool [Kudo and Matsumoto 2002] for data pre-processing. For each pair, preprocessing consists of tokenizing, chunking, named entity recognition, and dependency parsing. Parsed content of each sentence is represented in XML format. 4.2.2. English Pairs. Each Japanese T/H pair in our corpus is associated with its English translation. We use Stanford-CoreNLP tool to perform preprocessing for En-glish pairs 3 . Stanford-CoreNLP provides a set of fundamental natural language pro-cessing tools which can take raw English text input. At lexical level, we use the tool to perform tokenization, lemmatization, part-of-speech tagging, and named-entity recog-nition. At syntactic level, dependency parsing is done. In the system, we train an entailment classifier on the training set consisting of an-notated pairs T/H. Each pair T/H is represented by a feature vector f 1 , ..., f m which contains multiple similarity measures of the pair and some other features. For each training instance consisting of a pair T/H, features are extracted from both the orig-inal pair in Japanese and its associated English translation pair. In this section, we describe features used in the entailment classifier. 4.3.1. Similarity Features. A large part of the similarity features used in the entailment classifier is similar to features used in Malakasiotis and Androutsopoulos [2007]. We use different kinds of text similarity/distance measures applied on each pair T/H and its English translation pair. These measures capture how H is covered by T.
For each pair T/H (Japanese pair or English translation pair), text similarity and distance measures are applied on two pairs as follows.  X  Pair 1 is two sequences of words of T and H in surface forms. Punctuations and special characters are removed. Stop words are removed for English pairs.  X  Pair 2 is two sequences of words in T and H in base forms. Punctuations and special characters are removed. Stop words are removed for English pairs.

The preceding two pairs are representations for T and H when we compute similar-ity features.

We give a brief description of similarity features which are used to train the entail-ment classifier as follows.
 lap between T and H, which is a score based on matching each word in H with some words in T [Dagan et al. 2007]. Japanese WordNet [Isahara et al. 2008] 4 and English WordNet [Fellbaum 1998] are used in computing lexical matching. The matching cri-terion for two English words is the same as in Dagan et al. [2007]. An English word h w in H is considered a match with an English word t e w in T if one of the following holds.  X  h e w has the same surface or base form with t e w .  X  h e w is a synonym of t e w .  X  Hypernym or meronym distance from t e w to h e w is not greater than 3.
For Japanese, a word h w in H is considered as a matching word of a word t w in T if they have the same surface or base form, or h w is hypernym, meronym, or entailment word of t w . 5 tis and Androutsopoulos 2007] of two strings is the minimum number of edit operations needed in order to transform a string to the other one. Allowable edit operations are deletion, insertion, or substitution of a single token. In our system, the Levenshtein distance from T to H is computed. We consider words as the smallest units when computing Levenshtein distances.
 machine translation [Papineni et al. 2002]. It measures how a translation generated by an MT system is close to reference translations. The main idea is to compute n -gram matching between automatically generated translations and reference translations. In the RTE problem, we used BLEU precision of H and T based on uni-gram, 2-gram, and 3-gram. In our case, we want to measure how the Text T subsumes the Hypothesis H, so T is cast as the reference translation and H is cast as the candidate translation. We used both BLEU measure and modified n -gram precision.
 the longest common subsequence string between T and H [Hirschberg 1977]. The LCS feature is normalized by dividing its value by the length of H.
 where X and Y are the sets of unique words of T and H, respectively; | X | denotes the number of elements in the set | X | .
 where X and Y are the same as in the Jaccard Coefficient measure.
 y = y 1 , ..., y n in an n -dimensional vector space is defined as the following.
Similar to Malakasiotis and Androutsopoulos [2007], in our case, n is the number of distinct words that occur in T and H; and x i , y i show how many times each one of these distinct words occur in T and H, respectively.
 In this case, x and y are defined the same as those in the previous measure. similarity between two strings. It is a variant of the Jaro distance metric.
The Jaro distance d j of two given strings s 1 and s 2 is computed by the equation. where | s 1 | and | s 2 | are lengths of two strings s 1 and s 2 , respectively and m is the num-ber of matching characters. Two characters from s 1 and s 2 are considered matching transpositions is the number of matching characters in different sequence order.
The Jaro-Winkler distance d w is defined as the following. where is the length of the longest common prefix of s 1 and s 2 ,and p is a constant scal-ing factor which controls how much the score is adjusted upwards to having common prefixes.
 y where x and y are binary vectors; x denotes the norm of the vector x .Ele-ments x i and y i indicate whether or not the corresponding word occurs in T or H , respectively. 4.3.2. Entailment Probability. The entailment probability that T entails H is computed based on the probabilistic entailment model in Glickman et al. [2005]. The main idea is as follows. The probability that the entailment relationship exists in the pair, P ( H | T ) is computed via the probability that each individual word in H is entailed by T. The probability P ( H | T ) is computed by the following equation.
 where the probability P ( h j | T ) is defined as the probability that the word h j in H is entailed by T. The probability P ( h j | T ) is computed by the following. where t i isawordin T .

In Equation (9), P ( h j | t i ) can be interpreted as the lexical entailment score between words t i and h j . By this decomposition, the overall probability P ( H | T ) is computed by the following equation.
 The lexical entailment score of two words w 1 and w 2 is computed by using the word similarity score between them. For English, lexical entailment scores are computed based on Levenshtein distance as in MacCartney [2009].
 where dist ( w 1 ,w 2 ) is Levenshtein distance of two words w 1 and w 2 .
Different from English, a Japanese word may be comprised of characters in differ-ent character systems. Furthermore, the length of a Japanese word in term of charac-ters is short, so it is not reasonable to use the Levenshtein distance of two Japanese words based on their characters. Therefore, we use the Japanese thesaurus, Nihongo goitaikei [Ikehara et al. 1997] to compute the similarity of two Japanese words. 4.3.3. Dependency Relation Overlap Features. Dependency relation overlap has been used in paraphrase identification [Wan et al. 2006]. For RTE task, we compute the dependency relation overlap of H and T by the following equation: where relations ( s ) denotes the set of head-modifier relations of the sentence s .
In English, a head-modifier relation of a sentence is defined as a triple of a head word, modifier word and their relation type extracted from the dependency parse of the sentence. In Japanese, a head-modifier relation of a sentence is a pair of two words or two  X  X unsetsu X  segments, one of which depends on the other. 4.3.4. Named-Entity Mismatch. In a pair T/H, if the hypothesis contains a named en-tity which does not occur in the text, the text may not entail the hypothesis. We use an indicator function  X  to compute the named-entity mismatch feature of T and H:  X  ( T , H ) = 1 if H contains a named-entity that does not occur in T and  X  ( T , H )=0, otherwise. We compute named-entity mismatch for both Japanese pairs and their as-sociated English translation pairs. 4.3.5. Polarity Mismatch. The polarity mismatch in a pair T/H may indicate that T does not entail H. We compute polarity mismatch in a pair T/H using the Polarity Weighted Word List [Takamura et al. 2005]. In that list, each Japanese word is associated with a weight that indicates whether the word has positive meaning or negative meaning. We use an indicator function to capture if words in the root nodes of dependency parses of T and H have opposite polarity. The polarity mismatch is applied only on Japanese pairs. The NTCIR9 RITE workshop [Shima et al. 2011] provided benchmark data for several Japanese RTE subtasks: binary-class subtask (BC subtask), multi-class subtask (MC subtask), Entrance Exam subtask (Exam), and RITE4QA subtask. In order to eval-uate our system, we use data sets of BC subtask and Entrance Exam subtask. The BC subtask is the basic problem setting of RTE which is to determine whether the meaning of a hypothesis H can be inferred from the meaning of a text T. The Entrance Exam subtask is the same as BC subtask in terms of input and output, but data set of Entrance Exam subtask are created from actual college-level entrance exams. There-fore, data of Entrance Exam subtask may be closer to real-world data than those of the BC subtask. The RITE4QA subtask is the same as BC Subtask and Exam subtask in terms of the form of input and output, but the subtask aims to measure the impact of RTE to a Question Answering system. The test set of RITEQA was automatically created toward that purpose. In this study, we evaluate the performance of our RTE system as an independent RTE system, so we do not use the test set of RITE4QA for evaluation. Another reason why we do not use the test set of RITE4QA is that the test set of RITE4QA is quite noisy, namely a Y label does not necessarily represent an entailment between two text segments.
 A development set and test set are provided for the BC subtask and the Entrance Exam subtask. Each data set consists of pairs T/H along with their gold-standard la-bels  X  X  X  or  X  X  X . For each subtask, we train an entailment classifier on the development portion and evaluate the trained classifier on the test portion. Table I shows statistical information of each data set. In experiments, classification accuracy and average F1 score are used to evaluate RTE methods. The F1 score for each label (Y or N) is computed as follows.
 In our case, the average F1 score is the average on F1 scores of two labels Y and N.
Since the label distribution in the test sets of the Exam subtask is unbalanced, the average F1 score is a better evaluation measures than classification accuracy for the Exam subtask. In our machine learning based RTE framework, any machine learning algorithms can be used. In experiments, we investigate several machine learning algorithms for the task.

The first machine learning method used in experiments is support vector machines, which is a robust method for classification problems. We used libSVM [Chang and Lin 2011], an efficient SVM tool for classification problems. The second machine learn-ing algorithm is maximum entropy model (MEM) [Berger et al. 1996]. We used the Maximum Entropy Modeling Toolkit (maxent) 6 for experiments.
 In order to analyze effects of ensemble learning methods for the RTE task, we used Weka tool [Hall et al. 2009], an open source machine learning and data mining suite. Parameters in bagging, random forest and AdaBoost algorithm are selected by per-forming five-fold cross-validation on the development set of each subtask. When we apply Bagging algorithm, we choose JRip, which is an implementation of RIPPER rule learner [Cohen 1995] as the base learner. The number of iterations in the bagging algorithm and the number of trees used in the random forest algorithm are tuned by performing five-fold cross-validation on the training set.

When we applied AdaBoost, we used  X  X ecision stumps X  [Dietterich 2000] as weak learners. The only parameter of AdaBoost algorithm we need to tune is the number of iterations. 5.4.1. Local Lexical Matching Method (LLM). A trivial baseline for the task is to randomly choose a label for each pair. In experiments, we use a stronger baseline which is based on local lexical matching between T and H. Lexical matching score computed on each Japanese pair is compared with a threshold value tuned on the development portion of each data set. 5.4.2. Predicate-Argument Matching Method (PA-matching). The second baseline which we use in experiments is the PA-matching method [Shibata and Kurohashi 2011]. The PA-matching method is based on matching text and hypothesis, considering predicate-argument structure as a basic unit of handling the meaning of text/hypothesis. In this method, wide-coverage relations between words/phrases were utilized in matching a text and a hypothesis. We refer to the predicate-argument matching as PA-marching. 5.4.3. Two-stage Method. The main problem of the PA-matching method comes from parsing error, the lack of lexical knowledge, and world knowledge. Therefore, Shibata and Kurohashi [2011] also proposed a  X  X wo-stage X  method. The main idea of the  X  X wo-stage X  method is as follows. First, the PA-matching method is applied. If  X  X  X  label for binary-class subtask is obtained, then the result is selected; otherwise an SVM-based method which considers shallow features such as overlap ratio of characters and morphemes is applied. Experiments in the current study are conducted to answer questions as follows.  X  First, we determine whether the machine translation component which incorporates extracted features from English translation pairs can be utilized to improve the system performance of the Japanese RTE system. We also investigate how different
MT engines affect the system performance.  X  What features are effective for Japanese RTE data?  X  How do various RTE resources such as Japanese WordNet, Polarity Weighted Words
List, or Nihongo goitaikei affect the system performance?  X  What is the effectiveness of ensemble learning methods on the performance of our
Japanese RTE system?  X  In this study, we analyze the main linguistic phenomena in Japanese RTE data sets that need to be considered. In Pham et al. [2011], we previously presented the official runs of our team at NTCIR9-RITE [Shima et al. 2011]. We submitted three runs for the BC subtask as follows.  X  Run 1 (SVM bi) used libSVM [Chang and Lin 2011] as the machine learning tool and all features extracted from original Japanese pairs and their associated English translation pairs. We tuned parameters for learning on the development set by using the parameter selection tool in the libSVM package.
  X  Run 2 (SVM mono) used libSVM as the machine learning tool and monolingual fea-tures extracted from the original Japanese pairs. We compare the result obtained in Run 2 with the result of Run 1 to see if bilingual constraints can improve the performance of the system.  X  Run 3 (MEM mono) used Maximum Entropy Model as the machine learning tool and monolingual features extracted from original Japanese pairs.

For the Exam Subtask, we submitted results obtained by SVM bi, SVM mono, and the method based on lexical matching (LLM). The submitted models are learned by using the development portion provided for each subtask. For the Exam subtask, we added tree edit distance measures [Kouylekov and Magnini 2005] applied on T/H pairs in feature extraction.

Tables II and III, respectively, show official results of our team at NTCIR9-RITE on the BC subtask and the Exam subtask.

Although our RTE system is very lightweight and does not require deep semantic analysis, among participated teams at NTCIR9-RITE, our proposed system (SVM bi) obtained the first rank in BC subtask and the median rank in the Exam subtask [Shima et al. 2011]. In the current article, we modified the feature extraction module. Specifically, tree edit distance is not used in the Exam subtask 7 and minor bugs in word matching are fixed.
Experimental results achieved on test sets of the BC subtask and the Exam subtask are shown on Tables IV and V, respectively.

For each machine learning algorithm applied in our framework, we run the system in two settings. In the first setting, we use only monolingual features extracted from Japanese pairs for training and testing. In the second setting, we use all features extracted from both original Japanese pairs and their associated English translation pairs. In Tables IV and V, the numbers in parentheses represent the performance improvement when all features are used.
 Compared with results in Pham et al. [2011], the accuracies of the SVM mono, SVM bi, MEM mono slightly decrease on BC subtask. However, the accuracy of SVM bi on the Exam subtask is significantly improved. The reason for this may be that in this current article, we do not use features derived from tree-edit distances which did not show their advantages in system development, especially in the Exam subtask.
In the BC subtask, our proposed machine learning-based methods significantly out-perform three baselines. Especially, we obtained the best accuracy when we use bag-ging algorithm with all features (accuracy of 58 . 6%).

In the Exam subtask, combining SVM with all features results in the best perfor-mance (accuracy of 69 . 2%). However, ensemble learning methods did not show their effectiveness on the test set of the Exam subtask. Tables IV and V show that generally, for each machine learning algorithm, using bilin-gual features results in better performance than using only monolingual features.
The effect of using bilingual features on the Exam subtask is more significant than in the BC subtask. A possible explanation for this result is that in the BC subtask the data was created so that simple surface overlap does not result in Y or N label easily [Shima et al. 2011]. The performance of the baseline using word overlap shows the evidence for our claim. It obtained low classification accuracy on the BC subtask (accuracy of 49%) while on the Exam subtask, it obtained quite good accuracy (accuracy of 62.2%).

In order to analyze the sensitivity of overall system performance to the machine translation component used in the system, in experiments, we tried two popular MT engines; Google Translator and Microsoft Bing Translator. Table VI shows results in two subtasks when different MT engines are used. In Table VI, the numbers in the parentheses represent the difference in term of accuracies when Microsoft Bing Trans-lator are used. The results indicate that the system performance is sensitive to the MT engine used, especially on the Exam subtask. On average, using Google Translator in the bilingual enrichment component has achieved better results. However, it is dif-ficult to conclude that using  X  X etter X  MT engines always results in a better overall system performance. In the current study, we investigated several machine learning algorithms for the RTE task. Experimental results on Tables IV and V show that methods which apply support vector machines and maximum entropy models obtain more stable performance than ensemble learning methods. In the Exam subtask, using the SVM method with all features obtained the best performance among methods.

The results also indicated that ensemble learning methods show moderate perfor-mance improvement. In the BC subtask, using bagging algorithms with all features obtained the best performance among methods. However, using ensemble methods did not show performance improvement in the Exam subtask. This result might be related to the significant dependence of performance of ensemble learning methods on data sets and features used for each subtask. Tables VII and VIII show confusion matrices of the BC test and the Exam test, re-spectively. We compare the number of false-positive pairs and false-negative pairs pre-dicted by some methods on the test set of each subtask. False-positive pairs are pairs which are predicted as  X  X  X  pairs by a system while in gold standard, they are  X  X  X  pairs. False-negative pairs are pairs which are predicted as  X  X  X  pairs by a system while in gold standard, they are  X  X  X  pairs.

Analyzing false-positive pairs predicted by methods SVM bi and SVM mono, we see that false-positive pairs mainly come from  X  X  X  pairs in which H is highly covered by T in terms of lexical, such as pair 15 in Figure 2. Among true-entailment pairs which our systems do not correctly classify, many pairs use complex entailment or paraphrase rules, such as pair 148 shown in Figure 2. Therefore, a large paraphrase table of phrases and a database of entailment rules may be important in order to improve the classification accuracy of the system.

In the BC subtask, the difference between using monolingual features and using all features is not so significant. On the other hand, in the Exam subtask, features derived from English translation pairs show significant contribution to performance of the system. As shown in Tables VII and VIII, the number of false-negative pairs predicted by SVM bi is less than the number of false-negative pairs predicted by SVM mono. It may indicate that the MT component used in SVM bi provides more evidences for detecting entailment relationship in  X  X  X  pairs through translation. Pair 243 in BC X  X  test set and pair 12 in Exam X  X  test set in Figure 2 show two examples in which SVM bi correctly predicts their entailment labels while SVM mono does not. A possible explanation is that in pair 243, the synonym relation between two English words  X  X ousewives X  and  X  X ives X  can be recognized by using English WordNet while the relation between corresponding Japanese words was not detected by using Japanese WordNet. In pair 12, the English translation pair may strengthen the entailment  X  X vidence X  in the pair with its high word overlap score. We conduct feature analysis in order to understand impacts of features on the perfor-mance of machine learning-based RTE systems.

We divide the features set into three categories as follows.  X  LemmaSim consists of similarity features computed on base (lemma) form of each pair T/H.  X  SurSim consists of similarity features applied on surface form of each pair T/H.  X  SynSem consists of other features: entailment probability, dependency relation overlap feature, named-entity mismatch and polarity mismatch features.

Entailment classifiers are trained using above features subsets and a combination of them on the development sets. Table IX shows accuracies of various settings on the test sets of two subtasks. In Table IX, the numbers in the parentheses represent differences between settings and the system using all features.

Feature analysis indicated that similarity features significantly contribute to the performance of RTE systems. As shown in Table IX, without using similarity features (in the group LemmaSim and SurSim), the accuracies of SVM bi and SVM mono de-crease significantly.

Similarity features applied on surface form of each pair T/H and its English transla-tion (in the group SurSim) are important in both subtasks. The contribution of features in the SynSem group to the performance of SVM mono method is not so significant in both subtasks. However, the contribution of SynSem features is significant to the per-formance of SVM bi method in the Exam subtask. In the RTE task, it is interesting to know how additional resources or components con-tribute to the performance of our Japanese RTE system. This section presents ablation tests for two subtasks. We only analyze the effects of RTE resources and components to the SVM mono method to avoid unpredictable errors propagated from the machine translation component.

We conduct ablation tests as follows. For each test, we remove one or some resources used in the system. Features corresponding to an ablated resource will be omitted or only be changed depending on whether they are directly derived from the resource or not. Table X shows features corresponding to each ablated resource.

Table XI provides accuracies of the SVM mono method without using some re-sources. The percentages shown in Table XI shows the accuracies of SVM mono method without using some resources. the numbers in parentheses represent the dif-ference of each setting with the system using full resources in terms of classification accuracies. As indicated in the table, the impact of additional resources on the perfor-mance of our system is not so significant in the Exam subtask. A possible explanation for this result is that word overlap of true-entailment pairs in data sets of the Exam subtask is very high.

The contribution of semantic resources is significant in BC subtask. It may be re-lated to the way the data sets of BC subtask are created. Data sets of the BC subtask were created so that simple surface overlap does not result in Y or N label easily [Shima et al. 2011]. Therefore, we need to incorporate more semantic resources such as paraphrase corpora or world knowledge in order to improve the accuracy of RTE system in the BC subtask. This section discusses entailment phenomena in the RTE corpus. We have observed the data and tried to classify the linguistic phenomena of textual entailment. We distinguish true-entailment pairs and false-entailment pairs. Table III shows some examples of T/H pairs in the BC-subtask X  X  development set. 7.1.1. World Knowledge-Based Inference. In order to determine the label for a pair in this type, world knowledge is indispensable. In the pair, we cannot make a decision based on only textual evidences conveyed in the text and the hypothesis. For instance, in the pair 26 shown in Figure 3, we cannot determine whether the text entails the hypothesis if we do not know that the person called Oyama Nobuyo is a woman. 7.1.2. Inference Based on Paraphrasing and Entailment Words/Phrases. In pairs of this type, the decision can be made based on paraphrasing phrases or entailment words. For instance, in the pair 25 (Figure 3), it uses paraphrasing phrases pair,  X  X aptured the heart of the public X  and  X  X ttracted the public. X  7.1.3. Hypotheses Are Facts Extracted from Texts. In a pair of this type, information con-veyed in the hypothesis is a fact which can be extracted from the text. An example is the pair 496 as shown in Figure 3.
 7.2.1. Negation Structure. In a pair of this type, the hypothesis may use negation struc-tures, and the meaning of the hypothesis contrasts with the meaning of the text. An example is the pair 188 as shown in Figure 3. 7.2.2. Hypothesis Discusses an Aspect of a Topic, Which Is Not Mentioned in the Text. In the pair 206 (Figure 3), the text said that human being could understand language. How-ever, the hypothesis said that human being was the only animal that can acquire lan-guage, which is not mentioned in the text. 7.2.3. Factuality Degree of a Statement. In the pair 17, the hypothesis is completely covered by the beginning statement of the text, but the remaining part of the text inverses the veracity of the statement. 7.2.4. Wrong Inference. In pairs of this type, there are inferences that are not nec-essarily true. For instance, in the pair 357 (Figure 3), the text said that the average income in Japan was higher than that in England, but it is not necessarily true that Japanese people are happier than English people.

Textual entailment phenomena which were discussed above indicated that the BC subtask X  X  data sets have very complicated nature, and extensive encoded world knowl-edge in the machine-readable form is indispensable for the RTE task. Textual entailment recognition is not new in the field of NLP, but for the Japanese lan-guage, NTCIR9-RITE is the first shared-task in RTE. There are two main approaches to the RTE task in participant groups. The first approach tries to recognize entailment relation in a pair based on matching constituents of the text and the hypothesis. The matching may be computed in various levels such as lexical matching, syntactic matching, predicate-argument matching. For instance, Shibata and Kurohashi [2011] presented the PA-matching method that is based on matching text and hypothesis, considering predicate-argument structure as a basic unit of handling the meaning of text/hypothesis. Sugimoto [2011] presented a method of computing the overlap of the text and the hypothesis based on dependency triples which are extracted from the text and hypothesis.

The second approach is the machine learning-based approach. The main idea of this approach is to formalize the RTE task as a classification problem and use machine learning techniques to solve the classification problem. In the machine learning based approach, the important point lies in linguistic analyses and feature extraction. Most of the features are pair features, which are based on matching between constituents of the text and the hypothesis in various levels, such as lexical match, n -gram match, and syntactic dependency relation match, predicate-argument match, and syntactic differences [Akiba et al. 2011; Tsuboi et al. 2011].

In our study, we have adopted the machine learning-based approach. We investi-gated both features and machine learning algorithms. The novelty of our method is that we propose to use machine translation for RTE. Our proposed method is a very lightweight method. It does not require deep semantic analyses and extensive linguis-tic engineering. Nevertheless, experimental results achieved on Japanese data sets indicate the advantages of our proposed method. Our system obtained the best perfor-mance in BC subtask and competitive results in the Exam subtask among participant groups at NTCIR9-RITE.

However, our study still has some limitations. First, the system is not very precise at detecting hard false-entailment pairs in which H is highly covered by T. Second, due to the lack of entailment and paraphrase knowledge, our system fails to determine the entailment relationship in pairs that need complex inference. We plan to address these problems by developing an alignment component for RTE task and acquiring entailment/paraphrase rules from large text corpora. We have presented an empirical study of recognizing textual entailment for Japanese. Our system is based on machine learning, in which multiple entailment features ex-tracted from both original Japanese pairs and their English translation are combined to learn an entailment classifier. Extensive analyses and ablation tests have been conducted to quantitatively measure the effects of various entailment features, ma-chine learning algorithms, and additional resources on the performance of our RTE system. Experimental results achieved on the two benchmark data sets indicated that our proposed method significantly outperforms the baseline method based on lexical matching and syntactic matching, and the machine translation component can be used to improve the performance of the RTE system.

