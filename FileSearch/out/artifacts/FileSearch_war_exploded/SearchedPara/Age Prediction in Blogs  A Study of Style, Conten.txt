 The evolution of the internet has changed the way that people communicate. The introduction of instant messaging, forums, social networking and blogs has made it possible for people of ev-ery age to become authors. The users of these social media platforms have created their own form of unstructured writing that is best char-acterized as informal. Even how people com-municate has dramatically changed, with multi-tasking increasing and responses generated im-mediately. We should be able to exploit those differences to automatically determine from blog posts whether an author is part of a pre-or post-social media generation. This problem is called age prediction and raises two main questions:  X  Is there a point in time that proves to be  X  What features of communication most di-
We hypothesize that the dividing line(s) oc-cur when people in generation Y 1 , or the millen-nial generation , (born anywhere from the mid-1970s to the early 2000s) were typical college-aged students (18-22). We focus on this gen-eration due to the rise of popular social media technologies such as messaging and online social networks sites that occurred during that time. Therefore, we experimented with binary clas-sification into age groups using all birth dates from 1975 through 1988, thus including students from generation Y who were in college during the emergence of social media technologies. We find five years where binary classification is sig-nificantly more accurate than other years: 1977, 1979, and 1982-1984. The appearance of social media technologies such as AOL Instant Messen-ger (AIM), weblogs, SMS text messaging, Face-book and MySpace occurred when people with these birth dates were in college.

We explore two of these years in more detail, 1979 and 1984, and examine a wide variety of features that differ between the pre-social me-dia and post-social media bloggers. We examine lexical-content features such as collocations and part-of-speech collocations, lexical-stylistic fea-tures such as internet slang and capitalization, and features representing online behavior such as time of post and number of friends. We find that both stylistic and content features have a significant impact on age prediction and show that, for unseen blogs, we are able to classify authors as born before or after 1979 with 80% accuracy and born before or after 1984 with 82% accuracy.

In the remainder of this paper, we first dis-cuss work to date on age prediction for blogs and then present the features that we extracted, which is a larger set than previously explored. We then turn separately to three experiments. In the first, we implement a prior approach to show that we can produce a similar outcome. In the second, we show how the accuracy of age prediction changes over time and pinpoint when major changes occur. In the last experiment, we describe our age prediction experiments in more detail for the most significant years. In previous work, Mackinnon (2006) , used Live-Journal data to identify a blogger X  X  age by ex-amining the mean age of his peer group using his social network and not just his immediate friends. They were able to predict the correct age within +/-5 years at 98% accuracy. This ap-proach, however, is very different from ours as it requires access to the age of each of the blogger X  X  friends. Our approach uses only a body of text written by a person along with his blogging be-havior to determine which age group he is more closely identified with.

Initial research on predicting age without us-ing the ages of friends focuses on identifying im-portant candidate features, including blogging characteristics (e.g., time of post), text features (e.g., length of post), and profile information (e.g., interests) (Burger and Henderson, 2006). They aimed at binary prediction of age, classify-ing LiveJournal bloggers as either over or under 18, but were unable to automatically predict age with more accuracy than a baseline model that always chose the majority class. In our study on determining the ideal age split we did not find 18 (bloggers born in 1986 in their dataset) to be significant.

Prior work by Schler et al. (2006) has ex-amined metadata such as gender and age in blogger.com bloggers. In contrast to our work, they examine bloggers based on their age at the time of the experiment, whether in the 10 X  X , 20 X  X  or 30 X  X  age bracket. They identify interesting changes in content and style features across cat-egories, in which they include blogging words (e.g.,  X  X OL X ), all defined by the Linguistic In-quiry and Word Count (LIWC) (Pennebaker et al., 2007). They did not use characteristics of online behavior (e.g., friends). They can distin-guish between bloggers in the 10 X  X  and in the 30 X  X  with relatively high accuracy (above 96%) but many 30s are misclassified as 20s, which results in a overall accuracy of 76.2%. We re-implement Schler et al. X  X  work in section 5.1 with similar findings. Their work shows that ease of classi-fication is dependent in part on what division is made between age groups and in turn moti-vates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler et al., nor we, attempt to determine how a person X  X  writ-ing changes over his lifespan (Pennebaker and Stone, 2003; Robins et al., 2002). Goswami et al. (2009) add to Schler et al. X  X  approach using the same data and have a 4% increase in accu-racy. However, the paper is lacking details and it is entirely unclear how they were able to do this with fewer features than Schler et al.
In other work, Tam and Martell (2009) at-tempt to detect age in the NPS chat corpus be-tween teens and other ages. They use an SVM classifier with only n-grams as features. They achieve &gt; 90% accuracy when classifying teens vs 30s, 40s, 50s, and all adults and achieve at best 76% when using 3 character gram features in classifying teens vs 20s. This work shows that n-grams are useful features for detecting age and it is difficult to detect differences between con-secutive groups such as teens and 20s, and this provides evidence for the need to find a good classification split.

Other researchers have investigated weblogs for differences in writing style depending on gen-der identification (Herring and Paolillo, 2006; Yan and Yan, 2006; Nowson and Oberlander, 2006). Herring et al (2006) found that the typi-cal gender related features were based on genre and independent of author gender. Yan et al (2006) used text categorization and stylistic web features, such as emoticons, to identify gender and achieved 60% F-measure. Nowson et al (2006) employed dictionary and n-gram based content analysis and achieved 91.5% accuracy using an SVM classifier. We also use a super-vised machine learning approach, but classifica-tion by gender is naturally a binary classification task, while our work requires determining a nat-ural dividing point. Our corpus consists of blogs downloaded from the virtual community LiveJournal. We chose to use LiveJournal blogs for our corpus because the website provides an easy-to-use format in XML for downloading and crawling their site. In addition, LiveJournal gives bloggers the op-portunity to post their age on their profile. We take advantage of this feature by downloading blogs where the user chooses to publicly provide this metadata.
 We downloaded approximately 24,500 Live-Journal blogs containing age. We represent age as the year a person was born and not his age at the time of the experiment. Since technol-ogy has different effects in different countries, we only analyze the blogs of people who have listed US as their country. It is possible that text written in a language other than English is included in our corpus. However, in a man-ual check of a small portion of text from 500 blogs, we only found English words. Each blog was written by a unique individual and includes a user profile and up to 25 recent posts written between 2000-2010 with the most recent post be-ing written in 2009-2010. The birth dates of the bloggers range in years from 1940 to 2000 and thus, their age ranges from 10 to 70 in 2010. Fig-ure 1 shows the number of bloggers per age in our group with birth dates from 1950 to 1996. The majority of bloggers on LiveJournal were born between 1978-1989. We pre-processed the data to add Part-of-Speech tags (POS) and dependencies (de Marn-effe et al., 2006) between words using the Stan-ford Parser (Klein and Manning, 2003a; Klein and Manning, 2003b). The POS and syntactic dependencies were only found for approximately the first 90 words in each sentence. Our classifi-cation method investigates 17 different features that fall into three categories: online behavior, lexical-stylistic and lexical-content. All of the features we used are explained in Table 1 along with their trend as age decreases where applica-ble. Any feature that increased, decreased, or fluctuated should have some positive impact on the accuracy of predicting age. 4.1 Online Behavior and Interests Online behavior features are blog specific, such as number of comments and friends as described in Table 1.1. The first feature, interests , is our only feature that is specific to LiveJournal. In-terests appear in the LiveJournal user profile, but are not found on all blog sites. All other online behavior features are typically available in any blog.
We extracted the top 200 interests based on occurrence in the profile page from 1500 random blogs in three age groups. These age groups are used solely to illustrate the differences that oc-cur at different ages and are not used in our classification experiments. We then pruned the list of interests by excluding any interest that occurred within a +/-10 window (based on its position in the list) in multiple age groups. We show the top interests in each age group in Ta-ble 2. For example,  X  X isney X  is the most popu-lar unique interest in the 18-22 age group with only 39 other non-unique interests in that age group occurring more frequently.  X  X anfiction X  is a popular interest in all age groups, but it is significantly more popular in the 18-22 age group than in other age groups.

Amongst the other online behavior features, the number of friends tends to fluctuate but seems to be higher for older bloggers. The num-ber of lifetime posts (Figure 2(d)), and posts de-creases as bloggers get younger which is as one would expect unless younger people were orders of magnitude more prolific than older people. The mode time (Figure 2(b)), refers to the most common hour of posting from 00-24 based on GMT time. We didn X  X  compute time based on the time zone because city/state is often not in-cluded. We found time to not be a useful feature in this manner and it is difficult to come to any conclusions from its change as year of birth de-creases. 4.2 Lexical -Stylistic The Lexical-Stylistic features in Table 1.2, such as slang and sentence length , are computed us-ing the text from all of the posts written by the blogger. Other than sentence length , they were normalized by sentence and post to keep the numbers consistent between bloggers regardless of whether the user wrote one or many posts in his/her blog. The number of emoticons (Figure 2(a)), acronyms , and capital words increased as bloggers got younger. Slang and punctuation , which excludes the emoticons and acronyms counted in the other features, increased as well, but not as significantly. The length of sentences decreased as bloggers got younger and the num-ber of links/images varied across all years as shown in Figure 2(c). 4.3 Lexical -Content The last category of features described in Ta-ble 1.3 consists of collocations and words, which are content based lexical terms. The top words are produced using a typical  X  X ag-of-words X  ap-proach. The top collocations are computed us-ing a system called Xtract (Smadja, 1993).

We use Xtract to obtain important lexical col-locations, syntactic collocations, and POS col-locations as features from our text. Syntac-tic collocations refer to significant word pairs that have specific syntactic dependencies such as subject/verb and verb/object. Due to the length of time it takes to run this program, we ran Xtract on 1500 random blogs from each age group and examined the first 1000 words per blog. We looked at 1.5 million words in total and found approximately 2500-2700 words that were repeated more than 50 times.

We extracted the top 200 words and colloca-tions sorted by post frequency (pf), which is the number of posts the term occurred in. Then, similarly to interests, we pruned each list to include the features that did not occur within +/-10 window (based on its position in the list) within each age group. Prior to settling on these metrics, we also experimented with other met-rics such as the number of times the collocation occurred in total, defined as collocation or term frequency (tf), the number of blogs the colloca-tion occurred in, defined as blog frequency (bf), and variations of TF*IDF (Salton and Buck-ley, 1988) where we tried using inverse blog fre-quency and inverse post frequency as the value for IDF. In addition, we also experimented with looking at a different number of important words and collocations ranging from the top 100-300 terms and experimented without pruning. None of these variations improved accuracy in our experiments, however, and thus, were dropped from further experimentation.

Table 3 shows the top words for each age group; older people tend to use words such as  X  X ouse X  and  X  X ld X  frequently and younger peo-ple talk about  X  X chool X .

In our analysis of the top collocations, we found that younger people tend to use first per-son singular ( I,me ) in subject position while older people tend to use first person plural ( we ) in subject position, both with a variety of verbs. We ran three separate experiments to determine how well we can predict age: 1. classifying into three distinct age groups (Schler et al. (2006) experiment), 2. binary classification with the split at each birth year from 1975-1988 and 3. Detailed classification on two significant splits from the second experiment.

We ran all of our experiments in Weka (Hall et al., 2009) using logistic regression over 10 runs of 10-fold cross-validation. All values shown are the averages of the accuracies from the 10 cross-validation runs and all results were compared for statistical significance using the t-test where applicable.

We use logistic regression as our classifier be-cause it has been shown that logistic regression typically has lower asymptotic error than naive Bayes for multiple classification tasks as well as for text classification (Ng and Jordan, 2002). We experimented with an SVM classifier and found logistic regression to do slightly better. 5.1 Age Groups The first experiment implements a variation of the experiment done by Schler et al. (2006). The differences between the two datasets are shown in Tables 4. The experiment looks at three age groups containing a 5-year gap be-tween each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006).

We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early de-mographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dom-inant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal demographic (Kumar et al., 2004) reported that 28.6% of blogs are written by bloggers between the ages 13-18 whereas based on the current de-mographic statistics, in 2010 2 , only 6.96% of blogs are written by that age group and the number of bloggers in the 31-36 age group in-creased from 3.9% to 12.08%. We chose the later age groups because this study is based on blogs updated in 2009-10 which is 5-6 years later and thus, the 13-17 age group is now 18-22 and so on.

We use style-based (lexical-stylistic) and content-based features (BOW, interests) to mimic Schler et al. X  X  experiment as closely as possible and also experimented with adding online-behavior features. Our experiment with style-based and content-based features had an accuracy of 57%. However, when we added online-behavior, we increased our accuracy to 67%. A more detailed look at the better results show that our accuracies are consistently 7% lower than the original work but we have similar findings; 18-22s are distinguishable from 38-42s with accuracy of 94.5%, and 18-22s are distin-guishable from 28-32s with accuracy of 80.5%. However, many 38-42s are misclassified as 28-32s with an accuracy of 72.1%, yielding overall accuracy of 67%. Due to our findings, we believe that adding online-behavior features to Schler et al. X  X  dataset would improve their results as well. 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone who was in one age group now will be in a different age group in 5 years. Furthermore, a blogger X  X  posts can fall into two categories de-pending on his age at the time. Therefore, our second experiment looks at year of birth instead of age, as that never changes. In contrast to Schler et al. X  X  experiment, our division does not introduce a gap between age groups, we do bi-nary classification, and we use significantly less data.

We approach age prediction as attempting to identify a shift in writing style over a 14 year time span from birth years 1975-1988:
The experiment focuses on the range of birth years of bloggers from 1975-1888 to identify at what point in time, if any, shift(s) in writing style occurred amongst college-aged students in generation Y. We were motivated to examine these years due to the emergence of social me-dia technologies during that time. Furthermore, research by Pew Internet (Zickuhr, 2010) has found that this generation (defined as 1977-1992 in their research) uses social networking, blogs, and instant messaging more than their elders. The experiment is balanced to ensure that each birth year is evenly represented. We balance the data by choosing a blogger consec-utively from each birth year in the category, re-peating these sweeps through the category until we have obtained 1500 blogs. We chose to use 1500 blogs from each group because of process-ing power, time constraints, and the amount of blogs needed to reasonably sample the age group at each split. Due to the extensive running time, we only examined variations of a combination of online-behavior, lexical-stylistic, and BOW fea-tures.

We found accuracy to increase as year of birth increases in various feature experiments which is consistent with the trends we found while exam-ining the distribution of features such as emoti-cons and lifetime posts in Figure 2. We ex-perimented with style and content features and found that both help improve accuracy. Figure 3 shows that content helps more than style, but style helps more as age decreases. However, as shown in Figure 4, style and content combined provided the best results. We found 5 years to have significant improvement over all prior years for p  X  .0005: 1977, 1979, and 1982-1984.

Generation Y is considered the social me-dia generation, so we decided to examine how the creation and/or popularity of social media technologies compared to the years that had a change in writing style. We looked at many pop-ular social media technologies such as weblogs, messaging, and social networking sites. Figure 5 compares the significant years 1977,1979, and 1982-1984 against when each technology was created or became popular amongst college aged students. We find that all the technologies had an effect on one or more of those years. AIM and weblogs coincide with the earlier shifts at 1977 and 1979, SMS messaging coincide with both the earlier and later shifts at 1979 and 1982, and the social networking sites, MySpace and Facebook coincide with the later shifts of 1982-1984. On the other hand, web forums and Twit-ter each coincide with only one outlying year which suggests that either they had less of an impact on writing style or, in the case of Twit-ter, the change has not yet been transferred to other writing forms. 5.3 A Closer Look: 1979 and 1984 Our final experiment provides a more detailed explanation of the results using various feature combinations when splitting pre-and post-so-cial media bloggers by year of birth at two of the significant years found in the previous sec-tion; 1979 and 1984. The results for all of the experiments described are shown in Table 5.
We experimented against two baselines, on-line behavior and interests. We chose these two features as baselines because they are both easy to generate and not lexical in nature. We found that we were able to exceed the baselines sig-nificantly using a simple bag-of-words (BOW) approach. This means the BOW does a better job of picking topics than interests. We found that including all 17 features did not do well, but we were able to get good results using a subset of the lexical features. We found the best re-sults to have an accuracy of 79.96% and 81.57% for 1979 and 1984 respectively using BOW, in-terests, online behavior, and all lexical-stylistic features.

In addition, we show accuracy without in-terests since they are not always available. BOW, online-behavior, and lexical-stylistic fea-tures combined did best achieving accuracy of 77.45% and 80.88% in 1979 and 1984 respec-tively. This indicates that our classification method could work well on blogs from any web-site. It is interesting to note that colloca-tions and POS-collocations were useful, but only when we use 1984 as the split which implies that bloggers born in 1984 and later are more homo-geneous. We have shown that it is possible to predict the age group of a person based on style, content, and online behavior features with good accu-racy; these are all features that are available in any blog. While features representing writ-ing practices that emerged with social media (e.g., capitalized words, abbreviations, slang) do not significantly impact age prediction on their own, these features have a clear change of value across time, with post-social media blog-gers using them more often. We found that the birth years that had a significant change in writing style corresponded to the birth dates of college-aged students at the time of the cre-ation/popularity of social media technologies, AIM, SMS text messaging, weblogs, Facebook and MySpace.

In the future we plan on using age and other metadata to improve results in larger tasks such as identifying opinion, persuasion and power by targeting our approach in those tasks to the identified age of the person. Another ap-proach that we will experiment with is the use of ranking, regression, and/or clustering to cre-ate meaningful age groups. This research was funded by the Office of the Director of National Intelligence (ODNI), In-telligence Advanced Research Projects Activity (IARPA), through the U.S. Army Research Lab. All statements of fact, opinion or conclusions contained herein are those of the authors and should not be construed as representing the of-ficial views or policies of IARPA, the ODNI or the U.S. Government.

