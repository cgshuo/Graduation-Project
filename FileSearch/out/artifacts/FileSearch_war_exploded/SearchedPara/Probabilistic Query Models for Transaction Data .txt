 We investigate the application of Bayesian networks, Markov random fields, and mixture models to the problem of query answering for transaction data sets. We formulate two ver-sions of the querying problem: the query selectivity estima-tion (i.e., finding exact counts for tuples in a data set) and the query generalization problem (i.e., computing the prob-ability that a tuple will occur in new data). We show that frequent itemsets are useful for reducing the original data to a compressed representation and introduce a method to store them using an ADTree data structure. In an exten-sion of our earlier work on this topic we propose several new schemes for query answering based on the compressed repre-sentation that avoid direct scans of the data at query time. Experimental results on real-world transaction data sets pro-vide insights into various tradeoffs involving the offline time for model-building, the online time for query-answering, the memory footprint of the compressed data, and the accuracy of the estimate provided to the query. 
In this paper we address the problem of query-answering on large binary transaction data sets. Such data sets can be thought of as a high-dimensional data matrices, where columns could be particular products or Web pages and rows represent market baskets or Web sessions. The matrix is generally very sparse, with l's indicating that a particular basket contains a particular product, for instance, and O's elsewhere. 
We formulate two versions of the query-answering prob-lem: requires prior speci tic permission and/or a fee. KDD 01 San Francisco CA USA Copyright ACM 2001 1-58113-391-x/01/08...$5.00 The two types of query are conceptually quite different. An-swering selectivity queries can essentially be regarded as data compression, while generalization queries involve learn-ing. 
Both forms of querying are useful in interactive data min-ing applications and exploratory analysis of transaction data. It is easy to imagine a human analyst who is exploring var-ious hypotheses in the data and would prefer to get an ap-proximate count to a query in real-time rather than to walt for an exact count to be generated. Query selectivity esti-mation is an important practical problem in the optimiza-tion of database management systems where query profilers and query optimizers routinely rely on fast mad reasonably accurate estimates of the query counts [18]. Query general-ization has many potential applications in data mining, from ad hoc interactive query for decision support to automated recommender systems. In this paper we focus on the basic techniques and algorithms rather than addressing specific applications. 
Any Boolean query can be answered using a single scan through the data set. While this approach has linear com-plexity and works well for small data sets, it becomes infea-sible for real-time queries on massive data sets not residing in main memory. On the other hand, commercial relational databases often use a simple independence model to quickly estimate the selectivity of particular queries [18]. In general, a key trade-off is the time and space efficiency of the method used to answer the query versus the accuracy of the resulting answer. Consequently, we seek approximate algorithms that allow us to trade accuracy in the estimate PM(Q) time and memory taken to calculate it. In previous work we have introduced a maximum entropy Markov random field (maxent/MRF) approach for building PM(Q) for selectivity estimation [11] and further extended these results in [15, 16]. can be formally defined as follows. Let R = {A1,... ,Ak} be a table header with k 0/1 valued attributes (variables) and r be a table of n rows over header R. We assume that ber of l's per row is substantially smaller than the number of attributes. By definition, a row of the table r satisfies a conjunctive query Q if and only if the corresponding at-tributes in the query and in the row have equal values. We are interested in finding the number of rows in the table r satisfying a given conjunctive query Q defined on a subset of its attributes. We cart view this query selectivity estima-tion problem in a probabilistic light and pose the problem as estimating the true frequency of Q in the table r using an approximate probability model PM. 
In this paper we mainly focus on the query generalization problem, i.e., the problem of predicting the frequency of a given query in unseen future data. We claim that prob-abilistic models ranging from the independence model to arbitrary Bayesian networks represent a very useful "tool-box" that allows systematic trade-offs between the accuracy of a model, the memory required to store it, and the online time to generate the prediction. We present results for the specific case of conjunctive queries: it is straightforward to extend these results to the case of arbitrary Boolean queries (e.g., see [15]). There are three main contributions in the paper: 
Previous work on query approximation has mainly fo-cused on non-probabilistic approaches [12, 5], multidimen-sional histograms [14, 18] and sampling [10, 9]. Mixtures of Gaussian independence models were proposed for query se-lectivity estimation on real-valued data sets [21]. The exper-iments reported in these and related papers only deal with relatively low dimensional data sets (order of 10 attributes), while the methods we describe here can answer queries di-rectly on hundreds of attributes. Generalized queries were considered in the context of language modeling using con-text free grammars [19]. To our knowledge, our paper is the first to directly address the problem of generalization queries for large high-dimensional transaction data sets and to sys-tematically compare several different probabilistic modeling techniques in this context. 
The rest of this paper is organized as follows. In Sec-tion 2 we introduce some general notation and discuss the performance metrics used to compare the models. Section 3 defines itemsets and discusses how ADTrees can be used to store itemsets and quickly produce counts for general queries on sparse binary data. Section 4 provides the definitions of all probabilistic models that we investigate for the query se-lectivity estimation and generalization problems. Section 5 presents the empirical results and in Section 6 we discuss conclusions. 
We use the following general notation in the paper. Let P denote the "true" unknown distribution that generated the data. Let xQ denote the variables in a conjunctive query Q, so that P(xQ) is the distribution on the query variables and P(Q) is its value for an instantiation of the variables defined by the query. Note that P(xQ) is a specific distribution over the subset of variables in Q, not over all variables in the table R. We use PM to denote an estimate of P from the data (i.e., a probabilistic model), PM(XQ) is the estimate of P(xQ), and PM(Q) is the estimate of P(Q). 
We use the following criteria to compare performance of different models: 
Definition 1. Time. The offline time cost Tp is the time taken to learn the model or to collect summary information about the data set. The online time cost tp(Q) is the time taken to answer the query Q online using the model PM. The online cost tp(Q) depends directly on the query. One general strategy is to have a fast and accurate online answer at the expense of potentially much higher oitline computa-tional investments. 
Definition 2. Memory. Memory is the complexity of the learned model PM (e.g., its minimum description length in bits [20]). We can expect more complex models to generate more ac-curate predictions but also to be more expensive in terms of online time. 
Definition 3. Error. Let r(Q) denote the query distri-bution 1, i.e., the probability that a particular query Q is issued. The error in answering the query Q, ep(Q), is de-fined as the difference between the query true count Ct(Q) on the test data and the count estimated from the model PM. The expectation of the relative error with respect to 7r(Q) is then 1We assume that this distribution is known, but in principle we could learn 7r(Q) for a population of individuals. We use the empirical relative error defined as where NQ,~ is the number of random query drawings from ~r(Q) and Ct(Qj) is the true count of the query Qj on the test data. Similarly, we define/~tr,~ with the only difference that this time Ct(Q) refers to the count of the query Q on the training data. 
Definition 4. An itemset associated with the binary table r (with header R) is either a single positively initialized at-tribute or a conjunction of mutually exclusive positively ini-tialized attributes from R [1]. We call an itemset T-frequent fined non-negative threshold. The size of an itemset is the number of conjuncts it is defined on. 
Itemsets have several attractive properties for binary trans-action data. For example, define a conjunctive count query to be simply a conjunctive query on the original training data (we use "count queries" to avoid referring repeatedly to selectivity and generalization queries, since counts are usually required in either case). To provide an error-free answer to any count query expressed as a Boolean expres-sion on the attributes of the binary table r it is sufficient to know all 0-frequent itemsets and their counts in r. The proof of this statement follows directly from the inclusion-exclusion principle and the definition of the itemsets. We discuss this method in the next subsection in more detail where we introduce ADTrees that efficiently implement the inclusion-exclusion principle. In what follows we will use the following two theorems: 
THEOREM 1. All T-frequent itemsets have a hierarchical structure, i.e., if an itemset on a set of variables X is T-frequent then any itemset on a subset of variables from X is T-frequent as well. 
PROOF. The proof follows immediately from the defini-tion of a T-frequent itemset by contradiction. [] 
THEOREM 2. If an itemset on a set of variables X is T-frequent then any count query Q (expressed as an arbitrary Boolean expression) involving variables that are all contained in the set X can be answered exactly. 
PaOOF. Notice first that if query Q mentions only vari-ables in the set Y and Y C X then any itemset on vari-ables from Y is T-frequent due to Theorem 1. An arbitrary Boolean query Q can be converted to the disjunctive nor-mal form (DNF), the probability of which equals the sum of the probabilities of the individual disjuncts due to their mu-tual exclusiveness. Each disjunct is a conjunction of query attributes or their negations whose probability due to the inclusion-exclusion principle can be expressed as a linear combination of probabilities of conjunctions of positively ini-tialized attributes from Y. The former probabilities in turn can be read directly from the T-frequent itemsets (due to Theorem 1). [] 
There exist well-known efficient algorithms to compute all the itemsets from large binary tables (e.g., [2]). Provided that the data are sparse, the running times of these algo-rithms have been found in experimental analyses to be lin-ear in both the size of the table and the number of frequent itemsets. Thus, computing itemsets in practice often does not incur a high preprocessing cost on sparse data. We com-pute itemsets offiine and then learn the probabilistic models (such as the maxent model and the Bayesian network) on-line, without referring to the original data set at all. 
The ADTree is a sparse data structure that is useful for a variety of applications involving symbolic attributes, in-cluding fast counting, learning belief networks, association rule mining. The details of the original algorithm and its modification for the case of binary sparse data (which we only briefly describe here) can be found in [13, 3, 16]. For sparse binary transaction data we modify the original ADTree model so as to (a) always prune the child corre-sponding to the zero value of the attribute being varied and not the most common value (MCV) as in the original for-mulation, (b) not keep the values of the attributes, and (c) not construct the Vary nodes. 
With these modifications we can create the ADTree in a single scan of the data. We start with a tree containing a single root node and sequentially scan records in the data set. Each record is represented by the array of attributes ini-tialized to 1. The existing tree is updated so that all possible subsets of attributes ordered by the attribute number of the current record get an additional count of 1. Adding a sub-set, if done in increasing order of the cardinality of subsets, results in either adding a leaf with a count of 1 or increasing the count of an existing node by 1. Once the ADTree is learned one can use an efficient recursive procedure that im-plements the inclusion-exclusion principle to find the count of any conjunctive query on the data [13]. 
In this paper we use ADTrees for several purposes: storing the itemsets that were precomputed by any standard algo-rithm (such as Apriori [2]), and speeding up the learning of Bayesian networks, where one of the main computational efforts lies in producing counts for the data. 
Notice that the offiine time and the memory required by the algorithm can be bounded by Y']in=l 2 Si in the worst case, where Si is the number of ls in the i-th record. To minimize this, we would like to avoid "long" records, i.e., records with a lot of ls in them. There are several possible strategies here: 1. If the data are sparse then all records may be short in 2. To avoid potential memory problems we propose a 
Building the ADtree models is relatively fast and straight-forward. The main limitation, the exponential time and memory complexity in the size of the largest record in the data, can in principle be overcome by storing long exceptions separately. 
Our models naturally fall into two groups: 2. Models where the full data set is first used to estimate 
Bayesian networks (also known as belief networks, or di-rected graphical models) provide a systematic language for characterization and inference of parsimonious factored rep-resentations of full joint distributions. Thus, they are poten-tially useful candidates for answering generalization queries. We have explored two varieties of this general idea: (1) learning a full Bayesian network offiine on all k variables and performing inference on this network in real-time to calculate the marginal probability of the query Q, and (2) learning a smaller Bayesian network in real-time on the vari-ables in the query and using this network model to answer the query. The Appendix describes in more detail the al-gorithm that we used for learning Bayesian networks: it essentially performs local heuristic search among the candi-date graphs to optimize the posterior probability, i.e., the Bayesian score of such graphs given the data set of observa-tions [6]. 
Our original idea was to learn a Bayesian network on all variables (offline) and then use this network for approxi-mate query answering. The problem with this approach however is that exact inference in a full Bayesian network has exponential time and memory complexity in the in-duced width of the network graph. To see this, say we have k = 100 attributes and a query of size 4. To calculate the marginal probability of interest on the 4 query variables re-quires "summing out" up to 96 other variables. Of course, the structure of the graph can be leveraged to make this sum tractable, but for large values of k we have found that the resulting graph can end up with quite large cliques (e.g., of size 20 or more), making exact inference intractable. Ap-proximate inference can be done using Gibbs sampling [17] but due to its slow convergence (especially for the queries with small probabilities) it appears to be impractical. 
Given this, we investigated a second technique, namely learning query-specific Bayesian networks in real time, using the aggregate information contained in the frequent item-sets or an MBADTree. Thus, for example, if we had fre-quent itemsets {A, B}, {B, C, D}, {A, E} and {D, F} (and all their subsets) and wanted to answer a query on variables B, C, and F, we would find all itemsets that contain these variables and then use this information to construct a joint distribution p(B, C, F) in the form of a Bayesian network. If variable X is in a query, then the only candidate parent variables for X are those that appear in the same itemsets as X since in the absence of the training data itemsets are the only objects mentioning X we know the counts for. In ef-fect, the Bayesian network structure learning algorithm uses the itemset information to construct a consistent joint prob-ability distribution on the query variables. What is perhaps surprising about this approach is that it can be performed relatively quickly, where relative is measured against alter-native techniques such as sampling from the full Bayesian network or scanning the original data directly to generate a count query. 
In the Appendix we describe the Bayesian network learn-ing algorithm. It represents conditional probability tables in the network as decision trees [6]. When learning from item-sets in this context, our approach is to evaluate the decision tree splits based on the itemsets and not on the whole data set. This is possible because having itemsets enables us to use inclusion-exclusion principle for counting (Theorem 2). We refer the reader to the Appendix where we give more technical details on this approach. 
In previous work we investigated the maxent/MRF model extensively in the context of query selectivity estimation [11, 15, 16]. To save space we refer the reader to the above-mentioned papers for complete details on the method and just briefly outline the salient aspects of this model. 
We assume that T-frequent itemsets and the associated frequency counts have been estimated offline (e.g., by the Apriori algorithm), and we view them as specifying con-straints on the unknown query distribution PM(XQ). maximum entropy criterion is then used to select a unique estimate PM(XQ) from the set "P of all plausible ones satis-fying the constraints. If the constraints are consistent the target distribution exists, is unique [4], and can be found in an iterative fashion using an algorithm known as iterative scaling [7]. The constraints generated by itemsets are con-sistent by definition since the empirical distribution of the data satisfies them. 
The algorithmic approach is quite similar in spirit to the online Bayesian network learning approach of the previous section. Both approaches have the following general struc-ture: (1) itemsets are learned offline, (2) a query is then posed in real-time, and (3) a joint probability distribution for the query variables is then estimated based on the item-sets alone. In both approaches the time taken to compute the query online depends on the number of variables in the query and the number and nature of the itemsets, but does not depend on the size of the data directly. 
However, there is are two significant differences between the Bayesian network (BN) approach and the maximum en-tropy (ME) one. The first difference is that the BN method defines a directed graphical model for the distribution of in-terest, whereas the ME method defines an undirected graph-ical model (a Markov random field) [16]. The directed and undirected models can be quite different in practice, both in terms of structure (i.e., which variables end up being con-nected to which other variables in the model) and in terms of parameters (the actual joint probabilities). 
The second main difference is that the BN approach (as we implement it) need not include dependencies among all members of an itemset in the graphical model, i.e., the al-gorithm greedily looks for the best scoring structure, and some of the edges may be excluded as non-promising. In contrast, the ME method models all dependencies between members of an itemset (i.e., they are fully-connected in the underlying graph). In theory one could also "prune" this model to trade-off parsimony with complexity but, uulike BN learning, there are no standard algorithms available for this purpose. Thus, in general, the ME method may construct much more complex graphs, particularly for large; queries and dense data sets. 
The ME algorithm (known as iterative scaling) for infer-ring an undirected joint distribution on the query variables has worst-case time complexity exponential in the number of query variables [17]. In [16] we considered several graph-based algorithms that reduce the time complexity of itera-tive scaling to exponential in the induced width w* of the.' graph of the MRF. We also showed that the gain in time comes at the expense of increased memory, from linear to exponential in the induced width. In the results reported in this paper we use the bucket elimination algorithm [8] to speed up our implementation of iterative scaling. Nonethe-less, as we will see in the experimental results section, the undirected graphical modeling method tends to be slower for query answering than the directed Bayesian network mod-eling method. 
Assuming independence of the attributes leads to the sim-plest possible probabilistic model. Since the data are binary-valued, we only have to store one parameter per attribute. The probability of a conjunctive query is approximated by the product of the probabilities of the single attribute-value combinations occurring in the query. The memory complex-ity associated with storing k counts is small in this method. The preprocessing can be done by a single scan through the: data, and the online cost consists of nQ --1 multiplications, where nQ is the size of the query Q. However, as we shall see later, the quality of the approximations produced by the independence method can be poor. Nonetheless, because of its simplicity, the independence model is widely used in com-mercial database management systems for query selectivity estimation (see, e.g. [18]). 
We also evaluate finite Nc component mixture models as a representation for PM. Each component consists of a con-ditionally independent Bernoulli distribution, i.e., the bi-nary attributes are assumed to be conditionally indepen-dence given the component. This mixture model family of distributions provides a relatively flexible tradeoff between parsimony and accuracy in modeling. The model contains O(Nck) parameters, where k is the number of attributes. We learn the model offline on all k attributes using the Expectation-Maximization algorithm. The time complexity of EM per iteration for of[line learning is O(Ncnk), where n is the number of observations. In practice we find that convergence occurs within 10 to 20 iterations. Full details are provided in [16]. 
Once the mixture model is learned it is straightforward to calculate PM(Q) for any query Q: details are provided again in [16]. The online query calculation takes time proportional to the number of mixture components Arc, the total number of attributes k, and the number of attributes in the query Q. The online query time is independent of the size of the original data. In practice, this real-time calculation can be performed very quickly relative to the Bayesian network or maxent/MRF approaches discussed above, and much more quickly than a full scan of the data. 
For generalization queries there is an interesting trade-off between data size and the type of model one expects to per-form best. For very small data sets, we expect statistical models to be essential, i.e., direct scanning and counting will not work very well since many of the cells will have zero counts in the observed data (so generalization from the observed data is critical). For "large" data sets (say 100,000 rows, 50 variables), and generalization queries with relatively few variables (e.g. 5 to 10), the empirical esti-mates (counts) may be much better and indeed may per-form quite well in terms of prediction power compared to any parametric model for the queries (we will see an exam-ple of this below in Sections 5.3 and 5.4). However, as we go to a "third regime," namely massive data sets (with say 30 million rows), while the direct scan approach is likely to produce very good predictions for our generalization queries, it will take an inordinately long time to compute. Thus, in effect there are two regimes where model-based techniques can be particularly useful: at the very small sample end (and traditionally this is where statistics has played an important role), but also at the massive sample end of the spectrum where one wants to use statistical models not because they are more accurate (indeed they may be less accurate) but because they are more tractable to work with. 
With this in mind we conducted two sets of experiments with (1) very large simulated data sets to demonstrate how the different approaches scale in terms of time taken to an-swer a query, and (2) more modest real-world transaction data sets where we systematically evaluated the trade-offs among accuracy, time, and memory. All experiments in this Section were performed on a Sun Solaris 2.7 UNIX workstation with two 168MHz Sparc CPUs and 256Mb of main memory. We used simulated data to investigate how the different generalization query methods Table 1: Query processing time of different models relative to the mixture model. The times are in "units" of 0.002 CPU seconds, which is the time the mixture model takes for queries of size 4. ME -the maxent model, MM -a mixture model with Nc = 100 components, and SS -a single scan through the data. scale up. (We would have used real-world data for this pur-pose, but real-world data sets that we have research access to are relatively small compared to many commercial trans-action data sets). 
The simulated data were generated as follows. We first learned a mixture model of 20 independent Bernoulli com-ponents (as described in Section 4.4) on a publicly available Web transaction data set (described later in the paper). We then used this model to simulate data sets with 30K, 300K and 3000K records. The sample of size 30K is roughly equal to the size of our real-world transaction data sets, while the other two samples are correspondingly 10 and 100 times larger. 
Our goal here was to evaluate how the query time changed as the data size was increased. By simulating from a non-trivial model (i.e., not just an independence model) built from real data, the resulting simulated data can be expected to be similar in many respects to a real data set of the same size, e.g., relatively large itemsets and/or records with large number of l's can be generated. Thus, the simulated data provides a reasonably challenging modeling problem for all the methods. However, we purposely did not use the simulated data to evaluate the accuracy of the methods (but only the time taken for query computation) since the simulation method will likely tend to be biased in favor of certain models, e.g. Bernoulli mixture model, over others. 
For the maxent model we set the value of the threshold T to 30, 300 and 3000 respectively and computed T-frequent itemsets for each of the samples. 
We found in general that the MBADTrees on large data were either too large to be practical or, if memory-limited, were much less accurate than the other methods. For exam-ple, in recent simulations with 32 MBytes of data we con-strained all the models, including the MBADTree, to be no larger than 32 MBytes. We found that the accuracy of the MBADTree was at least an order of magnitude worse than all competing models. Thus, MBADTrees did not offer a practical option for these very large data sets, and we did not pursue further experiments with them on the simulated data. 
We investigated how the maxent and mixture models com-pared to a full single scan through the data, in terms of Table 3: Distribution of the itemsets for the Web data and the retail data, The last row provides a heuristic estimate of the induced width w* in the graph for all attributes. both memory and online time. The memory for the maxent models built for each of three data sets was approximately 0.1Mbit. This is compared with 0.43Mbit memory for stor-ing the whole dataset with 30K records, 4.6Mbits for the data with 300K records, and 46Mbits for 3000K records. 
Table 1 describes the online timing results. As expected, the time of a full scan increases linearly with the size of the data set. The average online time of the maxent model, however, remains roughly constant as the size of the data set increases. For the largest data set with 3 million records, the maxent method is two orders of magnitude faster than a di-rect scan for queries of length 4 and similar in speed to a direct scan for queries of length 8. For a given fixed size data set, as query length increases, the maxent model will eventu-ally become slower than a direct scan of data (again a func-tion of the worst-case exponential growth in time complexity as a function of query length for the maxent approach). The times for the mixture model are independent of the data size (since the model is independent of the data size) and varies linearly with query length. In absolute terms the mixture model is significantly faster than either the maxent approach or the direct scan. As we will see in the sections to follow, the mixture models are also quite accurate, indicating that for large real-world data sets they may well be the technique of choice for fast and accurate approximate querying. 
We conducted experiments on two real-world transaction data sets: the Microsoft Anonymous Web data set (publicly available at the UCI KDD archive, kdd. ios.uci.edu)with roughly 32,000 records (Web site visitors) and 294 attributes (Web pages), and a large proprietary data set of consumer retail transactions with 55,000 records (transactions) and 52 attributes (categories of items that can be purchased). The Web data set comes with a predefined test data set with 5000 records. To obtain the test set for the retail data we split it into two equal halves. 
General characteristics of the data sets are given in Ta-ble 2. The retail data set is much more dense than the Microsoft Web data as indicated by sparsity, defined as the probability that a 1 appears in any randomly selected cell in the data matrix (for the retail data sparsity is almost 8 times higher than for the Microsoft data). As data density grows, the larger itemsets become more frequent and the N~,8 is the number of l's in the data, E(NI,s) = deviation of the number of l's in the record, and memory footprints of the maxent and ADTree models will also increase. Furthermore, the induced graphs of the max-ent models can also become dense, leading to potentially significant increases in the online estimation time of this ap-proach. We will see empirical examples of these effects later in this section. 
To analyze the structure of the frequent itemsets for each data set we considered different values of the threshold T and counted the number of T-frequent itemsets in the data. 
Table 3 gives the distribution of the number of T-frequent itemsets of size s for different values of s and T. The last row provides a heuristic estimate of the induced width w* of the graphs of the model, using the maximum cardinality ordering d on all attributes. The largest clique in the trian-gulated graph of the retail data set mentions roughly haft of all variables, while the same parameter for the Web data is only 10% of the number of all variables, despite the order of magnitude difference between the corresponding thresholds 
T. Thus, even for queries on the retail data that mention only 6 to 8 variables, we can expect to get much more dense graphs in the maxent models and correspondingly higher online query times. 8 Figure 1: Dependence of the average online time taken to answer a random query of size 8 on the Web data using maxent (with bucket elimination) as a function of model complexity C, where C is defined as a sum of the logarithm of the number of itemsets and the induced width of the graph of the maxent model. 
Figure 1 further illustrates this point. We ran 500 queries of size 8 on the Microsoft Web data and used the maxent approach enhanced with bucket elimination to compute the count. We recorded the online time taken to build the model as a function of the complexity C of the model for each query, namely the sum of the logarithm of the number of itemsets that participated in model estimation and the size of the largest clique of the graphical model estimated by the maxent method (induced width of the graph). Note that, up to a multiplicative constant, e c is an upper bound on the time complexity to estimate the distribution for a given query using bucket elimination. The clouds of points plotted with different markers correspond to different values of w*, ranging from 1 to 6. It is clear that queries yielding greater induced widths take more time to answer on average. In fact, the mean computation time tends to scale exponentially in w*. Thus, the sparsity of the underlying data will have a significant impact on the space and time complexity of the maxent method. In contrast, a method such as mixture modeling has time and space complexity independent of the original properties of the data, once the model is estimated. 
Of course the unknown factor here is the relative accuracy of the various approaches, which we investigate in more detail below. 
We generated 1000 random queries for query sizes of 4, 6, and 8, and evaluated different models with respect to the average memory taken by the model, the online time taken to answer a query tp(Q), and the errors/~t~t as defined in 
Equation 1 and ~tr,,. To select a query we first fixed the number of its variables nq = 4, 6 or 8. Then we picked nQ attributes according to the probability of the attribute taking a value of "1" and generated a value for each selected attribute according to its univariate probability distribution. 
Note, that zero values for the attributes are more likely in sparse data sets than positive ones. Using purely random queries (randomly chosen attributes with randomly chosen values) would result in a preponderance of queries whose count is zero in the data (since any query consisting of more than one positively instantiated attribute will often not have occurred in the data). 
All experiments on the real-world data sets were per-formed on a Pentium IV, 500 MHz machine running Win-dows NT and having 256Mb of memory. 
The plots in Figure 2 show the errors ~t~,~ and ~?t~t as a function of online CPU time for the Microsoft Web data for a number of models: the single scan, the independence, the mixture and the max entropy models, the Bayesian networks and ADTrees. The training error corresponds to counts evaluated on the training data (selectivity queries) and is included for reference. Of primary interest is the test error, which is estimated from counts on the test data, i.e., inde-pendent data that has not been used to construct the query 
Figure 2: Average relative error for 1000 random queries of length 4, 6 and 8 as a function of the average online time for the Web data. For a given model, points corresponding to query sizes 4, 6 and 8 are connected with a line, where a query of size 4 takes the least time (the leftmost point of 3), and of size 8 -the most time (the right most point of 3). 
For the full scan log10 ~trn = -co and logz0 tp(Q) -1.5. models. Notice that overall /~t,n ranges from less than 1% for queries of size 4 to about 4% on queries of size 8; /~,st is generally higher: from roughly 3% on queries of size 4 to 7% on queries of size 8. by performing a single scan through the training data. It performs surprising well on the test data, i.e., raw empiri-cal counts do relatively well on new data compared to the alternative models. However, in practice, as demonstrated in Section 5.1, the direct scan approach requires inordinate memory and time as the data sizes scale up. least memory. However, it is also the most inaccurate model among those considered here. 
MBADTrees from Section 3 with a maximum memory foot-print of M = 35MBytes allowed for the tree. Note that 35MBytes is significantly larger than roughly 400KBytes re-quired to store the data directly. Thus, MBADTree can in effect substantially amplify the storage requirements. The specified memory bound M translated into the following se-lection rule for data records: if the maximum number of positively initialized attributes in a data record was less than 13 then it was included in the MBADTrees and dis-carded otherwise. From Figure 2 we can see that this leads to degradation of performance on the training data and but nonetheless relatively decent results out of sample. Notice that timewise the MBADTrees are the second fastest model (after the independence model) in these experiments. Re-call, however, that as the data size scales up (e.g., in our simulated experiments), the MBADTrees become less com-petitive since to fit in memory they should discard a lot of information and, thus, become quite inaccurate. was learned on the 30-frequent, and the other on 0-frequent, itemsets. The former version is annotated as "BN Itemsets" on the figure and the latter as "BN Full data" since having all 0-frequent itemsets on the query variables corresponds to learning a belief network directly from the full data set. Both versions were learned online as discussed in Section 4.1. We notice that "BN Full data" is more accurate than "BN Itemsets" but the latter is considerably faster. 
The maxent model was using the speed-up method of bucket elimination that we mentioned in Section 4.2 but it still took exponential time to learn, and for this reason it is the slowest model of all. Its test set accuracy is among the best. 
For the mixture of independence models we fixed the num-ber of clusters Nc at 80. The number of parameters in the mixture model (linear in Arc) is 80 times greater than for the independence model. It is almost an order of magni-tude more accurate both in and out of sample. The mixture models are somewhat less accurate on both test and training data than most of other models. 
Overall the results in Figure 2 demonstrate a basic correla-tion between increasing online time and increasing accuracy of the query (whether on training or test data), with the 
MBADTree approach being somewhat of an exception since it exhibits better tradeoff characteristics than the other ap-proaches for a data set of this size. However, we emphasize that MBADTrees scale poorly from a memory viewpoint as discussed in Section 5.1. 
Since this data set is more dense, the threshold T was increased to 150 for itemsets used to construct the maxent models and the Bayesian network models. All the remaining models (the baseline, the independence, the MBADTrees, and the mixture) were set up in the same fashion as for the Web data. 
The accuracy and time of the various models relative to one another on the retail data was qualitatively simi-lar to that on the Web data with one significant exception, namely that the mixture model now became the most accu-rate model overall among models considered in the experi-ment (see Figure 3). In theory we could likely find a maxent model or a Bayesian network that would outperform the best mixture model, by lowering the threshold T (i.e., including more itemsets). However, this would incur a very signifi-cant computational penalty in terms of online computation time for the queries (for queries of size 8 the average CPU time per query is already over 1 second). Similarly, for the 
MBADTree models, the accuracy could be improved by al-lowing the model to take up more memory, however, for this data set this would again be impractical. 
We make the following observations over both data sets and query distribution and sizes we considered: '~ 
Figure 3: Average relative error for 1000 random queries of length 4, 6 and 8 as a function of the av-erage online time for the retail data. Same symbols as in Figure 2. For the full scan loga0 ~:trn = -oo and logt0 tp(Q) ~ -1.5.  X  The MBADTree models are much faster than all other  X  With a proper choice of the number of clusters the  X  The Bayesian networks learned from the frequent item- X  The maxent model that employs bucket elimination is  X  The baseline model (direct data scan) is the best model 
We have investigated the application ofprobabilistic mod-els to the problem of answering generalization queries for binary transaction data sets. We proposed several different approaches, including both online model learning based on itemset information and ADTrees as well as offiine model learning. In a variety of experiments on real-world and sim-ulated transaction data we found that all of these models provided gains in accuracy over the simple independence model. However, the improvements in accuracy came with an associated cost in terms of time taken to answer the query and memory footprint of the model. From a practical view-point, the model-based approaches appear to offer signifi-cant advantages over either direct scanning of the data or simple independence models, particularly as data sizes scale up. We use the Bayesian approach described by [6] to learn 
Bayesian networks with local parent structure in the form of decision trees. A greedy search algorithm is used to search the space of possible structures with the objective of maxi-mization of a Bayesian score function. 
Our current implementation is a basic version of the al-gorithm that uses uniform priors over the network struc-tures and parameters and that uses decision trees instead of decision graphs. In our assumptions the Bayesian score of a Bayesian network G with each node xi storing a deci-sion tree with leaves L(i) corresponding to the distribution 
P(xi[Parents(xi)), can be written as: where F(.) is the gamma function, Nij,xi=k,k m 0, 1 is the number of data points for which xi = k and Parents(xi) have values prescribed by the leaf j of a decision tree stored in the node xi, and Nij = Nij,~i=o + Nij,xi=l. 
The outline of the greedy algorithm (which is for the most part the same as the one described in [6]) is as follows A. Offline Phase B. Online Phase 1. Create graph G on nq nodes, with no edges, 2. Score G using Bayesian score 3. For each node xi in G: 4. Add every non-descendant 5. For all possible splits s of leaves of a decision tree 6. Apply split s to G 7. 8. 9. 10. 11. 12. 13. 14. 
The only operator we allow is a split operator that works as follows. Initially, a decision tree stored in each node is just a root node storing the count N(xi = O) and N(xi = 1). When in step 5 the node xj is tested for becoming a parent of the node xi, the root and the only current leaf of a decision tree for the node xi is split into two leaves, storing the counts g(xl = k[xj = 0) and Y(xi = klxj = 1), k = 0, 1, correspondingly. 
For evaluating the split of the node xi with a variable xj at the leaf L, corresponding to the values of the variables in the parental set Parents(xi) = ki, where each ki E {0, 1}, it is necessary and sufficient to require that the itemset on the variables Parents(xi)U{xj} is T-frequent. As we have shown in Section 3.2 ADTrees can be used to efficiently generate counts in this case. If the itemset on the vari-ables Parents(xi) U{xj} is not frequent we can not evaluate the split even though it might have had high improvement should we have full data. We thus prohibit such split in the algorithm. 
Once the split is done and the counts in the newly created leaf nodes are obtained we can check the equation above to see how splitting the original leaf changed the score of the structure. Notice that since the scoring function is node-decomposable this operation can be performed locally, with-out recomputing the score for the nodes other than xi. In general algorithm will have to evaluate all possible splits of the node xl with variables from the set in line 4 of the pseudocode for all the decision tree leaves. The research described in this paper was supported in part by NSF CAREER award IRI-9703120. [1] R. Agrawal, T. Imielinski, and A. Swami. Mining [2] R. Agrawal and R. Srikant. Fast algorithms for mining [3] B. S. Anderson and A. W. Moore. ADtrees for fast [4] A. Berger, S. D. Pietra, and V. D. Pietra. A maximum [5] K. Chakrabarti, M. N. Garofalakis, R. Rastogi, and [6] D. Chickering, D. Heckerman, and C. Meek. A [7] J. N. Darroch and D. Ratcliff. Generalized iterative [8] R. Dechter. Bucket elimination: A unifying framework [9] P. B. Gibbons and Y. Matias. New sampllng-based [10] R. J. Lipton, J. F. Naughton, and D. A. Schneider. [11] H. Mannila, D. Pavlov, and P. Smyth. Predictions [12] Y. Matias, J. Vitter, and M. Wang. Wavelet-based [13] A. W. Moore and M. S. Lee. Cached sufficient [14] M. Muralikrishna and D. DeWitt. Equi-depth [15] D. Parlor, H. Mannila, and P. Smyth. Probabilistic [16] D. Pavlov, H. Mannila, and P. Smyth. Beyond [17] J. Pearl. Probabilistic Reasoning in Intelligent [18] V. Poosala and Y. Ioannidis. Selectivity estimation [19] D. Pynadath and M. Wellman. Generalized queries on [20] J. Rissanen. A universal prior for integers and [21] J. Shanmugasundaram, U. Fayyad, and P. Bradley. 
