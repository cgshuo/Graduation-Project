 Recently,  X  X op-k learning to rank X  has attracted much atten-tion in the community of information retrieval. The mo-tivation comes from the difficulty in obtaining a full-order ranking list for training, when employing reliable pairwise preference judgment. Inspired by the observation that users mainly care about top ranked search result, top-k learning to rank proposes to utilize top-k ground-truth for training, where only the total order of top k items are provided, in-stead of a full-order ranking list. However, it is not clear whether the underlying assumption holds, i.e. top-k ground-truth is sufficient for training. In this paper, we propose to study this problem from both empirical and theoretical as-pects. Empirically, our experimental results on benchmark datasets LETOR4.0 show that the test performances of both pairwise and listwise ranking algorithms will quickly increase to a stable value, with the growth of k in the top-k ground-truth. Theoretically, we prove that the losses of these typical ranking algorithms in top-k setting are tighter upper bounds of (1  X  NDCG@ k ), compared with that in full-order setting. Therefore, our studies reveal that learning on top-k ground-truth is surely sufficient for ranking, which lay a foundation for the new learning to rank framework.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models Algorithms, Performance, Experimentation, Theory Learning to Rank, Top-k, Full-Order, Sufficient
Learning to rank has become an important means to tack-le the ranking problem in many applications, such as infor-mation retrieval, collaborative filtering and natural language processing. Taking Web search as an example, the process of learning to rank is as follows. In training, a number of queries are given, and each query associates with a number of documents and labels representing their rankings (usual-ly in terms of multi-level ratings). Then a ranking function is constructed by minimizing a certain loss function on the training data. In testing, given a new query and associat-ed documents, the ranking function is applied to produce a ranking list and the performance of the ranking algorithm is evaluated by IR measures such as MAP [3], NDCG [11]and ERR [7].

Recently, a new learning to rank framework named  X  X op-k learning to rank X  has emerged and gain much attention. The motivation comes from the difficulty in obtaining reliable training data for applying learning to rank to real systems: (1) conventional multi-level ratings based training data are not reliable [16, 19, 20]; (2) when employing more reliable pairwise preference judgment, it would be prohibitively ex-pensive to obtain a full-order ranking list [5, 6, 19]. Based on the fact that users mainly care more about top ranked search result, top-k learning to rank proposes to utilize top-k ground-truth for training ( k is usually small), where only the full ordering of top k items are provided, instead of a full-order ranking list.

The underlying assumption of top-k learning to rank is that top-k ground-truth is sufficient for ranking, i.e. training on top-k ground-truth is as good as that on a full-order ranking list. On this basis, top-k learning to rank describes how to conduct labeling, ranking and evaluation process. However, it is unclear whether the assumption holds. In this paper, we propose to study this problem from both empirical and theoretical aspects.

Empirically, we proposed to conduct experiments to study how the test performances of ranking algorithms change with respect to k in the training data of top-k learning to rank. Intuitively, with the increase of k , more information is con-veyed by the training data, and the test performances of ranking algorithms will increase. If k reaches the maximum (i.e. full-order ground-truth), we obtain the best test perfor-mance as all the ranking information is involved. Therefore, if the test performances quickly increase to a stable value, we say that top-k ground-truth is sufficient for ranking.
We conduct extensive experiments based on benchmark data sets LETOR4.0, and consider three state-of-the-art pair-wise algorithms, Ranking SVM [10], RankBoost [9] and RankNet [1], and a popular listwise algorithm, ListMLE [22]. We plot the test performance curves of these algorithms on two data sets in LETOR4.0, MQ2007-list and MQ2008-list. Our ex-perimental results indeed show that the test performances of all the four algorithms increase quickly to a stable value with the increase of k . As a consequence, we haven proven empirically that top-k ground-truth is sufficient for ranking.
At a first glance, the theoretical analysis of  X  X hether top-k is sufficient for ranking X  is to study the relationship between the loss functions of these algorithms in top-k setting and that in full-order setting. It is obvious that the former ones are lower bounds of the latter ones, which means that the minimization of these loss functions in full-order setting will lead to the minimization of them in top-k setting. However, what we really care about is the opposite side of the coin, i.e. whether the minimization of these loss functions in top-k setting will lead to the minimization of them in full-order setting. Seemingly the answer is negative.

By revisiting the problem of  X  X hether training on top-k ground-truth is as good as that on a full-order ranking list X , we find that the theoretical analysis need to further take IR evaluation measures into consideration, due to the fact that the performances of ranking algorithms are usually evaluated by them. In this paper, we take NDCG as an example to conduct the theoretical analysis.

To reveal the relationships among the three, we define a loss function named Weighted Kendall X  X  Tau (WKT for short). First, it can be proved that WKT is an upper bound of (1  X  NDCG@ k ). Second, it can be proved that the pairwise losses in Ranking SVM, RankBoost and RankNet, and the listwise loss in ListMLE are all upper bounds of WKT, in top-k setting. As a consequence, we come to the conclu-sion that the loss functions used in these ranking algorithms in top-k setting can bound (1  X  NDCG@ k ). Further consid-ering the relationship between loss functions in full-order setting and that in top-k setting, we can see that loss func-tions in top-k setting are tighter bounds of (1  X  NDCG@ k ), as compared with those in full-order setting. Therefore, we have proven theoretically that top-k ground-truth is not on-ly sufficient, but even better than full-order ground-truth for ranking.

According to the above empirical and theoretical study, we come to the conclusion that top-k ground-truth is suffi-cient for ranking, which lay a foundation for the new top-k learning to rank.

The reminder of the paper is organized as follows. In Sec-tion 2, we introduce some background on conventional learn-ing to rank and top-k learning to rank. In Section 3, we de-scribe some ranking algorithms both in top-k and full-order settings, including Ranking SVM, RankBoost, RankNet and ListMLE. Section 4 and Section 5 presents our experimen-tal and theoretical analysis on whether top-k is sufficient for ranking, respectively. Section 6 concludes the paper.
In this section, we will introduce some backgrounds on conventional learning to rank and top-k learning to rank, respectively.
Taking Web search as an example, we describe the frame-work of conventional learning to rank as follows.
In the training process, a number of queries q 1 , q 2 ,  X  X  X  are given. For each query q i , we are given a set of associ-ed in the form of multi-level ratings, such as 3-level ratings (highly relevant:2, relevant:1, irrelevant:0).

With the training data, different ranking algorithms are proposed to conduct the learning process. According to the different objects considered in the loss functions, they are mainly divided into three categories: pointwise, pairwise and listwise approach. In pointwise approach [13], single items are viewed as the objects and ranking is transformed to regression on items to represent the absolute label on each item. In pairwise approach [1, 9, 10], item pairs are recognized as the objects and ranking is transformed to a pairwise classification problem to represent the preference between these two items. In listwise approach [4, 18, 22, 23], instances as document lists are taken as objects and ranking is transformed to a permutation level prediction problem.
In the testing process, for a query q t , we are given it-s associated documents x t = ( x ( t ) 1 , x ( t ) 2 ,  X  X  X  ground-truth labels y t = ( y ( t ) 1 , y ( t ) 2 ,  X  X  X  , y art IR measures such as MAP [3], NDCG [11], ERR [7] are usually adopted to evaluate the performance of the learned ranking function.
Although conventional learning to rank techniques have been widely applied to many real applications, such as in-formation retrieval and collaborative filtering, and made a great success, they are mainly criticized for depending on unreliable training data [2, 19, 20]. To address this prob-lem, many researchers have proposed to utilize more reli-able pairwise preference judgment as an alternative [6, 19, 20]. However, the complexity would be O ( n log n ) to con-struct a full-order ranking list with size n under the pairwise preference judgments [16, 19].

Based on the assumption that top-k ground-truth is suf-ficient for ranking, i.e. training on top-k ground-truth is as good as that in full-order setting , a new top-k learning to rank framework [16, 21] is proposed to utilize top-k ground-truth for training, instead of a full-order ranking list. Specif-ically, the top-k ground-truth is represented as a mixture of the total order of the top k items, and the relative prefer-ences between the set of top k items and the set of the rest n  X  k items. With the top-k ground-truth, new top-k ranking algorithms are proposed to facilitate the learning process. For example, Xia et.al [21] proposed to modify traditional listwise ranking algorithms such as ListMLE[22], ListNet [4] and RankCosine [18] to fit the top-k setting. Niu et.al [16] introduced a mixed model named FocusedRank, in which pairwise losses and listwise losses are employed to model the relative preference relationship and the total order relation-ship, respectively. In [17], a new probabilistic model based on the sequential generation process was proposed for the top-k ranking problem.

Since top-k learning to rank introduces a novel reliable training data construction method and the performances of top-k ranking methods have been shown more effective, it h as gained great attention recently 1 . However, it is not clear whether the underlying assumption that top-k ground-truth is sufficient for ranking is correct. In [21], the authors prove that listwise ranking algorithms such as ListMLE, ListNet and RankCosine are consistent with respect to a permuta-tion level 0-1 loss in top-k setting. However, permutation level 0-1 loss is not appropriate for evaluation since it omits the position information, which is quite an important factor for the ranking problem [8, 14]. Therefore, the correctness of the underlying assumption remains an open question. In this paper, we propose to study the problem from both em-pirical and theoretical aspects.
As mentioned above, the underlying assumption of top-k learning to rank is that training on top-k ground-truth is as good as that on a full-order ranking list. Therefore, to investigate the correctness of the assumption, we propose to conduct both empirical and theoretical analysis on ranking algorithms in both full-order and top-k settings. Before the analysis, we first introduce the precise forms of ranking algo-rithms in both full-order and top-k settings in this section. Specifically, four state-of-the-art ranking algorithms are u-tilized in this paper, including pairwise ranking algorithms such as Ranking SVM [10], RankBoost [9] and RankNet [1], and a listwise ranking algorithm ListMLE [22].
In full-order setting, a full-order ranking list is utilized as the ground-truth. Therefore, we formulate the training ( x 1 , ..., x y denotes the index of the item ranked in the j -th position of y . Please note that x ( i )
Pairwise ranking algorithms utilize the losses on all the pairs as the training objective, therefore the training loss in the full-order setting can be formulated as follows. where L p stands for a pairwise loss, such as the hinge loss used in Ranking SVM, the exponential loss used in Rank-Boost and the logistic loss used in RankNet. (1) Ranking SVM in Full-Order Setting
Ranking SVM [10] utilizes the following hinge loss as the loss function, and applies the SVM technology to optimize the number of misclassified pairs respectively.

Based on the total loss represented by Eq.(1), we formu-lated Ranking SVM in full-order setting as the following
Plea se note that [16] has won the best student paper award of SIGIR2012.

Alg .1: Learning Algorithm for RankBoost in Full-Order Setting 1 Inp ut : training data in terms of full-order ground-truth. 2 Given : initial distribution D i on all the pairs of q i 3 For t = 1 ,  X  X  X  , T 4 train weak ranker f t to minimize: 7 update 8 Output : f ( x ) = op timization probelm: where 1 2  X  w  X  2 co ntrols the complexity of the model w , and C is a trade-off parameter between the model complexity and hinge loss relaxations. (2) RankBoost in Full-Order Setting
RankBoost [9] adopts the boosting technology to output a ranking model by combining the week rankers, where the combination coefficients are determined by the probability distribution on document pairs.

Based on the total loss represented by Eq.(1) and the ex-ponential loss presented as follows, we give the detailed algo-rithm for RankBoost in full-order setting, as shown in Alg.1. (3) RankNet in Full-Order Setting
RankNet aims to optimize a cross entropy between the target probability and the modeled probability, where the probability is defined based on the exponential function of difference between the scores of any two documents in all document pairs given by the scoring function f . The loss function in full-order setting is presented as follows.
L log ( f ; x where,  X  P jl = 1, if j &lt; l , and  X  P jl = 0, otherwise.
In this paper, we use ListMLE [22] as an example of list-wise ranking algorithms due to its nice empirical and the-oretical properties [8]. ListMLE models the generation of a ranking list according to Plackett-Luce Model [15], and utilizes the following likelihood loss for training. where P ( y | x ) is defined as: On this basis, the total loss on the training data { ( q i is represented as follows.

According to the definition of top-k ground-truth that on-ly the total order of top k items are given, we can formu-late the training data in top-k setting as ( q i , x i , Y 1 ,  X  X  X  , N , where q i stands for a query, x i stands for the n i associated documents, Y ( i ) k stands for a set of full-order ranking lists with size n i , such that the total orders of the top k items in these ranking lists are the same while the remaining n i  X  k items form different permutations.
Pairwise algorithms are proposed to utilize all the pairs constructed from training data as the total loss for optimiza-tion. Therefore, with top-k ground-truth, pairs constructed between the last n  X  k items will no longer exist in the total loss, different from the setting of full ordering ground-truth. Furthermore, according to the definition of top-k ground-truth, for any y  X  Y k , the following loss is the same.
Therefore, the total loss of a pairwise ranking algorithm in top-k setting can be represented as follows.
 Incorporating different loss functions L p as described in Eq.(2), Eq.(3) and Eq.(4) into the above equation, we can obtain the total loss of Ranking SVM, RankBoost and RankNet in top-k setting. Since the optimization processes are the same as that in full-order setting, we omit them here for clear representation.
As described in [21], the top-k ground-truth with respec-t to a full-order ranking list y is generated according the probability as follows. S imilarly to the above analysis for pairwise algorithms, for each y  X  Y k , the above probability is the same. Therefore, the probability of top-k ground-truth can be represented as follows.

As a consequence, the total loss in top-k setting can be formulated as the following form.

In this section, we propose to empirically study whether the assumption that top-k ground-truth is sufficient for rank-ing holds. As described in Section 2, the assumption can be formulated as training in top-k setting is as good as that in full-order setting. Therefore, the empirical study can be conducted by comparing the test performances of ranking algorithms in top-k setting and that in full-order setting.
We conduct extensive experiments on the benchmark dataset-s LETOR4.0 2 . In LETOR4.0, the ground-truth for a query is a full-order ranking list in MQ2007-list and MQ2008-list. Therefore, it is easy to construct top-k ground-truth by just preserving the total order of top k items. As a result, these two datasets are suitable for our study in both top-k and full-order setting. The four learning to rank algorithms as mentioned above are all included in our experiments, in-cluding pairwise ranking algorithms such as Ranking SVM, RankBoost and RankNet and a listwise ranking algorithm ListMLE. The training set, validation set and test set have already been divided in LETOR4.0 and we follow the default setting of LETOR 4.0 in our experiments.

In order to compare the test performances of ranking al-gorithms in top-k setting and that in full-order setting, we conduct training process for each ranking algorithm with top-k ground-truth. It is obvious to see that, when k e-quals to the total number of documents for each query, the top-k setting becomes the full-order setting. For each k , parameters are selected through the validation set. For ex-ample, in RankSVM, the tradeoff parameter C is tuned from { 10 5 , 10 4 ,  X  X  X  , 10 1 , 0 . 2 ,  X  X  X  , 1 , 10 , 100 , 1000 Boost, the relative loss variation between two iterations are chosen from 0 . 1 to 10 6 to control the stop condition, and the maximal number of iterations is set to 500. For gra-dient descent procedures as in RankNet and ListMLE, the learning rate is selected from { 10 5 , 10 4 ,  X  X  X  , 10 1 } the maximal number of iterations 500.

Finally, the performances on test set with selected pa-rameters is evaluated with the full-order ground-truth, using NDCG as the evaluation measure.
We plot the performance curves of different ranking al-gorithms with the increase of k in terms of NDCG@5 and NDCG@10, as shown in Figure 1 and Figure 2. For each ranking algorithm, the top sub-figure stands for the overall test performance curves, with k varies from 1 to 1000, and the value in full-order setting is plotted as the rightmost point in the figure. The bottom sub-figure stands for the test performance curves with k varies from 1 to 100.
From the results in Figure 1 and 2, we can see that: (1) Overall, the test performances of ranking algorithms in top-k setting increase to a stable value with the growth of k . This can be clearly illustrated by the experimental results on MQ2008-list as shown in Figure 2. In general, the experimental results on MQ2007-list also agree with the claim. However, it shows in the figure that when k keep-s increasing, the performances will decrease. For example, the performances of Ranking SVM, RankNet and ListMLE h ttp://research.microsoft.com/en-us/um/beijing/projects/letor// will drop when k exceeds 100. More surprisingly, the perfor-mances of these algorithms in full-order setting are even not comparable with that in top-1 setting. At a first glance, this experimental results seem deviate from our intuition that the performance should be better with larger k since more information is conveyed in the training data. However, the results can be explained since there are usually many noises in real training data, especially for labels on the tail docu-ments in a full-order setting. For example, in MQ2007-list, there are 1700 queries and 700 documents per query on av-erage. Therefore, it is difficult to obtain a reliable full-order ground-truth with respect to such a large data set, especially to obtain reliable orders among the tail documents in a list. That is why ranking algorithms in full-order setting perform so badly. (2) By carefully looking into the variance of curves with k varying from 1 to 100 as shown in the bottom sub-figure of each ranking algorithm, we can see that the test perfor-mances of all the four ranking algorithms increase quickly to a stable value with the increase of k . For example, when k exceeds 10 in MQ2007-list and MQ2008-list, the perfor-mances of Ranking SVM, RankNet and ListMLE keep sta-ble. when k exceeds 20, the performance of RankBoost also keeps stable.

In summary, our experimental results on benchmark dataset-s LETOR4.0 show that the test performances quickly in-crease to a stable value with the growth of k in the train-ing data. Therefore, we have empirically proven that top-k ground-truth is sufficient for ranking.
In this section, we propose to study whether the assump-tion of top-k is sufficient for ranking holds from theory as-pect.

Firstly, we formalize the problem as finding the relation-ships among losses in top-k setting, losses in full-order set-ting and IR evaluation measures, theoretically. Inspired by the technique used in [8], we propose a new loss function named Weighted Kendall X  X  Tau (WKT for short), and then deduce the concerned relationships by finding the relation-ship between WKT and losses in top-k setting, and the re-lationship between WKT and IR evaluation meeasures, re-spectively.
As described in Section 2, the assumption can be formulat-ed as training in top-k setting is as good as that in full-order setting. At a first glance, it seems natural to formalize the problem (i.e. whether the assumption holds) as finding the relationship between losses in top-k setting and that in full-order setting. Based on the formulations of total losses in top-k setting and that in full-order setting, we can obtain the following relationships. (1) The pairwise loss functions in full-order setting are upper bounds of that in top-k setting, described as follows. (2) The listwise loss function of ListMLE in full-order set-ting are upper bounds of that in top-k setting, described as follows.
  X 
Thes e relationships mean that the minimization of the former (i.e. loss functions in full-order setting) will lead to the minimization of the latter (i.e. loss functions in top-k setting). However, what we really care about is the opposite side of the coin, i.e. whether the minimization of these loss functions in top-k setting will lead to the minimization of them in full-order setting. Seemingly the answer is negative.
Inspired by the contradiction between the negative answer and the claim of top-k learning to rank, we need to revisit the assumption: training on top-k ground-truth is as good as that on a full-order ranking list. We can see that the term  X  X s good as X  is actually related to the evaluation procedure in ranking. According to the fact that a ranking algorithm is usually evaluated by IR evaluation measures in learning to rank, we find that the theoretical analysis on whether the as-sumption holds need to further take IR evaluation measures into consideration.

Therefore, a more appropriate formalization of the theo-retical problem is to study the relationships among losses in top-k setting, losses in full-order setting and IR evaluation measures . In this paper, we take NDCG as an example to conduct the theoretical analysis, and leave the analysis on other measures such as MAP, ERR in the future work.
As described above, a reasonable theoretical formalization is to study the relationships between the losses in full-order setting, losses in top-k setting and NDCG. Since the re-lationships between losses in full-order setting and that in top-k setting has been revealed in the last subsection, we focus on the relationship between losses in top-k setting and NDCG here.
 Firstly, we give the precise definition of NDCG as follows. where x and y stands for the set of documents and the corre-sponding full-order ground-truth, respectively. r j stands for the rank of x j in the ranking list obtained by f . In the eval-uation[16], the position information is transformed to labels for the computation of NDCG as l ( y j ) = n  X  y j . g ( l ( y is the gain function with g ( l ( y j )) = 2 l ( y j )  X  1, D ( r discount function with D ( r j ) = 1 log (1+ r the maximum of
Here we also list the pairwise losses and listwise loss in top-k setting to make theoretical analysis easier.
L l ( f ; x , Y k )=min Inspired by [8] and [12], we propose a new loss named Weighted Kendall X  X  Tau (WKT) to facilitate the theoretical analysis, which is defined as follows.
 where  X  (  X  ) is a decreasing function to represent the impor-tance of position information, and I fg is the indicator func-tion with I A = 1 if A is true, otherwise I A = 0.
Weighted Kendall X  X  Tau has a nice property that for any full-order ranking list in which the top-k items are consis-tent with that in top-k ground-truth, the loss is the same, described as the following lemma. The property makes WK-T easier to relate NDCG to losses in top-k ground-truth.
Lemma 1. For any set of items x , given the full-order ground-truth y and the top-k ground-truth Y k , for any rank-ing function f , the following equalities hold,
Proof. Firstly, from the definition of the top-k ground-truth as a set of full-order ranking lists where the total orders of the top k items are the same, we can see that y  X  Y k .
Secondly, we prove that for  X  y 1 , y 2  X  Y k , the following equality holds.
According to the definition of top-k ground-truth Y k , the orders of top k items in y 1 and y 2 are the same. Therefore, the following statement holds.
As a consequence, we have Combining the above results, we can obtain that: Therefore, we have proven the results in the lemma.
First, we study the relationship between Weighted K-endall X  X  Tau and (1  X  NDCG). It can be proven that WKT is an upper bound of (1  X  NDCG@ k ), as shown in the following theorem.

Theorem 1. For any set of items x , given the full order-ing ground-truth y and the top-k ground-truth Y k , for any ranking function f , the following inequality holds, wh ere  X  ( j ) = G ( l ( y j )) D ( j ) .
 Proof. First, we formulate N DCG as follows, Ac cording to the definition of N k , we have, Therefore, we have, Second, we consider the Weighted Kendall X  X  Tau case by case. Let  X  ( j ) = G ( l ( y j )) D ( j ), note that 1. If 2. Otherwise, at least  X  l 0  X  [ j + 1 , n ], such that Combining the above results, we can obtain that, Further considering Eq.(15), we have Considering the result of Lemma 1, we have proven that the inequality in the theorem holds.
Here we study the relationship between Weighted Kendal-l X  X  Tau and loss functions of ranking algorithms in top-k set-ting. It can be proven that WKT is a lower bound of loss functions of four ranking algorithms, including pairwise loss in Ranking SVM, RankBoost and RankNet, and a listwise loss in ListMLE, as shown in the following theorem.
Theorem 2. For any set of items x , given the top-k ground-truth Y k , for any ranking function f , (1) Weighted Kendall's Tau L is the lower bound of the pairwise loss function L p ( f ; x , Y k ) , as shown in the following inequality: (2) Weighted Kendall's Tau L is the lower bound of the listwise loss function L l ( f ; x , Y k ) , as shown in the following inequality: Proof. We first prove Eq.(17).

From the definition of hinge loss, exponential loss and logistic loss in Eq.(2), Eq.(3) and Eq.(4), the pairwise loss function can all be represented as a function  X  (  X  ) with  X  (0) = 1, as shown below.
 Therefore, the following equation holds.
 Therefore, it is obvious that Eq.(17) holds.
 Now we prove Eq.(18). Note that 1. If 2. Otherwise, at least  X  l 0  X  [ j + 1 , n ], such that Combining the above results, we can obtain that, Therefore, we have proven that Eq.(18) holds.
Based on the above theorems, the theoretical results can be summarized as follows: (1) Weighted Kendall X  X  Tau is an upper bound of (1  X  NDCG@ k ), as described below with  X  ( j ) = G ( l ( y j )) D ( j ). (2) Weighted Kendall X  X  Tau is a lower bound of loss func-tions in top-k setting, as described below.

Based on these results, we immediately obtain that loss functions in top-k setting are upper bounds of (1  X  NDCG@ k ), described as below with  X  ( j ) = G ( l ( y j )) D ( j ). 1  X  N DCG @ k ( f ; x , y )  X  1
Further considering the relationship between loss func-tions in top-k setting and that in full-order setting, we can obtain the relationships of the three: loss functions in top-k setting are tighter lower bounds of (1  X  NDCG @ k ) , as com-pared with loss functions in full-order setting.

From this theoretical result, we can see that, if a rank-ing algorithm such as Ranking SVM, RankBoost, RankNet and ListMLE in full-order setting performs good, then the same ranking algorithm in top-k setting will definitely per-form better. Therefore, we have proven theoretically that top-k ground-truth is sufficient for ranking. This is also in accordance with our experimental finding that the test per-formances of algorithms in top-k setting (when k reaches certain value) are better than that in full-order setting.
This paper addresses the problem of whether the under-lying assumption of top-k learning to rank holds from both empirical and theoretical aspects. (1) Empirically, we propose to check the variance of test performance curves of ranking algorithms with respect to k in top-k ground-truth to study the problem. For this purpose, we conduct extensive experiments on benchmark datasets LETOR4.0 with pairwise ranking algorithms Rank-ing SVM, RankBoost and RankNet, and a listwise ranking algorithm ListMLE. The results show that the test perfor-mances of all the four algorithms quickly increase to a sta-ble value with the growth of k . As a consequence, we have proven empirically that top-k ground-truth is sufficient for ranking. (2) Theoretically, we formulate the problem as the study of the relationships among loss functions in full-order set-ting, loss functions in top-k setting and IR evaluation mea-sures such as NDCG. Firstly, it is obvious that loss functions in top-k setting are lower bound of that in full-order set-ting. Secondly, through a newly defined loss function named Weighted Kendall X  X  Tau, we prove that (1  X  NDCG@ k ) is a lower bound of losses in top-k setting. Therefore, loss functions in top-k settings are tighter lower bounds of (1 NDCG@ k ), as compared to that in full-order setting. In oth-er words, we have proven theoretically that top-k ground-truth is sufficient for ranking.

In summary, our analysis have proven the correctness of the assumption of the top-k learning to rank and lay a foun-dation for the new learning to rank framework.

There are still many issues need further investigation. For example, in this paper, we conduct theoretical analysis based on the relationship between different objectives. It would also makes sense to conduct statistical consistency analysis between algorithms in top-k setting and that in full-order setting.
 This research work was funded by the National Natural Science Foundation of China under Grant No. 61003166 , No. 61203298 , No. 61232010, 973 Program of China under Grants No. 2012CB316303, No. 2013CB329602, and Nation-al Key Technology R&amp;D Program under Grants No. 2012BAH46B04, No. 2012BAH39B02. [1] C. Burges, T. Shaked, E. Renshaw, A. Lazier, [2] R. Burgin. Variations in relevance judgments and the [3] C. Burkley and E. M. Voorhees. Retrieval System [4] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. [5] B. Carterette and P. N. Bennett. Evaluation measures [6] B. Carterette, P. N. Bennett, D. M. Chickering, and [7] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. [8] W. Chen, T.-Y. Liu, Y. Lan, Z.-M. Ma, and H. Li. [9] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An [10] R. Herbrich, T. Graepel, and K. Obermayer. Large [11] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [12] Y. Lan, J. Guo, X. Cheng, and T.-Y. Liu. Statistical [13] P. Li, C. Burges, and Q. Wu. McRank: Learning to [14] T.-Y. Liu. Learning to rank for information retrieval. [15] R. D. Luce. Individual Choice Behavior . Wiley, New [16] S. Niu, J. Guo, Y. Lan, and X. Cheng. Top-k learning [17] S. Niu, Y. Lan, J. Guo, and X. Cheng. A new [18] T. Qin, X.-D. Zhang, M.-F. Tsai, D.-S. Wang, T.-Y. [19] F. Radlinski and T. Joachims. Query chains: learning [20] R. Song, Q. Guo, R. Zhang, and X. Guo.
 [21] F. Xia, T.-Y. Liu, and H. Li. Statistical consistency of [22] F. Xia, T.-Y. Liu, J. Wang, W. Zhang, and H. Li. [23] J. Xu and H. Li. Adarank: a boosting algorithm for
