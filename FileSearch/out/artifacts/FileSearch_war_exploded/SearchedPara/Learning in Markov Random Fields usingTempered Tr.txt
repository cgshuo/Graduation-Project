 Markov random fields (MRF X  X ) provide a powerful tool for repr esenting dependency structure be-tween random variables. They have been successfully used in various application domains, includ-ing machine learning, computer vision, and statistical phy sics. The major limitation of MRF X  X  is set of random variables. Maximum likelihood learning in MRF  X  X  is often very difficult because of the hard inference problem induced by the partition functio n. When modeling high-dimensional, richly structured data, the inference problem becomes much more difficult because the distribution we need to infer is likely to be highly multimodal [17]. Multi modality is common in real-world distributions, such as the distribution of natural images, in which an exponentially large number of possible image configurations have extremely low probabi lity, but there are many very different images that occur with similar probabilities.
 connected MRF X  X  that contain millions of parameters. While there exists a substantial literature on developing approximate learning algorithms for arbitrary MRF X  X , many of these algorithms are un-likely to work well when dealing with high-dimensional inpu ts. Methods that are based on replacing the likelihood term with some tractable approximations, su ch as pseudo-likelihood [1] or mixtures of random spanning trees [11], perform very poorly for dense ly-connected MRF X  X  with strong de-pendency structures [3]. When using variational methods, s uch as loopy BP [18] and TRBP [16], learning often gets trapped in poor local optima [5, 13]. MCM C-based algorithms, including MCMC maximum likelihood estimators [3, 20] and Contrastive Dive rgence [4], typically suffer from high variance (or strong bias) in their estimates, and can someti mes be painfully slow. The main problem In this paper we concentrate on the class of stochastic appro ximation algorithms of the Robbins-Monro type that use MCMC to estimate the model X  X  expected suf ficient statistics, needed for max-imum likelihood learning. We first show that using this class of algorithms allows us to make very rapid progress towards finding a fairly good set of parameter s, even for models containing millions of parameters. Second, we show that using MCMC operators bas ed on tempered transitions [9] en-improves parameter estimates, particularly in large, dens ely-connected MRF X  X . Our results on the MNIST and NORB datasets demonstrate that the stochastic app roximation algorithm together with tempered transitions can be successfully used to model high -dimensional real-world distributions. Let x  X  X  K be a random vector on K variables, where each x the following parameterized set of probability distributi ons: For example, consider the following binary pairwise MRF. Gi ven a graph G = ( V,E ) with vertices V and edges E , the probability distribution over a binary random vector x  X  X  0 , 1 } K is given by: The derivative of the log-likelihood for an observation x obtained from Eq. 1: where E as the tree structured graphs exact maximum likelihood lear ning is intractable, because exact com-putation of the expectation E One approach is to learn model parameters by maximizing the p seudo-likelihood (PL) [1], which replaces the likelihood with a tractable product of conditi onal probabilities: where x estimates for weak dependence, when p ( x likelihood function. For MRF X  X  with strong dependence stru cture, it is unlikely to work well. Another approach, called the MCMC maximum likelihood estim ator (MCMC-MLE) [3], has been shown to sometimes provide considerably better results tha n PL [3, 20]. The key idea is to use importance sampling to approximate the model X  X  partition f unction. Consider running a Markov samples can be used to approximate the log-likelihood ratio for an observation x Algorithm 1 Stochastic Approximation Procedure. vided our Markov chain is ergodic, it can be shown that L shown that, under the  X  X sual X  regularity conditions, if  X   X  then  X   X  tions, goes to infinity, MCMC-MLE will converge to the true ma ximum likelihood estimator. While particularly when the parameter vector  X  is high-dimensional. In high-dimensional spaces, the vari -ance of an estimator L MCMC-MLE by considering a mixture of proposal distribution s [20], they do not fix the problem when learning MRF X  X  with millions of parameters. We now consider a stochastic approximation procedure that u ses MCMC to estimate the model X  X  mation algorithms of the Robbins-Monro type [19, 12]. The al gorithm itself dates back to 1988 [19], but only recently it has been shown to work surprisingly well when training large MRF X  X , including restricted Boltzmann machines [15] and deep Boltzmann mach ines [14, 13].
 The idea behind learning a parameter vector  X  using SAP is straightforward. Let x tion. Then the state and the parameters are updated sequenti ally: Given x t , we sample a new state x t +1 using the transition operator T tion E model X  X  expectation is replaced by the sample average 1 / M P M summarized in Algorithm 1.
 One important property of this algorithm is that just like MC MC-MLE, it can be shown to asymp-MRF X  X , if one uses a Gibbs transition operator and the learni ng rate is set to  X  is a positive constant, such that U &gt; 2 KC is the dimensionality of x , C gradient, and C only: C true gradient of the log-likelihood function: S (  X  ) =  X  log p ( x 0 ;  X  ) parameter update rule then takes the following form: Algorithm 2 Tempered Transitions Run. algorithm is therefore a perturbation of this discretizati on with the noise term  X  small compared to the mixing rate of the Markov chain, the cha in will stay close to the stationary ensure that the noise term  X  progress towards finding a sensible region in the parameter s pace. However, as the algorithm be-gins to capture the multimodality of the data distribution, the Markov chain tends to mix poorly, producing highly correlated samples for successive parame ter updates. This often leads to poor pa-rameter estimates, especially when modeling complex, high -dimensional distributions. The main problem here is the inability of the Markov chain to efficient ly explore a distribution with many isolated modes. However, the transition operators T imation algorithm do not necessarily need to be simple Gibbs or Metropolis-Hastings updates to guarantee almost sure convergence. Instead, we propose to u se MCMC operators based on tem-implementing tempered transitions requires very little ex tra work beyond the implementation of the Gibbs sampler. 3.1 Tempered Transitions bility distributions: p from than p general depend on the problem. One general way to define this s equence is: with  X  X nverse temperatures X   X  define a transition operator T is the Gibbs sampling operator. We also need to define a revers e transition operator e T satisfies the following reversibility condition for all x and x  X  : If as Metropolis X  X astings, are reversible. Non-reversible o perators are usually composed of several reversible sub-transitions applied in sequence T in a Gibbs sampler. The reverse operator can be simply constr ucted from the same sub-transitions, but applied in the reverse order e T Given the current state x of the Markov chain, tempered transitions apply a sequence o f transition operators T Since p x label state will be much broader than the mode in which the current s tart state resides. The procedure is shown in Algorithm 2. Note that there is no need to compute t he normalizing constants of any intermediate distributions.
 Tempered transitions can make major changes to the current s tate, which allows the Markov chain to produce less correlated samples between successive para meter updates. This can greatly improve the accuracy of the estimator, but is also more computationa lly expensive. We therefore propose to alternate between applying a more expensive tempered trans itions operator and the standard Gibbs updates. We call this algorithm Trans-SAP. In our experiments we used the MNIST and NORB datasets. To spe ed-up learning, we subdivided few preliminary experiments and picking the learning rates that worked best on the validation set. We also use natural logarithms, providing values in nats. 4.1 MNIST The MNIST digit dataset contains 60,000 training and 10,000 test images of ten handwritten digits 10,000 images was set aside for validation.
 In our first experiment we trained a small restricted Boltzma nn machine (RBM). An RBM is a par-ticular type of Markov random field that has a two-layer archi tecture, in which the visible binary bility that the model assigns to a visible vector x is: approximation procedure, the total number of parameter upd ates was 100,000, so the learning took about 25.6 minutes on a Pentium 4 3.00GHz machine. The learni ng rate was kept fixed at 0.01 for trained the same model using exact maximum likelihood with e xactly the same learning schedule. Perhaps surprisingly, SAP makes very rapid progress toward s the maximum likelihood solution, even though the model contains 8634 free parameters. The top panel of Fig. 1 further shows that combining regular Gibbs updates with tempered transitions provides a more accurate estimator. We applied tempered transitions only during the last 50,000 Gi bbs steps, alternating between 200 Gibbs The acceptance rate for the tempered transitions was about 0 .8. To be fair, we compared different algorithms based on the total number of Gibbs steps. For SAP, parameters were updated after each Gibbs step (see Algorithm 1), whereas for Trans-SAP, parame ters were updated after each Gibbs time compared to the plain SAP. Pseudo-likelihood and MCMC m aximum likelihood estimators perform quite poorly, even for this small toy problem.
 In our second experiment, we trained a larger semi-restrict ed Boltzmann machine that contained 705,622 parameters. In contrast to RBM X  X , the visible units in this model form a fully connected pairwise binary MRF (see Fig. 1, bottom left panel). The mode l had 500 hidden units and was of Gibbs updates was set to 200,000, so the learning took abou t 19.5 hours. The learning rate was The bottom panel of Fig. 1 shows classification performance o n the full MNIST test set. As ex-Using tempered transitions further improves classificatio n performance. As in our previous exper-iment, tempered transitions were only applied during the la st 100,000 Gibbs updates, alternating between 1000 Gibbs updates and a single tempered transition s run that used 500  X   X  X  spaced uni-formly from 1 to 0.9. The acceptance rate was about 0.7. After learning was complete, in addition to classification performance, we also estimated the log-pr obability that both models assigned to the test data. To estimate the models X  partition functions, we used Annealed Importance Sampling [10, 13]  X  a technique that is very similar to tempered transi tions. The plain stochastic approxi-mation algorithm achieved an average test log-probability of -87.12 per image, whereas Trans-SAP achieved a considerably better average test log-probabili ty of -85.91. To get an intuitive picture of how tempered transitions oper ate, we looked at the sample particles before and after applying a tempered transitions run. Figur e 2 shows sample particles after 100,000 tempered transitions reveals that the current model is very unbalanced, with more probability mass placed on images of four. To further test whether the  X  X efres hed X  particles were representative of the current model, we generated samples from the current mod el by randomly initializing binary states of the visible and hidden units, and running the Gibbs sampler for 500,000 steps. Clearly, the refreshed particles look more like the samples generate d from the true model. This in turn al-learning a better generative model. 4.2 NORB Results on MNIST show that the stochastic approximation alg orithm works well on the relatively simple task of handwritten digit recognition. In this secti on we present results on a considerably more difficult dataset. NORB [6] contains images of 50 differ ent 3D toy objects with 10 objects in each of five generic classes: planes, cars, trucks, animals, and humans. The training set contains 24,300 stereo image pairs of 25 objects, whereas the test set contains 24,300 stereo pairs of the training data, 4,300 cases were set aside for validation.
 the dimensionality of each image from 9216 down to 4488 by usi ng larger pixels around the edges of the image 5 . We also augmented the training data with additional unlabeled data by applying simple followed the approach of [8] by first learning a Gaussian-bin ary RBM with 4000 hidden units, and then treating the the activities of its hidden layer as  X  X rep rocessed X  data. The model was trained using contrastive divergence learning for 500 epochs. The l earned low-level RBM effectively acts as a preprocessor that transforms greyscale images into 400 0-dimensional binary vectors, which we use as the input for training our models.
 by the preprocessor module 6 . The RBM, containing over 16 million parameters, was traine d in a completely unsupervised way. The total number of Gibbs upda tes was set to 400,000. The learn-ing rate was kept fixed at 0.01 for the first 100,000 parameter u pdates, and was then annealed as last 200,000 Gibbs updates, alternating between 1000 Gibbs updates and a single tempered transi-tions run that used 1000  X   X  X  spaced uniformly from 1 to 0.9. Figure 3 shows samples generated from two models, trained us ing stochastic approximation with ing conditions. The plain stochastic approximation algori thm produced a very unbalanced model with a large fraction of the model X  X  probability mass placed on images of humans. Using tempered transitions allowed us to learn a better and more balanced ge nerative model, including the light-ing effects. Indeed, the plain SAP achieved a test log-proba bility of -611.08 per image, whereas Trans-SAP achieved a test log-probability of -598.58.
 We also tested the classification performance of both models simply by fitting a logistic regression model to the labeled data (using only the 24300 labeled train ing examples without any translations) using the top-level hidden activities as inputs. The model t rained by SAP achieved an error rate of 8.7%, whereas the model trained using Trans-SAP reduced t he error rate down to 8.4%. This is compared to 11.6% achieved by SVM X  X , 22.5% achieved by logis tic regression applied directly in the pixel space, and 18.4% achieved by K-nearest neighbors [ 6]. We have presented a class of stochastic approximation algor ithms of the Robbins-Monro type that can be used to efficiently learn parameters in large densely-connected MRF X  X . Using MCMC oper-ators based on tempered transitions allows the stochastic a pproximation algorithm to better explore highly multimodal distributions, which in turn allows us to learn good generative models of hand-written digits and 3D objects in a reasonable amount of compu ter time.
 of other methods for sampling from distributions with many i solated modes, including simulated tempering [7] and parallel tempering [3], all of which can be incorporated into SAP. In particular, the concurrent work of [2] employs parallel tempering techn iques to imrpove mixing in RBM X  X . There are, however, several advantages of using tempered tr ansitions over other existing methods. First, tempered transitions do not require specifying any e xtra variables, such as the approximate values of normalizing constants of intermediate distribut ions, which are needed for the simulated tempering method. Second, tempered transitions have modes t memory requirements, unlike, for states are generated. Finally, the implementation of tempe red transitions requires almost no extra work beyond implementing the Gibbs sampler, and can be easil y integrated into existing code. Acknowledgments We thank Vinod Nair for sharing his code for blurring and tran slating NORB images. This research was supported by NSERC.
 [1] J. Besag. Efficiency of pseudolikelihood estimation for simple Gaussian fields. Biometrica , [2] G. Desjardins, A. Courville, Y. Bengio, P. Vincent, and O . Delalleau. Tempered Markov chain [3] C. Geyer. Markov chain Monte Carlo maximum likelihood. I n Computing Science and Statis-[4] G. Hinton. Training products of experts by minimizing co ntrastive divergence. Neural Com-[5] A. Kulesza and F. Pereira. Structured learning with appr oximate inference. In NIPS , 2007. [6] Y. LeCun, F. J. Huang, and L. Bottou. Learning methods for generic object recognition with [7] E. Marinari and G. Parisi. Simulated tempering: A new Mon te Carlo scheme. Europhysics [8] V. Nair and G. Hinton. Implicit mixtures of restricted Bo ltzmann machines. In Advances in [9] R. Neal. Sampling from multimodal distributions using t empered transitions. Statistics and [10] R. Neal. Annealed importance sampling. Statistics and Computing , 11:125 X 139, 2001. [11] P. Pletscher, C. Ong, and J. Buhmann. Spanning tree appr oximations for conditional random [12] H. Robbins and S. Monro. A stochastic approximation met hod. Ann. Math. Stat. , 22:400 X 407, [13] R. Salakhutdinov. Learning and evaluating Boltzmann m achines. Technical Report UTML TR [14] R. Salakhutdinov and G. Hinton. Deep Boltzmann machine s. In Proceedings of the Interna-[15] T. Tieleman. Training restricted Boltzmann machines u sing approximations to the likelihood [16] M. Wainwright, T. Jaakkola, and A. Willsky. Tree-rewei ghted belief propagation algorithms [17] M. Welling and C. Sutton. Learning in Markov random field s with Contrastive Free Ener-[18] J. S. Yedidia, W. T. Freeman, and Y. Weiss. Constructing free-energy approximations [20] S. Zhu and X. Liu. Learning in Gibbsian fields: How accura te and how fast can it be? In
