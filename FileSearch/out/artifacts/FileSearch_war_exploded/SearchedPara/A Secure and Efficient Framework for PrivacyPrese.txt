 A Recommender system automatically generates meaningful recommendations to a collection of users for items such as books and movies that might interest them. Collaborative filtering (CF) is a mature technique adopted by most mod-ern recommender systems such as Amazon and Netflix. The basic idea of CF is that similar users will like the same items (user-based CF), and that a user will prefer items that are similar to other items he or she has purchased in the past (item-based CF). One typical challenge of CF in practice is the well-known cold start problem: new users should rate sufficient number of items to get their preferences captured by the recommender system, and new items should also be rated by sufficient number of users before they could be recommended to users. To address the cold start problem, a wide variety of social recommenda-tion approaches [7, 17] have appeared in the literature. The motivation of social recommendation is that the explicit social relations among users provided by a social graph could be used as a data source to calculate user similarities required in CF. Recent studies have shown that soc ial recommendation outperforms tra-ditional, non-social approaches in many application domains.

Though the benefits brought by recommender systems is significant, it also poses a serious threat to personal pri vacy. In non-social recommendation, the private user transaction data, such as which item were bought by a user and how the user rates these items, is required to report to the recommender system. Personal information like gender, age, health condition can be easily inferred from these data. In addition, the r ecommender system must have full access to user social relations to enable social recommendation, which clearly violates against personal privacy.

The public concern over privacy stimulated lots of research efforts in privacy preserving recommender sys tems recently [15, 13, 12, 3, 11, 5, 8]. While most studies have focused on non-social reco mmendation, little attention has been paid to privacy preserving social recommendation. In [5], the authors study this problem under the differential privacy paradigm. This work prevents the inference of any single user X  X  data from the recommendation results, but has a strong assumption that the underlying data, including user-item matrix and social graph, reside with a trusted and s ecured central party, and that the recom-mender has full, unfettered access to the data. In practice, however, social graph is owned by a third party such as Facebook or Twitter (we refer to the social net-working service provider as Bob). The proprietary social graph is an important asset with inestimable value, thus Bob must keep it secret for obvious reasons of commercial benefits, as well as due to pr ivacy legislation. For the same rea-son, the recommender system (typically established by an electronic commerce platform like Amazon and we refer to it as Alice) must keep his historic sales data (e.g., the user-item matrix) secret. Therefore, we face a scenario in which Alice holds only historic sales data and Bob holds only the social graph. It is therefore necessary to design a method that enables Alice and Bob to cooper-atively perform social recommendation without any information leakage about their individual data.

In this paper, we present a secure and efficient framework for privacy preserv-ing social recommendation. The main contributions of our work can be summa-rized as follows: 1. We combine homomorphic cryptosystem and Yao X  X  garbled circuit to design 2. We theoretically analyze the complexity of the proposed framework and
The rest of paper is organized as follo ws. Section 2 formalizes our model and definitions, while Section 3 reviews some background knowledge and re-lated work. In Section 4, we present our f ramework for privacy preserving social recommendation. We report the experiment al results on real-world datasets in Section 5 and conclude our work in Section 6. 2.1 Data Model Following the model presented in [5], we have two parties Alice and Bob. Alice provides an electronic commerce platform and has the historic transaction data. Bob provides a social networking platform and has the social relation data. The historic transaction data and the social relation data are modeled as a transaction graph and a social graph , respectively.
 Definition 1 (Transaction Graph). A transaction graph, G t =( U, I, E t ) ,isa bipartite graph where U is a set of users, I is a set of items, and E t  X  U  X  I is a set of directed edges. Every edge ( u, i ) is associated with a weight w ( u, i )  X  0 , indicating user u has not purchased item i if w ( u, i )=0 and otherwise the rating user u gives to item i .
 Definition 2 (Social Graph). A social graph, G s =( U, E s ) , consists of a set of users, U , and a set of edges, E s  X  U  X  U , where an edge ( u, v )  X  E s represents a social relation between two user u, v  X  U .

Note that the transaction graph could be easily extended to model data in other application domains. For example, an edge ( u, i ) might indicate that a user u of Last.fm has listened to a song by artist i , or that a user u of Brightkite.com has visited location i . In these cases, the weight w u,i might be the number of times that u listened to a song by artist i ,orthat u visited location i . Also note that many real-world online social networks can be modeled with the social graph. For example, an edge ( u, v ) in the social graph might indicate that the  X  X riendship X  relation between two users u and v in Facebook, or the  X  X ollowing X  relation between two users u and v in Twitter. 2.2 Privacy Preserving Social Recommendation For each user u of the electronic commerce platform, Alice recommends a size K item set R u  X  I with the highest scores. Here, the score of recommending item i to user u (or just the score of item i where the context is c lear), is denoted as s ( u, i ), and is computed as follows: where sim ( u, v ) is the similarity between two users u, v  X  U . In non-social recom-mendation, sim ( u, v ) is typically evaluated based on the purchase profiles p of u In social recommendation, however, sim ( u, v ) is usually evaluated based on so-cial similarity measures[10], such as common neighbors (CN), Katz, and random walk with restart (RWR), just to name a few.

An important observation here is that the calculation of sim ( u, v )innon-social recommendation can be conducted solely on the transaction graph G t , while in social recommendation the social graph G s is indispensable for this calculation. Clearly, to enable social recommendation, Alice must have full, un-fettered access to G s that is owned by Bob. As stated before, however, Bob wants to keep it secret for both commercial benefi ts and privacy legislation. This chal-lenging situation inspires us to give the definition of privacy preserving social recommendation as follows: Definition 3 (Privacy preserving social recommendation). Given a private transaction graph G t =( U, I, E t ) hold by Alice, a private social graph G s = ( U, E s ) hold by Bob, and a social similarity measure sim , Alice and Bob cooper-atively compute, for each user u  X  U , a size K item set R u  X  I with the highest scores, without revealing their private data (i.e., G t and G s )toeachother. 2.3 Assumptions Static Recommendation. For simplicity, we only consider in this paper static social recommendation, that is, we take a snapshot of G t and G s at some time and all the recommendations are generated based on these fixed graphs at that time. Dynamic behaviors on G t and G s , such as the insertion/deletion of new/old nodes and edges, will cause Alice and Bob to run the proposed protocols from the beginning. We leave extending our protocols to dynamic recommendation as a subject for future work.
 Adversarial Model. We assume that Alice and Bob are semi-honest , also known as  X  X onest but curious X . They run the protocol exactly as specified (no deviations, malicious or otherwise), but may try to learn as much as possible about the input of the other party from their views of the protocol. It should be noted that though secure protocols against malicious adversaries exist, they are far too inefficient to implement and be used in practice. Secure protocols against semi-honest adversaries, however, are not only useful in practice but also the foundation of designing secure protoc ols against malicious adversaries. 3.1 Paillier Cryptosystem We use the Paillier cryptosystem [14] to encrypt the private data of Alice and Bob. The encryption function E is defined as E pk ( m, r )= g m  X  r N mod N 2 where m  X  Z  X  N is a message for encryption, N is a product of two large prime numbers p and q , g generates a subgroup of order N ,and r is a random number in Z is ( p, q ). The details of decryption function D with secret key sk can be found in [14]. The properties of the Paillier cryptosystem include homomorphic addition and semantic security. Homomorphic addition : The product of two ciphertexts will be decrypted to the sum of their corresponding plaintexts, and the k th power of a ciphertext will be decrypted to the product of k and its corresponding plaintext. Semantic security : Given a set of ciphertexts, an adversary cannot deduce any information about the plaintexts. 3.2 Yao X  X  Protocol Yao X  X  protocol [16, 9] (a.k.a. garbled circuits) allows two semi-honest parties holding inputs x and y , respectively, to evaluate an arbitrary function f ( x, y ) without leaking any information about the inputs beyond what can be deduced by the function output. The basic idea is that one party (the garbled-circuit constructor ) constructs a garbled version of a circuit to compute f , while the other party (the garbled-circuit evaluator ) obliviously computes the output of the circuit without learning any intermediate values. Two simple circuits will be used in this paper to realize secure integer comparison required in the top-K selection. An ADD circuit takes two  X  -bit integers x and y as input, and outputs a(  X  +1)-bit integer z , such that z = x + y . A CMP circuit takes two  X  -bit integers x and y as input, and outputs 1 if x&gt;y and 0 otherwise. The details of ADD and CMP circuits can be found in [6]. 3.3 Privacy Preserving Recommender Systems The need for privacy preserving in reco mmender systems triggered lots of re-search efforts in the past years. Shokri et al . present a recommender system built on distributed aggregation of user profiles, which suffers from the trade-off between privacy and accuracy [15]. In [13, 12], Nikolaenko et al . consider two ba-sic problems in model-based recommendation algorithms: matrix factorization and ridge regression. For the first problem, they propose a solution based on Yao X  X  protocol. For the second problem, they design a hybrid method by comb-ing Yao X  X  protocol and homomorphic encryption. In [3], the authors present a solution for privacy preserving recommendation via homomorphic encryption and data packing. These efforts focus on non-social recommendation and what has being protected is users X  individual data, for example, which items were bought by a user and how the user rate these items. That is, Alice does not have full access to the transaction graph G t . In this paper, however, we aim at privacy preserving in social recommendation. Following the model defined in [5], we assume Alice has full access to G t and Bob has full access to G s . In the course of recommendation, Alice is not willing to reveal her private data G t to Bob, and vice versa. Privacy preserving social recommendation is also studied in [8] where the authors present a framework for secu re social recommendations in geosocial networks. They introduce a mix network for message transmitting to prevent the service provider (i.e., Alice in our model) from learning users X  social relations. However, this work is not secure as the service provider can easily learn a lot of social relations by statistical analysis.

There is also a number of achievements that aim at privacy preserving recom-mender systems under the differential privacy paradigm. McSherry and Mironov [11] integrates differential privacy in to non-social recommender systems. How-ever, their work will lead to an unacceptable loss of utility when applied to the social recommendation. To overcome t his weakness, Jorgensen and Yu [5] incorporates a clustering procedure that groups users according to the natural community structure of the social network and significantly reduces the amount of noise. This kind of work is orthogonal to ours. In differential privacy, the recommender system has fu ll access to the data ( G t in the non-social recom-mendation, while G t and G s in the social recommendation). The privacy threat arises from releasing a function (e.g., get recommendation for a given user) over the data to a third party, who may use it to infer data values of users in the database. Whether the final results expose personal privacy is not the concern of our work. Instead, we are interested i n keeping data secret during computation. In this section, we present our framewor k for privacy preserving social recom-mendation. In Section 4.1, we present a p rotocol that computes the scores of items while keeping both Alice X  X  and Bo b X  X  data secret. As these scores are in the encrypted form, it is impossible to compare them directly. Instead, we combine Yao X  X  garbled circuits with homomorphic encryption to realize secure comparison between two encrypted values, based on which an efficient protocol for secure top-K selection is proposed, as discussed in Section 4.2. Section 4.3 analyzes the security and complexity of the proposed protocols. 4.1 Privacy Preserving Recommendation Score Computation For a target user u and every user v  X  U \{ u } , the similarity between them, sim ( u, v ), should be available before computing the score of recommending an item i to user u , as seen in Formula 1. Once the similarity measure sim is fixed, the computation can be carried out directly for a simple similarity measure such as common neighbors . For a complex similarity measure, some mature algorithms can be adopted, for example, the bookmark-coloring algorithm [1] can be used to efficiently calculate the similarity measure random walk with restart . Social similarity measures and their efficient c alculations is an interesting topic but not the focus of this paper, so we simply assume that Bob is able to compute sim ( u, v ) based on his private social graph G s and the given similarity measure sim .

These similarities, however , cannot be sent directly to Alice, as this might lead to serious privacy leakage. Specifically, Alice might learn part even the whole social graph G s , the private data of Bob. Suppose common neighbors is used for similarity computation and Alice has the background knowledge that there are totally 3 users u, v, w in the social network. If Alice learns sim ( u, v )=1 and sim ( u, w ) = 1, she can infer that any two of them are friends, that is, she knows the whole social graph. To keep his private data secret, Bob adopts the Paillier cryptosystem to encrypt these similarities. More specifically, he first chooses a key pair ( pk, sk ) in the Paillier cryptosystem and encrypts sim ( u, v ) for all v  X  U \{ v } using the public key pk . These encrypted similarities as well as the public key pk can then be safely sent to Alice. Provided Alice does not know Bob X  X  secret key sk , she cannot deduce any information from these encrypted data, which is guaranteed by Paillier X  X  semantic security .

After receiving the encrypted similarities, Alice needs to compute the score of recommending item i to the target user u for every i that u has not purchased yet, as defined in Formula 1. This computation is feasible on ciphertexts as Paillier supports homomorphic addition .Inparticular, s ( u, i ) can be calculated by Alice as follows: Note that, w ( v,i ) is a plaintext as it is the private data of Alice, but the final result E pk ( s ( u, i )) is still an encrypted value as Alice only knows the public key pk of Bob.

The above procedure is summarized in Algorithm 1. Alice and Bob cooper-atively run this protocol for privacy preserving recommendation score compu-tation. In the end, Alice obtains the scores of recommending new items to the target user u in the encrypted form.
 Recall that in social recomme ndation Alice recommends a size K item set R On ciphertext, however, this becomes a much harder task as comparison is not supported by the Paillier cryptosystem. Considering only Bob has the secret key, a simple solution is that these encrypted scores are sent to Bob for decryption. However, this is not secure, as for each d ecrypted score, Bob can create a system of linear equations based on Formula 1. Clearly, there are | U | X  1 equations and |
U | X  1 variables. Therefore, Bob can know Alice X  X  private data w ( v,i ) for all v  X  U \{ u } by solving these equations.

Next, we will present an efficient protocol for top-K selection on encrypted scores. Based on these protocols, we can build a secure and efficient framework for privacy preserving social recommendation. 4.2 Secure Top-K Selection Recall that the objective of social r ecommendation is to recommend a set of K items with the highest scores. As we ar e not interested in the order among Algorithm 1. Privacy Preserving Recommendation Score Computation these K items, we build our protocol for secure top-K selection based on the well-known randomized-sel ection algorithm with expected linear time [2]. At the beginning of Algorithm 2, an array A is used to store the indices of items that the target user u has not purchased yet (line 1). Then, a value k is selected randomly from the range [ l,h ] for the index of the pivot (line 3), followed by a partition on the subarray A [ l..h ] that returns the pivot X  X  new index (line 4). This partition holds. In other words, the subarray A [1 ..k ] contains the indices of all items with the highest scores. Therefore, if k equals to K , the protocol terminates by lines 7-8, a new partition is performed on a new subarray ( A [ k +1 ..h ]if k&lt;K or A [ l..k  X  1] if k&gt;K ) and this process continues until the returned pivot X  X  index equals exactly to K .

The key operation in the partition procedure is the comparison of two scores encrypted by the Paillier cryptosystem (lines 13 and 16). As Paillier does not support comparison over ciphertexts, we first make these scores additively se-cret shared between Alice and Bo b. More specifically, a score s is additively secret shared between two parties Alic e and Bob if Alice holds a uniformly dis-tributed random number r sampled from a sufficiently large domain, Bob holds s ,and r + s = s . Clearly, neither Alice nor Bob knows the actual value of s . first picks N = | I n u | random integers and computes the product of E pk ( s ( u, i j )) and E pk (  X  r j ) for each random integer r j based on Bob X  X  public key pk . Clearly, Alice now has two lists L r and L E ( s  X  r ) in hand where L r = { r 1 ,  X  X  X  ,r N } and L to Bob. As Bob has the secret key sk , he can decrypt all elements in L E ( s  X  r ) Clearly, every score s ( u, i j )in L is now additively secret shared between Alice and Bob, because Alice holds r j and Bob holds s ( u, i j )  X  r j . Then, Alice prepares a garbled circuit to compare two additi vely secret shared values and makes it available to Bob. This circuit is quite simple as it only consists of two ADD circuits and a CMP circuit. One ADD circuit takes for example r 1 and s ( u, i 1 )  X  r 1 as input and the other takes for example r 2 and s ( u, i 2 )  X  r 2 as input, while their encoding of garbled circuits) serve as the inputs of the CMP circuit. Algorithm 2. Secure Top-K Selection 4.3 Theoretical Analysis Security Analysis. In Algorithm 1, Bob sends E pk ( sim ( u, v )) and pk to Alice. These data do not reveal any private information of Bob due to the semantic security of the Paillier cryptosystem. In Algorithm 2, Alice sends a list of en-crypted values L E ( s  X  r ) to Bob for secret sharing. As Bob can decrypt them using his private key sk , we build a simulator S to simulate this kind of information. As all the values obtained by Bob are masked by random numbers chosen from a sufficiently large domain, they are independent from Alice X  X  input. S can also randomly choose some elements in the same domain. It is clear that there does not exist an adversary that is able to distinguish between interaction with Alice verses interaction with S , which means revealing this kind of information will not harm the private information of Alice. After secret sharing, Alice and Bob cooperatively execute a garbled circuit, so Algorithm 2 is secure as long as Yao X  X  garbled circuit is secure, which has been proved in [9].
 Complexity Analysis. In Algorithm 1, Bob needs to perform | U | encryptions and Alice needs to do | I | exponentiations. In Algorithm 2, | I | encryptions and exponentiations are required to be done by Alice and | I | decryptions by Bob for secret sharing. The garbled circui t prepared by Alice consists of two ADD circuits and one CMP circuit, thus containing 3  X  + 1 non-free gates given the input of ADD circuits are  X  -bits long. As this garbled circuit will be executed |
I | times in average, the total cost is (3  X  +1) | I | non-free gates.
 Four public available datasets are used to evaluate the performance of our frame-work. Last.fm 1 is a relatively small dataset containing social networking and mu-sic artist listening information. Flixter.com 2 is a social movie site allowing users to share movie ratings, discover new movies and meet others with similar movie taste. Brightkite.com 3 and Gowalla.com 4 are location-based social networking websites where users share their locations by checking-in. The statistics of these four datasets are summarised in Table 1.

We adopt random walk with restart [10] as the social similarity measure and use the bookmark-coloring algorithm [1] to calculate item scores. For Paillier cryptosystem, we also use a public available Java implementation 5 . The Paillier encryption key size is set to 1024. Note that this size will make encryption and decryption much more time-consuming, but will increase the level of security at the same time. Besides, we implement Yao X  s garbled circuits based on FasterGC [4]. The size K of recommended item set is set to 10. All experiments all per-formed on a PC with 3.4GHz CPU, 16GB RAM, JDK 7, and OS X Yosemite.

As shown in Table 2, our framework takes less than 4 minutes to generate recommendations on Last.fm dataset that contains 1892 users and 17632 items. Even for the biggest dataset Gowalla that contains 196,591 users and 1,280,969 items, our framework only requires about 4 hours to get the final result. We believe this running time is acceptable in practice considering the computation could be done offline and high performan ce servers and clusters could be used.
It is also worth noting that the running time of Algorithm 1 increases linearly with respect to the number of users and items. As seen from the fifth column of Table 2, the average time is about 2ms. Similarly, the running time of Algorithm 2 increases linearly with respect to the number of items, and the average time is roughly 8ms (see the 6th column of Table 2) . All these experimental results coincide with our theoretical analysis. Therefore, our framework has a good scalability and is practical in real applications. In this paper, we have presented a secure and efficient framework for privacy preserving social recomme ndation. We have designed a protocol that computes the scores of recommending items to use rs securely in the sense that the two parties involved in the computation do not know the data of the other party. We have also presented an efficient protocol for secure top-k selection with the linear time. We have theoretically and empirically shown the performance of the proposed protocols. The results on four real-world datasets show our framework has a good scalability and is practical in real applications.
 Acknowledgments. This work was partially supported by Natural Science Foundation of China (Grant N os. 61232006, 61303019, 61402313) and Collab-orative Innovation Center of Novel Software Technology and Industrialization, Jiangsu, China.
