 In this paper, we give an approximate algorithm for dis-ing (LSH) technique. We propose an algorithm for the cen-from various input sources, often the data is distributed across the network. Accordingly, we show that our algo-rithm can be effectively extended to a constant round pro-with horizontal partitioning.
 H.2.8 [ Database Management ]: Database Applications Algorithms, Performance we use the converse of this idea and say an object to be a non-outlier if it has enough neighbors within the radius d in our approach whenever we identify a non-outlier we will even considering those objects separately. Thus, we obtain a very efficient pruning technique where, most of the non-percent of the objects in the dataset need to be processed  X  This work was partly supported by Naval Research Board, India.
 in a large dimensional data, we use the Locality Sensitive Hashing(LSH) scheme. The idea of Locality Sensitive Hash-idea is formalized as follows [1]:
Definition 1. A family H = h : S  X  U is called ( r 1 , r 2 p , p 2 ) -sensitive if for any two objects p, q in S: where d ( p, q ) is the distance between objects p and q . For the hashing scheme to be locality sensitive, two con-der to amplify the gap between the probabilities p 1 and p standard practice is to concatenate several hash functions to obtain a function family G = { g : S  X  U k } such that hash function and h i  X  H . For a hash function family G , the probabilities in Equation 1 and 2 are modified as: for j =1 , 2 ...L ;whereeach g is drawn independently and uniformly at random from G i.e., each object is hashed us-ing L hash functions drawn from G andstoredinthecorre-detection method using LSH, but unlike our approach their scheme uses the definition of an outlier given by [3].
In this section we describe our algorithms for both cen-tralized as well as distributed scheme in detail. ting takes as input the dataset D , distance threshold d t rithm for centralized setting is executed in three phases.
In the First phase, initially the parameters R = r 1 = d is an approximation factor. The LSH scheme is applied on L hashed to that bin. In the Second phase ApproximateOD Algorithm 1 CentralizedOD Output: Outliers M 1: p t =(1  X  p t )  X | D | 2: R = r 1 = d t / (1 + ) 3: T L  X  H = LSH ( D,R ) 4: Compute b t // using Equation 5 5: M = ApproximateOD ( D,T L  X  H ,p t ,b t ) 6: M = BrutForceOD ( D, M ,d t ,p t ) Algorithm 2 ApproximateOD Input: Dataset D , Hash Table T L  X  H , Point Threshold p Output: Outliers M 1: M = {} 2:  X  o  X  D, flag [ o ] = 0 // mark all objects as outliers 3: for each object o in D do 4: if flag [ o ]=0 then 5: l o = { g i ( o ) | i =1to L } 6: S = FindNeighbors ( D,T L  X  H ,o,l o ,b t ) 7: if | S | &gt;p t then 8:  X  o  X  S ,flag [ o ]=1//markobjectsin S as 9: else 10: M = M  X  X  o } // add current object into set of 11: end if 12: end if 13: end for (Algorithm 2), using the LSH binning structure, most of the non-outliers in the dataset are pruned. We consider an object o and find all L bins to which it is hashed by LSH. L bins (without removing duplicates). The objects in this Equation 4, we know that each object in S is within the only those objects which are repeated at least b t ( b t  X  S . In other words, we are reducing the error probability Algorithm 3 FindNeighbors Output: Set S of objects satisfying Bin Threshold criteria 1: S = S = {} 2: for i =1to | l o | do 3: S = S T [ i, l o [ i ]] 4: end for 5:  X  o  X  D, count [ o ]=0 6: for each object o = o in S do 7: count [ o ]= count [ o ]+1 8: if count [ o ]  X  b t then 9: S = S  X  X  o } 10: end if 11: end for of considering an actual non-neighbor as a neighbor of the latter in this section.

If the cardinality of S , returned by the FindNeighbors (Algorithm 3) protocol is greater than the modified point in S i.e., every object other than o also has more than p (with a very high probability). Hence, all the objects in S are marked as non outliers. If, on the other hand the p , we consider the object o as a probable outlier. This as non-outliers or probable outliers. We denote the number of objects for which the FindNeighbors protocol is queried resulting set of probable outliers M can have a few false are removed and the final set of approximate outliers M is returned.
 The overall computational complexity of Algorithm 1 is Algorithm 4 BruteForceOD Input: Dataset D , Probable Outliers M , Distance Thresh-Output: Outliers M 1: M = {} 2: for each object o in M do 3: count =0 4: for each object o in D do 5: if Dist ( o ,o ) &gt;d t then 6: count = count +1 7: end if 8: end for 9: if count  X  p t then 10: M = M  X  X  o } 11: end if 12: end for
False Positives and False Negatives: In the context on the probabilities of both based on the value of the bin threshold parameter b t . Consider a LSH scheme where each object is hashed using L hash functions each of width k. The probability of two objects at a distance greater than r = r 1  X  (1 + )= d t , to be hashed to the same bin is at scheme, for a non-neighbor to be counted as a neighbor of R being hashed to two different bins is at most (1  X  p k 1 of L times is given as: This gives an upper bound for the probability of a false positive.

Bin Threshold: As seen from the Equations 5 and 6, the false negative probability desired, using Equations 5.
We consider the horizontal distribution where each player Algorithm 5 DistributedOD Input: Player P A with Dataset D A ,Player P B with Output: Player P A Outliers M A 1: At P A : 2: P A sends | D A | to P B 3: At P B : 4: n = | D A | + | D B | 5: P B sends n to P A 6: At P A : 7: p t =(1  X  p t )  X  n 8: R = d t / (1 + ) 10: compute b t 11: M A = ApproximateOD ( D A ,T A L  X  H ,p t ,b t ) 12: M A = GlobalApproxOD ( M A ) 13: M A = GloabalOD ( M A )
We present the algorithm such that one player, say P A the end of the algorithm. Similarly the algorithm can be liers by simply interchanging the roles of P A and P B in algorithm, we give the following definitions.

Definition 2. local outlier : Given a distance threshold d and a point threshold p t ,anobject o with player P i is a of the total dataset D .

Definition 3. global outlier : Given a distance threshold d and a point threshold p t ,anobject o in a dataset D is a a distance greater than d t from o .
 Algorithm 6 GlobalApproxOD Input: Players P A and P B ,Player P A Dataset D A ,Player Output: Player P A Global Approximate Outliers M A 1: At P A : 2: for each object o in M A do 3: l A o = { g i ( o ) | i =1to L } 4: end for 5: send l A to P B 6: At P B : 7:  X  l  X  l A ,c B [ l ]=0 8: for each label l in l A do 9: S = FindNeighbors ( D B ,T B L  X  H , null, l, b t ) 10: c B [ l ]= | S | 11: end for 12: send c B to P A 13: At P A : 14: M A = {} 15: for each object o in M A do 16: l o = { g i ( o ) | i =1to L } 17: S = FindNeighbors ( D A ,T A L  X  H ,o ,l o ,b t ) 18: count = | S | + c B [ o ] 19: if count  X  p t then 20: M A = M A  X  X  o } 21: end if 22: end for P
B and gets the size of the entire dataset (i.e. | D A | + Player P A locally computes its local probable outliers M the second phase, for each object o in the set M A , P A element l in l A and runs the FindNeighbors algorithm on returned by FindNeighbors and sends the set of counts to P A .Player P A considers each object o in M A and runs the FindNeighbors algorithm to obtain its count of the number computes the sum of this count and the corresponding count P , P A stores o in the set M A of global probable outliers.
The set M A contains some false positives which can be removed in third phase with another round of communica-tion as follows: P A sends the set M A to P B .Player P B considers each object o in M A and computes the distance to each object in its dataset D B and counts the number of objects which lie at distance greater than the distance threshold d t from o . P B sends all the counts back to P P
A then considers each object o in M A and computes the distance to each object in its dataset D A and counts the number of objects lying at distance greater than d t . P A then computes the sum of this count and the corresponding The overall communication complexity of player P A would be O ( m A L + m A d ), where m A = | M A | and m A = | M Algorithm 7 GlobalOD Input: Players P A and P B ,Player P A Dataset D A ,Player Output: Player P A Global Outliers M A 1: send M A to P B 2: At P B : 3:  X  o  X  M A ,c B [ o ]=0 4: for each object o in M A do 5: for each object o in D B do 6: if Dist ( o ,o ) &gt;d t then 7: c B [ o ]= c B [ o ]+1 8: end if 9: end for 10: end for 11: send c B to P A 12: At P A : 13: for each object o in M A do 14: count =0 15: for each object o in D A do 16: if Dist ( o ,o ) &gt;d t then 17: count = count +1 18: end if 19: end for 20: count = count + c B [ o ] 21: if count  X  p t then 22: M A = M A  X  X  o } 23: end if 24: end for
All experiments are performed on Intel(R) Core i 7CPU
Centralized: Table 1 outline the performance of pro-posed CentralizedOD algorithm. First 3 columns lists the various datasets with respective number of objects and di-mensions. The execution time (in seconds) averaged over lated in column 4. We computed the optimal bin threshold b (listed in column 5) as described in Section 2 for men-tioned datasets and ran our algorithm using the same bin case of optimal Bin Threshold. In other words, we achieved 100% detection rate on optimal bin threshold.

For each dataset considered, we computed the percentage
All datasets are taken from UCI Machine Learning Repos-itory. http://archive.ics.uci.edu/ml Dataset Objects Dim Time b t FP Letter 20000 16 7.53 2 0.12 Corel 68040 32 32.27 20 0.09 MiniBooNE 130064 50 29.86 4 0.01 Server 494021 5 41.93 22 0.02
YearPrediction 515345 90 193.11 4 0.03 Figure 1: (a) Queried Objects N q (b) Communica-tion Cost in Horizontal Distribution The results are shown in Figure 1(a). For small datasets is evident from the figure.

Distributed: For the distributed case, we have uniformly For all datasets, the union of the outliers found at each centralized algorithm run on the same dataset. This shows We have repeated the experiment by varying the number of players from 1 to 5 and studied the effect on the commu-be seen that the percentage of the communicated objects is indeed very less.
In this paper, we have proposed an approximate algorithm ing technique. Further, we have extended our scheme to efficient in terms of the communication cost. [1] P. Indyk and R. Motwani. Approximate nearest [2] E. M. Knorr and R. T. Ng. Algorithms for mining [3] S. Ramaswamy, R. Rastogi, and K. Shim. Efficient [4] Y. Wang, S. Parthasarathy, and S. Tatikonda. Locality
