 Many works have been proposed in order to improve the recommendation accuracy. Algorithms aiming to improve recommendation accuracy have been developed and eva luated. These algorithms usually work with training data sets which are learned and used to make predictions on users X  tastes. The training data set choice is a difficult task not only due to the technical nature of the algorithm used, but also because of the user issues associated with the acquisition of their opinions, since the training data consist of users X  opinions. In this work we show the importance of understanding which predictions are impacted when a rating is acquired by developing a na X ve activ e learning criterion based on the number of impacted predictions. To do that, a Rating Impact Analysis method for the user -based collaborative filtering is proposed and applied to the active learning issue. H.3.3 [ Information Systems ]: Information Search and Retrieval  X  information filtering . Algorithms, Management, Measurement Recommender Systems, Active Learning, Impact Analysis Collaborative r ecommender systems have bee n increasingly used in industry over the last few years , especially in e -commerce [1] . Based on a training set, these systems are able to predict unknown ratings and thus mak e recommendations. Therefore , decreasing the prediction error has been pursued through recommender algorithm s. Another way to improve the recommendation quality is to ac quire the most appropriate training set to the recommender algorithm used , a problem known as Active Learning [4] . However, it relies on asking users to evaluate products, task known as User Preference Elicitation [10] . As new ratings are added into the training data set, some predictions have their values updated . Identifying which predictions are subject to impact is important to avoid problems along the user preference elicitation. For instance, an active learning method could lead the recommender system to systematical ly improve a small set of predictions. That would result in improvements in the overall accuracy, but not in the improvement of the recommendation diversity . In this paper we address the problem Rating Impact Analysis and its application on Active Leaning. Impact Analysis means to identify the potential consequences of a change, where this  X  X hange X  , in our context , is to add a new rating into the training data set. Therefore, it aims at identifying which rating predict ions are subject to the impact of the acquisition of a new rating to the training data set. We developed a Rating Impact Analysis method for the user -based collaborative filtering which is capable of identifying all predictions impacted by a new rating. I n order to evaluate our approach and show its benefits, a simple active learning criterion based on the number of impacted predictions is proposed . The number of impacted predictions is used to select unknown ratings to acquire. This criterion is compared with two well -known criteria in the literature that usually provide good results. Our criterion demonstrates very good improvements in terms of accuracy despite a na  X ve strategy. The main contributions of this work are threefold: noticing the problem of a nalyzing the impact of a new rating on the predictions, the development of a rating impact analysis method, and providing a new active learning criterion.
 This work is organized in 7 sections, where this is the first. In the next section we present related work . In section 3 the problem statement is described. In section 4 we present our proposed method of Rating Impact Analysis for the user -based collaborative filtering. Section 5 briefly discusses our active learning strategy. Section 6 draws the experime nts and discusses the results. Finally, in section 7, conclusions and future work are presented. In machine learning literature, active learning has been used to enhance the best selection of training data for supervised learning methods, espe cially classifiers [4] . In recommender systems we have to deal with other constraints related to the process of acquiring user preferences. One of the first works that points out the problem of selecting products to ask users to rate them is [10] , in which the authors are concerned with the new user problem. Given a new user signing in the recommender system, there is not much data to make predictions about her tastes. So, th e recommender system should query this user about her tastes so as to make better recommendations. Selection criteria for products are proposed in order to improve the prediction accuracy and decrease the user X  X  effort in rating products. Several w orks pro posing new criteria of data selection or extending those ones defined by [10] have been done. Carenini et al. in [3] propose a conversational recommender system framework where a user preference elicitation method based on the criteria in [10] is adapted . However, instead of selecting a rating to ask for improving the whole prediction, the authors focus on improving the predictio ns of a specific product as a result of their conversational interactions. These methods which are based on the use of criteria can be categorized as Heuristic -based methods . Active learning methods have also been developed with machine learning approaches [4] . In [2] , a method that uses the Expected Value of Information (VOI) so as to decrease the uncertainty on the probabilistic model of ratings is proposed . In [7] , following the idea of working on the probabilistic models, a criteri on to select ratings to query is developed. This method takes into account not only the expected loss on the current model , as the other similar work s, but also the posterior model by using a Bayesian approach to calculate these values. Harpale et al . in [5] propose to consider the probability of the target user being able to rate the product, which is called  X  X ersonalization X  in the active learning process.
 Other approaches in the literature intend to understand the relationship between ratings and predictions but do not focus on acquiring data. In [8] , a method to predict the influence of a user on predictions to other users is developed . In [9] , Rashid et al. propose to compute the value of contribution so as to motivate users to rate products. It is shown to the user which groups of users will be benefited with better predictions if she rates a certain product. To do so, groups of users are defined and samples of predictions from each group are drawn in order to estimate the impac t of the potential rating on these groups.
 Despite the fact that all these mentioned works analyze somehow the impact of a new rating on the recommender system, they do not actually deal with this problem in the level of details we intend to. Therefore, to the best of our knowledge there is no work that is concerned with rating impact analysis. In our context, recommender systems and collaborative filtering are interchangeable terms . A recommender system receives as input a set of ratin gs, which are usually stored as user -product matrix of ratings. This matrix is naturally sparse, i.e. , most users do not give their opinions about products. In order to make recommendations, recommender systems make predictions on the unknown ratings exist ing in the user -product matrix. Thus they are able to offer the product with the best predicted rating to the corresponding user. The predictions on unknown ratings are made by the recommender algorithm used based on the knowledge in the training data set. When a new rating is acquired, a set of predictions suffers some impact from this new data. Depending on the new rating, the set of impacted predictions varies. So, a rating given by a certain user to a certain product impacts a set of predictions that i s different if the same user rates another product. Moreover, a prediction is made by using different ratings, so, depending on the nu mber of ratings that contribute to the prediction, the new rating may impact less or more. In this way, to select an unkno wn rating to acquire it should take into account which predicted ratings will be impacted and to which degree each will be impacted.
 Rating Impact Analysis consists in identifying which rating predictions are subject to impact and to which degree they will be impacted. In fact, it is to understand to where the information of a new rating propagates changing the predictions.
 In order to perform Rating Impact Analysis, we should consider a rating to acquire (i.e., an unknown rating), the current training data set, and the recommender algorithm behavior. As the value of the new rating is unknown , Rating Impact Analysis does not take any assumption about rating values . Therefore , the analysis of the potential impact on the rating predictions is free of value cho ices. In this section we describe our Rating Impact Analysis method for the user -based c ollaborative filtering algorithm . This proposal is based on the use of a bipartite graph to model user -product interactions . Our method exploits four -node path s , a bipartite graph structure proposed by Huang and Zeng in [6] , and how it affects the predictions of the user -based collaborative fil tering. The method receives as input an unknown rating to analyze and the current training data set . As output, it returns the set . The training data set can be represented as an undirected bipartite graph where the circle nodes the ratings (lines ) and the predictions (dashed lines) . Figure 1 shows three examples.
 In this bipart ite graph model we define two operators over the user set and product set. The objective of these operators is to manipulate fast the bipartite graph. The operator on the user set is edges (lines) , which represent ratings, to make bijections from the user set to the product set. The operator on the product set is defined as , where and , and is analogous to the first operator. For instance, in Figure 1 , on the left graph, we may have operations such as , the right graph, operations such as , The user -based collaborative filtering algorithm exploits the four -node path for making predictions [6] , see Figure 2 . A four -node path between a user node and product node which are not rated allow s the user -based collaborative filtering algorithm to estimat e the rating between these two nodes. In other words, a prediction is estimated by the target product ratings given by the target user X  X  neighbors. The more four -node paths between a pair of user -product nodes exist, the more information this prediction will have to compose itself . Therefore, identifying impacted predictions is to discover which predictions have new four -node paths created by the new rating acquired. In order to identify the predictions impacted by , we should first identify who are the users impacted. To do so, we need to identify which four -node path s are created by the addition of the edge into the graph. There are three possibilities to create a four -node path that would contain . In Figure 2 , we have the three possibilities illustrated. In Figure 2 (a), user is impacted. In Figure 2 (b), all users who rated are impacted and in (c) all users who rated some product also rated by are subject to impact.
 Based on the graph in Figure 2 , we define the expressions to identify the impacted users. In case (a), there is only to identify, therefore . In case (b), we have all users who rated , defined as . And finally, for (c), we have all users who rated products which were also rated by , and thus, close set of all users impacted by . We identified all users who are subject to impact. By now, we describe how to identify the impacted predictions . For each user we apply a graph expression to identify the set of products which the predictions are impacted. According to the kind of four -node path where a user come s from, the expression varies . Basically, this problem consists in identifying which predicted ratings have new four -node paths passing by them after the addition of the edge . So, we have an impacted user who is , or is from or . For each we identify which products have predictions to that have been impacted. The algorithm 1 shows how to perform this task.
 For each P y of (After  X  Before) The set Before consists of all unrated products which the user -based collaborative filtering is able to predict a rating to a user before the addition of the edge . That is, all  X  X  unrated products in which there is at least one four -node path. Therefore, all products rated by use rs who co -rated products with is defined as ), and products which has not rated yet is defined as . The set After consists of all unrated products which the addition of the edge creates at least one new four -node path between them and a user . However, it depends on the position where and hold in the four -node path (see Figure 2 ). In case (a), we have all products rated by users who rated , i.e. , products rated by that has not rated. Finally, in case (c), we have only . The intersection between After and Before consists of products which will have their predictions impacted, i.e. , predictions that will have new four -node paths as long as is acquired. The difference between After and Before form s the predictions which the recommender algorithm is not able to make but will be , as long as is acquired. Therefore, the set impacted by the acquisition of and the set recommender al gorithm is not able to make but only after acquiring . Our active learning criterion is to select user -product pairs from a pool of c andidates based on the number of predictions impacted. Selecting the user -product candidates to acquire with the highest number of impacted predictions gives the largest coverage over the prediction and thus more chance to improve the overall accuracy. The refore, our strategy consists in comput ing the Rating Impact Analysis for each candidate by the algorithm 1, and choosing the candidate with the largest number of elements in that also belong to the target predictions we intend to improve . Evaluation was conducted offline with the MovieLens data set contain ing 100,000 ratings of 943 users on 1682 movies as also preformed in [10] . To do that, we randomly spi tted these ratings into three sets: Knowledge  X  K (2% of ratings), Candidates  X  C (68% of ratings), and Test  X  T (30% of ratings).
 The evaluation consisted in picking ratings from set C, adding them into set K and evaluating the gain of accuracy on the predictions made by the user -based collaborative filtering with cosine similarity to the ratings belonging to set T. The set K is used as the training data set . Therefore, as ratings are inserted from C to K, the recommender algorithm predicts rating on set T. The measure of accuracy is the Mean Absolute Error (MAE) over the predictions made on the set T. It was performed 40 rounds and the means of prediction er rors were computed in order to have statistical confidence in our results . Our proposed criterion is applied to impacted predictions which belong to set T. Thus the ratings acquired are those that cover as many as possible predictions on set T. To compare our criterion, we choose the log pop * entropy criterion described in [10] due to its good results and being used as a ben chmark measure in several works. In addition to these predictions, we use a random select ion strateg y in order to have a baseline . We performed the experiment selecting roughly 1,000 ratings from set C. For each 100 rating s picked , we measure d the MAE on the set T. The initial MAE obtained on K (roughly 2 ,000 ratings) was approximately 1.023 8. After moving the 1,000 ratings to the set K, we obtained for the log pop * entropy criterion 0.98 27 of MAE and for our proposal 0 .9616 of MAE, an accurac y improvement of 2.2 %. In Figure 3 , MAE (vertical axis) is shown along the process of adding rating s into K (horizontal axis) . It is clear that the Impact criterion outperfoms in all the entire process the log pop * e ntropy and Random criteria . The standard deviation of the MAE for each criterion is very small despite Impact being the largest verified . In this paper, we presented the problem Rating Impact Analysis for Collaborative Recommender Systems. We show the importance of understanding to which predictions the rating information propagates when inserted into the training data. In order to stand our point, we developed a Rating Impact Analysis method for the u ser -based collaborative filtering algorithm, applied it to establish a criterion to select ratings to ask about, and compared with criteria well -established in the literature. Our results show that our criterion really outperformed the entropy criterion, s howing that Rating Impact An alysis can provide interesting and useful information for active learning, even using a na X ve strategy of selection. The main drawback of this criterion is not to consider the impact degree on each prediction and deal with noise in ratings.
 Our next research step is to work on detection of users who introduce noise into the training data set. So, we can ask for candidates with the highest impact number and users who usually introduce little noise into the training data set. Ano ther future work is to develop the part of the rating impact analysis method that measures the degree of impact on each prediction. Thus, we will be able to identify which predictions of the impacted predictions are more impacted with a rating, i.e. , which predictions have more chance to have an abrupt change in their value. Our thanks to CNPq and EUBRANEX for funding this research. [1] Adomavicius, G. and Tuzhilin, A. Toward the Next [2] Boutilier, C., Zemel, R., and Marlin, B. Active [3] Carenini, G., Smith, J., and Poole, D. Towards more [4] Cohn, D.A., Ghahramani, Z., and Jordan, M.I. Active [5] Harpale, A.S. and Yang, Y. Personalized acti ve learning [6] Huang, Z. and Zeng, D.D. Why Does Collaborative [7] Jin, R. and Si, L. A Bayesian approach toward active [8] Rashid, A.M., Karypis, G., and Riedl, J. Influence in [9] Rashid, A.M., Ling, K., Tassone, R.D., Resnick, P., Kraut, [10] Rashid, A.M., Albert, I., Cosley, D., et al. Getting t o know 
