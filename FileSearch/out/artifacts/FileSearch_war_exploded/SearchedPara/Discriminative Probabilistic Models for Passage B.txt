 The approach of using passage-level evidence for document retrieval has shown mixed results when it is applied to a variety of test beds with different characteristics. One main reason of the inconsistent performance is that there exists no unified framework to model the evidence of individual passages within a document. This paper proposes two prob-abilistic models to formally model the evidence of a set of top ranked passages in a document. The first probabilistic model follows the retrieval criterion that a document is rele-vant if any passage in the document is relevant, and models each passage independently. The second probabilistic model goes a step further and incorporates the similarity correla-tions among the passages. Both models are trained in a discriminative manner. Furthermore, we present a combi-nation approach to combine the ranked lists of document retrieval and passage-based retrieval.

An extensive set of experiments have been conducted on four different TREC test beds to show the effectiveness of the proposed discriminative probabilistic models for passage-based retrieval. The proposed algorithms are compared with a state-of-the-art document retrieval algorithm and a lan-guage model approach for passage-based retrieval. Further-more, our combined approach has been shown to provide better results than both document retrieval and passage-based retrieval approaches.
 H.3.3 [ Information Storage and Retrieval ]: Retrieval Models Design, Algorithms, Experimentation Discriminative Models, IR, Passage Retrieval
Previous research has demonstrated that using passage-level evidence can improve the accuracy of document re-trieval when documents are long or span different subject areas [2, 10, 16]. However, the performance of passage-based retrieval is mixed when this approach is applied to a variety of test beds with different characteristics [12, 16].
One important reason of the inconsistent performance is that there exists no unified framework to model the evidence of individual passages within a document. Most previous research only considered evidences from the best matching passage in each document for ranking documents (e.g., [2, 11, 16]), while some other previous work used methods that would require a significant amount of tuning effort to com-bine the evidence of several top ranked passages (e.g., [7, 20, 23]).

To improve the performance of passage-based retrieval, this paper proposes two probabilistic models to estimate the probability of relevance of a document given the evi-dence of a set of top ranked passages in the document. The first probabilistic model captures the retrieval criterion that a document is relevant if any passage in the document is relevant. Since the first model estimates the probability of relevance for each passage independently, the model is called the independent passage model. On the other side, the sec-ond probabilistic model goes a step further and models the correlation among individual passages by analyzing content similarities. The second model is called the correlated pas-sage model. Both these models are trained in a discrimi-native manner on a set of training queries. Furthermore, a combination approach is proposed to combine the ranked lists of document retrieval and passage-based retrieval for more accurate retrieval results. The probabilistic modeling method we proposed in this work can be classified as a den-sity estimation method [4, 6]. To the best of our knowledge, this is the first research work that applies jointly modeling of passage evidence and discriminative training methods for passage-based retrieval.
 Empirical studies have been conducted on four different TREC test beds to show the effectiveness of the proposed discriminative probabilistic models for passage-based retrieval. The new models are compared with the document retrieval algorithm and a language model approach for passage-based retrieval. Experiment results demonstrate that our first in-dependent passage model always outperforms the language model approach of passage-based retrieval, while the second correlated passage model performs even better by consid-ering the similarity information among passages. Both of the two proposed models are robust. In particular, the per-formance of the correlated model is at the same level or much better than the document retrieval method on all the test beds. Furthermore, experiments have shown that the proposed combination approach can improve the retrieval results of both the document retrieval approach and the passage-based retrieval approach.

The next section discusses related work. Section 3 de-scribes the new probabilistic passage-based retrieval models as well as the new combined retrieval approach. Section 4 explains our experimental methodology. Section 5 presents the experimental results and the corresponding discussions. And finally section 6 gives conclusions and future work.
Passage retrieval has been an very attractive research di-rection in IR for two main reasons. The first apparent advan-tage of passage retrieval is that users are able to locate rel-evant information from returned passages much faster than if they were overloaded with long full-text documents [2, 20, 24, 22].

The second attraction of passage-based retrieval is that passage-level evidence can be used to improve effectiveness on many IR tasks. For example, Allan  X 95 [1] showed that using fixed window passages instead of full documents is a more effective approach for relevance feedback. MultiText retrieval system [3] also demonstrated the effectiveness of passage retrieval in a variety of tasks including query refine-ment and document relevance ranking. This brings us to the focus of this study  X  how passage-level evidence can be used to make more accurate relevance predictions for documents.
Salton et al. [20] experimented with a vector-space passage retrieval model on an encyclopedia collection and showed that retrieving paragraphs and sections instead of full-text documents yielded a significant gain on mean average preci-sion.

UMass X  X  system at TREC 2003 HARD track [9] experi-mented with passage retrieval using a language model ap-proach. But in most cases, their passage retrieval results did not surpass document retrieval baseline.

Callan  X 94 [2] compared different passage creation meth-ods, and tested on four TREC 1 and 2 collections using INQUERY retrieval system. For passage retrieval, the top 1 passage was considered for each query. Empirical re-sults showed that using fixed-size window based passages was much more effective than paragraph-based passages. A significant improvement was found on the Federal Register (FR) collection (contains mostly long documents), and mod-erate improvement were found on two other collections. He also showed that combining document and passage retrieval scores using simple heuristic gave another 2% gain.
Zobel et al. [25] conducted similar experiments on TREC disk 1 and 2 collections using a vector-space model. Their findings were similar to Callan  X 94 that section-based pas-sages degrade retrieval performance. Retrieval based on fixed-size window passages was shown to be more effective than document baseline on the FR part of the collection, but test results on the whole collection showed no signifi-cant difference.

A later study done by Xi et al. [24] re-examined fixed-size window passages on TREC 4 and 5 collections using their in-house vector-space retrieval model. Contrary to Callan  X 94, they did not obtain an improvement using a linear com-bination of passage score and whole-document score.
Hearst and Plaunt  X 93 [7] proposed an approach for divid-ing documents into passages in a way that reflects the un-derlying subtopic structure of the document. Their method first broke a document into small blocks of 3-5 sentences, then computed the cosine similarity of neighboring blocks based on adjusted tf-idf. Blocks were then linearly grouped into passages based on finding dramatic changes in the co-sine similarity between neighbors. They conducted retrieval experiments on the Ziff subset of TIPSTER collection (con-taining mostly long documents) using the SMART system. And by summing up the scores of passages belonging to the same document, they obtained a substantial improvement on some of the P5-P30 measures.

Knaus, Mittendorf and Sch  X  auble [18, 13] presented a dif-ferent approach for finding passage boundaries that was based on hidden Markov model. Their preliminary experimental results favored their method over a baseline sentence re-trieval model, but no comparison with full-text document retrieval was given.

Wilkinson  X 94 [23] designed a set of heuristic functions for assigning scores to section-based passages based on section types. In one set of experiment the top 1 passage score was used for re-ranking documents, but in a second experiment he introduced another heuristic function based on cosine similarity of passages to combine scores of passages belong-ing to the same document. Evaluated on a subset of the FR collection, results of the passage-based retrieval were mixed.
The work that are most closely related to ours are the work done by Kaskiel and Zobel  X 01 [11] and Liu and Croft  X 02 [16]. Kaskiel and Zobel  X 01 [11] used a vector-space model as their basis to compare passage retrieval results of different passage types against document retrieval on 5 dif-ferent TREC collections  X  FR-12, FR-24, TREC24, TREC25 and WSJ. They showed consistent and significant improve-ments over document retrieval baseline on the longer FR collections, but the results were either negative or mixed on the shorter TREC24, TREC-45 and WSJ collections.

More recently, Liu and Croft  X 02 showed very similar re-sults to Kaskiel and Zobel in their study [16]. They com-pared language model based passage retrieval using only the top 1 passage and document retrieval also using lan-guage model, and obtained significant improvement on FR-12 collection. But their results also showed noticeable drop on TREC-45 and AP collections. Note that our focus is passage-based retrieval algorithms that do not use query ex-pansion and pseudo relevance feedback in order to make fair comparison with document retrieval approach that does not use query expansion and pseudo relevance feedback. There-fore, we do not compare with Liu and Croft X  X  method based on the relevance model.

In general, results of the passage-base retrieval systems that we described were somewhat mixed. Most systems that were tested on long document collections gained im-provements over document retrieval baseline, but those that were tested on other types of collections often resulted in significant drop in performance.

Another line of research that has recently received in-creasing attention in IR is discriminative methods for doc-ument retrieval tasks. Traditional approaches for document retrieval such as LM and BIR explicitly model the genera-tion process of query terms from documents. However, some modeling assumptions that are often made in these models, such as query terms are generated independently [19] from documents, are often violated in reality and thus pose lim-itations to these models [19, 5]. Discriminative models on the other hand, make fewer assumptions and allow arbitrary features to be incorporated into the model. Often trained to directly optimize retrieval performance [5, 19], these mod-els have been shown to achieve significant improvements over state-of-the-art generative models in both document retrieval [5] and home-page finding tasks [19].

In this work, we propose two novel probabilistic models for passage-based retrieval which are trained discriminatively. We will describe our models and our training methods in more details in the next section.
This section first proposes two discriminative probabilistic models for passage-based retrieval. It then presents a com-bined retrieval approach that combines both passage-based retrieval and document-based retrieval.
Our first model aims at accurately estimating the prob-ability of relevance of each individual passage, as well as providing a probabilistic framework for combining the evi-dence from different passages to make a joint prediction for the document X  X  relevance.

Given a set of n top-ranked passages ~s = { s 1 ,  X  X  X  ,s n a document d , the relevance judgment criterion states that the document d is relevant if any one of the n passages is relevant. In other words, the relevance probability of docu-ment d is one minus the probability of all n passages being irrelevant. This can be formulated as the following
P ( Y = 1 | d ) = 1  X  P ( ~ Z = ~ 0 | ~s )) = 1  X  where Y and Z i are Boolean variables that have value 1 when d and s i are relevant, respectively, and 0 otherwise. An independent assumption is made here that whether a specific top-ranked passage s i is relevant or not is not related to the relevance of any other top-ranked passage.

We use the parametric form of logistic regression to model the probability of relevance of a passage as P ( Z | s ): where ~ f ( s ) is a feature vector of the passage s , and corresponding weight vector.

Given a training set consists of m queries { q 1 ,  X  X  X  ,q each with a set of documents { d m 1 ,  X  X  X  ,d m k } and their rele-vance judgment { t m 1 ,t m 2 ,  X  X  X  ,t m k } , we can express the condi-tional likelihood of the data as the following: where each Y m k is a Boolean random variable that has value 1 when d m k is relevant and 0 otherwise.

To train the model, we used the BFGS Quasi-Newton [8] method to estimate the parameters ~  X  that would maximize the conditional log likelihood of the data L , which can be expressed as
Since the focus of this study is on the probabilistic models rather than feature engineering, we only used two features in the independent passage model  X  the rank and the score of each passage that come from the baseline language model retrieval model. Despite the simplicity of these features, we were able to obtain substantial improvements over the language model approaches, as we will show in Section 4.
The independent passage model makes an assumption about the independence among individual passages. Although this assumption is reasonable for certain documents, such as the ones that contain short passages summarizing multiple top-ics, we would expect this assumption not to hold in many other cases, especially for long documents that elaborate on a single topic. To address this limitation, we take a step further in this model and exploit the correlations among in-dividual passages. Among many different kinds of passage correlations, we focus on the correlations that are charac-terized by the content similarity of passages. We compute pair-wise passage similarity using the cosine similarity mea-sure based on tf-idf vectors of the passages.

For computing the cosine similarity, we first performed a standard L2 normalization on each passage X  X  tf-idf vec-tor. We use ~c { c 1 ,  X  X  X  ,c n } to denote an unnormalized tf-idf vector of a passage, where n is the vocabulary size. A L2-normalized vector ~ c 0 is calculated as
Then we created a document background vector by sum-ming up the tf-idf vectors of individual passages that belong to the same document. Finally we subtracted the document background vector from each passage X  X  vector, and use the resulting vector to calculate cosine similarity. The cosine similarity of two vector ~a and ~ b (both of length n )is given as
In the independent passage model described in last sec-tion, the conditional probability of a set of passages ~s = { s 1 ,  X  X  X  ,s n } having relevance judgments ~v = { v 1 ,  X  X  X  ,v is expressed as We now re-define this term to be P ( ~v | ~s ) = 1 Z exp where  X  ij denotes the correlation (cosine similarity) between passage s i and s j ;  X  is a parameter for controlling the weight of the correlation term; g (  X  ) is a normalizing function de-fined as where t is a threshold parameter and Z is a partition func-tion gen ( ~ v 0 ) to denote a generation function that enumerates over all possible values of the zero-one vector v 0 exactly once.
The first operand of the plus operator models the inde-pendent passage relevance, while the second operand models the passage correlations. Notice that when  X  is set to 0, the model becomes exactly the same as the independent passage model.

For training, we first used the independent passage model to obtain the ~  X  values, then we used 10x10 depth-4 grid-search method to choose the  X  and t values by directly op-timizing mean average precision (MAP) on the training set. We also experimented with gradient-based search methods to optimize the conditional probability instead of MAP. The resulting objective function is very bumpy, yielding many bad local minimas, and the results of gradient-based search are not as good as the grid search. Since this model is a generalization of the independent passage model, it is guar-anteed to improve MAP on training set over the first model. Despite the greedy nature of the grid-search method, we ob-served good generalization performance on the final test set, as we will show in Section 4.
Previous research [2] has demonstrated that combining passage-level evidence with document-level evidence often yields better retrieval results than any one model alone. We propose an approach for systematically combining passage retrieval results with document retrieval results.
Our approach is similar to the CombMNZ method de-scribed in Lee  X 97 [15]. We first take the top n ranked lists of document retrieval and passage retrieval. Then for each document, we count the number of times it occurred in the two rank lists (denoted as c ), and linearly interpolate the two retrieval scores to produce the combined score (we use d and p to denote document and passage retrieval scores, and s for combined score). The formulae we used is
We used a greedy search procedure similar to the one de-scribed in Section 3.2 to find parameters n and  X  that max-imize MAP on training set. And finally the combined scores were used to re-rank documents on the testing set.
We evaluated our models on four TREC data sets: the As-sociated Press newswire 1998-1990 (AP) with TREC topics 51-150, the Federal Register 1988 and 1989 (FR-12) with TREC topics 51-150, all the data on TREC disk 4 and 5 (TREC-45) with TREC topics 351-450, and the Wall Street Journal 1986-1989 (WSJ) with TREC topics 51-150. The FR-12 collection is the smallest in size, containing less than 1/5, 1/10 and 1/4 as many documents as the AP, TREC-45 and WSJ collections, respectively. But the documents in FR-12 are much longer on average, and have a larger vari-ance in length than the documents in AP and TREC-45. The TREC-45 collection represents a heterogeneous collec-tion, including materials from 5 different document sources. Queries are taken from the  X  X itle X  fields of TREC topics. Document-level relevance judgments come from the judged pool of TREC participating teams. Queries without rele-vant documents in the judged pool are removed from the query set. Table 1 and Table 2 gives detailed statistics of the collections and query sets. Previous work on passage-based retrieval has shown negative or mixed results on AP, TREC-45 and WSJ collections [11, 16].

For training and testing, we split the 100 queries used for AP, TREC-45 and WSJ sets into the first half and the second half, and then we carried out 2-fold cross-validations. In each fold, no test data was seen at training time for all our models. For the FR-12 collection, since Liu and Croft  X 02 [16] used only queries 51-100 in their experiments, we added queries 101-150 for training, while leaving out queries 51-100 for testing.
In all our experiments, both query and documents were stemmed using Krovetz stemmer. All punctuations in the queries were replaced with spaces, and no acronym expan-sion or replacement were used. Stopwords were removed based on the standard INQUERY 418 words stoplist [14].
In order to compare with generative models based on lan-guage model, we used Indri 1 retrieval engine [17] to retrieve top 1000 passages for each query. And all 1000 passages of each query from Indri X  X  passage retrieval were used as inputs to our models for training and testing. Passages were created the merits of language model and inference network. Strictly speaking, it is not a purely LM-based system, but we think it is a very strong generative baseline to compare against. Descriptions of Indri X  X  retrieval model can be found here: http://ciir.cs.umass.edu/ , a  X nmetzler/indriretmodel.html . splits on the query sets. using half-overlapping windows of size 50, and we took the top 3 ranked passages of each document as input to our mod-els. We also used Indri as the baseline document retrieval system for comparison. In both Indri X  X  passage retrieval and document retrieval, we used Jelinek-Mercer smoothing method (linear smoothing) with the lambda parameter set to 0.5.
An extensive set of experiments were conducted on 3 test beds to address the following questions: 1) How good are the proposed passage-based retrieval al-gorithms compared with other passage-based retrieval algo-rithms? Experiments are conducted to compare the two new discriminative probabilistic models with the language model based algorithm for passage-based retrieval [16]. 2) Whether the proposed passage-based retrieval algo-rithms are robust compared with document retrieval algo-rithm? Experiments are conducted to compare our passage-based retrieval algorithms with the document retrieval algo-rithm described in Section 4.2. 3) Whether the combined retrieval approach can further improve the accuracy of both passage-based retrieval and document retrieval? Experiments are conducted to compare our approach of combining the language model based doc-ument retrieval with our discriminative correlated passage-based retrieval, to the language model based passage-retrieval and document retrieval approaches.

To provide more detailed information, we did statistical significance test to compare the results. Sanderson and Zo-bel  X 05 [21] showed in their recent paper that t-test is more reliable than sign test or Wilcoxon test, and mean average precision (MAP) is more reliable than precision at rank 10. Inspired by their findings, we report our results mainly using MAP and report significance test results of non-directional paired t-test.
From Table 3 we can see that on all four collections, all of our models consistently out-performed language model pas-sage retrieval. On AP, TREC-45 and WSJ collections, the improvements over LM-based passage retrieval from both our independent model and correlated model were found to be statistically significant with large margin. Two-tailed paired t-tests on comparing the correlated model with the LM passage model showed p-values of 1.85e-10 on AP, 9.9e-4 on TREC-45 and 3.37e-11 on WSJ.

On FR-12 data set, our correlated model also made a sub-stantial improvement over the LM-based passage retrieval (over 3 percentage points and over 13% relative improve-ment in MAP), but the difference was not found to be sta-tistically significant. However, it is worth noting that the number of queries with relevant documents on the testing set of FR-12 collection is smaller (21), as compared to 99 and 100 queries on the AP and TREC-45 sets (we performed Table 3: Comparison of mean average precision with Indri LM-based passage retrieval using half-overlapping window of size 50 on FR-12, AP, TREC-45 and WSJ datasets. LM-psg-lin-0.5 denotes In-dri LM with linear smoothing parameter set to 0.5. Inde denotes our independent passage model, Corr denotes our correlated passage model. % +  X  LM de-notes relative percentage change over LM-psg-lin-0.5. Best results on each collection are highlighted. The  X  symbol indicates statistical significance at 0.95 confidence interval.
 Table 4: Comparison of mean average precision with Indri LM document retrieval on FR-12, AP, TREC-45 and WSJ datasets. LM-doc-lin-0.5 denotes Indri LM document retrieval with linear smoothing pa-rameter set to 0.5. Inde denotes our independent passage model, Corr denotes our correlated passage model. % +  X  Doc denotes relative percentage change over LM-doc-lin-0.5. Best results on each collection are highlighted. The  X  symbol indicates statistical significance at 0.95 confidence interval.
 2-fold cross-validations on these two sets, and therefore we have full test results for all queries, see Table 2). Therefore the power of the significance test on FR-collection is weaker, giving rise to a higher chance of type II errors [21]. Table 6 gives more detailed statistics of different model X  X  perfor-mance on FR-12 collection, and thus helps us to make a better comparison. We noticed from the table that our cor-related model improves over LM-base passage retrieval at all recall levels and on every other measure. The improvements are most salient in P5-P20 and the top 5 recall levels of the 11-point precisions. We think that improvements on these measures are particularly important, perhaps more so than MAP, because the top documents are most likely to have an impact on user X  X  perception of retrieval quality.

We can also see from Table 3 that our correlated model is consistently better or at leaset as good as the indepen-dent model on all four data sets. This result indicates that incorporating passage similarity correlations into our model helped us to make more accurate predictions of document relevance than treating passages solely independently. The parameter values of the learned correlated model are given in Table 7 to aid reproducing our results. Note that for the WSJ corpus, when training on topics 101-150 the passage Table 5: Comparison of combination model with In-dri LM-based document retrieval and passage re-trieval. LM-doc-lin-0.5 denotes Indri LM document retrieval with linear smoothing parameter set to 0.5, and LM-psg-lin-0.5 denotes Indri LM passage re-trieval with the same setting. Combo denotes our combination model. Best results on each collection are highlighted. The  X  symbol indicates statistical significance at 0.95 confidence interval.
 correlation is not found helpful, and therefore the  X  weight is set to 0.0, which means we back off to the independent model.
On the FR-12 dataset, both our independent model and correlated model out-performed document retrieval algorithms with very significant margin, as shown in the FR-12 row of Table 4. A more thorough analysis of several different mea-sures such as R-precision, P5-P10 and 11-point precision showed that our models retrieved 17.2% more relevant doc-uments that were not retrieved by document retrieval, and precision on almost all recall levels were significantly better than document retrieval.

Our two models also significantly outperformed the doc-ument retrieval model on the WSJ dataset. On AP and TREC-45 datasets, the retrieval performance obtained by our models were extremely close to the performance of doc-ument retrieval algorithms (see Table 4), with relative per-centage changes ranging from 0.19% to 1.64%, and p-value of t-statistics as high as 0.9376 (the higher the p-value, the less likely that the differences are statistically significant). When we compared the LM-based passage retrieval against LM-based document retrieval (see Table 5), although LM-based passage retrieval showed a substantial improvement on long document collection (FR-12), its performance was significantly worse than document retrieval on the other three shorter collection (-14.51% reduction in MAP on AP, -7.50% on TREC-45, and -6.67% on WSJ, with t-test p-values 1.9e-05, 9.3e-03 and 1.2e-02). In contrast, our independent model and correlated model achieved higher improvements on FR-12 and WSJ, and performed at the same level as doc-ument retrieval on AP and TREC-45 set with statistically insignificant differences.

Our results confirm the deficiency of LM-based passage-retrieval models on shorter collections, which was also ob-served in Liu and Croft  X 02 [16], and also demonstrated the robustness of our proposed models.
The combination model that we proposed was able to combine the merits of our passage retrieval models and doc-ument retrieval, and achieved the best performance on all four collections (see Table 5). The improvement of combi-Table 6: Detailed comparison with passage retrieval using half-overlapping window size of 50 on FR-12. LM-psg-lin-0.5 denotes Indri LM with linear smoothing parameter set to 0.5. Inde denotes our independent passage model, Corr denotes our cor-related passage model. % +  X  LM denotes relative per-centage change over LM-psg-lin-0.5. The total num-ber of relevant docs over all queries on FR-12 is 502. Rel-ret is the total number of rel docs retrieved; R-prec is precision after R (= rel) retrieved docs; ircl-prn lists the 11-point precisions.
 nation model over document retrieval was statistically sig-nificant on all four data sets, with p-values 0.045 on FR, 0.029 on AP, 0.038 on TREC-45 and 3.8e-06 on WSJ. The results were also significantly better than LM-based passage retrieval on all collections except for FR-12. However, as we explained in Section 5.1, due to the on the small number of queries on the testing portion of the FR-12 collection, the power of the significance test on FR-collection is weaker.
To better illustrate why our combination model worked well, we draw the  X  and n values that were learnt from each training set in Table 8. As we can see from the table, the combination model learned to choose very small  X  values for collections TREC-45 and AP in the process of optimizing MAP on training set, and therefore assigning more weights to the document retrieval scores in the final combination scores. On the other hand, the model learnt a much larger  X  value for collection FR-12, putting more weight on pas-sage retrieval scores. The learned model corresponds well to our knowledge about the relative strength and weakness of document retrieval and passage retrieval on these collec-tions, and was able to adapt to different collections and to make decisions better than any one model alone.
 Table 7: Parameter values of the correlated passage model, learnt from each training set Table 8: Parameter values of the combination model, learnt from each training set
In summary, our independent passage model achieved 33+% relative improvement over the state-of-the-art Indri docu-ment retrieval algorithm on long document collections (FR-12) and maintained a level of performance better or at least as good as the document retrieval algorithm on short (AP), medium length (WSJ) and heterogeneous (TREC-45) col-lections. By modeling passage correlations in the correlated passage model, we further improved retrieval results on all four collections. And finally, through combining passage-level and document-level evidences in our combination model, we obtained even further improvements consistently across all collections, and out-performed the document retrieval al-gorithms on all four collections.

Our models also gave consistent and significant gains over state-of-the-art LM-based passage retrieval approaches. Em-pirical results demonstrated that our method overcomes the inconsistency problem found in LM-based passage retrieval approaches and our models were very robust across different test beds with diverse characteristics.
It is an intuitive idea to utilize passage-level evidence for document retrieval. Passage-based retrieval has shown promising results in collections where the documents are long or span different subject areas. However, most prior passage-based retrieval algorithms were not robust enough when they were tested on collections with different types of corpus characteristics. Many previous passage-based re-trieval algorithms only considered the evidence of the best matching passage in each document for ranking available documents, while some other previous work used heuristics to combine the evidence of several top ranked passages.
In this paper, we have proposed a novel probabilistic frame-work for formally modeling the evidence of individual pas-sages in a document. Our first probabilistic model captures the retrieval criterion that a document is relevant if any pas-sage of the document is relevant and models individual pas-sages independently. The second probabilistic model goes a step further and takes into account the content similari-ties among passages. The proposed probabilistic models of passage-based retrieval are trained in a discriminative man-ner. Furthermore, we have presented an approach to com-bine document-level and passage-level evidence.

The proposed models were evaluated on four TREC col-lections with diverse characteristics. Our models achieved consistent and significant improvements over state-of-the-art language model approaches to passage retrieval. Whereas previous approaches to passage retrieval have shown mixed results when tested on collections of different characteris-tics, we have demonstrated that our proposed models are much more robust and performed consistently across collec-tions. Furthermore, our proposed combination approach has demonstrated promising results on all four collections, with significant improvements over both document retrieval and passage-based retrieval.

There are several possibilities to extend the research in this paper. For example, a more sophisticated query-specific combination approach may provide more accurate results, which automatically adjusts the weights on passage-based retrieval and document retrieval with respect to the charac-teristics of user queries. This research was partially supported by the NSF grant IIS-0749462 and a research grant from the State of Indiana. Any opinions, findings, conclusions, or recommendations ex-pressed in this paper are the authors X , and do not necessarily reflect those of the sponsor. [1] J. Allan. Relevance feedback with too much data. In [2] J. P. Callan. Passage-level evidence in document [3] G. V. Cormack, C. L. A. Clarke, C. R. Palmer, and [4] R. O. Duda, P. E. Hart, and D. G. Stork. Pattern [5] J. Gao, H. Qi, X. Xia, and J.-Y. Nie. Linear [6] D. J. Harper. Relevance Feedback in Document [7] M. A. Hearst and C. Plaunt. Subtopic structuring for [8] J. J. E. Dennis and R. B. Schnabel. Numerical [9] N. A. Jaleel, A. Corrada-Emmanuel, Q. Li, X. Liu, [10] M. Kaskiel and J. Zobel. Passage retrieval revisited. In [11] M. Kaskiel and J. Zobel. Effective ranking with [12] K. Kise, M. Junker, A. Dengel, and K. Matsumoto. [13] D. Knaus, E. Mittendorf, and P. Schauble. Improving [14] V. Lavrenko and B. Croft. Relevance based language [15] J. H. Lee. Analyses of multiple evidence combination. [16] X. Liu and B. Croft. Passage retrieval based on [17] D. Metzler and B. Croft. Combining the language [18] E. Mittendorf and P. Sch  X  auble. Document and passage [19] R. Nallapati. Discriminative models for information [20] G. Salton, J. Allan, and C. Buckley. Approaches to [21] M. Sanderson and J. Zobel. Information retrieval [22] C. Wade and J. Allan. Passage retrieval and [23] R. Wilkinson. Effective retrieval of structured [24] W. Xi, R. Xu-Rong, C. S. Khoo, and E.-P. Lim. [25] J. Zobel, A. Moffat, R. Wilkinson, and
