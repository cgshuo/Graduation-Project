 1. Introduction
The standard IR system paradigm models relevance as a dichotomous entity. Indeed, the bipolar nature of relevance is incorporated and reflected in a number of areas within IR research. However, relevance has been spectrum that needs to be accounted for. However, search engines presenting items on the commonly used one-dimensional ranked list do not make the distinction between documents of varying grades of relevance.
The user must guess the cutoff point between highly relevant and partially relevant items without any clear indication of how many documents should be examined within the list returned. With search engines com-monly returning thousands of results, this task becomes almost impossible. Access to the most highly rele-vant documents in a ranked list is limited by the lack of clear boundaries delineated for each region of relevance. To solve this problem, the regions of relevance should be clearly delineated on a system level.
This paper presents a clustering scheme to group documents by relevance so that documents within rel-
An algorithm was devised to distinguish between the relevance of documents presented in a one-dimen-sional ranked list and to determine the feasibility of clustering the documents based on relevance. Based on the clustering decisions made by the algorithm and user relevance judgments for each item, the degree of overlap between users and the system was measured.

The search queries were inputted on the World Wide Web and an interface displays the resultant doc-uments grouped in clustered format. To evaluate the clusters, end-users issued categorical, interval, and descriptive relevance judgments for the documents returned from the search. The degree of overlap between users and the system, along with the overall effectiveness of the algorithm was measured for each of the clustered regions. 2. Related studies
Few previous studies have developed and tested a clustering scheme based on relevance regions. Previous studies have identified the existence of documents of varying degrees of relevance. Relevance is not a con-set only to a certain degree. However, systems typically collapse results into two sets, in which one set com-bines partially relevant items with highly relevant items, and the other set consists of non-relevant items ( Spink et al., 1998 ).

Rees and Schultz (1967) determined that a simple two-point scale is insufficient and inappropriately col-lapses  X  X  X  variety of degrees of relevance into yes/no decisions X  X . Sperber and Wilson (1986) emphasized that relevance should be considered in terms of degrees, since the presence or absence of relevance is not abso-lute. Certainly, a conspicuous middle region exists in between the two absolutes. Wallis and Thom (1996) stress that it is not simple to convey relevance in terms of degrees but emphasize the need to retrieve mate-tinuity of relevance ( Schamber, 1994 ).

Since relevance is a non-dichotomous concept, it is important to reflect this in the system  X  s ranking and evaluation. Indeed, it is important that highly relevant documents are isolated from those documents that are marginally relevant. This would allow easy access to the documents that are most highly relevant to the information need. Likewise, partially relevant items should be separated from non-relevant items, as par-tially relevant documents can also play an important role to certain users.

Specifically, partially relevant documents can provide users with new information, shifting them towards new directions ( Spink et al., 1998 ). Novice users can often utilize information obtained from partially rel-evant documents to lead them through further stages of the information seeking process toward a possible resolution of their information problem ( Spink &amp; Greisdorf, 1997 ). Partially relevant documents can help users redefine their initial query to obtain the results they are looking for.
 In TREC, the need to use a non-binary scale to effectively retrieve documents has come to the forefront.
Sormunen introduced a four-point relevance scale to reassess the document pools in TREC-7 and TREC-8 to distinguish between highly relevant documents rich in topical information, and marginally relevant documents poor in topical information ( Sormunen, 2002 ). The study found that about 50% of documents assessed as relevant in TREC were actually marginally relevant and of the remaining half, only 16% of doc-uments deemed relevant were actually highly relevant ( Sormunen, 2002 ). Thus, the study emphasizes that relevant documents can consist of both highly and somewhat relevant.

Past research has heavily emphasized the need for clustering within IR systems. Indeed, there has been extensive research on how clustering can be used to improve retrieval. Traditionally, clustering was intro-duced for efficiency of retrieval since matching a query against a centroid might be more efficient than matching against the entire collection ( Hearst &amp; Pedersen, 1996 ). Many clustering techniques build on the cluster hypothesis, which states that relevant documents tend to be more similar to each other than to non-relevant documents. Statistical clustering algorithms form clusters based on topical similarities be-tween documents among a set of retrieved documents. The Scatter/Gather method clusters documents by this paradigm, documents are clustered into topically coherent groups that are displayed through summa-
Past clustering techniques emphasize the matching of the query to cluster centroids ( Willett, 1998 ). Through a hierarchical approach, a query could be compared against each cluster from the top X  X own or bottom X  X p ( Willett, 1998 ). A similarity score generated between the query and the centroid would determine the rank-ing of the clusters to be displayed.

While most clustering schemes emphasize topicality as a means of grouping documents, our technique strives to group documents according to how relevant they are to the user. Instead of forming cluster cent-roids and obtaining a similarity score between the query and the centroid, our scheme provides a score for individual documents based on pre-defined document text characteristics that associate a document as being relevant, partially relevant, and non-relevant. These scores are then grouped together according to a cutoff point that determines the score necessary for a document to be displayed in a certain cluster. 3. Research design The intent of this study is to incorporate the non-dichotomous nature of relevance within search engines.
The fundamental research questions that this study attempts to answer include: Can the middle range of relevance be identified to enhance the output of traditional IR systems? Are there certain characteristics inherent within partially relevant documents that can help identify this middle region? If the partially rel-evant documents can be extracted, can we also distinguish relevant and non-relevant documents in a results set? How successful are the clusters in grouping results that match user judgments and in guiding users to-wards uncovering documents that correspond to their needs? To answer these questions, we have designed a system that consists of two main components. The system component produces the clustered results through a series of automated steps, while the user element involves end-users generating relevance judg-ments and creating clusters through a manual approach. Both of these clustered results can then be com-pared to determine how well the algorithm clustered the results. 3.1. Algorithm
The documents returned in a ranked list produced by AlltheWeb.com will be clustered according to the specifications set forth by the algorithm. The algorithm decides which cluster the documents belong in, and makes the distinction between highly relevant, partially relevant, and not relevant documents. The algo-rithm utilizes similarity measures and ranking heuristics that evaluate the relevance of a page. The high-level workflow of the algorithm is in Fig. 1 .

Each document in the collection is evaluated based on key similarity metrics and ranking heuristics. For the given field and grade. A ranking function produces an overall score that combines the grades with the weight for each field for a given document and is explicitly detailed in a later section. The resultant score determines the cluster the document belongs in. The fields, weights, ranking criteria, and relevancy grades used to deduce a score for each item is illustrated in Table 1 .
 In Table 1 , key fields within each document are identified and assigned a weight and relevancy grade.
The motivation for choosing these fields is further identified in the next section. h represents the maximum number of words in the end-user query minus words that have no meaning. It is assumed that more than
Thus, C 1 h and C 2 h represent fractions of the number of query terms. In all cases, the resulting value is rounded to the nearest whole number. Thus, the notation [ C the number of query terms that must be included within the specified field. Y number of occurrences of a query term in a document. The values used for this trial were Y 2 6 Y 2 &lt;3, 0 6 Y 1 &lt;2. Note that W 1 , W 2 ,and W 3 field, and were set to 0.214, 0.142, and 0.072 respectively.

As an example, suppose the end-user query consists of six distinct terms. Thus, h is 6, C 2 since C 1 and C 2 are set to 2/3 and 1/3 respectively. For the term frequency category, the document re-turned for the given query must contain between 4 and 6 query terms inclusive with each term occurring with a frequency of at least Y 3 in order to receive a relevant grade. To receive a partially relevant grade, the document must contain between 4 and 6 query terms with each term occurring with a frequency of
Y . A grade of not relevant is given as the default case for a document that does not satisfy the relevant vant grade for each of the remaining fields. The motivation for using these fields, weights, constants, and criteria are delineated in the sections below. 3.2. Fields
The HTML makeup of page contains key fields that can indicate the importance of the document and near the beginning of the page may carry greater significance than terms lower on the page ( Notess, 1999 ).
For term frequency, if a term occurs many times in the document, it represents the importance of the term within the page and may symbolize the importance of the term in the document. 3.3. Constants
C 1 and C 2 were used to account for variation in the number of query terms to include since queries may contain multiple words. In our scheme, including these constants allows for flexibility in the evaluation of query terms, since the user may repeat or add multiple terms in the query with the same meaning. Speci-fically, setting C 1 to 2/3 and C 2 to 1/3 provides three ranges that can be used to represent regions of relevance within our scoring breakdown, based on ad-hoc common sense. 3.4. Relevancy grades
The relevance grades used in this study are derived from the notion of multi-graded relevance that is amply evident previous work. For each heuristic, a top grade is given assuming the document satisfies the necessary requirements to the fullest. This stringent criteria for each field is visible down the leftmost column of Table 1 under grade three. Similarly, a satisfactory grade is given when a document only par-tially satisfies the criteria. The requirements across each field are evident in the middle column of Table 1 under grade two. Finally, a low grade, which is displayed in Table 1 under grade one, characterizes non-relevant documents that either fail to meet the ranking criteria. Many documents may receive conflict-
Thus, these scores are aggregated into a weighted ranking function that combines individual scores as a weighted average to predict the most fitting category for the document, based on nature of relevance criteria within the document. 3.5. Weights
Each measure and heuristic is given a weight to assign an appropriate importance value to the field. This value represents how much weight the field carries in assessing the relevance of a document ( Cutler et al., 1997 ) and is included in out clustering scheme. In our algorithm, the assignment of weights to each heuristic is based on tiered-approach, where fields that are equally important are grouped together based on ad-hoc common sense and given a proportional weight in comparison to the other tiers. 3.6. Ranking criteria
To determine the nature of the criteria in Table 1 that best fits relevant, partially relevant, and non-relevant documents, previous work on document text characteristics was applied. Since our algorithm attempts to cluster according to regions of relevance, characteristics of relevant, partially relevant, and non-relevant regions serve as decisive factors within our ranking function. Highly relevant pages tend to discuss the topic at length, deal with several aspects of the topic, have many terms that pertain to the requested topic, and have many expressions to refer to the concepts discussed ( Sormunen, Kekalainen, et al., 1998 ).

In contrast, partially relevant items tend to mention the topic only briefly. They contain only a few words matching the topic, and may discuss the topic from alternative viewpoints extending upon the original re-query, and contain multiple concepts ( Spink et al., 1998 ).
Finally, non-relevant documents are often totally off target ( Sormunen et al., 2001 ). This description of relevant documents, partially relevant, and non-relevant items can be translated into specified criteria that these classes of documents possess, as described in Table 1 . 3.7. Ranking function
Scores for each field in a document are aggregated to achieve a total overall score based on the weight of importance of every ranking factor through a weight proportional to the projected value ( Rapela, 2001 ).
Thus, our ranking function combines the weights and relevancy grades received by a given document for each factor. The overall score is calculated as: where n represents the total number of ranking factors, W is the weight of each factor, k is the relevancy grade received by a document for each factor, q is the query, and d represents the document. The score rep-resents the category that best suits the document, and can fall in any one of three possible regions depend-ing upon the characteristics of the document itself. The score category result for the document will fall in one of the following clusters by converting sc( q , d ) to a region of relevance, namely Cluster ( q , d ).
The constant r represents the maximum score possible from sc( q , d ), f 1 represents a constant factor of the maximum, and f 2 represents a second constant factor of the maximum. The settings for the values used in query q will be placed in either the relevant, partially relevant, or non-relevant cluster. 3.8. Cluster interface
Fig. 2 displays a sample cluster interface that is returned by the system for a query. This interface illus-trates how the document URLS should be displayed to the user once the user submits a query. The clusters delineate the region of relevance each document belongs in. Documents within a specific cluster are not grouped internally according to relevance. Note that this interface represents the output of the system and was not shown to users for evaluation purposes. Instead, users were presented with the original list of results produced by AlltheWeb.com to make their judgments to ensure that the clusters formed by the algorithm do not influence the judgments of users. 4. Relevance data collection 4.1. Study participants
Users  X  relevance judgments provided the basis for determining the success of the algorithm, as the clusters created by the users could be matched with the clusters created by the system. The data analyzed in our study was gathered from five end-user computer science undergraduate and graduate students at the Pennsylvania State University within the department of Computer Science and
Engineering during the spring semester 2003. While they did not have any formal training in IR eval-uation, they were all Computer Science and Engineering students searching a topic related to Computer Science.

The end-users were provided with a ranked list of search results for a predetermined topic. The topic chosen in this study was exactly stated as  X  X  X iography of computer science pioneer John Von Neu-mann X  X . This topic was chosen since it is unambiguous, intelligible, and returned a suitable number of results. This topic yielded a total of 98 results. All users evaluated the same set of search results pro-duced by AlltheWeb.com for the same exact query. Search results were saved and compiled on a web page that provided the URLs that link to each resultant page in the order they were produced from
AlltheWeb.com. We ran our system to produce the clusters 15 min before users conducted the study to maintain consistency. 4.2. Relevance worksheet
Volunteers were given a worksheet on which they could indicate and describe their relevance judgments for the given topic. This worksheet first developed by Spink et al. (1998) is shown in Fig. 3 .

The first measure on the worksheet provided an interval measure of the users  X  relevance judgments on a 77-mm line ranging from not relevant (NR) to relevant (R). The next measure on the worksheet provided a categorical measure of users  X  relevance judgments and was comprised of three boxes labeled relevant, par-tially relevant, and not relevant. The third measure on the form allowed users to explain  X  X  X hy X  X  they made their judgments through a brief description. 5. Results
Measuring the degree of overlap between the user-generated clusters and the system-generated clusters serves as a key measure in revealing the algorithm  X  s effectiveness in classifying the results. 5.1. Relevance judgments
Our data collection consisted of six sets of clusters, with one system-generated set, and five user-derived sets based on the relevance judgments the end-users made. Evaluating the degree of overlap on a cluster-by-cluster basis provides an underlying measure of how well the algorithm performed. Table 2 displays the percentage of overlap between the system and end-user relevance judgments for each cluster.
The relevance judgments made by each user for documents within the system  X  s relevant, partially rele-vant, and not relevant clusters represents the variation of the system compared to each individual user. This variation is depicted in Table 3 . 5.2. Overlap: relevant cluster
The first region considered here is the relevant cluster. Each URL within the system  X  s relevant cluster is matched with the number of users classifying that URL as relevant, partially relevant, or not relevant. In this case, the system determined that a total of nine documents out of the 98 total returned from the search belonged in the relevant cluster. Thus, 45 collective user judgments made by the five end-users were con-judgments were marked as relevant. As a result, 87% of end-user relevance judgments were also relevant in agreement with the system. On the other hand, only six out of 45, or 13% of the judgments, varied from the system-generated results. The extent of agreement between the system and all five end-users for the relevant cluster is depicted in Table 2 . This was a binomial distribution with five subjects with the mean number of respondents for whom algorithm the matched correctly being 4.333.

In calculating these statistics, it is assumed that each URL selected and evaluated by a given user is inde-pendent from other selections. The variance in the number of users who produced matching results is 0.578 and the standard deviation is 0.767. From the data, it is evident that unanimous agreement between the system and all five end users existed for seven out of the nine total documents. The relevance judgments made by each user for documents within the system  X  s relevant cluster represents the variation of the system compared to each individual user. This variation is depicted in Table 3 .

The six total judgments that differed from the system varied only by a single relevance category. The high proportion of matching end-user judgments combined with the low variance and standard deviation indi-cate the relative success of the algorithm in correctly clustering relevant results. 5.3. Overlap: partially relevant cluster
Besides the relevant cluster, the degree of overlap between the system and users within the partially rel-evant cluster was determined. The system determined that 20 documents out of the 98 total returned from the search were indeed partially relevant, accounting for exactly 100 user judgments made for documents within the cluster. Among the 100 user judgments issued in this cluster, 69 were also found to be partially relevant and overlapped with the system  X  s classification.

Thus, the system overlapped with 69% of end-user relevance judgments within the partially relevant clus-ter. Only five out of 100 judgments, or 5% of the user judgments were deemed relevant, while 26 judgments, or 26% were classified as not relevant. Thus, 31% of user judgments varied from the system  X  s classification.
The overall agreement between the system and end-users for the partially relevant cluster is Table 2 . The mean number of end-users that matched the output of the system was 3.45 out of five for this cluster. In addition, the variance in the number who produced matching results is 1.067 and the standard deviation is 1.034. Thus, the variance and deviation within these results is higher than that of the relevant cluster. Yet, the heaviest concentration of judgments overwhelmingly remains within the partially relevant region.
For this cluster, 16 out of 20 documents were judged partially relevant by the majority of users (three or more). The extent of overlap on a per-user basis within the system  X  s partially relevant cluster reveals the scatter of relevance judgments surrounding this cluster. Table 3 depicts the distribution of judgments made by each user in this cluster. 5.4. Overlap: not relevant cluster
The extent of overlap between the system  X  s not relevant cluster and user derived not relevant clusters was also measured. The system determined that 69 documents out of the 98 documents returned from the ori-ginal AlltheWeb.com search were not relevant. The data shows that the majority of users (three of more) also classified 61 out of these 69 documents as not relevant.

Since all five users made judgments for each URL in this cluster, the total number of relevance judg-ments to consider within this cluster is 345. Out of the 345 relevance judgments issued for these documents in the not relevant cluster, 300 user judgments agreed with the system and were not relevant, producing an 87% overlap. Not a single user classified these documents as relevant. Only 45 out of 345, or 13% of judg-ments varied from that of the system and were classified as partially relevant.

The system  X  s not relevant cluster extensively matched the judgments of users, the majority of whom con-sidered 61 of the 69 total documents to be not relevant. The agreement between the system and end-users for the not relevant cluster is displayed in Table 2 . The mean number of end-users who matched the clus-tering of the system was 4.35 out of five users. The variance in the number of users who produced matching results is 0.567 and the standard deviation is 0.752. Thus, the mean, variance, and standard deviation of these results are nearly equal to that of the relevant cluster. Table 3 displays the distribution of judgments within the not relevant cluster for each user. 5.5. Comparison across clusters
Overall, comparisons can be made regarding the system  X  s ability to cluster across the relevant, partially relevant and not relevant clusters. The percentage match between the system and users for the relevant and not relevant regions is nearly identical at 87%. The partially relevant region, however, showed more vari-ance, with an overlap of only 69%. This data reveals that our system was better able to pull out and cluster documents that were either relevant or non-relevant, as opposed to the partially relevant region. Such a in which the document either fits the criteria or does not. However, partially relevant documents tend to exhibit features that characterize relevant along with non-relevant documents. 5.6. Overlap on a continuous scale
The judgments made on the interval scale corresponding to each categorical judgment further exposed the range spanned by each cluster. Fig. 4 illustrates the distribution of end-user relevance judgments in our study on a 77 mm interval ( Greisdorf &amp; Spink, 2001 ).

From our data, the range of relevance judgments exhibited a pattern of a high peak at the tail end, a relatively flat middle region, and a sharp upswing near the head end, conforming to the distribution pattern exposed by Spink and Greisdorf (2001) . This distribution shows the striking number of non-relevant doc-uments that are returned to users from search engines, emphasizing the need for clustering documents re-turned from search engines on the Web. 5.7. Descriptive characteristics identifying each region
On a descriptive scale, users identified the specific criteria they used to rank documents as relevant, par-tially relevant, or not relevant. This compiled set of descriptions is available in Table 4 .
From the compiled descriptions, the criteria for establishing a document as relevant seem very evident and unambiguous. The relevant documents were those that focused on the topic and served as valuable sources of information. The non-relevant documents were often unrelated, out of context, and completely off topic. Partially relevant documents partly discussed the topic, provided satisfactory links to other doc-uments, and often contained minor tidbits of information about the topic at hand. 5.8. Order and clustering
The motivation to cluster by relevance is evident through the impact of order within search results. Doc-uments are often scattered throughout the result set in a one-dimensional ranked list. The most highly rel-evant results may not always be listed at the top of the ranked list and partially relevant results can be scattered throughout the set. There exist no clear indication about where the relevant results end and non-relevant results start. Fig. 5 displays the most frequent user relevance judgment for each of the 98 doc-uments in the result set preserved in the order retrieved from AlltheWeb.com.

Indeed, the distribution of user judgments in our data set for documents returned from AlltheWeb.com reveals that documents of varying relevance can be scattered. For instance, the 92nd document was consid-ered relevant while the sixth document was non-relevant. Although the general trend does reveal an order-ing from high to low relevance, useful documents may be skipped just because of the order in which they appear. 6. Limitations
This research is not without limitations, which are recognized here. The user aspects of the study were limited with a total of five end-users participants. This small sampling of users prevents achieving an opti-mal number of user judgments to produce the most accurate test data. Since this system is intended to run in the real-world environment of the Web, conducting the study with only five participants limits the extent of evaluation. Also, our user group consisted entirely of undergraduate and graduate Computer Science and Engineering students. However, the user pool could be diversified to include a more assorted group of users with various backgrounds and experiences.

Additionally, our implementation ran one search query returning 98 results. This study could be ex-panded to include data from multiple search queries returning varied results to provide an even more exten-sive set of results for the evaluation purposes. Queries should be of a varying nature along with the relevance of the documents returned for each query. Indeed queries retrieving a different mixture of rele-vant, partially relevant, and not relevant documents should be tested and evaluated.

The query used in our study was intelligible, well-defined and static. However, in a real-world environ-ment, queries may be less clearly defined. In a real-world scenario, the query would shift to account for interactive information seeking. This study did not account for this variation in the types and makeup disparity should be accounted.

Another limitation of this study is that the documents to be evaluated by users were presented in the original order produced by the search engine. This may have an effect of swaying the user towards a group-ing the document in a specific cluster based on the position of the document in the original ranked list. The URLs could be permuted when presented to users to avoid any subjectivity in the order of results presented.
Moreover, the constants and criteria used in the algorithm for this study could be further tested to find the combination yielding optimal results. 7. Discussion
Despite these limitations, this research provides key evidence that documents can effectively be clustered based upon regions of relevance. This study considered the non-binary nature of relevance on the system level and tested it with a small pool of users. Based on the data retrieved from our user group, we can con-clude that our clustering scheme directs highly knowledgeable users that are certain about their search requirements directly towards the relevant cluster so that they can efficiently access the types of documents they seek. Likewise, the system provides quick and easy access to partially relevant results that novice users uncertain about their search goals may require.
 In our test run, the system  X  s clustering overlapped significantly with the clusters formulated by the users.
Although the extent of overlap might change with future test runs accounting for a greater number of user a conspicuous overlap between the algorithm  X  s decisions and user classification. While the system success-fully clustered documents within all the regions, certain regions were more accurate than others based upon the user judgments provided.

The system  X  s equally high success in clustering relevant and non-relevant documents provides some key implications. Both relevant and non-relevant documents were seen as highly distinguishable. Both of these documents within these clusters. In comparison to the relevant and not relevant clusters, the system  X  s par-tially relevant cluster overlapped with users to a lesser extent. The boundary between they partially relevant and not relevant regions had noticeable overlap. 7.1. Role of order
Based on user judgments, it was found that the order of documents returned by search engines with one-dimensional lists does not always conform to the assumption that results are ranked from high to low rel-evance. For instance, it was shown that out of 98 possible positions in the ranked list, documents in the 20th, 26th, and 92nd position were judged as relevant while documents in the 6th, 7th, and 8th positions were deemed as non-relevant. With search engines often returning thousands of results, detecting all of the relevant, partially relevant, or not relevant documents in the pool is virtually impossible, unless each result is examined. 8. Conclusion
This research showed that clustering documents on the Web by their regions of relevance is not only fea-sible, but also quite successful. Our clustering scheme offers an accessible, systematic, and versatile ap-proach towards retrieving and organizing search results to enhance the way in which users of all domains meet their information seeking goals. Since partially relevant documents are useful for novice users at the beginning stages of their search, these documents are now clearly identified and grouped to-uments within the relevant cluster with our scheme.

Indeed, for a given information problem, individual users vary significantly in their levels of expertise, knowledge, certainty, and progression through the search process. Some users have a clearly defined notion of what they are looking for, while other users have only a loosely formed idea of the information they are seeking. Some users may have high knowledge about the search topic while others are learning about the search goals, while others are near the final stages of their search. Thus, a vast disparity exists among all classes of users, and this difference needs to be accounted for within IR systems. 9. Future research
The research presented in this study can be extended in numerous directions.  X  The algorithm can be embedded directly within a major Web search engine clustering scheme so that it can be fully operable on of the Web.  X  Within each cluster, results can be ordered so that end-users could more selectively target potentially use-ful documents within each cluster.  X  The number of clusters could be expanded to create an even more fine-grained clustering system.  X  An optimal interface to present the clusters to users can be discovered.  X  Variables within the algorithm can be tuned to find an optimal combination.  X  The effects of order can be measured against the relevance of results.  X  The system  X  s performance can be further correlated with user behavior and search patterns. References
