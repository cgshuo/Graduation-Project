
Abstract  X  Automated sentiment extraction from social media is enabling tec h-nology to support gat hering online customer insights . The basic sentiment extraction is semantic classification of a text unit as positive or negative using lexical and/or contextual clues in a natural language system. From the input side, it is observed that social media as a sub -language often uses emoticons mix ed with text to show em o-tions. Most emoticons, e.g. :=), are not natural language words, but textual symbols using characters to present a smiley face. Intuitively, such symbols are innately ass o-ciated with emotions, whether happy, annoyed or don X  X  care , hence important clues for hel ping sentiment classification. Previous research has involved the limited use of emoticons as noisy labels in sentiment learning but detailed study on how noisy or us eful they ar e has not been done. This paper presents a comprehensive data analysis vestigations are conducted on a fairly large annotated social media corpus, selected by our consumer insight analytics sys tem. This corpus consists of 40,548 sentiment -rich sentences which business users a re truly interested in mining. The study shows that the consistency between positive/negative emoticons with human judgment in this corpus is as high as 75.2 %. Another large r randomly selected corpus consisting of 300,000 sentences from social media shows its consis tency with human judgment to be 40.1 % . A further stu dy finds that emoticons X  recall contribution to sentiment cl a s-sification is moderate, nevertheless, the data containing emoticons and brands are guaranteed to be quality social media representing customers X  voice instead of bus i-nes ses X  voice such as press news. In addition, emoticon is a n additional factor to help extract sentiments where other lingu istic clues are insufficient.
 Facebook has aroused enormous interest in the mining and discovery of customer i n-sights, recognized as significant for businesses. For instance, Twitter has over 500 million registered users as of 2012, generating over 340 million tweets daily, which is equivalent to 3 , 935 tweets per second. Sina Weibo, a Twitter like micro -blog service in China, has an active use r base of over 40 million. Such huge amounts of unstructured text data involve enormous amount of customer voice that is invaluable to leadin g brands and businesses, especi ally in marketing and sales departments. They need to monitor, react, engage, and publish at the speed of social in real time in o rder to co m-pete. The main motivation behind the adoption of social media intelligence tools lik e ours lies in the fact that people are increasingly sharing their opinions on products and services they buy or want to buy on social networks. Recent estimates indicate that on average one in every three blog posts and one in five tweets involve comments on products , services or brands (Hogenboom e t al. 2013). Nett ers freely talk about whet h-er they love or hate a brand, and lots of times they compare it with othe r brands in the same category. Apparently, such information would be really important for bus i nesses to keep track of consumers' attitudes toward their brands and the management can make faster decisions based on the social intelligence when it is extracted from the huge social data pool and analyzed properly. platform . The majority of sentiment analysis systems are machine learning based, ta k-ing a traditional text classification approach to train models like Na X ve Bayes, Max i-mum Entropy or Support Vector Machine. T he text unit for classification is usually a document or paragraph con sisting of multiple sentences. Typical examples of such data are movie or product reviews. When trained on domain data, those classifiers generally achie ve over 80% accuracy for coarse -g rained sentiment classification, as positive, negative or neutral, as reported in the study (Pang and Lee 2008). While machine learning based sentiment classification works well in domain data at document or pa r-agraph level, it faces challenges in handling object focused shor t messages (e.g. twits) in a commercial sentiment analysis system today when the dominant social media platform is mobile and the posts tend to be shorter from mobile user s .
 show emotions of the poster. Most emoticons, e.g. :=), are not natural language words, but tex tual symbols using characters. Among various definitions, Wikipedia defines emoticon as  X  X  meta -communicative pictorial representation of a fa cial expression ... draw a receiver's attention to the tenor or temper of a sender's nominal verbal comm u-nication, changing and improving its interpretation X . It mainly uses a combination of punctuation marks to mimic a smiley face to express a person's feel ing, mood or inte n-tion. Intuitively, people would assume that such symbols are innately associated with emotions, whether love , hate or don X  X  care , hence important clues for helping sent i-ment classification. With the rapid growth of social media uses glob ally, it X  X  generally recognized that emoticons have been playing an increasingly important role in online guage system built for sentiment analysis is expected to take ad vantage of this special linguistic phenomenon, which is typically not in the scope of the grammar or vocab u-lary research of a language.
 chine learning, we have built a rule -based high precision sentiment analysis system based on a parser for use in the product of mining consumer insights from social m e-dia. This system is designed to address two major challenges of machine learning sy s-tems: (i ) brand focused sentence -level sentimen t class ification for short messages; (ii ) extracting reasons behind sentiments to answer why questions. The research on emot i-cons reported in this paper is motivated by the need to enhance the system in handling (i ) in the context of mining customer senti m ents towards a brand. But the analysis and experiments we have done also serve the purpose of enlightening the researchers in both machine learning world and the grammar world with better understanding of the role of em oticons in sentiment analysis . In fac t, it reveals a pitfall facing some earlier researchers ( Read 2005 ; Zhao et al. 2012 ) who assume emoticons are handy and reli a-ble sentiment indicators and therefore use them to collect training corpus for sentiment classification. icon X  X  distribution in social media and its role in a sentime nt analysis syste m . We aim to accom plish two specific goals . in using emoticon as a clue for sentiment classification . Sec tion III briefs our parsing -supported sen tence -leve l deep sentiment system to provide a background for this study . In Section IV, emoticon -related experim ents are set up and results are presented, focu s-impact on data quality . We present our findings and conclusions in Sec tion VI . social network. They have been extremely popular in social media among the younger generation and the seasoned netters. Despite their use everywhere in the online text, linguistically, they are not a  X  X  egitimate X  part of natural language vocabulary or mo r-phology, hence belonging to so -called Unnatural Language Processing (UNLP, Ptaszynski et al. 2011). Some emoticons are fairly universal as symbols of emotion , and others are language dependent. Survey sh ows that they are the second most i m-portant vehicles for expressing emotions in online communication ( Ptaszynski et al. 2011).
 searchers for the sentiment classification. Emotion s seem to be a handy and reliable indi cator of emotions and hence are used either to help automatically generate a trai n-ing corpus for sentiment classification or to act as seeds or one type of evidence fe a-tures to enhance sentiment classification (Davidov , Tsur and Rappoport 2010 ; Liu, Li and Guo 2012; Read 2005; Zhao et al. 2012; Yang, Lin and Chen 2007 ; Hogenboom1 et al. 2013 ). al life social media corpora, in the context of bran d -centered sentiment analysis. That is one major motiva tion and value for this study. (6) evalu a tion. Our work involves (1), (2) and (6). The work involved in (3), (4) and (5) assumes the productive nature of emoticons, similar to the open morphology study issue. of its components, in ways that are very close to flexible word formation in s ome nat u-ral language morphology, with a smiley face being made with various types of eyes, nose and mouth etc. (Strapparava and Mihalcea 2008). However, our study demo n-strate s that the fr e quency distribution of different emoticons is very different, and infr e quency of their a p pea r ance in data. At least for English, the top n (n&lt;1000) emo t-very high prec i sion and recall. developed . Each in coming sentence is analyzed by the full NLP parser , starting from token ization , POS (Part -of -Speech) tagging, chunk ing and endi ng in decoding a d e-pendency parse tree enriched with various syn tactic and semantic features, on top of which deep sentiment extraction capability is built. For instance, nant practice of shallow, course -grained sentiment analysis, thumbs -up and down (or plus neutral) classification, coupled with sentiment associatio n based on proximity . This concept is inspired by the needs from the real world market analysts who were initially very happy with the precision of our sentiment insights and later told us they need more actionable insights and hope we can answer the why questions with regards to sentiments. Over time, the deep sentiments evolve in the process of engaging the users of customer insights and become fairly mature as a standard to drive the research and development supported by deep parsing. To shed some lig ht in the process, a deep sentiment system should be able to extraction insights that can answer these questions in addition to the sentiment classification insight: businesses. For instance , it is much more insightful to know that consumers love the online speed of iPhone 4s but are very annoyed by the lack of support to flash. This is an actionable insight, one that a company could use to redirect resources to address issues or drive a product X  X  develop ment. Extraction of such insights is enabled by our deep parsing.
 extracted must be toward a topic or an object mentioned in a sentence , which could be a brand, or person or location name. We typically select 10 -20 brands to evaluate the system . For instance, in the most recent release the brands we use d are: 75% or above inter -annotator agreement with at l east four judges each time is used for benchmarking . The precision we have achieved is 87% on average across the brands. quire annotating a significant amount of data than precision evaluation. Also, our exp e-riences have shown that to a certai n point, increasing recall is an incremental process, especially when taking into consideration multip le domain factors . Thus , our evalu a-tion has been focused on precision benchmark. For tracking relative recall, we simply measure the total number of extracted sentiment mentions and their percentage given a certain amount data processed by the system.
 volving emoticons in a sentiment system. It needs to be noted that in our approach t o brand -focused, sentence -level classification, the identification of sentiment from a sentence must be targeted at a specific object. A. Experiment Setups of 1258 entries, wh ich we collected during the system development from social data. W e manually marked 10 6 entries as positive indicator and 233 as negative indicator, leaving the rest as unspecified. experiment. The first one is a human annotated corpus with 40 , 548 sentences, which is an acc umulation of some of the data which our QA department prepared for system evaluation. Each sentence is annotated by four annotators, and a 75% agreement am ong annotators is the cutoff threshold we adopt for an agreement. To ensure the objective evaluation, our QA department uses a crowd sourcing service for the annot a-tion so the human judges have no association whatsoever with the development team. Each sen tence is annotated with a sentiment choice of positive, negative or neutral towards the corresponding object associated with the sentiment. lected, but selected from our s entiment analysis system X  X  output. The implication of this choice is that the data must be sentiment -rich, meaning that many sentences from this corpus would be either positive or negative due to the fact that it is a much smaller main practical reasons for this is that, the primary use of this corpus is for evaluating system X  X  precision, not recall, and the standard precision metric is measured by the fraction of extracte d sentiments that are correct against human annotations. For prec i-sion measurement, this selection of data is good enough and as a matter of fact, much better. This is because, if the data is randomly selected, the maj ority of the random data would not c o ntain any sentiment and it requires a much bigger s ize of data to be ann o-tated . That is not only costly but also meaning l ess for precision evaluation. Our empi r-ic al study has shown that about 15% -25 % of data contains a sentiment, depending on a specific br and. Given the fact that this corp us is selected in a way that it i s guaranteed to be sentiment ric h , we name it SelectCorpus. made up of randomly collected data from our content store. The only requirement for Listerine. Unlike the sentiment -rich SelectCorpus, the sentiment is much sparser in RandomCorpus. As discussed earlier, on average only 1 5 % -25% of sentences are e x-pressing a sentiment, either explicit or implicit. From a system evaluation point of view, such a random corpus is more representa tive of so cial media content . Hence, we would like this corpus to be another set of evaluation data used in the experiments. 40 , 548 se ntences from Select Corpus. Without annotation, how would we measure precision and recall based on this corpus? Here we are not seeking for meas uring the absolute performance in the traditional sense. Instead, we estimate precision and recall through these two formulas : is obtained through our series of evaluation over the system development co urse . Likewise, 0.2 is the average sentiment richness score in the range of 0.15 -0.25 obtained for different brands in our evaluation. Sentiment Richness is defined as the ratio of th e number of sentences containing sentiment versu s the total number of sentences . B. Experiment Results ating emoticons: (i) s tatistical distribution of emoti con uses in social m edia; (ii) e mot i-con X  X  impact on precision and recall for sentiment extraction . distribution in the corpus . number of sentences containing an emoticon versus the total number of sentences in the corpus. This metric informs us of the overall frequency of emoticons used in social media and their maximum possible impact on a sentiment extraction system.
 each of these emoticons is actually used in social media. For this purpose, we count the freque ncy of each emoticon X  X  use and its expressed emotion or mood based on the RandomCorpus. T he top 10 used emoticons are listed in Table II.
Rank Emotico n Frequency Percent Emotion 1 :) 3,505 34.00% Happy 2 :D 1,273 12.35% Laugh 3 :( 927 0.89% Sad 4 ;) 773 7.50% Wink 5 : -) 711 6.86% Happy 6 :P 433 4.21% Tongue out 7 =) 319 3.10% Happy 8 (: 309 3.00% Happy 9 ; -) 226 2.19% Wink 10 XD 175 1.70% Grin Total N/A 8,651 83.90% N/A big, only a handful of emoticons are used far more fr equently than all others. ii) Emoticon X  X  impact on sentiment precision and recall is 65.4%, 12.9% and 21.9%. T his gives us the impression that most emoticons used are conveying positive emotions, either explicit or implicit. However, to what extent is using emoticons as a single sentiment clue correct, especially in our context o f brand focused sentiment extraction? For instance, in the message  X  Someone asking a greeter at walmart to watch their child ----JOKE :) ha ha ha ha  X , e ven though there is a pos i-men t is for the object  X  X almart X . Our major goal here is to find out how reliable it is to use emoticon alone as a sentiment indicator. are listed in Table IV and Table V, with the precision to be 75.2% from SelectCorpus and 40.1% from RandomCorpus .
 however. Since the data in SelectCorpus is from our sentiment extraction system X  X  se ntiment of this data set is muc h richer. However, the precision number obtained from SelectCorpus still offers insights into how emoticon X  X  sentiment may overlap with the actual sentiment judged by human standards. The 75.2% precision seems to suggest that, when a sentence is guaranteed to be positive or negative, and when there is an emoticon in it, there is a fairly high chance of being the case that the emoticon can be trusted to be a fairly good sentiment indicator. In this case, the chanc e is 75.2%. world, emoticon alone is not reliable enough to be taken as a sentiment dictato r. As we can see from Table V , there are a large number of neutral sentences that have been incorrectly classified as either pos itive (300 1) or negative (1400) using emoticon . Mistak ing neutral ones as positive or negative has been a common problem for a se n-timent analysis system, and our study shows that emoticon cannot be immune to this headache either. For instance, the brand we are interested in . as a sentiment indicator. The 3.4% Emoticon R ichness score listed in Table I informs us that the maximum contribution to the system recall wou ld be 3.4 % , assuming i ) none of the se ntences containing an emoticon have been correctly classified by the system without using emoticon ; ii) emoticon X  X  precision as an emoticon indicator is w ould be lower . The result is presented in Table V I . The first column shows emot i-cons X  agreement with the annotation, col umn 2 is for the emoticons X  agreement with annotation missed by the system, column 3 is the recall improvement and column 4 shows the overall recall improvement.
 So how to assess the 2.72% recall improvement on SelectCorpus ? The number does no t seem to be impressive and signifi cant . However, from a system development point of vie w, this improvement is meaningful . In our fairly mature English system , we have semantic parser . However, the top ten mostly fired rules contribute to nearly 50% of all sentiments extracted. The vast majority of all other rules account for the long tail of the remaining 50% sentiments , where many individual rules contribute to less than 1% . These ar e either domain specific or linguisti cally specific rules. Table VII lists the top emoticon provides a low -hanging fruit for enhancing the data quality which should not be ignored either. sampled as discusse d earlier, the actual number will be different from 2.72% , but the upper boundary woul d be 4.2% for RandomCorpus . More experiments will be need ed in future to estimate the recall improvement using the formula  X  X stimated Recall X  presented earlier , based on randomly select ed data .
 are used in social media, how reliable it is to use emoticon alone as a sentiment trigger, and what could be the recall contribution of emoticon in a brand focused sentiment extract ion system. We demonstrate that emoticon alone without considering other li n-guistic evidence is no t sufficient to dictate a sentiment toward an object. Our study shows that its recall contribution in our context is not significant, but it is meaningful to help enhance linguistic and/or domain specific sentiment extraction. Ongoing and fu ture work will be focused on what other linguistic factors could be used together with emoticon to improve precision and recall , such as sentence length, and othe r em o-tion -related lexic al items including many weak emotion words . In addition, the study of language -dependent part of emoticons , especially for the Eastern vs. Western di s-tinction, is also interesting and would be beneficial to our multilingual program. we are enabled to conduct the data analysis. 
