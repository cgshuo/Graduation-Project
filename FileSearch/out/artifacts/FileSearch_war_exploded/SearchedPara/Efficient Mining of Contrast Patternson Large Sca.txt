 Contrast patterns [11] are the itemsets showing the discrimination between two classes in a data set, and they are very useful to detect anomalies. It has been widely studied in terms of emerging pattern [3], jumping emerging pattern [5], and contrast capturing method [11]. In addition, classifiers built by the con-trast patterns, such as CAEP [4], are shown to outperform most of the existing methods (e.g. C4.5 [12], CMAR [8]) on accu racy. However, the existing contrast pattern mining methods do not consider the issue of class imbalance (i.e. the data distribution is extremely imbalanced among different classes). Such char-acteristics is commonly observed in the real-life applications.

Table 1 gives an example of four fraudulent patterns that appear in online banking with their False Positive Rates ( FPR ). There are 1,000,000 genuine transactions (Genuine for short) and 1,000 fraud transactions (Fraud for short) in the transaction set that involves 112 attributes. In order to catch frauds effectively, two criteria are proposed: FPR  X  0 . 8 and the support in Genuine is no larger than 0.0001. We can see that only p 4 is qualified. In contrast, patterns p ,p 2 and p 3 have rather high FPR and larger supports in the Genuine, so they can not be applied at an acceptable cost of the investigation fee spent on post-inspection.

The fraudsters invariably try to disguise their behaviors maliciously and by-pass the detection system, some typica l features are then identified: (i) The itemsets that frequently occur in the Fraud are also usually frequent in the Gen-uine (such as p 1 , p 2 , p 3 ). (ii) The itemsets with a strong discriminative power generally are rarely seen ( support  X  0 . 0001) in Genuine (e.g. p 4 ). Therefore, there are three main challenges in mining contrast patterns to detect the Fraud. (1) A strict constraint on FPR demands an extremely small support in the Genuine (as shown in Table 1). Given a small support threshold, a huge number of itemsets will be generated, especially when plenty of attributes are involved. (2) Mining contrast patterns among the large scale data is computationally ex-pensive. (3) Selecting the optimal pattern set for classification is also with a high computational complexity. It is common to see that the serious overlapping among patterns, on which the classifiers are built, negatively impact the overall performance in catching the Fraud.

However, the existing Emerging pattern miner MDB-LL border [3] dose not con-sider the imbalance issue. By applying Max-Miner [1] to mine long patterns with a small support threshold in the Genuine, MDB-LL border consumes a overwhelming memory and computational time due to challenges (1) and (2). Though jumping emerging patterns [5] can be quickly captured, they are rarely observed in the fraud detection scenario acco rding to the feature (i). CAEP [4] suffers from the serious pattern overlapping confronting with challenge (3).

In this paper, we propose a novel approach to mine contrast patterns in the large scale imbalanced data by explorin g the converging patterns, which effec-tively handle the above challenges. The main contributions are as follows.  X  Define the converging patterns, a novel type of contrast patterns that signif- X  Introduce a series of branch bound pruning strategies to reduce the com- X  Perform extensive experiments to eval uate the effectiveness of our approach The rest of the paper is organized as follows: Section 2 reviews the related work. Section 3 defines the problems and t erminologies. Sect ion 4 presents the approach of pattern border operation. Section 5 introduces two refining strate-gies, T*tree and border splitting. Section 6 proposes the algorithm of converging pattern mining. Section 7 proposes the pattern selection and scoring methods for prediction. Section 8 shows the evaluation. We conclude in Section 9. Several approaches have been proposed to mine the contrast patterns [11]. Emerg-ing Patterns (EPs), firstly introduced in [3], uses growth rate to measure the support contrast of an itemset. Disjunctive emerging pattern [11] is a variant of EPs to discover the contrast patterns in a high dimensional data set. The work in [5] extends the concept of EPs, and introduces the Jumping Emerging Patterns (JEPs) whose supports increase abruptly from zero in one data set to non-zero in another one. According to [ 5,4], classifiers built by the EPs or JEPs outperform most methods (e.g. C4 .5 [12], CMAR [8]) on accuracy.

All the above methods are proposed for the class balanced data. However, more researchers pay attention to the class imbalanced problems [13,10], which widely exit in the real world and greatly challenge the classic data mining al-gorithms. Tremendous research efforts have been made on the class-imbalanced data, for instance, Cost-Sensitive Neural Network [10], Ad-Cost [13], Cost-SVM [9], etc. None of them addresses the mining of contrast patterns in the class imbalanced data set, while we focus on solving this problem. Let I = { i 1 ,i 2 ,...,i m } be a set of items, an itemset X is a subset of I .A transaction T is an itemset X whose number of elements is fixed according to the number of attributes in the data set. A data set D is a set of T . Suppose there are two classes denoted as C t (the target class, e.g. Fraud) and C b (the background class, e.g. Genuine), and two data sets D t and D b in D correspond to the respective classes C t and C b . Transactions in D b are labeled as C b ,and those in D t are marked as C t . S b ( X )and S t ( X ) denote the supports of itemset X in D b and D t , respectively.
 Definition 1. Converging Patterns (CPs for short) are composed of the S ( X )  X   X  } ,andthe Contrast Rate of CPs is defined as F ( X )=( S t ( X ))  X  / S ( X ) ,where k&gt; 0 is the contrast coefficient,  X &gt; 0 is the converging exponent, and  X &gt; 0 is the threshold of the minimal support in D t .
 As the above definition indicates, CPs are controlled by k and  X  . The larger the  X  , the higher the contrast rate of the gener ated converging patterns. For example, in Fig. 1, itemsets are projected onto the support plane where the vertical axis stands for S b ( X ) and the horizontal axis denotes S t ( X ).AccordingtoDefinition 1, the itemsets in the shadow region I ABF J compose CPs, denoted as {I ABF J } . It is also derived by: where I represents all the itemsets in region .

The itemsets in I BFDH can be obtained by the Max-Miner [1] in D t , i.e. {I {I to that in I BFDH .Let  X  =max( k, X  ), where  X  is a proper support threshold for Max-Miner to output long patterns successfully in D b . Unlike the algorithm in [3], which applies a strict growth rate  X  to mine EPs and does not work in imbalanced data as mentioned in Section 1. Then the itemsets in I ICDE are obtained as {I ICDE } = { X | S b ( X )  X   X  } .Thus, {I GCDH } = { X | S t ( X )  X   X  } X  X  X | S becomes the effective filtering of all the itemsets in I AJCG , i.e., the last term in Equation (1). Accordingly, the mining of CPs is fulfilled by two phases (as shown in Fig. 2): candidates generation and pattern verification (in phase 1), and predica-tive classifier building (in phase 2). Sect ion 4 introduces the method to generate the candidate itemsets, section 5 provides the strategies to eliminate the redun-dancy, section 7 presents the techniques to select the optimal pattern set and calculate the prediction score. As specified in Section 3, CPs is identifie d by Equation (1). In order to perform the substraction of itemsets quickly, we propose the Pattern Border to collect the itemsets and provide several theorems to support the retrieve of the candidate CPs by algebraic operations rather than traversing all elements in borders. 4.1 Pattern Border Definition 2. Given two itemsets L and R ( L X  X  ), the ordered interval [ L , R ] forms a Pattern Border , composed of a set of patterns. The collection of item-sets in [ L , R ] is defined as: [ L , R ]= { Y | X  X  X  X  , L X  Y  X  X } . Example 1. Border [ a,abcd ] contains 8 patterns: a,ab,ac,ad,abc,abd,acd,abcd . Pattern border is an important concept in CPs mining. A proper adjustment on the pattern border greatly avoids the full iteration of every candidate itemset in I
AJCG , and dramatically speeds up the search of CPs. Since the smallest itemset in [ L , R ]is L and R is the largest one, an itemset X  X  [ L , R ] then satisfies the following conditions: Definition 3. The Upper Bound F u ([ L , R ]) and Lower Bound F l ([ L , R ]) of the contrast rate F ( X ) ,where X  X  [ L , R ] , are defined as follows: In Section 5.2, F u ( X )and F l ( X ) are applied to prune the searching space. 4.2 Subtraction of Pattern Borders As shown in Example 1, pattern border is a simple and efficient way to collect patterns. Border substraction is frequently performed to generate the candidate itemsets in I BFCG , according to Equation (1). The most straightforward method is to enumerate each element in the border and eliminate the redundant elements. But, it is rather costly in both computational time and memory when the border is large. Thus, we implement the substraction of two borders only based on two operators  X  and  X  , rather than exploring the borders directly.

Let itemset X  X  I , I X = { X | X  X  X } ,and I + X = { X | X  X  X,X =  X  X  , several definitions and theorems are proposed to support the border subtraction on the two sets of itemsets: S 1 and S 2 .
 Definition 4. The Operator  X  for S 1 and S 2 is defined as: The Operator  X  for S 1 and S 2 is defined as: X The operator  X  is adopted during the subtraction of two collections of itemsets, generating the candidate itemsets in I BFCG . We then easily get the following properties and theorems for the operators: Theorem 1 decomposes I X 1  X  X 2 into smaller parts easily to be processed. as X 1  X  X 3 =  X  Below, we illustrate the use of these two operators for the border substrac-tion.The above techniques are applied to Algorithm 1 (line 4-7) in Section 6. Example 2. The border subtraction [  X  ,abcdefgh ]  X  [  X  ,ab ]  X  [  X  ,bc ] is obtained I [ f,abcfgh ]  X  [ g,abcgh ]  X  [ h,abch ]  X  [ ac,abc ] . The qualification of itemsets in I AJCG is verified in a Branch-and-Bound manner. Given a border [ L , R ], F u ( X )and F l ( X ) are estimated by Equation (4), and are used to check the qualification of [ L , R ]. Instead of scanning the database which are used to compute F u ( X )and F l ( X ) by scanning database only once. Then, the strategies are presented to split [ L , R ] for checking the sub borders. 5.1 T*-tree Index Transaction Tree (T*-tree) extends the classic spatial index, i.e. R-tree [2], to obtain new properties which significantly accelerate the calc ulation of support. In a R-tree, an object is represented by its Minimal Bounding Box (MBB) [2], which is the minimum bounding rectangle surrounding the object. R-tree is built on all the MBBs recursively. In order to efficiently get the support of an itemset, we introduce a novel index T*-tree, in which all the transactions are treated as spatial objects wrapped by their M BBs. The query on T*-tree is to check how many transactions match a given pattern. Accordingly, the patterns to be queried are also mapped to MBBs.

The main challenge of using T*-tree in a high dimensional data set is that the overlapping among nodes increases w hen more objects are inserted. Serious overlapping affects the query efficiency s everely. Therefor e, based on the data distribution, the data space is partitioned into multiple subspaces to reduce the overlapping of nodes as much as possible. The space partition follows a two-tier tree structure, as showed in Fig. 3. In this way, the computational time is dramatically cut by taking the following advantages: 1) A T*-tree consists of two layers: trunk and branch. All the attributes are 2) Each node stores two values (i.e. D t and D b , called local supports ), which 3) The leaf nodes store the transaction chains that record the numbers of trans-5.2 Splitting Strategies Definition 1), then [ L , R ] needs to be split into smaller borders for further val-idation. The splitting strategies belo w are used to speed up the search process, output CPs and remove unqualified borders quickly.
 no itemset in [ L , R ] is qualified to be chosen. So [ L , R ] is safely removed. for each single item i  X  X R} X  X L} ,weextend L to the sub-border [ L X  X  i } , R ] ,de-sub-borders that can be removed immediately with Strategy 1 by narrowing borders decreases as fast as possible. If max the sub-borders which can b e delivered directly with Strategy 2 by increasing borders increases as quickly as possible. If max Here, a novel algorithm ConvergMiner is proposed to mine CPs efficiently. Algo-rithm 1 presents the main process of mining CPs, and function CheckContrast is the key function to validate the qualification of candidate itemsets. There are four steps in the main process: Step 1 . Build the T*-tree on D t and D b (Line 1). Step 2 . Employ the Max-Miner to extract the pattern borders located at I ICDE and I BFDH (Line 2-3). Step 3 . Perform the border substraction to obtain the pattern borders locate at I BFCG (Line 4-7). Step 4 .SearchCPsin I BFCG by a Divide-and-Conquer procedure (Line 8-9). There are two critical issues to be solved during the construction of an accurate CPs-based classifier: pattern selection a nd risk scoring. We adopt an effective measure, Maximal Coverage Gain ( MCG ) [7], to select the globally optimal pattern set. Once the optimal pattern set P has been obtained, a base score for Algorithm 1. ConvergMiner each rule r : p  X  C t in P is calculated by Equation (11). The base score of p i represents its impact in classifiers.
 In the prediction phase, the score of u is calculated as follows: bility of u 1  X  C t is larger than that of u 2  X  C t . Consequently, transaction u with a larger S ( u ) is more likely to be classified into C t . Two real-life data sets are used: DS 1 , the online banking transaction data from a major Australian bank. It contains 1,000,000 Genuine ( D b ) and 1,000 Fraud ( D t ), and the number of attributes involved is 112; DS 2 , the social welfare payment claim data from Australia. It has 120,000 Genuine ( D b ) and 2,120 Fraud ( D t ) with 85 attributes. Below, ConvergMiner is compared with the state-of-the-art classification algorithms on these two class imbalanced data sets in terms of accuracy (i.e. Ada-Cost [13], Cost-NN [10], Cost-SVM [9] and CAEP [4]), efficiency (i.e. MDB-LL border ), and effectiveness of pruning strategies. 8.1 Accuracy We compare the performance of the classifier powered by CPs with Ada-Cost [13], Cost-NN [10], Cost-SVM [9] and CAEP [4], from the perspective of False Positive Rate ( FPR ) and Detection Rate ( DR , or True Positive Rate), which are defined as: In fact, the smaller the FPR and the larger the DR , the better the classifier. Fig. 4 shows that when 60% Fraud are caught, the FPR sofCPs,CAEP,Cost-NN, Ada-Cost and Cost-SVM are 6 ,9 ,12 ,18 and 30 , respectively.
 However, with the increase of FPR , all the classifiers achieve a higher DR. When FPR =11 , CPs catches 82% Fraud, but CAEP only catches 72%, Cost-NN catches 55%, Ada-cost catches 40%, and Cost-SVM catches 38%. The accuracy test on the data set 2 reveals the simila r performance for the above methods (as shown in Fig. 5). Overall, we observe that at the same level of FPR ,CPs achieves much higher DR than other methods; with the same DR , CPs obtains much lower FPR . In Fig. 4, when FPR = 5%, CPs outperforms CAEP by 65%, Cost-NN by 80%, Ada-Cost by 90%, and Cost-SVM by 250%. In Fig. 5, for DR = 60%, CPs outperforms CAEP by FPR =15 , which is only 60% of that of CAEP ( FPR =24 ). So, CPs outperforms benchmark methods in accuracy. 8.2 Efficiency We compare the computation time consumed by ConvergMiner and MDB-LL border to evaluate their efficiency on DS 1 . For both algorithms, we choose the same level of converging exponent  X  =1. The contrast rate in ConvergMiner and MDB-LL border are 1 /k and the growth rate, respectively. As shown in Fig. 6, with the increase of 1 /k , ConvergMiner gains more benefit from the splitting strategies, by which a huge number of sub-borders are eliminated more easily. As a result, the number of borders to be split for the further checking decreases dramatically. In addition, MDB-LL border takesmoretimetoprocessahuge number of the sub-border iterations due to the extremely low support in D b . For instance, when the contrast rate is 1000, ConvergMiner takes only around 5% of the computation time consumed by MDB-LL border .When1 /k is larger than 1000, MDB-LL border does not succeed in identifying the itemsets with the support less than 0.0005, but ConvergMiner still works stably. The reason is that ConvergMiner assigns a looser value rather than a fixed value to  X  (in D b ), and leaves the redundancy to the next step: bound checking and further valida-tion. In summary, the results show that ConvergMiner significantly outperforms MDB-LL border on the imbalanced data set in terms of the efficiency. 8.3 Effectiveness of the Pruning Strategies Two benchmark algorithms, i.e. Split-and tTree-, are designed to evaluate the ef-fectiveness of our pruning strategies on DS 1 . Split-is a variant of ConvergMiner when the splitting strategies are replaced by a random one at line 17 in Func-tion CheckContrast. tTree-is a variant of ConvergMiner by removing the local supports in T*-tree. Other components remain the same as ConvergMiner. Fig 7 displays the computational time of the three algorithms and the corresponding improvements gained from our pruning strategies under different contrast rates. ConvergMiner obtains the improvem ent of 50% (upon tTree-) and 90% (upon Split-), when the contrast rate is 100 due to the T*-tree and splitting strate-gies . With the increase of contrast rate , the improvement rate grows rapidly and reaches 2700% (upon tTree-) and 1700% (upon Split-) when the contrast rate is 5000. Thus, the proposed splitting strategies and T*-tree are effective in enhancing the computational efficiency. In this paper, we introduce a novel type of patterns, i.e. converging patterns (CPs), on the extremely imbalanced data; and propose an efficient algorithm ConvergMiner equipped with effective sp litting strategies and a fast tree index to mine CPs. The experiments show that our algorithm greatly outperforms the state-of-the-art techniques on two real-life large scale imbalanced data sets in terms of accuracy and efficiency. In addition, ConvergMiner exhibits a strong capacity on the scalability and gains more advantages with a larger contrast rate. In future, we are going to mine CPs on the sequential data for online banking. Acknowledgments. This work is sponsored by the Australian Research Coun-cil Discovery grant (DP1096218) and Linkage grant (LP100200774).

