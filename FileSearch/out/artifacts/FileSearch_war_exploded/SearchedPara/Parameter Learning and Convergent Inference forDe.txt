 Philipp Kr  X ahenb  X uhl philkr@cs.stanford.edu Vladlen Koltun vladlen@cs.stanford.edu Random field models are often used to express im-age coherence priors in computer vision applications, such as segmentation and reconstruction (Blake et al., 2011). Most random field models explored in the lit-erature are sparsely connected, with the most com-mon structure being a grid. Such models can lead to excessive smoothing of object boundaries and to in-consistencies over longer ranges in the image. Mod-els with hierarchical structure and higher-order poten-tials have been proposed to reduce these artifacts (He et al., 2004; Roth &amp; Black, 2009; Kohli et al., 2009). Nevertheless, the connectivity of the models remained relatively sparse due to the limitations of available in-ference algorithms.
 Recently, Kr  X ahenb  X uhl and Koltun (2011) introduced an efficient algorithm for performing mean field in-ference in fully connected random fields. Such dense random fields support explicit modeling of long-range correlations in the image and have enabled substantial accuracy gains in pixel-level labeling problems. The algorithm of Kr  X ahenb  X uhl and Koltun handles pairwise potentials that can be expressed in terms of Gaussian kernels in feature space, and inference is performed by means of rapid approximate Gaussian convolutions. Vineet et al. (2012a; 2012b) have extended convolu-tional inference to more general Gaussian kernels and to models with higher-order terms.
 Despite the development of efficient inference algo-rithms, parameter estimation in dense random fields is still poorly understood. Prior works use piecewise training, in which different types of parameters are learned separately. For example, parameters for the unary potentials and for the pairwise potentials are separately estimated (Kr  X ahenb  X uhl &amp; Koltun, 2011; Vi-neet et al., 2012a;b). Kr  X ahenb  X uhl and Koltun esti-mate some parameters using grid search, and Vineet et al. use a simplified generative model with additional independence assumptions.
 In this paper, we present a general algorithm for pa-rameter estimation in dense random fields. All pa-rameters are learned jointly, thus capturing dependen-cies between them. The algorithm supports a vari-ety of loss functions formulated over the mean field marginals. The learning algorithm thus estimates pa-rameters that optimize the performance of mean field inference.
 Algorithms for parameter estimation in random field models minimize a loss function, such as the nega-tive log-likelihood (LeCun et al., 2006; Koller &amp; Fried-man, 2009; Tappen, 2011). This is commonly done using gradient-based optimization. Computing the ex-act gradient is computationally intractable in general because it requires performing exact inference in the model. One way to deal with this is to approximate the gradient by substituting approximate inference in place of exact inference (Wainwright et al., 2003; Sut-ton &amp; McCallum, 2005; Kumar et al., 2005; Vish-wanathan et al., 2006; Levin &amp; Weiss, 2009; Pal et al., 2012). While it can be shown that the approximate gradient obtained in this way corresponds to a well-defined surrogate objective (Wainwright, 2006), it may not optimize the performance of the learned model on the data (Kulesza &amp; Pereira, 2007).
 We take a different approach and directly minimize a loss function on the approximate distribution that is used by the inference algorithm (Tappen, 2007; Samuel &amp; Tappen, 2009). This is known as marginal-based loss (Domke, 2013). The advantage is that the perfor-mance of the inference algorithm is optimized directly: parameters are learned so as to maximize the accuracy of the mean field approximation.
 To optimize the marginal-based loss function we need to compute its gradient. This is challenging because there is no closed-form expression for the mean field marginals. However, the marginals can be defined re-cursively, as the product of iterative message passing. Using this definition, we derive an efficient algorithm for computing the gradient of the marginal-based loss function over the parameters of the model.
 As a supporting result, we develop an efficient mean field inference algorithm for dense random fields that is guaranteed to converge. Mean field inference is known to converge if message passing is performed se-quentially (Wainwright &amp; Jordan, 2008). However, for dense random fields, sequential message passing is im-practical due to the huge number of pairwise connec-tions. The convolutional inference of Kr  X ahenb  X uhl and Koltun performs all message passing in the model in parallel. This is the key to its efficiency, but it also in-validates the traditional convergence guarantees. We present a different convolutional inference algorithm that is guaranteed to converge. Model. The dense conditional random field is de-fined over a set X = { X 1 ,...,X N } of variables con-ditioned on the image I and the model parame-ters  X  . The domain of each variable is a set L = { l 1 ,l 2 ,...,l M } of labels. The Gibbs energy of a label assignment x  X  X  N is where i and j range from 1 to N . The unary potentials  X  ( x i |  X  ) and the pairwise potentials  X  ij ( x i ,x j |  X  ) are implicitly conditioned on the image I . Each variable X i is associated with a fixed feature vector f i , deter-mined by the image I . The pairwise potentials are modeled as mixtures of kernels in feature space:  X  ij ( x i ,x j |  X  ) = Here  X  ( m ) is a label compatibility function that mea-sures how likely two classes are to occur near each other. The simplest such label compatibility is the Potts model:  X  ( m ) ( x i ,x j |  X  ) = 1 [ x Inference. Mean field inference computes a distri-bution Q ( X ) that best approximates the probability model. Q ( X ) = Q i Q i ( X i ) is a product of indepen-dent marginals over each of the variables. Each of the marginals is constrained to be a proper probability dis-tribution: P x field approximation minimizes the KL divergence D ( Q k P ) =
X
X Traditional mean field inference performs the following message passing update on each marginal Q i in turn until convergence: Q ( x i ) = where Z i is the marginal partition function. Each up-date is guaranteed to decrease the KL divergence and this inference algorithm is guaranteed to converge to a local optimum (Wainwright &amp; Jordan, 2008; Koller &amp; Friedman, 2009).
 In dense random fields the computational bottleneck is the evaluation of the sum P complexity of a single update of a marginal Q i ( X is O ( N ) and the complexity of updating all the marginals is O ( N 2 ).
 Kr  X ahenb  X uhl and Koltun (2011) observed that a high dimensional Gaussian filter can be used to update all the mean field marginals concurrently in time O ( N ). This makes inference tractable. Unfortunately, the convergence guarantees traditionally associated with mean field inference break down when message pass-ing is performed in parallel. In the next section, we present two variants of a new efficient inference al-gorithm in dense random fields that is guaranteed to converge for a broad class of kernels and label compat-ibility functions. We begin with two sufficient conditions under which we can perform parallel message passing and still guar-antee convergence. The first condition is that all ker-nels k ( m ) must be positive definite. A kernel k is defined to be positive definite if and only if for an arbitrary set of feature vectors { f 1 ,..., f N } the ker-nel matrix K with entries K ij = k ( f i  X  f j ) is pos-itive definite. Bochner X  X  theorem implies that any kernel k ( m ) with a non-negative Fourier spectrum is positive definite. Positive definite kernels are also known as Mercer kernels and K is their Gram ma-trix. The Gaussian kernel k ( x ) = e  X  1 2 x 2 , the tent filter k ( x ) = max(1  X  k x k 1 , 0), and the sinc filter k ( x ) = sin( x ) x are examples of positive definite kernels. Note that conventional grid-structured random field models are a special case of the tent filter; in this case k ( f i  X  f j ) = max(1  X  1 2 k f i  X  f j k 1 , 0), where f two-dimensional coordinate vector of pixel X i . The second convergence condition is that each label compatibility function  X  ( m ) is negative semidefinite. A label compatibility function  X  is defined to be nega-tive semidefinite if and only if there exists a constant c for which the matrix  X  with entries  X  ij =  X  ( l i ,l j ) + c is negative semidefinite. Note that adding the con-stant c to all label compatibility values simply repa-rameterizes the Gibbs energy of the random field and does not change the modeled probability distribution. The Potts model  X  ( l i ,l j ) = 1 [ l inite with c =  X  1. Other negative semidefinite la-bel compatibility functions include negative diagonal models  X  ( l,l ) =  X   X  l , negative diagonally dominant models  X  ( l i ,l i ) &lt;  X  P l  X  ( l i ,l j ) = | l i  X  l j | .
 We now present an efficient parallel mean field infer-ence algorithm for dense random fields that is guar-anteed to converge for models with positive definite kernels and negative semidefinite label compatibility functions. 3.1. Convergent parallel mean field We begin by rewriting the KL divergence (3) in vector notation: where q and u are vectors of length N  X  M with el-respectively. We use the tuple ( i,l ) to refer to variable X i and label l . For notational convenience we use q i to denote a vector of the M elements in q associated with variable X i . The vector u i is defined analogously. The pairwise potentials make up the symmetric matrix  X  there is no pairwise term between a random variable X i and itself,  X  has a zero block diagonal. Equiva-lently, we can express  X  as the Kronecker product of the kernel matrix K and the label compatibility matrix  X  : For notational simplicity we assume that the kernel Subtracting the identity matrix I N from K ( m ) in the above equation yields a zero block diagonal in  X . For a negative semidefinite label compatibility func-tion  X  ( m ) and a positive definite kernel k ( m ) the Kro-necker product K ( m )  X   X  ( m ) is negative semidefi-nite and hence concave. The block diagonal matrix lows us to write the KL divergence as the sum of a convex function f ( q ) and a concave function g ( q ): f ( q ) = q &gt; log q  X  g ( q ) = q &gt; u + Note that the concave function g ( q ) includes all the pairwise interactions between different marginals q i and q j , while f ( q ) only involves local terms over indi-vidual marginals q i .
 We use the concave-convex procedure (CCCP) to minimize the KL divergence (Yuille &amp; Rangarajan, 2001). CCCP iteratively minimizes a series of energy where q ( t ) and q ( t  X  1) are the mean field marginals at iteration t and t  X  1, respectively. CCCP is guaran-teed to converge to a local minimum (Sriperumbudur &amp; Lanckriet, 2009).
 CCCP leads to the following optimization problem: minimize subject to 1 &gt; q i = 1 for i = 1 ,...,N (6) restricts the domain of q to non-negative values. This makes an explicit constraint q  X  0 redundant.
 For each variable X i , the gradient is defined as This is almost identical to message passing in Kr  X ahenb  X uhl and Koltun X  X  algorithm (2011). It is the combination of a matrix multiplication  X  ( m ) q ( t  X  1) a convolution with a kernel k ( m ) , both of which can be evaluated in linear time.
 In the mean field optimization problem (6), each marginal q i is independent of every other marginal q . We minimize each marginal q i independently. The Karush-Kuhn-Tucker (KKT) conditions are Strong duality holds since the objective in (6) is convex and continuously differentiable, and the constraints are affine. This means that a solution to the KKT conditions (8) minimizes the objective (6). We solve the KKT conditions using Newton X  X  method.
 This algorithm is somewhat slower than the algorithm of Kr  X ahenb  X uhl and Koltun since we need to solve a nonlinear system of equations rather than simply exponentiating and normalizing the marginals after each parallel message passing step. In Section 3.2 we present a slight modification of the mean field objec-tive that leads to a faster and simpler convergent infer-ence algorithm that produces almost identical results in practice. 3.2. Concave cross-entropy approximation The cross-entropy term of the KL divergence in Equa-tion 4 is close to concave, especially for large kernels k ( m ) . The only source of non-concavity is the block di-agonal matrix I N  X   X  , which contributes very little to the pairwise term  X . For example, a two-dimensional Gaussian kernel of standard deviation  X  3px contains less than 1% of its mass at the center. In practice, the error introduced by simply ignoring the presence of the extraneous block diagonal is negligible, as we will verify in Section 5. This motivates the concave approximation of the cross entropy:
D ( Q k P ) = q &gt; log q Equation 9 is the sum of a convex function, the en-tropy, and a concave function, the approximate cross entropy. We again use the concave-convex procedure. The gradient of the approximate cross entropy yields the same message passing step as Equation 7 and is again evaluated efficiently using high-dimensional fil-tering.
 The CCCP algorithm then minimizes the convex en-constraint that q is a proper probability distribution. We minimize the convex objective by solving the KKT conditions for each mean field marginal: The solution is the standard mean field update q The resulting algorithm is almost identical to the algo-rithm of Kr  X ahenb  X uhl and Koltun. Like the algorithm in Section 3.1, it is guaranteed to converge. However, since the KKT conditions have a closed-form solution, this algorithm is more than three times faster in prac-tice than the algorithm in Section 3.1 and has analo-gous performance to the algorithm of Kr  X ahenb  X uhl and Koltun, as shown in Section 5. We now derive the main result of this paper: a pa-rameter learning algorithm for dense random fields. The algorithm minimizes a differentiable loss function L ( q ) over the mean field marginals q . A number of loss functions are described in Section 4.3.
 It is easy to see that the marginals q depend on the model parameters  X  . For example, changing the pa-rameters of the unary potentials  X  i can move the mode of the variational approximation and change the marginal distributions q obtained by the inference pro-cedure. Let X  X  make this functional dependence ex-plicit: q = q (  X  ). As shown in supplementary ma-terial, q (  X  ) is continuously differentiable. Differentia-bility implies that for any pair of sufficiently similar model parameter vectors, the mean field approxima-tions are also similar: no pair of sufficiently close pa-rameter vectors can lead the mean field inference into different local optima.
 We use gradient-based optimization to minimize L ( q (  X  )). For the remainder of this section we as-sume that inference is performed using the algorithm described in Section 3.2. The algorithm described in Section 3.1 and the original algorithm of Kr  X ahenb  X uhl and Koltun can be handled analogously. 4.1. Mean field gradient The gradient of the marginal-based loss is We use implicit differentiation of the KKT conditions (10) to derive the gradient  X  q  X   X  of the mean field ap-proximation. The gradient  X  X   X  q of the loss function will be treated in Section 4.3.
 The derivative of the KKT conditions with respect to the model parameters yields a set of linear constraints on the gradient of each marginal: As shown in supplementary material, the linear system (12) is full rank and invertible. The gradient  X  q ( t ) thus always well-defined and is given by convenience let A ( t ) be the block diagonal matrix with blocks A ( t ) i , for i = 1 ,...,N .
 We compute the gradient of the message passing term e ( t ) using the product rule: ous iteration, the unary gradient  X  u  X   X  , and the pairwise gradient tensor  X   X   X   X   X  . Unary and pairwise gradients with respect to various model parameters are derived in Sec-tion 4.2.
 Evaluating equations 13 and 14 directly involves n message passing steps per parameter. Computation-ally this is as expensive as computing the numeric gra-dient using finite differencing. For models with more than a few parameters this is infeasible.
 While a direct evaluation of the gradient  X  q ( t ) i  X   X  practical, we can still evaluate the gradient  X  X   X   X  ciently. We recursively substitute the gradient of the mean field marginals (13) and the gradient of the mes-sage passing term (14) back into Equation 11. The resulting gradient expression is like a direct evaluation, this back substitution leads to an algorithm that requires only n parallel message passing steps in total, independent of the number of parameters. The gradient computation is summarized in Algorithm 1.
 Algorithm 1 Mean field gradient 1: for t = 1 to n do 2: Run inference to compute q ( t ) 3: end for 5: for t = n  X  1 to 1 do 7: end for 8: g  X  0 9: for t = 1 to n do 12: end for This algorithm is closely related to back belief prop-agation (Eaton &amp; Ghahramani, 2009) and back tree-reweighted belief propagation (Domke, 2013).
 Algorithm 1 begins by performing inference to com-pute the mean field marginals q ( t ) for every iteration t (lines 1 -3). Next, message passing is used to com-pute the normalized loss gradient b ( t ) (lines 4 -7). This message passing step is similar to inference, but instead of exponentiating and normalizing we simply multiply by the matrix A ( t ) . Finally, the gradient of the objective is computed as the sum of unary and pairwise gradients (lines 10 and 11). We will now show how to evaluate these gradients efficiently. 4.2. Unary and pairwise gradients In this section, we describe how to efficiently evaluate the gradient terms in lines 10 and 11 of Algorithm 1 with respect to various model parameters. Let b ( t ) and q ( t ) be given. For notational simplicity we drop the superscript for the remainder of this section. Logistic parameters. We assume that the unary term is a logistic regression model with u i =  X h i for a parameter matrix  X  and features h i for variable X i . (In our experiments, h i is the result of a TextonBoost classifier at pixel i (Shotton et al., 2009).) The unary gradient with respect to the logistic parameters  X  is given by Label compatibility. Recall the definition of the pairwise term  X   X  = P C m =1 K ( m )  X   X  ( m ) . The pair-wise gradient with respect to the label compatibility parameters is given by The second summation is simply a convolution of the marginals q with kernel k ( m ) . As with message pass-ing, this convolution can be performed efficiently and the gradient can be computed in linear time. Note that we usually require  X  to be symmetric; this is enforced by setting  X  ( a,b ) =  X  ( b,a ) to be a single variable and adapting the gradient expression accordingly.
 Kernel shape. Consider a Gaussian kernel of the this function with respect to its parameters is  X  X  ( f i  X  f j ) This expression is no longer Gaussian. However, we can express it as a weighted sum of Gaussians and gradient with respect to the kernel parameters  X  is  X  b &gt;  X   X  q 1 2 1 2 Each of the four summations over j is a high-dimensional Gaussian convolution and can be per-formed efficiently. In order to compute this gradient we perform a total of 2 M ( D + 1) convolutions, where M is the number of labels and D is the dimensionality of the feature vector. The total running time is linear in the number of variables N . 4.3. Loss functions We now consider a number of loss functions L ( q ) de-fined over the mean field marginals q and derive their analytic gradient  X  L ( q ). Each of the loss functions is formulated in terms of a ground truth labeling T  X  X  N for an individual training image.
 Log-likelihood. The commonly used log-likelihood loss is defined as where w T i is a label-dependent weight that can nor-malize out imbalances in the available training data. The gradient of the log-likelihood loss is given by The log-likelihood objective does not cope well with outliers or mislabeled variables. For example, improv-ing the likelihood of a hopeless outlier from 10  X  5 10  X  4 reduces the loss more than improving the likeli-hood of a different data point from 1 10 to 1 2 . To ame-liorate this sensitivity to outliers, we can use a robust version of the log-likelihood.
 Robust log-likelihood. The robust log-likelihood loss is defined as This objective can be interpreted as a softmax of the log-likelihood loss with a threshold  X  log( ). In this formulation, the penalty incurred by outliers with ex-tremely low likelihoods is fixed. The gradient of the robust log likelihood objective is Hamming loss. The log-likelihood and robust log-likelihood objectives may not reflect performance mea-sures that can be relevant for particular computer vi-sion tasks. For example, for a per-pixel labeling task, we may want to maximize global labeling accuracy, class-average accuracy, or another measure of label-ing performance such as intersection over union. Our approach can incorporate such performance measures directly, by explicitly casting them as marginal-based loss objectives that should be optimized by the learn-ing algorithm.
 We first consider global and class-average accuracy. These can both be cast as weighted versions of the Hamming loss h ( x ) = P i w T i 1 [ x the number of incorrect labels in a label assignment x . For w l = 1, the Hamming loss corresponds to global labeling accuracy. Setting w l = 1 P class-average accuracy measure. We can also use a weighted geometric mean to interpolate between the two objectives.
 The Hamming loss is not continuous and is not imme-diately amenable to gradient-based optimization. We use the expected Hamming loss instead: where C = P i w T i is a constant. The corresponding gradient is given by Intersection over union. The intersection-over-union objective can be used to correct for imbalances in the training data. The discrete intersection-over-union score is defined as where n l = P i 1 [ T label l in the training data. The intersection-over-union score is evaluated over the complete dataset, which sets it apart from the preceding objectives. We formulate a relaxed marginal-based intersection-over-union loss: L iu ( q ) ties together all the marginals for all the images in the training set, not just a single image. Despite this global interdependence, the gradient is simple: In fact, once the intersection and union values i l and u are known the partial derivative of the intersection-over-union loss is independent for every variable X i . We build on the publicly available implementa-tion of Kr  X ahenb  X uhl and Koltun (2011). The orig-inal implementation uses normalized filter kernels  X  creases the accuracy of the approximate filtering, but it breaks the symmetry assumptions of the ferently. We use a symmetric normalization instead:  X  kernel is symmetric and positive definite while keeping the approximation error of the filtering data structure low.
 We evaluated the learning algorithm on the Pascal VOC 2010 dataset with the publicly available unary potentials and the training/validation/test split of Kr  X ahenb  X uhl and Koltun. All parameters are learned on the validation set. We use the non-linear conju-gate gradient algorithm for gradient-based optimiza-tion. We found that it performs better than L-BFGS for non-convex learning objectives.
 We use a class weight w l = n  X  0 . 25 l for all loss functions, where n l is the number of pixels with label l in the training set. To prevent overfitting, we use a weak L2 regularizer. All experiments are performed on a single core of a 3.2GHz Intel Core i7 CPU. 5.1. Inference We begin by comparing the performance of the con-vergent inference algorithm presented in Section 3.1, the faster convergent algorithm of Section 3.2, and the original inference algorithm of Kr  X ahenb  X uhl and Koltun. For this experiment we use a Potts model with a single Gaussian kernel with spatial standard devia-tion 40px, color standard deviation 15, and interaction penalty 5. This is consistent with the settings used by Kr  X ahenb  X uhl and Koltun on the Pascal VOC dataset. All inference algorithms were run for five iterations. The three algorithms produce almost identical results. The difference in the inferred marginal probabilities, averaged over all images, pixels and labels is less than 2  X  10  X  5 between each pair of algorithms. On average, for a given pair of algorithms, less than 0 . 013% of the pixels in an image have a different MAP assignment. On the other hand, the running times differ signifi-cantly. The convergent parallel mean field algorithm of Section 3.1 takes 2 . 49s per image, while the conver-gent approximate algorithm of Section 3.2 takes 0 . 69s on average, which is slightly faster than the algorithm of Kr  X ahenb  X uhl and Koltun (0 . 72s). 5.2. Learning We now evaluate the parameter learning algorithm. Label compatibility learning. In the first experi-ment, we focus on learning the label compatibility pa-rameters. An approximate MLE algorithm for learn-ing these parameters was described by Kr  X ahenb  X uhl and Koltun. We compare their approach to our algorithm using a single-kernel model. For this experiment, we trained the kernel parameters using grid search and kept them fixed, to match the setting of the prior work. Our algorithm converged in 20-30 iterations. The run-time of each iteration is equivalent to two inference passes over the dataset.
 The results are shown in Table 1. We observe signif-icant differences between the various objectives sup-ported by our algorithm. The straightforward log-likelihood loss is very sensitive to outliers: while the log-likelihood objective improved by several orders of magnitude during the optimization, this improvement is not reflected in the accuracy of the model. The ro-bust log-likelihood reduces this sensitivity and signif-icantly improves the results. It also outperforms the approximate MLE approach. Nevertheless, the log-likelihood in general does not correspond to the eval-uation metric by which performance on the dataset is measured. The Hamming loss and the intersection-over-union loss better model the evaluation metric and offer additional performance improvements.
 Kernel parameter learning. In the next experi-ment, we learn the kernel parameters, specifically the spatial and color standard deviations of the kernel. Kr  X ahenb  X uhl and Koltun (2011) used grid search to es-timate the kernel parameters and Vineet et al. (2012a) described a generative approach for this estimation task. To evaluate the different approaches, we train a Potts model with a single interaction penalty and five parameters for the Gaussian kernel: the standard deviations in the image coordinates and the color chan-nels.
 In evaluating grid search, we estimate only three parameters due to the exponential computational complexity of this approach: the Potts penalty, an isotropic spatial standard deviation, and an isotropic color deviation. (This mirrors the setup of Kr  X ahenb  X uhl and Koltun.) Both grid search and our algorithm are able to learn the kernel parameters jointly with the weight of the Potts model. They also take the unary terms into account during learning and find jointly optimal parameters. The generative approach learns the five kernel parameters independently; we then es-timate an optimal weight for the Potts model using grid search.
 The results are shown in Table 2. Our algorithm and grid search significantly outperform the generative learning framework. As further shown in the table, our algorithm is also able to learn the label compatibility parameters jointly with the kernel parameters, which increases the performance of the model by 2%.
 Full model. In the final experiment we learn the parameters of the unary potentials jointly with the parameters of the pairwise potentials. These include the logistic regression parameters in the unary poten-tials, the label compatibility parameters, and the ker-nel parameters. The total number of learned param-eters in the model is close to 700. To prevent overfit-ting, we use strong ridge regularization on the logistic regression parameters and on the off-diagonal entries of the label compatibility matrix. The accuracy of the learned model is 31 . 65% , which is a 1 . 5% increase over the model of Kr  X ahenb  X uhl and Koltun, a 4% increase over the unary potentials with a simple logistic regres-sion model, and almost 10% over the raw TextonBoost features. Note that we did not include any additional information, such as dense SiftFlow initialization or bounding box detection (Vineet et al., 2012a;b). We presented efficient convergent inference and learn-ing algorithms for dense random fields. The learn-ing algorithm jointly optimizes all parameters in the model and significantly outperforms alternative algo-rithms. Implementation of the presented algorithms will be made freely available.
 Philipp Kr  X ahenb  X uhl was supported by the Max Planck Center for Visual Computing and Communication. Blake, Andrew, Kohli, Pushmeet, and Rother,
Carsten. Markov Random Fields for Vision and Im-age Processing . MIT Press, 2011.
 Domke, Justin. Learning graphical model parameters with approximate marginal inference. PAMI , 2013. To appear.
 Eaton, Frederik and Ghahramani, Zoubin. Choosing a variable to clamp. JMLR , 5:145 X 152, 2009.
 He, Xuming, Zemel, Richard S., and Carreira-
Perpinan, Miguel A. Multiscale conditional random fields for image labeling. In CVPR , 2004.
 Kohli, Pushmeet, Ladick  X y, Lubor, and Torr, Philip
H. S. Robust higher order potentials for enforcing label consistency. IJCV , 82(3), 2009.
 Koller, Daphne and Friedman, Nir. Probabilistic Graphical Models: Principles and Techniques . MIT Press, 2009.
 Kr  X ahenb  X uhl, Philipp and Koltun, Vladlen. Efficient in-ference in fully connected CRFs with Gaussian edge potentials. In NIPS , 2011.
 Kulesza, Alex and Pereira, Fernando. Structured learning with approximate inference. In NIPS , 2007. Kumar, Sanjiv, August, Jonas, and Hebert, Mar-tial. Exploiting inference for approximate parameter learning in discriminative fields. In Energy Mini-mization Methods in Computer Vision and Pattern Recognition . 2005.
 LeCun, Yann, Chopra, Sumit, Hadsell, Raia, Ran-zato, Marc X  X urelio, and Huang, Fu Jie. A tutorial on energy-based learning. In Predicting Structured Data . MIT Press, 2006.
 Levin, Anat and Weiss, Yair. Learning to combine bottom-up and top-down segmentation. IJCV , 81: 105 X 118, 2009.
 Pal, Christopher J., Weinman, Jerod J., Tran, Lam C., and Scharstein, Daniel. On learning conditional ran-dom fields for stereo. IJCV , 99(3):319 X 337, 2012. Roth, Stefan and Black, Michael J. Fields of experts. IJCV , 82(2):205 X 229, 2009.
 Samuel, Kegan G. G. and Tappen, Marshall F.
Learning optimized MAP estimates in continuously-valued MRF models. In CVPR , 2009.
 Shotton, Jamie, Winn, John M., Rother, Carsten, and
Criminisi, Antonio. Textonboost for image under-standing. IJCV , 81(1), 2009.
 Sriperumbudur, Bharath K. and Lanckriet, Gert R. G.
On the convergence of the concave-convex proce-dure. In NIPS , 2009.
 Sutton, Charles A. and McCallum, Andrew. Piecewise training for undirected models. In UAI , 2005. Tappen, Marshall F. Utilizing variational optimization to learn Markov random fields. In CVPR , 2007. Tappen, Marshall F. Learning parameters in continuous-valued Markov random fields. In Markov Random Fields For Vision And Image Processing . MIT Press, 2011.
 Vineet, Vibhav, Warrell, Jonathan, Sturgess, Paul, and Torr, Philip H. S. Improved initialization and
Gaussian mixture pairwise terms for dense random fields with mean-field inference. In BMVC , 2012a. Vineet, Vibhav, Warrell, Jonathan, and Torr, Philip
H. S. Filter-based mean-field inference for random fields with higher-order terms and product label-spaces. In ECCV , 2012b.
 Vishwanathan, S. V. N., Schraudolph, Nicol N.,
Schmidt, Mark W., and Murphy, Kevin P. Accel-erated training of conditional random fields with stochastic gradient methods. In ICML , 2006.
 Wainwright, Martin J. Estimating the  X  X rong X  graph-ical model: Benefits in the computation-limited set-ting. JMLR , 7:1829 X 1859, 2006.
 Wainwright, Martin J. and Jordan, Michael I. Graphi-cal models, exponential families, and variational in-ference. Foundations and Trends in Machine Learn-ing , 1(1-2), 2008.
 Wainwright, Martin J., Jaakkola, Tommi S., and
Willsky, Alan S. Tree-reweighted belief propaga-tion algorithms and approximate ML estimation by pseudo-moment matching. In Proc. Workshop on Artificial Intelligence and Statistics , 2003. Yuille, Alan L. and Rangarajan, Anand. The concave-
