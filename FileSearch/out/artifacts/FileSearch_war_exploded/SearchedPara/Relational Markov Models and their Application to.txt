 Relational Markov models (RMMs) are a generalization of Markov models where states can be of different types, with each type de-scribed by a different set of variables. The domain of each variable can be hierarchically structured, and shrinkage is carried out over the cross product of these hierarchies. RMMs make effective learn-ing possible in domains with very large and heterogeneous state spaces, given only sparse data. We apply them to modeling the behavior of web site users, improving prediction in our PROTEUS architecture for personalizing web sites. We present experiments on an e-commerce and an academic web site showing that RMMs are substantially more accurate than alternative methods, and make good predictions even when applied to previously-unvisited parts of the site. Markov models, relational probabilistic models, Web mining, per-sonalization, shrinkage 
Markov models [27] are widely used to model sequential pro-cesses, and have achieved many practical successes in areas such as web log mining, computational biology, speech recognition, nat-ural language processing, robotics, and fault diagnosis. However, Markov models are quite limited as a representation language, be-cause their notion of state lacks the structure that exists in most real-world domains. A first-order Markov model contains a sin-gle variable, the state, and specifies the probability of each state and of transiting from one state to another. Hidden Markov models (HMMs) contain two variables: the (hidden) state and the observa-tion. In addition to the transition probabilities, HMMs specify the personal or classroom use is granted without fee provided that copies are permission and/or a fee. SIGKDD '02 Edmonton, Alberta, Canada Copyright 2002 ACM 1-58113-567-X/02/0007 ...$5.00. relation, with the state's variables corresponding to the arguments of the predicate. The domain of each argument can in turn have a hierarchical structure, over which shrinkage is carried out [19]. 
RMMs compute the probability of a transition as a function of the source and destination predicates and their arguments. RMMs are an example of a relational probabilistic representation, combining elements of probability and predicate calculus. Other representa-tions of this type include probabilistic relational models [10], prob-abilistic logic programs [21] and stochastic logic programs [20]. 
We expect RMMs to be particularly useful in applications that combine low-level and high-level information, such as plan recog-nition from low-level actions, or speech recognition aided by nat-ural language processing. An example of the former is infemng information-seeking goals of web site users from the sequence of links they follow. Doing this inference makes it possible to au-tomatically adapt web sites for different users, and as a result, to minimize users' effort in reaching their goals. RMMs are able to predict user behavior even in web sites (or parts thereof) that the user has never visited before, and are thus potentially much more broadly useful than previous approaches to web log mining, includ-ing traditional Markov models. In this paper we:  X  Precisely describe relational Markov models and how they extend traditional Markov models;  X  Apply RMMs to predict web navigation patterns;  X  Empirically compare a variety of RMMs with traditional 
Markov models, demonstrating that RMMs predict users' ac-tions more accurately. 
The next section describes representation, inference and learn-ing in RMMs. The following sections describe their application to adaptive web navigation, and the experimental results obtained. We conclude with a discussion of related and future work. 
Consider a discrete system that evolves by randomly moving from one state to another at each time step. A first-order Markov model is a model of such a system that assumes the probability distribution over the next state only depends on the current state (and not on previous ones). Let St be the system's state at time step t. Formally, a first-order Markov model is a triple (Q, A, 7r), where: Q = {qz,q2,... ,q,~} is a set of states; A is the transi-tion probability matrix, where alj = P(St = qj I St-t = q+) is the probability of transiting from state q~ to state qj, assumed the same for all t &gt; 0; and zr is the initial probability vector, where 7r~ = P(So = q~) is the probability that the initial state is q~. 
Given a first-order Markov model, the probability of observing a se-quence of states (so, st,..., ST) is P(So =so, St =st .... , ST = = P(So = so) ~tT=t P(St = st I St-I = St-l). Given a set of observed sequences, the maximum-likelihood estimate of an initial probability ~r~ is the fraction of sequences that start in state q~, and the maximum-likelihood estimate of a transition probability a~j is the fraction of visits to q+ that are immediately followed by a transition to q~. In an nth order Markov model, the probability of transiting to a given state depends on the n previous states, and the transition matrix is (n + 1)th-dimensional. We refer to Markov models of any order defined in this way as propositional Markov 
Relational Markov models (RMMs) are obtained from the propo-sitional variety by imposing a relational structure on the set of states. For example, consider a Markov model of an e-commerce 
Web site, in which each page is a state. A PMM would have a Product  X  ..ram m~,, 
Figure 3: Abstraction hierarchy of products. Leaves in the tree represent ground values, while internal nodes denote categories of related values. 
Formally, an RMM is a five-tuple (79, 7~, Q, A, 7r). :D is a set of domains, where each domain, D E 79, is a tree representing an abstraction hierarchy of values. Each leaf of D represents a ground value. R is a set of relations, such that each argument of each relation takes values from the nodes of a single domain in D. Q is a set of states, each of which is a ground instance of one of the relations in T~, i.e., where each argument is instantiated with a leaf of the corresponding domain. A (the transition probability matrix) and rr (the imtial probability vector) are the same as in a PMM. To continue our simplified e-commerce example, suppose that 79 contains abstraction hierarchies for Products and StockLevels as shown in Figure 3. R is the set {MainEntryPage0, ProductPage(Product,StockLevel) CheckoutPage0}, where 
ProductPage(Product,StockLevel) specifies that the first and second arguments of the ProductPage relation must come from the Product and StockLevel domains, respectively. Q consists of several states, one of which is ProductPage(iMac, in_stock). We now show how to use the relations and domain abstraction hierarchies to define sets of states as abstractions over Q. These ab-stractions are distinguished sets of states whose members are sim-ilar to each other by virtue of their relations and parameter values. 
That is, states whose parameter values are in common subtrees of their respective domains will appear in many abstractions together, while states with very different parameter values (or belonging to different relations) will appear together in only the most general abstractions. We define these abstraction sets by instantiating a relation, R, with interior nodes (instead of just leaf nodes) from the domains of R's arguments. More formally, Let nodes(D) denote the nodes of a domain D. If d is a node in domain D, then let leaves(d) denote the leaves of D that are descendants of d. Let R E 7~ be a in the corresponding domains. We define the state abstraction cor-responding to R(dl,..., dk) to be the following subset of Q. For example, given the domain trees shown earlier, Fig-ure 4 shows several abstractions for the e-commerce RMM. 
Note that the abstraction ProductPago(AIIProducts,in_stock) is the set of two ground states: {ProductPage(iMac,in_stock), 
In PMMs, the only possible learning consists of estimating the transition probabilities alj and initial probabilities Iri, and these estimates can be done reliably only for states that occur frequently in the training data. In many cases (e.g., when modeling a user of a large Web site), most states are not observed in the training data, but it is still possible to generalize usefully from the observed behavior to unseen states. RMMs provide a formal framework for doing this generalization. 
For each possible state abstraction a, we can define the corre-sponding initial probability 7r~ as the probability that the initial state is an element of a: Ir,~ = ~q~ 7rl. Similarly, for each pair of state abstractions (a,/3) we can define the corresponding tran-sition probability a~,~ as the probability of transiting from a state in a to any state in/3: a,~,a = ~q~ P(qila) ~qjE,O alj, where P(q~[a) is the probability that the current state is q~ given that the current state is a member of ~. The abstraction transition probabil-ities a~,a can be estimated directly from the training data by count-ing. By making suitable simplifying assumptions, they can then be used to estimate the probabilities of transitions that are absent from the data. For example, if we assume that the destination state qd is independent of the source state q~ given the destination abstraction /3, then a~d = a~,~P(qdl/3), where a is the source abstraction. P(qd[/3) can be estimated as uniform: P(qd[/3) = 1/I/31, where [/31 is the number of states in abstraction/3. To make maximum use of all the available information, we propose to use a mixture model for each transition probability: where the sum is over all abstractions of the source and destination states, and the X~,~'s are non-negative mixing coeJficients that sum to 1. The generative model implicit in Equation 1 is that, to gener-ate a transition, we first choose a pair of abstraction levels (a,/3) with probability X~,~, and then move to destination state qd with probability a~,~P(qd[/3). Effectively, this model performs shrink-age between the estimates at all levels of abstraction. Shrinkage is a statistical technique for reducing the variance of an estimate by averaging it with estimates for larger populations that include the target one [19]. Equation 1 applies shrinkage across an entire abstraction lattice, rather than over a single abstraction path (as is more usual). For example, a forecast of the number of Apple iMacs sold at a given store can be shrunk toward a more reliable forecast for the average of this quantity at all stores in the same city as the store of interest. The comparative values for the X~,z's effectively trade offbias and variance in the probability estimate. Terms corre-sponding to more general abstractions have lower variance, because they are estimated with more training data, but have a larger bias than terms from more specific abstractions. Thus, good shrinkage weights have two desirable properties: (1) they reduce the influence of abstractions with very little data; and (2) they allow increasingly specific abstractions to dominate as the training set size grows, with the RMM reducing to a PMM in the infinite-data limit. The mix-ing coefficients X~,~ can be estimated in a number of ways, corre-sponding to different variations of our system: 
ProductPage. Rounded-comer boxes represent tree nodes. The path the page ProduetPage(iMae, in_stock) follows is high-lighted. Each node has an associated distribution over the desti-nation relations; these are shown for the highlighted nodes. Each node along this path selects a set of (a,/3) abstraction pairs that are combined according to Equation 1. The a abstraction for a node is derived from the decisions made along the sub-path from the root to that node, and the/3 abstractions are the abstractions the PET is predicting (the destination relation in this example). coefficients computed using any of the methods described above. 
In this paper, we choose these weights using EM; by predicting the destination relation, and not more specific abstractions, there is suf-ficient data to perform EM reliably. In our experiments, we call this variant RMM-PET. ing transitions to a different partition of the states; thus, the source state would follow multiple paths, one in each PET. For example, one PET would predict the destination relation, another would pre-dict the destination at a lower level of abstraction (for instance, the relation and one variable's ground value), etc. The terms collected from all the PETs would then be combined according to Equation 1. fraction of the states are directly reachable from a given state. For example, on a Web site only the pages that the ctwrent page links to are directly reachable from it. In this case, the P(qal~) terms in Equation 1 can be replaced by terms that also condition on the knowledge of the set of states C(s) that are directly reachable from qs. For states that are not reachable from qs, P(qal/3,C(s)) = O. 
For states that are reachable from qa, under the previous assumption of uniform probability, P(qalfl, C(s)) = 1/IC(s) l. used to predict the destination state as a function of properties of the source state. The approach proposed here implicitly encodes the 
As we demonstrate in the next section, RMMs effectively ad-
In this section, we address the following questions: (1) Is our 
To answer these questions we selected three sets of log 
For both sites we collected clickstream data and the list of links 
Generating good relational structure at each site was straight-
Figure 7: KDDCup 2000 data (wmc.g'azeZle. X tm). The z-axis shows the number of training instances scaled logarithmically, and the y-axis is the average negative log-likelihood of a test exam-ple. Curves are based on 2000 test instances. RMMs outperform 
PMMs with ~ few as ten training examples. pages even existed at the time that the training data was collected. 
As a result, the PMM can do nothing better than predict a uniform distribution over the links on each page. In contrast, an RMM takes advantage of the related common relational structure of the training and test data to significantly improve prediction (see Figure 8). 
The computation time required for the RMM variants is not sub-stantially more than that for PMMs. The RMM variants require some preprocessing of the data, to build the abstraction sets, but this work can be done at learning time, independent of the test set. In this third experiment, for example, preprocessing the site (containing 3,749 pages)for RMM-rank and RMM-uniform took four minutes (our RMM code is implemented in C++ and the ex-periments were run on an 850MHz Pentium III) 2. Inference in a 
PMM for a test example requires only a single ratio of counts, while a more complex set of counts must be shrunk together in the RMM variants. However, we found that, on average, RMM-rank, RMM-uniform, and the PMM method all required the same amount of time (about 430 milliseconds) per example for inference. 
The added cost of the RMM is hidden largely because the work for one test instance may be cached and applied to another (e.g., two instances with a common source state). RMM-PET requires a dif-terent preprocessing (to learn the PET) which took 76 seconds and completed the prediction runs in 1960 milliseconds. 
Finally, we have combined RMMs with our MINPATI-I algorithm to evaluate their use for adaptive web navigation. In preliminary testing we compared three models: RMM-uniform, RMM-rank, and a PMM. We found that the RMMs performed significantly bet-ter than the PMM, allowing MINPATH to save users more links--often 50% to 80% more links than with the PMM, particularly when training data was sparse. In future work we will more ex-haustively compare the RMM variants and PMMs as used in MIN-PATH. 
In summary, we conclude that RMMs significantly outperform 2Our implementation calculates the non-leaf abstraction transition probabilities directly from the data, and not from lower-level ab-stractions as we suggested in Section 2.3. Thus, our computation could be improved substantially. wards into the page adds relational information --a set of predi-cates and a domain of variables for each argument. 
Viewed in this context, the connection between RMMs and other first-order probabilistic representations becomes clearer. Friedman et al. [10] extended the notion of Bayesian network to propose probabilistic relational models (PRMs). Objects in a PRM are di-vided into a set of classes, and a different probabilistic model is built for each class, specifying how its attributes depend on each other and on attributes of related classes. Dynamic Bayesian net-works (DBNs) [6, 7, 29] form a probabilistic dependency graph for uncertain temporal reasoning. A DBN has a separate Bayesian net-work for each time step, in which the values of variables for time t can depend on the values of variables in previous time slices. Thus, DBNs "improve" on RMMs in their use of explicit conditional in-dependences amongst a set of variables, but in contrast to an RMM every state in a DBN is treated the same way D it has the same variables and dependencies. To our knowledge, RMMs are the first probabilistic first-order model of sequential processes to be pro-posed. However, it is interesting to note that dynamic Bayesian networks can be viewed as a special form of PRM where there is only one class (the state) and the only relation is the sequential or-der between successive states. PRMs have been extended to allow the class to be chosen from a hierarchy [12]. RMMs allow hierar-chies over the attributes in each class, and combining models at all levels using shrinkage. This approach should be useful in PRMs also. One obvious area for future work is to combine ideas from RMMs, DBNs, and PRMs to define "Dynamic probabilistic rela-tional models" (DPRMs). 
Hidden Markov models have been extended in a number of ways to accommodate richer state and observation information. For ex-ample, factorial hidden Markov models [13] decompose model states into k components, described by k state variables, that de-pend on each other only via the observation variable. A factorial hidden Markov model can be viewed as a form of RMM with hid-den state, in which all states belong to the same k-ary relation, but which has a conditional independence assumption that state vari-ables in subsequent states depend only on the corresponding vari-ables in the previous state. An area of future work is in explonng how these conditional independences can be leveraged by relational Markov models. Other extensions of HMMs have been proposed (e.g., Lafferty et al. [17]). It should be possible to subsume these within our framework; this is a matter for future research. RMMs are also related to work on abstraction in reinforcement learning (e.g., Dietterich [8], Dzeroski et al. [9]), and may be useful in that field. 
Since Perkowitz and Etzioni challenged the research community to build adaptive web sites [24], many projects have addressed com-ponents of this task. In this section we highlight the subset of work related specifically to adaptive web navigation. 
Our MINPATH system [2] processes server access logs offline in order to learn a model of web navigation patterns (similar to how WebCANVAS [4] builds visitor clusters for visualization). At run-time MINPATH combines the probabilistic estimates from this model with distance information to compute expected savings of shortcuts, adding the links it deems most useful. In our earlier work, we evaluated a variety of visitor models, including Naive Bayes mixture models and mixtures of Markov models, conclud-ing that a mixture of Markov models performed best for the task. In this paper, we argue that RMMs can perform substantially better for this same task. 
Perkowitz and Etzioni [25] also address the shortcut problem, ology. This paper makes the following contributions:  X  We provide a precise definition of relational Markov models  X  We explain how RMMs can be used for adaptive web nav- X  We compare several variations of RMMs and found that us-
Our experiments have shown that relational Markov models are a suitable alternative to traditional Markov models--RMMs infre-quently perform worse, and can perform much better. When data about all states is available in quantity, or if the relations between states are not reflected in the distribution of the data, RMMs offer no advantage relative to traditional Markov models, and, in fact, could perform worse than PMMs. However, when data is scarce or non-existent about some states, but abundant for conceptually sim-ilar states (based on relational abstractions of the states), relational 
Markov models significantly outperform traditional Markov mod-els. Intuition suggests that this latter case holds true for the vast majority of web sites, and that RMMs should prove widely useful. 
In future research we plan to both extend relational Markov mod-els and explore additional applications. An immediate area to pur-sue is in further developing the RMM-PET approach, by building PETs to predict finer partitions among the destination abstractions. 
An interesting evolution of RMMs is to relational hidden Markov models, where both the states and the observations are described by typed relations and shrinkage is carried out over their respec-tive abstractions. Another direction is incorporating a model clus-ter identity into the transition probability, such as the identity of a cluster of visitors at a web site, and shrinking between many mod-els learned for different sizes and scope of user cluster (such as a site). A third path of research is to apply RMMs to other domains, such as mobile robot localization or speech recognition. The authors thank Cathy Anderson, AnHai Doan, Oren Etzioni, 
Geoff Hulten, Zack Ives, Cody Kwok for their insightful comments on this work, and to Blue Martini for providing the gaze 11 e. corn data. This work was funded in part by NSF grants #IIS-9872128 and #IIS-9874759, an NSF CAREER and IBM Faculty awards to the second author, and a gift from the Ford Motor Company. [I] R. Agrawal, T. Imielinski, and A. Swami. Mining [2] C. R. Anderson, P. Domingos, and D. S. Weld. Adaptive web [3] C. R. Anderson, P. Domingos, and D. S. Weld. Personalizing [4] I. V. Cadez, D. Heckerman, C. Meek, P. Smyth, and [21] L. Ngo and P. Haddawy. Answering queries from [22] M. Pazzani, J. Muramatsu, and D. Billsus. Syskill &amp; Webert: [23] M. J. Pazzani and D. Billsus. Adaptive web site agents. In 
Autonomous Agents, 1999. [24] M. Perkowitz and O. Etzioni. Adaptive web sites: an AI [25] M. Perkowitz and O. Etzioni. Towards adaptive web sites: Conceptual framework and case study. Artificial Intelligence 
Journal, 118(1-2), 2000. [26] E Provost and R Domingos. Tree induction for probability-based ranking. Machine Learning. To appear. [27] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77:257-286, 1989. [28] R. R. Sarukkai. Link prediction and path analysis using Markov'chains. In Proceedings of the Ninth International [29] P. Smyth. Clustering sequences with hidden Markov models. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, 
Advances in Neural Information Processing 9, 1996. [30] P. Smyth, D. Heckerman, and M. I. Jordan. Probabilistic independence networks for hidden Markov probability models. Neural Computation, 9:227-269, 1997. APPENDIX The relations for www. gazelle, com take up to three param-eters: Assortment, Product, and Collection. The domain hierar-chies for these parameters are described explicitly in the KDDCup 2000 data.  X  Home()  X  Boutique()  X  Departments() 
Legcare_vendorO  X  Lifestyles()  X  Vendor() 
AssortmentDefaultO  X  Assortment(Assortment) 
ProductDetailLegcareDefaultO  X  ProductDetailLegcare(Product) 
ProductDetailLegwearDefault0  X  ProductDetailLegwearProduct(Product) 
ProductDetailLegwearAssortment(Assortment)  X  ProductDetaULegwearProdCollect(Product, Collection)  X  ProductDetailLegwearProdAssort(Product, Assortment)  X  ProductDetailLegwear(Product, Collection, Assortment) 
