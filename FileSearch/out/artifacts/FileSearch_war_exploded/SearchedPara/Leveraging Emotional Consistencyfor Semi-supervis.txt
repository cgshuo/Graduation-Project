 With the explosion of Web 2.0 services, popular social media mediums like Twit-ter enable user to easily express and share their own opinion on various kinds of topics [ 16 ]. These opinions often serve as helpful advice and influence fol-lowing users X  decision making. For instance, when a customer wants to buy a laptop on Amazon he/she will usually looks for reviews and comments written by previous customers [ 13 ]. Sentiment analysis can also provide organizations or company with the ability to listen customer X  X  voice on social media forums in timely manner and act instantly. As such, advertisers, companies and politicians are seeking ways to make sense user X  X  sentiments through social media on their product, service and policy quality. Sentiment analysis for social media platforms like Twitter and MySpace poses been extensively investigated for user reviews [ 12 , 13 ] with good performance. However, the social text data in blog posts is different substantially from the traditional product review data. The social text data often contains short and noisy messages [ 1 ]. It also contains lots of emotional abbreviations, emoticons and has no syntactic structure. Because of highly discourse variations, sentiment data in social media often lacks of sufficient labeled data. Thus, it is not easy to automatically identify the sentiment meanings of these messages, though it can be understood conveniently in human communications.
 Besides textual content, social media platforms often provide additional infor-mation about user-user relationships in online social networks. In particular, rela-tions between messages can be represented via a matrix of between users and messages and a matrix of between user interactions. Blog messages is potentially networked through user connections. This is a distinct feature because it may contain useful structural or community information that are not able to explore from purely text-based methods for sentiment analysis. Social networks is useful for two reasons. Firstly, social relation graph information is now more easily to obtain in social media platforms X  API. Secondly, according to the principle of homophily [ 11 , 17 ], if two users hold a personal relationship, they may be tend to hold the same opinions about some affairs.
 However, these popular sentiment analysis methods require sufficient texts labeled with polarity, thereby, not suitable for social media data. Currently, there are two ways to overcome this issue. The first way is supervised method [ 14 ] to model message similarity by exploiting user relationship. The second way is reducing the dependence on labeled texts by using either distant supervision on noisy labels [ 9 ] or semi-supervised label propagation on unlabeled tweets upon social relations [ 24 ]. To the best of our awareness, there has been no effort on bringing together several of the above ideas for social media sentiment analysis. This paper proposes a semi-supervised approach for sentiment analysis in social media by leverage emotional consistency on label information obtained by label propagation and distant supervision. In particular, it takes the advantage of label propagation based on both textual and social relation information and the emotional consistency of propagated labels and distant supervision labels in tackling the insufficient labels issue and noisy nature of the tweets. We propose a unified three-phase framework for semi-supervised sentiment classification. Our framework leverages on both labeled, unlabeled tweets, social graph and sen-timent lexicons. First, we use label propagation to learn propagated labels for unlabeled tweets and partition all tweets into different clusters. Second, we train a distant supervision classifier based on sentiment lexicon resources. We also train a linear classification model based on training dataset. Next, we determine the relevance of each classifier to the unlabeled tweet, using the label consistency between the clustering given by the propagated tweet labels and the clustering given by these trained sentiment classifiers. Third, we train the final classifier by trading-off between using relevance-weighted trained classifiers and the labeled tweet data. Finally, we conduct empirical experiments to evaluate the effective-ness of the proposed model. We compare the proposed three-phase framework with state-of-the-art classification baselines for the sentiment analysis task, and we find that our method outperforms the baselines. Sentiment analysis has been studied extensively on various kinds of text data such as movie and product reviews [ 12 , 21 ]. The basic method is to build a hand-crafted sentiment features, which can effectively express the sentiment of the texts, and apply machine learning. With the growing popularity of social media recently, sentiment analysis for user generated contents has attracted lots of attention from researchers [ 2 , 4 ].
 ging and make use of the social relation information of micro-blogging [ 4 ]. Similar to traditional methods, there are some ongoing efforts on sentiment analysis for the micro-blogging data. Alec et al. [ 9 ] used distant supervision with noisy labels obtained from emoticons for Twitter sentiment analysis. Barbosa and Feng [ 2 ] analyze the linguistically features of tweets as well as the meta-data informa-tion of words for Twitter sentiment. However, the above two methods have not exploited the social relation information.
 pre-defined sentiment lexicons or vocabularies [ 15 , 18 ], which are highly domain-dependent. Standard supervised classification methods improve the situation somewhat [ 20 , 21 ], by training a text similarity model purely based on the con-tent. However, these require sufficient text labeled with polarity. To overcome this issue, some efforts have been made to explore other external information such as emoticons [ 9 ] and especially social relation information [ 10 , 27 ], on sentiment analysis. Distant supervision [ 9 ] based on noisy labels can reduce dependence on labeled texts with promising performance. In addition, label propagation [ 24 ]is develop to prorogate sentiment of labeled tweets to unlabeled tweets upon social relations. In [ 14 ], a supervised method based on l 1 -norm least squares and Lapla-cian graph regularization have also been proposed to model message similarity by exploiting user relationship. The basis idea of above two algorithms is deter-mining the sentiment of a tweet posted by a user based on both of sentiments of its tweets and its neighbor X  X  tweets collectively upon social relation graph. by incorporating both of textual and social graph. It leverages the unlabeled data as compared with [ 14 ]. It goes beyond than merely use noisy labels [ 9 ]by considering the relevancy. Given a corpus D = { t 1 ,t 2 , ..., t n } of n tweets. Let sentiment lexicon resources, where each of them is a list of sentiment words corresponding to their sentiment polarity, e.g., positive a feature extraction  X  that maps a tweet t to its feature vector x .Foreach message in the corpus t i  X  D , t i =( x i ,y i )  X  R m + c corresponding sentiment label, where x i  X  R m is the tweet feature vector and y  X  R c is the sentiment label vector. The sentiment dataset has a some labeled data D l = { ( x i ,y i ) } n l i =1 and plenty of unlabeled data D n is the number of labeled instances, n u is the number of unlabeled instances, x is the feature vector, y i is the corresponding label (if available). Let n = n D =[ X, Y ], where X  X  R n  X  m is the feature matrix, Y  X  R matrix, m is the number of tweet features, n is the number of tweets and c is number of sentiment labels. Let u = { u 1 ,u 2 , ..., u d R n be a user-tweet matrix, where U ij = 1 denotes that tweet t user u i .Let F  X  R d  X  d be the user-user matrix, where F u is connected by user u j .
 Learning a sentiment classifier can then be abstracted to finding a function p such that p (  X  ( t )) = p ( x )= y . We define the problem media as : Given a corpus of tweets D = D labels Y as well as the user-tweet relation U and user-user relation F, it aims to learn a sentiment classifier p (  X  ( t )) = p ( x )= y polarity for new tweets t. In this section, we describe our three-phase approach, which comprises of a label propagation, emotional clustering consistency and combined classifier learning phases.
 Our key idea is to exploit the concept of emotional consistency information obtained by label propagation and distant supervision. The propa-gated labels are obtained by spectral-based label propagation. The distant super-vision labels are obtained by a sentiment classifier trained based on lexicon-based unsupervised sentiment predictions, also known as noisy labels main challenges in our approach. Firstly, it is not easy to effectively propagate labels to unlabeled data based on both of textual content and social relation graph. Secondly, how to effectively leverage the sentiment prediction perfor-mance based on the distant supervision labels, a.k.a noisy labels ground-truth labels and noisy labels come from the same dataset, they proba-bly have different marginal distributions on the sentiment classess. If we merely combine ground-truth labels and noisy labels to train a sentiment classifier, this can produce a negative transfer phenomenon [ 22 ], where using knowledge from noisy labels degrades the performance on the ground-truth labels.
 To tackle these challenges, we propose a three-phase Robust Semi-supervised Sentiment Propagation (RSSP) framework. Our method is inspired by [ 8 ]for multi-class case. In the first phase, based on the social graph and textual con-tent, we use label propagation to learn noisy labels for unlabeled tweets and partition all tweets into different regions. In the second phase, we train two different sentiment classifiers: one linear classifier based on ground-truth labels and one distant supervision classifier based on noisy labels. Next, we determine the relevance of each classifier to a region, using the label consistency between the clustering given by the propagated labels and the clustering given by these trained classifiers. By using unlabeled data, we alleviate the lack of labeled sam-ples for rarer classes due to imbalanced distributions in labels.
 a reference predictor by weighing the pre-trained classifiers for each unlabeled sample separately. The intention is to alleviate the effect of mismatched distri-butions. The final classifier in the unlabeled data is trained on the labeled data while taking reference from the reference predictions on the unlabeled data. This ensures reasonable predictive performance even when all the noisy labels are irrelevant and augments the rarer classes with examples in the unlabeled data. 4.1 Phase 1: Label Propagation To apply this idea to sentiment classification, we need to (i) partition the entire data input space into clusters/regions and (ii) assign preliminary labels for all the examples. We approximate the our data input space with all the samples from D l and D u . With data from both the labeled and unlabeled data sets, we apply transductive inference or semi-supervised learning [ 28 ] to achieve both (i) and (ii). By augmenting with unlabeled data D u , we aim to alleviate the effect of imbalanced relation distribution, which causes a lack of labeled samples for rarer classes in a small set of labeled data. Briefly, the known labels in D propagated to the entire target input space by encouraging label smoothness in neighborhoods. The next three paragraphs give more details.
 between the i th and the j th input samples in D l  X  D u . Matrix W then determines the neighborhoods and is defined as follows: contents of t i and t j . Here, the similarity matrix W Sim K ( x, x ) = exp( x  X  x 2 / 2  X  2 ), which is based on textual features. W U W connected friends in the social graph. Let  X  be a diagonal matrix where the ( i, i )th entry is the sum of the i th row of W . Let us also encode the labeled data D l in an n -by-c matrix H , such that H ij = 1 if instance i is labeled with sentiment class j in D l ,and H ij = 0 otherwise. Our objective is the c -dimensional sentiment-class indicator vector F i for the i th instance, for every sample. This is achieved via a regularization framework [ 28 ]: This trades off two criteria: the first term encourages nearby samples (under distance metric W ) to have the same labels, while the second encourages samples to take their labels from the labeled data. The closed-form solution is where L = X   X  1 / 2 W  X   X  1 / 2 ; and the n -by-c matrix F F s.
 Using vector F  X  i , we now assign preliminary labels to the samples. For a sample i , we transform F  X  i into probabilities p 1 i ,p propagated label i for sample i is then Next, we partition the data in D l  X  D u into c regions, R sponding to the c sentiment class labels. The intuition is to use the true label in D when available, or otherwise resort to using the propagated label. That is, 4.2 Phase 2: Emotional Clustering Consistency [ 19 , 26 ] to build three different sentiment predictors base three different lexicons resources. The three sentiment lexicon resources include: (1) MPQA Opinion Corpus 1 for daily sentiment words; (2) Twitter sentiment words ular Twitter emoticons 3 . Due to this unsupervised setting, logistic regression classifier will be used for tweets, which does not have any sentiment words. We then combine these three sentiment predictors to a final unsupervised predictor based on majority voting, which outputs noisy labels for unlabeled tweets. Using both ground-truth and noisy labels, we train a distant supervision classifier [ 9 ]. We also train a logistic regression classifier based on label data. We use the concept of clustering consistency to determine the relevance of a trained classifier to particular regions in the unlabeled input space. Figure 1 illustrates this. There, both enclosing circles in the left and right figures denote the same input space of the target domain. There are four disjoint regions within the input space, located at the left, right, top and bottom of the space. There are two classes of labels: asterisk (  X  ) for positive sentiment and circle ( negative sentiment.
 The labels in the left figure are given by a preliminary predictor data using label propagation, while the labels in the right figure are given by a predictor trained on the noisy labeled data. Comparing the figures, we see the preliminary predictor and noisy labeled predictor are consistent for the bottom and right regions, but are inconsistent for the top and left regions. This suggests that the predictor trained on noisy labels is very relevant for the bottom and right regions of the target input space, but less so for the top and left regions. a region in the original input space. Intuitively, this is the agreement between the trained predictor and the preliminary predictor within the original input space. We use supervised weighting in the following manner. Let D { we first train a sentiment predictor p s based on its training data D every region R j , we compute the relevance score as: where [[  X  ]] is the Iverson bracket.
 train classifier with the regions in original input space of OMD corpus. We observe, for example, that the classifier trained on noisy labels ( D more relevant in the R 1 region than R 2 region of the original input space. These relevance scores will be used in the next phase of the framework to weigh the contributions of each predictor to the eventual classifier. 4.3 Phase 3: Target Classifier Learning This phase uses both of the previous predictions from all trained classifiers and the labeled data D l to learn a sentiment classifier. This ensures that the perfor-mance of proposed method will not degrade badly even when most of the source instances are irrelevant, The previous phase has computed the relevance w s,j for trained classifier p in region R j . We translate this to the relevance weight u ple x i :if x i 2 sentiment predictors p s that have been trained on D weight the predictions from multiple classifiers to obtain the  X  r = 2 s =1 u s,i (2[[ p s ( x i )= j ]]  X  1) for example x i j , using the  X  1 encoding.
 The sentiment classifier consists of c functions f 1 ,...,f rest decoding for multi-class classification. 4 Based on the Domain Adaptive Machine [ 6 ], we incorporate the reference predictions and the labeled data of the target domain to learn the final classifier: min where r ji =2[[ y i = j ]]  X  1isthe  X  1 binary encoding for the i labeled sample belonging to relation j . Here, we have three objectives: the first term specifies the training error; the second governs the complexity of the functions f Reproducing Kernel Hilbert Space (RKHS) H ; and the third favors the predicted labels of the unlabeled data D l to be close to the reference predictions. The third term provides additional pseudo-training samples for the rarer sentiment classes, if these are available in D u . Parameters  X  and  X  govern the trade-offs between these objectives.
 Let K (  X  ,  X  ) be the reproducing kernel for H . By the Representer Theorem [ 23 ], the solution for Eq. 5 is linear in K ( x i ,  X  ): f j ( x )= into Eq. 5 , parameter vectors  X  j are [ 3 ]: Here, R j is an ( n l + n u )-vector, where R ji = r ji if instance i is in the labeled set, and R ji = X  r ij if it is in the unlabeled set; and J is an ( n diagonal matrix where the first n l diagonal entries are ones and the rest are 5.1 Experimental Settings We evaluate our algorithm using two corpora: the Stanford Twitter Sentiment (STS) and the Obama-McCain Debate (OMD). Table 1 provides some statistics on them.
 original purpose, it does not have social relation graph information among users. To overcome this, we obtain the social graph by using the Twitter complete graph crawled by Kwak et al. [ 16 ]. After that, we exclude tweets that its author has no friend or has less than two tweets. Finally, we got a dataset consists of 22,262 tweets with labels.
 during the presidential debate [ 24 ]. Similar as in STS dataset, we also obtain the social relation graph for this dataset by exploiting the Twitter complete follower graph [ 16 ]. Next, we also filter out tweets as with the STS datasets. Finally, we got a dataset of 1,827 tweets with labels.
 learning and common sentiment analysis methods. These are described below. Support Vector Machine (SVM) [ 5 ] is a typical text classification method. Logistic Regression with l 1 -norm regularization (LG) [ 7 ] is also a tradi-Distant Supervision (DS) is a semi-supervised learning algorithm that makes Label Propagation (LPROP) [ 24 ] is a semi-supervised graph regularization Linear Regression with graph regularization (SANT) [ 14 ]isasupervised RSSP-LP is a simple version of our approach, which combines ground-truth baselines according to published articles. In our experiments, we set  X  =0 . 8in Eq. 2 ;  X  =0 . 18 in Eq. 3 ;and  X  =0 . 1and  X  =0 . 3inEq. 5 . We use five-fold cross validation. 5.2 Experimental Results Figure 3 presents the sentiment classification accuracy results on STS and OMD datasets. We see that the proposed RSSP method has consistently outperformed the other methods on accuracy. We also observe that although the noisy labels learnt from RSSP are helpful on sentiment task, using only noisy labels to train a classifier (DS) marginally increases the accuracy as compared with supervised ground-truth methods like SVM and LG. This suggests that there would be negative effects from the noisy labels. More importantly, we also see that RSSP-LP, which exploits both text and social graph information, can also only gain a marginal accuracy improvement as compared with LPROP and SANT. This emphasizes the effectiveness of Phase 2 and 3 of RSSP, which considers the relevance of each trained classifier to each unlabeled sample before training the final classifier. As a result, RSSP outperforms the best SANT method by 5.5 % on average.
 Weakly-Supervised Setting: We conduct experiments to verify the sensitivity of RSSP according to different training data sizes. We cross validate our model with five-folds. in the Table 2 (a) and (b), D percentage of data used for training out of the entire training dataset. Due to five-fold cross validation, 80 % of the entire dataset is used for training in each round of the experiment. For instance, OMD 50 % indicates that 50 % of 80 % thus 40 % of the whole dataset as training data. The test set always occupies 20 % of the entire dataset.
 From Table 2 (a) and (b), we find that our method has consistently outper-formed all the other methods on accuracy peformance. We first notice that DS generally perform quite well, and it performs better than SVM and LG espe-cially when the number of labeled instances is small. However, the training size increases, the performance gap becomes smaller. The reason is that DS aims to obtain a consensus on the entire dataset, and this will give a worse label than SVM and LG when there are enough irrelevant and noisy labeled sam-ples to influence the classification decision wrongly. There is another side effect of noisy propagated labels based on both textual and social graph information under small training set situation. In fact, one can roughly deduce that a RSSP classifier has few relevant noisy propagated labels by simply comparing rows LPROP with rows RSSP-LP in the tables: a decrease in accuracy from LPROP to RSSP-LP suggests that the noisy labels are somewhat irrelevant. For exam-ple, for datasets STS 10 % , STS 30 % , OMD 10 % and OMD 30 % accuracy decreases from LPROP and RSSP-LP in Table 2 (a), (b) when there are only few labeled samples, which suggests that noisy labels from STS STS 30 % , OMD 10 % and OMD 30 % are generally irrelevant to train a classifier. We investigate this further by examining the relevance scores w that the decreases in accuracy from LPROP and RSSP-LP happen when there are more regions in the original input space to which noisy labels learnt by RSSP-LP are irrelevant.
 We also observe that label propagation methods such as LPROP and RSSP-LP are generally better than distant supervision method DS. However, we find that the performances of RSSP-LP is not quite stable: for example, on STS STS 30 % , OMD 10 % and OMD 30 % datasets. In contrast, we find the performance of LPROP and SANT to be more stable. The reason is their reduced vulnerability to negative effect from irrelevant noisy labels by relying on similarity of feature vectors based on labeled, unlabeled data and social graph information. Further improvements can still be made, as shown by the better performance of RSSP over LPROP and SANT. This is achieved by further adjusting the relevances between a trained classifier and a sample according to its region in the original input space. We have developed a robust semi-supervised sentiment propagation (RSSP) app-roach for the social media sentiment analysis problem where labeled data is scarce and information about social relations is available. Existing sentiment analysis approaches suffer from lacking of labeled data and under imbalanced distributions with noisy labels. To overcome these, we have proposed a three-phase approach to leverage only relevant information from the noisy labels, and thus leverage accuracy performance on the unlabeled data. Experimental results on OMD and STS have shown that the our semi-supervised method outperforms the other methods on accuracy performance when only few labeled instances are used. Because of the practical importance of sentiment analysis on social media data due to lack of labeled data in these domains, we hope our research will open up several investigations in the future.

