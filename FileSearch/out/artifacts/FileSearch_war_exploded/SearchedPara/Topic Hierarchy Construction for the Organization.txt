 User generated contents (UGCs) carry a huge amount of high quality information. However, the information overload and diversity of UGC sources limit their potential uses. In this research, we propose a framework to organize informa-tion from multiple UGC sources by a topic hierarchy which is automatically generated and updated using the UGCs. We explore the unique characteristics of UGCs like blogs, cQAs, microblogs, etc. , and introduce a novel scheme to combine them. We also propose a graph-based method to enable incremental update of the generated topic hierarchy. Us-ing the hierarchy, users can easily obtain a comprehensive, in-depth and up-to-date picture of their topics of interests. The experiment results demonstrate how information from multiple heterogeneous sources improves the resultant topic hierarchies. It also shows that the proposed method achieves better F 1 scores in hierarchy generation as compared to the state-of-the-art methods.
 H.0 [ Information Systems ]: General; H.3.2 [ Informa-tion Storage and Retrieval ]: Information Storage User Generated Contents, Information Organization, Topic Hierarchy
With the rapid development of Web 2.0, user generated contents (UGCs) on the internet are becoming important sources for information navigation and knowledge acquisi-tion. For example, when a user wants to know Barack
Thi s work was done when the first author was a visiting student in National University of Singapore. Corresponding author.
 Obama X  X  performance in the 2012 presidential campaign, he may refer to blogs on Blog sites like Blogger 1 for au-thoritative criticisms, ask questions on community question answering (cQA) sites like Yahoo! Answers 2 for specific in-formation and read tweets from Twitter 3 to follow up with his friends X  opinions.

However, the volume of UGCs is huge and increasing ev-ery day. Even for a specific topic, it is usually impossible for users to go through all the contents and manually identify the newly emerging and important sub-topics. On the other hand, though in some UGC sources like Wikipedia 4 , the data is well organized into structured format which can be eas-ily accessed, they cannot catch up with the ever changing internet since they rely on human to compile and update.
The characteristics of different kinds of UGCs are diversi-fied. Information in any single source is always limited and domain specific. For example, if a user requires a techni-cal report for  X  X Phone 5 X , it is better to refer to blogs or cQAs instead of tweets in Twitter. But when he wants to know how his friends like  X  X Phone 5 X , Twitter turns out to be a better place. As a result, in order to have an overall picture of the topic, users have to refer to multiple UGC sources, which further increases their burdens to integrate these heterogeneous contents together.

To address the above problems, in this paper, we propose to organize information from multiple UGC sources using an automatically generated topic hierarchy. The task is not trivial due to the following three challenges: h ttp://www.blogger.com/ http://answers.yahoo.com/ https://twitter.com/ http://en.wikipedia.org/wiki/Main P age Fi gure 1: The topic hierarchy for  X  X arack Obama X . It organizes 119 blogs, 476 cQAs and 49749 tweets. Due to the space limit, we only illustrate the title of one blog, one cQA and one tweet for one of its sub-topics, debate .
In view of the above challenges, a three step framework is proposed to organize UGCs using automatically gener-ated topic hierarchies. Given a collection of UGCs such as blogs, cQAs and tweets on a specific topic, we first identify potential topic terms from these sources. Then assisted by external knowledge from Wikipedia, WordNet 5 and search engine results, we propose a novel scheme to identify sub-topic relations between topic terms using multiple evidences. Finally, by treating topic terms as nodes and sub-topic re-lations between them as edges, a graph-based algorithm is used to incrementally generate a topic hierarchy. Each time new data is available, the same framework can also be used to update the previously generated hierarchy with newly emerging sub-topics. Using the resultant topic hierarchy, the UGCs can be organized to nodes on the hierarchy ac-cording to their relevant sub-topics. In Figure 1, we show an example topic hierarchy for the topic  X  X arack Obama X . It contains 11 sub-topics, under which a total of 119 blogs, 476 cQAs and 49749 tweets are organized. The contributions of our work can be summarized as: The remainder of this paper is organized as follows: In sec-tion 2 we present the related work and in Section 3 we for-mally define the problem. Section 4 presents the frame-work of our approach, followed by detailed description on h ttp://wordnet.princeton.edu the three main modules, i.e. , topic term identification, topic relation identification and topic hierarchy generation includ-ing the real time hierarchy updating algorithm. In section 5, we discuss our evaluation method, experiments and results. Finally Section 6 concludes the paper. Topic Term Detection: TF-IDF weighting has been found to be very effective [2] [6] for topic term extraction from documents. To avoid the need to estimation IDF, which requires huge document collections, Matsuo et al.[11] em-ployed a sentence-level word co-occurrence matrix to find the keywords in a single document. NLP tools such as Tex-tRunner [20] has also been applied to extract keyword terms, however, since these tools are linguistics-based, it is hard to use them to analyze UGCs which usually contain multi-ple languages and are ill grammar. In some recent works [10], the hierarchical cluster structure of documents (e.g., Wikipedia) is also adopted to improve the keyword selec-tion performance.
 Taxonomy Induction: Given a small document set, Lawrie et al. [9] proposed to extract its intrinsic topic hierarchy by estimating the topicality of terms and co-occurrence proba-bility between them using only the given documents. Given a candidate term set, Navigli et al. [13] trained classifiers to detect is-a relations between terms and utilized a graph-based algorithm to optimize the term taxonomy. Besides, Snow et al.[16] introduced a probabilistic model to determine the most possible hierarchy for a set of concepts. Using both statistics-based and pattern-based features, Yang et al.[19] further proposed the metrics of information function and created hierarchies by an insert process, in which nodes are inserted onto the hierarchy to minimize the change of infor-mation functions. A recent work [21] extended this approach by employing more objective functions, i.e. , minimum Hier-archy Discrepancy and minimum Semantic Inconsistency to achieve a better insertion decision.
 Approaches using Multiple Sources: Information from multiple sources provides researchers clues in different views and helps to achieve better results by overcoming the bias of any single information source [3] [5] [17]. Han et al.[3] used information from Wikipedia, WordNet and a NE co-occurrence corpus to measure the semantic relatedness be-tween words. Although they just chose the conditionally most confident source to estimate the relatedness, instead of integrating the three sources together, the results have already outperformed the methods which only used single source. On the other hand, Hoffart et al.[5] proposed to in-tegrate information from Wikipedia, WordNet, Geo-Name corpus, etc. , to build Yago2, an open domain structured knowledge base.
We define the root topic C as a word or phrase which indi-cates the users X  search intends. It can be an entity ( e.g. ,  X  X arack Obama X ), an event ( e.g. ,  X  X enghazi Attack X ) or other informative concept. Given a root topic, we define its information source set S c as S c = { s i } N i =1 , in which s indicates a collection of documents from the i th information source. They are collected for C and can be automatically updated when new data is available.
The data in S c is usually unstructured and contains noise and errors. We define a topic hierarchy as H = { T, M, R } in which all useful information in S c is organized using the following three components: Formally, we define our task as follows: Information Organization Task : Given a root topic C and its information source set S c , we aim to build and con-tinuously update a topic hierarchy H for C in order to orga-nize the information in S c according to their relevant topics.
Inevitably, every single UGC source has flaws. Take blog as an example, although well-written, blog usually focuses on narrow points ( e.g. , technical reports for  X  X Phone 5 X  or big events for  X  X arack Obama X ) and takes a long time work before being published online. On the other hand, tweets can provide timely information ( e.g. , release date for  X  X Phone 5 X  in Europe), while they also contain a huge amount of noises ( e.g. ,  X  should I buy a IPhone 4S or IPhone 5?  X ). These drawbacks limit the potential uses of the UGCs.

In this paper, we will tackle the above problem by combin-ing the power of three prevailing UGCs, i.e. , Blogs, cQA and Twitter as our information sources. we also utilize domain-independent factoid knowledge from Wikipedia, WordNet, etc. to supplement the limited and specific UGC sources.
To address the information organization task, we intro-duce a three step framework as illustrated in Figure 2. For a given root topic C , we first identify potential sub-topic terms from S c . Then we identify the sub-topic relations between the sub-topics. Finally we generate the topic hierarchy and assign UGCs in S c onto the hierarchy. The following three sections will describe the details for each module. We will also show how the framework can be used to update an ex-isting hierarchy when new data is available.
We collect potential sub-topics for C in two steps: (1) we extract keywords from documents in S c to obtain an initial topic set; and (2) we extend the topic set with more abstract and general topics using knowledge from external sources.
The documents in S c contains many potential sub-topic terms. Since these terms directly reflect people X  X  focuses and Fi gure 2: The proposed method: maintaining a Topic Hierarchy using real-time data from multiple heterogeneous UGC sources by a three step frame-work.
 T able 1: Heuristic rules used in topic identification interests, we denote them as grounding topics , t g . To charac-terize a potential grounding topic, we first adopt four heuris-tic rules from [7], i.e. , the pos-tag heuristic , length heuristic , frequency heuristic and linguistic-alteration heuristic . In Ta-ble 1, we present a brief introduction of them.
 Next, for each source in S c , we separately estimate the TF-IDF scores for the potential grounding topics and obtain topic terms for each document as follows.
 Blogs: We use the blog title and content to compute the TF-IDF scores for terms in blogs. Since the title of a blog usually indicates its main topics, we double the weights of terms in titles. For each blog, the top 5 ranked terms by TF-IDF are selected as its topic terms. cQAs: We use the question title, description and the best answers to compute the TF-IDF scores. For each cQA, the top 5 ranked terms are selected as its topic terms. Tweets: We use the content and the words surrounded by hash tags to compute the scores. Since tweets are short and cover fewer topics, we only collect the top ranked term as their topic terms.

Simply putting the topic terms of documents together may bring lots of noise. In order to select high quality and pop-ular topic terms for the root topic, we adopt the following two assumptions:
A ssumption 1: A topic term is of high quality only if it can be extracted from documents in different information sources.

Assumption 2: A topic term is popular only if it can be extracted from many different documents.
W e use the Stanford CoreNLP toolkit (http://nlp.stanfo -rd.edu/software/corenlp.shtml) to get the POS-tags.
W e thus only collect the topic terms that are among the top 200 frequent topic terms in at least 2 different informa-tion sources into the grounding topic set , T G = { t g 1
Although T G contains many low-level topic terms ( e.g. , siri , battery for  X  X Phone 5 X ), it lacks middle level topic terms ( e.g. , software and device ) partly because they are too abstract and general for UGCs. Since these middle level terms are also useful in topic hierarchy generation, we inves-tigate external information sources to obtain them. Search Engine: For each term in T G , we use two pat-its higher level topic terms. We first fill the term into the slot and submit it to a search engine like Bing 7 . Then we collect the noun phrases in the position of the wildcard on the returned search pages as middle level topics. WordNet: WordNet contains hypernym relations between concepts. If a topic term in T G is included in WordNet, we collect the terms in its direct hypernym synset as middle level topics.
 Wikipedia: If a topic term in T G is a Wikipedia title, its category tags are also collected as middle level topics.
The middle level topics shared by at least 2 sources are collected into the extended topic set , T E . Then the final candidate topic set T = {C} X  T G  X  T E .
The sub-topic relation between topic terms provides es-sential information to organize the topics. Take  X  X arack Obama X  as an example, if we know that there is a sub-topic relation between two of its sub-topics, e.g. , policy  X  tax , which indicates that tax is a sub-topic of policy , it will be very probable that there is a path between the two topic terms on the topic hierarchy.

To infer a sub-topic relation r ( t A , t B ), we need to esti-mate the probability that the topic t B is a sub-topic of t Inspired by [18], we approximate this probability with an empirical score e ( r ( t A , t B )) which is estimated by evidences from multiple sources. The evidences are summarized in Ta-ble 2 and the details are listed as follows: Evidences from the Information Source Set: If there is a sub-topic relation between two topic terms, they must be highly related, where contextual distribution can be used to measure this relatedness. More specifically, for each topic term, the nouns, verbs and adjectives that co-occur with it in the documents/sentences in S c are collected as its docu-ment/sentence level contexts. For each term pair t A and t the document and sentence level contextual evidences, i.e. , e sine similarity between the corresponding contexts of them. Evidences from Wikipedia : Pointwise Mutual Informa-tion (PMI) is also a measurement for the relatedness be-tween two terms. We compute the PMI over a subset of Wikipedia corpus, which only includes pages that are not redirect pages and contain more than 1000 words. For t A and t B , we compute the normalized PMI as npmi ( t A , t h ttp://www.bing.com
We do not use tweets in generating document level contex-tual evidence since they are relatively too short. We also use the category and sub-title evidences from be estimated as follows, respectively: e e Evidences from WordNet : If t A and t B can be found in WordNet and t A is an ancestor of t B , then it is very probable that t B is a sub-topic of t A . In practice, if t ancestor of t B in WordNet, we use the WordNet similarity [15] to estimate the WordNet evidence as e wnet ( t A , t the shortest path between t A and t B in WordNet. Otherwise we just let e wnet ( t A , t B ) = 0.
 Evidences from Search Engine Results : We also use evidences from the internet. For each term pair t A and t we generate a query by filling them into the pattern ( e.g. , X  t such as t B and X ) and submit it together with the root topic to the search engine. Denote pattern i as the i th pattern, we can obtain a 0 / 1 pattern-based evidence e spattern i ( t whose value is set to 1 only if the search engine returns more than  X  results that contain this query; otherwise it is set to 0. In practice, we select 6 patterns as listed in Appendix A and  X  is set to 10 empirically.

To combine the above evidences, instead of simply adding or multiplying them together like [19][21], we first divide the evidences into two sets as shown in Table 2, i.e. , the directed-evidence set E dir which includes the evidences that can determine the direction of the sub-topic relation and the undirected-evidence set E und in which the evi-dences bear no directionality information.

For the directed-evidences, we use a linear combination to combine them together as follows: where w k is the weight of the k th evidence in determining the direction of the sub-topic relation and
Since the training data is not always available for open domain topics, supervised methods used in previous works [21] on weight estimation cannot be used to calculate w k In this paper, we propose an unsupervised method to meet this challenge. The basic idea of our method is that since sub-topic relation is directed, it is not possible that both r ( t
A , t B ) and r ( t B , t A ) exist. Therefore, if a directed-evidence e k supports both r ( t A , t B ) and r ( t B , t A ), which happens when the difference between e k ( t A , t B ) and e k ( t significant, e k should be less weighted. More specifically, we estimate the weight w k for each directed-evidence e k w
Th e root topic is used to filter out irrelevant search results. T able 2: The sources of evidences we use to estimate the probability of a sub-topic relation weights to the evidences with high values and p k =  X  dences that are too general. Then the final score e (( r ( t is estimated using the following equation: where nces for the two topic terms.
By treating the sub-topics in T as nodes, sub-topic rela-tions between them as edges, we can generate a sub-topic graph. Next, we estimate the weight for each edge using the scores estimated in section 4.4 using the following equation: w ( r ( t A , t B )) = in which w ( r ( t A , t B )) is proportional to both e ( r ( t and the difference between e ( r ( t A , t B )) and e ( r ( t dicating the strength of the edge from the node t A to t B removing the zero weighted edges, equation 5 also guaran-tees that there is only one directed edge between two nodes, which is essential for a valid hierarchy.

Next, we need to prune this graph into a hierarchy. In-spired by [13], we employ a graph based method to tackle this problem. Different from this work, we take an itera-tive approach: at each step we only add one sub-topic into the hierarchy, which makes our method amendable to incre-mentally update the hierarchies. In general, the proposed hierarchy generation algorithm can be formalized as Algo-rithm 1.

Given a candidate topic set T for C , the algorithm func-tions as follows. Let T i and R i be the resultant topic set and sub-topic relation set of the hierarchy after the i th iteration, we initialize them as T 0 = {C} and R 0 =  X  (line 1). In the i th iteration, we first add a topic term t in T  X  T i  X  1 into T  X  1 (line 3 -9) using the following function: where t is the topic term that maximizes score ( t ) = Al gorithm 1 Hierarchy Generation Algorithm Inpu t: T : the candidate topic set; Output: R ret : the sub-topic relation set of the resultant hierarchy; T ret : the topic set of the resultant hierarchy;
Initialize T 0 = {C} , R 0 =  X  for i = 1 TO  X  do end for la tedness between t s and topic terms in T i  X  1 . Note that NIL will be returned if T  X  T i  X  1 =  X  or score ( t ) is 0.
Once we have added t into T i  X  1 to form T i , we also add all the edges between t and topics in T i  X  1 into R i  X  1 , resulting in R i (line 10 -15). In order to guarantee that edges in R i make up a valid hierarchy, next we use a graph based method to prune the edges in R i as follows.
 Edge Weighting using Topic Relatedness (line 16 ): Edge weighting assigns score to each edge in R i , indicating its importance in constructing the hierarchy. Our method generalizes that of [13] by weighting each edge in R i with the estimated weights instead of simple 0/1 values. The process is as follows: Hierarchy Pruning using Optimum Branching (line 17 ): Given the edge weighting results, we can use the Chu-Liu/Edmond X  X  optimum branching algorithm [1] to find a subset of the current edge set R i , which is the optimized hierarchy for the given topic terms where every non-root node has only one parent and the sum of the edge weights are maximized .
When the iteration terminates at the N th iternation, the resultant topic set T N  X  1 and sub-topic relation set R N will be collected for the final topic hierarchy. To guarantee that the hierarchy is specifically related to the given topic and the documents in S c , we further remove (1) the nodes that are not reachable for the root topic and (2) the leaf nodes that are not in the grounding topic set. Finally, for each topic term t in the topic set, we assign the documents in S c whose topic terms contain t to the corresponding node, resulting in M , the document-topic mapping function of the resultant topic hierarchy.
For a given topic, the information on the internet is ever-changing. Different from many previous approaches that work on static corpus, we find it useful and necessary to dynamically sketch evolving topic hierarchies for users. For example, assume we have built a topic hierarchy for  X  X arack Obama X  X efore the presidential campaign; when people start to talk about his inauguration ceremony on the internet, we need to detect the corresponding new sub-topic inaugura-tion and insert it and its relevant documents to the correct place on  X  X arack Obama X  X  topic hierarchy.

To this end, we make it a key function for our proposed framework to be able to incrementally update the topic hi-erarchy by using the newly obtained data. Let H old = {
T old , M old , R old } be the existing hierarchy and S new newly obtained data set, a new hierarchy H new = { T new , M R new } can be obtained by updating H old using the following process: Up date the candidate topic set: Update the topic hierarchy: Update the document-topic mapping function: Th is update process is robust. This is evidenced from the fact that, when there are mistakes in the existing hierar-chy, the newly obtained information can be used to correct the wrong relations. For example, the sub-topic relation set R old = { barack obama  X  tax } contains a very ambigu-ous relation 10 . When a new topic term policy is discovered from the new data set, instead of just adding it as a child to any of the two existing nodes, our method can further break the original ambiguous relation and create a better structure for the three topic terms; thus R new = { barack obama  X  policy , policy  X  tax } .
We collect UGCs from the internet to form a corpus of four categories: Digital Products, Politicians, Cosmetics and
It may means barack obama  X  X  policy on tax or barack obama  X  X  own tax .
 T able 3: Statistics on the collected data sets in each information source T able 4: Resultant candidate topic sets for four ex-emplar root topics Corporations. In each category, two to three topics are se-lected, resulting in 11 root topics. For each topic, blogs, cQAs and tweets are collected. We crawl blogs for a topic by submitting the topic name as the query into the Google Blog search engine 11 and collect the first 200 returned blogs. For cQAs and tweets, we use the Yahoo! Answer API and Twitter API to obtain the data stream on the target topic. A brief statistics of our corpus can be found in Table 3.
Note that the data in all the three information sources are tagged with time stamps. For blogs, they can be obtained from the snippets in Google Blog search results which indi-cate when the blogs are published. The data from Yahoo! Answer and Twitter APIs also contains time stamps on when the questions are asked or the tweets are created.
In this section, we will first analysis the candidate topic sets generated by the method described in section 4.3. Next we will demonstrate how the use of different UGC sources improve its performance.

Table 4 shows a portion of identified topic terms for four exemplar root topics. From the results we can see that UGCs contain very rich and diversified information. For  X  X arack Obama X , sub-topics on different aspects like politics (e.g., law ), personal information (e.g., islam ) and latest events (e.g., debates ) can be precisely extracted. We even obtain more comprehensive product-related topics (e.g., sunglass ) for  X  X hanel X  than those in Wikipedia.

Define the coverage of the candidate topic set T as the ratio of the documents in the information source set that contain at least one term in T as its relevant topics, the av-erage coverage is 18 . 4% for all root topics. Although twitter contains a huge amount of noise (more than 85% are noise from statistics on a randomly selected data set that contains 550 tweets), the proposed method can effectively filter out most of them, hence only 18 . 2% high-quality tweets are cov-ered. On the other hand, higher coverage is observed for blogs (54 . 7%) and cQAs (40 . 4%).

From the covered documents, we sample 20 blogs, 20 cQAs and 50 tweets for each topic. Three annotators are asked to h ttp://www.google.com/blogsearch d etermine whether the topic terms we found are relevant to the corresponding documents. Only the documents that have agreement among all annotators are used for the statis-tics. The result shows that for all UGC sources and topic categories, our method can achieve a precision of 73 . 2% to 90 . 4%. Fi gure 3: The percentage of topic terms supported by each information source on the topic set
Figure 3 shows the contribution of different UGC sources in topic term identification. We can see that all sources are indispensable. Although cQAs and blogs provide the major-ity of the topic terms, tweet tends to contribute timely and popular topics such as release date of iphone 5 and price of ipad mini . Though very limited, external sources pro-vide middle-level topics such as os of microsoft and policy of barack obama , which are essential when organizing the topics into a hierarchy.
We evaluate our results against manually created gold standards. For each topic, three annotators are employed to create hierarchies independently using terms from the can-didate topic set according to the following three rules. Rule 1: Relevancy. All nodes on the hierarchy must be reasonable sub-topics of the root topic. It guarantees that users won X  X  get noisy information from the topic hierarchy. Rule 2: Maximum coverage. All relevant nodes should be included into the hierarchy. Hence users won X  X  miss any useful information about the root topic.
 Rule 3: Hierarchical structure. Each two connected nodes must be directly related that no other nodes in the candi-date topic set can be inserted between them. This makes the hierarchy completely structured for users to quickly find their interested contents.

For example, given the candidate topic set { barack obama , policy , tax , medic care , friday } for X  X arack Obama X . First, only friday will be removed according to rule 1 and 2. Then according to rule 3, the gold standard hierarchy should be { barack obama  X  policy , policy  X  tax , policy  X  medic care } , which provides users a completely hierarchical view of the available UGCs about  X  X arack Obama X .

Next, the three annotators compare their resultant can-didate hierarchies and come up with the gold standards through discussions. On average, the gold standard hier-archies contain 22 . 3 nodes and 21 . 3 edges with an average depth of 3 . 64.

We use the precision, recall and F 1 scores to measure the hierarchy generation performance. Denote R and R gold as the sub-topic relation sets of our output and the gold stan-dard, respectively, the metrics can be calculated as follows: Fi gure 4: Performance on topic hierarchy generation when using different information source set
In Figure 4, we first compare the performance of our pro-posed methods when using different information source set, which consists of (1) only cQAs and tweets ( noBlog ), (2) blogs and tweets ( noCQA ), (3) blogs and cQAs ( noTweet ), and (4) all the three sources ( All ). The results show that the more the sources we use, the better the performance we can achieve, where the improvements of around 31 . 2% -74 . 8% are observed on the average F 1 scores of All against those of the other three combinations. There are mainly two rea-sons. First, since multiple sources provide more topic terms (as shown in Figure 3), the recall is improved by 39% -124%. Second, though not for all the topics, the average precision is also improved. This is partly because more UGCs help to estimate better evidences which result in building more optimal topic hierarchies.

On the other hand, when comparing the results of noBlog , noCQA and noTweet , we can see that noBlog performs the poorest for most topics (for topics like X  X box Kinect X , the F score is even 0.). It indicates that blogs play a critical role in our method, partly because blogs are usually well-written and contain rich contents. For topics like  X  X hanel X , the per-formance does not drop that much when removing the blog data. This is partly because many of the crawled blogs are about fashion events and product comparison instead of fo-cusing on real sub-topics like perfume and lipstick . Once we can collect more appropriate blogs for these topics, even higher performances can be expected.
The proposed evidence combination scheme plays an im-portant role in our method. In this section, we compare it with three baseline methods: (1) Linear , which simply com-bines all evidences linearly and has been used in [19] [21]. For each topic, we adopt ridge regression [19] to optimize the weight vector using the training data from the other topics in the topic category. (2) No undirect , a variation of the proposed scheme which does not use undirected-evidences. (3) Equal direct , a variation of the proposed scheme in which Fi gure 5: Performance on topic hierarchy generation when using different evidence combination schemes the weights of all the directed-evidences are set to be equal. All methods run on the same topic sets as those used in generating the gold standards 12 .

The result is shown in Figure 5. Compared to the Lin-ear method, all the three methods that adopt our proposed scheme perform significantly better on the F 1 scores (t-test, p-value &lt; 0.05). This indicates that considering the directed and undirected evidences separately is a better way to es-timate the probability of sub-topic relations than putting all the evidences together undistinguishedly. The use of undirected-evidences also significantly improve the perfor-mance (t-test, p-value &lt; 0.05). Since we only adopt nine care-fully selected directed-evidences, the effect of weights is lim-ited. However, as shown in Table 5, the weight vector indeed reflexes the quality of different evidences. For example, the Wikipedia-based evidences (e.g., e wcate , e wtitle ) usually ob-tain higher weights since they are from high quality sources. Stricter patterns (e.g., e spattern 0 ) are also higher weighted than general patterns (e.g., e spattern 2 ). As the result, more improvement could be observed when more evidences of var-ied qualities [21] are introduced. Table 5: Part of the weight vector of directed-evidences for  X  X Phone 5 X 
Based on the results in previous two sections, our method performs the best when using all information sources and adopting the proposed combination scheme. We now com-pare our best method with three state-of-the-art methods: (1) Yang X  X  Method [19], which organizes concepts into a hi-erarchy according to a information function. For each topic, the information function employs all the evidences in Ta-ble 2 and is trained using the gold standard of this topic. (2) Navigli X  X  Method [13], a graph based method which only employs a classifier-based 0/1 evidence and does not sup-port real time update. Since the evidence used in this paper only provides clues for is-a relation, we extend it with extra directed-evidences from our evidence set for the sake of fair comparison. (3) Snow X  X  Method [16], which uses a proba-bility model to obtain the most probable hierarchy for the
In fact, since these methods (including those presented in the following section) use the same topic identification pro-cess, they all share the same candidate topic sets. concepts in a given concept set. For fair comparison, we use the probability of a sub-topic relation approximated for our method here.

In Table 6, we can see that our proposed method achieves the best performance on all metrics for most topics and sig-nificantly outperforms the state-of-the-art methods on the averaged F 1 score (t-test, p-value &lt; 0.05). Compared to Yang X  X  method, the proposed graph based method makes better use of the relations among three or more topics. Taking the root topic  X  X hanel X  as an example, given its sub-topic set { chanel , product , perfume , ... } , while Yang X  X  method returns the relation set { chanel  X  product , chanel  X  perfume , ... } by considering only the strongness of pair-wise sub-topic relations, our method can further detect the sub-topic chain along the three topics, i.e. , chanel  X  prod-uct  X  perfume , ,which better captures the global relation. Moreover, the proposed method outperforms Snow X  X  method in term of F 1 score by about 12%. It is partly because the re-sults of Snow X  X  method are strongly affected by the insertion order of the topics. Once an insertion error occurs in one step, it cannot be corrected in the following steps. But our incremental updating mechanism can naturally solve this problem. Navigli X  X  method tends to generate very deep hi-erarchies [13], where errors occur sometimes (e.g., iphone 5  X  camera  X  cost , where the cost of IPhone 5 X  X  camera does not make sense). This type of errors can be solved by our method through the use of multiple evidences. As for the iphone 5 example, we will determine that the relatedness between iphone 5 and cost is much stronger than that be-tween camera and cost in term of evidences like PMI, thus a direct connection is established between iphone 5 and cost .
In this section, we analyse the strength and weakness of our method using a few examples. First, rather than simply assigning all sub-topics as direct children of the root topic, our method tends to generate completely structured hierar-chies (average depth is 5 . 27). For example, ( facebook  X  application  X  business  X  marketing  X  ads ) is a sub-topic chain in the resultant hierarchy of  X  X acebook Inc. X . Evidences from all sources contribute to this result. Pattern-based evidences support the relations that frequently occurs on web pages like facebook  X  application . On the other hand, Wikipedia-based and WordNet-based evidences help to find many novel relations ( rather than traditional is-a or has-a relation), such as marketing  X  ads for the given example and policy  X  tax for  X  X arack Obama X . The undirected-evidences are also important. For the given ex-ample, both contextual-based and pmi-based evidences sug-gest that marketing and ads are more relevant than busi-ness and ads . Based on all these evidences, our method can best capture the relations among all the sub-topics of a given root topic.
 However, multiple sources also bring in different errors. For pattern-based evidences, when a pattern  X  &lt; topic &gt; such as &lt; subtopic &gt; and X  matches a string  X  ... as well as other companies/brands/ games such as Bing and Gears of War ...  X , a sub-topic relation between game and bing will be detected. This is obviously wrong but is hard to be corrected by NLP tools. On the other hand, for an error sub-topic relation ( event  X  lipstick ) for  X  X hanel X , we found that 1 p re. rec. F 1 pre. rec . F 1 p-value &lt; 0.05) compared to all three baseline methods. Fi gure 6: Hierarchy update on  X  X Phone 5 X  and  X  X arack Obama X  between 1 brackets) in each period. the only evidence that supports it is from WordNet, since there is a WordNet path 13 between the two words.
Online UGCs increase every minute. In this section, we demonstrate how the proposed method can be used to up-date the topic hierarchies incrementally with real time in-formation. We use the data of blogs, cQAs and tweets pub-lished before 15 th Dec, 2012 on two example topics, i.e. ,  X  X arack Obama X  and  X  X Phone 5 X . According to their pub-lished date, we split the data into 7 sub sets. We initiate the hierarchy using the data before 1 st Oct and update it using the data in the other 6 sub sets, each indicates a dura-tion of 15 or 16 days. As our baselines are not designed for real time data, we only show our results for the hierarchy updating experiments here.
 The result in Figure 6 offers us a close look of this process. We can see that as time passes and new topics emerge, our method can effectively detect these topics and merge them into the hierarchy. As the results, topics like jailbreak for  X  X Phone 5 X , debate , inauguration for  X  X arack Obama X  are updated onto the appropriate positions of the topic hierar-chy shortly after they become popular on the internet. From the results, we can also find that  X  X arack Obama X  is a more time-sensitive topic, which brings in new sub-topics in each
Th e WordNet path: event  X  makeup  X  lipstick . period. On the contrary, the change of topics on  X  X Phone 5 X  is very small during the two and a half months.
In this paper, we proposed an automatic method for incre-mental information organization for multiple UGC sources. Given a root topic, we used evidences from multiple UGCs to identify topic terms and sub-topic relations between them. With these topic terms, a graph-based algorithm was applied to generate and update the topic hierarchies, on which the UGCs can be organized according to their relevant topics. Comprehensive experiments on 11 root topics demonstrated the effectiveness of our method. For future work, we will explore more UGC sources such as forums and try to find available initial topic hierarchies to enhance our system. It is also interesting to apply the generated topic hierarchy in more sophisticated text analysis tasks.
This research is supported by the Singapore National Re-search Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office and The National Key Basic Re-search Program (also called 973 Program), No.2012CB316301 and NSFC under project No.61272227. [1] J. Edmonds. Optimum branchings. Journal of [2] Y. HaCohen-Kerner, Z. Gross, and A. Masa.
 [3] X. Han and J. Zhao. Structural semantic relatedness: [4] C. Hayes, P. Avesani, and U. Bojars. An analysis of [5] J. Hoffart, F. Suchanek, K. Berberich, and [6] A. Hulth. Improved automatic keyword extraction [7] S. N. Kim and M.-Y. Kan. Re-examining automatic [8] Z. Kozareva and E. Hovy. A semi-supervised method [9] D. J. Lawrie and W. B. Croft. Generating hierarchical [10] X. Mao, Z. Ming, Z. Zha, T. Chua, H. Yan, and X. Li. [11] Y. Matsuo and M. Ishizuka. Keyword extraction from [12] Z. Ming, K. Wang, and T. Chua. Prototype hierarchy [13] R. Navigli, P. Velardi, and S. Faralli. A graph-based [14] K. Nishida, R. Banno, K. Fujimura, and T. Hoshide. [15] T. Pedersen, S. Patwardhan, and J. Michelizzi. [16] R. Snow, D. Jurafsky, and A. Ng. Semantic taxonomy [17] X. Wang, K. Zhang, X. Jin, and D. Shen. Mining [18] H. Yang and J. Callan. Feature selection for automatic [19] H. Yang and J. Callan. A metric-based framework for [20] A. Yates, M. Cafarella, M. Banko, O. Etzioni, [21] J. Yu, Z. Zha, M. Wang, K. Wang, and T. Chua.
In Table 7, we list the patterns we use in estimating the pattern-based evidences. T able 7: Patterns used to estimate the pattern-based evidences
