 Jovian Lin 1 , Kazunari Sugiyama 1( Traditional recommendation approaches either learn a user X  X  preference from their ratings ( i.e. , collaborative filtering) or the contents of previously-consumed items ( i.e. , content-based filtering). Despite the pervasive use of collaborative filtering in several domains such as books, movies, and music, its effectiveness is hindered by insufficient ratings, particularly towards newly-released items  X  a problem that is commonly known as the  X  X old-start. X  Moreoever, due to noisy and unreliable descriptions of apps, content-based filtering does not work well in the app domain [ 10 ].
 recommendation techniques that take advantage of the unique characteristics of the app domain have emerged. The first type focuses on collecting additional internal information from the user X  X  mobile device, which analyzes the usage behavior of individual apps via anonymized network data from cellular carri-ers [ 18 ] as well as usage patterns of users via their in-house recommender sys-tems [ 1 , 6 , 19 ]. The second type makes use of external information such as spatial data from GPS sensors to provide context-aware app recommendations [ 7 , 22 ]. These two types, however, rely on data that is generally difficult to obtain, caus-ing the secondary problem of data-sparsity. On the contrary, the third type con-sists of works that capitalize on more unique characteristics of the app domain that may not be applicable to other domains. For instance,  X  X ollower X  infor-mation of an app X  X  Twitter account was used to substitute missing user rat-ings [ 10 ], which proved to be useful in cold-start situations. Another work tried to find the likelihood of which a current app would be replaced by another [ 20 ]. Alternatively, by taking the fact that apps change and evolve with every new version update, a  X  X ersion-sensitive X  recommendation technique was constructed to identify desired functionalities (from various version descriptions of apps) that users are looking for [ 11 ].
 With a variety of app recommendation techniques utilizing different sources of information, of which some may be available while others are not ( e.g. , not all apps have user ratings), we explore the advantages of a hybrid app recommen-dation framework that combines traditional and novel techniques. More impor-tantly, through the hybrid framework, we seek to identify the most important app-related indicators for the recommendation task.
 The steps are as follows: First, using gradient tree boosting (GTB) [ 8 ], several recommendation techniques and their information sources are integrated to form a hybrid app recommender framework. After that, we further look into each component of the feature set to find the most significant features in the hybrid framework. Our findings show an interesting correlation with data from third-party app analytics companies, and suggest that, in the context of mobile app recommendation, more focus could be placed in user and trend analysis via social networks. 2.1 Mobile App Retrieval Chen et al. [ 5 ] proposed a framework for detecting similar apps by constructing kernel functions based on multi-modal heterogeneous data of each app (descrip-tion text, images, user reviews, and so on) and learning optimal weights for the kernels. They also applied this approach to mobile app tagging [ 4 ]. While Chen et al.  X  X  work utilized different modalities of an app, Park et al. [ 14 ] exclusively leveraged text information such as reviews and descriptions (written by users and developers, respectively) and designed a topic model that can bridge vocab-ulary gap between them to improve app retrieval. Zhang et al. [ 21 ] developed a mobile query auto-completion model that exploits installed app and recently opened app. In addition, Martin et al. [ 13 ] has published a nice survey on app store analysis that identifies some directions for software engineering such as requirements engineering, release planning, software design, testing, and so on. 2.2 Mobile App Recommendation In order to deal with the recent rise in the number of apps, works on mobile app recommendation are emerging. Some of these works focus on collecting additional information from the mobile device to improve recommendation accu-racy. Xu et al. [ 18 ] investigated the diverse usage behaviors of individual apps by using anonymized network data from a tier-1 cellular carrier in the United States. While Yan and Chen [ 19 ], Costa-Montenegro et al. [ 6 ], and Baeza-Yates et al. [ 1 ] analyzed internal information such as the usage patterns of each user to construct app recommendation system, Zheng et al. [ 22 ] and Davidsson and Moritz [ 7 ] uti-lized external information such as GPS sensor information to provide context-aware app recommendation. Lin et al. [ 10 ] utilized app-related information on Twitter to improve app recommendation in cold-start situations. Their subsequent work focused on app X  X  uniqueness of version update, and then proposed an app rec-ommendation system that leverages version features such as textual description of the changes in a version, version metadata [ 11 ]. These two works are compiled into [ 9 ]. Yin et al. [ 20 ] considered behavioral factors that invoke a user to replace an old app with a new one, and introduced the notion of  X  X ctual value X  (satisfac-tory value of the app after the user used it) and  X  X empting value X  (the estimated satisfactory value that the app may have), thereby regarding app recommendation incorporated both each user X  X  interest and privacy preferences to provide app rec-ommendation as apps could have privileges to access the user X  X  sensitive personal information such as locations, contacts, and messages. While the aforementioned works recommend apps that are relevant to each user X  X  interests, Bhandari et al. [ 2 ] proposed a graph-based method for recommending serendipitous apps. 3.1 Feature Set Inspired by Wang et al.  X  X  work [ 17 ], the features that we use can be categorized into the following three distinct groups: 1. the app X  X  m arketing-related m etadata ( M ), 2. the user X  X  h istory-related information ( H ), and 3. the r ecommendation scores of different recommender systems ( posed of all three groups of information: X u,a = { X M a X u,a represents the feature vector of the app a for user u , while represent the features from the users X  history, apps X  metadata, and recommen-dation scores from various recommendation techniques, respectively. 3.1.1 App X  X  Marketing-Related Metadata ( M ) The features here pertain to the app X  X  metadata or marketing-related informa-tion. We include most of the components of an app X  X  official metadata from the iTunes App Store, such as the various genres that the app is assigned to, its price, average ratings, etc . We also include external information, particularly ubiquitous data from social networks, such as the number of versions an app has, the number of Facebook  X  X ikes X  it has (zero if the app has no Facebook handle), and the number of Twitter followers it has (zero if the app has no Twitter handle). The blue components in Fig. 1 show all the information of an app X  X  marketing-related features. 3.1.2 User X  X  History-Related Information ( H ) User history is primarily extracted from the rating history of users, and it is a crucial component for the purpose of providing personalized recommendations. In addition, inspired by Wang et al.  X  X  method [ 17 ] for generating additional user metadata by scrutinizing the genres of items that users have consumed, we also consider the user X  X  preference of each app genre g . For instance, a user might be a loyal consumer of the  X  X ames X  genre, yet not in the  X  X ood &amp; drink X  genre. We thus include the number of times ( i.e. , the  X  X ount X ) that apps in genre g were consumed by user u (represented in green in Fig. 1 ). 3.1.3 Recommendation Scores from Different Recommender We also include the recommendation scores generated from four recommendation techniques: (i) collaborative filtering, (ii) content-based filtering, (iii)  X  X witter-follower-based app recommendation X  (TWF) [ 10 ], and (iv)  X  X ersion-sensitive recommendation X  (VSR) [ 11 ]. These are represented by the red components in Fig. 1 .
 laborative filtering as it is a state-of-the art technique that models the user-item ratings matrix as a product of two lower-rank user and item matrices, and it has been used in many previous recommendation works due to its highly flex-ibility and extendability. We also employ latent Dirichlet allocation (LDA) [ 3 ] to implement content-based filtering (on apps X  textual descriptions) as it effec-tively provides an interpretable and low-dimensional representation of the items. In addition, we select TWF and VSR due to their ability to make use of ubiq-uitous information from Twitter X  X  API and version data from third-party app analytics companies, respectively. With the hybrid app recommendation that is modeled by gradient tree boosting (GTB) [ 8 ], we further look into each com-ponent of the feature set ( i.e. , M , H ,and R ) in the hybrid model based on relative influence 1 . 3.2 Combining App Features Inspired by BellKor X  X  winning solution for the Netflix Prize Tree Boosting (GTB), a machine learning algorithm that iteratively constructs an ensemble of weak decision tree learners through boosting [ 8 ]. It produces an accurate and effective off-the-shelf procedure for data mining that can be directly applied to the data without requiring a great deal of time-consuming data preprocessing or careful tuning of the learning procedure.
 user may give to an app. After which, it ranks all recommended apps in descend-ing order of rating to produce a ranked list for each user. Here, we use a popular Python machine learning package from scikit-learn 3 to implement GTB. We construct our experimental dataset by crawling the information on Apple X  X  iTunes App Store 4 (app metadata, users, and ratings), App Annie information of apps), Twitter (for the Twitter followers of apps), and Facebook (for the  X  X ikes X  information of apps). Our dataset includes 33,802 apps, 16,450 users, and 3,106,759 ratings after we retain only unique users who give at least 30 ratings. Among the 33,802 apps, 7,124 (21.1 %) have Twitter accounts, 9,288 (27.5 %) have Facebook accounts, and 10,520 (31.1 %) have at least five versions. Note that 678 (2.0 %) apps have both Twitter and Facebook accounts. We per-form 5-fold cross validation, where in each fold, we take the first 80 % of the apps (chronologically) as training data for the individual recommendation techniques, use the following 10 % as the training data for the unified model ( i.e. , the probe set of GTB), and use the remaining 10 % for testing. 4.1 Comparative Recommender Systems We compare two types of recommender systems: individual and hybrid. For individual systems which are baselines, we implement the four state-of-the-art recommender algorithms mentioned in Sect. 3.1.3 , namely, collaborative filtering (PMF) [ 15 ], content-based filtering (LDA) [ 3 ], TWF [ 10 ], and VSR [ 11 ]. For the hybrid systems, we create three subsets of the GTB framework using a smaller set of features. That is, on top of our gradient boosting hybrid framework GTB( H , R ), we create three more hybrid systems: GTB( R ), GTB( H , R ), where  X  M  X ,  X  H  X , and  X  R  X  represent the various information u,a mentioned in Sect. 3.1 , respectively.
 Table 1 shows the details of the various recommendation techniques and their feature set. For the individual recommender systems, the feature set contains the user X  X  h istory-related features ( X H u,a ) that are generated from the user X  X  previous ratings history as well as the app data. The hybrid models further integrate the product X  X  marketing-related m etadata ( X M a )andther ecommender scores generated by the individual recommender systems ( X R u,a 4.2 Evaluation Metric Our system ranks the recommended apps based on the probability in which a user is likely to download the app. This methodology leads to two possible evaluation metrics: precision and recall. However, a missing rating in the training set is ambiguous as it may either mean that the user is not interested in the app, or that the user does not know about the app ( i.e. , truly missing). This makes it difficult to accurately compute precision [ 16 ]. But since the known ratings are true positives, recall is a more pertinent measure as it only considers the positively rated apps within the top M , namely, a high recall with a lower M will be a better system. We thus chose Recall@ M (especially, M = 50) as our primary evaluation metric. 5.1 Individual Recommender Techniques Figure 2 shows Recall@50 obtained by different recommender systems. Among the individual recommender techniques ( i.e. , the first four bars from the left), content-based filtering (LDA) achieves the best performance, i.e. ,itoutper-forms collaborative filtering (PMF), TWF, and VSR. At first, it is surprising that content-based filtering (LDA) is the best individual technique among the other individual algorithms, especially against state-of-the-art ones. But given that the dataset contains some apps that: (i) do not have enough ratings for collaborative filtering, (ii) do not have Twitter accounts (78.9 %), and (iii) do not have sufficient version information (68.9 %), it is reasonable that these tech-niques underperform due to the lack of sufficient information for every app, whereas content-based filtering (LDA) works better because apps always have app descriptions to construct a recommendation model. In other words, in gen-eral and practical situations where there are a variety of apps that have and do not have ratings, Twitter accounts, and version information, content-based filtering is the more reliable technique. 5.2 Hybrid Recommender Techniques Next, we explore the GTB models in Fig. 2 (the last four bars). All of our GTB models outperform the individual techniques described in Sect. 5.1 . This is expected as many other works that use GTB, particularly those involved in the Netflix prize, have also reported improvements against individual baselines. We also observe a general improvement in recall when we incorporate more components into the feature set. For example, GTB( M , R )andGTB( outperform GTB( R )andGTB( M , R ), respectively. We observe an interesting small anomaly, in which GTB( H , R ) slightly underperforms GTB( GTB( M , R ) significantly outperforms both GTB( R )andGTB( words, the recommendation scores ( R ) is more effective when it is combined with app metadata ( M ) than when it is combined with user features ( suggests that app metadata ( M ) complements the feature of recommendation scores ( R )  X  which actually makes sense as, given the assortment of app meta-data ( M ) that coincides with recommendation scores ( R ), a correlation pattern can be better identified. For example, the app metadata of Twitter followers would complement the recommendation score provided by TWF, while the num-ber of versions would complement the recommendation score generated by VSR; likewise, the number of ratings would complement the recommendation score given by collaborative filtering. On the contrary, as features from user history (
H ) mainly consists of the number of times each genre is consumed, it has less obvious correlations. 5.3 Ablation Testing 5.3.1 Ablation Testing for Hybrid Recommendation Techniques The experimental results described in Sect. 5.2 show the overall effectiveness of all four combined recommendation techniques as well as user features and app information. To gain a deeper understanding of the individual recommendation techniques, we further perform ablation testing by excluding one of the four recommendation techniques from GTB( M , H , R ), while at the same time, using the user features and app metadata, X H u,a and X M a .
 Table 2 shows recall@50 obtained by the ablation testing in which we ablate one recommendation technique out of the four. We observe the followings from Table 2 :  X  Content-based filtering (LDA), which achieves the best recall among all indi-vidual baselines, also causes the largest dip in recall when we ablate it from the unifying model. That is,  X  X TB( H , M , R ) excluding content-based filter-ing X  has the lowest score (0.237) among the four ablation baselines. This is unsurprising as it is expected when we omit the strongest individual predictor.  X  Although VSR individually outperforms collaborative filtering (0.141 against 0.094), ablating it from the unifying model does not have very much impact; in fact, ablating collaborative filtering (PMF) has more impact than ablating
VSR.  X  It would seem that, from this initial ablation study, both of the traditional recommendation techniques, collaborative filtering (PMF) and content-based filtering (LDA) are more effective than VSR and TWF as the two traditional techniques bring about the two biggest dips in recall when we ablate them.  X  However, we should not let this relative ablation comparison undermine the improvements that VSR and TWF have brought about. In fact, VSR and
TWF improve recall by 16.5 % and 11.0 %, respectively. More importantly, by utilizing these unique and less obvious signals in the app domain (compared with other traditional domains in recommender systems), we have gained sig-nificant improvements for general app recommendation 6 . In other words, dif-ferent pieces of evidences ( e.g. , Twitter followers and versions) that, when present, can be utilized sufficiently to create a discernible improvement in recommendation quality.
 regarding VSR and TWF, as 68.9 % of apps do not have sufficient version infor-mation while 78.9 % of apps do not have Twitter accounts (see Sect. 4 ). There-fore, the lack of information does not provide a well grounded conclusion. In order to investigate the real utility of VSR and TWF, we further scrutinize our data by utilizing a subset of data that has sufficient Twitter and version information in the unifying model. 5.3.2 Ablation Testing Using Sufficient Twiter Information Similar to Sect. 5.3.1 , we also perform ablation testing using a dataset with full Twitter information. Table 3 shows recall@50 obtained by this study where GTB
TWF ( ... ) represents the model that uses full Twitter information in our controlled ablation testing. Table 3 indicates the followings:  X  Under a dataset with full Twitter information, we observe a reordering of recommendation techniques whereby TWF becomes consequential  X  ablating it causes the largest dip in recall scores (0.338) for the unifying model.  X  Not only does this justify TWF X  X  effectiveness but more importantly, it indi-cates that when certain evidence is available (here, Twitter followers informa-tion), this changes the signals that are used in the unifying model, allowing
TWF to displace the traditional, well-established recommendation techniques. 5.3.3 Ablation Testing Using Sufficient Version Information Furthermore, we perform another ablation testing using a dataset with full ver-sion information. Table 4 shows the recall@50 obtained by this study where GTB
VSR ( ... ) represents the model that uses full version information in our controlled ablation testing. According to Table 4 , we observe the followings:  X  Similar to our ablation testing with TWF in Sect. 5.3.2 , under a dataset with full version information, we observe a reordering of recommendation tech-niques.  X  Even though VSR does not displace collaborative filtering in this ablation testing, it still results in the second largest dip in recall scores (0.344) when we ablate it from the unifying model. In addition, under this dataset, improve-ment in recall obtained by VSR increases from 16.5 % (in Table 2 )to22%.  X  This further substantiates that when certain evidence is accessible, it changes the way signals are used in the unifying model, which the reordering of rec-ommendation techniques in our ablation study suggests.
 The ablation studies on the two controlled datasets (pertaining to full Twit-ter and version information) clearly demonstrate the importance of TWF and VSR in app recommendation, without which we would not have been able to cap-ture Twitter and version signals for the purpose of improving recommendation quality.
 5.4 Feature Importance in GTB We further analyze each component of the feature set in Fig. 1 of the GTB( H , R ) model based on the relative influence. GTB allows us to measure the importance of each component feature. Basically, the more often a feature is used in the split points of a tree, the more important the feature is. Feature importance is essential because the input features are seldom equally relevant. While only a few of them often have substantial influence on the response, the vast majority are irrelevant and could just as well have not been included. Thus, it is helpful to learn the relative importance or contribution of each input feature in predicting the response. Figure 3 shows the relative importances of the top features and gives the following insights (starting with the most important feature):  X  Not surprisingly, the average rating (all versions) is the most important factor as, when the average rating is high, it is natural for users to download the app because of its positive ratings. Therefore, this feature can be used as a strong signal in the unifying framework to make a split in the decision tree. This reasoning is also similar for the average rating (current version) .  X  Price ( i.e. , free vs paid) is also an important factor, and this evidence coincides with the trend that apps in the app store are heading towards the freemium model  X  with the proportion of free apps taking up 90 % of the app store.
Therefore, the price of an app could be a strong signal for a split in the decision tree.  X  X he number of ratings is also a strong indicator, as the more ratings an app has garnered, the clearer the sign that it is popular and hence, likely to be consumed. It is also a clear sign that the collaborative filtering technique can be employed.  X  Not only the number of Twitter followers to the app X  X  Twitter handle is an indicator of a strong social reach, but also the availability of additional
Twitter-followers information is an indicator that our Twitter-followers based recommendation technique can be utilized. Additionally, on a related note, the same reasoning could be used to explain why the number of Facebook likes is also one of the top features, as this indicator from Facebook is also a hint of the app X  X  social presence on the popular social networking site.  X  X he number of versions also plays an important role as this is a sign that our version-sensitive recommendation technique (VSR) may be employed. Given that this feature is one of the top features of GTB, it suggests that the version-sensitive recommendation technique [ 11 ] is useful here.  X  We also observe that some app genres fall under the top features, notably  X  X ames, X   X  X ntertainment, X  and  X  X ocial networking X   X  with  X  X ames X  having a much more significant influence score. The three genres are consistent with alternate findings by Flurry Analytics 7 whereby they discovered that people spend most of their time in apps in the  X  X ames, X   X  X ocial networking, X  and  X  X ntertainment X  genres across iOS and Android devices.
 Finally, we also observe that our results of the top GTB features in Fig. 3 coincide with another set of findings from Flurry Analytics, ComScore, and Net-MarketShare 8 . For instance, the significant chunks that relate to genres ( i.e. ,  X  X ames, X   X  X ntertainment, X  and  X  X ocial messaging X ) coincide with our genre labels shown in Fig. 3 . Additionally, the  X  X acebook X  and  X  X witter X  chunks also coincide with the  X # of Facebook likes X  and  X # of Twitter followers X  features in Fig. 3 , which suggests that apps with a strong presence on these two popu-lar social networks have a tendency to be spotted and subsequently consumed, making them popular candidates to be recommended. The data from the alter-nate user studies (See footnotes 7 and 8) demonstrates a strong correlation with our GTB feature component analysis shown in Fig. 3 . It indicates how two disci-plines ( i.e. , user studies and GTB feature component analysis) from two different sources of opinions and quantitive angles managed to arrive at similar findings. This further suggests a future direction in mobile app recommendation whereby more focus could be placed in user and trend analysis through social networks  X  a direction that deviates from traditional research in recommender systems. Given that different recommendation techniques work in different settings, we need to evaluate a method for integrating the various sources of information into a hybrid model that can recommend a set of apps to a target user. To achieve this, we have proposed incorporating the user X  X  prior history, app metadata, and the recommendation scores of various individual recommendation techniques into a hybrid recommendation model for app recommendation. We then used gradi-ent tree boosting (GTB) as the core of the unifying framework to integrate the recommendation scores by using user features and app metadata as additional features for the decision tree. Experimental results show that the unifying frame-work achieves the best performance against individual state-of-the-art baselines. We also performed a series of in-depth analysis through ablation studies, and demonstrated how different pieces of evidences (such as Twitter and version information) that, when available, could be utilized sufficiently, and how the unifying model dynamically alters the recommendation based on available sig-nals. Finally, we discovered an interesting correlation between important feature components in our unifying framework and user analysis from third-party data analytics companies, which further suggests a future direction in mobile app recommendation, where more focus could be placed in user and trend analysis via social networks.

