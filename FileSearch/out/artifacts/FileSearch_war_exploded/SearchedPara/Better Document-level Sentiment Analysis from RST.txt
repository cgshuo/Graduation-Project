 Sentiment analysis and opinion mining are among the most widely-used applications of language technology, impacting both industry and a vari-ety of other academic disciplines (Feldman, 2013; Liu, 2012; Pang and Lee, 2008). Yet senti-ment analysis is still dominated by bag-of-words approaches, and attempts to include additional linguistic context typically stop at the sentence level (Socher et al., 2013). Since document-level opinion mining inherently involves multi-sentence texts, it seems that analysis of document-level structure should have a role to play.

A classic example of the potential relevance of discourse to sentiment analysis is shown in Fig-ure 1. In this review of the film The Last Samu-rai , the positive sentiment words far outnumber the structure  X  indicated here with Rhetorical Struc-ture Theory (RST; Mann and Thompson, 1988)  X  Figure 1: Example adapted from Voll and Taboada (2007). clearly favors the final sentence, whose polarity is negative. This example is illustrative in more than one way: it was originally identified by Voll and Taboada (2007), who found that manually-annotated RST parse trees improved lexicon-based sentiment analysis, but that automatically-generated parses from the SPADE parser (Soricut and Marcu, 2003), which was then state-of-the-art, did not.

Since this time, RST discourse parsing has im-proved considerably, with the best systems now yielding 5-10% greater raw accuracy than SPADE, depending on the metric. The time is therefore right to reconsider the effectiveness of RST for document-level sentiment analysis. In this pa-per, we present two different ways of combin-ing RST discourse parses with sentiment analy-sis. The methods are both relatively simple, and can be used in combination with an  X  X ff the shelf X  discourse parser. We consider the following two architectures:  X  Reweighting the contribution of each dis- X  Recursively propagating sentiment up
Both architectures can be used in combination with either a lexicon-based sentiment analyzer, or a trained classifier. Indeed, for users whose start-ing point is a lexicon-based approach, a simple RST-based reweighting function can offer signif-icant improvements. For those who are willing to train a sentiment classifier, the recursive model yields further gains. 2.1 Rhetorical Structure Theory RST is a compositional model of discourse struc-ture, in which elementary discourse units (EDUs) are combined intro progressively larger discourse units, ultimately covering the entire document. Discourse relations may involve a nucleus and a satellite , or they may be multinuclear . In the ex-ample in Figure 1, the unit 1 C is the satellite of a relationship with its nucleus 1 B ; together they form a larger discourse unit, which is involved in a multinuclear CONJUNCTION relation.

The nuclearity structure of RST trees suggests a natural approach to evaluating the importance of segments of text: satellites tend to be less important, and nucleii tend to be more impor-tant (Marcu, 1999). This idea has been leveraged extensively in document summarization (Gerani et al., 2014; Uz  X  eda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential re-lations, eliminating all words except those in the top-most nucleus within each sentence. More re-cent work focuses on reweighting each discourse unit depending on the relations in which it partic-ipates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and com-pare it with a compositional method, in which sen-timent polarity is propagated up the discourse tree.
Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a re-cent spike of interest in this task, with contempo-rary approaches employing discriminative learn-ing (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisen-stein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publicly-To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shift-reduce parser (Sagae, 2009), and its time complex-ity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analy-sis (Pang and Lee, 2008; Liu, 2012), with partic-ular interest in determining the overall sentiment polarity (positive or negative) of a document. Bag-of-words models are widely used for this task, as they offer accuracy that is often very competitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis de-pends on having training data in the same domain as the target, and this is not always possible. More-over, in social science applications, the desired labels may not correspond directly to positive or negative sentiment, but may focus on other cat-egories, such as politeness (Danescu-Niculescu-Mizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emo-tions (Kim et al., 2012). In these cases, labeled documents may not be available, so users of-ten employ a simpler method: counting matches against lists of words associated with each cate-gory. Such lists may be built manually from intro-spection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Al-ternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to Figure 2: Dependency-based discourse tree repre-sentation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness. 2.3 Datasets We evaluate on two review datasets. In both cases, the goal is to correctly classify the opinion po-larity as positive or negative. The first dataset is comprised of 2000 movie reviews, gathered by Pang and Lee (2004). We perform ten-fold cross-validation on this data. The second dataset is larger, consisting of 50,000 movie reviews, gath-ered by Socher et al. (2013), with a predefined 50/50 split into training and test sets. Documents are scored on a 1-10 scale, and we treat scores  X  4 as negative,  X  7 as positive, and ignore scores of 5-6 as neutral  X  although in principle nothing prevents extension of our approaches to more than two sentiment classes. Our first approach to incorporating discourse in-formation into sentiment analysis is based on quantifying the importance of each unit of text in terms of its discourse depth. To do this, we em-ploy the dependency-based discourse tree (DEP-DT) formulation from prior work on summariza-tion (Hirao et al., 2013). The DEP-DT formal-ism converts the constituent-like RST tree into a directed graph over elementary discourse units (EDUs), in a process that is a close analogue of the transformation of a headed syntactic constituent parse to a syntactic dependency graph (K  X  ubler et al., 2009).
 The DEP-DT representation of the discourse in Figure 1 in shown in Figure 2. The graph is con-structed by propagating  X  X ead X  information up the RST tree; if the elementary discourse unit e i is the satellite in a discourse relation headed by e j , then there is an edge from e j to e i . Thus, the  X  X epth X  of each EDU is the number of times in which it is embedded in the satellite of a discourse relation. The exact algorithm for constructing DEP-DTs is given by Hirao et al. (2013).

Given this representation, we construct a simple linear function for weighting the contribution of the EDU at depth d i : Thus, at d i = 0 , we have  X  i = 1 , and at d i  X  3 , we have  X  i = 0 . 5 . Now assume each elementary dis-course unit contributes a prediction  X  i =  X  &gt; w i , where w i is the bag-of-words vector, and  X  is a vector of weights, which may be either learned or specified by a sentiment lexicon. Then the overall prediction for a document is given by, Evaluation We apply this approach in combi-nation with both lexicon-based and classification-based sentiment analysis. We use the lexicon of Wilson et al. (2005), and set  X  j = 1 for words marked  X  X ositive X , and  X  j =  X  1 for words marked negative. For classification-based analysis, we set  X  equal to the weights obtained by training a logis-tic regression classifier, tuning the regularization coefficient on held-out data.

Results are shown in Table 1. As seen in the comparison between lines B1 and D1, dis-course depth weighting offers substantial improve-ments over the bag-of-words approach for lexicon-based sentiment analysis, with raw improvements of 4  X  5% . Given the simplicity of this approach  X  which requires only a sentiment lexicon and a dis-course parser  X  we strongly recommend the ap-plication of discourse depth weighting for lexicon-based sentiment analysis at the document level. However, the improvements for the classification-based models are considerably smaller, less than 1% in both datasets. Discourse-depth reweighting offers significant im-provements for lexicon-based sentiment analy-sis, but the improvements over the more accurate classification-based method are meager. We there-fore turn to a data-driven approach for combining sentiment analysis with rhetorical structure theory, based on recursive neural networks (Socher et al., Baselines B1. Lexicon 68.3 74.9 B2. Classifier 82.4 81.5 Discourse depth weighting D1. Lexicon 72.6 78.9 D2. Classifier 82.9 82.0 Rhetorical recursive neural network R1. No relations 83.4 85.5 R2. With relations 84.1 85.6 Table 1: Sentiment classification accuracies on two movie review datasets (Pang and Lee, 2004; Socher et al., 2013), described in Section 2.3. 2011). The idea is simple: recursively propagate sentiment scores up the RST tree, until the root of the document is reached. For nucleus-satellite dis-course relations, we have: where i indexes a discourse unit composed from relation r i , n ( i ) indicates its nucleus, and s ( i ) in-dicates its satellite. Returning to the example in Figure 1, the sentiment score for the discourse unit obtained by combining 1 B and 1 C is obtained Similarly, for multinuclear relations, we have, In the base case, each elementary discourse unit X  X  sentiment is constructed from its bag-of-words,  X  i =  X  ument is different, the network architecture varies in each example; nonetheless, the parameters can be reused across all instances.

This approach, which we call a Rhetorical Re-cursive Neural Network (R2N2), is reminiscent of the compositional model proposed by Socher et al. (2013), where composition is over the constituents of the syntactic parse of a sentence, rather than the units of a discourse. However, a crucial differ-ence is that in R2N2s, the elements  X  and K are scalars : we do not attempt to learn a latent dis-tributed representation of the sub-document units. This is because discourse units typically comprise multiple words, so that accurate analysis of the sentiment for elementary discourse units is not so difficult as accurate analysis of individual words. The scores for individual discourse units can be computed from a bag-of-words classifier, or, in fu-ture work, from a more complex model such as a recursive or recurrent neural network.

While this neural network structure captures the idea of compositionality over the RST tree, the most deeply embedded discourse units can be heavily down-weighted by the recursive compo-sition (assuming K s &lt; K n ): in the most ex-treme case of a right-branching or left-branching structure, the recursive operator may be applied N times to the most deeply embedded EDU. In con-trast, discourse depth reweighting applies a uni-form weight of 0 . 5 to all discourse units with depth  X  3 . In the spirit of this approach, we add an addi-tional component to the network architecture, cap-turing the bag-of-words for the entire document. Thus, at the root node we have: with  X  rst-root defined recursively from Equations 3 and 4,  X  indicating the vector of per-word weights, and the scalar  X  controlling the tradeoff between these two components.
 Learning R2N2 is trained by backpropagating from a hinge loss objective; assuming y t  X  { X  1 , 1 } for each document t , we have the loss L t = (1  X  y t  X  doc ,t ) + . From this loss, we use backpropagation through structure to obtain gradients on the parameters (Goller and Kuch-ler, 1996). Training is performed using stochas-tic gradient descent. For simplicity, we fol-low Zirn et al. (2011) and focus on the dis-tinction between contrastive and non-contrastive relations. The set of contrastive relations in-Evaluation Results for this approach are shown in lines R1 and R2 of Table 1. Even without dis-tinguishing between discourse relations, we get an improvement of more than 3% accuracy on the Stanford data, and 0 . 5% on the smaller Pang &amp; Lee dataset. Adding sensitivity to discourse rela-contrastive relations) offers further improvements on the Pang &amp; Lee data, outperforming the base-line classifier (D2) by 1.3%.

The accuracy of discourse relation detection is only 60% for even the best systems (Ji and Eisen-stein, 2014), which may help to explain why re-lations do not offer a more substantial boost. An anonymous reviewer recommended evaluating on gold RST parse trees to determine the extent to which improvements in RST parsing might trans-fer to downstream document analysis. Such an evaluation would seem to require a large corpus of texts with both gold RST parse trees and sentiment polarity labels; the SFU Review Corpus (Taboada, 2008) of 30 review texts offers a starting point, but is probably too small to train a competitive senti-ment analysis system. Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intra-sentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is re-lated to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the dis-course structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level pre-diction. None of the prior work considers the sort of recurrent compositional model presented here.
An alternative to RST is to incorporate  X  X hal-low X  discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentence-level sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sen-timent flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a fea-ture (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse rela-tions within sentences and between adjacent sen-tences can be viewed as complementary to our fo-cus on higher-level discourse relations across the entire document.

There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) dataset, but neither of their results are directly comparable: Heerschop et al. (2011) exclude doc-uments that SPADE fails to parse, and Wachsmuth et al. (2014) evaluates only on individual sentences rather than entire documents. The only possi-ble direct comparison is with very recent work from Hogenboom et al. (2015), who employ a weighting scheme that is similar to the approach described in Section 3. They evaluate on the Pang and Lee data, and consider only lexicon-based sentiment analysis, obtaining document-level ac-curacies between 65% (for the baseline) and 72% (for their best discourse-augmented system). Ta-ble 1 shows that fully supervised methods give much stronger performance on this dataset, with accuracies more than 10% higher. Sentiment polarity analysis has typically relied on a  X  X reponderance of evidence X  strategy, hop-ing that the words or sentences representing the overall polarity will outweigh those representing counterpoints or rhetorical concessions. How-ever, with the availability of off-the-shelf RST dis-course parsers, it is now easy to include document-level structure in sentiment analysis. We show that a simple reweighting approach offers robust advantages in lexicon-based sentiment analysis, and that a recursive neural network can substan-tially outperform a bag-of-words classifier. Future work will focus on combining models of discourse structure with richer models at the sentence level.
