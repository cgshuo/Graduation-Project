 Database designers construct schemas with the goal of accurately reflecting the environment modeled by the database system. The resulting schema is assumed to be stable enough to remain valid even as the modeled environment changes. However, in practice, data models are not nearly as stable as commonly assumed by the database designers. As a result, modifying the database schema is a common, but often troublesome, occurrence in database administration. These are significant industrial concerns, both from the viewpoint of database system manufacturers and information system users. Schema evolution, and its stronger companion, schema versioning, have have been amended. A more formal definition of schema evolution is the ability for a database schema to evolve without the loss of existing information [1]. Motivating Example. To better motivate the need for schema evolution support, we running example in the rest of the paper. Fig. 1 outlines our example, which has three schema versions, V 1 through V 3 . 
Due to a new government regulation, the company is now required to store more employees X  personal profiles from their bu siness-related information to ensure the privacy. For these reasons, the database layout was changed to the one in version V 2 , Personal, storing the personal information about the employees, and Employees, maintaining business-related information about the employees. 
The company chose to change its co mpensation policy: to achieve  X  X air X  compensation and to better motivate employees, the salaries are made dependent on their individual performance, rather than on their job titles. To support this, the salary modification was also introduced that the firs t name and last name are now stored in two different columns to simplify the surname-based sorting of employees. These changes were represented as the last schema version, V 3 . 
Assume that a department works for a project, and view E_P is used to correlate the employees with the projects they work for. On top of this view, we consider that the report module contains an aggregate query that calculates the expenses of the compare them with the budget of the project. Along with the evolution of the schema, the view E_P becomes unavailable. How to effectively keep the application available is our object. Contribution. Our main contributions in this paper are summarized as follows. 1. A novel on-demand schema evolution approach based on virtual views (named as on-demand approach) is proposed, which only deals with the schemas effected by the schema evolution and preserves the new data instead of the version data. 2. Subsequently we construct view version with mapping inversion, which can recover all the source information with complementary approach. 3. Next, an optimization algorithm is presented to improve application/queries efficiency. 4. At last, we have performed comprehensive experiments to compare our approach with traditional database schema evolution techniques, which show that our approach achieves remarkable improvement in efficiency. The remainder of this paper is organized as follows: Section 2 discusses related works, Section 3 introduces preliminary definitions, Section 4 discusses in details the design of our schema evolution method, Section 5 is dedicated to experimental results. We conclude in Section 6 where we also state our future work. Schema evolution means modifying schemas within a database without loss of existing data. With the acceleration of database schema modification frequency of Internet and enterprise, database schema evolution becomes a hotspot in current implemented manually. 
Schema evolution has been extensively addressed in the past and a variety of techniques have been proposed to execute change in the least erratic way possible to avoid disruption of the operation of the database. A bibliography on schema evolution can be categorized mainly by following one of these approaches: modification, versioning and views. Modification. The original schema and its corresponding data are replaced by a new schema and new data. This approach does not exactly adhere to the schema evolution definition, which makes the applications that use the original schemas inconsistent with the new database schemas [3]. This renders the approach unsuitable in most real cases, yet it remains the most popular with existing DBMS. In [4], the authors discuss extensions to the conventional relation algebra to support both aspects of evolution of a database X  X  contents and evolution of a database X  X  schema. In [5], authors present an approach to schema evolution through changes to the ER schema of a database. In [6], been performed. Versioning. The old schema and it corresponding data are preserved and continued to be used by existing applications, but a new version of the schemas is created, which incorporates the desired changes [7]. There are two most used versioning methods. The first is sequential revisions, which consists of making each new version a modification of the most recent schema. This approach is adopted in Orion Database For instance, Encor Database System[9]. Ge nerally, the versioning approach presents performance problems. View. A view is a derived table. It makes possible to change the schema without Bellahsene [10] proposes a method that uses view to simulate the schema changes and the data migration is not needed, i.e., views are viewed as the target schema. However, this method has scalability limitations. In fact, after several evolution steps, the applications/queries may involve long chains of views and thus deliver poor performance. Moreover, it is difficult to change current schema. 
In [11], the authors deal with the adaption of the view definition in the presence of aspect of the view adaptation problem. The wo rk of [14] employs a directed graph for representing the object dependencies in O-O database environments and finding the impact of changes in database objects towards application objects. 
As of today, in [15], the authors tend to extend the work of [16]. They first consider a set of evolution changes occurring at the schema of a data warehouse and provide an informal algorithm for adapti ng affected queries and views to such changes. The most representative achievement is PRISM developed by Curino. One contribution of the work on PRISM is a language of Schema Modification Operator. Meanwhile, automatic query rewriting of queries specified against schema version N into semantically equivalent queries against schema Version N+1 , and vice versa [17]. SMOS have a good semantic express for schema evolution, but still has some limitations. infinite set Const of constants and a countably infinite set Var of labeled nulls that is ( v An instance is often identified with its set of facts. and T . M is semantically identified with the binary relation: Here, S i is the instance of source schema and T i is the instance of target schema. We will  X  ; furthermore, we will sometimes define schema mappings by simply defining the set of ordered pairs (I, J) that constitute M (instead of giving a set of constraints that specify M). If (I, J)  X  M, we say that J is a solution of I (with respect to M). paper, we will focus on schema mappings specified by source-to-target tuple-generating dependencies. 
An atom is an expression of the form R ( x 1 ,..., x n ). A source-to-target tuple-generating dependency (s-t tgd) is a first-order sentence of the form as follow: where  X  ( x ) is a conjunction of atoms over S , each variable in x occurs in at least one above formula. Another name for S-T tgds is global-and-local-as-view (GLAV) constraints. They contain GAV and LAV constraints, which we now define, as important special cases. 
A GAV (global-as-view) constraint is an S-T tgd in which the right-hand side is a following equation: where P ( x ) is an atom over the target schema. A LAV (local-as-view) constraint is an following equation: where Q ( x ) is an atom over the source schema. In this section we will discuss the details of our on-demand approach (supporting backward compatibility) and the optimization of our approach. Here, the mappings between source schema and target schema are expressed by the S-T tgds. A main requirement for database schema evolution management is thus to propagate the schema changes to the instance, i.e., to execute instance migration correctly and efficiently. S-T tgds represent the semantics of conversion from source schema instance to target schema instance. The S-T tgds can express both simple changes, such as addition, modification or deletion of individual schema constructs, and complex changes refer to multiple simple changes. The converted semantics of S-T tgds can automatically execute instance migration from source schemas to target schemas with the change of schemas. 4.1 Our On-Demand Approach In our approach, the original schema and its corresponding data are not preserved. To reuse the legacy applications/queries, we must support backward compatibility. Here, virtual versions (view version) are proposed to support backward compatibility, which times the evolution operation only involves several tables. We create views not for all the tables but only for the tables evolved. schema version S represents an initial (legacy) schema that goes through mapping M forming target schema version T . The instances migrate automatically through conversion (chase). In order to save memory space and improve performance, we with the deleted schema to realize the backward compatibility. Applications deal with views the same way they deal with base tables. Supporting different explicit view created through mapping M  X  , which is obviously the mapping inverse of M . 
The most important thing is to calculate the inverse of mapping M . The ideal goal for schema mapping inversion is to be able to recover the instances of source schema. Concretely, if we apply the mapping M on some source instances and then the inverse applying a schema mapping M to an instance means generating the instance by chase. However, a schema mapping may drop some of the source information, and hence it is not possible to recover the same amount of information. 
The example of the scenario described in Fig. 3(a) illustrates the schema evolution process with information loss. Consider the following two schema versions V 2 and V 3 in Fig. 1, where V 2 consists of two relation symbols Employees and Job, and schema V consists of one ternary relation symbol Employees that associates each employee with salary and title. Given existing the schema mapping M 23 =( V 2 , V 3 ,  X  23 ), where The nature  X  X nverse X  that one would expect here is the following mapping: Here, we verify whether mapping  X  23 can recover instances of source schema versions V . If we start with a source instance I for schema V 2 where the source tuples contain some constant values, and then apply the chase with mapping  X  23 and then the reverse equivalent to the original instance I . To give a concrete example, consider the source instance I over version V 2 that is shown in Fig. 3. 
Schema version V 2 could not be created from V 3 by mapping  X  32 . In our approach separate table is established for the lost data. In Fig. 3(b), the red rectangle represents only when computing mapping inverstion and evolution rollback. The special table cannot be modified. The inversion of mapping  X  23 can be expressed as  X  + 32 . Mapping  X  + 32 can completely recover the instances of source schema versions. The structure of old schema versions can be co rrectly described by views that are created by mapping  X  + 32 . We present the algorithm for calculating the views of old schema in the following. 
First, we determine whether there is information loss before schema evolving. If and modify the mapping M  X  . The operator of SUPPLEMENT() aims to modify the mapping M without information loss. Here, data migrate is automatically executed with chase algorithm. We compute inversion of full mapping M and generate the view concept with the operator VIEW CREATE(). can be computed by operator INVERS(). We get the mapping M -1 , which can compute the views that describe the old schema. The views concepts are computed through mapping M -1 . 4.2 Optimized Approach In on-demand approach, we support backwa rd compatibility to reuse the legacy applications and queries by creating virtual version. But it has scalability limitations. chain of views and thus deliver poor performance. Fig. 5 shows the limit of our na X ve approach. Schema version S 1 ,..., S n represents each version in the progress of schema evolution. S n is the current schema version, then the other schema versions are represented by views. The old schema versions connect with existing schema version through long views chains, e.g., schema version S 1 is mapped into schema version S n Fig. 5 shows, we hope that each view version would have been directly mapped into schema version S n , rather than through the intermediate steps. So the implementation of applications/queries could not operate physic data through long views chains. Mapping composition is a good choice. 
We do not preserve the data of old schema version. The mappings created by schema version matching are not accurate and cannot reflect the semantic of schema evolution process. In this paper, we compute the views concepts directly from existing schema version by mapping composition. The algorithm of view mapping composition is given in the following. 
Here, we illustrate the computed progress of our optimized method with an concrete example of schema evolution. We also use employees database as our example. Mapping  X  21 is the relation between version V 2 and V 1 . The view mapping from V 3 to V 2 is  X  32 . Employees and Personal in  X  21 by relation symbols from that use the GAV S-T tgds of  X  arrive at an intermediate tgd shown in the following. otherwise unintended join with Personal, which also contains the variable S . We then specify the composition of  X  32  X   X  21 .  X 
We can get the view concept directly from schema V 3 through view mapping  X  proposed approach for schema evolution. Table 1 describes our experimental environment. The data-set used in these experiments is obtained from the schema evolution benchmark of [17] and consists of actual queries, schema and data derived from Wikipedia. We also do some experiments on the actual database data-set. 
Now approaches for schema evolution management mostly base on version management. We get the data of wikipadia from 2009-11-3 to 2012-03-7. The size of data grows from 31.2GB to 57.8GB. If we use versioning approach to manage the schema evolution, we must spent 1056.7GB memory space to store all versions of wikipadia from 2009-11-3 to 2012-03-7. However, our approach only needs to store the existing version, i.e., 57.8GB. 
We evaluate the effectiveness of our approach with the following two metrics: (1) overall percentage of queries supported, and (2) the applications/queries running time. To make comparison with the PRISM, we use the same data-set obtained from the schema evolution of [17]. Support for Backward Compatibility. An important measure of performance of our system is the percentage of queries supported by the old version. To this purpose we select the 66 most common query templates designed to run against version 28 of the Wikipedia schema and execute them against every subsequent schema version. The overall percentage of queries supported is computed by the following formulas. 
Fig.7 provides a graphical representation of the percent of queries supported for the various schema evolution approaches. Our approach can fully automatically realize the backward compatibility without rewriting queries. The original queries, failing when columns or tables are modified, highlig ht the portion of the schema affected by represents the original queries shows how the schema evolution invalidates at most 82%of the schema. For PRISM, in the last version, about 26% of the queries fail due last version, which is very close to user rewritten query shown by green curve. Obviously, our approach effectively cures a wide portion of the failing input queries. Run-time Performance . Here we focus on the response time of queries that represents one of the many factors determining the usability of our approach. We make a statistic for the query rewrite times of PRISM, the average of the query rewrite time for PRISM is 26.5s. 
Since we cannot get the dataset of the PRIMS, we could not do the experiment to employees with 5 versions to compare the effectiveness of our approach with traditional view approach[10]. The database consists of approximately 500,000 tuples for about 1.3Gb of data. We selected 10 queried operated on the employees database, the response times of them are shown in Fig. 8: (1) traditional represents the approach with traditional view version; (2) on-demand is our on-demand approach; (3) response times of traditional approach and our naive approach grows with schema optimized method has outperformed traditional approach and our na X ve approach. In this paper, we present a novel approach for schema evolution, which supports the backward compatibility. Traditionally, database schema evolution management is conducted by versioning, which generates high costs and requires much memory space. Such a time and space consuming approach severely limits the usability and convenience of the databases. 
We exploit the virtual version approach which supports the applications/queries of old schemas. Our optimization for the virtual version makes our approach low time-consuming and high scalability. Both analysis and experiments verify the better that others schema evolution approach. 
Despite recent progress we therefore see a need for substantially more research on schema evolution. For example, distributed architectures with many schemas and mappings need powerful mapping and evolution support, e.g., to propagate changes of a data source schema to merged schemas. New challenges are also posed by dynamic settings such a stream systems where the data to be analyzed may change its schema. Acknowledgement. The National Natural Science Foundation of China (Grant No. 60973021, 61003060), and the Fundamental Research Funds for the Central Universities (N100704001). 
