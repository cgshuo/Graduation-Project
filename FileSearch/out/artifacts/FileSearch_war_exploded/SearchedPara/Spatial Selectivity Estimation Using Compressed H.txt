 Most of database management systems (DBMS) use summary data for efficient proc-essing of a query. The summary data consists of paired attribute values and frequen-cies, which implicitly represent the data distribution for attribute value of records stored in the database. With the recent dramatic increase in the scale of the database, the significance of the summary data has further intensified. 
Especially, for estimating selectivity of spatial query, the summary data can be generated by histogram methods using spatial partitioning, graphic theory, dimension transformations, and trees. Among these methods, the spatial histogram is the sim-plest method, which preserves the buckets produced by spatial partitioning to be ad-justed under any circumstances. Various histograms that have thus far been proposed in the field display the variety of performance according to bucket partitioning meth-ods and the information kept within the buckets[1,3,6,8]. 
Also recent advancements in computing an d mobile technology make it possible to provide information services on the user X  X  position and geography using small size database, thus the importance, in practical as well as in theoretical aspects, of selectiv-ity estimation method for small database is on the increase. However, the existing methods are capable of producing good selectivity estimation only when sufficient memory space is available. If such methods are used in given small memory capacity, good selectivity cannot be obtained. 
In this paper we propose a compressed histogram called MW histogram that yields a good selectivity estimation using a small space. This method exploits the spatial properties which allocate more buckets to place with more spatial distribution, and ensure each bucket to have uniform density. The proposed histogram method is de-signed to maintain summary data using a small space that results from compression of these partitioned buckets. 
The rest of this paper is organized as follows. In the next section we summarize re-lated work. The proposed structure of MW Histogram is presented in section 3. In section 4 we describe the strengths and weakness of the proposed method through experiments. Finally, we draw conclusions and give a future work in Section 5. Selectivity estimation is a well-studied problem for traditional data types such as integers. Histograms are the most widely used form for doing selectivity estimation in relational database systems. Many different histograms have been proposed in the literature and some have been deployed in commercial DBMSs. In case of selectivity estimation in spatial databases, some techniques for range queries have been proposed in the literature[2,4,5,7]. 
In [2], Acharya et. al. proposed the MinSkew algorithm. The MinSkew algorithm starts with a density histogram of the dataset, which effectively transforms region objects to point data. The density histogram is further split into more buckets until the given bucket count is reached or the sum of the variance in each bucket cannot be reduced by additional splitting. In result, the MinSkew algorithm constructs a spatial histogram to minimize the spatial-skew of spatial objects. The CD (Cumulative Den-sity) histogram is proposed in [5,7]. Typically when building a histogram for region objects, an object may be counted multiple times if it spans across several buckets. The CD algorithm address this problem by keeping four sub-histogram and store the number of corresponding corner points that fall in the buckets, so even if a rectangle spans several buckets, it is counted exactly once in each sub-histogram. The Euler Histogram is proposed in [4]. The mathematical foundation of the Euler Histogram is based on Euler X  X  Formula in graph theory. As in the CD Histogram, Euler Histogram also addresses the multiple-count problem. 
Though these techniques are efficient methods to estimate selectivity in spatial da-tabases, these techniques require a large amount of memory for better accuracy. 
To compress the summary information in conventional databases, in [1] Matias et al. introduce a new type of histograms, called wavelet-based histograms, based upon multidimensional wavelet decomposition. Wavelet decomposition is performed on the underlying data distribution, and most significant wavelet coefficients are chosen to compose the histogram. In other words, the data points are compressed into a set of numbers via a sophisticated multi-resolutio n transformation. Those coefficients con-stitute the final histogram. For estimating the selectivity for spatial query using small memory space, the pro-posed MW histogram is constructed by through the spatial partitioning and wavelet transformation stage. 3.1 Spatial Partitioning The partitioning of space is conducted by using spatial density and spatial skew. Spa-tial density refers to an elementary function h among the partitioning function MF , skewness corresponds to a weight function g , and is computed by the statistical proc-fined as a combination of the following functions ( MF = f-g-h ). 
This partitioning function MF makes the spatial skewness of each partitioned bucket as small as possible. Fig.1 shows the process of the spatial split. First, the spatial frequency inside the grid cell is obtained using the function h. Second, compute the axis skew by applying function g to each axis after calculating cumulative spatial frequency abstracted in each axis. Third, choose the bucket and axis that has the maximum skew using the elementary function h, and then partition until the skew of the divided bucket is at its lowest level. Finally, generate split node 1 possessing the partitioning information and extrapolate into the binary split tree. Follow-ing these steps, repeat the process until a desired number of buckets is generated. 3.2 Wavelet Transformation If all process of the split terminate, generate the gird cell with elementary resolution r, and establish the value of each grid cell after applying the summary function TF . The summary function will produce the output value, counting the number of objects with the center of the spatial object included in lattice c i,j . Summary function is defined as follows: 
Next step is to wavelet transform the grid that exists inside the domain that each bucket occupies. In this process, one dimensional wavelet transformation is applied in MW histogram. 
First procedure is to transform two dimensional grid of a bucket into one dimen-sional grid. This process is accomplished using a space-filling order method. When close to 0, increasing the compression effects further. As shown in Fig.2, the search similar values in the direction of the split axis will be distributed more likely, it can be said to be an efficient compression method because it has many coefficients with automatic 0 values. Fig 2(b) is an error tree for wavelet transformation of single bucket. Second procedure is to shrink wave let coefficients. In order to choose wavelet coefficients retained, we use a deterministic threshold with simple computations, while effectively minimizing the total error. The number of wavelet coefficients pre-limited storage space. When the number of buckets needed is determined using Equa-tion 5, the wavelet coefficients that are maintained on average can be found. How-ever, if all buckets preserve average number of wavelet coefficients, it may generate much error, because the skewness of each bucket is different, and the size of the oc-cupied space is also different, a number of coefficients excepts those with 0 are quite different. For buckets with large occupied space size and high spatial skewness, aver-age square error of the removed wavelet coefficients increases. Thus, if a given query intersects with this bucket space, the selectivity error rate increases. On the other hand, a bucket that occupies small space and has skewness close to 0 results in wast-ing of the storage space. Thus, we set differently the number of the coefficients pre-served in each bucket. If the skewness is cl ose to 0, the spatial frequency of grid cell becomes consistent. Therefore, even if we use the least number of coefficients, a low lowing equation ( coeff_size is the total number of preserved coefficients): In this section, we compare MW histogram with MinSkew histogram and use the 11,000 building data in JoongGu, Seoul, Korea as the experimental data. Also we changed storage space to 60~720 units as an experimental parameter, and the size of the query to 5%~20% of the total space. Finally, to evaluate the relationship between the number of buckets and the number of wavelets, we produced MW histogram with the required number of buckets and the size of the storage space. MW0~MW2 is a histogram that makes preserved number of the buckets be {0.3, 0.5, 0.7} * M/6, proposed method, we compared MinSkew histogram with 360 storage space with MW histogram, MW0~MW2 with 180 storage space. 
As shown in Fig.4, MW0~MW2 has relatively lower than or similar to MinSkew histogram despite the storage space being half the size. We can see that the size of the relative error to the large size of the query is similar in MW0 through the experimen-tal results. Also, in case of MW1, the larger the query, the lesser the relative error. On the other hand, MW2 has higher error than MW0 and MW1 in 20% of query. The probability of false counting is high, resulting in higher error. But, MW0, in which preserved wavelet coefficient is big, reduces the probability of false counting because it stores efficiently as compressing the distribution information inside each bucket into wavelet summary data. The big size query includes completely one bucket, or most buckets, so that it can get more accurate selectivity. This result implies that the designed MW histogram can solve the problem of distributional skewness in a rela-tively large bucket space, even in the case where the spatial domain is big, or the restriction to the storage space is severe. 
Fig.4 (a) and (b) show the average relative error of MW0~MW2 according to the storage space in 5% and 20% query. In Fig.4 (a), since the intersecting number of result demonstrates that MW histogram can maintain more information even with small storage space. The relative error curve in 20% query of Fig.4 (b) shows a big change as the size of the storage space increases. Especially, MW histogram in 60 storage space has lower error than the relative error of the MinSkew histogram. MW0, in which the number of wavelet coefficients preserved per bucket are big, has lower error than other histogram. That is, the bigger the number of preserved wavelet coef-ficients, the better selectivity we can get even with small storage space. Selectivity estimation is used in query optimization and decision of optimal access path cardinally. The existing works for spatial selectivity estimation have been fo-cused on obtaining high accuracy and fast response time. However, they require very large memory space to maintain high accuracy of selectivity if spatial domain is also large. Therefore, we proposed a new method called MW histogram that could get reasonable selectivity with small memory size. Based on our experimental analysis, we showed that the proposed technique can obtain maximum compression effects and reasonable selectivity simultaneously. 
In the future, we need to analyze our histogram to improve much experimental evalua-tion. We also will extend our histogram to do work easily about dynamic insertion. 
