 In domains such as Marketing, Advertising or even Human Resources (sourcing), decision-makers have to choose the most suitable channels according to their objectives when starting a campaign. In this paper, three recommender sys-tems providing channel ( X  X ser X ) ranking for a given cam-paign ( X  X tem X ) are introduced. This work refers exclusively to the new item problem, which is still a challenging topic in the literature. The first two systems are standard content-based recommendation approaches, with different rating es-timation techniques (model-based vs heuristic-based). To overcome the lacks of previous approaches, we introduce a new hybrid system using a supervised similarity based on PLS components. Algorithms are compared in a case study: purpose is to predict the ranking of job boards (job search web sites) in terms of ROI (return on investment) per job posting. In this application, the semi-supervised hybrid sys-tem outperforms standard approaches.
 H.3.1 [ Content Analysis and Indexing ]: Indexing meth-ods; I.2.6 [ Learning ]: Knowledge acquisition Algorithms, Experimentation Recommender systems, feature extraction, PLS, channels
With the expansion of internet to advertise, the number of potential channels (and targets) is exponentially grow-ing. Today, a great challenge common to several research domains is the development of intelligent tools to support (or to replace) users in their choices. In this context, we are introducing algorithms which aim at providing a rank-ing of channels according to the expected ROI, in order to help decision-makers to identify the best channels. To do that, we resort to an innovative application of recommender system, in which items are assumed to be campaigns, users are assumed to be channels, and ratings are assumed to be observed returns of campaigns on channels. The type of recommender studied is very specific: since each campaign is different, we don X  X  have any explicit preference on items of interest. Consequently, traditional collaborative methods are excluded: we have to face to item cold-start problem, which is still a challenging topic in the literature. In order to simplify and to compare the effectiveness of algorithms on high dimensional data, items are only described by tex-tual data. Background is presented in Section 2. Algorithms and performance indicators are described in Section 3. Sec-tion 4 is dedicated to a case study: identify the most effective sourcing channels to support recruiters in their choice.
As previously mentioned, campaigns are characterized by a text. To extract a set of features from the text we will use several common techniques in Information Retrieval and compare them. First, we use the well-known Vector Space Model in order to obtain a vector of term frequencies for each campaign. To improve text representation we will use TF-IDF weighting, which decreases weights of keywords ap-pearing in many documents and not useful to distinguish a relevant document from an irrelevant one. After weighting, documents will be indexed by Latent Semantic Analysis, a dimensionality reduction technique through a singular value decomposition of term-document matrices [4].
Recommender systems are usually classified into three main categories: content-based recommendations, collabo-rative recommendations, and hybrid approaches [1]. The first approach proposed is a content-based algorithm which recommendation technique is based on a model (PLS regres-sion, see 2.3). The second approach uses a heuristic-based recommendation technique (computing of a feature-based similarity measure) in a content-based approach. In addi-tion to these two basic approaches, we introduce a hybrid recommender (output produced by a content-based model is used as an input in a collaborative approach) based on a heuristic technique to estimate ratings. Hybridization strat-egy used is the same as in [5] or [2], also called  X  X ollaboration through content X .
Partial Least Squares Regression (PLS-R), introduced by [9], is a technique that generalizes and combines features from principal component analysis and multiple regression. This method is used when the number of predictors is large, and also large compared to the number of observations. The higher the number of predictors is, the higher the risk of im-portant correlations between variables is. In case of high correlations between predictors, standard regression meth-ods fail in estimating coefficients. As an alternative, PLS-R provides robust components (linear combinations of predic-tors), independent and highly correlated with the dependent variable. In this work, we have to cope with a large number of predictors (number of features extracted from campaign descriptions) and high correlations, so PLS-R seems to be a very suitable technique.
One part of PLS-R algorithm consists in computing non-correlated components, highly correlated with the depen-dent variable. The computing of components is based on NIPALS algorithm, first introduced by [8] for principal com-ponent analysis. Considering ( x 1 , ..., x p )asetoffeatures, potentially highly correlated, and a dependent variable r , the first component is: t 1 = w 11 x 1 +  X  X  X  + w 1 p x p ,where w ing r on t 1 . The second component t 2 is a linear combina-tion of x 1 j , residuals coming from the regressions of x t The regression of r on t 1 and t 2 gives the residual r 2 iterative process continues until reaching H components, where H is determined by cross validation [3].
Let r u,i and p u,i be respectively actual and predicted rat-ing of user u for item i .
The first approach is content-based, and ratings are es-timated by a PLS regression model learned on each user. After computing of PLS components (see 3.1), a linear re-gression is applied: r = c 1 t 1 +  X  X  X  + c H t H + r H +1 are the regression coefficients. PLS components and predic-tions p u,i are computed by 10-fold cross-validation.
The second approach is also content-based but ratings are predicted by an heuristic technique. The similarity of the new item with respect to all past items is computed. It is a feature-based similarity since no rating is known for this new item. This approach assumes that similar items regard-ing to their features should have a similar rating for a given user. Four similarity measures between items i 1 and i 2 are tested. Since we are working on textual data, cosine similar-ity measure will be used. As a particular case, we will test constant similarity measure. The following similarity func-tions are based on Euclidean distance: d i 1 ,i 2 (the lower the Euclidean distance, the greater the similarity). We use the same method as [6] for generating a third similarity mea-sure: sim ( i 1 ,i 2 )=max i of | K | nearest neighbors of i 1 according to d i the fourth similarity function is inverse proportional to Eu-clidean distance: sim ( i 1 ,i 2 )=1 /d i 1 ,i 2 .
Ratings are then estimated thanks to an aggregating func-tion [1], computed on item neighborhood. Expected rating of user u for item i 1 is given by: where K is the set of | K | nearest neighbors of i 1 with respect to the correspondent similarity measure. For constant sim-ilarity, which means computing average rating on i 1 neigh-borhood, nearest neighbors are determined by Euclidean dis-tance.
While recommender introduced in Section 3.2.2 is based on a  X  X aive X  similarity, this approach is based on a super-vised similarity measure which allows to identify nearest neighbors with respect to relevant features. Instead of com-puting Euclidean distance on item features, it is computed on PLS components which are extracted so as to explain as much as possible actual ratings. Similarity measures are computed as defined in Section 3.2.2. Cosine similarity is not used because in practice, the number of components kept is very low (1 to 12). Similarities are then taken as inputs in a collaborative approach by respecting (1) formula.
These three approaches will be respectively named S 1, S 2, and S 3 in the rest of the paper. The third algorithm is built so as to overcome weaknesses of the first two approaches. PLS-R implies a linear constraint between components and the dependent variable, whereas other approaches are non-linear. In addition, the risk of overfitting is high (because of the high number of input variables) while it is low or absent in other approaches. We appreciate the ability of S 1and S 3 to provide interpretation tools of variable impact (at the PLS modeling step), absent in S 2.
Recommender systems are sys tematically compared with the performance of the  X  X verage X  recommender ( AR ). The latter provides channel recommendations based on their av-erage rating (computed on all past campaigns) and does not take campaign features into account.
Mean Absolute Error (MAE) or Root Mean Squared Er-ror (RMSE) are commonly used to assess the capability of a system to provide good rating estimations. In our con-text, users have big differences in the number of rated items. This can bias our estimator because of the high variability between average ratings of users. Consequently, the mean of users MAE is used to compare system performances on the U is the set of users and D u the set of items previously rated by user u .
Although providing an accurate prediction is important, professionals want to choose channels with the best ROI under their budget constraint. The estimated return on in-vestment of campaign i on channel u is: ROI u,i = p u,i c given that the cost of a channel c u is independent from the campaign. Since the cost is fixed for a given channel, ROI is deducted in an obvious way from the estimated return p u,i . In order to simplify and without loss of generality towards performance evaluation, we consider a fixed cost c for all channels. Consequently, classifying estimated re-turns in decreasing order is sufficient to give us the ranking of channels. In order to assess system performances on a domain-driven way, we are interested in return loss gener-ated by an error in channel ranking. In this case study, we focus on the first rank channel because it is by definition that with the most important return. Two measures of per-formance are considered: the ability of system to find the first rank channel, and the reduction of return loss when us-ing an alternative recommender S instead of using average recommender AR .Let a be the number of campaigns for which first rank channel is correctly identified, and a + b the number of campaigns, the first evaluation measure for rec-ommender S is: P recision S = a a + b .Let r R 1 be the return associated with actual first rank channel and r P 1 ,S the re-turn associated with first rank channel predicted by system S .Perse, r R 1  X  r P 1 ,S , equality being true when the first channel is correctly predicted. The second indicator is de-
The increasing number of online job boards has made cru-cial the introduction of decision-making tools adapted to re-cruiter needs. On a job board, a job posting ROI can be measured by the number of applications received per cur-rency unit spent (or symmetrically the cost per application received). We consider that each job board has the same cost and focus on the number of applications received on channels. The purpose of application is to provide a tool which automatically recommends the best job board with respect to the expected return. To our knowledge, this kind of data has never been studied in the recommender system literature. Data are provided by Multiposting.fr , an online job posting distributor, and concern generalist and special-ized job boards.
This kind of dataset is quite unusual in recommender sys-tem literature: only few users (31 job boards), very small dataset (about 30 500 ratings), and high rating variability inside and between users. Return on a job board is not lim-ited contrary to usual recommenders where ratings take val-ues between 0 and 5, which explains that our collaborative recommendation approaches are item-based. The number of items is reasonable with about 7 730 jobs posted on 4 differ-ent job boards in average. We are studying job boards with 100 postings and more.
The first step is the preprocessing of job offer texts to ob-tain  X  X ag-of-words X  representation: lemmatization and tag-ging, filtering according to grammatical category, filtering words occurring in less than five postings. Before prepro-cessing, a posting is in average 165 tokens long, and the Figure 1: S2 and S3 performance according to fea-ture representation method and similarity measure. total size of vocabulary is about 20 000 distinct words. Af-ter preprocessing, a posting is in average 92 tokens long, and the vocabulary size is reduced to 5 000 distinct words. During experiments, several text representation techniques are tested: term frequency (TF), TF-IDF weighting, LSI (with TF-IDF weighting). Since S 2 is a non supervised sys-tem, the number of dimensions kept with LSI can impact the recommender performance: experiments lead us to keep 50 dimensions (highest loss reduction ).
Loss reduction will be used to identify the best recom-menders while other indicators, MAE and Precision ,have an illustrative purpose. Table 1 shows S 1resultsaccord-ing to model input data, and average recommender ( AR ) results. S 1 globally outperforms average recommender and differences associated with different feature representation techniques are very slight. Results of experiments for S 2 and S 3 systems are presented in Figure 1. Results obtained Figure 2: The best system for each job board accord-ing to the number of postings and return variability. with cosine similarity are not represented because they are very close to those obtained with average on neighborhood (constant similarity). Whatever the similarity measure, for both S 2and S 3 approaches, LSI representation allows to obtain the best performance indicators (except for MAE in S 2 approach where TF representation performs equally). Assuming that LSI provides the most relevant features to explain the job board return, we now focus on loss reduc-tion criterion and comment the impact of similarity measure. While max  X  d is better than other similarities in approach S 2, the three measures are fairly equivalent in approach S 3. The highest loss reduction is reached with max  X  d similarity in both approaches, so we choose it for a general compar-ison of recommender performances (Table 2). The three approaches outperform average recommender. S 2 allows to reach a higher loss reduction than S 1, but S 3isthebest recommender with regard to this performance indicator.
In the non supervised approach ( S 2), the optimal number of neighbors is very low: 20 or less. Especially with constant similarity (average prediction), MAE increases drastically with the number of neighbors. That measure gives too much importance to distant neighbors (contrary to 1 /d weighting). In the semi-supervised approach ( S 3), indicators are more stable from 20 to 100 neighbors. PLS components operate as an information smoothing method.
In Figure 2, each point represents a job board and color designates the winner recommender (that which has pro-vided the lowest MAE on the channel). S 1isthebestrec-ommender on only 2 job boards, S 2 on 10 job boards and S 3 is winning on 19 job boards. While S 3seemstobeeffi-cient on job boards with few postings, on the contrary, S 2 seems to perform better on job boards with a high number of postings (the highest the number of postings, the highest the probability to find a very similar offer on the job board). Sincewehavekeptaselectionoffeatures(andnotallfea-tures) as input in PLS modeling, some information has been lost in the process. But when job boards have few postings, generalization power of PLS provides better results.
We have introduced a hybrid recommender suitable in the cold-start case. This system outperforms content-based (model-based and heuristic-based) approaches, by combin-ing the understanding of campaign features impact on chan-nel ROI and the usage of collaborative knowledge. The evaluation of system performances on the basis of channel returns ensures relevant results in practice for similar appli-cations.

Campaigns are described by texts but we could add other information to the vector of descriptors. In this latter case, S 3 would be a suitable recommendation approach (fitting of predictor weights according to their power of explanation) contrary to S 2. Weights of variables could be even more controlled with techniques such as multiblock PLS [7]. In the future, we will test other similarity functions (e.g. gaussian) under a nonparametric theoretical framework. We would like to thank St  X  ephane Le Viet and Gautier Machelon ( Multiposting.fr company) for supporting this work. We also thank Guillaume Bandet ( Multiposting.fr company) for his many helpful comments on this paper. [1] G. Adomavicius and A. Tuzhilin. Toward the next [2] M. Balabanovic. An adaptive web page [3] A. H  X  oskuldsson. PLS regression methods. Journal of [4] D.I.MartinandM.W.Berry.Mathematical [5] M. J. Pazzani. A framework for collaborative, [6] U. Shardanand. Social Information Filtering for Music [7] L. E. Wangen and B. R. Kowalski. A multiblock [8] H. Wold. Estimation of principal components and [9] S. Wold, H. Martens, and H. Wold. The multivariate
