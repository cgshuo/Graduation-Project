 Knowledge about a (Web) document X  X  creation time has been shown to be an important factor in various temporal in-formation retrieval settings. Commonly, it is assumed that such documents were created at a single point in time. While this assumption may hold for news articles and similar doc-ument types, it is a clear oversimplification for general Web documents. In this paper, we investigate to what extent (i) this simplifying assumption is violated for a corpus of Web documents, and, (ii) it is possible to accurately estimate the creation time of individual Web documents X  components (so-called sub-documents ).
 Categories and Subject Descriptors: H.3.3 Information Storage and Retrieval: Information Search and Retrieval Keywords: timestamping; sub-documents; Web archiving
Accurately estimating at what point in time a (Web) doc-ument has originally been created is of importance for a number of applications, including the tracking of ideas over time, the detection of copied content, and temporal infor-mation retrieval (IR)  X  for some topics users might prefer to be served older Web documents, while for others users may prefer more recently created content.
 Current research in Web-document based temporal IR usu-ally considers either the documents X  creation timestamp (i.e. when the document first appeared on the Web) or the ex-tracted content timestamps (i.e. which time periods the document contains information about) as a raw signal to be included in retrieval models [2]. In this work we focus on the creation time of Web documents. Previous work, e.g. [9, 5, 8], has made the simplifying assumption that each Web doc-ument d i has been created at one moment in time t i and t can either be approximated by the first time the document (its URL) was crawled or by the first/oldest timestamp ap-pearing in the document content. On the Web this is a highly unrealistic assumption  X  documents are constantly c altered and updated, a classic example being blogs, which contain many different  X  X ub-documents X  (blog entries) cre-ated at different points in time. While the different sub-documents of a blog page may be easy to timestamp, for many other types of Web documents this is harder. Thus, in this work, we aim to arrive at a first understanding of sub-document timestamping . Specifically, we empirically investigate the following two research themes:
RT1: To what extent do Web documents consist of sub-documents created at different times? What kind of doc-uments contain two or more sub-documents? What is the timespan between the oldest and most recent sub-document of a document?
RT2: To what extent are we able to classify each sub-document as either having been created within the past month (relative to the document crawl time), within the past year or more than m years ago? What document fea-tures are most useful in the classification? Which type of sub-documents can we most accurately identify?
We investigate a subset of documents from the ClueWeb12 is a sub-document) individually based on historic Web crawl
Having dated all sub-documents, we first analyse this cor-pus of sub-documents before turning towards estimating the creation time of each sub-document with a standard machine learning pipeline.
 We find that two thirds of the investigated Web docu-ments (66 . 5%) do indeed contain sub-documents created at different points in time. More importantly, we also find a large gap between the oldest and most recently created sub-document ( 1052 days on average ), indicating that rely-ing on a single creation timestamp per document provides at best a very distorted picture of the true creation times. Classifying sub-documents according to their creation time using only sub-document internal features is possible with more than 66% of instances correctly classified.
Document creation timestamps are used in different tem-poral IR settings, such as timeline construction [11, 5], im-proving retrieval relevance [10, 8] and the estimation of a document X  X  focus time [7].
 A few existing works aim to infer the creation timestamps of document. De Jong et al. [4] built temporal language mod-ht t p://www.lemurproject.org/clueweb12.php/ https://archive.org/ Figure 1: Overview of our processing pipeline for sub-do cument timestamping. els from existing newspaper articles across a range of years and tagged non-timestamped articles based on the likeli-hood of being generated by a particular model. Kanhabua et al. [9] improve the temporal language model by using word interpolation, temporal entropy and external search statistics. They rely on documents recorded on the IA for their experiments, with the document X  X  creation time being the first recorded crawl within the IA. Chambers et al. [3] use machine learning to infer documents X  cration timestamps based on the temporal expressions by leveraging the MaxEnt model and additional time constraints. Ge et al. [6] propose an event-based time label propagation model by using the relationship between events and documents (exploiting the fact that news articles are often about events).
 All these works infer a single creation time per document. In fact, most works [4, 9, 3, 6] rely on news corpora, which by design are rarely (or never) updated and usually contain an easily accessible creation timestamp. For general Web documents , there is little research work on inferring the sub-document creation timestamps. We attempt to fill this gap with our work. To investigate our research questions we require a set of Web documents for which to determine the sub-document creation times. Instead of randomly sampling Web doc-uments, we rely on the 11 , 075 relevant documents D rel available for the ClueWeb12 corpus (topics topics 201-300), which consists of more than 700 million English Web docu-ments and was crawled between 02/2012 and 05/2012. We thus investigate documents that are at least relevant to some information needs based on their textual content, avoiding Web spam documents and Web documents that contain very little to no text in the process.

Historical Versions Extraction In Fig. 1 we present an overview of our pipeline. For each document in D rel (identi-fied through its URL), we retrieve all available historic ver-sions from the IA, which began archiving Web documents in 1996. 7118 of the documents in D rel contain at least one historic version. We continue our processing with those doc-uments only ( D archived rel ). On average we are able to identify 17 historic versions per document in D archived rel .
Sub-document Extraction In the second step we iden-tify the different sub-documents of each document d i  X  D rel as well as the sub-documents of d i  X  X  m historic versions Hist i = { d h 1 i , d h 2 i , ..., d h m i } where h cent archived version of d i (most recent but older than d crawl date) and h m is the oldest available version. In or-der to split a Web document d i into k sub-documents d i = { s 1 ,i , s 2 ,i , .., s k,i } , we parse d i  X  X  HTML. A sub-document is least 50 non-markup characters. We empirically found this process to be a simple but robust mechanism to identify sub-documents. The number of sub-documents identified are on average 39 per document (median 21).

Sub-document Timestamping Let Hist subdocs i be the set of all sub-documents created across all historic versions of document d i . Then, for each sub-document s i,j of d i determine all matching (using approximate string match-ing) elements in Hist subdocs i and assign to s i,j the creation timestamp of the oldest historic sub-document we found. Table 1: Features derived for sub-document s k,i  X  d i . All features are based on the non-markup content.
Model Training Having identified for each sub-document its creation time, we now derive a set of 21 features in or-der to investigate RQ2 . We restrict ourselves to document-internal features only.
 The features are listed in Tab. 1. All features are based on the non-markup content extracted for a particular sub-document. While features F1 to F9 gather basic paragraph and sentence statistics, features F10 to F21 are based on the TEs can be classified into four different categories, depend-ing on the specificity of the information: [F12] Date (e.g. Feb. 18, 2015 ), [F13] Duration (e.g. from 1996 to 2012 ), [F14] Time (e.g. 1pm ) and [F15] Set (e.g. every weekend ). Since the focus of our work is an exploratory analysis of sub-document timestamping, we chose an established clas-sifier with fixed parameter settings (Random Forest [1] with 5 features per tree and 100 trees in total) instead of experi-menting with different algorithms and configurations. sub-document creation timestamp ). We distinguish 5 classes and annotate each pair accordingly depending on the differ-ence between a sub-document s k,i  X  X  creation time and the 3 TEs are extracted with the SUTime tagger: http://nlp. stanford.edu/software/sutime.shtml . Figure 2: Overview of the number of documents con-taini ng content created at different points in time. (973 . 5 , 2183 . 5] and E = (2183 . 5 ,  X  ). That is, class A con-tains those sub-documents created within the first 20 days of the page crawl time, while class E contains those sub-documents created more than 6 years before the page was actually crawled. We chose these interval settings to create a balanced data-set: each class has  X  55K instances. In a second set of experiments we consider a subset of all instances, namely those 120K in which each sub-document contains at least one TE, as we aim to investigate the effect TEs have on the accuracy of the classification.
 We employed the classifier to predict into which class a par-ticular sub-document falls in a 10-fold cross-validation setup.
Let us first consider RT1 and the question to what ex-tent sub-document timestamping is actually an issue on the Web. In Fig. 2 we plot the number of documents within D rel and the number of different timestamps we as-signed to their respective sub-documents. Overall, 62 . 5% of documents have between 2 and 8 creation timestamps; very few documents contain content created at eight or more dif-ferent times (4%).
 Since not only the number of different creation timestamps a document possesses, but also the time interval between the timestamps is important, in Fig. 3 we present the av-erage difference (in days) between the oldest and most re-cent creation timestamp of a document, with the document set partitioned according to the total number of creation timestamps found in a document. For documents with two creation timestamps, the median difference is 400 days, i.e. 50% of those documents contain content created more than one year apart.
 Considering these numbers we next investigate how much content is created at different points in time. For each doc-creation timestamps we determined what fraction of docu-ment content was created when. The results are shown in Fig. 4. Here, we consider all sub-documents (i.e. the non-markup text) of d i as 100% of the content and compute what percentage of text was existing at each creation timestamp. available (as is the case for the ClueWeb12 corpus) This is a simplification of how Web documents are main-tained (content might also be updated, deleted and added again over time). However, since we use the content of d i as our starting point, we are only interested in the time a particular sub-document of d i was first created. The graph shows that most content is created initially  X  for documents with 2 creation timestamps, on average 78% of the content is available after the first version of the document. For doc-uments with 3 and 4 creation timestamps, 68% and 55% of content are created initially. Interestingly, the amount of content added in subsequent creation timestamps is roughly the same. Figure 3: The document set D arch ived rel is partitioned according to the number of creation timestamps (documents with a single creation timestamp are ig-nored). Shown is the difference (in days) between the oldest and most recent creation timestamp.
 Figure 4: The document set D arch ived rel is partitioned according to the number of creation timestamps (documents with a single creation timestamp are ig-nored). A bar shows the mean fraction of content available at each creation timestamp for documents with 2, 3 and 4 creation timestamps. Ver. 1 indi-cates the content created at the oldest timestamp, Ver. 2 the content created at the second oldest timestamp and so on.

Finally, we consider whether or not different information needs (topics) attract different kinds of documents, i.e. doc-uments with few or many creation timestamps. Fig. 5 shows the distribution of documents with differing creation times for the 25 ClueWeb12 TREC adhoc topics with the largest number of relevant documents (the median number of rel-evant documents is 126). The results show that for most topics a relatively large percentage of relevant documents contain two or more creation timestamps. If we were able to predict what type of topics favour what kind of documents (a single creation time vs. several) we could employ these appearing in the sub-document). creation time-based signals in a retrieval ranking function (a direction of future work).

Our vision is to eventually develop techniques that are reliably able to tag any Web page X  X  sub-documents with an accurate estimate of their creation time. To answer the ques-tions raised in RT2 , we consider the results of the creation timestamp classification experiments in Tab. 2. The Ran-dom Forest (RF) classifier classifies  X  65% of the instances correctly, independent of the existence of TEs in a sub-document (rows 1 &amp; 2). Instances of class E (i.e. those sub-documents created 6+ years before the page crawl time) can be classified with highest accuracy. We also present the results of two baselines for those instances that contain one or more TEs: using as single feature either the oldest or most recent TE for classification purposes only. About two thirds of the instances are not correctly classified showing that TEs alone are not sufficient in this setup and additional features (which on first sight may not always be pertinent to creation timestamps) are required.
Our work shows that sub-document timestamping is an issue which should be considered when employing document creation timestamps in IR applications. Not only the amount of documents containing content created at several points in time is significant, but also the interval between the changes is considerable.
 One of the limitations of our work is the fact that we re-lied on the Internet Archive and its historic versions of a document to determine each sub-document X  X  creation time. While this approach yields very precise results for documents archived often by the Internet Archive, for less well-archived the number of creation timestamps. Correlating the num-son we resorted to a classification setup with five classes instead of estimating the exact creation time.
 In future work we will (i) investigate the impact of sub-document timestamps on retrieval applications, and (ii) ex-periment with document-external features to increase the classification accuracy. ber of records of documents with the number of creation tim estamps found in them, yields r = 0 . 37.
