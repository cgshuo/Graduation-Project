 The increasing volume of streaming data on microblogs has re-introduced the necessity of effective filtering mechanisms for such media. Microblog users are overwhelmed with mostly uninteresting pieces of text in order to access information of value. In this paper, we propose a personalized tweet ranking method, leveraging the use of retweet behavior, to bring more important tweets forward. In addition, we also investigate how to determine the audience of tweets more effectively, by ranking the users based on their likelihood of retweeting the tweets. Finally, conducting a pilot user study, we analyze how retweet likelihood correlates with the interestingness of the tweets.
 H.2.8 [ Database Management ]: Data Mining; J.4 [ Com-puter Applications ]: Social and Behavioral Sciences Algorithms, Experimentation, Human Factors Twitter, Retweet behavior, Filtering
Although microblogs serve as a useful medium for vari-ous activities, the excessive number of posts users receive reduces their utility. In order to find interesting tweets, for example, users must scan potentially hundreds of less rele-vant posts every day from the people they subscribe to. This situation shows the potential value of an effective filtering system for microblogs.

Information filtering requires some criteria as the basis for the filtering process. In the case of Twitter, one of the po-tential criteria is whether a tweet is being disseminated by the users who read it. The practice of propagating a tweet from another user is called retweeting . Since the practice of retweeting includes reading the tweet, deciding that it is worthwhile to share, and then acting on it; we can use retweet (RT) behavior as an explicit signal that the user considers the tweet to contain useful or interesting informa-tion.

In this paper, we approach the problem of reducing infor-mation overload in Twitter from two directions. First, we train a model using a coordinate ascent algorithm to rank the incoming tweets based on the likelihood that the user will RT them. Secondly, for a given tweet, we rank the users who receive that tweet, so that the user who is more likely to RT the given tweet will appear at the top of the ranking. Finally, we analyze how the tweet ranking approach based on RT likelihood correlates with the actual user preference by conducting a pilot user study.
One way to address the problem of improving the attrac-tiveness of incoming tweets is choosing which user to follow in a more selective manner. The idea is that if a user re-ceives the tweets of the right users, then she is less likely to get lost among uninteresting tweets. A few papers propose effective user recommendation approaches to overcome this issue. Hannon et al. utilize content and collaborative based approaches to evaluate a range of different user profiling and recommendation strategies [4]. In another paper, Golder et al. investigate a number of user similarity measures to be used in contact recommendation in Twitter [3]. Discover-ing both global and topic-sensitive influential users is also studied [12, 13].

A number of papers have studied how to classify tweets to improve information filtering. Sriram et al. trained a Naive-Bayes classifier to determine which predefined class a tweet falls into [10]. In their paper, they used categories such as news, events, opinions, deals, and private messages. Classifying the tweets solely on their news-relatedness was studied in [2, 9]. All these classifications are generic, not user oriented.

In order to shed light on what sort of information people propagate on Twitter, several studies investigated the RT behavior of the users. Boyd et al. focused on the qualitative aspect of the RT behavior and gave answers to the questions like  X  X hy people retweet? X  and  X  X hat people retweet? X  [1]. Having a similar motivation to this paper, Suh et al. ana-lyzed 9 features to see how they correlate with the retweet-ability of a tweet [11]. Their hypothesis is that recommen-dation and personalization could help to optimize the in-f ormation diffusion, and help the users to catch interesting tweets. Apart from the global statistical analysis of these features, they did not build a personalized user model using the RT prediction.

To the best of our knowledge, there are four papers ex-tending the analysis to building a retweet prediction model. Yang et al. used 22 features for observation, then built an RT prediction model using a factor graph model [14]. In an-other study, Zaman et al. used a probabilistic collaborative filtering model, called Matchbox, to make RT predictions [15]. Hong et al. used 5 features to train a logistic regres-sion model and achieved a performance with relatively low recall score: 0.44 [5]. Lastly, Petrovic et al. introduced a few more features such as novelty of a tweet and the number of times the author is listed, to train a model using a pas-sive aggressive algorithm [6]. All these papers approach the RT prediction problem from a global perspective, answering the question of  X  X hether a given tweet will be retweeted by anyone or not? X . Thus, they fail to capture which tweets are more retweetable from a user-centric perspective. In this paper, we build a model which is adaptable for individual users.

Finally, Ramage et al. investigated which topics users are interested in using a Labeled-LDA approach, to classify the tweets based on whether each one is worth to be read or not [8]. They also addressed the user recommendation task, however, what they do is basically deciding whether a user is in the followee list of a given user or not.
The goal of ranking the Twitter feed of individual users is to display incoming tweets in a descending order based on their likelihood of being retweeted by the specific user. An effective ranking will help the user to find potentially more interesting tweets. Compared to a filtering approach where the incoming information either passes or fails the filter, the ranking method is more conservative in that all the relevant information is presented to the user in a more organized way.
Another approach for reducing the information overload is presenting the posted tweets to the potential audiences more selectively. Twitter already addresses this issue by hiding personal conversations from other users X  timelines. However, this is just a small step towards filtering out unin-teresting tweets. Our approach for this problem is to rank the potential audience (users) of a tweet based on their like-lihood of retweeting that tweet.

In the next two subsections, we explain our approach and experiments in detail.
As a preliminary experiment, we trained a decision tree accurately we can classify the tweets as retweetable or not for a specific user. To train the classifier, we used four groups of features explained below. Then, with the same set of fea-tures, we took a learning to rank approach using the Coor-dinate Ascent (CA) algorithm. The experimental setup and the results are explained below as well. In all our experi-ments, we used 5-fold cross-validation to split the training and test sets.
Author-based: These are basically the features that ap-pear on or can be inferred through the user profile: Is the author locally elite (i.e. the # of followers she has is in the range of (10K -50K)), is she globally elite (i.e. she has more than 50K followers), followers count, friends count, age (i.e. # of days since the creation of her account), statuses count, favourites count, her tweet rate (i.e. avg. tweet count per week), # of times she is listed, is she a verified user, does she have a description, does she have a url, is her language English.

Author-related features mainly give clues about the au-thority of the author and how active user she is.
Tweet-based: These are the syntactic features of the tweet: Does it contain hashtags (#xyz), urls (http://xyz..), mentions (@user), question mark (?), exclamation mark (!), quotation mark ( X ), first person pronoun (I), same character consecutively three times (e.g. cooool), emoticons (e.g. :P ), is the tweet retweeted by anyone, is the tweet an RT itself, the length of the tweet, and the tf-idf score of the tweet.
Some of these features give implications about how well-written the tweet is, the category, the audience, and the popularity of the tweet.

Content-based: Content based features are the ones re-lated to the information contained by the tweet. These are the novelty of the tweet (i.e. minimum cosine distance to the other tweets that appear on the user X  X  timeline in the last week), the unexpectedness of the tweet from the author (i.e. minimum cosine distance to the other tweets of the author), and the Query Likelihood (QL) [7] score of the author based on the Language Model (LM) of her tweets.
 User-based: These features are related to the user whose Twitter feed is being ranked. From the user X  X  point of view, the features are as follows: Is the author my friend (i.e. is she also following me), is the author my conversation friend (i.e. did we mention each other before), did I RT her before, did I list her, did I use the hashtag in the tweet (if any), did I use the url domain in the tweet (if any), is the tweet mentioning me, did I mention the any of the users mentioned in the tweet (if any).

The first four features show how closely the author and the user is interacting with each other. The remaining ones indicate how the tweet is related to the user and her inter-ests.
Dataset: We used the Twitter REST API 2 to crawl in-formation about the users and their tweets. To train the classifier, we need both positive and negative examples. The positive examples in our case are obvious: the user retweet-ing a given tweet. However, the negative examples are a little bit problematic since we do not know whether the user did not retweet a given tweet on purpose or she did not even see that tweet. In order to make sure that the latter is not the case, we randomly chose seed users who are con-sidered as  X  X rdinary X . We assumed that if a user has (10-1,000) friends/followers, tweets (1-200) times a week, and has tweeted more than 10 times so far, then she is consid-ered to be an ordinary user. Most active Twitter users fall into this category. These users are periodically logging into API-Documentation Table 1: Classification results for predicting retweet-a bility of the tweets. The metrics are based on the positive instances.
 Table 2: Tweet ranking results based on the retweet-a bility.
 Features NDCG@1 NDCG@5 NDCG@10 All 0.814 0.834 0.809 T weet-based 0.797 0.722 0.718 U ser-based 0.306 0.381 0.392 C ontent-based 0.376 0.326 0.339 A uthor-based 0.239 0.263 0.277 Random baseline 0.095 0.099 0.111 Twitter (i.e. tweeting 1-200 times a week), therefore, they a re less likely to skip the tweets appearing on their timelines. Yet, we cannot guarantee that they read all their tweets.
We crawled 242 ordinary seed users, all their followees and tweets. Then, for each seed user, we randomly selected 100 tweets that would appear on her Twitter feed. All together, we had 24,200 tweets, 2,547 of which were retweeted by the seed users. For each of the 24,200 tweets, we extracted the features using information from the author of the tweet, the tweet itself, and the user who is receiving that tweet. We fol-lowed the  X  X T @username X  convention on deciding whether a tweet is RT or not. Twitter X  X   X  X etweet X  X utton also adheres to this convention implicitly.

Results: The classification results using each group of features are shown in Table 1. Precision and recall metrics are used in the evaluation. The metrics are evaluated based on the positive instances. Since the RT ratio is almost 0.1 in our corpus, building an effective classifier on the posi-tive instances is quite challenging. Nevertheless, the results obtained are reasonable.

Among the feature groups, the tweet-based ones have bet-ter performance. Since the tweet-based features are quite common in other microblogging services, this is a useful re-sult. On the other hand, none of the feature groups gives satisfactory results alone.

We also applied the X  X eave-one-out X  X echnique to see which features are more useful. From the tweet-based features, the presence of a URL, whether the tweet is retweeted, and the tf-idf score of the tweet were the most effective features. In addition, the X  X s she my conversation friend? X  and X  X id I use that URL domain X  X eatures from the user-based category are also useful features.

In the main part of the experiments, we ranked the incom-ing tweets for the 242 users to optimize the retweetability probability of the top ranked tweets. The results are shown in Table 2. For this part of the experiments, we used the NDCG@k metric. The relevance score for a tweet is 1 if the user retweets it later, 0 otherwise. Along with the results using each set of features, we also listed the performance of a random baseline, which is quite similar to how Twitter Table 3: Classification results for predicting whether a user will retweet a given tweet.
 would rank the tweets. Again, tweet-based features outper-f orm other groups of features. Using all the features, it is possible to achieve very effective ranking of the tweets for retweetability. In other words, the Coordinate Ascent algo-rithm can learn how to rank the tweets to place the the ones that will be retweeted on the top.
Similar to the previous section, we attempted to answer the following two questions:  X  X an we classify the users based on whether they retweeted a given tweet? X  X nd X  X an we rank the users to potentially identify which users should receive a tweet? X . Again, we used the same classifier and learning to rank algorithm with a slightly different set of features. 5-fold cross-validation is also applied to split the dataset.
Author-based: From the author X  X  point of view, the fea-tures are as follows: Is the user my friend (i.e. am I also following her), is the user my conversation friend, did I RT her before, did she RT me before, did she use the hashtags in the tweet (if any), am I mentioning her in the tweet.
Content-based: Novelty of the tweet (i.e. minimum co-sine distance of this tweet to the user X  X  previous tweets) and the QL score of the user based on the LM of her tweets, where the tweet is the query.

User-based: We used the same set of author-based fea-tures with the tweet ranking task, which are applied to the users, not to the author of the given tweet.

We did not consider the tweet-based features here because our main focus is ranking the users and tweet-related fea-tures would be the same for all the users seeing this tweet.
Dataset: In this part of the experiments, we randomly selected 665 tweets which were retweeted at least by one user. For each tweet, we crawled all the users who follow the author of the tweet. The total number of users were 53,136. Due to the problem we stated about the negative instances of retweeting, we eliminated non-ordinary users from this pool. In addition to the described ordinary user criteria, we also enforced these users to tweet at least 10 times a week, to make sure that they are more likely to read all their incoming tweets. Finally we had 20,397 followers for the 655 tweets.

Results: Table 3 lists the classification results, where the the task was to decide whether a user will retweet a given tweet or not. This problem is more challenging than the previous classification task, because out of 20,397 people, just 780 retweeted something. In other words, the average number of RTs for the selected 665 tweets is 1.17. Even so, our classifier managed to achieve a relatively high F-measure. User-based features dominated other features, but still benefited from them in the overall model. The content-Table 4: User ranking results based on the retweet l ikelihood.
 Features Best@1 Best@5 Best@10 RR@10 All 0.602 0.756 0.828 0.684 U ser-based 0.602 0.657 0.736 0.637 A uthor-based 0.528 0.675 0.782 0.592
C ontent-based 0.362 0.676 0.795 0.508 based features had unacceptably poor performance on the p ositive instances. Our feature analysis through  X  X eave-one-out X  technique revealed that the best feature was the tweet-rate of the users. From the author-based features,  X  X id she use the hashtags in the tweet (if any) X  X nd  X  X m I mentioning her in the tweet X  also proved to be effective.

Considering that approximately one follower retweets each tweet, instead of NDCG@k , we used Best@k and Reciprocal Rank metrics for evaluating how effectively we can rank the users. The results are demonstrated in Table 4. We can infer that, for instance, 75% of the times, the user who will RT the given tweet will appear on the top 5 rankings (e.g. Best@5: 0.756). It is also shown that the retweeter appears either on the top, or the 2nd position in the list on average (e.g. RR@10: 0.684). Although the feature groups do not have significant variances in performance, it is notable that the content-based features do work here even when used alone.
In order to understand whether RT prediction can be an indicator of the interestingness of the tweets, we conducted a pilot user study on 10 volunteers. In the study, the par-ticipants rated a total of 700 tweets that they see on their Twitter feed, based on the following rating scheme: 2: I X  X  glad seeing this tweet. 1: I don X  X  mind seeing this tweet. I may enjoy reading it 0: I prefer not to see this tweet at all. It X  X  a waste of my The average rating was 0.95.
 We then applied the tweet ranking model described in Section 3.1 to the tweets presented to the participants. As shown in Table 5, when the tweets are ranked temporally (as Twitter does), the NDCG values are lower than our method of ranking the tweets. The size of the pilot study is too small to make sound conclusions. Nevertheless, ranking the incoming tweets based on their likelihood of being retweeted by a specific user yields promising results in this user study, which supports our motivation.
In this paper, we proposed two methods for tackling the information overload problem in microblogs. Using four groups of features, we trained a Coordinate Ascent learn-ing to rank algorithm to rank the incoming tweets to help the users interact with the tweets they are more likely to retweet. Additionally, we ranked users given a tweet, so that the users who are more likely to retweet have higher ranks. While our first approach effectively ranks the tweets, the second approach can help to decide the priority of a tweet for a specific user at an earlier stage. Finally, conducting a pilot user study, we observed that the tweets users want to read correlates with the ones they are likely to retweet. Table 5: Performance of the RT likelihood based tweet ranking on interestingness.

T his work was supported in part by the Center for In-telligent Information Retrieval. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor. [1] D. Boyd, S. Golder, and G. Lotan. Tweet, tweet, [2] C. Castillo, M. Mendoza, and B. Poblete. Information [3] S. A. Golder, A. Marwick, and S. Yardi. A structural [4] J. Hannon, M. Bennett, and B. Smyth. Recommending [5] L. Hong, O. Dan, and B. D. Davison. Predicting [6] S. Petrovic, M. Osborne, and V. Lavrenko. Rt to win! [7] J. M. Ponte and W. B. Croft. A language modeling [8] D. Ramage, S. T. Dumais, and D. J. Liebling.
 [9] J. Sankaranarayanan, H. Samet, B. E. Teitler, M. D. [10] B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu, [11] B. Suh, L. Hong, P. Pirolli, and E. H. Chi. Want to be [12] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: [13] Y. Yamaguchi, T. Takahashi, T. Amagasa, and [14] Z. Yang, J. Guo, K. Cai, J. Tang, J. Li, L. Zhang, and [15] T. R. Zaman, R. Herbrich, J. Van Gael, and D. Stern.
