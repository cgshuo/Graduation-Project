 Large-scale, organization-wide groupware systems are high risk development efforts. Requirements gathering and early evaluation are constrained by the need to attain a critical mass of users and content. One approach to mitigate this risk is to employ Wizard of Oz style system simulations during the requirements gathering phase. While this method has historically been used to test quasi-functional system prototypes, we have found it to be a useful method for assessing organizational feasibility. H.5.3 [Information Interfaces and Presentation]: Gr oup and Organizational Interfaces  X  computer supported collaborative work . Design, Experimentation, Human Factors Requirements gathering, Wizard of Oz, methodology. Information systems which support collaborative work are notoriously difficult to design, implement, and evaluate [4]. The processes for large-scale, organization-wide groupware systems, such as workflow management or organizational memory systems, are particularly pernicious. Due to the complex and situated requirements gathering, iterative development methods, and carefully managed adoption strategies. This requires the commitment of considerable time and resources, often without any certainty of success. To mitigate this risk, effective alternatives must be identified. While there is active software engineering research regarding the enterprise-level development problem, it sidesteps many CSCW-specific concerns. For example, because these types of systems typically require both a critical mass of users and of content, traditional prototyping techniques are ineffectual. In an ongoing field study of cross-organizational expertise recommendation and organizational memory system (ER-OMS) development, we found great utility in adapting a traditional usability engineering technique, Wizard of Oz (WOZ) prototype evaluation, for a proof-of-concept requirements gathering field experiment. In this poster we introduce our modification of this usability testing method and abstract lessons learned. WOZ simulation, first used by Gould et al. [3], is a technique used to test limited functionality prototypes to inform final designs. User feedback from these simulations greatly reduces the resource risk to build functional systems for early testing. In traditional WOZ simulations only the representation of a working system is constructed, thereby reducing the complexities associated with system building. The simulation relies on a  X  X izard X  to provide system output, while a participant in the study interacts with the system as though working with the actual product [6]. While it is not able to fully replicate an implemented software system, it does mimic the anticipated user experience, yielding valuable insights about the interaction. An important aspect of using the WOZ technique is preserving the believability of the simulation. Response time is critical to preserving this illusion. During experimentation there is a time delay between the participant X  X  input and feedback from the  X  X ystem X  with which they are interacting. This is caused by the requisite human intervention. As the WOZ method is adapted to field (uncontrolled) environments it becomes grounded with real work, real problems, and real users, raising new benefits and challenges. Our research project required understanding both work practice and system support used by IT departments in public school systems. The ultimate goal of the project was to develop a unified, cross-organizational ER-OMS to support the IT help desk function across multiple school districts. Typically these districts do not have sufficient internal IT expertise to address all problems and must rely on costly external assistance. Pooling inter-organizational expertise should decrease this external reliance. To accomplish this we first needed to assess whether existing content was available to pre-populate a central repository, gauge the context appropriateness of existing content, and determine the organizational feasibility of using the existing knowledge. The field experiment involved 20 IT staff across three sites and generated a simulated system response to 66 help desk queries. Participants would pose the query to the  X  X ystem X  and await a response before deciding and acting upon a final solution. This field implementation of a WOZ simulation required significant deviations from traditional WOZ processes. This was caused by our need to study pre-existing knowledge bases located within participant sites, thereby precluding the use of a controlled, centralized environment. In our study time-lag significantly increased (typically one hour to one day) when compared to the traditional technique. This time-delay required us to disclose the process we were using to participants, as well as have them agree not to attempt to solve their problems through alternate means. It also made it prohibitive for participants to re-phrase or clarify their request. The simulation ran in both directions, with askers also becoming answerers (searching their own knowledge bases for solutions to partner site requests). This had a dual impact. Firstly, it shifted the traditional paradigm in which participants played the role of  X  X orothy, X  to a study in which participants were both  X  X orothy X  and the  X  X izard. X  Secondly, it provided us the opportunity to probe whether requests for information routed directly to a colleague through a system, such as [1,2], could be appropriately deciphered and answered without n ecessitating any additional communication. In this field experiment participants were using real problems to test our simulation, whereas in a controlled setting they would role-play using a series of artificial, preset tasks. We discovered an almost immediate buy-in to the WOZ process, likely caused by the value of receiving real solutions to actual problems. This reliance on real data did create one complication. As each site would receive two suggested solutions from the  X  X ystem X  (one from each of the other sites), evaluating their effectiveness was complex. If the first solution they attempted fixed the problem, they had to either re-create the problem or abstractly hypothesize about the second. In a controlled environment, this would have been a simple issue to manage. Regardless, the use of real problems and solutions assisted in identifying design considerations which may not have been otherwise uncovered.
 Increased time-lag was a primary concern in our WOZ field implementation. Firstly, it required us to disclose the process to participants in order to gain their cooperation. Secondly, we had to rely on participants to wait for a response from their partner sites, whereas in a laboratory environment we would have been able to control access to alternative resources and problem solving techniques. Thirdly, in a traditional WOZ simulation, users are given a predefined set of tasks to complete, providing significant control over the variables introduced by participants. Such was not the case in our field experiment. Although we were able to narrow the potential scope of variables by specifying the type of questions that sites were allowed to submit, it was impossible to fully control the complexity or depth of questions and solutions exchanged. It was likewise impractical to ensure that sites did not ask questions for which they already knew the answers. While this makes our approach more closely aligned with an implemented system, it sacrifices control. To reduce the potential of sites requesting solutions to problems that they already knew the answer to we relied on participant cooperation and time lag, believing that participants would not want to wait for a solution that they could have applied in minutes. Finally, traditional WOZ simulations are conducted in a series with only one simulation occurring during a specified time, allowing for greater control over data collection. In our implementation, however, multiple requests and solutions were exchanged simultaneously. The process of tracking requests for information, corresponding solutions and their accompanying evaluations required us to mark each document so that they could be easily tracked. We found that marking each document with the code of each site the document passed through as well as whether the site was requesting or providing information was beneficial. In addition to document coding, we believe that great benefit would be derived from developing a flow chart indicating the path each document was supposed to travel. Although this study involved only sixty-six question-answer pairs at three sites, document management was a serious issue. As similar studies scale to include more sites and greater interaction, it becomes a necessity. The initial design of enterprise-wide groupware systems, such as organizational memory systems, remains a daunting challenge. Critical mass requirements, both of users and of content, render traditional requirements gathering and prototype evaluation techniques ineffectual. While this will remain a difficult problem, we have described a novel approach which eases the process. Using a WOZ field experiment to test proof-of-concept and facilitate requirements gathering, we were able to quickly assess the feasibility of our concept, identify core design requirements, and understand organizational forces which need to be managed to ensure successful adoption of a fully-functional system. This approach may be valuable in other similar CSCW research and design efforts. Thanks to Anita Komolodi, Stephen Holden, and Carolyn Seaman for their guidance in the development of our WOZ simulation. [1] Ackerman, M.S. Augmenting the Organizational Memory: A [2] Ackerman, M.S. &amp; D.W. McDonald. Answer Garden 2: [3] Gould, J.D., J. Conti, &amp; T. Hovanyecz. Composing Letters [4] Grudin, J. Groupware and social dynamics: eight challenges [5] Preece, J., Y. Rogers &amp; H. Sharp. Interaction Design. New 
