 ZHIYUAN LIU, YABIN ZHENG, LIXING XIE, MAOSONG SUN, and LIYUN RU, What is the relationship between Information Retrieval (IR) and Artificial Intelligence (AI)? We might regard IR as a research bra nch of AI. And which term is more related to IR, Data Mining or Genetic Algorithm? We might think that the former is more related. A problem arises when we want to find more words that are related to the seed word IR. And the more related words should be returned earlier. We regard this problem as a related word retrieval task [Ghahramani and Heller 2006; Google 2010; Sarmento et al. 2007; Zheng et al. 2010]. For this task, Google Sets [2010] provides an interesting tool which takes one or several words as input and returns some re-lated words as output. In general, it performs a large-scale clustering algorithm to gather the related words. Due to its proprietary issue, we are not able to describe more details.

Recently, with the development of social network, such as Facebook and Twitter, new words are generated at a great speed. How to efficiently and correctly identify these new words becomes an important task. For new word detection task [Chen and Bai 1998; Li et al. 2004; Peng et al. 2004; Wang et al. 1995; Zhang et al. 2002; Zheng et al. 2009], we have some domain-specific lexicons at hand, and want to find some new words that are related to the specific domain but are not included in the original lexicons. These words are regarded as new words. Chinese new word detection is even more challenging because there are no natural separators between Chinese words. Previous works [Sproat and Emerson 2003] show that new words also have a crucial impact on the performance of Chinese word segmentation task.

In this article, we want to investigate the advantage of exploiting user behaviors in Chinese Pinyin input method to measure the semantic relatedness between words, and then solve the related word retrieval and new word detection tasks. User records in the Chinese Pinyin input method keep the words that users have used. As shown in Figure 1, User 1 has used two words Word 1 and Word 2 . From this perspective, we can find connections between user records and typical collaborative filtering systems. Words in user records can be regarded as ite ms in collaborative filtering systems and described using a bipartite graph. If a user buys an item or uses a word, we can add a link between them in the bipartite graph. Intuitively, if two words are highly related with each other, they tend to co-occur frequently in user records. Thus, we can quantify the semantic relatedness between words through user behaviors and solve the related word retrieval task. Our method for related word retrieval is unsupervised without requiring any labeled data.

New words are created and used by users. As a result, we can detect new words from user records. We first utilize some domain-specific lexicons to find potential experts who use these domain-specific terminologies very frequently. Then, we detect domain-specific new words from these potential experts. The underlying idea is that experts tend to have the same tastes on certain domain-specific words, while common users seldom use them. In other words, these domain-specific words tend to appear more frequently among the potential experts than other users. We regard these words as the candidate new words. Our method for new word detection is weakly supervised as we only require domain-specific lexicons. Experimental results indicate that it is reasonable and applicable to incorporate user behaviors and collaborative filtering in both tasks.

The contributions of this article are threefold. First, we introduce user behaviors and collaborative filtering in the related word retrieval and new word detection tasks. Following the typical settings of collaborative filtering systems, we construct a User-Word bipartite graph using user records, which is different from other methods. Second, we define a semantic relatedness measure between words based on the constructed bipartite graph. We make a straightforward assumption that if two words are frequently used by the same user, they are very related with each other. And finally, our method is language-independent, which can be easily extended to other languages.

The rest of this article is organized as follows. Related works about related word re-trieval, new word detection, and collaborative filtering are discussed in Section 2. We introduce the data set used in this article as well as our method for related word re-trieval in Section 3. Then, we demonstrate our method for new word detection task in Section 4. Experimental results for both tasks and discussions are shown in Section 5. Finally, we present our conclusions and future work in Section 6. Given one or several words, how can you find other words that are related to the in-put query words in an ordered list? For this kind of related word retrieval task, Google Sets [2010] is a leading and interesting application. For input words in English, Google Sets can return reasonable results. As mentioned in Zheng et al. [2009], the perfor-mance drops rapidly for input words in Chinese. Bayesian Sets [2006] solves the same problem under the framework of Bayesian in ference. It computes a score for each can-didate word by comparing the posterior probability of the word given the input words, to the prior probability of that candidate word. Bayesian Sets returns a ranked list of candidate words according to their semantic relatedness with the input words.
Some researchers pay their attentions to the entity set expansion task [Etzioni et al. 2005; Pantel et al. 2009; Pas  X ca 2007; Pas  X ca and Van Durme 2008; Pas  X ca et al. 2006; Van Durme and Pas  X ca 2008; Wang and Cohen 2007, 2008, 2009]. Entity set expansion is the task of finding related words that belong to the same entity class. For example, from the seed words  X  X oyota X  and  X  X ord X , we can expand the entity class to find other car brands. Most approaches harvest related words belonging to the same entity class from the Web. Some approaches [Wang and Cohen 2007, 2008, 2009] expand the tar-get entity class from semi-structured documents written in markup languages (e.g., HTML, XML). Other approaches adopt distributional similarity [Pantel et al. 2009; Pas  X ca et al. 2006; Van Durme and Pas  X ca 2008] to find more entity words. The obser-vation is that if two words belong to the same entity class, they tend to have similar distributional contexts. Finally, query logs from the search engine [Pas  X ca 2007; Pas  X ca and Van Durme 2008] provide a novel and effective perspective to entity set expansion.
The entity linking task [Ji et al. 2010; McNamee and Dang 2009] organized by NIST, aims to map named entities in texts to corresponding entries stored in an existing knowledge base. This task also needs to compute similarities between words. Recently, researchers propose to model the relationships between two texts that essentially have the same meaning, which is a paraphrase discovery task [Bannard and Callison-Burch 2005; Heilman and Smith 2010; Lin et al. 2010]. In paraphrase discovery, it is crucial to decide whether two pieces of superficially distinct texts indicate the same thing.
However, the entity set expansion and entity linking tasks only aim to harvest named entities like person, location and organization names. In this article, we aim to harvest other kinds of words, not only named entities. Paraphrases refer to lin-guistic expressions that convey the same meaning. We focus on finding related words rather than words with the same meanings, which is a more general task.

We can formulate the related word retrieval task as the definition of semantic re-latedness between words and return the candidate words with higher semantic relat-edness earlier. Recently, Zheng et al. [2009] introduce user behaviors in related word retrieval task via a collaborative filtering manner. The basic assumption is that the more frequently two words co-occur in user records the more related they are.
However, our previous method [Zheng et al. 2009] is still preliminary. We only rank the candidate words based on their co-occurrence features on user records. In this article, we aim to exploit context features to enhance the performance. First, we utilize co-occurrence features to produce candidate words. Then, we employ the idea of re-ranking to reorder these candidate words using context features extracted from external resources.

As discussed before, we can treat related word retrieval task as measuring the se-mantic relatedness between words. Word pa irs can be regarded as pairs of very short texts such as queries in a search engine. Researchers try to propose accurate measures to define similarities between short texts, which is useful in query expansion [Riezler et al. 2008] and query suggestion tasks [Jones et al. 2006].

Sahami and Heilman [2006] propose a Web kernel function as a semantic related-ness measure between short texts based on snippets returned by search engines. The returned snippets of a search engine are re garded as enriched context features of the short text. This method is especially effective when the query words have no common terms. For example, the query word  X  X VM X  and  X  X upport vector machine X  indicate the same concept although they do not share any common word in the surface. But if we enter them into a search engine, the returned snippets are similar. Thus we can find that the two words are related by their context features. This work is followed by Metzler et al. [2007] and Yih and Meek [2007]. They combine the Web kernel with other similarity metrics, such as Dice Coefficient, Jaccard Coefficient and KL Divergence. Yih and Meek [2007] take some machine learning techniques into account to further improve the performance.

In this article, we follow the idea of using search engine to enrich the context fea-tures of word pairs, and define a better semantic relatedness between words. We re-gard the returned snippets as the context of the query word and use vector space model [Salton et al. 1975] to measure the semantic relatedness between words.

In brief, we want to investigate the effectiveness and flexibility of user behaviors and re-ranking framework in the related word retrieval task. User behaviors are used to generate candidate words based on statistical features. Then we reorder the candidate words using context features and expect that more related candidate words can be retrieved earlier. Our related word retrieval algorithm can also process multiple seed words. Since Chinese does not have natural separators between words, segmentation is very important for Chinese text processing [Sproat and Emerson 2003]. Previous works [Peng et al. 2004; Zhang et al. 2002] indicate that the new word detection can be applied simultaneously with Chinese word segmentation to achieve better results on both tasks. In the past, many techniques have been proposed to solve the new word detection problem. We roughly classify these methods into two categories: rule-based methods and statistical machine learning methods.

As for rule-based methods, Wang et al. [1995] use an n -gram based approach to iden-tify and classify Chinese unknown words. Their approach adopts n -gram to obtain the collocating word sequences t hat are possible new words in Chinese. Some structural and semantic characteristics are introdu ced to make their approach more robust. In Chen and Bai [1998], the authors present a corpus-based method that derives sets of syntactic rules to identify new words. The advantage of their method is that it can perform automatic rule learning and evaluation of each generated rule. Experimental results show that their proposed method outperforms hand-crafted rules created by human experts.

Researchers in the statistical machine learning community have paid attention to the new word detection problem. Li et al. [2004] regard the new word detection task as a binary classification problem and use the SVM classifier to identify the candidate words as new words or not. Meanwhile, various features, including the analogy be-tween new words and lexicon words, in-word probability of a character, frequency in documents and anti-word list, have been extracted to solve empirically two types of new word where F -scores can achieve 64.4% and 54.7% respectively. In Peng et al. [2004], they bring conditional random field into Chinese new word identification and integrate new word detection in the framework of Chinese word segmentation. They prove that new word detection and Chinese word segmentation can promote each other. In Li et al. [2004], new words are identified according to their component tokens and context tokens. And then they define a set of word roles to detect new words in real texts based on role tagging. Their method achieves acceptable results, especially for transliterations and person names.

Different from these previous methods, we incorporate user behaviors in the new word detection task. New words in this article refer to the words that should be in-cluded in certain lexicons but are excluded, which is analogous to the definition of out-of-vocabulary words. Our method is weakly-supervised and follows a straightforward collaborative way, which is easy to understand and performs well. Recommendation systems and collaborative filtering [Adomavicius and Tuzhilin 2005] have become a hot research topic since last decade. Recommendation systems are try-ing to predict the interests of users according to their historical tastes, and then rec-ommend useful items that the users might be interested in. According to Breese et al. [1998], collaborative filtering algorithms can be roughly divided into two categories: model-based and memory-based methods.

Model-based methods [Breese et al. 1998; Deshpande and Karypis 2004; Hofmann 2003] build a model using the collections of rating or purchasing records to discover the relations between different items and use the trained model to determine which items should be recommended. Item-based top-N recommendation algorithm [Deshpande and Karypis 2004] belongs to model-based methods. It analyzes the similarities between items and then recommends the items that are similar to the previous items that the user has purchased. We need to find a good similarity metric between items. This metric can be adopted in related word retrieval task if we treat words as items. Then, we utilize the idea of model-based methods in the related word retrieval task.
Memory-based methods [Breese et al. 1998; Nakamura and Abe 1998] make rec-ommendations based on the previous rating records by users. The basic assumption is that each user can be classified in a large group of similar tastes and users with similar tastes tend to choose the same item in the future. As a result, when the sys-tem tries to predict some items to a user, items frequently purchased or liked by the members of the same group can be used to generate candidates for recommendation. The system first searches similar users based on the historical rating records, which is an item-to-user step. The next step is to recommend items liked by most of those members, which is a user-to-item step.

We employ the idea of this method to perform new word detection tasks. Words in the user records are treated as items. If a user types in a word, we can consider that a user purchase an item. From this perspective, our settings are similar to typical collaborative filtering systems. For the new word detection task, we have some domain-specific lexicons at hand. And we want to detect new words in that domain which are not included in the original lexicons. First, we find some potential experts who have typed in many terminologies in that domain. This can be recognized as an item-to-user step. Then we detect the candidate words that are used by most of those experts. This is a user-to-item step. It is clear that our method for new word detection follows the collaborative filte ring methodology. In this section, we demonstrate how to discover related words from one or several seed words through user behaviors. The basic observation is that high association ratios or co-occurrence frequencies indicate a strong semantic relationship between words [Church and Hanks 1990]. In this article, we adopt five co-occurrence measures to calculate semantic relatedness between words, namely Jaccard coefficient, Dice coeffi-cient, Point-wise mutual information [Bollegala et al. 2007], Google Distance [Gracia et al. 2006], and conditional probability [Deshpande and Karypis 2004].

First, in order to give a better explanation, we introduce the data set used in this article. All the resources used here are generated from Sogou Chinese Pinyin input method editor. We use Sogou-Pinyin for abbreviation hereafter. Users can use Sogou-Pinyin to type in Chinese words. The word lists that users have typed in are kept in their user records. Volunteers are encouraged to upload their anonymous user records to servers. The advantage is that they can download user records and personal set-tings on a different computer, which can greatly enhance user experience. In order to maintain user privacy, user information is hidden using MD5 hash algorithm. So, the data set is completely anonymous and user privacy is safeguarded.

We also introduce how to formulate related word retrieval in a typical collaborative filtering framework. We construct a User-Word bipartite graph with users on one side and words they have used on the other side. The construction can be accomplished while traversing the data set within linear time.

Second, we focus on how to perform the unsupervised related word retrieval task under this framework. Five co-occurrence based measures are proposed to generate candidate words. Intuitively, if users tend to use two words very frequently, that is, two words always co-occur in user records, the two words are related with each other. Start-ing from a single seed word, we can identify candidate words using different measures.
Third, in order to further improve the performance, we can extract context features to supplement statistical features. We follow the methods introduced in Bollegala et al. [2007] and Sahami and Heilman [2006]. A search engine is used to extract context features for input seed words and candidate words. Each word is issued to a search engine, then the top 20 returned snippets are regarded as context features of the cor-responding word. We can use vector space model and cosine distance to measure the similarities between two words.

Finally, we extend our method from a single seed word to multiple seed words. A candidate word is related to input seed words if it has close relationships with most of the seed words. We make further explanations about the above steps in the following subsections.
 In a typical collaborative filtering system , the recommendation problem is usually for-malized in a bipartite graph, with users on one side and items on the other side. If an item is purchased or rated by a user, then we can add one edge between them in the bipartite graph.

Similarly, we can build a bipartite graph from user records in Figure 1. The bipartite graph has two layers, with users on one side and words they have used on the other side. We traverse the user records, and add a link between user u and word w if w appears in the user record of u . This procedure can be acco mplished in a linear time. AsshowninFigure1,wecanseethat User 3 has used Word 1 , Word 3 and Word 4 .Asa result, node U 3 is connected with node W 1 , W 3 ,and W 4 in the corresponding bipartite graph. After building the bipartite graph, we can measure the semantic relatedness between two words from corresponding graph. Intuitively, two words are related if they always co-occur in user records. However, co-occurrence information alone does not accurately define semantic relatedness between words. For example, some stop words such as  X   X  (of) and  X   X  (I) in Chinese tend to co-occur frequently with other words. As a result, we should consider not only the co-occurrence of two words w 1 and w 2 ,butalsothe individual occurrence of word w 1 and w 2 to assess the semantic relatedness between w 1 and In this article, we utilize five co-occurrence based measures: Jaccard coefficient, Dice coefficient, Point-wise mutual information, Google Distance, and conditional prob-ability to calculate the semantic relatedness between two words. We use notation Score ( w 1 ,w 2 ) to denote the semantic relatedness score between words w 1 and w 2 . Freq ( X ) denotes the number of users who have used all the words in the set X . The Jaccard coefficient is used to calculate the similarity between two sets. Jacc ( w 1 ,w 2 ) is defined as estimation of co-occurrence of w 1 and w 2 . Equation (1) defines the ratio of the proba-bility of finding a user who have used words w 1 and w 2 together over the probability of finding a user who have used either w 1 or w 2 .If w 1 and w 2 are the same word, Jacc ( w 1 ,w 2 ) is equal to 1. If w 1 and w 2 never co-occur, Jacc ( w 1 ,w 2 ) is equal to 0.
Dice coefficient Dice ( w 1 ,w 2 ) is similar to the Jaccard coefficient and is calculated in Equation (2). Again, if w 1 and w 2 never co-occur, Dice ( w 1 ,w 2 ) is equal to 0. And Dice ( w 1 ,w 2 ) is equal to 1 if w 1 and w 2 are identical.

We can regard the number of users who have used word w 1 and w 2 as random vari-ables. Then, point-wise mutual information can be adopted to measure the mutual dependence between the two words using the following Equation: where U is the number of users. Mutual information quantifies the mutual depen-dence of two random variables and can be regarded as the reduction of uncertainty about one random variable when another is known. Low mutual information indicates a small reduction, that is, two random variables are less related. Zero mutual informa-tion means two random variables are independent. High mutual information indicates a large reduction in uncertainty, that is, two random variables are highly related. Mu-tual information reaches its maximum when two random variables are identical. Inspired by Kolmogorov complexity, a page-count-based similarity measure called Normalized Google Distance [Cilibrasi and Vitanyi 2007; Gracia et al. 2006] is pro-posed to compute the semantic relatedness between words. Google distance-based se-mantic relatedness measure Google ( w 1 ,w 2 ) is defined as
Finally, we adopt the conditional probability [Deshpande and Karypis 2004] to mea-sure the semantic relatedness between words. The conditional probability Prob ( w 2 | w 1 ) can be estimated as the number of users who have used both w 1 and w 2 divided by the numberofuserswhohaveused w 1 ,
We can clearly see that usually Prob ( w 2 | w 1 ) = Prob ( w 1 | w 2 ), which indicates that conditional probability is an asymmetric measure. Suppose w 2 isastopwordthat is used by most users, then all the other words tend to have a close relationship with w 1 according to Equation (5). In order to alleviate this disadvantage, we use a weighted harmonic averaging measure [Forman 2003; Li and Sun 2007] to consider both Prob ( w 2 | w 1 )and Prob ( w 1 | w 2 ) together. Words w 1 and w 2 areexpectedtobehighly related to each other when Prob ( w 2 | w 1 )and Prob ( w 1 | w 2 ) are both relatively high, ei-probability based semantic relatedness measure Cond ( w 1 ,w 2 ) is defined as
In Equation (6), parameter  X   X  [0 , 1] is the weight for Prob ( w 1 | w 2 ), which controls how much Prob ( w 1 | w 2 ) should be emphasized. We carry out comparative experiments when parameter  X  changes from 0 to 1, stepped by 0.1. Experimental results show that we can get best performance when  X  =0 . 5, which indicates that we should consider Prob ( w 2 | w 1 )and Prob ( w 1 | w 2 ) equally.

So far, we have introduced how to compute the semantic relatedness between two words using various measures. We also want to investigate whether we can combine these co-occurrence based measures to obtain better performance, that is, these mea-sures could benefit from each other. More details and discussions are given in the experiment section.
 For a single input seed word w , we can calculate the semantic relatedness score Score ( w, c ) between seed word w and candidate word c . We can easily extend our method to multiple input seed words. For multiple input seed words, we calculate the semantic relatedness score between candidate word c and each seed word w i .Then the final score of candidate word c is assigned with the average score values, as shown in the following Equation: where M is the number of input seed words. Score ( w i , c ) can be computed using co-occurrence based measures discussed before. Then we sort these candidate words in a descending order. Finally, Top N candidate words are returned. Alternatively, we can also set a threshold score for Score ( c ) and only keep those candidate words whose Score ( c ) are higher than a threshold. However, this threshold is difficult to decide be-cause different input seed words may have different score thresholds.

We can see that this candidate generation step is completely based on statistical features because we only consider the co-occurrence of two words and their individ-ual occurrences. Inspired by Sahami and Heilman [2006] and Bollegala et al. [2007], we investigate whether the context features extracted from search engine can be a complement to our statistical method. As stated before, for one or several input seed words, we can generate top N related candidate words using statistical features. To enhance the performance, we use search engines to enrich seed words and candidate words with more context features. Context is proved to be a good feature for semantic similarity computation [Iosif and Potami-anos 2010; Pantel et al. 2009]. The basic assumption is that two words appearing in similar contexts tend to be close in meaning. Then, seed words and candidates can be enriched with their corresponding context features [Church and Hanks 1990]. These candidate words are reordered acco rding to their context features.

Intuitively, if we introduce more candidate words (increase the value of N ), we are more likely to find related words from the candidate sets. However, noisy words are introduced inevitably. We show how parameter N affects the performance in the ex-periment part.

Specifically, we enter a word to Chinese search engine Sogou, and get top 20 re-turned snippets. For different query words, Sogou returns snippets of different lengths. Generally, each snippet contains about 100 Chinese characters. We show some snippet examples in Figure 2. We get context features for query word  X   X  (Ericsson) using the returned snippets.

We assume that top 20 snippets contain enough context features about query word, and more snippets will bring some noise. Following the method proposed by Sahami and Helman 2006, each query word can be represented as a feature vector using bag-of-words model. We calculate a new semantic relatedness score between input seed words and a candidate word using the cosine distance between their feature vectors. Finally, top N candidate words are reordered accord ing to the semantic relatedness scores.

Notice that we only utilize snippets as features in re-ranking. Our re-ranking method is unsupervised, as we do not require any training data set. More features can be explored to enhance the performance, and we can also build labeled training data to adopt more sophisticated re-ranking framework. This is our future work.
As a result, re-ranking can be regarded a s a complementary step after candidate generation. Candidate words that are more related to seed words can be returned ear-lier with enriched context features. As shown in the experiment part, we can enhance the performance of related word retrieval task by performing re-ranking.
 However, we also observe some noisy results in related word retrieval experiments. The main reason is that our method is unsupervised, we do not have any prior knowl-edge about input seed words. For instance, for ambiguous seed word  X   X  (apple), we do not know whether it is a kind of fruit or an IT company. We can add labeled domain-specific knowledge to solve this ambiguous problem. Starting from the domain-specific lexicons which contain all kinds of fruit names,  X   X  (apple) in this lexicon refers to fruit. When  X   X  (apple) is included in computer science-related lexicon, it means an IT company name. From this perspective, we can extend our unsupervised related word retrieval method to a weakly supervised new word detection task. Given labeled domain-specific lexicons, our goal is to find related new words that are excluded in original lexicons. In this section, we present our method for the new word detection task which takes user behavior and collaborative filtering into consideration. New word in this article refers to a word that should be included in specific lexicons but is excluded. In other words, we need to retrieve missing words t hat are related to the words included in specific lexicons. From this perspective, new word detection is similar to the related word retrieval task. Both tasks need to calculate semantic relatedness between words. The main difference is that, for new word detection task, we need to construct lexicons that contain words belong to the same domain, such as  X  X omputer science X .
When using the Chinese input method, users may need some domain-specific lexi-cons to help them type in terminologies more efficiently and accurately. For example, computer science researchers will be happy if they are provided with a lexicon that con-tains the latest terminologies in computer science. Fortunately, Sogou-Pinyin provides various domain-specific lexicons in different areas. From their configuration files, we can obtain the information of what kind of domain-specific lexicons users have used. Like the mode of Wikipedia, these lexicons are maintained by volunteers, which can keep terminologies up-to-date. However, this can also bring noisy words inevitably because everyone can modify them.

As discussed before, our new word detection algorithm mainly performs in three steps. First, we select the most representative words from domain-specific lexicons and remove the noisy words. Second, starting from the cleaned domain-specific lexicons, we aim to discover potential experts in this particular domain through their user records. In our opinion, users who use representative words quite often tend to be potential experts in that domain. In other words, the more domain-specific terminologies they have used, the more likely they are potential experts. Finally, we detect new words in that domain from the behaviors of those potential experts. The idea is that words used much more frequently in the community of potential experts than other users are candidate new words.

In brief, our new word detection method fo llows the collaborative filtering strategy: first from representative words to potential experts, then from these experts to find new words. Domain-specific lexicons are maintained by volunteers, which brings noise inevitably. Some noisy and unrelated words are included in the lexicon. For example, lexicon in computer science field contains words like  X   X (problem)and X   X (contact). These words should be removed from domain-specific lexicons. Some words that are very related to the specific domain are excluded. In our experiment, words  X   X  (complexity) and  X   X  (recursion) are absent from the original lexicon in computer science. In fact, we are trying to identify these missing new domain-specific words to enrich the domain-specific lexicons.

In this subsection, we introduce how to filter noisy words in the lexicon, and select most representative words. A word is supposed to be representative if it is very related to specific domain (we use discriminability to denote whether a word is related to a domain) and has a wide coverage among the experts in specific domain. For example, word  X   X  (pseudo pass rate) is a terminology in computer science. But only few persons use this word in their records because it is over specialized. Word  X   X  (redirect) is a word widely used among experts in computer science as well. As a result, word  X   X  (redirect) is more representative than  X   X  (pseudo pass rate).
 Inspired by [Li and Sun 2007], we generally consider two factors: discriminability and coverage to select representative words.

First, given a domain-specific lexicon, we can infer whether a user has used this lexicon from his configuration file. Users who have used certain lexicon are labeled as positive users. Other users who have not used certain lexicon are labeled as negative users. A user can be labeled as either positive or negative given different domain-specific lexicons. For instance, a computer science expert is a positive user given a computer science related lexicon, while he/she is a negative user given a biology related lexicon.

Then, we adopt discriminability to measure how unbalanced the distribution of a word in positive and negative users is. If a word always appears in positive users and seldom occurs in negative users, it has a powerful discriminability that can distinguish positive users from negative users. According to Forman [2003], we use a straightfor-ward metric, probability ration, to define the discriminability of a word as following: (for brief, we use PR instead)
In Equation (8), w refers to a word, PR ( w, l ) refers to the discriminability of word w in a domain-specific lexicon, l +and l  X  refers to positive and negative users, re-spectively. Freq ( w, l + ) indicates the number of positive users who have used word w . Freq ( l + ) indicates the number of positive users. Freq ( w, l  X  ) indicates the number of negative users who have used word w . Freq ( l  X  ) indicates the number of negative users.
Second,wesimplyusethenumberofuserswhohaveusedword w ,thatis, Freq ( w ) to measure the coverage of w . In general, coverage and discriminability have a slightly negative correlation. Words with high coverage always have poor discriminability. For stop words like  X   X (of)and X   X  (I), almost every user tends to use them in their user records. It is not reasonable to label a user as positive or negative using these words. On the other hand, if a word mainly appears in positive users which shows strong discriminability, it always has weak coverage because it rarely appears in negative users.

In this article, we consider the discriminability and coverage together to select rep-resentative words. A representative word should have strong discriminability that can distinguish positive users from negative users. Meanwhile, it should have wide enough coverage. If we select words that ra rely appear in user re cords, we cannot dis-cover enough potential experts in the next step, which will hurt the performance of the new word detection task. Therefore, we need to consider both discriminability and cov-erage at the same time. Similar to Equation (6), a weighted parametric representative words selection criterion is defined as follows:  X   X  [0 , 1] is adopted to balance discriminability and coverage. In our experiment, we set  X  to 0.5, which means that we treat discriminability and coverage equally. Besides, we can select representative words using only discriminability or coverage. We select the top 1,000 most representative words fro m a domain-specific lexicons using three selection criterions. Expe rimental results show that we can get best results if we consider two factors together. In this subsection, we discuss how to search potential experts using the most repre-sentative words. Users who have used corresponding representative words very fre-quently are potential experts in certain field. If a user has used 90 percent of these selected representative words in computer science, we are confident enough to believe that this user is a potential expert in computer science. We sort users according to the percentages of representative words they have used.

Alternatively, we can simply mark the positive users as potential experts, because they explicitly choose domain-specific lexicons in their configuration files. However, as shown in the experiment part, we observe that many users indicate they are positive users in computer science, but they seldom use terminologies in computer science in their user records. As a result, it is not accurate if we label them as potential experts. We cannot rely on the configuration files.

We do not take all the words in a domain-specific lexicons into consideration be-cause some words are not related to the domain. For example, original domain-specific lexicon in computer science contains noisy words like  X   X (problem)and X   X (con-tact). We cannot label a user as an expert in computer science if he uses these two words very frequently. In this subsection, we introduce how to detect new words from discovered potential ex-perts in the previous step. As mentioned before, original domain-specific lexicons are maintained by volunteers. Obviously, humans are not able to enumerate all the termi-nologies in specific domain. This disadvantage causes that some words that should be included are missing. We regard these missing words as new words and try to detect them. As a result, we can make the domain-specific lexicons complete.

Intuitively, if a word w is frequently used among the community of these potential experts with high coverage and seldom appears in other users X  records and w is ex-cluded in the original domain-specific lexicon, then we can fully believe that w is a missing new word that should be detected. In other words, w can distinguish potential experts from other users.

Similar to representative words selection step, we also take coverage into account when detecting new words. Assume a word only appear once within one of the potential experts X  record. Then, the ratio of distributions between potential experts and other users is infinite because the denominator in Equation (8) is 0. However, this word may be a personal word used by this expert, which is not a valid terminology in this domain. To solve this problem, we consider the coverage in potential experts together. We adopt Equation (9) to sort our detected new words and evaluate our method based on the ranked results. More details are given in experiment part.

Our weakly supervised new word detection method relies on prior domain-specific knowledge, either domain-specific lexicons or configuration files. It will fail in detect-ing new words in emerging new domains. To alleviate this problem, we can ask domain experts to annotate seed words that belong to the new domains. Then our method can iteratively detect new words from these seed words. How to automatically detect new domains and collect domain-specific kn owledge is left as our future work. We carry out our experiments on the Sogou Chinese input method data set. The data set contains 849,134 users and 165,820,037 words. We should note that users are freely to type in whatever they want in their user records. As a result, there are many noisy words in the original data set. In order to alleviate this problem, we remove the words that are used by fewer than 10 users.

For the related word retrieval task, we randomly select 10,000 user records and con-struct a bipartite graph using the method described in section 3.1. The corresponding bipartite graph contains 10,000 nodes on user side, 183,870 nodes on the word side, and the number of edges is 42,250,718. As we can see, the data set is very sparse, be-cause users tend to use only few words. For the evaluation of the related word retrieval task, we need judge whether a candidate word is related to the input seed words. The firstwayistoaskdomainexpertstodomanuallabeling.Thesecondwayistousea standard data set with accurate labeling. Baidu encyclopedia, is used as our golden standard in this article. We consider both expert labeling and Baidu encyclopedia to evaluate our method.

For the new word detection task, we use three different domain-specific lexicons which are in computer science, idiom and saying, and World of Warcraft, respec-tively. These are the most popular domain-specific lexicons with 33,513, 47,225 and 27,622 users, respectively. The three lexicons contain 9,464, 31,758 and 20,194 domain-specific words, respectively. We show how to select the most representative words from the three lexicons. Experimental results show that it is effective if we consider the discriminability and coverage together. We find that weakly supervised new word de-tection task generally performs better than unsupervised related word retrieval task, which indicates that we can get better results when given more prior knowledge. We adopt three evaluation metrics to validate two tasks. (1) Precision@N ( P@N ). P@N is the precision evaluate at a given cut-off rank N ,which (2) Binary preference measure ( Bpref ). As we cannot list all the related words of one (3) Mean reciprocal rank of the first relevant result (MRR). For a number of input
All these metrics give rewards if we can return correct results earlier and give penal-ties if we discover wrong results earlier. Detailed experimental results are given in the next subsections. In this section, we show the experimental results for the unsupervised related retrieval task. We randomly select 2,000 seed words from Baidu encyclopedia for parameter tuning and automatic evaluation. In addition, we select 100 discriminative seed words in computer science for manual labeling and evaluation. We want to in-vestigate whether discriminative seed wo rds gain better performance than randomly selected seed words. We first investigate the related word retrieval performance under different co-occurrence based measures discussed in Section 3.2. Then, we utilize search engines to extract context feature s and further improve the performance. Finally, we show experimental results of multiple seed words. 5.3.1 Retrieval Without Re-ranking. Beforewegetintothedetails,wefirstgivesomere-sults of the related word retrieval task in Table I. Our method can deal with single seed word (the first column in Table I) or multiple seed words (last two columns in Table I). For an ambiguous seed word like  X   X  (apple), we can add more seed words to perform disambiguation. Intuitively, if  X   X  (apple) appears with other IT compa-nies like  X   X  (Microsoft), it refers to the IT company Apple. If it appears with other fruit names like  X   X  (strawberry), then it refers to a kind of fruit. In general, our method can return words that are relevant to the input seed words.

As discussed in Section 3.2, we have introduced five co-occurrence based mea-sures to define semantic relatedness between two words. The first four measures are parameter-free. For conditional probability, we introduce a parameter  X  in Equation (6) which controls the weight of Prob ( w 1 | w 2 ). In our experiment,  X  varies from 0 to 1 stepped by 0.1. For each seed word selected from Baidu encyclopedia, we keep the first 100 returned candidate words ranked by Equation (6). Then we record the cor-responding values of Bpref, MRR, P@5, P@10, and so on. The results are shown in Figure 3.
 We can clearly see that all the evaluation values increase first when  X  increases. Then, we get best performance when  X  =0 . 5, which indicates that we should consider Prob ( w 1 | w 2 )and Prob ( w 2 | w 1 ) equally. After that, all the evaluation values decreases when  X  keeps increasing. We note that performance decreases dramatically when  X  is severe detriment. If there is no specific declaration,  X  issettobe0.5hereafter. We also carry out comparisons with othe r co-occurrence based measures and Bayesian Sets, which are shown in Table II. It is interesting that conditional probabil-ity gains similar performance as compared to Jaccard coefficient and Dice coefficient. When  X  =0 . 5, we can find that Cond ( w 1 ,w 2 )= Dice ( w 1 ,w 2 ):
As shown in Table II, Jaccard coefficient, Dice coefficient, and conditional proba-bility gain the best performance, followed by Google distance and Bayesian Sets. In general, the basic assumption of these co-occurrence based measures is that high asso-ciation or co-occurrence ratio s indicate a semantic relatedness between words [Church and Hanks 1990]. Moreover, Iosif and Potamianos [2010] also verify the effectiveness of co-occurrence based measures for computing the semantic relatedness between words. They also study the properties and performances of various similarity measures. Un-fortunately, based on their results, there are no complementarities among these mea-sures. Similarly, in our experiment, we find that Jaccard coefficient, Dice coefficient and conditional probability return nearly the same related words for the same seed word, which indicate that we cannot combine them to improve the performance. We observe that point-wise mutual information performs worst in our experiment. We further analyze the shortcoming of poin t-wise mutual information measure. For an input seed word w 1 , we find that PMI ( w 1 ,w 2 ) tends to select words w 2 whose Prob ( w 1 | w 2 ) = 1. In other words, users who use w 2 will certainly use w 1 ( w 2 co-occurs with w 1 with probability 1). Based on the observation that Freq ( w 1 ,w 2 )  X  Freq ( w 2 ), we get: As shown in Equation (13), when Prob ( w 1 | w 2 ) = 1, or equivalently, Freq ( w 1 ,w 2 )= Freq ( w 2 ), PMI ( w 1 ,w 2 ) reaches its maximum. However, as shown in Figure 3, related word retrieval performance decre ases rapidly if we only consider Prob ( w 1 | w 2 ). For comparison, we also list results when  X  =1 . 0 in Table II. PMI gets exactly the same results with conditional probability when  X  =1 . 0, which confirms our inference.
From Table II, we observe that the performance is relatively poor using randomly selected seed words. Intuitively, we can get better performance if the seed words are chosen carefully. We select 100 discriminative seed words in computer science and carry out experiments on conditional probability, Bayesian Sets and Google Sets. For each seed word, we keep the first 10 returned candidate words. Domain experts are asked to label the results. We record the values of Bpref, MRR, P@5, and P@10 in Table III.
 As shown in Table III, conditional probability gets comparable results with Bayesian Sets. Google Sets gives relatively worse results with seed words in Chinese. It does not return any results for seed words  X   X  (block diagram),  X   X (wordsegmen-tation) and  X   X  (weighting). However, Google Sets works well with seed words in English. We find that Google Sets generally harvests related words from structured or semi-structured Web pages. Chinese Web pages always contain much more noise as compared to English Web pages. Some Chinese Web pages are not written in stan-dard HTML language. Chinese word segmentation makes it more difficult for finding related words in Chinese. As a result, Google Sets performs worse for seed words in Chinese. On the other hand, Bayesian Sets gains better performance than conditional probability with discriminative seed words, which indicates that Bayesian Sets ben-efits most if we select seed words carefully. For randomly selected seed words, con-ditional probability is better than Bayesian Sets. Finally, we can clearly see that the performance makes great progress under various evaluation metrics as compared to Table II. This confirms that we can gain better performance if we have prior knowledge of the seed words and choose them carefully. 5.3.2 Candidate Words Re-ranking. In this subsection, we investigate the effectiveness of our re-ranking framework. We first give an example in Table IV. The input seed word is  X   X  (Ericsson), and the first column in Table IV shows the returned top 10 candidate words without re-ranking. After using search engines and context features, we reorder candidate words (as shown on the second column).

AsshowninTableIV,wecanreturnthemostrelevantcandidatewordssuchas X  the first two places. Some famous brands such as  X   X (Alcatel)and X   X  (Siemens) are also returned earlier after re-ranking. Words such as  X   X  (dilatation) and  X   X  (Core Network) that are not very re lated are removed from the top 10 list. From these observations, we can see that the re-ranking framework and context features can improve the performance.

We also conduct experiments on the parameter N discussed in Section 3.3. For a single seed word, top N candidate words are returned based on statistical features. Then, we utilize search engines to add context features for both the seed word and the candidate words. Finally, top N candidate words are reor dered according to their context features. For each seed word, we keep the first 10 reordered candidate words. Detailed results are illustrated in Figure 4.

From Figure 4, We can see that too many candidate words tend to harm the perfor-mance because we may inevitably introduce noisy words. For example, Bpref drops to 0.25 when N = 100. In general, N =10and N = 20 give relatively best results. Our method usually returns useful candidate words in the first 20 places. 5.3.3 Multiple Seed Words. In this subsection, we report experimental results for mul-tiple seed words. Candidate words are ranked according to Equation (7). Number of seed words M changes from 2 to 8. We construct queries which contain M seed words, and keep the top 100 returned candidate words for each query.

As shown in Figure 5, performance under various evaluation metrics improves steadily when the number of seed words increases. We can draw the conclusion that more seed words result in better results. We take the queries in Table I as an exam-ple. Word  X   X  (apple) is constrained to an IT company if it co-occurs with  X   X  (Microsoft) and  X   X  (Google) in the input, while it is constrained to a kind of fruit if it co-occurs with  X   X  (carrot) and  X   X  (strawberry).

Furthermore, we can perform our related wo rd retrieval task iteratively from a sin-gle seed word. In each iteration, we add the most related three candidate words to enlarge the set of seed words. Then, the enriched seed words are used for the next it-eration. We show the iterative experiments for two seed words  X  (Zhuge Liang) X  and  X   X  (Wudaokou) in Table V. The first seed word is a famous personage of the Three Kingdoms, and the second seed word is a place name in Beijing. As we can see, in each iteration, we can find proper related words from seed words. From seed word  X  (Zhuge Liang) X , we can find a list of personages of the Three Kingdoms. While from seed word  X   X  (Wudaokou), we can find a list of place names in Beijing. This experiment demonstrates the effectiveness of our method.

We have demonstrated that we can get better results if we have prior knowledge of the seed words and select discriminative s eed words in previous subsections. What can we learn if we have multiple discriminative seed words? Fortunately, domain-specific lexicons contain some discriminative terminologies. Then from the domain-specific lexicons, we can detect related words in th e specific domain accurately. Based on the above analysis, we extend our unsupervised related word retrieval method to solve the weakly-supervised new word detection task. As we can see, for the unsupervised related word retrieval task, we can gain better per-formance if we have prior knowledge about th e seed words. Discrimi native words, for example,  X   X  (machine learning) always generate better results than ambigu-ous words, such as  X   X  (apple). On the other hand, multiple seed words result in better performance than a single seed word. I deally, from multiple discriminative seed words, we can detect related words with good performance. Domain-specific lexicons always contain some discriminative words. Then from domain-specific lexicons with label information, we aim to detect new words that are related to the specific domain but are not included. As a result, we extend our unsupervised related word retrieval method to solve the weakly supervised new word detection task.

We use three domain-specific lexicons to conduct our representative words selection experiment. We remove noisy words and sele ct discriminative words if we consider both coverage and discriminability together. Then, we select top 1,000 words from each domain-specific lexicon as the most re presentative words. We can find potential experts based on the representative words and their user records. Finally, words used frequently by these potential experts are identified as new words. 5.4.1 Selecting Representative Words. As discussed before, we first try to filter noisy words in the original domain-specific lexico ns. We focus on coverage and discriminabil-ity. Coverage reflects the popularity of word s while discriminability emphasizes dis-tinguishing positive users from negative users. We show words with good coverage or discriminability in three different lexicons respectively. In additional, we demonstrate we can get better results if we consider both coverage and discriminability.
Table VI shows words with good coverage in three lexicons. Take the computer sci-ence lexicon as an example, the most popular word in this lexicon is  X   X (problem), which is used by 78.33 percent of users. Some words such as  X   X  (contact) and  X   X  (study) are not related with computer sci ence. The reason is that domain-specific lexicons are maintained by volunteers and everyone can modify them. In general, these widely used words have poor discriminability. If a user uses these words very frequently, we are not confident enough to label him/her as a potential expert, because every user tends to use these words frequently.
 Table VII shows the most discriminative words in three domain-specific lexicons. These words are quite related to their co rresponding domains. Different from the words shown in Table VI, once these discriminative words appear in one user X  X  record, he/she is very likely to be an expert because other users rarely use these words. How-ever, we are encountering some problems if we select these words as representative words. The disadvantage is that these wo rds have poor coverage. For example, the word  X   X  (parallel database) only appears in about 10 user records. In other words, we are not able to discover enough potential experts if we use these words as representative words. This leads to a negative impact on the new word detection task.
Based on the above observations, we should consider both coverage and discrim-inability to select representative words. We treat coverage and discriminability equally to select representative words. We rank wo rds according to Equation (9) and select the top 1,000 words as the representative word s. Table VIII shows the corresponding re-sults. In general, words listed in Table VIII have good discriminability as well as wide enough coverage. On one hand, they are used more frequently than words in Table VII. On the other hand, they maintain better discriminability than words in Table VI. As a result, we are confident to find enough potential experts using these words. We demon-strate how to find potential experts and detect new words in the next subsections. 5.4.2 Finding Potential Experts. We have two ways to find potential experts in specific areas. The first way is to utilize user configuration files. We can label users who ex-plicitly choose the domain-specific lexicons as experts. However, users may randomly choose some domain-specific lexicons and indicate that they are experts. For example, about 40.3 percent of users choose  X  X diom and saying X  lexicon in their configuration files but use less than 10 words in that lexicon. It is not reliable to label these users as potential experts. Furthermore, we rank users according to the number of words they have used in the corresponding lexicons. We plot the data on a log-log graph in Figure 6, with the axes being log ( rank )and log ( number ). This distribution roughly fol-lows Zipf X  X  law [Newman 2005], which indicates that many users use few domain-specific words although they choose domain-specific lexicons in their configuration files. As a result, it is not reliable to find potential experts using user configuration files.

Alternatively, we can find potential experts using representative words generated in the previous step. The more frequently these representative words appear in a user X  X  record, the more likely he/she is a potentia l expert. We select 1,000 representative words in each domain-specific lexicon. Similarly, we rank users according to the num-ber of representative words they have used. We select the top 8,000 users as potential experts. As shown in Figure 7, these representative words are frequently used by a small percentage of users. These users are potential experts that we are trying to find. Then we are trying to detect new words by analyzing user behaviors in the community of these potential experts.
 5.4.3 Detecting New Words. As discussed before, we have discovered potential experts in particular domains. These experts tend to have similar tastes on certain terminolo-gies, while other users seldom use them. Based on this observation, we detect new words according to how unbalanced the distri butions of them in potential experts and other users are. If a word is widely used by potential experts and rarely appear in other users X  records and it is absent from the original lexicon, then we believe that this word is a new word that should be included. Table IX shows the top 30 new words in com-puter science detected by our method. Most of these words have strong relationships with computer science, which indicates that our method is effective.

Specifically, we adopt Equation (8) to measure the discriminability which can dis-tinguish potential experts from other users. Then Equation (9) is used to rank the candidate new words. Candidates with higher scores are more likely to be new words. We select the top 2,000 words according to t heir scores. Then we filter words that are included in the original lexicon and get 1,629 new words. We ask five volunteers with a strong background in computer science to judge whether a word is related to computer science. The final results are made based on their votes. As shown in Table X, our method gains up to 0.86 in accuracy, which me ans that 1,400 out of 1,629 detected new words are related to computer science. It is promising that our method gets 1.0 and 0.92 in P@30 and P@100 respectively. Based on these observations, we are confident to claim that it is helpful to incorporate use r behaviors in the new word detection task. In this article, we propose a novel method for unsupervised related word retrieval and weakly supervised new word detection tasks. Different from previous methods, we take user behaviors, collaborative filtering, and re-ranking framework into considera-tion. We make a reasonable assumption that if two words frequently co-occur in user records, then they are likely to have a stro ng semantic connection with each other. Based on this assumption, we generate a list of candidate words that are related to the seed words. Then we utilize search engines to extract context features and further enhance the performance of related word retrieval task.

Furthermore, we observe that we can get b etter performance with multiple and discriminative seed words. Then we extend our unsupervised related word retrieval method to solve weakly supervised new word detection task. From the domain-specific lexicons which contain some discriminative terminologies, we first find potential ex-perts who use these terminologies frequently. Then, we investigate user behaviors of these potential experts. We believe that words used much more frequently among po-tential experts than other users are new words for the given domain. Experimental results on the both tasks show the effectiveness of our method. Our method for the both tasks is language independent and can be easily extend to other languages.
However, we observe some noisy results in both tasks. The main reason is that our data set is generated from Chinese input method users. Users can type in whatever they want when using an input method. How to filter the noisy words will be left as our future work. We also plan to utilize learning to rank literature [Liu 2009] to improve the performance of related word retrieval tasks. We can extract more features and build a labeled training set. Then various machine learning techniques can be used for both tasks.

Another problem of our new word detection is that the set of representative words is relatively small. We require a lot of manual efforts to evaluate the performance of both tasks, which is time-consuming and expensive. We can try some extrinsic evaluation methods by applying our detected new words in other applications such as Chinese new word detection and automatic speech recognition. Moreover, how to automatically detect new words and collect domain-specific knowledge for emerging new domains is also an interesting problem.

Finally, it is important to build an accurate and complete ground truth for the re-lated word retrieval task. This is difficult because we may need a lot of manual efforts. Moreover, people may have different opinions on whether two words are related or not which makes this task more complicated.

