 Events convey semantic information such as who did what to whom where and when. They also corefer to each other, playing a role of discourse connection points to form a coherent story. These aspects of events have been already utilized in a wide variety of natural language processing (NLP) applications, such as automated population of knowledge bases (Ji and Grishman, 2011), topic detection and tracking (Allan, 2002), question an-swering (Bikel and Castelli, 2008), text summa-rization (Li et al., 2006), and contradiction detec-tion (de Marneffe et al., 2008). This fact illustrates the importance of event extraction and event coref-erence resolution.

Those semantic and discourse aspects of events are not independent from each other, and in fact often work in interactive manners. We give two examples of the interactions: E1 corefers to E2, and E3 does to E4. E2 is more abstract than E1, and has less evidence of being an event. E4 is a pronoun, and thus may seem to refer to an entity rather than an event. Thus, E2 and E4 are relatively difficult to be recognized as events by themselves. However, event coref-erence E1-E2, which is supported primarily by E2 X  X  participants Barclays and Zaragozano shared with E1, helps determine that E2 is an event. The same logic applies to E3 and E4. On the other hand, previous works typically rely on a pipelined model that extracts events (e.g., E1 and E3) at the first stage, and then resolves event corefer-ence at the second stage. Although this modularity is preferable from development perspectives, the pipelined model limits the interactions. That is, the first stage alone is unlikely to detect E2 and E4 as events due to the difficulties described above. These missing events make it impossible for the second stage to resolve event coreference E1-E2 and E3-E4.
 In this work, we address the problem using the ProcessBank corpus (Berant et al., 2014). Follow-ing the terminology defined in the corpus, we in-troduce several terms: We aim to explore the interactions between event mentions and event coreference. As a first step to-ward the goal, we focus on the task of identifying event triggers and resolving event coreference, and propose a document-level joint learning model us-ing structured perceptron (Collins, 2002) that si-multaneously predicts them. Our assumption is that the joint model is able to capture the interac-tions between event triggers and event coreference adequately, and such comprehensive decision im-proves the system performance. For instance, the joint model is likely to extract E2 as well as E1 successfully via their event coreference by simul-taneously looking at coreference features.

Our contributions are as follows: 1. This is the first work that simultaneously pre-2. The incremental token-based prediction in 3. Our experiments indicate that the joint model No previous work deals with event extraction and event coreference resolution simultaneously. We thus describe how these two tasks have been ad-dressed separately, and how joint structured learn-ing has been studied in other NLP tasks.

Event extraction has been studied mainly in the newswire domain and the biomedical domain as the task of detecting event triggers and deter-mining their event types and arguments. In the for-mer domain, most work took a pipelined approach where local classifiers identify triggers first, and then detect arguments (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Li et al. (2013) presented a structured perceptron model to detect triggers and arguments jointly. Simi-larly, joint dependencies in events were also ad-dressed in the latter domain (Poon and Vander-wende, 2010; McClosky et al., 2011; Riedel and McCallum, 2011; Venugopal et al., 2014). How-ever, none of them incorporated event coreference into their model.

Event coreference resolution is more chal-lenging and less explored. To set up event triggers as a starting point of the task, some works use hu-man annotation in a corpus (Bejan and Harabagiu, 2014; Liu et al., 2014), and others use the output of a separate event extraction system (Lee et al., 2012). Berant et al. (2014) presented a model that jointly predicts event arguments and event coref-erence (as well as other relations between event triggers). However, none of them tries to predict event triggers and event coreference jointly.
Joint structured learning has been applied to several NLP tasks, such as word segmenta-tion and part-of-speech (POS) tagging (Zhang and Clark, 2008a), POS tagging and dependency pars-ing (Bohnet and Nivre, 2012), dependency pars-ing and semantic role labeling (Johansson and Nugues, 2008), the extraction of event triggers and arguments (Li et al., 2013), and the extraction of entity mentions and relations (Li and Ji, 2014). Their underlying ideas are similar to ours. That is, one can train a structured learning model to globally capture the interactions between two rel-evant tasks via a certain kind of structure, while making predictions specifically for these respec-tive tasks. However, no prior work has studied the interactions between event trigger identifica-tion and event coreference resolution. We formalize the extraction of event triggers and event coreference as a problem of structured pre-diction. The output structure is a document-level event graph where each node represents an event trigger, and each edge represents an event corefer-ence link between two event triggers. 3.1 Corpus The ProcessBank corpus consists of 200 para-graphs from the textbook Biology (Campbell and Reece, 2005). Table 1 shows statistics of our data splits. The original corpus provides 150 para-graphs as training data, and we split them into 120 and 30 for our training and development, respec-tively. We chose ProcessBank instead of a larger corpus such as the Automatic Content Extraction (ACE) 2005 corpus for the following two reasons. First, the human annotation of event coreference links in ProcessBank enables us to apply the best-first clustering directly; on the other hand, this is not readily feasible in ACE 2005 since it anno-tates event coreference as clusters, and gold stan-dard event coreference links required for the best-first clustering are not available. Second, event coreference resolution using ProcessBank is novel since almost no previous work on the task used that corpus. The only exception could be (Berant et al., 2014), where they extracted several types of relations between event triggers, including event coreference. However, they did not report any performance scores of their system specifically on event coreference, and thus their work is not com-parable to ours.

Unlike previous work (Berant et al., 2014; Li et al., 2013), we explicitly allow an event trigger to have multiple tokens, such as verb phrase  X  X ook into X  and compound proper noun  X  X orld War II X . This is a more realistic setting for event trigger identification since in general there are a consid-3.2 Event Graph Learning Let x denote an input document with n to-kens where x i is the i -th token in the docu-ment. For event graph learning, we use structured perceptron (Collins, 2002), and average weights to reduce overfitting as suggested in (Collins, 2002). The algorithm involves decoding to gener-ate the best event graph for each input document. We elaborate on our decoding algorithm in Sec-tion 3.3. Since an event graph has an exponen-tially large search space, we use beam search to approximate exact inference. We extract a range of features by using Stanford CoreNLP (Manning et al., 2014), MATE (Bj  X  orkelund et al., 2009), Levin verb classes (Levin, 1993). For brevity, we provide details of the structured perceptron algo-rithm and features in the supplementary material.
We use the standard-update strategy in our structured perceptron model. As variants of struc-tured perceptron, one could employ the early up-date (Collins and Roark, 2004) and max-violation update (Huang et al., 2012) to our model. Our initial experiments indicated that early updates happen too early to gain sufficient feedback on weights from entire documents in training exam-ples, ending up with a poorer performance than the standard update. This contrasts with the fact that the early-update strategy was successfully ap-plied to other NLP tasks such as constituent pars-ing (Collins and Roark, 2004) and dependency parsing (Zhang and Clark, 2008b). The main rea-son why the early update fell short of the stan-dard update in our setting is that joint event trigger identification and event coreference resolution is a much more difficult task since they require more complex knowledge and argument structures. Due to the difficultly of the task, it is also very difficult to develop such an effective feature set that beam search can explore the search space of an entire document thoroughly with early updates. This ob-servation follows (Bj  X  orkelund and Kuhn, 2014) on entity coreference resolution. In contrast, the max-violation update showed almost the same perfor-mance as the standard update on the development data. From these results, we chose the standard-update strategy for simplicity. 3.3 Joint Decoding Given that an event trigger has one or more to-kens, event trigger identification could be solved as a token-level sequential labeling problem with BIO or BILOU scheme in the same way as named entity recognition (Ratinov and Roth, 2009). If one uses this approach, a beam state may repre-sent a partial assignment of an event trigger. How-ever, event coreference can be explored only from complete assignments of an event trigger. Thus, one would need to synchronize the search process of event coreference by comparing event corefer-ences from the complete assignment at a certain position with those from complete assignments at following positions. This makes it complicated to implement the formalization of token-level se-quential labeling for joint decoding in our task. One possible way to avoid this problem is to ex-tract event trigger candidates with a preference on high recall first, and then search event coreference from those candidates, regarding them as com-plete assignments of an event trigger. This recall-oriented pre-filtering is often used in entity coref-erence resolution (Lee et al., 2013; Bj  X  orkelund Algorithm 1 Joint decoding for event triggers and coreference with beam search.
 and Farkas, 2012). In our initial experiments, we observed that our rule-based filter gained around 97% recall, but extracted around 12,400 false posi-tives against 823 true positives in the training data. This made it difficult for our structured perceptron to learn event triggers, which underperformed on event coreference resolution.

We, therefore, employ segment-based decod-ing with multiple-beam search (Zhang and Clark, 2008a; Li and Ji, 2014) for event trigger identi-fication, and combine it with the best-first clus-tering (Ng and Cardie, 2002) for event coref-erence resolution in document-level joint decod-ing. The key idea of segment-based decoding with multiple-beam search is to keep previous beam states available, and use them to form segments from previous positions to the current position. Let l max denote the upper bound on the number of tokens in one event trigger. The k -best partial structures (event subgraphs) in beam B at the j -th token is computed as follows:
B [ j ] = k -B EST where 1  X  l  X  l max , y [1: j ] is an event subgraph ending at the j -th token, and y [ j  X  l +1 ,j ] = s means that partial structure y [ j  X  l +1 ,j ] is a segment, i.e., an event trigger candidate with a subsequence of tokens x [ j  X  l +1 ,j ] . This approximates Viterbi de-coding with beam search.

The best-first clustering incrementally makes coreference decisions by selecting the most likely antecedent for each trigger. Our joint decoding algorithm makes use of the incremental process to combine the segment-based decoding and best-first clustering. Algorithm 1 shows the summary of the joint decoding algorithm. Line 3 -7 imple-ments the segment-based decoding, and line 8 -11 implements the best-first clustering. Once a new event trigger is appended to an event subgraph at line 6, the decoder uses it as a referring mention regardless of whether the event subgraph is in the beam, and seeks the best antecedent for it. This enables the joint model to make a more global decision on event trigger identification and event coreference decision, as described in Section 1. When training our model, we observed that 20-iteration training almost reached convergence, and thus we set the number of iterations to 20. We set l max to 6 because we observed that the longest event trigger in the entire ProcessBank corpus has six tokens. When tuning beam width k on the de-velopment set, large beam width did not give us a significant performance difference. We attribute this result to the small size of the development data. In particular, the development data has only 28 event coreferences, which makes it difficult to reveal the effect of beam width. We thus set k to 1 in our experiments. 4.1 Baseline Systems Our baseline is a pipelined model that divides the event trigger decoding and event coreference de-coding in Algorithm 1 into two separate stages. It uses the same structured perceptron with the same hyperparameters and feature templates. We choose this baseline because it clearly reveals the effectiveness of the joint model by focusing only on the architectural difference. One could develop other baseline systems. One of them is a determin-istic sieve-based approach by Lee et al. (2013). A natural extension to the approach for performing event trigger identification as well as event coref-erence resolution would be to develop additional sieves to classify singletons into real event triggers or spurious ones. We leave it for future work. 4.2 Evaluation We evaluate our system using a reference implementation of coreference scoring algo-rithms (Pradhan et al., 2014; Luo et al., 2014). As for event trigger identification, this scorer computes precision (P), recall (R), and the F1 score. With respect to event coreference reso-lution, the scorer computes MUC (Vilain et al., metrics CEAF m and CEAF e (Luo, 2005), and BLANC (Recasens and Hovy, 2011) extended by Luo et al. (2014). We also report the CoNLL av-erage (Denis and Baldridge, 2009), which is the We first show the result of event coreference reso-lution on the test data in Table 2. The joint model outperforms the baseline by 6.9 BLANC F1 and 1.8 CoNLL F1 points. We observed that this over-all performance gain comes largely from a preci-sion gain, more specifically, substantially reduced false positives. We explain the superiority of the joint model as follows. In the baseline, the second stage uses the output of the first stage. Since event triggers are fixed at this point, the baseline ex-plores coreference links only between these event triggers. In contrast, the joint model seeks event triggers and event coreference simultaneously, and thus it explores a larger number of false positives in the search process, thereby learning to penalize false positives more adequately than the baseline. Table 3: Results of event trigger identification.  X  X aseline X  refers to the first stage of our baseline.
Table 3 shows the results of event trigger iden-tification on the test data. We observed that the joint model also reduced false positives, similarly in event coreference resolution. However, its im-provement on precision is small, ending up with almost the same F1 point as the baseline. We spec-ulate that this is due to the small size of the corpus, and the joint model was unable to show its advan-tages in event trigger identification.

Below are two error cases in event coreference resolution, where our model fails to resolve E5-E6 and E7-E8. The model was unable to ade-quately extract features for both event triggers and event coreference, particularly because their sur-face strings are not present in training data, they are lexically and syntactically different, and they do not share key semantic roles (e.g., agents and patients) in a clear argument structure. We present a joint structured prediction model for event trigger identification and event coreference resolution. To our knowledge, this is the first work that solves these two tasks simultaneously. Our experiment shows that the proposed method ef-fectively penalizes false positives in joint search, thereby outperforming a pipelined model substan-tially in event coreference resolution.
 There are a number of avenues for future work. One can further ensure the advantage of the joint model using a larger corpus. Our preliminary ex-periment on the ACE 2005 corpus shows that due to its larger document size and event types, one will need to reduce training time by a distributed learning algorithm such as mini-batches (Zhao and Huang, 2013). Another future work is to incorpo-rate other components of events into the model. These include event types, event arguments, and other relations such as subevents. One could lever-age them as other learning targets or constraints, and investigate further benefits of joint modeling. This research was supported in part by DARPA grant FA8750-12-2-0342 funded under the Deep Exploration and Filtering of Text (DEFT) Pro-gram, and by U.S. Army Research Office (ARO) grant W911NF-14-1-0436 under the Reading, Ex-traction, and Assembly of Pathways for Eviden-tiary Reading (REAPER) Program. Any opinion, findings, and conclusions or recommendations ex-pressed in this material are those of the authors and do not necessarily reflect the view of DARPA, ARO, or the U.S. government. Jun Araki is partly supported by a Funai Overseas Scholarship.
