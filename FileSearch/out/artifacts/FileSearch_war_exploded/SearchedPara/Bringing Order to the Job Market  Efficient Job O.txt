 E-recruitment uses a range of web-based technologies to find, evaluate, and hire new personnel for organizations. A crucial challenge in this arena lies in the categorization of job offers: candidates and operators often explore and analyze large numbers of offers and profiles through a set of job categories. To date, recruitment organizations de-fine job categories top-down, relying on standardized vo-cabularies that often fail to capture new skills and require-ments that emerge from dynamic labor markets. In order to support e-recruitment, this paper presents a dynamic, bottom-up method to automatically enrich and revise job categories. The method detects novel, highly characterizing terms in a corpus of job offers, leading to a more effective categorization, and is evaluated on real-world data by Mul-tiposting (http://www.multiposting.fr/en), a large French e-recruitment firm.
 E-Recruitment, Job Categorization, Classification
E-recruitment can be defined as the process of matching people to appropriate jobs using different on-and off-line strategies and technologies. As the number of candidates and jobs varies by expanding, shifting, and contracting, the recruitment process presents remarkable challenges in infor-mation management, indexing, and matching. The usage of the web helps employers reach larger population of candi-dates, lowering geographic barriers [10]. Several companies currently handle large volumes of job offers and applications across the globe, including Multiposting (multiposting.fr), LinkedIn (linkedin.com), and Monster (monster.com).
 Conventional recruitment methods deployed in Human Resource Management (HRM) are notorious for being costly and time-consuming, particularly when applied to large pools of offers and candidates. Since the 1970s, job categorization has been used in human resources departments for personnel c  X  selection and promotion, as well as for salary administration [2], and is currently recognized as a major issue in recruit-ment [1, 4]. To tackle the complexity of the matching pro-cess, a common approach relies on the categorization of job offers, identifying and grouping salient characteristics, tasks, and skills. Top-down categorizations encode domain knowl-edge, and are commonly used to explore, search, and analyze data. While fully bottom-up, keyword-based techniques can be applied to e-recruitment, curated and human-readable categorizations are necessary to obtain high-quality results, reducing the noise in the matching.

Existing categorization strategies fail to identify the terms that capture salient aspects in the descriptions of potential candidates. Similarly, job descriptions contain vague and overly generic information, which is hard to exploit in the matching process. Moreover, the vocabulary used by em-ployers and recruiters change over time, reflecting the evo-lution of the labor market. For this reason, the detection of these variations is key to design an effective job categoriza-tion strategy that reflects the underlying data more closely.
Let us consider for example a category descriptor related to computer programming. The  X  X rogramming languages X  field might present a fixed list of keywords including popu-lar languages (e.g., Java, C++, Python), without including recent languages such as Clojure or Swift that are likely to be in high demand in the immediate future. In this context, it is considerably hard, even for a domain expert, to update the descriptors, anticipating the rapid changes in the in-dustry. To tackle the challenges of e-recruitment, top-down and bottom-up approaches need to be leveraged, updating expert-defined resources with dynamic knowledge extraction from the data.

In this paper, we propose a data-driven, bottom-up ap-proach to enrich the textual descriptions of job categories. Given a domain categorization, the approach automatically updates the terms from the corpus of job offers. The en-riched descriptions are then used to support a field-to-field similarity computation in the matching between jobs and candidate categories. The matching focuses on the differ-ences between structured textual fields and the extracted terms, maximizing the probability of a correct classification. The proposed approach is evaluated in different application contexts on real-world data collected by Multiposting, one of the largest companies in the e-recruitment sector. The French company provides a web platform for e-recruitment, and processes more than 3M job offers per year and 100M applications in 50 countries. Figure 1: Flow diagram of the proposed hybrid job offer categorization method.
The objective of this work is to support the categorization of a corpus of job offers by semantically enriching the job categories with recent and contextually relevant terms. The flowchart of the method is showed in Figure 1. In this study, we define two entities: job offers and job categories.
A job offer can be defined as a structured text document that formalizes an offer of employment, authored by an em-ployer. A job offer contains textual fields, such as  X  X ompany description, X   X  X equired skills, X   X  X ducation level, X  depending on the specific conceptualization. Formally, a job offer o as a set of keyword vectors, each one representing a textual field o = { ~o 1 ,..., ~o k } where k is the total number of textual fields in job offer o , and ~o i (with i &lt; k ) is a vector of weighted keywords, which represents the frequency of terms of its i -th field. Each component w k,i of ~o i is the term weight of the i -th vocabulary term in the k -th field of the considered job offer. This weight is calculated as: where tf k,i is the term frequency value of the i -th vocab-ulary term in k -th field. M is the entire set of job categories and m i the number of job categories containing the i -th term in at least one field.

A job category is a description of a type of jobs provided by a domain expert, and has a structure analogous to that of job offers. We formalize a job category c as a set of vectors c = { ~c 1 ,..., ~c l } where l is the number of textual fields in the job category description, and c j a vector of weighted keywords that represent the frequency of terms of the j -th field of the job category (with j &lt; l ).
Given a corpus of job offers and job categories, we want to enrich a category c to a c 0 that includes new keywords to better reflect the job offers. As a first step, we retrieve the set of most representative categories for each job offer, quantifying the representativeness of categories through the cosine similarity of vector sums. Formally, for each offer o  X  O , we compute the cosine similarity cos with category c as: For each offer, we sort all categories in C in decreasing order in terms of similarity to ~o . As the similarity values in this context follow a power law, we select a subset of categories so that the sum of their similarities sim reach 90% of the sum of all similarities P l j =1 sim ( o,c j ), excluding the tail of categories with low similarities [8]. At the end of step, each job offer in O has a non-empty set of categories associated to it.

Using these sets, we search for the most contextually in-formative keywords for each category. The relevance weight rw c,x of a candidate keyword x for category c is computed as: where r c,x is the number of job offers associated to the cate-gory c containing the keyword x , and n x is the total number of job offers containing x . R c is the number of job offers as-sociated to the category c , and N is the total number of job offers in the corpus. Intuitively, the keywords that appear frequently only in specific associations and rarely in others will tend to have higher weights.

Subsequently, for each category, we select the terms hav-ing a positive enrichment value as as a set of enriching key-words K x  X  c . This set is used to compute the enrichment vector to be added to the original job category vector c . The enrichment weight e c,x of the term x for category c is calculated as: where rw c,x is the relevance weight, r c,x is the number of job offers associated to the category. M the total number of job categories, and m x is the number of job categories c containing the term x in its keywords set K x  X  c . The homogeneity of the function is assured by expressing rw c,x as a sum of probabilities while log ( M m probability of observing term x in a category [9].

Finally, we define the enriched job category as an extended set of vectors c 0 = { ~c 1 , ~c 2 ,..., ~c l , ~ev c } where ~ev knowledge extracted from the corpus. The other vectors of the category remain unchanged.
A job offer o can now be matched against the enriched job categories. For this purpose, we define a field-to-field simi-larity (FtFs) matching approach, taking into account both the information extracted from the corpus and the structure of the original data. First, we define a FtFs matrix as:
S ( o,c 0 ) = Table 1: The corpus of job offers and categories provided by Multiposting and P X ole Emploi.
 Each element s ( o,c 0 ) i,j represents the normalized similarity between the i -th field of the offer o (with i &lt; k ) and the j -th textual field of the enriched category c 0 (with j &lt; l ), that is: where cos denotes the cosine vector similarity. This similar-ity calculation leverages the differences between the fields. For instance, the offer of a programming job can have highly discriminant terms in the  X  X kills X  field, but not in the  X  X m-ployer description X  field, which contains a set of general terms occurring in all offers by the same employer. Fol-lowing this intuition, the similarity s between the offer o and the enriched category c 0 is therefore calculated as: where  X  i,j is a similarity probability between textual field calculated based on a training data-set (see [5] for details). The higher s ( o,c ), the more similar the offer o to the con-sidered category c . The function has no upper bound, while the lower bound is 0.

At the end of this matching step, we have a matching score s ( o,c 0 ) for each enriched category c 0 . The last step consists of the selection of the most similar categories, ob-taining the strength of association between job offer o and a set of enriched categories c 0 . This data-driven categorization embeds knowledge from the corpus of job offers, overcoming the limitations of the initial static categorization.
The proposed categorization approach was evaluated through several experiments, using real job offers and job categories. For the evaluation, company Multiposting provided a cor-pus of 215,375 job offers, advertised on its online platform from 2009 to 2014. A set of 531 static job categories was ob-tained from P X ole Emploi, the French governmental agency that supports job seekers (www.pole-emploi.fr). The cate-gories are part of the R  X epertoire Op  X erationnel des M  X etiers et des Emplois (ROME) nomenclature, which can be seen as the French equivalent of O*NET, a job categorization widely used in the US (www.onetcenter.org) [3].

A job category by P X ole Emploi is structured into 8 textual fields ( X  X itle, X   X  X efinition,  X  X dmission, X   X  X onditions, X   X  X nviron-ment X   X  X ompetences, X   X  X ctivities, X  and  X  X abor mobility X ), and is linked to manually defined similar categories. By contrast, the Multiposting job offers have only 4 textual fields:  X  X itle, X   X  X ob description, X   X  X andidate profile, X  and  X  X ompany descrip-tion. X  Both offers and categories are in French. Table 1 summarizes the characteristics of these data-sets.

As ground truth to evaluate our approach, we produced an annotated set of 1,339 job offers, randomly selected from the corpus. Two teams of 3 domain experts performed a manual categorization, manually selecting the most fitting category for each job. When the experts disagreed about the categorization of a job, the conflict was discussed and resolved. In the instances where the conflicts were not easily settled, the job offers were discarded as too ambiguous.
To obtain a realistic picture, we applied four methods to the manually-generated data-set, comparing the perfor-mance of our approach with three alternative methods: Error rate ( E ). First, we observed the categorization er-rors with respect to the ground truth. The error rate E 1 calculated as 1  X  p , where p is the categorization precision with respect to the top category selected by each of the four approaches. E 1 ranges from 0 to 1, where 0 means a perfect categorization, and 1 is an entirely wrong categorization. Receiver Operating Characteristic ( AAC-ROC ).
 This measure evaluates binary classifiers by plotting two pa-rameters: TP rate (fraction of True Positives) and FP rate (fraction of False Positives) [7]. To compare the methods, it is possible to reduce the ROC to a single scalar value by measuring the area above the curve (AAC), which quantifies the overall error.

Hinge-Loss ( HL ). The Hinge-Loss function computes the average distance between the proposed model and the valid data for multi-class categorizations[6]. For each job offer, HL considers the vector of similarity values of all cate-gories generated by a method. This vector is then compared to the ground truth vector, in which the correct category is marked as 1, while the others are set to 0. The distance between a vector and the ground truth is inversely propor-tional to the quality of the categorization method.

As the top category is particularly important, we first ob-served the results for the top ranked category argmax c s ( o,c ) with indicators HL 1 and AAC-ROC 1 . Subsequently, consid-ering that the each category in the ROME nomenclature also points to similar categories, we tested if the candidate cate-gory proposed by each approach falls in this extended set of valid categories, with indicators E sim and HL sim . As the results in Table 2 show, our Enriched Field-to-Field Similarity method ( e-FtFs ) outperforms the alterna-tive methods with respect to all of the evaluation metrics. More specifically, e-FtFs obtained 0.25 for E 1 , and 0.21 for E sim . Considering the fact that job offers and categories were generated by different communities using different vo-cabularies, in different time ranges, we consider this error e-FtFs 0.25 0.21 0.645 0.472 0.152 Table 2: Performance of the proposed approach ( e-FtFs ) compared with three alternatives, on a set of 1,339 job offers and 531 job categories. rate promising. The HL indicators follow a similar trend, showing that the e-FtFs performs better than the other methods even when adopting a fuzzy categorization.

With respect the other indicators, HL shows higher er-ror values. This is due to the fact that we compare the performance of a fuzzy classifier (the automatic method) with a binary one (the manual classification). As a result, the evaluation is very pessimistic: to obtain an error value equals to 0, the method should return a null vector with only the correct category set to 1. While both e-CM and FtFs outperform the simple cosine measure CM , the best perfor-mance is obtained only when combining the two methods into e-Ftfs , confirming the benefits of both the bottom-up category enrichment and the field-to-field similarity.
In this paper, we presented a novel categorization method targeted at industrial applications in e-recruitment. Our method semantically enriches the job categories, and then leverages the structure of textual documents using a field-to-field similarity comparison. The approach was evaluated on real-world data by the French corporation Multiposting. The experiments showed several improvements in the task of job categorization, providing a novel solution for weaving dynamic, bottom-up knowledge into static job categories.
The classification problem of job offers we tackled in this paper deserves further investigation. We plan to explore al-ternative families of categorization approaches, drawing on supervised and unsupervised machine learning techniques. While our current approach relies on a bag of words model, performance might be improved with more semantic knowl-edge, for example clustering synonyms, hypernyms, and hy-ponyms. To better support the exploration and search of job offers, we will integrate named entity recognition and classification (NERC) into the method, identifying compa-nies, universities, and government agencies. The usability of the job categories might also be improved by grouping them into meaningful hierarchies, helping e-recruitment operators face rapidly changing labor markets.
 [1] R. Boselli, M. Cesarini, F. Mercorio, and M. Mezzan-[2] E. T. Cornelius, T. J. Carron, and M. N. Collins. Job [3] E. C. Dierdorff, J. J. Norton, C. M. Gregory, D. Rivkin, [4] T. Gonzalez, P. Santos, F. Orozco, M. Alcaraz, V. Zal-[5] E. Malherbe, M. Diaby, M. Cataldi, E. Viennet, and [6] R. Moore and J. DeNero. L1 and L2 Regularization for [7] Z. Omary and F. Mtenzi. Machine learning approach [8] Y.-J. Park and A. Tuzhilin. The Long Tail of Recom-[9] I. Ruthven and M. Lalmas. A survey on the use of [10] S. Snell, S. Morris, and G. Bohlander. Managing Hu-
