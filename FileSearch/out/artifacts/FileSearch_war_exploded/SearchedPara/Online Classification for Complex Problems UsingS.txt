 In this paper we discuss and analyze a framework for devising efficient online learning algorithms for complex prediction problems such as multiclass categorization. In the settings we cover, a com-plex prediction problem is cast as the task of simultaneously coping with multiple simplified sub-problems which are nonetheless tied together. For example, in multiclass categorization, the task is to predict a single label out of k possible outcomes. Our simultaneous projection approach is based on the fact that we can retrospectively (after making a prediction) cast the problem as the task of making k  X  1 binary decisions each of which involves the correct label and one of the competing labels. The performance of the k  X  1 predictions is measured through a single loss. Our approach stands in contrast to previously studied methods which can be roughly be partitioned into three paradigms. The first and probably the simplest previously studied approach is to break the problem into multiple decoupled problems that are solved independently . Such an approach was used for instance by Weston and Watkins [ 1 ] for batch learning of multiclass support vector machines. The simplicity of this approach also underscores its deficiency as it is detached from the original loss of the complex decision problem. The second approach maintains the original structure of the problem but focuses on a single, worst performing, derived sub-problem (see for instance [ 2 ]). While this approach adheres with the original structure of the problem, the resulting update mechanism is by construction sub-optimal as it oversees almost all of the constraints imposed by the complex pre-diction problem. (See also [ 6 ] for analysis and explanation of the sub-optimality of this approach.) The third approach for dealing with complex problems is to tailor a specific efficient solution for the problem on hand. While this approach yielded efficient learning algorithms for multiclass cate-algorithms required dedicated efforts. Moreover, tailored solutions typically impose rather restric-tive assumptions on the representation of the data in order to yield efficient algorithmic solutions. In contrast to previously studied approaches, we propose a simple, general, and efficient framework for online learning of a wide variety of complex problems. We do so by casting the online update task as an optimization problem in which the newly devised hypothesis is required to be similar to the current hypothesis while attaining a small loss on multiple binary prediction problems. Casting the online learning task as a sequence of instantaneous optimization problems was first suggested and analyzed by Kivinen and Warmuth [ 12 ] for binary classification and regression problems. In our optimization-based approach, the complex decision problem is cast as an optimization problem that consists of multiple linear constraints each of which represents a simplified sub-problem. These constraints are tied through a single slack variable whose role is to asses the overall prediction quality for the complex problem. We describe and analyze a family of two-phase algorithms. In the first phase, the algorithms solve simultaneously multiple sub-problems. Each sub-problem distills to an optimization problem with a single linear constraint from the original multiple-constraints problem. The simple structure of each single-constraint problem results in an analytical solution which is efficiently computable. In the second phase, the algorithms take a convex combination of the independent solutions to obtain a solution for the multiple-constraints problem. The end result is an approach whose time complexity and mistake bounds are equivalent to approaches which solely deal with the worst-violating constraint [ 9 ]. In practice, though, the performance of the simultaneous projection framework is much better than single-constraint update schemes. In this section we introduce the notation used throughout the paper and formally describe our prob-lem setting. We denote vectors by lower case bold face letters (e.g. x and  X  ) where the j  X  X h element of x is denoted by x j . We denote matrices by upper case bold face letters (e.g. X ), where the j  X  X h hinge function [ a ] + = max { 0 , a } .
 Online learning is performed in a sequence of trials. At trial t the algorithm receives a matrix X t of size k t  X  n , where each row of X t is an instance, and is required to make a prediction on the in the prediction. After making a prediction  X  y t the algorithm receives the correct labels y t where y by calculating the inner product between a weight vector  X  t  X  R n with each instance in X t , thus  X  y t = X t  X  t . Our goal is to perfectly predict the entire vector y t . We thus say that the vector  X  y t error is a computationally difficult task. Therefore, we use an adaptation of the hinge-loss , defined often referred to as the (signed) margin of the prediction and ties the correctness and the confidence In this section we further explore the motivation for our problem setting by describing two different complex decision tasks and showing how they can be cast as special cases of our setting. We also would like to note that our approach can be employed in other prediction problems (see Sec. 7 ). Multilabel Categorization In the multilabel categorization task each instance is associated with a set of relevant labels from the set [ k ] . The multilabel categorization task can be cast as a special case of a ranking task in which the goal is to rank the relevant labels above the irrel-evant ones. Many learning algorithms for this task employ class-dependant features (for ex-ample, see [ 7 ]). For simplicity, assume that each class is associated with n features and de-note by  X  ( x , r ) the feature vector for class r . We would like to note that features obtained for different classes typically relay different information and are often substantially different. A categorizer, or label ranker, is based on a weight vector  X  . A vector  X  induces a score for each class  X   X   X  ( x , r ) which, in turn, defines an ordering of the classes. A learner is required to build a vector  X  that successfully ranks the labels according to their relevance, namely for each pair of classes ( r, s ) such that r is relevant while s is not, the class r should be ranked higher than the class s . Thus we require that  X   X   X  ( x , r ) &gt;  X   X   X  ( x , s ) for every such pair ( r, s ) . We say that a label ranking is imperfect if there exists any pair ( r, s ) which violates this requirement. The loss associated with each such violation is [1  X  (  X   X   X  ( x , r )  X   X   X   X  ( x , s ))] + and the loss of the categorizer is defined as the maximum over the losses induced by the violated pairs. In order to map the problem to our setting, we define a virtual instance for every pair ( r, s ) such that r is relevant and s is not. The new instance is the n dimensional vector defined by  X  ( x , r )  X   X  ( x , s ) . The label associated with all of the instances is set to 1 . It is clear that an imperfect categorizer makes a prediction mistake on at least one of the instances, and that the losses defined by both problems are the same.
 Ordinal Regression In the problem of ordinal regression an instance x is a vector of n features that is associated with a target rank y  X  [ k ] . A learning algorithm is required to find a vector  X  and k thresholds b 1  X   X  X  X   X  b k  X  1  X  b k =  X  . The value of  X   X  x provides a score from which the is violated. In order to map the ordinal regression task to our setting, we introduce k  X  1 instances. if i = j and to 0 otherwise. The label of the first y  X  1 instances is 1 , while the remaining k  X  y instances are labeled as  X  1 . Once we learned an expanded vector in R n + k  X  1 , the regressor  X  is are set to be the last k  X  1 elements. A prediction mistake of any of the instances corresponds to an incorrect rank in the original problem. After performing its prediction, the algorithm receives the corresponding labels y t . Each such by  X  t then  X  t +1 is set to be  X  t and the algorithm proceeds to the next trial. Otherwise, we would like to set  X  t +1 as close as possible to  X  t while satisfying all constraints.
 Such an aggressive approach may be sensitive to outliers and over-fitting. Thus, we allow some of the constraints to remain violated by introducing a tradeoff between the change to  X  t and the As we discuss below, this formalism effectively translates to a cap on the maximal change to  X  t . We rewrite the above optimization by introducing a single slack variable as follows: We denote the objective function of Eq. ( 1 ) by P t and refer to it as the instantaneous primal problem to be solved on trial t . The dual optimization problem of P t is the maximization problem Each dual variable corresponds to a single constraint of the primal problem. The minimizer of the Unfortunately, in the common case, where each x t j is in an arbitrary orientation, there does not exist an analytic solution for the dual problem (Eq. ( 2 )). We tackle the problem by breaking it down into k t reduced problems, each of which focuses on a single dual variable. Formally, for the j  X  X h optimization problem amounts to the following problem We next obtain an exact or approximate solution for each reduced problem as if it were inde-pendent of the rest. We then choose a distribution  X  t  X   X  k t , where  X  k t = {  X   X  R k t : P j  X  j = 1 ,  X  j  X  0 } is the probability simplex, and multiply each  X  t j by the corresponding  X  . Since  X  t  X   X  k t , this yields a feasible solution to the dual problem defined in Eq. ( 2 ) for We next present three schemes to obtain a solu-tion for the reduced problem (Eq. ( 3 )) and then combine the solution into a single update.
 Simultaneous Perceptron: The simplest of the update forms generalizes the famous Perceptron algorithm from [ 8 ] by setting  X  t j to C if the j  X  X h instance is incorrectly labeled, and to 0 otherwise.
 We similarly set the weight  X  t j to be 1 |M t | for j  X  M t and to 0 otherwise. We abbreviate this scheme as the SimPerc algorithm.
 Soft Simultaneous Projections: The soft simul-taneous projections scheme uses the fact that each reduced problem has an analytic solution, yield-ing  X  t j = min C, `  X  t ; ( x t j , y t j ) / x t j 2 . We independently assign each  X  t j this optimal solu-solution may update  X  t j also for instances which were correctly classified as long as the margin they attain is not sufficiently large. We abbreviate this scheme as the SimProj algorithm. Conservative Simultaneous Projections: Combining ideas from both methods, the conservative simultaneous projections scheme optimally sets  X  t j according to the analytic solution. The difference with the SimProj algorithm lies in the selection of  X  t . In the conservative scheme only the instances To recap, on each trial t we obtain a feasible solution for the instantaneous dual given in Eq. ( 2 ). This solution combines independently calculated  X  t j , according to a weight vector  X  t  X   X  k t . While this solution may not be optimal, it does constitutes an infrastructure for obtaining a mistake bound and, as we demonstrate in Sec. 6 , performs well in practice. The algorithms described in the previous section perform updates in order to increase the instanta-neous dual problem defined in Eq. ( 2 ). We now use the mistake bound model to derive an upper bound on the number of trials on which the predictions of SimPerc and ConProj algorithms are imperfect. Following [ 6 ], the first step in the analysis is to tie the instantaneous dual problems to a global loss function. To do so, we introduce a primal optimization problem defined over the en-optimization problem as the following equivalent constrained optimization problem, A competitor who may see the entire sequence of examples in advance may in particular set (  X  ,  X  ) to be the minimizer of the problem which we denote by (  X  ? ,  X  ? ) . Standard usage of Lagrange multipliers yields that the dual of Eq. ( 4 ) is, variables.
 Clearly, the optimization problem given by Eq. ( 5 ) depends on all the examples from the first trial through time step T and thus can only be solved in hindsight. We note however, that if we ensure proceeding round t . As we show next, we use this primal-dual view to derive the skeleton algorithm from Fig. 2 by finding a new feasible solution for the dual problem on every trial. Formally, the instantaneous dual problem, given by Eq. ( 2 ), is equivalent (after omitting an additive constant) to the following constrained optimization problem, to the values set in previous rounds, forcing  X  t +1 through  X  T to the zero vectors, and choosing a omitting constants which do not depend on  X  t Eq. ( 6 ) can be rewritten as, The problems defined by Eq. ( 7 ) and Eq. ( 2 ) are equivalent. Thus, weighing the variables  X  , . . . ,  X  t k  X  t,j =  X  t j  X  t j . We now tie all of these observations together by using the weak-duality theorem. Our first bound is given for the SimPerc algorithm.
 Theorem 1. Let X 1 , y 1 , . . . , X T , y T be a sequence of examples where X t is a matrix of k t examples and y t are the associated labels. Assume that for all t and j the norm of an instance x t j is at most R . Then, for any  X  ?  X  R n the number of trials on which the prediction of SimPerc is imperfect is at most, Proof. To prove the theorem we make use of the weak-duality theorem. Recall that any dual feasible solution induces a value for the dual X  X  objective function which is upper bounded by the optimum above equation as the following sum, perfect ( M t =  X  ) then SimPerc sets  X  t to the zero vector and thus  X  t = 0 . We can thus focus on trials for which the algorithm X  X  prediction is imperfect. We remind the reader that by unraveling the update of  X  t we get that  X  t = P s&lt;t P k s j =1  X  s,j y s j x s j . We now rewrite  X  t as follows, The squared norm, k X k 2 is a convex function in its vector argument and thus  X  t is concave, which yields the following lower bound on  X  t , The SimPerc algorithm sets  X  t j to be 1 / |M t | for all j  X  M t and to be 0 otherwise. Furthermore, written as, We expand the norm in the above equation and obtain that, for every j  X  X  t . Therefore,  X  t can further be bounded from below as follows, where for the second inequality we used the fact that the norm of all the instances is bounded by R . To recap, we have shown that on trials for which the prediction is imperfect  X  t  X  C  X  1 2 C 2 R 2 , while in perfect trials where no mistake is made  X  t = 0 . Putting all the inequalities together we obtain the following bound, where is the number of imperfect trials. Finally, rewriting P (  X  ? ,  X  ? ) as 1 2 k  X  ? k 2 + C P T t =1 ` (  X  ? ; ( X t , y t ) yields the bound stated in the theorem.
 The ConProj algorithm updates the same set of dual variables as the SimPerc algorithm, but selects  X  j to be the optimal solution of Eq. ( 3 ). Thus, the value of  X  t attained by the ConProj algorithm is never lower than the value attained by the SimPerc algorithm. The following corollary is a direct consequence of this observation.
 Corollary 1. Under the same conditions of Thm. 1 and for any  X  ?  X  R n , the number of trials on which the prediction of ConProj is imperfect is at most, Table 1: The percentage of online mistakes of the three variants compared to Max-Update (Single prototype (SP) and Multi prototype (MP)) and the Mira algorithm. Experiments were performed on seven users of the Enron data set.
 Note that the predictions of the SimPerc algorithm do not depend on the specific value of C , thus for R = 1 and an optimal choice of C the bound attained in Thm. 1 now becomes. We omit the proof for lack of space, see [ 6 ] for a closely related analysis.
 We conclude this section with a few closing words about the SimProj variant. The SimPerc and ConProj algorithms ensure a minimal increase in the dual by focusing solely on classification errors and ignoring margin errors. While this approach ensures a sufficient increase of the dual, in practice it appears to be a double edged sword as the SimProj algorithm performs empirically better. This superior empirical performance can be motivated by a refined derivation of the optimal choice for  X  . This derivation will be provided in a long version of this manuscript. In this section we describe experimental results in order to demonstrate some of the mer-its of our algorithms. We tested performance of the three variants described in Sec. 4 on a multiclass categorization task and compared them to previously studied algorithms for multiclass categorization. We compared our algorithms to the single-prototype and multi-prototype Max-Update algorithms from [ 9 ] and to the Mira algorithm [ 2 ]. The experiments were performed on the task of email classification using the Enron email dataset (Available at email messages into user defined folders. Thus, the instances in this dataset are email messages, on the sequence of email messages from 7 different users.
 Since each user employs different criteria for email classification, we treated each person as a sep-arate online learning problem. We represented each email message as a vector with a component for every word in the corpus. On each trial, and for each class r , we constructed class-dependent vectors as follows. We set  X  j ( x t , r ) to twice the number of time the j  X  X h word appeared in the message if it had also appeared in a fifth of the messages previously assigned to folder r . Similarly, construction is closely related to the construction given in [ 10 ]. Next, we employed the mapping described in Sec. 3 , and defined a set of k  X  1 instances for each message as follows. Denote the rel-and set its label to 1 . All these instances were combined into a single matrix X t and were provided to the algorithm in trial t .
 The results of the experiments are summarized in Table 1 . It is apparent that the SimProj algo-rithm outperforms all other algorithms. The performances of SimPerc and ConProj are comparable with no obvious winner. It is worth noting that the Mira algorithm finds the optimum of a projec-tion problem on each trial while our algorithms only find an approximate solution. However, Mira employs a different approach in which there is a single input instance (instead of the set X t ) and constructs multiple predictors (instead of a single vector  X  ). Thus, Mira employs a larger hypothesis space which is more difficult to learn in online settings. In addition, by employing a single vector representation of the email message, Mira cannot benefit from feature selection which yields class-dependent features. It is also obvious that the simultaneous projection variants, while remaining simple to implement, consistently outperform the Max-Update technique which is commonly used in online multiclass classification. In Fig. 3 we plot the cumulative number of mistakes as a function of the trial number for 3 of the 7 users. The graphs clearly indicate the high correlation between the SimP erc and ConP roj variants, while indicating the superiority of the SimP roj variant. We presented a new approach for online categorization with complex output structure. Our algo-rithms decouple the complex optimization task into multiple sub-tasks, each of which is simple enough to be solved analytically. While the dual representation of the online problem imposes a global constraint on all the dual variables, namely P j  X  t j  X  C , our framework of simultaneous projections which are followed by averaging the solutions automatically adheres with this constraint and hence constitute a feasible solution. It is worthwhile noting that our approach can also cope with multiple constraints of the more general form P j  X  j  X  j  X  C , where  X  j  X  0 for all j . The box constraint implied for each individual projection problem distils to 0  X   X  j  X  C/ X  j and thus the simultaneous projection algorithm can be used verbatim. We are currently exploring the usage of this extension in complex decision problems with multiple structural constraints. Another pos-sible extension is to replace the squared norm regularization with other twice differentiable penalty functions. Algorithms of this more general framework still attain similar mistake bounds and are easy to implement so long as the induced individual problems are efficiently solvable. A particu-larly interesting case is obtained when setting the penalty to the relative entropy. In this case we obtain a generalization of the Winnow and the EG algorithms [ 11 , 12 ] for complex classification problems. Another interesting direction is the usage of simultaneous projections for problems with more constrained structured output such as max-margin networks [ 3 ].

