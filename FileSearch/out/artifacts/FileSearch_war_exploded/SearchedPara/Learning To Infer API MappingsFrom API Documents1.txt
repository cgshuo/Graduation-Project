 To support business requirements of different platforms or devices, software de-velopers often need to release several corresponding versions of their software projects or products. Open source projects, like Lucene and JUnit, often support different versions for Linux, Windows and Mac OS X. Then with the develop-ment of mobile devices, application products also release versions correspond-ing to iOS, Android and Windows Phone. Usually, developers often write code under one platform first, then migrate them from the current platform (anno-tated as  X  X he source platform X ) to another (annotated as  X  X he target platform X ). Compared with developing different versions independently, it is usually more economical to make the above migration (Figure 1). Since the programming lan-guages used in the source and target platforms may be different, this migration process is often called language migration or code migration.
 Fig. 1: Migrating Software Projects from One Platform to Another Platform pings between API libraries of the source and target platforms [10, 1, 4]. Here API mappings are defined as the mappings of APIs that belong to different li-braries but implement the same or similar functionality. Since modern software development heavily relies on API libraries[9], code migration usually need to re-place APIs according to the knowledge of API mappings. For example, JavaSE is the basic library for Java projects and .N ET for C# projects. Then API map-pings between the JavaSE library and the .N ET library are important for the migration process of software code from platforms supporting Java to platforms supporting C#.
 ally[10], researchers proposed several code-based approaches to mine API map-pings automatically. These approaches mostly built parallel code bases from software projects X  different versions and took API calling information parsed by static[10, 4, 7, 8] or dynamic[1] code analysis to figure out API mappings. How-ever, they have the issues that there may be no available corresponding versions of software projects and it is usually slow to parse API calling information with the static and dynamic code analysis.
 pings. We find that API documents provide functional information of APIs in API names and descriptions, which can be leveraged to infer APIs of the same or similar functionality. Our assumption is that two APIs have the mapping re-lation if their names or descriptions express similar semantics in functionality. So our approach tries to understand the semantics of API names and descrip-tions first by learning embeddings of words in them. On this basis, we use a text similarity algorithm to compute the semantic similarity of APIs and infer API mappings. Our experiments on JavaSE and .N ET libraries outperform the baseline model at precision@ k (1,5,10,20) by 41.5% averagely. Compared with current code-based work, it is easy to access API documnets. Then the process of word embedding learning and similarity computation is fast and effective to infer API mappings.
 proach to infer API mappings from API documents; Section 3 presents details of the dataset and the experiment results; Section 4 introduces related work; Section 5 gives the conclusion and discusses future work.
 2.1 Overview In API documents, API names and their descriptions provide useful semantic information of APIs X  functionality. Because API documents are originally pub-lished to help developers understand what functions APIs have implemented. If we could understand the semantics of API names and descriptions, it seems to be feasible to infer API mappings based on their similarity.
 the literature[4]. We can find that mapped APIs share words in their names and descriptions, such as  X  X o X ,  X  X xception X ,  X  X ength X  and  X  X ml X . Besides the same words in API names and descriptions, there are also words of relevant semantics in them, such as  X  X ength X  and  X  X umber X ,  X  X equence X  and  X  X tring X . So we proposed the following approach to capture semantic relevance of API names and descriptions based on word embeddings and evaluate API similarity to infer API mappings.
 source and target libraries from their official website and use HTML parser to extract names, descriptions and types of APIs as the preliminary corpus. Then our approach uses the following four steps to infer API mappings:  X  We clean the preliminary corpus with text processing operations, which  X  Then we learn word embeddings so that we can capture semantic relevance  X  Before matching APIs based on the names and descriptions, we need to  X  Finally, for a given API in the source library, we take APIs of the same 2.2 Understanding API Documents tics of words in API documents. The CBOW model is proposed by Mikolov[3] to learn the language model from the natural language corpus. As shown in Figure 3, its basic idea is predicting the intermedia word w t through the previous k tic relevance implicated in co-occurrence of words. Its training objective is to maximize the following log-likelihood function: API to sentences, and merge all the sentences of the source and target libraries together as the training corpus. We expect that the learnt word embeddings by the CBOW model can capture the shared semantics between words in documents of the source and target libraries. 2.3 Computing Similarity between APIs On the basis of learnt word embeddings, we take a text similarity algorithm proposed in the literature[2] to compute the similarity between APIs. Here one concatenated sentence of the API name and description is treated as one bag-of-words. The similarity of two APIs A s and A t is computed as the similarity of two bag-of-words based on the word-to-word similarity, that is: The directed similarity sim ( A s  X  A t ) is computed by the weighted summation of the similarity between words in A s and the text A t . The weights here use IDF (Inverse Document Frequency,) values. As for the similarity sim ( w s , A t ) between A s  X  X  word w s and the text A t , it is defined as the maximal similarity between word w s and all the words in A t . Then the key point of this algorithm is a reasonable measure of the similarity between words. Here we use the cosine similarity between learnt embeddings of words from Section 2.2, which is used widely in natural language processing tasks.
 3.1 Dataset We use the documents of JavaSE and .N ET libraries to evaluate our approach. The text processing operations have been introduced in Section 2.1. Here we present details of transferring API types. Ideally, given an API A s in the source library, its matching candidate A t in the target library should have the same type so that mappings with mis-matched types will not be inferred. For example, APIs of the  X  X ackage X  type should not be matched with APIs of the  X  X lass X  type. However, API types of different libraries are usually different, especially when they support different programming languages. Thus we do statistics on API types of JavaSE and .N ET (the  X  X riginal X  column in Table 3) and predefine a transfer map of API types based on their definitions (Table 2). Finally we get 8 unified API types for these two libraries (the  X  X ransfered X  column in Table 3). 3.2 Experimental Settings We use the Word2Vec module in gensim 0.13.3 1 to implement the CBOW model. Its basic parameters are set as: embedding dimension = 128, the context window = 10 words, training epoch = 200. The training process of CBOW is fast which takes less than 30 minutes on the dataset of Table 3 in the Core i7 CPU. Then the process of computing API similarity is also quick which outputs results averagely for 5  X  10 given APIs per minute of the source libraries. The speed is related to the number of candidate APIs with the same type in the target library. vector of which the dimension is the same as the vocabulary size. If the name or description of the API contains the i th word of the vocabulary, then the value at the i th position of the one-hot vector is 1, otherwise 0. API similarity in the baseline is computed by the cosine similarity of one-hot vectors.
 mappings like  X  X 1 X , we finally get 145 standard mappings from JavaSE to .N ET . The inferred API mappings is evaluated by precision@ k . Given an API A s from the source library, if the standard mapped API A s  X  t of the target library is at the top-k results of inferred matched A t , then we record it as one hit at top-k . The final precision@ k is the ratio of the hitting count at top-k to the total number of test mappings.
 3.3 Results Table 4 shows precision@ k (k=1,5,10,20) results of the baseline and our work (embedding dimension = 128, the context window = 10 words, training epoch = 200). It shows that our work outperforms the baseline at all the k -values, which improves precision@k (1,5,10,20) by 61.95%47.60%34.63%21.86% respectively. The average promotion is 41.51%.
 training parameters of word embeddings. First, we compare results with differ-ent embedding dimensions (Table 5). We find that precision@1 and precision@5 decrease distinctly with the growth of dimension from 128 to 256 then to 512. It shows that 128 dimension is enough for the current corpus to avoid over-fitting. Then we analyze results with different training epochs (Table 6). These exper-iments use 128 dimension of embeddings. We find that the growth of training epochs after 200 has little effect on the precision@ k results.
 in the process of inferring API mappings. We concatenated the name and de-scription of an API as a sample in the above experiments. Here we try to divide these two parts from the corpus. Table 7 shows the statistical information about different kinds of training corpus.  X  X AME X  and  X  X ESC X  means use only API names and only API descriptions respectively.  X  X ULL X  means the concatenated corpus of names and descriptions. Table 8 presents precision@ k results with dif-ferent kinds of corpus. We can find that the results only used names is better then the results only used descriptions, but both of them can not achieve the results of concatenated corpus. It shows that the name part contributes most semantics in the process of inferring API mappings and the description part provides supplementary information for this process. The state-of-art work of discovering API mappings mostly takes code-based ap-proaches.
 ent versions of software client code. They first constructed API transformation graphs (ATGs) based on aligned client code snippets, then leveraged heuristic rules to infer API mappings between JavaSE and .N ET libraries.
 mappings between JavaM E and Android libraries. They crawled mobile graphic applications using the above two libraries and recorded the information parsed by dynamic code analysis to mine API mappings.
 discovering API mappings as a machine translation task. They also built parallel code bases from different version of client code. Then they extracted API usage sequences from source code with static analysis and applied the IBM translation model to align API usages and infer API mappings.
 sequences extracted from Java and C# source code and proposed the API2VEC model to learn APIs X  vector representations. Then based on API2VEC X  X  vectors and a large amount of known API mappings between JavaSE and .N ET , they trained a transformation classifier (implemented as a multilayer perceptron) to find API mappings.
 alignment relations between method-level code snippets. These relations acquire parallel code bases of different client versions which may be unavailable for parts of projects. Then API2VEC needs a large amount of known API mappings. These approaches also have the issue of high time expense caused by static or dynamic code analysis.
 basis of understanding words in API documents. API documents are available from official websites of API libraries. Compared with code analysis, it is fast to processing documents, learning word embeddings and ranking potential API mappings via similarity in our approach. Also, our approach is unsupervised. It can avoid issues of the above code-based approaches and be effective for any two API libraries without available code bases. Software developers often need to release different versions of projects or prod-ucts to support different platforms or devices. They usually migrate developed code from one platform to another. API mappings provide the key knowledge acquired in the process.
 in API documents and computing API similarity to infer API mappings. Our approach achieves averagely 41.51% improvement of precision@ k (k=1,5,10,20) to the baseline model. While existed code-based approaches may come across the unavailability of parallel code and high time expense of code analysis, API documents is easy to access and our approach can infer API mappings more quickly by learning word embedding and computing API similarity. Then our approach only leverages weak-supervised knowledge of API types rather than strong supervision of method-level alignment on code or many known API map-pings.
 rithms or other networks, such as recurrent neural networks or convolutional neural networks. Then the available number of known API mappings for us is too small to provide supervision knowledge. We expect to collect more available API mappings and extend our approach by training supervised modules in the future.

