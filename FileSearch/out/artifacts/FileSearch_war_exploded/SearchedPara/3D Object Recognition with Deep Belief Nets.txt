 Recent work on deep belief nets (DBNs) [10], [13] has shown that it is possible to learn multiple layers of non-linear features that are useful for object classification wi thout requir-ing labeled data. The features are trained one layer at a time as a restricted Bo ltzmann machine (RBM) using contrastive divergence (CD) [4], or as some form of a utoencoder [20], [16], and the feature activations learned by one module become the data for trai ning the next module. After a pre-training phase that learns layers of features which are good at modeling the statistical structure in a set of unlabeled images, supervised back propagation can be used to fine-tune the features for classification [7]. Alternatively, classifica tion can be performed by learning a top layer of features that models the joint density of the class labels and the highest layer of unsupervised features [6]. These unsupervised features ( plus the class labels) then become the penultimate layer of the deep belief net [6].
 Early work on deep belief nets was evaluated using the MNIST dataset of handwritten di gits [6] which has the advantage that a few million parameters are adequate for m odeling most of the structure in the domain. For 3D object classification, however, many more par ameters are probably required to allow a deep belief net with no prior knowledge of spatial s tructure to capture all of the variations caused by lighting and viewpoint. It is not yet clear how well deep belief nets perform at 3D object classification when compared with shallow techni ques such as SVM X  X  [19], [3] or deep discriminative techniques like convolutional neur al networks [11].
 In this paper, we describe a better type of top-level model for deep belief nets that is t rained using a combination of generative and discriminative gradients [5], [8], [9 ]. We evaluate the model on NORB [12], which is a carefully designed object recognition task that req uires Figure 1: The Third-Order Restricted Boltzmann Machine. (a) Every clique in the model contains generalization to novel object instances under varying lighting conditions and viewpo ints. Our model significantly outperforms SVM X  X , and it also outperforms convoluti onal neural nets when given additional unlabeled data produced by small translations of the training images. We use restricted Boltzmann machines trained with one-step contrastiv e divergence as our basic module for learning layers of features. These are fully described elsew here [6], [1] and the reader is referred to those sources for details. Until now, the only top-level model that has been considered for a DBN is an RBM with two types of observed units (one for the label, another for the penultimate feat ure vector). We now consider an alternative model for the top-level joint distribution in whic h the class label multiplicatively interacts with both the penultimate layer units and the hidden units to determine the energy of a full configuration. It is a Boltzmann machine with three-wa y cliques [17], each containing a penultimate layer unit v i , a hidden unit h j , and a label unit l . See figure 1 for a summary of the architecture. Note that the parameters now form a 3D tensor , instead of a matrix as in the earlier, bipartite model.
 Consider the case where the components of v and h are stochastic binary units, and l is a discrete variable with K states represented by 1-of-K encoding. The model can be defined in terms of its energy function where W ijk is a learnable scalar parameter. (We omit bias terms from all expressions fo r clarity.) The probability of a full configuration { v , h , l } is then the distribution over v and l alone. The main difference between the new top-level model and the earlier one is that now the class label multiplicatively modulates how the visible and hidden units contribute t o the slice of the tensor determines the energy function. In the case of soft activations (i .e. more than one label has non-zero probability), a weighted blend of the tensor X  X  slices specifies the energy function. The earlier top-level (RBM) model limits the label X  X  effect to chang ing the biases into the hidden units, which modifies only how the hidden units contribute to the energy of a full configuration. There is no direct interaction between the label and the visible units. Introducing direct interactions among all three sets of variables allows the model to learn features that are dedicated to each class. This is a useful property when the object classes have substantially different appearances that require very different f eatures to describe. Unlike an RBM, the model structure is not bipartite, but it is still  X  restricted X  in the sense that there are no direct connections between two units of the same type. 2.1 Inference to sample from exactly. The simplest case is P ( h | v , l ). Once l is observed, the model reduces to an RBM whose parameters are the k th slice of the 3D parameter tensor. As a result P ( h | v , l ) is a factorized distribution that can be sampled exactly. For a restricted third-order model with N v visible units, N h hidden units and N l class labels, the distribution P ( l | v ) can be exactly computed in O ( N v N h N l ) time. This result follows from two observations: 1) setting l k = 1 reduces the model to an RBM defined by the k th slice of the tensor, and 2) the negative log probability of v , up to an additive constant, under this RBM is the free energy : The idea is to first compute F k ( v ) for each setting of the label, and then convert them to a discrete distribution by taking the softmax of the negative free energies: Equation 3 requires O ( N v N h ) computation, which is repeated N l times for a total of O ( N v N h N l ) computation.
 We can use the same method to compute P ( l | h ). Simply switch the role of v and h in equation 3 to compute the free energy of h under the k th RBM. (This is possible since the model is symmetric with respect to v and h .) Then convert the resulting N l free energies to the probabilities P ( l k = 1 | h ) with the softmax function.
  X  l = 1. Then the model reduces to its k th -slice RBM from which  X  v  X  P ( v | h ,  X  l k = 1) can be easily sampled. The final result {  X  v ,  X  l } is an unbiased sample from P ( v , l | h ). 2.2 Learning 3D parameter tensor W for the restricted third-order model. When trained as the top-level model of a DBN, the visible vector v is a penultimate layer feature vector. We can also train the model directly on images as a shallow model, in which case v is an image (in row vector form). In both cases the label l represents the N l object categories using 1-of-N l encoding. For the same reasons as in the case of an RBM, maximum likelihood lea rning is intractable here as well, so we rely on Contrastive Divergence learning i nstead. CD was originally formulated in the context of the RBM and its bipartite architect ure, but here we extend it to the non-bipartite architecture of the third-order model. An unbiased estimate of the maximum likelihood gradient can be computed by running a Contrastive divergence uses the parameter updates given by three half-steps of this c hain, with the chain initialized from a training case (rather than a random state). As explained in section 2.1, both of these distributions are easy to sample from. The st eps for computing the CD parameter updates are summarized below: Contrastive divergence learning of P ( v , l ): Let W , ,k denote the N h  X  N v matrix of parameters corresponding to the k th slice along the label dimension of the 3D tensor. Then the CD update for W , ,k is: where  X  is a learning rate parameter. Typically, the updates computed from a  X  X ini-batch X  of training cases (a small subset of the entire training set) are averaged tog ether into one update and then applied to the parameters. In practice the Markov chain used in the learning of P ( v , l ) can suffer from slow mixing. In particular, the label l  X  generated in step 3 above is unlikely to be different from the true label l + of the training case used in step 1. Empirically, the chain has a tendency to stay  X  X tuck X  on the same state for the label variable because in the positive phase the hidden activities are inferred with the label clamped to its true value. So the hidden acti vities contain information about the true label, which gives it an advantage o ver the other labels. Consider the extreme case where we initialize the Markov chain with a training pair { v + , l + k = 1 } and the label variable never changes from its initial state during the chain X  X  entire run. In effect, the model that ends up being learned is a class-conditional generative distribution P ( v | l k = 1), represented by the k th slice RBM. The parameter updates are identical to those for training N l independent RBMs, one per class, with only the training cases of each class being used to learn the RBM for that class. Note that this is very different from the model in section 2: here the energy functions implemented by the class-conditiona l RBMs are learned independently and their energy units are not commensurate with each other.
 Alternatively, we can optimize the same set of parameters to represent yet another distri-bution, P ( l | v ). The advantage in this case is that the exact gradient needed for maximum likelihood learning,  X  X ogP ( l | v ) / X  X  , can be computed in O ( N v N h N l ) time. The gradient expression can be derived with some straightforward differentiation of equation 4. The dis-advantage is that it cannot make use of unlabeled data. Also, as the results sho w, learning a purely discriminative model at the top level of a DBN gives much worse perfor mance. However, now a new way of learning P ( v , l ) becomes apparent: we can optimize the parameters by using a weighted sum of the gradients for log P ( v | l ) and log P ( l | v ). As explained below, this approach 1) avoids the slow mixing of the CD learning for P ( v , l ), and 2) allows learning with both labeled and unlabeled data. It resembles pseudo-likeli hood in how it optimizes the two conditional distributions in place of the joint distribut ion, except a model trained with this hybrid learning algorithm has the highest classificatio n accuracy, beating both a generative model trained using CD as well as a purely discriminativ e model. The main steps of the algorithm are listed below.
 Hybrid learning algorithm for P ( v , l ): Let { v + , l + k = 1 } be a labeled training case.
 Generative update: CD learning of P ( v | l ) Discriminative update: ML learning of P ( l | v ) The two types of update for the c th slice of the tensor W , ,c are then combined by a weighted sum: where  X  is a parameter that sets the relative weighting of the generative and discrimina tive updates, and  X  is the learning rate. As before, the updates from a mini-batch of training cases can be averaged together and applied as a single update to the parameters. In ex -periments, we set  X  by trying different values and evaluating classification accuracy on a validation set.
 Note that the generative part in the above algorithm is simply CD learning o f the RBM for the k th class. The earlier problem of slow mixing does not appear in the hybrid algorit hm because the chain in the generative part does not involve sampling the label.
 Semi-supervised learning: The hybrid learning algorithm can also make use of unlabeled training cases by treating their labels as missing inputs. The model first infers the missing label by sampling P ( l | v u ) for an unlabeled training case v u . The generative update is then computed by treating the inferred label as the true label. (The discriminative upda te will always be zero in this case.) Therefore the unlabeled training cases contribute an ex tra generative term to the parameter update. Discriminative performance is improved by using binary features that are only rarely active. then adding an additional penalty term that encourages an exponentially decaying averag e, q , of the actual probability of being active to be close to p . The natural error measure to use is the cross entropy between the desired and actual distributions: p log q +(1  X  p ) log(1  X  q ). For logistic units this has a simple derivative of p  X  q with respect to the total input to a unit. This derivative is used to adjust both the bias and the incoming weights of each hi dden unit. We tried various values for p and 0 . 1 worked well. In addition to specifying p it is necessary q current is the average probability of activation for the current mini-batch of 100 t raining cases. It is also necessary to specify how strong the penalty term should be, but this is easy to set empirically. We multiply the penalty gradient by a coefficient that is chosen to ensure that, on average, q is close to p but there is still significant variation among the q values for different hidden units. This prevents the penalty term from dominating the learning. One added advantage of this sparseness penalty is that it revives any hidden units whose a verage activities are much lower than p . 5.1 NORB Database For a detailed description see [12]. The five object classes in NORB are animals , humans , planes , trucks , and cars . The dataset comes in two different versions, normalized-uniform and jittered-cluttered . In this paper we use the normalized-uniform version, which has objects centred in the images with a uniform background. There are 10 instances of ea ch object class, imaged under 6 illuminations and 162 viewpoints (18 azimuths  X  9 elevations). The instances are split into two disjoint sets (pre-specified in the database) of five each to define the training and test sets, both containing 24,300 cases. So at test time a t rained model has to recognize unseen instances of the same object classes.
 Pre-processing: A single training (and test) case is a stereo-pair of grayscale images, each of size 96  X  96. To speed up experiments, we reduce dimensionality by using a  X  X oveal X  image representation. The central 64  X  64 portion of an image is kept at its original resolution. The remaining 16 pixel-wide ring around it is compressed by replacing non-overlapping square blocks of pixels with the average value of a block. We split the ring into four smaller ones: the outermost ring has 8  X  8 blocks, followed by a ring of 4  X  4 blocks, and finally two innermost rings of 2  X  2 blocks. The foveal representation reduces the dimensionality of a stereo-pair from 18432 to 8976. All our models treat the stereo-pair ima ges as 8976-5.2 Training Details Model architecture: The two main decisions to make when training DBNs are the number of hidden layers to greedily pre-train and the number of hidden units to use in each layer. To simplify the experiments we constrain the number of hidden units to be the same at all layers (including the top-level model). We have tried hidden layer sizes of 2000, 4 000, and 8000 units. We have also tried models with two, one, or no greedily pre-trained hidden layers. To avoid clutter, only the results for the best settings of these two pa rameters are given. The best classification results are given by the DBN with one greedily pre-t rained sparse hidden layer of 4000 units (regardless of the type of top-level model).
 A DBN trained on the pre-processed input with one greedily pre-trained layer of 4000 hidden units and a third-order model on top of it, also with 4000 hidden units, has roughl y 116 million learnable parameters in total. This is roughly two orders of m agnitude more parameters than some of the early DBNs trained on the MNIST images [6], [10 ]. Training such a model in Matlab on an Intel Xeon 3GHz machine takes almost two weeks . See a recent paper by Raina et al. [15] that uses GPUs to train a deep model with roughly t he same number of parameters much more quickly.
 We put Gaussian units at the lowest (pixel) layer of the DBN, which have been show n to be effective for modelling grayscale images [7]. See [7], [21] for details abo ut Gaussian units. The results are presented in three parts: part 1 compares deep models to shallow ones, all trained using CD. Part 2 compares CD to the hybrid learning algorithm for training the top-level model of a DBN. Part 3 compares DBNs trained with and without unlabel ed data, using either CD or the hybrid algorithm at the top level. For comparison, here are some published results for discriminative models on normalized-uniform NORB (wit hout any pre-processing) [2], [12]: logistic regression 19.6%, kNN (k=1) 18 .4%, Gaussian kernel SVM 11.6%, convolutional neural net 6.0%, convolutional net + SVM hybrid 5.9%. 6.1 Deep vs. Shallow Models Trained with CD We consider here DBNs with one greedily pre-trained layer and a top-level model that contains the greedily pretrained features as its  X  X isible X  layer. The corresponding shallow version trains the top-level model directly on the pixels (using Gaussian visible units), with no pre-trained layers in between. Using CD as the learning algorithm (for both gr eedy pre-training and at the top-level) with the two types of top-level models gives us four p ossibilities to compare. The test error rates for these four models(see table 1) show that one g reedily pre-trained layer reduces the error substantially, even without any subsequent fine-tuning of the pre-trained layer.
 Table 1: NORB test set error rates for deep and shallow models trained using CD wit h two types of top-level models.
 The third-order RBM outperforms the standard RBM top-level model when they both have the same number of hidden units , but a better comparison might be to match the number of parameters by increasing the hidden layer size of the standard RBM model by five times (i.e. 20000 hidden units). We have tried training such an RBM, but the error rate is worse than the RBM with 4000 hidden units. 6.2 Hybrid vs. CD Learning for the Top-level Model We now compare the two alternatives for training the top-level model of a DBN. Ther e are four possible combinations of top-level models and learning algorithms, and tabl e 2 lists their error rates. All these DBNs share the same greedily pre-trained first layer  X  only the top-level model differs among them.
 Table 2: NORB test set error rates for top-level models trained using CD and the hybr id learning algorithms.
 The lower error rates of hybrid learning are partly due to its ability to avo id the poor mixing of the label variable when CD is used to learn the joint density P ( v , l ) and partly due to its greater emphasis on discrimination (but with strong regularization provided b y also learning P ( v | l )). 6.3 Semi-supervised vs. Supervised Learning In this final part, we create additional images from the original NORB training set by applying global translations of 2, 4, and 6 pixels in eight directions (two hor izontal, two images are treated as extra unlabeled training cases that are combined with the original labeled cases to form a much larger training set. Note that we could have assi gned the jittered images the same class label as their source images. By treating them a s unlabeled, the goal is to test whether improving the unsupervised, generative part of the learning alone can improve discriminative performance.
 There are two ways to use unlabeled data: Table 3 lists the results for both options.
 Table 3: NORB test set error rates for DBNs trained with and without unlabeled da ta, and using the hybrid learning algorithm at the top-level.
 The key conclusion from table 3 is that simply using more unlabeled training data in the unsupervised, greedy pre-training phase alone can significantly improve the classificati on accuracy of the DBN. It allows a third-order top-level model to reduce its error from 6 .5% to 5.3%, which beats the current best published result for normalized-uniform NORB without using any extra labeled data . Using more unlabeled data also at the top level further improves accuracy, but only slightly, to 5.2%.
 Now consider a discriminative model at the top, representing the distribution P ( l | v ). Unlike in the generative case, the exact gradient of the log-likelihood is tractable to compute. Table 4 shows the results of some discriminative models. These models use the sa me greedily pre-trained lower layer, learned with unlabeled jitter. They differ in how the top-level parameters are initialized, and whether they use the jittered images as extra labeled cases for learning P ( l | v ).

Initialization Use jittered of top-level images as Error parameters labeled? from table 3 Table 4: NORB test set error rates for dis-significantly improves accuracy over random initialization (7.1%). But note t hat discrimina-tive training only makes a small additional improvement (5.2% to 5.0%) o ver the accuracy of the pre-trained model itself. Our results make a strong case for the use of generative modeling in object recognit ion. The main two points are: 1) Unsupervised, greedy, generative learning can extract an image representation that supports more accurate object recognition than the r aw pixel representation. 2) Including P ( v | l ) in the objective function for training the top-level model results in better classification accuracy than using P ( l | v ) alone. In future work we plan to factorize the third-order Boltzmann machine as described in [18] so that some of the top-level features can be shared across classes. [1] Y. Bengio, P. Lamblin, P. Popovici, and H. Larochelle. Greedy Layer-Wise Training of [2] Y. Bengio and Y. LeCun. Scaling learning algorithms towards AI. In Large-Scale Kernel [3] D. DeCoste and B. Scholkopf. Training Invariant Support Vector Machines. Machine [4] G. E. Hinton. Training products of experts by minimizing contrastive div ergence. Neural [5] G. E. Hinton. To Recognize Shapes, First Learn to Generate Images. Technical Report [6] G. E. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep belief nets. [7] G. E. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural [8] M. Kelm, C. Pal, and A. McCallum. Combining Generative and Discriminativ e Methods [9] H. Larochelle and Y. Bengio. Classification Using Discriminative Res tricted Boltzmann [10] H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. An empirical evalu-[11] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to [12] Y. LeCun, F. J. Huang, and L. Bottou. Learning methods for generic object recogni tion [13] H. Lee, R. Grosse, R. Ranganath, and A. Ng. Convolutional Deep Belief Net works for [14] V. Nair and G. E. Hinton. Implicit mixtures of restricted boltzmann m achines. In [15] R. Raina, A. Madhavan, and A. Ng. Large-scale Deep Unsupervised Learning usi ng [16] Marc X  X urelio Ranzato, Fu-Jie Huang, Y-Lan Boureau, and Yann LeCun. Unsupervis ed [17] T. J. Sejnowski. Higher-order Boltzmann Machines. In AIP Conference Proceedings , [18] G. Taylor and G. E. Hinton. Factored Conditional Restricted Boltzma nn Machines for [19] V. Vapnik. Statistical Learning Theory . John Wiley and Sons, 1998. [20] P. Vincent, H. Larochelle, Y. Bengio, and P. A. Manzagol. Extracting and Composing [21] M. Welling, M. Rosen-Zvi, and G. E. Hinton. Exponential family harm oniums with an
