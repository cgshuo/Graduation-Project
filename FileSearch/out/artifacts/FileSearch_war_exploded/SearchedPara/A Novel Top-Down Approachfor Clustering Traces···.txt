 Business process mining techniques aim at discovering, monitoring and improv-ing real processes by extracting knowledge from event logs recorded by enterprise information systems [ 1 ]. In general, current process mining techniques mainly consider three perspectives: workflow discovery, conformance checking and pro-which is a set of cases, where each case is an instance of a business process. Every case in an event log has an attribute trace which is a set of ordered events. Cases and events are uniquely identified in the event log by case id and event id respectively. Additionally, typical event logs may contain much more process information, e.g., the performer and cost of each event.
 ment (CRM) and product development [ 3 ]. As a result, the existing business process mining techniques might generate inaccurate and impalpable analysis environments. The problem is largely due to the dense distribution of cases with a high variety of behaviors in the real-life event log.
 the current workflow discovery techniques also encounter great challenges in the scenario of real-life event logs. For instance,  X  X paghetti-like X  business process models might be generated by existing process discovery algorithms with an input of real-life event log [ 2 ]. Such models are often inaccurate and too com-plex to be well interpreted. Accordingly, some pioneering approaches have been and then groups the traces with similar behaviors into the same sub-log. After-wards, by applying workflow discovery algorithms on each simpler sub-log, more accurate and comprehensible process models can be obtained. Figure 1 shows the basic procedure for trace clustering .
 Nevertheless, most currently available trace clustering techniques treat all of some important trace behaviors are reduced. Moreover, these techniques focus ity of the underlying process model for each cluster learned is not taken into account [ 3 ]. Hence, high-quality sub-process models from these trace cluster-ing techniques can not be guaranteed. A promising method called Active Trace Clustering (ATC) was put forward in [ 3 ] which directly optimises the accuracy of each cluster X  X  underlying process model. However, ATC only considers model accuracy metrics while the complexity of process models is neglected during trace clustering. The complexity of process models is also a very important met-ric and should not be ignored for trace clustering . Because a highly accurate process model can still be very complicated. space. The proposed technique employs a greedy strategy for searching for the optimal way to cluster the traces in an event log based on a specific model eval-uation schema that considers both the accuracy and complexity of the potential sub-process models during the run time: -The problem addressed by this paper is discussed in Section 2. -Section 3.2 formalises definitions related to trace behaviors firstly. After--In Section 3.3, a top-down approach is put forward which identifies the opti--To test the efficiency of our method, we carry out a case study in Section 4 U nder certain conditions, an inaccurate and complex business process can be divided into several simpler and more accurate sub-processes where each sub-process performs some unique functions reflected by certain specific sub-process constructional behaviors. These behaviors can be recorded in the event log after the execution of the sub-process and expressed through the structural behav-iors of traces (trace behaviors). In this paper, the trace behaviors that adhere to a more accurate and simpler sub-process model compared with the original (defined in Section 3.2). Discovering these significant trace behaviors from the based on these behaviors. However, due to the lack of domain knowledge about the significant trace behaviors, capturing them directly from the event log seems to be a difficult task.
 problem of finding the optimal way for clustering the traces among all possible solutions. As shown in Figure 2, each element in the solution space represents one strategy for clustering the traces from an event log into several subsets of traces. A best solution is defined as a solution which is able to divide the the underlying sub-models for these subsets is optimal. Given a process model evaluation schema, how to find the optimal solution for clustering the traces from an event log is the main problem that this paper is going to solve. traditional trace clustering techniques and ATC for discovering the optimal way of clustering the traces. This technique considers both the behaviors of traces and the accuracy and complexity of each potential sub-process model during the mining procedure for the optimal solution. In this section we propose a new trace clustering technique which differs from ing the traces among all of the possible solutions. Four kinds of trace behaviors process. 3.1 Notation Before introducing our method, we discuss some of the important basic concepts over
I . A sequence S j  X  S of length n is denoted &lt;i j 1 ,i j item i jk represents an item from I . For any two sequences  X  = &lt;a and  X  = &lt;b if 1  X  p Let SC be the set of event logs, ST be the set of all sets of traces from  X  :
ST  X  S X  be a workflow discovery algorithm, where S X  is the set of process models.  X  :( S X  , ST )  X  SV represents a process model evaluation schema with an input of process model and a set of traces and an output of assessed value from SV (the set of all possible values output by  X  ).
 Let D be a database of sequences, for a given minimum support (0 &lt;min sup &lt; 1), a sequence  X  is called a sequential pattern if min sup  X | D | , where support (  X  ) is the number of sequences in  X  and | D | represents the total number of sequences in D . The set of sequen-tial patterns , SP , contains all of the subsequences from are no less than min sup .Thesetof closed sequential patterns is defined as CSP = {  X  |  X   X  SP a n d  X   X  SP such that  X   X  and support (  X   X  :
SD smin sup  X  X  X  SCSP represents a closed sequential pattern mining algorithm, where SD is the set of all databases of sequences, SCSP is the set of all sets of closed sequential patterns and smin sup is the set of all possible minimum supports. CSP effectively decreases the total number of sequential patterns gen-erated but in the meantime preserves the complete information about all the sequential patterns. Additional information related to sequential pattern mining techniques can be found in [ 8 , 9 ].
 that influence the comprehensibility of a business process model expressed as Petri net [ 11 ]. These factors primarily include the number of control-flows and arcs, places and transitions, etc.) in the process model. Based on this previous research the authors of [ 3 ] develop an effective metric called Place/Transition Connection Degree (PT-CD) for quantifying the complexity of a Petri net. Let | a | be the total number of arcs in the process model, | P | and | T | be the number of transitions, the PT-CD is defined as [ 3 ]: paper we employ the Heuristics Miner (HM) [ 12 ] for generating the process models because HM is well designed to deal with real-life event logs and also has a good computational performance. Then the Heuristic Net to Petri Net plugin in ProM 2 is used for transforming the heuristic net output by the HM into a Petri Net. Afterwards, the PT-CD is used for evaluating the complexity of the Petri Net obtained. 3.2 Concepts Related to Trace Behaviors Traces are generated performing a specific category of functions determined by business process-based domain criterion. Such criteria can be very diverse, e.g., presence or absence of activities, presence or absence of combinations of activi-technique searches for the structural behaviors of traces in an event log, then is carried out.
 Trace Behaviors and Significant Trace Behaviors. Given a closed sequen-tial pattern mining algorithm  X  and a minimum support min sup trace behaviors TB from an event log C is defined as: Definition 1. TB = { tb | tb  X   X  ( T C ,min sup ) } , where from C .
 pattern mined from T C . In our opinion, certain frequently appeared subsequences among traces in an event log are able to reveal some particularly important criteria of business processes and can help distinguish sub-process models with patterns is that they can not only represent consecutive structural behaviors of traces, but inconsecutive trace behaviors as well. For instance, given an event log C and a minimum support min sup =0 . 4, the set of trace behaviors &lt;A,C&gt;,&lt;A,E&gt; } can be discovered, the sequential pattern consecutive trace behavior because activity C always appears right next to in a trace, and &lt;A, E&gt; is an inconsecutive trace behavior because activity and
E may appear in a trace discretely. However, most existing pattern-based trace clustering techniques are only able to capture consecutive trace behaviors in an event log. Moreover, employing frequent patterns is also in accordance with the main idea of most advanced process discovery techniques: only the frequent structures should be considered in the process mining procedure [ 2 ]. Additionally, we classify the behaviors of traces from a real-life event log into significant behaviors and nonsignificant behaviors .Let T the event log C , tb is a trace behavior discovered from C of C , where T C 1 consists of all of the traces with a subsequence is the sub-log of C where T C 2 contains all of the traces without a subsequence tb , V
C =  X  (  X  ( T C )), V C 1 =  X  (  X  ( T C 1 )) and V C 2 =  X  values obtained by performing the process model evaluation schema following definition: Definition 2. For a given minimum threshold  X  , the trace behavior is called a significant trace behavior (STB) if (( V C 1 otherwise tb is called an insignificant behavior.
 As stated in Definition 2, a STB is able to divide the original set of traces into two subsets that lead to two process models of which the average quality should be increased by at least  X  (a minimum threshold) compared with the quality of the model generated by utilising the original set of traces. Sub-Model Improvement for STB. According to Definition 2, the start-ing point for identifying a STB is a process model evaluation schema mentioned in Section 2, while evaluating a process model both the accuracy and complexity should be taken into account. Accordingly, the model evaluation schema  X  should contain two parts: the fitness 3 [ 2 ] computing schema the complexity evaluation schema  X  c .Let  X  be a process model mining algo-rithm, T C be a set of traces from the event log C , a trace behavior from
C separates T C into T C of
C , the sub-model improvement SMI is defined as:
SMI F ( T C
SMI C ( T C is related to the model accuracy and the second part is related to the model ation of process models. The main reason for using the ICS fitness is that it has a computationally efficient calculative process and also includes a punishment schema for an underfitting process model (such models allow for many additional behaviors that are not registered in the event logs). In Equation 2, resent the weights for the two parts and meet the condition of values of  X  and  X  should be set upon the conditions of accuracy and complexity of the original model. For instance, if the original model has a good accuracy but suffers from a bad complexity then the value of  X  should be set higher than  X  and vice versa. According to Definition 2, given a minimum threshold trace behavior tb is a STB if SMI ( T C 1 ,T C 2 ,T C )  X   X  Strict STB and Conditional Strict STB. The sub-model improvement cri-terion SMI considers both the fitness and complexity of the process models at the same time. However, in reality the fitness and complexity of a model are not associated with each other. The increment of fitness is not always accom-panied by a decrement of the model complexity and vice versa. For example, let tb be a trace behavior from the event log C which divides the original set of traces T C into T C 1 and T C 2 , pretend that  X  =0 . 15, SMI F ( T C 2 and Definition 2, the SMI ( T C 1 ,T C 2 ,T C )=0 . 15 is equal to the value of tb is judged to be a STB. Even though the average fitness of the sub-models for T average complexity of the sub-models is greatly reduced.
 Let stb be a STB mined from a log C which divides the set of traces T Definition 3. The stb is called a strict significant trace behavior (SSTB) if SMI F ( T C threshold for the average fitness increment of the models for pared with the original model and  X  c is a minimum threshold for the average complexity decrement of the models for T C 1 and T C 2 .
 meantime some additional conditions should be fulfilled: both the average fitness and average complexity of the related sub-models need to be improved to a certain extent. Let  X  f be a fitness computing schema,  X  c be a complexity computing schema,  X  be a process model mining algorithm, given a minimum threshold maximum threshold  X  c : Definition 4. The trace behavior tb is called a fitness-based conditional strict STB (FCSTB) if (  X  f (  X  ( T C 1 )) +  X  f (  X  ( T C 2 )))  X   X  ( Definition 5. The trace behavior tb is called a complexity-based conditional strict STB (CCSTB) if (  X  c (  X  ( T C 1 ))+  X  c (  X  ( T C  X   X  ( The FCSTB is defined to deal with an event log of which the potential model has a high fitness but an inferior complexity. For instance, let behavior from the event log C which divides the original set of traces T and T C 2 , pretend that  X  =0 . 15,  X  =0 . 5,  X  =0 . 5, SMI  X  0 . 1, SMI C ( T C 1 ,T C )=0 . 4,  X  f =0 . 9, (  X  f (  X  ( T C according to Definition 2 and Definition 3, tb is a STB but not a SSTB. However, even though the average fitness of the sub-models decreases compared to the original model, it still remains a large value and greater than FCSTB is complexity-based conditional strict STB (CCSTB) which is defined in Definition 5. It should also be noticed that a tb can be both the FCSTB and the CCSTB at the same time. 3.3 A Top-Down Algorithm for Clustering Traces the traces in an event log based on the definitions elaborated in Section 3.2. This algorithm applies a greedy strategy which discovers the best trace behavior (that is either a SSTB or a FCSTB or a CCSTB) for splitting the original set of traces for each stage according to the value of SMI. Let trace behavior removing method, TB represents a set of trace behaviors mined from the set of traces T , a trace behavior tb  X  TB is able to divide subsets: T 1 (contains the traces with a subsequence tb )and traces without a subsequence tb ), if | T 1 | X   X  or | T 2 TB . In our technique  X  stands for a minimum number of traces for each cluster. A trace behavior that leads to a cluster with a number of traces less than not be considered. Given a workflow discovery algorithm  X  pattern mining algorithm  X  , a process model fitness evaluation schema a process model complexity evaluation schema  X  c , the details of our method is described in Algorithm 1.
 To prevent the tendency of our technique to generate the clusters containing too few traces (too few traces means a very simple model), a minimum size of each potential cluster is requested to be set before starting the algorithm. Steps 4  X  9 in Algorithm 1 check the number of traces in the original trace set Algorithm 1. Discovering the best solution for clustering traces (DBSCT) generated are larger than or equal to  X  then the algorithm stops. Afterwards, the can X  X  lead to a valid division of the original trace set according to the minimum size rule are removed. Step 10 searches for the best trace behavior among all of the behaviors found in step 6 through the algorithm  X  depicted in Algorithm 2. A best trace behavior is defined as a behavior (either a SSTB or a FCSTB or a CCSTB) which can help generate a maximum sub-model improvement shown in the steps 12  X  13 in Algorithm 2. The main reason to set the parameter SMI is: if the average quality of the sub-models can X  X  be improved to a certain extent based on the division procedure compared with the quality of the original model, then it is not worth making the division (this requirement stems from the consideration for the balance between the integrity and the quality of the process model). Algorithm 1 takes a greedy strategy for clustering the traces step by step, the same procedure continues on the subsets of traces generated by Algorithm 2. Searching for the best trace behavior (  X  ) the present stage as shown in the steps 11  X  15 in Algorithm 1. Finally, a binary tree bt is output by Algorithm 1 where each leaf node in bt represents a found cluster of traces. 3.4 Assumptions In this paper we assume that the inaccurate and complex business process sub-jected to our method is able to be divided into several simpler and more accurate sub-processes where each sub-process carries out some specific functions. These overdraft approvals process from Business Process Intelligence Challenge 2012 (BPIC 2012). This log contains 13087 traces and 36 event classes. A process model (as shown in Figure 3) which has an ICS fitness equal to 0.9268 and a Place/Transition Connection Degree (PT-CD) equal to 3.939 is generated by using the Heuristics Miner on this log.
 complicated because it has a high complexity. So we set the fitness weight and the complexity weight  X  =0 . 6 for calculating the SMI support min sup for the closed sequential pattern mining algorithm is set to 0.3, the minimum threshold  X  for SMI is set to 0.04, both the minimum thresholds  X  f and  X  c for SSTB are set to 0.02, the minimum threshold to 0.84, the maximum threshold  X  c is set to 2.5 and the minimum size cluster is set to 655 (5% of the total number of traces in the event log). With these parameters set above, five clusters are generated by our technique. The weighted average ICS fitness 4 , the weighted average control flows, the weighted average PT-CD and the weighted average number of and/xor join/splits for the process models mined from the traces clustered are calculated and shown in by employing the original event log. Through the evaluation results exhibited in Table 1, we can see that the weighted average fitness of the sub-models from our technique is higher than the fitness of the original model, in the meantime the average complexity of these models has been greatly reduced. Such a result benefits from the thought of a trade-off between the accuracy and complexity in our technique.
 which are 3-gram [ 6 ], MR and MRA [ 5 ], ATC [ 3 ], GED [ 4 ] and sequence clus-tering (SCT) [ 7 ]. Except for the original event log, four random sub-logs that contain 60%, 70%, 80% and 90% of the instances from the original log have been is set to equal to the number of clusters discovered by our technique. Figure 4 shows the results for the comparison. For the entire accuracy of the sub-process models discovered, our technique and the ATC perform better than other trace clustering techniques. The main reason is that both our technique and the ATC try to optimise the accuracy of the potential model for each cluster during the run time. However the ATC doesn X  X  consider the complexity of process models during the clustering proce-dure. As a result, the entire complexity of the sub-process models discovered by ATC is much higher. The models discovered by utilising our technique are less complicated than the models mined by other techniques. The sequence cluster-ing technique performs better than our technique on the evaluation related to weighted average control flow. Nevertheless, the accuracy of the models mined by the sequence clustering technique is not as good as the accuracy of models discovered by our technique. In the literature, different trace clustering approaches have been put forward to overcome the negative impacts from high variety of behaviors stored in event can be defined among traces.
 files defined into an aggregate vector the distance between any two traces can be measured. One advantage of this technique is that it provides a full range of metrics for clustering traces.
 discovered may support a high variety of behaviors that are not registered in event log, as a result some significant structural features may be concealed in the mined model. Such a problem can be dealt with by considering the metric soundness [ 2 ] which measures the percentage of behaviors of the mined model that are recorded in the log among all of the behaviors supported by the model. An efficient technique is proposed in [ 14 ] which divides the whole process into a set of distinct sub-processes based on a greedy strategy which makes sure the This method can also help solve the problem of high complexity of the initial model.
 the authors indicate that the feature sets based on sub-sequences of different lengths are context-aware for the vector space model and can reveal some set of common functions. Two traces that have a lot of conserved features in com-mon should be gathered in the same cluster. In [ 4 ] the authors present an edit between traces is more accurate.
 cluster through an expectation-maximization algorithm. A sequence is assigned to a cluster which is able to generate it with higher probability. The technique proposed in this paper also inherits the idea from sequence clustering, the dif-ference is our technique represents each cluster with a set of separate sequences (significant trace behaviors).
 mises the fitness of each cluster X  X  underlying process model during the run time. This method doesn X  X  consider the vector space model for trace clustering, it sim-ply discovers the suitable traces for each cluster so that the combined accuracy of the related models for these clusters is maximised. This method sufficiently resolves the gap between the clustering bias and the evaluation bias. possible solutions. This technique considers both the accuracy and complexity of the potential model for each cluster during the clustering procedure. Through the results from the experiment we demonstrated the effectiveness of our technique by comparing it with other six classical trace clustering techniques. However, the technique presented in this paper encounters challenges on per-formance while dealing with event logs generated by totally unstructured busi-ness processes because such processes contain a tremendous number of behaviors. Our next main research task will be to focus on filtering the trival trace behav-iors in the event logs so that the performance of our technique can be improved. In the meantime, we will also validate our methods on some other real-life cases.
