 Sarcasm is a sophisticated communicative act which allows a speaker to express sentiment-rich viewpoints in an implicit way. Sarcastic writing is common in many online texts. This linguistic phenomenon has much significance for tasks such as sentiment analysis, opinion mining and advertising [1].

Sarcasm is classically defined as the rhetorical process of intentionally us-ing words or expressions for uttering a meaning different (usually the opposite) from the one they have when used literally [2]. Consider the following tweet on Twitter 1 , which includes the words  X  X ay X  and  X  X ucky X  but actually expresses a negative sentiment:  X  X ay! It X  X  a holiday weekend and i X  X  on call for work! Couldn X  X  be more lucky! #sarcasm. X  In this case, the hashtag #sarcasm reveals the intended sarcasm, but we don X  X  always have the benefit of an explicit sarcasm label.

Automatic sarcasm detection is conside red as a simple text classification prob-lem. They use lexical and syntactic feat ures to detect sarcasm in text. For ex-ample, lexical cues interjections, emo ticons and N-grams. However, they are commonly used features for text classificat ion, not specifically for detecting sar-casm. Sarcasm detection i s a complex and challenging task, which needs a set of explicit features cutting through every aspect of language, from pronunciation to lexical choice, syntactic structu re, semantics and conceptualization.
In recent years, most researches [3 X 5] a dopt supervised or semi-supervised learning approaches to perform sarcasm detection. However, they normally as-sume the balance between sarcastic and non-sarcastic samples, which may not keep in practice. Actually, many sarcasm classification applications involve im-balanced class distributions in that the sample number of sarcasm in the training data is much smaller than the non-sarcasm.

To have a better understanding of the imbalanced class distribution phe-nomenon in sarcasm detection, Table 1 gives the statistics on the number of sarcastic and non-sarcastic sentences occurring in experimental datasets. For more details about data sources, please refer to Section 4.

Where MI represents sarcasm sample se t, MA represents non-sarcasm sample set. As we can see from Table 1, all the class distributions are imbalanced, with the imbalanced ratios (MA/MI) ranging from 10 to 17, which are greater than the imbalance rate 2.333 of  X  X erman X , a famous UCI imbalanced dataset (Merz &amp; Murphy, 1995) on Germany credit scoring [6].

The imbalanced class distribution can cause many serious problems in the training process of sarcasm detection. Firstly, datasets suffer from class over-lapping and are short of rare sarcastic samples, which make the classifier learn-ing difficult. Furthermore, evaluation criterion, which guides learning procedure, tends to ignore minority samples (treating them as noise) and makes the in-duced classifier lose its classification ability in this scenario. These indicate the necessity of dealing with imbalanced problem in sarcasm detection.

In this paper, we propose a novel multi-strategy ensemble classification algo-rithm and a comprehensive sarcasm featu re set to automatic detection of sarcas-tic sentences in both English and Chinese social media. Compared to existing methods, the main advantages of our model can be summarized as follows: (i) our classification algorithm combines weighted random sampling with ensemble of multiple classifiers based on information entropy to guarantee the high diver-sity of the involved member classifiers and the weighted voting being fairer. (ii) the sarcasm feature set is a multidimensional model, including lexical, syntactic, semantics and constructions. The sarcasm model can automatically differentiate an sarcastic text from a non-sarcastic one in both English and Chinese. As far as we know, it X  X  first time to explore the sarcasm detection in chinese social media and the imbalanced class distribut ion problem of sarcasm detection.
The rest of the paper is organized as fo llows. Section 2 introduces the related work. In section 3, we present our model which is made up of sarcasm feature set and multi-strategy ensemble learning algorithm. Section 4 describes the data sets and sarcastic dictiona ry. Section 5 shows our expe riment results. Section 6 concludes the research and gives directions for future studies. 2.1 Sarcasm Detection Sarcasm is a well-studied phenomena in linguistics, psychology and cognitive science [7]. But in the text mining literature, automatic detection of sarcasm is considered a difficult problem and has been addressed in only a few studies. Gen-erally, sarcasm detection m ethods can be divided into two categories: supervised [3 X 5] and semi-supervised [8].

In the supervised mothods, Burfoot and Baldwin use SVM to determine whether newswire articles are true or sarcastic [3]. They introduce the notion of validity which models absurdity via a measure somewhat close to PMI. Valid-ity is relatively lower when a sentence c ontains unusual combinations of named entities. Gonz  X  alez-Ib  X  a  X  nez et al. explored the usefulness of lexical and pragmatic features for sarcasm detection in tweet s [4]. They found that positive and neg-ative emotions in tweets have a strong correlation with sarcasm. Liebrecht et al. explored N-gram features from 1 to 3-grams to build a classifier to recognize sarcasm in Dutch tweets [5]. They made an interesting observation from their most effective N-gram features that peo ple tend to be more sarcastic towards specific topics such as school, homework, weather, public transport, etc.
Tsur et al. presented a semi-supervised learning framework that exploits syn-tactic and pattern based features in sar castic sentences of Amazon product re-views [8]. They observed correlated sen timent words such as  X  X ay! X  or  X  X reat! X  often occurring in their most useful patterns.

To the best of our knowledge, no existing methods consider the class imbalance problem in sarcasm detection. 2.2 Imbalanced Classification Many techniques are proposed to solve classification problems based on imbal-anced data sets. There are two major categories of techniques developed to address the class imbalance issue. One is at data level and the other is at algo-rithmic level.

At the data level, different forms of re-sampling, such as over-sampling and under-sampling, are proposed. Specifically, over-sampling aims to balance the class populations through replicating the MI samples [9] while under-sampling aims to balance the class populations through eliminating the MA samples [10].
At the algorithmic level, the solutions mainly include cost-sensitive learning, one-class learning, and ens emble learning. Many cost-s ensitive learning methods have been proposed [11, 12]. They intentionally increase the weights of samples with higher misclassification cost in the training process. Tax and Duin pro-posed a support vector algorithm for one-class classification, using kernels to obtain a tight boundary around normal samples in high dimensions [13]. Sun et al. investigate cost-sensitive boosting algorithms for advancing the classifica-tion of imbalanced data and propose three cost-sensitive boosting algorithms by introducing cost items into the learning framework of AdaBoost [14]. In addi-tion, Maalouf et al. proposes a robust weighted kernel logistic regression. It can correct the bias of logistic regression in imbalanced classification [15]. However, their methods focus on either data processing or learning algorithm. Our approach combines them together to improve the classification accuracy. A schematic representation of the pro posed imbalanced sarcasm detection ap-proach is shown in Fig.1. In general, our approach consists of two main compo-nents: (1) feature extraction and (2) multi-strategy ensemble learning. In this section, we first present a set of English s arcasm features which are important for sarcasm detection. Then we proposed a C hinese sarcasm feature set according to the differences between the English and Chinese sarcastic sentence. Finally we describe our multi-strategy ensemble learning algorithm handling imbalanced class distribution. 3.1 English Sarcasm Features In spoken discourse, we are usually able to detect a variety of external clues that enable the perception of sarcasm. In written text, a set of explicit linguis-ticstrategiesisalsousedtoexpresssarcasm.Accordingtotheresearchefforts on sarcasm detection, we summarize the following three categories of linguistic features that are related to the expression of sarcasm: 1) Punctuation symbols: they are focused on explicit marks which reflect a sharp distinction of sarcasm in text. These punctuation symbols include punc-tuation marks (, ;, ?, !, :), emoticons, quotes and capitalized words [3][4][8]. 2) Lexical features: lexical features play an important role in the delivery and detection of sarcasm. A ccording to the work in [4], it contains different aspects features such as c ounter-factuality(e.g. yet ), temporal compression(e.g. suddenly ), recurring sequences(n-grams, skip-grams, polarity s-grams) and emo-tional scenarios(activation, imagery, pleasantness). 3) Syntactic features: these features c ontain recurrent sequences of morphosyn-tactic patterns and degree of opposition in text with respect to the information profiled in the present and past tenses. According to the work in [16], they are composed of POS-grams(e.g. ADV+ADJ+N ) and temporal imbalance(e.g. hate and didn X  X  ).

Semantic factor has received little attent ion in the existing studies. However, semantic factor is a critical feature to ex press the context contradiction in sar-casm detection. Thus, we propose semantic imbalance rate as a new feature. 4) Semantic imbalance rate: this is intended to capture inconsistencies within a context. The intuition here is: the smaller the semantic inter-relatedness of a text, the greater its semantic imbalance (sarcastic text); the greater the semantic inter-relatedness of a text, the lesser its semantic imbalance (non-sarcastic text). In order to measure this feature, we define semantic imbalance rate as follows: Definition 1 Semantic imbalance rate (SIR) is the reciprocal of a text X  X  se-mantic relatedness, which is summing the maximum semantic similarity scores (across different senses of words in text) and dividing by the length of the text. where N is the length of text, Sim ( w i ,w j ) denotes the semantic similarity be-tween word w i and word w j . 3.2 Chinese Sarcasm Features In Chinese culture, sarcasm as a rhetorical device has a long history. It is more commonly used than English sarcasm. However, there is no work on automatic sarcasm detection in Chinese document. S ince the Chinese grammar is different from English, we have to investigate Chinese sarcasm features independently.
By comparing the English and Chinese sar castic sentence in our experimental data sets, we find the following differences between them:
According to Table 2, we propose a Ch inese sarcasm feature set including punctuation symbols, recurring sequences, semantic imbalance rate, rhetorical feature, homophony and construction. Among them, the first three features are the same as the English features. The remaining features are explained as follows: 1) Rhetorical feature: rhetorical feature includes extreme positive or nega-tive nouns, extreme adjectives, adverbs of degree, demonstratives, honorifics and proverbs. This feature carries on valuable information about authors X  emotions. 2) Homophony feature: homophony is commonly used in Chinese. It can be sarcastically used for expressing an insult or depreciation towards the entity they represent. For example,  X   X  X  X   X  X  X   X   X   X   X   X   X   X (  X   X   X  )  X   X (I call them  X  X xam-ining pigs X (examining groups) ). Pigs and groups are homophonic in Chinese. 3) Construction feature: construction feature is inherently tied to a particular model of the  X  X emantics of understanding X , which offers a way of structuring and representing meaning while taking into account the relationship between lexical meaning and grammatical patterning. For example,  X  N  X  N (as more as), adverb + adjective + interjection,  X  A  X  B (take A as B), etc. 3.3 Imbalanced Classification In order to fully utilize the training data and to guarantee the diversity of the multiple classifiers, we propose a novel multi-strategy ensemble learning ap-proach (MSELA) for imbalanced sarcasm d etection, which integrates sample-ensemble strategy, classifier-ensemble strategy and weighted voting strategy.
The basic motivation of MSELA is as follows. Firstly, sample-ensemble strat-egy uses weighted random sampling which can fully utilize features of the whole training data and cost less time. Secondly, classifier-ensemble strategy guarantees the diversity of multiple classifiers. Thirdly, weighted voting strategy considers both the accuracy of different classification algorithms and the importance of sample subsets to achieve fairer weighted voting and higher prediction accuracy. A. Sample-Ensemble Strategy Weighted random sampling is an effective method to deal with class imbalanced problem. In sample-ensemble strategy, the small samples are set various weights and merged with large samples into new datasets. With a weighted random sampling for each new dataset, N balanced datasets are obtained. These balanced datasets are used to train sub-classifie rs which will vote for the last result. B. Classifier-Ensemble Strategy Besides the sample-ensemble strategy, we also propose a classifier-ensemble strat-egy to guarantee the diversity of the invol ved classifiers. The classifier-ensemble strategy involves more than one classification algorithm. That is to say, multiple classification algorithms are prepared and the classifier of each dataset is trained with a random selected classification al gorithm. In our experiments, we employ three algorithms: Naive Bayes, SVM and Maximum Entropy.
 C. Weighted Voting Strategy Information entropy can measure the uncertainty of a random variable. The greater the information entropy of the data set is, the more uniform its class distribution will be. The smaller the information entropy, the more consistent the class distribution of data set will be. Assume that data set S contains c classes, then the information entropy E(S) of data set S is: where P i is the proportion of class i in the whole data set.

Following the simple weight calculation method in [17], our weight formula of sub-classifier C i is: E ( i ) is the information entropy of data subset D i . Our multi-strategy ensemble learning approach is illustrated in Algorithm 1. Algorithm 1 Multi-strategy ensemble learning algorithm MI represents sarcasm sample set, MA r epresents non-sarcasm sample set. K denotes the imbalanced ratio. The small samples are set various weights(step 6), and merged with large samples into new datasets D i (step 8). With a weighted random sampling for each new dataset D i , N balanced datasets D i ( i =1 , 2 , ..., N ) can be obtained(step 9). These balanced datasets are used to train different classifiers(step 10), which will vote for the last result(step 13). The information entropy is used to measure the differen ces among various N balanced datasets D , and then the weight for each classifie r is computed using Eq.(3) (step 11). The above process (step 4 to step 11) is executed K rounds. We use two corpora to evaluate our proposed model. The first corpus is used to verify English Sarcasm Features, whi ch contains a Amazon data set provided in [8], a Twitter data set from [16] and a News article set from [3]. The sec-ond corpus is used to verify Chinese Sarcasm Features, which contains three data sets obtained by crawling differ ent topic comments from Sina Weibo 2 ,Ten-cent Weibo 3 and Netease BBS 4 . The class distributions of these data sets are described in Section 1.

Since the datasets are highly skewed, we use Area under the Curve (AUC) for the ROC curve as the measure of evaluation. AUC is a common evaluation metric that has been shown to be more resistant to skew dataset than F-score, due to using true positive rate (TPR) rather than precision.
To extract rhetorical feature, we create a sarcastic dictionary with manually annotated sarcastic keywords and phrases. The sarcastic dictionary is composed by 1230 adjectives, 1096 nouns, 189 adverbs of degree, 65 demonstratives, 120 honorifics and 2322 proverbs. Among them, the adjectives, nouns and adverbs of degree come from Dalian University of Technology Affective Lexicon Ontology 5 . In this section, we evaluate the perform ances of our proposed model with three experiments. In the first experiment, we compare our multi-strategy ensemble learning algorithm with popular imbalanced classification methods. The second experiment evaluates feature correlati on of our model. In the third experiment, we compare our method with the state-of-the-art sarcasm detection model. 5.1 Imbalanced Sarcasm Classification In this subsection, we report the performances of ensemble methods for imbal-anced sarcasm classification. The Maximum Entropy classifier and Naive Bayes classifier are implemented using the Mallet tool 6 , while SVM is implemented using the SVM-light tool 7 . For thorough comparison, various kinds of ensemble methods are implemented including: 1. Full-training (FullT): directly throwing all the training data for training. 2. Bagging [9]: creating sub-classifiers on data subsets that are uniformly sam-3. AdaBoost [9]: generating weak classifiers sequentially and then combining 4. SMOTEBoost [10]: combining the over-sampling method SMOTE and boost-5. Random Forest [9]: containing many decision tree classifiers where each tree 6. Undersampling + multi-classifiers ensemble (EUM): performing clustering-7. Logistic Regression: correcting bias of logistic regression as proposed by [15].
Among them, bagging, adaboost, smoteboost and random forest are imple-mented using the Weka tool 8 . Since most methods involve random selection of samples, we run 10 times for each method and report the average performance of the 10 runs.
Table 3 compares the seven methods with our multi-strategy algorithm. It shows that almost all the specifically designed methods outperform full-training. The reason is that full-training fails to take the sample imbalance into account. Consistently, ensemble-learning always performs much better than the other approaches, especially in the Chinese corpus. Among the ensemble approaches, undersampling plus multi-classifiers ensemble learning significantly outperforms sample ensemble learning or classifier ensemble learning alone. Our approach (multi-strategy) achieves the best per formance on average, which confirms its effectiveness to enlarge the diversities of the member classifiers and keep balance between positive and negative samples.

We also analyze the cost of time among the seven ensemble methods for imbalanced sarcasm classification, which is shown in Fig.2. From Fig.2, we can see that Random Forest takes the least time while Logistic Regression takes the most time. Our multi-strategy ensemble learning always takes less time than the undersampling plus multi-classifiers ensemble learning. 5.2 Feature Correlation Verification Our model operates with a series of features, each type of feature can be analyzed in terms of information gain to determine its individual contribution to the discrimination power of the system. Fig.3 and Fig.4 present the results of an information gain filter (Y axis) on each type of our features (X axis).
As shown by the results in Fig.3 and Fig.4, this relevance is a function of the kinds of texts that are to be discriminated. For example, the features recurring sequences, pleasantness and semantic im balance appear to be sufficiently indica-tive to represent sarcastic sentences fr om the three English datasets. While, the features semantic imbalance, rhetorical feature and construction feature appear to be indicative to represen t sarcastic sentences from th e three Chinese datasets.
We analyze the performance improvements when each time a new type of feature is added. We use tenfold cross validation and results are shown in Fig.5.
Fig.5 indicates an acceptable performan ce on the automatic Chinese sarcasm detection. The model evidently improves i ts performance in almost all cases each time a new type of feature is added. 5.3 Comparison with the State-of-the-Art For comparison, we implement a state-of-the-art supervised model (SASM) for sarcasm detection, as proposed by [18], which takes n-grams, POS n-grams, funny profiling, positive/negative profiling, affective profiling, and pleasantness profiling as their feature set. They assess classification accuracy employing three classifiers: Naive Bayes, Support Vector Machine and Decision Tree.

We compare our sarcasm feature set with theirs, successively using our multi-strategy ensemble learning(MSELA) and decision tree(DT), which performs best in their experiment. Table 4 shows the superiority of our model due to its effec-tively ensemble learning on imbalanced data and explicit sarcasm feature set. Sarcasm is one of the most subjective phenomena related to linguistic analysis. Automatic sarcasm detection is a real challenge, not only from a computational perspective but from a linguistic one as well. In this paper, we present multi-strategy ensemble learning, a novel algor ithm for detection of sarcastic sentences in both Chinese and English social media. Our method can guarantee the high di-versity of the sub-classifiers and take full advantage of training data. We propose an explicit sarcasm feature set which attempts to describe salient characteristics of both Chinese and English sarcasm. They intend to symbolize low and high level properties of sarcasm. We compare our model against existing approaches using three different experiments. The e xperiments give promising results.
In the future, we plan to automatically annotate the sarcastic samples and study new features in order to come up with an improved model capable of detecting more sarcastic sent ences in different kinds of texts.
 Acknowledgments. This research is supported by the National High Technol-ogy Research and Development Program of China (No. 2012AA011002), Natu-ral Science Foundation of China (No. 61300003), Specia lized Research Fund for the Doctoral Program of Higher Education(No. 20130001120001) and Research Foundation of China Information Technology Security Evaluation Center (No. CNITSEC-KY-2013-018).

