 A topic propagating in a social network reaches its tipping point if the number of users discussing it in the network ex-ceeds a critical threshold such that a wide cascade on the topic is likely to occur. In this paper, we consider the task of selecting initial seed users of a topic with minimum size so that with a guaranteed probability the number of users discussing the topic would reach a given threshold. We for-mulate the task as an optimization problem called seed min-imization with probabilistic coverage guarantee (SM-PCG) . This problem departs from the previous studies on social in-fluence maximization or seed minimization because it con-siders influence coverage with probabilistic guarantees in-stead of guarantees on expected influence coverage. We show that the problem is not submodular, and thus is harder than previously studied problems based on submodular function optimization. We provide an approximation algorithm and show that it approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplica-tive ratio is tight while the additive error would be small if influence coverage distributions of certain seed sets are well concentrated. For one-way bipartite graphs we analytically prove the concentration condition and obtain an approxi-mation algorithm with an O (log n ) multiplicative ratio and an O ( nodes in the social graph. Moreover, we empirically verify the concentration condition in real-world networks and ex-perimentally demonstrate the effectiveness of our proposed algorithm comparing to commonly adopted benchmark al-gorithms.
This work was supported in part by the National Natu-ral Science Foundation of China Grant 61170062, 61222202 and the National Program for support of Top-notch Young Professionals.
 H.4 [ Information Systems Applications ]: Miscella-neous; F.2.2 [ Analysis of Algorithms and Problem Complexity ]: Nonnumerical Algorithms and Problems Algorithms, Experimentation, Performance social networks, influence diffusion, independent cascade model, seed minimization
With online social networks such as Facebook and Twitter becoming popular for people to express their thoughts and ideas, or to chat with each other, online social networks pro-vide a platform for triggering a hot topic and then influenc-ing a large population. Different from most traditional me-dia (such as TV and newspapers), information spread on so-cial networks mainly base on the trust relationship between individuals. Consider the following scenario: when some-one publishes a topic on the online social network, his/her friends will see this topic on the website. If they think it is interesting or meaningful, they may write some comments to follow it or just forward it on the website as a response. Similarly, the comments or forwarding from these friends will attract their own friends, leading to more and more people on the social network paying attention to that topic. When the number of users discussing about this topic on the online social network reaches certain critical threshold, this topic becomes a hot topic , which is likely to be surfaced at the prominent place on the social networking site (e.g. 10 hot topics of today), and is likely to be picked up by traditional media and influential celebrities. In turn this will generate an even wider cascade causing more people to discuss about this topic.

Therefore, making a topic reach the critical threshold (also called the tipping point [10]) is the crucial step to generate huge influence on the topic, which is desirable by companies large and small trying to use social networks to promote their products, through the so called viral marketing cam-paigns . Besides making the content of the topic attractive and viral, another key aspect is to select seed users in the network that initiate the topic discussion effectively to trig-ger a large cascade on the topic. Due to the cost incurred for engaging seed users (e.g. providing free sample products), it is desirable that the size of seed users is minimized. More-over, the marketers also need certain probabilistic guarantee on how likely the viral marketing campaign could reach the desired critical threshold in order to trigger an even larger cascade via hot topic listings, traditional media coverages, and celebrity followings. Hence, the problem at hand is how to select a seed set of users of minimum size to trigger a topic cascade such that the cascade size reaches the desired critical threshold with guaranteed probability.

In this paper, we formulate the above problem as the fol-lowing optimization problem and call it seed minimization with probabilistic coverage guarantee (SM-PCG) . A social network is modeled as a directed graph, where nodes rep-resent individuals and directed edges represent the relation-ships between pairs of individuals. Each edge is associated with an influence probability , which means that once a node is activated, it can activate its out-neighbors through the outgoing edges with their associated probabilities at the next step. Our analytical results work for a large class of in-fluence diffusion models that guarantee submodularity (the diminishing marginal return property in terms of seed set size), but for illustration purpose, we adopt the classic in-dependent cascade (IC) model [14] as the influence diffusion model. In the IC model, initially all seed nodes are activated while others are inactive, and at each step, nodes activated at the previous step have one chance to activate each of its inactive out-neighbors in the network. The total number of active nodes after the diffusion process ends is referred as the influence coverage of the initial seed set. Given such a social network with influence probabilities on edges, given a required coverage threshold  X  and a probability threshold P , the SM-PCG problem is to find a seed set S  X  of minimum size such that the probability that the influence coverage of S  X  reaches  X  or beyond is at least P .

The formulation of the SM-PCG problem significantly de-parts from previous optimization problems based on social influence diffusion (e.g. [14, 5, 4, 12]) in that it requires the selected seed set to satisfy a probabilistic coverage guarantee, while previous research focuses on expected coverage guaran-tee. For the application of generating a hot topic, we believe that it is reasonable to ask for a guarantee on the probabil-ity of influence coverage exceeding a given threshold, since this provides direct information on the likelihood of success of the viral marketing campaign, which is very helpful for marketers to gauge their cost and benefit trade-offs for the campaign. Merely saying that the expected influence cov-erage exceeds the required coverage threshold is not enough in this case. To the best of our knowledge, this is the first work that focuses on probabilistic influence coverage guar-antee among existing studies on social network influence op-timization problems.

In this paper, we first show that the set functions based on the SM-PCG problem are not submodular, which means that it is more difficult than most of the existing social in-fluence optimization problems that rely on submodular set function optimizations. Next, we investigate two computa-tion tasks related to SM-PCG problem, one is to fix a seed set S and a coverage threshold  X  and compute the probabil-ity of influence coverage of S exceeding  X  , and the other is to fix a seed set S and a probability threshold P , and compute the maximum coverage threshold  X  such that the probabil-ity of influence coverage of S exceeding  X  is at least P . We show that the first problem is #P-hard but can be accu-rately estimated, while the second one is #P-hard to even approximate the value within any nontrivial ratio. These results further demonstrate the hardness of the problem.
We then adapt the greedy approximation algorithm tar-geted for expected influence coverage problem (which is sub-modular) to the SM-PCG problem. Although the adapted algorithm still follows the greedy approach, our main con-tribution is on a detailed analysis, which proves that our algorithm approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplica-tive ratio is due to the greedy approximation algorithm for expected influence coverage and is tight, while the additive error is determined by the concentration property (in partic-ular the standard deviations) of influence coverage distribu-tions of two specific seed sets. For one-way bipartite graphs where edges are directed from one side to the other side, we analytically show that the influence coverage distributions are well concentrated and we could reach an additive error of O (
Finally, using several real-world social networks including a network with influence probability parameters obtained from prior work, we empirically validate our approach by showing that (a) influence coverage distributions of seed sets are well concentrated, and (b) our algorithm selects seed sets with sizes much smaller than commonly adopted benchmark algorithms.

To summarize, our contributions include: (a) we propose the study of seed minimization with probabilistic coverage guarantee (SM-PCG), which is more relevant to hot topic generation in online social networks and has not been stud-ied before; (b) we show that neither of the two versions of set functions related to SM-PCG is submodular, one ver-sion is #P-hard to compute but allows accurate estimation while the other version is #P-hard to even approximate to any nontrivial ratio; (c) we adapt the greedy algorithm targeted for expected coverage guarantee to SM-PCG, and analytically show that the adapted algorithm provides an approximation guarantee with a tight multiplicative ratio and an additive error depending on the influence coverage concentrations of certain seed sets; and (d) we empirically demonstrate the effectiveness of our algorithm using real-world datasets.
Influence maximization , as the dual problem of seed mini-mization, is to find a seed set of at most k nodes to maximize the expected influence coverage of the seed set. Domingos and Richardson are the first to formulate influence maxi-mization problem from an algorithmic perspective [7, 17]. Kempe et al. first model this problem as a discrete opti-mization problem [14], provide the now classic independent cascade and linear threshold diffusion models, and estab-lish the optimization framework based on submodular set function optimization. A number of studies follow this ap-proach and provide more efficient influence maximization algorithms (e.g. [5, 4, 6, 13]). In [16], Long et al. first study independent cascade and linear threshold diffusion models from a minimization perspective. In [12], Goyal et al. pro-vide a bicriteria approximation algorithm to minimize the size of the seed set with its expected influence coverage reaching a given threshold. Recently, a continuous time dif-fusion model is proposed and studied in [18] and [8]. All these existing studies focus on expected influence coverage, and rely on the submodularity of expected influence cover-age function for the optimization task. In contrast, we are the first to address probabilistic coverage guarantee for the seed minimization problem, which is not submodular.

Seed minimization with non-submodular influence cover-age functions under different diffusion models have been studied. Chen [3] studies the seed minimization problem under the fixed threshold model, where a node is activated when its active neighbors exceed its fixed threshold. He shows that the problem cannot be approximated within any polylogarithmic factor (under certain complexity theory as-sumption). Goldberg and Liu [11] study another variant of fixed threshold model and provide an approximation algo-rithm based on the linear programming technique. Influence coverage functions in both models are deterministic and non-submodular. However, these models are quite different from the model we study in this paper, and thus their results and techniques are not applicable to our problem.

The rest of this paper is organized as follows. We define the diffusion model and the optimization problem SM-PCG in Section 2, and provide related results and tools in Sec-tion 3, including the non-submodularity of the set functions for SM-PCG. In Section 4 we investigate the computation problems related to SM-PCG. In Section 5 we provide our algorithm for general graphs and analyze its approximation guarantee. In Section 6 we provide algorithmic and ana-lytical results for one-way bipartite graphs. We empirically validate our concentration assumption on influence coverage distributions and the effectiveness of our algorithm in Sec-tion 7, and conclude the paper in Section 8 with a discussion on potential future directions. Due to the space constraint, some of the technical proofs and empirical results are omit-ted, and they are included in our full technical report [20].
In our problem, a social network is modeled as a directed social graph G = ( V,E ), where V is the set of n nodes rep-resenting individuals in a social network, and E is the set of directed edges representing influence relationships between pairs of individuals. Each edge ( u,v )  X  E is associated with an influence probability p u,v . Intuitively, p u,v is the proba-bility that node u activates node v after u is activated. The influence diffusion process in the social graph G follows the independent cascade (IC) model, a randomized process sum-marized in [14]. Each node has two states, inactive or active . The influence diffusion proceeds in discrete time steps, and we say that a node u is activated at time t if t is the first time step at which u becomes active. At the initial time step t = 0, a subset of nodes S  X  V is selected as active nodes, defined as the seed set , while other nodes are inac-tive. For any time t  X  1, when a node u is activated at step t  X  1, u is given a single chance to activate each of its inac-tive out-neighbors v through edge ( u,v ) independently with probability p u,v at step t . Once activated, a node stays as active in the remaining time steps. The influence diffusion process stops when there is no new activation at a time step.
Given a target set U  X  V , let Inf U ( S ) be the random variable denoting the number of active nodes in U after the diffusion process starting from the seed set S ends. When the context is clear, we usually omit the subscript U and use Inf ( S ) to represent this random variable, and we refer Inf ( S ) as the influence coverage of seed set S (for target set U ). The optimization problem we are trying to solve is to find a seed set S of minimum size such that the influence coverage of S is at least a required threshold with a required probability guarantee. The formal problem is defined below. Definition 1 (Seed minimization with probabilistic coverage guarantee) We define the problem of seed min-imization with probabilistic coverage guarantee (SM-PCG) as follows. The input of the problem includes the social graph G = ( V,E ) , the influence probabilities p u,v  X  X  on edges, the target set U , a coverage threshold  X  &lt; | U | , 1 a probability threshold P  X  (0 , 1) . The problem is to find the minimum size seed set S  X  such that S  X  can activate at least  X  nodes in U with probability P , that is,
The following theorem shows the hardness of the SM-PCG problem.

Theorem 1. The problem SM-PCG is NP-hard, and for any  X  &gt; 0 , it cannot be approximated within a ratio of (1  X   X  ) ln n unless NP has n O (log log n ) -time deterministic al-gorithms.

Proof (Sketch). We show that the NP-complete prob-lem Set Cover is a special case of SM-PCG, and the lower bound on approximation ratio is due to the result in [9] on the Set Cover problem.

With the above hardness result, we set our goal as to find algorithms that solve the SM-PCG problem with approxi-mation ratio close to ln n .
In this section, we provide some useful results and tools in preparation for our algorithm design.

Almost all previous work on social influence maximization or seed minimization is based on submodular function op-timization techniques. Consider a set function f (  X  ) which maps subsets of a finite ground set into real number set R We say that f (  X  ) is submodular if for any subsets S  X  T and any element u 6 X  T , f ( S  X  X  u } )  X  f ( S )  X  f ( T  X  X  u } )  X  f ( T ). Moreover, we say that f (  X  ) is monotone if for any subsets S  X  T , f ( S )  X  f ( T ).

Consider a monotone and submodular function f (  X  ) on subsets of nodes in the social graph G = ( V,E ). Suppose that each node v  X  V has a cost c ( v ), given by a cost func-tion c : V  X  R + . The cost of a subset S is defined as problem of finding a subset S  X  V with minimum cost such that f ( S ) is at least some given threshold  X  . As in many optimization tasks for submodular functions, the following greedy algorithm is applied to solve the problem: start-ing from the emptyset S 0 =  X  , in the i -th iteration with
We believe that  X  &lt; | U | is reasonable for the application scenarios we described since typically it requires only a frac-tion of the entire target node set to make a topic hot. For the case of  X  = | U | , we also worked out a separate solution for one-way bipartite graphs, but due to page limit, we omit it in this paper. i = 1 , 2 ,... , find a node v i that provides the largest marginal gain on f per-unit cost, that is find and add v i to S i  X  1 to obtain S i ; continue this process until iteration j in which f ( S j )  X   X  , where  X  is a threshold that could be  X  or some other value chosen by the algorithm as the stopping criteria, and output S j as the selected subset S . However, generally computing f (  X  ) exactly is #P-hard, but for most influence spread models, it can be estimated by Monte Carlo simulation as accurately as possible. We say an estimation  X  f (  X  ) is a  X  -multiplicative error estimation of show a bicriteria approximation result for the above greedy algorithm when  X  = 0 [12]. For the case of uniform node cost and  X  &lt; f ( V ), we slightly improve the above result by removing the bicriteria restriction and generalizing to the case of  X   X  0.

Theorem 2. Let G = ( V,E ) be a social graph, and let f (  X  ) be a nonnegative, monotone and submodular set func-tion on the subsets | V | . Given a threshold 0 &lt;  X  &lt; f ( V ) ,let S  X   X  V be a subset of minimum size such that f ( S  X   X  , and S be the greedy solution using a  X  -multiplicative error estimation function  X  f (  X  ) with the stopping criteria  X  f ( S )  X  (1 +  X  )  X  . For any 0  X   X  0  X  1 , for any 0  X   X   X 
Note that when  X  =  X ( f ( V )), we have  X   X 
Kempe et al. show that set function E [ Inf ( S )] for expected influence coverage is monotone and submodular under the IC model [14]. Therefore, if our problem is to find a seed set of minimum size such that the expected influence coverage is at least a threshold value  X  , Theorem 2 already provides the approximation guarantee of the greedy algorithm. We call this problem the seed minimization with expected coverage guarantee (SM-ECG) , to differentiate with the problem con-cerned in this paper  X  seed minimization with probabilistic coverage guarantee (SM-PCG).

For the SM-PCG problem, we want the influence coverage to be at least  X  with a guaranteed probability P . This seem-ingly minor change from SM-ECG actually alters the nature of the problem. The SM-PCG corresponds to two variants of set functions, but neither of them is submodular. In the first variant, we fix influence threshold  X  , and define f  X  : 2 R + where f  X  ( S ) = Pr( Inf ( S )  X   X  ). In the second vari-ant, we fix probability P , and define g P : 2 | V |  X  R + g submodular, as shown by the two examples below. For f  X  , see Figure 1(a), G is a bipartite graph where all edges are associated with probability 1, and U contains all the nodes in the lower part. We fix  X  = 5. Let S = { a } and T = { a,b } , then f  X  ( S  X  X  u } )  X  f  X  ( S ) = 0, since neither S nor S  X  X  u } could reach 5 nodes in U . Similarly, f  X  ( T ) = 0. However, f ( T  X  X  u } ) = 1, since 5 nodes are reached by T  X  X  u } . There-fore, f  X  ( T  X  X  u } )  X  f  X  ( T ) &gt; f  X  ( S  X  X  u } )  X  f is not submodular. For g P , see Figure 1(b), G is a bipartite graph where all edges are associated with probability 0 . 5, and U = { u } . We set P = 0 . 8. Let S = { a } and T = { a,b } , Figure 1: Function f  X  and g P are nonsubmoduar.
 Algorithm 1 Function MC-CompProb [ R ]: R is a tuning parameter controlling the accuracy of the estimate Output: estimate of P = Pr( Inf ( S )  X   X  ) 1: t = 0 2: for i = 1 to R do 3: simulate IC diffusion with seed set S 4: N i = number of final active nodes in U 5: if N i  X   X  then 6: t = t + 1 7: end if 8: end for 9: return t/R then g P ( S  X  X  c } )  X  g P ( S ) = 0 and g P ( T  X  X  c } )  X  g Since g P ( S  X  X  c } )  X  g P ( S ) &lt; g P ( T  X  X  c } )  X  g submodular.

Since neither f  X  (  X  ) nor g P (  X  ) is submodular, we cannot apply Theorem 2 on f  X  (  X  ) or g P (  X  ) to solve the SM-PCG problem. In this paper, we address this non-submodular optimization problem by relating it to the SM-ECG prob-lem through a concentration assumption on random variable Inf ( S ) for certain seed sets S .
Before working on the SM-PCG problem directly, we first address the related computation issue when a seed set S is given. As we mentioned in last section, there are two variants in influence coverage computation. The first vari-ant is that, given a seed set S and a coverage threshold  X  , we need to compute the probability f  X  ( S ) that S can acti-vate at least  X  nodes in U . Note that we have E [ Inf ( S )] = P putation of f  X  ( S ) must be #P-hard in the IC model since computing expected influence coverage E [ Inf ( S )] of seed set S has shown to be #P-hard in the IC model [4]. However, we can use Monte Carlo simulation to compute an accurate es-timate of the probability. Algorithm 1 shows the procedure MC-CompProb [ R ] for this task, which simulate the diffusion from seed set S for R runs and use the fraction of runs in which the number of active nodes in U reaches  X  as the estimate of the probability.

The following lemma shows the relationship between the number of simulations R and the accuracy of the estimate. Lemma 1. Let  X  P be the estimate of true value P = Pr( Inf ( S )  X   X  ) output by MC-CompProb [ R ] in Algorithm 1. To guarantee an error of at most  X  , i.e. |  X  P  X  P |  X   X  , with probability at least 1  X  1 /n  X  , it is sufficient to set R  X  ln(2 n  X  ) / (2  X  2 ) .

Proof (Sketch). This is a direct application of Hoeffd-ing X  X  Inequality since Monte Carlo simulation runs are mu-tually independent.

The second variant is that, given a seed set S and a spec-ified probability P , we need to compute the maximum in-fluence coverage  X  of S with at least probability P , that is, show below that this problem is #P-hard to approximate to any non-trivial ratio. We say that an algorithm approx-imates a true value v for a computing problem with ratio  X  &gt; 1 if the output of algorithm  X  v satisfies v/ X   X   X  v  X   X v . Note that if the range of value v is from 1 to n , then using  X  v = n 1 / 2 gives a trivial approximation ratio of  X  = n
Theorem 3. For any fixed probability P  X  (0 , 1) , the a directed social graph G = ( V,E ) , influence probabilities { p u,v | ( u,v )  X  E } , target set U = V , and a seed set S is #P-hard to approximate within a ratio of | V | 1 / 2  X   X   X  &gt; 0 .

Note that we treat P as a fixed parameter of the problem rather than as part of the input to the computation problem, which makes the result stronger.

Proof (Sketch). We prove the theorem by first reduc-ing the #P-complete counting problem of s -t connectivity in a directed graph [19] to its decision version, and then reduc-ing the decision version to our computation problem.
In this section, we overcome the nonsubmodularity na-ture of the SM-PCG problem discussed in Section 3 by con-necting it with the submodular problem SM-ECG. We first provide the general algorithm, and then show that the al-gorithm returns a seed set that approximates the optimal solution with both a multiplicative ratio and an additive er-ror. The multiplicative ratio is due to the connection with the SM-ECG problem. For the additive error term, we show that it would be nontrivial when certain concentration as-sumption on influence coverages holds.

Algorithm 2 illustrates algorithm MinSeed-PCG for solving the SM-PCG problem. The algorithm builds up a sequence of subsets S 0 ,S 1 ,S 2 ,... , where for each i  X  1, S i one more element u than S i  X  1 such that u provides the largest marginal increase in expected influence coverage to seed set S i  X  1 . The way of constructing seed sets S i  X  X  is in line with the greedy approach as discussed in Section 3. In our algorithm,  X  E [ Inf (  X  )] is a  X  -multiplicative error estimation of exact expected influence E [ Inf (  X  )]. Every time a new set S is constructed, we compute the probability that the influence coverage of S i is at least  X  (line 5). The CompProb in line 5 is a generic function computing Pr( Inf ( S i )  X   X  ), which could be MC-CompProb [ R ] in Algorithm 1 for general graphs, or Bi-CompProb in Algorithm 3 for one-way bipartite graphs, or some other functions for this purpose. If the probability computed is at least P +  X  , where  X   X  [0 , (1  X  P ) / 2) is a pa-rameter of the algorithm, we stop and return S i as the seed
This lemma holds when  X  &gt; P . However, we usually set  X  smaller than P to make the estimate more reasonable. Algorithm 2 MinSeed-PCG [  X  ]:  X   X  [0 , (1  X  P ) / 2) is a control parameter Output: seed set S , which is an approximation to S 1: S 0 =  X  2: for i = 1 to n do 3: select u = argmax v {  X  E [ Inf ( S i  X  1  X  { v } )]  X  5: prob = CompProb ( G, { p u,v } ( u,v )  X  E ,U,S i , X  ) 6: if prob  X  P +  X  then 7: return S i 8: end if 9: end for set found by the algorithm. Parameter  X  is related to the accuracy of the function CompProb . If CompProb accurately computes Pr( Inf ( S )  X   X  ) (e.g. Bi-CompProb for one-way bi-partite graphs), we set  X  to 0. If CompProb only provides an estimate (e.g. MC-CompProb [ R ] for general graphs), we set  X  to be an appropriate value related to the error term of the estimate given by the function. We will discuss parameter  X  with more technical details later.

Let S  X  be the optimal seed set for the SM-PCG problem, m = | U | . Let S = { S 1 ,S 2 ,...,S n = V } be the sequence of greedy seed sets computed by algorithm MinSeed-PCG [  X  ] (considering the entire sequence even when MinSeed-PCG [  X  ] actually stops). Let S a be the output of MinSeed-PCG [  X  ] and a is its index in sequence S , and thus S a  X  1 is the set in S just before S a .

We define c = max {  X   X  E [ Inf ( S  X  )] , 0 } and c 0 max { E [ Inf ( S a  X  1 )]  X   X , 0 } . Intuitively, we know that Pr( Inf ( S  X  )  X   X  )  X  P , and c indicates how much E [ Inf ( S  X  )] could be smaller than  X  . If Inf ( S trates well, c should be small. Similarly, we also know that isfying Pr( Inf ( S a )  X   X  )  X  P +  X  . Thus, c 0 indicates how much E [ Inf ( S a  X  1 )] could be larger than  X  , and if Inf ( S concentrates well, c 0 should be small.
 The following theorem shows that the output S a of MinSeed-PCG [  X  ] approximates the optimal solution S  X  with c and c 0 included in the additive error term.

Theorem 4. For any 0  X   X  0  X  1 and any 0  X   X   X  output by algorithm MinSeed-PCG [  X  ] approximates the size of the optimal solution in the following form: | S a | X  ln (1 +  X  0 )  X n
First, note that we assume m &gt;  X  , so the multiplicative term above is well defined. Moreover,  X  + c 0 must be less than m , because otherwise E [ Inf ( S a  X  1 )] = m = | U | , which implies Pr( Inf ( S a  X  1 ) = m ) = 1, contradicting the fact that Pr( Inf ( S a  X  1 )  X   X  ) &lt; P +  X  &lt; 1. Second, for the multiplica-tive ratio of d ln  X n m  X   X  e , when  X  is a constant fraction of m , i.e.  X  =  X m where  X  is a constant independent of m and n , it is ln n + O (1), which is tight, since Theorem 1 already states that the ratio cannot be better than ln n . The additive error term involves c and c 0 , and we will discuss it in more detail after providing the proof to the theorem below. Third, when  X  + c 0 is a constant fraction of m ,  X   X   X  0 ( m  X  (  X  + c Fourth, by Chernoff bound, to achieve a  X  -multiplicative er-ror estimation of expected influence with probability 1  X  1 /n for all subsets computed in our algorithm, it is sufficient to sample  X (  X   X  2 n log n ) number of graphs for each set.
Proof. We only prove the case of  X  =  X  0 = 0 in this paper. Let i be the minimum index such that S i  X  S and E [ Inf ( S i )]  X   X   X  c , and S  X  i be the minimum-sized seed set such that E [ Inf ( S  X  i )]  X   X   X  c . Since E [ Inf ( S know that | S  X  i | X | S  X  | . By Theorem 2, since l ln (  X   X  c ) n 0, we have that | S i | X  ln Let j be the minimum index such that S j  X  S and E [ Inf ( S j )]  X   X  + c 0 . Since E [ Inf ( S a  X  1 )]  X   X  + c that | S j |  X  | S a  X  1 | . To bound the difference between | S and | S i | , it is sufficient to compute the difference between | S j | and | S i | .

By the definition of j , we have that E [ Inf ( S j  X  1 )] &lt;  X  + c thus E [ Inf ( S j  X  1 )]  X  E [ Inf ( S i )] &lt; c + c 0 submodularity of E [ Inf (  X  )], we know that for each i &lt; t &lt; j , Thus, we have that | S j  X  1 \ S i |  X  E [ Inf ( S j  X  1 )]  X  E [ Inf ( S i )] It means that Since | S a | X | S j | + 1 = | S i | + | S j \ S i | + 1, we have The theorem holds.

We now discuss the additive term in Inequality (1). To make it nontrivial, we need the additive term to be o ( n ) as n grows. This means first that the target set size m should be increasing with n , which is reasonable. Then we should have c + c 0 = o ( m ) in order to make the additive term o ( n ). In the following theorem, we bound c and c by the variances of the influence coverage of S  X  and S a  X  1 respectively using Chebyshev X  X  inequality, and thus linking the above requirement on c and c 0 to the requirement on the variances of influence coverages.

Theorem 5. For algorithm MinSeed-PCG [  X  ] with any pa-rameter  X  , we have If we use MC-CompProb [ R ] for function CompProb and set R  X  ln(2 n 2 ) / (2  X  2 ) , then algorithm MinSeed-PCG [  X  ] finds a seed set S a such that, with probability at least 1  X  1 /n , Pr( Inf ( S a )  X   X  )  X  P and
Theorem 5 shows that the variances of influence coverages of seed sets, or more exactly the standard deviations of in-fluence coverages, determine the scale of the additive error term of the algorithm MinSeed-PCG [  X  ]. If influence cover-ages concentrate well with small standard deviations, the algorithm would have a good additive error term. Consider the common case where target set size m =  X ( n ), and  X  is a constant fraction of m , and P is a normal probability re-quirement not too close to 0 or 1 (e.g. 0 . 1 or 0 . 5), if we could have Var ( Inf ( S  X  )) = O ( m ) and Var ( Inf ( S a  X  1 then c + c 0 = O ( O ( n/ know that In the next section, we analytically show that for one-way bipartite graphs indeed c + c 0 = O ( verify that in real-world graphs the standard deviations of influence coverages are indeed small, close to fore, our algorithm are likely to perform well in practice.
We remark that our theorems in this section can be ap-plied to a class of models with the following characteristics: 1. the influence coverage function of a seed set (i.e., 2. the influence coverage when choosing the whole set The above class includes many diffusion models, such as linear threshold model, general threshold model and contin-uous time diffusion model.
In this section, we solve the SM-PCG problem on a one-way bipartite graph G = ( V 1 ,V 2 ,E ), where all edges in E are from V 1 to V 2 . For the sake of convenience, we just assume that U = V 2 in this section. It is easy to remove this assumption and make U to be any subset of V 1  X  V 2 .
One-way bipartite graphs provide two significant advan-tages over general graphs. First, it allows a dynamic pro-gramming method to compute the exact influence coverage distribution given any seed set S . Second, it allows a theo-retical analysis on the concentration of influence coverages of seed sets. We illustrate both aspects below.

We first show how to implement exact computation of function CompProb . We assign indices for nodes in V v ,v 2 ,...,v m . Let A ( S,i,j ) denote the probability that seed set S can activate exactly j nodes in the first i nodes of V : v 1 ,...,v i , where j  X  i . Let p ( S,v ) be the probability that v can be activated by S . When i = 1, it is trivial to get A ( S, 1 ,j ). When i &gt; 1, we can use A ( S,i  X  1 ,j  X  1) and A ( S,i  X  1 ,j ) to compute A ( S,i,j ). If j = 0, it means v ,...,v i  X  1 and v i are all inactive. If 0 &lt; j &lt; i , there are two cases: j nodes are activated in the first i  X  1 nodes while v is not activated; j  X  1 nodes are activated in the first i  X  1 nodes and v i is activated. If j = i , both v 1 ,...,v i  X  1 are activated. Thus, we have the following recursion, and For IC model, p ( S,v i ) = 1  X  Q u  X  S (1  X  p u,v i ); for LT model, p ( S,v i ) = P u  X  S p u,v i . Using the above dynamic program-ming formulation, we can implement function CompProb as function Bi-CompProb given in Algorithm 3.
 Algorithm 3 Function Bi-CompProb for bipartite graphs Output: P = Pr( Inf ( S )  X   X  ) 1: for i from 1 to n , and j from 1 to i do 2: compute A ( S,i,j ) via dynamic programming 3: end for 4: return P m j =  X  A ( S,m,j )
One-way bipartite graphs have an important property that the activation events of nodes in V 2 are mutually in-dependent. This allows us to bound c and c 0 defined in Section 5 using Hoeffding X  X  Inequality, and get the following result.
 Theorem 6. For one-way bipartite graphs, algorithm MinSeed-PCG [0] using function Bi-CompProb returns seed set S a such that Pr( Inf ( S a )  X   X  )  X  P , and when we con-sider the probability threshold P as a constant independent of n and m , we have
We note that one-way bipartite graphs are a restricted class of graphs, where the influence cascading is a 1-hop cascading process and cannot be generated to a cascade with greater depth. However, we believe their analytical results can shed lights on more realistic networks when most of node activations in the network are independent.
We conduct experiments on real social networks for the following purposes: (1) test the concentration of influence coverage distributions of seed sets; (2) validate the perfor-mance of our algorithm against baseline algorithms.
Datasets. We conduct experiments on three real social networks. The first one is wiki-Vote [15], a network relation-ship graph from Wikipedia community with totally 7,115 nodes and 103,689 edges. In wiki-Vote graph, each node represents a user, and an edge ( u,v ) represents user u votes for user v , which means that v has an influence on u . Thus, in our experiment, we reverse all edges to express the influ-ence between pairs of nodes. We use weighted cascade (WC) model [14] to assign the influence probabilities on edges. For each edge ( u,v ), we assign its probability to be 1 /d where d in ( v ) is the in-degree of node v .

The second network is NetHEPT, which is a standard dataset used in [5, 4, 6, 13, 12]. NetHEPT is an academic collaboration network from arXiv (http://www.arXiv.org), with totally 15,233 nodes and 58,891 edges. In NetHEPT graph, each node represents an author, and each edge repre-sents coauthor relationship between two authors. NetHEPT is an undirected graph, and in our experiment we add two directed edges between two nodes if there exists at least one edge between these two nodes in NetHEPT. Similar to wiki-Vote, we use WC model to assign edge influence prob-abilities. We assign the probability on directed edge ( u,v ) to be d ( u,v ) /d ( v ), where d ( u,v ) is the number of papers collaborated by u and v , and d ( v ) is the number of papers published by v .

The last one is Flixster, an American movie rating social site. Each node is a user, and edges describe the friendship between users. In this network, we use a Topic-aware Inde-pendent Cascade Model from [1] to learn the real influence probabilities on edges for different topics. We simply use two different topics, say topic 1 and topic 2, and get the edge probabilities that one user influences his/her friend on the specific topic. In both topics, we remove edges with prob-ability 0 and isolated nodes. For topic 1, there are 28,317 nodes and 206,012 edges. The mean of edge probabilities is 0.103, and the standard deviation is 0.160. For topic 2, there are 25,474 nodes and 135,618 edges. The mean of edge probabilities is 0.133, and the standard deviation is 0.205.
Experiment methods. In the experiment, for the sake of convenience, we set U = V .

Our first task is to test the concentration of influence cov-erage distributions of seed sets. To do so, we test the vari-ances (or their square roots, i.e. standard deviations). Ac-cording to Theorem 5, small standard deviations imply small c and c 0 and thus small additive errors of the MinSeed-PCG [  X  ] algorithm output. By Inequality (3), to verify that c small, we just need to test the standard deviations of all seed sets generated by the algorithm. For quantity c , we need to test the standard deviation of the influence cov-erage of the optimal seed set, according to Inequality (2). However, finding the optimal seed set is NP-hard, therefore we cannot fully verify the bound on c . To compensate, we test randomly selected seed sets as follows. For each fixed seed set size k , we independently select 10 seed sets of size k at random, and compute the maximum standard devia-tions of the influence coverage distributions of these selected seed sets. Although randomly selected seed sets may be far from the optimal seed set, what we hope is that by test-ing standard deviations on both randomly selected sets and greedily selected sets by algorithm MinSeed-PCG [  X  ], we have a general understanding of standard deviations of influence coverages of seed sets, which may provide us with hints for other seed sets, such as the optimal seed set. To estimate the standard deviations of influence coverage of a seed set S , we use 10,000 times Monte Carlo simulation and compute the standard deviation.

Our second task is to test the performance of seed se-lection algorithm MinSeed-PCG [  X  ]. We compare the perfor-mance with three baseline algorithms: (a) Random , which generates the seed set sequence in random order; (b) High-degree , which generates the seed set sequence according to the decreasing order of the out-degree of nodes; and (c) PageRank , which is a popular method for website ranking [2]. We use p v,u / P ( w,u )  X  E p w,u as the transition probability for edge ( u,v ). Higher p v,u means that v is more influential to u , indicating that u ranks v higher. We use 0.15 as the restart probability and use the power method to compute PageRank values. When two consecutive iterations are dif-ferent for at most 10  X  4 in L 1 norm, we stop. As for our MinSeed-PCG [  X  ] algorithm, to speed up the algorithm, we use the state-of-the-art PMIA algorithm of [4] to greedily generate the seed set sequence. For all the above algorithms, we use the same MC-CompProb [ R ] algorithm to compare whether a seed set S in the sequence satisfies the condition Pr( Inf ( S )  X   X  )  X  P +  X  . Since the seed set sequence gen-erations in all the above algorithms are fast comparing to the Monte Carlo simulation based MC-CompProb [ R ] algo-rithm, our implementation actually generates the sequence first and then uses binary search to find the seed set in the sequence satisfying Pr( Inf ( S )  X   X  )  X  P +  X  .

We set parameters R = 10 , 000 and  X  = 0 . 01. One may see that these settings do not satisfy the condition R  X  ln(2 n 2 ) / (2  X  2 ) in Theorem 5 for our datasets: in our datasets, n is around 10 4 , and thus ln(2 n 2 ) / (2  X  2 9 . 6  X  10 4 . However, we can justify our choice as follows. First, the condition R  X  ln(2 n 2 ) / (2  X  2 ) is a conservative the-oretical condition for obtaining high probability of 1  X  1 /n for our approximation guarantee. In practice, a smaller R of 10 , 000 is good enough for illustrating our results. Second, all algorithms use the same MC-CompProb [ R ] algorithm, so the comparison is fair among them, and is focused on the difference in their generations of seed set sequences, not on the accuracy of the estimate of function CompProb . Third, the seed selections actually depends only on the combined parameter P 0 = P +  X  , and not on P and  X  separately. Thus setting  X  = 0 . 01 is only for intuitive understanding and set-ting it to some other value would not change the results as long as P 0 remains the same.
Concentration of influence coverages. Figure 2 shows the standard deviations of influence coverages of ran-domly selected seed sets and greedily selected seed sets (by algorithm MinSeed-PCG [  X  ]) on wiki-Vote, NetHEPT and Flixster. We can see that in all graphs, standard devia-tions for greedily selected seed sets quickly drop, while for randomly selected seed sets sometimes it has a small in-crease when the seed set size is small, and then quickly drop too. The maximum value is about 130 for wiki-Vote ( | V | = 7 , 115), 105 for NetHEPT ( | V | = 15 , 233), 760 for Flixster with topic 1 ( | V | = 28 , 317), and 270 for Flixster with topic 2 ( | V | = 25 , 474). Thus by observation the stan-dard deviation is at the order of p | V | . As discussed after Theorem 5, this means that the additive error of our algo-rithm would be O ( p | V | ), a small and satisfactory value. Figure 2: Standard deviations of influence coverages of seed sets. Figure 3: Size of selected seed sets vs. coverage threshold  X  under a fixed probability threshold P = 0 . 1 .
 The standard deviations for wiki-Vote are larger than those for NetHEPT at small seed set size even though the num-ber of nodes of wiki-Vote is smaller. We believe this is be-cause wiki-Vote has more edges (103,689) than NetHEPT (58,891), and thus when the seed set size is small more edges could cause larger variances in influence coverage. This can also explain why in Flixster topic 1 (with 206,012 edges) has larger standard deviations than topic 2 (with 135,618 edges).

Performance of MinSeed-PCG [  X  ] compared with baselines. We conduct two sets of tests for this purpose. First, we fix the probability threshold P to 0 . 1 and 0 . 5, and vary the coverage threshold  X  to compare the size of seed sets selected by various algorithms. Figure 3 and Figure 4 show Figure 4: Size of selected seed sets vs. coverage threshold  X  under a fixed probability threshold P = 0 . 5 . the test results on three datasets. All test results consis-tently show that our algorithm performances the best, and sometimes with a significant improvement over the Random , High-degree and PageRank heuristics. In particular, for wiki-Vote and P = 0 . 1 (Figure 3(a)), on average our algorithm MinSeed-PCG [  X  ] selects seed sets with size 88 . 2% less than those selected by Random , 20 . 2% less than High-degree , and 30 . 9% less than PageRank . For NetHEPT and P = 0 . 1 (Fig-ure 3(b)), on average our algorithm selects seed sets with size 56 . 7% less than Random , 46 . 0% less than High-degree , and 24 . 4% less than PageRank . The High-degree heuristic performs close to MinSeed-PCG [  X  ] in wiki-Vote, but performs badly in NetHEPT, even worse than Random when  X  is large. This shows that High-degree is not a good and stable heuris-tic for this task. For Flixster with topic 1 and P = 0 . 1 (Fig-ure 5(c)), on average MinSeed-PCG [  X  ] selects seed sets with size 94 . 4% less than Random , 54 . 0% less than High-degree , and 29 . 2% less than PageRank . For Fixster with topic 2 and P = 0 . 1 (Figure 5(d)), on average MinSeed-PCG [  X  ] selects seed sets with size 91 . 1% less than Random , 73 . 0% less than High-degree , and 24 . 4% less than PageRank . Figures 4 show the results for P = 0 . 5. The curves are almost the same as the corresponding ones for P = 0 . 1. This can be explained by the sharp phase transition to be observed in the next set of tests, which is due to concentration of influence cover-age, such that typically only a few tens of more seeds would satisfy probability threshold P from 0 . 1 to 0 . 5.
Our second set of tests is to fix a coverage threshold  X  , and observe the change of coverage probability Pr( Inf ( S )  X   X  ) as the seed set S grows as computed by various algorithms. Figure 5 shows the test results. Wiki-Vote, NetHEPT and Flixster with topic 2 (Figure 5(a), (b), (d)) have sharp phase transition: there is a short range of seed set size where the probability increases very fast from 0.01 to very close to 1 (only several nodes are needed to reach a 0.1 increment in probability). While Filxster with topic 1 (Figure 5(c)) has a relatively smooth phase transition. This phase transition Figure 5: Size of selected seed sets vs. probability threshold P under a fixed coverage threshold  X  . phenomenon is clearly due to the concentration of influence coverages of seed sets, as already verified in Figure 2.
In all our tests, MinSeed-PCG [  X  ] performances the best: its phase transition comes first before the other algorithms, which means it uses less number of seeds to achieve the same probability threshold P . Random performs much worse than MinSeed-PCG [  X  ], while PageRank and High-degree per-form close to MinSeed-PCG [  X  ] when  X  is small, but notice-ably worse than MinSeed-PCG [  X  ] when  X  gets larger. For wiki-Vote, on average MinSeed-PCG [  X  ] selects a seed set with size 34 . 1% less than PageRank , 27 . 7% less than High-degree , and 86 . 4% less than Random when  X  = 3 , 000. When  X  = 4 , 500, MinSeed-PCG [  X  ] selects a seed set with size on average 38 . 8% less than PageRank , 30 . 8% less than High-degree , and 76 . 3% less than Random . For NetHEPT, when  X  = 6 , 000, on average MinSeed-PCG [  X  ] selects a seed set with size 22 . 8% less than PageRank , 51 . 8% less than High-degree , and 59 . 2% less than Random . When  X  = 10 , 500, on aver-age MinSeed-PCG [  X  ] selects a seed set with size 36 . 1% less than PageRank , 52 . 9% less than High-degree , and 49 . 6% less than Random . For Flixster with topic 1, when  X  = 2 , 000, on average the output number of seeds by MinSeed-PCG [  X  ] is 44 . 1% less than PageRank , 78 . 9% less than High-degree , and 98 . 3% less than Random . When  X  = 4 , 000, the correspond-ing results are 53 . 2%, 70 . 7% and 93 . 9%. For topic 2, when  X  = 2 , 000, the output number of seeds by MinSeed-PCG [  X  ] is 59 . 0% less than PageRank , 78 . 6% less than High-degree , and 95 . 8% less than Random . When  X  = 4 , 000, the corre-sponding results are 54 . 9%, 76 . 2% and 89 . 0%.

For all these graphs, we do not test the case when  X  is very close to the number of nodes. Since in this case a large seed set close to the full node set is needed, and greedy-based seed selection loses its advantage comparing to simple random or high-degree heuristics when a large number of seeds are needed. Moreover, we believe that requiring  X  to be close to the full network size is not a realistic scenario in practice.

As a summary, our experimental results validate that in-fluence coverages of seed sets are concentrated well in real-world networks, and thus support the claim that our algo-rithm provides good approximation guarantee. Moreover, our algorithm performs much better than simple baseline algorithms, achieving significant savings on seed set size.
This study may inspire a number of future directions. One is to study the concentration property of other classes of graphs, especially graphs close to real-world networks such as power-law graphs, to see if we can analytically prove that a large class of graphs have good concentration property on influence coverage distributions. Another direction is to speed up the estimation of Pr( Inf ( S )  X   X  ), which is done by Monte Carlo simulation in this work and is slow. One may also study influence maximization problem where reaching the tipping point is the first step, which is followed by further diffusion steps. Our algorithm and results may be an integral component of such influence maximization tasks. [1] N. Barbieri, F. Bonchi, and G. Manco. Topic-aware [2] S. Brin and L. Page. The anatomy of a large-scale [3] N. Chen. On the approximability of influence in social [4] W. Chen, C. Wang, and Y. Wang. Scalable influence [5] W. Chen, Y. Wang, and S. Yang. Efficient influence [6] W. Chen, Y. Yuan, and L. Zhang. Scalable Influence [7] P. Domingos and M. Richardson. Mining the network [8] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha. [9] U. Feige. A threshold of ln n for approximating set [10] M. Gladwell. The Tipping Point:How Little Things [11] S. Goldberg and Z. Liu. The Diffusion of Networking [12] A. Goyal, F. Bonchi, L. V. Lakshmanan, and [13] A. Goyal, W. Lu, and L. V. S. Lakshmanan.
 [14] D. Kempe, J. Kleinberg, and  X  E. Tardos. Maximizing [15] J. Leskovec. Wiki-vote social network. [16] C. Long and R.-W. Wong. Minimizing seed set for [17] M. Richardson and P. Domingos. Mining [18] M. G. Rodriguez and B. Sch  X  olkopf. Influence [19] L. G. Valiant. The complexity of enumeration and [20] P. Zhang, W. Chen, X. Sun, Y. Wang, and J. Zhang.
