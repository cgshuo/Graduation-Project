 With the rapid growth of Web 2.0, there exist a large amount of reviews on various types of social medias, such as discussion forums, microblogs, blogs and shopping websites. These reviews contain people X  X  opinions and sentiments to-wards different products and services. It i s important and helpful for both cus-tomers and manufacturers to discover and summarize aspects and sentiments from online reviews in detail. It is still a challenging task for the following two reasons. First, it is almost useless to do analysis manually because of the huge number of reviews. Second, the reviews are composed of unstructured texts. Accurately understanding these texts is difficult for machines.

Most earlier researches [1 X 3] adopt sup ervised learning models to classify the entire document as positive or negative. However, sentiment polarities are often dependent on topics or aspects. For example, in the hotel review  X  X he staff are very friendly, but the price is so high! X , sentiment for aspect staff is positive while sentiment for aspect price is negative. It is not sufficient to simply classify the entire review as positive or negative. Therefore, it is more suitable to analyze aspect and sentiment simultaneously.

In recent years, how to auto matically discover aspects and sentiments from online reviews has attracted many attent ions. Recent researches have proposed many methods to extract aspects and sentiments from online reviews. These methods can be divided into two categories. One kind of method only extracts as-pects without extracting sentiments. How ever, it can not provide aspect-specific sentiment information, which is also very important. The other kind extracts aspects and sentiments simultaneously. This kind of method first identifies dif-ferent aspects for the given product and then extracts specific sentiments for each aspect. In the extracted sentiment s for each aspect, positive and negative words are mixed together. This makes it hard for users to know how sentiment are expressed according to different p olarities for a particular aspect.
In this paper, we focus on the problem of simultaneously aspect and sentiment extraction and sentiment classification of online reviews. The problem setup is illustrated in Fig. 1. We propose two novel probabilistic generative models to address this problem. The first model is called APSM and the second model is called ME-APSM. Our models can not on ly extract different aspects (e.g. staff , room , meal and price for hotel), but also extract specific sentiments (positive or negative) for each aspect.

Compared to existing methods, the key advantage of our models is that we can extract polarity-aware sentiments for each aspect. For example, for aspect room , positive sentiments are  X  X arge X , X  X lean X  and  X  X afe X  while negative sentiments are  X  X irty X , X  X mall X  and  X  X oise X . Another advantage of APSM and ME-APSM is that they can be directly applied to the sentiment classification task for the entire review. Moreover, it is easy to integrat e aspect and sentiment prior knowledge into our models.

The rest of the paper is organized as fo llows. Section 2 introduces the related work. In section 3, we present our models and describe how to integrate prior information. Section 4 describes the data sets and experiment settings. Section 5 shows our experiment results. Section 6 concludes the research and gives di-rections for future studies. There are many existing works on aspect -based sentiment analysis. One ap-proach is to use frequent itemset mining algorithm to extract frequent nouns and noun phrases as aspect candidates [4 X 6]. The main limitations of frequent-based methods are that they do not group related aspects together and can not extract implicit aspect expressions. Sequ ential labeling techniques are also used to extract aspects and sentiments from reviews [7 X 9]. These supervised methods suffer from the hardness to obtain labeled training data.

In recent years, several unsupervise d unified aspect and sentiment models have been proposed. Zhao [10] proposed ME-LDA model by using a MaxEnt component to help separate aspect and s entiment words. ME-SAS proposed in [11] can further integrate aspect seeds by i ntroducing a two-level tree structured aspect distribution. Both ME-LDA and M E-SAS extract asp ects by separating aspect and sentiment words. However, th ey do not separate sentiments according to their polarities.

Some researchers focus on the separatin g of different sentiment polarities [12 X  14]. Lin and He [12] presented a JST model which can detect review-level sen-timent and extract mixture of aspects. The ASUM model proposed in [14] im-proved JST by constraining the words i n a single sentence to come from the same language model. However, aspect and sentiment words are mixed together in the aspects extracted by JST and AS UM, which make it hard for users to understand.

Our proposed APSM and ME-APSM models can not only separate aspect and sentiment words for each extracted asp ect, but also separate sentiment words according to their polarities. Moreover, APSM and ME-APSM are capable of detecting review-level sentiments. In this section, we first present our proposed Aspect-specific Polarity-aware Sen-timent model (APSM). Then we extend APSM to Maximum Entropy Aspect-specific Polarity-aware Sentiment Model (ME-APSM), with a maximum entropy component. Finally we describe how to integrate sentiment and aspect prior in-formation to the proposed models by using asymmetric Dirichlet prior. 3.1 APSM Model To understand how we model the reviews, we demonstrate the generative pro-cess of APSM by the following scenario. The reviewer wants to write a review about a hotel. She first decides a distribution of aspects, for example, 30% about price , 40% about staff and 30% for other aspects. Then she decides a sentiment distribution for each aspect, for example, 80% satisfied and 20% unsatisfied for aspect price . For each sentence, she decides which aspect to evaluate and what sentiment to express about the aspect. She also decides the distribution of as-pect and sentiment of the sentence. For each word in a sentence, she first decides whether it is an aspect word or a sentiment word. If she chooses aspect, then the word is generated from the aspect model. If she chooses a sentiment, then the word is generated from the asp ect-specific sentiment model.
The graphical representation of APSM is shown in Fig.2(a). Let V be the vocabulary size, D be the number of reviews, S d be the number of sentences in review d and N d,s be the number of words in sentence s of review d .Let K denote the number of aspects and M denote the number of sentiments. There are K aspect models  X  A k =1  X  X  X  K . For each aspect k ,thereare M aspect-specific for each word to denote whether it is an aspect word or a sentiment word. The variable  X  d,s denotes the distribution of aspects and sentiments in sentence s of review d .

The formal generative process of APSM is as follows: 1. For each aspect k  X  X  1 ,...,K } : 2. For each review d  X  X  1 ,...,D } : We use collapsed Gibbs Sampling [15] to inference the model. Due to space limit, we only show the sampling formulas without detailed derivations. The sampling formula of latent variables z and l is: where  X  (  X  ) is the gamma function. n Sent. d,k is the number of sentences assigned to sentiment m in review d . n A ( O ) d,s is the number of aspect (sentiment) words in (sentiment) word in sentence s of review d . n A k,v is the number of times word v assigned to aspect k as an aspect word. n O k,m,v is the number of times word v assigned to aspect k and sentiment m .  X  d, s denotes counts excluding sentence s of review d .

Assume that z d,s = k and l d,s = m , the sampler of latent variable r is : where  X  d, s, n denotes counts excluding w d,s,n .

With the above samples, we can estimate the model parameters  X  ,  X  ,  X  A and  X 
O as: We use  X  d,k to estimate the probability of aspect k in review d .Weextractthe aspect words for each aspect by  X  A k,v .  X  O k,m,v is used to identify aspect-specific sentiment words.  X  d,k,m is used to analyze the sentiment distribution of aspect k in review d . The overall sentiment score of entire review d is estimated as follows: 3.2 ME-APSM Model We improve APSM by employing Maximun Entropy(MaxEnt) priors to separate sentiment and aspect words better. This method was previously used in [10] and [11]. The basic idea is that aspect words tend to be nouns or noun phrases, while sentiment words tend to be adjective and adverbs. Thus we can train a MaxEnt by utilizing the POS features to help separate sentiments and aspects.
Following [10] and [11], we choose two types of features:lexical fetures and POS features. For word w d,s,n , we denote its corresponding feature vector as x d,s,n = { be trained automatically by using a sentiment lexicon, eliminating the need of manual annotation of labeled training data. We indicate the new model as ME-APSM, as shown in Fig.1(b).

In ME-APSM, the Gibbs samplers are the same except for variable r .The sampler for r changes as: p ( r d,s,n = X  a | Z, L, R  X  d,s,n ,W )  X  exp ( where f 1  X  X  X  n are the n binary features of the learned MaxEnt model and  X  1  X  X  X  n are their corresponding weight parameters. 3.3 Incorporating Prior Knowledge Although APSM and ME-APSM are unsupervised models, we can incorporate prior information which can be obtained in many ways. We consider the following two kinds of prior information: sentiment prior and aspect prior.
 Sentiment Prior. The first type of sentiment prior can be obtained from sen-timent lexicon. In some cases, user can a lso provide a few positive and negative sentiment seeds for some aspects. We inco rporate these two types of sentiment prior information into hyperparameter  X  O .

Let M = { M p ,M n } denote the sentiment lexicon, where M p is the positive word list and M n is the negative word list. Let  X  O k,m denote the aspect sentiment seeds. Intuitively, we expect that no ne gative sentiment word appears in each aspect X  X  positive sentiment model, and vice versa. We also expect that positive (negative) word will be more likely to app ear in each aspect X  X  positive (negative) sentiment model. Under these intuitions, we define  X  O as follows: Aspect Prior. In many cases, user can provide some seed words for a few aspect categories. We integrate this information into the hyperparameter  X  A . For aspect k , say user provides a seed set  X  k , we define  X  A k as follows. If word v is a sentiment word, then  X  A k,v =0;ifword v is in the seed set  X  k ,thenweset  X  k,v =0 . 1; else  X  We use two data sets to evaluate our proposed models. The first data set provided in [16] contains 10508 hotel reviews from TripAdvisor 1 . We construct a balanced version of this data set, which contains 2500 positive reviews and 2500 negative reviews. The second data set is a Amazon product reviews data set from [17]. This data set contains four product types : books, DVDs, electronics and kitchen appliances. For each product type, there are 2000 positive reviews and 2000 negative reviews.

To learn the parameters  X  1  X  X  X  n of ME-APSM, we randomly select 2000 sen-tences from both data sets. Then we use Stanford POS Tagger 2 to tag the reviews. Words contained in the sentiment lexicon are automatically labeled as sentiment words, otherwise as aspect words. We use the sentiment lexicon from [4], which contains 2006 positive sentiment words and 4783 negative sentiment words. The sentiment lexicon is also used to incorporate prior information into APSM and ME-APSM, as des cribed in section 3.3.

In our experiments, the number of aspects T issettobe30andthenumberof sentiments M is set to be 2. For all models, we set the Gibbs sampling iterations to be 5000. We fix  X  and  X  as:  X  =50 /T ,  X  =1.Following[11],weset  X  A =2 . 35,  X 
O =3 . 44 in APSM. In this section, we evaluate the perform ances of our proposed models with three experiments. In the first experiment, we show the aspects and aspect-specific sentiments extracted by APSM and ME-APSM with some qualitative analysis. The second experiment evaluates sentime nt identification performances of our models. In the third experiment, we apply a review-level sentiment classification task to compare our models with several baselines. 5.1 Qualitative Results In the first experiment, we show some samp le aspects and aspect-specific senti-ments extracted by APSM and ME-APSM by using the TripAdvisor data set. Table 1 lists the top 10 aspect words of three aspects ( staff , room and meal ) discovered by APSM and ME-APSM. For each aspect, top 10 positive and top 10 negative sentiment words are also listed.

We can see from Table 1 that both APSM and ME-APSM can extract coherent aspects and aspect-specific sentiments we ll. For example,  X  X rea kfast X ,  X  X offee X ,  X  X uffet X ,  X  X ruit X  and  X  X ggs X  are all words related to the aspect meal .Theyare correctly identified by APSM and ME-A PSM. In general, ME-APSM performs better than APSM. For the aspect staff , both APSM and ME-APSM discover aspect word  X  X taff X , but APSM fails to di scover more staff-related words like  X  X aiter X  and  X  X aitress X , which are successfully captured by ME-APSM. APSM incorrectly identifies the aspect word  X  X  taff X  as positive sentiment words. ME-APSM can discover more specific negative sentiment words, such as  X  X ude X  and  X  X nfriendly X . 5.2 Aspect-Specific Sentiment Extraction The key advantage of APSM and ME-APSM is their ability to identify polarity-aware sentiment words for different aspects. In this second experiment, we quan-titatively evaluate the quality of positive and negative sentiment words identified by our models. The m etric precision at n ( P @ n ) is used for evaluation. We use the manually annotated aspect-specific sentiment gold standard from [18]. Since there is no aspect-specific sentiment gold standard for the product data set, we only use the hotel data set.

We choose ME-LDA [10] as the compared method. ME-LDA can also extract aspects and sentiments simultaneously . However, it does not directly separate positive and negative sentiment words. Thus, we apply the following postprocess-ing process for ME-LDA. Given the ranke d sentiment words for each aspect, we obtain the positive word list by removing negative words; we obtain the negative word list by removing positive words.

Table 2 gives P @ n values for ME-LDA, APSM and ME-APSM. Due to space limit, we only show the results on three aspects ( staff , room and meal ). It can be seen that APSM and ME-APSM give better results than ME-LDA. ME-APSM further outperforms APSM, which suggests the effectiveness of the MaxEnt com-ponent.
 5.3 Sentiment Classification In this section, we present the results o f sentiment classification. We compare the performance of our models with ASU M [14], lexicon-based method and su-pervised method [19]. The lexicon-base d method classifies each review according to the number of positive and negative words contained in the review.
The experimental results are shown in Table 3. The performance of unified as-pect and sentiment models (ASUM, DS-LDA, APSM and ME-APSM) are better than lexicon based method on both data sets. This is because sentiment polar-ities are dependent on aspects. The lexicon based method can not capture the aspect information of the sentiment words. ASUM and our models jointly model aspect and sentiment, which can improve the sentiment classification accuracy.
APSM and ME-APSM consistently outperform ASUM. ASUM can not sep-arate aspects and sentiments. This suggests that separating aspects and senti-ments not only improve the aspect extraction performance, but also improve sentiment classification accuracy.
 To study the effect of aspect and sentiment seeds on sentiment classification. We choose three aspect seeds for three a spects. For each aspect, we choose three positive seeds and three negative seeds. We indicate the models with aspect and sentiment seeds as APSM+ and ME-APSM+. It can be seen from Table 3 that APSM+ performs better than APSM and ME-APSM+ performs better than ME-APSM. The performace of ME-APSM+ is comparable to supervised method in [19]. Note that the supervised method needs labeled training data while ME-APSM+ only needs several asp ect and sentiment seeds. This suggests that incorporating aspect and sentiment seeds can improve sentiment classifica-tion performance.

We also analyze the influence of the number of aspects T .Theexperimental results are shown in Fig. 3. We can see from Fig. 3 that as the number of aspects increase, the sentiment classification per formance increases. This trend is more evident on the product data set.
 In this paper, we focus on the problem of simultaneously aspect and sentiment extraction and sentiment classification of online reviews. We proposed two unified aspect and sentiment models (APSM and ME-APSM) to address the problem. Our models can not only extract aspects a nd polarity-aware sentiments for each aspect, but also be applied to the sentiment classification task. We compared our models against existing approaches using three different experiments. The experiments give promising results.

In APSM and ME-APSM, how to improve the sentiment classification per-formance still needs more work. In the future, we also plan to apply our models to more sentiment analysis tasks, such a s aspect-level sentiment classification. Acknowledgments. This research is supported by the National High Technol-ogy Research and Development Program of China (Grant No. 2012AA011002, 2011AA010706).

