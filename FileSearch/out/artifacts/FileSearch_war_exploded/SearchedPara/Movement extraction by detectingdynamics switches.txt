 Motion capture systems have become widespread in many application areas such as robotics [18], games [1], etc. These systems are used for extracting the movement templates characterizing basic actions contained in their recordings. In physical therapy and sports sciences, these templates are ity, movie generation or computer games, they become the basic elements for composing complex actions.
 In order to obtain the movement templates, boundaries between actions need to be detected. Further-more, fundamental similarities and differences in the dynamics underlying different actions need to be captured. For example, in a recording from a game of table tennis, observations corresponding to diverse types of underlying movements (such as in the case of a forehand and a backhand), or not (such as in the case of two forehands that differ only in speed).
 To date, most approaches addressed the problem by using considerable manual interaction [16]; an important advancement would be to develop an automatic method that requires little human inter-vention. In this paper, we present a probabilistic model in which actions are assumed to arise from noisy transformations of a small set of hidden trajectories, each representing a different movement boundaries are explicitly modeled through a set of discrete random variables. Segmentation is ob-underlying movement template. To guide segmentation, we impose constraints on the minimum and maximum duration that each action can have. Figure 1: (a) The hidden dynamics shown on the top layer are assumed to generate the time-series at the bottom. (b) Belief network representation of the proposed segmentation model. Rectangular We apply the model to a human game of table tennis recorded with a Barrett WAM used as a haptic input device, and show that we can obtain a meaningful segmentation of the time-series. In the proposed segmentation approach, the observations originate from a set of continuous-valued hidden trajectories, each representing a different movement template. Specifically, we assume that the observed time-series consists of a concatenation of segments (basic actions), each generated generated from the three underlying hidden trajectories on the upper graph. Time re-scaling happens of length 75, 68 and 94 respectively.
 The observed time-series and the S hidden trajectories are represented by the continuous random used to infer which movement template generated the observations at each time-step, to detect ac-tion boundaries, and to define hard constraints on the minimum and maximum duration of each observed action. The second set is used to model time re-scaling from the hidden trajectories to the observations. We assume that the joint distribution of these variables factorizes as follows These independence relations are graphically represented by the belief network of Figure 1 (b). explicit regime-duration distribution (ERDMs) [4]. The variable s t  X  { 1 ,...,S } indicates which the time interval spanned by the observations forming the current action, and takes a value between d dynamics-switching distribution, and  X  is a vector defining the action-duration distribution. The variable z t indicates which of the M elements in the hidden trajectory generated the observa-ensures that subsequent observations are generated by subsequent elements of the hidden trajectory accounts for the d t  X  c t and c t  X  1 observations preceding and following v t in the action. The hidden trajectories follow independent linear Markovian dynamics with Gaussian noise, that is Finally, the observations are generated from a linear transformation of the hidden variables with Gaussian noise where the term  X  d t ,t + c t  X  1 is common to all obser-vations belonging to the same action and allows for spatial translation.
 The generative process underlying the model is de-scribed in detail in 4 Table 1.
 The set  X  of unknown model parameters is given by After learning  X  , we can sample a segmentation from p (  X  1: T | v 1: T ) or compute the most likely Relation to previous models. From a modeling point of view, the presented method builds on previous approaches that consider the observed time-series as time-warped transformations of one or several continuous-valued hidden trajectories. In [11], the authors introduced a model in which different time-series are assumed to be generated by a single continuous-valued latent trace, with spatial and time re-scaling. This model was used to align speech sequences. In [6], a modified from demonstrations. In [12] and [14], the authors considered the case in which each time-series is generated by one of a set of different hidden trajectories. None of these models can deal with the situation in which possibly different dynamics underlie different segments of the same time-series. From an application point of view, previous segmentation systems for extracting basic movements employed considerable human intervention [16]. On the other hand, automatic probabilistic methods for modeling movement templates assumed that the time-series data was pre-segmented into basic movements [5, 17]. The interaction between the continuous and discrete hidden variables renders the computation of the we present and analyze three different approximation methods for dealing with this problem. In the q , and the optimal q and  X  are found by maximizing a tractable lower bound on the log-likelihood using an Expectation-Maximization (EM) approach. In the second (maximum a posteriori) method, EM approach. In the third (Gibbs sampling) method, we use stochastic EM [3] with Gibbs sampling. 3.1 Variational Method In the variational approximation, we introduce a distribution q in which the problematic dependence between the hidden dynamics and the segmentation and time-warping variables is relaxed, that is 6 From the Kullback-Leibler divergence between this distribution and the original posterior distribu-tion we obtain a tractable lower bound on the log-likelihood log p ( v 1: T |  X ) , given by variational EM algorithm in which B ( q,  X ) is iteratively maximized with respect to q and the model parameters  X  until convergence 7 .
 Maximization with respect to q leads to the following updates Before describing how to perform inference on these distributions, we observe that all quantities posteriors for which the count variables take value 1 are required 8 .
 of the following linear gaussian state-space model (LGSSM) h m = F where  X  v m  X  1 /a Therefore, inference on q ( h 1: S 1: M ) can be accomplished with LGSSM smoothing routines [7]. bution of an ERDM using separate duration and count variables [4]. Therefore, we can employ  X  Since we have imposed the constraints c 0 = 1 ,c T = 1 , we need to replace terms such as p ( d t = used in hidden Markov models (HMMs).
 Sampling a segmentation. A segmentation can be sampled by using the factorization Suppose that, at time t , c t = 1 and we have sampled dynamics type s t = i and duration d t = k . 3.2 Maximum a Posteriori (MAP) Method Instead of approximating the posterior distribution of all hidden variables, we can approximate only with respect to h 1: S 1: M and  X  using an EM algorithm. 3.3 Gibbs Sampling Method  X  z by iterative drawing from the tractable conditionals Table 2: Segmentations given by the variational, MAP and Gibbs sampling methods on 5 artificial time-series.
 and then use a HMM forward-filtering backward-sampling method for sampling from ing the forward-filtering backward-sampling procedure described in [8]. 3.4 Comparison of the Approximation Methods In this section, we compare the performance of the approximation methods presented above on 5 artificially generated time-series. Each time-series (with V=2 or V=3) contains repeated occurrences In the second row of Table 2, we give the correct segmentation for each time-series. Each number underlying the actions. In the rows below, we give the segmentations obtained by each approxima-tion method with 4 different initial random conditions (with minimum and maximum action duration between 5 and 30).
 From the results, we can deduce that Gibbs sampling performs considerably worse than the deter-ministic approaches. Between the variational and MAP methods, the latter is preferable and gives a good solution in most cases. The poor performance of Gibbs sampling can be explained by the continuous hidden variables are sampled given a single set of segmentation and time-warping vari-ables (unlike update (1) in which we average over segmentation and time-warping variables), which may result in poor mixing. The inferior performance of the variational method in comparison to the MAP method would seem to suggest that the posterior covariances of the continuous hidden variables cannot accurately be estimated. from table tennis recordings using a robot arm moved by a human. The generic goal is to extract movement templates to be used for robot imitation learning [2, 9]. Here, kinesthetic teach-in can be advantageous in order to avoid the correspondence problem.
 and replaying movements. We recorded a game of table tennis where a human moved the robot arm making the typical moves occurring in this specific setup. These naturally include forehands, going into an awaiting posture for a forehand, backhands, and going into an awaiting posture for a backhand. They also include smashes, however, due to the inertia of the robot, they are hard to perform and only occur using the forehand. adduction-abduction and humerus rotation) of a robot arm when used by a human as a haptic in-put device playing table tennis. The upper graph shows the joint positions while the lower one numbers the underlying movement templates. This sequence includes moves to the right awaiting posture (1), moves to the left awaiting posture (2), forehands (3, 5), two incomplete moves towards the awaiting posture merged with a backhand (4), moves to the left awaiting posture with humerus rotation (6) and backhands (7).
 The recorded time-series contains the joint positions and velocities of all seven degrees of freedom (DoF) of an anthropomorphic arm. However, only the shoulder and upper arm DoF, which are the most sig-nificant in such movements, were considered for the analysis. The 1.5 minutes long recording was sub-sampled at 5 samples per seconds. The minimum and maximum durations d min and d max were set to 4 and 15 respectively, as prior knowledge about ta-ble tennis would suggest that basic-action durations are within this range. We also imposed the con-straint that nearly complete movements are observed (  X  = 2 , = M  X  1 ). The length of the hidden dy-namics M was set to d max , the variable w max was set to 10 4 , and the number of movement templates S was set to 8, as this should be a reasonable upper bound on the number of different underlying move-ments. Given the results obtained in the previous section, we used the MAP approximation method.
 We assumed no prior knowledge on the dynamics of the hidden trajectories. However, in a real ap-plication of the model we could simplify the problem by incorporating knowledge about previously identified movement templates.
 As shown in Figure 3, the model segments the time-series into 59 basic movements of forehands (numbers 3, 5), backhands (7), and going into a right (1) and left (2, 6) awaiting posture. In some cases, a more fluid game results in incomplete moves towards an awaiting posture and hence into a composite movement that can no longer be segmented (4). Also, there appear to be two types of moving back to the left awaiting posture: one which needs untwisting of the humerus rotation degree of freedom (6), and another which purely employs shoulder degrees of freedom (2). The action boundaries estimated by the model are in strong agreement with manual visual segmen-tation, with the exception of movements 4 that should be segmented into two separate movements. At the web-page http://silviac.yolasite.com we provide a visual interpretation of the segmentation from which the model accuracy can be appreciated. In this paper we have introduced a probabilistic model for detecting repeated occurrences of ba-games, etc., for automatic extraction of the movement templates contained in a recording. We have presented an evaluation on table tennis movements that we have recorded using a robot arm as hap-tic input device, showing that the model is able to accurately segment the time-series into basic movements that could be used for robot imitation learning.
 Constraints on z 1: T z  X  X  ,...,M } . Suppose that z  X  = m for  X   X  X  1 ,...,t  X  1 } . Then it must be Therefore, we need to modify the original priors  X   X , X  with time-dependent priors with zero values outside the appropriate range.
 [1] R. Boulic, B. Ulicny, and D. Thalmann. Versatile walk engine. Journal of Game Development , [2] S. Calinon, F. Guenter, and A. Billard. On learning, representing and generalizing a task in a [3] G. Celeux and J. Diebolt. The SEM algorithm: A probabilistic teacher algorithm derived from [4] S. Chiappa. Hidden Markov switching models with explicit regime-duration distribution. Un-[5] S. Chiappa, J. Kober, and J. Peters. Using Bayesian dynamical systems for motion template [6] A. Coates, P. Abbeel, and A. Y. Ng. Learning for control from multiple demonstrations. In [7] J. Durbin and S. J. Koopman. Time Series Analysis by State Space Methods . Oxford Univ. [8] S. Fr  X  uhwirth-Schnatter. Data augmentation and dynamic linear models. Journal of Time-Series [10] U. Kersting, P. McAlpine, B. Rosenhahn, H. Seidel, and R. Klette. Marker-less human motion [11] J. Listgarten, R. M. Neal, S. T. Roweis, and A. Emili. Multiple alignment of continuous time [14] W. Pan and L. Torresani. Unsupervised hierarchical modeling of locomotion styles. In Pro-[15] M. Peinado, D. Maupu, D. Raunhardt, D. Meziat, D. Thalmann, and R. Boulic. Full-body [16] W. Takano, K. Yamane, and Y. Nakamura. Capture database through symbolization, recogni-[17] B. Williams, M. Toussaint, and A. Storkey. Modelling motion primitives and their timing in [18] K. Yamane and J. K. Hodgins. Simultaneous tracking and balancing of humanoid robots for
