 Image tagging is a growing application on social media web-sites, however, the performance of many auto-tagging meth-ods are often poor. Recent work has exploited an image X  X  context (e.g. time and location) in the tag recommendation process, where tags which co-occur highly within a given time interval or geographical area are promoted. These models, however, fail to address how and when different im-age contexts can be combined . In this paper, we propose a weighted tag recommendation model, building on an exist-ing state-of-the-art, which varies the importance of time and location in the recommendation process, based on a given set of input tags. By retrieving more temporally and geo-graphically relevant tags, we achieve statistically significant improvements to recommendation accuracy when testing on 519k images collected from Flickr. The result of this paper is an important step towards more effective image annotation and retrieval systems.
 Categories and Subject Descriptors: H.3.1 Informa-tion Storage and Retrieval -Content Analysis and Indexing ; I.2.10 AI -Vision and Scene Understanding General Terms: Performance, Experimentation Keywords: Photo Tag Recommendation, Temporal, Ge-olocation
With the amount of multimedia data rapidly increasing, it becomes important to organize this content effectively. Pho-tographs uploaded to image sharing websites such as Flickr often contain few or no tags, making effective retrieval diffi-cult. Photo tag recommendation has offered one such solu-tion where new, additional tags are offered based on those already assigned to an image. Much research has been taken  X  out in this area where tag recommendation models have ex-ploited the co-occurrence of tags [7], user tendencies [2] and the image context [8, 6] in the recommendation process. To be able to facilitate efficient multimedia retrieval, in this pa-per we propose to annotate these images with keywords 2 by exploiting its context.

The time and location an image is taken in, has been seen to be a reliable source of evidence for tag recommendation, achieving significant improvements over a baseline which ig-nores the image context [8, 6]. These works, however, fail to combine the time and location contexts of images, as well as capture the varying levels of association different key-words have with different temporal windows (e.g. the time of day) and geographical areas (e.g. continents). For ex-ample, Figure 1 demonstrates this by showing four tags, sunrise , sunset , autumn and leaves . As can be seen, sun-rise/sunset have strong, recurring hourly trends, whereas on the contrary they have noisy, monthly temporal distri-butions. The opposite effect is observed on the tags autumn and leaves . Therefore, in this paper, we consider a tag X  X  as-sociation with the different image contexts, and their com-bination . For time intervals we consider the time of day, the season and the day of the week , and for geographical areas we consider the continent 3 an image is taken in, in our tag recommendation process.

The rest of this paper is organised as follows. In Section 2, we present an overview of work in image tag recommenda-tion. Section 3 describes how we exploit an image X  X  context in the tag recommendation process. Section 4 details our evaluation procedure, the results of which are detailed in Section 5. Finally, we conclude in Section 6.
The automatic process of annotating images with tags takes two forms: automatic image annotation , which looks to identify tags based solely on the image contents, and tag recommendation which takes the tags already present in an image X  X  tag list as a query, in order to offer new tag sug-gestions to the user. Automatic image annotation has been a widely researched area over the last decade with a large number of works attempting to bridge the semantic gap be-tween low level image features and high level concepts [1, 3, 4, 5]. Although these works have made significant progress in achieving this end goal, the semantic gap still largely ex-ists, and annotations are often very unreliable. As a result, social image tagging websites, such as Flickr, depend solely on user tagging to allow for image retrieval.

For tag recommendation , a number of works have been proposed in recent years which attempt to offer new tags to the user, based on the already existing tags in the collection. For example, Sigurbjornsson et al. proposed a tag recom-mendation strategy to support users annotating photos on Flickr [7]. The relationships between tags were exploited to suggest highly co-occurring tags. Garg et al. offered personalised tag recommendations [2] in their Hybrid ap-proach which combined suggestions made from personalised and global tag co-occurrence matrices. These works, how-ever, ignore the time and place an image is taken in the recommendation process.

Zhang et al. looked to go beyond tag co-occurrence by clustering tags based on geolocation and temporal trends [8]. McParlane et al. exploited the daily, monthly and yearly trends of tags are exploited for the task of image tag recom-mendation [6]. These works which consider image context, however, fail to address the way in which these time and location dimensions differ from tag to tag, and their combi-nation.

In this paper we consider the exploitation of time and loca-tion in the recommendation process by offering a weighted model which considers a tag relationship with each of the temporal and geographical dimensions.
In the following sections, we introduce and formulate the problem of image tag recommendation and detail our weighted model which attempts to improve recommendation accuracy by considering an image X  X  context.

Problem Statement Let m denote an image in our collection, containing a number of tags, d , assigned by the user. The overall goal in tag recommendation is therefore to recommend a set of tags p , given a subset of tags, q , from d ( q  X  d ), so that is maximizes p  X  ( d  X  q ).

In order to make tag recommendations, our state-of-the-art (SOTA) model, as defined in Section 3.2, calls upon a tag co-occurrence matrix. In the following section we introduce a number of co-occurrence matrices for this purpose.
If we assume that in total k unique tags represent the images in a collection of size n , the tag co-occurrence matrix would be a square matrix C k where the value of the element c ij represents the number of images that contain both t i and t tags. We define the representation of a tag t i as a vector t = ( c t i 1 ,c t i 2 ,...,c t ik ) where each dimension corresponds t  X  X  co-occurrence value with another tag.

In this work, we compute a number of temporal and ge-ographical matrices. These capture the time and location an image is taken in the co-occurrence measures (i.e. c t by computing the number of images two tags coexist in for a given time interval, or geographical location. Firstly, let us introduce a number of image sets used to create the tag co-occurrence matrices.

Sets Let S x denote a set of images in our training set, where x can be either Global (i.e. a set containing all images in our training set) or Context , where the context can be one of the following values:  X  Time(y) : a subset of images taken within a given time-span. y takes four different values: morning (06:00 to 11:59), afternoon (12:00 to 17:59), evening (18:00 to 23:59) and night (00:00 to 05:59).  X  Day(y) : a subset of images taken on a particular day of the week. y takes two different values: weekday and weekend.  X  Season(y) : a subset of images taken in a particular season. y takes four different values: winter, spring, summer and autumn.  X  Cont(y) : a subset of images taken in a particular conti-nent. y takes seven different values: Africa, Antarctica,
Asia, Europe, North America, Oceania and South Amer-ica.

For example, S Cont ( Africa ) denotes the subset of images taken in Africa. In our approach, we consider the time an image is taken from its exchangeable image file (exif ) data , and the continent from its GPS location .

Matrices The definition of these sets, allows us to con-struct different co-occurrence matrices C x , where x , takes the same values as defined above. Each co-occurrence ma-trix is built using the images corresponding to its set ( S Africa, in which tags t i and t j coexist.

In our baseline approach, our tag recommendation model uses the Global co-occurrence matrix ( C Global ), whereas in our experimental approaches, we take co-occurrence values and C Cont ( y ) ), thus offering temporally and geographically significant suggestions.
Given a co-occurrence matrix C x , a number of existing al-gorithms can be used to generate tag recommendations. We choose to adopt a tf-idf approach proposed in Algorithm 2 in [2] due to its simplicity in implementation and performance in comparison to other tag recommendation baselines. It be-gins by computing a new matrix  X  C x from C x in two stages. Firstly, all diagonal values of C x are set to zero. Secondly, each column of this new matrix is scaled, so that the maxi-mum value in each column is 1. The output from this model (a vector of scores where each element refers to a tag), de-noted as O q , is then computed as: O q = (  X  C x  X  q )  X  idf . We define idf to be the vector of inverse document frequencies , where each element computes the idf score, log( n/n ( t for each tag in the collection, where n ( t j ) is the number of images containing tag t j . q is the binary vector of tags used as a query from the image X  X  tag list. The  X   X   X  is the component-wise product of the output vector from  X  C x  X  q and idf . For multiple tags, the corresponding contributions are added. In our approach, it is the C x matrix which is changed (and combined) between the various co-occurrence matrices defined in Section 3.1.
The main novelty of this paper considers the combina-tion of co-occurrence measures based on the association of tags, with each of the different time and location dimensions. Therefore two combination approaches are introduced:
Option (1) As our first approach we take the average co-occurrence score, from the four contextual co-occurrence matrices (i.e. time, day, season and continent). This model is therefore a non-weighted approach.

Option (2) As a more elaborated approach we consider the relationship between the input tags and the different dimensions using a weighted combination approach. There-fore, the overall weighting for a tag, for each contextual co-occurrence matrix, can be expressed as follows:  X P ( C x | t (1  X   X  ) P ( C x ). In the computation of co-occurrence vectors for a tag t j , we consider (a) the association P ( C of the given input tag, for image m , to each matrix C and (b) the global perceived effectiveness P ( C x ) of each co-occurrence matrix.

P ( C x | t j ,m ) is computed as the likelihood of the tag occur-ring within a given set of images, normalised by the sum of probabilities for the tag existing in all of the contextual sets i.e. P ( C x | t j ,m ) = P ( t j | S x ) / P x  X  Context P ( t j | S x ) is the fraction of images containing t j in S
P ( C x ) is a weighting, computed on a validation set, for each type of contextual co-occurrence matrix. Each weight, is computed as the proportional improvement (using preci-sion at five as a measure) of the given matrix over the base-line ( C Global ). These weights are normalised and summed to 1. In our experiments these weights were computed as C
In our experiments, in order to select  X  we tested on our validation set, optimising for precision at five. We varied  X  between [0 , 1] with a step of 0 . 1. Best results were achieved when  X  = 0 . 2, showing that weighting the most effective co-occurrence dimensions higher is most important.
In this section, we describe the experimental setup that supports the evaluation of our proposed framework. In par-ticular, our experiments aim to answer two main research questions: (i) can the association between different tags and time and location dimensions be exploited to better model the use of time and place in photo tag recommendation? (ii) can image meta-data, such as time and location, be combined to improve tag recommendation accuracy?
In the following, we detail the training and test collections, the parameter tuning and the metrics used in our evaluation.
Data Collection For our experiments we collect an image dataset from Flickr 4 consisting of 2M images. The dataset was collected by querying Flickr for 2000 popular nouns extracted from WordNet (categorised as animal, ar-tifact, body, food, plant, substance ). The top 2000 images (containing GPS co-ordinates) from the results page, for each search were then considered for use in our collection.
Pre-processing A number of pre-processing stages were then taken out on the dataset to make it useful for tag rec-ommendation. Due to the large amount of noise present in online image collections [7], we first had to remove a num-ber of tags deemed irrelevant for tag recommendation. We therefore manually removed (using three assessors) those tags which fell into the following categories: camera meta data (e.g. d60 ), Flickr awards (e.g. excellentphotogra-pheraward ) and Flickr groups (e.g. 5photosaday ), from the top 1000 most frequently occurring keywords. Additionally, those tags which were used by less than 20 users were also removed. This approach has been used by previous work [6].
Training and Test Set After this pre-processing stage, there existed 517k images in the training set , uploaded by 77k users, using 20k tags. Each image contained on average 15.4 tags and over 99% of the images were taken between January 1999 and October 2012. The tags within these im-ages were used to build the various co-occurrence matrices as described in Section 3.1.

We created two further collections (external from the train-ing set), the first of which was used for parameter tuning , and the other for performance testing . These collections were col-lected using the same procedure as described in the previous section and comprised of 1000 images each. In each of these, the user tags were used as the ground truth .

Evaluation Metrics To evaluate our methods, we use four standard metrics, all of which are commonly used and are adopted by previous work in image tag recommendation [2]. We evaluate performance for a recommended tag list by comparing those suggested tags, with those already provided by the user. The metrics are as follows: (i) Precision at One (P@1) : The percentage of runs where the top tag is relevant (equal to S@1). (ii) Precision at Five (P@5) : The percentage of relevant tags amongst the top five, averaged over all runs. (iii) Success at Five (S@5) : The percentage of runs, where there exists at least one relevant tag amongst the top five returned. (iv) Mean Reciprocal Rank (MRR) : Computed as 1 /r where r is the rank of the first relevant tag returned, averaged over all runs.

Systems We denote R x a system which takes co occur-rence measures from a single matrix, where x denotes the different types of co-occurrence matrices defined in Section 3.1. For example, R Cont ( y ) , is a system where co-occurrence values are taken from C Cont ( y ) , where y , is the continent, the given image is taken in. R Global is our baseline. We intro-take co-occurrence values as a combination of the four con-textual matrices. These approaches compute these values using the two combinations options described in Section 3.3 e.g. R Option (1) , is the system where co-occurrence values are combined using the non-weighted method i.e. Option 1 .
Evaluation Procedure We selected N random tags (with N = [1 , 2 , 3]) from an image X  X  ground truth which were used to query the recommendation model. The top five tags were retrieved and used as recommendations. This evalua-tion procedure has been used by previous work [2]. Finally, we compute paired t-test statistical significance tests com-paring our the experimental approaches against our baseline ( R
As can be seen from Table 1, exploiting time and location in the photo tag recommendation process can have dramatic increase in effectiveness, where up to 21% (for P@5) statis-tically significant improvements are achieved over our base-line. An image X  X  location gives larger increases to recommen-dation accuracy when compared to the temporal dimensions. This is possibly due to the large number of location type tags used by users on Flickr [7]; this is an interesting feature which needs further investigation. For the temporal dimen-sions, the season is the most effective dimension, achieving larger increases to accuracy than the day and time based approaches. Encouragingly, all of the temporal and location based dimensions increase recommendation accuracy, across different metrics and N (except for R T ime &amp; R Day N = 1).

The findings of our results show that a combination of temporal and geographical dimensions are complimentary in the photo tag recommendation process. Of our two com-bined approaches, using the weighted model ( R Option (2) gives better results than simply averaging the co-occurrence measures. This therefore supports our hypothesis that by combining different evidences, given the associations between the input tags and each of the contextual evidences, recom-mendation accuracy improves.

Finally, recommendation accuracy increases as the num-ber of inputs increases (the same trend exists for N = 2). Further, our combined approaches, are able to maintain the same level of performance over our baseline as N increases.
To further investigate the effectiveness of our approach, we computed the top tags for each of the contextual approaches by computing P ( t | S x )  X  P ( t | S Global ) (where x 6 = Global ), for each dimension. As can be seen in Table 2, there exists a strong temporal and geographical link between tags and each subset; the tags are highly relevant each of the given temporal and geographical dimensions.
In this paper we exploited the effect of the contextual aspects of an image in the tag photo recommendation pro-cess. In particular, we constructed several contextual co-occurrence matrices built only on images taken within three time intervals (i.e. the time of day, the day of the week, the season) and one geographical area (i.e. continent). By offering temporally and geographically significant tag recom-mendations, statistically significant improvements of up to 21% (for P@5), in the best case, were achieved when testing on a Flickr image collection.

Our results demonstrated that, firstly, the exploitation of time and place can improve tag recommendation accuracy. Second of all, combing these evidences can further improve the accuracy of the model if the association between tags and each of the dimensions is taken into account.

This work opens up a number of interesting questions, such as why is the continent an image is taken in considered a more reliable source of evidence than the time it is taken? Future work will look to answer this question as well as the exploration of a number of new image dimensions and more elaborate methods of contextual combination.
