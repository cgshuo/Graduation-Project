
Department of Computer Science, Brigham Young University, Provo, UT, USA Department of Health Science, Brigham Young University, Provo, UT, USA 1. Introduction
Surveys and questionnaires are ubiquitous instruments of systematic data collection and empirical re-search in the social, political and health sciences. Many questionnaires are expressly designed to test hypotheses. That is, researchers begin with a specific hypothesis, or small set of hypotheses, and build a questionnaire to query respondents in a direct and targeted way to gather relevant data for the pur-pose of confirming (or refuting) said hypotheses. While this use of questionnaires for hypothesis testing is clearly a valuable scientific activity, it is expert-driven and may miss other valuable information in the response data that is not obvious, and of which the researchers may be unaware [8]. This is par-ticularly true of larger, more general questionnaires, such as the Health Information National Trends Survey (HINTS), 1 the National Health an d Nutrition Examination Survey (NHANES), 2 the Behavioral Risk Factor Surveillance System (BRFSS) 3 and many others, which are administered over time to track population-based statistics and trends. As a result, researchers have become increasingly interested in data-driven approaches, where by exploring and mining the data algorithmically, they may be led to discover potentially interesting hypotheses that would otherwise most likely go unnoticed. One commonly used technique to generate hypotheses from data is association rule mining [1,2]. Association rule mining originated in the area of market-basket analysis, where the data of interest consists of purchasing transactions made up of store items, and association rules capture dependencies between the presence of certain items in a transaction. For example,  X  X eople who buy bread and butter also tend to buy honey. X  One can naturally generalize this idea to other areas. Assuming that the data of interest is represented by records defined over a set of attributes, association rules can now be used to capture dependencies among attribute-value pairs of the form: if attributes a 1 ,...,a k have values v ,...,v k in a record, then attribute a t has value v t , with some degree of confidence. In the context of questionnaire mining, the attributes are question items and the values are the possible responses, so that association rules establish dependencies among question-answer pairs. For example,  X  X espondents who said they ate out a lot, exercised little and had an irregular sleep pattern also said they often lacked energy during the day. X  Association rule mining algorithms will generate rules of this form based on user-specified parameters generally involving at least a minimum support threshold (i.e., the fraction of records in the data that contain the rule X  X  question-answer pairs). All sets of question-answer pairs whose frequency is higher than the minimum support are candidates for rule generation. The final set of rules is then ranked based on some criterion such as confidence or lift.

As stated above, one of the advantages of using association rule mining is that dependencies may be found that were not explicitly planned for by the questionnaire designers, and thus there is increased potential for knowledge discovery. Interestingly, however, there is a natural tension between expert-driven questionnaire design and data-driven association rule mining. Indeed, one of the advantages of using expertise in the crafting of questionnaires is that much can be done in the design to:  X  Reduce the risk of confounding effects through careful wording (e.g.,  X  X n a regular work week, how  X  Build redundancy to increase accuracy by, for example, asking the same question a few different  X  Include several related questions to seek information about the same issue at varying levels of details
Unfortunately, while such practices inject a number of what are, in one way, desirable built-in de-pendencies among the question-answer pairs, they also, in another way, become a hindrance to the association rule mining algorithm, since they will be among the dependencies the algorithm  X  X iscovers. X  Subjectively, the more interesting association rules are those that highlight unexpected relationships. For example, an association rule stating that most individuals who are employed tend to have good medical insurance coverage is less interesting than one stating that most individuals who have rich and active so-cial networks tend to find it easier to maintain good health habits. The former rule is rather obvious while the latter is less so. Similarly, bringing out known dependencies is clearly of no value to researchers and only a waste of computational resources. Yet, because these dependencies are very strong, the corre-sponding rules have accordingly high support, and will thus be generated and ranked high in the list of results. Consequently, other, potentially more interesting rules, will be ranked lower on the list and become less likely to be found by researchers.

Hence, when applied to questionnaire data, association rule mining is likely, due to the nature of that data, to bring out a large number of association rules that are very accurate, but not actionable, surprising, or particularly useful. What is needed is an efficient way of either removing such rules from the results list or avoiding their generation in the first place. One may argue that researchers and practitioners could take some measure, most likely in data pre-processing, to avoid discovering trivial association rules, so that an extension to association rule mining is unnecessary. However, we contend that questionnaire designers usually are not planning on using association rule mining, but rather focus on traditional statistical methods of hypothesis testing based on their own observations. Hence, they would not have put in place any pre-processing to avoid the generation of  X  X ad X  rules. Furthermore, many questionnaires are rather generic, surveying respondents over a wide range of health-related issues to support various analyses, hypothesis generation, and longitudinal studies. Thus, given the potential of association rule mining in augmenting user expertise for hypothesis generation from questionnaire data, an automatic means of avoiding poor rules, as suggested here, seems desirable.

In this paper, we present a simple, yet effective, approach at identifying and pre-pruning association rules that involve built-in dependencies, using a clustering technique on related questions. In addition to increasing the efficiency of the algorithm, the ranks of association rules more likely to be interesting to subject matter experts are improved. The benefit of this approach is that association rule mining can become a more practical tool to be used by social scientists in questionnaire analysis. We demonstrate the success of this method on two real-world, public health questionnaires. 2. Related work
It has long been known that association rule mining algorithms have a tendency to 1) produce very large sets of rules, and 2) generate trivial or uninteresting rules. The solutions proposed tend to revolve around a few general approaches. In the first approach, the algorithm is allowed to generate many rules, but these are then filtered to alleviate problem 2. These filters generally use some measure of interest-ingness, such as lift, conviction, added value and Loevinger to rank rules [12], or they cluster rules to produce profiles that serve as summaries for rule subsets [47], or they apply summarization techniques to remove rule redundancy by considering the deviation between observed and expected frequencies [26]. In another approach, the algorithm attempts to reduce the size of the rule set (problem 1) through tech-niques such as hashing and pruning [14,34], using genetic algorithms to identify a small set of high quality rules [11], transaction clustering where within-cluster transactions share a common large set of items followed by rule mining within each cluster [22], and focusing on frequent closed itemsets to remove redundant rules [49,50].

Solutions to problem 1 also address part of problem 2, but only as it pertains to redundant rules. Re-dundancy is only one aspect, however. There are many other situations where rules may be uninteresting. The third approach, then, tries to address both problems 1 and 2 via pre-pruning techniques, as we do. Closely related to our specific approach is the work of Plasse et al. [38], who focus the clustering on attributes (questions, in our context) rather than on transactions. Their motivation, and hence approach, are however very different from ours. Indeed, they consider the situation where there is a very large number of attributes so that interesting associations among rare attributes may be lost in the volume of generated rules. Hence, they first cluster attributes, as we do, but then compute association rules within each cluster. After isolating a cluster of highly correlated attributes that produce many complex rules, their approach is able to generate rules in other clusters that would otherwise be  X  X nvisible. X  By contrast, we assume the existence of built-in dependencies among questions, such that within-cluster rules are most likely to be trivial or uninteresting, with the more relevant rules being formed by questions from different clusters.
Another similar approach is that of Shekar and Natarajan, who explicitly exploit the idea that the sub-jective interestingness of association rules is inversely proportional to the relatedness among items [41]. However, our work differs from theirs in several significant ways. First, they focus on the hierarchical structure of transactional data, extending the approach of Srikant and Agrawal [42], whereas we focus on the specific problems that arise in questionnaire responses. Second, their metric for relatedness among items is based on a user-defined taxonomy, whereas our approach utilizes an automated clustering pro-cess, which can potentially model patterns found in the data that are not known to the experts. Finally, and most importantly, ours is a pre-pruning method, where relatedness is exploited in a pre-processing step rather than following rule generation, which results in computational savings.

Also relevant to our work is that in [19,27,43] where the system uses either statistical measures or background knowledge specified in a Bayesian network to remove rules by determining the amount of deviation between observed frequencies and expected ones, and retaining rules only when such deviation is significant. Similarly, but focused on itemsets rather than rule sets, Webb [45,46] has shown that statistical filtering can be used to compare an itemset to its subsets, eliminating those itemsets that are only valuable because they contain other core itemsets. Our work differs in that it pre-prunes the itemsets before they are generated, not requiring ex post facto statistical tests. And, perhaps more importantly, because of the questionnaire context, our approach operates at a higher level of abstraction, namely the question level, as opposed to the item, or answer level, enabling pruning that could not be done for all association rule mining problems. 3. Methods
Our approach consists in reducing the size of the association rule list generated for questionnaire data by including a pre-processing step to prune rules that are likely to be obvious or involve implicit dependencies already known to the researchers. This pruning increases the algorithm X  X  efficiency by reducing the size of the search space. In addition, by removing rules involving implicit dependencies, the pruning increases the prevalence of potentially interesting rules among the top ones returned, thus augmenting the precision of the remaining list. As with any pruning approach, this technique may also remove some valuable rules, but the excluding of a few good rules with many bad ones will result in shorter list of overall more actionable rules.

The basic idea is that rules that are likely to involve built-in dependencies, or obvious rules, can be identified by finding unusually strong relationships between questions. For example, a strong relation-ship between the questions  X  X o you use drugs? X  and  X  X id you use drugs last week? X  could indicate a likely dependency, and that rules between them are less likely to be novel or actionable. Hence, our pre-pruning approach is a two part process. First, questions are clustered together based on the strength of the relationships among them. Second, any set of question-answer pairs that would involve answers to questions that belong to a common cluster are pre-pruned, resulting in rules whose components all belong to separate clusters. 3.1. Clustering of questions
In order to cluster questions, a metric must be defined to determine the distance between pairs of questions. We first define a bi-conditional prediction (BCP) measure for two questions, Q 1 and Q 2 ,as follows: value of BCP ( Q 1 ,Q 2 ) is essentially the average accuracy of two decision stumps [15], one predicting Q one question predict the answers to another. Because BCP is a measure computed directly from the data, it does not require any human involvement. The distance between Q 1 and Q 2 is then simply given by:
Equipped with the distance d , we can cluster the set of questions using hierarchical agglomerative clustering (HAC) [17,20]. One of the advantages of HAC is that it does not assume a predetermined number of desired clusters. Rather, it produces a complete sequence of nested clusterings. HAC starts by assigning each question to its own cluster. Then, the two closest clusters are merged into a single new cluster. This pairwise merging process is repeated until a single cluster containing all of the questions is obtained. Although we have a distance defined over questions, HAC also needs a distance over clusters. Several distance measures may be considered, the most common of which are complete linkage, which uses the maximum distance between all pairs of objects across clusters, single linkage, which takes the minimum distance, and average linkage, which computes the average of all inter-cluster distances. We choose complete linkage here as it tends to create more compact, clique-like clusters [18]. As an illustration, the dendrogram resulting from clustering a sample of questions from the Health Information National Trends Survey (HINTS) [31,32] is shown in Figs 1 and 2, with the original variable names replaced by more descriptive text. Figure 1 is provided for visualization of the overall structure of the dendrogram, whereas individual variable names can be read in a magnified portion (rectangular area) shown in Fig. 2. Note the similarity among questions clustered tightly together, such as  X  X eard of National Cancer Institute X  and  X  X eard of the Centers for Disease Control, X  as well as a perhaps less obvious association between  X  X ny exercise in past month X  and  X  X xtent obesity caused by overeating. X 
As stated above, the dendrograms produced by HAC contain a sequence of nested clusterings. While this provides flexibility over the rigid, a pri ori, choices of partit ional methods (e.g., k -means), it also begs the question of which of the several possible clusterings is preferable over the others. The choice of a specific clustering is typically made by selecting a level at which to cut through the dendrogram, and defining the clusters as the groups of questions hanging from the subtrees whose top branches intersect with the horizontal line corresponding to the chosen level.

The selection of a cut point directly impacts the actual clustering, and thus the ensuing pre-pruning task. If the cut point is too low (i.e., just above the leaf nodes), then each cluster contains a single question, and our approach offers no advantage over the standard association rule mining approach. Conversely, if the cut point is too high (i.e., just above its root), then all questions belong to a single cluster, and our approach is useless since it pre-prunes all rules and returns nothing.

Designing a general method for finding an appropriate level at which to cut a dendrogram remains largely an open problem. Typical solutions include automatic approaches such as cutting where the gap between two successive merges is largest [28], as well as expert-driven approaches where domain knowledge may be used to fine-tune and discriminate among possible clusterings.

There is also added value to the automatic clustering we propose in that it may highlight dependencies that were not built-in. For example, one often designs a questionnaire along themes, so that, for example, there may be a theme about the use of media, with questions about what type of media (e.g., Internet, mobile phone, TV, etc.) one uses to find information, and another theme about level of trust associated with various sources of information, with questions about whether the respondent trusts certain sources (e.g., friends, doctors, Internet, etc.). In this case, clustering might reveal a strong dependency between trusting the Internet and using the Internet. While they are separate in the questionnaire and would lead to rules in a standard association rule mining approach, rules of that nature are actually not very insightful and would be pruned here. 3.2. Pre-pruning during large itemset generation
Association rule mining algorithms generally work in two phases. In the first phase, large itemsets (i.e., sets of items, here question-answer pairs, whose support exceeds the user-specified minimum support threshold) are generated, capitalizing on the downward closure property of support, namely, that the support of an itemset is always smaller than that of any of its subsets. In the second phase, all rules consisting of permutations of items in an itemset are considered, and those satisfying the user-specified rule quality condition, often a mini mum confidence level, are kept.

Our approach acts as a pre-pruning mechanism that modifies the large itemset generation phase as follows. Whenever the large itemset generation method considers adding an item i to an existing itemset S , it first checks to see whether the question associated with i is in the same cluster as any of the questions associated with the items currently in S . If the answer is yes, then the itemset S  X  i is not generated. In other words, when generating candidate itemsets, only those whose items are associated with questions from different clusters are considered. 5
For example, consider the clustering of questions {{ Q 1 ,Q 2 ,Q 3 } , { Q 4 ,Q 5 } , { Q 6 ,Q 7 }} , and assume that the itemset { Q 1 = a 1 ,Q 4 = a 4 } was determined to be a large 2-itemset. During candidate set generation for itemsets of size 3, only items with answers to questions Q 6 or Q 7 will be considered. No items with answers to questions Q 1 through Q 5 will be considered because they would result in a 3-itemset with two items whose associated questions are in the same cluster.

The result of this pre-pruning approach is that no rules will be generated with answers from questions in the same cluster. This means that these answers will not appear together in the premise, the conse-quent, or with one in the premise and the other in the consequent. The motivation for pruning rules in each of these cases is that if two questions are clustered together then by definition the answer to one can be inferred from the answer to the other with some degree of confidence. Thus, at a high level, no value is added by including both answers in the premise or the consequent. More importantly, the case where one is in the premise and the other is in the consequent is the specific case of the true but obvious rule to be removed.

Not only does the proposed pre-pruning increase the relevance of the returned rule list, but it also results in computational savings. First, it significantly reduces the size of the search space, because not only are itemsets at the current level pre-pruned, but also all supersets thereof. Second, not only is the space of candidate itemsets reduced, but all subsequent permutations of rules are also preemptively pruned.

Finally, since the rules generated by the pre-pruning approach are a subset of those generated by the standard approach, every rule in the pruned rule list will also appear in the standard rule list. The benefit of the pruning is that these rules will have higher rank in the rule list, not requiring the researcher to look through as many rules to find them. In addition, because similar rules ar e pruned, the res ulting rule list is more diverse, which is beneficial in generating new hypotheses, due to the nature of having additional distinct ideas presented.

As with any pruning approach, it is possible that some desirable rules could be excluded with the bad ones. Specifically, this pruning process takes advantage of the fact that answers are not completely inde-pendent items as in market-basket analysis, but rather have meaning that allows them to be grouped by question. Thus, by clustering at the question-level, the process generalizes to infer that answers to related questions also have relations. This assumption allows the pruning to take advantage of the questionnaire structure. However, it also has a bias that all answers to related questions are related, when it is possible that one answer might not share in this relationship, and rules involving that specific answer should not be pruned. Despite this bias, if the BCP measure between two questions is relatively high, the likelihood of one specific answer behaving differently than all the others is decreased. 4. Experimental setup
Before we proceed with a description of results, we must decide what association rule mining algo-rithm will serve as the basis for our proposed extension. The Apriori algorithm [2] has probably become the most popular data mining technique for market-basket analysis and several other related areas. 6 One of the important limitations of the Apriori algorithm, however, is that because it focuses on frequent rules, it often overlooks interesting rules that have very high confidence but a low support value. Rules with low support but high confidence are especially pertinent in health questionnaire data, because often infrequent, or low incidence, responses, such as having cancer, are more valuable to researchers than the more frequent responses, such as not having cancer. A variant of the Apriori algorithm, MSApriori [24], seeks to address this issue by allowing different minimum support thresholds to be set for different items in an itemset. In questionnaire data, this means different minimum support thresholds can be established for each answer, thus permitting the relatively lower frequency items to make it into association rules. Of course, one of the difficulties of implementing MSApriori is determining how to set the different min-imum support thresholds. Kiran et al. [21] provide a mechanism to systemically establish the specific thresholds of each item using statistics of the dataset. We use that version of MSApriori for association rule mining here. Note that we did not further extend MSApriori to employ well known pruning methods (e.g., if y s is a specialization of y ,then y s  X  x is excluded if y  X  x has no smaller confidence than the rule), which may favor our approach in the comparison results reported below.
Similarly, we must decide upon a mechanism to evaluate the precision of interesting rules in a set, and hence some notion of interestingness must be defined. One approach is to use objective measures, such as those surveyed by Geng and Hamilton [12], which include the common support, confidence, and lift, as well as other less well-known, metrics. These measures are based on statistical properties of the data, and most can easily be maximized by rules that are accurate but useless. For example, a rule such as  X  X o you use drugs = No X   X   X  X id you use drugs last week = No X  will be rated very highly by almost all statistical measures, yet it is not very useful. Our approach is aimed explicitly at eliminating such rules, subsequently increasing the concentration of rules more likely to be useful to researchers. Hence, in this context, the actual evaluation of interest is a subjective measure such as surprise or actionability. Since such measures cannot be computed from the data only, we rely on subject matter experts in the specific areas of the questionnaires under consideration to rate rules according to their subjective opinion of  X  X nterestingness. X 
For this evaluation process, a subject matter expert was selected for each dataset, and asked to rank each rule for potential  X  X nterestingness X  on a scale of 1 (completely uninteresting) to 10 (highly inter-esting). They were instructed that interesting rules could include those that are actionable, surprising, or confirmation of theory. The rules from the standard MSApriori as well as our modified version were presented together in a single list without identification to remove bias and increase consistency among the ratings. 5. Results and analysis
The following two case studies show the effects of the cluster-based pre-pruning approach with respect to two real-world, public health datasets. For each dataset, we have pre-processed the data, removing questions that were unique identifiers, as well as questions containing only one answer above the least support threshold of MSApriori. 7 For presentation purposes, the question names shown in the tables for each survey are abbreviated from how they were actually presented in the questionnaire. 5.1. Global youth tobacco survey
Our first dataset is taken from the Global Youth Tobacco Survey for the Pan American Health Or-ganization (GYTSPAHO) [33]. Our sp ecific dataset contains answers to 65 questions on the cigarette smoking habits and attitudes o f about 13,000 youth in Mexico.

After clustering the 65 questions, we examined the structure of the dendrogram visually and performed minor experimentation to empirically select a cut point at d =0 . 47 , yielding 44 clusters. We also set empirically the least support threshold for MSApriori to 0.1.

The top 15 rules, sorted by lift, discovered from this dataset by the standard MSApriori algorithm are shown in Table 1, while the top 15 rules, also sorted by lift, discovered by the modified, cluster pruning version of MSApriori are shown in Table 2. As shown in these tables, the rules discovered by the standard MSApriori algorithm have higher lift than those found by the cluster pruning method, because they includes many rules that are very accurate (high confidence and lift) but rather useless (with both the premise and the consequent simply restating that the respondent does not smoke). Many of these rules are pruned by the cluster pruning method in favor of slightly more interesting ones.
The difference between the rank of each rule in the cluster pruning list, compared to where that rule appears in the standard MSApriori list is shown in Fig. 3 where each of the top 25 rules discovered by the cluster pruning method are shown. While all of the rules discovered by the cluster pruning method also appear in the list of standard MSApriori rules, they are significantly lower down that list, requiring a researcher to look much further to find them.

The expert ratings for the top 25 rules for each list are summarized in Table 3. These results show that for the standard MSApriori rules, the expert rated only 8 of the 25 rules higher than a 1, with the highest rule being rated a 3. Conversely, for the cluster pruning version of the algorithm, the expert rated 18 of the 25 rules higher than a 1, including rules rated up to a 6. This clearly shows that while none of the rules were rated as highly interesting, the expert clearly preferred the rules in the cluster pruning list to those from the original algorithm.

In particular, from a domain expert perspective, the following was observed:  X  Given the likelihood for low rates of smoking during early adolescence, much of the tobacco control  X  Beyond measures of susceptibility, Rule 5 from the list produced by the cluster pruning method
Another benefit of the cluster pruning method is the pruning of many similar rules, leaving a shorter list of more diverse rules. One way to measure this diversity is to consider the unique questions rep-resented by the produced rules. Figure 4 shows the total number of unique questions covered by rules generated using our cluster pruning method as compared to the standard MSApriori method. These re-sults demonstrate that the cluster pruning method is able to include more diversity in terms of the number of unique questions covered in the same amount of rules. 5.2. Health information national trends survey
Our second dataset is taken from the Health Information National Trends Survey (HINTS) [31,32], focusing on the 2007 data which has approximately 475 questions for 8,000 respondents. Our specific subset contains 76 questions, including those that have categorical and ordinal responses, and excluding those with numerical or open ended response types, as well as those not asked of all respondents.
After clustering the 76 questions, we again examined the structure of the dendrogram visually and performed minor experimentation to empirically select a cut point at d =0 . 51 , yielding 32 clusters. We also set empirically the least support threshold for MSApriori to 0.15.

The top 15 rules, sorted by lift, discovered from this dataset by the standard MSApriori algorithm are shown in Table 4, while the top 15 rules, also sorted by lift, discovered by the modified, cluster pruning version of MSApriori are shown in Table 5. Again, these results show that many of the rules generated by the standard MSApriori algorithm are very similar to each other and are very accurate but obvious, such as former smokers identifying that they have smoked at least 100 cigarettes in their life. On the other hand, many of the rules generated by the cluster pruning MSApriori version are still rather straightforward, such as people with high income being likely to be employed and use the internet, they are at least not simple redundant restatements of fact.

The difference between the rank of each rule in the cluster pruning list as compared to where that rule appears in the standard MSApriori list is shown in Fig. 5 where each of the top 25 rules discovered by the cluster pruning method are shown. Again, while all of the rules discovered by the cluster pruning method also appear in the list of standard MSApriori rules, they are significantly further down in that list. In particular, the second rule of the cluster pruning algorithm is ranked 147 th by the standard MSApriori.
The expert ratings for the top 25 rules for each list are summarized in Table 6. As with our other dataset, the expert ratings are increased for the cluster pruning method, and while they are not overall as striking, they show one very significant improvement in the presence of rules rated 8 in the top 25 of the cluster pruning list, whereas the maximum rating for rules in the standard MSApriori list is 3.
In particular, from a domain expert perspective, the following was observed:  X  Results from studies outside the United States indicate that knowledge of HPV (Human Papillo- X  In this regard, Rules 12 and 14 are significant because they demonstrate that higher income/educated
Results on diversity are similar to those obtained with our other dataset, as shown in Figure 6. Signif-icantly more diversity is present in the results of the cluster pruning version than in the standard one. 6. Conclusion
Questionnaire data contains many properties that cause difficulties for association rule mining algo-rithms. Among these difficulties are implicitly related questions which often result in the generation of rules that are very accurate but so obvious that they are useless to researchers. To address this problem, we have introduced an enhancement to association rule mining algorithms for questionnaire data that uses clustering to identify highly-related questions to pre-prune itemsets containing questions from the same cluster, which are likely to be less interesting than others.

As demonstrated on two real-world, health-related questionnaires, this cluster pruning approach is su-perior to the standard approach in the context of questionnaire data in two principal ways. First, because the pruning takes place during large itemset generation and maintains the downward closure property, the search space of itemsets and rules is significantly reduced resulting in increased performance. Sec-ond, by pruning out many rules less likely to be interesting, the remaining list contains more diverse rules that are more likely to be actionable and valuable to researchers.

We have focussed here on positive results. It is possible that our method causes the algorithm to overlook potentially interesting rules. Further analysis is necessary to appreciate the extent to which this may be the case, and what the trade-off is with the pruning of clearly unwanted rules. Since BCP is also an empirical measure, there may be room for improvement, for example, with the use of semantic distance functions. Finally, we would like to investigate the use of semi-supervised techniques to infuse our method with background knowledge. For example when certain dependencies are known to exist, either by design or through human observation, the user could label the corresponding questions as must-link constraints as proposed in [44].
 References
