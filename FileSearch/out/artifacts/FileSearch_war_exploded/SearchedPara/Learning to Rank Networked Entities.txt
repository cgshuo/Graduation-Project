 Several algorithms have been proposed to learn to rank en-tities modeled as feature vectors, based on relevance feed-back. However, these algorithms do not model network con-nections or relations between entities. Meanwhile, Pager-ank and variants find the stationary distribution of a rea-sonable but arbitrary Markov walk over a network, but do not learn from relevance feedback. We present a framework for ranking networked entities based on Markov walks with parameterized conductance values associated with the net-work edges. We propose two flavors of conductance learning problems in our framework. In the first setting, relevance feedback comparing node-pairs hints that the user has one or more hidden preferred communities with large edge con-ductance, and the algorithm must discover these communi-ties. We present a constrained maximum entropy network flow formulation whose dual can be solved efficiently using a cutting-plane approach and a quasi-Newton optimizer. In the second setting, edges have types, and relevance feedback hints that each edge type has a potentially different conduc-tance, but this is fixed across the whole network. Our algo-rithm learns the conductances using an approximate Newton method.
 H.3.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Information Search and Retrieval[Retrieval models; Relevance feedback]; I.5.1 [ PATTERN RECOGNITION ]: Models[Statistical] Algorithms, Experimentation, Measurement Pagerank, conductance, network flow, maximum entropy
Consider a set V of entities (such as documents) that can be returned by a search engine in response to queries. Each entity v  X  V may be represented by a feature vector x v  X  d . E.g., if the entities are documents, they can be represented in the vector space model used in Information Retrieval (IR) [21]. In standard IR, given a query vector Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. q  X  d , responses are presented in decreasing order of the dot product q x v .

In fact, any vector w  X  d defines a scoring function w x and thus (in general) a total order over V . A series of papers [14, 16, 1] explore how to learn w , given a partial order  X  involving some of the entities. If u  X  v ,wewant w x u  X  w x v . (Throughout, we will use  X  both as an operator, as in  X  a  X  b , X  and as a set of preferences, as in  X ( a, b ) Also, a  X  b means b a .) We will review some of this work in Section 2.1. None of this family of algorithms models entities as nodes in a graph.

Increasingly, documents are not isolated sequences of words, but are interconnected through a network. This is true not only of the Web, where hyperlinks greatly assist ranking [6, 17], but also of entity-relationship (ER) graphs [5, 3], XML data [12], and Semantic Web networks [2] where nodes rep-resent entities with textual attributes and edges represent diverse relations.

In these networked data models, ranking is often achieved by some generalization of Pagerank [6] or HITS [17]. A Markovian random walk is defined on the graph, and the score of a node is defined as its steady-state visit probability. The random walk, while usually intuitive and reasonable, is arbitrarily designed, in the sense that no preference  X  is au-tomatically incorporated to improve its design. We produce several examples below, and will review the techniques in Sections 2.3 and 2.4.

In standard Pagerank [6], all edges are considered the same. In ObjectRank [3], the Intelligent Surfer [20], and XRank [12], the random walk favors nodes containing query keywords in a fixed, arbitrary manner. In topic-sensitive Pagerank [13], the random walk preferentially moves to nodes (Web pages) on a specified topic. In personalized Pagerank [15] the random walk preferentially moves to pages visited by the user in the past. Only very few projects [8, 24, 10, 19] attempt to learn the parameters of the random walk. Our primary contribution is to bring together the power of Markovian walk-based scoring functions and the flexibility of improving the scoring function using relevance judgments. (We focus on the Pagerank family, but it should be possible to extend our work to some members of the HITS family as well.)
We propose a framework for learning certain edge param-eters of Markovian walks on graphs, given preference orders over nodes. Within this framework, we consider two learn-ing problems that have to estimate conditional and absolute transition probabilities X  X r( v | u ) and Pr( u  X  v ) X  X n each edge ( u, v ) of the graph (see Section 1.2 for details).
The difference between the two settings is that in one, we must estimate the transition probability on each edge separately (Section 3) but in the other, edges are associated with a few types (person wrote book, company located-in city etc.) and each type of edge has a globally fixed (but unknown) transition probability, which our algorithm must discover (Section 4).

We evaluate the proposed algorithms on synthetic data generated by state-of-the-art graph generators, using broad statistics measured from real graphs collected from DBLP ( http://dblp.uni-trier.de/ ) and CiteSeer ( http://citeseer. ist.psu.edu/ ). We show that the algorithms are scalable and that they compute Markovian walk parameters that lead to good prediction of unseen user preferences.
Throughout this paper, our  X  X ull hypothesis X  or  X  X arsi-monious belief X  is that standard Pagerank is the ideal rank-ing mechanism unless  X  provides contrary evidence. Based on  X  , our learners must pick up an  X  X deal X  Markovian walk from a larger hypothesis space. Here we consider two spaces, the first containing the second.
In this setting,  X  is non-empty because the user has one or few favorite communities. Not only is the  X  X deal X  random walk disproportionately likely to transit to nodes in these communities, but the edges within these communities may have large transition probability Pr( v | u ) compared to the rest of the graph. E.g., to a computer vision researcher, papers and citations related to computer vision in DBLP are more significant than other papers and citations, which are mere distractions.

With rare exceptions [24], existing personalization litera-ture has proposed arbitrary biases in the Markov procedure  X  X y force X  [13, 15] and not discovered a modified Markov walk parameters from preference data. In contrast, we pro-pose an efficient and scalable procedure to estimate transi-tions modeled as a network flow p with p uv = Pr( u  X  v ) on each edge ( u, v ) of the graph, such that the total inflows into the nodes satisfy  X  as far as possible.
In the second setting the graph represents entity-relation-ship (ER) connectivity with multiple kinds of relationship edges. Graph-structured databases are becoming a  X  X owest common denominator X  representation not only for XML [12, 2], but also for relational data [5, 3].

Each edge ( u, v ) in an ER graph adheres to a schema, i.e., has an associated type t ( u, v )  X  X  1 ,...,T } , a fixed and typically small set of edge types. E.g., the edge connecting a paper to an author has a type different from a paper-to-paper citation edge, and the  X  X deal X  random walk is likely to transit along edges of different types with different prob-abilities. Our assumption is that  X  is generated because of these differences between the ideal and baseline random walks.

Our algorithm sees the graph G and preferences  X  ,and knows the baseline walk, and has to discover the ideal walk by estimating the relative conductance of each type of edge. In contrast, many systems [12, 3] that use Pagerank-like Markovian walks over typed graphs associate each edge type t with an arbitrarily fixed weight  X  ( t ) (or two weights if the edge is bidirectional) which then determines its conductance.
We review two kinds of prior work: those that we build upon, and those that we enhance or generalize.
Most algorithms that learn to order items model them as feature vectors x  X  d [9, 14, 16]. The quest is for a model vector w  X   X  d so that the score of item x is w x  X  , and items are ranked in decreasing order of this score. A preference i  X  j means we want w to be such that w x i  X  w x j . A max-margin search for w introduces a set of slack variables s  X  ij  X  0 and solves the quadratic optimization Note that if w x j  X  1+ w x i then i  X  j is satisfied, s ij and no penalty is paid. As with support vector classifiers, B is a tuned parameter that trades off the model complexity w w = w 2 against the penalty for violating preferences. Note that no graphical connection is modeled between any x and x j ; they remain independent feature vectors.
Pagerank [6] is a total order on nodes in a graph G = ( V, E ) imposed via a  X  X andom surfer X  model. The random surfer performs a Markovian walk on G , and is at node j with probability p j = i p i p ( j | i ). If we write p ( j |
V | X | V | transition matrix C , the column vector p solves p = Cp , where C is designed as Here I = 1 if boolean condition I is true, and 0 otherwise. V o  X  V is the set of nodes which are not dead-ends, i.e., have at least one out-link. The two design variables are  X  , the probability of walking to a neighbor instead of jumping to a random node; and r =( r j ), the teleport or personaliza-tion vector, which, in ordinary Pagerank, is set uniformly to (1 /n,..., 1 /n ) where n = | V | .With r set thus, p depends only on the structure of G and the value of  X  .
Follow-up work on Pagerank has attempted to modify the teleport vector r to  X  X ersonalize X  the scores heuristically, based on topics [13], words [20, 3], or user preferences on graph nodes [15].
 We will compare our work with that of Tsoi et al. [24]. They propose a quadratic programming (QP) approach to optimizing r given preferences  X  . For simplicity, assume V o = V , i.e., that there are no dead-end nodes in G .(We can add new edges to connect any dead-end node u to itself or all other nodes.) Let A be the node adjacency matrix of G with each row scaled to add up to 1. Given teleport vector r  X  | V | X  1 , the Pagerank vector satisfies Here is the identity matrix. The inverse in (1) always ex-ists, but we will not be concerned with the complications of computing it. We are looking for a r so that elements of the resulting p satisfies inequalities given by  X  . These pref-erences are easily encoded in a matrix  X   X  X  X  1 , 0 , 1 } | X  X  X | V | and written as  X  p  X  0 | X  X  X  1 . Each row of  X  represents one preference u  X  v and has one  X  1(inthe u column) and one 1 (in the v column) and the other columns are zeros. If for r we used the uniform teleport r U , we would get the stan-dard Pagerank vector p U = Mr U .Tsoi et al. propose to minimize p  X  p U 2 while making p satisfy the constraints given by  X . This leads to the  X  X ard constraint X  QP: Here is a vector of 1s of suitable size. (We also need Mr  X  0 but that is guaranteed by r  X  0 .) Surprisingly, Tsoi et al. do not enforce r = 1, i.e., r 1 =1,which is essential to keep r meaningful as a teleport probability vector, and which is generally violated unless enforced. Tsoi et al. note that (even without the r = 1 constraint) (2) may not be feasible, and propose a  X  X oft constraint X  QP in which they replace the one-sided constraint  X  Mr  X  0 with an additional symmetric quadratic penalty in the objective: min r  X  | V | ( Mr  X  Mr U ) ( Mr  X  Mr U )+ Br ( M  X   X  M ) r Here, too, enforcing  X  Mr  X  0 leads to infeasibility and not enforcing it generally leads to violation. Also, it is unclear why  X  Mr &gt; 0 is being penalized. One simple fix is to introduce slack variables and rewrite the optimization as but the resulting QP optimizer turns out to be much slower than Tsoi et al.  X  X  formulation. As we shall see in Section 3.4.3, these are serious limitations from which our proposals do not suffer.
Equation (UnweightedPagerank) can be generalized to in-corporate edge weights. Each edge e has an associated edge type t ( e ) taken from a flat set of edge types T . Any edge e nonexistent edge has weight zero. The modified Pagerank equation is where OutWeight( i )= j  X  ( t ( i, j )). C is a function of the weights  X  , and we are looking for  X  such that the p that solves p = Cp also satisfies  X  . Unlike (1) where M is a constant, we will now face quadratic equality constraints, which poses more difficulty than quadratic objectives with linear constraints.

There have been various attempts to approximate this optimization via gradient descent [8], error backpropagation [10] or simulated annealing [19]. Unfortunately the objective is not well-behaved, and the search procedures are complex and time-consuming. Usually, the search routine has to ef-fectively call Pagerank a large number of times with various weight choices. We propose a simple and efficient way to search for  X  ( t )s approximately in Section 4.
We now give a different formulation that not only captures teleport learning, but generalizes to learning a network flow throughout G , from which node ranks can then be derived naturally. In Pagerank, since p j = i p ij = i p i p ( j | can cast our transition process in terms of flows p ij along each edge ( i, j ), with i,j p ij =1.

A Markov process must also satisfy the flow balance prop-erty: i p iu = j p uj for each node u . Any Pagerank, bi-ased or unbiased, with uniform or non-uniform teleport, sat-isfies the above two properties. But there are other classes of solutions as well. In particular, Tomlins [22] advocates maximizing the entropy H ( p )of { p ij } , i.e.,  X  i,j p while enforcing the above constraints. In this Section we will combine Tomlin X  X  view of Pagerank as a flow system together with Joachims and others X  notions of max-margin scoring/ranking.
Before we get to our formulations, we provide a uniform device to handle teleport. We add a special dummy node d , and directed edges ( v, d )and( d, v ) for all v  X  V . The augmented graph is called G =( V ,E ).

If in the original graph G , u had no outlinks, the entire inflow into u has to pass out through ( u, d ). If u had at least one outlink in G , a fraction 1  X   X  of the net inflow into u passes out through ( u, d ) and the remaining fraction  X  is apportioned into the original outlinks ( u, v )in G .
The outflows from d back to other nodes along ( d, v ) edges are variables included in our optimization; i.e., the search for a good teleport vector is embedded in our formulation. The  X  X ard constraint X  optimization can be cast as follows: such that  X  v  X  V :  X   X  v  X  V o :  X   X p vd +(1  X   X  ) fiers use the notion of a margin to make the system more robust to minor perturbations of training points on either side of the decision boundary, analogous to the margin of  X 1 X  in (RankSVM). An arbitrary margin can be asserted because any margin can be satisfied by suitably scaling the model (  X  in case of (RankSVM)). However, in our case, there is no such scaling capability: all p uv  X  [0 , 1] and in-deed u,v p uv = 1. Therefore, a margin would represent an arbitrary decision and will simply add more parameters to the system. Also, given that we are dealing with extremely small numbers (a typical flow could be O (1 / | E | ), say), too large a choice of the margin may easily lead to infeasibility.  X  X oft margin X  counterpart introduces and penalizes slacks s uv with a penalty function L ( s ) weighted with a magic penalty parameter B . Some common choices for L ( s ) are the L1 penalty u  X  v s uv and the L2 penalty u  X  v s 2 uv cause 0  X  s uv  X  1, L2 downplays violations and so L1 is usu-ally more suitable; therefore we focus on L1. (Preference) changes to mizing the entropy of flow { p uv } seeks to make all edge flows equal. A more meaningful  X  X ull hypothesis X  or  X  X ar-simonious belief X  is that all edges are functionally identical and the teleport follows a uniform distribution X  X his is just (UnweightedPagerank) and gives what we call a  X  X eference X  flow { q uv } .Flow q may already satisfy some preferences. Our objective is to perturb q minimally to get a flow p that (largely) satisfies  X  , and the KL divergence KL( p || q )isa natural measure of perturbation. Based on the above dis-cussion our final primal objective becomes ing  X  in the optimization for two main reasons. First, this would result in quadratic constraints, making the optimiza-tion much more difficult. Also, if  X  were an optimization variable, the hypothesis space would include a degenerate solution: with  X  set to zero, and p dv  X  X  set to satisfy a total order extending  X  , the empirical risk reduces to zero. Even in the soft-constraint version, too large a B may drive us toward this solution, overriding the KL( p || q ) term. Hence we felt that it is better in practice to do a grid search over a small range of  X  X ensible X  values of  X  rather than include  X  in the optimization.
We propose to solve the dual of the above optimization, because the dual has some useful and interesting properties. Instead of O ( | E | ) variables as in the primal problem, it has O ( | V | + | X  X  ) dual variables. Each dual variable turns out to be either unconstrained, or bounded below and above by two constants (a so-called  X  X ox-constrained X  variable). Each it-eration of the dual optimizer is analogous in computational cost to an iteration of Pagerank. And, as we shall see in Section 3.3, we can induct only a carefully chosen subset of dual variables into the optimization, implicitly setting the rest to zeros, and considerably speed up the optimization.
Let {  X  v : v  X  V } ( | V | + 1 variables), {  X  v : v  X  V variables) and {  X  uv : u  X  v } ( | X  X  variables) be the dual variables corresponding to constraints (Balance), (Teleport) and (SoftPreference) respectively. Let Using a standard Lagrangian procedure, we arrive at the following observations.
 Proposition 1. The primal flows can be expressed as  X  v  X  V \ V o p vd =(1 /Z ) q vd exp(  X  d  X   X  v )  X  ( u, v )  X  Ep uv =(1 /Z ) q uv Here all  X  and  X  are unconstrained, and each  X  uv  X  [0 ,B ] . The dual objective to maximize is  X  log Z , where
Z = + Once we have routines to compute  X  X / X  X  x ,  X  X / X  X  x and  X  X / X  X  (we omit the tedious expressions) the dual can be solved us-ing the BLMVM optimizer [4].
Computing the dual objective and gradient takes time roughly proportional to | V | + | E | and | X  X  , as we shall see in Section 3.4.3. However, in a deployed search system, V , E and  X  can be large, and  X  can grow indefinitely with time.
Two features of our setting come to our rescue. First, while satisfying balance equalities exactly is mathematically appealing, it matters less in practice. Small imbalances near low-ranked nodes may not matter at all to the best-ranked nodes. Second, some pairs in  X  may (approximately) sub-sume others.

Following the cutting-plane approach of Tsochantaridis et al. [23], we propose an approach to introduce dual vari-ables gradually to the dual optimizer. We present some theoretical guarantees of progress and termination, and also provide experimental evidence that our approach can be ef-fective. 1: Input: V , E ,  X  and tolerance 2: Let B , T , P be current sets of dual variables 3: B X   X  , T X   X  , P X   X  (implicitly all  X ,  X ,  X  =0) 4: repeat 5: { estimate violations } 6: V (  X  v )= | OutFlow( v )  X  InFlow( v ) | 7: V (  X  v )= |  X p vs  X  (1  X   X  ) 8: V (  X  u,v ) = InFlow( v )  X  InFlow( u ) 9: discard candidates with violation V less than 13: Run dual optimizer over variables in B , T , P 14: until B , T , P stabilize or test accuracy saturates Figure 1: Constraint inclusion heuristic. Here arg max ( k ) selects the arguments corresponding to top-k values.

Figure 1 shows the dual variable inclusion heuristic. Un-like StructSVM [23] we wish to include not one but several violators, because we do not have an exponential number of dual variables, and in comparison the relatively heavyweight optimizer needs to be run after every inclusion step. Note that the parameters k and which control the number of variables that will be included in an optimization step are crucial to the success of the algorithm. Too small a value of k will lead to a prohibitively large number of iterations to induct a sufficient number of constraints for an acceptable quality of solution. Too large a k can lead to the induction of an extremely large number of constraints, thereby defeating the purpose. Similar arguments hold for .

We adaptively tune k and so that, even if their initial values are not very good, we can quickly reach a reasonable value. Every time the number of violators found above the threshold is greater than k , we increment k .Thisallows us to start off with a conservatively small k . For adapting , when we see that the number of variables being inducted is extremely low for several consecutive iterations, we increase . This is based on our observation that towards the end, the optimizer drags on, adding very few violators per iteration, and hardly improving in the quality of solution. Hence, we increase so that only significant violators, if any left, are inducted and can make a perceptible change in the quality of solution. The exact formulae by which we set k and are deferred to an extended version of this paper [18]. Proposition 2. The primal problem in Section 3.1 can be superficially rewritten to represent all dual variables  X  ,  X  and  X  collectively as a vector  X  =(  X  j ) with j ranging over a suitable index space, and to express where f j ( u, v )  X  [0 , 2] are features that encode the contribu-tions of various  X  j sto p uv . The modified dual objective to maximize is where each  X  j is a fixed small constant.
 We can also show the following important guarantee. Proposition 3. Suppose vector  X  (  X  1) is updated to  X  ( ) the th step of the dual variable inclusion algorithm shown in Figure 1. Assume that  X  ( ) is the same as  X  (  X  1) except for newly-included dual variables, which are greedily set to values that maximize the dual objective. Then, for &gt; 0 and all f j ( u, v )  X  [0 , 2] , i.e. the dual optimization makes monotonic progress. The proofs can be found in the full version of this paper [18]. Therefore, the algorithm will terminate in a finite number of inclusion phases. We can also show that we will make a good progress when we are far away from the dual optimum, and make smaller progress when we approach close to it.
For the problem we are studying there are no publicly available or widely-used benchmarks. Given the subtle in-terplay between E and  X  , a great deal of care is needed to generate these in a meaningful and realistic manner, so as to tease out the nature of the problem, the behavior of various algorithms, and the effects of different system parameters.
Real social networks have many well-studied properties: degree and Pagerank distributions tend to be power-law [11], diameter is small (small-world phenomena), and there are clustered communities. To achieve these goals, we used the RMAT graph generator [7]. RMAT populates edges one by one, driven by four parameters b xy with x, y  X  X  1 , 2 } and x,y b xy = 1. Starting with source and destination node ranges [1 ,n ], RMAT bisects each range and picks quadrant ( x, y ) with probability b xy , and then recurses until only one source and one destination node remain, at which point an edge is added. In all our experiments, we used b 11 =0 . 48, b 12 = b 21 =0 . 16, and b 22 =0 . 20, giving us graphs with characteristic clustering and power-law degree distributions Figure 2: Characteristic near-power-law degree dis-tribution of the DBLP+CiteSeer graph. very similar to real data from DBLP+CiteSeer, shown in Figure 2.

We also experimented with multiple overlapping graphs, each created using an RMAT invocation (as described in Section 4.2) and the results were subjectively similar.
Perhaps the simplest  X  X idden cause X  for  X  train disagreeing with flow q is that the user has a personal preference for an unknown region of G . (Tsoi et al. [24] make basically the same assumption.) After computing reference flow q ,we  X  X ecretly X  picked a seed node u  X   X  V o and sent it a relatively large flow from the dummy node d ,say r u  X  = p ( u  X  | d )=0 . 1. We divided the remaining teleport mass of 0.9 equally among other v  X  V . This gave us our  X  X idden X  flow p  X  .
In applications, users are more likely to provide feedback on, and benefit from, the ranking of nodes near the top of the lists ordered by q and p  X  scores, rather than low-scoring nodes. (For any flow p or q , the total inflow into a node v is its  X  X core, X  written as p v or q v .) Accordingly, we prepared two sorted lists, and considered all distinct node pairs ( u, v ) drawn from a large prefix over each list. If q u  X  q v and p  X  u  X  p  X  v or q u  X  q v and p  X  u  X  p it an agreement between q and p  X  ; the other two cases are disagreements . Using reservoirs, we sampled a fixed num-ber of agreements and (an equal number unless specified) of disagreements, which together constitute  X  train .  X  test was collected similarly. This generally led to an overlap of the node set involved in  X  train and  X  test (we always ensured  X  train  X  X  X  test =  X  ), but if this was undesired, we partitioned the node set ahead of time (say odd and even node IDs) and sampled  X  train from one and  X  test from the other.
We also experimented with multiple hidden favored seeds, and also with hidden, well-connected communities having high-conductivity edges grown around the seeds. The results were qualitatively similar. ables at zero, the initial primal flow p is equal to q , which satisfies all (Balance) and (Teleport) constraints. However, as the optimizer seeks to respect  X  , many primal constraints are abruptly violated, major flow readjustments take place, and the violations reduce. Gradually, egregious primal vi-olations become rare, as shown in Figure 3. A meaning-ful primal solution can be read off only at this stage, and BLMVM termination has to take care to monitor primal violations over and above dual objective saturation. Figure 3: Satisfaction of primal feasibility con-straints (Balance) and (Teleport) as dual optimization progresses.
 with | V | = 1000 and | E | = 4644. Then we created some 10 separate problem instances by picking 10 hidden seeds v  X  random to favor with a teleport of r v  X  =0 . 1 as described before. Figure 4: Reduction in test error as training | X  X  is increased, for three random choices of the hidden teleport seed.

For each problem instance, we first selected a fixed  X  test of size 600 (pairs). Then we picked  X  train of sizes 300, 600, 900, 1200, 1500, and 1800 pairs, and plotted training and test error, as a fraction of the total number of pairs, in Figure 4 (only three representative instances are shown, but they give some idea of the observed variance).
  X  train in Figure 4, the set of nodes involved in  X  test started overlapping with the set of nodes involved in  X  train , although we obviously ensured  X  train  X  X  X  test =  X  at all times. Figure 5: Effect of overlap between nodes involved in  X  train and  X  test on test error. Four random tele-port seeds were used.

For several different hidden teleport seeds, we increased the size of  X  train and plotted, in Figure 5, the test error against the fraction of nodes involved in  X  test that also ap-peared in  X  train . In search applications, users are typically focused on specific communities, and have no need to rank nodes far from and unrelated to nodes about which they already have ranking opinions.
 periments, Tsoi et al. [24] first computed (UnweightedPagerank), and then picked a pair of nodes (typically, one was highly ranked, the other not) and flipped their order to produce a  X  train with only one pair. Their goal was to study the effect of this inversion on various clusters of G . Figure 6: Comparison of maxent flow with QP tele-port tuning.

Used in our setting, the QP formulation of Section 2.3 performs surprisingly poorly (Figure 6), with an error rate comparable to random guessing, even if node overlap be-tween  X  train and  X  test is allowed. For five out of ten choices of the random favored teleport seed, the QP optimization as-signed zero teleport to the secret favored node. In contrast, in all ten cases, our algorithm assigned a positive primal inflow into the secret favored node.
 (4) with slack variables gives much better solutions, but is computationally very expensive because it has not | V | but |
V | + | X  X  variables and the constraints are more challenging than a symmetric square loss. Compared to our two al-gorithms, the quadratic programming approach, which also involves a matrix inversion to get M , appear impractical. Figure 7: Flow optimization time scales linearly optimization involving all dual variables takes time roughly linear in | X  X  , | V | and | E | . In Figure 7 G wasfixedand  X  train was scaled. In Figure 8  X  train was fixed and | V | |
E | scaled separately.
 with 21000 nodes and about 42000 edges, and scaled up | V |
E | and | X  X  in tandem. Figure 9 shows the running time of the one-shot dual optimizer and the total time of the multi-round dual variable inclusion strategy given in Figure 1. As the problem size scales up, we get bigger and bigger gains from the variable selection strategy. Figure 8: Flow optimization time scales roughly lin-early with | V | (relative sizes 0.5, 1, 1.5 shown) and with | E | (relative sizes 0.5 X 5 shown).
 Figure 9: Running time of the one-shot dual opti-mizer vs. the gradual inclusion strategy. The x-axis is | X  X  ; | V | and | E | are scaled up proportionately.
In this Section we address the problem of learning weights for each edge type from  X  .
The conductance matrix C used in (UnweightedPagerank) is modified to reflect edge weights, as follows:
C ( j, i )= Here d is the dummy node and r =( r j ) is the teleport vector as before. Note that C is a function of  X  , and we seek a set of  X  ssuchthe p solves p = Cp and p satisfies  X  .
As in soft-margin approaches, we again turn the latter hard constraint into a part of the objective that penalizes violations of  X  . The transformation of (Preference) into (SoftPreference) and (SoftObjective) essentially adds a vio-lation penalty note that if p u  X  p v as  X  wants, no penalty is incurred. Two problems remain: the max function is not differentiable at zero, and p u cannot be expressed easily in terms of  X  .
The first problem is common, and readily removed by ap-proximating (8) with a everywhere-differentiable function such as the Huber penalty with window width W :
Because we are searching for  X  ( t )s, we will need to find of the rhs of (9). The only missing piece is  X  X  u / X  X  ( t ) for each node u and type t . Let g ( u, t ) be an approximation to  X  X  u / X  X  ( t ). 2:  X  0 3: while any element of p or g changes significantly do 4:  X  +1 5: for each u set p ( ) u  X  6: for each node u and type t do 7: g ( ) ( u, t )  X  8: end for 9: end while Figure 10: Iterative approximation to  X  X  u / X  X  ( t ) .
We show in Figure 10 how to compute all the g ( u, t )s by accompanying the regular Pagerank iterations with gradient-finding steps. This is just an application of chain rule itera-Once we calculate p and g , we can evaluate the objective and gradient and use a Newton method like BLMVM [4].

From (Conductance) we see that scaling all  X  sbyafixed factor does not change C .Topreventany C ( i, j ) from going to zero, we arbitrarily set the lower bound  X  ( t )  X  1 for all types t . We can also penalize large  X  s with a standard Ridge-penalty of the form  X   X  .
Generating a synthetic graph through a single call to RMAT, and then randomly assigning types and weights, would lead to very unrealistic graphs that would look locally statisti-cally homogeneous at all nodes wrt incident weights.
To generate natural graphs with typed nodes and edges, such as the DBLP or CiteSeer citation graphs, we first called RMAT with a single set of 10000 paper nodes, creating 86382 citation links between them. Then we created a sep-arate set of 10000 author nodes, and called RMAT to con-nect papers and authors with 26280 edges. Similarly, we connected papers to 1000 venue nodes using 15930 edges. These numbers were derived from an informal study of the degree distribution of the DBLP and CiteSeer graphs (see Figure 2). We also experimented with a graph derived from IMDB ( http://imdb.com ) and the results were similar.
Edges connecting two node communities have a desig-nated type, e.g., paper written-by author. As in several ER graph databases [5, 3] all edges logically exist in both directions. Another way to say this is that each edge has two types, e.g. an  X  X uthor wrote paper X  also has a  X  X aper written-by author X  in the reverse direction.

We first assigned all edges unit weights (all  X  = 1) and computed the reference flow q . Then we assigned the edges various hidden weights (default values were paper-author: 6, 10; paper-paper: 20; paper-venue: 1, 4), and computed the hidden flow p  X  . Finally, as in Section 3.4, we sampled from the agreements and disagreements between q and p  X 
In this section we give evidence that the approximate gradient-descent is very effective at recovering the hidden parameters that led to  X  , in terms of both accuracy and speed. A direct comparison with Nie et al.  X  X  system was not feasible because they use a sophisticated, highly-tuned simulated annealing approach whose code is not public, and their running times range into several hours [19, Figure 8] while our algorithm takes a few minutes. Figure 11: Like Pagerank itself, the gradients con-verge within very few iterations.
 is plotted against iterations for several edge types t in Figure 11. The difference between successive values decay exponentially, and convergence is achieved in practice be-tween 30 and 50 iterations. We therefore feel confident to use these gradients in a gradient-descent procedure. Figure 12: Reduction in test errors out of 2000 as  X  train is increased.
 2000, the test error as  X  train is increased. Unlike in the maxent flow approach, here node overlap between  X  train and  X  test had no systematic effect on test error, so we en-sured zero node overlap between  X  train and  X  test through-out. Compared to the maxent flow setting, we are estimat-ing only a handful of  X  s,sothesizeof  X  train needed to attain good test accuracy is much smaller.
 we varied 1 X 2 edges weights away from the defaults listed above, and saw if our algorithm can estimate values close to the hidden values. The results are shown in Figure 13. The prominent diagonal is reassuring. Thanks to the  X   X  Ridge penalty, there is a downward pressure on some  X  s leading to the below-diagonal entries. However, we note that an infinite number of combinations of edge weights can lead to the same Pagerank ordering per (WeightedPagerank). Even where we underestimated a  X  , the effect on train or test error was negligible. Figure 13: Accuracy of estimation of hidden  X  s.
 time per iteration as the graph size is scaled up. The time per iteration scales essentially linearly with | V | while the number of iterations is more erratic, but grows slowly with G . The overall result is that the training time is proportional to the scale factor raised to the power of about 1.34, which is mildly superlinear. Figure 14: Scaling of running time with graph size. The x-axis represents the factor by which our syn-thetic DBLP graph X  X  V and E were expanded.
Most existing approaches to ranking entities involve learn-ing weights for feature vectors, or Markovian walks with arbitrarily-designed conductance matrices. We have initi-ated the study of a uniform framework for learning the pa-rameters of Markovian walks in graphs to satisfy pairwise preference constraints between nodes.

We presented two learning problems in this framework. In the first, the preferences hint at one or more favored com-munities that the learning algorithm must discover. We pro-posed a maximum entropy flow estimation algorithm for this setting. In the second problem, edges have types that deter-mine their conductance, and the learner must estimate these weights. We proposed an approximate gradient-descent al-gorithm for this setting. Our formulations enhance and gen-eralize some previous approaches. We showed experimen-tally that our approaches are effective.

The flow approach has to estimate a large number of vari-ables, scaling with G . The flow approach applies to settings where edges are not typed, and  X  train and  X  test are nat-urally clustered (as they would be in many relevance feed-back or collaborative filtering applications). In contrast, the approximate gradient-descent approach estimates relatively few global weights, and can therefore generalize from  X  train to  X  test that involve completely different nodes, far away in G , with a much smaller number of examples. However, the second approach requires a notion of global edge types.
In ongoing work we are trying to go beyond just counting satisfied node-pairs to a more rank-aware objective that pays more importance to top-ranking nodes. We are also trying to extend the framework to integrate node feature vectors (e.g. text on Web pages) in an elegant manner. [1] S. Agarwal, C. Cortes, and R. Herbrich, editors. [2] K. Anywanwu, A. Maduko, and A. Sheth. SemRank: [3] A. Balmin, V. Hristidis, and Y. Papakonstantinou. [4] S. J. Benson and J. J. Mor  X  e. A limited memory [5] G. Bhalotia, A. Hulgeri, C. Nakhe, S. Chakrabarti, [6] S. Brin and L. Page. The anatomy of a large-scale [7] D. Chakrabarti, Y. Zhan, and C. Faloutsos. R-MAT: [8] H. Chang, D. Cohn, and A. McCallum. Creating [9] W. W. Cohen, R. E. Shapire, and Y. Singer. Learning [10] M. Diligenti, M. Gori, and M. Maggini. Learning Web [11] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On [12] L. Guo, F. Shao, C. Botev, and [13] T. H. Haveliwala. Topic-sensitive PageRank. In [14] R. Herbrich, T. Graepel, and K. Obermayer. Support [15] G. Jeh and J. Widom. Scaling personalized web [16] T. Joachims. Optimizing search engines using [17] J. M. Kleinberg. Authoritative sources in a [18] NetRank project home page. [19] Z. Nie, Y. Zhang, J.-R. Wen, and W.-Y. Ma.
 [20] M. Richardson and P. Domingos. The intelligent [21] G. Salton and M. J. McGill. Introduction to Modern [22] J. A. Tomlin. A new paradigm for ranking pages on [23] I. Tsochantaridis, T. Joachims, T. Hofmann, and [24] A. C. Tsoi, G. Morini, F. Scarselli, M. Hagenbuchner,
