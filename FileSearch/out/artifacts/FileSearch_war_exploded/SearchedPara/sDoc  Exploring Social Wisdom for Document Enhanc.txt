 Web document could be seen to be composed of textua l content as well as social metadata of various forms (e.g., anc hor text, search query and social annotation), both of which are val uable to indicate the semantic content of the document. However, due to the free nature of the web, the two streams of web data suff er from the serious problems of noise and sparseness, which hav e actually become the major challenges to the success of many web mining applications. Previous work has shown that it could enhance the content of web document by integrating anchor text and search query. In this paper, we study the problem of explo ring emergent social annotation for document enhancement and prop ose a novel reinforcement framework to generate  X  social representation  X  of document. Distinguishing from prior work, textual c ontent and social annotation are enhanced simultaneously in ou r framework, which is achieved by exploiting a kind of mutual re inforcement relationship behind them. Two convergent models, social content model and social annotation model , are symmetrically derived from the framework to represent enhanced textual content and enhanced social annotation respectively. The enhanced docume nt is referred to as Social Document or sDoc in that it could embed complementary viewpoints from many web authors and many web visit ors. In this sense, the document semantics is enhanced exactly b y exploring social wisdom. We build the framework on a large De l.icio.us data and evaluate it through three typical web mining ap plications: annotation, classification and retrieval. Experimen tal results demonstrate that social representation of web docum ent could boost the performance of these applications significantly .
 H.3.3 [ Information Systems ]: Information Search and Retrieval. Algorithms, Experimentation. Document representation, Social annotation, Social document, Content enhancement, Social metadata. Unlike traditional document only containing textual content, web document (e.g. web page, blog entry, image and vide o) is typically associated with a variety of social metadata, eithe r explicitly or implicitly, such as anchor text, search query and s ocial annotation. Comparing to textual content, social metadata is eq ually valuable to indicate the semantic content of web document. Anch or text normally subsumes summative description of the link ed document [1]. Search query issued by a person is more or les s relevant to his clicked result documents [2]. In recent years, soci al annotation, an emergent form of tagging service, is rapidly rising on the web 2.0, where people like to adopt keyword-like annotations to collect, organize and share their favorite documents online. Such social annotations are usually good summaries to the corre sponding web documents from different perspectives [3]. Therefore, in terms of semantic content, a web docu ment could be regarded to be composed of textual content as well as associated social metadata, both of which are useful to develo p the content-based mining applications [1, 2, 3, 4, 5, 10, 14, 1 5, 19, 20, 21]. Unfortunately, the two streams of web data suffer f rom the severe problems of both noise and sparseness, which primar ily arises from the free nature of the web. On the web, a document author could publish almost arbitrary content in a web document, and a document visitor could assign almost arbitrary metadata to a web document. Though such web freedom helps to ease the use of we b applications and thus promote their popularity, it adversely cau ses serious problems in data quality of web data. As regards th e noise problem, many web documents contain advertising and even spa m content; furthermore, many web documents are appointed with irrelevant and even spurious social metadata. On the other hand, a s regards the sparseness problem, many web documents contain litt le or no text; furthermore, many newly-created or rarely-visited d ocuments have no any associated social metadata at all. In reality, these problems have evolved as the majo r challenges to the success of content-based web applications from two aspects: 1) the application performance would be limited, impai red and even deteriorated due to noisy content mixed in textual content and/or social metadata; and 2) many web applications would be restricted, hindered and even disabled due to sparse textual co ntent and/or sparse social metadata. More fundamentally, the pro blem of poor data quality actually poses a great challenge for w eb applications in modeling the documents to be handled effectively. S pecifically, in the context of document representation, 1) sparse c ontent fails to capture the semantic richness of the document suffi ciently; and 2) noisy content gives rise to a polluted and biased r epresentation. It is thus important and also necessary to enhance the semantics of web documents before using them in content-based ap plications. This work is conducted while the author was on an internship at IBM China Research Lab.
 Prior work has shown that it could possibly achieve this goal by integrating anchor text and search query into  X  X irt ual document X ,  X  X xtended anchor text X  and  X  X irtual queries X  [1, 2, 5, 7, 9]. In this work, we instead study the problem of exploring soc ial annotation to enhance the content of web document. Specifically, we propose a novel reinforcement framework to generate social re presentation of web document. In contrast to prior research, textua l content and social annotation are simultaneously enhanced in ou r framework, which is achieved by revealing and exploiting a kin d of mutual reinforcement relationship between them. Two symmet ric models, social content model and social annotation model , are derived from the framework to boost textual content and soc ial metadata respectively. Both models are proved to converge an alytically. We further prove that the two models could be speciali zed to adapt to extensive types of web documents, and could also be simplified to reduce the iterative computation cost. The resultin g document is referred to as Social Document or sDoc in that it could embed complementary viewpoints from many web authors and many web visitors. In this sense, the document semantics is enhanced exactly by exploring social wisdom. We build the framework on a large Del.icio.us [30] corpus and evaluate it through thr ee typical web applications: annotation, classification and retrie val. Experimental results indicate that our social representation of web documents could increase the performance of these application s significantly. The main contributions of this paper are summarized as below: 1. We review existing work on exploring anchor text an d search query to enhance the content of web document, and p ropose to study the problem of exploring social annotation fo r this task. 2. We reveal the mutual reinforcement relationship bet ween the author-centric and visitor-centric data on the web, and extend link propagation to content propagation among web d ocuments. 3. We present a novel reinforcement framework to gener ate social representation of web document, and derive two mode ls from it to enhance textual content and social metadata resp ectively. The remainder of this paper is organized as follows . Related work is reviewed in Section 2. The iterative reinforcement framework for social representation of web documents is presented in Section 3. Experiment and evaluation are conducted in Section 4. Finally, the conclusion and future work are given in Section 5. On the current web, there are numerous web applicat ions to meet people X  X  diverse information needs. Such traditiona l applications include annotation, classification and retrieval, m ost of which are developed mainly on top of textual content. They ty pically assume that textual content could well expound the themes and utilize the words occurring on the documents to build the respe ctive models. Web annotation aims to summarize the content of web document using concise keywords. The keywords are either sel ected with the great TFIDF weights [10], or learned by a bunch of content-bas ed features [14, 15]. Web page categorization targets to put web pages into some predefined categories automatically accor ding to textual content of the documents. Na X ve Bayes ( NB ) [5, 18, 22] has been approved to be effective at categorization. Web ret rieval serves to return the documents relevant to a search query. So me classical models in information retrieval have been used for web retrieval, such as BM25 [23]. We demonstrate the effectiveness of social representation just on these three web mining appli cations. With the booming of the web 1.0 and 2.0, a vast amo unt of social metadata has been accumulated and aggregated on the web. Much research has devoted to exploiting this huge data i n the past years. On the one hand, many of them have used social meta data purely. To name a few, anchor text has been utilized for qu ery refinement [21] and website finding [24]; search query has bee n applied to event detection [19], query expansion [8] and query clustering [25]; social annotation has been employed to build semant ic web [20] and social network [26]. On the other hand, those tradi tional applications based solely on textual content have a lso benefited from integrating social metadata into their models. In specific, auto-annotation of web pages [10] and blog entries [11] has been made possible by selecting proper social annotations; we b page categorization has been enhanced by exploring ancho r text [1] and query log [5]; web search has been improved by expl oiting anchor text [4], query log [2] and social annotation [3]. In short, content-based mining applications have be en developed based on the two types of web content, alone or bot h. Since our social representation can simultaneously enhance te xtual content and social metadata for a web document, it is promi sing to many web applications for their further development and improvement. For success, nowadays, more and more applications o f web have taken content enhancement of documents as an indisp ensable step. This line of previous study has generally two main concerns: what type of web data can be used to enhance the documen t and how to exploit the selected data to achieve this goal. Gen erally speaking, there are two major genres of data on the web: auth or-centric and visitor-centric web data [19]. Author-centric data mainly refers to textual content of web documents created by web aut hors while visitor-centric data refers to social metadata of w eb documents created by web visitors. Prior literature has utili zed two types of visitor-centric metadata to enhance document conten t, including anchor text [5, 7] and search query [2, 9]. Notably , in these work, textual content and social metadata have been enhan ced separately. On the one hand, textual content has been enhanced by expanding the associated search queries [2], appending anchor text or anchor sentence to form  X  X irtual document X  [5] and smoothi ng collection statistics to tune the language model [6]. On the o ther hand, social metadata has been enriched by extending the surroun ding textual content ( X  X xtended anchor text X  [7] and query expan sion [8]), and finding more from relevant documents ( X  X irtual quer ies X  [2, 9]). By contrast, our work makes use of emergent social annotation to enhance web document in their semantic content. Qui te different from the aforementioned work, in our work, mutual r einforcement relationship between the author-centric and visitor -centric data is unearthed and simultaneous enhancement of textual c ontent and social metadata is achieved. In this paragraph, we first describe the target pro blem in Section 3.1. After that, we present the reinforcement framework in Section 3.2 and derive two convergent models in Section 3.3. La stly, in Section 3.4, we discuss some issues about our framework. Social web has fundamentally changed many things an d objects in their existence forms. The web of today provides a wide range of applications and services for people to express the ir viewpoints, thoughts and insights to a web document freely, rea dily and timely. As illustrated in Figure 1, there are generally thr ee popular types of web users possibly providing the content to a web d ocument, including web document authors , web document annotators , and web document searchers . Differently, these users make their own contributions to the content of web document. More specifically, 
Web document authors create textual content of web document and also link to other documents by creating anchor text. 
Web document searchers retrieve interested web documents by issuing content-relevant queries to search engines.

Web document annotators bookmark favorite web documents by using content-relevant annotations on tagging servi ces. As seen, different users closely collaborate with e ach other for the creation, edition and revision of a web document. I t means that a document is no longer isolated as usual, which inst ead exists in social environment of the web. The sociality of web document is actually presented in two aspects: 1) a document is now associated to various forms of social metadata explicitly and implicitly; and 2) more implicitly, but importantly, social metadata a cts as a kind of  X  X emantic bridge X  which widely connects the corresp onding web document to many other content-relevant documents. A significant problem thus emerges: how to best represent a web document in such social environment . Document representation is always crucial to semantics analysis and content mi ning. Some classical models, such as vector space model ( VSM ) [28] and language modeling ( LM ) [6], are originally designed to represent textual content of orthodox documents, which is qui te unsuitable for representing such documents of social form. In fact , just like textual content created by web authors, social metadata pro vided by web visitors is also informative to indicate semantic c ontent of web document. From the social perspective, to a web doc ument, textual content describes the web authors X  point of view wh ile social metadata describes the web visitors X  point of view [19]. In this work, we come up with a principled way to integrate the t wo complementary viewpoints for an enhanced representa tion of web documents. In particular, we consider how to achiev e the semantic enhancement by exploring emergent social annotation . We believe that it could derive a better representation of web doc uments by leveraging crowd wisdom and collective knowledge em bedded in large amount of social annotations . It is worth mentioning that our framework is applicable for exploiting anchor text and search query after preprocessing these social metadata appropria tely. To a web document, web author and web annotator wou ld provide complementary content to it. Intentionally or unint entionally, they are very likely to choose different but relevant te rms to describe the same topic of the documents. Such complementarities between web author and web annotator essentially imply a kind o f mutual reinforcement relationship between textual content and social annotation, which could be formally stated as: on social web, relevant social annotation is usually assigned to r elevant textual content, and relevant textual content is usually as sociated with relevant social annotation. As a result, textual co ntent could reinforce social annotation, and vice versa. In essence, what we reveal is the underlying correlation between the tw o heterogonous types of social data, where social annotation is af fected by textual content while textual content is analogously influe nced by social annotation. It is important to note that the former correlation is explicit whereas the latter correlation is implicit . In the light of the above interconnected reinforcem ent relationship, we present a novel iterative reinforcement framewor k ( IRF ) to enhance the representation of web documents. Assume that there are totally D N web documents, A N social annotations and terms in training corpus. AT M is the T A N N  X  association matrix between social annotations and textual terms. We ap ply the idea of TFIDF weighting to represent an initial web document by denoting textual terms as 0 T elements are respectively given by where d t w : and d a w : represent the estimated weights of the term t and the annotation a on the document d ; d t c : and numbers of t and a occurring on d ; ( ) t URL and ( ) a URL designate the numbers of documents containing t and a . In this way, we build the two vector spaces respectively on textual terms and social annotations of web documents. Let { } i T vectors for the same web document, IRF is formulated as The above two equations can be interpreted as follo ws. In IRF , textual content of web document is composed of orig inal terms and additional terms i AT A M documents with the bridge of relevant social annota tions. Similarly, social annotation of web document is composed of or iginal annotations 0 A extended from relevant web documents with the clue of relevant textual terms. The parameters  X  and  X  are in ( ) designed to reconcile the relative contributions of the original and additional content in enhanced document. In the end , a web document resides in a dual-vector representation wi th two integral components: enhanced textual content 1 + i T in the fact that it could embed complementary conte nt into a web document from the viewpoints of both many web autho rs and many web annotators. In view of this, we term our enhanced web document as Social Document or sDoc . Note that the vocabulary from original term space and annotation space will not be mixed in social document. In other words, IRF does not pull any vocabulary from textual terms into social annotations, and vic e versa. The two parts provide possibly overlapped but semantically different content. We give an illustrative example to clarify the gene ration process of social document. Consider the homepage of Google [3 8], highly sparse since there are only a very few terms on the page itself, but 0 A vast number of social annotations available for thi s page. For example, the page has thousands of annotations on D el.icio.us [30] and the most frequent ones include  X  X earch X ,  X  X earc hengine X ,  X  X ngine X  and  X  X eb X . Simply starting with 0 A associated with 0 A annotations associated with 1 T iteratively proceeds to achieve a stable status. Ev entually, the social representation of Google homepage is made up of two interdependent components, including both 1 + i T Define ( ) y x AT t a M , as the element of the association matrix which ought to be indicative of the associative deg ree between the annotation x a and the term y t . Here, we adopt a widely adopted where A is the co-occurrence time of x a and y t , B is the occurring time of x a without y t , C is the occurring time of 
D is the number of times neither x a nor y t occurs. Notably, association degree rather than the independence deg ree of t in the task of document enhancement. Once AT M is calculated, each row of both AT M and its transpose ' AT M must be normalized 
M and ' AT M become Markov stochastic matrices, which is necessary for the convergence of IRF as proved soon. In this section, we pursue two models from IRF to represent enhanced textual content and enhanced social annota tion in social document, referred to as social content model ( SCM ) and social annotation model ( SAM ) respectively. In fact, SCM and SAM correspond to the sequences { } i T conduct the proof on the convergence of { } i T form of SCM . Let ' ) 1( AT M w  X   X   X  = and AT M w ) 1(  X  loop in Equations (1) and (2) iterates, we have ..., r + (3), where I represents an identity matrix. Noting that  X  stochastic matrices,  X   X  w w is thus a symmetric stochastic matrix and its eigenvalues fall in ( ) 1,1  X  . So the following equations hold, Accordingly, we can infer that 1 + i T Similarly, we can also infer the closed form of SAM as below, As seen, sDOC enjoys an analytical representation composed of tw o convergent vectors * T mathematical duality, which reflects the fact that textual content and social metadata are just as important for represent ing a social document. Next, we show how to specialize IRF to adapt to heterogeneous types of documents and simplify IRF to reduce the computation cost almost half. Meaningfully, IRF could be specialized to adapt to diverse types of web documents. The prerequisite is that original do cuments have some initial textual terms and/or initial social an notations. This property is closely related to the duality of IRF , so we could elaborate on it from two aspects: 
On the web, there are a great number of web documen ts having no social annotations at all, e.g., new/unpopular w eb pages and traditional text documents. In this case, 0 0 = A
SCM and SAM in Equations (4) and (5) could be specialized as 
There are also a large number of web documents havi ng no textual terms but possibly having some social annot ations, e.g., web images on Filckr [36] and web videos on YouTube [31]. In this setting, 0 0 = T On most of web corpora, the scale of AT M is usually too large to calculate the inverse matrices efficiently in Equat ions (4) and (5), so it prefers using the iterative procedure in Equatio ns (1) and (2) for practical implementation of IRF . However, such iteration is still time-consuming mainly due to twice matrices multipl ication of involve only once matrices multiplication within ea ch round of iteration. To see how, substitute Equation (2) into (1) and we get Equation (8) is the simplified iteration form of { } calculate * T iteration using Equation (2). In this way, the comp utation cost is reduced to almost half. Symmetrically, we can also obtain More details for efficient implementation of IRF will be discussed in Section 4.2.3. Next, we establish two important fac ts about IRF from Equations (8) and (9). First, 0 T  X  X ersonalized X  representation of each web document. Some classical representations of document, such as VSM and LM , can be leveraged as the two initial vectors. In an extreme case wher e T r equations. Should this happen, textual term and soc ial annotation of all documents are collapsed to the principal eigenv ectors of and  X   X  w w respectively. Second, in general, the element of  X   X  w w reflects the association degree between two textual terms while the element of indicates the association degree between two social annotations. It means that we could build a reinforcement framework for textual terms themselves without social annotations or vice versa. In other words, IRF could also work for traditional corpora of text wi th an aim to enhance textual content purely, and web corp ora of image/ video with an aim to enhance social annotation pure ly. Our idea of social representation for web documents is inspired by a semi-supervised classification method where the lab els of the small amount of labeled data are gradually propagated to the large amount of unlabeled data [33, 35]. To apply such semi-supe rvised principle to document representation, original textual terms and/or social annotations of a web document are analogously treat ed as initial  X  content labels  X  to its semantics. After that, these original sema ntic labels are iteratively propagated to more relevant textual terms and social annotations. In particular, with the novel semi-supervised representation in IRF, the problem of term weightin g for document representation is reformulated as the prob lem of term ranking . All textual terms and social annotations are rank ed according to relevant degree to the corresponding d ocument. In IRF , web document is enhanced via content propagation among many relevant documents. Broadly speaking, there ha ve been two major categories of propagation algorithm: one prop agates among homogenous objects, e.g., PageRank [29], and HITS [ 17]; and the other among heterogeneous objects, e.g., SimRank [2 , 3, 13]. First of all, none of the aforementioned algorithms condu ct propagation for the purpose of document representation. More im portantly, the further difference is at least twofold: 
Most of these algorithms weave a graph for propagat ion on top of the hyperlink structure among web documents. In thi s sense, the association matrix in IRF can be seen as a form of bipartite graph between textual terms and social annotations. Diffe rently, it is built based entirely on the document content, indep endent of explicit hyperlink graph of web. In IRF , we draw implicit links between web documents that are tagged after the sam e or relevant textual terms and/or social annotations 
In previous algorithms, the propagated objects incl ude quality score [29, 17], similarity score [2, 3, 13], anchor text [1, 32], and relevance score [16] etc. By contrast, IRF spreads relevant content among web documents, including both textual terms and social annotations. In summary, IRF successfully extends link propagation to content propagation for the purpose of enhancing document semantic representation . IRF is a very general framework for enhancing document content. 
It can exploit various types of social metadata pro vided that its metadata is relevant to the semantic content of web document. 
Such social metadata extensively include anchor tex t, search query, social annotation and so on. 
It can adapt to extensive types of web documents pr ovided that the documents have initial textual terms and/or ini tial social annotations. Such applicable documents range from w eb pages, web images, web videos to traditional text document s. 
It can even be generalized to three or more types o f social data for enhancing their content concurrently. The premi se is they follow a circular correlation as simply illustrated in Figure 2. 
Figure 2. IRF for three types of social content: U , V and W . We conduct the evaluation of IRF on three typical web mining applications: annotation, classification and retrie val. Among these applications, annotation and retrieval are two unsu pervised tasks while categorization is a supervised one. Next, we present three experiments one by one with their data, evaluation and analysis. IRF can enhance textual content as well as social meta data for a web document. During this course, those significant tex tual terms and social annotations would emerge due to the mechanis m of term ranking in IRF as argued earlier. The more important an item is, the more likely it emerges. These significant items can serve as the semantic annotations for the corresponding web docu ments. It requires web documents which have both textual c ontent and social annotation for developing IRF . For experiment, we use web pages crawled from the Del.icio.us [30], a popular social tagging service, during May 2006. In all, we obtain 1,736,2 68 web pages and 269,566 annotations. All textual terms and soci al annotations are simply preprocessed in the following steps: 1) non-English and system-generated terms (e.g., imported, system:unde fined) are filtered; 2) highly infrequent terms appearing less than 10 times and highly frequent terms analogous to stop words are d iscarded. Finally, 20,354 textual terms and 13,596 social annotations are reserved for calculating the association matrix between them. For visually examining the built association matrix to some extent, we find the most relevant textual terms to one soci al annotation or vice versa. Some familiar topical keywords are list ed in Table 1, each of which is taken as textual term as well as s ocial annotation. To each of topical keywords, top 10 textual terms ( T ) and social annotations ( A ) are listed in the upper and lower rows respective ly. From the table, we can see that web authors and web annotators indeed choose literally different yet semantically relevant terms to describe the same topic. For example, there are onl y one common term in the topic of  X  bush  X  and two ones in  X  airport  X . As such, the semantic relevance between textual terms and social annotations. Next, content propagation and reinforcement in IRF is conducted on the crawled web pages using the normalized associat ion matrix. The parameters  X  and  X  are set to be 0.3. We will discuss the issue of parameter selection in Section 4.2.4. Table 2 gives some illustrative web pages with top 10 original textual terms ( OT ), enhanced textual terms ( ET ), original social annotations ( OA ) and enhanced social annotations ( EA ). From these web pages, we can see that: 1) a certain number of common terms appear between the e nhanced representations (i.e., ET and EA ) and the original ones (i.e., OT and OA ). It is mainly because the contribution ratio of o riginal content is as high as 0.3 in enhanced documents. Such a high ratio is believ ed to make for the preservation of information diversi ty in the original representations. 2) Even with 0.3 , IRF still successfully discovers many new relevant terms for each page. The extended terms indeed enhance semantic representation of the documents so that the problem of content sparsity is alleviated as desire d. 3) The common terms are ranked rather differently from the origin al to enhanced representations. In IRF , the relevance of a term to a web document is determined by a social voting, where relevant terms are social ly up-weighted while irrelevant terms are socially dow n-weighted. In this way, the noisy content mixed in the document c ould be suppressed heavily with trivial weights. 4) Web aut hors and web annotators really provide a same document with comp lementary information. For example, to the homepage of  X  eclipse  X , social annotations  X  ibm  X ,  X  plugin  X  and  X  freeware  X  are clearly good supplements to the semantics of the original page. 5) For a web document, textual terms and social annotations coul d indeed provide semantically complementary content. Very often, we can easily see quite a few seemingly informal tags among social an notations, including coined tags, abbreviation tags and conjun ction tags. Many of these peculiar tags seldom appear in normally fo rmal textual content. Although somehow casual, they are undoubte dly good supplements to the semantic content of the correspo nding web pages. We also run some exploratory trials on several web images from a Wikipedia website [27] by exploiting surrounding te xt of images. Some interesting results are shown in Table 3, whic h lends the evidence of IRF in enhancing diverse genres of web documents. Despite the fact that we have no ground-truth annot ations of web pages, we still attempt to make a quantitative anal ysis as to the annotation performance of IRF. To do this, we randomly select 1,000 web pages from our Del.icio.us corpus, each o f which has at least 200 distinct social annotations. To every web page, the most frequent 20 ones are selected as a kind of syntheti c ground-truth bush bush bush bush java java java java google google google google airport airport airport airport movie movie movie movie annotations. IRF is then performed on these web pages not using their social annotations. We are interested in how many synthetic annotations are retrieved by IRF . For evaluation, we measure the recall accuracy of IRF within top 20 annotations. We believe that such a measurement could evaluate IRF to some degree in terms of its capability of predicating social annotations fo r a web page. We repeat such trials 20 times. The recall accuracy of each trial is averaged over 1,000 web pages and the overall recal l is averaged over 20 times. Finally, we obtain a recall of 82.18 % at a precision of 83.26%, which means that most ground-truth annotati ons are predicted by IRF . Such an automatic annotation capability brings good prospects since there remain an enormous numbe r of web pages which are not annotated yet. It should be rea lized that the IRF annotations differ a lot from the keywords generate d by some heuristic or learning methods. Those conventional k eywords are just chosen among textual terms pertaining to the body o f the documents themselves. Such keywords only reflect the summary of the authors by any means. On the contrary, IRF annotations are collectively elected by a large crowd of both web authors and we b annotators. Typically, they might not be present on the documen ts themselves but more summative and descriptive than the origina l terms. Such annotations hereby possess the sociality similar to those real-world annotations on Web 2.0. At the same time, it is imp ortant to note that the other 16.74% of IRF annotations are not mistaken or erroneous. In fact, they also exhibit distinct rele vance to the respective web page, and make a substantial supplem ent and enhancement in their semantic content. The second experiment is about web page categorizat ion. We start with the introduction of the experimental data, and then conduct in-depth experimental analysis including the issues of accuracy, efficiency, parameter and adaptation in turn. Figure 3. The imbalanced category distribution of O DP data. We investigate the effectiveness of social document for web page categorization. The data are crawled from the first -level category of  X  X omputers X  on the ODP [34], a popular web director y service. Web pages are preprocessed by passing word stemmer and tossing out stop tokens. Only English web pages containing more than 10 terms are reserved in our experiment. Eventually, w e obtain a total number of 22,000 pages belonging to 30 second-level categories. The category distribution is plotted in Figure 3, w hich is under an observable unbalanced distribution. As compared, fo r example, the largest  X  Programming  X  category contains 4,143 web pages while the smallest  X  E-books  X  category merely 87 ones. The corpus manifests two evident characteristics: 1 ) there are only a very small portion of ODP web pages having been ann otated on Del.icio.us. The annotation rate is only 12.14% (2, 670/22,000). To make matters worse, the situation of sparseness is even more severe on the global web, where it has been estimated that the ratio of the annotated web pages is no more than 0.1% [37]. As a result, most applications dependent on social annotations have t o be limited to a small-scale web. Thus, an automatic and effective s ocial-annotation method is desirable and it ought to be applicable f or the majority of web pages. 2) A considerable portion of ODP web pag es (72.65%, 15,982/22,000) contain less than 100 terms in their bodies. Sparse text falls short of describing the semantic content of web documents adequately. Thus, an effective content enhancement method is desirable and it ought to be suitable for the major ity of web pages. IRF could favorably meet the above two expectations at once by enhancing not only textual content but also social metadata for a web document in the mean time. We compare four representations for a web document including original textual content ( TFIDF ), enhanced textual content ( SCM ), enhanced social annotation ( SAM ) and social document ( IRF ). IRF is the combination of SCM and SAM by concatenating them into a longer vector. Noting the fact that textual terms a nd social annotations could provide overlapped yet different semantics, for the words sharing between SCM and SAM , an auxiliary prefix is inserted before the head (say,  X  X _ X  and  X  X _ X  are us ed in our work). It should be emphasized that the common words sharing between SCM and SAM might be ultimately assigned with fairly different weights which are collectively determined in a soci al manner. We leave more sophisticated combination explored in th e future. NB is selected as the classifier of web pages due to its popularity, effectiveness and efficiency [5, 22]. It estimates the possibility of a document belonging to a category with the joint pro babilities of term and category. The term weight in four represen tations is used as a kind of real-valued frequency for calculating NB probabilities. We select NB for evaluation also considering that it could dire ctly reflect the effect of term weighting for each repre sentation on the performance because the categorization probabilitie s are estimated completely based on the statistics of term frequenc ies. Standard measures are adopted to evaluate the accuracies, in cluding micro-averaged F-score ( MicroF ) and macro-averaged F-score ( MacroF ). MicroF gives equal weight to every document and tends to be dominated by the performance on common categories; in contrast, MacroF gives equal weight to every category and is subjec t to the performance on rare categories. As reported in [3], the imbalanced categories in our ODP corpus give rise to low MacroF accuracies as shown in the following experimental results. All web pages are randomly split into 10 groups to perform 10-fold cross validation. The average results are reported in Figure 4. From the results, we can see that: 1) Among four represe ntations, TFIDF performs worst in terms of both MicroF and MacroF . It desperately suffers a lot from noisy content and sparse semanti cs in the crude web pages. 2) SCM is much better than TFIDF with 9.60% increase in MicroF and 17.93% increase in MacroF . It attributes to the fact that many relevant textual terms are extended into web pages. These enriched textual terms are indeed helpful for impro ving the categorization. 3) The classification accuracies of SAM are similar with that of SCM . It attests to the fact that the two representatio ns aggregate approximate discriminative power for cate gorization by a way of content pulling. 4) IRF is superior to the competing representations. Compared with TFIDF , MicroF is increased by as much as 20.08% while MacroF is increased by as much as 34.83%. It should benefit from fact that the content from SCM and SAM is incorporated in social document. The great compleme ntarities in the two genres of social content are of great help to b oost the categorization performance. It is worth mentioning that the starting point of IRF , namely the na X ve integration of 0 T 0.5814 in MicroF and 0.3112 in MacroF . It is decently better than T r alone. Considering the fact that SCM , SAM and IRF all build their representations by taking account of social a nnotations, they beat TFIDF hopefully in the context of web page categorizatio n due to the intuition that web pages with identical and/ or relevant annotations are more likely to belong to the same c ategory. But, the starting precision is far from that of the ultimate IRF . In fact, we observe that the categorization accuracies of SCM , SAM and IRF are increased gradually as the iteration proceeds. It c onfirms that more and more content-relevant terms are helpfully added to these representations. A direct fusion of vector space mo dels on textual terms and social annotations remains the problems o f noise and sparseness largely unsolved and heavily exposed. According to Equation (8), the optimized form of IRF performs almost twice as fast. But, it still involves expens ive computation. The inefficiency is mainly rooted in dense vectors { } i matrix drastically. Fortunately, it could prune the consid erable number of unnecessary elements from both { } i T without loss of classification performance too much . In the context of content enhancement, it is expected that only re levant terms and annotations are transferred among web pages. We car efully examine 
T r with smaller weights lean to be noise. It motivates us to throw away small elements from these vectors in prior to conte nt propagation of each round, since they are barely relevant to the c ontent of the web page. In fact, a small fraction of large elements s uffice to embody the semantic of the current page. In the final impl ementation, only 10% of the largest elements (i.e. 2,035 top terms) are reserved in for propagation. The ratio of 10% is tuned with a careful tradeoff between the efficiency and the effectiveness by rep eating the trials. The same pruning is also performed on each row (i.e ., column) of w w , which thus turns into a sparse matrix and allows for a rapid convergence of IRF . Once after the tailing irrelevant elements are eliminated,  X   X  w w is renormalized into a stochastic matrix, and is renormalized into a probabilistic distribution. The experimental results reported in Figur;e 4 confirm the validity of our scheme in pruning irrelevant elements. It favorably achieves a balance between losing little representational power for categoriza tion while saving much computational cost for implementation. Finally, on a Intel Core2 2.66GHz Pentium-4 class m achine with 2.0 GB RAM and a 7200 RPM SATA-IDE hard drive, it total ly takes about 7 hours for once evaluation on our Del.icio.u s and ODP corpora. We are aware of that the current implement ation of IRF is still inadequate for those online web applications, but in many cases content enhancement of web documents could be offli ne performed before hand. To further improve the efficiency, we plan to adopt some optimization strategies for a more rapid conve rgence of IRF , such as minimal count restriction [13]. We also pla n to set up a cloud platform of distributed computing for perform ing IRF more expeditiously. It needs to determine two kinds of parameters in IRF for practical implementation. One is  X  and  X  in Equations (1) and (2) while the other is the iteration number of times for conv ergence. There are no closed forms for these parameters. We set them e mpirically. The parameters  X  and  X  control the relative contributions of the original and additional content in social represent ation. Due to the limit of implementation time, it is impractical to examine many combinations of the two parameters. For simplicity, we set them equal and examine four representative groups of par ameter setting, including 0.1, 0.3, 0.7 and 0.9. Noting the symmetr y and duality of textual content and social annotation in IRF , it is reasonable to set  X  and  X  equal always. We find that: 1) When the parameters are 0.9, IRF makes trivial improvement over TFIDF in web page categorization. At this point, IRF could only add a handful of relevant terms to social document. In an extreme ca se when the two parameters are 1.0, IRF is exactly degenerated into TFIDF . 2) When the parameters are 0.1, IRF is inferior to TFIDF . At this time, too many irrelevant terms are wrongly added to document . In an extreme case when the parameters are 0, as stated i n Section 3.3.2, all of documents take on the same collapsed represe ntation unreasonably. 3) Finally, the parameters are set to be 0.3 due to much higher improvement than 0.7. On the one hand, such a parameter value ensures the personalized representa tion of each document with sufficient diversity of the original content; on the other hand, it enables IRF to effectively find a mass of relevant terms for final representation since the additional content accounts up to 70%. Considering a real-world web document, t he ratio of 0.3 might also be tenable since a document could only c ontain a relatively small fraction of terms relevant to its topic in most cases. The iteration number of times for convergence varie s from page to page. Based on this consideration, we adopt a heuri stic rule to set this parameter for each web page. In specific, we c alculate cosine distance between the vectors 1 + i T iterations. The iterative procedure terminates if t he distance is smaller than a given threshold. We also track the a ccuracies at all rounds. We find that the average accuracies attain a peak at the 8 iteration and become basically stable since then. I t hints that the majority of web pages have converged rapidly within 8 iterations. In essence, IRF is an unsupervised representation of document requiring no manual preparation and intervention. T o shed more insight on the unsupervisity of IRF , we look into its adaptation capability for the situation when the documents use d to build it and the documents to be enhanced belong to different ty pes (e.g., web page vs. news report) and/or different domains (e.g ., biology vs. computer). The experiment is performed on the Reute rs-21578, a benchmark corpus for text categorization. The corpu s consists of 7,769 training and 3,019 testing documents, both of which belong to 90 categories. These documents are well-edited news papers of high quality, which makes them quite different from free ly-edited ODP pages. We leverage the IRF built upon Del.icio.us corpus to enhance the representation of Reuters newspapers including both textual content and social annotations, and then perform th e text categorization on enhanced representations of news reports. The experiment reveals some insightful findings. We analyze the results from two aspects: 1) Globally, IRF is distinctly worse than TFIDF on the entire corpus. Specifically, MicroF is down from 82.97% to 74.76% and MacroF from 47.83% to 39.50%. The main reason for such a dramatic degradation is that our IRF is trained based on the Del.icio.us data. As pointed out in [3 ], the majority of web pages and social annotations on Del.icio.us are related to the domains of  X  Computers  X  and  X  Web  X , which totally differ from the domains of most categories in Reuters-21578, e.g.,  X  Oilseed  X ,  X  Propane  X  and  X  Rye  X . As a result, irrelevant and even erroneous terms are improperly associated to the document, wh ich causes deteriorated categorization accuracies. It warns th at content propagation might be more harmful than helpful if i t is performed inappropriately. 2) Locally, it is found that IRF impressively gains obvious improvement on a minority of Reuters-21578 categories partially listed in Table 5. For these categories, a certain number of documents misclassified by TFIDF are correctly classified by IRF . We scrutinize these documents and they turn out to be more or less inclusive of terms in the Del.icio.us corpus. For e xample, the documents in the categories of  X  Trade  X  and  X  Gnp  X  contain quite a few terms related to the  X  Economy  X  domain, e.g.,  X  export  X ,  X  business  X  and  X  product  X . IRF could enhance these documents in their topical semantics. Based on these encouraging results, we are confident that our IRF can be adaptable to various types of text data if built and applied between the corresponding doma ins. The last evaluation is conducted for the task of we b retrieval. In the experiment, documents are just retrieved only accor ding to the relevance judgment of the query to the document con tent without resorting to hyperlink information among web docume nts. We still use the 22,000 web pages in the previous e xperiment. The queries and their ground truths are automatically g enerated from the ODP directory in a similar way to [3]. Specifically , we employ the category path as the query and the corresponding we b pages as the ground truths. Specially, the term TOP in the category path was removed. For example, TOP/Computers/Software/Graphics would constitute the query  X  Computers Software Graphics  X . The second-level ( 2nd-lev ) and third-level ( 3rd-lev ) categories in the ODP taxonomy are extracted as probing queries. We end u p with 366 queries. From the retrieval standpoint, the 3rd-lev queries are more focused on the expected documents than the 2nd-lev queries. The relevance between the query and the document is evaluated with the BM25 formula [23]. The term weight in representations i s used as the real-valued frequency for calculating BM25 score. We evaluate retrieval performance with two widely adop ted metrics namely Mean Average Precision ( MAP ) and R-Precision ( R-Pre ). MAP is the mean of average precision over all queries while R-Pre is the precision after R documents have been retrieved. The experimental results are reported in Figure 5, whic h clearly shows that IRF outperforms TFIDF in terms of retrieval. It bears out that IRF succeeds in enriching the content of web document including both relevant textual terms and relevant social ann otations. The extended content is of great benefit to boost retri eval accuracies. In fact, for the task of information retrieval, it is well known that the classical vector space model, i.e., TFIDF in our work, always suffers from the inherent problems of noise and sparsity. LSI (i.e., latent semantic indexing, [39]) tries to alleviate this pr oblem using low-dimensional latent vectors which are typically not sparse. But, LSI contains negative entries in its dense representati on which are not interpretable from physical meanings. PLSI (i.e., probabilistic latent semantic indexing, [40]) assumes a generation proce ss of document, and takes the positive coefficients over multinomia l mixture distributions as the entries of low-dimensional vec tors. In comparison to these classical representations, IRF does not recur to dimensionality reduction or mixture clustering, but strictly meet the properties of density and non-negativity. As demons trated in our experiments, such an enhanced representation could boost the accuracy of some fundamental web applications, incl uding web annotation, web classification and web retrieval. In this paper, we propose a novel way of document m odeling. Its novelty is primarily three-fold. 1) A web document is regarded to be composed of textual content as well as social metad ata in terms of its semantic content. 2) Further, a kind of mutual reinforcement relationship between the two types of social data i s revealed based on their social semantic complementarities. 3) Fina lly, an iterative reinforcement framework ( IRF ) is built based on this relationship to generate an enhanced social representation of we b documents. Our enhanced representation is referred to as social document or sDoc in that semantic content of documents is enhanced exactly by exploring social wisdom. It can embed complementary content from the viewpoints of many web authors and many web vis itors. Two models, social content model and social annotation model , are derived from the framework, one capturing enhanced textual content and the other capturing social annotation. Experime nts on web annotation, web classification and web retrieval in dicate the superiority of social representation over tradition al representations for content-based mining applications on the web. Our proposed IRF is a very general framework for enhancing the semantic content of web documents. Considering the popularity of content-based applications and the generality of IRF , we believe that social representation of web documents has great po tential in a wide range of content-based mining applications. Next, w e plan to collect a larger scale of web corpus, build a more accurate IRF , and investigate social representation using more algori thms such as K-means, SVM and AdaBoost. We also continue finding m ore efficient way of implementing IRF for real-world applications. [1] S. Brin and L. Page. The Anatomy of a Large-Scale [2] G. Xue, H. Zeng, Z. Chen, Y. Yu, W. Ma, W. Xi, and W. Fan. [3] S. Bao, X. Wu, B. Fei, G. Xue, Z. Su, and Y. Yu. Op timizing [4] H. Oh, S. Myaeng, and M. Lee. A Practical Hypertext [5] D. Shen, J. Sun, Q. Yang, and Z. Chen. A Comparison of [6] J. Ponte and W. Croft. A Language Modeling Approach to [7] E. Glover, K. Tsioutsiouliklis, S. Lawrence, D. Pen nock, and G. [8] H. Cui, J. Wen, J. Nie, and W. Ma. Probabilistic Qu ery [9] D. Brian, G. David, and B. David. Finding Relevant Website [10] C. Brooks and N. Montanez. Improved Annotation of the [11] G. Mishne. AutoTag: A Collaborative Approach to Aut omated [12] X. Wang, L. Zhang, F. Jing, and W. Ma: AnnoSearch: Image [13] G. Jeh and J. Widom. SimRank: A Measure of Structur al-[14] P. Chirita, S. Costache, S. Handschuh and W. Nejdl. PTAG: [15] W. Yih, J. Goodman, and V. Carvalho. Finding Advert ising [16] A. Shakery and C. Zhai. A Probabilistic Relevance P ropagation [17] J. Kleinberg. Authoritative Sources in a Hyperlinke d [18] T. Mitchell. Machine Learning . McGraw-Hill, 1997. [19] Q. Zhao, T. Liu, S. Bhowmick, and W. Ma. Event Dete ction [20] X. Wu, L. Zhang, and Y. Yu. Exploring Social Annota tions for [21] R. Kraft and J. Zien. Mining Anchor Text for Query Refinement, [22] A. McCallum and K. Nigam. A Comparison of Event Mod els [23] S. Robertson, S. Walker, M. Beaulieu, A. Gull, and M. Lau. [24] N. Craswell, D. Hawking, and S. Robertson. Effectiv e Site [25] J. Wen, J. Nie, and H. Zhang. Clustering User Queri es of a [26] P. Mika. Ontologies Are Us: A Unified Model of Soci al [27] http://en.wikipedia.org [28] G. Salton and M. J. McGill. Introduction to Modern [29] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank [30] http://del.icio.us [31] http://www.youtube.com [32] O. Mcbryan, GENVL and WWWW: Tools for Taming the We b. [33] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch  X olkopf. [34] http://www.dmoz.org [35] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch  X olkopf. [36] http://www.flickr.com [37] http://blog.del.icio.us/ [38] http://www.google.com/ [39] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. La ndauer, and [40] T. Hofmann. Probabilistic latent semantic indexing. In Proc. of
