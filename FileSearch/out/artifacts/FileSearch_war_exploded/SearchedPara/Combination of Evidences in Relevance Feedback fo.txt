 The main objective in XML Retrieval is to select the relevant elements of XML document instead of the whole document. Many open issues appear when considering Relevance Feed-back (RF) in XML documents. They are mainly related to the form of XML documents, which mix content and struc-ture information and to the new information granularity. In this paper, a new flexible method of relevance feedback in XML retrieval using two sources of evidence is described. We propose to use the context criterion to select terms to extend the initial query and to use generative structures to express structural constraints. Both approaches are applied in different combined forms. Experiments are carried out with the INEX evaluation campaign and results show the effectiveness of our approach.
 H.3.3 [ Information storage and retrieval ]: Information search and retrieval X  retrieval models ; H.3.4 [ Information storage and retrieval ]: Systems and Software X  perfor-mance evaluation Measurement, Experimentation, Performance Relevance Feedback, Structure, Context, Combined evidences, XML Retrieval
Whatever the Information Retrieval System (IRS) used, retrieved documents cannot be relevant to the user if the query does not explicitly and clearly describe his/her needs. Relevance Feedback (RF) is an important step in the In-formation Retrieval (IR) process. It consists in enriching the user query in order to express his/her needs in a more expressive way [2]. RF can be seen as a way to personal-ize the retrieval process. It learns the user X  X  interest in a single session by extracting relevant terms from documents judged as relevant. These terms are then added to the initial query [9] [10]. New challenges appear when applying RF in XML retrieval. The character of this type of documents is that they contain both structural and textual information. Queries can be expressed with structural constraints and results can have different granularities ( article, title, para-graph, etc. ). In XML Retrieval, RF was investigated into two main directions: enriching queries with content con-straints (i.e. relevant terms) [7], [1] or context items by specifying the context in which relevant elements can be retrieved) [8], [14]. These approaches were evaluated with the INEX protocol [3] and improvements do not exceed 6%. Our aim is to propose a new approach of RF that considers XML document features. Many open issues arise: Can sim-ple adaptations of traditional RF methods (relevant terms extraction) used in traditional IR be effective to improve the performance of XML retrieval? Should we consider the se-mantics of the tags to extract the new query terms? Indeed, when the structural constraints are not explicitly expressed by the user, results are elements having different granulari-ties. Our hypothesis is that for a given query, some elements are more likely to contain relevant information than others. It has been showed in [4] that for a given query, we can find at least one relevant structure and that the main part of relevant elements are related to 3 types of structures. The question concerns the effectiveness of enriching the query with structural constraints.
 As a consequence, we think that using both sources of evi-dence contained in XML documents (structural and content dimensions) may improve XML retrieval. For this purpose, we propose to enrich initial queries in two different ways: by adding significant terms and relevant structures. The rest of the paper is organized as follows. Section 2 presents our content-oriented RF method based on the con-text. In section 3, we develop the three forms of combined approach. Experiments are presented in section 4.
The approach we propose in this paper is composed of two steps: Term Extraction and Term Selection.
Simple term extraction (without query terms re-weighting) using the Rocchio X  X  algorithm [10] has already been explored in [13] and did not show any improvement. The main ques-tion is still how to extract and to weight the best terms that will be added to the query. Our approach in this paper is in-spired from a known way to do RF, the probabilistic model [9]. We need to select relevant terms according to known elements judged relevant by the user. We thus consider the term relevance as a probabilistic event. Let us consider E as a set of relevant elements; we define the probability of rel-evance of term t i by P ( t i | E r ), and we estimate it according to a simplified version of the Robertson X  X  formula [9]: Where | r e | is the number of elements in E r containing the term t i and R e = | E r | is the number of relevant elements.
The weights assigned to the terms in the first step are somewhat independent of their proximity to the initial query terms. Our objective in this step is to refine the score evalu-ation by considering the context of a term. The term context is a criterion used to evaluate a term in a given element w.r.t the query. It is based on the likelihood of a term to be a main topic, expressed by its relative position to query terms. (i.e. if the term is closely linked to query terms, it has an important probability to be semantically linked to the query context). Therefore, it is measured by its distance from the nearest query term, relative to the average expected distri-bution of all query terms in the document. In this work we adapted term context proposed by [12], originally used to evaluate the relevance of a document w.r.t. a query: here, we evaluate the relevance of a term in a given element to be added to the initial query. distribution e i ( q ) is the expected distribution of all query terms in element e i , assuming terms are equally distributed, | e | is the size of the element e i and Occ ( q, e i )isthenumber of query terms in the element e i , position e i ( t j )istheposi-tion of term t j in element e i and min e i ( t j ) is the minimum difference from any occurrence of term t j to query term t The final function, contextual weight(CW), used to select terms is the product of the weight of term (equation 1) and term context in the set of relevant elements ( E r ): | r | : the number of relevant elements containing the term t .
 The new query is finally composed of the k top terms ranked andweightedaccordingtoequation5whichareaddedtothe original query terms weighted according to equation 1.
We propose to combine the content-oriented approach with a structure-oriented approach [13]. Our structure oriented RF approach consists in refining the initial query by adding structures, extracted from the set of judged elements that could contain the information needed by the user. In our previous work [4], we showed the value of the Structure-oriented approach by using generative structures 1 extracted by the SCA ( Smallest Common Ancestor ) algorithm [13]. Combined approaches consist in adding both content and structure constraints to the initial query. The new query is thus composed of the most appropriate generative struc-tures and of the k terms having the best scores according to formula 5. The question is: are both approaches dependent from each other? or is each approach influenced by results of the other and in which way? In this paper, we propose to combine the content oriented and structure oriented approaches in 3 different ways: we talk about naive, semantic or flexible combination.
In this paragraph we present the most simple form of com-bination that we called  X  X aive combination X . It consists in adding results issued from both the content-and structure-oriented RF. In case of unstructured queries, the selected rel-evant terms are added to the original query terms with their associated weights and are conditioned with the extracted generative structure. In case of structured queries, the se-lected relevant terms are only added to original terms in generative structures. The new query parts are then linked to the initial query with the  X  X R X  Boolean operator.
In this section we propose to take into account the seman-tic of elements from which we extract relevant terms. The idea behind this is that it seems more important to extract terms from elements that are semantically more significant. For example, we consider that the section element is more often relevant than an hypertext link element. It is how-ever difficult to define an importance degree for each type of element, as this degree is related to each query. As a conse-quence,weproposetousetheal ready extracted generative structures. We can restrict th e relevant elements from where we extract the relevant terms to elements being a generative structure: E r res . The terms extraction formula is: This technique can be refined: an other way to introduce the semantic of relevant elements is to consider their structure X  X  scores to extract relevant terms. This score (score(GS)) translates the importance of the semantic of the element from which we extract the term. It is the Generative Struc-ture score calculated according to the SCA algorithm [4].
In this paragraph, we proposed a flexible combination technique which allows to highlight the semantic relation-ship existing between the relevant terms and the relevant
A generative structure is a structure shared by the greatest amount of relevant elements. structures. Our aim is to add a term according to the ele-ments where it appears. Initially, we will express this rela-tionship by a distribution of the selected terms (using the Structure-Oriented RF) according to structure X  X  types. Let us consider the terms: t i , t j and t k and the structures A, B and C. We suppose that the occurrences of terms according to structure X  X  types are summarized in table 1: Table 1: Terms distribution according to the gener-ative structures The idea is to calculate the distribution of a term in the considered structures. The distribution of the term t i ac-cording to the structures is as follows: 2/10, 5/10 and 3/10. We notice that the term t i ismoreofteninastructureof type B. The distribution value allows us to have a score of membership that will be used for the query weighting. In fact, we take into account the size of elements to evaluate the distribution values. The occurrence of a term t i in a structure type A is calculated as follows: Where: N is the number of elements ( e j ) having the A tag in which t i occurs, Occ ( t i ,e j )isthenumberof t i occurrences in element e j and | e j | the size of the element e j .Anewscore is calculated for each extracted terms in each structure: CW ( t i )isthescoreofterm t i according to equation (5). The same idea is applied to original query terms: PW ( t i )isthescoreofterm t i according to equation (1). This method is only significant when we consider at least 2 generative structures. We obtain structured queries in which terms are weighted according t o structural constraints.
Our relevance feedback method is applied on the XFIRM retrieval system [13]. This system is based on a relevance propagation method. We used the well-known INEX 2006 framework [6] to evaluate our RF methods. The reported evaluation scores for each RF submission will measure the improvement of the RF run over the original base run. We use the proposed metrics in INEX 2005 [5]: MAnxCG[i] (average of relative gain the user accumulated up to rank i ) andMAep(uninterpolatedmeanaverageeffort-precision). We use metrics evaluated with generalized 2 quantization. generalized quantization has been used in order to credit document components according to their degree of rele-vance.
 To study the effectiveness of the relevance feedback approaches, we use the Relative Improvement ( RI ) computed as: ( MAP ( RF  X  run )  X  MAP ( Base  X  run )) /M AP ( Base  X  run ) where MAP is MAnxCG[50], MAnxCG[1500] or MAep .We use the freezing method of RF evaluation [3].
We tested the new technique of terms selection (equa-tion 1) and weighting using the context criterion to expand the initial query (equation 5). The experiments consist in adding a varied number of terms from 1 to 10. Runs are designated by Cont-i where i is the number of added terms. Table 2 shows the results we obtained (Relative Improve-ment RI) with the different metrics for structured queries (SQ) and unstructured queries (USQ).
 SQ: base-run 0,1376 0,0427 0,0048 SQ: Cont-1 0,73% 27,40% 31,25% SQ: Cont-2 1,24% 28,34% 31,25% SQ: Cont-4 1,16% 26,23% 27,08% SQ: Cont-6 0,94% 25,53% 25,00% SQ: Cont-8 1,16% 25,53% 25,00% SQ: Cont-10 -4,14% 23,42% 25,00% USQ: base-run 0,1391 0,0284 0,0042 USQ: Cont-1 -0,65% 7,04% 4,76% USQ: Cont-2 -1,15% 4,93% 4,76% USQ: Cont-4 -1,51% 1,76% 0,00% USQ: Cont-6 -1,08% -0,35% 0,00% USQ: Cont-8 -1,37% 3,17% 2,38% USQ: Cont-10 -1,22% -1,76% -2,38%
We notice that the content oriented approach of RF is more efficient to improve the performance of IRS when we consider structured queries (SQ) than when we consider un-structured queries (USQ). In case of SQ, the most important improvements are seen in MAnxCG [1500] and MAep Met-rics when we consider one or two added relevant terms (the improvement is about 30%). These metrics present a gen-eral view of retrieved elements. This note is confirmed on unstructured queries (USQ) but with weak values. How-ever, when comparing results on structured and unstruc-tured queries, it is difficult to conclude on the best number of added terms.
To evaluate the combined approach, we use the context criterion to extract terms (equation 5) and we use the SCA algorithm to extract generative structures. We choose to test the addition of 2 significant terms (it shows an impor-tant impact according to the previous section). We varied the number of generative structures from 1 to 3 in the case of unstructured queries and we test the three forms of combi-nation : Naive (N), Semantic (Sem) and Flexible (F), where S in the run name is the number of added generative struc-tures. Moreover, we test the impact of this approach on structured queries using only one generative structure and we only present two forms of combination. In both cases SQ:N 0,80% 37,70% 66,67% SQ:Sem1(eq. 6) -0,44% 36,30% 62,50% SQ:Sem2(eq. 7) -0,22% 37,24% 66,67% USQ:N-S1 10,21% 110,92% 76,19% USQ:Sem1-S1(eq. 6) 8,84% 118,66% 80,95% USQ:Sem2-S1(eq. 7) 9,99% 115,14% 100,00% USQ:N-S2 9,63% 116,20% 78,57% USQ:Sem1-S2(eq. 6) 8,63% 117,96% 80,95% USQ:Sem2-S2(eq. 7) 9,78% 130,28% 92,86% USQ:F-S2(eq. 9) 6,83% 113,03% 73,81% USQ:N-S3 9,49% 115,14% 78,57% USQ:Sem1-S3(eq. 6) 8,48% 116,90% 78,57% USQ:Sem2-S3(eq. 7) 9,42% 115,49% 78,57%
USQ:F-S3(eq. 9) 9,27% 114,79% 80,95% (SQ and USQ), we evaluate the semantic combination using the 2 equations presented in paragraph 3.2 called Sem1 (eq. 6) and Sem2 (eq. 7). The different forms of combination are compared in table 3.

We notice that the three forms of combination give more important improvements than the content oriented RF. This approach allows an important improvement in case of USQ; RI(MAnxCG[1500]) exceeds 100% while it does not exceed 50% in case of SQ. Therefore, it can be explained by the fact that the addition of structures is more beneficial to USQ than to SQ. If we compare the three forms of combination, we notice that the naive approach is the most effective when we only consider one generative structure. The semantic combination and the flexible combination are the effective when we respectively use 2 and 3 generative structures. This can be explained by the fact that the naive approach keeps all selected terms to be added for one structure and that the other approaches can keep more selected terms when considering different types of structures. In the whole ta-ble, we notice that the semantic approach using the second equation (7) is more efficient than when we use the first equation (6). Moreover, the global metrics (MAnxCG[1500] and MAep) are increasing when we increase the number of added generative structures.
We notice that we can not conclude on what is the suitable number of terms to be added. This can be interpreted like in the literature of traditional IR [11]: the suitable number of added terms is specific to each query. We study the vari-ation of MAep generalized of some queries according to the number of added terms. We notice that for each query, it exists a suitable number of terms to be added (which varies from 1 to 10). Our idea is that the number of suitable added terms depends on the query size. We propose thus to study deeply these queries. As a result, we have noticed that there are no proportionality relationship between the original size of queries and the best number of added terms. However we have noticed that we can find a complementary relationship (for example: 11+3 and 2+9) but it can not be generalized. We plan then to study this aspect in future work. The average of the original results is weak but in reality, the retrieval system can allows a good precision (higher than the best average given in INEX 2006: MAep=0,0384, like for example in the query 331 (MAep= 0,0481)) and our RF approach is still effective (MAep becomes 0,0504).
In this paper, we proposed two new flexible approaches (applied on structured and unstructured queries) for rele-vance feedback: Content-oriented RF and Combined RF. In the first approach, we used the context of relevant terms to extend queries. We then proposed to combine both sources of evidence (content and structure) in the combined RF. We developed 3 forms of combination. Our proposals were evaluated using the INEX 2006 protocol. According to the results we obtained, we notice the effectiveness of the two approaches to extend and to refine the initial query and in particular, the combined approach where the improvements of MAep exceed 50% for the two types of queries.
 In future, we plan to study the variation of the number of added terms to the initial query according to its length. We will also test the effectiveness of our RF approaches in het-erogeneous and multimedia collections.
