 We are interested in the problem of understanding the con-nections between human activities and the content of textual information generated in regard to those activities. Firstly, we define and motivate this problem as an important part in making sense of various life events. Secondly, we introduce the domain of massive online collaborative environments, specifically online virtual worlds, where people meet, ex-change messages, and perform actions as a rich data source for such an analysis. Finally, we outline three experimental tasks and show how statistical language modeling and text clustering techniques may allow us to explore those connec-tions successfully.
 H.3 [ Information Storage And Retrieval ]: General; H.3.4 [ Information Storage And Retrieval ]: Systems and Soft-ware X  performance evaluation (efficiency and effectiveness) ; H.3.3 [ Information Storage And Retrieval ]: Informa-tion Search and Retrieval X  clustering,information filtering Experimentation, Theory Activity Detection, MMORPG, Massively Multiplayer On-line Role-Playing Game, Virtual Worlds
January 12th, 2003. 10:23pm. A giant minotaur Gavron is slain not too far from village Binu in a fantasy world of BladeMistress Online. The monitoring software dutifully recorded the names of six people present at the site of the monster X  X  death. Why was the monster killed? Who else participated in tracking down the minotaur? When did the hunt begin? What are the hunters going to do with the Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. spoils? Can we detect when the next great hunt will begin? Suppose we have the records of everything every inhabitant of the world has said for the last several hours. Could we answer those questions?
February 9th, 2005. 8:01am. Hewlett-Packard issues a brief press release announcing that Carly Fiorina would step down from her role as CEO of the company. By 8:10am the announcement is picked up and broadcast by three major news-wires. Can we predict what effect this announcement is going to have on the stock market? By 8:20am on the same day the Hewlett-Packard stock is trading substantially above its expected price at nearly three times the usual vol-ume. Why is there such a sharp increase in price and trade volume? Could have we predicted the change?
These examples originate in two different worlds but they have much in common. In both cases we have a record of human activities,  X  monster killings in the first example and stock trading prices in the second,  X  and a record of text generated in regard to those (and other) activities,  X  a record of chat messages and a record of news stories on a newswire. Note that both the record of activities and the text records contain the interesting or relevant informa-tion interspersed with non-interesting or non-relevant data, e.g., the chat messages that can be linked to Gavron X  X  death are interspersed with chat messages of players in the other parts of the virtual world and the price of the HP stock is recorded among many others financial indicators. Note also the prominent time factor in each record set  X  we are deal-ing with streams of activities and streams of text. Finally, note that both the activities and the text are reflections of an underlying stream of life events such as all the events in the virtual world in the first example or the real life events in the second. That event stream is the one we would want to study and analyze, but it is never completely observable on its own.

We are interested in the relationships or links that exist between the streams of activities and the streams of text. Analysis of these links could help us to understand the un-derlying events much better than considering each stream independently. For example, retrieving the text linked to an interesting activity would help us to describe the context, we may attempt to answer questions why and how the activity took place. On the other hand, starting with text analysis and knowing how the text can be linked to the activities, we would be able to estimate the effect that text would have on the activities, detect or predict an interesting activity taking place.

Such an analysis will be relevant in any domain that pro-duces a dense stream of well-defined data together with a stream of textual information. Some examples of such do-mains include military, where we have the records of battle-field activities collected from various sensors and the record of command net chatter; political, where the poll results are interdependent with news stories from various sources; ed-ucational, where we have links between the content of the chat messages exchanged by a tutor and his students in a remote tutoring chat room and the test scores of the stu-dents; and user interfaces, where the text presented on the screencanbelinkedwiththeapplicationactivity.

This paper has three following contributions: 1. We have outlined and motivated the problem of anal-2. We are interested in using statistical techniques to an-3. We describe three experiments we conducted using the
Information Retrieval, specifically, search deals with re-trieving documents that are topically-similar to a user query from relatively static collections. Topic Detection and Track-ing (TDT) focuses on locating and following interesting top-ics in a continuous and constantly changing stream of stories. Data Mining (DM) and Information Extraction (IE) focus on extracting well-defined properties or features of entities from static collections. In this paper we explore another re-search area that deals with analyzing a continuous stream of textual information that is linked to a parallel and also continuous stream of data (see Table 1). Table 1: A comparative classification of text-related research fields. The problems we discuss in this pa-peroccupythebottomrightcornerofthetable.
 In the domain of Language Grounding and Situational Language researchers focus on relating language to the phys-ical world. They study how language understanding and language learning is connected to every day activities and human ability to perceive and explore the world. They at-tempt to build machines that can converse about what the observe and do [12]. More than three decades ago Winograd demonstrated the importance of integrating world models with language planning and understanding [14]. Some more recent applications of these techniques include automatic report generation from sensory data [11], natural language interfaces to robots [7], and location-dependent web-search queries.

The knowledge of how the words and actions link together makes possible development of successful language training systems. Johnson and his colleagues [6] created an interac-tive virtual environment that simulates student X  X  presence in a foreign country. The students hear and read new words together with both observing and performing actions in the simulations. On the other hand, computers also can ben-efit from a clearly defined link between words and actions. For example, Fleischman and Hovy [5] studied a virtual en-vironment where users converse with computer-generated characters. They demonstrated that taking into account the situational context  X  predicting what kind of language the system should expect from the user based on the current state of the virtual world, the user X  X  task, and her progress through the task,  X  may significantly improve system X  X  nat-ural language understanding. In other words, the system predicts the content of the text stream from the content of the action stream.

Most of the current research deals primarily with one-on-one interactions where either two humans talk to each other or a human converses with a robot or a character in a virtual world. We are interested in analyzing text and activity dependencies in large collaborative environments where multiple people organize, perform actions together, and exchange information regarding those actions. Another difference of our approach is the focus on a large scale sta-tistical techniques for information analysis as compared to more knowledge-intensive approaches employed in Language Grounding. A MMORPG (Massively Multiplayer Online Role-Playing Game) is an online computer role-playing game in which a large number of players can interact together or against one another in the same game at the same time. An MMORPG follows a client-server model in which players, running the client software, are represented in the game world by an avatar  X  this is usually a graphical representation of the character they play. Providers, usually the game X  X  publisher, host the persistent worlds these players inhabit. This inter-action between a virtual world, always available for play, and an ever-changing, potentially worldwide stream of play-ers characterizes the MMORPG genre [13].

Once a player enters the game world he or she can engage in a variety of activities with other players ranging from chat with their friends or guild members to teaming up in order to kill large enemies or to complete complex tasks or quests that are not achievable alone. Killing these enemies (typically referred to as mobs by gamers) yield the players experience points and equipment or loot such as armor and weapons. Both the experience points (used to  X  X pgrade X  the character or his abilities) and the loot gained from slay-ing mobs, help to improve the character so he can handle fighting in more adverse situations.

Players interact with each other using both the textual chat and through the avatar actions. Some more advance games have elaborate avatars that may represent a wide variety of gestures and emotions.

MMORPGs (sometimes the term Virtual Worlds is also used) are immensely popular, with several commercial games reporting millions of subscribers. Some analysis suggests that there are at least 35-40 million MMORPG subscribers around the world [15]. The demographics analysis con-ducted by Lee [16] shows that 40% of the subscribers are spending more than 20 hours per week on-line.

Most of the virtual worlds have well-developed economy rules. Players collect or purchase resources, produce items such as swords or magic potions and sell those items to other players. Castronova [2] did a thorough economic analysis of the game called EverQuest and concluded that the vir-tual goods (items, loot, experience points, etc) produced by the players have a noticeable monetary value and can be exchanged for real-life money at places such as eBay ( http://www.ebay.com/ ), ige ( http://www.ige.com/ ), etc. His analysis showed that the players generated quite signif-icant $2,266 per capita yearly. The currency exchange rates for the most popular games can be found on the web [4]. We give such an extended introduction into the domain of MMORPGs to highlight two important points: First, mas-sive multiplayer online games are a very serious human ac-tivity. This activity is primarily recreational, but it does not make it less serious. A significant number of people spend-ing a significant amount of time living these games and po-tentially accumulate a noticeable amount of wealth doing so. We expect that as technology develops, these games are going to attract more and more participants. We also ob-serve the appearance of non-recreational virtual worlds, i.e., games oriented towards learning. Making sense of the things that are happening in these environments is becoming a very important task.

The second point is that these on-line games are a very good model of social processes existing in the real world. We have a massive record of what people were saying, who said what, where they said it, when, and what they were doing at that moment. Statistical analysis of this data creates exciting opportunities and novel challenges to the field of Information Retrieval.

We continue the paper by introducing a collection of logs from one of the small MMORPGs. We define three ques-tions that we investigate on that collection: we study how well we can detect a presence of a particular player activity from the content of their conversations; we establish who of the players participated in the activity; and we consider how the topic of a players X  conversation depends on their geographic location in the virtual world. We describe our experiments, present the results of our analysis and conclude the paper with an extensive outline of possible direction for future work.

Our experimental data comes from BladeMistress ,asmall non-profit low-bandwidth fantasy-oriented MMORPG. As in much larger virtual worlds, this game has players collect-ing resources, exploring the world, killing dragons and other monsters, practicing magic, trading items and stories. The player avatars move around in a 3D virtual world which is divided into squares. Our data includes both chat and game logs from September 2002 to August 2003.

The chat log is the record of all chat messages exchanged in the game. Each message is tagged with the time of the message (with one second resolution), the grid coordinates of the speaker, the speaker name and the message addressee. There are several different modes of messaging that deter-mine who is going to see it: a player can broadcast the message to the whole world, limit its scope to players in the same square, direct the message to a specific player or to a group of players.

The game log records a single game activity  X  players killing monsters. Each activity is tagged with its time (with one minute resolution), the name of the monster and the names of the people present at the same square at the mo-ment of the kill.
As we discussed in the introduction, the goal of this work is to understand the connections between collaborative ac-tivities of players in a social environment and messages they exchange in relation to these activities. In this section we will attempt to turn this informal description into a mathe-matical formalism which will ultimately guide us towards a solution.

We start by describing the observable variables. Our data consists of a set of messages {M i : i =1 ...N M } and a set of activities {A j : j =1 ...N A } . Each message M is represented as a tuple { W, X, Y, T , S, R } .Here S and R represent the sender and recipient of the message; both are discrete ran-dom variables taking values in V  X  , the list of known players. V  X  may also include special values representing groups of players, such as  X  X veryone X  . X, Y and T are integer-valued variables representing the location and the time when the message was produced by the sender S .Finally, W is a sequence of words representing message content, each word being a discrete random variables drawn from the vocabu-lary V w . An activity A is a tuple { A, X, Y, T,  X  } , where A represents activity type (e.g. a  X  X onster kill X  ), taking val-ues in a discrete set V a . As before, X, Y and T represent the time and location of the activity. When the activity is stretched is space and time, we assume that X, Y, T marks an important event, such as the moment when the monster died.  X  represents players directly involved in the activity, it is a set of discrete random variables drawn from V  X  .Note that it is possible to extend the framework to model the role of each participant in the activity. While straightforward, such extension is beyond the scope of this paper.
The aim of our research is to discover hidden  X  X onnec-tions X  between the messages M i and observed activities A We will attempt to capture these connections by construct-ing statistical language models for the various activity types. We can then use these language models to tackle a wide ar-ray of mining and discovery problems. We are particularly interested in addressing the following tasks: (A) Activity detection. Suppose we cannot observe ac-(B) Player forensics. Suppose we know the time when (C) Investigative search. Givenaninstanceofactiv-(D) World mapping. Given all messages from all play-Beyond the four tasks suggested above, one could certainly define other problems that would become feasible if we had an accurate model of what type of language is likely to be associated with specific activities. The scope of this paper will be limited to tasks (A), (B), and (D). While we are very interested in addressing (C), the absence of relevance judg-ments makes this task difficult to evaluate quantitatively and we leave this task for future work. In the following two sections we will describe our approach to constructing activity-specific language models and will discuss their per-formance on tasks (A) and (B).
We processed the chat log by removing non-ASCII charac-ters and empty messages, and normalizing the time stamps of the messages and the log format  X  the original log for-mat showed some variations over the collection time period. We have a chat log of 5,514,173 messages that take approx-imately 310MB of disk space. There are 284,728 unique terms in the vocabulary and 19,144 unique login names.
In the game log we normalized the timing of the activ-ities to synchronize it with the chat log. We do not have up-to-a second accurate information from the game log, so we assume that each kill happens at the last second of the recorded minute. We also tag each record with an approx-imate location of the activity. We consider the recent lo-cations of each player present at the kill from the chat log,  X  locations of all the messages from the players in the pre-ceding minute,  X  and average those coordinates. There are 447,874 monster kills recorded. Some monsters are stronger than others and require more people getting together to suc-ceed at the task. Such activities are more interesting to us because they potentially require a more elaborate and in-tense discussion among the players. Figure 1 shows the plot of the number of individual activities as a function of the number players involved. We focus our attention only on the activities with at least three players involved that makes it 16,337 recorded kills.

We divided the data into training and testing sets at mid-night of June 1st, 2003. We completely excluded a day full of data (May 31) to avoid contaminating the test set. Table 2 shows the size of the testing and training sets.
In the activity detection task, we are given a testing col-lection of messages {M} and asked to guess the time t and location x, y of all activities of a given type a .Wedonot have to predict the participants of each activity, and further-more we will assume that the training set will not include Figure 1: Shows the distribution of number of kill activities as a function of the number of people present. The plot is drawn on logarithmic scale.
 # of kills with at least 3 people 12,129 4,174 Table 2: The size of the training and testing subsets. We show the number of kills with at least 3, 5, and 7 players present. any information about the participants. This is done in-tentionally, because in many non-virtual domains we will not know who participated in the activity of interest. How-ever, our training data will include a set of training messages M 1 ..m and a set of activities A 1 ..n with known times and locations.
 We approach the problem of activity detection as follows. First, we cluster the training and testing messages into a set of groups G xyt by their proximity in space and time. The exact grouping procedure is described below. Then we use the training groups to estimate language models P a ( specific to each activity a . Finally, for each testing group we determine whether it is more likely to be a sample from activity-specific language model P a (  X  ), or from its opposite P  X  a (  X  ). We evaluate the quality of our models using the standard signal detection methodology.
We are given a set of training messages M 1 ..m and a set of training activities A 1 ..n . Our goal is to construct a model of language associated with all activities of a given type, e.g. a monster kill. The difficulty comes from the fact that even when messages and activities are fully observable, we do not know which messages are related to which activities. To re-solve this problem, we are going to consider spatio-temporal proximity of messages and activities. We are going to as-sume that all messages M i that are generated in a small radius around the activity A i and around the same time are relevant to that activity. Upon close examination of the data we must admit that the assumption is false. There will always be bystanders  X  players that happen to be in the immediate vicinity of the activity without participating in it. Even more frequently, activity participants will exchange messages on topics that are not directly related to the ac-tivity. Occasionally there may also be remote participants  X  players who incite or coordinate the activity without being physically present at the site. Nevertheless, assuming that allnearbymessagesarerelevanttotheactivityisnoten-tirely unreasonable. First, from a brief analysis of our data a large proportion of nearby messages do appear to be rel-evant. Second, when we estimate activity-specific language models we will average word probabilities over a large num-ber of activities of the same type. We hope that words that come from genuinely relevant messages will occur time after time, whereas words that come from unrelated messages will be different every time and their statistics will  X  X ash out X .
For a given activity type a , we estimate the corresponding language model in the following fashion. First, we aggregate the messages M 1 ..m into a set of groups G indexed by time and location: Where the function g ( x )=  X   X  x/ X  quantizes its argument to a given granularity  X  . We use separate  X  for space and time dimensions. The groups are arranged in such a way that they overlap by half along each dimension, so every mes-sage falls into 2 3 =8 distinct groups. Forcing the groups to overlap helps us to avoid boundary effects where an activ-ity and a nearby message fall into different (neighboring) groups. After constructing the groups, we label them with activities that happen within the time-space region corre-sponding to the group, so that a  X  L xyt if and only if there is an activity A j of type a such that g ( X j )= x, g ( Y j g ( T j )= t . Once all the groups are labeled, we construct activity-specific word counts as follows: Here the first summation goes over all groups k labeled with activity a , and the second summation computes the total number of times the word w occurred in all messages falling into group k . After we have word counts for all activity types, we estimate the activity-specific probability of ob-serving the word w as: P a ( w )=  X  2 N a ( w ) Here  X  is the smoothing parameter, which was set to 0.9 in our experiments. N  X  a ( w ) represents the overall count of w in groups not labeled by a ,and |V w | is the vocabulary size. Equation 3 is a variation of Jelinek-Mercer smoothing [18], which is widely used in the language modeling literature. The main difference is that back-off is performed twice: first to the non-relevant counts N  X  a ( w ) and then to the uniform distribution 1 |V w | . The second step is necessary because we need to allocate non-zero probability mass to words that do not appear in any training messages.
In this section we describe how we can predict the times and locations of activity a using the activity-specific lan-guage model P a (  X  ) derived in the previous section. Our pre-dictions will be based on the time, location and content of testing messages. First, we aggregate the individual test-ing messages M i into groups G xyt employing exactly the same procedure that we used to cluster the training mes-sages (equation 1). Then, for each testing group G xyt we perform the likelihood ratio test: Likelihood ratio is a standard procedure for testing statis-tical hypotheses, and in this case is closely related to the well-known Naive Bayes classifier [10]. The numerator in equation (4) represents the likelihood that all messages in group G xyt are i.i.d. random samples from the activity-specific language model P a (  X  ). Similarly, the denominator gives the likelihood of observing G xyt as a random sample from P  X  a (  X  ), the language model not associated with activ-ity of type a . Large values of equation (4) indicate that the language of messages around time t and location x, y closely resembles word statistics associated with activity a , and al-lows us to hypothesize that activity a took place around this time and location. Conversely, small values of the likelihood ratio indicate that most likely activity a did not take place around x, y, t .
If we set a decision threshold  X  over the likelihood ratio and take all tuples x, y, t that scored above  X  as positive, we will get a fixed set of hypotheses ( { H  X  } ). We can then compare { H  X  } against the ground truth  X  the set {A} of activities that are known to have occurred in the testing set. Comparison can be carried out with many different metrics, for example average distance to the true activity, binary accuracy, etc. We are going to adapt signal detection methodology and use True Positive and False Positive rates as our evaluation measures. True positive rate (TP) is the proportion of real activities that were correctly identified in our list of hypotheses. False positive rate (FP) is the proportion of non-activity locations that were erroneously included among the hypotheses. Formally the measures are defined as: Different settings of the decision threshold  X  will lead to different true positive and false positive rates. In general, different users exhibit different tolerance to false alarms, and consequently prefer different thresholds. A common way to evaluate performance for all users is through a Receiver Operating Characteristic (ROC) curve, which graphically shows a tradeoff between true positive and false positive rates for all possible settings of the decision threshold  X  .
Figure 2 shows ROC curves for the task of detecting signif-icant activities from the message content. In this case the ac-tivities we are detecting represent monster kills involving at least 3, 5 or 7 participants. Kills involving many participants are rare, but also more interesting because of the extensive collaboration required for success. Messages and kills were aggregated into regions covering 6x6 squares on the map and spanning 10 minutes. From looking at the ROC curves we immediately see that the system is substantially more accurate in detecting larger kills (7 participants), achieving an impressive 90% true positives with a false alarm rate of 10%. For users requiring higher levels of recall, the system would be able to cut the monitoring costs in half (50% false positives) while retaining 98% of true positives. Detection Figure 2: ROC curves for detecting a monster kill by analyzing message content. The system is more accurate on kills involving more players, achieving 90% recall with a 10% false positive rate. square size 3-person kill 5-person kill 7-person kill time span Table 3: Accuracy of the detection system for differ-ent square sizes and time spans. Numbers represent the area under the corresponding ROC curve. The system is generally more accurate for small square sizes and longer time spans. However, detection on short (3-minute) time spans is not significantly worse. accuracy is somewhat lower for kills involving fewer partic-ipants, yielding 60% and 80% true positives at 10% false alarm rate for kills with 3 and 5 participants respectively.
An attentive reader may wonder how sensitive the system is to the way we aggregated messages into groups. Using a resolution of 6x6 squares and 10-minute intervals may not provide sufficient resolution for some applications. In table 3 we show how detection accuracy varies with the square size and time span. The numbers reported represent the area under ROC , which is a single-number measure commonly used to evaluate the quality of an ROC curve. The table suggests that our system is more accurate on smaller square sizes and longer time ranges. This means that the system will be able to pinpoint the location of a hypothesized ac-tivity, but may not be very accurate about the time when that activity will take place. However, detection accuracy is still very respectable on shorter time intervals, particularly if we are concerned with detecting larger kills. Figure 3: ROC curves for detecting the players in-volved in a monster kill. The system achieves simi-lar performance detecting participants of 3-, 5-, and 7-person kills.
We now turn our attention to the second task defined in section 3. This time, we are given a time and location of a particular activity of interest, but we do not know the play-ers who were involved. We are also given a set of all messages observed within the same time span when the activity was recorded. We know the sender of each message, but do not know the location where the message was sent from. Our goal is to figure out which players participated in the activ-ity by analyzing the content of their messages. We approach this problem in the same manner as activity detection. The main difference is that this time we are not provided with message coordinates (if we were, the problem would become trivial). We aggregate all messages from a given player in a given time span, then label as positive the groups that correspond to activity participants. We use labeled training groups to estimate activity-specific language models as de-scribed in section 5.1. After the models are computed, we compute the likelihood ration (equation 4) for every player group in the testing set. We evaluate the detection accuracy using ROC curves as described in section 5.3.

Figure 3 shows performance of the system in identifying participants in 3-, 5-, and 7-person kills with the time span of 10 minutes. The results are pool-averaged over all players and all time spans containing a target kill. The overall per-formance is noticeably lower than what the system achieved on the activity detection task. However, performance is still substantially above the random baseline, and the higher false alarm rates may be tolerable due to a smaller overall number of negatives in this task. Another interesting obser-vation is that detection accuracy appears to be insensitive to the size of a kill in question  X  the ROC curves for identi-fying participants in 3-person and 7-person kills are almost the same. Table 4 shows how much performance is affected by varying the time span around the activity. The num-bers represent the area under the corresponding ROC curve and suggest that the system identifies participants most ac-time span 3-person kill 5-person kill 7-person kill Table 4: Accuracy of participant detection for differ-ent time spans. Numbers represent the area under the corresponding ROC curve. The system is gen-erally more accurate when provided with a longed stretch of messages from a particular player. Table 5: Precision at different ranks in a sorted list of hypothesized activity participants. curately when given longer spans of messages from a user. However, performance is reasonable for time spans as short as 20 seconds.

The task of finding activity participants can also be viewed of as a ranked retrieval task  X  in some settings the goal may be to quickly find a few obvious participants, and then use additional information gained from them (e.g. alliances, guild membership, friend lists) to identify the remaining par-ticipants. In such precision-oriented setting, it would be appropriate to rank the hypothesized participants by the likelihood of their involvement and evaluate using precision at different ranks. Table 5 shows precision at ranks 5-100 for ranking hypothesized participants of 3-,5-and 7-person kills. We observe very high accuracies for 5-and 7-person kills: out of the top 100 hypotheses over 75 times the player in question was actually involved in a kill. The precision is somewhat lower for 3-person kills, especially at the very top of the ranked list. Overall, table 5 suggests that our system may be used to rapidly identify a few players involved in an activity of interest.
In the last set of experiments for this paper we explored dependencies between the content of the chat messages and the speaker locations in the virtual world. Our goal was threefold: first, we wanted to see if the message content is linked to the speaker location; second, we were looking to discover and map out interesting areas of the world; and finally, we were interested whether the content of the textual clusters would allow us to understand and characterize those areas.

We clustered the world locations based on the content of the messages originating from those locations. Specifi-cally, we segmented the virtual world into half-overlapping squares of size 2  X  2. For each segment we aggregated all chat messages from all players that originated from the location included into the segment G xy = { M i : g ( X i )= x, g ( Y We then computed a language model for that text aggre-gate using Equation 3. The smoothing parameter  X  was set to 0.9. We calculated the pair-wise distances between the language models and the corresponding segments using a symmetric version of Kullback-Leibler divergence [17, 8]: where D ( G i ,G j ) is the content-based distance between two world locations i and j and P i ( w )and P j ( w ) are the corre-sponding language models.
 We clustered the segments using the Ward algorithm [9]. Each cluster includes a number of locations and defines a region in the virtual world. The clusters can be naturally visualized on the world map. Figure 5 shows 7 clusters of the message content. We terminated the clustering algo-rithm when 100 clusters were produced, selected six largest clusters, and merged the rest into the seventh miscellaneous group. The clusters are labeled with numbers from 0 to 6 and each cluster is assigned a unique color starting from red for the largest cluster ( X 0 X ) to purple for the miscellaneous one ( X 6 X ). The color legend is at the top right corner of the picture. We also show the locations of the towns (squares) and the monster killings which involved five or more players (circles). For comparison Figure 4 shows the actual physical map of the virtual world.

The white color areas correspond to the locations with no messages. Comparing that area to the world map we see that is the area covered with the river and the ocean.
The first thing to notice is that the clusters seems to have well-defined borders and occupy distinct regions of the world. For example, cluster 1 (yellow color) almost com-pletely covers the top-right quadrant and cluster 4 (light-blue) primarily occupies the center of the map and the very top-right corner. There is also a good correlation between the cluster location and geographical features of the virtual world. For example, cluster 3 (cyan) is spread along the river and ocean shores and cluster 5 (dark blue) covers the mountain region at the top of the map.

We were surprised by the almost perfect square shape of cluster 1 (yellow). From the description on the game web site we determined that the game world has an underground realm called the  X  X pirit realm X . The coordinates in the spirit realm are mapped to the top-right quadrant of the map and killings represented by circles. it is not clear from the logs whether the author of a chat message is located on surface of the world or underground.
We observed a good correlation between the locations of monster killings (circles) and cluster 4. Indeed, the signifi-cant number of circles co-occurs with the light-blue shaded squares.

We explored the content of the clusters by looking at the most representative terms from each cluster. We used the clarity score [3] to calculate individual word importance in the clusters:
Sc ( w )= P ( w | C i )log P ( w where P ( w | C i ) is the probability of the word w occurring in cluster C i , P ( w | C ) is the probability of w occurring in the whole collection, and N C i ( w )and N C ( w ) represent the over-all count of w in cluster C i and collection C . We processed the resulting list of terms to remove all words shorter than 5 characters, standard stopwords, adverbs, and adjectives.
Table 6 shows the top best terms for clusters  X 0 X ,  X 1 X ,  X 3 X , and  X 4 X . It is easy to notice that cluster 4 is described by the  X  X ighting X  words such as dodge, attack, fight, killed, dodging, health, killing . On the other hand, cluster 3 that occupies the river region contains words river, water, cross, island, bridge and names of several towns at the bottom of the map. The top words from cluster 1 include the name of the spirit realm and the names of the monsters that in-habit it. Meanwhile, cluster 0 (the largest cluster)seems to deal with exploratory game activities, i.e., looking, tokens, coords, coming, quest .
These are our first experiments with the MMORPG do-main. We see several possible improvements for the current study and many research questions (ranging from text pro-cessing to other activity detection and player classifications) remain open.

In Section 5 while constructing the language model we considered chat messages from all players that appear in the time-space block surrounding the monster killing. By this definition the language model picks up chat messages both from the players involved in the killing activity and those that are not. A more accurate solution would be to consider only chat messages coming from the players that actually killed the monster. It should result in a more accurate esti-mation of the language linked to the activity and potentially in better detection results. We believe that the presented Table 6: Top best terms in some of the largest clus-ters. approach works well on our data because BladeMistress has much fewer players online at the same time comparing to such popular titles as World of Warcraft.

Our model of time and space dependencies was quite sim-ple  X  we segmented the time and the space into blocks with well-defined boundaries and all words collected from the chat messages inside those blocks had the same weight. We plan to investigate more elaborate models of those dependencies. Forexample,wemayconsiderthewordsthatoccurinclose proximity to the activity to be more important than those that occur at some distance. We can use a bell-shaped weighting function on the word probability estimations in the language models.

We observed that the language of chat messages is rather different from the traditional well-formed text we can ex-pect from newspaper articles or web pages. Messages are very reach on typos, acronyms, and domain-specific lexicon. They are informal and ungrammatical. Often important and unusual information is expressed using punctuation charac-ters, e.g., the author X  X  emotion is conveyed with the emoti-cons. It is clear that traditional text processing techniques such as stemming will not be successful without significant effort on adapting them to this environment. Even the pro-cess of word tokenization is an open question.

Our exploration was mostly data-driven by the available data set. We studied various activity dependencies on the content of the chat messages. This is because the truth judgments for the kill activities are readily available from the game log. The other potentially very interesting set of questions is to consider how messages depend on activities. For example, imagine a game historian who is interested on how a particularly big and strong monster was slain. She has to start from the records of the kill and then collect all chat messages that relate to the event. These messages would include the dialogs of the first few people getting to-gether, how they decided to go and kill the monster, how they invited other players, and so on. Suppose we build an automatic system that extracts the relevant chat lines. Evaluating such a system requires a significant effort in man-ually annotating the messages. Note that simple strategies for obtaining the relevance judgements such as considering relevant all the messages from the participating players in the immediate proximity to the activity would not work be-cause the players join and leave the hunting party at different times and locations. We consider the manual annotation of the relevant messages for future work.

We only have one type of players X  activity recorded in our data set  X  monster killings. While this activity is impor-tant to the game process, we are also interested in analyzing other activities, e.g., quests, item exchange, goods trading, resource farming, tutoring of new players, etc. Such an anal-ysis may require an extensive annotation effort. However, we can automatically detect when several players meet and stay together for a significant period of time. We hope that such gatherings are noticeable events in the players X  life and carry important meanings. We may attempt to cluster the conversations that happen during those meetings, e.g., to isolate when people trading items from the cases when one player coaches another.

Another area of analysis that remains unexplored is the classification of players. Suppose you meet an unknown per-son in the virtual world and start chatting with her. How quickly can you estimate her level of experience? Can you detect if her statements are truthful? Is she likely to be helpful? Friendly? To setup such an experiment we can ap-proximate the skill of each player by analyzing the time she spent on-line and the number of activities in which she has participated. Or, estimate how many game friends she has by the number of one-on-one conversations.

Bartle [1] did an extensive analysis of player types and concluded a successful game attracts four major types of players: achievers (people who strive to improve their play-ing skills and their avatars, explorers (the ones who tend to explore the world and discover hidden treasures), socializes (who come into the world primarily to meet other players and interact with them), and killers (who focus on killing the monsters and other player). We hypothesize that the players of different types will have distinct language patterns. We plan to construct individual language models for the players, cluster them, and attempt to verify his statement.
In this paper we outlined and motivated the problem of analysis of relationships between a stream of activities and text generated in regard to those activities. We discussed how this problem applies to various domains and relates to the other areas of IR. We introduced the domain of Massive Multiplayer Online Games as a testbed for developing tech-niques for such an analysis. One of the motivating factors for exploring such a domain was access to a sufficiently large collection of records for both the players X  activities and the chat messages they exchanged in the game.

We described three experiments we conducted using the data from one of the MMORPGs. Firstly, we established that we can effectively detect the location and time of an interesting activity that involves a sufficiently large number of participants solely from the content of the chat messages produced by the players. Secondly, we showed that we can effectively determine some of the participants in the activity by analyzing the message content, however detecting all of the participants proved to be a difficult task. Finally, we conducted an exploratory analysis of the spatial layout of the virtual world using the topics of inter-player conversations and discovered some interesting facts about the world.
For our analysis we used a modified version of a statistical language modeling approach developed for other IR appli-cations. Our primary goal was to explore how well these techniques can be transferred to a completely new domain and also establish where the existing modeling approaches break down. The final contribution of this paper is the out-line of potential directions for exploring both the modeling approach and the experimental domain in the future.
The project or effort described here has been sponsored by the U.S. Army Research, Development, and Engineer-ing Command (RDECOM). Statements and opinions ex-pressed do not necessarily reflect the position or the policy of the United States Government, and no official endorsement should be inferred.

This work was supported in part by the Center for Intel-ligent Information Retrieval and in part by the Defense Ad-vanced Research Projects Agency (DARPA). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessar-ily reflect those of the sponsor. [1] R. Bartle. Designing Virtual Worlds . New Riders [2] E. Castronova. Virtual worlds: A first-hand account of [3] S. Cronen-Townsend, Y. Zhou, and W. B. Croft. [4] P. Dhingra. MMO markets. [5] M. Fleischman and E. Hovy. Taking advantage of the [6] W.L.Johnson,H.Vilhjalmsson,andM.Marsella.
 [7] J. Juster and D. Roy. Elvis: Situated speech and [8] V. Lavrenko, J. Allan, E. DeGuzman, D. LaFlamme, [9] A. Leuski. Evaluating document clustering for [10] D. D. Lewis. Naive (Bayes) at forty: The [11] J. Robin and K. McKeown. Empirically designing and [12] D. Roy and E. Reiter. Connecting language to the [13] Wikipedia. MMORPG  X  Wikipedia, The Free [14] T. Winograd. A process model of language [15] B. S. Woodcock. An analysis of MMOG subscription [16] N. Yee. The Daedalus project. [17] C. Zhai. Risk Minimization and Language Modeling in [18] C. Zhai and J. Lafferty. A study of smoothing
