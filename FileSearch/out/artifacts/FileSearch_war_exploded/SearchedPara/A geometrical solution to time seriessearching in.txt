 REGULAR PAPER Mi Zhou  X  Man-Hon Wong  X  Kam-Wing Chu Abstract The technique of searching for similar patterns among time series data is very useful in many applications. The problem becomes difficult when shifting and scaling are considered. We find that we can treat the problem geometrically and the major contribution of this paper is that a uniform geometrical model that can analyze the existing related methods is proposed. Based on the analysis, we conclude that the angle between two vectors after the Shift-Eliminated Transfor-mation is a more intrinsical similarity measure invariant to shifting and scaling. We then enhance the original conical index to adapt to the geometrical proper-ties of the problem and compare its performance with that of sequential search and R  X  -tree. Experimental results show that the enhanced conical index achieves larger improvement on R  X  -tree and sequential search in high dimension. It can also keep a steady performance as the selectivity increases.
 Keywords Information search and retrieval  X  Similarity search  X  Spatial indexing  X  Time series database 1 Introduction Generally, a time series is a sequence of real numbers. The technique of searching for similar patterns among time series data is very useful in a wide range of appli-find all companies whose stock price sequences are similar to a given one in shape to predict future trends. Moreover, time series searching is also essential for time series data mining tasks [ 4 ] such as clustering, classification, and rule discovery. The first one is whole matching. Given a query sequence Q and a set of data sequences S ={ S 1 ,..., S N } , each of the data sequence is of the same length with Q , all data sequences S i ( 1  X  i  X  N ) that are similar to Q are reported as the query result. The other one is subsequence matching. Given a query sequence Q and a much longer data sequence S , all subsequences of S with the same length of Q and similar to Q are reported as the query result. However, we can always convert subsequence matching into whole matching by sliding a window of the same length as query sequence along the data sequence. The subsequence in the window will be matched with Q as in whole matching. We consider only whole matching problem in this paper.
 the time series searching problem. Many similarity measures have been proposed, among them, Euclidean distance is the most popular one. Given two sequences X ( x as Note that what we are really concerned with is the shape of time series which is invariant to offset shifting or even amplitude scaling. If we simply use Euclidean distance as the similarity measure regardless of these transformations, we may ob-tain very counter-intuitive results. In the following example below, we show how shifting and scaling (for brevity, we refer scaling to uniform amplitude scaling) affect the sequence similarity.
 Example 1 In Fig. 1 , two sequences are shown. They are A ( 5 , 10 , 6 , 12 , 4 ) and B ( between them is 28 . 57, they are closely related. B can be obtained from A by scaling it up 2 times then shifting it up 5 units. That means they are actually the same after applying suitable scaling and shifting transformations.
 mations. In [ 22 ], the authors propose a general idea that sequence A is similar to B if A can be transformed to B by a series of pre-defined transformations. Each transformation applied incurs a cost, and the total cost is used to measure the dissimilarity between A and B . Based on this framework, several similarity measures have been proposed that are invariant to shifting and scaling. A widely used method is the normalization method proposed in [ 20 ]. Given a time series S ( The resulting sequence is called the normalized form of S . The Euclidean distance between the two normalized sequences is used as the similarity measure. Consider showninFig. 2 . In this example, A is already normalized, B is normalized to B 1 by shifting it down 3.6 units then scaling it down 1.8547 times. The Euclidean distance between A and B 1 is 1.966.
 In [ 12 ], another similarity measure is proposed, in which shifting and scaling are applied only to one sequence, say B . The minimum attainable distance between A and B is defined as the similarity measure. The method proposed in [ 12 ]tothe same sequences A and B are shown in Fig. 3 . B is transformed to B 2toobtain the minimum distance, and the value is 1.766, which is less than the distance in the normalization method. This method is different with the normalization method in the sense that the optimal shifting and scaling are used. Obviously, it is not effi-cient to find the minimum distance by brute-force checking for all possible shifting offsets and scaling factors of B . Instead, by using a geometrical model, one can determine the optimal scaling factor and shifting offset directly. In this example, tively. However, as pointed out in [ 27 ], this similarity measure is not symmetric. The minimum distance between A and B may be different from that between B and A . In particular, in the previous example, the minimum distance obtained by transforming A is 3 . 276 = 1 . 766 . The authors of [ 27 ] then propose using the smaller value of the two minimum distances as the similarity measure so that the new definition of similarity is symmetric.
 related. In this paper, we extend the model in [ 12 ] and provide a more general ge-ometrical model to explain the three similarity measures. We find that they are all distance based and do not capture the essence of time series similarity in the con-text of shifting and scaling. We then propose an angle-based similarity measure, which is symmetric and invariant to shifting and scaling.
 ometrical model and some background knowledge about vector manipulation in Sect. 2 . Based on the model, the three distance-based methods are analyzed in index to index data using the proposed similarity measure is discussed in Sect. 5 . The performance of conical index is investigated in Sect. 6 . In Sect. 7 , the related work is summarized and, finally, a brief conclusion is given in Sect. 8 . 2 Geometrical model of the problem 2.1 Geometrical view of the problem Our model is based on vector geometry, some basic properties about vector ma-nipulation are listed in the appendix. Generally, a time series of length n can be regarded as a multi-dimensional point in n . A point can also be represented by a position vector in n . Therefore, for the rest of the paper, we will regard time series, points, and vectors as the same.
 ( scalar X  X ector multiplication, i.e., if vector u is scaled by a factor a , it becomes a u . Geometrically, the set of all possible scaling of u can be represented by a line scaling line of u .Itisthelocusof u when u is scaled by all possible factors a  X  . formation is degenerate, i.e. all items of the sequence become zero. When a &lt; 0, the sequence is amplitude scaled followed by reflecting with respect to the time axis. This will change the shape of sequence greatly. Therefore, the scaling factor is restricted to be a positive real number from now on.
 (v the standard basis of n , denoted by e 1 ,..., e n .The shifting vector of n is regarded as: v + b N ( n ) ,where b  X  . In the following, N will be used instead of N ( n ) where n is understood. Geometrically, the set of all possible shifting of v This line, Line sh , v , is called the shifting line of v .Itisthelocusof v when v is shifted by all possible offsets b  X  .
 [
R +  X  R ] , the set of all possible resulting vectors can be represented by a half b N ,( a , b )  X  X  R +  X  R ]} . This plane is called the scaling X  X hifting plane of u .It is the locus of u when u is scale-shifted by all possible factors and offsets. The scaling line, shifting line, and scaling X  X hifting plane are depicted in Fig. 4 . 2.2 Shift-Eliminated transformation It is well known that shifting a sequence will not change its shape at all. In other words, when measuring the similarity of sequences, we should remove the effect of shifting completely. In [ 12 ], a transformation that projects every shifting line to a point on a hyper-plane is defined as follows: Definition 1 A transformation T se : n  X  n is defined to be where p is a position vector in n .
 Transformation ). It, in fact, projects the point p to the plane ( P  X  0 )  X  N = 0 along the direction of N . This plane which passes through the origin O and has its normal vector in the direction of N is called Shift-Eliminated Plane (or SE-Plane ). The dimension of SE-Plane is n  X  1.
 called the SE-line of u . A scaling X  X hifting plane Plane sa  X  sh , u will be also trans-of u .
 figure, N is the shifting vector and O is the origin. u 1 and v 1 are the com-ponents of u and v that are parallel to N , respectively. When we draw se-quences u and v in a two-dimensional graph, u 1 and v 1 only represent the off-all. u 2 and v 2 are the components of u and v that are perpendicular to N ,re-spectively. They are the actual components of sequences determining the shape. Therefore, we should only use u 2 and v 2 to measure the similarity between u and v . 3 Geometrical analysis of the existing methods Based on the geometrical model, we can explain the three aforementioned meth-ods in a uniform way. 3.1 Normalization method the form of ( s i  X  mean ( S )) equals projecting the point S onto the SE-Plane. The reason is: Here n is the length of sequence S . The step of transforming ( s i  X  mean ( S )) into  X  n . This is because: Given two sequences u and v , after normalization, the Euclidean distance between the two resulting sequences is used as the similarity measure. The geometrical meaning of the normalization method is shown in Fig. 6 ,where Normal ( u ) and Normal (v) are the normalized forms of u and v , respectively. We can see that after plane. We will exploit this geometrical feature when building index invariant to shifting and scaling in later sections.
 However, based on our geometrical model, we can see that this transformation does not remove the component parallel to the shifting vector completely. In other words, it is not shift-eliminated. So, this definition of similarity is not suitable for time series searching invariant to shifting and scaling. 3.2 Minimum distance method Given two sequences u and v , the authors of [ 12 ] propose applying shifting and scaling to only one sequence, say u , the minimum attainable distance between where F a , b ( u ) = a u + b N and D 2 ( u , v) stands for the Euclidean distance be-tween u and v . Using the geometrical model, we can easily get the formula set. Consider Fig. 7 , we want to shift and scale u to find the minimum dis-tance between u and v .Here O is the origin and N is the shifting vector. Let w be the projection of v on the Plane able distance between u and v is the point-to-plane distance of the point v to the Plane sa  X  sh , u ,i.e. v  X  w . By simple geometrical deduction, we know that v  X  w = T T tween u and v is T se ( u ) sin  X  .
 distance are a and b , respectively. From Fig. 7 , we know that u should be scaled to s then shifted to w to get the minimum distance. We then have: and
T
T they are not symmetric similarity measure. The authors of [ 27 ] then choose is symmetric. 3.3 Analysis In [ 20 ], the authors introduce the notion of similarity class . They first define that two sequences X , Y are similar if there exists some ( a , b )  X  X  R +  X  R ] such that Therefore, the set of sequences similar to each other constitutes an equivalence class. From the geometrical view, given a vector u , its similarity class consists of all shifting and scaling transformations of u , i.e. the scaling X  X hifting plane of u . After SE-Transformation, a similarity class becomes a radial Line sa , T se ( u ) in SE-Plane. The problem then becomes how to measure the similarity/dissimilarity between two radials. The authors of [ 12 ] choose the distance of one point on one radial to another radial as the similarity measure. The authors of [ 27 ] consider the counterpart of the distance in [ 12 ] in addition, and choose the minimal one as the similarity measure. The normalization method [ 20 ] takes the point whose dis-tance to the origin is between the two representatives is used as the similarity measure.
 the angle between them. Different from the earlier methods above using various kinds of point-to-point distance to measure the difference, we propose using the angle between two radials directly as the similarity measure as explained in the next section. 4 Angle-based similarity measure Definition 2 Given two sequences u and v of the same length. Let  X  be the angle between vectors T se ( u ) and T se ( v) .Ifcos  X   X   X  ,where  X  is a user-specified threshold, then u is similar to v .
 not change the shape of a sequence, we assume all sequences have been SE-transformed onto the SE-Plane in the later discussion. Given two vectors u and v ,let p be the projection of u along v ,and q be the projection of u perpen-dicular to v . p is similar to v in the sense that it can match v exactly by scaling it properly. We can regard p as the component of u that is similar to v .Since q is perpendicular to v , it cannot be transformed to v by scaling. We regard q as the component of u that is not similar to v .  X  is a measure of the ratio of the simi-lar component, i.e. p , to the dissimilar component, i.e. q .If  X  is small enough, the component similar to v dominates vector u , then we can say u is similar to v surely. Notice that in the earlier definition, we use cos  X  instead of  X  as the simi-larity measure. This is because as  X  approaches 0, the value of cos  X  approaches 1. It is more convenient to use cos  X  as a similarity measure.
 different:  X 0  X   X   X   X  4 ,since p  X  q , u and v are similar to each other, however,  X   X  4 &lt; X  &lt;  X  2 , u has some component similar to v , however, since p &lt; q ,in  X   X  =  X  2 , u is not similar to v at all.  X   X  2 &lt; X   X   X  , u is similar to the mirror image of v to some extent. Now we can summarize the three distance-based methods as follows:  X  D 2 ( Normal ( u ), Normal ( v)) =  X  X in { D 2 ( F a , b ( u ), v) }= T se ( v) sin  X  We can see that all of them involve the angle  X  . In other words, the angle is a more intrinsical factor that determines the similarity between sequences invariant to shifting and scaling than various distance-based measures. This can be further illustrated by the following example. Given a set of data sequences of length 24 (in particular, the random walk data [ 44 ] consisting of 65,000 sequences are used) and 100 query sequences randomly picked from the data sequences, for each query we carry out the range query using different methods (namely, normalization method and the minimum distance method in [ 12 ]), the average values are collected and compared. We first specify the same Euclidean distance as the error bound in normalization method [ 20 ], Min refers to the minimum distance method [ 12 ],  X  denotes the error bound in Euclidean distance,  X  denotes the angle correspond-ing to the error bound in the method, and R denotes the answers yielded by a query. Although the same error bound is set, from Table 1 we can see that the minimum distance method yields more answers than the normalization method, furthermore, R norm is a subset of R min in all cases. An obvious explanation for this results is that given the same Euclidean distance as the error bound, since the optimal shifting and scaling are applied in the minimum distance method, gener-ally more sequences similar to the query will be found than in the normalization method. However, the more intrinsical reason is that the same Euclidean distance the minimum distance method is larger than that in the normalization method, therefore, more answers will be found. In another experiment, we set different Euclidean distances as the error bounds in the two methods; however, they corre-spond to the same angle. This time they produce the same answer sets as shown in Table 2 . This result further consolidates our conclusion. 5 Conical index 5.1 Original conical index consider an angle, based index structure. As far as we know, the only angle-based index structure is the conical query index structure (for brevity, we call it coni-cal index hereafter) proposed in [ 15 ]. First, a conical query is defined as: given a query point Q andanangle  X  , the query result is all points in the hyper cone with cone angle 2  X  and axis OQ ,where O is the origin of the data space. The cone corresponding to a conical query is shown in Fig. 9 . Conical index is an index structure based on data space partitioning [ 11 , 18 ] as depicted in Fig. 10 . Assume the data space is the hypercube [ X  1 .. 1 ] n , it can be partitioned into 2 n hyperpyramids, where n is the dimension of the data space. The apex of all these hyperpyramids is the origin O . The bases of the hyperpyramids are the surfaces of the hypercube. For each of the hyperpyramids, the base is divided into p par-allel slices according to a chosen dimension such that the volumes of the slices are the same. For a given conical query, the cone corresponding to the query will intersect some of the hyperpyramids. For each of the intersected hyperpyramids, all the data in the slices which intersect the cone will be retrieved and passed to post-processing. This procedure is depicted in Fig. 11 . 5.2 Enhanced conical index problem. However, because of the special geometrical properties of our problem, it may not be very suitable for the problem. Thus, we modify the original conical index structure to further adapt to our problem. 5.2.1 Hyper-plane property After SE-Transformation, all sequences are projected onto the SE-Plane. Note that the dimension of SE-Plane is n  X  1, and the data space partitioning approaches work more efficiently in case of uniform or dense distributed data [ 3 , 18 ]. If we still partition the data space in the original n -dimensional coordinate system, most of the slices are empty, the efficiency of the conical index will be tampered. By with the shifting vector N , the projected points in SE-Plane can be represented by the new ( n  X  1 ) -dimensional coordinate system. Since rotation of axes does not change the relative position between vectors, the angle between two vectors remains the same. It is easy to prove that when calculating angle between vectors using the original representation or the new representation yields the same result. So, we can transform all vectors in SE-Plane from their n -dimensional representa-tion into the ( n  X  1 ) -dimensional representation, then build index and query in the new ( n  X  1 ) -dimensional data space. Given an n -dimensional space, the rotation matrix R can be calculated in the following way: where and For any vector p , R  X  p is the new vector after rotation. For example, the shifting is based on the rotated data space without confusion. 5.2.2 Hyper-sphere property The similarity measure we propose is the angle between vectors after SE-Transformation. However, to simplify processing, we can further apply scal-will not change the angle between vectors. Thus, we will normalize all sequences before indexing and query regardless of angle or distance used as the similarity measure. Note that the normalization method we use is slightly different from the one in [ 20 ] that after normalization, the Euclidean distance of the normalized sequence to the origin is 1 not on this property, an enhanced conical index is devised as shown in Fig. 12 , note that this is a two-dimensional case. The enhanced conical index is built as follows. First, we should number the pyramids, that is, assign a different integer to each of the pyramids. For a data point D , after determining which pyramid it is located in (suppose D is located in pyramid i ), a value called pyramid value is calculated as i pyramid (for pyramid P 1 ,itisthe X dimension). Then the data point is inserted into a B + -Tree using its pyramid value as the key. Note that d + 1 2 is a real num-ber in the range ( 0 , 1 ) and the label of each pyramid is an integer; therefore, the pyramid values of a pyramid cover an interval of ( i , i + 1 ) , and any two pyramids cover different sets of pyramid values.
 query cone intersects the hyper-sphere at a region (in Fig. 12 it is the arc AB ). Similar to [ 15 ], we will find the extreme values of the region in every dimension using the Lagrange multiplier. However, because of the special geometrical prop-erty, the procedure is easier and clearer than that in [ 15 ] (please refer to [ 15 ]for more details). Suppose the dimension of data space is n (note that the data space  X  , the following steps illustrate how to find the extreme values of the intersection region along each dimension. For dimension k , the extrema of the intersection region is exactly the extrema of the function: subject to the following two constraints: The extrema are obtained when the following equation holds: Divide both sides of the equations by  X  1 ,wehave: Combined with the two constraints we have n + 2 variables and n + 2 equations, theoretically, we can calculate the values of x k ,i.e.theextremaof x k .
 form a linear equation group. After solving the equation group, we can represent equation of x k , the roots of the equation are the extrema.
 can determine which pyramids the query cone intersects. Assume the query point Q ( u query cone intersects the pyramid x k = p . For other pyramids, the determination two end points of the major diagonal of the minimum bounding rectangle (MBR) of the intersection region. The MBR intersects a pyramid, iff there exists a vertex of the MBR which falls into the pyramid. This procedure is shown and explained in Fig. 13 : Procedure Intersection ( i ) // i = k intersected = 0; if ( p == 1) if ( u i  X  0) { if ( l k &lt; h i ) intersected = 1; } // intersect the pyramid x i = 1 if ( l k &lt; | l i | ) intersected = X  1; } // intersect the pyramid x i = X  1 if ( u i  X  0) { if ( | h k | &lt; h i ) intersected = 1; } // intersect the pyramid x i = 1 if ( | h k | &lt; | l i | ) intersected =  X  1; } // intersect the pyramid x i = X  1 construct a range of pyramid values to search in the B + -Tree. Refer to Fig. 12 ,the MBR intersects pyramids P 2 and P 3 .For P 2 ,theextremain Y -dimension is a and data on the arc QB .
 the pyramid is sliced with planes parallel to the base of pyramid, while in con-ical index we use the planes perpendicular to the base of pyramid. Suppose the intersection region is the arc AB , pyramid technique has to retrieve all data on the arcs AB and CD , while conical index will only retrieve all data on the arc AB .In other words, conical index will retrieve much less false alarms than the pyramid technique. In addition, we can use more than one dimensions to slice the pyramid while the pyramid technique can use only one dimension. We will discuss this in later section. 6 Experiment In the experiment, we compare the performance of enhanced conical index with that of distance-based method (we use R  X  -Tree as the representative) and of se-quential search, and we consider only range query in the experiment. Based on the relation between angle and Euclidean distance, the error bound in angle can also be converted into Euclidean distance, then the query can also be stated as finding all sequences whose Euclidean distance to the query is smaller than the converted error bound.
 Professional, with 512 MB of main memory. The disk page size is 4 KB. The settings of R  X  -Tree are: the number of maximum entries of each internal node is set that the size of each internal node is 4 K Bytes to optimize the disk access efficiency, other settings are set as suggested in [ 6 ].
 data consisting of 18,000 sequences; power supply data consisting of 35,000 se-quences; and random walk data consisting of 65,000 sequences. In each experi-ment, 100 queries are performed and the average value is collected. Each query is a sequence picked from the data sequences randomly.
 performance by varying query dimension under page access number, hit rate and searching method. It is defined as the ratio of the number of sequences in final result to the number of sequences retrieved by the searching method. The re-sults are shown in Figs. 15 X 17. From the results we clearly see that except the power data, the conical index achieves larger improvement on R  X  -Tree and se-quential search as the dimension increases. This phenomenon is due to the  X  X urse structures must use the 50% quantile when splitting a data page, they will tend to access almost all data in the index especially in high-dimensional space. While the performance of the pyramid like index structures does not deteriorate too much in high dimension.
 under different query selectivities. The results are shown in Figs. 18 X 20. From the results we can see that except the power data, besides the better performance in high dimension, the conical index also has the advantage that its performance is much steadier than that of R  X  -Tree as the selectivity increases.
 however, we can further improve it by using more dimensions to slice the slice a pyramid, in every slicing dimension except the last one, i.e. d k ,weparti-tion the dimension into p uniform slices. Then the 2 n pyramids can be labeled as ( i with label V , its coordinates in the k slicing dimensions are S d i , 1  X  i  X  k , re-spectively, then the pyramid value of the data point can be calculated as: Given the formula of pyramid value, the building index and query process is the same as that in one-dimensional conical index. We investigate the performance of multi-dimensional conical index using random walk data. The settings for multi-dimensional conical index are: for two-dimensional conical index, every slicing dimension is partitioned into 200 uniform slices, and for four-dimensional conical index every slicing dimension is partitioned into 20 uniform slices. The results are plotted in Figs. 21 and 22 . Note that the results are plotted in a relative way using thedataof R  X  -Tree as the baseline.
 does improve the performance remarkably. However, as the dimension of data space increases, the performance of multi-dimensional conical index degrades, since the dimension of index keeps the same. This suggests that we should slice more dimensions to build conical index. Nevertheless, since the storage struc-of retrieving data also increases as the dimension of conical index gets higher, a tradeoff should be considered. 7 Related work The most popular approach to define the similarity between sequences is to map sequences into feature vectors (i.e. the idea of dimensionality reduction) and then use the L p metric between feature vectors to define the similarity measure. The L p metric have been used and/or extended in various approaches [ 1 , 9 , 19 , 42 ]. In addition, many techniques have been proposed to extract the feature vectors n -point Discrete Fourier Transform (DFT) and the first f c coefficients are kept number and has two components actually). These points are then indexed by ST-index to handle subsequence matching. Various Discrete Wavelet Transforms (DWT) instead of DFT are used to reduce the dimension [ 8 , 34 , 39 ]. However, the DFT-based and the DWT-based techniques yield comparable results on similarity searching in time series databases [ 41 ]. While in [ 26 ], the author uses Singular Value Decomposition (SVD) for dimensionality reduction. All these techniques use L p metric as the similarity measure and most of them do not consider any transformation.
 Approximation. The basic idea is to represent a segment of time series as a mensionality reduction and has several advantages such as fast computation, supporting non-Euclidean similarity measure, etc. [ 25 ]. This technique can be further classified into three categories [ 25 ]: Piecewise Linear Approximation (PLA) [ 23 , 32 , 33 , 35 ], Piecewise Aggregate Approximation (PAA) [ 24 , 42 ], and Adaptive Piecewise Constant Approximation (APCA) [ 9 ]. points. The distance between time series based on the turning points is invariant to six common transformations: shifting, uniform amplitude scaling, uniform time scaling, uniform bi-scaling, time warping and non-uniform amplitude scaling. However, if the turning points are used as the only representation of a time se-ries, part of the time information will be lost. This information is important to form the shape of time series and are unavailable to queries if only turning points are used.
 which includes a transformation rule language T .In[ 38 ], the authors consider the case that T contains the transformations of moving average, time scaling, ampli-tude scaling, and shifting. They propose the first indexing method that can handle moving average and time scaling. In a later paper [ 37 ], the same authors improve the work in [ 38 ] by searching the index only once while a set of transformations is applied simultaneously instead of only one transformation applied per searching. However, the method used in the two papers to handle scaling and shifting is the same as the normalization method.
 time series. After the data sequence are projected onto a hyper-plane, signatures are created and the searching is performed among these signatures. However, no indexing structure is proposed.
 in [ 2 ]. The main idea is that after some non-matching gaps between two sequences are ignored, they can be regarded as similar if they have enough non-overlapping corresponding similar subsequences. This idea is similar to the longest common subsequence ( LCSS ) concept in string matching problem. In [ 5 ]and[ 13 ], the simi-larity they proposed are based on LCSS too. They propose an efficient algorithm to determine whether two sequences are similar with respect to shifting and scaling. However, they do not propose any indexing method.
 Probabilistic Generative Modeling [ 21 ] is  X  X odel based X . Different from other work, time series is modeled by a K -state segmental hidden Markov model where each state is dedicated to the generation of one segment of the time series. Given the model and a query sequence Q , the similarity is measured by the possibil-ity that Q can be generated by the model. Though this method does have a solid mathematical background, since the computation is fairly complicated, it will not scale well to large amount of data. 8Conclusion In this paper, we consider the problem of searching for similar patterns among time series data invariant to shifting and scaling. We find that we can treat the problem geometrically and the similarity relation between two time series is closely related to the resulting sequences after SE-Transformation. Based on this uniform geometrical model, we analyze the existing related methods and conclude that the angle between vectors after SE-Transformation is a more intrinsical simi-larity measure.
 to adapt to the geometrical properties of the problem and compare its performance with that of sequential search and R  X  -Tree. Experimental results show that the enhanced conical index achieves larger improvement on R  X  -Tree and sequential search in high dimension. It can also keep a steady performance as the selectivity index to further improve the performance.
 Appendix References
