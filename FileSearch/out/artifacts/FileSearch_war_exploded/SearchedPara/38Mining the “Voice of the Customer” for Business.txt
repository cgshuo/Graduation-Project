 WEI PENG, TONG SUN, and SHRIRAM REVANKAR, Xerox Corporation The goal of mining the  X  X oice of the Customer X  (VOC) [Griffin and Hauser 1993] is to understand the needs of customers and transform them into key functional re-quirements. Instead of diving into product development directly by assuming that customers X  requests are known, we let customers speak their own concerns. To gain competitiveness and sustained growth in the 21st century, most businesses are on a mission to become more customer-centric. In order to succeed in this work, it is crucial to collect and analyze the requests from customers (e.g., the voice of the customer), and also quickly act on this knowledge and quickly turn them into desired features in the products, solutions, or services. Typically, a customer request for new or enhanced fea-ture(s) contains at least the following metafields: a textual description about a desired feature or a current problem, the associated product(s), and the customer information. Customer information usually includes (but is not limited to) the customer name, the products owned, the associated market segment, and the business size. The prod-uct mentioned in the request belongs to a product family or a hierarchical product category. The customer requests are normally gathered from various customer touch-points, such as product support call centers, sales engagements, emails, marketing events, surveys, etc.

Traditionally, customer needs are gathered through a mass of interviews. Engineer, marketing, or customer representatives will distill, break down, and identify key cus-tomer requirements manually. These are ad hoc, time-consuming, error-prone, people-based processes which hardly scale well as the quantity of customer information explodes. There are also many data analytic methods developed for analyzing various forms of the customer data, but mostly are data-driven only and focus around front-end of CRM (Customer Relationship Management) applications. Several approaches are available [Clarabridge 2007; Gao et al. 2004; Romano et al. 2000] for synthesizing and mining customer textual data for information retrieval. These methods suffer the following major shortcomings: (1) They are applied mostly in the front-end of CRM applications (i.e., customer support, marketing research, etc.) while focusing on solic-iting and synthesizing the customer information from various channels. None of them directly addresses the decision support for the back-end product/service feature devel-opment based on VOC data analysis. (2) They are completely data-driven (i.e., focusing on the discovery of the meaning or the underlying data structure itself via linguistic techniques), and lack support of adding domain knowledge into the data analytical process. (3) Most importantly, understanding the relative importance of a customer request on certain product features is extremely critical and has a direct impact on effective prioritization in the development process. The current methods are not able to rank customer requests and products to identify key requirements and products by considering both semantics and product/customer relationships.

In this article, we develop a hybrid framework that integrates domain knowledge (any prior knowledge from domain experts in marketing, sales, product/service de-velopment, customer support, analysts, etc.) with data-driven mining algorithms to analyze the VOC data. The integrated analytical framework consists of the following components: (i) categorizing VOC data into product feature clusters by leveraging do-main knowledge and identifying the evolving feature trends, (ii) prioritizing customer requests using a novel semantic enhanced link-based ranking algorithm, (iii) conduct-ing a case study on a real VOC data collected by XOG (Xerox Office Group), called FER (Feature Enhancement Requirement) dataset, which contains 1878 feature enhance-ment requests from year 2000 to 2006. The total number of Xerox products referenced by these requests is 83. The results received promising feedback from domain experts. A preliminary version of the work focusing on discovering actionable knowledge for decision support has appeared in Sun et al. [2011]. Before diving into the methodology design, some terminology used throughout the entire article needs to be explained. Requests are also called documents or require-ments in this article. In our FER data, they refer to customer requests. For example, a customer request in FER is  X  X equesting authenticated SMTP functionality. Users are required to authenticate to network to scan to email externally at WCP for email customer considers it more secure that email works via user credentials in-stead of enabling a relay exception for WCP X . This request is associated with product  X  X orkCenterPro35:45:55 X  and it is raised by a customer A with about 1000 Xerox ma-chines. As for FER dataset, the request contents and associated products/customers are recorded in spreadsheets. Features refer to the functionalities that customers de-mand for some products, for example, a scan-to-email feature for a copy machine. Feature clusters (or document clusters) are groups of features/requests where fea-tures/requests in the same group are similar. For example, in our case study, features such as  X  X ultipage TIDD X  and  X  X CR X  are grouped into the same feature cluster  X  X can X  by domain experts. Some requests are clustered together since they all talk about  X  X can X . Figure 1 illustrates a high-level overview of the proposed hybrid VOC analytic framework. It encompasses the following steps and components.  X  In step (1), the raw VOC textual data is first preprocessed [Rajagopalan and Isken 2001] using text processing techniques such as skipping the stop-words and extract-ing key words using TFIDF (Text Frequency Inverse Document Frequency) [Salton and Buckley 1988].  X  In step (2), the semantic VOC data are then categorized or clustered into key fea-ture clusters using the knowledge transformation model [Li et al. 2008]. The do-main knowledge is captured from domain experts in certain domain areas, and can be presented in a formal ontology model, such as product taxonomy, marketing ter-minology, customer type hierarchy, bag of keywords for major product feature, and inter-relationships among these ontological elements. We use the knowledge trans-formation model when domain terminology is available (as shown in Table II).  X  In step (3a), sum up the importance of each feature cluster in each time period. If the time is taken into account, the importance of each feature group varies over the time. The importance trend of all feature groups can be visualized to capture the key evolving themes in a timely fashion [Last et al. 2001; Zhang and Zhou 2004]. In step (3b), the pairwise overlap between feature clusters can also be calculated. (3a) and (3b) are not our focus in this article. They can be easily derived from feature clusters obtained from step (2).  X  In step (4) and (5), since it is always crucial to prioritize customer requests for deci-sion making, we develop a novel semantic enhanced link-based ranking algorithm (SELRank) to prioritize the requests within each feature cluster or across feature clusters based on the query context.

Steps (4) and (5) illustrate the key components of this article. Since there is a trade-off between customers X  satisfaction by enhancing the required features and efforts the companies have to invest, the requests need to be prioritized or ranked in order to tar-get the most important and least satisfying one. Comparing with the existing ranking algorithms [Haveliwala 2002; Jiang et al. 2004; Kleinberg 1999; Page et al. 1998; Wu and Aberer 2005; Xue et al. 2005; Zhou et al. 2007], the novelty of SELRank is in two perspectives: First, it considers not only the explicit topological links (e.g., hyperlinks in Web pages. In FER data, they represent the relationship between the data fields al-ready recorded in the semi-structured format.), but also the implied semantic -links in a set of inter-related networks based on the semantic similarity and domain knowledge (in FER data, these links indicate the semantic relationship between unstructured request text contents or are defined by domain experts); second, it simultaneously computes more than one iteratively reinforced ranking vectors per feature cluster, per domain semantic term across feature clusters, or per query term. This proposed SELRank algorithm can be used to prioritize the individual customer requests within a feature cluster or across feature clusters. For example, it can rank the individual cus-tomer requests which talk about  X  X ecurity Scan X  or product  X  X orkCentrePro35:45:55 X . It can also prioritize the products which have the  X  X ecurity Scan X  feature/functionality. When the Focus Group of  X  X can X  wants to address customer requests, they can look at the top prioritized  X  X can X -related requests and products (usually most representative and important) first to make a quick decision and response to customers.

The remainder of the article is organized as follows. Section 3 introduces domain-knowledge-based semi-supervised clustering approaches to categorize VOC data into feature clusters; Section 4 describes the novel semantic enhanced link-based ranking (SELRank) for prioritizing VOC data; Section 5 presents the detailed case studies on analyzing XOG FER data. Finally, Section 6 concludes. In order to understand the main theme of VOC data and disseminate them into the corresponding functional groups, we discover the feature clusters with domain knowl-edge. The textual description of customers X  requests directly tells the customers X  needs and can be represented as a document. Since it is voiced by various customers and may be reported by diverse operational sources, it is preprocessed and projected into a canonical semantic space by using common text mining techniques.

Usually domain knowledge can be represented in various forms, such as taxonomy, hierarchical types, data labels or keywords, rules, etc. When certain domain knowledge (such as product types, functional feature taxonomy, customer categories) is available, we can use it to obtain more meaningful and practical categorization results [Dayanik et al. 2006; Liu et al. 2004]. In this article, the domain knowledge is presented as a set of distinguishing keywords. These keywords can be captured for each feature cluster. For instance, the  X  X ecurity X  feature cluster can be described by a collection of keywords, such as  X  X uthentication X ,  X  X assword X  and  X  X ogin X .

To utilize the prior knowledge of domain keywords, we use the knowledge trans-formation model proposed in Li et al. [2008] to utilize those distinguishing keywords for discovering feature clusters of requests. Basically, this knowledge transformation model uses a nonnegative matrix factorization model where X is a m  X  n word-request semantic matrix, F is an m  X  k nonnegative matrix representing prior knowledge in the word space, that is, the i -th row of F represents the posterior probability of word i belonging to the k -th feature classes, and G is an n  X  k nonnegative matrix representing knowledge in document space, that is, the i -th row of G represents the posterior probability of request i belonging to the k -th feature classes (e.g.,  X  X can X ,  X  X ecurity X , etc.) S is an k  X  k nonnegative matrix providing a condensed view of X . Note that the matrix factorization model offers a natural framework for coclustering of words and documents. The prior knowledge of the domain keywords can help us obtain the F 0 in the framework and F 0 is incorporated into the unsupervised clustering frame as a constraint Note that  X  F  X  F 0 2 is used to constrain that the final word clusters F should be highly consistent with the prior domain word clusters F 0 . Moreover,  X &gt; 0 is a parameter that determines the extent to which we enforce F  X  F 0 . After the feature clusters are obtained, we can know what are major features that customers are asking for, and the importance of each feature varying with time. In product requirement engineering and design practices, understanding the relative importance of a customer request on certain product features is extremely critical and has a direct impact on the effective prioritization in the development process. Although the importance of a customer request on product features is an inherently subjective matter which depends on emerging trends, the product marketing strategy, and the customer X  X  influence (e.g., size, revenue, role, market share) in the related markets, there is still much that can be said objectively about the relative importance of cus-tomer requests based on data-driven analysis techniques. These objective analysis results can provide on-demand insights to support the decision makers in prioritizing the overall product development. We aim to prioritize and handle individual requests either within a feature cluster or cross feature clusters. With more and more cus-tomers X  requests coming in, it is very difficult for domain experts to understand and handle all of these in short time. Then a trade-off exists between customers X  satisfac-tion by enhancing the required features and efforts the companies have to invest. We need to prioritize or rank the requirements in order to target the most important and representative one. 4.1.1. Introduction. We propose a novel semantic enhanced link-based ranking (SELRank) algorithm for rating customer requests by considering not only the importance of the customers who ask for them, but also the importance of the products they are related with and how representative they are. Meanwhile, the relative impor-tance scores of the products among all customer requests are also calculated according to the importance of their related requests and related products. The representative request is the request semantically similar to many other requests. The represen-tative request is important because solving it may help to solve other requests. It is straightforward that the request related to the important products and important customers is important, and the product associated with important requests and im-portant products is also important. In a sentence, the intuition behind our proposed ranking algorithm is a request is important if it is strongly linked with many other im-portant requests, targeted to many important products, and asked by many important customers.

Figure 2 illustrates a generic conceptual model for these customer requests. The explicit links (similar to hyperlink in a Web page) embedded in a customer request are the associations between Request and Customer, and Request and Product. These associations are usually already indicated in the VOC data. In addition, semantics help to provide additional link-based relationships that are not available from the aforesaid explicit links, such as: (1) the hidden (i.e., nonexplicit) links between cus-tomer requests based on their content semantic similarity; (2) the semantic links be-tween products based on the hierarchical product family structure; (3) the semantic links between customers based on their related market segments. The link structure embedded in the customer requests exhibits a set of interrelated and intrarelated com-plex networks (such as product-product network, request-request network, customer-customer network, product-request network, request-customer network), where there are three types of nodes: Product, Customer, and Request. They could have the ini-tial assigned importance scores. In our FER dataset, we have prior importance scores assigned to different customers. 4.1.2. Link Structure. The links between requests are weighted with the semantic similarity. The links between products can be weighted with the  X  X onceptual dis-tance X  [Rada et al. 1989]. It can be derived from the domain hierarchical product family graph that shows the taxonomy of the product nodes. The conceptual distance between two nodes can be the number of intervening nodes. These intervening nodes form the shortest path between the two nodes. We calculate the shortest path by adopting the breadth-first search that iteratively explores one node X  X  neighbors and its neighbors X  neighbors, etc., until the other node is found. The nodes that are  X  X onceptually closer X  to each other in the domain hierarchical product family graph should have more sim-ilar functionalities and features. The semantic links between customers can be also weighted by using conceptual distance. Our current algorithm does not take into ac-count the links (relationships) between customers, but they can be easily included into the algorithm.
 4.1.3. The Algorithm and Its Convergence. In the following, we will describe our SEL-Rank algorithm. Given the similarity matrix A with A i , j be the semantic similarity between the requests R i and R j (it can be the similarity between two bags of words), C with C l , j be the hierarchical semantic similarity between the products U l and U j , which can be easily derived from their conceptual distance (for example, product  X  X ig-ital Bookmark Copier X  is very close to product  X  X igital Bookmark Multifunction X ), the vector w with w i be the weight of the customer (e.g., the number of machines that cus-tomer bought can represent the importance of customer) who raises the request R i , the vector o with o l be the weight of U l (the importance of product defined by domain experts, or initiated with the equal weight to all other products), the vector f with f i be the final ranking score of the request R i , the vector h with h l be the final ranking score of the product U l , and the matrix B with B i , l be 1 if R i is linked with U l and 0 otherwise (e.g., the request  X  X equesting authenticated SMTP functionality. Users are required to authenticate to network to scan to email externally at WCP for email customer con-siders it more secure that email works via user credentials instead of enabling a relay exception for WCP X  is associated with product  X  X orkCenterPro35:45:55 X . It is raised by a customer A with about 1000 Xerox machines as his/her importance weight.). Since a request is important if it is strongly linked with many other important requests, with k A i , k . For example, if request A is similar to request B and C with similarity scores 0.4 and 0.5, and the importance scores of B and C are 0.5 and 0.4, then the importance score of A is 0.4 (0 . 4  X  0 . 5+0 . 5  X  0 . 4). The intuition behind it is that the request similar to many other requests should be the center of this request clus-ter. It can serve as the most representative request of these requests. In addition, a request is important if it targeted to many important products, so U up the importance of connected products. The request is also important if it is asked by many important customers, w i ing the customers X  weights. Similarly, the product is important if it is identified to be important by customers, linked to many important requests, and connected to many important products. They are represented as o l portance flowing on different types of edges is weighted and adjusted by  X  ,  X  ,  X  ,and  X  . Here  X  and  X  are parameters to adjust the influence of importance propagation along interlinks and intralinks. The links between the same types of nodes are called intralinks, for example, the links among requests. The links between different types of nodes are called interlinks, for example, the links between requests and products.  X  and  X  are other parameters to adjust the influence of the stationary preference (initial importance) [Baeza-Yates et al. 2006] of requests and the importance flow along the semantic links between requests. 0 &lt;  X , X , X , X  &lt; 1, which can be defined by domain experts. In our experiments, they are chosen from 0.85 to 0.99 that are commonly used in practice [Kamvar et al. 2003a; Page et al. 1998; Sepandar 2003]. Then where U l  X  R i means that the product U l is linked with the request R i . In our experi-ments, domain experts give more influence to importance propagation along intralinks ALGORITHM 1: The SELRank algorithm.
 than interlinks since  X  X epresentativeness X  of a request is considered to be more empha-sized. More influence is given to semantic links than stationary preference. We can see that the SELRank algorithm is similar to HITS [Kleinberg 1999] in the way that f and h continuously reinforce each other until they converge. The detailed algorithm is listed in Algorithm 1, where A is the request semantic similarity matrix, C is the prod-uct similarity matrix, w is the customer weight vector, o is the product weight vector, and B indicates the request-product link matrix. Algorithm 1 presents the SELRank algorithm in the matrix computation format.

Note that the final rank vectors can be obtained from eigenvector solutions. We can write that v =( f , h ) T ,and v = D v , where
The entries in matrix D indicate the amount of  X  X mportance X  the related customer, product, and requests can contribute to the importance of the entry node. In the fol-lowing, we will show that SELRank algorithm can converge by proving two theorems. T HEOREM 4.1. D is an Ergodic matrix.
 tion matrix because it is a square matrix each of whose rows consists of nonnegative real numbers, with each row summing to 1. It is also an Ergodic matrix to represent the transition probabilities in a discrete-time Markov process. The Markov network is composed of both products and requests. The links in the network could be request-request links, product-product links, and request-product links. The entry value in matrix D is nonzero and can be regarded as the corresponding transition probability. D is both strongly connected and aperiodic .
 T HEOREM 4.2. The SELRank algorithm will converge.
 chain as proved before, then, as n  X  X  X  , the powers P n approach a limiting matrix with all rows the same vector. This stationary vector is a strictly positive probability vector. We can obtain this stationary solution from the principle eigenvector [Axelsson 1994; Berkhin 2005; Langville and Meyer 2005].

The SELRank algorithm can be regarded as the modified PageRank algorithm [Page et al. 1998], where the links are both hyperlinks and semantic links weighted by D . The similarity between SELRank and PageRank is that: (1) they both model a dis-crete Markov process; (2) the importance score of each node is calculated by summing the importance scores of the connected nodes; (3) the importance of the node is split averagely onto connected edges. We can observe that v is the eigenvector centrality of a weighted graph D . Moreover, v can be obtained by calculating the principle eigen-vector corresponding to the greatest eigenvalue. The algorithm therefore converges as fast as the PageRank algorithm. In order to search VOC data, first, the rank scores of products and requests are com-puted by using the SELRank algorithm offline. Here we consider two use scenarios for searching VOC with our SELRank algorithm, assuming the users can be sales representatives, product marketing personnel, executive decision makers, product de-velopment managers, or developers.  X  Scenario-1: Keyword-based search on VOC data . This is in which a user types in a keyword query, and then a list of ranked customer requests and ranked relevant products are provided.  X  Step (1) the keyword query is transformed into a semantic query using LSI, and  X  Step (2) a root set of matched requests are obtained by measuring the cosine  X  Step (3) the requests that are not in the root set with strong semantic links to the  X  Step (4) finally, the retrieved requests and their related products are presented  X  Scenario-2: Product-based query on VOC data . This is in which a user types in one or more product names, and then a list of ranked customer requests linked to these products are provided respectively. Steps in this scenario are very similar to the
Scenario-1 except that the retrieved set only contains the requests that are directly linked with the query product(s). Thus we do not state it here in detail. As we know, link analysis algorithms play key roles in Web search systems. They ex-ploit the fact that the Web link structure conveys the relative importance of Web pages. The HITS algorithm [Kleinberg 1999] relies on query-time processing to find the hubs and authorities that exist in a subgraph of the Web consisting of both the results to a query and the local neighborhood of these results. Google X  X  PageRank [Page et al. 1998] precomputes a ranking vector that provides a priori  X  X mportance X  estimates for all of the pages on the Web. This vector is computed once, offline and is independent of the search query. At query time, these importance scores are used in conjunction with query-specific IR (Information Retrieval) scores to rank the query results. There are several enhanced PageRank algorithms being developed recently, such as a weighted PageRank [Jiang et al. 2004], two-layer PageRank [Wu and Aberer 2005], hierarchical PageRank [Xue et al. 2005], and the topic-sensitive PageRank [Haveliwala 2002]. All the preceding methods only consider the explicit graph-topological links (either flat or hierarchical networks) residing in a Web page, and most of them generate a single page-ranking vector. The linguistic-based topic structure used in Haveliwala [2002] is only used for biasing the ranking scores based on different topics, and it does not provide any additional  X  X emantic-link X  structure into the Web page. Although multiple ranking vectors can be computed by Haveliwala [2002], these ranking vectors are still for Web pages with biasing by different topics. None of these existing ranking algo-rithms is sufficient to effectively handle the prioritization of customer requests. This is because the analysis of customer requests is a very domain-driven problem, and also the link-based relationships embedded in them are well beyond the explicit hyperlinks and involve much more complex inter-related networks. Figure 4 illustrates the dif-ference between the original PageRank and our proposed SELRank, and the Table I provides a tabular comparison among SELRank and the existing representative rank-ing methods. The key novelty claims in our SELRank algorithm are highlighted in bold letters. In this section, we conduct case studies on the XOG (Xerox Office Group) FER (Fea-ture Enhancement Requirement) dataset, which contains 1878 feature enhancement requests from year 2000 to 2006. The total number of Xerox products referenced by these requests is 83. XOG FER is a synthesized collection of customer requests cap-tured via multiple touch-points, such as call center notes, sales initiatives or meeting notes, emails, marketing events, or survey. Each data entry with the reported time in FER describes a customer request for enhancement for one or more XOG products. The relevant customer information, such as how many Xerox machines they already owned, is also available.

Our analytic framework integrates domain knowledge with data-driven analytical methods to extract domain-specific actionable knowledge from the VOC dataset. Upon this actionable knowledge, the following decision support scenarios can be enabled.  X  Based on the categorization with domain knowledge, VOC data are disseminated into the corresponding feature clusters for understanding the main theme and evolving trends of the voice of the customer.  X  Based on the VOC search, we can retrieve the ranked requests and products ac-cording to generic keyword query, feature cluster query, or product-specific query, to facilitate the feature development process or perform market research.
 In the following, we discuss several application scenarios in detail. First, the XOG FER dataset is fed into the proposed framework (described in Section 2) going through preprocessing step (1). Table II illustrates one form of do-main knowledge on existing XOG feature teams. It lists the commonly used keywords or terminology in each feature team. Generally, there are 15 feature clusters on  X  X can X ,  X  X I X ,  X  X edia X ,  X  X rint X ,  X  X opy X ,  X  X ax X ,  X  X ccounting X ,  X  X ecurity X ,  X  X evice Management X ,  X  X ob Management X ,  X  X mail X ,  X  X epository X ,  X  X rotocol X ,  X  X inishing X , and  X  X isc Category X  (as in bold letters), and parts of corresponding keywords are listed below for each fea-ture cluster. These are provided by domain experts. Each feature cluster is responsible for handling the corresponding type of requests.

In this subsection, we mainly present the experimental results from feature cluster-ing by using the knowledge transformation model on FER. Before it, we tried applying the unsupervised clustering algorithm on the XOG FER dataset while ignoring the provided knowledge of feature teams and their related keywords. We found we could not obtain very reasonable results. First, most unsupervised clustering algorithms re-quire that the number of clusters are known. Second, some important but infrequent keywords are removed in the preprocessing step. Third and most importantly, the clusters of requests from unsupervised clustering cannot be linked to domain-defined feature clusters.

By incorporating domain knowledge, our clustering algorithm successfully dissem-inates requests into these known domain feature clusters as verified by domain ex-perts. The experimental results shown in Table III are evaluated to be meaningful in the XOG feature team context. The first column is the feature cluster id, the second one is the feature cluster name, and the third one is the number of requests in the corresponding feature cluster while the last one is the normalized importance scores summed to 1. We observe that the  X  X ecurity X  feature cluster obtains the highest im-portance score (here we assume the importance of a feature cluster is based on the number of machines that this feature cluster-related customers own). It is verified by domain experts that the security is the main issue that they will look into.
With considering the time, the evolving importance trend of the previous 15 feature clusters shown in Table II can be obtained and captured in Figure 5. Time is quanti-fied into 14 periods from 2000 to 2006 onto the x-axis. There are 15 importance curves corresponding to feature clusters. The sum of importance scores in each period are normalized to 1. The importance score of a feature cluster in a period is the verti-cal gap between this feature curve and the underneath feature curve in this period. From Figure 5, we can find that, for example,  X  X ecurity X  feature cluster and  X  X isc X  feature cluster (they are the curves with marks) increasingly become more and more important. The domain experts verified that  X  X ecurity X  and  X  X isc X  increasingly be-come more important than before while  X  X rint X ,  X  X can X , and  X  X opy X  oscillate with time. We use cosine similarity to weight the semantic links between requests. The semantic links between products are weighted with the conceptual distance derived from the domain hierarchical product family graphs, a small part of which is shown in Figure 6. Then we use the novel SELRank algorithm described in Algorithm 1 to rank the re-quests in each feature cluster. The parameters  X  and  X  are set to 0 . 85, the same as the PageRank algorithm, and  X  and  X  are 0 . 9. The ranking results are evaluated to be very useful by domain experts. Due to the space limit, the entire ranking in all 15 fea-ture clusters is not presented here. Table V lists the top ranked two requirements in feature clusters  X  X can X ,  X  X ecurity X , and  X  X ccounting X . The first column in the table is the number of products that the corresponding customer has, the second column is one related product, and the last column is the request text description. The top ranked products in these three feature clusters is shown in Table IV.

We also conduct user studies on both keyword-based queries and product-based queries according to Scenario-1 and Scenario-2 described in Section 4.2. Figure 7 shows the screenshot of a VOC search interface for both keyword and product queries (this figure shows the keyword query with the keyword  X  X ecurity Scan X ). Each re-turned request has the feature cluster that the request belongs to, the number of products that the corresponding customer has, and a brief text description. For example, the returned results from searching  X  X ecurity Scan X  which are across two features clusters  X  X ecurity X  and  X  X can X  as shown in Figure 7. The top 5 ranked prod-ucts related to  X  X ecurity Scan X  are found to be WorkCentrePro35:45:55 , WorkCen-trePro232:238:245:255:265:275 , AllDocumentCentres , WCP2128:2636:3545Color ,and WorkCentrePro32:40Color .

As for the product-based query, a very small part of the search results are summa-rized in the following.  X  For product WorkCentreM24, the top ranked customer requests are from  X  X can X  and  X  X epository X ;  X  For product DC5xxST, the top ranked customer requests are from  X  X rint X  and  X  X I X .  X  For product WorkCentrePro232:238:245:255:265:275, the top ranked customer re-quests are about  X  X evice Management X ,  X  X ecurity X , and  X  X ax X .  X  For product WorkCentrePro123:128, the top ranked customer requests are about  X  X rotocol X  and  X  X ecurity X .  X  For product DocuColor240:250, the top ranked requests are about  X  X rint X .
The search results are verified to be helpful for domain experts to understand the key feature enhancement, facilitate the feature development or market research pro-cess, and prioritize the handling process of customer requests. We want to emphasize that the effectiveness of the SELRank algorithm is subjective like other ranking al-gorithms, thus it is validated by domain experts. We conducted user studies on the effectiveness of several queries together with the ranked results for each feature clus-ter and product as shown before. Those queries are  X  X can to email X ,  X  X CP X ,  X  X ecu-rity scan X ,  X  X olor print X ,  X  X ccount auditron X ,  X  X FD UI X ,  X  X MTP authentication X ,  X  X rint driver X , and  X  X mage adjustment X . Over 90% of the time all three domain experts for our case study agree that the SELRank algorithm performs better than other strate-gies such as ranking only based on the importance of customers, ranking with only considering the hyperlinks, and ranking with only considering the semantic links by using the PageRank algorithm. In addition, the SELRank algorithm provides a general framework for ranking in multiple intercorrelated networks. As for the computation complexity perspective, the efficiency of the SELRank algorithm can be easily boosted by directly applying some methods such as the extrapolation method [Kamvar et al. 2003b], the adaptive method [Kamvar et al. 2003], the block structure method [Broder et al. 2004; Kamvar et al. 2003a], etc. [Berkhin 2005], used in PageRank. In this article, a hybrid framework that integrates domain knowledge with data-driven mining algorithms is developed to analyze VOC data. We have successfully applied the integrated framework for analyzing the customer request data at Xerox Office Group. In particular, the analytical framework can enable the following analysis of VOC data: (1) disseminating VOC data into the corresponding feature clusters for understand-ing the main theme of the voice of the customer and identifying the evolving feature trends; (2) prioritizing customer feature requests. These analyses can help companies facilitate the feature development process and gain market competitiveness.
